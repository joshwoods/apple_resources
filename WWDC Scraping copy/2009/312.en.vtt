WEBVTT

00:00:13.019 --> 00:00:20.759
>> Name's John Rosasco, my colleague Benj Lipchak are here
today to present to you OpenGL ES Tuning and Techniques.

00:00:20.760 --> 00:00:24.640
So without further adieu, let's get going with this session.

00:00:24.640 --> 00:00:35.090
So in today's session, we're going to cover some of
the hardware architecture and some of the differences

00:00:35.090 --> 00:00:43.810
between the iPhone and iPod Touch family of devices
and the new iPhone 3G S and how the difference

00:00:43.810 --> 00:00:49.520
in those architectures will affect application
performance and how to program to them.

00:00:49.520 --> 00:00:57.660
We're then going to take a look at a list of top
ten performance optimizations that we've compiled,

00:00:57.659 --> 00:01:03.009
to try and help steer you clear of any pitfalls
that you may run into while writing your app.

00:01:03.009 --> 00:01:10.250
Once we've gone through that list and Ben just helped
me demonstrate how to approach and resolve some

00:01:10.250 --> 00:01:13.849
of those problems, we're going to look
at a section on finding bottlenecks.

00:01:13.849 --> 00:01:19.349
So let's go into hardware.

00:01:19.349 --> 00:01:28.329
The family of iPhone and iPod Touches prior to the iPhone 3G
S recently announced, are all based on the PowerVR MBX-lite,

00:01:28.329 --> 00:01:32.179
which you may have seen in some of the earlier sessions.

00:01:32.180 --> 00:01:38.940
These devices use a tile base deferred renderer
and we're going to talk some about how that differs

00:01:38.939 --> 00:01:46.590
from a stream renderer in today's session and this
family of devices supports OpenGL ES 1.1 only.

00:01:46.590 --> 00:01:50.740
There's an architectural difference that's relevant
and we'll talk to some details about that as well

00:01:50.739 --> 00:01:58.679
and there's a fairly hard limit on texture and
surface memory for the MBX-lite family of devices.

00:01:58.680 --> 00:02:04.410
Moving on to the new iPhone 3G S hardware architecture.

00:02:04.409 --> 00:02:13.490
This is based on the PowerVR SGX and this also uses a tile
based deferred renderer and it supports both OpenGL ES 1.1

00:02:13.490 --> 00:02:19.330
and 2.0, which implies of course it has, it's fully
programmable and has a hardware shading capability.

00:02:19.330 --> 00:02:25.620
The iPhone 3G S has a much higher
memory bandwidth capability

00:02:25.620 --> 00:02:30.560
and there's no real hard limit as you saw in the MBX family.

00:02:30.560 --> 00:02:38.180
You get more of a kind of linear drop off in performance
as you increase the load on, the memory load on the system.

00:02:38.180 --> 00:02:46.090
A couple of other notable differences with the
iPhone 3G S is that it has hardware VBO support,

00:02:46.090 --> 00:02:50.740
so VBO performance is increased because of
that and there's also stencil buffer support.

00:02:50.740 --> 00:02:54.000
So tile based deferred rendering.

00:02:54.000 --> 00:02:56.250
Let's talk about that a little bit.

00:02:56.250 --> 00:03:02.389
The slide here is showing what a stream rendering
GPU and that's kind of a conventional GPU that many

00:03:02.389 --> 00:03:06.519
of you may have programmed prior
to the iPhone family of GPU's

00:03:06.520 --> 00:03:11.730
The sudo code that you're seeing
there at the top is relatively simple

00:03:11.729 --> 00:03:17.560
and there's an outer while loop there showing while there
are more rendering commands, compile a set of state changes

00:03:17.560 --> 00:03:24.469
and then take those state changes with some draw command
and effectively draw the data at that point in time.

00:03:24.469 --> 00:03:28.580
Once you've iterated over that full list of draw
commands and all the state changes that go with each

00:03:28.580 --> 00:03:35.469
of those draw commands, you go to this simple
set up of presenting the data on screen

00:03:35.469 --> 00:03:39.039
for view with the presentRenderBuffer call.

00:03:39.039 --> 00:03:44.259
So notice that's a pretty simple set of
sudo code and notice this is all-specific.

00:03:44.259 --> 00:03:51.849
This isn't really a CPU side sudo code you're looking at,
it's just what the GPU's doing to draw a single frame.

00:03:51.849 --> 00:03:56.310
So let's compare that to a tile based
deferred renderer that's on the iPhone,

00:03:56.310 --> 00:03:59.599
on the entire iPhone and iPod Touch family.

00:03:59.599 --> 00:04:04.319
This sudo code as you notice is a
little bit more sophisticated than it is

00:04:04.319 --> 00:04:06.719
for a streamer renderer, a little more complex.

00:04:06.719 --> 00:04:13.789
There is this initial highlighted code that you're
seeing here, essentially showing that each frame

00:04:13.789 --> 00:04:18.699
of rendering is cached, so all of the drawing
commands for that frame of rendering are cached

00:04:18.699 --> 00:04:23.099
and while there are more drawing commands on all the
state changes that influence those drawing commands

00:04:23.100 --> 00:04:33.370
that the system caches that to allow it to effectively
take advantage of how the scene data is arranged

00:04:33.370 --> 00:04:36.519
so that it can call and run at higher performance.

00:04:36.519 --> 00:04:43.240
So once that data is all cached, each frame of data
is divided effectively into screen tiles and a list

00:04:43.240 --> 00:04:46.810
of drawing commands is created for each of those tiles.

00:04:46.810 --> 00:04:54.139
So once you've done that division, you know what's
required to draw each tile and all the drawing commands,

00:04:54.139 --> 00:05:02.399
the set of tiles for the frame buffer is iterated
over and each of those tiles requires that the color,

00:05:02.399 --> 00:05:05.629
the depth and the stencil buffers are all loaded.

00:05:05.629 --> 00:05:11.959
Then the visibility of the pixels for that tile
is determined using that list of drawing commands.

00:05:11.959 --> 00:05:18.659
Then the fragment shader is executed
for those visible pixels and the color,

00:05:18.660 --> 00:05:23.390
depth and stencil buffers are then stored out.

00:05:23.389 --> 00:05:30.990
So once each of the entire set of tiles has been
processed, the data is presented on screen as it was simply

00:05:30.990 --> 00:05:34.490
with the present RunnerBuffer as in the previous slide.

00:05:34.490 --> 00:05:38.879
So all this sophisticated sudo code, why
is that relevant to your application?

00:05:38.879 --> 00:05:42.370
There's a couple of reasons.

00:05:42.370 --> 00:05:49.030
Specifically I guess starting with while, why that
more complicated rendering model to begin with.

00:05:49.029 --> 00:05:57.259
Well effectively, that TBDR is set up to do
better on chip utilization of data essentially.

00:05:57.259 --> 00:06:03.370
So you're not doing as many memory accesses as if you
just constrain the drawing to a single tile worth of data,

00:06:03.370 --> 00:06:08.360
frame buffer data and all the drawing command associated
with it, you can keep all that processing on chip

00:06:08.360 --> 00:06:12.400
so it makes for a much higher performance GPU.

00:06:12.399 --> 00:06:19.889
So you have this higher performance but there is a couple
of caveats that are associated with that and that is

00:06:19.889 --> 00:06:27.089
at any time that you have a drawing command that has
a dependency, a downstream dependency in the stream

00:06:27.089 --> 00:06:34.959
of rendering, it can cause a performance problem on
this architecture that is a bit dissimilar to that

00:06:34.959 --> 00:06:40.769
of a stream renderer and some examples of those rendering
commands with these dependencies are frame-buffer binds,

00:06:40.769 --> 00:06:44.959
read pixels calls and anything that does texture updating.

00:06:44.959 --> 00:06:48.310
So let's take a look at an ideal kind of frame architecture.

00:06:48.310 --> 00:06:54.110
If you take all of those things in mind, what is it that you
need to do, how do you need to lay out your frame drawing

00:06:54.110 --> 00:07:00.639
and all the commands there in such that you're not
going to violate this TBDR architecture and you're going

00:07:00.639 --> 00:07:04.250
to help it along to do the fastest frame rendering it can.

00:07:04.250 --> 00:07:13.589
So the beginning of this frame, it's always advisable on
this TBDR to avoid texture updates in general and that is

00:07:13.589 --> 00:07:21.379
because in order for the TBDR to cache entire frames
of rendering, anytime you do a texture modification,

00:07:21.379 --> 00:07:25.899
the TBDR has to make a copy of that data because there
could be some drawing that's going to happen with that

00:07:25.899 --> 00:07:30.250
and if it's caching a frame's worth of rendering
and it needs to be able to process it, it may,

00:07:30.250 --> 00:07:31.970
it has to make another copy of that data.

00:07:31.970 --> 00:07:37.780
So that's why the comment you see here on the slide
about avoiding this if possible but if you do need

00:07:37.779 --> 00:07:43.000
to do texture updates during your frame
rendering, rather than just pre-computing them

00:07:43.000 --> 00:07:46.089
and binding textures, do them at
the beginning of your frame.

00:07:46.089 --> 00:07:50.699
That way you won't cause a flush and
interruption in mid-frame while you're rendering.

00:07:50.699 --> 00:07:56.430
Down below that is the initial call to bind the framebuffer.

00:07:56.430 --> 00:08:04.310
So you'd bind your framebuffer there, you do your clear and
then any other GL commands in the frame and then getting

00:08:04.310 --> 00:08:08.850
down toward the end, the last draw command is listed there.

00:08:08.850 --> 00:08:15.340
And then if you have to do readpixels, try to avoid that if
possible because it's very expensive on the architecture,

00:08:15.339 --> 00:08:18.949
but some applications actually require that.

00:08:18.949 --> 00:08:22.930
Do that at the very end of the frame for the same
reason, you don't interrupt the command stream and you,

00:08:22.930 --> 00:08:29.509
kind your kind of, this laminar
flow and the high frame rate going.

00:08:29.509 --> 00:08:37.379
So let's move into that top ten list we were talking about
earlier in the intro and I'm going to hand it over to Benj

00:08:37.379 --> 00:08:40.379
to describe how we're going to
go about attacking these items.

00:08:40.379 --> 00:08:41.519
>> Thanks John.

00:08:41.519 --> 00:08:44.259
So hi, I'm Benj.

00:08:44.259 --> 00:08:50.480
John and I thought it would be fun for this
session to artificially construct a demo app

00:08:50.480 --> 00:08:53.759
in our laboratory which does everything wrong.

00:08:53.759 --> 00:08:58.439
So all of those top ten list items
you just saw, ignore them all

00:08:58.440 --> 00:09:02.490
and it basically serves an example of how not to do things.

00:09:02.490 --> 00:09:07.990
So that way one by one we can turn on the right way
of doing things and see the performance improvement.

00:09:07.990 --> 00:09:15.070
And one thing I'll say up front is that we targeted
OpenGL ES 2.0 with this app and that's primarily just

00:09:15.070 --> 00:09:19.440
because the last item in the top
ten list is all about shaders.

00:09:19.440 --> 00:09:27.490
But all the rest of the tips applied to both OpenGL
ES 1.1 and 2.0 and so not only this iPhone 3G S

00:09:27.490 --> 00:09:32.970
which we'll be demoing on, but also
other iPhones and iPod Touches.

00:09:32.970 --> 00:09:43.320
So let me describe the app to you while I run it in the
simulator, just so you can see what I'm talking about.

00:09:43.320 --> 00:09:46.200
Bring down the heads up display.

00:09:46.200 --> 00:09:53.520
OK, so the spheres that you're seeing spinning around
there, those are actually four sided polyhedral

00:09:53.519 --> 00:09:59.289
that have been tessellated recursively a bunch
times in order to increase our vertex load,

00:09:59.289 --> 00:10:01.789
each time pushing the vertices out to radius 1.

00:10:01.789 --> 00:10:04.500
So that's why they look like spheres.

00:10:04.500 --> 00:10:10.529
And each of the original faces of the
tetrahedron has a different rendering state

00:10:10.529 --> 00:10:13.759
and so it has different shaders, different textures.

00:10:13.759 --> 00:10:22.319
Some of the ones you can see there, you've got a picture
of the Earth plastered onto one side, you've got,

00:10:22.320 --> 00:10:26.940
you can see the colorful side, that's actually
the normals being visualized, the face normals.

00:10:26.940 --> 00:10:34.050
So you can see the tessellation One of those
sides has kind of a polished sea stone look to it.

00:10:34.049 --> 00:10:35.039
It's got a fong shader.

00:10:35.039 --> 00:10:45.219
And the fourth side is using blending to toss out some
of the pixels and keep the rest of them semitransparent.

00:10:45.220 --> 00:10:48.529
So then we take that sphere, we've got
seven of them going from the foreground

00:10:48.529 --> 00:10:53.179
out into the distance and so this is pretty simple demo app.

00:10:53.179 --> 00:10:59.709
There's no bunnies being inflated,
there's no cars with environmental mapping

00:10:59.710 --> 00:11:02.970
with funnel turn being twisted.

00:11:02.970 --> 00:11:09.930
So you might ask, what could possibly go
wrong here and the answer is about ten things.

00:11:10.940 --> 00:11:18.410
So with that I would like to official conclude our
use of the simulator in this session and that is

00:11:18.409 --> 00:11:22.659
because simulator is a great prototyping tool,

00:11:22.659 --> 00:11:26.699
but it has drastically different performance
characteristics than the target devices.

00:11:26.700 --> 00:11:30.940
And so I'm going to switch over to the phone now.

00:11:30.940 --> 00:11:41.620
Nice. OK. Where you can see what is basically
a slide show of the sphere family vacation,

00:11:41.620 --> 00:11:46.690
running at about 6, 6 1/2 frames per second in there.

00:11:46.690 --> 00:11:51.530
And so with that I'm going to bring
up a tool that you should use as part

00:11:51.529 --> 00:11:54.980
of your performance tuning arsenal
and that's called Instruments.

00:11:54.980 --> 00:12:00.550
And you can see there is an OpenGL ES template here.

00:12:00.549 --> 00:12:03.049
We're going to choose that.

00:12:03.049 --> 00:12:10.699
I'm going to attach to our running
process and I'm going to click Record.

00:12:10.700 --> 00:12:18.900
And at this point, well you can
notice the CPU is pretty much pegged.

00:12:18.899 --> 00:12:22.199
This is the CPU load down here.

00:12:22.200 --> 00:12:29.920
But what I'm interested right now in is the Core Animation
frames per second, which is showing about the same thing

00:12:29.919 --> 00:12:32.610
as we're seeing on screen there
with the frames per second counter.

00:12:32.610 --> 00:12:34.539
Getting about 6 frames per second.

00:12:34.539 --> 00:12:38.360
One interesting thing you should note
about core animation frames per second,

00:12:38.360 --> 00:12:42.879
this is the number of frames per second
being sent to the compositing engine.

00:12:42.879 --> 00:12:48.679
So if you're doing off screen rendering to
FBO, that's not counted against this limit.

00:12:48.679 --> 00:12:54.789
So here we are with our OptimizeMe App,
called OptimizeMe, you can guess why.

00:12:54.789 --> 00:12:59.899
We starting off at around 6 frames per
second and it's totally broken state

00:12:59.899 --> 00:13:05.379
with ignoring all the top ten list items, so
this is a good time to send it back to John

00:13:05.379 --> 00:13:08.250
to talk about those first top ten list items.

00:13:08.250 --> 00:13:10.000
>> OK thanks Benj.

00:13:10.000 --> 00:13:11.860
Let's get started on that top ten list.

00:13:11.860 --> 00:13:16.810
The first on our list is avoiding
alpha test and fragment shader discard.

00:13:16.809 --> 00:13:21.629
Alpha test is a costly operation on these TBDR renderers.

00:13:21.629 --> 00:13:28.439
It effectively defeats the hidden surface, hidden surface
removal and the culling, the core screen culling that can,

00:13:28.440 --> 00:13:33.970
that the you know, gathering all that
frame data allows the TBDR to do.

00:13:33.970 --> 00:13:42.050
Usually alpha test can be, that operation can be very
well simulated or duplicated using frame buffer blending,

00:13:42.049 --> 00:13:46.909
especially if you have a fragment shader in combination
so you can modulate the alpha value and have it feed

00:13:46.909 --> 00:13:51.929
into the blending functions that you've got set
on the frame buffer to achieve the same effect

00:13:51.929 --> 00:13:55.099
that you would doing an alpha test kind of discard.

00:13:55.100 --> 00:14:03.899
The use of the keyword discard and a fragment
shader under ES 2.0, is also an expensive operation

00:14:03.899 --> 00:14:09.529
because it causes the GPU to have to
go through an expensive visibility test

00:14:09.529 --> 00:14:11.740
for all the fragments that are going to be generated.

00:14:11.740 --> 00:14:15.549
So the use of discard is discouraged in general.

00:14:15.549 --> 00:14:19.709
So let's move on to number two.

00:14:19.710 --> 00:14:22.670
Don't depth-sort opaque surfaces.

00:14:22.669 --> 00:14:29.029
Conventional kind of stream renderer's it's natural to
do a depth-sorting of opaque surfaces so that you can,

00:14:29.029 --> 00:14:34.939
so that you can basically take the data and
at the depth test, discard the fragments.

00:14:34.940 --> 00:14:40.960
Because the TBDR is doing that for you and you know,
doing this core stream culling that we're talking

00:14:40.960 --> 00:14:47.670
with the hidden surface removal, you're effectively
kind of defeating that mechanism by depth,

00:14:47.669 --> 00:14:52.409
doing the depth-sort of the opaque surfaces, and
you're essentially performing a redundant operation.

00:14:52.409 --> 00:14:54.459
So it's kind of expensive.

00:14:54.460 --> 00:15:02.310
When it comes to the draw order of your data in
your scene, there is an advisable kind of pattern

00:15:02.309 --> 00:15:05.239
of these three latter bullets that
you're seeing on the slide.

00:15:05.240 --> 00:15:10.639
And that is to render the opaque object first
and that is effectively because you're kind

00:15:10.639 --> 00:15:18.580
of successively refining your frame data and if you can, the
more, the larger chunks of stuff you can get rid of earlier

00:15:18.580 --> 00:15:22.040
on in your frame rendering, the
higher performance it will be.

00:15:22.039 --> 00:15:28.620
By rendering these big opaque objects first, all of the
fragment processing, vertex processing, all of the blending,

00:15:28.620 --> 00:15:33.860
all of those operations on anything that would
have been obscured essentially gets avoided.

00:15:33.860 --> 00:15:38.350
If you do need to use discard however,
given that it is expensive,

00:15:38.350 --> 00:15:40.450
it's nice that you have that second in the list here.

00:15:40.450 --> 00:15:44.580
Because those opaque objects may prevent
that operation as well, but put those second.

00:15:44.580 --> 00:15:51.480
And then finally, because blending, anything that's
blended is going to depend on destination fragments

00:15:51.480 --> 00:15:54.670
in your frame buffer, you need to
render those in sorted order last.

00:15:54.669 --> 00:16:02.039
So going back through the list, render opaque objects first,
then render each of these kind of implies a grouping right.

00:16:02.039 --> 00:16:11.309
So if you have like a scene of data that you're rendering,
it's sometimes tough in your application to take that domain

00:16:11.309 --> 00:16:16.789
of how your scene rendering is done and shuffle it
around, shuffle the data around so that it's grouped

00:16:16.789 --> 00:16:18.319
such that it works well with the renderer.

00:16:18.320 --> 00:16:23.900
But if you can group all of your opaque objects
so that and then those with discard and then those

00:16:23.899 --> 00:16:29.409
with blending together, it will allow you to kind of execute
in this order and get the optimal kind of performance

00:16:29.409 --> 00:16:33.819
out of these renderer's So moving on to number three.

00:16:33.820 --> 00:16:37.040
Number three is a little bit more of generic advice.

00:16:37.039 --> 00:16:43.969
A lot of today's session that Benj and I are doing
is really targeted at kind of device specifics.

00:16:43.970 --> 00:16:50.350
You know you saw the earlier sessions with the kind
of foundation layer that Michael and Alex built

00:16:50.350 --> 00:16:57.460
and then the cool rendering techniques and you know, kind
of accessorizing you can do that Alex and Luke described.

00:16:57.460 --> 00:17:05.019
Well this session is you know, about the tuning
and it's kind of, it's got pieces of both kind

00:17:05.019 --> 00:17:09.400
of general GL programming advice
and others that are device specific.

00:17:09.400 --> 00:17:14.019
This one kind of falls into that general programming
area where you want to batch as much drawing,

00:17:14.019 --> 00:17:21.430
general GL programming that is, that you want to batch
as much drawing as you can and minimize state changes.

00:17:21.430 --> 00:17:25.680
Every time you issue a draw call,
there's an overhead associated with it.

00:17:25.680 --> 00:17:30.820
So naturally, if you, if you've got 10,000 vertices
to render, if you issue one draw call to do that,

00:17:30.819 --> 00:17:34.189
you're going to get much higher performance
than if you issue 100 calls to do that.

00:17:34.190 --> 00:17:41.150
So there's an example here showing that kind of competition

00:17:41.150 --> 00:17:46.060
between application domain space problems
and pipeline efficiency domain space.

00:17:46.059 --> 00:17:52.940
So pipeline efficiency, there's a couple of these
examples in this presentation that are like this and Benj

00:17:52.940 --> 00:17:58.860
and I realize the hazard of presenting the wrong way to do
stuff on the slides, but we thought it was worthwhile doing

00:17:58.859 --> 00:18:03.089
because hopefully it's triggering you know, one or
two people to say hey, wait, that's how I'm doing it.

00:18:03.089 --> 00:18:10.369
So the better of these two examples is at the top, the
top condition of that if and that's the batched rendering.

00:18:10.369 --> 00:18:17.379
Where a single VBO is bound on the first program statement,
second to that a leaf texture is drawn and then an array

00:18:17.380 --> 00:18:21.430
of leaves is drawn with that rendering state.

00:18:21.430 --> 00:18:30.019
This atrocious example in the else condition has a
draw command that's essentially a leaf draw method,

00:18:30.019 --> 00:18:36.190
is up here and it's iterating over all of the leaves,
asking the tree which leaf it is and then the leaves,

00:18:36.190 --> 00:18:40.799
you know you have this nice cool oops thing with
this encapsulation where it knows how to draw itself,

00:18:40.799 --> 00:18:46.529
but in the process it disregards the rendering state of the
rest of the pipeline and completely thrashes it with all

00:18:46.529 --> 00:18:50.970
of these instances to draw where it's binding
the VBO redundantly and it's extra etc,

00:18:50.970 --> 00:18:58.600
etc. So that is a paramount performance
issue and it happens.

00:18:58.599 --> 00:19:00.009
It's a pretty pervasive problem.

00:19:00.009 --> 00:19:04.640
So try to keep the lookout for that when you're
looking to tune your application or better yet,

00:19:04.640 --> 00:19:07.140
when you're architecting your scene graph to begin with.

00:19:07.140 --> 00:19:15.259
So with those three, I'm going to hand it back to Benj and
he's going to apply some of that to our broken application.

00:19:15.259 --> 00:19:16.129
>> OK thanks.

00:19:16.130 --> 00:19:18.030
Thanks John.

00:19:18.029 --> 00:19:22.680
All right, the first stuff that John
talked about is really easy one to show.

00:19:22.680 --> 00:19:26.950
Here you're seeing one of our slow fragment shaders.

00:19:26.950 --> 00:19:31.410
So we have slow versions of our shaders
and fast versions for this demo app.

00:19:31.410 --> 00:19:40.009
Here you see we are discarding pixels if the computed
alpha value in the fragment shader is close to 0

00:19:40.009 --> 00:19:44.730
and also if the incoming color is non-opaque.

00:19:44.730 --> 00:19:50.009
So if those two conditions are true,
we are discarding our pixel entirely.

00:19:50.009 --> 00:19:54.809
This is similar to alpha test in ES 1.1.

00:19:54.809 --> 00:20:01.169
Now in the fast version of the shader, we just remove
the discard entirely and we turn on blending and we end

00:20:01.170 --> 00:20:03.570
up getting the same result on the frame buffer.

00:20:03.569 --> 00:20:05.929
So that was an easy one to show.

00:20:05.930 --> 00:20:14.320
Next tip that John talked about was about not
spending CPU time sorting your opaque geometry.

00:20:14.319 --> 00:20:20.740
Some of the sub-bullets there were that
you do want to draw your opaque stuff first

00:20:20.740 --> 00:20:23.039
and then anything that's discarded or blended.

00:20:23.039 --> 00:20:31.059
So you can see in our code here, we are drawing
the first three quadrants of our spheres opaque,

00:20:31.059 --> 00:20:35.579
so we're drawing those first, followed by fourth quadrant,

00:20:35.579 --> 00:20:41.079
which is the one that we use discard or
we replace the discard with blending.

00:20:41.079 --> 00:20:42.799
And we draw that last.

00:20:42.799 --> 00:20:50.500
So that brings me to the next one, which is about state
grouping, and this is the example of how not to do it.

00:20:50.500 --> 00:20:59.619
So you can see here, we are looping over all seven
of our spheres and for each sphere we're setting

00:20:59.619 --> 00:21:06.629
up a rendering state for the first quadrant, drawing that
quadrant, setting up rendering state for the next quadrant,

00:21:06.630 --> 00:21:09.360
drawing that one and so on, for all four quadrants.

00:21:09.359 --> 00:21:13.449
Then we go to the next object and do
that same thing over and over again.

00:21:13.450 --> 00:21:18.819
So for every object we're switching between every
state, that's the suboptimal way of doing it.

00:21:18.819 --> 00:21:23.689
Instead, we recommend you group your
state like John was talking about.

00:21:23.690 --> 00:21:30.019
And so here, we've drawn the pieces of each object that
use the initial state, then we switch to state one.

00:21:30.019 --> 00:21:35.940
So here, you're seeing setting up the first state, then
we loop over all objects and drawing just the pieces

00:21:35.940 --> 00:21:42.940
of those objects that use that state and we move on
to the next state, loop over all the objects there.

00:21:45.099 --> 00:21:48.719
The last one I want to talk about
here is batching your data.

00:21:48.720 --> 00:21:52.519
So when I said that we artificially
constructed this demo app in our laboratory,

00:21:52.519 --> 00:22:03.170
I failed to mention it's an evil laboratory and we are
drawing each triangle individually with its own draw call.

00:22:03.170 --> 00:22:07.789
The better way of doing this, infinitely
better, is to batch up your draws

00:22:07.789 --> 00:22:09.829
so you're drawing lots of triangles all at once.

00:22:09.829 --> 00:22:18.699
So in this case we are drawing and entire quadrant at a time
and it makes a huge difference and I'd like to demonstrate.

00:22:18.700 --> 00:22:21.340
So if we can bring up the phones side by side.

00:22:21.339 --> 00:22:25.759
I think for starters, so this is where
we left off around 6 frames per second.

00:22:25.759 --> 00:22:29.220
I already have Instruments running here.

00:22:29.220 --> 00:22:38.309
So I want you to keep your eye on the CPU, because
not batching up your draws, not combining like state,

00:22:38.309 --> 00:22:45.049
has a pretty nasty CPU overhead required for
validating and setting up each draw call.

00:22:45.049 --> 00:22:51.129
So I'm pulling up the heads of displays, I'm going
to turn on state grouping and batching and I'll have

00:22:51.130 --> 00:23:00.680
to keep animating and there you can see we've just
jumped up from 6 to about 15 or 16 frames per second

00:23:00.680 --> 00:23:05.740
and notice the CPU load here has
gone down to almost nothing.

00:23:05.740 --> 00:23:11.120
So with that let me send it back to John to
talk about the next bunch of top ten tips.

00:23:11.119 --> 00:23:14.199
>> OK. Thanks Benj.

00:23:14.200 --> 00:23:21.370
So four and five are regarding data management with
number four being proper vertex data management.

00:23:21.369 --> 00:23:27.609
The inputs to GL as you know, are vertices and pixels
and how you treat those vertices is very important.

00:23:27.609 --> 00:23:35.349
Probably the easiest advice you can get for
better kind of vertex handling is to use VBO's.

00:23:35.349 --> 00:23:42.929
VBO's are really dovetailed in really easily
with the vertex array specification in GL

00:23:42.930 --> 00:23:45.490
and it's a very simple matter to use VBO.

00:23:45.490 --> 00:23:48.019
So if you're not using them already,
go ahead and make that switch.

00:23:48.019 --> 00:23:50.650
It's a very comfortable change.

00:23:50.650 --> 00:23:58.210
The second tip that's very important on the iPhone
architectures is to keep the, keep the vertices's,

00:23:58.210 --> 00:24:02.590
the vertex data each of the attributes for you
vertex data, aligned on four white boundaries.

00:24:02.589 --> 00:24:07.129
And that may include increasing the size of
the vertex if it gets you better alignment

00:24:07.130 --> 00:24:13.500
and there's always some empiricism involved in there but
you know, if you can put you know, three component normals

00:24:13.500 --> 00:24:18.309
on 4 byte boundaries, you despite the fact
that you have an additional component there

00:24:18.309 --> 00:24:21.049
and you know the memory associated with it,
you may actually get higher performance.

00:24:21.049 --> 00:24:22.690
So keep that in mind.

00:24:22.690 --> 00:24:26.150
Use of smaller data types, do some
empiricism around that too.

00:24:26.150 --> 00:24:30.890
If you can get away with a short instead of a float
for instance or an unsigned byte instead of a short,

00:24:30.890 --> 00:24:36.430
by all means take a look at those and conserve
bandwidth in the system, especially embedded systems.

00:24:36.430 --> 00:24:38.580
And then interleaving the vertex data.

00:24:38.579 --> 00:24:44.199
With these diagrams on the right just showing a
simple way to improve cache locality so that the

00:24:44.200 --> 00:24:49.069
when a device fetches individual vertices,
it's got all of the relevant information

00:24:49.069 --> 00:24:52.139
in a kind of cache coherent friendly manner.

00:24:52.140 --> 00:25:00.380
So a small example here of proper vertex data alignment
with the good case on the top, faster, smaller,

00:25:00.380 --> 00:25:04.760
interleave the line vertices and the bad case on the bottom.

00:25:04.759 --> 00:25:08.059
The top example is showing 16 bytes per vertex.

00:25:08.059 --> 00:25:14.129
We've got a struct there defined and so
we have an array of structs effectively

00:25:14.130 --> 00:25:21.300
and each of the types is unsigned.I'm sorry,
shorts rather and they're four components each.

00:25:21.299 --> 00:25:29.409
So notice that as I alluded to a moment ago, that the
normal pointer there is using the size of that structure

00:25:29.410 --> 00:25:33.830
as the stride between each subsequent normal.

00:25:33.829 --> 00:25:38.049
And although there's additional memory
associated with that, this is higher performance.

00:25:38.049 --> 00:25:40.220
So keep that in mind when you're constructing it.

00:25:40.220 --> 00:25:42.059
It doesn't matter the number of vertex attributes.

00:25:42.059 --> 00:25:48.599
The example shown here is in ES 1.1, it's the
same you know, general idea in 2.0 certainly.

00:25:48.599 --> 00:25:55.279
On the bottom the slow performing example, is using
a bigger data type for the vertex information.

00:25:55.279 --> 00:25:56.559
It's using floats.

00:25:56.559 --> 00:25:59.069
Your app may need that, it may not.

00:25:59.069 --> 00:26:03.519
And then it's using shorts for the normals
and in this case, it's three components each.

00:26:03.519 --> 00:26:11.029
When that data adds up and in the case of the vertex data,
those are well aligned because they're four bytes apiece

00:26:11.029 --> 00:26:16.389
and there's three components so no problem, but the
normal data is not and each of those has to be fetched

00:26:16.390 --> 00:26:22.100
on a per vertex basis and that's going to slow your
app down if your vertex data is arranged as such.

00:26:22.099 --> 00:26:26.750
So moving on to texture data management.

00:26:26.750 --> 00:26:28.059
Tip number five.

00:26:28.059 --> 00:26:33.399
A really easy thing is use compressed textures and
now I hope I'm not hammering an issue that's you know,

00:26:33.400 --> 00:26:40.110
going to be the proverbial beating the dead horse
here but, the compressed textures are a great way

00:26:40.109 --> 00:26:44.939
to improve the memory efficiency of your
application and reduce the bandwidth demands.

00:26:44.940 --> 00:26:52.180
Hopefully some of you have had a chance to work with
the texture tool in the PBRTC compressed texture format.

00:26:52.180 --> 00:26:58.180
If you have you probably noticed that not only can you
get higher performance because you're putting less demand

00:26:58.180 --> 00:27:02.680
on the system, but the compressed textures
actually will give you higher quality too

00:27:02.680 --> 00:27:04.730
and with lossy compression, that's
totally counterintuitive.

00:27:04.730 --> 00:27:06.670
It's like why would that give me higher quality?

00:27:06.670 --> 00:27:14.090
Well even the 4 bit per component, compressed
texture format, PBRTC, is eight time smaller,

00:27:14.089 --> 00:27:19.759
it's 1/8th the size of a 4 component
unsigned byte texture format.

00:27:19.759 --> 00:27:23.619
So that means that if you double the
size of the textures you're using

00:27:23.619 --> 00:27:26.929
in two dimensions you're still using
only half the memory footprint.

00:27:26.930 --> 00:27:33.000
And if you take a look at those textures side by
side and Benj will go into that in some detail

00:27:33.000 --> 00:27:37.210
when we take a look there, you'll notice that most

00:27:37.210 --> 00:27:40.740
of the time you'll get much better
quality with the compressed textures.

00:27:40.740 --> 00:27:43.690
Now there are some exceptions to that
and that's application domain specific.

00:27:43.690 --> 00:27:48.620
Certainly if you're doing a lot of textures that
are line art or vector based and you have you know,

00:27:48.619 --> 00:27:54.009
real low frequency images with high contrast edges
and these sort of things, you can sometimes see some

00:27:54.009 --> 00:27:58.309
of the ringing artifacts and macroblocks
that you get out of texture compression.

00:27:58.309 --> 00:28:03.279
But for anything that comes off of a camera or anything
that's even remotely analog and many of the kind

00:28:03.279 --> 00:28:07.629
of simple textures for games and things like
that, they work great as compressed textures.

00:28:07.630 --> 00:28:10.800
Much higher quality, much higher performance.

00:28:10.799 --> 00:28:15.389
Use of mipmapping, now that's an old adage
that goes with any GL application programming.

00:28:15.390 --> 00:28:19.660
There's an additional one third
memory allocation required for that.

00:28:19.660 --> 00:28:28.360
But on the back end, when the texture is processed and those
texels are fetched, the CPU effectively is allowed to fetch

00:28:28.359 --> 00:28:34.529
from smaller texture levels and that
can really conserve on the bandwidth.

00:28:34.529 --> 00:28:40.069
Going hand in hand with mipmapping is
deciding on what type of filtering to do.

00:28:40.069 --> 00:28:46.189
If you use mipmapping, it's kind of natural to think OK,
well I'm going to do tri-linear filtering so I can look

00:28:46.190 --> 00:28:51.430
at it not only in the neighborhood of the current
level but the levels that are before and after it.

00:28:51.430 --> 00:28:56.560
That's a natural thing to do but, note that that takes
double the operations than a bi-linear filter does.

00:28:56.559 --> 00:29:02.399
So you may want to do that quick switch of
that text parameter to geo linear to try

00:29:02.400 --> 00:29:06.910
to the bi-linear filtering mode to see if it actually
affects you rendering quality and if it doesn't

00:29:06.910 --> 00:29:11.950
by all means turn that to bi-linear
and save yourself some performance.

00:29:11.950 --> 00:29:14.670
The next bullet here is use texture atlases.

00:29:14.670 --> 00:29:21.230
The use of texture atlases, well it doesn't jive too well
with the use of mipmapping because you're going to get kind

00:29:21.230 --> 00:29:25.089
of filtering artifacts when you try
to go through that mipmapping chain.

00:29:25.089 --> 00:29:29.240
That's really not a memory bandwidth saving
tip, it's more of a state management tip.

00:29:29.240 --> 00:29:35.029
So if you're able to create this mothership texture
and it's got you know, fifty little textures in it

00:29:35.029 --> 00:29:42.399
and you can do a single texture bind and then do, use
texture coordinates and maybe some scales and biases

00:29:42.400 --> 00:29:47.390
to extract the texels you want from that, you're going
to get a lot higher performance than if you go through

00:29:47.390 --> 00:29:51.200
and you know you got a single character and
he's got you know, fourteen texture on them

00:29:51.200 --> 00:29:55.130
and doing fourteen different texture
binds to accessorize that guy.

00:29:55.130 --> 00:29:57.590
So use texture atlases when you can.

00:29:57.589 --> 00:30:04.709
We talked about avoiding mid-frame texture updates
and again, that's a memory kind of footprint issue

00:30:04.710 --> 00:30:10.340
and again there's a copy associated with
that on the TBDR, so those should be avoided.

00:30:10.339 --> 00:30:22.959
So a code sample here is a simple loading if a
compressed texture, mipmap stack and these textures,

00:30:22.960 --> 00:30:26.120
if you haven't had a chance, if you haven't had
a chance to work with the compressed textures,

00:30:26.119 --> 00:30:36.789
you use the offline texture tool that's part of the iPhone
developer SDK to compute these texture levels offline

00:30:36.789 --> 00:30:40.069
and then just go through and iterate overall levels.

00:30:40.069 --> 00:30:45.669
We talked about the filtering mode, bi-linear versus
tri-linear, that's the second, the text parameter line

00:30:45.670 --> 00:30:51.210
that you're seeing there with the last argument
there dictating whether you're doing bi-linear

00:30:51.210 --> 00:30:52.360
or tri-linear filtering.

00:30:52.359 --> 00:30:57.059
If you want to do bi-linear filtering, you
simply switch that last parameter to GL linear.

00:30:57.059 --> 00:31:03.899
Moving down there, you're always going to have to set your
you know, the commensurate kind of mad filter and rat modes,

00:31:03.900 --> 00:31:07.180
but that's not really relevant to this example
and then just iterate over the text levels

00:31:07.180 --> 00:31:08.910
and load the texture, the compressed texture.

00:31:08.910 --> 00:31:10.630
It's fairly simple.

00:31:13.589 --> 00:31:18.990
So minimizing memory footprint, this is a little bit
of a rehash but whenever you go to look at performance

00:31:18.990 --> 00:31:26.630
of an application, one of the toughest thing can be
like where do I look and how do I tune this application?

00:31:26.630 --> 00:31:35.140
Well if you generally are a good steward of the
bytes on your system and you're very conscientious

00:31:35.140 --> 00:31:41.920
about how you use them, you'll have a lot less trouble
kind of diagnosing performance problems down the way.

00:31:41.920 --> 00:31:50.610
So the use of these smaller and more efficient texture and
vertex form and the mid-frame texture updates of course,

00:31:50.609 --> 00:31:52.990
but also consider how your depth buffer is allocated.

00:31:52.990 --> 00:31:57.380
Do you need a depth buffer and if you do,
can you get away with 16 bits versus 32?

00:31:57.380 --> 00:32:01.220
The same argument can be made for color buffer set up.

00:32:01.220 --> 00:32:08.890
The visible color buffer when you specify the dictionary
for the EAGL Layers properties that you probably saw in some

00:32:08.890 --> 00:32:14.820
of the earlier sessions, you can reduce the size of the
color buffer if it's not needed and any of these steps,

00:32:14.819 --> 00:32:21.809
all of these things in cooperation will
reduce the bandwidth pressure on the system

00:32:21.809 --> 00:32:23.529
and will increase the performance undoubtedly.

00:32:23.529 --> 00:32:29.059
So with that I'm going to hand it back
over to Benj for four, five and six.

00:32:29.059 --> 00:32:30.819
>> Thank you John.

00:32:30.819 --> 00:32:38.169
So this groups of tips was all about data management
and we're going to start by looking at vertex data.

00:32:38.170 --> 00:32:41.460
Here is an example of how not to store your geometry.

00:32:41.460 --> 00:32:47.950
This is code that is not using VBO's, so
we're using client side vertex arrays

00:32:47.950 --> 00:32:56.190
You'll notice there's no buffer object found and we malloc
our own data here, getting back a pointer to client memory.

00:32:56.190 --> 00:32:58.700
Pay no attention to this misalignment bytes term.

00:32:58.700 --> 00:33:01.700
I'll talk about that in just a moment.

00:33:01.700 --> 00:33:07.980
But our vertex array pointers are all pointers to
the actual client memory here and the code subsequent

00:33:07.980 --> 00:33:13.299
to this will then fill in our tessellated
geometry at this next vertex data pointer.

00:33:13.299 --> 00:33:20.869
So now, let me bring you to the VBO version of
this code, right up here, which looks very similar.

00:33:20.869 --> 00:33:29.289
Difference being we have a non-zero buffer object bound and
instead of calling malloc, we are calling GL buffer data

00:33:29.289 --> 00:33:33.389
to allocate memory and manage it for us by the GL.

00:33:33.390 --> 00:33:38.050
Now our vertex attribute pointers are no
longer actual pointers to client memory,

00:33:38.049 --> 00:33:43.470
instead they are offsets, starting
at 0, within our buffer object.

00:33:43.470 --> 00:33:48.710
And finally, we map our buffer object.

00:33:48.710 --> 00:33:55.610
So again, we have a CPU accessible pointer and we'll
continue to fill that data the same way as we did

00:33:55.609 --> 00:33:59.179
in the non-VBO case with our tessellated geometry.

00:33:59.180 --> 00:34:03.620
And later on, we'll unmap it before we draw with it.

00:34:03.619 --> 00:34:08.670
So now, let's talk about this misalignment bytes term.

00:34:08.670 --> 00:34:14.940
What better way to demonstrate how bad it is
to not have your vertex array data aligned,

00:34:14.940 --> 00:34:18.260
then to intentionally throw it off by a byte.

00:34:18.260 --> 00:34:25.980
So again, evil laboratory, so we're allocating, you
can see we're calculating our size for our allocation.

00:34:25.980 --> 00:34:28.440
We're just allocating an extra byte.

00:34:28.440 --> 00:34:34.960
All of our vertex array pointers, whether they're
in VBO's or not, are all offset by one byte

00:34:34.960 --> 00:34:39.829
and you'd be surprised the impact that
can have and you'll get to see it.

00:34:39.829 --> 00:34:42.750
So next, let's talk about texture data management.

00:34:42.750 --> 00:34:48.800
And for this I will talk about a couple
techniques, which are near and dear to my heart,

00:34:48.800 --> 00:34:55.090
well won't really talk about them, John
talked about them so I'm just going to show.

00:34:55.090 --> 00:35:00.500
So here, you see side by side,
uncompressed and compressed textures.

00:35:00.500 --> 00:35:07.230
So John talked about the performance gains, you're
probably familiar with wide use compressed textures

00:35:07.230 --> 00:35:16.219
for performance reasons but you may still be asking
yourself, why do I really want to use compressed textures,

00:35:16.219 --> 00:35:19.099
don't they degrade the image quality, not improve it.

00:35:19.099 --> 00:35:25.409
And so I'd like to spin it the other way and show
you in kind of an apples to apples comparison.

00:35:25.409 --> 00:35:34.389
On the left here you have 32 bit per pixel
uncompressed 128x128 dimension texture

00:35:34.389 --> 00:35:44.409
and for the exact same memory footprint cost, here is
a 512x512 2 bit per pixel PBRTC compressed texture.

00:35:44.409 --> 00:35:49.369
And you can probably see, I'll zoom
in for the people in the back row,

00:35:49.369 --> 00:35:56.730
just a little bit, but you know, huge difference here.

00:35:56.730 --> 00:35:59.280
So that's why we recommend using the compressed formats.

00:35:59.280 --> 00:36:04.990
You can actually, for the same cost,
get a much better image quality.

00:36:04.989 --> 00:36:09.139
And now if we can bring up the phone as well.

00:36:10.559 --> 00:36:17.269
I would like to show, actually if we can go full screen
for a moment on the phone, if we have that technology.

00:36:17.269 --> 00:36:26.039
Great. Because we'd like to, I'd like to look at the
furthest away spheres showing the Earth texture on them.

00:36:26.039 --> 00:36:28.029
I've freeze framed it.

00:36:28.030 --> 00:36:30.040
Look at the white sparklies.

00:36:30.039 --> 00:36:35.969
As I animate it again, you can kind of see
them shimmering off in the distance there.

00:36:35.969 --> 00:36:46.959
Now I'm going to turn on mipmapping and now once the,
once it spins around you can see the Earth again,

00:36:46.960 --> 00:36:50.670
no more shimmering, it's a nice, smooth Earth texture.

00:36:50.670 --> 00:36:52.909
So you're not getting those aliasing artifacts.

00:36:52.909 --> 00:37:06.579
Now if we can go split screen again, I'm going to
go to Instruments and going to start recording here.

00:37:06.579 --> 00:37:15.920
I want to show you the memory footprint
difference as we turn on alignment, OK,

00:37:15.920 --> 00:37:19.680
compressed textures is the one
we're mostly interested in in here

00:37:19.679 --> 00:37:23.839
and now this resource bytes metric,
I haven't talked about yet.

00:37:23.840 --> 00:37:29.850
This is all of the resources used by ES,
that includes textures, render buffers

00:37:29.849 --> 00:37:34.319
and on the iPhone 3G S, it includes vertex buffer objects.

00:37:34.320 --> 00:37:49.300
And I will tell this to keep animating and you can see that
the resource bytes went from about 40 megs to unde@r 20 megs,

00:37:49.300 --> 00:37:51.560
just from turning on the compressed textures.

00:37:51.559 --> 00:37:57.039
Now you might be thinking well, that 20 megs
still seems like a lot for this simple demo app,

00:37:57.039 --> 00:38:03.900
keeping the note about some of these, actually
all of the metrics sampled here by Instruments,

00:38:03.900 --> 00:38:07.070
these are sampled across the entire system.

00:38:07.070 --> 00:38:11.260
So what you're seeing there isn't
necessarily caused by your own app.

00:38:11.260 --> 00:38:17.850
There's lots of other things going on in the system, many
things layered on top of OpenGL ES, so keep that in mind.

00:38:17.849 --> 00:38:20.869
What you're seeing here isn't just caused by you.

00:38:20.869 --> 00:38:26.329
But if you make changes in your app, you can see
the differences as they affect the entire system.

00:38:26.329 --> 00:38:35.099
So we're now up to about 22 frames per second,
jumping around around 20, 22, up from the original 6.

00:38:35.099 --> 00:38:40.299
With that, I'd like to send it back to
John to talk about the last group of tips.

00:38:40.300 --> 00:38:42.500
>> OK thanks Benj.

00:38:42.500 --> 00:38:44.190
So moving on to number seven.

00:38:44.190 --> 00:38:53.000
Number seven is related to the iPhone compositing
system and how your GL application interacts

00:38:53.000 --> 00:38:56.860
with core animation in the layering system.

00:38:56.860 --> 00:39:02.150
It's, this is kind of an A or B kind of advice.

00:39:02.150 --> 00:39:09.570
It's relatively simple to just take your GL
and use your GL to draw your landscape content.

00:39:09.570 --> 00:39:14.730
Unfortunately, it's even simpler to use Core
Animation to do it, but the performance isn't as good.

00:39:14.730 --> 00:39:22.659
So try not to take that carrot of just doing a
layer transform and using Core Animation, you know,

00:39:22.659 --> 00:39:28.730
the layer property for Core Animation to do
your layer, to do your landscape transforms.

00:39:28.730 --> 00:39:35.349
There is, when you get a landscape event, you can simply
swap the width and height on your viewport calculations

00:39:35.349 --> 00:39:42.989
and do kind of a rotation about Z, to keep your model
upright when you're, when the device gets landscaped so.

00:39:42.989 --> 00:39:44.969
Moving on to tip number eight.

00:39:44.969 --> 00:39:47.459
Making your GL layer opaque.

00:39:47.460 --> 00:39:53.849
It's always a good idea in this compositing system,
you're going to have any number of layers there and

00:39:53.849 --> 00:39:59.089
but the best way to get the best performance
out of a compositing system is to make sure

00:39:59.090 --> 00:40:07.710
that all your 2D content is on- top, the GL content is
on the bottom, then opaque and it's a simple matter

00:40:07.710 --> 00:40:11.380
of setting the property on the layer
as in the example here, where you're,

00:40:11.380 --> 00:40:15.490
this is drawn directly from that
OpenGL ES template application

00:40:15.489 --> 00:40:17.979
that is created when you create a new project in Xcode.

00:40:17.980 --> 00:40:26.030
And it's simply a manner of obtaining a layer and setting
that property to ES and then that layer will be opaque

00:40:26.030 --> 00:40:32.970
and it will tell Core Animation not to be
compositing your GL content to things below it.

00:40:32.969 --> 00:40:35.569
So draw only when needed.

00:40:35.570 --> 00:40:43.600
It's like duh right, but there's a little bit of
a trap when it comes to writing code for embedded devices

00:40:43.599 --> 00:40:46.569
and that is that you're not plugged into the wall anymore.

00:40:46.570 --> 00:40:52.090
So if you're not plugged into the wall,
anytime you render and you keep the GPU

00:40:52.090 --> 00:40:55.050
and the CPU busy, it's eating up your battery.

00:40:55.050 --> 00:41:01.960
So you really want to take a look at your application
domain and say OK well, my data's not really that dynamic,

00:41:01.960 --> 00:41:06.199
maybe I can get away with 30 frames
a second or 15 rather than 60.

00:41:06.199 --> 00:41:13.149
So setting the animation interval, again
drawing on the ES template application,

00:41:13.150 --> 00:41:16.480
to a larger interval such that you're
not, you're just not just hammering away

00:41:16.480 --> 00:41:20.780
on the GPU can really be friendly
to your user's battery life.

00:41:20.780 --> 00:41:26.450
And then the other thing is, if your data is
really static, the example on the latter part

00:41:26.449 --> 00:41:30.480
of the slide is just stopping the
animation entirely and that is just a matter

00:41:30.480 --> 00:41:37.579
of invalidating the timer that's actually
generating the method calls into your EAGL class.

00:41:37.579 --> 00:41:40.069
In your drawing class.

00:41:40.070 --> 00:41:46.800
So write efficient shaders is our
number ten on the top ten list.

00:41:46.800 --> 00:41:51.900
And number ten is special and it gets
an asterisk because it's not applicable

00:41:51.900 --> 00:41:55.430
to both the MBX family and the SGX family.

00:41:55.429 --> 00:42:03.609
It's applicable just to the iPhone 3G
S, which is SGX based and OpenGL ES 2.0.

00:42:03.610 --> 00:42:12.809
So here's some general tips on
writing, on writing efficient shaders.

00:42:12.809 --> 00:42:19.029
Let's go into the, just right into the general tips.

00:42:19.030 --> 00:42:22.810
And that is we talked a little bit earlier in
some of the earlier sessions if you were here,

00:42:22.809 --> 00:42:30.190
about doing pre-compilation and linking and although the
complication and linking is going to happen on the device,

00:42:30.190 --> 00:42:35.079
try and keep in mind that that state is
very expensive to compute and you know,

00:42:35.079 --> 00:42:37.579
it's kind of like, it's like a set of derived state.

00:42:37.579 --> 00:42:42.799
You send in to the implementation, here's my
shader source and then you want the implementation

00:42:42.800 --> 00:42:47.250
to derive an efficient compiled binary
out of that that you're running with.

00:42:47.250 --> 00:42:52.750
And when you do that it's unlike any other kind of GL
state where you could just you know, poke a bit in there

00:42:52.750 --> 00:42:59.090
and say OK there, it's ready to go, it's you know
blending's enabled, etc, etc. It's a very important

00:42:59.090 --> 00:43:03.120
that that's an initialization time
operation if that's not obvious enough.

00:43:03.119 --> 00:43:05.009
Unrolling small loops.

00:43:05.010 --> 00:43:12.330
There's always an overhead associated with
any execution where a loop is processed.

00:43:12.329 --> 00:43:19.730
If the loop overhead can be removed by a small,
in a small, well the loop overhead can be removed

00:43:19.730 --> 00:43:23.710
if you have a small enough loop and just,
even just simply unroll it in your shader.

00:43:23.710 --> 00:43:27.389
Using static array access is if possible.

00:43:27.389 --> 00:43:35.039
Whenever you set up an array in a shader and you do
static array accesses, it tells the compiler essentially,

00:43:35.039 --> 00:43:41.869
what elements of the array are being accessed and can
effectively throw away unused elements and do better

00:43:41.869 --> 00:43:44.089
at kind of register allocation if you will.

00:43:44.090 --> 00:43:50.820
And then there's always a cost associated with branching
and especially so on GPU's because branching can,

00:43:50.820 --> 00:43:58.750
it's obvious that branching is going to be needed for
any real program, but using so judiciously will help kind

00:43:58.750 --> 00:44:02.400
of minimize the tendency to break parallelism in the device.

00:44:02.400 --> 00:44:04.769
Because these are, they're [inaudible]
devices, they were meant,

00:44:04.769 --> 00:44:13.110
a shader is meant to process shading hardware rather
is meant to process multiple logical instances

00:44:13.110 --> 00:44:19.660
of vertex shaders and multiple logical instances
of fragment shaders and any time you kind of break

00:44:19.659 --> 00:44:23.670
that parallelism, you're going to get lesser performance.

00:44:23.670 --> 00:44:27.099
So moving on to respect device limits.

00:44:27.099 --> 00:44:37.039
There are various qualified variable types in GLSL
and those are uniforms, attributes and varyings.

00:44:37.039 --> 00:44:41.230
Shading architecture is always take the
variables and try to keep things in registers

00:44:41.230 --> 00:44:48.519
like any journalized computing architecture and if
you respect the device limits by querying the limits

00:44:48.519 --> 00:44:53.489
for uniforms, variants and attribs, you get two benefits.

00:44:53.489 --> 00:44:59.579
One your code is guaranteed to work right and you don't get
that guarantee if you don't, if you exceed these limits.

00:44:59.579 --> 00:45:01.079
It may work, it may not.

00:45:01.079 --> 00:45:04.009
And two you get better performance.

00:45:04.010 --> 00:45:15.500
And these analagous calls here are just, are these simple
get integer calls to determine what the max limit on some

00:45:15.500 --> 00:45:20.500
of these are and you notice here in the get
integer call it says, uniform and fragment vectors.

00:45:20.500 --> 00:45:27.099
So it's actually telling you how many vectorvec4s you
can get or how many vec4s are valid on the system.

00:45:27.099 --> 00:45:31.619
And if you're interested in looking at packing
rules and things like that about declaring kind

00:45:31.619 --> 00:45:41.819
of heterogeneous data types for you shaders, you can
look at that more in the GLSL, ESGL, SL specification.

00:45:41.820 --> 00:45:44.769
So moving on.

00:45:44.769 --> 00:45:47.769
Hoisting computation up and out.

00:45:47.769 --> 00:45:53.909
Fragment shaders and vertex shaders execute a lot
and the tendency, especially when you have a screen

00:45:53.909 --> 00:46:01.099
with a small screen like an embedded
device, the fragment shading operations tend

00:46:01.099 --> 00:46:04.599
to be the overwhelming majority if the computation.

00:46:04.599 --> 00:46:09.389
So if you can take any operation that was in the
fragment shader and move it up into the vertex shader,

00:46:09.389 --> 00:46:16.940
you're likely to save computation, similarly if you can take
that computation out of the vertex shader and hoist it up

00:46:16.940 --> 00:46:21.700
and make it like a uniform, like keep
it constant across all the vertices,

00:46:21.699 --> 00:46:24.619
you're going to save a lot of computation as well.

00:46:24.619 --> 00:46:29.559
You know, taking a lighting example, if
you're doing per pixel lighting and a shader,

00:46:29.559 --> 00:46:34.750
maybe you can get away with per vertex
lighting and even with per-vertex lighting,

00:46:34.750 --> 00:46:40.849
maybe you can get away with doing an inverse transform
on the light and model space and preventing any

00:46:40.849 --> 00:46:44.699
of those you know, basically a multiply
in the vertex shader in doing so.

00:46:44.699 --> 00:46:51.389
So try to take a look at the lighting model that
you've chosen for instance or any other operation

00:46:51.389 --> 00:47:00.619
that may be reasonable to hoist to a higher level in
the chain and see if you can get the results you desire

00:47:00.619 --> 00:47:09.710
without you know, getting down into that nitty gritty of
you know, the fragment of the vertex shader at that level.

00:47:09.710 --> 00:47:11.900
So efficient texture fetching.

00:47:11.900 --> 00:47:24.430
So texture fetching logic in the MBX and the SGX systems
is dedicated silicone on the chip and it's separate

00:47:24.429 --> 00:47:26.829
from the rest of the shading architecture.

00:47:26.829 --> 00:47:30.440
So if you can issue a texture fetch early in your shader,

00:47:30.440 --> 00:47:33.809
you're increasing the parallelism and
the overall performance of your app.

00:47:33.809 --> 00:47:41.509
So try to issue your fetches from the shader early
and that's simply the texture 2D look up call

00:47:41.510 --> 00:47:44.330
that you're seeing at the bottom of the slide here.

00:47:44.329 --> 00:47:46.900
That is the fetch operation.

00:47:46.900 --> 00:47:50.000
You can issue that early in the shader
you're going to get better performance.

00:47:50.000 --> 00:47:53.159
The second bullet there is avoiding dependent texture reads.

00:47:53.159 --> 00:48:01.349
A dependent texture read is defined as any time your
fragment shader takes a texture coordinate value

00:48:01.349 --> 00:48:03.309
and changes it by any amount.

00:48:03.309 --> 00:48:05.009
That's a dependent texture read.

00:48:05.010 --> 00:48:12.140
And what that effectively does is it creates a dependency,
a serialization in your fragment shader, as of that instant.

00:48:12.139 --> 00:48:20.000
Because it can no longer take that fetch operation, hoist
it out of the shading logic and execute it into parallel

00:48:20.000 --> 00:48:23.750
because the shading logic itself is
computing the coordinate you're trying to use.

00:48:23.750 --> 00:48:29.289
So it by definition has to happen
downstream of that calculation.

00:48:29.289 --> 00:48:36.599
You know sometimes you know, the example here is
showing just a simple bias to a texture coordinate.

00:48:36.599 --> 00:48:44.099
So this variant, this texture coordinate variant is
coming in and a bias, a simple bias is being applied to it

00:48:44.099 --> 00:48:48.630
and that simple add is enough to serialize that fetch.

00:48:48.630 --> 00:48:53.300
You know, there are other examples of like you know, if
you have two texture units enabled and you're using one

00:48:53.300 --> 00:48:58.120
for instance as a look up into another,
so you have one texture that's defined

00:48:58.119 --> 00:49:01.210
with coordinates in it and then you fetch from that.

00:49:01.210 --> 00:49:04.960
Then you grab the coordinates out of it and then
you use those coordinates to fetch from another one.

00:49:04.960 --> 00:49:06.449
That's a dependent texture read as well.

00:49:06.449 --> 00:49:13.989
So if you can avoid that and make your algorithm
work around that, you'll get better performance.

00:49:16.590 --> 00:49:23.430
So making empirical precision choices
is the last in our shader tips.

00:49:23.429 --> 00:49:34.730
And the addition of the shading language to ES
2.0 came, brought with it precision qualifiers

00:49:34.730 --> 00:49:41.329
and there are three precision qualifiers, lowp,
mediump and highp, as you see on the slide there.

00:49:41.329 --> 00:49:44.679
Each of those has a certain range
in precision associated with it.

00:49:44.679 --> 00:49:51.279
With a lowp that's probably going to be the most kind
of outlyers, as far as general understanding is

00:49:51.280 --> 00:49:55.570
because it's got this range of
-2 to +2 and 8 bits of precision.

00:49:55.570 --> 00:50:02.519
Mediump and highp can be considered you
know, like the iEEE spec and they're kind

00:50:02.519 --> 00:50:05.699
of basic terms of half precision and single precision.

00:50:05.699 --> 00:50:21.369
It's very important, well I guess first, this kind of
floating, varying lowp color code up here on the right,

00:50:21.369 --> 00:50:29.739
that example is listed as a known example of where you
can get a lot of efficiency by reducing the fidelity

00:50:29.739 --> 00:50:32.339
of your color, your incoming color varying.

00:50:32.340 --> 00:50:37.579
We've noticed, the GL team has noticed a
lot of kind of performance efficiency there.

00:50:37.579 --> 00:50:45.380
The GPU can do parallelism with these lower,
these lower precision varyings and you know,

00:50:45.380 --> 00:50:48.400
combine them as a SIMB operation
so you get higher throughput.

00:50:48.400 --> 00:50:51.349
So that's kind of a canonical example of using lowp.

00:50:51.349 --> 00:50:58.880
But when it comes to generally deciding how
do I qualify my shader variables by precision,

00:50:58.880 --> 00:51:00.840
you really need to be empirical when you do that.

00:51:00.840 --> 00:51:08.730
The first step is kind of a few step process and
the first thing is you can set up your shader

00:51:08.730 --> 00:51:15.309
in relatively high precision or the highest precision, in
highp, get the results that you want and then you can kind

00:51:15.309 --> 00:51:19.980
of successfully, successively refactor
those, some of those values down.

00:51:19.980 --> 00:51:26.760
Bring a highp into a medium or a medium to a low
and see first if you're getting the correct results,

00:51:26.760 --> 00:51:32.030
the render results are satisfactory for your application
and second, do you actually get more performance.

00:51:32.030 --> 00:51:37.730
Because it's not guaranteed that going from you know,
one of the higher levels to the lower levels is going

00:51:37.730 --> 00:51:39.269
to give you more performance by any stretch.

00:51:39.269 --> 00:51:41.050
I mean, it could actually cause the other direction.

00:51:41.050 --> 00:51:46.550
Depends on how the compiled code is generated so,
you always need to validate that and be empirical

00:51:46.550 --> 00:51:49.530
about making decisions about your precision qualifiers.

00:51:49.530 --> 00:51:58.370
So with that, I'll hand it back to Benj
and he can go through these few tips here.

00:51:58.369 --> 00:51:59.359
>> Thanks John.

00:51:59.360 --> 00:52:07.300
So before we do one last check in on the performance
of OptimizeMe, I just wanted to show you a comparison,

00:52:07.300 --> 00:52:10.340
zoom in on this so you can see a little better.

00:52:10.340 --> 00:52:13.660
No, too much.

00:52:13.659 --> 00:52:22.929
OK. So this is on the left, slow version of a particular
vertex shader and on the right, the fast version.

00:52:22.929 --> 00:52:26.789
And I just want to highlight a few things here

00:52:26.789 --> 00:52:30.409
First is the incoming color to the vertex shader.

00:52:30.409 --> 00:52:36.509
In the slow version, it's a per-vertex attribute,
whereas in the fast version we're using uniform color.

00:52:36.510 --> 00:52:43.980
Just so happens that in our tessellated spheres,
that we just have a color for each quadrant.

00:52:43.980 --> 00:52:45.090
A base color for each quadrant.

00:52:45.090 --> 00:52:48.940
So we didn't actually need to use per vertex colors.

00:52:48.940 --> 00:52:54.690
Next thing there, John was just
talking about, highp versus lowp.

00:52:54.690 --> 00:52:59.519
For colors, we can often get away with
lowp and we're able to do that here.

00:52:59.519 --> 00:53:02.460
So I'm using lowp for our color varying.

00:53:02.460 --> 00:53:07.550
I would point at each thing, but
I'm zoomed in so I can't do that.

00:53:07.550 --> 00:53:11.480
The last thing in the vertex shader that
I want to point out in difference is

00:53:11.480 --> 00:53:14.559
in the texture coordinate that we're writing out.

00:53:14.559 --> 00:53:18.840
In the slow version, we're writing
out the object space vertex position

00:53:18.840 --> 00:53:21.079
and we're going to use that as a texture coordinate.

00:53:21.079 --> 00:53:26.159
But that's going to range from -1 to +1 and
in order to use it to index into a texture,

00:53:26.159 --> 00:53:29.079
we're going to need to map it to the range 0 to +1.

00:53:29.079 --> 00:53:34.210
So in the slow version, we don't think too
much about it and we just decide all right,

00:53:34.210 --> 00:53:36.329
fragment shader can do that right before it fetches.

00:53:36.329 --> 00:53:37.949
No problem.

00:53:37.949 --> 00:53:43.149
In the fast version, we are doing this hoist that John
was talking about and we're hoisting that computation

00:53:43.150 --> 00:53:48.590
so that we do it on a per vertex
basis instead of a per pixel basis.

00:53:48.590 --> 00:53:54.309
So you can see the scale by one half and the
offset by one half, happening in the fast version

00:53:54.309 --> 00:53:58.170
of the shader before we write out that texture coordinate.

00:53:58.170 --> 00:54:03.260
So now if we switch to the matching fragment shader.

00:54:03.260 --> 00:54:09.720
OK again the first diff is just
the highp versus the lowp color.

00:54:09.719 --> 00:54:16.189
Next thing you'll see here is the work that we hoisted
out of the vertex shader, out of the fragment shader

00:54:16.190 --> 00:54:19.019
in the fast version while it's still
sitting here in the slow version.

00:54:19.019 --> 00:54:25.599
So we are calculating a scaled and biased texture
coordinate based on the incoming texture coordinate

00:54:25.599 --> 00:54:32.980
in the slow fragment shader and not only is that costing
us the performance of actually having to do that scale

00:54:32.980 --> 00:54:37.230
and multiply, the multiply and add on a per pixel basis

00:54:37.230 --> 00:54:41.889
but it also hits this dependent texture
read case that John was talking about.

00:54:41.889 --> 00:54:50.119
So the fast path is to use your texture coordinate as is, as
it was interpolated, use it directly for your texture fetch.

00:54:50.119 --> 00:54:59.559
Here we are doing some math operations on it before using it
for the texture fetch, causing us to fall off that fast path

00:54:59.559 --> 00:55:03.900
and so don't do that if, you can avoid it.

00:55:03.900 --> 00:55:11.230
And the last difference here is you remember from
way back, tip number one, getting rid of the discard.

00:55:11.230 --> 00:55:17.309
You'll see the discard in the slow fragment shader here,
in the fast one we've turned on blending, we don't need it,

00:55:17.309 --> 00:55:24.139
much faster because it doesn't take us off the
fast path or tile based deferred rendering.

00:55:24.139 --> 00:55:31.789
And so without further adieu, let's
bring up the phone next to the code.

00:55:31.789 --> 00:55:42.539
And let's turn on our fast shaders and you can see that we
have gone up to about hovering towards 40 frames per second.

00:55:42.539 --> 00:55:45.630
That's up from the original 6 1/2 frames per second.

00:55:45.630 --> 00:55:53.530
So all you had to do was follow these top ten
tips and recognize the performance improvement.

00:55:53.530 --> 00:56:01.890
So hopefully showing you what the wrong way of doing things
is, how not to do things, you might be able to remove some

00:56:01.889 --> 00:56:05.440
of the evil code from your own applications.

00:56:05.440 --> 00:56:13.400
Send it back to John to talk about
some, the art of finding the bottleneck.

00:56:13.400 --> 00:56:17.010
>> OK. Thank you Benj.

00:56:17.010 --> 00:56:22.550
[ applause ]

00:56:22.550 --> 00:56:28.210
OK, so we've talked about these various approaches
and if you're going to follow those guidelines,

00:56:28.210 --> 00:56:32.220
you're definitely going to get, your application's
going to be much closer to that you know,

00:56:32.219 --> 00:56:35.419
kind of sweet spot on the performance curve for the devices.

00:56:35.420 --> 00:56:43.010
But how do you go about looking for those
problems once you've got an application written?

00:56:43.010 --> 00:56:50.980
The finding bottlenecks thing is common to any GL
programming, every kind of pipeline architecture,

00:56:50.980 --> 00:56:55.320
at least that we're familiar with, has
always got different parts or components

00:56:55.320 --> 00:56:58.210
of it where you can run into limitations.

00:56:58.210 --> 00:57:00.869
And it can be a little disheartening at times.

00:57:00.869 --> 00:57:06.469
Like if you go and you look at your app and it's running
at 12 frames a second and you're trying to target 30

00:57:06.469 --> 00:57:12.939
and you spend two weeks like reworking your
entire scene database with all you vertex data,

00:57:12.940 --> 00:57:18.490
making it incredibly efficient, only to find out that
you in fact were fragment limited and it doesn't matter

00:57:18.489 --> 00:57:21.619
if you were only rendering one vertex,
your frame rate wouldn't change.

00:57:21.619 --> 00:57:35.799
So the key is to find what stage your application is limited
by and the key of the key of finding that one stage is

00:57:35.800 --> 00:57:41.760
to find the fewest strings to pull or the
least turning of knobs and pulling of levers

00:57:41.760 --> 00:57:45.950
to make your application respond by increased frame rate.

00:57:45.949 --> 00:57:49.139
So some of these limitations, we're
going to go through those.

00:57:49.139 --> 00:57:56.509
CPU limited is you know, if you're doing scene calling
or you know, view custom calling or physics

00:57:56.510 --> 00:58:02.480
in your application, you can use Shark and
see if in fact you have a CPU hotspot there.

00:58:02.480 --> 00:58:08.210
If your CPU's pegged at 100%, it's
pretty likely that a little bit of tuning

00:58:08.210 --> 00:58:13.110
on that side is going to give you an increase in frame rate.

00:58:13.110 --> 00:58:14.780
So vertex processing limited.

00:58:14.780 --> 00:58:19.260
If you have lots of huge vertices in your application,
you're trying to render battleships or something

00:58:19.260 --> 00:58:24.430
on your phone, you can run into
bandwidth limitations pretty easily.

00:58:24.429 --> 00:58:30.859
And we talked about some of the kind of optimization
techniques of using the smaller vertex attribute types,

00:58:30.860 --> 00:58:37.610
the real kind of key there again is looking for those
easy things to touch is the conversion, to VBOs.

00:58:37.610 --> 00:58:41.090
Aligning your vertex data is probably more difficult.

00:58:41.090 --> 00:58:45.710
You know, using smaller vertex data types and
aligning your vertex data are probably more difficult

00:58:45.710 --> 00:58:47.240
to do than to switch to VBO's.

00:58:47.239 --> 00:58:51.069
So you always should kind of successfully start
with the you know, the low hanging fruit and then go

00:58:51.070 --> 00:58:56.390
through the more sophisticated manners
of eliciting this vertex limitation.

00:58:56.389 --> 00:59:00.849
And those bullets are a little bit
out of order now that I look at them.

00:59:00.849 --> 00:59:05.719
It really should be, they convert the
VBO's first, then perhaps the smaller size

00:59:05.719 --> 00:59:07.949
and then that line vertex data after that.

00:59:07.949 --> 00:59:09.519
And then you can also be shading limited.

00:59:09.519 --> 00:59:16.789
If you running the ES 2.0 application, take your vertex
shader that does all this fancy stuff and bumpmapping

00:59:16.789 --> 00:59:20.559
or whatever it's doing and put a pass through
shader, just punch a pass through shader in there.

00:59:20.559 --> 00:59:25.139
Obviously your rendering is not going to be what you want
but if you boom you've got 5 more frames a second out of it,

00:59:25.139 --> 00:59:30.049
you know that maybe limiting some of the operations
you're doing there or finding another technique

00:59:30.050 --> 00:59:34.960
or hoisting is going to result in improved performance.

00:59:34.960 --> 00:59:40.470
So if you're using massive textures in your application,
obviously we talked about using the compressed

00:59:40.469 --> 00:59:48.809
and mipmap textures, if your textures are already mipmap,
you can try and determine if you're texture fetch limited.

00:59:48.809 --> 00:59:57.039
Like in the architecture, whether
it's fix function or programmable.

00:59:57.039 --> 01:00:01.110
By using the LOD bias values.

01:00:01.110 --> 01:00:08.950
Both ES 1.1 and ES 2.0, have ways to set the
texture level higher which will effectively make it

01:00:08.949 --> 01:00:13.539
such that the GPU is fetching from a smaller texture
level and when it's fetching from a smaller texture level,

01:00:13.539 --> 01:00:17.779
it's not blowing the caches out as much,
the memory bandwidth requirements are lower

01:00:17.780 --> 01:00:20.810
and you may actually see a performance
difference simply by setting that.

01:00:20.809 --> 01:00:26.739
And then if that becomes the case, then take
a more close look at how you're fetching.

01:00:26.739 --> 01:00:30.689
Can you move that up earlier in your fragment
shader for instance, can you reduce the size

01:00:30.690 --> 01:00:39.360
of the levels you're using, you use compress textures,
etc. So moving on from that, fragment shading limited.

01:00:39.360 --> 01:00:48.059
This is, the fragment shading limited is the
easiest kind of lever to pull and that is

01:00:48.059 --> 01:00:50.779
that you can just simply take your
window size and make it smaller.

01:00:50.780 --> 01:00:57.040
If you're generating fewer fragments, limitations
and computing those fragments are going to show

01:00:57.039 --> 01:01:02.400
up pretty quickly in your frame rate so, make a
quick change of the size of the window, the viewport,

01:01:02.400 --> 01:01:04.700
render fewer fragments and see what you get.

01:01:04.699 --> 01:01:10.649
Then similar to the vertex optimization
tip, make a pass through fragment shader.

01:01:10.650 --> 01:01:17.099
Just write the color out and you know, bypass your
entire fragment shader and see if you get a result there.

01:01:17.099 --> 01:01:21.589
And then once you've made that determination, if
you decided yes in fact I am fragment limited,

01:01:21.590 --> 01:01:26.050
then just do some successive refinement to your
fragment shader, maybe use a less sophisticated method.

01:01:26.050 --> 01:01:31.300
Sometimes you can get away with lesser methods on a
smaller screen and things, things are less perceptible,

01:01:31.300 --> 01:01:38.510
especially if you're porting from a desktop app where
you're required to run at 1600x1200 for instance.

01:01:38.510 --> 01:01:44.500
So compositing limited is probably a little bit of a
new kind of bottleneck consideration if you're coming

01:01:44.500 --> 01:01:48.050
from a desktop or you know, various
other GL implementations.

01:01:48.050 --> 01:01:53.280
And that is just looking to see that you're
efficiently using the iPhone compositing system.

01:01:53.280 --> 01:02:00.250
And we talked earlier about using GL to do the landscape
transforms and making sure that your GL layer's opaque

01:02:00.250 --> 01:02:03.989
and at the bottom of the stack so
that the compositing is simplified.

01:02:03.989 --> 01:02:09.629
But the compositing check is another quick lever
to flip, which is just switch the compositing off.

01:02:09.630 --> 01:02:11.579
Just render the GL only.

01:02:11.579 --> 01:02:17.279
If rendering your HUD on top of your game for instance, is
causing a problem or if you're trying to render something

01:02:17.280 --> 01:02:23.160
in fact below you game even worse yet, if you quickly,
if you disable compositing by setting the layer property

01:02:23.159 --> 01:02:29.139
to opaque like we talked about earlier, you'll
see, you could very well see a frame rate increase.

01:02:30.570 --> 01:02:34.570
So summarizing today's session.

01:02:34.570 --> 01:02:39.240
If you have existing applications, start by identifying
those bottlenecks and look for those real easy,

01:02:39.239 --> 01:02:46.419
easy things to tweak to see if you can get some, you
know elicit some changes with increases in frame rate.

01:02:46.420 --> 01:02:50.180
And batching your drawing state.

01:02:50.179 --> 01:02:57.469
There's, the spectrum of yes, here's my ideal application
domain kind of object oriented representation of the data

01:02:57.469 --> 01:03:04.099
and way over here is the pipeline optimal
kind of representation of that same data.

01:03:04.099 --> 01:03:09.029
So look at that spectrum and that's something
that's obviously desirable to do before you kind

01:03:09.030 --> 01:03:11.900
of write your game and during the design process.

01:03:11.900 --> 01:03:19.079
But batching that drawing state and minimizing
state changes, getting as much state you know,

01:03:19.079 --> 01:03:28.329
grouping all of your scene data into these various
groups is a really easy way to increase performance.

01:03:28.329 --> 01:03:34.400
Choosing appropriate data types, formats and
precision and just conserving memory where possible.

01:03:34.400 --> 01:03:39.940
I mean, that's kind of common sense stuff but,
it's always something that's got to be looked at.

01:03:39.940 --> 01:03:46.360
Accounting for your variable declarations in your shaders
and respecting those device limits we talked about.

01:03:46.360 --> 01:03:53.050
And then finally, knowing how tile base deferred
renderer differs from a stream renderer that you know,

01:03:53.050 --> 01:03:58.289
many of the applications and again, if you have ported or
whatever, there can be some ramifications there you know,

01:03:58.289 --> 01:04:03.509
there's many applications out there that are doing text
sub image calls regularly and if there's a way to architect

01:04:03.510 --> 01:04:06.690
around that, you're going to get better performance.

01:04:06.690 --> 01:04:09.340
So that's the rundown for today's session.

01:04:09.340 --> 01:04:18.880
There's a related session to this that is not GL
specifically, but just application tuning on the Mac OS

01:04:18.880 --> 01:04:26.660
on the iPhone platform, on the iPhone family and
that's tomorrow or rather Friday morning at 9 am.

01:04:26.659 --> 01:04:33.269
And then there are a couple of labs that were mentioned
in previous sessions, both tomorrow, one at 9 am,

01:04:33.269 --> 01:04:40.469
and one at noon and many of the guys you see here from
the GL embedded team are going to be at those labs

01:04:40.469 --> 01:04:44.579
and you can ask as many questions as you
can fit into those time slots I suppose.

01:04:44.579 --> 01:04:47.380
And then documentation.

01:04:47.380 --> 01:04:49.950
Apple is incredible about documentations.

01:04:49.949 --> 01:04:56.619
One of the things I love about developing on the platform
is that you go to the developer website and I've worked

01:04:56.619 --> 01:04:58.289
with these documentation guys, they're amazing.

01:04:58.289 --> 01:05:05.929
They produce incredibly clear and concise
documentation to really kind of help you along.

01:05:05.929 --> 01:05:11.929
So check out that url on Apple's site
and then look at the Khronos website

01:05:11.929 --> 01:05:16.789
for the GL ES specification and the extension registry.

01:05:16.789 --> 01:05:22.759
And again, pointing to Allan Schaffer
as our graphics evangelist.

01:05:22.760 --> 01:05:24.810
For more information, you can contact him.