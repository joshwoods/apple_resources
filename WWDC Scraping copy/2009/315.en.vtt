WEBVTT

00:00:12.839 --> 00:00:17.000
>> Welcome to the iPhone OS Audio session.

00:00:17.000 --> 00:00:21.420
My name is William Stewart.

00:00:21.420 --> 00:00:27.760
We're going to be talking about - taking
drinks of water in between your sentences.

00:00:27.760 --> 00:00:34.439
We're going to be talking about audio on the iPhone, how
it works, how it integrates in with the user experience.

00:00:34.439 --> 00:00:44.859
And we thought that we would delve deeply into how the user
perceives the phone or the iPod Touch as an audio device,

00:00:44.859 --> 00:00:52.350
and how you as an application can understand what
the user is doing, understand the user's expectations

00:00:52.350 --> 00:01:00.130
for how they should use your application and the
kinds behaviors I'd like to see from your application.

00:01:00.130 --> 00:01:05.810
And the APIs that we use to express all
of this is done through AudioSession,

00:01:05.810 --> 00:01:09.710
as you may have heard from some other sessions.

00:01:09.709 --> 00:01:17.889
And there's a few concepts in AudioSession
that we'll go into in detail, category, routes,

00:01:17.890 --> 00:01:25.780
what to do about interruptions, and then just
an overall sort of view of managing the state.

00:01:25.780 --> 00:01:31.870
So before we go into that, I'd like to just
give you a very brief overview of the APIs

00:01:31.870 --> 00:01:36.329
that you have for both playing and recording audio.

00:01:36.329 --> 00:01:46.459
These are a collection of different frameworks and these are
the primary objects that you have, MPMusicPlayerController,

00:01:46.459 --> 00:01:54.129
AVAudioPlayer and Recorder from AVFoundation,
AudioQueue, OpenAL, and then AudioUnits.

00:01:54.129 --> 00:01:57.949
So how do these look in the system?

00:01:57.950 --> 00:02:06.170
The first thing is a little bit divorced from the rest of
the audio frameworks which is the MediaPlayer Framework,

00:02:06.170 --> 00:02:10.610
and that just gives you an object MPMusicPlayerController,

00:02:10.610 --> 00:02:15.480
and it allows you to access the iPod
library that's on the user's system.

00:02:15.479 --> 00:02:20.049
And it plays with the same rules as the iPod application.

00:02:20.050 --> 00:02:25.480
So if you're running a current phone and the
user could be playing iPod in the background,

00:02:25.479 --> 00:02:28.959
MPMusicPlayerController behaves the same way.

00:02:28.960 --> 00:02:36.870
And when we talk about background or iPod playing in the
background in relationship to your application's audio,

00:02:36.870 --> 00:02:46.120
MPMusicPlayerController has exactly the same behavior,
so you can sort of think about that as well as iPod.

00:02:46.120 --> 00:02:52.400
So then here's a sort of a system
view of the audio frameworks,

00:02:52.400 --> 00:02:55.500
or the frameworks that have substantial APIs for audio.

00:02:55.500 --> 00:02:58.030
AVFoundation is the top level framework.

00:02:58.030 --> 00:03:04.340
This is an object say framework,
it's built on AudioToolbox objects,

00:03:04.340 --> 00:03:07.460
AudioQueue and AudioFile that we'll look at in a moment.

00:03:07.460 --> 00:03:11.790
And it's the simplest API that you can
use for playing and recording files.

00:03:11.789 --> 00:03:21.899
AVAudioRecorder is new in 3.0,
AVAudioPlayer was provided in 2.2 OS releases.

00:03:21.900 --> 00:03:26.150
In the next session we'll be going
into these objects in more detail.

00:03:26.150 --> 00:03:32.240
But just to give you a very brief overview, the
intention of these objects is to be utilitarian,

00:03:32.240 --> 00:03:39.010
they're provided to give you a utility model,
I want to play this file, I want to stop it,

00:03:39.009 --> 00:03:44.379
I want to loop it this many times,
this kind of basic sort of solution.

00:03:44.379 --> 00:03:50.049
It also has delegates for handling
state changes and for interruptions.

00:03:50.050 --> 00:03:56.760
So if you just need to play or record files,
AVFoundation is all you need to really know.

00:03:56.759 --> 00:04:02.669
If you're doing a game, OpenAL
is the one-stop shop for this.

00:04:02.669 --> 00:04:12.669
OpenAL is an API that's across the platform on
various platforms, it gives you 3D source posit=ioning,

00:04:12.669 --> 00:04:18.360
you can move sources around the listener, the game player.

00:04:18.360 --> 00:04:24.509
You can do independent rate control so you can have
different sample rates on sources if you want to do that.

00:04:24.509 --> 00:04:29.409
You can do "Doppler" effects so that you
can simulate sound sort of going past you,

00:04:29.410 --> 00:04:33.280
you get that sort of ambulance fading sound.

00:04:33.279 --> 00:04:36.939
You can do looping, the basic set of controls that you need

00:04:36.939 --> 00:04:44.430
for mixing separate sound sources
into one mix and outputting that mix.

00:04:44.430 --> 00:04:49.709
Now AudioToolbox is a general collection of audio services.

00:04:49.709 --> 00:04:57.589
AudioQueue and AudioFile are the two APIs that are used
to implement AVFoundation, which you can sort of see

00:04:57.589 --> 00:05:01.319
from the way the frameworks are structured here.

00:05:01.319 --> 00:05:05.209
But there's also a collection of other
utilities, and some of these utilities are used

00:05:05.209 --> 00:05:09.930
by AudioQueue or AudioFile, and AudioConverter.

00:05:09.930 --> 00:05:15.389
But you can use these APIs directly as well,
so if you want to get down into more detail

00:05:15.389 --> 00:05:19.469
and have more control, you can use these things directly.

00:05:19.470 --> 00:05:25.030
ExtendedAudioFile combines AudioFile
which is reading and writing to the disc,

00:05:25.029 --> 00:05:29.559
and AudioConverter, which is transforming data formats.

00:05:29.560 --> 00:05:33.250
And then AudioFormat gives you
information about AudioFormats.

00:05:33.250 --> 00:05:36.670
Is MP3 a variable bitrate format?

00:05:36.670 --> 00:05:39.970
What decoders do I have on the system at the moment?

00:05:39.970 --> 00:05:44.690
And then if you're just doing simple beep
sounds as the audio services play calls

00:05:44.689 --> 00:05:49.670
and that's the general set of APIs for AudioToolbox.

00:05:49.670 --> 00:06:00.680
Now AudioQueue itself uses AudioUnits to render
the audio that you're providing, the AudioQueue,

00:06:00.680 --> 00:06:06.829
and it uses output units, it uses mixers,
and you can use these same objects yourself.

00:06:06.829 --> 00:06:12.319
Now we're going lower down, there's some more rules
about how you can interact with these objects,

00:06:12.319 --> 00:06:17.680
the kinds of things that you can and shouldn't
do because the I/O services that are embodied

00:06:17.680 --> 00:06:24.810
at this level are deadline driven and you have a limited
time which you've got to fill a buffer of audio in order

00:06:24.810 --> 00:06:29.829
for it to be heard, otherwise you'll
get glitching and bad sort of behavior.

00:06:29.829 --> 00:06:34.089
The mixing AudioUnits here, there's a 3D
mixer, that's the mixer that's used by OpenAL.

00:06:34.089 --> 00:06:41.179
Then of course at the bottom of
all of this is the AudioHardware,

00:06:41.180 --> 00:06:44.990
and the AudioHardware, there's no direct access to it.

00:06:44.990 --> 00:06:53.509
On the desktop system you could have the core audio
framework which is not available on the iPhone,

00:06:53.509 --> 00:07:00.120
so the access you do have is through the AudioUnit
remote I/O or the voice processing AudioUnit.

00:07:00.120 --> 00:07:08.759
And the main thing about the AudioHardware is that
there's also a state associated with AudioHardware

00:07:08.759 --> 00:07:12.240
like do you have input available, do you have output, etc?

00:07:12.240 --> 00:07:19.829
And you manage this state through AudioSession, and
that's what we'll be looking at in the rest of this talk.

00:07:19.829 --> 00:07:28.509
So AudioSession really describes an
application's interaction with the audio system.

00:07:28.509 --> 00:07:34.480
So it represents a snapshot, a current
state of the audio on the device.

00:07:34.480 --> 00:07:45.950
You can have settings to establish your preference, like
I want this sample right, or I want to do input or output.

00:07:45.949 --> 00:07:54.149
And AudioSession also gives you a way to handle state
transitions, so it has a notion of being active,

00:07:54.149 --> 00:07:58.500
that you're an active client, you're really
using the audio system or you're not.

00:07:58.500 --> 00:08:01.300
It has explicit notions about being interrupted.

00:08:01.300 --> 00:08:04.610
A phone call will interrupt your application's audio.

00:08:04.610 --> 00:08:08.439
High priority items besides phone calls could be alarms.

00:08:08.439 --> 00:08:12.779
So all of this is embodied in the AudioSession object.

00:08:12.779 --> 00:08:21.629
Now the AudioSession API itself is in AudioToolbox, it's
a C API , and all the implementation and detail is here,

00:08:21.629 --> 00:08:26.139
there's a collection of properties,
there's property listeners.

00:08:26.139 --> 00:08:34.110
And in 3.0 we introduced AVAudioSession
which is in AVFoundation,

00:08:34.110 --> 00:08:40.820
and this is a wrap of utility class
built on top of AudioSession.

00:08:40.820 --> 00:08:49.350
Now it's convenient for you because you're in
Objectve-C to write your application.

00:08:49.350 --> 00:08:55.560
But whether you use AVAudioSession or the underlying
AudioSession APIs, it's exactly the same thing,

00:08:55.559 --> 00:09:01.719
you don't get any benefit by doing something in
AudioSession that you can do with AVAudioSession.

00:09:01.720 --> 00:09:07.009
So in the rest of the talk, what I'm going to do
is where possible I'll talk about AVAudioSession

00:09:07.009 --> 00:09:09.850
because it's a little bit cleaner and simpler,

00:09:09.850 --> 00:09:16.149
and then we'll look at some specific AudioSession
things that AVAudioSession doesn't give you.

00:09:16.149 --> 00:09:21.389
So the first thing that I want to go through is categories.

00:09:21.389 --> 00:09:27.949
AudioSession categories really describe the basic
role and the basic set of services that you want

00:09:27.950 --> 00:09:30.940
from the audio system in your application.

00:09:30.940 --> 00:09:38.620
Now some of these categories will define priorities.

00:09:38.620 --> 00:09:43.580
It will decide whether you allow mixing with iPod or not.

00:09:43.580 --> 00:09:49.410
And because it's going to set a collection
of priorities, you may interrupt the iPod

00:09:49.409 --> 00:09:52.529
if it's playing back and you go to play audio.

00:09:52.529 --> 00:09:57.000
So that's another thing an AudioSession
category is going to establish for you.

00:09:57.000 --> 00:10:04.309
And it also dictates fundamental behaviors about
your audio in relationship to the ringer switch,

00:10:04.309 --> 00:10:11.669
in relationship to the screen lock, and also in
relationship to whether you have input or output.

00:10:11.669 --> 00:10:19.479
So using AVAudioSession to set a category,
because there isn't really an AudioSession object,

00:10:19.480 --> 00:10:27.100
there's a single term pattern it's a single instance
that's global for your application, for your process.

00:10:27.100 --> 00:10:32.649
So in the AVAudioSession you just have the
shared instance method on AVAudioSession

00:10:32.649 --> 00:10:39.620
that gives you back an AVAudioSession object, but that's
it, there's no way to allocate an AVAudioSession object.

00:10:39.620 --> 00:10:43.929
So in the rest of the slides I'm just
going to refer to it as the session.

00:10:43.929 --> 00:10:49.039
So you get the session object and then you make
a call on that which is to set the category.

00:10:49.039 --> 00:10:51.089
And we'll look at the different types of categories.

00:10:51.090 --> 00:11:00.149
And this is basically all you need to do to establish
your priorities with the AVAudioSession object.

00:11:00.149 --> 00:11:09.090
So the collection of features that a category defines, we've
got this down to five columns; whether you mix with others,

00:11:09.090 --> 00:11:13.710
whether your audio will obey the ringer switch
or not if the ringer switch is set to silent,

00:11:13.710 --> 00:11:17.550
is the audio silent or does it play through?

00:11:17.549 --> 00:11:24.009
When the screen is locked, when the phone
is locked, does your audio go silent?

00:11:24.009 --> 00:11:26.600
Does your application require input?

00:11:26.600 --> 00:11:29.040
Does your application require output?

00:11:29.039 --> 00:11:36.159
So this is what the table looks like, the rows are
the categories, and the columns are the behaviors.

00:11:36.159 --> 00:11:41.549
So the top row is Ambient, and
the second row is SoloAmbient.

00:11:41.549 --> 00:11:47.699
And the difference between these two categories is the
SoloAmbient goes solo, it doesn't mix with the iPod

00:11:47.700 --> 00:11:52.340
or MPMusicPlayerController in the
background, whereas Ambient does.

00:11:52.340 --> 00:11:56.280
But both categories will go silent with the ringer switch.

00:11:56.279 --> 00:12:00.850
Both categories will go silent when you lock the screen.

00:12:00.850 --> 00:12:04.240
Both categories only do audio output.

00:12:04.240 --> 00:12:09.169
Now you can use the playback category,
and the rest of the categories

00:12:09.169 --> 00:12:14.610
as you can see will both disobey the ringer switch
and disobey screen lock, so they'll keep playing

00:12:14.610 --> 00:12:19.190
when the screen is locked or the
ringer switch is set to silent.

00:12:19.190 --> 00:12:26.110
And then those three categories, one is for playback,
one is for record, one is for both playing and recording.

00:12:26.110 --> 00:12:33.620
And then they have an override mark in the mix with
others, and we'll look at this in more detail in a moment.

00:12:33.620 --> 00:12:36.750
So what are some examples for the categories?

00:12:36.750 --> 00:12:41.309
What type of categories would you
use for what type of application?

00:12:41.309 --> 00:12:46.929
Now for games we would recommend either Ambient
or AmbientSolo because typically the audio

00:12:46.929 --> 00:12:53.809
in a game is incidental or it's
not critical to the application.

00:12:53.809 --> 00:12:59.969
You can play the game without hearing the audio if you're
in a movie theater, if you're in a WWDC session talking

00:12:59.970 --> 00:13:04.370
about AudioSession and you're getting bored and you want
to play a game, you don't want everybody else to know

00:13:04.370 --> 00:13:10.669
that you're playing a game, so you want the game
to be quiet so that you don't disturb the speaker.

00:13:10.669 --> 00:13:13.479
Anybody there?

00:13:13.480 --> 00:13:21.310
No, okay. So Ambient is a great category for
this reason, and also if you're playing a game

00:13:21.309 --> 00:13:26.279
and you're really interacting with the device, you
want the audio to go quiet when the screen is locked

00:13:26.279 --> 00:13:30.319
because there's really nothing
for the user to do at that point.

00:13:30.320 --> 00:13:37.170
For the playback category, you can imagine the iPod is
this category, if you've got an app that's similar to that

00:13:37.169 --> 00:13:42.029
in intention that it's going to play
music or do something with audio

00:13:42.029 --> 00:13:45.470
that you'd want even if the ringer switch is silent.

00:13:45.470 --> 00:13:49.420
So it's an intentional music application.

00:13:49.419 --> 00:13:50.479
PlayAndRecord.

00:13:50.480 --> 00:13:54.000
Same kind of thing except now you've got record as well.

00:13:54.000 --> 00:13:58.799
So if you're doing a chat application,
that would be an example of that.

00:13:58.799 --> 00:14:06.019
Now you don't need to do both playback and recording
at the same time, but if you want to do either one

00:14:06.019 --> 00:14:10.490
at different points, you might want to use this category,
and we'll get into that a little bit more later.

00:14:10.490 --> 00:14:15.980
And then of course the record category, if you're
doing recording and you just want to get input,

00:14:15.980 --> 00:14:23.320
and this will mean you don't have any output at all.

00:14:23.320 --> 00:14:31.080
In 2.2 we had another two categories, UI Sounds and
Live Audio, and we've decided to deprecate them to try

00:14:31.080 --> 00:14:37.280
and make this a simpler set of
categories and concepts to understand.

00:14:37.279 --> 00:14:41.259
So UI Sounds is equivalent to Ambient,
and Live Audio is equivalent

00:14:41.259 --> 00:14:43.870
to playback, there's no difference between those two.

00:14:43.870 --> 00:14:51.190
And if you're using them just use the Ambient or playback.

00:14:51.190 --> 00:14:58.710
So there's a couple of behaviors that have got
to do with categories, not directly but it kind

00:14:58.710 --> 00:15:00.650
of fits in with the notion of categories.

00:15:00.649 --> 00:15:05.049
And the first one is, is other audio playing on the system?

00:15:05.049 --> 00:15:13.319
Now an example of it we've seen with some games for
example this, is if the user is playing their iPod already

00:15:13.320 --> 00:15:18.190
and the game launches, then you can use this
to determine if there's other audio playing

00:15:18.190 --> 00:15:23.000
so then they can set their category to
Ambient so that they'll mix in with the iPod,

00:15:23.000 --> 00:15:25.710
and they won't play their own background music.

00:15:25.710 --> 00:15:31.490
So that could be used a decision point to provide
a user experience that's a little bit polished

00:15:31.490 --> 00:15:34.980
and sensitive to what the user is currently doing.

00:15:34.980 --> 00:15:43.029
Another category sort of behavior that's
interesting is OtherMixableAudioShouldDuck.

00:15:43.029 --> 00:15:49.389
So what this means is that when
your application plays audio,

00:15:49.389 --> 00:15:54.269
any other audio on the system should
be attenuated, should go quiet.

00:15:54.269 --> 00:16:01.399
An example of this is Nike, you know, you're
running along, you've got your 120 beats per music,

00:16:01.399 --> 00:16:03.929
you're pumping up the hill and
it's like keep going, you're there.

00:16:03.929 --> 00:16:08.879
Well you want to hear the Nike saying you've been
running for ten miles and you're nearly there.

00:16:08.879 --> 00:16:13.950
So it ducks the iPod down, it makes its
announcement, then it comes back up.

00:16:13.950 --> 00:16:21.420
So you can set this property so that
the system will do that for you.

00:16:21.419 --> 00:16:26.799
So with that I'd like to bring out Michael [inaudible]
to give us some demos, and we're going to look

00:16:26.799 --> 00:16:29.740
at some category behaviors and switch to the Wolfson.

00:16:29.740 --> 00:16:30.529
Thank you.

00:16:30.529 --> 00:16:31.579
>> Thanks, Bill.

00:16:31.580 --> 00:16:37.480
So as Bill mentioned, what I want to show you is a
couple of applications that exhibit the behaviors

00:16:37.480 --> 00:16:40.500
of various categories and setting
them using the AudioSession.

00:16:40.500 --> 00:16:45.990
The first I'm going to show is a program called AVTouch,
and now this is using the media playback category,

00:16:45.990 --> 00:16:48.379
as he mentioned, this would be for an
application where media is critical

00:16:48.379 --> 00:16:50.809
or something like an internet radio station.

00:16:50.809 --> 00:16:52.509
So I'm going to start the application.

00:16:52.509 --> 00:16:53.919
[ Music ]

00:16:53.919 --> 00:16:58.229
>> And we've got the music playing, and now
you'll see what will happen if I screen lock.

00:16:58.230 --> 00:17:00.529
It's going to keep playing through.

00:17:00.529 --> 00:17:02.549
[ Music ]

00:17:02.549 --> 00:17:07.809
>> Similarly I can set the ringer and
the application is just going to blow

00:17:07.809 --> 00:17:09.429
through that, this is just going to continue playing.

00:17:09.430 --> 00:17:14.519
The application really has no idea as to the states
being performed on it because as we mentioned,

00:17:14.519 --> 00:17:17.049
this is critical for the application function.

00:17:17.049 --> 00:17:23.379
To contrast that, I'm going to use another application
called OALTouch, so this something more similar

00:17:23.380 --> 00:17:27.870
to what a game would use, OpenAL
with a SoloAmbient category.

00:17:27.869 --> 00:17:31.399
And you'll see I can play this very boring game.

00:17:31.400 --> 00:17:37.269
But now you'll notice if I screen lock,
we're actually going to pause the audio.

00:17:37.269 --> 00:17:40.389
Again, the application doesn't
have any indication this happening,

00:17:40.390 --> 00:17:42.180
the audio is just being paused from underneath them.

00:17:42.180 --> 00:17:48.060
I can restore this and we get the
audio back just as we were before.

00:17:48.059 --> 00:17:51.269
Now the ringer switch similarly is going to mute the audio.

00:17:51.269 --> 00:17:56.269
I can put this back and we'll continue just as normal.

00:17:56.269 --> 00:18:02.089
The other thing I want to show you, as Bill
mentioned, we have this OtherAudioIsPlaying property.

00:18:02.089 --> 00:18:08.000
And where that's helpful as he mentioned, is if we have -

00:18:08.000 --> 00:18:11.650
[ Music ]

00:18:11.650 --> 00:18:13.420
>> -- music playing.

00:18:13.420 --> 00:18:19.310
Now I'm going to launch the app again, and what we
do here is we see that the other audio is playing,

00:18:19.309 --> 00:18:23.069
so instead of setting the SoloAmbient
category, we set just the Ambient category,

00:18:23.069 --> 00:18:25.269
which allows the iPod to continue playing.

00:18:25.269 --> 00:18:28.450
But I can still get my game sounds.

00:18:28.450 --> 00:18:33.730
To contrast that, I've got a bad version of this application
which is just setting the SoloAmbient no matter what.

00:18:33.730 --> 00:18:40.960
And what will happen here is you see now that we've lost
the background audio, which the user was kind of expecting

00:18:40.960 --> 00:18:44.500
to continue, but we don't have anything
aside from the regular game audio.

00:18:44.500 --> 00:18:47.009
Which is kind of disruptive to the user experience.

00:18:47.009 --> 00:18:53.569
And so you can see what you really want to do is make
sure you don't interrupt what the user intends to do,

00:18:53.569 --> 00:18:59.089
and that OtherAudioIsPlaying property will let you do that.

00:18:59.089 --> 00:19:00.829
Back to you, Bill.

00:19:00.829 --> 00:19:06.369
>> And of course if you want to,
you can do MPMusicPlayerController

00:19:06.369 --> 00:19:10.149
to play the background music as
well while your game is playing.

00:19:10.150 --> 00:19:13.170
Now what about mix with others, how does this work?

00:19:13.170 --> 00:19:20.970
So the mix with others is a characteristic of
categories and it dictates the behavior of two things.

00:19:20.970 --> 00:19:28.210
So can a background application like iPod
play or record while your app is active?

00:19:28.210 --> 00:19:34.440
And this really defines whether your
application is going to interrupt another app.

00:19:34.440 --> 00:19:42.430
So as we saw with the demo just then when we launched
with the AmbientSolo, it interrupted the iPod application,

00:19:42.430 --> 00:19:47.269
so that's that characteristic of mix with
others, and the characteristic with AmbientSolo

00:19:47.269 --> 00:19:50.690
of course is not going to mix with others.

00:19:50.690 --> 00:19:55.180
And in the previous case, he used
Ambient where it did mix with others.

00:19:55.180 --> 00:20:02.870
Now the second characteristic that this controls is
whether you have access to hardware or software codecs.

00:20:02.869 --> 00:20:06.109
So what do we mean by hardware and software codecs?

00:20:06.109 --> 00:20:16.740
Hardware codecs are codecs that use some chip
on the iPhone or the iPod Touch to take some

00:20:16.740 --> 00:20:21.750
of the load off the main application
process in order to decode the audio.

00:20:21.750 --> 00:20:30.140
Now this gives an advantage in that we take
CPU cycles off the CPU so that you have more

00:20:30.140 --> 00:20:33.050
for your game, more for your application.

00:20:33.049 --> 00:20:39.779
And it also has a low power usage, it's less
power to do the decode using this chip than it is

00:20:39.779 --> 00:20:42.910
to run on the main application processor.

00:20:42.910 --> 00:20:49.019
But there's some limitations to that, and that
is that you can only run one of them at a time,

00:20:49.019 --> 00:20:54.349
it has to be a negotiated resource, you can't just
have everybody doing all kinds of things with it

00:20:54.349 --> 00:20:57.119
because it's fairly restricted in what it can do.

00:20:57.119 --> 00:21:01.909
So the software versions of codecs are
flexible, that's their main feature,

00:21:01.910 --> 00:21:04.870
is that you can run more than one of them.

00:21:04.869 --> 00:21:12.489
You can have the iPod using the hardware and you can be
using the software codecs, and that will all be just fine.

00:21:12.490 --> 00:21:17.180
But the cost to you for using software
is that we will take CPU

00:21:17.180 --> 00:21:21.130
or application processing time away from your application.

00:21:21.130 --> 00:21:27.130
So if you're doing a game and you're really pushing
it to the limit and you start to use a software codec

00:21:27.130 --> 00:21:31.360
to decode your backing track in MP3,
you'll probably lose frames in your game.

00:21:31.359 --> 00:21:35.699
So this is a tradeoff that you would need to understand.

00:21:35.700 --> 00:21:38.840
So it can affect application performance.

00:21:38.839 --> 00:21:44.470
So what about the formats, what are
the formats that are used for hardware?

00:21:44.470 --> 00:21:52.069
In the decoders there's an MPEG-4 AAC which is the
main format that we use for the music store content,

00:21:52.069 --> 00:21:56.609
for ripping CDs, etc. There's MP3, Apple Lossless.

00:21:56.609 --> 00:22:00.139
With the 2.2 release there's an HE-AAC code.

00:22:00.140 --> 00:22:07.200
HE-AAC is a lower bit rate version that's
really optimized for sort of internet steaming

00:22:07.200 --> 00:22:10.990
and kind of places where low bit rates are good.

00:22:10.990 --> 00:22:16.190
So you can get a pretty good reproduction
of audio at 64 kilobits per second,

00:22:16.190 --> 00:22:22.279
so that's about 20 to 1 compression
ratio or something, so it's pretty good.

00:22:22.279 --> 00:22:28.680
Now with the iPhone 3GS, there is also an AAC encoder.

00:22:28.680 --> 00:22:37.789
If you've seen the keynote talking about capturing
video and you're recording the audio into AAC,

00:22:37.789 --> 00:22:44.809
you can access this AAC encoder yourself
and you can record and use AudioQueue

00:22:44.809 --> 00:22:52.460
or AVAudioRecorder to encode into AAC on the iPhone 3GS.

00:22:52.460 --> 00:23:00.529
For software with 3.0, we've also added software
versions of the hardware codecs, MPEG-4 AAC, MP3,

00:23:00.529 --> 00:23:05.129
and Apple Lossless, these are all new with 3.0.

00:23:05.130 --> 00:23:13.300
So they will take a lot of time on the application
processor to do work, and that varies of course on model

00:23:13.299 --> 00:23:21.879
and how fast the clocks are on the CPUs, etc. And then
the software for all of the other formats like ulaw

00:23:21.880 --> 00:23:31.740
and alaw iLBC which is speech codec, etc.
So to access the hardware codecs you need

00:23:31.740 --> 00:23:34.059
to have mix with others set to false.

00:23:34.059 --> 00:23:41.159
That is I'm not going to mix with others, I'm not
wanting to go to any party, this is me, this is mine.

00:23:41.160 --> 00:23:47.500
So that's every category by default
except for the Ambient category.

00:23:47.500 --> 00:23:53.720
So if you are doing any kind of application and
you're not Ambient, then you have, by default,

00:23:53.720 --> 00:24:00.440
you are going to turn off other people,
and you are not going to mix with them.

00:24:00.440 --> 00:24:11.559
Now you can override this category in the Playback category
and the PlayAndRecord category so that you can allow mixing

00:24:11.559 --> 00:24:16.339
with others and get the other behavior that
you would want for Playback and PlayAndRecord.

00:24:16.339 --> 00:24:23.740
For example, if you wanted to mix with the iPod but you
wanted your music to keep playing when the screen was locked

00:24:23.740 --> 00:24:30.819
or the ringer switch was silent, then you can use
the Playback category and you can override the mix

00:24:30.819 --> 00:24:33.960
with others characteristic of the category.

00:24:33.960 --> 00:24:44.340
And the hardware codecs are described in
more detail in the AudioFormat header.

00:24:44.339 --> 00:24:54.509
And also that gives you details about how you can
explicitly control when you make an AudioQueue

00:24:54.509 --> 00:24:58.430
for instance, whether you use hardware or software.

00:24:58.430 --> 00:25:06.310
And then if you use a format that's supported in
hardware but have mix with others set to true,

00:25:06.309 --> 00:25:08.220
then you can default to the software codec.

00:25:08.220 --> 00:25:17.299
So if you go to use AAC and you're the Ambient category
then you're going to default to the software codec.

00:25:17.299 --> 00:25:23.000
So you really need to understand something about what
you're doing here if you're using the Ambient category

00:25:23.000 --> 00:25:26.559
or if you're using one of these overrides.

00:25:26.559 --> 00:25:34.299
So how you do the override, it's an AudioSession
property, you just do the AudioSessionSetProperty call,

00:25:34.299 --> 00:25:37.559
it defaults to false which means that Playback

00:25:37.559 --> 00:25:43.109
and Play/Record categories will not
mix with others by the default setting.

00:25:43.109 --> 00:25:52.039
Now you set this and you may file, we may decide to change
the before, but at the moment we have no plans to do so.

00:25:52.039 --> 00:25:54.609
But you should be prepared to just not get it.

00:25:54.609 --> 00:26:00.909
If your application changes the category,
you need to reassert this if you want.

00:26:00.910 --> 00:26:08.080
So if you go from Playback to PlayAndRecord, you
need to reassert if you've done this override.

00:26:08.079 --> 00:26:11.069
So that's on that.

00:26:11.069 --> 00:26:18.109
So we're going to move on now to audio routes, and
covers the audio categories, I hope that's clear.

00:26:18.109 --> 00:26:22.119
We'll go a little bit back into this
later in the session and see how

00:26:22.119 --> 00:26:25.669
that all fits together with the flow in your application.

00:26:25.670 --> 00:26:29.200
So what about audio routes, what do we mean by audio routes?

00:26:29.200 --> 00:26:33.620
Well it's where does your audio go,
where does your audio come from.

00:26:33.619 --> 00:26:37.679
And this looks like a simple device, doesn't it?

00:26:37.680 --> 00:26:42.110
There it is, it fits in your pocket and
you think oh great, this should just work.

00:26:42.109 --> 00:26:44.829
Well it's not quite so simple.

00:26:44.829 --> 00:26:54.319
And iPhone at least, has a microphone, it has a speaker, it
has another speaker which we call a receiver to distinguish

00:26:54.319 --> 00:26:58.599
between something that is a speaker
and something that you put to your ear,

00:26:58.599 --> 00:27:01.750
so we call it the ear speaker, the receiver.

00:27:01.750 --> 00:27:04.700
You can also plug in headphones.

00:27:04.700 --> 00:27:10.019
You can also plug in headphones that actually have a
microphone, and we call these headsets to distinguish

00:27:10.019 --> 00:27:13.920
between headphones and headphones with microphones.

00:27:13.920 --> 00:27:23.900
You can also use a hands-free device like a Bluetooth
device that has both a speaker and a microphone.

00:27:23.900 --> 00:27:30.360
New with 3.0 you can use A2DP Bluetooth
headphones or speakers.

00:27:30.359 --> 00:27:31.779
We're not even finish yet.

00:27:31.779 --> 00:27:38.849
When you turn it around to the side you can
also get line out through the 30-pin connector.

00:27:38.849 --> 00:27:47.609
You can interface to car kits through
USB outputs or through A2DP Bluetooth.

00:27:47.609 --> 00:27:54.109
So that's all of the places audio can go in and
come out of, then there's a collection of controls.

00:27:54.109 --> 00:27:59.979
There's volume key controls, there's the
ringer switch, and there's the screen lock.

00:27:59.980 --> 00:28:07.789
So really this is not at all a simple device, this is
quite a complex device to understand what's going on.

00:28:07.789 --> 00:28:11.279
And when we looked at this and we
thought well what are the expectations

00:28:11.279 --> 00:28:14.460
that the user has for how this device should behave?

00:28:14.460 --> 00:28:16.590
That was our fundamental question.

00:28:16.589 --> 00:28:20.629
And our answer to that was the last in wins.

00:28:20.630 --> 00:28:22.830
So last in could be last out.

00:28:22.829 --> 00:28:29.480
If I plug headphones in, then my intention
is the audio goes to the headphones.

00:28:29.480 --> 00:28:36.250
If I pull the headphones out, then the audio
goes to whatever I had on before the headphones.

00:28:36.250 --> 00:28:40.400
So if I just had nothing else connected
on the iPhone it would go to the speaker.

00:28:40.400 --> 00:28:48.380
But what happens when you get into using A2DP where
you don't have a concept of plugging something in,

00:28:48.380 --> 00:28:55.000
you just walk into a room with A2DP
speakers on and suddenly they're there.

00:28:55.000 --> 00:29:01.480
So we had to describe some interface to
allow the user to actually specify behavior

00:29:01.480 --> 00:29:07.279
when the default might not be what they want, and this
is the audio device speaker and it looks like this.

00:29:07.279 --> 00:29:13.029
And this just occurs as something that the user sees,
but I just wanted to bring this up in this context

00:29:13.029 --> 00:29:18.839
so that you understand that these things can
change and you have no control over these changes,

00:29:18.839 --> 00:29:24.319
this is the user's device and it is the
user controling where the audio is going to

00:29:24.319 --> 00:29:28.259
or coming from based on what they've plugged in.

00:29:28.259 --> 00:29:34.269
So how do you know what the current
state of these connections are.

00:29:34.269 --> 00:29:39.490
We're going into AudioSession now, there's
an AudioSession property called AudioRoute,

00:29:39.490 --> 00:29:43.289
and that tells you the current route.

00:29:43.289 --> 00:29:48.799
And there's also a property that you can listen to for
when that route changes, when the user plugs headphones

00:29:48.799 --> 00:29:56.639
in for example, or they pick a different device from
the picker in the case of A2DP on the Bluetooth.

00:29:56.640 --> 00:30:03.310
And this is a notification, and the notification tells
you why the route changed, and what the old route was.

00:30:03.309 --> 00:30:06.450
And you can always find the current
route through AudioRoute.

00:30:06.450 --> 00:30:16.170
So when you're using AudioSession as a C API, you can
get the current route through the AudioRoute property,

00:30:16.170 --> 00:30:19.590
and this describes the current route as a CFString.

00:30:19.589 --> 00:30:24.189
You can get an empty string if there's
no current route, an iPod Touch I guess,

00:30:24.190 --> 00:30:28.140
if you had nothing plugged in or
no speaker or you were silent.

00:30:28.140 --> 00:30:37.850
So if the route changes, you listen to the
AudioRouteChange property, and you listen to this property

00:30:37.849 --> 00:30:41.029
through adding a property listener on an AudioSession.

00:30:41.029 --> 00:30:47.950
And we'll have a look at what this
property listener might look like.

00:30:47.950 --> 00:30:51.250
So this is the prototype for the property listener.

00:30:51.250 --> 00:30:55.210
The property ID that's going to come in
to this listener that we're interested

00:30:55.210 --> 00:31:00.069
in is AudioRouteChange, so we check to see if that's it.

00:31:00.069 --> 00:31:02.649
And then the payload for this property is

00:31:02.650 --> 00:31:07.060
of the voice start data is the CFDictionary,
so we're going to cast it to that

00:31:07.059 --> 00:31:14.509
And the CFDictionary has two keys in it; one is the
reason why the route changed and that's a number,

00:31:14.509 --> 00:31:20.869
and it will either be a new device appeared, so
headphones plugging in is a new device appearing.

00:31:20.869 --> 00:31:29.269
The existing device went away, so that would be the user
pulling out headphones or user taking the iPhone off

00:31:29.269 --> 00:31:33.480
from a dock or a 30-pin out ty0pe connection.

00:31:33.480 --> 00:31:37.620
And then you'll get a CFStream which is the
same kind of string format as the current route,

00:31:37.619 --> 00:31:43.489
but in the AudioRouteChange parallel,
this tells you what the old route was.

00:31:43.490 --> 00:31:50.569
And then of course in this case, you can get the current
route using AudioSession get property on AudioRoute

00:31:50.569 --> 00:31:57.990
to see what is my new route, what's my now current route
given that I've lost whatever my route was previously.

00:31:59.279 --> 00:32:07.230
So as with the category, there's an override for
AudioRoute and the override exits to give you the facility

00:32:07.230 --> 00:32:12.990
to make a choice when we don't
really know what the right choice is.

00:32:12.990 --> 00:32:19.230
So if you're in an iPhone and you have nothing plugged
in and you're sitting there, you have two speakers.

00:32:19.230 --> 00:32:28.039
Now in some categories you could imagine that the earpiece
speaker, the receiver is the correct speaker to use.

00:32:28.039 --> 00:32:35.450
In other use cases, you can imagine that the
speaker itself is the right route to use.

00:32:35.450 --> 00:32:39.600
And they're both there, it's not the user has
plugged something in or out, they're both just there,

00:32:39.599 --> 00:32:43.159
so the override exists for you to make a choice.

00:32:43.160 --> 00:32:49.470
And the typical way you'd make a choice would be to present
some kind of speaker icon like you do with the speakerphone.

00:32:49.470 --> 00:32:54.200
So this is how you implement the speakerphone type button.

00:32:54.200 --> 00:33:02.630
And the override is a set property and you can set it to
speaker or you can set it to none, and it's not sticky.

00:33:02.630 --> 00:33:08.040
So when the route changes, you're going to lose
your override, and if it's appropriate for you

00:33:08.039 --> 00:33:12.230
to reassert the override, you can attempt to do so.

00:33:12.230 --> 00:33:15.589
But remember, the route changes
because the user has done something,

00:33:15.589 --> 00:33:19.250
they have plugged something in or
they have plugged something out.

00:33:19.250 --> 00:33:25.859
So it's really better to try and respond to what the
user has done rather than try to dictate behavior

00:33:25.859 --> 00:33:30.299
and feel like you can really control what this
thing should do, because it's the users device,

00:33:30.299 --> 00:33:34.519
and that's the view we took on all of this.

00:33:34.519 --> 00:33:40.190
So with that, I'd like to get Michael to
come back up and demonstrate AudioRoutes.

00:33:40.190 --> 00:33:41.640
Thank you.

00:33:41.640 --> 00:33:48.750
>> So as Bill mentioned, what I want to show you is using
the AudioRoute properties to actually mimic the behavior.

00:33:48.750 --> 00:33:54.500
I'm sure you guys know if you have an iPod and you unplug
while you're playing back audio it'll actually pause.

00:33:54.500 --> 00:33:57.279
Whereas if you're playing the audio through the
speaker, you plug it in and it'll continue going.

00:33:57.279 --> 00:33:59.750
And what I want to show you is how
we can actually mimic that behavior.

00:33:59.750 --> 00:34:02.000
[ Music ]

00:34:02.000 --> 00:34:06.890
>> So we have the application going, and
I've got my handy dandy Apple headset here.

00:34:06.890 --> 00:34:11.510
So we're going to play, and then while
it's playing I'm going to plug this in.

00:34:11.510 --> 00:34:17.280
You'll see that the audio is going to continue playing, the
last in rule will make the audio now go through the headset.

00:34:17.280 --> 00:34:20.310
Basically we receive the route notification
here and we've checked the reason

00:34:20.309 --> 00:34:25.090
and said well the new device is available, I
don't really care about that, so just keep going.

00:34:25.090 --> 00:34:30.730
However, if I unplug, you'll see that
now the device is actually paused.

00:34:30.730 --> 00:34:35.039
What we've done is we checked the reason again when
we got that property notification and seen well

00:34:35.039 --> 00:34:40.269
if the old device went away, what I want to do is
update the UI so that we pause the application.

00:34:40.269 --> 00:34:44.389
And this way what we manage to do is kind of
streamline the user experience so that the behavior

00:34:44.389 --> 00:34:48.139
of your app is what the user would
expect just as they get from the iPod.

00:34:48.139 --> 00:34:52.219
>> So what are some of the other
things that AudioSession can tell you?

00:34:52.219 --> 00:34:58.079
AudioSession can tell you about the hardware format,
what is the current state of the AudioHardware,

00:34:58.079 --> 00:35:02.659
how many number of channels do you have for
input and output, what's the sample rate?

00:35:02.659 --> 00:35:07.609
Now when you ask these questions, in whatever
state the device is in at the moment,

00:35:07.610 --> 00:35:12.579
whatever its active category is,
whatever is going on on the device.

00:35:12.579 --> 00:35:18.819
Now before you're active, you can say - sorry,
with AVAudio I'm jumping one slide ahead.

00:35:18.820 --> 00:35:24.530
So with AVAudioSession this is the calls
you make, you just get the session object

00:35:24.530 --> 00:35:30.420
and you just say what's the current hardware sample
rate and the number of input or output channels?

00:35:30.420 --> 00:35:33.510
Now before you're active, and we'll
look at that in a minute.

00:35:33.510 --> 00:35:38.590
I'm planting all these seeds and hope they'll
sprout into understanding by the end of the session.

00:35:38.590 --> 00:35:43.240
So before your session is active,
before you have asserted your ownership

00:35:43.239 --> 00:35:46.719
of the audio system or your use of the audio system.

00:35:46.719 --> 00:35:55.659
You can express your preferences, you can say well
when I'm active, when I'm using the audio system,

00:35:55.659 --> 00:36:02.399
I'd like the sample rate to be at 44.1 kilohertz
or at 8 kilohertz, whatever is possible.

00:36:02.400 --> 00:36:07.480
I would also like to have an I/O
size because I'm a chat application

00:36:07.480 --> 00:36:12.990
of 5 milliseconds because I want very low latent CIO.

00:36:12.989 --> 00:36:16.809
Or I'm really concerned about battery
life and I'm just playing back

00:36:16.809 --> 00:36:21.150
so I'm going to put an I/O size of milliseconds.

00:36:21.150 --> 00:36:26.880
So these are settings that have to do with
hardware and the way that the hardware works.

00:36:26.880 --> 00:36:33.289
And based on your category or based on some
other things that may be going on on the device,

00:36:33.289 --> 00:36:37.000
you may not get these settings, so we call them preferences.

00:36:37.000 --> 00:36:43.409
And you express them through AVAudioSession,
setPreferredHardwareSampleRate,

00:36:43.409 --> 00:36:50.259
setPreferredIOBufferDuration, and the duration
is in seconds or typically milliseconds.

00:36:50.260 --> 00:36:54.520
And sample rate of course in hertz.

00:36:54.519 --> 00:36:56.650
Now what about hardware volume?

00:36:56.650 --> 00:37:01.369
So hardware volume is the volume
that you set with the volume keys.

00:37:01.369 --> 00:37:09.839
And hardware volume is a lot more complicated than you
would think, and we don't try to make it more complicated,

00:37:09.840 --> 00:37:16.309
we try to understand the complications of this
so that it doesn't look complicated to the user.

00:37:16.309 --> 00:37:28.309
So we collect volumes for a whole different set of use
cases, and the volumes are set per category, per route.

00:37:28.309 --> 00:37:34.429
So here is a couple of examples, there's
a volume for a phone call and headphones.

00:37:34.429 --> 00:37:40.699
So when you've got headphones plugged in and
you're on a phone call, there's a volume for that.

00:37:40.699 --> 00:37:47.809
When you're in the playback category, so if your
playback category or your iPod playing back or something

00:37:47.809 --> 00:37:51.299
and you're going out to speaker, there's a volume for that.

00:37:51.300 --> 00:37:56.289
There's a volume for the ring tone, for the speaker,
there's a volume for the ring tone for headphones.

00:37:56.289 --> 00:38:02.489
So there's a whole collection of volumes that
are a pair of the route and the category.

00:38:02.489 --> 00:38:07.139
And not all routes can have volumes,
we don't currently support a volume

00:38:07.139 --> 00:38:11.690
for A2DP, so there's no volume for that route.

00:38:11.690 --> 00:38:18.559
So we understand that there's a use case there,
but we don't have a volume stored for it.

00:38:18.559 --> 00:38:25.000
Now you can get the current volume at any time, and
once again, the volume that you get here will be based

00:38:25.000 --> 00:38:27.969
on the current category and the current route.

00:38:27.969 --> 00:38:34.179
So if you're in the Ambient category in your game and
you're active and you're playing out to the speaker,

00:38:34.179 --> 00:38:37.460
then you'll get the volume for speaker in Ambient.

00:38:37.460 --> 00:38:43.980
Now to set it there is no AudioSession set
property current hardware output volume.

00:38:43.980 --> 00:38:48.869
We decided that this was really user action
and we wanted the user to control this

00:38:48.869 --> 00:38:53.199
and not to have volume set sort
of behind their back if you like.

00:38:53.199 --> 00:39:00.519
And with all of the devices except for the original iPod
Touch, they have volume keys, so there really isn't a need

00:39:00.519 --> 00:39:04.900
to have a hardware volume control here
as well because there's keys there.

00:39:04.900 --> 00:39:10.829
And you can also bring out the slider, and the
slider can be used to set the hardware volume.

00:39:10.829 --> 00:39:14.250
Now this is the hardware volume, this
is the volume across the whole device

00:39:14.250 --> 00:39:17.889
that affects everything, the audio going out.

00:39:17.889 --> 00:39:25.980
You can of course with AudioQueues and AVAudioPlayer set
individual volumes for those objects so you can do mixers

00:39:25.980 --> 00:39:29.059
that are relative different sound sources and so forth.

00:39:29.059 --> 00:39:37.840
So this is just the overall volume of
the audio coming out of the device.

00:39:37.840 --> 00:39:45.800
Another property that's interesting for the
hardware is whether you have input available.

00:39:45.800 --> 00:39:56.140
On the current iPod Touch, if you plug in headset, you
have a microphone now and you have input available.

00:39:56.139 --> 00:40:00.619
If you do not have a headset plugged
in, you have no input available.

00:40:00.619 --> 00:40:05.139
So if you're doing a recording app or
you're doing some kind of input and output,

00:40:05.139 --> 00:40:13.609
you'd probably want to know is the device running with
input, should I allow my application or that feature

00:40:13.610 --> 00:40:20.010
of my application to run if I made input and
input is not there, would be kind of difficult

00:40:20.010 --> 00:40:22.540
for the user to understand what's going on.

00:40:22.539 --> 00:40:29.779
And you can instantiate a property listener so that if
they're on an iPod Touch and they plug in a headset,

00:40:29.780 --> 00:40:37.190
your property listener will fire up and say hey,
you've got input now, and you could change your UI.

00:40:37.190 --> 00:40:43.360
So in order to see some of that in action, I'm going to
get Michael to come up again and give us a demo of that.

00:40:43.360 --> 00:40:48.190
>> So what I have here, as Bill mentioned,
is a second generation iPod Touch.

00:40:48.190 --> 00:40:51.550
And what I'm going to do is I'm going
to start the recording app we have here,

00:40:51.550 --> 00:40:56.300
and you'll see that what it's telling me is I can't
record because there's no input device available.

00:40:56.300 --> 00:41:00.390
And I'm guessing you're probably wondering why
do we demo a recording app that can't record.

00:41:00.389 --> 00:41:09.219
But what we can do is bring back his
headset, and as soon as I plug that in,

00:41:09.219 --> 00:41:13.549
you'll see that now we've actually enabled the record
button and found the characteristics of the input hardware.

00:41:13.550 --> 00:41:17.360
What we've done is just added a property
listener for that is input available.

00:41:17.360 --> 00:41:20.180
When that's available, we use that to update the UI.

00:41:20.179 --> 00:41:23.480
So now I can continue and I can
actually record something here.

00:41:23.480 --> 00:41:30.030
Welcome to WWDC 2009.

00:41:30.030 --> 00:41:35.830
And I'll stop that, actually I'm going to record that again.

00:41:35.829 --> 00:41:36.289
Welcome to WWDC.

00:41:36.289 --> 00:41:39.969
Now of course as Bill mentioned also, the last in rule
is going to play this back through the headphones,

00:41:39.969 --> 00:41:44.669
so to show you guys, I'm going to
unplug that and I'll play it back now.

00:41:44.670 --> 00:41:45.630
>> Welcome to WWDC.

00:41:45.630 --> 00:41:52.640
>> And you can see that basically using that is input
available, we've made a recording application still relevant

00:41:52.639 --> 00:41:57.489
for the iPod Touch, and most importantly
allowed the user interface to update

00:41:57.489 --> 00:42:00.799
to what the available system devices are.

00:42:00.800 --> 00:42:01.970
>> Thank you, Michael.

00:42:01.969 --> 00:42:06.859
Okay, so we're getting near the
end, I hope you're all still awake.

00:42:06.860 --> 00:42:11.010
There will be a test at the end of this session.

00:42:11.010 --> 00:42:12.550
We'll let you leave if you pass.

00:42:12.550 --> 00:42:19.019
So how do we fit all of this together,
what's the order of operations,

00:42:19.019 --> 00:42:21.619
how are we going to get all of
this to work in your application?

00:42:21.619 --> 00:42:23.250
That's a lot of stuff.

00:42:23.250 --> 00:42:30.090
And maybe you don't need to know all this stuff, but it's
good to know that it's there so that you can really try

00:42:30.090 --> 00:42:36.980
to integrate your behavior and your application with
the user and what the user is doing with their device.

00:42:36.980 --> 00:42:43.949
So the typical use case that you do with
AudioSession is that you initialize it.

00:42:43.949 --> 00:42:46.089
You establish some basic state.

00:42:46.090 --> 00:42:52.660
Typically this is your category, you may want
some preferred hardware settings and so forth.

00:42:52.659 --> 00:42:58.139
Then you make yourself active, and then
you have to respond to changes of state.

00:42:58.139 --> 00:43:00.519
Let's have a look through this.

00:43:00.519 --> 00:43:03.509
With AVAudioSession initialization is implicit.

00:43:03.510 --> 00:43:10.690
Once you call any AVAudioSession call will
initialize the AudioSession object for you.

00:43:10.690 --> 00:43:16.599
So this is the line of code we
saw at the start o of my session.

00:43:16.599 --> 00:43:25.230
AVAudioSession has a delegate, and you should implement
those delegate operations that you are interested.

00:43:25.230 --> 00:43:33.480
Most importantly, you should implement the interruption
methods on the delegate, and we'll go through that.

00:43:33.480 --> 00:43:37.119
And you can also use the delegate
to get notifications of changes

00:43:37.119 --> 00:43:42.329
in hardware, like sample rate or something like that.

00:43:42.329 --> 00:43:49.569
So after you've got your session object, then you can
set your category, in this case we're doing SoloAmbient.

00:43:49.570 --> 00:43:54.890
I'm not doing any error checking here,
obviously you might want to do that in your code,

00:43:54.889 --> 00:43:56.500
but this should be pretty straightforward.

00:43:56.500 --> 00:44:04.690
And then at this point you might want to establish any
other state, if you're interested in changing behavior based

00:44:04.690 --> 00:44:12.190
on changes in routes or doing overrides or something, these
are the kinds of things, you either set those state here

00:44:12.190 --> 00:44:17.340
or you would establish the listeners for, you
know, is input available here, something like this.

00:44:17.340 --> 00:44:21.650
So this is where you do all of this kind of setup.

00:44:21.650 --> 00:44:23.539
Then you're ready.

00:44:23.539 --> 00:44:29.070
Finally after 45 minutes we geEt
to the AudioSession, set active.

00:44:29.070 --> 00:44:30.640
Yes, that's all you need to do.

00:44:30.639 --> 00:44:35.710
What that says is hey, I'm around and
I'm going to use the audio system.

00:44:35.710 --> 00:44:45.019
And we have a category for you, so you assert a category and
the behaviors associated with that category are now active.

00:44:45.019 --> 00:44:55.179
And this is where we will apply those settings
and make this the device behavior conform to this.

00:44:55.179 --> 00:44:59.960
So you have use of the audio system based
on the limitations of your category.

00:44:59.960 --> 00:45:06.240
You can use the hardware codecs if you have a
category where mix with others is set to false.

00:45:06.239 --> 00:45:11.119
You can get input, you can get output
based on the category settings.

00:45:11.119 --> 00:45:19.210
Now you don't lose just by accident,
access to the audio system.

00:45:19.210 --> 00:45:27.210
You only lose it from one of three actions; the
session is interrupted through a high priority item,

00:45:27.210 --> 00:45:33.470
if you explicitly deactivate yourself,
or the application is quit.

00:45:33.469 --> 00:45:36.909
Why would you want to explicitly deactivate yourself?

00:45:36.909 --> 00:45:44.259
Well the only real case we can think of is that if
you're doing recording and you want to do your best

00:45:44.260 --> 00:45:50.290
to make sure the recording is not interrupted,
then you would set the record category.

00:45:50.289 --> 00:45:56.230
That means that you've turned off output, there is
no output available to the device at this point.

00:45:56.230 --> 00:46:04.679
So the user is happily recording and they get an
SMS message, they're not going to hear the SMS alert

00:46:04.679 --> 00:46:11.449
because there's no output device available on the
system at the moment because your session owns it.

00:46:11.449 --> 00:46:17.219
So at the end of the recording, if you want to
make the system kind of give it back a little bit,

00:46:17.219 --> 00:46:25.500
you might want to do SetActive to no to make your
ownership of the system, to give that back to the system.

00:46:25.500 --> 00:46:31.960
And so then if they need to play an alert or
something like this, then the system can do that.

00:46:31.960 --> 00:46:37.990
Otherwise, you probably don't need to do the SetActive.

00:46:37.989 --> 00:46:45.929
So one of the common misunderstandings or
misconceptions about AudioSession that I'm hoping to clear

00:46:45.929 --> 00:46:55.149
up with the talk today is what do we mean by categories and
AudioSession active, and what is this kind of, you know,

00:46:55.150 --> 00:46:58.260
how do I understand this and how do I use this?

00:46:58.260 --> 00:47:01.390
And it's not a change on play type of property.

00:47:01.389 --> 00:47:07.769
I don't play one sound as an Ambient sound and
play another sound as a playback category sound.

00:47:07.769 --> 00:47:15.170
Okay, the categories and you being active
describe your application's basic role,

00:47:15.170 --> 00:47:18.230
it's your application's basic personality.

00:47:18.230 --> 00:47:24.849
Now if you have distinct faces in your application where
you might want to change categories or you might want

00:47:24.849 --> 00:47:29.049
to turn audio off and on, then of course you can do that.

00:47:29.050 --> 00:47:33.450
But you really I think need to have a pretty
good understanding if you are going to do that.

00:47:33.449 --> 00:47:41.339
And I think by default, the idea that you just set
things up and make yourself active is really 90 percent

00:47:41.340 --> 00:47:45.840
of the use cases where you really need to worry about it.

00:47:45.840 --> 00:47:50.460
So if you're just doing playback, you can
be active all the time, just get going,

00:47:50.460 --> 00:47:55.170
set your category appropriately,
make yourself active, you're done.

00:47:55.170 --> 00:47:59.740
If you're doing recording and playing
back, pretty much the same thing.

00:47:59.739 --> 00:48:04.479
There's no need to kind of fiddle around with
the categories or set active false or whatever

00:48:04.480 --> 00:48:10.210
because the system can still function
as you'd think the user would expect,

00:48:10.210 --> 00:48:13.710
and everything should be just pretty straightforward.

00:48:13.710 --> 00:48:20.869
If you're doing record only, this is maybe the only real
exception at the sort of top level where you may want

00:48:20.869 --> 00:48:27.289
to at least manage the active state so
that alerts and things can come through

00:48:27.289 --> 00:48:32.759
Because once you do AudioSessionSetActive,
you're potentially interrupting the user,

00:48:32.760 --> 00:48:38.290
you're potentially as we saw with Michael's
demo, interrupting the iPod playback,

00:48:38.289 --> 00:48:40.559
or interrupting something that the user was doing.

00:48:40.559 --> 00:48:46.799
So once you kind of set things up, you make yourself active
then you're done, it's a very understandable experience

00:48:46.800 --> 00:48:50.730
for the user to know how your app
behaves and what's going to happen

00:48:50.730 --> 00:48:53.340
with their device while they're using your application.

00:48:53.340 --> 00:49:01.090
And of course all of this gets
into priorities and interruptions,

00:49:01.090 --> 00:49:06.840
and the one thing that can upset the Apple
cart here for your app is getting interrupted.

00:49:06.840 --> 00:49:10.410
And this happens basically with a phone call.

00:49:10.409 --> 00:49:15.909
So when you're active, you have a priority, and
a phone call or a clock alarm is going to be

00:49:15.909 --> 00:49:20.279
at a higher priority every time
than your application can be.

00:49:20.280 --> 00:49:29.880
So a phone call coming in can interrupt you, and your
application of course can interrupt iPod playback

00:49:29.880 --> 00:49:32.470
if you've got mix with others set to false.

00:49:32.469 --> 00:49:44.089
And so the phone call will also interrupt iPod playback,
it interrupts basically everything, as does a clock alarm.

00:49:44.090 --> 00:49:47.789
So what happens when you get interrupted?

00:49:47.789 --> 00:49:54.289
The system is going to make your session inactive,
it's not going to ask you to become inactive,

00:49:54.289 --> 00:49:58.000
it's not polite about it, that's
why we call it an interruption.

00:49:58.000 --> 00:50:03.619
It just makes your session interactive, any
audio that's playing on the system is stopped.

00:50:03.619 --> 00:50:11.319
And furthermore, because you've been interrupted, you
can't become active again, you can't start playing again

00:50:11.320 --> 00:50:14.960
until the high priority item has completed.

00:50:14.960 --> 00:50:26.780
So we notify you through these two delegate methods on
AVAudioSession, begin interruption, and we interrupt you.

00:50:26.780 --> 00:50:30.980
And we're not telling you that we're going
to interrupt you, we're not telling you hey,

00:50:30.980 --> 00:50:33.820
would you mind kind of stopping some time soon?

00:50:33.820 --> 00:50:37.789
We've stopped you, and you can't start playing again.

00:50:37.789 --> 00:50:45.009
So this is a notification to you that we did this
to you, we're bad people and we've done this.

00:50:45.010 --> 00:50:51.290
So you are inactive, you have lost control of the system.

00:50:51.289 --> 00:50:54.539
What you should do here is to change your state.

00:50:54.539 --> 00:51:02.070
You should reflect to the user anything that you
would want to change to say that hey, I've lost audio,

00:51:02.070 --> 00:51:09.880
your play button could become a stop button, could
become a play, whatever you want to do to show the user

00:51:09.880 --> 00:51:13.000
that you've been interrupted and
your app is no longer making sound.

00:51:13.000 --> 00:51:22.780
Now if the interruption completes and your application is
still running, for instance, if you've got a clock alarm,

00:51:22.780 --> 00:51:27.440
they've got the interruption option and they said
yeah, yeah, I know, and you could come back

00:51:27.440 --> 00:51:30.809
and your application is still there,
it hasn't been terminated.

00:51:30.809 --> 00:51:36.779
In that case, we'll send an end
interruption notification to you.

00:51:36.780 --> 00:51:44.350
This means that we have made your session active,
we're giving it back to you, and you can go ahead

00:51:44.349 --> 00:51:47.159
and do whatever it is that you want to do.

00:51:47.159 --> 00:51:52.210
And you can make your session active, this one,
because the interruption guy has gone away.

00:51:52.210 --> 00:51:57.829
Now you might decide well actually you know,
you've kind of ruined my recording so I'm not going

00:51:57.829 --> 00:52:03.340
out there make my session active again here
because the user has to click a record button.

00:52:03.340 --> 00:52:09.470
So your response may not be to make a session
active, but you can do it at this point,

00:52:09.469 --> 00:52:14.839
and you could resume whatever activity
you think is appropriate.

00:52:14.840 --> 00:52:17.970
So let's have a look at a demo of how you can do this.

00:52:17.969 --> 00:52:23.569
>>What I'm going to show you here is the application
I had up before which is the game application.

00:52:23.570 --> 00:52:29.990
I'm going to launch the application, I'm going to play
the audio, and you'll see it's operating as expected.

00:52:29.989 --> 00:52:32.579
[ Video game sound ]

00:52:32.579 --> 00:52:34.489
>> I can play with the background music.

00:52:34.489 --> 00:52:36.339
[ Music ]

00:52:36.340 --> 00:52:37.120
>> I can keep going.

00:52:37.119 --> 00:52:40.400
And you see now I have an incoming call.

00:52:40.400 --> 00:52:47.119
I'm a little busy right now so I'm going to go ahead
and decline that, probably against my better judgment.

00:52:47.119 --> 00:52:51.599
And you'll see that the application resumes as it
should just kind of right back from where it started.

00:52:51.599 --> 00:52:57.989
Now to contrast that, I have a version of the
application, which you shouldn't use, that's why it's bad.

00:52:57.989 --> 00:53:01.349
[ Video game sound ]

00:53:01.349 --> 00:53:02.799
>> It's really eager.

00:53:02.800 --> 00:53:09.570
So I'm going to launch the bad version and
you'll see it operates just like the normal one,

00:53:09.570 --> 00:53:12.490
but I've removed the interruption handling code from this.

00:53:12.489 --> 00:53:17.489
And you'll see that when an actual
interruption will come in.

00:53:17.489 --> 00:53:18.519
[ Phone ringing ]

00:53:18.519 --> 00:53:22.219
>> Still going to decline it.

00:53:22.219 --> 00:53:27.209
Now I've actually lost audio to my system because
as Bill mentioned, the audio system has been paused,

00:53:27.210 --> 00:53:28.889
but since the application is not handling it,

00:53:28.889 --> 00:53:32.179
what we've actually done is hit a pause
state, but the UI doesn't know that.

00:53:32.179 --> 00:53:38.029
So here I've just kind of put my system in a state that
the user is not going to know what's going on and the UI is

00:53:38.030 --> 00:53:41.850
out of sync with the actual application
audio, so it doesn't really know what to do.

00:53:41.849 --> 00:53:44.809
And as you can imagine, you've kind
of disrupted the user experience here

00:53:44.809 --> 00:53:48.980
because they don't really know why there's
no audio, it just isn't there anymore.

00:53:48.980 --> 00:53:52.869
Now I'm going to run off stage
before he actually tracks me down.

00:53:52.869 --> 00:53:55.190
>> Okay, so that's pretty much it.

00:53:55.190 --> 00:54:03.470
So if you want to use AudioSession to do some more
fine grain control over the behaviors you can,

00:54:03.469 --> 00:54:08.819
you just use it in conjunction with AVAudioSession,
there's no sort of this or that type of thing,

00:54:08.820 --> 00:54:14.559
you just use whichever is most appropriate for you to do.

00:54:14.559 --> 00:54:19.039
AudioSession, you just use those get
and set property calls to manage state.

00:54:19.039 --> 00:54:24.610
You instantiate property listeners for the various
properties as we've seen in some of the slides.

00:54:24.610 --> 00:54:27.890
And that's really it, that's all I wanted to cover.

00:54:27.889 --> 00:54:33.849
So use AVAudioSession, and I think the key
points here are to understand the category,

00:54:33.849 --> 00:54:38.420
what that means to you in terms
of the features that you need.

00:54:38.420 --> 00:54:44.329
If you want to interact with the audio environment
there are of course a collection of APIs to do that.

00:54:44.329 --> 00:54:51.259
And really the fundamental thing about AVAudioSession is
you should at least understand the interruption delegate,

00:54:51.260 --> 00:54:58.760
you should understand begin interruption, end
interruption, otherwise as we saw with Michael's last demo,

00:54:58.760 --> 00:55:04.830
you can get your application in a confused state where
the user just doesn't really know what's going on,

00:55:04.829 --> 00:55:08.829
just because their boss called them to
get back to work, it's a shocking thing.

00:55:08.829 --> 00:55:14.900
So a little bit of work in your app can make
a vast difference to the user experience

00:55:14.900 --> 00:55:21.300
and that's why we thought we would spend all this time
tonight talking about AudioSession in some detail.

00:55:21.300 --> 00:55:27.210
If you need more information, you can contact
Allan Schaffer and I'll leave this detail up here

00:55:27.210 --> 00:55:29.789
so you can get Alan's email and spam him.