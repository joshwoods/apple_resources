WEBVTT

00:00:12.900 --> 00:00:13.620
>> Jason: All right.

00:00:13.619 --> 00:00:14.759
Good morning everyone.

00:00:14.759 --> 00:00:18.259
Thank you very much for showing up
at a 10:30 session on Friday morning.

00:00:18.260 --> 00:00:21.290
I know between the bash and plane flights
out of here it might be a challenge for some.

00:00:21.289 --> 00:00:22.800
But thank you, we really appreciate it.

00:00:22.800 --> 00:00:25.870
My name is Jason Thorpe, I'm the Manager
of the Directory and Sharing Technologies Team

00:00:25.870 --> 00:00:27.990
for Mac OS X server, and that includes Xsan.

00:00:27.989 --> 00:00:34.339
I've seen a lot of you at, at previous WWDC, and I see
familiar faces and a lot of new faces here, so welcome.

00:00:34.340 --> 00:00:38.470
We've got a great session here for you
today talking about Xsan configuration,

00:00:38.469 --> 00:00:41.619
optimization, and integration best practices.

00:00:41.619 --> 00:00:44.049
And so without further ado we've
got a lot of content to cover.

00:00:44.049 --> 00:00:46.009
I'd like to introduce JD Mankovsky.

00:00:46.009 --> 00:00:52.579
[ applause ]

00:00:52.579 --> 00:00:53.199
>> JD: Thank you Jason.

00:00:53.200 --> 00:00:54.010
Good morning.

00:00:54.009 --> 00:00:58.769
[ audience good mornings ]

00:00:58.770 --> 00:01:02.630
>> JD: So my name is JD Mankovsky, I
manage Apples Professional Services.

00:01:02.630 --> 00:01:07.409
We've been doing a lot of Xsan
deployments for, for many, many years.

00:01:07.409 --> 00:01:13.030
And with me today we have Jason Deraleau and Ken
Holden who are on the Professional Services Team

00:01:13.030 --> 00:01:16.290
who actually do a lot of implementations across the country.

00:01:16.290 --> 00:01:18.700
And they're going to share a lot of the best practices.

00:01:18.700 --> 00:01:23.170
This session is something that we've been doing
for many, many years, so we try to, you know,

00:01:23.170 --> 00:01:31.120
every year kind of go through some new best practices,
as well as for those of you who are new to Xsan make sure

00:01:31.120 --> 00:01:34.450
that you've got some of the fundamentals.

00:01:34.450 --> 00:01:38.850
So, first thing is to make sure you're paying attention.

00:01:38.849 --> 00:01:39.759
I know it's early in the morning.

00:01:39.760 --> 00:01:42.440
I have 3 questions for the people in the room here.

00:01:42.439 --> 00:01:49.319
First of all, how many of you are looking
to deploy Xsan in the next 6 to 12 months.

00:01:49.319 --> 00:01:52.559
Wow, so there's a lot of new people in the audience.

00:01:52.560 --> 00:01:58.420
How many of you actually are consultants that are,
you know, deploying Xsan or focused on deploying Xsan?

00:01:58.420 --> 00:02:02.359
OK. And how many of you already have Xsan deployed today?

00:02:02.359 --> 00:02:06.849
Great. So I think we've got a good mix
of a session today to cover, you know,

00:02:06.849 --> 00:02:11.729
a lot of interesting tidbits and
share some best practices with you.

00:02:11.729 --> 00:02:14.189
So we appreciate you coming today.

00:02:14.189 --> 00:02:18.859
So, you know, this is kind of a high level
agenda what you're going to learn today.

00:02:18.860 --> 00:02:21.130
We're going to talk a little bit
about where Xsan is being deployed.

00:02:21.129 --> 00:02:25.129
You know, we're going to talk about,
a little bit about Xsan 2.2.

00:02:25.129 --> 00:02:31.199
So as developers you guys have access to the
upcoming version, and Jason will talk about that.

00:02:31.199 --> 00:02:37.409
We'll talk about some best practices, some backups,
solutions that are available for Xsan, obviously.

00:02:37.409 --> 00:02:38.049
Some tuning.

00:02:38.050 --> 00:02:38.939
Some debugging.

00:02:38.939 --> 00:02:44.979
And we'll talk about Promise, who's the storage vendor
of choice that plugs in, that is supported by Apple.

00:02:44.979 --> 00:02:46.429
And some updates from them as well.

00:02:46.430 --> 00:02:47.689
And then we'll finish with the Q&A's.

00:02:47.689 --> 00:02:49.650
Our session should be about an hour.

00:02:49.650 --> 00:02:51.409
And we'll have at least 50 minutes for Q&A.

00:02:51.409 --> 00:02:54.229
And there'll be a lab this afternoon,
you guys can come and talk to us.

00:02:54.229 --> 00:03:02.389
So the first thing I wanted to mention is, you
know, Xsan has been around for, for many years now.

00:03:02.389 --> 00:03:07.949
And at the beginning, you know, we were very
focused on, you know, the video customers.

00:03:07.949 --> 00:03:13.250
And I'm sure a lot of you that, you know, are looking at
deploying, you know, Xsan for, you know, video deployments.

00:03:13.250 --> 00:03:18.060
But it's been an interesting, it's been an interesting
2 years, because we have a lot of other customers

00:03:18.060 --> 00:03:24.479
that are coming to us wanting to, you know,
to deploy Xsan and other, you know, areas.

00:03:24.479 --> 00:03:26.959
And one of them is forensic.

00:03:26.960 --> 00:03:32.189
So, you know, you might be familiar with forensic, you
know, government agencies do a lot of forensic work.

00:03:32.189 --> 00:03:37.639
They might be capturing, you know, laptops, and wanting
to do a, you know, forensics analysis on the hard drive.

00:03:37.639 --> 00:03:44.159
A lot of, you know, commercial companies who have possibly
disgruntled employees, or one needs to do analysis

00:03:44.159 --> 00:03:50.240
on computers, they all use, you know, they all do forensic
work some way or another through their security groups.

00:03:50.240 --> 00:03:54.610
And what's interesting is that
obviously requires a lot of storage.

00:03:54.610 --> 00:03:59.590
Right? So look at the hard drives today, you get
a new Mac Book Pro with a 500 gig hard drive,

00:03:59.590 --> 00:04:04.729
if you need to do any analysis on that,
that takes a significant amount of storage.

00:04:04.729 --> 00:04:11.119
And so, you know, I wish we could actually show you
a picture, a real picture of what this looked like.

00:04:11.120 --> 00:04:16.370
Well you can imagine like a, you know, 4
racks with about, you know, 32 Promise units.

00:04:16.370 --> 00:04:22.399
This is a 3 letter agency in the,D.C. area.

00:04:22.399 --> 00:04:29.399
But they basically deployed Xsan for forensic use,
and it's about 250 terabytes of usable storage,

00:04:29.399 --> 00:04:38.299
so we don't really like talking about raw storage, but
it's usable, 250, one single volume, 250 terabytes.

00:04:38.300 --> 00:04:46.460
And when deploying this solution they saw improvements
in terms of throughput to do their work in the order of,

00:04:46.459 --> 00:04:52.979
you know, 20 times the speed of what they were accustomed
to before using, you know, a NAS type, you know,

00:04:52.980 --> 00:04:55.520
solution, with, you know, over a gigabit Ethernet.

00:04:55.519 --> 00:04:57.909
So they really sought tremendous improvement.

00:04:57.910 --> 00:05:04.540
And, and so we've been deploying quite a bit of
forensics fans in the past, you know, year or so.

00:05:04.540 --> 00:05:11.160
And then obviously there's some really new interesting
technologies, you know, Podcast Producer is going

00:05:11.160 --> 00:05:15.480
to be what we, you know, think huge with PCP2.

00:05:15.480 --> 00:05:19.629
And I'm sure a lot of you are looking at
deploying Xsan as the backend to Podcast Producer.

00:05:19.629 --> 00:05:24.750
But also final, Final Cut server has also
really picked up since its introduction.

00:05:24.750 --> 00:05:32.829
And that really is a great, those are two great
solutions that integrate well with, with Xsan.

00:05:32.829 --> 00:05:37.279
So with that I want to turn it over to Jason to
kind of give you a high level overview of Xsan.

00:05:37.279 --> 00:05:38.009
Thank you.

00:05:38.009 --> 00:05:42.719
[ applause ]

00:05:42.720 --> 00:05:44.240
>> Jason: Good morning everybody.

00:05:44.240 --> 00:05:47.790
So amongst all the hands there I saw
we did have some newbies to Xsan.

00:05:47.790 --> 00:05:51.280
And so I want to just kind of start out with a
bit of an introduction to Xsan for those of you

00:05:51.279 --> 00:05:54.119
who are not quite as familiar with the platform.

00:05:54.120 --> 00:06:00.149
Just kind of a quick review here in the idea of
how we've come to use clustered file systems.

00:06:00.149 --> 00:06:03.370
If you think back to the classic example
of a local file system, you know,

00:06:03.370 --> 00:06:08.449
you have a hard drive inside your workstation, and then
that's going to be formatted into some kind of format,

00:06:08.449 --> 00:06:13.019
such as HSS Plus, or NTFS, you know, even FAT32.

00:06:13.019 --> 00:06:16.620
But basically the idea is that I
have a storage device that's going

00:06:16.620 --> 00:06:20.709
to be most likely directly attached,
you know maybe a hard drive over setup.

00:06:20.709 --> 00:06:24.250
Some kind of local bus like FireWire or USB.

00:06:24.250 --> 00:06:27.720
Or this could even be a, you know,
like an array of disks, like a,

00:06:27.720 --> 00:06:31.920
arrayed fiber ray that is set up
as the logical unit of LUNs.

00:06:31.920 --> 00:06:35.750
And basically the way that this is going to work is
that when my operating system wants to request data

00:06:35.750 --> 00:06:41.470
from the storage, it's first going to go over that
local bus and take a look at the metadata, right?

00:06:41.470 --> 00:06:45.380
So the metadata and the data are
stored on the same physical device.

00:06:45.379 --> 00:06:48.730
Just a quick side note, no metadata's
going to be your information

00:06:48.730 --> 00:06:51.660
like what particular blocks on the disk contain that data?

00:06:51.660 --> 00:06:52.300
Who owns it?

00:06:52.300 --> 00:06:53.350
What are the permissions?

00:06:53.350 --> 00:06:54.970
You know, that kind of thing.

00:06:54.970 --> 00:07:01.700
So once it locates the metadata on the disk that's going to
again be piped backup to the kernel, which will then go back

00:07:01.699 --> 00:07:05.389
down to the device and request the raw blocks.

00:07:05.389 --> 00:07:10.740
Now when you, to have this kind of scenario the problem
is this doesn't really scale well for multiple use, right?

00:07:10.740 --> 00:07:15.250
It's great when I'm using it within the confines of
a single machine, but when I want to share this data

00:07:15.250 --> 00:07:19.399
with other users I'm then going to have to
find some other method of distributing it.

00:07:19.399 --> 00:07:23.139
So the next step in this evolution
was network files systems.

00:07:23.139 --> 00:07:29.829
And the idea here is now I'm using some sort of
protocol, such as NT, I'm sorry, NFS or AFP, or SMB,

00:07:29.829 --> 00:07:32.740
and we're kind of just abstracting this out one level.

00:07:32.740 --> 00:07:40.720
So instead of having, you know, this, still this hard
drive is kept within the confines of a single server,

00:07:40.720 --> 00:07:44.890
but now that I'm kind of dividing
it out and making it available

00:07:44.889 --> 00:07:48.759
over these different protocols, I
can share that with multiple clients.

00:07:48.759 --> 00:07:52.889
So in this case, now we're going to have the
client initiate the connection over AFB again,

00:07:52.889 --> 00:07:55.329
and that's going to cross over the Ethernet.

00:07:55.329 --> 00:08:00.620
Right? And now the server is going to perform those same
kind of operations that we saw in the previous slide.

00:08:00.620 --> 00:08:06.009
So the idea is that it's going to go over the local
bus, connect into the storage to locate the metadata,

00:08:06.009 --> 00:08:11.610
and then from there find the actual blocks
and pipe those backup to the client.

00:08:11.610 --> 00:08:17.569
Now again this is great when you want to share this
information over a connection such as Ethernet.

00:08:17.569 --> 00:08:22.879
But the problem is again this isn't going to get you the,
you're still kind of limiting yourself in that bottleneck.

00:08:22.879 --> 00:08:26.879
So the next step along the evolution
was to a clustered file system.

00:08:26.879 --> 00:08:31.670
And in this case what we're going to have is a storage
system that is going to use most likely Fibre Channel.

00:08:31.670 --> 00:08:37.080
We have an integration of a couple of different networks,
so for example, the, Ethernet network for metadata,

00:08:37.080 --> 00:08:39.530
an Ethernet network for the front side of the house.

00:08:39.529 --> 00:08:45.639
And because of these different systems working in concert
we're able to share this storage to even more devices.

00:08:45.639 --> 00:08:49.039
So in the case of a clustered file system
what's going to happen here is, again,

00:08:49.039 --> 00:08:51.500
you know I'm going to have my client initiate a request.

00:08:51.500 --> 00:08:54.789
But this time it's going to go over
Ethernet, over the metadata network.

00:08:54.789 --> 00:08:59.949
And the idea is I have these two servers, or, well,
at least two servers in your best deployments.

00:08:59.950 --> 00:09:04.490
But basically those are going to be responsible
for locating the data on the storage.

00:09:04.490 --> 00:09:09.389
So the metadata controllers will go over Fibre
Channel at that point and access the metadata LUN

00:09:09.389 --> 00:09:14.080
to locate the metadata that's related
to the particular request.

00:09:14.080 --> 00:09:17.570
Once that's occurred that information's
going to be sent back to the client,

00:09:17.570 --> 00:09:20.990
which will then go over Fibre Channel
to access the data directly.

00:09:20.990 --> 00:09:25.740
So the idea here is I have a little bit of a slow down
as far as when I'm going to look for that data initially,

00:09:25.740 --> 00:09:31.509
but once I know where the data is on the storage
I can over Fibre Channel and access it over fiber.

00:09:31.509 --> 00:09:36.429
The other advantage of this, of course, is that
when I have this, these larger rays of disks,

00:09:36.429 --> 00:09:42.559
I'm much more able to expand that storage down the road,
I'm able to allow concurrent access to the storage.

00:09:42.559 --> 00:09:46.629
And really the critical part of this that might
differentiate it from other SAN products is

00:09:46.629 --> 00:09:51.929
that multiple clients can access
the storage at the same time.

00:09:51.929 --> 00:09:55.759
This is phenomenal for when you're working
with large data files and you want to be able

00:09:55.759 --> 00:09:57.799
to distribute that load across different machines.

00:09:57.799 --> 00:10:05.319
So one of the things we introduced in
Xsan 2 is this concept of volume presets.

00:10:05.320 --> 00:10:08.720
And for those of you who kind of worked with the
product as you have come up through the years,

00:10:08.720 --> 00:10:12.620
you may remember a lot of this was sitting down
with a calculator and figuring out, you know,

00:10:12.620 --> 00:10:17.139
what's the optimal striping, or the optimal
block size for my particular application?

00:10:17.139 --> 00:10:21.699
In the earlier days this took, like I said, a good
amount of work to figure out what was going to be best,

00:10:21.700 --> 00:10:26.620
especially when you're working with Xserve RAID and figuring
out what the optimal settings were for your buffers.

00:10:26.620 --> 00:10:30.490
But with Xsan 2 we've actually done a
lot of that work for you back in the lab.

00:10:30.490 --> 00:10:35.740
And the idea is that when you're initially configuring your
storage and setting up the volume, you have the ability go

00:10:35.740 --> 00:10:40.889
to in and choose a preset that kind of fits
the type of deployment that you're doing.

00:10:40.889 --> 00:10:43.919
Now what are these things really working with?

00:10:43.919 --> 00:10:47.589
There's several different variables
related to an Xsan volume

00:10:47.590 --> 00:10:52.330
that are paramount in how the storage is going to be used.

00:10:52.330 --> 00:10:54.940
And a great example of this is storage pool sizing.

00:10:54.940 --> 00:11:01.750
And what we're doing here basically is determining what
is the best ratio of LUNs, which are again like a a set

00:11:01.750 --> 00:11:06.769
of disks working together as one
logical unit, and the number of pools

00:11:06.769 --> 00:11:10.220
that we put these LUNs into to allocate the storage.

00:11:10.220 --> 00:11:16.580
And basically the key concepts are that we have more LUNs,
there's going to be more spindles working at that data.

00:11:16.580 --> 00:11:22.680
So if I need a lot of throughput I'm going to
want to use a larger ratio of LUNs per pool.

00:11:22.679 --> 00:11:25.959
While the other factor that we're
kind of working against is that pools,

00:11:25.960 --> 00:11:28.930
in order to work best, should be uniform in size.

00:11:28.929 --> 00:11:35.389
So if I have, for example, 4 LUNs per pool and I want
to grow my storage down the road, I'm going to have to,

00:11:35.389 --> 00:11:38.000
again, buy another 4 LUNs worth of storage.

00:11:38.000 --> 00:11:43.200
So it's kind of a balance between the cost of upgrading
and expanding your storage versus the throughput you need

00:11:43.200 --> 00:11:48.970
to support the type of access you're
going to be supporting for your clients.

00:11:48.970 --> 00:11:53.600
Another variable we're taking a look at is going
to be the block and stripe sizing of the storage.

00:11:53.600 --> 00:11:59.450
And basically the idea here is how are we allocating
chunks of data across these LUNs as we stripe them?

00:11:59.450 --> 00:12:04.770
And the thing we want to look at here is, again larger
amounts of data are going to help with throughput.

00:12:04.769 --> 00:12:10.399
So if I'm using a larger block size and stripe size I'm
going to be able to read larger chucks of data at a time.

00:12:10.399 --> 00:12:15.549
This is great when I'm working with large continuous files
where I need a lot of throughput to read in all that data.

00:12:15.549 --> 00:12:21.809
However, if I'm using an application, such as, you know,
maybe file services or something where my files are smaller,

00:12:21.809 --> 00:12:25.269
you know I'm going to kind of steer towards
a smaller block size to conserve space,

00:12:25.269 --> 00:12:30.259
and I think everybody here can remember the old days when
you used to have huge blocks, and you just, you know,

00:12:30.259 --> 00:12:35.169
you allocate a file and it would chew up a lot
more space than was really required for that data.

00:12:35.169 --> 00:12:38.439
So again, these same kind of concepts
apply here, but we're just applying them

00:12:38.440 --> 00:12:43.180
to large amounts of hard drives at a time.

00:12:43.179 --> 00:12:46.719
One last variable we're taking a look at
is the allocation strategy of the volume.

00:12:46.720 --> 00:12:51.889
And this basically comes down to the way
that files are allocated to different pools.

00:12:51.889 --> 00:12:55.830
And depending on the allocation strategy,
you can actually make different use

00:12:55.830 --> 00:12:59.759
and make sure you're getting the optimal
amount of space out of the, I'm sorry,

00:12:59.759 --> 00:13:01.899
the optimal amount of use out of the storage.

00:13:01.899 --> 00:13:06.980
But you also want to make sure that as you
allocate files to the storage devices that you kind

00:13:06.980 --> 00:13:09.730
of balance them between different pools of storage.

00:13:09.730 --> 00:13:16.840
The idea is that, you know, as my clients go to request
data, if I have multiple clients accessing that storage,

00:13:16.840 --> 00:13:20.139
they're all going to kinda be vying
for that same set of spindles.

00:13:20.139 --> 00:13:23.360
So if I can distribute the data across different pools,

00:13:23.360 --> 00:13:27.279
then different clients can access
different storage simultaneously.

00:13:27.279 --> 00:13:32.709
And by the same token, when I'm working with
applications, such as video, where I have multiple streams

00:13:32.710 --> 00:13:38.050
of HD I can have my client kind of rotate
between these different pools of storage.

00:13:38.049 --> 00:13:43.579
The most common one you're going to be seeing with this
deployment is going to be a Round-Robin distribution.

00:13:43.580 --> 00:13:48.660
And basically the idea with Round-Robin is that as
the files are getting written out to the storage,

00:13:48.659 --> 00:13:51.649
each file will be alternated amongst a different pool.

00:13:51.649 --> 00:13:57.149
So if I'm, you know, ingesting different streams of video
content, that first stream might go into the first pool,

00:13:57.149 --> 00:14:00.720
and then the second stream into
the second pool, and so forth.

00:14:00.720 --> 00:14:05.279
This is again, great to balance out the storage when you're
working with it, but you kind of run into a little bit

00:14:05.279 --> 00:14:09.019
of a headache when you go to expand the size of the storage,

00:14:09.019 --> 00:14:14.519
and this is because at that point the new storage
you're bringing into the environment is going to be not,

00:14:14.519 --> 00:14:17.019
you know, not as full as the existing storage.

00:14:17.019 --> 00:14:20.929
So what we've seen is that when you're
working with the allocation strategy,

00:14:20.929 --> 00:14:23.899
you can actually change this after you've set up the volume.

00:14:23.899 --> 00:14:27.730
So I add that new storage, and I
could choose the balance strategy.

00:14:27.730 --> 00:14:31.460
And what the balance strategy, what's
that going to do is fill up that,

00:14:31.460 --> 00:14:34.360
that new storage until it's about as even as the other ones.

00:14:34.360 --> 00:14:42.389
And at that point I could switch it back to Round-Robin
to again, rotate the files across that storage.

00:14:42.389 --> 00:14:47.699
So once you've picked out an allocation strategy, and
you have the right stripe size, and you've got the preset

00:14:47.700 --> 00:14:50.930
that you think is going to work best for you,
there's some things you can do to kind of check

00:14:50.929 --> 00:14:54.329
on how this is really working out, right?

00:14:54.330 --> 00:14:59.629
And basically the idea here is that I want to go
in and determine, have I set this volume up right?

00:14:59.629 --> 00:15:01.659
Is it supporting the application I need?

00:15:01.659 --> 00:15:04.589
And for that there's a couple of
different tools you can use.

00:15:04.590 --> 00:15:10.480
And for example, you can go in and the real
simple one is, you can just grep the cvlog file.

00:15:10.480 --> 00:15:12.899
And in that file you just look for the term SUMMARY.

00:15:12.899 --> 00:15:18.340
And every hour or so the FSM daemons that host
the volume will log some information in there.

00:15:18.340 --> 00:15:23.070
Specifically what you're looking for is the
amount of time it takes to write to metadata.

00:15:23.070 --> 00:15:26.510
In most Xsan deployments your bottleneck
really becomes metadata.

00:15:26.509 --> 00:15:30.340
You're looking at the Ethernet connection
to get to that metadata network,

00:15:30.340 --> 00:15:32.750
that's really the slowest part of this entire system.

00:15:32.750 --> 00:15:37.090
Everything else is going to be done over 4 gigabit,
8 gigabit fiber and if you have the new stuff.

00:15:37.090 --> 00:15:40.860
So basically what you can do is grep
that log, look for these values,

00:15:40.860 --> 00:15:44.680
and you'll see a minimum average and
maximum time it's taking to read.

00:15:44.679 --> 00:15:49.349
And in our testing we've seen that, you know, the best
values are going to be under 500 milliseconds or so.

00:15:49.350 --> 00:15:54.710
So if you see anything beyond that range you might
want to be concerned, because the degradation

00:15:54.710 --> 00:15:59.889
of metadata performance will have a profound
effect upon the rest of your access to the volume.

00:15:59.889 --> 00:16:03.259
Some other simple stuff you could do,
you know, monitor copy performance.

00:16:03.259 --> 00:16:07.419
Sit there and use the stopwatch on your
iPhone, see how long it takes to copy

00:16:07.419 --> 00:16:10.149
that file over to the storage and the finder.

00:16:10.149 --> 00:16:14.439
Remember, what you're really doing here is testing
what your user experience is going to be like.

00:16:14.440 --> 00:16:18.850
So in order to tune for the application you want
to make sure that the storage is set up in a way

00:16:18.850 --> 00:16:21.840
that allows your users to have a pleasant experience.

00:16:21.840 --> 00:16:26.990
Another similar thing you can do, you know,
do some UNIX copies and use the time command.

00:16:26.990 --> 00:16:29.830
And just see how long it's taking to work with that storage.

00:16:29.830 --> 00:16:32.860
Make sure it's as fast as you can get it,
because otherwise you're going to hear about it

00:16:32.860 --> 00:16:36.190
when the users are waiting for that work to get done.

00:16:36.190 --> 00:16:39.550
A couple of other places you can look,
you know, don't exclude your devices.

00:16:39.549 --> 00:16:42.099
A lot of the newer Fibre Channel
switches have some tools in there.

00:16:42.100 --> 00:16:43.899
You can use SNMP monitoring.

00:16:43.899 --> 00:16:48.039
A lot of them have like a web interface
you can go into and take a look at.

00:16:48.039 --> 00:16:50.969
But basically look for information on, maybe, errors;

00:16:50.970 --> 00:16:55.480
know how long they might get some latency
information about the fiber performance.

00:16:55.480 --> 00:16:59.220
Whatever you can find from the switch vendor,
and they'd probably know better than we would.

00:16:59.220 --> 00:17:04.309
As far as storage devices go, you know there's
some great stuff in the different storage arrays

00:17:04.309 --> 00:17:05.889
that are coming out in the market right now.

00:17:05.890 --> 00:17:09.910
We recently partnered up with Promise and
JD will get in this a little bit later.

00:17:09.910 --> 00:17:14.150
But in the new Promise firmware there's actually
some options in there to monitor performance

00:17:14.150 --> 00:17:19.180
of the storage device, so I can see information
about how long is it taking to seek across the disk,

00:17:19.180 --> 00:17:25.420
how long is it taking to fill those buffers and make sure
that I'm getting the throughput I need for my application.

00:17:25.420 --> 00:17:32.330
So let's just kind of briefly go over some of these
different volume scenarios and give an idea of what they do.

00:17:32.329 --> 00:17:35.929
They can kind of be divided into a couple major categories.

00:17:35.930 --> 00:17:38.509
The first ones are going to be video solutions.

00:17:38.509 --> 00:17:43.720
So for this what you'll tend to see is that you're going
to again use more disks, because you need to support

00:17:43.720 --> 00:17:47.100
that throughput for these high bandwidths applications.

00:17:47.099 --> 00:17:50.839
So in a video deployment with a video preset you'll tend

00:17:50.839 --> 00:17:55.609
to see a volume allocation strategy
that's going to be again Round-Robin.

00:17:55.609 --> 00:17:59.049
You're going to see some presets that are
along the lines of using 4 LUNs per pool,

00:17:59.049 --> 00:18:02.789
so that I can have many, many spindles working on that data.

00:18:02.789 --> 00:18:09.480
And again, we're going to tune for a larger
number of, for large files for these operations.

00:18:09.480 --> 00:18:14.220
You know? Anybody who's worked with a video workflow can
tell you that HD video, and especially when you're getting

00:18:14.220 --> 00:18:17.210
into the higher resolutions, takes a lot of space.

00:18:17.210 --> 00:18:22.620
And basically in order to tune properly
for those types of client applications,

00:18:22.619 --> 00:18:28.459
you want to make sure that you're using an Xsan preset
that will tune for large files and high throughput.

00:18:28.460 --> 00:18:32.120
So some of the workloads, I'm sorry,
some of the presets you'll see that work

00:18:32.119 --> 00:18:37.199
with this will be something along the lines of Final
Cut Studio, Final Cut Server, Podcast Producer.

00:18:37.200 --> 00:18:43.470
You can actually tune it for a particular type of
codec, so there's options in there for uncompressed HD,

00:18:43.470 --> 00:18:48.490
or standard definition, or whatever's
appropriate for your application.

00:18:48.490 --> 00:18:54.920
Another major category of the types of
presets that you're using is for IT solutions.

00:18:54.920 --> 00:19:01.000
And basically what these, the focus
tends to be on a smaller file size.

00:19:01.000 --> 00:19:03.599
Typically with an IT solution your bottlenecks not going

00:19:03.599 --> 00:19:07.469
to be really the fiber access, but
it's going to end up being Ethernet.

00:19:07.470 --> 00:19:14.559
So for solutions such as mail servers, you know, PHDs,
this kind of thing is, the limiting factor's going to be

00:19:14.559 --> 00:19:16.750
that Ethernet on the other side of the server.

00:19:16.750 --> 00:19:24.410
So with these types of volumes what actually ends up
happening is the most, the most performance, the, I'm sorry,

00:19:24.410 --> 00:19:27.960
the key point of performance to monitor
is going to be metadata performance.

00:19:27.960 --> 00:19:33.140
If you think about a video workflow you tend to have a
small number of large files, and that's not going to incur

00:19:33.140 --> 00:19:39.430
as much data, metadata use as using
a large number of small files.

00:19:39.430 --> 00:19:45.620
So with an IT solution what you're looking at
is, again, optimizing that metadata performance.

00:19:45.619 --> 00:19:49.479
The metadata is going to be the
bottleneck in your deployment.

00:19:49.480 --> 00:19:52.120
A couple of things we've found
pretty good luck with, with this is,

00:19:52.119 --> 00:19:54.649
we've actually started starting
using multiple metadata LUNs.

00:19:54.650 --> 00:20:00.190
This is something's we've been testing, and really
the key benefit of this is that when you're using more

00:20:00.190 --> 00:20:06.630
than one metadata LUN, the Xsan software can divide up
the file system journal, and the file system metadata.

00:20:06.630 --> 00:20:09.560
And what that allows us to do is as
it's working with this data it can kind

00:20:09.559 --> 00:20:12.669
of split the operation between those two different pools.

00:20:12.670 --> 00:20:18.190
So that allows the different spindles that are working
on that data to be able to work on it simultaneously.

00:20:18.190 --> 00:20:23.799
The other big focus when you're using IT
solutions is going to be conserving space.

00:20:23.799 --> 00:20:27.609
So what you'll tend to see are smaller block
and stripe sizes, and you'll also see that,

00:20:27.609 --> 00:20:30.169
that are going to use fewer number of LUNs per pool.

00:20:30.170 --> 00:20:35.019
So that the, first of all your expansion of the storage
is a little bit cheaper for you, and also again it's going

00:20:35.019 --> 00:20:39.789
to make more, more conservative use of
that storage as it goes through the system.

00:20:39.789 --> 00:20:45.329
As JD was talking about earlier, you know, a new
area we've been looking at is computer forensics.

00:20:45.329 --> 00:20:50.329
And initially you might this is real
similar to the file server solution, right?

00:20:50.329 --> 00:20:52.789
But really the thing here is these files are big.

00:20:52.789 --> 00:20:59.069
If you're working applications like NKFDK
you're taking images of entire hard drives.

00:20:59.069 --> 00:21:05.939
And, you know, in the newest machines are coming with 500
gig drives, people are, it's not unusual to see RAID arrays,

00:21:05.940 --> 00:21:09.410
especially in some of the newer,
newer gamer rigs and stuff like that.

00:21:09.410 --> 00:21:13.860
So you need a lot of storage to be able
to keep all this forensic information.

00:21:13.859 --> 00:21:18.369
Because it is a newer area of our system we aren't
really, we don't have a preset necessarily for it.

00:21:18.369 --> 00:21:21.779
But you do want to use a larger number of LUNs per pool.

00:21:21.779 --> 00:21:29.109
Basically this allows it again to put more spindles at it,
and also going to be using a more throughput to support

00:21:29.109 --> 00:21:32.740
that application as it goes to read
these large files from the storage.

00:21:32.740 --> 00:21:35.339
So you definitely want to tune for a larger file size.

00:21:35.339 --> 00:21:43.399
And make sure that the storage is going to be
supporting that application in the best way possible.

00:21:43.400 --> 00:21:49.680
So once you've gotten everything all set up the key point
you want to do is backing up your configuration information.

00:21:49.680 --> 00:21:56.570
I know I, we were actually, before the session, we
were just talking about an email came through where one

00:21:56.569 --> 00:22:02.389
of our clients had a problem where they accidentally
overwrote some information on their Xsan metadata controller

00:22:02.390 --> 00:22:05.450
and after that they could no longer
find the data on the SAN.

00:22:05.450 --> 00:22:07.830
And really the information's still there, right?

00:22:07.829 --> 00:22:12.519
Because they didn't erase the files necessarily, but
because they didn't have the geometry information,

00:22:12.519 --> 00:22:16.579
the Xsan metadata controller could no
longer locate, say, the metadata LUN.

00:22:16.579 --> 00:22:18.619
So these files are critical.

00:22:18.619 --> 00:22:23.029
And you want to make sure that anytime you make any kind
of change to your SAN, whether it be expanding the size

00:22:23.029 --> 00:22:29.980
of the storage, changing allocation strategy,
adding clients or controllers, backup this file.

00:22:29.980 --> 00:22:34.849
Easiest way to do it, run a CD gather on all the
metadata controllers, and basically that, you know,

00:22:34.849 --> 00:22:39.519
take the resulting file and send it
to your MobileMe account, email it,

00:22:39.519 --> 00:22:42.079
print it out on the wall, do something to keep it.

00:22:42.079 --> 00:22:46.909
And basically this is going to preserve all of
the geometry information related to your SAN.

00:22:46.910 --> 00:22:50.040
Again, run it on all of the metadata controllers,
so that if you have a problem with any

00:22:50.039 --> 00:22:52.430
of them you can restore it back at a later time.

00:22:52.430 --> 00:22:57.930
If you're particularly paranoid, you know, go
ahead and use a launchd job to back it up weekly

00:22:57.930 --> 00:23:01.549
Maybe you're using Time Machine, and Time
Machine's going to preserve the files.

00:23:01.549 --> 00:23:05.109
But no matter what you're doing, you want to make
sure that you have this information for down the road

00:23:05.109 --> 00:23:08.449
in case you have a problem with the metadata controllers.

00:23:08.450 --> 00:23:11.620
And with that I'd like at this point
welcome Jason Thorp back on the stage,

00:23:11.619 --> 00:23:14.009
and he's going to give us some information about Xsan 2.2.

00:23:14.009 --> 00:23:18.549
[ applause ]

00:23:18.549 --> 00:23:18.809
>> Jason Thorpe: All right.

00:23:18.809 --> 00:23:23.029
Great. OK.

00:23:23.029 --> 00:23:27.809
So you may have heard us talking about
Xsan 2.2 in some of the various labs.

00:23:27.809 --> 00:23:30.809
This is some actual details here.

00:23:30.809 --> 00:23:37.440
And this is actually available to you on the
developer website, the seed is available now.

00:23:37.440 --> 00:23:42.529
Basically what we've done is we've fixed
a lot of bugs, a lot in Xsan Admin.

00:23:42.529 --> 00:23:44.180
But the primary driver for this, of course,

00:23:44.180 --> 00:23:47.090
was compatibility with Snow Leopard,
the new version of the operating system.

00:23:47.089 --> 00:23:49.009
That's kind of the main feature.

00:23:49.009 --> 00:23:51.220
However, we didn't stop there.

00:23:51.220 --> 00:23:56.980
We took this opportunity to, since we have a sort
of better foundation in the operating system,

00:23:56.980 --> 00:24:00.690
took this opportunity to make some
improvements in the actual file system itself.

00:24:00.690 --> 00:24:06.049
And the main one there is we now have support for
Native Finder info and resource fork information,

00:24:06.049 --> 00:24:08.909
and extended attributes, and all
that kind of other good stuff

00:24:08.910 --> 00:24:13.480
that makes files systems sort of
first class in Mac OS X environment.

00:24:13.480 --> 00:24:17.420
So the big thing there is no more Apple double files.

00:24:17.420 --> 00:24:18.539
Yeah. Yeah.

00:24:18.539 --> 00:24:20.569
[ applause ]

00:24:20.569 --> 00:24:24.669
Nothing like cutting the number of
files in your volume in half, right?

00:24:24.670 --> 00:24:29.519
So that feature is available for systems
that have sort of all new clients.

00:24:29.519 --> 00:24:31.869
We do support legacy clients in the SAN.

00:24:31.869 --> 00:24:37.519
And there'll be a migration path for that, so you can start
out with your existing volumes and actually upgrade them

00:24:37.519 --> 00:24:39.579
to the sort of native way of doing things.

00:24:39.579 --> 00:24:43.629
Or if you have older clients, understand
you can keep the old way.

00:24:43.630 --> 00:24:45.590
So this will be an Intel-only release.

00:24:45.589 --> 00:24:48.619
We are not going to support Power
PC in this next update.

00:24:48.619 --> 00:24:52.969
However, Xsan 2.1.1 clients on
Power PC will still be supported.

00:24:52.970 --> 00:24:56.319
And we are removing support for Xsan 1 clients.

00:24:56.319 --> 00:24:59.740
So everyone should be up on Xsan 2 by now.

00:24:59.740 --> 00:25:04.509
If you're not I really strongly encourage you to do
so, because we fixed a whole lot of bugs in Xsan 2.

00:25:04.509 --> 00:25:07.329
And that pretty much is it.

00:25:07.329 --> 00:25:12.720
I will be happy to answer questions about Xsan 2.2 during
the Q and A, and also in the Xsan lab later this afternoon.

00:25:12.720 --> 00:25:16.009
And with that I'm going to bring up Ken.

00:25:16.009 --> 00:25:22.000
[ applause ]

00:25:22.000 --> 00:25:24.380
>> Ken: Thank you Jason.

00:25:24.380 --> 00:25:26.340
So I'm here to talk about best practices today.

00:25:26.339 --> 00:25:30.319
As many of you know if you've deployed Xsan in the past,

00:25:30.319 --> 00:25:34.509
this is simply just installing the Xsan
software, configuring it, and moving forward.

00:25:34.509 --> 00:25:41.119
As there is many third party components that make up your
Xsan, each with their own configurations and best practices.

00:25:41.119 --> 00:25:46.199
So as JD mentioned earlier, we've deployed, you
know, hundreds of SANs since this initial release.

00:25:46.200 --> 00:25:52.360
And through a lot of trial and error, and field
testing to come up with a set of best practices

00:25:52.359 --> 00:25:56.479
that really encompass the third part
devices as well as the Xsan software.

00:25:56.480 --> 00:26:02.769
So if you're going to be deploying Xsan we highly recommend
that you follow some of these Apple best practices

00:26:02.769 --> 00:26:05.450
in order to have a solid Xsan deployment.

00:26:05.450 --> 00:26:09.569
So the first thing I want to talk about
is networking, and specifically I want

00:26:09.569 --> 00:26:11.480
to talk about the metadata Ethernet network.

00:26:11.480 --> 00:26:15.490
And this is something that a lot of times is overlooked.

00:26:15.490 --> 00:26:21.380
Each time your Xsan clients try to communicate
with the Xsan volume, the communication is handled

00:26:21.380 --> 00:26:27.810
by your metadata controllers over this metadata gigabyte
Ethernet switch, or excuse me, just regular network.

00:26:27.809 --> 00:26:33.539
So we recommend to have the fastest
switch available with the lowest latency.

00:26:33.539 --> 00:26:35.529
And therefore we do recommend gigabyte switches.

00:26:35.529 --> 00:26:40.809
It's not a requirement, but we have seen clients that
have used 100 megabit switches and it has some latency.

00:26:40.809 --> 00:26:43.250
So we definitely prefer them.

00:26:43.250 --> 00:26:46.200
And also with the switch we recommend
that it be a dumb switch

00:26:46.200 --> 00:26:50.890
So that's good, because you don't have to go out
and buy a $10,000, you know, Cisco gigabyte switch.

00:26:50.890 --> 00:26:55.080
You want something that has less management
capabilities, or little to no management capabilities.

00:26:55.079 --> 00:27:00.019
As any of those advanced features can
actually cause latency on your switches.

00:27:00.019 --> 00:27:06.160
Also you want to be sure that plugged into this
switch is only your metadata clients and your, your,

00:27:06.160 --> 00:27:09.070
your Xsan clients and your Xsan metadata controllers.

00:27:09.069 --> 00:27:14.139
So avoid VLANing you switch and using
it for your public's networks as well.

00:27:14.140 --> 00:27:19.250
When you're IPing your Xsan clients and
metadata controller, stay away from the ACP.

00:27:19.250 --> 00:27:21.589
The ACP with static is supported.

00:27:21.589 --> 00:27:24.659
But just general the ACP we want to avoid.

00:27:24.660 --> 00:27:30.519
And also you want to make sure that the
network used for metadata is unique.

00:27:30.519 --> 00:27:35.779
So when you're deploying it the best thing to do is
before you configure your metadata interface with your,

00:27:35.779 --> 00:27:38.000
your private network that you're going to use for metadata,

00:27:38.000 --> 00:27:41.500
be sure to try to ping the broadcast address
to that address space that you're using.

00:27:41.500 --> 00:27:49.890
So if you're using 192168.1, with a, you
know, 524, just ping the 192168.1.255.

00:27:49.890 --> 00:27:53.509
Make sure it's not pinging out the public
interface and getting any responses.

00:27:53.509 --> 00:27:55.089
If it is you want to choose a different network.

00:27:55.089 --> 00:27:58.959
You want to make sure that that
network is not routed anywhere else.

00:27:58.960 --> 00:28:05.630
Also if you switch has Port Fast capabilities you want to
be sure that you disable, or excuse me, enable port fast.

00:28:05.630 --> 00:28:11.340
If you don't and the switch supports port fast, what can
happen is your operating system is going to boot prior

00:28:11.339 --> 00:28:17.619
to having a network link established, and this is going to
cause issues or the bind not to mount at boot.

00:28:17.619 --> 00:28:19.639
So next thing, DNS.

00:28:19.640 --> 00:28:24.910
If you heard in many other slides, or many other
presentations here this week is, you know, DNS is critical.

00:28:24.910 --> 00:28:26.230
Xsan is no different.

00:28:26.230 --> 00:28:29.589
Actually Xsan is, I find its even more finicky with DNS.

00:28:29.589 --> 00:28:36.289
So we definitely want and require forward or reverse
records for every metadata and public interface

00:28:36.289 --> 00:28:39.279
of every Xsan client and metadata controller.

00:28:39.279 --> 00:28:43.569
You want to make sure that this is configured
properly prior to even installing Xsan.

00:28:43.569 --> 00:28:47.399
So, so definitely important.

00:28:47.400 --> 00:28:52.060
When you're deploying that and you're pulling
your own DNS you can use one forward domain.

00:28:52.059 --> 00:28:58.950
So if you have example.com, you can create
records for your servers as server.example.com,.

00:28:58.950 --> 00:29:00.330
pointing to your public IP address.

00:29:00.329 --> 00:29:02.009
And for your metadata you can create records

00:29:02.009 --> 00:29:06.920
like server-Xsan.example.com pointing
to your metadata IP address.

00:29:06.920 --> 00:29:14.400
So for there you have a public zone, and, a forward zone,
excuse me, and then two reverse zones on your DNS server.

00:29:14.400 --> 00:29:17.620
And your DNS server doesn't need
to be on the metadata controllers.

00:29:17.619 --> 00:29:20.039
I mean it can be in smaller networks that's fine.

00:29:20.039 --> 00:29:24.359
But in your larger environments may have
active directory DNS, you may have 2 IP

00:29:24.359 --> 00:29:28.079
or another BIND solution, or DNS for your open directory.

00:29:28.079 --> 00:29:29.210
So you can utilize that.

00:29:29.210 --> 00:29:33.309
We just care about forward and
reverse records for each metadata

00:29:33.309 --> 00:29:37.129
and public interface of every client
and metadata controller.

00:29:37.130 --> 00:29:44.440
In certain situations you may find that your
DNS admins don't want to host a reverse records,

00:29:44.440 --> 00:29:47.140
a reverse zone for your metadata IP addressing.

00:29:47.140 --> 00:29:50.320
We see this a lot in the federal space
where the AD admins don't want

00:29:50.319 --> 00:29:55.179
to host a 192168.X or whateverh in their DNS.

00:29:55.180 --> 00:30:01.380
So in these certain environments where they don't allow us
to run DNS on our own servers and we're not allowed to have

00:30:01.380 --> 00:30:07.640
that second metadata reverse domain, we're
able to use host files for the metadata.

00:30:07.640 --> 00:30:12.570
So we don't recommend, we always recommend using DNS,
but in the situations where you need to use host files,

00:30:12.569 --> 00:30:19.139
just be sure that the host files contains, you know,
metadata IP to fully qualified name of every Xsan client

00:30:19.140 --> 00:30:24.790
in metadata, and make sure that their metadata controller,
and make sure that that host file is copied to every client

00:30:24.789 --> 00:30:28.569
and metadata controller prior to installing Xsan.

00:30:28.569 --> 00:30:35.079
So once you've established proper DNS you want to make sure
that each client in metadata controller can query the names,

00:30:35.079 --> 00:30:37.470
or query the DNS, for both forward and reverse.

00:30:37.470 --> 00:30:42.269
So you can use commands like dig, or nslookup,
or host to, just to run a check to make sure

00:30:42.269 --> 00:30:45.809
that the IP translates hostname, and hostname translates IP.

00:30:45.809 --> 00:30:48.819
The second thing you want to do once you've
verified your DNS is you want to make sure

00:30:48.819 --> 00:30:52.609
that the metadata controllers fix
the servers and the clients,

00:30:52.609 --> 00:30:56.849
that what they think that their local
hostname is matches what DNS thinks it is.

00:30:56.849 --> 00:31:01.679
So for servers you can use the
change IP command -checkhostname.

00:31:01.680 --> 00:31:06.279
And this will actually forward the name servers
for the, what DNS believes what your hostname is,

00:31:06.279 --> 00:31:10.460
and then it also asks the server what it thinks
its hostname is and tell you if it's valid or not.

00:31:10.460 --> 00:31:18.250
If it's not you definitely want to run change IP to
change the server to match the hostname to the DNS name.

00:31:18.250 --> 00:31:24.019
For clients you can use the scutil command
to either get or set these settings.

00:31:24.019 --> 00:31:29.440
So convenient over ARD you can just, if you have a
lot of clients just push that out to all your clients.

00:31:29.440 --> 00:31:33.029
So next directory services.

00:31:33.029 --> 00:31:41.379
Xsan uses a file level locking to allow multiple clients,
to simultaneously access your Xsan and read and write to it.

00:31:41.380 --> 00:31:46.330
Read, write features are if your client's
writing to a file that's the only client

00:31:46.329 --> 00:31:49.339
that can write to that file while he's writing to it.

00:31:49.339 --> 00:31:52.269
Once it's done writing to it other
users can read and write to it.

00:31:52.269 --> 00:31:54.359
But this is achieved by using directory services.

00:31:54.359 --> 00:31:58.649
The directory services are manual, or
excuse me, mandatory for, for Xsan.

00:31:58.650 --> 00:32:04.210
You can use Open Directory, you can use Active
Directory, or you can use another open, or L.

00:32:04.210 --> 00:32:06.640
based directory services.

00:32:06.640 --> 00:32:13.140
So for smaller Xsan deployments where you don't want
to, you don't have active directory or you don't want

00:32:13.140 --> 00:32:17.009
to manage open directory on your own, during
the Xsan set up you can actually choose

00:32:17.009 --> 00:32:20.230
to have Xsan manage users in groups for you.

00:32:20.230 --> 00:32:24.319
What it actually does is it creates an open
directory master on your metadata controller.

00:32:24.319 --> 00:32:27.889
And it gives you the option in Xsan admin
where you actually see users in groups.

00:32:27.890 --> 00:32:31.270
So you can manage users and groups
and quotas from within Xsan Admin,

00:32:31.269 --> 00:32:33.730
rather than having to go to Workgroup
Manage or Active Directory.

00:32:33.730 --> 00:32:39.740
So for smaller environments that's totally acceptable.

00:32:39.740 --> 00:32:42.210
Access control lists very important for SAN.

00:32:42.210 --> 00:32:50.079
It used to be that your Xsan admins would modify your umask
settings to allow read and write access for all your users

00:32:50.079 --> 00:32:53.289
to be able to access their, each others work.

00:32:53.289 --> 00:32:55.119
This is no longer necessary.

00:32:55.119 --> 00:33:00.849
With access control lists you're going to be able to
define your read and writes for your user polices.

00:33:00.849 --> 00:33:02.859
And this is also can be done within the Xsan admin.

00:33:02.859 --> 00:33:09.819
You no longer have to go out to server admin or workgroup
manager as you used to manage access control lists.

00:33:09.819 --> 00:33:16.539
And the other thing that makes you sure you plan out your
access control list problems before you deploy your Xsan.

00:33:16.539 --> 00:33:21.700
It can also be tricky once you've deployed it and
you've, didn't spend a lot of time thinking about it.

00:33:21.700 --> 00:33:24.650
So you want to make sure that you know
who your users are, you know your groups,

00:33:24.650 --> 00:33:27.810
you know what access policies you're going to need for them.

00:33:27.809 --> 00:33:31.529
Another thing you want to think
about is the ACL inheritance.

00:33:31.529 --> 00:33:36.720
They're extremely useful, especially as your volume grows,
because you don't have to continuously have to change ACLs

00:33:36.720 --> 00:33:39.059
to match what your users and groups need.

00:33:39.059 --> 00:33:42.869
However, it can be really annoying if you
haven't planned it out from the beginning,

00:33:42.869 --> 00:33:45.149
going back and having to fix this on a production SAN.

00:33:45.150 --> 00:33:50.480
So just spend a lot of time beforehand
mapping out your ACLs.

00:33:50.480 --> 00:33:57.009
So out of the Xsan users out there, how many
are actually backing up their Xsan volume?

00:33:57.009 --> 00:34:01.059
OK. So again we see a lot of clients that they're not.

00:34:01.059 --> 00:34:05.740
It actually still astounds me that when we go
out to clients and they're not backing up Xsan.

00:34:05.740 --> 00:34:09.559
And that professional services a lot of
times we're going into worst case scenarios,

00:34:09.559 --> 00:34:15.170
you know where an air conditioning unit when offline for
20 minutes on a summer day, or they had a water damage

00:34:15.170 --> 00:34:18.300
from a floor above, and their entire Xsan's lost.

00:34:18.300 --> 00:34:24.420
And I've seen federal clients; I've seen private clients
with 20, 30 terabytes  gone, completely unrecoverable.

00:34:24.420 --> 00:34:26.650
So, backup your SAN.

00:34:26.650 --> 00:34:29.730
When you're deploying your SAN that should
be the first thing that you're planning

00:34:29.730 --> 00:34:33.159
when you're ordering your equipment
is also a proper backup solution.

00:34:33.159 --> 00:34:36.409
And also as Jason mentioned, backup your config files.

00:34:36.409 --> 00:34:42.659
When I'm changing, or when I'm doing anything with Xsan
admin, prior to making any change I run the CD Gather,

00:34:42.659 --> 00:34:44.489
because I want to be sure that I have those files.

00:34:44.489 --> 00:34:50.379
And as Jason said when we just saw that client yesterday
complain about they now cannot recover their SAN,

00:34:50.380 --> 00:34:52.010
because they do not have a current, current backup.

00:34:52.010 --> 00:34:56.640
And we've had to rewrite some of these
files before, by memory and manually.

00:34:56.639 --> 00:35:00.409
And sometimes we've had some luck doing
it, but it's sometimes very difficult.

00:35:00.409 --> 00:35:04.299
And a lot of times without the
configuration files you're really hosed, so.

00:35:04.300 --> 00:35:11.420
And this slide shows five backup vendors, three of
which have backup software servers that run on OS X.

00:35:11.420 --> 00:35:18.280
So that's going to be TIMEnavigator by Atempo,
ARCHIWARE PresSTORE, and BakBones NetVault.

00:35:18.280 --> 00:35:24.560
All these vendors on the slide states that they have
Xsan compatibility and they will backup Xsan volumes.

00:35:24.559 --> 00:35:26.920
No problem, we use them in the enterprise regularly.

00:35:26.920 --> 00:35:33.650
Also if you have existing backup architecture in your
enterprise environment, two very popular clients Tivoli TSM

00:35:33.650 --> 00:35:37.690
and Veritas have clients for OS X that actually backup Xsan.

00:35:37.690 --> 00:35:39.010
So very, very important.

00:35:39.010 --> 00:35:44.230
[ silence ]

00:35:44.230 --> 00:35:49.059
>> Ken: If you're setting up a fiber based tape backup
library, a couple of things you want to keep in mind.

00:35:49.059 --> 00:35:53.849
You don't just want to plug your library
into your, to your fiber switch and go.

00:35:53.849 --> 00:35:56.000
Cause actually it can, it can blip your SAN.

00:35:56.000 --> 00:36:00.679
You want to be sure that you zone your
fiber, your fiber tape library accordingly.

00:36:00.679 --> 00:36:04.969
And the way you do this is you have to have a
backup server that's got multiple fiber ports.

00:36:04.969 --> 00:36:07.750
You want to make sure that you zone only one of those ports

00:36:07.750 --> 00:36:12.780
from the backup server to your
tape backup drive and library.

00:36:12.780 --> 00:36:15.019
This is, this is to prevent fiber loops.

00:36:15.019 --> 00:36:19.199
Because the tape drives only have one fiber
strand, where as your cards have 2 or 4.

00:36:19.199 --> 00:36:20.809
So it can actually cause a loop.

00:36:20.809 --> 00:36:23.570
And you also want to make sure
that you turn off RSCN suppression

00:36:23.570 --> 00:36:27.019
on your fiber switch for your tape drive, specifically.

00:36:27.019 --> 00:36:28.219
And I'll go into that in a second.

00:36:28.219 --> 00:36:33.230
Oh, one thing I also want to mention about tape backup.

00:36:33.230 --> 00:36:37.760
If you want to avoid having to plug your
tape library into your fiber switch,

00:36:37.760 --> 00:36:45.000
you can just sometimes buy an extra fiber card
or a 4 port fiber card, and use 2 ports for Xsan

00:36:45.000 --> 00:36:47.090
and 2 ports directly attached to your library.

00:36:47.090 --> 00:36:50.630
It's another way of configuring
a smaller library based solution.

00:36:50.630 --> 00:36:50.690
Oops.  Going to go back here.

00:36:50.690 --> 00:36:57.190
OK. Next thing we want to talk about is file manager.

00:36:57.190 --> 00:37:02.289
You have your file, you have your Xsan configured for
the type of SAN that you're going to be deploying,

00:37:02.289 --> 00:37:05.880
but there's some best practices in just
about how to set up the actual file structure

00:37:05.880 --> 00:37:08.240
on the SAN for better optimization and performance.

00:37:08.239 --> 00:37:09.269
So we're going to go into that.

00:37:09.269 --> 00:37:14.150
The first thing we'll talk about is your video
type SAN, specifically in this slide Final Cut.

00:37:14.150 --> 00:37:19.740
What we generally would do with any Xsan volume is
you want to keep your top level of the volume simple.

00:37:19.739 --> 00:37:25.929
So you want to have a small amount of top level folders
that you use ACLs to prevent users from modifying

00:37:25.929 --> 00:37:28.960
or deleting these top level folders,
and you've also prevented your users

00:37:28.960 --> 00:37:30.860
from writing to the top level volume in the SAN.

00:37:30.860 --> 00:37:33.809
And I'm going to get into that in a second,
but the reason why you want to avoid that.

00:37:33.809 --> 00:37:40.659
But for here at Xsan, you know, create a media
folder on the top level, and you know, have your,

00:37:40.659 --> 00:37:43.899
and then underneath that media folder
create a folder for each edit workstation.

00:37:43.900 --> 00:37:50.050
And then have your users set their capture
settings to that, their corresponding edit folder.

00:37:50.050 --> 00:37:54.760
And this makes Final Cut Server integration a lot easier,
because you can point the watch folder Final Server

00:37:54.760 --> 00:37:59.950
to your media folder and it will
dig down into that file structure.

00:37:59.949 --> 00:38:08.529
So for general file servers, again you want to
keep the top level simple, have a few small,

00:38:08.530 --> 00:38:13.010
have a small number of folders on the top level
to prevent users from writing to the top levels,

00:38:13.010 --> 00:38:15.760
and preventing your users from
deleting those top level folders.

00:38:15.760 --> 00:38:18.410
And this example on the screen is what you don't want to do.

00:38:18.409 --> 00:38:22.230
You don't want to have your, your top of
your volume in just a drop zone for anything.

00:38:22.230 --> 00:38:27.889
And the reason why we've seen is, we've had
clients that have folder and file structures that,

00:38:27.889 --> 00:38:31.129
they go inside a folder that's got thousands of entries.

00:38:31.130 --> 00:38:35.539
What we've seen is that when a user traverses into
a folder like that it actually can slow down the SAN

00:38:35.539 --> 00:38:41.219
for every other user until that folder has been
redrawn, and all that information is gathered.

00:38:41.219 --> 00:38:45.289
Because you're metadata controllers are taxed
getting the thumbnails, getting the information

00:38:45.289 --> 00:38:47.539
about the folder, the modification times.

00:38:47.539 --> 00:38:52.559
So until that, that process is done, the
SAN is actually slowed down for your users.

00:38:52.559 --> 00:38:56.519
So you want to kind of file, if you
look at OS X's general operating system,

00:38:56.519 --> 00:39:01.920
this is the way we've laid our file structure it, it's
a very small amount on the top level, it digs down in.

00:39:01.920 --> 00:39:06.800
And you want to kind of maintain that
level of file systems for your Xsan.

00:39:06.800 --> 00:39:10.180
Same thing with the general directive
tasks, but just Xsan kind of exacerbates it,

00:39:10.179 --> 00:39:13.859
because your metadata controllers
are separate, a separate entity.

00:39:13.860 --> 00:39:18.809
So use a lot of ACLs too for, for users and groups access.

00:39:18.809 --> 00:39:20.139
And move the folder.

00:39:20.139 --> 00:39:23.569
Oh, also with resharing, if you're
going to be resharing your Xsan volume,

00:39:23.570 --> 00:39:28.530
don't just reshare the actual Xsan volume itself,
reshare top-level folders or reshare folders.

00:39:28.530 --> 00:39:32.980
Make sure your administration of
your ACLs a lot easier to handle.

00:39:32.980 --> 00:39:37.280
And you can prevent some issues, so.

00:39:37.280 --> 00:39:40.680
For collaborative services, such
as Mail or Podcast Producer,

00:39:40.679 --> 00:39:44.429
again you want to follow the same laws,
small amount of top-level folders.

00:39:44.429 --> 00:39:50.159
The only thing I really want to say about this
slide is, if you have a volume that is optimized

00:39:50.159 --> 00:39:56.500
for a collaborative service, don't use that volume for file
services or file, you know, home directories, or Final Cut.

00:39:56.500 --> 00:40:00.889
Because what happens is you have a Mail server
Monday morning at 8AM, everybody's logging in.

00:40:00.889 --> 00:40:04.519
That Mail server needs to have as maximum
amount of IO for that, to that Xsan.

00:40:04.519 --> 00:40:08.009
If you also have your users home directories on
there you're going to cause some major bottlenecks.

00:40:08.010 --> 00:40:14.420
As well as that volume is tuned specifically for that
purpose, so create a separate volume for your other needs.

00:40:14.420 --> 00:40:19.200
So next we're going to talk about
fiber fabric and interconnects.

00:40:19.199 --> 00:40:23.829
There's a lot of different switches out there, a lot of
different third party products, each with their, you know,

00:40:23.829 --> 00:40:26.429
their own configurations, their own naming of things.

00:40:26.429 --> 00:40:28.869
But generally the fundamentals are the same.

00:40:28.869 --> 00:40:32.230
So in this solution we're showing 2
object switches, but it could be Cisco,

00:40:32.230 --> 00:40:34.670
it could be Brocade, it could be other, other switches.

00:40:34.670 --> 00:40:41.280
You want to be sure that you don't connect each
client to your fabric, to your fiber switches.

00:40:41.280 --> 00:40:46.230
And you want to set one port to one switch, one port to
another switch to provide best redundancy and multipathing.

00:40:46.230 --> 00:40:48.539
Leopard brought with us multipathing.

00:40:48.539 --> 00:40:50.179
So we really want to utilize that.

00:40:50.179 --> 00:40:54.710
And with Promise we now have storage multipathing,
'cause you have 4 ports per Promise RAID.

00:40:54.710 --> 00:41:00.630
So you can truly have a very bolt tolerance
environment, such as what's shown here.

00:41:00.630 --> 00:41:07.000
In this environment if I were to unplug a switch
while writing, I would actually not loose a beat.

00:41:07.000 --> 00:41:11.360
My performance may go down a little bit, because I've
lost multipathing and I may have lost half of my fiber,

00:41:11.360 --> 00:41:14.400
but the thing is I'm still writing
to it, I haven't crashed my volume.

00:41:14.400 --> 00:41:16.630
I can also shut down the metadata controller.

00:41:16.630 --> 00:41:22.220
I can also yank out a fiber strand from a client,
or even loose a controller in a Promise RAID.

00:41:22.219 --> 00:41:29.609
So it truly with Promise and multipathing Leopard
this design really causes a fault tolerance up SAN.

00:41:29.610 --> 00:41:32.370
Now this environment shows 2 fiber switches.

00:41:32.369 --> 00:41:36.920
But when you're in an environment where
you have fiber switches that have blades,

00:41:36.920 --> 00:41:41.590
or you have multiple fiber switches, you want to be
sure that you just isolate your metadata controllers

00:41:41.590 --> 00:41:44.500
and your metadata LUNs on the same fiber switches.

00:41:44.500 --> 00:41:49.559
This prevents a lot of cross talk,
unnecessary cross talk between your switches.

00:41:52.360 --> 00:41:56.260
So for Fibre Channel interconnects
and every fiber optic card

00:41:56.260 --> 00:42:02.240
that Apple ships comes with our 2 or 4 copper fiber cables.

00:42:02.239 --> 00:42:04.679
They're totally fine to use with your SAN.

00:42:04.679 --> 00:42:08.549
However, you really want to, they, they
have a length limitation is 3 meters.

00:42:08.550 --> 00:42:13.220
So the reason why you're going to go to optical
fiber cable is when you need to go above 3 meters.

00:42:13.219 --> 00:42:20.799
So for your longer runs, not only do you see multimode
LCNs to LCNs, LC connection type, excuse me, LC to LC.

00:42:20.800 --> 00:42:25.140
And you're going to make sure that you need to
purchase small form factor fiber transceivers

00:42:25.139 --> 00:42:29.000
for your switch side and your, and your fiber card side.

00:42:29.000 --> 00:42:33.239
Depending on what type of fiber is going to be depending
on how long the lengths, the runs are going to be.

00:42:33.239 --> 00:42:36.939
As well as you're going to need more powerful
transceivers to handle longer, longer,

00:42:36.940 --> 00:42:40.230
longer hauls and different types of fiber cables.

00:42:40.230 --> 00:42:46.000
And another thing if you can is avoid
mismatch of fiber transceivers, the brands.

00:42:46.000 --> 00:42:50.130
You don't want to have a QLogic on one,
on your server side, and a ProOptic,

00:42:50.130 --> 00:42:52.099
or Finasar on the other side.

00:42:52.099 --> 00:42:55.839
Because we have seen sometimes it
causes issues and errors in your switch.

00:42:55.840 --> 00:42:59.250
So if you can avoid it, try to avoid that.

00:42:59.250 --> 00:43:03.920
So in this example we're showing some
QLogic switches stacked together.

00:43:03.920 --> 00:43:07.769
And if you're just using other brands
of switches you can do stacking as well.

00:43:07.769 --> 00:43:14.099
What we're showing here is we're interconnecting
your fiber switches using 10 gigabit stacking tables.

00:43:14.099 --> 00:43:16.940
And the first example, it's showing that we're using 2.

00:43:16.940 --> 00:43:19.659
And this provides better performance as well as redundancy.

00:43:19.659 --> 00:43:22.139
And this is, of course, the minimum recommended.

00:43:22.139 --> 00:43:29.199
You can use 4 if you wanted, or you can use 2 or 4 gig
standard fiber cables still also be inner switch lengths.

00:43:29.199 --> 00:43:33.089
But we recommend the 10 gigabyte stacking tables.

00:43:33.090 --> 00:43:35.010
In the second example there's 3 switches.

00:43:35.010 --> 00:43:36.620
And this one we're not cascading.

00:43:36.619 --> 00:43:40.119
We're not going from switch 1 to switch
2, and then from switch 2 to switch 3.

00:43:40.119 --> 00:43:46.349
We're having that switch 1 to switch 3 link as well, to
provide multipathing and better performance and redundancy.

00:43:46.349 --> 00:43:47.980
Same thing with when you go into 4.

00:43:47.980 --> 00:43:51.619
And QLogic switches, like these actually support up to 6.

00:43:51.619 --> 00:43:56.609
And so. So next thing we're going
to talk about is fiber zoning.

00:43:56.610 --> 00:44:01.390
What we recommend is that we create
a fiber zone for your storage.

00:44:01.389 --> 00:44:05.079
You create a fiber zone for each
client and metadata controller.

00:44:05.079 --> 00:44:09.929
And this storage is, it is our zone
to only contain the fiber ports

00:44:09.929 --> 00:44:13.279
of that specific client or metadata
controller and the storage.

00:44:13.280 --> 00:44:17.150
Therefore the client and metadata controller can
only see the storage, but can't see one another.

00:44:17.150 --> 00:44:22.789
And this can prevent interference from clients and
tape backup devices, and also people plugging in things

00:44:22.789 --> 00:44:25.449
to your switch without having Xsan software installed.

00:44:25.449 --> 00:44:32.409
This is definitely something that is strongly
recommend and it prevents client interference.

00:44:32.409 --> 00:44:37.230
And one other thing to note, if you're plugging in Windows
clients into your SAN and you're going to use another,

00:44:37.230 --> 00:44:42.599
say a product to allow them to join the Xsan,
if they don't have that software installed

00:44:42.599 --> 00:44:48.420
and you haven't zoned you switch, Windows clients
can actually format and wipe out your entire SAN

00:44:48.420 --> 00:44:50.409
on the fly while in the middle of using it.

00:44:50.409 --> 00:44:55.789
So if you zone your switch accordingly, and also another
good recommendation is to turn off your unused switch ports

00:44:55.789 --> 00:45:00.400
so that the users that are not familiar with
what they're doing, don't bring down your SAN.

00:45:00.400 --> 00:45:05.300
Next thing we want to talk about is fiber port section.

00:45:05.300 --> 00:45:09.380
I spoke about RSCN suppression earlier.

00:45:09.380 --> 00:45:17.730
And what this actually does is, RSCN is a notification
that when a device comes online or offline to the rest

00:45:17.730 --> 00:45:20.480
of the switch ports, and that can actually blip your SAN.

00:45:20.480 --> 00:45:25.360
So for initiators or clients, want to be able
to be sure that you suppress those events.

00:45:25.360 --> 00:45:28.599
For storage, however, you want
to make sure that that's enabled.

00:45:28.599 --> 00:45:37.519
And also the best practices are to configure the
ports to be auto-detect and for speed and type.

00:45:37.519 --> 00:45:43.590
Unless you're using your older 2 gig card, like in your
Xserve G5's or your power Mac, where on those you want

00:45:43.590 --> 00:45:48.420
to set them statically to 2 gig on this,
on the client side, not the switch side,

00:45:48.420 --> 00:45:52.019
as well as point-to-point for, for a switch type.

00:45:52.019 --> 00:45:57.579
But for your, your clients you want to set them on the
switch to be the generic, the default, which is the GL-Port.

00:45:57.579 --> 00:46:03.250
And that'll negotiate to F-Port, which is a
fiber port, is you want it to be a set at.

00:46:03.250 --> 00:46:04.840
Also Device Scan.

00:46:04.840 --> 00:46:11.519
We used to say, state to not enable this,
especially with some of the RAID firmware.

00:46:11.519 --> 00:46:17.050
But now with Promise you can enable your
device scanning for your clients and storage.

00:46:17.050 --> 00:46:21.070
Next I want to talk about power and cooling.

00:46:21.070 --> 00:46:25.769
This is something that you really want to spend time
on prior to even turning on your, your, your equipment.

00:46:25.769 --> 00:46:30.929
You want to make sure that your data center or
server room has enough adequate power and cooling.

00:46:30.929 --> 00:46:37.029
We've seen a lot of times where, you know, clients haven't
planned for this, we just deployed that 250 terabyte SAN,

00:46:37.030 --> 00:46:40.210
actually the one was pictured earlier, in November.

00:46:40.210 --> 00:46:44.090
And one wall of their server room was windows.

00:46:44.090 --> 00:46:46.829
And in November it was fine, it had adequate cooling.

00:46:46.829 --> 00:46:49.980
And when we visited in March it was
starting to get really warm in there.

00:46:49.980 --> 00:46:54.320
And now they're actually having to buy
external, you know, portable cooling units just

00:46:54.320 --> 00:46:56.700
to be able to provide enough cooling for that SAN.

00:46:56.699 --> 00:47:00.899
And the problem is that your servers will start auto
shutting down when they reach to a certain heat.

00:47:00.900 --> 00:47:04.410
But at that point the damage to your drives is already done.

00:47:04.409 --> 00:47:10.259
So if you want to avoid, you know, unexpected
drive crashes and issues with your SAN,

00:47:10.260 --> 00:47:13.040
you really want to make sure that
adequate cooling and power.

00:47:13.039 --> 00:47:18.469
And a lot of times it would also power, you know, it's a
terrible situation when we're in clients and we're plugging

00:47:18.469 --> 00:47:22.669
in things, and all of a sudden we're blowing a
circuit, the server room, or the entire building.

00:47:22.670 --> 00:47:24.380
And all it is, all of which has happened.

00:47:24.380 --> 00:47:29.470
So, these are just a couple of examples
of our output of power and thermal.

00:47:29.469 --> 00:47:33.049
You can reach; you can find a lot more
of this stuff on support@Apple.com,

00:47:33.050 --> 00:47:38.280
as well as the vendor sites have
most of that information posted.

00:47:38.280 --> 00:47:45.480
So for UPS integration, the first thing to
talk about is you want the smaller SANs.

00:47:45.480 --> 00:47:47.690
Don't just buy one UPS.

00:47:47.690 --> 00:47:49.429
You want to make sure you have at least 2.

00:47:49.429 --> 00:47:54.699
Cause you have the redundancy throughout the rest of your
SAN, don't leave the single point of failure with the UPS.

00:47:54.699 --> 00:47:58.669
Your batteries, 1, 2, 3 years, those lead
batteries are going to start to fail,

00:47:58.670 --> 00:48:03.130
and you really want to make sure you
have redundancy in your, in your power.

00:48:03.130 --> 00:48:08.410
Another thing is when you're purchasing your equipment you
want to make sure that you purchase as much of your devices

00:48:08.409 --> 00:48:11.929
that have dual power redundancy as possible.

00:48:11.929 --> 00:48:14.289
Xserves now do with the Intel Xserves.

00:48:14.289 --> 00:48:19.639
Promise RAIDs, QLogic switches, so all that,
you really want to look at that from the beginning.

00:48:19.639 --> 00:48:24.239
You want to be able to also make sure
that you can shut down one of your UPS's

00:48:24.239 --> 00:48:26.179
and be sure that the other UPS can handle the load.

00:48:26.179 --> 00:48:31.879
So if you just distribute it equally you don't want
to be frying your UPS when one of the UPS's goes down.

00:48:31.880 --> 00:48:36.320
And also for every UPS you buy you want
to be sure that you buy a management card.

00:48:36.320 --> 00:48:38.570
I'm going to go into that in a second here.

00:48:38.570 --> 00:48:39.610
Yeah, buy your management card.

00:48:39.610 --> 00:48:45.530
With the management cards and UPS's you can
do testing to show how much power can be, how,

00:48:45.530 --> 00:48:50.010
how long the batteries can run when you're on
power, when you're off of power, excuse me.

00:48:50.010 --> 00:48:53.730
So the it allows you to actually
plan accordingly automated shutdown,

00:48:53.730 --> 00:48:59.110
so that when UPS's are on battery it actually can
contact your servers and shut down the servers.

00:48:59.110 --> 00:49:03.809
And with an upcoming Promise release, that JD's
going to speak to you in a few minute about,

00:49:03.809 --> 00:49:08.000
you can actually now shut down your Promise
RAID as well, so that, that's pretty excellent.

00:49:08.000 --> 00:49:13.030
[ applause ]

00:49:13.030 --> 00:49:16.500
>> Ken: And also with the management cards
you want them to email you notifications,

00:49:16.500 --> 00:49:20.429
they do self tests regularly, the
batteries dying and so forth.

00:49:20.429 --> 00:49:24.750
So be sure, be sure to configure those.

00:49:24.750 --> 00:49:29.579
So shut down procedures, this is something important,
not just to know, but also you want to print it out,

00:49:29.579 --> 00:49:34.690
you want to, you want to paste it on your SAN rack,
so that when you're not there and they tell you that,

00:49:34.690 --> 00:49:39.519
they tell you that the other people that are, that are at
your office that they need to shut down the power that day,

00:49:39.519 --> 00:49:42.230
you don't want somebody just powering things off.

00:49:42.230 --> 00:49:46.659
Because that, if you do it in the wrong order it can
really cause some major, major issues with your SAN.

00:49:46.659 --> 00:49:50.679
So, so document this and, and you
know, let everybody know about it.

00:49:50.679 --> 00:49:56.119
So the first thing you want to do is, what I generally do
is you want to unmount your, your volumes from your SAN.

00:49:56.119 --> 00:49:58.789
This isn't a necessary step, but I recommend it.

00:49:58.789 --> 00:50:04.469
This way this actually tells the clients now to
automount backup when they, when they start up.

00:50:04.469 --> 00:50:09.269
Because if I'm doing a controlled shutdown I want to make
sure that my controlled start up is controlled as well

00:50:09.269 --> 00:50:11.210
where the clients aren't mounting the SAN at will.

00:50:11.210 --> 00:50:13.190
I want to make sure I mount them for them.

00:50:13.190 --> 00:50:17.220
So once you do that you can stop the volume.

00:50:17.219 --> 00:50:18.969
That's another process that I do.

00:50:18.969 --> 00:50:23.459
It's not mandatory, because as you start shutting down
your client's they're going to shut down just fine.

00:50:23.460 --> 00:50:28.420
Once your clients and your servers are shut down, go
ahead and shut down your secondary metadata controller.

00:50:28.420 --> 00:50:33.909
If you're not sure what is the primary and what's the
secondary, you can look in Xsan Admin select your volume,

00:50:33.909 --> 00:50:38.179
it's going to tell you what's actually
hosting the volume at that time.

00:50:38.179 --> 00:50:42.039
So once your secondary metadata controller's shut down,
go ahead and shut down your primary metadata controller.

00:50:42.039 --> 00:50:43.050
And make sure it's offline.

00:50:43.050 --> 00:50:44.430
Make sure it's powered off.

00:50:44.429 --> 00:50:47.179
And at that point you can begin to shut down your storage.

00:50:47.179 --> 00:50:51.379
And then if you have any additional servers that
are not part of your SAN, but they provide services

00:50:51.380 --> 00:50:54.030
like open directory or DNF, you can shut those down as well.

00:50:54.030 --> 00:50:58.200
And then lastly shut down your switches,
your Ethernet and your fiber switches.

00:50:58.199 --> 00:51:04.099
So on the start up procedure the first thing you
want to do is bring on your Ethernet switches.

00:51:04.099 --> 00:51:06.210
Make sure they come online first.

00:51:06.210 --> 00:51:07.769
And then bring on your QLogic switches.

00:51:07.769 --> 00:51:12.190
The reason you want your Ethernets to come on first
is, not QLogic, but just fiber switches in general.

00:51:12.190 --> 00:51:16.010
But fiber switches actually talk to each
other over Ethernet, a lot of times,

00:51:16.010 --> 00:51:17.600
so you want to make sure the Ethernet's on first.

00:51:17.599 --> 00:51:22.889
Once your fiber switches are online, and take note they can
take like 10 minutes to come up depending on what brand.

00:51:22.889 --> 00:51:24.489
So be sure that they're online.

00:51:24.489 --> 00:51:27.389
You can go ahead and bring on your
other services that weren't Xsan related

00:51:27.389 --> 00:51:30.599
if you shut those down-- your OD, your DNS, and so forth.

00:51:30.599 --> 00:51:33.480
And once those are online go ahead and bring on your RAIDs.

00:51:33.480 --> 00:51:37.039
When you're using Promise and you're using EJ Pair's,
you want to make sure that you bring

00:51:37.039 --> 00:51:40.289
on the J Pair first, so that the J Box first.

00:51:40.289 --> 00:51:44.809
Give it about 30 seconds to st0art up, then
power on your, your, your Promise E Class,

00:51:44.809 --> 00:51:47.199
which may take about 3 to 5 minutes to come up.

00:51:47.199 --> 00:51:52.169
So once all your storage has come up and you can verify that
you actually see link likes on your, your fiber switches,

00:51:52.170 --> 00:51:55.769
go ahead and shut on your, turn on
your, your primary metadata controller.

00:51:55.769 --> 00:52:01.110
And when the primary metadata controller comes up
it's going to actually start your Xsan volume for you.

00:52:01.110 --> 00:52:03.740
So I want to make sure that that volume is started.

00:52:03.739 --> 00:52:09.019
And I also like to make sure that I can actually mount it
on my metadata controller just to verify the data's there.

00:52:09.019 --> 00:52:13.320
Because I want to know that if there's anything wrong with
my SAN, at this point there's no other clients affected,

00:52:13.320 --> 00:52:16.200
or there's no other clients turned on trying
to write to it or do anything wrong with it.

00:52:16.199 --> 00:52:18.730
So I want to make sure that that's up and running fine.

00:52:18.730 --> 00:52:22.510
So secondly you want to start up your,
your secondary metadata controller.

00:52:22.510 --> 00:52:26.580
And once that comes online it's a good thing to
verify that both you're getting a green light

00:52:26.579 --> 00:52:30.069
in Xsan admin, so both metadata primary and secondary.

00:52:30.070 --> 00:52:32.720
So next you want to turn on your SAN clients.

00:52:32.719 --> 00:52:37.409
You don't need to, you don't need to stagger these
necessarily, you can bring them all online at the same time.

00:52:37.409 --> 00:52:41.190
And, as I said, if you unmounted them in the
shut down procedures you're going to have

00:52:41.190 --> 00:52:43.519
to mount them again at the startup procedures.

00:52:43.519 --> 00:52:47.659
So you're going to mount the clients
and that's and just check to make sure

00:52:47.659 --> 00:52:50.980
that they can see and write to the storage.

00:52:50.980 --> 00:52:56.059
So with that I'm going to turn it back over to JD, who's
going to talk about getting support as well as some

00:52:56.059 --> 00:52:57.860
of the new stuff up and coming for Promise RAID's.

00:52:57.860 --> 00:52:58.039
Thank you.

00:52:58.039 --> 00:52:59.000
Thank you.

00:52:59.000 --> 00:53:02.869
[ applause ]

00:53:02.869 --> 00:53:07.480
>> JD: So let's talk a little bit about, about support.

00:53:07.480 --> 00:53:13.139
And, you know, the first thing I wanted to mention is for
those of you who are, you're going to be purchasing Xsan

00:53:13.139 --> 00:53:19.099
in the near future, it does come with 90
days of support with the, with the software.

00:53:19.099 --> 00:53:25.719
But obviously what we recommend is that you also purchase
the extended support, which is a kind of a yearly renewal.

00:53:25.719 --> 00:53:30.219
So for those of you who are already using Xsan
today, make sure you do renew your support.

00:53:30.219 --> 00:53:35.259
And that's for all, and that includes, you know,
all the clients as well as the metadata server.

00:53:35.260 --> 00:53:40.740
So each machine that has Xsan loaded on there should
also, should have a support contract tied to it.

00:53:40.739 --> 00:53:44.189
There's some good support articles up there.

00:53:44.190 --> 00:53:48.869
You know, if you're running, if you ever run into an issue
where you cannot mount your SAN or you run into a problem,

00:53:48.869 --> 00:53:51.279
just, you know, we put the KBase
article up there.

00:53:51.280 --> 00:53:56.140
But we always recommend that you call
AppleCare and that they help you know,

00:53:56.139 --> 00:53:58.549
run through some of the trouble shooting steps.

00:53:58.550 --> 00:54:04.150
IT's better to do it with someone, a technician on
the phone, who might be aware of, you know, an issue,

00:54:04.150 --> 00:54:07.079
and might be able to help you and assist you.

00:54:07.079 --> 00:54:12.269
If there is, if, you know, you can, the first thing we
would recommend if you can't get to an AppleCare tech,

00:54:12.269 --> 00:54:17.009
support engineer, would be to run
a cvfsck in the read-only mode.

00:54:17.010 --> 00:54:22.150
And then if there's a problem detected you
can then basically do, do the right mode.

00:54:22.150 --> 00:54:24.240
And again, that's all in the support article.

00:54:24.239 --> 00:54:33.129
As Ken mentioned, you know, Xsan is basically
not just Apple products, there's, you know,

00:54:33.130 --> 00:54:35.890
Fibre Channel switches, there's storage that's involved.

00:54:35.889 --> 00:54:42.009
So from an Apple perspective you want to make sure that you
get the right AppleCare support contract for the hardware,

00:54:42.010 --> 00:54:48.550
for the server, and obviously when you, when you deploy
storage, you know, our recommendation is always make sure

00:54:48.550 --> 00:54:50.690
that you've got, you know, spare parts kits.

00:54:50.690 --> 00:54:56.230
Right? So the server, the Xserve, there's
a spare parts kit that's available online.

00:54:56.230 --> 00:55:01.139
So typically what we recommend is one spare
parts kit for about, for each 5 servers.

00:55:01.139 --> 00:55:08.440
And the reason for that is, yes you could have, you know,
if you call in for support we've got the 4 hour, you know,

00:55:08.440 --> 00:55:14.630
onsite, where an engineer, a technician come in and
replace it, but you don't often have that 4 hours.

00:55:14.630 --> 00:55:18.450
You've got people who need to do work and editing,

00:55:18.449 --> 00:55:24.639
and you know if you have a spare parts kit
available its usually very easy for, you know,

00:55:24.639 --> 00:55:27.019
an IT person to go in and just swap the part.

00:55:27.019 --> 00:55:32.059
And then call it in and then, you know, send
the defective part back and ship it back.

00:55:32.059 --> 00:55:34.539
And the same thing applies with Promise.

00:55:34.539 --> 00:55:39.029
If you do purchase Promise E Class and J
Class, they do have different parts kits,

00:55:39.030 --> 00:55:42.890
so you want to make sure you have
one parts kit for each of the units.

00:55:42.889 --> 00:55:48.279
And both on the Xserve and on the Promise,
those devices do not come with extra drives.

00:55:48.280 --> 00:55:54.560
Right? Because you could buy an Xserve with 100 and,
you know, 80 gigabyte drive, or a 1 terabyte drive.

00:55:54.559 --> 00:55:57.369
So you want to make sure that you
also buy a few extra, you know,

00:55:57.369 --> 00:56:00.219
SATA drives and the same thing applies with Promise units.

00:56:00.219 --> 00:56:03.309
So if you have a bad drive, you have a spare on hand.

00:56:03.309 --> 00:56:09.579
The other thing you want to look at is, you
know, when you, when you get a spare parts kits,

00:56:09.579 --> 00:56:13.610
especially around storage, you've got a spare controller.

00:56:13.610 --> 00:56:19.640
Right? And as you update firmware on those
controllers, on your production unit,

00:56:19.639 --> 00:56:23.150
you want to make sure you update the
firmware on those spare parts kits.

00:56:23.150 --> 00:56:24.139
So that's really important.

00:56:24.139 --> 00:56:26.789
So you got to think about that
and make sure that you plan that.

00:56:26.789 --> 00:56:31.009
So that when you do run into a problem that spare kit,

00:56:31.010 --> 00:56:34.620
that spare controller is already up
to date with the latest firmware.

00:56:34.619 --> 00:56:38.059
OK? So that, that's kind of essential.

00:56:38.059 --> 00:56:41.710
We talked about the Xsan support.

00:56:41.710 --> 00:56:51.360
There's also for those of you who deploy much larger, you
know, Apple, backend type environments, AppleCare also has,

00:56:51.360 --> 00:56:55.890
you know, alliance level contracts, which
are much higher end that will give you know,

00:56:55.889 --> 00:57:01.000
UNIX command line support as well
as even some patches if need be.

00:57:01.000 --> 00:57:06.030
And finally, if you are only going
to be deploying one Xsan, right,

00:57:06.030 --> 00:57:09.780
it's probably best to rely on, you know, a consultant.

00:57:09.780 --> 00:57:13.590
And we saw quite a few raise their hands in the crowd today.

00:57:13.590 --> 00:57:16.720
But, you know, just get in touch with you and
we'll put you in touch with the right consultants

00:57:16.719 --> 00:57:20.289
out there to help assist you with the deployment.

00:57:20.289 --> 00:57:24.619
Again, I mean this is, this is probably
going to be critical to your deployment.

00:57:24.619 --> 00:57:29.139
So by the time you learn how to deploy Xsan
and make sure everything is all set properly,

00:57:29.139 --> 00:57:33.579
it's probably best to just have someone
come in and help deploy for you.

00:57:33.579 --> 00:57:38.329
And then kind of hand you the keys at the end and
make sure that you've got a really solid deployment.

00:57:38.329 --> 00:57:42.860
So let's talk about Promise.

00:57:42.860 --> 00:57:47.970
So Promise has been, you know, our, our
vendor of choice in terms of, you know,

00:57:47.969 --> 00:57:51.909
that is the supportive source device that plugs into Xsan.

00:57:51.909 --> 00:58:00.539
And obviously there is the upcoming, you
know, future release of the Promise firmware

00:58:00.539 --> 00:58:02.909
that will, that has quite a few new features.

00:58:02.909 --> 00:58:05.519
And the first one is UPS support.

00:58:05.519 --> 00:58:10.230
And as Ken mentioned, that's a, that's
pretty big I think for, for all of us.

00:58:10.230 --> 00:58:14.460
So they also support NTP and SSH.

00:58:14.460 --> 00:58:20.240
They've done some, some nice performance
tuning to both ingest and playback.

00:58:20.239 --> 00:58:25.629
So, so basically you, it's the same controller, but
they've tweaked the software to get some, some more,

00:58:25.630 --> 00:58:30.550
some more juice out of those controllers and more
performance out of them, so that's kind of neat.

00:58:30.550 --> 00:58:33.860
And you also now have the ability to export a configuration.

00:58:33.860 --> 00:58:42.190
So if you configure the Promise unit to your liking
with the right tune settings, you can now export those,

00:58:42.190 --> 00:58:46.780
those settings, and them import them into
the, you know, to another Promise unit.

00:58:46.780 --> 00:58:48.110
So that's very neat.

00:58:48.110 --> 00:58:52.200
And then finally they have a graphical
performance monitoring system.

00:58:52.199 --> 00:58:57.399
So for those of you who remember Xsan
Tuner, that is a product that, you know,

00:58:57.400 --> 00:59:01.889
with for power PC machines, and
there's no Intel version of that.

00:59:01.889 --> 00:59:07.309
And so you can actually use this to look
at some of the performances from your LUNs.

00:59:07.309 --> 00:59:13.869
And as Jason mentioned, you can also do the same thing on
the QLogic, some of the Fibre Channel switches as well.

00:59:13.869 --> 00:59:15.639
So we'll show you some UI on that as well.

00:59:15.639 --> 00:59:17.759
You can keep your applauses.

00:59:17.760 --> 00:59:22.120
And then serviceability enhancements
as well are, are available.

00:59:22.119 --> 00:59:27.329
So here's the UPS support and the user interface.

00:59:27.329 --> 00:59:31.949
So you can see that the way it will work
is you basically you have IP addresses.

00:59:31.949 --> 00:59:36.659
And those IP addresses tie into your SNMP card.

00:59:36.659 --> 00:59:43.019
And that's why it's so important that each UPS device
that you have in your environment has that SNMP card.

00:59:43.019 --> 00:59:48.639
Not only so that the, all the UPS
devices can copy each other, right?

00:59:48.639 --> 00:59:52.309
So what happens is, is as we mentioned,
those lead batteries,

00:59:52.309 --> 00:59:55.659
you know, they have a certain, you know, lifetime.

00:59:55.659 --> 01:00:03.129
And if you have multiple UPS's and one of those UPS's
has a battery that's pretty much, that's going to die,

01:00:03.130 --> 01:00:07.470
it needs to alert all the other UPS's that
they need to shut down the system, right?

01:00:07.469 --> 01:00:12.480
Typically, because you've low balanced across
multiple UPS's and you probably want to shut

01:00:12.480 --> 01:00:15.630
down your whole environment and
replace, you know, fix your UPS.

01:00:15.630 --> 01:00:19.090
So the SNMP Cards are essential in any deployment.

01:00:19.090 --> 01:00:23.600
And that will just plug into, the
Promise will just plug into that.

01:00:23.599 --> 01:00:26.699
So when you've noticed 2 IP addresses, again for redundancy.

01:00:26.699 --> 01:00:32.769
The configuration export script, right there,
that's what the user interface will look like.

01:00:32.769 --> 01:00:34.829
So again, very simple to export.

01:00:34.829 --> 01:00:41.090
And then one thing I wanted to mention is Apple has
scripts that are posted on our support, you know, website.

01:00:41.090 --> 01:00:44.390
Those are, those are good, you know, example scripts.

01:00:44.389 --> 01:00:49.589
There are, we definitely support you tuning
some of those scripts for your needs, right?

01:00:49.590 --> 01:00:51.130
So that's really important.

01:00:51.130 --> 01:00:54.769
If you, if you tweak some of those scripts, it's
not because you've tweaked them that we're not going

01:00:54.769 --> 01:00:57.920
to support you if you call in for escalation.

01:00:57.920 --> 01:01:00.480
So I wanted to clarify that.

01:01:00.480 --> 01:01:03.090
And then here's the graphical performance monitoring.

01:01:03.090 --> 01:01:04.750
It's very, very neat.

01:01:04.750 --> 01:01:08.010
And you can see that you can actually monitor LUNs.

01:01:08.010 --> 01:01:11.310
Right? So you can actually say, OK, what's
the throughput coming out of my metadata LUN?

01:01:11.309 --> 01:01:14.929
What's the throughput coming out of, you know, XYZ data LUN?

01:01:14.929 --> 01:01:17.960
So, and you can also look at the, some latency as well.

01:01:17.960 --> 01:01:22.599
Both on drives, and again on, on LUN that need to be.

01:01:22.599 --> 01:01:23.589
So very neat.

01:01:23.590 --> 01:01:30.010
So a big round of applause for those kind of new features.

01:01:30.010 --> 01:01:34.280
And then, you know, we've been
deploying a lot of SANs over the years,

01:01:34.280 --> 01:01:36.550
and most of them have been in the RAID 5 environment.

01:01:36.550 --> 01:01:38.850
And Promise supports RAID 6.

01:01:38.849 --> 01:01:41.409
So we've, we're beginning a lot of
questions on, as far as like, you know,

01:01:41.409 --> 01:01:43.719
well should we go to, should we switch to RAID 6?

01:01:43.719 --> 01:01:47.119
And what kind of performance, you
know, are we going to get out of it?

01:01:47.119 --> 01:01:50.719
And what we found is reality is
you're not going to get a lot

01:01:50.719 --> 01:01:54.459
of degraded performance when going from RAID 5 to RAID 6.

01:01:54.460 --> 01:01:57.780
So, and we've had quite a few customers now deploy RAID 6.

01:01:57.780 --> 01:02:02.400
So we're fine with you actually deploying RAID 6 if need be.

01:02:02.400 --> 01:02:12.930
You know the other thing we wanted to mention
is, you know, when you're deploying Promise,

01:02:12.929 --> 01:02:19.579
and especially in a file server environments, we have the,
you guys remember there's an option called read ahead?

01:02:19.579 --> 01:02:24.139
Right, so there's a read ahead
check box in the Promise units.

01:02:24.139 --> 01:02:26.329
Everyone familiar with the read ahead?

01:02:26.329 --> 01:02:31.789
OK, we should all be familiar with a read ahead, because
that's, that's something you need to be very careful of.

01:02:31.789 --> 01:02:39.029
So if you're using, you know, an Xsan
backend with let's say Portable Home, right?

01:02:39.030 --> 01:02:45.390
And you've got a, you've got the Portable Home thinking
going on, if you had that read ahead turned on your home,

01:02:45.389 --> 01:02:49.699
network home directory, your portable home
thinking could probably take up to 20 minutes.s tylY

01:02:49.699 --> 01:02:52.500
By upchecking that box it'll take about 2 minutes.

01:02:52.500 --> 01:02:57.280
So you want to make sure you know, and
again, some of the scripts that we have

01:02:57.280 --> 01:03:01.910
on the website might have the read
ahead check, you know, enabled.

01:03:01.909 --> 01:03:07.309
So that's again that's some of those settings that are,
that you can dynamically turn on and off and play with

01:03:07.309 --> 01:03:09.009
and see what fits best to your environment.

01:03:09.010 --> 01:03:14.420
And it's the same thing applies to video, where if
you have a small Xsan and a small video environment,

01:03:14.420 --> 01:03:18.240
the read ahead is actually very neat to have turned on.

01:03:18.239 --> 01:03:25.119
But if you're deploying a very large Xsan, you know,
environment with 10 plus machines, client machines,

01:03:25.119 --> 01:03:31.339
that are editing multiple video tracks at the same
time, that read ahead is not going to buy you much,

01:03:31.340 --> 01:03:35.530
because you've got so much data going into
your SAN at the same time that you're not going

01:03:35.530 --> 01:03:38.260
to get any significant improvement by having the read ahead.

01:03:38.260 --> 01:03:39.920
You might actually slow it down.

01:03:39.920 --> 01:03:43.480
So again, that's definitely something that I
wanted to mention that, that you should be,

01:03:43.480 --> 01:03:47.320
you know, play or pay careful attention to.

01:03:47.320 --> 01:03:55.350
And then, and then as we mentioned the scripts are,
are definitely there, and you can tweak them somewhat.

01:03:55.349 --> 01:04:01.130
And as far as, you know, another question we get
a lot is, you know, what about SAS versus SATA?

01:04:01.130 --> 01:04:08.789
And what we found is SATA pretty much, SATA
drive pretty much works for, for video.

01:04:08.789 --> 01:04:14.699
And possibly you can get a little bit of improvements
when you use SAS drives for like a, you know,

01:04:14.699 --> 01:04:17.889
in a file server kind of environment,
you know, backed up by an Xsan.

01:04:17.889 --> 01:04:28.569
So you can potentially get some extra SAS drive, input those
as your metadata LUN for optimize tuning for smaller files.

01:04:28.570 --> 01:04:32.309
And that's it.

01:04:32.309 --> 01:04:38.449
So as a wrap up, you know, we want to thank you again
for using Xsan, for those of you who have it deployed.

01:04:38.449 --> 01:04:43.559
For those of you who are going to be deploying
this in the future we appreciate your business.

01:04:43.559 --> 01:04:47.090
As we mentioned, you know, Xsan is a very flexible solution.

01:04:47.090 --> 01:04:54.890
A very high throughput, and, you know, the biggest thing
that I can, you mentioned here, is planning is everything.

01:04:54.889 --> 01:05:00.549
So when Ken talked about cooling and power, I mean
that's really essential for you to do that ahead

01:05:00.550 --> 01:05:03.880
of deploying your SAN, and making sure
you've got the right environmentals

01:05:03.880 --> 01:05:07.680
in place before you even start racking your equipment.

01:05:07.679 --> 01:05:14.139
And we've saved quite a few customers by making sure
that we did all those calculations ahead of time,

01:05:14.139 --> 01:05:17.549
where they were going to put us in a very
small room, and you know, obviously with just,

01:05:17.550 --> 01:05:18.950
the cooling was not going to be adequate.

01:05:18.949 --> 01:05:20.969
So make sure you plan everything.

01:05:20.969 --> 01:05:22.379
Make sure you've got good networking.

01:05:22.380 --> 01:05:25.349
Work with your networking folks, and don't cut corners.

01:05:25.349 --> 01:05:29.650
I mean if you don't cut corners you'll have a
system that is very robust, that will give you know,

01:05:29.650 --> 01:05:34.400
that will allow you to run, you
know, 24 by 7 and, and, you know,

01:05:34.400 --> 01:05:37.460
have you as an IT person, you know, focused on other things.

01:05:37.460 --> 01:05:40.090
And the SAN will just keep on humming.

01:05:40.090 --> 01:05:42.309
And then again, as we mentioned, backup is very important.

01:05:42.309 --> 01:05:45.119
So for those of you who are backing up today that's good.

01:05:45.119 --> 01:05:48.139
For those of you who aren't, you should.

01:05:48.139 --> 01:05:52.789
For more information, way to get in touch
with us, just Consultingservices@apple.com,

01:05:52.789 --> 01:05:54.849
that's the best way to get in touch with us.

01:05:54.849 --> 01:05:58.880
And now I'm going to bring in the
rest of the team up for, for Q and A.

01:05:58.880 --> 01:06:00.030
So thank you very much.

01:06:00.030 --> 01:06:03.200
[Applause]