WEBVTT

00:00:12.630 --> 00:00:15.020
>>David: So my name is David Hayward, and we'll be talking

00:00:15.019 --> 00:00:19.009
about creating image processing
effects and filters using Core Image.

00:00:19.010 --> 00:00:21.050
This is what we'll be talking about today.

00:00:21.050 --> 00:00:25.580
Give a brief introduction to Core Image for those
of you who may be unfamiliar with the technology,

00:00:25.579 --> 00:00:28.769
and show how easy it is to get started
using Core Image in your application.

00:00:28.769 --> 00:00:33.789
After that, we'll get to the heart of our conversation
today which is to show you how to write CIFilters.

00:00:33.789 --> 00:00:36.460
We have several great examples to show you how to do this.

00:00:36.460 --> 00:00:42.609
And then we'll conclude with some final thoughts
on debugging and other resources to consult.

00:00:42.609 --> 00:00:46.310
So first, a quick introduction to Core Image.

00:00:46.310 --> 00:00:48.340
So what is Core Image?

00:00:48.340 --> 00:00:55.790
So first and foremost, Core Image is a framework
that allows you to do ultra-ast image processing,

00:00:55.789 --> 00:00:59.229
and to apply the effects for fun or profit.

00:00:59.229 --> 00:01:03.509
It works in realtime with other parts of
the system such as Core Video on video,

00:01:03.509 --> 00:01:06.759
or also on the user interface using Core Animation.

00:01:06.760 --> 00:01:11.330
Runs optimized in all the supported Snow Leopard
hardware, and it has several key features,

00:01:11.329 --> 00:01:16.659
not the least of which are floating point
accuracy and a full color managed pipeline.

00:01:16.659 --> 00:01:24.369
In addition to the image processing framework, Core Image
also includes a base set of 125 filters to get you started.

00:01:24.370 --> 00:01:30.870
And in addition to those 125 filters you can extend
that filter set with your own custom filters.

00:01:30.870 --> 00:01:36.990
And that we'll be talking about considerably
later on in the presentation today.

00:01:36.989 --> 00:01:41.169
So here's how we use Core Image
today on our operating system.

00:01:41.170 --> 00:01:45.490
It's used throughout Mac OS X, our applications,
and in third party applications as well.

00:01:45.489 --> 00:01:50.769
We use it for user interface candy,
such as the Dashboard ripple effect,

00:01:50.769 --> 00:01:56.989
we use it for video effects in
iChat and in Photo Booth for fun.

00:01:56.989 --> 00:02:00.189
We also use it for screen savers and iTunes visualizers.

00:02:00.189 --> 00:02:06.429
And then we also use it in our professional
and, you know, consumer type-applications

00:02:06.430 --> 00:02:09.790
like iPhoto and aperture to do image processing.

00:02:09.789 --> 00:02:12.409
So that's where we use it.

00:02:12.409 --> 00:02:15.680
Let me show you a little bit about how it
works as part of our overall framework.

00:02:15.680 --> 00:02:20.300
At the top, the key part of Core Image are its filters.

00:02:20.300 --> 00:02:24.620
And these filters are written in an
architecture-independent language that's C-like,

00:02:24.620 --> 00:02:30.080
that'sbeen extended to have vector types, and
is a subset of the OpenGL shading language.

00:02:30.080 --> 00:02:40.260
These kernels are then executed through Core Image,
combined optimally, and then executed either using OpenGL

00:02:40.259 --> 00:02:46.419
or Open CL use -- either the CPU or the GPU,
depending on what's best for your application.

00:02:48.389 --> 00:02:53.419
So here's a brief illustration of how Core
Image works in the most trivial example.

00:02:53.419 --> 00:02:57.379
Start out with an original image, and you
want to apply one of our filters to it.

00:02:57.379 --> 00:03:04.210
In this simple example we want to apply a sepia tone
filter, and the end result of this filter is a new image

00:03:04.210 --> 00:03:08.290
which is outputted, which is a sepia tone image.

00:03:08.289 --> 00:03:14.599
Obviously, this is a very simple example, we can start
to contrive more complex examples by combining filters.

00:03:14.599 --> 00:03:19.419
And this is where the flexibility
of Core Image really starts to grow.

00:03:19.419 --> 00:03:21.509
And this simple example we now have 2 filters.

00:03:21.509 --> 00:03:27.829
An original image goes through a sepia tone filter, and
then the output of that goes into a hue rotation filter.

00:03:27.830 --> 00:03:33.940
And that gives us a look at the output which looks kind
of like a blue tone rather than a sepia tone image.

00:03:33.939 --> 00:03:38.460
And obviously these are just 2 filters, but if you
can combine more you can see how you can get much more

00:03:38.460 --> 00:03:41.340
complex effects.

00:03:41.340 --> 00:03:47.580
One key aspect of Core Image is that it
will concatenate filters whenever possible.

00:03:47.580 --> 00:03:51.540
The idea behind this is even though we're
applying 2 filters we don't necessarily want

00:03:51.539 --> 00:03:53.699
to have an intermediate image in between them.

00:03:53.699 --> 00:03:58.829
And so by concatenating filters we're reducing the
number of images, and that improves performance.

00:03:58.830 --> 00:04:05.580
And of course, as I alluded to earlier,
complex graphs of filters are supported.

00:04:05.580 --> 00:04:07.480
It doesn't have to be a linear chain.

00:04:07.479 --> 00:04:13.409
You can have tree-type graphs with multiple input
images producing in the end a final output image.

00:04:13.409 --> 00:04:16.219
And this again allows for much
more complicated filter effects,

00:04:16.220 --> 00:04:20.170
including spacial effects and distortion
effects, and so forth.

00:04:20.170 --> 00:04:25.530
And no matter how complex your graph
is, Core Image will work to optimize

00:04:25.529 --> 00:04:29.349
that graph to give the best possible performance.

00:04:29.350 --> 00:04:33.670
So as I mentioned, Core Image includes 125 base filters.

00:04:33.670 --> 00:04:38.370
So let me just give you a quick demonstration
of what some of those filters look like.

00:04:38.370 --> 00:04:40.009
We have an original image here.

00:04:40.009 --> 00:04:46.029
We include four different types of geometry filters
for doing A fine scales, or rotations of an image.

00:04:46.029 --> 00:04:53.789
We have a bunch of distortion effects, such as
this glass effect that we can apply to an image.

00:04:53.790 --> 00:04:55.830
We have a whole bunch of different blur operations.

00:04:55.829 --> 00:04:59.699
We'll be talking about that a little
bit more later on in the show.

00:04:59.699 --> 00:05:03.719
We have typically Gaussian blurs, but
we also have something called a disblur,

00:05:03.720 --> 00:05:06.110
which is used for more photographic effect.

00:05:06.110 --> 00:05:13.129
We have several different types of sharpening
an image, several different color adjustments,

00:05:13.129 --> 00:05:18.680
and color effects to produce different
distortions on an image.

00:05:18.680 --> 00:05:20.259
More fun, stylized filters.

00:05:20.259 --> 00:05:24.829
These are some of the filters that you see in Photo Booth.

00:05:24.829 --> 00:05:29.469
Halftone effects, such as a cmyk halftone effect.

00:05:29.470 --> 00:05:32.210
Different tilings of images, which will be useful.

00:05:32.209 --> 00:05:34.000
We also have 7 generators.

00:05:34.000 --> 00:05:38.750
A generator is a special class of filter that
produces an image but doesn't take an input image.

00:05:38.750 --> 00:05:43.139
So for example, this one produces a star burst pattern.

00:05:43.139 --> 00:05:48.430
We also have nine different filters which are of
a class of filters we call transition filters.

00:05:48.430 --> 00:05:50.629
And transition filters are very useful for video.

00:05:50.629 --> 00:05:57.810
They take 2 images and a transition time, which will
allow you to do wipes between a source and a destination.

00:05:57.810 --> 00:06:04.639
We have lots of composite operations, all the
standard porter-duff composite modes and others.

00:06:04.639 --> 00:06:07.839
And then we have several reduction type filters.

00:06:07.839 --> 00:06:12.310
These are filters that allow you to get
information about an image and reduce it down.

00:06:12.310 --> 00:06:15.480
The most typical example of that is a histogram.

00:06:15.480 --> 00:06:19.310
So we have histogram filters as well.

00:06:19.310 --> 00:06:22.800
So that's our filter set, or a brief tour of it at least.

00:06:22.800 --> 00:06:28.840
Let me talk to you a bit more about how Core Image optimizes
filter graphs, because this is one of the key features

00:06:28.839 --> 00:06:32.109
that I think Core Image provides to your application.

00:06:32.110 --> 00:06:39.699
So Core Image contains a runtime just-in-time Compiler
that is designed to optimize your filter graph.

00:06:39.699 --> 00:06:43.019
The optimization is deferred until
the image is actually drawn.

00:06:43.019 --> 00:06:49.199
And this allows us to only evaluate just the
portion of your image as needed to render.

00:06:49.199 --> 00:06:52.420
That means, for example, if you're zooming
in on a very small portion of your image,

00:06:52.420 --> 00:06:58.650
Core Image will only execute the portion of the
kernel that's needed to render that sub-wrapped.

00:06:58.649 --> 00:07:04.239
Another thing about Core Image and its optimization
is it will concatenate and prune the tree

00:07:04.240 --> 00:07:10.509
to remove any redundant operations
in order to improve performance.

00:07:10.509 --> 00:07:17.310
Once all this is concatenated we have Redo passes
over the filter graph to do global optimizations,

00:07:17.310 --> 00:07:23.410
such as traditional Compiler optimizations such
as peephole and sub-expression elimination.

00:07:23.410 --> 00:07:27.850
And then another real important aspect
is that we perform several optimizations

00:07:27.850 --> 00:07:31.860
that are unique to the domain of image processing.

00:07:31.860 --> 00:07:35.300
Let me talk about that, because that's
where we get some of our key benefits.

00:07:35.300 --> 00:07:42.050
But the great thing is that in Snow Leopard
we now have -- because of these optimizations,

00:07:42.050 --> 00:07:45.490
we have 20% improvement on average in our filters.

00:07:45.490 --> 00:07:47.590
This is great news.

00:07:47.589 --> 00:07:49.419
Some are even more.

00:07:50.970 --> 00:07:56.630
So let me talk to you about -- now you've got an
introduction of what Core Image is capable of,

00:07:56.629 --> 00:08:02.639
let me give you an illustration of how easy
it is to add Core Image to your application.

00:08:02.639 --> 00:08:06.300
So there's 3 key data types you need to
know about when working with Core Image.

00:08:06.300 --> 00:08:07.740
The first is a CIImage.

00:08:07.740 --> 00:08:14.139
The CIImage is an immutable object which represents either
a pixilated image that comes from disc or from memory,

00:08:14.139 --> 00:08:18.800
or it represents the output of a
filter, which we'll talk about next.

00:08:18.800 --> 00:08:25.620
A CIFilter is a mutable object that
represents the recipe to produce the CIImage.

00:08:25.620 --> 00:08:32.889
And this CIFilter has input parameters which are
based on Key/Value coding, and these input parameters,

00:08:32.889 --> 00:08:37.850
such as the input image, will affect the output image.

00:08:37.850 --> 00:08:41.500
The last key data type is the CIContext.

00:08:41.500 --> 00:08:45.559
The CIContext is a destination where
Core Image will render its results.

00:08:45.559 --> 00:08:54.529
And a CIContext image is based on either an
OpenGL context or a Core Graphics context.

00:08:54.529 --> 00:09:00.579
So to walk you through the process we have five
steps for how to add Core Image to your application.

00:09:01.750 --> 00:09:03.529
The first is to create a CIImage.

00:09:03.529 --> 00:09:06.459
And there's 3 easy ways to create a CIImage.

00:09:06.460 --> 00:09:13.420
We can create a CIImage from a CGImage ref, we
can create it from a URL that references a file,

00:09:13.419 --> 00:09:18.500
or we can reference it from data that your
application has produced using some other means.

00:09:18.500 --> 00:09:22.379
Next step is to create a CIFilter.

00:09:22.379 --> 00:09:28.409
CIFilters are represented or instantiated
in Core Image by name.

00:09:28.409 --> 00:09:36.329
So typical code to create a CIFilter would be to
call CIFilter, filter with the name Sepia Tone.

00:09:36.330 --> 00:09:38.960
Or CIFilter, filter with name Hue Adjust."

00:09:38.960 --> 00:09:44.389
If you add your own custom filters in your
application, these too can be created by name.

00:09:44.389 --> 00:09:47.629
So for example, if you have a custom
filter you can reference that by name.

00:09:47.629 --> 00:09:51.529
So we have 125 of these filters.

00:09:51.529 --> 00:09:55.579
In order to know which one you want to
put in your code you may want to discover

00:09:55.580 --> 00:09:57.940
which ones we have available in more detail.

00:09:57.940 --> 00:10:03.030
So we have a utility that's part of the developer
install package which is a Dashboard widget,

00:10:03.029 --> 00:10:08.299
which allows you to explore and see the
parameters and all the filters that we include.

00:10:08.299 --> 00:10:13.779
So in order to get this, you go to your
Dashboard, bring up the Core Image filter browser,

00:10:13.779 --> 00:10:20.279
and it brings up this blue pane which allows you to scroll
through all the filters we install, search through them,

00:10:20.279 --> 00:10:22.879
see which parameters they take as inputs.

00:10:22.879 --> 00:10:27.929
There's another kind of secret feature of
this browser is it supports copy and paste.

00:10:27.929 --> 00:10:34.750
Which allows you to paste -- once you find the filter you
want, paste the template for it into your application.

00:10:36.889 --> 00:10:41.759
Once we have the CIFilter, the next thing we
need to do is set the input parameters on it.

00:10:41.759 --> 00:10:46.519
So filter parameters are set via Key/Value coding.

00:10:46.519 --> 00:10:51.169
One of the most common input parameters
on a filter is the input image.

00:10:51.169 --> 00:10:59.500
You set that by calling filter, set value forKey and
the value is the image we want to set as the input,

00:10:59.500 --> 00:11:04.570
and the key that we pass in is KCI InputImageKey.

00:11:04.570 --> 00:11:06.600
Filters may have additional parameters.

00:11:06.600 --> 00:11:11.690
For example, the sepia tone filter has a parameter
to set the intensity of the amount of sepia tone.

00:11:11.690 --> 00:11:13.850
So that's set again via Key/Value coding.

00:11:13.850 --> 00:11:20.990
This time the value we pass in is an NSNumber, and
the key that we specify is KCI InputIntensityKey.

00:11:22.730 --> 00:11:25.670
So now we have an image, and its filter.

00:11:25.669 --> 00:11:27.719
Next thing we need is context.

00:11:27.720 --> 00:11:32.200
We can create a Cox text from a
CG using context from a CGContext.

00:11:32.200 --> 00:11:37.509
Or we can create it from an OpenGL
context, using create with OpenGL context.

00:11:37.509 --> 00:11:43.909
There's a convenience method for Cocoa programmers,
which is that if you have an NSView custom drawing proc,

00:11:43.909 --> 00:11:53.449
within that draw proc you can call AppKit
to get the current CIContext for that view.

00:11:53.450 --> 00:11:57.780
One important thing that you might want to
consider is that if you're using a GL --

00:11:57.779 --> 00:12:03.019
I'm sorry, a Core Graphics base context, to get
the best performance out of that context you want

00:12:03.019 --> 00:12:07.990
to have your application opt into QuartzGL acceleration.

00:12:07.990 --> 00:12:14.870
And you can do that by adding the QuartzGL
Enable key to your applications info P-list.

00:12:14.870 --> 00:12:21.179
This greatly improves of the performance of Core
Image because it allows Core Image in conjunction

00:12:21.179 --> 00:12:25.799
with Core Graphics to be fully accelerated on the GPU.

00:12:25.799 --> 00:12:31.519
It avoids the read back from the graphics
card into Core Graphics backing store.

00:12:31.519 --> 00:12:36.639
So this is a great way to get optimal
performance when using a CGContext.

00:12:36.639 --> 00:12:41.000
Next and final step is to draw the result.

00:12:41.000 --> 00:12:44.620
So first thing we want to do is we have our last filter.

00:12:44.620 --> 00:12:47.669
We want to get the output image of that last filter.

00:12:47.669 --> 00:12:51.029
And we do that by again using Key/Value accessors.

00:12:51.029 --> 00:12:55.189
In this case, we access the value KCI output image key.

00:12:55.190 --> 00:12:59.570
And then we tell the context to draw that image,
which is a very simple call to tell your context

00:12:59.570 --> 00:13:03.990
to draw the image at a point in the wrap.

00:13:03.990 --> 00:13:09.669
So a common question we often get is "Well, what if
I want the results of a filter for other purposes?"

00:13:09.669 --> 00:13:14.219
And there's 2 calls you may want to consider
if that's what your application needs.

00:13:14.220 --> 00:13:20.940
One is once you have a context you can
create a CGImage from it, and another call -

00:13:20.940 --> 00:13:24.420
with CGImage you can then call image
I/O to write the image to disc.

00:13:24.419 --> 00:13:25.490
So that's useful.

00:13:25.490 --> 00:13:29.139
Another option is you can call -- you can
ask the context to render to a bitmap,

00:13:29.139 --> 00:13:35.009
and that allows you to get the raw
bits that came out of the filter.

00:13:35.009 --> 00:13:41.269
So just to summarize those steps, we can put everything we
talked about on these preceding slides into one screen here.

00:13:41.269 --> 00:13:47.840
And this screen shows us how little code it takes
to do an image processing effect using Core Image.