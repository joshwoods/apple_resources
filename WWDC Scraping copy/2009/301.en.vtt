WEBVTT

00:00:12.890 --> 00:00:21.250
>> Luke: My name is Luke Wallis and I'll be delivering this
presentation together with my colleague Ken Greenebaum.

00:00:23.089 --> 00:00:28.390
What we are hoping that you're going
to learn today is, first of all,

00:00:28.390 --> 00:00:36.370
how the Color Management Architecture
is done in Snow Leopard.

00:00:36.369 --> 00:00:43.769
Then we'll touch on the subject of new ColorSync
API that was introduced in Snow Leopard.

00:00:43.770 --> 00:00:50.470
And later on we'll talk about changes to system
gamma that were also introduced in Snow Leopard.

00:00:50.469 --> 00:00:58.379
Following that we'll touch on the subject of Window Backing
Store Color Space that was also introduced in Snow Leopard.

00:00:58.380 --> 00:01:07.520
And after that Ken will talk more specifically
about Video Color Management in QuickTime X.

00:01:07.519 --> 00:01:14.619
So before we go to the details of Color
Management Architecture in Snow Leopard let's start

00:01:14.620 --> 00:01:23.620
with a simple example of a scenario
which is quite typical on the Mac.

00:01:23.620 --> 00:01:33.310
I have a digital camera that I use for taking
pictures, let's say of being on my vacation in Hawaii

00:01:33.310 --> 00:01:41.890
and I brought this thing back home, I have my Mac,
I have a printer and what I would like to do is

00:01:41.890 --> 00:01:48.799
to download the images from the
camera to my computer, preview them,

00:01:48.799 --> 00:01:55.289
perhaps make some editorial small changes and print them.

00:01:55.290 --> 00:01:58.780
When I do all that I have a certain goal in mind.

00:01:58.780 --> 00:02:05.519
What I'd like to do is to make sure that the
images that I'm going to view on my display

00:02:05.519 --> 00:02:10.009
and later on print will be consistent in terms of color.

00:02:10.009 --> 00:02:16.299
[ Background noise ]

00:02:16.300 --> 00:02:23.230
>> Luke: Why this is important, because
I don't want to waste paper unnecessarily

00:02:23.229 --> 00:02:26.619
on images I don't like I will like the same way.

00:02:26.620 --> 00:02:32.810
I will like to make sure that my display reproduces
faithfully what camera was able to capture

00:02:32.810 --> 00:02:43.000
Is that really is my goal is easy to formulate
but is that really technically easy to achieve?

00:02:43.000 --> 00:02:49.639
Well, I need to step back a little bit
and think about how those devices work.

00:02:49.639 --> 00:02:55.789
Certainly they use completely different
technologies to represent color and this is

00:02:55.789 --> 00:03:00.469
where the differences between those devices are.

00:03:00.469 --> 00:03:08.150
The fundamental problem that I have is that each of
those devices will represent color a different way,

00:03:08.150 --> 00:03:18.569
so in order to achieve what I want in my application I'm
going to write, is to make sure that I can somehow translate

00:03:18.569 --> 00:03:27.599
or convert the color from one device to another
in the way it will preserve its appearance,

00:03:27.599 --> 00:03:33.289
so this is where I need what we call color management.

00:03:33.289 --> 00:03:41.030
Color management will take care of proper
conversions between different color representations.

00:03:41.030 --> 00:03:54.650
In order to understand this better we need to look into
a way of how to represent color capabilities of each

00:03:54.650 --> 00:03:59.969
of those devices, and here I give
you an example which is quite simple.

00:03:59.969 --> 00:04:06.469
I'm talking about one camera, one display and one
printer, but when I'm thinking about moving forward

00:04:06.469 --> 00:04:14.610
with the application that I'm going to develop to help
user working this workload I'm thinking that, well,

00:04:14.610 --> 00:04:21.530
very often he may have access to some other images which
were acquired by completely different cameras and stored

00:04:21.529 --> 00:04:25.969
on the disk on somewhere else and
my user may want to combine all

00:04:25.970 --> 00:04:30.470
that with new picture I just brought from Hawaii.

00:04:30.470 --> 00:04:37.750
Well, my Mac is also on the network, there's a Web
maybe I've seen the images of the place I stayed in

00:04:37.750 --> 00:04:42.910
but the weather was bad I couldn't really take good
pictures but maybe I can take something from the Web

00:04:42.910 --> 00:04:47.990
and add to my album I'm going to be creating.

00:04:47.990 --> 00:04:53.290
Well, I work on one computer but very often
maybe I will be moving from one place to another.

00:04:53.290 --> 00:04:55.050
I may be working on different devices.

00:04:55.050 --> 00:05:02.500
I will, perhaps, do some work on my laptop or my
iMac somewhere else so I'm not going to be dealing

00:05:02.500 --> 00:05:05.490
with only one display but multiple devices.

00:05:05.490 --> 00:05:15.079
And then recently we added new devices which I
can connect to my Mac and also take advantage

00:05:15.079 --> 00:05:18.529
of presenting the content that I'm working on on them.

00:05:18.529 --> 00:05:26.349
I may want to upload some of the images to
my iPhone so I can show people, you know,

00:05:26.350 --> 00:05:32.510
my kind of abbreviated version of my
album I'm working on on my iPhone.

00:05:32.509 --> 00:05:39.289
But, perhaps, I can also do the similar thing and
upload images to my Apple TV and then when I have the

00:05:39.290 --> 00:05:50.260
after vacation homecoming party my friends may look at
this on my high-definition TV connected to Apple TV.

00:05:50.259 --> 00:05:56.930
So that's a great picture but I realize,
as I said, all those devices are different.

00:05:56.930 --> 00:06:00.870
How I'm going to tackle the problem?

00:06:00.870 --> 00:06:14.240
So let's take a look at how can I represent different
devices in terms of their color capabilities?

00:06:14.240 --> 00:06:22.370
I'm showing you something very simple in terms of
a model of the visible spectrum; this is called,

00:06:22.370 --> 00:06:27.790
as many of you may know, chromaticity
diagram that shows a visible spectrum,

00:06:27.790 --> 00:06:32.680
and each of my devices can reproduce a part of that.

00:06:32.680 --> 00:06:37.199
There's really no device who could
reproduce the full visible spectrum.

00:06:37.199 --> 00:06:48.740
I give you an example of the Adobe RGB which is one of
the typical color spaces using digital SLR cameras today.

00:06:48.740 --> 00:06:53.129
But let's go in order of introducing those new concepts.

00:06:53.129 --> 00:06:59.199
So, first of all, my device can
be characterized by its gamut.

00:06:59.199 --> 00:07:04.800
Gamut, basically, means the color range
that my device is able to reproduce.

00:07:04.800 --> 00:07:11.759
On this particular graph this triangle
represents the device gamut,

00:07:11.759 --> 00:07:18.589
and all colors which are inside the triangle
are reproducible in this particular color space.

00:07:18.589 --> 00:07:21.489
So here is another term I use, color space.

00:07:21.490 --> 00:07:30.560
As we think about device gamut as kind of a volume
or a range of color as a part of physical colors

00:07:30.560 --> 00:07:39.209
in nature color space allows me to
mathematically express the color.

00:07:39.209 --> 00:07:46.039
And here this is a very simple example of Color
Space using three primaries, red, green and blue

00:07:46.040 --> 00:07:53.180
and each of the colors can be represented
as a linear combination of all three.

00:07:53.180 --> 00:08:03.280
So, great, I kind of came out with the model of how to
express and define my device color capabilities so now

00:08:03.279 --> 00:08:12.289
when I go back to the problem I'm trying to solve is I need
to reproduce the color, produce on one device on another.

00:08:12.290 --> 00:08:19.810
And I know they have different gamuts so I go
back to devices I showed you on the first line

00:08:19.810 --> 00:08:28.750
and my camera is a pretty good camera using Adobe RGB
as the color in which all the images will be produced.

00:08:28.750 --> 00:08:34.210
I have my laptop display with another
gamut and I have an inkjet printer.

00:08:34.210 --> 00:08:45.860
And as you see all those gamuts are different so if I
pick a color somewhere in Adobe RGB which is in the middle

00:08:45.860 --> 00:08:53.800
of the gamut and I want to reproduce
this color on my LCD I see that at least

00:08:53.799 --> 00:08:57.529
from the physical capabilities perspective I have no problem

00:08:57.529 --> 00:09:05.779
because this color fits quite well inside the
LCD Display Gamut, same thing with the printer

00:09:05.779 --> 00:09:10.919
that color is inside of inkjet printer gamut.

00:09:10.919 --> 00:09:16.329
So there's no color shift, colors are in gamut.

00:09:16.330 --> 00:09:26.440
But what if I chose some other color which is still
in my RGB camera but, obviously, as you can tell;

00:09:26.440 --> 00:09:30.120
this is way beyond the gamuts of my two other devices.

00:09:30.120 --> 00:09:38.370
So then in order to do anything and reproduce this
color I need to do something and in the example

00:09:38.370 --> 00:09:48.019
of my LCD display I have to push it to the closest point
I have in gamut to my point in the visible spectrum

00:09:48.019 --> 00:09:53.399
and as you see my green is no longer
green it changed, right?

00:09:53.399 --> 00:10:02.590
I had to in order to reproduce it anyway
I'm going to add an unfortunate color shift.

00:10:02.590 --> 00:10:11.330
This color is also outside of the gamut of my
printer but it's not as bad it was quite close and,

00:10:11.330 --> 00:10:14.910
you know, it's kind of green the same as it was.

00:10:16.450 --> 00:10:29.090
So one more quite important point I'd like to make here is
that the choice of making conversions is very important.

00:10:29.090 --> 00:10:33.470
Very often my color conversion can be lossy.

00:10:33.470 --> 00:10:42.529
So if I decided to take my green color and first convert
to the smaller gamut and then go from there to the printer,

00:10:42.529 --> 00:10:48.850
obviously, I introduced kind of damage to
my color that I cannot recover anymore.

00:10:48.850 --> 00:10:53.470
So point is, it is important to remember

00:10:53.470 --> 00:10:59.519
that color conversions can introduce certain
changes which are not always desired.

00:11:00.990 --> 00:11:06.269
So I know all that and so I go back
to my application I wanted to write.

00:11:06.269 --> 00:11:15.600
So I have only the camera and I have display and the printer
and I have to do now all this handling of those differences

00:11:15.600 --> 00:11:20.920
in gamuts and mapping and making
smart decisions and all that.

00:11:20.919 --> 00:11:33.240
Well, this may be quite a big task so this is when we're
designing Mac OS X one of the decisions that we made is

00:11:33.240 --> 00:11:38.279
that we need to really help applications
to handle all those issues.

00:11:38.279 --> 00:11:46.519
And the way we wanted to do it was by introducing what we
called Integrated and Automatic Color Management to kind

00:11:46.519 --> 00:11:50.529
of separate application from dealing with all those details.

00:11:50.529 --> 00:11:58.490
There was already a very well known component existing
in the old Mac OS called ColorSync so, obviously,

00:11:58.490 --> 00:12:05.389
there was an obvious choice to use
ColorSync as a color management technology.

00:12:05.389 --> 00:12:13.399
ColorSync was very well established already in the
publishing industry and as many of you may know it is based

00:12:13.399 --> 00:12:25.889
on the standard produced by International Color Consortium
or ICC and recently ICC became an ISO Standard as well.

00:12:25.889 --> 00:12:38.159
And the ICC as well as ColorSync is based on two
fundamental concepts of ICC profiles which will define

00:12:38.159 --> 00:12:43.719
in general terms color capabilities
of any devices of color spaces.

00:12:43.720 --> 00:12:50.500
And another part of that is so called CMM
or, in other words, Color Management Module

00:12:50.500 --> 00:12:56.279
which in essence is a mathematical engine which
does all the mathematical operations required

00:12:56.279 --> 00:13:00.539
by converting the color from one representation to another.

00:13:03.240 --> 00:13:06.100
So how all that works?

00:13:06.100 --> 00:13:17.060
In a nutshell a profile contains the information
in forms of tags that allow me to convert the data

00:13:17.059 --> 00:13:25.139
from device color space to some arbitrary chosen
reference color space called Profile Connection Space.

00:13:25.139 --> 00:13:34.809
So let's say I have, again, my camera and my printer
and I have profiles associated with those devices.

00:13:34.809 --> 00:13:41.829
Using the profile I can convert the data to my
Profile Connection Space and then from there,

00:13:41.830 --> 00:13:45.240
using the printer profile, convert it to the printer.

00:13:45.240 --> 00:13:50.629
In a very similar way I may have
the scanner with the proper profile.

00:13:50.629 --> 00:13:57.769
It might have a profile for my
display and by using connection

00:13:57.769 --> 00:14:05.159
through Profile PCS I can convert the
data from the scanner to my display.

00:14:05.159 --> 00:14:09.000
It's not difficult to imagine that the same
thing can be applied to the video content

00:14:09.000 --> 00:14:12.429
which is defined to be in a specific Color Space.

00:14:12.429 --> 00:14:21.189
I convert it to PCS and then by converting to
my display I can play it with the proper colors.

00:14:21.190 --> 00:14:24.690
I'd like to bring your attention to a little detail here.

00:14:24.690 --> 00:14:32.730
As you see the printer is considered typically an output
device but my profile shows the arrows going both ways.

00:14:32.730 --> 00:14:41.870
Why this is important because what I am trying to represent
here is the fact that I can kind of convert my color

00:14:41.870 --> 00:14:47.929
to the printer and then having that color
converted to the printer bring it back

00:14:47.929 --> 00:14:51.859
to PCS and display, converted then to display.

00:14:51.860 --> 00:14:55.649
What it allows me to do is to simulate
the behavior of the printer.

00:14:55.649 --> 00:14:59.539
And in the publishing industry this
process is called soft proofing.

00:14:59.539 --> 00:15:07.469
So instead of checking my colors every time by throwing
ink on the paper I can preview that and this becomes more

00:15:07.470 --> 00:15:13.580
and more reliable and more popular
tool in real big printing business.

00:15:13.580 --> 00:15:21.139
There is a little bit of more details
in terms of what profiles contain.

00:15:21.139 --> 00:15:27.370
As I said they allow us to convert the color
between the device in PCS and vice versa

00:15:27.370 --> 00:15:35.779
but they can provide also information how to do
it in some different standard pre-defined ways.

00:15:35.779 --> 00:15:41.379
Those ways are called The Rendering Intent and each
profile contains the information you have to do it

00:15:41.379 --> 00:15:45.250
for 3 different rendering intents, one is perceptual.

00:15:45.250 --> 00:15:53.460
Perceptual is the intent where we are not necessarily
worrying only about faithfully representing the color

00:15:53.460 --> 00:15:59.030
as I showed you by moving those
color dots from one gamut to another.

00:15:59.029 --> 00:16:08.409
I know that I have some limitations in my device so
I'm trying to move the colors, preserve the perception

00:16:08.409 --> 00:16:12.990
of the color which works well for pictorial images.

00:16:12.990 --> 00:16:19.200
Another more mathematical kind of rendering and this
is colorimetric; this is the one I was presenting you.

00:16:19.200 --> 00:16:27.330
I really want to represent take the color from one device
and put it in PCS exactly as it is with sometimes I have

00:16:27.330 --> 00:16:35.110
to do some clipping or moving but I want to
minimize that, so that one is called colorimetric.

00:16:35.110 --> 00:16:43.430
And there's yet another one called saturation which
tries to explore the kind of vividness of my device

00:16:43.429 --> 00:16:48.679
or in which very useful for things like
business graphics when I want my red

00:16:48.679 --> 00:16:51.309
to be really the best red possible on that device.

00:16:51.309 --> 00:16:58.189
Already I know I started with some color space but maybe
I can do something better in terms of presenting that.

00:16:58.190 --> 00:17:09.480
So all that, as you see, gives me the ways of selecting a
path through the profile according to that rendering intent.

00:17:09.480 --> 00:17:15.490
And this is where CMM comes to play because
when I'm creating a transform from one device

00:17:15.490 --> 00:17:24.380
to another I give the CMM profiles and as well as
rendering intent and direction of the transform.

00:17:24.380 --> 00:17:32.990
So the example here on the slide shows you how I created
a transform growing from my device A which was my source

00:17:32.990 --> 00:17:38.950
and doing just Colorimetric transformation which, basically,
says, you know, just represent these colors as I had

00:17:38.950 --> 00:17:42.340
on my device the best possible way in PCS.

00:17:42.339 --> 00:17:49.099
And then from there I wanted to do perceptual
rendering on my output device which says, you know,

00:17:49.099 --> 00:17:59.089
here are the colors in PCS and try to make the best in
terms of converting them in perceptual way which may be

00:17:59.089 --> 00:18:02.859
as good as I told you for pictorial images.

00:18:02.859 --> 00:18:08.429
I think this is also a good moment to mention
what kind of data CMM is going to convert.

00:18:08.430 --> 00:18:16.940
We deal with 8-bit and 16-bit integers and
as well added recently 32-bit floating point.

00:18:16.940 --> 00:18:23.000
So I'd like to illustrate that with some numerical example.

00:18:23.000 --> 00:18:28.269
Let's take again as example two
profiles I already mentioned.

00:18:28.269 --> 00:18:35.490
My source this time will be the LCD Display Profile
and my destination's going to be my Adobe RGB.

00:18:35.490 --> 00:18:41.509
So, you know, there are many different types
of profiles and the one I'm going to talk about

00:18:41.509 --> 00:18:45.109
or using as an example here so-called Matrix Based Profile.

00:18:45.109 --> 00:18:52.559
It contains the information which allows me to build the
tone rendering curves that are applied in the process

00:18:52.559 --> 00:19:00.139
of converting the data from device to PCS by
applying those individual tone rendering curves

00:19:00.140 --> 00:19:04.220
that popularly very often are called
gamma; this is some old display.

00:19:04.220 --> 00:19:11.220
As you see, it had 1.8 gamma so I was able
to build those tables based on the profile.

00:19:11.220 --> 00:19:19.220
Another information I was going to extract the
profile is LCD Display Matrix is based on the values

00:19:19.220 --> 00:19:26.470
of my primaries I represented in XYZ Color
Space, and this allows me to convert the data

00:19:26.470 --> 00:19:29.230
from my device to Profile Connection Space.

00:19:29.230 --> 00:19:36.470
Well, the Adobe RGB is a very similar type of
the profile so what I have to do is, again,

00:19:36.470 --> 00:19:43.329
build the matrix based on some information contained in
the profile but this time it's going to be inverted matrix

00:19:43.329 --> 00:19:47.750
because I'm going in the opposite
direction, and the same thing with TRC's.

00:19:47.750 --> 00:20:03.059
As we know Adobe RGB has a gamma 2.2 so I'll be applying the
inverted 2.2 gamma to my data to convert it to Adobe RGB.

00:20:03.059 --> 00:20:08.549
So now let's take and put a real
number that I want to convert.

00:20:08.549 --> 00:20:15.220
I've chosen the most saturated green
that I can reproduce on this device.

00:20:15.220 --> 00:20:17.690
Well, we are not going to go through the math here

00:20:17.690 --> 00:20:23.750
but if I really did the math what comes
on the other end looks quite different.

00:20:23.750 --> 00:20:31.180
My pure green which has zero red, zero blue
suddenly introduced quite a bit of red and blue

00:20:31.180 --> 00:20:35.740
and my green is far away from fully saturated color.

00:20:35.740 --> 00:20:40.279
There often people are surprised by that
so this is why I'm talking about this.

00:20:40.279 --> 00:20:44.799
Let's look, again, at the gamuts of those two profiles.

00:20:44.799 --> 00:20:47.720
The one in the middle is my display.

00:20:47.720 --> 00:20:53.480
So what is {0, 255, 0} in terms of red, green and blue?

00:20:53.480 --> 00:21:01.970
Well, this is my vertex of my gamut, right; this is
the most green color I can reproduce on this device.

00:21:01.970 --> 00:21:11.610
Well, just by reference if I want the same device values
{0, 255, 0} in my AdoUbe RGB, well, I'm far away from there.

00:21:11.609 --> 00:21:21.949
I'm in much more saturated green than my LCD,
so this is why when I represent LCD {0, 255,

00:21:21.950 --> 00:21:27.830
0} in Adobe RGB I'm getting something which
is a linear combination of the other three

00:21:27.829 --> 00:21:32.879
and really the device values has
nothing to do with each other.

00:21:32.880 --> 00:21:39.030
So this brings me to the most important that I'd
like to make here, that color values are only

00:21:39.029 --> 00:21:42.410
on unequivocal if they are tagged with proper profile.

00:21:42.410 --> 00:21:46.009
If we drop that information we really don't
know what kind of color we are talking about.

00:21:46.009 --> 00:21:51.569
[ Background noise ]

00:21:51.569 --> 00:21:57.480
>> Luke: So this part covers the mathematics
and profiles that are used in ColorSync

00:21:57.480 --> 00:22:01.660
but ColorSync on Mac OS X has another role.

00:22:01.660 --> 00:22:06.700
Besides all this math and profiles
it contains Device Integration.

00:22:06.700 --> 00:22:16.920
Device Integration is a database that contains the
information about color devices connected to the system.

00:22:16.920 --> 00:22:25.519
So as you know Mac OS X contains different device managers
for different types of devices, and those device managers

00:22:25.519 --> 00:22:31.200
in Mac OS X are integrated in ColorSync in the
sense that they not only provide the awareness

00:22:31.200 --> 00:22:38.080
of the device being connected to the system
but also allow us an access to their profiles.

00:22:38.079 --> 00:22:46.519
So part of this process where the Device
Integration is being used is Device Registration.

00:22:46.519 --> 00:22:48.009
You might have seen it.

00:22:48.009 --> 00:22:55.200
Every time you plug in your camera to the computer and you
have ColorSync Utility open you will see that, you know,

00:22:55.200 --> 00:23:00.610
the new device showed up and if the driver
had a profile for it it will register

00:23:00.609 --> 00:23:04.759
and the profile can be seen in the ColorSync utility.

00:23:04.759 --> 00:23:08.869
Same thing of the printer I have my USB printer I connect it

00:23:08.869 --> 00:23:17.369
without any specific action automatically the proper
device manager, printing manager will talk to the driver,

00:23:17.369 --> 00:23:24.699
get the proper profiles, register those profiles
on behalf of the driver for that specific printer.

00:23:24.700 --> 00:23:33.490
This may be important for some of the programmers who
need to know about new devices coming or going away.

00:23:33.490 --> 00:23:38.319
An important point I'd like to make here
is that device drivers not necessarily have

00:23:38.319 --> 00:23:44.109
to register their full profiles specifically for
display devices like, you know, just a regular display

00:23:44.109 --> 00:23:50.979
or very often projectors, those devices carry so called
EDID information, which is I don't remember exactly that

00:23:50.980 --> 00:23:55.660
but what it means is Extended Display
Information -- something -- Data, right?

00:23:55.660 --> 00:24:02.009
And it contains color metric information out
of which ColorSync can build the profile.

00:24:02.009 --> 00:24:06.539
And this is actually what is happening with
every single panel that we produce at Apple,

00:24:06.539 --> 00:24:10.889
they don't come with the profiles they
come with this color metric information.

00:24:10.890 --> 00:24:14.300
The same thing happens very often with LCD projectors.

00:24:14.299 --> 00:24:21.470
When you plug it in the EDID contains the data and Mac will
build that profile on the fly and we're going to use it.

00:24:21.470 --> 00:24:25.190
So this is how it works.

00:24:25.190 --> 00:24:34.980
What may be important for developers is the fact that Device
Integration will send notification every time an event

00:24:34.980 --> 00:24:39.660
like registration or changing the profile
happens and its application needs to know

00:24:39.660 --> 00:24:44.390
that it can register for that and handle that.

00:24:44.390 --> 00:24:52.460
Important part to know about Device Integration is
the fact the user can override those factory profiles.

00:24:52.460 --> 00:24:54.150
ColorSync Utility allows you to that.

00:24:54.150 --> 00:25:02.390
Here's a screen shot from my computer where I have
the Epson Stylus 1280 which at the moment of plugging

00:25:02.390 --> 00:25:09.780
in registered nine profiles and as is shown
on the right-hand side of the slide it came

00:25:09.779 --> 00:25:13.869
with a specific factory profile but
I have my own tools which allow me

00:25:13.869 --> 00:25:19.879
to create my own custom profile that
I'm going to use instead of that.

00:25:19.880 --> 00:25:28.920
How it works that if the component that needs to know
or what kind of profile is associated with the device

00:25:28.920 --> 00:25:37.950
in context when I am the current user my custom profile
will be returned instead of the factory profile.

00:25:37.950 --> 00:25:46.120
So a quick summary, ColorSync, some database of
profiles that come preinstalled over the system,

00:25:46.119 --> 00:25:49.679
user can add the profiles into specific location.

00:25:49.680 --> 00:25:53.980
Besides that we have Device Integration
that just described to you how it works

00:25:53.980 --> 00:25:56.870
for different kind of devices connected to the system.

00:25:56.869 --> 00:25:59.909
And last but not least CMMs.

00:25:59.910 --> 00:26:11.900
Mac OS X ships with one Apple CMM but there are
ways for other applications register their own CMMs.

00:26:11.900 --> 00:26:19.710
So now after all that what I said let's take a look at
what's going to happen in the application that wants

00:26:19.710 --> 00:26:24.279
to do some color processing, deal with color devices.

00:26:24.279 --> 00:26:28.720
So my simple application is obviously a Cocoa application.

00:26:28.720 --> 00:26:34.089
I listed here all those lower-level
frameworks that deal with the color data

00:26:34.089 --> 00:26:40.059
and in my example a camera is connected to the system.

00:26:40.059 --> 00:26:49.179
So from the high-level application I sent a query through
the component through the frame we'll call Image Capture,

00:26:49.180 --> 00:26:53.900
'please acquire an image from the camera for me'.

00:26:53.900 --> 00:27:02.610
So when Image Capture talks to a specific device
module for my camera it checks the content of the image

00:27:02.609 --> 00:27:10.659
and if that image contains the profile is being
passed on and we know we have properly characterized

00:27:10.660 --> 00:27:14.290
or tagged image being passed back to the application.

00:27:14.289 --> 00:27:21.609
But if that image did not contain anything
I go back to ColorSync Integration and say,

00:27:21.609 --> 00:27:27.069
where is the profile for this camera and
my image will be tagged with that profile.

00:27:27.069 --> 00:27:36.329
So what application's receiving is we'll tag an object
or what we call CG Image or we can call it just an image

00:27:36.329 --> 00:27:42.220
for the purpose of this talk that contains
everything I need to properly process that.

00:27:42.220 --> 00:27:49.240
So the very next thing I would like to do in
my application is to draw it on the screen.

00:27:49.240 --> 00:27:57.039
Do I need to do anything about this image, no I take the
image I receive from Image Capture and I pass it to Quartz

00:27:57.039 --> 00:28:05.119
which an old terminology core graphics which will
rasterize it for me and display it on my display.

00:28:05.119 --> 00:28:12.250
And in that process without any involvement
of the application Quartz itself will query,

00:28:12.250 --> 00:28:17.759
ColorSync will find out the proper profile for
the display and what has to happen in terms

00:28:17.759 --> 00:28:22.299
of color conversion will be done without
any involvement of the application.

00:28:22.299 --> 00:28:27.250
So you can imagine the exactly same thing
is going to happen when I want to print.

00:28:27.250 --> 00:28:35.549
I just pass my image as is to CUPS with the selected
printer and the underlying frameworks will take care

00:28:35.549 --> 00:28:45.220
of selecting the current profile for the given printing
condition and sending the rasterized data to the printer.

00:28:45.220 --> 00:28:49.809
And here are other example that maybe I should mention.

00:28:49.809 --> 00:28:58.379
I can same way using proper lower-level
framework open as an example PDF document

00:28:58.380 --> 00:29:00.960
which may contain many different color spaces.

00:29:00.960 --> 00:29:06.319
As you know PDF can represent -- doesn't have
to be just RGB it can be many different objects

00:29:06.319 --> 00:29:09.079
and images in completely different color spaces.

00:29:09.079 --> 00:29:18.119
Application without even looking inside just by creating
an object of PDF document can send it to Quartz and say,

00:29:18.119 --> 00:29:23.889
display for me, and besides providing some
geometrical information about the placement

00:29:23.890 --> 00:29:28.160
in the window it doesn't have to do anything.

00:29:28.160 --> 00:29:36.120
The same process of converting the source color spaces
to the proper destination will happen automatically.

00:29:36.119 --> 00:29:43.750
Obviously, the same will be applied in terms of opening
typical image files and the same in terms of writing it out.

00:29:43.750 --> 00:29:52.519
When we are writing an image to a specific image
file we will tag it properly so next time we

00:29:52.519 --> 00:29:59.480
or anybody opens it it has the proper color
information to process that image properly.

00:29:59.480 --> 00:30:06.960
I would like to stop for a second on some details
of printing because it is slightly different.

00:30:06.960 --> 00:30:12.829
The general idea is exactly the same
but there is something additional there.

00:30:12.829 --> 00:30:17.769
So very quickly looking at the architecture
of printing how it works it consists of kind

00:30:17.769 --> 00:30:25.509
of two components the first we call Printing From, that's
the actual library your application is linking with

00:30:25.509 --> 00:30:29.869
and this is where the choice about
the profile and printer happens

00:30:29.869 --> 00:30:40.000
and if I decided what is my destination we spool the
spool file which contains both the content I want to print

00:30:40.000 --> 00:30:46.589
and the profiles for my printer and this is being sent to
the other component which we call the Printing Backend.

00:30:46.589 --> 00:30:52.409
And the Printing Backend will do the rasterization or
produce post script or whatever we need at the backend,

00:30:52.410 --> 00:31:00.550
but there is a detail that I want to mention here,
that Printing Backend may work in 2 different modes.

00:31:00.549 --> 00:31:07.609
The first and this is the default mode for most
of the printers is so called Color Hand-off.

00:31:07.609 --> 00:31:14.319
What it means that I really don't need to
match to my destination profile of the printer.

00:31:14.319 --> 00:31:22.029
The driver might have told us please rasterize everything
convert all these multiple color spaces that we may have,

00:31:22.029 --> 00:31:26.779
for example, in PDF document to that one
color space before you give it to me.

00:31:26.779 --> 00:31:28.500
The typical color space like that is sRGB.

00:31:28.500 --> 00:31:36.579
And then the driver takes it over from there and does
its own color management to put the ink on the paper.

00:31:36.579 --> 00:31:46.029
But, obviously, for kind of higher-level needs of more
advanced developers or users there is another mode

00:31:46.029 --> 00:31:52.349
where literally the profile that was registered for
that printer for a specific mode is going to be used

00:31:52.349 --> 00:31:59.549
and pre-matched by OS and the driver at this
moment should not be making no adjustment.

00:32:02.430 --> 00:32:09.370
So what is the summary of all those
things I was talking about?

00:32:09.369 --> 00:32:17.250
Well, that we, as I said, Mac OS X offers
the Integrated Automatic Color Management.

00:32:17.250 --> 00:32:24.140
So what it means in essence that the profiles will
be always used wherever they are or they are needed.

00:32:24.140 --> 00:32:32.050
So as a developer there are often the only thing you need to
is to choose the proper color space for additional drawings

00:32:32.049 --> 00:32:38.730
that you're doing besides handling the images that may
be coming from different sources and just leave it alone.

00:32:38.730 --> 00:32:43.009
The Mac OS X will do the proper color management for you.

00:32:43.009 --> 00:32:48.879
[ Background noise ]

00:32:48.880 --> 00:32:55.640
>> Luke: As I mentioned before for those who
really need to know more details is the fact

00:32:55.640 --> 00:33:07.880
that we rewrote the ColorSync API, ColorSync in Snow Leopard
that we have a new API based on core foundations it's C API.

00:33:07.880 --> 00:33:17.750
Now it's a lot smaller, contains only 32 functions just for
statistics which replace 129 of old functions, you know,

00:33:17.750 --> 00:33:20.970
which now are deprecated, of course,
they're still supported.

00:33:20.970 --> 00:33:25.440
You know ColorSync has grown for a
very, very long time ago until now

00:33:25.440 --> 00:33:29.390
and there was really a time to
make an adjustment in that sense.

00:33:29.390 --> 00:33:34.960
Unfortunately I don't have any sample code but
I promise they will be available at some point

00:33:34.960 --> 00:33:45.460
on Apple Developer Connection website so please check that
from time to time at some point everything will be there.

00:33:45.460 --> 00:33:51.019
But speaking of ColorSync API I would
like to mention kind of a new feature

00:33:51.019 --> 00:33:55.230
which is very unusual for other types of frameworks.

00:33:55.230 --> 00:34:01.960
So when I was talking about how this process works of
getting a profile and selecting the profile for my source

00:34:01.960 --> 00:34:05.779
and destination and creating and
transforming and then passing it back to CMM

00:34:05.779 --> 00:34:08.820
and requesting the data can be converted.

00:34:08.820 --> 00:34:15.260
We came up with a new idea of handling this
process which is very useful in presence

00:34:15.260 --> 00:34:20.050
of GPU which we know can be very powerful.

00:34:20.050 --> 00:34:23.800
So instead of going through all this what I described

00:34:23.800 --> 00:34:31.120
to you ColorSync can return kind of
recipe of how to apply the transform.

00:34:31.119 --> 00:34:37.329
What is that transform has to be applied in
order to convert from profile A to profile B?

00:34:37.329 --> 00:34:47.239
And this allows an application to ride a fragment
code in the Shader Language for a given GPU

00:34:47.239 --> 00:34:51.579
and really push those bits through that very quickly.

00:34:51.579 --> 00:34:57.009
This model is already used inside of Mac OS X
by components like Core Image and QuickTime.

00:34:57.010 --> 00:35:03.290
[ Background noise ]

00:35:03.289 --> 00:35:05.800
>> Luke: So that's -- this is all about ColorSync.

00:35:05.800 --> 00:35:13.710
Now there are certain topics related to color that I
would like to talk about which are new in Snow Leopard.

00:35:13.710 --> 00:35:19.440
First of all, the fact that we are
now using 2.2 as a system gamma.

00:35:19.440 --> 00:35:26.869
Another topic I'd like to mention is the Color
Space of the Window Backing Store and then something

00:35:26.869 --> 00:35:33.250
which is also important starting from Snow
Leopard is Display Change Notification.

00:35:33.250 --> 00:35:38.400
So let's go quickly to system gamma in Snow Leopard.

00:35:38.400 --> 00:35:46.750
Well, very brief reminder for those who are not familiar
with that gamma, basically, describes the relationship

00:35:46.750 --> 00:35:50.550
between digital counts or voltage and the luminance.

00:35:50.550 --> 00:35:57.110
And by nature this is an exponential function
and for most of CRT is very close to 2.2.

00:35:57.110 --> 00:36:04.140
Obviously, we are almost forgetting that CRTs
existed but LCDs that took over from there try

00:36:04.139 --> 00:36:11.029
to preserve the same behavior so they're behaving the
same way that the relation between the digital counts

00:36:11.030 --> 00:36:17.420
and luminance is also -- turn this off power function.

00:36:17.420 --> 00:36:24.240
So as you know traditional Mac gamma was
1.8, that was very good in the very old days

00:36:24.239 --> 00:36:28.609
when there was no color management you wanted to print.

00:36:28.610 --> 00:36:35.750
Many of you may be familiar with the problem of Dove
Game and so just not to go into the details of that,

00:36:35.750 --> 00:36:40.650
1.8 was really much better solution for printing.

00:36:40.650 --> 00:36:42.340
We needed to somehow implement that.

00:36:42.340 --> 00:36:45.289
We knew that native display gamma is 2.2.

00:36:45.289 --> 00:36:52.989
We wanted to have an effective gamma of 1.8 so what we
are doing is we are using so called Video Look-up tables

00:36:52.989 --> 00:36:56.849
of buffer lots as is written on
this display to make an adjustment.

00:36:56.849 --> 00:37:03.429
Those video LUTs should be actually used for
completely different things, more for like linearization

00:37:03.429 --> 00:37:08.409
of the display, you know, making sure
everything works as in the spec in terms

00:37:08.409 --> 00:37:12.649
of some small variations in hardware or firmware.

00:37:12.650 --> 00:37:22.860
But we were combining those with additional change
which will allow us to emulate 1.8 gamma on the system.

00:37:22.860 --> 00:37:29.289
So starting from Snow Leopard we are no longer doing that.

00:37:29.289 --> 00:37:36.059
The native gamma of the CRT or how our LCD is
displayed is close to 2.2 the reality is different

00:37:36.059 --> 00:37:41.289
but that's the model, so our system
gamma will be 2.2 as well.

00:37:41.289 --> 00:37:47.389
So what that means is we can leave the frame buffer
LUTs really for what they are supposed to be used for

00:37:47.389 --> 00:37:52.989
and we don't need to combine and tweak them
in order to achieve that result of 1.8.

00:37:52.989 --> 00:37:58.849
And there is another important reason why
we do that because we wanted to align --

00:37:58.849 --> 00:38:01.509
sorry; I went a little bit too far with this slide.

00:38:01.510 --> 00:38:10.000
We wanted to align our system gamma with what became the
fact of standard in the industry like digital photography,

00:38:10.000 --> 00:38:18.090
digital video, publishing and digital cinematography.

00:38:18.090 --> 00:38:21.890
So is there anything that you as
developers have to do about this?

00:38:21.889 --> 00:38:27.109
Well, if your data was tagged it really makes
no difference the images will be just matched

00:38:27.110 --> 00:38:29.890
to a different profile and everything will work fine.

00:38:29.889 --> 00:38:38.289
But in case when your applications was using untagged
data I think you would need to make some adjustments.

00:38:38.289 --> 00:38:42.460
Here is an example of what's going to
happen if the image was not tagged.

00:38:42.460 --> 00:38:49.289
Clearly the image on the right side is
a little bit too dark, too contrasting.

00:38:49.289 --> 00:38:56.329
We realize that this is a process of transition so we
added a ColorSync API which allows you to very quickly find

00:38:56.329 --> 00:38:59.190
out what is the current gamma of the display.

00:38:59.190 --> 00:39:07.639
If you are running on the old system which was still
supporting 1.8 or you're already on Snow Leopard and 2.2.

00:39:07.639 --> 00:39:11.150
The important point I would like to make at this moment is

00:39:11.150 --> 00:39:17.849
that untagged RGB data will be printed
differently on Snow Leopard than it was before.

00:39:17.849 --> 00:39:23.469
Again, kind of aligning with what is
happening out there besides the Mac.

00:39:23.469 --> 00:39:31.909
RGB data will be printed as RGB and if we have any
untagged gray data we printed as generic gray 2.2 gamma,

00:39:31.909 --> 00:39:42.129
which what that profile is or color space is exactly
the same piece wise gamma curve as in RGB profile.

00:39:42.130 --> 00:39:49.960
So next topic I would like to talk about
is the Window Backing Store Color Space.

00:39:49.960 --> 00:39:57.889
So when we think about drawing to a window we actually,
on Mac, we don't draw directly to the frame buffer.

00:39:57.889 --> 00:40:04.089
In reality there is a piece of memory set
inside which is called the Window Backing Store;

00:40:04.090 --> 00:40:09.510
this is where all the drawings and all the
compositing is happening before the data is moved

00:40:09.510 --> 00:40:11.830
to the frame buffer during the refresh.

00:40:11.829 --> 00:40:23.250
And by nature that Window Backing Store is tagged with
the display profile for where my window is residing

00:40:23.250 --> 00:40:26.889
and there is a CG context attached to that.

00:40:26.889 --> 00:40:37.049
So when I have, let's say, a JPG image and I'm going
to do some compositing in that window and I draw

00:40:37.050 --> 00:40:45.990
that sRGB image using a specific API of CG context
I can, for example, fill my window with that.

00:40:45.989 --> 00:40:49.109
So this will be source coming in one color space.

00:40:49.110 --> 00:40:56.220
I may have some HDR, High Dynamic Range image
I also want to compose in the same window.

00:40:56.219 --> 00:41:01.059
What I'm doing I'm actually doing everything in my
Window Backing Store but this is reflected then later

00:41:01.059 --> 00:41:05.549
on my window residing on the -- sitting on my display.

00:41:05.550 --> 00:41:08.630
So, again, this color space can be completely different.

00:41:08.630 --> 00:41:15.369
What is happening every time I do the drawing I
do the matching from the source like in the case

00:41:15.369 --> 00:41:20.859
of the first image sRGB to my display profile,
second case, most likely some linear RGB

00:41:20.860 --> 00:41:26.160
to my Window Backing Store depending
what kind of color space I had in my HDR.

00:41:26.159 --> 00:41:32.109
And as an additional illustration I may
have some PNG with some tags gray color.

00:41:32.110 --> 00:41:37.849
It will, again, be converted to the Backing Store and
composited together and then during the refresh sent

00:41:37.849 --> 00:41:40.059
to the frame buffer and displayed on display.

00:41:40.059 --> 00:41:47.650
So the thing that we added as a new
feature in Snow Leopard is an ability

00:41:47.650 --> 00:41:54.570
to assign specific color space to my Backing Store.

00:41:54.570 --> 00:42:02.450
So now you may ask, well, what
happens if I chose that color space?

00:42:02.449 --> 00:42:11.710
Then in essence the color matching from Window Backing
Store to my Frame Buffer will be done automatically

00:42:11.710 --> 00:42:14.769
by the system by a component called Window Server.

00:42:14.769 --> 00:42:20.800
It will be all performed in GPU which means it
will be as fast as we can get it on this box.

00:42:20.800 --> 00:42:27.940
And what the application sees in terms of
drawing destination is that color space.

00:42:27.940 --> 00:42:36.820
By default that color space will remain display profile
but as I mentioned in specific cases it may be beneficial

00:42:36.820 --> 00:42:39.880
for in an application to set it to something different.

00:42:39.880 --> 00:42:44.640
Example, I have an application which
displays the images from the Web.

00:42:44.639 --> 00:42:53.069
As many of you may know the standard color space on
the Web is sRGB, so one model would be to keep it as is

00:42:53.070 --> 00:43:00.080
and draw every time my sRGB image and use CPU to
do the conversion from sRGB to Window Backing Store

00:43:00.079 --> 00:43:06.079
and then do nothing in that moment when I transfer
the data from my Backing Store to the frame buffer.

00:43:06.079 --> 00:43:14.309
But in that case, actually, I may say no isn't it better
if I tag or I assign sRGB to my Window Backing Store?

00:43:14.309 --> 00:43:22.960
What it means is I avoid completely the CPU and matching
being done when I rasterize my image into Backing Store

00:43:22.960 --> 00:43:30.289
and allow the Window Server to do the fastest possible
conversion from the Window Backing Store to my display.

00:43:33.269 --> 00:43:42.659
So just to mention other important implications that,
as I told you, the matching in case pf differences

00:43:42.659 --> 00:43:50.719
between the Window Backing Store, color space and
display will be performed by Window Server by using GPU.

00:43:50.719 --> 00:44:00.489
The typical thing that is maybe worth mentioning is that
my Backing Store depth matches whatever my display is.

00:44:00.489 --> 00:44:07.699
And important thing to mention is how Open
GL applications work in this environment.

00:44:07.699 --> 00:44:14.769
So this is actually very similar to Window Backing
Store because the Open GL application have to render

00:44:14.769 --> 00:44:19.070
to a specific surface and that surface
has the color space assigned to it.

00:44:19.070 --> 00:44:25.920
If that color space is different from my display same
thing happens automatically Window Server will use GPU

00:44:25.920 --> 00:44:30.349
to convert the data from that surface to the display.

00:44:30.349 --> 00:44:34.349
And color -- the OpenGL applications are different.

00:44:34.349 --> 00:44:39.170
OpenGL doesn't have any built-in automatic color
management so if you're writing an application

00:44:39.170 --> 00:44:44.099
like this you are responsible for
making the proper color management.

00:44:44.099 --> 00:44:50.529
Very typical, let's say there's a game you just pick the
color space of your window of your surface and you draw OS

00:44:50.530 --> 00:44:56.230
in this which means no color conversions required
on your side and then Window Server will pick it

00:44:56.230 --> 00:45:02.190
up from your surface and move to the proper
-- and convert to proper display color space.

00:45:02.190 --> 00:45:07.730
Also OpenGL applications can take advantage
of this Code Fragment API from ColorSync

00:45:07.730 --> 00:45:11.610
and perform its own color management in GPU.

00:45:12.710 --> 00:45:21.150
ColorSync has no API to set those color spaces, but I
mentioned that because it is really important to understand

00:45:21.150 --> 00:45:25.539
that in the whole color architecture in Snow Leopard.

00:45:25.539 --> 00:45:30.980
For those I refer you to, first of
all, AppKit APIs see their tech note

00:45:30.980 --> 00:45:41.769
and same thing Carbon will support
those Window Backing Store color space.

00:45:41.769 --> 00:45:46.989
So next thing I would like to talk
about is Display Change Notification.

00:45:46.989 --> 00:45:57.049
So as I describe to you how this process of rendering to
window works I can have my compositing done and displayed

00:45:57.050 --> 00:46:03.170
on one display but let's say I
did everything on my small laptop

00:46:03.170 --> 00:46:10.900
and I have a pretty big gray color
capability display hooked up to my laptop?

00:46:10.900 --> 00:46:13.900
So what I do I move my window.

00:46:13.900 --> 00:46:23.400
Well, something's wrong here right, if we do nothing because
I pre-matched, I matched the color to my first display.

00:46:23.400 --> 00:46:32.550
So what we did in Snow Leopard in the situations like
this Cocoa or AppKit, the highest level framework

00:46:32.550 --> 00:46:38.490
that you're linking with will request
from you to redraw completely the content.

00:46:38.489 --> 00:46:45.959
So now if your applications was just doing that listening
to the request, you know, the direct calls, whatever

00:46:45.960 --> 00:46:50.289
for window and doing just that everything is fine.

00:46:50.289 --> 00:46:57.579
But if you were for some reason caching information
about this first match and you are now being called

00:46:57.579 --> 00:47:02.500
to redraw one more time you better dispose
of those caches and start from scratch.

00:47:02.500 --> 00:47:08.510
If that would be the case you should listen or
register for notification about display change,

00:47:08.510 --> 00:47:13.320
and if it happens purge your caches
and start drawing from scratch.

00:47:13.320 --> 00:47:21.039
I gave you an example of moving, which is most typical
from moving my window from one display to another

00:47:21.039 --> 00:47:25.929
but the same thing happens if I go to the System
Preferences and I change my display profile.

00:47:25.929 --> 00:47:32.319
Now this thing is going to happen for you
automatically except your caches should be purged.

00:47:32.320 --> 00:47:39.400
Now we can step back and say, well, you know, I have options
right; didn't you tell me I can set my Window Backing Store

00:47:39.400 --> 00:47:41.570
to some color space different than display?

00:47:41.570 --> 00:47:48.710
Absolutely, if your Window Backing Store was set to
some arbitrary display profile which has nothing to do

00:47:48.710 --> 00:47:56.250
with my current display your action is really not --
hopefully even if you're caching you just have to redraw,

00:47:56.250 --> 00:48:03.739
right, so when you move the window from
one to another the automatic matching

00:48:03.739 --> 00:48:09.789
from your Window Backing Store will be applied
and image will be, hopefully, displayed correctly.

00:48:09.789 --> 00:48:16.279
That brings a little details and fine points that I
mentioned to you before that a choice on some color space

00:48:16.280 --> 00:48:19.650
in the middle may be detrimental,
maybe it's not always the best;

00:48:19.650 --> 00:48:25.860
this is something that higher-level application
developers should consider, what is better.

00:48:25.860 --> 00:48:30.690
Most cases the best way is to draw
directly from my source to destination.

00:48:30.690 --> 00:48:35.079
In certain cases maybe I want that
color space in the middle,

00:48:35.079 --> 00:48:40.099
but the main reason for that introducing
that is performance.

00:48:40.099 --> 00:48:47.769
Because also this Backing Store color space
allows us to handle gracefully the problem

00:48:47.769 --> 00:48:53.730
of windows traveling multiple displays; this is a
very simple example maybe not realistic but it's easy

00:48:53.730 --> 00:49:00.389
to envision the systems in which I'll have the whole
mosaic or, you know, a lattice of displays and I want

00:49:00.389 --> 00:49:06.400
to display one big image so when I have one
Backing Store profile which is well determined

00:49:06.400 --> 00:49:15.740
when I match individual parts of that image to
different displays I can do the "right thing".

00:49:15.739 --> 00:49:25.509
A very important thing for that Backing Store support is
for video because I can set my video to the color space

00:49:25.510 --> 00:49:34.300
of the content and allow GPU to do all color conversions
instead of my application or even the system trying

00:49:34.300 --> 00:49:38.600
to do the match on every single frame using CPU.

00:49:38.599 --> 00:49:44.920
So I think this gives me a perfect way to pass the
microphone to Ken who will be talking about video.

00:49:44.920 --> 00:49:46.010
Thank you very much.

00:49:46.010 --> 00:49:51.260
[ Applause ]

00:49:51.260 --> 00:49:52.460
>> Ken: Thank you Luke.

00:49:52.460 --> 00:49:58.510
So we're running just a little bit long so I'll
be moving fairly quickly through this material.

00:49:58.510 --> 00:50:06.390
This is some content that I've been meaning to communicate
to developers for some time now and we're not going to talk

00:50:06.389 --> 00:50:11.619
about APIs, rather, we're going to talk about what's
happening inside the box behind your applications.

00:50:11.619 --> 00:50:14.989
So this will give you the ability
to evaluate what it is you see

00:50:14.989 --> 00:50:18.699
and why you see what you see and
why, hopefully, it's a good thing.

00:50:18.699 --> 00:50:22.489
So these are the topics we're going to talk about.

00:50:22.489 --> 00:50:28.099
The first two; Interpreting Video From a
Computer's Perspective as well as What Does it Mean

00:50:28.099 --> 00:50:32.789
to Color Manage Video are kind of motivational topics.

00:50:32.789 --> 00:50:37.789
Probably what you're here for is what's new
in QuickTime X in terms of color management.

00:50:37.789 --> 00:50:42.920
We're also going to, very quickly, talk about what
the implications of what Luke just introduced in terms

00:50:42.920 --> 00:50:48.260
of the new display gamma are to your
applications and then we're going to quickly go

00:50:48.260 --> 00:50:55.820
into some more advanced material regarding how to evaluate
the video that your application's actually producing.

00:50:55.820 --> 00:51:01.930
So one thing we have to remember is that
video's a pretty old technology already.

00:51:01.929 --> 00:51:11.079
In terms of electronic television that's really a
product of the 1930s, colors actually from the 1950s,

00:51:11.079 --> 00:51:14.630
and some really brilliant people created these technologies.

00:51:14.630 --> 00:51:19.180
We have to understand that these
technologies actually represent solutions

00:51:19.179 --> 00:51:23.389
from the 1950s era and you're talking tubes.

00:51:23.389 --> 00:51:32.170
A lot of the things that are baked into the standards that
we now know and maybe love in video actually are based

00:51:32.170 --> 00:51:40.510
on the compromises that these engineers made quite a long
time ago, and we're going to talk about a few of these.

00:51:40.510 --> 00:51:44.140
So this is a pretty old video camera.

00:51:44.139 --> 00:51:50.659
You have to understand that technology
from these days was inherently noisy.

00:51:50.659 --> 00:51:58.769
So a potential solution from that era was just to slope
limit to blacks and that is actually what makes it

00:51:58.769 --> 00:52:04.480
into a rec.709 standard as what we know
as this piecewise transfer function.

00:52:04.480 --> 00:52:07.400
We'll talk more about that.

00:52:07.400 --> 00:52:14.849
Another aspect of video is how it was intended to be
viewed and it was viewed on pretty old CRTs in sort

00:52:14.849 --> 00:52:20.579
of 1950s era living rooms which were fairly dim affairs.

00:52:20.579 --> 00:52:26.420
So one thing that's important to remember is that
or maybe you're not familiar with the concept is

00:52:26.420 --> 00:52:31.400
that if you take an image that was produced
in bright sunlight and then you display it

00:52:31.400 --> 00:52:37.440
in a darker environment kind of like this 16 Lux environment
that the video standards assume that people are going

00:52:37.440 --> 00:52:47.990
to be watching video in, the net affect will be that the
image appears to be kind of flat and it needs a gamma boost

00:52:47.989 --> 00:52:53.719
which is another way of saying it needs a contrast
enhancement in order to look linear, in order for it to look

00:52:53.719 --> 00:52:55.939
like what the original image looked like.

00:52:55.940 --> 00:53:03.440
So consequently built into the standards and
built into the video equipment that we've enjoyed

00:53:03.440 --> 00:53:12.159
for all these years is something around a 1.25 gamma
boost which means that the cameras were producing a signal

00:53:12.159 --> 00:53:17.849
that the CRTs that people had in their homes
purposely didn't completely unmatch,

00:53:17.849 --> 00:53:20.969
so you're not getting a one to one relationship.

00:53:20.969 --> 00:53:27.799
This is also true if you're familiar with print
film technology or at least slide film projectors.

00:53:27.800 --> 00:53:34.260
So that if you took a picture in a bright sunlit
room and watched it in a dark environment maybe

00:53:34.260 --> 00:53:39.560
like this room projected you'd
actually need a 1.5 gamma boost.

00:53:39.559 --> 00:53:44.179
And in the case of film that's built into
the emulsion because there's no place else

00:53:44.179 --> 00:53:49.099
in that system to provide the difference.

00:53:49.099 --> 00:53:55.940
Also in the 1950's they added Pthis thing called
color to the pre-existing black and white TV signals.

00:53:55.940 --> 00:53:59.550
And, again, they were really clever
about how this information was added.

00:53:59.550 --> 00:54:05.420
It was added as a subcarrier to the luma signal
but for our purposes we're really interested

00:54:05.420 --> 00:54:10.480
in that chroma information is at a lower
bandwidth than the video information.

00:54:10.480 --> 00:54:15.250
Pretty much for each of the chroma channels
there's half the information there is

00:54:15.250 --> 00:54:18.690
in the luma channel and that's based on our perception.

00:54:18.690 --> 00:54:25.070
As many of you know our perception of the luminar
black and white is a lot higher frequency than it is

00:54:25.070 --> 00:54:30.300
of the chroma information, and that's a
very early example of lossy compression.

00:54:30.300 --> 00:54:39.610
So moving forward quite a bit to the 1980s we have what
some of you may be aware of is the rec.601 standard

00:54:39.610 --> 00:54:48.820
and that was pretty much interested in taking the analog
video lines and just chopping it into individual pixels.

00:54:48.820 --> 00:54:56.670
It also talks about the Y'CbCr color space where Y
represents luma, that's what I have as the gray boxes

00:54:56.670 --> 00:55:01.780
on the slide and Cb and Cr are the two chroma channels.

00:55:01.780 --> 00:55:09.330
And you can see here is a representation of the
4:2:2 chroma sub-sampling that for each line

00:55:09.329 --> 00:55:14.480
of luma information you have half
as much of chroma information.

00:55:14.480 --> 00:55:21.219
So there's something that the rec.601
standard didn't talk about.

00:55:21.219 --> 00:55:26.469
It didn't talk about the gamma of video, specifically.

00:55:26.469 --> 00:55:31.779
It also didn't talk about the chrominance or
the color representation of video specifically.

00:55:31.780 --> 00:55:34.200
And that's because it really wasn't necessary.

00:55:34.199 --> 00:55:42.500
So if we look at the example of a DVD player
taking these are my own set of color test bars.

00:55:42.500 --> 00:55:50.590
The actual DVD player takes the information that's written
on that DVD, happens to be an MPEG-2, it decodes that,

00:55:50.590 --> 00:55:55.820
it goes to a frame buffer that's in the
DVD player and then it gets sent directly

00:55:55.820 --> 00:55:58.970
out to your TV without any further processing.

00:55:58.969 --> 00:56:03.599
So the idea is that the DVD player
is not interpreting the video at all.

00:56:03.599 --> 00:56:10.029
Whatever is on the DVD it basically puts out to the TV.

00:56:10.030 --> 00:56:12.480
Now the Mac environment's actually different.

00:56:12.480 --> 00:56:17.929
Luke just spent all this time describing all
the wonderful mechanisms that we have on the Mac

00:56:17.929 --> 00:56:21.779
in terms of being a fully color managed system.

00:56:21.780 --> 00:56:25.630
And there are some subtleties here that
I think it's important to remember.

00:56:25.630 --> 00:56:33.800
One is that the display profile is actually is calibrated
and that calibration includes whatever the nature

00:56:33.800 --> 00:56:37.810
of the ambient environment is at the time of calibration.

00:56:37.809 --> 00:56:46.130
So that means that where the original video standards
included this gamma boost that boost isn't needed

00:56:46.130 --> 00:56:49.430
and it also isn't desired in the environment that we have

00:56:49.429 --> 00:56:55.449
because our color management system's providing
whatever is appropriate for the given environment

00:56:55.449 --> 00:56:59.109
and that's a very good thing, but
it makes our lives more complicated.

00:56:59.110 --> 00:57:05.260
And then the other thing to recall
is that the display buffer

00:57:05.260 --> 00:57:09.940
in the Mac isn't at whatever the nominal video gamma is.

00:57:09.940 --> 00:57:18.840
So we have to do some work to figure out what the
Native video gamma is so we can provide the conversion.

00:57:18.840 --> 00:57:23.809
In Snow Leopard we're providing the
conversion to the new 2.2 display buffer Gamma.

00:57:23.809 --> 00:57:35.279
Prior to Snow Leopard and Leopard
before we had a match to the 1.8 value.

00:57:35.280 --> 00:57:39.040
So that leaves us with a problem
of interpreting video standards.

00:57:39.039 --> 00:57:45.000
To try to figure out what the actual
gamma of video is in the standard.

00:57:45.000 --> 00:57:50.230
And a lot of people look for these standards and they
look for numbers and they don't see what they're finding

00:57:50.230 --> 00:57:52.809
but they find something else and they'll go use that.

00:57:52.809 --> 00:57:55.980
But there are ways that we can derive these values.

00:57:55.980 --> 00:58:01.420
You don't find this derivation in video standards
there are some more modern standards usually

00:58:01.420 --> 00:58:05.220
from the computer industry that do provide derivation,

00:58:05.219 --> 00:58:08.980
and they come up with numbers very
similar to the numbers that we use.

00:58:08.980 --> 00:58:14.630
We're using a value of approximately
1.96 as the gamma of video.

00:58:14.630 --> 00:58:18.869
So very quickly I'll walk through
two ways to derive that information.

00:58:18.869 --> 00:58:27.009
CRTs, if you measure them, have a gamma of somewhere
between 2.4 and 2.5, and you see these varying numbers

00:58:27.010 --> 00:58:32.360
because it really is dependent on how the
brightness and contrast is set on the monitor.

00:58:32.360 --> 00:58:42.620
So if we pick a value halfway in between maybe 2.45 and
you remove that 1.25 adaptation that we already talked

00:58:42.619 --> 00:58:47.269
about then you'll get a value very similar to that 1.96.

00:58:47.269 --> 00:58:53.880
As you may know a gamma function is an exponential
function and you don't subtract the exponents,

00:58:53.880 --> 00:59:02.570
rather you divide so if you take 2.45 divided by
1.25 you get a value very similar to our 1.96 value.

00:59:02.570 --> 00:59:09.250
Also, if you look to the rec.709 standard and you
see this piecewise gamma function and if you go back

00:59:09.250 --> 00:59:16.940
to your calculus we can actually solve for the
area under that curve and that sort of area

00:59:16.940 --> 00:59:21.679
under the curve is proportional to what we call
tonality which is a real fancy way of talking

00:59:21.679 --> 00:59:25.029
about the brightness or contrast that curve represents.

00:59:25.030 --> 00:59:29.740
So if you solve for a pure power
function that has an area similar to that

00:59:29.739 --> 00:59:36.639
of what's underneath the piecewise function you'll
also get a value very close to this 1.96 value.

00:59:38.710 --> 00:59:41.570
So why color manage video?

00:59:41.570 --> 00:59:51.120
It's basically the same motivation as Luke
mentioned for 2D and this is really important.

00:59:51.119 --> 01:00:01.519
What we want to do is to produce the intention of the author
of the video content with as high a fidelity as possible.

01:00:01.519 --> 01:00:11.420
So that means when the producer, the director, the
cinematographer and the post-production people sit

01:00:11.420 --> 01:00:20.110
down behind their broadcast monitor and they say it's a
wrap, we like this we want to make sure that we provide

01:00:20.110 --> 01:00:27.650
that same video response, that same look on
across all the different displays that we produce.

01:00:27.650 --> 01:00:31.200
And what may not be obvious is that the different displays

01:00:31.199 --> 01:00:34.179
that you may have available to
you are actually very different.

01:00:34.179 --> 01:00:40.829
So LCDs that are in portable laptop
computers tend to be optimized for brightness

01:00:40.829 --> 01:00:43.940
and they sacrifice some saturation for that.

01:00:43.940 --> 01:00:50.889
A cinema display, on the other hand,
provides very wide gamut high saturation but,

01:00:50.889 --> 01:00:53.460
of course, it takes more power to use.

01:00:53.460 --> 01:00:57.949
So it's also important if you're authoring content.

01:00:57.949 --> 01:01:04.139
So if you're authoring our editing video you
want your application to be color managed

01:01:04.139 --> 01:01:10.879
and that way you get the same affect no matter
which display or workstation you happen to be using.

01:01:10.880 --> 01:01:16.740
So, perhaps, in your editing suite you have an
actual broadcast video monitor but we want to provide

01:01:16.739 --> 01:01:24.489
as close fidelity to that experience as possible
even if you're using your LCD and your laptop.

01:01:24.489 --> 01:01:34.689
So similar to the 2D color management we also tagged the
color intention via tags except we use a different tag.

01:01:34.690 --> 01:01:41.590
We use a tag called 'nclc' instead of an ICC Profile.

01:01:41.590 --> 01:01:47.500
So very quickly an 'nclc' is just shorthand
for describing video color imagery.

01:01:47.500 --> 01:01:55.750
These are some common examples of 'nclc's you see in the
table; this 'nclc' information can be tagged and included

01:01:55.750 --> 01:01:59.679
in a lot of places QuickTime Movies MPEG4.MP4 files.

01:01:59.679 --> 01:02:06.059
It can also be made into MPEG4 streams and other places.

01:02:06.059 --> 01:02:18.429
So the 'nclc' has three components and those aren't the
actual values rather they're indices into tables of values.

01:02:18.429 --> 01:02:26.029
So the first parameter are the primaries in
Luke did a very nice job at describing these.

01:02:27.309 --> 01:02:36.940
You can see the most common values we have correspond to
the rec.709, the SD PAL, the SD SMPTE-C color imageries.

01:02:38.090 --> 01:02:41.100
So the second parameter is the Transfer Function.

01:02:41.099 --> 01:02:45.360
It's kind of commonly called gamma.

01:02:45.360 --> 01:02:51.289
And usually we use just this one value the rec.709.

01:02:51.289 --> 01:02:56.009
The third and final parameter for the 'nclc' is the matrix

01:02:56.010 --> 01:03:03.170
and this is the 3x3 matrix that's used
to convert between Y'CbCr and RGB.

01:03:03.170 --> 01:03:10.490
And the part that's not obvious to a lot of people is that
you use a different matrix depending on the color imagery,

01:03:10.489 --> 01:03:15.869
and this is really critical while if you use
the wrong matrix it appears to largely work.

01:03:15.869 --> 01:03:22.009
The colors won't come out correctly and that's
especially noticeable if you look at SMPTE Color Bars.

01:03:22.010 --> 01:03:26.540
[ Background noise ]

01:03:26.539 --> 01:03:29.690
>> Ken: So, finally, what's new?

01:03:29.690 --> 01:03:38.360
So we have a GPU Accelerated Pipeline in QuickTime
X and it's providing not only the color management

01:03:38.360 --> 01:03:51.050
but it's also now providing a Chroma Siting-based Upsampling
from the Y'CbCr's chroma subsample space to RGB's 4:4:4.

01:03:51.050 --> 01:03:53.789
I'll go into details on that in a moment.

01:03:53.789 --> 01:04:01.079
We also provide colorimetrically
correct Export, Capture, Screen Capture.

01:04:01.079 --> 01:04:06.059
We're always color managing content
and that's a change from the past.

01:04:06.059 --> 01:04:07.750
We'll talk about that as well.

01:04:07.750 --> 01:04:13.079
We have an Automator action that
allows you to provide your own tagging.

01:04:13.079 --> 01:04:17.699
And additionally and, I think, most excitingly
we're providing consistent color management

01:04:17.699 --> 01:04:19.009
of video across the platform.

01:04:19.010 --> 01:04:24.580
[ Background noise ]

01:04:24.579 --> 01:04:33.969
>> Ken: So very quickly the steps that we go through
for upsampling Y'CbCr to 4:4:4 are basically controlled

01:04:33.969 --> 01:04:37.599
by this new tag it's the Chroma Tag or CHRM.

01:04:37.599 --> 01:04:43.119
And it also, the 'nclc' supplies which matrix to apply.

01:04:43.119 --> 01:04:50.420
So here are the luma values represented in gray.

01:04:51.429 --> 01:04:58.759
These orange boxes or pixels correspond
to the Cb and Cr chroma values.

01:04:58.760 --> 01:05:08.440
And you can see that the orange values are aligned
with the left most array of or column I should say

01:05:08.440 --> 01:05:13.829
of the luma pixels, so we consider this to be left-siting.

01:05:13.829 --> 01:05:19.799
By applying a GPU-based filter we
actually perform the conversion into RGB

01:05:19.800 --> 01:05:27.130
as well providing a filter-based
correct up-sampling to RGB 4:4:4.

01:05:27.130 --> 01:05:30.130
Now if we slide over the orange values somewhere halfway

01:05:30.130 --> 01:05:37.680
in between the two adjacent luma values then you
get another siting; this is called center siting,

01:05:37.679 --> 01:05:44.659
and we also correctly handle this
case as specified in the chroma tag.

01:05:44.659 --> 01:05:51.769
So one of the new features is that we make
sure that when we export that it's done

01:05:51.769 --> 01:05:55.320
in terms of ColorSync and it's done correctly.

01:05:55.320 --> 01:06:01.019
So primarily that means two things if there's a color
space conversion that's necessary not only do we use the

01:06:01.019 --> 01:06:06.079
appropriate matrix but now we also provide a ColorSync.

01:06:06.079 --> 01:06:12.150
And, two, we make sure that the video that we produce
is properly tagged so it can be processed correctly.

01:06:12.150 --> 01:06:19.539
In the case with Apple TV, Apple TV is a modern and color
managed platform like the Macintosh so if you started

01:06:19.539 --> 01:06:28.690
with rec.709 HD content you can leave it in that
content and Apple TV will preserve it correctly

01:06:28.690 --> 01:06:31.550
and it will provide the proper color management.

01:06:31.550 --> 01:06:37.260
When you export to an iPod or an iPhone those
things actually have SD output from them,

01:06:37.260 --> 01:06:43.570
so we perform a conversion from HD to SD and that
goes through a new step where we actually make sure

01:06:43.570 --> 01:06:49.059
that the color values are adjusted so they appear correct.

01:06:50.429 --> 01:06:58.889
The new QuickTime X QTKit Capture mechanisms now inquire
from the camera what the color space is and make sure

01:06:58.889 --> 01:07:08.509
that that 'nclc' information is piped all the way through
the pipeline so that previews are ColorSynced properly,

01:07:08.510 --> 01:07:15.280
any color conversions are performed
properly and the end result is also tagged.

01:07:16.639 --> 01:07:26.289
Also new QTKit Capture can capture from the display and
what that does if you think about it the display buffer

01:07:26.289 --> 01:07:34.130
of the computer isn't in a video color space at all it's
actually in an ICC profile that corresponds to the display.

01:07:34.130 --> 01:07:42.420
So before information, RGB information from the display
can be managed by the encoding pipeline you have

01:07:42.420 --> 01:07:50.170
to perform a conversion from that RGB
device space into an RGB video space.

01:07:50.170 --> 01:07:53.380
In our case we used RGB rec.709.

01:07:53.380 --> 01:08:00.579
So the end result is that the captured movie when played
back will have a very good fidelity with the original

01:08:00.579 --> 01:08:04.690
that you may have seen on the display and
it'll be true video so that you can take that

01:08:04.690 --> 01:08:08.409
and put it on a DVD or use it on another source.

01:08:08.409 --> 01:08:15.099
Otherwise if you naively captured RGB data, ran it through
the video pipeline and played it back again you would notice

01:08:15.099 --> 01:08:24.329
that the colors aren't quite right and, perhaps, even more
importantly the gamma would be off, it would be shifted.

01:08:24.329 --> 01:08:28.390
So QuickTime X now color manages all content.

01:08:28.390 --> 01:08:30.980
That's a change from past behaviors.

01:08:30.979 --> 01:08:37.609
We like it because it's consistent there's no guessing
nothing based on the size or any other information.

01:08:37.609 --> 01:08:47.309
We've chosen to use the classic SD color
imagery, which is as good of a guess as any.

01:08:47.310 --> 01:08:54.710
And you get this behavior with all modern
content which is H.264 and other fordmats.

01:08:54.710 --> 01:09:03.970
One thing that's important to know is that the QuickTime
X Player will fall back to the QuickTime 7 Pipeline

01:09:03.970 --> 01:09:09.960
and the QuickTime 7 behaviors with
legacy content and also legacy modes.

01:09:09.960 --> 01:09:14.119
QuickTime 7 Player always uses the QuickTime 7 Pipeline.

01:09:14.119 --> 01:09:21.279
So there's a new tagging tool it's an Automator
action and it allows you to tag all of your content

01:09:21.279 --> 01:09:24.389
and it's pretty easy to set up a workflow using Automator.

01:09:24.390 --> 01:09:29.510
That's especially important for old content
that's untagged, maybe content that's coming

01:09:29.510 --> 01:09:35.810
from an external source and anything
that's incorrectly tagged.

01:09:35.810 --> 01:09:41.630
So I'm very excited that we're providing consistent color
management which means we're using the same color math

01:09:41.630 --> 01:09:45.010
across all the applications on the platform.

01:09:45.010 --> 01:09:48.640
[ Background noise ]

01:09:48.640 --> 01:09:54.400
>> Ken: So Luke quickly mentioned
the new 2.2 gamma on Snow Leopard

01:09:54.399 --> 01:09:58.989
and you may be wondering what does
that mean to video on the platform.

01:09:58.989 --> 01:10:03.199
So the good news is that chances are
there's absolutely no impact to you.

01:10:03.199 --> 01:10:11.769
So the QuickTime Visual Context as well as QTKit those
applications have always been color managed and because

01:10:11.770 --> 01:10:15.220
of that they'll continue to be
color managed on Snow Leopard.

01:10:15.220 --> 01:10:19.400
You may get different values if, for
instance, where previously on Leopard

01:10:19.399 --> 01:10:26.879
and the default 1.8 display profile the 75%
Gray Bar is represented with 186 values.

01:10:26.880 --> 01:10:33.010
Now on Snow Leopard it'll be represented on 198 levels,
but the good news is those appear to be identical.

01:10:33.010 --> 01:10:37.550
[ Background noise ]

01:10:37.550 --> 01:10:44.880
>> Ken: Also if you're using an old, and you shouldn't if
anymore, be using an old application with an old framework

01:10:44.880 --> 01:10:50.680
like the Classic QuickTime Carbon G
Rule framework, there's also no change.

01:10:50.680 --> 01:10:57.310
Those frameworks were never color managed
they would process 74% grade value

01:10:57.310 --> 01:11:02.810
and produce 179 levels, they still do on Snow Leopard.

01:11:02.810 --> 01:11:09.460
And it may not be obvious on the slide
but they'll be a subtle change in luma.

01:11:09.460 --> 01:11:13.369
Basically on Snow Leopard 2.2 the end
results will be a little bit dimmer,

01:11:13.369 --> 01:11:17.659
and that's exactly the same behavior
as any old Carbon application.

01:11:17.659 --> 01:11:23.279
They look a little bit darker on
Snow Leopard's 2.2 display buffer.

01:11:23.279 --> 01:11:30.519
So this next section is fairly advanced and I'm
going to go through it very quickly as well.

01:11:30.520 --> 01:11:38.220
So very important things to remember is that
your pixels are changed by Color Management.

01:11:38.220 --> 01:11:43.949
That means if your application is trying to render
one value out Color Management's going to change it,

01:11:43.949 --> 01:11:49.800
and if you read the resulting pixel values back maybe using
Digital Color Meter you're going to get a different value.

01:11:49.800 --> 01:11:55.329
And that's a good thing that's the Value Add that
we're providing, but you should remember that.

01:11:55.329 --> 01:12:00.720
Also, as I mentioned earlier, that different
displays have different display profiles

01:12:00.720 --> 01:12:02.289
that means you're going to get different results.

01:12:02.289 --> 01:12:07.729
And what may not be obvious is that even
between two seemingly identical displays

01:12:07.729 --> 01:12:18.309
like two cinema displays those may have different display
profiles and they may produce different color results.

01:12:18.310 --> 01:12:21.780
So if you slide your video between the two displays

01:12:21.779 --> 01:12:29.479
and read the values back you may get different
values, and, again, that's a good thing.

01:12:29.479 --> 01:12:34.679
So these are some things you should remember if
you want to evaluate color on your own application.

01:12:34.680 --> 01:12:39.789
One, SMPTE Color Bars is the standard way to
accomplish this and it's a very good thing

01:12:39.789 --> 01:12:42.869
to do, but remember garbage in, garbage out.

01:12:42.869 --> 01:12:46.349
Those SMPTE Color Bars have to be tagged themselves.

01:12:46.350 --> 01:12:59.150
So 75% Bars in an 8-bit space they have that 191 energy
level, 191 happens to be 75% of 255 isu where that comes in.

01:12:59.149 --> 01:13:07.119
So ColorSync, in our case, won't change the gray
value if you have a perfect gray, which means the red,

01:13:07.119 --> 01:13:13.399
green and blue components all have the same
values they still will after being color managed

01:13:13.399 --> 01:13:23.089
but they may have different levels because the gamma
shift or the gamma adaptation will make them different.

01:13:23.090 --> 01:13:30.380
Pixel values that aren't gray like
the 75% green 0, 191, 0 may change.

01:13:30.380 --> 01:13:34.190
Luke went through a detailed description of this.

01:13:34.189 --> 01:13:39.239
So here's some values that we may
see if you read your 75% bars back.

01:13:39.239 --> 01:13:51.559
On Snow Leopard your 191 value will be processed by
a 1.96 to 2.2 gamma conversion producing 198 levels.

01:13:51.560 --> 01:13:56.260
That's the default QuickTime X behavior on Snow Leopard.

01:13:56.260 --> 01:14:05.820
QuickTime 7 on Leopard and earlier provided a 1.96 to 1.8
value of color correction that produces these 186 values.

01:14:05.819 --> 01:14:08.920
You may also have seen these 179 values.styyl

01:14:08.920 --> 01:14:15.380
They're the result of a very early QuickTime behavior
and that's the same behavior that's used in File Cut

01:14:15.380 --> 01:14:18.840
as well as QuickTime 7 on untagged content.

01:14:18.840 --> 01:14:22.529
It's the result of a 2.2 to 1.8 conversion.

01:14:22.529 --> 01:14:30.429
If you see 191s that means there was no processing done or
for whatever reason it tried to do a 2.2 to 2.2 conversion.

01:14:30.430 --> 01:14:32.360
You shouldn't see those values.

01:14:32.359 --> 01:14:42.479
So these are the concepts that I really want you to
really remember and take away with you and that is

01:14:42.479 --> 01:14:46.629
that it's really critical that all
content is tagged with an 'nclc'.

01:14:46.630 --> 01:14:53.739
You can use a new tagging Automator
action to perform that operation.

01:14:53.739 --> 01:15:00.579
And if you have applications or if you have components
in codecs that produce video please make sure

01:15:00.579 --> 01:15:06.449
that you provide the 'nclc' information
in the files that you write.

01:15:06.449 --> 01:15:10.649
Untagged content is color managed in the QuickTime X world.

01:15:10.649 --> 01:15:13.889
It's treated as SD.

01:15:13.890 --> 01:15:22.300
And lastly videos processed consistently across the
platform and this is true for all modern applications.

01:15:22.300 --> 01:15:27.710
So if you want more information
you can contact Allan Schaffer.