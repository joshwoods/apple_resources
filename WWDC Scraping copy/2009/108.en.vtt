WEBVTT

00:00:12.740 --> 00:00:17.920
>> Good morning and welcome to this
session Concurrent Programming in Cocoa.

00:00:17.920 --> 00:00:22.520
My name is Chris Kane and I'm an
Engineer on the Cocoa Frameworks team.

00:00:22.519 --> 00:00:28.210
So what we're going to be talking
about today is first of all NSOperation

00:00:28.210 --> 00:00:35.280
and NSOperationQueue we'll review what we had in
Leopard and talk about some new stuff in Snow Leopard.

00:00:35.280 --> 00:00:43.980
Then I'll be talking about some new Collection APIs and
NotificationCenter APIs which have to do with concurrency;

00:00:43.979 --> 00:00:52.849
and then we'll move on up to the AppKit and talk about
Concurrent Document Opening and Concurrent Drawing.

00:00:52.850 --> 00:00:58.590
Now, except for NSOperationQueue and
NSOperation which exist in Leopard,

00:00:58.590 --> 00:01:06.150
most of what I'm going to be talking
about today is Snow Leopard specific.

00:01:06.150 --> 00:01:12.690
It's not available in Leopard and
it's not available in iPhone OS.

00:01:14.489 --> 00:01:23.079
So let me begin by talking a bit
about Operations and Queues.

00:01:23.079 --> 00:01:30.269
When I talk about Operations and Queues I'm talking
about a particular kind of concurrent programming model

00:01:30.269 --> 00:01:41.949
where you have work to do or small jobs or independent
bits of work that need to be done; and you feed those bits

00:01:41.950 --> 00:01:50.689
of work in some way to some kind of execution engine which
executes them on your behalf in the background usually.

00:01:50.689 --> 00:01:57.299
In the case of NSOperation and
NSOperationQueue, we introduce these in Leopard

00:01:57.299 --> 00:02:06.649
and they have become really fundamental to the
concurrency story within Cocoa in just a short time.

00:02:06.650 --> 00:02:16.040
In fact already in Snow Leopard, we've seen NSOperation and
NSOperationQueue, and Operations and Queues in general begin

00:02:16.039 --> 00:02:24.250
to replace threads as a principle concurrency
mechanism within the operating system.

00:02:24.250 --> 00:02:29.960
Operations and Queues as a concurrent
programming model is so significant

00:02:29.960 --> 00:02:40.659
that in Snow Leopard we've introduced these two
concepts down at basically the lowest API level,

00:02:40.659 --> 00:02:44.699
the C API level within the operating system.

00:02:44.699 --> 00:02:56.419
First, we've introduced Blocks; we've modified the
compilers for the C, C++ and Objective-C languages

00:02:56.419 --> 00:03:04.969
to accept a new kind of syntax which we call Blocks;
and blocks are essentially analogous within the context

00:03:04.969 --> 00:03:11.199
of concurrency; they're analogous to operations.

00:03:11.199 --> 00:03:19.609
Blocks allow you to define bits of work very
conveniently and locally at the place you need it done,

00:03:19.610 --> 00:03:29.900
and so operations now have an analog
at the programming language level.

00:03:29.900 --> 00:03:35.480
For queues we've introduced Grand
Central Dispatch, also called GCD

00:03:35.479 --> 00:03:39.939
and I'll be referring to it as GCD in this talk often.

00:03:39.939 --> 00:03:52.800
Grand Central Dispatch introduces queues with a CAPI
down at the lowest level of the operating system APIs.

00:03:52.800 --> 00:04:05.030
To align all of the various queue and operation
implementations, NSOperationQueue and NSOperation

00:04:05.030 --> 00:04:09.990
as well have been re-implemented
in terms of Grand Central Dispatch.

00:04:09.990 --> 00:04:22.850
So GCD is now essentially the central execution engine
for all operation and queue APIs within Snow Leopard.

00:04:22.850 --> 00:04:30.730
One side benefit that I'll mention at this point of that
has been a good performance boost and I'll be talking

00:04:30.730 --> 00:04:41.750
about that more later, but also because NSOperationQueue has
been re-implemented on top of GCD, we've also adopted a lot

00:04:41.750 --> 00:04:53.420
of the-- well I hate to call paradigm, but programming
models that GCD uses, for example serial queues

00:04:53.420 --> 00:05:01.310
as a replacement for locking, and that itself
has also given us a good performance boost.

00:05:03.399 --> 00:05:12.929
So let's review where we stood when Leopard
shipped about a little over 1-1/2 years ago.

00:05:12.930 --> 00:05:19.720
So first we had NSOperation, and
NSOperation is an object which encapsulates

00:05:19.720 --> 00:05:26.440
and represents work to be done or a job if you will.

00:05:26.439 --> 00:05:35.029
Often an NSOperation will also encapsulate some
data necessary for that work to do its thing.

00:05:35.029 --> 00:05:40.549
NSOperation as an abstract class
also encapsulates various properties

00:05:40.550 --> 00:05:46.420
that are then common across all types of Operation objects.

00:05:46.420 --> 00:05:52.100
An operation can tell you whether it's
currently executing or whether it is finished;

00:05:52.100 --> 00:06:01.910
operations have an advisory Cancellation state and
behavior; when you put an operation into an OperationQueue,

00:06:01.910 --> 00:06:08.300
the operation can specify what priority
it should have within that OperationQueue;

00:06:08.300 --> 00:06:13.449
and operations also have a dependency
mechanism whereby you can set up a situation

00:06:13.449 --> 00:06:20.990
where one operation will not run
until another operation has finished.

00:06:20.990 --> 00:06:29.710
To define an operation or to make use of an operation,
you can use either of the two subclasses that we've built

00:06:29.709 --> 00:06:35.709
in for you-- NSBlockOperation which is new in
Snow Leopard and I'll be talking about that

00:06:35.709 --> 00:06:39.759
in a short while; or NSInvocationOperation.

00:06:39.759 --> 00:06:49.909
If you need to though, you can subclass NSOperation
yourself and unless you have fairly complex needs,

00:06:49.910 --> 00:06:59.240
you simply override the method called main and put all the
code you want executed as part of that operation into main.

00:06:59.240 --> 00:07:05.210
It's fairly straightforward for most kinds of NSOperations.

00:07:05.209 --> 00:07:15.639
To get an NSOperation then to be run, well you
can if you want to execute operations directly,

00:07:15.639 --> 00:07:24.719
but normally you would then give the operation to an
NSOperationQueue and the NSOperationQueue will be the engine

00:07:24.720 --> 00:07:31.510
that will cause your operation to be
run at some point in the background.

00:07:31.509 --> 00:07:35.639
So we have NSOperations.

00:07:35.639 --> 00:07:40.659
They are the mechanism for concurrently
executing the operations.

00:07:40.660 --> 00:07:49.470
Normally an operation queue is executing operations
concurrently; that is, as you feed in the operations

00:07:49.470 --> 00:07:55.470
and there is execution capacity on
the machine, the operations are run.

00:07:55.470 --> 00:08:02.930
But you can also set up an operation queue
to only execute one operation at a time.

00:08:02.930 --> 00:08:11.790
And this has various uses itself which I won't be going
into within this talk, but you may have seen references

00:08:11.790 --> 00:08:15.600
to that last year in Ali Ozer's talk.

00:08:15.600 --> 00:08:24.740
And for the queues that you can create within Grand
Central Dispatch those are also serial queues.

00:08:24.740 --> 00:08:30.189
Once you have an NSOperationQueue you can do various
things to it of course you can add operations;

00:08:30.189 --> 00:08:35.700
it wouldn't be much of a queue if you couldn't; you
can get the list of operations out of the queue;

00:08:35.700 --> 00:08:40.890
you can adjust the width of the queue and this
is what I was referring to just a moment ago.

00:08:40.889 --> 00:08:48.720
You can specify how many operations you want
the operation queue to run at any one time.

00:08:48.720 --> 00:08:58.460
If you need to you can suspend a queue and, for example, if
you don't want the queue to run things for a little while,

00:08:58.460 --> 00:09:04.700
and later resume it; and finally, if you
have to you can wait for all the operations

00:09:04.700 --> 00:09:08.540
that have been put into an operation queue to finish.

00:09:08.539 --> 00:09:15.139
So I'm going to illustrate this; I'm going to illustrate
adding operations; suspending and resuming a queue

00:09:15.139 --> 00:09:18.000
and waiting for all the operations to finish.

00:09:18.000 --> 00:09:23.470
So over on the right there you see that I have three Cores.

00:09:23.470 --> 00:09:30.610
For simplicity I'm just going to show three Cores
and the operations that end up in those Cores

00:09:30.610 --> 00:09:35.590
and I have an operation queue that operations may appear in.

00:09:35.590 --> 00:09:37.440
Let's see what happens.

00:09:37.440 --> 00:09:46.390
So first of all, I'm going to suspend the operation
queue-- that's what this little stop sign means here.

00:09:46.389 --> 00:09:52.669
So now if any operations happen to be put in
the queue, they're just going to sit there.

00:09:52.669 --> 00:09:59.649
You see the operations are not being executed because the
operation queue is suspended; that's fairly straightforward.

00:09:59.649 --> 00:10:08.329
What we'll see then is that if I unsuspend the queue
the operations will begin to be pushed, if you will,

00:10:08.330 --> 00:10:13.250
onto the different Cores and they'll be executed.

00:10:13.250 --> 00:10:19.120
Notice that the operations wait in the queue
until one of the Cores becomes available

00:10:19.120 --> 00:10:21.679
and then they can be pushed onto that Core.

00:10:21.679 --> 00:10:30.339
And now of course we're all waiting for the OperationQueue
to get empty for all the operations to finish;

00:10:30.340 --> 00:10:34.700
so the talk is basically blocked
until this animation is done.

00:10:36.159 --> 00:10:38.639
Now watch this.

00:10:38.639 --> 00:10:41.340
Notice there's a little flash of light here.

00:10:42.389 --> 00:10:47.480
I'm not promising that there's a little flash
of light when all your operations finish.

00:10:47.480 --> 00:10:50.789
Do not take this illustration too literally.

00:10:53.360 --> 00:10:59.090
What have we done to NSOperationQueue in 10.6?

00:10:59.090 --> 00:11:03.389
Well, we've added some new API as we often do.

00:11:03.389 --> 00:11:08.419
Two of the most important ones
are a waitUntilFinished method.

00:11:08.419 --> 00:11:13.329
The waitUntilFinished method allows
you to block if you need to,

00:11:13.330 --> 00:11:17.350
waiting for an individual, a single operation, to finish.

00:11:17.350 --> 00:11:26.879
This is often convenient to be able to do
this so we added that convenience in for you.

00:11:26.879 --> 00:11:31.269
And we've added a completionBlock property to NSOperation.

00:11:31.269 --> 00:11:37.439
The completionBlock property allows
you to assign a block to any operation

00:11:37.440 --> 00:11:42.640
which will be executed when the operation finishes.

00:11:42.639 --> 00:11:49.559
Now I want to point out two important things
about this while I'm talking about it.

00:11:49.559 --> 00:11:55.139
The completion block is not run in
any particular execution context.

00:11:55.139 --> 00:12:01.480
If you, for example, put the operation
onto an operation queue and run it,

00:12:01.480 --> 00:12:09.800
the completion block is not necessarily run in
the same execution context as the operation queue.

00:12:09.799 --> 00:12:18.649
The other is that the execution of the
completion block is concurrent with execution

00:12:18.649 --> 00:12:22.250
of any dependencies that the operation may have.

00:12:22.250 --> 00:12:28.139
So when an operation finishes, any dependencies
that were waiting for it to finish of course,

00:12:28.139 --> 00:12:34.129
might become ready to run and they
might begin running at that point.

00:12:34.129 --> 00:12:42.779
Well the completion block is running at the
same time as those dependencies are starting up.

00:12:42.779 --> 00:12:50.829
As I mentioned earlier, we've added a new
subclass of NSOperation called NSBlockOperation.

00:12:50.830 --> 00:12:56.520
And the NSBlockOperation holds one or
more blocks that you've given to it.

00:12:56.519 --> 00:13:01.549
These blocks are the work of the operation.

00:13:01.549 --> 00:13:08.079
So basically what an NSBlockOperation does
is run the blocks that you've given it;

00:13:08.080 --> 00:13:12.870
and when those blocks are done the
operation's finished-- fairly straightforward.

00:13:12.870 --> 00:13:17.990
If you give multiple blocks to NSBlockOperation,

00:13:17.990 --> 00:13:22.490
those blocks are executed concurrently
with respect to one another.

00:13:22.490 --> 00:13:27.210
And the NSBlockOperation becomes
finished when they have all finished.

00:13:27.210 --> 00:13:37.370
The blocks that you give an NSBlockOperation
have no parameters and return no result.

00:13:37.370 --> 00:13:45.759
So if you need parameters, need the blocks to
be parameterized in some way, then those values,

00:13:45.759 --> 00:13:51.620
that information, needs to be captured
when the block is created and possibly

00:13:51.620 --> 00:13:55.879
when it's assigned to the NSBlockOperation.

00:13:55.879 --> 00:13:58.820
What is a block with a type look like?

00:13:58.820 --> 00:14:06.930
Well here, I'm going to illustrate very briefly the
block syntax just in case you aren't familiar with it

00:14:06.929 --> 00:14:11.509
or in case you didn't see it discussed
yesterday in the What's New in Cocoa talk.

00:14:11.509 --> 00:14:16.639
On the left we have the return value.

00:14:16.639 --> 00:14:24.509
These blocks have no return value so we have void there;
and then we have the caret in the middle which indicates

00:14:24.509 --> 00:14:31.659
that this is a block type; and then on the
right side we have the parameter list just

00:14:31.659 --> 00:14:33.909
like an ordinary function declaration.

00:14:33.909 --> 00:14:40.139
And there are no parameters accepted by
these blocks and so we have a void there.

00:14:40.139 --> 00:14:46.569
Now I don't have time unfortunately to
go into greater depth on what blocks are.

00:14:46.570 --> 00:14:51.120
We'll see a couple of examples later in
the talk, but if you want to know more

00:14:51.120 --> 00:14:58.539
about blocks I'll give you a brief pointer now to the
Objective-C and Garbage Collection Advancements talk

00:14:58.539 --> 00:15:07.029
at 5:00PM later today and I'll have this again
at the end of the talk in case you missed it now.

00:15:07.029 --> 00:15:09.639
What have we done to NSOperationQueue?

00:15:09.639 --> 00:15:17.090
Well, again we've added some new API; we've added
a convenience method called addOperationWithBlock

00:15:17.090 --> 00:15:21.340
that allows you simply to give
a block to an operation queue,

00:15:21.340 --> 00:15:27.700
and what the operation queue will do then is
create a block for you and add it to itself.

00:15:27.700 --> 00:15:32.879
There's another method called
addOperations:waitUntilFinished.

00:15:32.879 --> 00:15:42.490
This allows you to provide an NSArray of operations to an
OperationQueue all at once; and optionally wait until all

00:15:42.490 --> 00:15:48.690
of those particular operations that
you just gave it have finished.

00:15:48.690 --> 00:15:55.140
Finally, we've added an operationCount
property to NSOperationQueue.

00:15:55.139 --> 00:15:59.679
We found that a lot of people were
getting the entire list of operations

00:15:59.679 --> 00:16:04.120
out of a queue which is a fairly expensive operation.

00:16:04.120 --> 00:16:12.100
Just to ask the result array for its count and then
throwing the array away; so this is a much cheaper way

00:16:12.100 --> 00:16:15.610
of getting the count of operations currently in the queue.

00:16:15.610 --> 00:16:22.399
But of course just to remind you as with all things
concurrent, by the time you've gotten the operation count,

00:16:22.399 --> 00:16:26.829
of course it may have changed because
some other threads may have put operations

00:16:26.830 --> 00:16:29.530
in that queue or operations may have finished.

00:16:29.529 --> 00:16:35.230
So operationCount is of course always an approximation.

00:16:35.230 --> 00:16:46.170
So as I mentioned earlier NSOperation, NSOperationQueue
have been re-implemented in terms of Grand Central Dispatch.

00:16:46.169 --> 00:16:53.149
However, if you're familiar with, well let's see
first I should say that Grand Central Dispatch,

00:16:53.149 --> 00:16:58.669
remind you that it also provides queues
and they're called Dispatch queues.

00:16:58.669 --> 00:17:07.629
If you're familiar with toll-free bridging, however,
there is no toll-free bridging between NSOperationQueue's

00:17:07.630 --> 00:17:14.890
and dispatch queues; even though NSOperationQueue's
are implemented on top of dispatch queues.

00:17:14.890 --> 00:17:18.040
There's also no 1:1 correspondence between them.

00:17:18.039 --> 00:17:23.700
You cannot convert between a dispatch
queue and an NSOperationQueue.

00:17:23.700 --> 00:17:33.110
What actually happens is that the NSOperations you put it
into an OperationQueue are run, that is they're started,

00:17:33.109 --> 00:17:41.109
on one of the special concurrent dispatch
queues that Grand Central Dispatch provides.

00:17:41.109 --> 00:17:46.289
The exception to this, and of course
there has to be an exception,

00:17:46.289 --> 00:17:52.389
is NSOperationQueue's main queue and
Grand Central Dispatch's main queue.

00:17:52.390 --> 00:18:01.120
Now if you're familiar with NSOperationQueue in Leopard,
you may be saying what the heck is the main queue?

00:18:01.119 --> 00:18:02.419
I never saw that before.

00:18:02.420 --> 00:18:06.320
Well, that's another thing we've now added in Snow Leopard.

00:18:06.319 --> 00:18:11.399
There's a new class method called
mainQueue which returns the queue

00:18:11.400 --> 00:18:17.490
that is the single queue which is bound to the main thread.

00:18:17.490 --> 00:18:25.990
Operations which are put into the
mainQueue are executed on the main thread.

00:18:27.099 --> 00:18:36.759
Because there's only one thread which can be,
if you will, the destination of the operations

00:18:36.759 --> 00:18:40.000
in this special queue, this is of course is a serial queue.

00:18:40.000 --> 00:18:44.200
It runs one operation at a time.

00:18:44.200 --> 00:18:49.870
Because this is a shared queue, most
of its properties cannot be modified.

00:18:49.869 --> 00:18:52.949
You cannot suspend the mainQueue.

00:18:52.950 --> 00:19:00.009
You cannot change the width; that is, the
maximum concurrency count of the mainQueue.

00:19:00.009 --> 00:19:10.579
This corresponds, this mainQueue,
corresponds to and uses GCD's main queue.

00:19:10.579 --> 00:19:23.079
So it's equivalent whether you put an operation in the main
NSOperationQueue or you put a block or function pointer

00:19:23.079 --> 00:19:27.069
to be executed into Grand Central Dispatch's mainQueue.

00:19:27.069 --> 00:19:33.759
Those things that are put in either of
those two queues are run at the same time.

00:19:33.759 --> 00:19:43.390
Now the main thread in a Cocoa application usually is
busy handling user input events and running the run loop.

00:19:43.390 --> 00:19:48.370
So how do these two main queues get serviced?

00:19:48.369 --> 00:19:54.659
Well, the main run loop on the main
thread services these two main queues

00:19:54.660 --> 00:19:59.700
and it services them just as if they were a run loop source.

00:19:59.700 --> 00:20:09.590
Specifically it's as if they were a run loop source put
into the "common modes", a special "common modes" constant.

00:20:09.589 --> 00:20:17.059
So they are only serviced, these main queues, when
the run loop is running in one of the common modes.

00:20:17.059 --> 00:20:23.750
And they are not serviced when the main
run loop is serviced in a private mode.

00:20:23.750 --> 00:20:34.700
They are also not serviced re-entrantly; that is,
while a block from the GCD main queue or an operation

00:20:34.700 --> 00:20:42.259
from NSOperationQueue's main queue are
running, no other blocks will be started.

00:20:42.259 --> 00:20:50.119
Now some of this is a little esoteric, a
little advanced what I'm mentioning here

00:20:50.119 --> 00:20:53.049
and if this is going over your head don't worry about it.

00:20:53.049 --> 00:20:57.549
You probably won't have to worry about it at this point

00:20:57.549 --> 00:21:01.690
if you aren't already familiar with
some of these terms that I'm using.

00:21:01.690 --> 00:21:09.590
But essentially what we have here with the main queues
is a new way to get work back to the main thread

00:21:09.589 --> 00:21:16.019
which is often useful for interacting, for example,
with the AppKit since we're talking about Cocoa.

00:21:16.019 --> 00:21:22.950
And it's basically similar in effect to
using the performSelectorOnMainThread method

00:21:22.950 --> 00:21:28.100
with the waitUntilDone parameter NO, that is asynchronously.

00:21:28.099 --> 00:21:39.139
So work you put in these queues will happen
asynchronously at some point later on the main thread.

00:21:39.140 --> 00:21:42.420
One other last API I'm going to talk about that we've added

00:21:42.420 --> 00:21:49.400
to NSOperationQueue is another new
class method called currentQueue.

00:21:49.400 --> 00:21:57.920
currentQueue returns the queue which is running
the currently executing operation; that is,

00:21:57.920 --> 00:22:08.779
if you call currentQueue from within the execution context
within the code of an NSOperation, the queue that is running

00:22:08.779 --> 00:22:16.399
that operation will be returned; and if
there is no currently executing operation,

00:22:16.400 --> 00:22:18.730
this method is going to return nil.

00:22:18.730 --> 00:22:23.549
The exception, of course again there has to be an exception,

00:22:23.549 --> 00:22:30.680
is that on the main thread the mainQueue
is always returned by this method.

00:22:30.680 --> 00:22:37.279
So the mainQueue is always returned by currentQueue
and this is to align the behavior of NSOperationQueue

00:22:37.279 --> 00:22:40.619
with the behavior in Grand Central Dispatch.

00:22:40.619 --> 00:22:43.789
Now this method can be a little tricky to use.

00:22:43.789 --> 00:22:50.079
If you call currentQueue expecting
to do something with that queue,

00:22:50.079 --> 00:22:55.339
for example add operations to the
queue, you might be surprised.

00:22:55.339 --> 00:23:01.019
If you get the current queue, well
somebody created that queue of course,

00:23:01.019 --> 00:23:05.710
and that somebody is the logical owner of that queue.

00:23:05.710 --> 00:23:12.910
And so if that owner goes and suspends that queue and
you've put work in whatever the current queue happened to be

00:23:12.910 --> 00:23:19.630
when you called this method, well
your work isn't going to run.

00:23:19.630 --> 00:23:24.570
Also if it isn't your queue, you
shouldn't be messing with it.

00:23:24.569 --> 00:23:28.559
You should not be changing its properties;
you should not suspend that queue;

00:23:28.559 --> 00:23:32.839
you should not change the maximum
concurrency count of that queue

00:23:32.839 --> 00:23:39.179
because of course you may surprise the actual
owner, the creator, of that OperationQueue.

00:23:39.180 --> 00:23:44.460
So the currentQueue method can be useful for debugging

00:23:44.460 --> 00:23:51.240
but you should think carefully before
actually using it for any actual purpose.

00:23:52.500 --> 00:24:00.619
The final thing I want to talk about with
respect to NSOperationQueue's and the new stuff

00:24:00.619 --> 00:24:04.259
in Snow Leopard is their better performance.

00:24:04.259 --> 00:24:09.720
So we've improved the performance over
Leopard and to a significant degree,

00:24:09.720 --> 00:24:13.279
this is a result of adopting Grand Central Dispatch.

00:24:13.279 --> 00:24:21.230
One thing for example that I give here is that
adding operations, adding operations in a loop,

00:24:21.230 --> 00:24:30.279
many of them as fast as you can for example, is about
2.8 times faster on typical multicore Intel machines.

00:24:30.279 --> 00:24:37.529
So going through a loop and creating
lots of operations is a fair bit faster.

00:24:37.529 --> 00:24:45.420
But also the re-implementation in terms of Grand
Central Dispatch has introduced greater asynchrony

00:24:45.420 --> 00:24:50.500
and simplified the concurrency
safety within the implementation;

00:24:50.500 --> 00:24:55.710
so for example there's less contention
on locks compared to Leopard.

00:24:55.710 --> 00:25:04.549
What this has allowed us to do is lower
the execution overhead for each operation.

00:25:04.549 --> 00:25:11.789
And by overhead what you can think about this
meaning is that if you have a do-nothing operation--

00:25:11.789 --> 00:25:14.359
an operation whose main method, for example, is empty.

00:25:14.359 --> 00:25:16.339
It doesn't do anything.

00:25:16.339 --> 00:25:23.279
It's the amount of time for that operation to be
executed by and processed through an operation queue.

00:25:23.279 --> 00:25:27.839
Well I'm going to show a chart.

00:25:27.839 --> 00:25:31.159
Much easier to visualize what's going on.

00:25:31.160 --> 00:25:35.340
So first of all I'm going to show Leopard.

00:25:35.339 --> 00:25:41.759
This is the overhead in Leopard for 1, 2, and 8 Cores.

00:25:41.759 --> 00:25:48.299
And of course the lines are overlapping one
another so it doesn't really matter which is

00:25:48.299 --> 00:25:51.569
which in this case because they're all basically the same.

00:25:51.569 --> 00:26:06.450
But what we see here is that once you get to either 128-
or 256,000 or more operations, you've begun to hit a wall

00:26:06.450 --> 00:26:14.890
in the overhead where it becomes impractical to try to
execute that many operations within a short period of time.

00:26:14.890 --> 00:26:27.720
If you're trying to execute say, 256,000 operations over the
course of a day, well about 220 seconds of overhead would be

00:26:27.720 --> 00:26:35.370
about a quarter of a percent of one
day, and so the overhead in that case--

00:26:35.369 --> 00:26:39.979
a quarter of a percent, is not really noticeable.

00:26:39.980 --> 00:26:47.370
But as you tried to get more operations through that
queue of course, we see this sort of either exponential

00:26:47.369 --> 00:26:54.589
or quadratic and I don't have the patience
to run larger numbers so I gave up at 256.

00:26:55.869 --> 00:27:01.419
Here's what we see in Snow Leopard.

00:27:01.420 --> 00:27:10.340
So the lines are much lower, the curves
are flatter for a longer period of time.

00:27:10.339 --> 00:27:17.740
One interesting thing to note is although in Leopard
for example, the lines were fairly coincident; that is,

00:27:17.740 --> 00:27:23.730
they overlapped one another like
they're diverging in Snow Leopard.

00:27:23.730 --> 00:27:30.089
So at least one good thing in Leopard was
that the overhead wasn't getting worse

00:27:30.089 --> 00:27:34.199
as you added more Cores which could have happened.

00:27:34.200 --> 00:27:36.799
But in Snow Leopard, something even better is happening.

00:27:36.799 --> 00:27:42.279
The top line is one Core, all these
operations running on one Core,

00:27:42.279 --> 00:27:46.180
the middle line is two Cores and the lower line is 8 Cores.

00:27:46.180 --> 00:27:51.650
So what we see is the lower line of course is lower.

00:27:51.650 --> 00:27:55.780
As you add more Cores and are executing
these operations on more Cores,

00:27:55.779 --> 00:28:01.490
the overhead is lower as well and the curve is more gentle.

00:28:01.490 --> 00:28:06.569
So what this is showing, of course,
would be that the overhead

00:28:06.569 --> 00:28:14.399
of running operations is being distributed itself
better among the various Cores that are available.

00:28:14.400 --> 00:28:17.820
So that's Operation Overhead.

00:28:17.819 --> 00:28:23.379
Now it's just Operation Overhead that I'm talking about.

00:28:23.380 --> 00:28:34.680
I've put up this chart and I have it going from 32,000
to 8 million; that is not to say that you should run out

00:28:34.680 --> 00:28:41.759
and write applications which try to execute 1
million operations in a short period of time.

00:28:41.759 --> 00:28:51.900
Of course, the operations themselves require RAM just
to represent the operation objects, and the operations--

00:28:51.900 --> 00:28:56.950
your operations, as they run will probably use memory.

00:28:56.950 --> 00:29:08.150
So what's going to happen as you try to create more
and more operations is you're going to begin to swap.

00:29:08.150 --> 00:29:14.960
Once you begin swapping, the Operation
Overhead is really the least of your problems.

00:29:14.960 --> 00:29:20.660
You have much bigger problems once you begin swapping, and
that's in fact why the chart doesn't go off to 16 million

00:29:20.660 --> 00:29:27.390
because that's where it began swapping on the
machine I was collecting these numbers on.

00:29:27.390 --> 00:29:35.020
Now let's go over to the collection APIs that
we've added in Snow Leopard within Foundation.

00:29:35.019 --> 00:29:45.139
So on NSArray, NSDictionary, NSSet, and NSIndexSet,
we've added some new APIs for enumeration and searching.

00:29:45.140 --> 00:29:53.310
Well it used to be that to enumerate you used an
NS enumerator or you used, in the case of Array,

00:29:53.309 --> 00:29:59.269
indexed enumeration, indexed access
to enumerate over an Array.

00:29:59.269 --> 00:30:11.700
Then in Leopard we added the four-in syntax to allow you to
enumerate over collections and that was faster and nicer.

00:30:11.700 --> 00:30:21.759
Now that we've introduced blocks into the languages,
we've added yet more ways to enumerate your collections;

00:30:21.759 --> 00:30:28.450
and the particular benefit in this
case is that we've added an option

00:30:28.450 --> 00:30:34.200
for doing this concurrently-- the
NSEnumerationConcurrent option.

00:30:34.200 --> 00:30:38.789
And when you provide that the block
may be invoked concurrently.

00:30:38.789 --> 00:30:44.930
Now to illustrate a point that's going to
come up a little bit later in the talk,

00:30:44.930 --> 00:30:49.799
I want to point out the example there in the middle.

00:30:49.799 --> 00:30:58.019
This is what the block signature of the NSArray method,
enumerateObjectsWithOptions:usingBlock: looks like.

00:30:58.019 --> 00:31:07.759
It gets the object being enumerated, it gets the integer
index of that object and it gets a Boolean parameter

00:31:07.759 --> 00:31:13.960
that allows the block to stop the
enumeration early if it wishes to.

00:31:13.960 --> 00:31:18.029
Now of course each collection has its own signature.

00:31:18.029 --> 00:31:23.670
For dictionaries, the dictionary gets
the key object and the value object

00:31:23.670 --> 00:31:27.990
and the Boolean stop parameter
instead of an object and an index.

00:31:27.990 --> 00:31:31.880
Well, why do we pass in that index?

00:31:31.880 --> 00:31:37.740
Well if you've turned on concurrent enumeration
or passing in this option to this method,

00:31:37.740 --> 00:31:47.079
there would be no way for the block that is practical at
least, to find out what the index is if the block needs it.

00:31:47.079 --> 00:31:53.659
When you've turned on concurrent enumeration, the objects in
the array will be enumerated in sort of an arbitrary order.

00:31:53.660 --> 00:32:00.070
There's no defined order that they will be
enumerated in and so there would be no practical way

00:32:00.069 --> 00:32:02.519
for the block to know what the index was.

00:32:02.519 --> 00:32:09.059
Calling index of object would just be horrendously
expensive if we didn't provide this parameter.

00:32:09.059 --> 00:32:16.589
So that's why at least the array
method takes the index of the object.

00:32:16.589 --> 00:32:20.929
To illustrate concurrent enumeration,
what I'm going to do is I'm going

00:32:20.930 --> 00:32:27.000
to implement a map function in a category on NSArray.

00:32:27.000 --> 00:32:33.000
A map is a function that's found often
within functional programming languages,

00:32:33.000 --> 00:32:40.690
and what it does is it takes an input array or
source array and processes each element in the array

00:32:40.690 --> 00:32:50.330
through a mapping function, and puts all the result objects
into a result array and that looks something like this.

00:32:50.329 --> 00:32:58.439
On the left side there I have my source array;
each object is given to the mapping function.

00:32:58.440 --> 00:33:05.390
And what the mapping function is supposed to do is
return a new object or potentially the same object,

00:33:05.390 --> 00:33:11.570
but an object which ends up then in the result array.

00:33:11.569 --> 00:33:17.589
And notice that in, for example as I'm illustrating
this diagram, there's a correspondence here

00:33:17.589 --> 00:33:27.019
between the two arrays; that is, the result
object from the mapper which is at say index 7,

00:33:27.019 --> 00:33:36.220
came from somehow the source object, the object
which was in the source array at index 7.

00:33:36.220 --> 00:33:41.360
So there is a correspondence here between
the source objects which are the inputs

00:33:41.359 --> 00:33:45.709
and the result objects which end up in the result array.

00:33:45.710 --> 00:33:51.400
So what are my design points for the
map function which I'm about to create?

00:33:51.400 --> 00:33:59.370
Well the caller is going to specify a mapping function
using a block since we have this nice new block syntax.

00:33:59.369 --> 00:34:09.049
I'm going to give the block that you provide, the
caller provides, the object and the index parameter;

00:34:09.050 --> 00:34:14.030
wouldn't necessarily need to give it the index but in
case the mapping function wants the index I'm just going

00:34:14.030 --> 00:34:18.620
to pass it along since I already
get it myself as you'll see.

00:34:18.619 --> 00:34:24.789
I'm not going to give the mapping function
the option to stop the mapping early though.

00:34:24.789 --> 00:34:32.400
I don't want to have to deal with and think about
what it would mean for the mapping to end prematurely.

00:34:32.400 --> 00:34:40.530
The block, the mapping block should return a
new object to of course put in the result array,

00:34:40.530 --> 00:34:45.070
and it should return that autoreleased
and it must not return nil.

00:34:45.070 --> 00:34:50.330
I'm not going to handle nil in my mapping function.

00:34:50.329 --> 00:34:57.239
Because this is a talk about concurrency in Cocoa,
of course I'm going to invoke the block concurrently

00:34:57.239 --> 00:35:02.099
and so that mapping block has to be concurrency safe.

00:35:02.099 --> 00:35:06.199
And finally, the map method is going to
return the new array, the new results array.

00:35:06.199 --> 00:35:10.239
Well this looks like this.

00:35:10.239 --> 00:35:19.009
I begin, of course, by declaring my method and
I'm going to call it my_mapUsingBlock in this case

00:35:19.010 --> 00:35:27.690
and it only takes one parameter, the mapper function
which takes an object and an index parameter.

00:35:27.690 --> 00:35:34.139
Now the source array in this case because this is
a category in NSArray is the receiving object self.

00:35:34.139 --> 00:35:41.980
So the first thing I do is get self's count and that's of
course going to be the size of the result array as well

00:35:41.980 --> 00:35:45.190
since there's a correspondence between them.

00:35:45.190 --> 00:35:55.030
And I create a temporary C array using malloc
of that size to hold the result objects.

00:35:55.030 --> 00:35:56.840
Well why am I doing this?

00:35:56.840 --> 00:36:00.380
Why am I creating a temporary C array?

00:36:00.380 --> 00:36:09.820
Well, the mapper block is going to be invoked
concurrently as I said, so in arbitrary order.

00:36:09.820 --> 00:36:15.420
It's not going to be invoked from
index zero on up necessarily.

00:36:15.420 --> 00:36:23.670
So because I want the result array to have a correspondence
to the source array, I would have to keep track of the order

00:36:23.670 --> 00:36:31.840
and the index of each result; but because I'm going
to use a C array I can just store the new object

00:36:31.840 --> 00:36:39.620
at the specific index in the C array that the source
object came from and you'll see that in a minute.

00:36:39.619 --> 00:36:46.679
It also means that I don't have to
thread-safely access any higher level collection.

00:36:46.679 --> 00:36:56.129
The C array, because I'm only going to touch and modify one
element within that C array from each invocation of a block,

00:36:56.130 --> 00:37:02.869
and I'm not going to-- well and the block
is only executed one time for each index.

00:37:02.869 --> 00:37:07.400
And because the block is only executed
one time for each index,

00:37:07.400 --> 00:37:11.789
then I don't need to do anything further for thread safety.

00:37:11.789 --> 00:37:17.829
So as I mentioned the mapper block
should return an autoreleased object.

00:37:17.829 --> 00:37:24.889
That's conventional in Cocoa so we'll try to
stick with that kind of convention for my API,

00:37:24.889 --> 00:37:39.119
and so the autoreleased object is being autoreleased
because this is concurrency going on, on various threads.

00:37:39.119 --> 00:37:47.569
Well the enumerateObjectsWithOptions method on
NSArray and the other methods as well that we added,

00:37:47.570 --> 00:37:53.610
take care of putting the autorelease pool in place
for you on those various threads that are in use,

00:37:53.610 --> 00:38:00.440
so it's going to be safe for the mapper to return an
autoreleased object-- there's not going to be a leak.

00:38:00.440 --> 00:38:11.700
But the problem then will be that I will have to retain
that return value of the mapping function temporarily

00:38:11.699 --> 00:38:22.389
as I store it in my C array, to ensure that that object
which is being created potentially on another thread,

00:38:22.389 --> 00:38:27.920
lives long enough so that I can
store it then in my result NSArray.

00:38:27.920 --> 00:38:35.400
Having created my C array called temp what I'm going
to do is call that enumerateObjectsWithOptions method

00:38:35.400 --> 00:38:43.180
and I'm going to pass in the NSEnumerationConcurrent option,
and I'm going to pass in a block with the correct syntax.

00:38:43.179 --> 00:38:52.009
For NSArray the correct syntax takes an
object argument, a integer which is the index

00:38:52.010 --> 00:38:56.860
and the Boolean BOOL star stop parameter.

00:38:56.860 --> 00:39:05.970
What I'm going to do in my block that I'm going to pass to
that enumerate method is I'm going to call the mapping block

00:39:05.969 --> 00:39:11.879
that I got as an argument, and I'm going to pass it
the object in the index, that's fairly straightforward,

00:39:11.880 --> 00:39:15.800
and it's going to do its little
computation and return a result.

00:39:15.800 --> 00:39:26.940
Then I'm going to have to retain, as I just said, that
potentially new object to make sure it lives long enough,

00:39:26.940 --> 00:39:37.900
lives at least beyond the call to the enumerate method,
and then I'm going to store that object at temp [idx].

00:39:37.900 --> 00:39:49.090
So I'm going to store it at the specific index of the source
object within the new temp array or the temporary C array.

00:39:49.090 --> 00:39:57.809
The enumerateObjectsWithOptions method is doing a bunch of
concurrency because I'm passing in the concurrent option,

00:39:57.809 --> 00:40:02.369
within itself, within the execution of that method.

00:40:02.369 --> 00:40:10.039
But it itself is synchronous; that is, it's
not going to return until all that concurrency,

00:40:10.039 --> 00:40:13.829
all those invocations of the block have actually finished.

00:40:13.829 --> 00:40:21.319
So that will end up being very convenient because once
that method returns, I know that all of the concurrency,

00:40:21.320 --> 00:40:26.930
all the new results have been stuffed into
my temporary C array so I don't have to worry

00:40:26.929 --> 00:40:32.309
about doing any waiting for anything
to happen or what have you.

00:40:32.309 --> 00:40:42.090
So what I'll do, is I'll simply create a new array
with an arrayWithObjects count using that new temp,

00:40:42.090 --> 00:40:48.670
that temporary temp buffer, and having created the array,

00:40:48.670 --> 00:40:57.170
what I'm going to have to do is then release all those
temporary retains that I talked about that I put in my block

00:40:57.170 --> 00:41:03.200
on the objects I stored in that temporary array.

00:41:03.199 --> 00:41:10.179
So I'm just going to loop, sending each of them release,
because they are now retained by that new array.

00:41:10.179 --> 00:41:14.199
Then I'm going to free my temp buffer.

00:41:14.199 --> 00:41:17.759
Ok so here is what that looks like then.

00:41:17.760 --> 00:41:24.090
In the pink or purple or whatever you call that color,
is the contents of that block I was talking about.

00:41:24.090 --> 00:41:29.910
I call the mapping function, I retain its return
value to make sure it lives beyond the execution

00:41:29.909 --> 00:41:40.489
of the enumerateObjectsWithOptions method and then I
simply store it in the C array at the proper index.

00:41:40.489 --> 00:41:48.059
Then I create my new array, NSArray with
that C array of objects full of objects,

00:41:48.059 --> 00:41:54.440
I release each of them as I mentioned because
I need to balance my previous temporary retain,

00:41:54.440 --> 00:42:00.619
I free the temporary C array and
I return the new result NSArray.

00:42:00.619 --> 00:42:02.699
That's what that looks like.

00:42:02.699 --> 00:42:07.250
Now of course because I use malloc,
I'll just mention in passing,

00:42:07.250 --> 00:42:14.000
I allocated there for that temporary
C array, unscanned memory.

00:42:14.000 --> 00:42:20.070
So this is the retained release version of this method.

00:42:20.070 --> 00:42:26.470
Under Garbage Collection you need to allocate
scanned memory for that temporary C array

00:42:26.469 --> 00:42:36.279
so the garbage collector doesn't come along and
collect those result objects from the mapper block

00:42:36.280 --> 00:42:39.820
because of course retain does nothing
under Garbage Collection;

00:42:39.820 --> 00:42:46.150
and the collector if it's unscanned
memory won't see the object there in temp.

00:42:46.150 --> 00:42:50.470
So let's move on quickly to Concurrent Sorting.

00:42:50.469 --> 00:43:00.349
We've added some new methods in NSArray and NSMutableArray
that allow you to sort using a block so that's one benefit.

00:43:00.349 --> 00:43:06.199
We were taking advantage again of this new block syntax
which is again extremely convenient for these sorts

00:43:06.199 --> 00:43:13.779
of things where you just need a little tiny method
or a little tiny bit of code to do a comparison.

00:43:13.780 --> 00:43:18.900
You pass in the NSSortConcurrent
option to enable concurrent sorting.

00:43:18.900 --> 00:43:23.309
The comparator block looks like what you might expect.

00:43:23.309 --> 00:43:30.079
You have to return an NSComparisonResult--
one of those enumerated values from the block,

00:43:30.079 --> 00:43:37.529
and the block gets as its parameters
the two objects to be compared.

00:43:37.530 --> 00:43:44.740
Now if you're going to use the NSSortConcurrent sort
option, your block of course has to be concurrency safe.

00:43:44.739 --> 00:43:52.969
One other thing I want to mention here, I guess this
is the last bullet, there's also an NSSortStable option

00:43:52.969 --> 00:44:00.980
that we've added in Snow Leopard so
you can get stable sorting out of this.

00:44:02.110 --> 00:44:13.430
But just because you're using concurrent sorting doesn't
mean you can't also get stable sorting at the same time.

00:44:13.429 --> 00:44:22.169
Concurrent sorting is of course arbitrarily sort of invoking
the comparator function across different pairs of objects,

00:44:22.170 --> 00:44:26.019
but stable sorting is also available at the same time.

00:44:26.019 --> 00:44:30.699
So you can combine these two options and
still get concurrent yet stable sorting.

00:44:30.699 --> 00:44:35.599
So what does this look like in a graph?

00:44:35.599 --> 00:44:39.529
A graph of course being an easy way to visualize all this.

00:44:39.530 --> 00:44:45.910
Well, what we have here is I wrote
a little program to sort an array

00:44:45.909 --> 00:44:51.559
of random fairly short, about 20
characters ea ch, short strings.

00:44:51.559 --> 00:45:00.690
Doing a standard nonconcurrent sort we see a line like this
and of course these specific values aren't really material,

00:45:00.690 --> 00:45:05.550
just how the different curves, and I'm
going to show you, relate to one another.

00:45:05.550 --> 00:45:14.110
Using concurrent sort with two Cores on the same
machine, we see a curve like this much lower.

00:45:14.110 --> 00:45:19.829
And on 8 Cores we see a lower curve yet.

00:45:19.829 --> 00:45:27.429
So basically what this means is that the
sorting is faster on more Cores or the latency

00:45:27.429 --> 00:45:35.230
of finishing the sort operation is less
if you want to look at it that way.

00:45:35.230 --> 00:45:39.269
Now let's go on to NSNotificationCenter.

00:45:39.269 --> 00:45:47.199
So in Snow Leopard we've added another new API and
you would have seen this in the What's New talk,

00:45:47.199 --> 00:45:55.359
yesterday called addObserverForName object queue usingBlock.

00:45:55.360 --> 00:46:04.110
Now if you remember in your head a traditional
API for adding an observer takes a target object

00:46:04.110 --> 00:46:08.490
which is the observer object and a selector to invoke.

00:46:08.489 --> 00:46:14.079
Well instead, this new method takes
advantage of this new block syntax we've added

00:46:14.079 --> 00:46:19.599
and you can specify an observer block
essentially-- a block to be invoked.

00:46:19.599 --> 00:46:27.349
So now you don't have to define some private method
or some method on some class somewhere to be invoked.

00:46:27.349 --> 00:46:35.949
You can simply put all the code you want to run when
the notification happens or is posted, into that block.

00:46:35.949 --> 00:46:41.329
The other difference that I'll point out
at this point is that the return value

00:46:41.329 --> 00:46:46.069
of this new method is id whereas
the traditional method returns void;

00:46:46.070 --> 00:46:51.430
and I'll explain what the significance
of that is in a second.

00:46:51.429 --> 00:46:57.559
The third parameter is also different--
that queue parameter there.

00:46:57.559 --> 00:46:58.630
What does that mean?

00:46:58.630 --> 00:47:06.180
Well, if you give a parameter here
that is a queue a non nil value,

00:47:06.179 --> 00:47:12.409
that block will be executed in the
context of that operation queue.

00:47:12.409 --> 00:47:18.019
And so this can be a convenient way
to get the handling of a notification

00:47:18.019 --> 00:47:22.329
onto the context of a particular operation queue.

00:47:22.329 --> 00:47:30.610
Well the most obvious example would be is if you're
using the main queue as the queue parameter here,

00:47:30.610 --> 00:47:35.930
you can get the notification handled on the main thread.

00:47:35.929 --> 00:47:46.049
If there are multiple observers registered for the same
notification about the same object, via this method,

00:47:46.050 --> 00:47:55.180
those observer blocks are all where possible
executed concurrently; that is, at the same time.

00:47:55.179 --> 00:48:02.989
So all the observers are handling the notification at the
same time potentially, but the posting that is the thread

00:48:02.989 --> 00:48:08.519
or the queue or whatever it is the code that is
posting the notification is still synchronous.

00:48:08.519 --> 00:48:16.570
That is, the posting operation still blocks waiting for
all the observers wherever it's going to be executed

00:48:16.570 --> 00:48:24.860
to have executed their handling of the
notification before the posting method returns.

00:48:24.860 --> 00:48:33.769
This of course is crucial in the case where
you have a notification like NSWindowWillClose.

00:48:33.769 --> 00:48:42.429
Well if the observers were simply processed asynchronously
at some later point and the posting was allowed to continue,

00:48:42.429 --> 00:48:48.369
the posting would occur and the window would get closed,

00:48:48.369 --> 00:48:53.569
and potentially an hour later your observer might
get executed saying hey the window's about to close

00:48:53.570 --> 00:48:56.470
but of course it's long since closed at that point.

00:48:56.469 --> 00:49:00.039
So the posting still has to be synchronous.

00:49:00.039 --> 00:49:08.920
If you don't want to specify a queue, you can pass
in nil and the handler block there will be executed

00:49:08.920 --> 00:49:16.000
on the posting thread just as is traditional
with the old style addObserver method,

00:49:16.000 --> 00:49:24.320
where the observers were all handled, called
synchronously on the thread which is doing the posting.

00:49:24.320 --> 00:49:28.440
The other thing is that return value as I mentioned.

00:49:28.440 --> 00:49:39.030
That return value can be thought of as the new observer if
you want, but basically it has to be retained and held on to

00:49:39.030 --> 00:49:47.810
as long as you want this notification registration to exist.

00:49:47.809 --> 00:49:55.900
When you want to remove the observer; that is, stop handling
this notification, you need to pass this return object

00:49:55.900 --> 00:50:00.070
to the removeObserver method as its parameter.

00:50:00.070 --> 00:50:04.220
So essentially this return object is like the observer.

00:50:04.219 --> 00:50:16.549
Well let's take a little break
here and move on up to the AppKit.

00:50:16.550 --> 00:50:28.730
So in AppKit in Snow Leopard we added two new major
functionalities that have to do with concurrency.

00:50:28.730 --> 00:50:33.639
The first of which is Concurrent Document Opening.

00:50:33.639 --> 00:50:39.759
NSDocument as you may have seen
alluded to at least yesterday

00:50:39.760 --> 00:50:43.080
at the What's New talk, can now open files concurrently.

00:50:43.079 --> 00:50:51.690
And TextEdit does this for most document types.

00:50:51.690 --> 00:50:56.670
The sketch example is an example you can look at as well

00:50:56.670 --> 00:51:01.159
where the sketch has been modified
to do concurrent document opening.

00:51:02.510 --> 00:51:07.320
To enable concurrent document opening
what you do is a fairly simple process.

00:51:07.320 --> 00:51:15.039
The first step is the hardest of course; it's to
make your document reading code concurrency-safe.

00:51:15.039 --> 00:51:21.860
If your document reading code is doing things
like modifying global data or just reading,

00:51:21.860 --> 00:51:32.420
accessing global data which itself might be modified by some
other thread, you of course have to make that thread-safe.

00:51:32.420 --> 00:51:39.500
Once you've done that you simply override
the canConcurrentlyReadDocumentsOfType method

00:51:39.500 --> 00:51:41.989
in your NSDocument subclass.

00:51:41.989 --> 00:51:45.489
This is a class method that returns a BOOL.

00:51:45.489 --> 00:51:52.399
It gets the type of the document and for those
documents whose type you recognize as now you're able

00:51:52.400 --> 00:51:59.610
to concurrently open them, you simply return YES.

00:51:59.610 --> 00:52:06.960
Once you've done that, documents of those
types may then be loaded in the background.

00:52:06.960 --> 00:52:10.510
The AppKit of course does not promise
to load them in the background.

00:52:10.510 --> 00:52:15.810
It may not load them in the background
for reasons of its own.

00:52:17.739 --> 00:52:25.029
The practical impact that you should be aware of, of course
once you've done this is that some NSDocument Controller

00:52:25.030 --> 00:52:33.440
and some NSDocument methods will
be invoked on nonmain threads.

00:52:33.440 --> 00:52:35.750
"Nonmain" isn't a word.

00:52:37.639 --> 00:52:44.670
So another thing of course you
should be doing and it's called

00:52:44.670 --> 00:52:51.530
out with its own bullet here is not
doing UI from your document reading code.

00:52:51.530 --> 00:52:54.290
That's part of making it concurrency safe.

00:52:54.289 --> 00:53:01.340
If of course your document reading code ends
up actually being invoked on another thread,

00:53:01.340 --> 00:53:08.850
it's not being invoked on the main thread of course, and
so you shouldn't be doing UI from the document reading.

00:53:08.849 --> 00:53:15.690
You should only read the data in the file
or files and create the model objects

00:53:15.690 --> 00:53:18.929
that represent the contents of your document.

00:53:18.929 --> 00:53:29.250
If there is a failure, just create an NSError and
stuff it in that out parameter to the various methods.

00:53:29.250 --> 00:53:34.349
Don't try to put up an alert panel
from within your document reading code,

00:53:34.349 --> 00:53:40.480
because that document reading code is not
necessarily running on the main thread.

00:53:40.480 --> 00:53:46.619
Another thing is you should disable undo
registration during your document reading.

00:53:46.619 --> 00:53:52.789
Just in general it's not particularly
interesting to allow a user to be able

00:53:52.789 --> 00:53:57.929
to undo the opening of a document; they can simply close it.

00:53:57.929 --> 00:54:09.149
But particularly in the case of concurrent document
opening because undo is essentially a UI facility

00:54:09.150 --> 00:54:13.809
with modifying the Undo and Redo menu items and so on

00:54:13.809 --> 00:54:21.340
and basically tracking what the user
does to the documents as they're opened.

00:54:21.340 --> 00:54:30.710
You should disable undo registration when you are doing
the document reading so that undo items don't end up--

00:54:30.710 --> 00:54:36.880
of course they'll be all scrambled if there are
many documents being opened at the same time

00:54:36.880 --> 00:54:42.680
and the user will just be totally
confused about what's going on.

00:54:42.679 --> 00:54:45.829
Then we have Concurrent Drawing.

00:54:45.829 --> 00:54:50.000
This is a new facility on NSView
that's been added in Snow Leopard.

00:54:50.000 --> 00:54:58.349
And views can be set so that they can be drawn
concurrently; again this is an advisory state.

00:54:58.349 --> 00:55:08.759
You simply call the setCanDrawConcurrently method and
pass it the Boolean value YES; and of course this is can.

00:55:08.760 --> 00:55:18.290
This is just indicating to the AppKit that it can if it
wants to draw the view that receives this concurrently

00:55:18.289 --> 00:55:22.529
with the drawing of other views when display happens.

00:55:22.530 --> 00:55:26.740
Subviews don't inherit this property from their superview.

00:55:26.739 --> 00:55:36.529
So each individual view that you want to enable as
a concurrent drawing on, has to have this set on it.

00:55:36.530 --> 00:55:42.460
So once you've done that a view may be
drawn on a background thread concurrently

00:55:42.460 --> 00:55:48.079
with other views which haven't had this set on them.

00:55:48.079 --> 00:55:51.860
Those will be still drawn on the main thread.

00:55:51.860 --> 00:55:55.550
The point of course it to produce a performance improvement.

00:55:55.550 --> 00:56:03.600
If you have multiple slowly drawing views within
a window, then you may see performance improvement

00:56:03.599 --> 00:56:11.909
if those slow views can draw concurrently
with respect to one another.

00:56:11.909 --> 00:56:20.869
Views as I said not set to draw concurrently still draw on
the main thread for backwards compatibility and display;

00:56:20.869 --> 00:56:29.219
the whole display process is still done on the main
thread as it always has been and is still synchronous.

00:56:29.219 --> 00:56:35.500
That is, display, the display process
does not return until all of the drawing,

00:56:35.500 --> 00:56:38.980
if there's any concurrent drawing, has finished.

00:56:38.980 --> 00:56:46.099
But it also means that any other activity
other than the display that wants to happen

00:56:46.099 --> 00:56:52.319
on the main thread is held up while the display is going on.

00:56:52.320 --> 00:57:02.840
So if your model objects which you are displaying
can only be modified say by a user input event

00:57:02.840 --> 00:57:08.550
like a button click on an Add button or that kind of thing.

00:57:08.550 --> 00:57:14.960
User input events are blocked while display is
going on and so your model objects aren't going

00:57:14.960 --> 00:57:18.380
to be changed while display is going on in that case.

00:57:18.380 --> 00:57:26.400
And so the thread-safety burden on your model does not
change just because you've enabled concurrent drawing.

00:57:26.400 --> 00:57:33.079
If it was already possible for your model objects to change
on other threads, you already should have had to deal

00:57:33.079 --> 00:57:38.509
with making your model accesses thread-safe
regardless of concurrent drawing.

00:57:38.510 --> 00:57:45.400
That's the general rule.

00:57:45.400 --> 00:57:47.740
So what do you do to enable concurrent drawing?

00:57:47.739 --> 00:57:50.250
Well first you measure the draw timing.

00:57:50.250 --> 00:57:56.280
You should always measure first to see where
you've ended up once you've done the change.

00:57:56.280 --> 00:58:04.390
And the point is to find those custom views
of yours which are the expensive views.

00:58:04.389 --> 00:58:13.759
If you need to, for example, if those views
during their drawing have side effects

00:58:13.760 --> 00:58:19.420
like they're incrementing a global counter or
they're modifying some data in their drawing

00:58:19.420 --> 00:58:23.210
which is maybe a little suspect to
begin with, but if you're doing that,

00:58:23.210 --> 00:58:32.659
then you need to make the drawing concurrency-safe; you mark
those views that you want to try out, concurrent drawing on,

00:58:32.659 --> 00:58:37.659
as being able to draw concurrently;
and then you measure again.

00:58:37.659 --> 00:58:48.159
Now drawing views concurrently adds some overhead because
some graphic state and what not has to be replicated

00:58:48.159 --> 00:58:53.359
across different contexts then which
normally doesn't have to happen.

00:58:53.360 --> 00:58:59.950
And so you may not see a performance
improvement so you should always measure.

00:58:59.949 --> 00:59:03.089
If you don't see a performance
improvement, don't turn this on.

00:59:03.090 --> 00:59:13.030
There are a couple of caveats that I want to point
out with respect to Snow Leopard specifically.

00:59:13.030 --> 00:59:18.750
Layer-backed views are not drawn
concurrently in Snow Leopard;

00:59:18.750 --> 00:59:26.659
overlapping sibling views are not handled correctly;
that is, if you turn on concurrent drawing for one

00:59:26.659 --> 00:59:33.730
or more overlapping sibling views, that is not
subviews of one another but they're just sibling views

00:59:33.730 --> 00:59:39.289
in the view hierarchy, you may see some drawing artifacts.

00:59:39.289 --> 00:59:46.159
And as I alluded to earlier, this is
mostly an option for your custom views.

00:59:46.159 --> 00:59:55.679
The AppKit's own views and controls have not yet been fully
vetted to be concurrency-safe; and so this is an option

00:59:55.679 --> 01:00:02.079
at this point where you should just be looking
at your own custom views for turning this on.

01:00:02.079 --> 01:00:09.170
You should absolutely go and see the
AppKit release notes for more information.

01:00:09.170 --> 01:00:12.269
I mentioned you should measure draw timing.

01:00:12.269 --> 01:00:13.639
Well how do you do that?

01:00:13.639 --> 01:00:19.429
Well the AppKit release notes have some helpful
tips on how to do that and also some debugging tips

01:00:19.429 --> 01:00:25.509
for debugging potential issues with concurrent drawing.

01:00:25.510 --> 01:00:29.010
So let's wrap up.

01:00:29.010 --> 01:00:37.280
For more information I'll point you to our Developer
Tools and Performance Evangelist, Michael Jurewitz.

01:00:37.280 --> 01:00:41.860
You should absolutely go look at
the Concurrency Programming Guide.

01:00:41.860 --> 01:00:49.460
This is a new document that we've
just added now with Snow Leopard.

01:00:49.460 --> 01:01:00.710
And there is a link to that if you go to this session's
site, if you will, on the attendee site there's a link

01:01:00.710 --> 01:01:03.309
to this new Concurrency Programming Guide.

01:01:03.309 --> 01:01:08.549
You can also get the AppKit and Foundation
Release Notes, I think, from there.

01:01:08.550 --> 01:01:15.690
I haven't checked that specifically but they
should also be available in Xcode or from Xcode.