WEBVTT

00:00:12.750 --> 00:00:18.769
>> Hi. And welcome to the session
of OpenGL ES Shading and Rendering.

00:00:18.769 --> 00:00:22.320
My name is Luc Semeria and joining
me on stage will be Alex Eddy.

00:00:22.320 --> 00:00:28.019
We are both part of the Embedded
Graphics Acceleration team here at Apple.

00:00:28.019 --> 00:00:30.269
Here is the agenda for today.

00:00:30.269 --> 00:00:35.880
We're going to start by talking about shaders
and how to write shaders in OpenGL ES 2.0.

00:00:35.880 --> 00:00:37.960
Then in the second part of this presentation,

00:00:37.960 --> 00:00:41.969
we'll talk about advanced rendering
techniques to make your games look even better.

00:00:41.969 --> 00:00:50.460
So if you have been writing applications over the last year
for the iPhone and the iPhone Touch using OpenGL ES 1.1,

00:00:50.460 --> 00:00:57.200
you are going to learn today how to write shaders
and particularly making use of OpenGL ES 2.0.

00:00:57.200 --> 00:01:00.350
We're also going to learn in the
second part of the presentation how

00:01:00.350 --> 00:01:10.879
to make advance rendering effects in
both OpenGL ES 1.1 and OpenGL ES 2.0.

00:01:10.879 --> 00:01:16.619
If you've been working on OpenGL on Desktop,
a lot of this may look like a review.

00:01:16.620 --> 00:01:24.329
You probably have written shaders already and have
used a lot of the OpenGL state techniques as well.

00:01:24.329 --> 00:01:28.789
But we'll find out some of the key
differences between ES and Desktop.

00:01:28.790 --> 00:01:32.870
And, you know, along the way you're
probably going to learn some new tricks.

00:01:32.870 --> 00:01:39.400
So let me start by a review of OpenGL ES
2.0 and the programmable graphics pipeline.

00:01:39.400 --> 00:01:44.670
So here is the overview of the pipeline.

00:01:44.670 --> 00:01:48.010
If you've been to the presentation,
you have already seen that slide.

00:01:48.010 --> 00:01:53.090
Well, this is the OpenGL ES 1.1
fixed function graphics pipeline.

00:01:53.090 --> 00:01:59.689
Let me just go through it quickly and just highlight a
few of the points that are relevant for OpenGL ES 2.0.

00:01:59.689 --> 00:02:03.560
So you start with your model that's
composed of, you know, primitives.

00:02:03.560 --> 00:02:04.760
Triangles typically.

00:02:04.760 --> 00:02:07.880
And the corner of those triangles are vertices.

00:02:07.879 --> 00:02:15.180
So in the first stage, you break those triangles into
vertices and you pass them to the vertex processing stage.

00:02:15.180 --> 00:02:19.040
That's particularly those, the
transformation of the coordinates

00:02:19.039 --> 00:02:24.109
from model space through eye space into window space.

00:02:24.110 --> 00:02:27.600
That's also, where you compute your textual coordinates.

00:02:27.599 --> 00:02:30.629
That's also, where lighting is typically done.

00:02:30.629 --> 00:02:37.039
Once you've done all this, the vertices
with the correct windows positions go

00:02:37.039 --> 00:02:40.900
through the primitive assembly block
that puts those back into triangles.

00:02:40.900 --> 00:02:45.710
Then those triangles get rasterized into separate fragments.

00:02:45.710 --> 00:02:49.580
Those fragments correspond to pixels
that are going to go on your screen.

00:02:49.580 --> 00:02:54.190
So each of those fragments are sent
to the fragment processing stage.

00:02:54.189 --> 00:03:00.460
And in a fixed function pipeline this is where
you do your textual loads, combine your textuals.

00:03:00.460 --> 00:03:03.800
This is where you do your fog computation and alpha testing.

00:03:03.800 --> 00:03:07.750
Then what you end up at the end of the
fragment processing stage is a color

00:03:07.750 --> 00:03:10.800
that you can dynamically display on your screen.

00:03:10.800 --> 00:03:13.130
What changes with OpenGL ES 2.0?

00:03:13.129 --> 00:03:17.689
Well, OpenGL ES 2.0 is a programmable graphic pipeline.

00:03:17.689 --> 00:03:23.710
What it means is that really the two boxes that
are highlighted here, the vertex processing box

00:03:23.710 --> 00:03:27.980
and the fragment processing box, are now programmable.

00:03:27.979 --> 00:03:34.590
And the way you program those two stages are using shaders.

00:03:34.590 --> 00:03:40.310
So we have our two programmable shaders
and they look like regular code.

00:03:40.310 --> 00:03:42.259
Almost looks like C.

00:03:42.259 --> 00:03:48.489
And this code gets compiled and
linked to run as a program on the GPU.

00:03:48.490 --> 00:03:53.670
So just like you would, you know, write C code, and
compile anything in that C code to run on your CPU, well,

00:03:53.669 --> 00:03:59.229
in OpenGL ES 2.0 you write GLSL, which is a
programming language we use for those shaders.

00:03:59.229 --> 00:04:02.669
And we compile and link those shaders to run on the GPU.

00:04:02.669 --> 00:04:05.750
It's accelerated on the GPU.

00:04:05.750 --> 00:04:12.780
And this allows you to do more effects
than what you can do on OpenGL ES 1.1.

00:04:12.780 --> 00:04:14.259
Here are some examples.

00:04:14.259 --> 00:04:19.659
You can do tangent space bump mapping,
especially if you do skinning.

00:04:19.660 --> 00:04:23.660
You can do better on the cubic environment map.

00:04:23.660 --> 00:04:26.550
You can do better effects like reflection.

00:04:26.550 --> 00:04:31.100
You can do better image processing and, you know,
this is programmable so it's really up to you.

00:04:31.100 --> 00:04:36.820
You can put your own algorithm in those
shaders and compute the effects that you want.

00:04:36.819 --> 00:04:39.480
So that was an overview.

00:04:39.480 --> 00:04:44.520
Now, let's dive down and see how you
actually write one of those shaders.

00:04:44.519 --> 00:04:49.519
So there are two kinds of shaders as we have seen.

00:04:49.519 --> 00:04:52.689
There is the vertex shader and there is a fragment shader.

00:04:52.689 --> 00:04:57.879
Well, first we are going to look at the interface in the
overview of both the vertex shader and the fragment shader.

00:04:57.879 --> 00:05:02.379
Then we'll dive down into really
how you write this GLSL code.

00:05:02.379 --> 00:05:09.939
So the vertex shader, as I mentioned, replaces
existing OpenGL ES 1.1 fixed functionalities.

00:05:09.939 --> 00:05:15.329
So namely, the vertex shader is where you
compute your vertex and normal transformation.

00:05:15.329 --> 00:05:18.709
Where you go from model space into window space.

00:05:18.709 --> 00:05:24.199
This is also, where you do transformation on your fixture
coordinates, and you can pass those fixture coordinates

00:05:24.199 --> 00:05:28.389
to the fragment shader to start drawing things.

00:05:28.389 --> 00:05:33.680
This is also, where lighting equations are
implemented if you do textured effects lighting.

00:05:33.680 --> 00:05:38.160
But you can do way more things in
the texture since it's programmable.

00:05:38.160 --> 00:05:43.590
This is where you can distort geometry, as
you have seen in the first illustration.

00:05:43.589 --> 00:05:49.969
This is also, where you can do skinning easily
and many more effects that you can come up with

00:05:49.970 --> 00:05:52.600
What is the interface of the vertex shader?

00:05:52.600 --> 00:05:54.960
The vertex shader has two kinds of inputs.

00:05:54.959 --> 00:05:58.759
The first kind of inputs are called attributes.

00:05:58.759 --> 00:06:02.019
And attributes are specific to each vertex.

00:06:02.019 --> 00:06:05.779
These are the characteristics of each vertex in your model.

00:06:05.779 --> 00:06:10.769
So an example of attributes are the coordinates of
each of those vertexes in model space specifically.

00:06:10.769 --> 00:06:16.659
The normal to each of those vertex
tangents or whatever your model has.

00:06:16.660 --> 00:06:20.980
Now, there is another kind of inputs,
which are called Uniforms.

00:06:20.980 --> 00:06:28.220
And the reason why they're called Uniforms is
because their value is uniform throughout the model.

00:06:28.220 --> 00:06:31.910
So these are constant data as far as the model is concerned.

00:06:31.910 --> 00:06:34.439
An example of Uniforms that you may want to pass

00:06:34.439 --> 00:06:40.209
to the vertex shader are your matrix
transformation, your transformation matrices.

00:06:40.209 --> 00:06:49.000
The light coordinates, because the light is going to
be fixed for all the different vertexes in your model.

00:06:49.000 --> 00:06:54.639
So based on those inputs, the attributes and the Uniforms,
the vertex shader is going to compute a set of outputs.

00:06:54.639 --> 00:07:03.279
And the set of outputs of a vertex shader are called
varyings because they vary from one vertex to the other.

00:07:03.279 --> 00:07:08.089
The varyings are defined for each vertex,
and they get interpolated and passed

00:07:08.089 --> 00:07:10.989
to the fragment shader to be used in the fragment shader.

00:07:10.990 --> 00:07:17.220
So an example of outputs, the first one is the
position in window space of the specific vertice.

00:07:17.220 --> 00:07:22.100
Picture a coordinate that you want
to pass to the fragment shader.

00:07:22.100 --> 00:07:24.780
Colors, you name it.

00:07:24.779 --> 00:07:29.799
How does that look inside in the pipeline?

00:07:29.800 --> 00:07:30.990
Let's take a look.

00:07:30.990 --> 00:07:36.819
So we have our vertex shader that's
following the primitive processing block.

00:07:36.819 --> 00:07:42.139
So we receive a bunch of vertices and the vertex
shader is going to run on all of those vertices.

00:07:42.139 --> 00:07:45.719
We have a set of generic attributes coming into the vertex.

00:07:45.720 --> 00:07:52.210
So if you are finding out with writing shaders on Desktop
you will notice here that we only have generic attributes.

00:07:52.209 --> 00:07:54.859
There are no predefined attributes.

00:07:54.860 --> 00:07:57.069
Likewise, we have a set of Uniforms.

00:07:57.069 --> 00:07:58.529
They are all generic Uniforms.

00:07:58.529 --> 00:08:02.009
No predefined Uniforms in OpenGL ES 2.0.

00:08:02.009 --> 00:08:08.939
And based on those two inputs, the attributes and the
Uniforms, the vertex shader is going to write varyings.

00:08:08.939 --> 00:08:13.290
Again, there are a lot of generic varyings
that you can use for anything you want.

00:08:13.290 --> 00:08:17.240
Colors, texture coordinates, so on and so forth.

00:08:17.240 --> 00:08:19.680
There are two predefined varyings.

00:08:19.680 --> 00:08:21.230
The first one is GL position.

00:08:21.230 --> 00:08:26.700
This is a position in window space of
your vertex that's computed in the shader.

00:08:26.699 --> 00:08:32.069
If you are drawing points, you can also
set the point size in the vertex shader.

00:08:32.070 --> 00:08:35.010
You must always write to GL position.

00:08:35.009 --> 00:08:39.939
You must always set the position of your vertex so
that it can be used in the later stages of the pipeline

00:08:39.940 --> 00:08:43.510
so you can render something on the screen.

00:08:43.509 --> 00:08:45.980
Let's now look at the fragment shader.

00:08:45.980 --> 00:08:56.050
So the fragment shader also replaces existing fixed function
blocks in the fragment's processing units in OpenGL ES 1.1.

00:08:56.049 --> 00:08:58.659
So things you would do in a fragment shader?

00:08:58.659 --> 00:09:00.639
This is where you do your texture loading.

00:09:00.639 --> 00:09:03.179
This is where you can combine textures.

00:09:03.179 --> 00:09:05.599
This is where you can do your fog computation.

00:09:05.600 --> 00:09:09.240
This is where alpha testing happens
if you need alpha testing.

00:09:09.240 --> 00:09:10.330
But you can do a lot more things.

00:09:10.330 --> 00:09:11.650
Again, it's programmable.

00:09:11.649 --> 00:09:16.750
So this is where you could do per pixel
lighting, per pixek bitmapping.

00:09:16.750 --> 00:09:20.309
You can animate pixels.

00:09:20.309 --> 00:09:24.269
Anything you want.

00:09:24.269 --> 00:09:30.730
Again, the fragment shader has a set of inputs and
based on those inputs compute a set of outputs.

00:09:30.730 --> 00:09:33.509
The inputs are the varyings.

00:09:33.509 --> 00:09:36.870
The varyings are well defined in the vertex shader.

00:09:36.870 --> 00:09:42.820
They get interpolated in the rasterization
stage and passed to the fragment shader.

00:09:42.820 --> 00:09:45.670
So these are the inputs of your fragment shader.

00:09:45.669 --> 00:09:49.689
Example of such varyings are the positions,
the texture coordinates, the color.

00:09:49.690 --> 00:09:52.100
You know, whatever you put in those varyings.

00:09:52.100 --> 00:09:55.570
The other kind of input to your
fragment shader are also Uniforms.

00:09:55.570 --> 00:10:02.660
Uniforms that are going to be constant
throughout all the fragments in your model.

00:10:02.659 --> 00:10:04.279
So things you would pass here.

00:10:04.279 --> 00:10:09.709
Your fog characteristics, which
texture you need you want to load from.

00:10:09.710 --> 00:10:12.050
Any of those characteristics you want to pass in.

00:10:12.049 --> 00:10:16.529
Based on those inputs the fragment shader
is going to compute basically one output,

00:10:16.529 --> 00:10:22.120
which is the color for the pixel that
corresponds to the fragment on the screen.

00:10:22.120 --> 00:10:29.220
You also have the option to discard that
fragment so it doesn't get drawn on the screen.

00:10:29.220 --> 00:10:31.519
Well, how does that fit in the pipeline?

00:10:31.519 --> 00:10:38.210
The fragment shader follows the rasterization stage,
and this is where bearings are getting interpolated

00:10:38.210 --> 00:10:41.710
from the vertex shader to the fragment shader.

00:10:41.710 --> 00:10:49.139
There are all the generic varyings that you defined in
your vertex shader that can be read in the fragment shader.

00:10:49.139 --> 00:10:54.159
There are three predefined bearings
coming into the fragment shader.

00:10:54.159 --> 00:11:05.399
The first one is the fragment color, and then the
chosen ones are the facts whether or not the primitive

00:11:05.399 --> 00:11:09.689
to which the fragment belongs is
whether this primitive is pointing.

00:11:09.690 --> 00:11:15.070
Is FrontFacing or BackFacing, so this is in GL FrontFacing.

00:11:15.070 --> 00:11:21.250
And if you are drawing points, the point
coordinates within the points that you are drawing.

00:11:21.250 --> 00:11:23.730
The other sets of inputs are the Uniforms, right?

00:11:23.730 --> 00:11:25.139
There are Uniforms for all those.

00:11:25.139 --> 00:11:27.860
That are constant for all those fragments.

00:11:27.860 --> 00:11:31.919
And you can also load from multiple texture units.

00:11:31.919 --> 00:11:36.279
Based on all those inputs you can
compute the fragment color.

00:11:36.279 --> 00:11:42.539
And again, if you want to draw the pixel on the screen
if you don't discard it, you must write to FragColor.

00:11:43.950 --> 00:11:51.110
So we've seen the overview of what the fragment
shader and what the vertex shader does.

00:11:51.110 --> 00:11:54.610
And we've seen the interface, what's
coming in and out of those shaders.

00:11:54.610 --> 00:11:59.070
Let's now look at how we can actually
program one of those shaders.

00:11:59.070 --> 00:12:04.070
The way you program one of those shaders
is through a language called GLSL.

00:12:04.070 --> 00:12:06.750
The OpenGL shading language.

00:12:06.750 --> 00:12:09.659
And GLSL is select, you know.

00:12:09.659 --> 00:12:11.909
It has a main function, it's procedural.

00:12:11.909 --> 00:12:14.740
And you get it compiled and linked to run on the GPU.

00:12:14.740 --> 00:12:22.460
It doesn't have any of the kind of dynamic features
of scene, no pointers, no goto's, no recursions.

00:12:22.460 --> 00:12:25.040
It's just simple C code.

00:12:25.039 --> 00:12:29.539
But it has several extensions to
make it usable for graphics.

00:12:29.539 --> 00:12:35.120
And in the last few slides, I just want to highlight
some of the specific extensions or features of GLSL.

00:12:35.120 --> 00:12:38.440
But first, let's start with a very simple example.

00:12:38.440 --> 00:12:42.230
This is probably the C+ shader you can write.

00:12:42.230 --> 00:12:49.250
Here what I'm doing is I'm just writing a constant
color, white, to all the fragments in my model.

00:12:49.250 --> 00:12:55.549
And so if I have the good old teapot it's
going to be all white and flat on my screen.

00:12:55.549 --> 00:12:59.629
This is kind of the matching vertex shader.

00:12:59.629 --> 00:13:01.350
This could be even C probably.

00:13:01.350 --> 00:13:03.600
This is pretty simple and typical vertex shader.

00:13:03.600 --> 00:13:08.490
What we do here is we have two kinds of inputs.

00:13:08.490 --> 00:13:12.940
We have the attributes that corresponds to
the position of each vertex in my model.

00:13:12.940 --> 00:13:14.840
And then we have the Uniform.

00:13:14.840 --> 00:13:21.660
That's my model view projection
transform matrix that I'm going to use

00:13:21.659 --> 00:13:29.500
to transform those position coordinates
from model space into window space.

00:13:29.500 --> 00:13:35.690
And so in the main function all I do is I
multiply my 4x4 matrix model view project matrix

00:13:35.690 --> 00:13:38.370
by my for valued position vector.

00:13:38.370 --> 00:13:45.730
And I end up with the transformed position that
I passed as the following stages of the pipeline.

00:13:45.730 --> 00:13:48.269
So let's look at it in little bit more detail.

00:13:48.269 --> 00:13:55.889
First thing, you notice at the top are the inputs and
outputs definitions that are part of the global definitions.

00:13:55.889 --> 00:14:01.449
So you have a set of storage qualifier that
you can use to define those inputs and outputs.

00:14:01.450 --> 00:14:07.710
So you have the attributes of storage qualifier to
define, you know, your core vertex attribute inputs.

00:14:07.710 --> 00:14:12.889
The Uniform qualifier to define these other Uniforms
of the fragment shader or the vertex shader.

00:14:12.889 --> 00:14:17.149
The varying storage qualifier that's
used to define the outputs

00:14:17.149 --> 00:14:20.470
of your vertex shader and the input of your fragment shader.

00:14:20.470 --> 00:14:25.940
And if you have constants and you want to let the compiler
know that those variables are going to be constant

00:14:25.940 --> 00:14:32.310
and can be optimized, you can use
the const storage qualifier as well.

00:14:32.309 --> 00:14:33.829
Any language as datatypes.

00:14:33.830 --> 00:14:37.490
So GLSL has all the basic datatypes
that you're familiar with.

00:14:37.490 --> 00:14:40.129
Floats, integer, Boolean.

00:14:40.129 --> 00:14:41.179
It also has vectors.

00:14:41.179 --> 00:14:44.909
It can have two component, three
component, four component vectors.

00:14:44.909 --> 00:14:49.089
And they can be of type floats, integer, Boolean.

00:14:49.090 --> 00:14:53.780
GLSL ES has also square matrices that are always for input.

00:14:53.779 --> 00:14:59.279
So if on Desktop you have non-square
matrices here, we have only square matrices.

00:14:59.279 --> 00:15:03.679
All those datatypes are either
logical or arithmetic datatypes.

00:15:03.679 --> 00:15:07.649
So they have the usual operators that are defined for those.

00:15:07.649 --> 00:15:11.459
And what's interesting here is multiplier
operator all these different matrices.

00:15:11.460 --> 00:15:15.110
So you can use multiplier operator
to do matrix multiplication.

00:15:15.110 --> 00:15:17.639
You can use the multiplier operator to do a matrix

00:15:17.639 --> 00:15:22.470
by a vector multiplication, just
like we did in the original shader.

00:15:22.470 --> 00:15:27.560
Now also datatypes, such as the central datatype.

00:15:27.559 --> 00:15:36.449
The central datatype is used to pass in the information
about which textual unit you want to load from.

00:15:36.450 --> 00:15:44.180
And there are also standard datatypes, arrays,
structures, and you use them just like you would them in C.

00:15:44.179 --> 00:15:51.370
In addition to the operators I mentioned, GLSL
has also a wide variety of built-in functions.

00:15:51.370 --> 00:15:53.789
So here is a list.

00:15:53.789 --> 00:15:58.209
It's not complete, but it's already
quite a few, built-in functions of GLSL.

00:15:58.210 --> 00:16:01.129
I'm not going to go into details
on one of those but, you know,

00:16:01.129 --> 00:16:04.889
you can recognize your favorite
arithmetic built-in functions.

00:16:04.889 --> 00:16:09.389
You know, sine, cosine, power,
absolute value, so on and so forth.

00:16:09.389 --> 00:16:13.220
I want to highlight some that are specific to graphics.

00:16:13.220 --> 00:16:16.779
So if you have a vector you can
normalize it using the normalize function.

00:16:16.779 --> 00:16:23.259
If you want to implement reflection or refraction, you
have built-in functions to help you in your algorithm.

00:16:23.259 --> 00:16:26.870
You have specific functions to do your textual lookup.

00:16:26.870 --> 00:16:32.560
And we also support the derivative functions
that are part of an extension in GLSL.

00:16:32.559 --> 00:16:39.689
So you can do derivative in the
X dimension of the Y dimension.

00:16:39.690 --> 00:16:43.860
With all this, you can start writing more real shaders.

00:16:43.860 --> 00:16:49.100
So here is also a fairly simple
example that does textual mapping.

00:16:49.100 --> 00:16:50.040
Here is my vertex shader.

00:16:50.039 --> 00:16:53.449
It looks pretty much the same as the one I showed before.

00:16:53.450 --> 00:16:55.370
There is one more attribute we have here.

00:16:55.370 --> 00:16:59.500
It's the texture data that is part of my model.

00:16:59.500 --> 00:17:06.380
And in this case in the main body of the function we
are just passing that through to the fragment shader.

00:17:06.380 --> 00:17:13.390
I'm also outputting this textual coordinate as a
varying so that I can pass it to the fragment shader.

00:17:13.390 --> 00:17:17.870
And I have my usual, you know, position model view defined

00:17:17.869 --> 00:17:21.139
by the model view projection matrix
multiplied by the position.

00:17:21.140 --> 00:17:27.290
If you've seen shaders on Desktop you've probably
seen that people use ftransform everywhere.

00:17:27.289 --> 00:17:30.670
Well, ftransform was not part of
my initial building functions.

00:17:30.670 --> 00:17:35.620
So in GLSL ES you need to explicitly do your computation.

00:17:35.619 --> 00:17:40.349
This is part of the fact that we
don't have predefined Uniforms here.

00:17:40.349 --> 00:17:46.209
They are all generic Uniforms, so you just define
which model projection matrix you are going to use.

00:17:46.210 --> 00:17:50.880
So here we computed our texture coordinate
varying that gets passed to the fragment shader.

00:17:50.880 --> 00:17:55.070
And here in the fragment shader I'm
going to load from two different textures

00:17:55.069 --> 00:17:58.000
and just combine them by adding the colors.

00:17:58.000 --> 00:17:59.259
So I have 2D Uniforms.

00:17:59.259 --> 00:18:04.589
Texture1 and Texture2 that are defined as sample2D Uniforms.

00:18:04.589 --> 00:18:10.019
And I use the texture2D function to
load from those two textual units.

00:18:10.019 --> 00:18:15.950
And then I just simply add those two colors
and assign that to my fragment color output.

00:18:15.950 --> 00:18:20.819
If you look at this shader a little carefully you
will notice two things I haven't mentioned yet.

00:18:20.819 --> 00:18:22.789
Highp and lowp.

00:18:22.789 --> 00:18:28.210
These are GLSL ES specific precision type qualifier.

00:18:28.210 --> 00:18:31.100
Well, this is something that doesn't exist on Desktop.

00:18:31.099 --> 00:18:33.349
This is GLSL ES specific.

00:18:33.349 --> 00:18:45.509
And what they mean is that the way you use them is you
use them to specify to the compiler that the variables

00:18:45.509 --> 00:18:50.230
that you defined using those qualifiers
have a reduced precision.

00:18:50.230 --> 00:18:51.660
So you can use lowp.

00:18:51.660 --> 00:18:54.259
Low precision, medium precision, high precision.

00:18:54.259 --> 00:18:57.930
And these are just compiler hints to let
the compiler know about this limited range.

00:18:57.930 --> 00:19:03.830
So for example, if you add the color and you know
the color is not going to go out of the range -2 to 2

00:19:03.829 --> 00:19:12.159
and you only 8 bits of precision for that color, well,
you can use the lowp qualifier for that color variable.

00:19:12.160 --> 00:19:16.790
But what happens if you don't use any precision qualifier?

00:19:16.789 --> 00:19:20.509
Well, in your vertex shader you don't have to.

00:19:20.509 --> 00:19:22.129
This is defined for you.

00:19:22.130 --> 00:19:25.610
There is a predefined default precision,
which is high precision.

00:19:25.609 --> 00:19:28.509
So you don't need to worry about
precision in your vertex shader.

00:19:28.509 --> 00:19:30.420
This high precision.

00:19:30.420 --> 00:19:39.370
But the OpenGL ES specification leaves the default
precision in the fragment shader as undefined.

00:19:39.369 --> 00:19:46.669
As a result you must define a precision for all your
floating point variables in your fragment shader.

00:19:46.670 --> 00:19:52.950
But the way you do this is simply by adding one
statement typically at the top of your shader that says,

00:19:52.950 --> 00:19:59.590
my default precision in my shader is going to be,
in this case, high precision for all my floats.

00:19:59.589 --> 00:20:04.629
And then the rest of your shader can be just a generic
shader and you don't have to worry about precision.

00:20:04.630 --> 00:20:09.360
Notice that if you define a default
precision for float that applies to vectors,

00:20:09.359 --> 00:20:13.109
matrices, arrays, floats and so on and so forth.

00:20:13.109 --> 00:20:19.149
So putting this all together this is how, you
know, a typical fragment shader would look like.

00:20:19.150 --> 00:20:22.759
At the top you have your default, you know, precision setup.

00:20:22.759 --> 00:20:28.079
And in the rest of the program it's
a pretty much a generic shader here

00:20:28.079 --> 00:20:32.629
and we just use lowp here for colors, but you don't have to.

00:20:32.630 --> 00:20:38.190
So this gives you an idea of what a shader looks
like, so now you know how to write a shader.

00:20:38.190 --> 00:20:41.190
Express your computation, your
algorithm in one of those shaders.

00:20:41.190 --> 00:20:44.019
How do you actually use it inside your application?

00:20:44.019 --> 00:20:53.730
Well, the way you do that is, as I mentioned, you
have your fragment shader, your vertex shader.

00:20:53.730 --> 00:20:57.160
And they get compiled and linked into a program.

00:20:57.160 --> 00:21:03.360
And the way you do all this is
through the typical OpenGL APIs.

00:21:03.359 --> 00:21:08.609
So to compile a shader, like the vertex shader, the
first thing you do is you create a name for the shader.

00:21:08.609 --> 00:21:10.349
You create a shader object.

00:21:10.349 --> 00:21:15.649
Then you attach your source card to
that shader object you just created.

00:21:15.650 --> 00:21:17.519
Then you can compile your shader.

00:21:17.519 --> 00:21:19.039
Make sure the compilation has succeeded.

00:21:19.039 --> 00:21:21.889
You do the same for the fragment shader.

00:21:21.890 --> 00:21:26.090
Now you have both fragment and
object shader that are compiled.

00:21:26.089 --> 00:21:29.319
You can create your program.

00:21:29.319 --> 00:21:34.589
You attach the compiled vertex shader
and fragment shader to your program.

00:21:34.589 --> 00:21:40.609
Now that you have attached both compiled fragment
and vertex shaders you can link your program.

00:21:40.609 --> 00:21:42.399
Verify that link has succeeded.

00:21:42.400 --> 00:21:46.670
And then you can use the program and
start drawing things on the screen.

00:21:46.670 --> 00:21:50.759
This is something you want to do in this
initialization step of your application.

00:21:50.759 --> 00:21:54.940
You don't want to compile and link
your shaders while referring.

00:21:54.940 --> 00:21:59.710
This is part of the initialization part of your application.

00:22:01.269 --> 00:22:02.150
This is good.

00:22:02.150 --> 00:22:04.060
Now you have your program ready.

00:22:04.059 --> 00:22:08.190
But how do you actually set the inputs
so that something gets computed, right?

00:22:08.190 --> 00:22:14.830
So the way you do that is you set your attributes and
Uniform values, and typically you do that for every frame.

00:22:14.829 --> 00:22:20.899
If things move, Uniforms may change for every
frame or attributes may change for frames.

00:22:20.900 --> 00:22:29.730
And now a couple of things you want to do still in the
application, in the initialization of your application.

00:22:29.730 --> 00:22:37.529
After you link the program you want to query
the location of your attributes and Uniforms.

00:22:37.529 --> 00:22:44.039
And then in the main body of your application
after you selected which program you want to use,

00:22:44.039 --> 00:22:51.329
then you use the location that you just, you know,
queried in this initialization to set the Uniform values.

00:22:51.329 --> 00:22:53.839
Then you can set all sorts of attribute values.

00:22:53.839 --> 00:22:57.980
And then you draw things on your screen.

00:22:57.980 --> 00:23:04.920
So that's pretty much all the steps that
are involved to create and run the shader.

00:23:04.920 --> 00:23:09.009
So with that, let's go to the demo
machine and actually see how it looks.

00:23:09.009 --> 00:23:14.069
[ Silence ]

00:23:14.069 --> 00:23:19.139
So here what I have is a simple Xcode
project that's basically the template.

00:23:19.140 --> 00:23:25.880
If you have used OpenGL ES 1.1 over the last
year, you probably have seen this template.

00:23:25.880 --> 00:23:28.710
And you can find the usual files here.

00:23:28.710 --> 00:23:35.870
The one thing I changed here is instead of using
OpenGL ES 1.1, I switched to OpenGL ES 2.0.

00:23:35.869 --> 00:23:45.239
So let's go and look at where we initialized our
GL context and see how we compile and link things.

00:23:45.240 --> 00:23:49.049
So I'm jumping to the function in it with color.

00:23:49.049 --> 00:23:52.049
This is where GL is being initialized.

00:23:52.049 --> 00:23:59.579
And if we scroll down a little bit we can see
that here I am creating my OpenGL ES 2.0 context.

00:23:59.579 --> 00:24:02.679
Make sure that the context gets created.

00:24:02.680 --> 00:24:10.430
If I'm on one of the iPhone 3G or
iPod Touch, then this would fail.

00:24:10.430 --> 00:24:14.840
Then the next thing I do is I call
the function that's going to compile

00:24:14.839 --> 00:24:20.349
and link my shaders, so let's jump into that function.

00:24:20.349 --> 00:24:25.629
This function is using a separate
function that does the compilation part,

00:24:25.630 --> 00:24:28.160
so let's look at the compilation part first.

00:24:28.160 --> 00:24:31.009
That's the function compile shader here.

00:24:31.009 --> 00:24:39.200
So what I do here is for the vertex shader and the
fragment shader here I'm creating the shader object.

00:24:39.200 --> 00:24:41.049
I get a name.

00:24:41.049 --> 00:24:46.690
Then I attach the source code for that shader that
was initially stored in a file that I'm reading.

00:24:46.690 --> 00:24:48.920
Then I can compile my shader.

00:24:48.920 --> 00:24:58.150
And then for debugging, say if I did the syntax there in
my shader or any other error, I need to check the info log

00:24:58.150 --> 00:25:02.240
because this is where all the warnings
and errors are being stored.

00:25:02.240 --> 00:25:06.049
So in this log here I'm dumping all this onto the console.

00:25:06.049 --> 00:25:11.289
And this works both in the simulator and on the device.

00:25:11.289 --> 00:25:14.450
After I checked and printed those
error and warnings messages,

00:25:14.450 --> 00:25:18.390
I make sure that the compilation has
succeeded by checking the compilation status.

00:25:18.390 --> 00:25:21.509
And then I return my shader.

00:25:21.509 --> 00:25:26.220
Now in my main compilation and linking
function, you can see that, you know,

00:25:26.220 --> 00:25:29.269
I compiled both the vertex shader and the fragment shader.

00:25:29.269 --> 00:25:30.869
Now I can create the program.

00:25:30.869 --> 00:25:33.529
The way I do that is I create the program.

00:25:33.529 --> 00:25:36.609
I attach the two shaders, vertex and fragment shaders.

00:25:36.609 --> 00:25:44.740
And in this case here I am buying my
attributes, and then I link the program.

00:25:44.740 --> 00:25:46.240
Same thing here for debugging.

00:25:46.240 --> 00:25:48.400
I want to print my error and warning messages.

00:25:48.400 --> 00:25:51.240
This is what I do here by checking the info log.

00:25:51.240 --> 00:25:56.319
And I make sure that linking succeeded.

00:25:56.319 --> 00:26:00.480
Then I can query the Uniform locations
that I had in my model.

00:26:00.480 --> 00:26:06.640
And I'm going to use this later in the main loop
to set both the attributes and the Uniforms.

00:26:06.640 --> 00:26:08.580
Then I can use the program.

00:26:08.579 --> 00:26:13.809
So let's take a look at in the simulator how this looks.

00:26:13.809 --> 00:26:15.099
So here we go.

00:26:15.099 --> 00:26:18.359
This looks pretty much like the simplest
shader I showed you before, right?

00:26:18.359 --> 00:26:21.539
Here we have the good old teapot, flat color.

00:26:21.539 --> 00:26:24.029
Let's make it more interesting.

00:26:24.029 --> 00:26:28.680
So here I'm bringing up the source code
for most of my vertex and fragment shader.

00:26:28.680 --> 00:26:30.049
Let's start with the vertex shader.

00:26:30.049 --> 00:26:39.629
What I'm doing here is just computing the position based on
the model view projection matrix multiplied by the position.

00:26:39.630 --> 00:26:43.930
Let's add some lighting to this.

00:26:43.930 --> 00:26:48.400
So I already set up the input so
I can compute lighting here.

00:26:48.400 --> 00:26:52.240
And the way I compute lighting is I
take the normal attributes that I have

00:26:52.240 --> 00:26:56.000
in my model, and I have the light direction.

00:26:56.000 --> 00:26:57.859
And here what I am doing is just to use lighting.

00:26:57.859 --> 00:26:59.019
Some very, very simple lighting.

00:26:59.019 --> 00:27:04.349
And I just do the dot products of the normal
for the vertex with the light's direction.

00:27:04.349 --> 00:27:07.779
That's Uniform because the light
is not changing for every vertex.

00:27:07.779 --> 00:27:10.220
And if both align then I want to make things brighter.

00:27:10.220 --> 00:27:14.190
And if they are in opposite directions I make things darker.

00:27:14.190 --> 00:27:22.289
So I just compute the dot product here, and I assign this
to the light bearing and pass this to the fragment shader.

00:27:22.289 --> 00:27:28.659
While I'm there I'm also going to pass the
pixel coordinates to my fragment shader.

00:27:28.660 --> 00:27:31.880
Let's now look at the fragment shader.

00:27:31.880 --> 00:27:38.700
Here in the main body of the code we can see that
we set the color to a constant value, yellow.

00:27:38.700 --> 00:27:41.500
So this is why everything is yellow.

00:27:41.500 --> 00:27:43.769
Let's now use lighting.

00:27:43.769 --> 00:27:52.379
And the way we do that is we just modulate the light,
the color, by the light component that I just computed.

00:27:52.380 --> 00:27:57.300
Let's run that and make sure the lighting works right.

00:27:57.299 --> 00:27:59.399
So I can check that it's lit properly.

00:27:59.400 --> 00:28:02.620
In animated, it works fine.

00:28:02.619 --> 00:28:05.409
Let's make it a little more interesting.

00:28:05.410 --> 00:28:10.950
You know, as I said, you know, you can
do texture loads in your fragment shader,

00:28:10.950 --> 00:28:15.460
so let's use those texture coordinates
and do some texture loads here.

00:28:15.460 --> 00:28:22.850
So I have a Uniform coming in that tells from
which texture I want to load my data from,

00:28:22.849 --> 00:28:28.369
and I just use my texture coordinates
to load the color for that fragment.

00:28:28.369 --> 00:28:34.529
And then to make it slightly more interesting
I use that color and use that color to lookup

00:28:34.529 --> 00:28:37.180
into a palette to make things more colorful.

00:28:37.180 --> 00:28:40.950
And that's going to be my final color.

00:28:40.950 --> 00:28:42.740
So let's run this.

00:28:42.740 --> 00:28:50.650
And now we have our little teapot
that also has a texture on that to it.

00:28:50.650 --> 00:28:59.040
And I can also, in this case, I passed in a Uniform
so that I can animate the way I look up in my textures.

00:28:59.039 --> 00:29:00.119
So this is a little plasma effect.

00:29:00.119 --> 00:29:04.029
I can use this to do also some simple water effects.

00:29:04.029 --> 00:29:12.410
Also effects that you would see in the second session.

00:29:12.410 --> 00:29:17.080
So with this, you know, I'd like
to hand it over to Alex who's going

00:29:17.079 --> 00:29:20.949
to show you more interesting rendering techniques.

00:29:20.950 --> 00:29:25.029
>> OK. So, so far you've seen an
overview of the OpenGL ES pipeline.

00:29:25.029 --> 00:29:29.210
And Luc gave you an overview of GLSL, the shading language.

00:29:29.210 --> 00:29:30.890
What it is.

00:29:30.890 --> 00:29:31.740
What you can do with it.

00:29:31.740 --> 00:29:32.960
And how it works.

00:29:32.960 --> 00:29:38.170
Now, for the rest of the session I'm going to be
talking about some advanced rendering techniques.

00:29:38.170 --> 00:29:42.779
How you construct and use all this information to
make some pretty pictures show up on the screen.

00:29:42.779 --> 00:29:46.899
And I'll be touching on a couple of different
topics here, starting with some 3D effects.s=tylY

00:29:46.900 --> 00:29:50.019
Then I'll talk a little bit about 2D and image processing.

00:29:50.019 --> 00:29:54.109
And finally I'll wrap up by combining 2D and 3D together.

00:29:54.109 --> 00:30:01.129
And I'll be talking about how to achieve these
rendering techniques and effects in both ES1 and ES2.

00:30:01.130 --> 00:30:09.470
Now, that's because, as you heard on the keynote on Monday,
there are now 40 million iPhones and iPod Touches out there.

00:30:09.470 --> 00:30:13.710
That's a very large installed customer
base, so this device is running ES1.1.

00:30:13.710 --> 00:30:16.289
And that number is still growing.

00:30:16.289 --> 00:30:23.710
We are still selling iPhone 3Gs and the new
iPhone 3GS supports both ES1.1 and ES2.0.

00:30:23.710 --> 00:30:27.840
So we think that ES1.1 is still important
and relevant to your application.

00:30:27.839 --> 00:30:34.579
And as we'll see a lot of these effects
can be done in both ES1 and ES2.

00:30:34.579 --> 00:30:37.109
But why are we talking about this at all today here?

00:30:37.109 --> 00:30:39.479
Why do we care about rendering techniques?

00:30:39.480 --> 00:30:41.299
Well, it's a pretty simple answer.

00:30:41.299 --> 00:30:46.089
We just want you to make your application
look as best as it possibly can.

00:30:46.089 --> 00:30:50.179
OpenGL is about more than just
drawing flat textured quasma screen.

00:30:50.180 --> 00:30:53.029
There's a lot of depth and functionality in this API.

00:30:53.029 --> 00:30:57.789
And there's a lot of silicone there
in the GPU waiting for you to use it.

00:30:57.789 --> 00:31:04.879
So we want you to use that hardware acceleration to its
fullest, and make your gaming application look really great.

00:31:04.880 --> 00:31:09.950
Now, in a little more detail OpenGL
provides multiple attributes to you,

00:31:09.950 --> 00:31:12.150
and you can combine these in different ways.

00:31:12.150 --> 00:31:14.720
You can also use multiple texture simultaneously.

00:31:14.720 --> 00:31:18.089
And a really key point to achieving a
lot of these effects is learning how

00:31:18.089 --> 00:31:21.809
to combine textures together in interesting combinations.

00:31:21.809 --> 00:31:29.069
In ES1 that means using APF features like the Texture
Matrix, or the Texture Environment combine modes.

00:31:29.069 --> 00:31:32.339
In ES2 of course you're going to use
program mover or text and fragment shooters.

00:31:32.339 --> 00:31:35.089
We can do all these things and a lot more.

00:31:36.170 --> 00:31:40.080
Now, to give you an idea about
what type of effects we're talking

00:31:40.079 --> 00:31:43.009
about let's go to the iPhone and look at a live demo.

00:31:43.009 --> 00:31:54.329
[ Silence ]

00:31:54.329 --> 00:31:58.609
Now, here you can see I had a pretty good looking 3D scene.

00:31:58.609 --> 00:32:01.359
What are we looking at specifically here?

00:32:01.359 --> 00:32:08.750
Well, I have an interactive 3D skybox, and I have
an anti alias good looking tesilated model here

00:32:08.750 --> 00:32:12.980
that I can interact with and zoom in and out.

00:32:12.980 --> 00:32:17.940
And you notice, if you look at this carefully, that
the object is reflecting the environment around it.

00:32:17.940 --> 00:32:20.220
It's not just a flat textured object.

00:32:20.220 --> 00:32:24.180
The object is responding to the
environment, and it's not just the reflection.

00:32:24.180 --> 00:32:27.430
There's actually a little bit of
dynamic part to this reflection,

00:32:27.430 --> 00:32:31.660
so it reflects around differently
when you put in how it's oriented.

00:32:31.660 --> 00:32:38.230
So this effect is an environ map using a fresnel term
that dynamically changed how the environment is reflected.

00:32:38.230 --> 00:32:42.370
This is an example of the type of effect
we're going to build up today step by step.

00:32:42.369 --> 00:32:47.879
And you can do these effects in
both ES2 using shaders and in ES1.1.

00:32:47.880 --> 00:32:51.210
Now, there are several other effects built into this demo.

00:32:51.210 --> 00:32:55.120
Just to give you a brief look at the
type of effects we're talking about,

00:32:55.119 --> 00:32:57.659
I want to go through a couple of them quickly.

00:32:57.660 --> 00:32:59.670
This effect has a couple models also.

00:32:59.670 --> 00:33:06.539
If you like car games here's how
that same thing looks on a car.

00:33:06.539 --> 00:33:13.109
And just to give you an idea, that fresnel term by
itself kind of gives you this edge highlighting effect

00:33:13.109 --> 00:33:17.849
so we see the edges are lighter than
the middle of the body of the car.

00:33:17.849 --> 00:33:23.129
If you combine that with some lighting we're going to get a
couple interesting backlighting and room lighting effects.

00:33:23.130 --> 00:33:26.310
Or we could use that fresnel term
for different purposes like blending.

00:33:26.309 --> 00:33:29.950
And we can make some interesting actually budding effects,

00:33:29.950 --> 00:33:36.230
which may change interactively to
achieve a variety of blending styles.

00:33:36.230 --> 00:33:39.279
Or a couple other ideas for effects here.

00:33:39.279 --> 00:33:43.750
We could do some none photorealistic
renderings such as toon shading.

00:33:43.750 --> 00:33:47.150
Again, this can be done with hardware
acceleration in ES2 and in ES1.

00:33:47.150 --> 00:33:53.350
For a more complicated version of this you
could do some anisotropic lighting effects

00:33:53.349 --> 00:33:56.730
and maybe I'll show the good old teapot here again.

00:33:56.730 --> 00:34:01.420
You can see you can get a kind of
nice looking brushed metal effect.

00:34:01.420 --> 00:34:05.460
So this is just a very quick overview of the
effects we'll be talking about in this session.

00:34:05.460 --> 00:34:08.090
I'll go back to the slides.

00:34:11.909 --> 00:34:17.079
Now hopefully you're asking yourself
how can I do that in my application?

00:34:17.079 --> 00:34:18.369
And let's be honest here.

00:34:18.369 --> 00:34:21.179
The first step is to learn OpenGL.

00:34:22.309 --> 00:34:25.750
To do these kinds of advanced rendering
techniques you're going to have to learn OpenGL

00:34:25.750 --> 00:34:27.710
and get comfortable with these in the pipeline.

00:34:27.710 --> 00:34:32.840
Now we don't have time to teach you everything about
OpenGL in this session, but I want to point out a couple

00:34:32.840 --> 00:34:37.990
of those hidden knobs and switches in the pipeline to
show you how you can start taking control of the pipeline

00:34:37.989 --> 00:34:40.359
and make these kinds of interesting effects.

00:34:40.360 --> 00:34:46.269
We'll also be looking at an example of how you can
redefine your problem, or your rendering technique,

00:34:46.269 --> 00:34:50.989
in terms that your OpenGL API can understand,
and the hardware can conceal and accelerate.

00:34:50.989 --> 00:34:54.359
In ES1, again that means using
texture coordinates and features

00:34:54.360 --> 00:34:57.710
like the texture matrix and the
texture environment combiners.

00:34:57.710 --> 00:35:00.849
In ES2 the same thing can all be done with shaders.

00:35:00.849 --> 00:35:06.940
We'll also be looking at breaking complicated effects
into multiple pieces using multipass and rendered texture.

00:35:06.940 --> 00:35:11.460
So let's get started looking at the pipeline.

00:35:11.460 --> 00:35:14.289
Now you've already seen today an overview of the pipeline.

00:35:14.289 --> 00:35:17.579
I want to go into just a little
more detail in a couple key parts.

00:35:17.579 --> 00:35:20.759
In each part I'll show you how
the pipeline is typically used,

00:35:20.760 --> 00:35:24.200
and how you can modify the behavior a little
bit to get some more flexibility out of it.

00:35:24.199 --> 00:35:31.339
So starting with vertex attributes here, anytime you
draw something with OpenGL you're defining a bunch

00:35:31.340 --> 00:35:33.730
of data that OpenGL is going to transform.

00:35:33.730 --> 00:35:35.320
Those are the vertex attributes.

00:35:35.320 --> 00:35:38.700
Things like the position and the
color and the normal and so on.

00:35:38.699 --> 00:35:42.809
And there are a lot of ways that you could lay
out that data for OpenGL to consume.

00:35:42.809 --> 00:35:46.029
But here's a diagram of a pretty typical way a bunch

00:35:46.030 --> 00:35:49.330
of different attributes can live
in a single vertex buffer object.

00:35:49.329 --> 00:35:53.590
Now you can see the attributes here on
things like the XYZ position, the normal.

00:35:53.590 --> 00:35:57.120
Maybe there's a texture coordinate ST or a per vertex color.

00:35:57.119 --> 00:36:03.639
And when you want to tell OpenGL to use this data,
you first tell it what the data is and where it is.

00:36:03.639 --> 00:36:07.759
With these APIs like VertexPointer or
TexCord Pointer, you point GL to the data

00:36:07.760 --> 00:36:11.010
and you say it's 2 floats or 2 bytes or whatever it is.

00:36:11.010 --> 00:36:15.290
And then you call draw erase or draw
elements and that kicks off the pipeline,

00:36:15.289 --> 00:36:20.829
pushing this data into the transformation
stage so the OpenGL starts processing it.

00:36:20.829 --> 00:36:22.360
So that's the next stage.

00:36:22.360 --> 00:36:23.230
Vertex transformation.

00:36:23.230 --> 00:36:31.289
Now again, this is a pretty standard overview of the
pipeline here where the positions are coming in on the left,

00:36:31.289 --> 00:36:35.659
and they're transformed through a series of
spaces, eye space and clip space and so forth.

00:36:35.659 --> 00:36:39.129
Finally ending up in window coordinates.

00:36:39.130 --> 00:36:45.210
And I want to point out here that your inputs into this, the
way that you can control this pipeline, are these matrices.

00:36:45.210 --> 00:36:47.360
The modelview matrix and the projection matrix.

00:36:47.360 --> 00:36:50.309
This is your control to tell OpenGL
how to transform the data.

00:36:50.309 --> 00:36:52.460
To scale it or rotate it or project it.

00:36:52.460 --> 00:36:56.110
How do you want to change the data so it shows
up on the screen directly for your application?

00:36:56.110 --> 00:36:59.680
You're probably all familiar with this
already, but I'll point out another part

00:36:59.679 --> 00:37:02.049
of this that you may not have used before.

00:37:02.050 --> 00:37:04.640
We also have texture matrices.

00:37:04.639 --> 00:37:09.400
The hardware has multiple texture units, and each
of those units has a matrix associated with it

00:37:09.400 --> 00:37:11.639
which works just like the other matrices.

00:37:11.639 --> 00:37:15.859
Except that instead of transforming the position
data, it transforms the texture coordinates coming in.

00:37:15.860 --> 00:37:17.079
And they work just the same way.

00:37:17.079 --> 00:37:20.110
You can do the same transformations
like scale or rotate or projection.

00:37:20.110 --> 00:37:23.590
Anything you can do with a 4x4 matrix.

00:37:23.590 --> 00:37:27.200
As we'll see this is extremely useful
for influencing and addressing effects.

00:37:27.199 --> 00:37:31.489
The first is just a little thought
experiment for you to think about.

00:37:31.489 --> 00:37:32.509
You'll probably recognize this.

00:37:32.510 --> 00:37:37.230
This is the Touch Fighter application that we
showed a year ago with the iPhone SDK 2.0 launch.

00:37:37.230 --> 00:37:43.119
And if we remember you're flying around this 3D
planet while you're battling these aliens in space.

00:37:43.119 --> 00:37:46.480
Now that planet is defined with some 3D geometry.

00:37:46.480 --> 00:37:47.780
It's a sphere.

00:37:47.780 --> 00:37:51.350
And as the game plays the planet is rotating towards you.

00:37:51.349 --> 00:37:56.119
By rotating those positions by the modelview matrix.

00:37:56.119 --> 00:38:01.519
Now if you think about it, you could achieve the
same type of effect by using the texture matrix.

00:38:01.519 --> 00:38:05.559
Instead of rotating the position if
you leave the positions where they are,

00:38:05.559 --> 00:38:08.869
and instead rotate the texture
coordinates around the geometry.

00:38:08.869 --> 00:38:14.250
It's exactly the same rotational transform what you do
on the textual matrix instead of the modelview matrix.

00:38:14.250 --> 00:38:15.940
Now why would you want to do that?

00:38:15.940 --> 00:38:18.840
Well, it depends on your application.

00:38:18.840 --> 00:38:23.150
But here you can see that you can't
see all the planet at the same time.

00:38:23.150 --> 00:38:26.300
If you're never rotating it you're
never going to see the back part of it.

00:38:26.300 --> 00:38:30.110
And in fact, in this picture you're never
going to see the bottom half of it either.

00:38:30.110 --> 00:38:33.700
So maybe you can get away with defining less geometry.

00:38:33.699 --> 00:38:38.389
If these are texture matrices this way
you could save yourself some video memory,

00:38:38.389 --> 00:38:43.289
and you could save yourself some transform costs because you
have less vertices to push into the pipeline to transform.

00:38:43.289 --> 00:38:46.320
So there's a simple example.

00:38:46.320 --> 00:38:50.120
And now we've talked about basically
all of the vertex transformation stage.

00:38:50.119 --> 00:38:52.329
Finding attributes and transforming them.

00:38:52.329 --> 00:38:56.559
So that takes us to the fragment part of the pipeline.

00:38:56.559 --> 00:39:06.559
Now Luc showed you how ES2 has a really flexible
fragment pipeline with the programmable power of GLSL.

00:39:06.559 --> 00:39:11.690
In ES1, you're a little more constrained to what you can do.

00:39:11.690 --> 00:39:16.179
And the fragment pipeline is really
defined in terms of texture combiners.

00:39:16.179 --> 00:39:20.079
So here's a diagram showing you what
type of things you can do there.

00:39:20.079 --> 00:39:24.400
You have a couple of inputs coming in which
are things like the primary vertex color.

00:39:24.400 --> 00:39:28.039
That's the lit color that was processing the vertex stage.

00:39:28.039 --> 00:39:32.110
You also have textures coming in that
you're sampling from on the current unit.

00:39:32.110 --> 00:39:36.000
And with those inputs you can do some
very simple math operations like modulate.

00:39:36.000 --> 00:39:39.550
That's a multiply or an add or a subtract.

00:39:39.550 --> 00:39:44.330
And a couple of other simple operations like interpolate
or dot product which are really just multiplies

00:39:44.329 --> 00:39:47.279
and adds combined into a single operator.

00:39:47.280 --> 00:39:53.930
After these operations are done, you can additionally scale
the result by 1 or 2 or 4, which gives you a little bit

00:39:53.929 --> 00:39:55.659
of extra flexibility for creating effects.

00:39:55.659 --> 00:40:02.639
And I want to point out here that the color data
that you're working with is all clamped to [0, 1].

00:40:02.639 --> 00:40:06.889
So that's both this vertex color and the texture color.

00:40:06.889 --> 00:40:11.029
This can be a little problematic for some effects
which seem to work with a wider range of data.

00:40:11.030 --> 00:40:15.130
But in the 2D section of this talk I'll
show you a way how to get around that.

00:40:15.130 --> 00:40:21.550
And I also want to point out here that again
the hardware has multiple texture units.

00:40:21.550 --> 00:40:27.300
So you can combine these texture environments together
to create more interesting complicated effects.

00:40:27.300 --> 00:40:31.200
For example in the first unit you might do a
multiply between the primary color and the texture.

00:40:31.199 --> 00:40:34.679
In the second unit do an add from a different texture.

00:40:34.679 --> 00:40:36.879
For example, add a highlight.

00:40:37.969 --> 00:40:40.869
Now the number of texture units depends
on the hardware you're running on.

00:40:40.869 --> 00:40:43.480
On the MBX base devices you have 2 units.

00:40:43.480 --> 00:40:47.050
And on the new iPhone 3GS you have 8 units available.

00:40:47.050 --> 00:40:52.190
This kind of limit is a thing that you can query out
of OpenGL dynamically at run time in your application

00:40:52.190 --> 00:40:55.059
so you can be sure that your algorithm
will work in available hardware.

00:40:55.059 --> 00:41:01.570
Now what happens if your algorithm doesn't
fit in the units that are available?

00:41:01.570 --> 00:41:04.980
You query it and you find you have 2
and that's not enough for your effect.

00:41:04.980 --> 00:41:09.929
Well, you can break your algorithm down into
smaller pieces using multipass rendering.

00:41:09.929 --> 00:41:15.230
There are a couple of ways to do this, but
a simple way is simply render the first part

00:41:15.230 --> 00:41:18.139
of your effect to the framebuffer normally.

00:41:18.139 --> 00:41:20.199
Then in the second pass change the state you're using.

00:41:20.199 --> 00:41:23.659
Maybe use different textures, different
combiners, and render the second half

00:41:23.659 --> 00:41:26.969
of the effect using blending to add
the result into the framebuffer.

00:41:26.969 --> 00:41:31.579
Drawing the same object for the same position,
but with different state and blending turned on.

00:41:31.579 --> 00:41:36.759
It's a pretty simple trick, but it
works in built-up complicated effects.

00:41:36.760 --> 00:41:40.440
Another similar approach is to use render to texture.

00:41:40.440 --> 00:41:44.240
Here is the same idea, except instead of
rendering the first pass to a framebuffer directly,

00:41:44.239 --> 00:41:48.329
you create a temporary texture to
capture the intermediate results.

00:41:48.329 --> 00:41:53.929
And that texture can then be fed into second or possibly
multiple additional passes to build up more parts

00:41:53.929 --> 00:41:56.500
of the effect or do post
processing or image filtering.

00:41:56.500 --> 00:42:00.440
And the final result is drawn back to the real framebuffer.

00:42:03.929 --> 00:42:07.179
So that's the points I wanted to touch on the pipeline.

00:42:07.179 --> 00:42:09.529
Just a bit of summary there comparing ES1 and 2.

00:42:09.530 --> 00:42:13.660
In ES1 you only have a couple of
attributes available to you.

00:42:13.659 --> 00:42:18.279
Things like the normal and the
toucher coordinate and the positions.

00:42:18.280 --> 00:42:22.810
And the transformations you can do on those are
fairly limited because it's a fixed function pipeline.

00:42:22.809 --> 00:42:26.769
Although I showed you how to use a texture matrix
to get a little more flexibility out of it.

00:42:26.769 --> 00:42:32.759
And again in the final stage you're pretty limited in what
you can do because you only have simple math operators.

00:42:32.760 --> 00:42:38.880
But there's a very large number of ways that you can combine
those operators together to create interesting effects.

00:42:38.880 --> 00:42:43.059
And because there's only a couple of texture
units available on the MBX based devices,

00:42:43.059 --> 00:42:47.230
you often have to break rendering
techniques into multiple passes.

00:42:47.230 --> 00:42:49.960
By comparison, in ES2 you have a lot more flexibility.

00:42:49.960 --> 00:42:55.840
You have more attributes available and they're completely
generic for you to define and use it anyway that you want.

00:42:55.840 --> 00:43:00.530
You also have the full power of GLSL, the
programmable vertex and fragment shaders.

00:43:00.530 --> 00:43:06.060
So you can do all of the things you
did in ES1 plus a whole lot more.

00:43:06.059 --> 00:43:10.659
Now let's use all the information I just described
to build up one of these effects step by step.

00:43:10.659 --> 00:43:15.049
And we'll look at that environment map sample
that I just showed you at the beginning.

00:43:15.050 --> 00:43:22.430
So let's start out by making a completely reflective object,
and then we'll improve the technique a little bit to add

00:43:22.429 --> 00:43:26.019
that fresnel term and make it look a little more realistic.

00:43:26.019 --> 00:43:33.539
Now the concept behind this kind of technique
is that we have a 3D model which= has a bunch

00:43:33.539 --> 00:43:37.440
of attributes defined for a vertex like such as the normal.

00:43:37.440 --> 00:43:41.179
What you can see here the normals are pointing
out in all directions from this model.

00:43:41.179 --> 00:43:46.369
We also have a texture which in this case contains
a spherical projection of the environment,

00:43:46.369 --> 00:43:49.029
as if you are looking around the
scene from the center of this object.

00:43:49.030 --> 00:43:57.210
Now the basic idea is that we want to take the normal in
one of those vertices, and use it as a texture coordinate.

00:43:57.210 --> 00:44:03.659
And to do that the normal will be transformed and
projected into 2D space to lie on this texture.

00:44:03.659 --> 00:44:08.609
Wherever that projected point lines up on the texture
we'll use that color for that vertex of the model.

00:44:08.610 --> 00:44:15.309
And if we do that for all the vertices it ends up looking
like the object is reflecting the environment around it.

00:44:15.309 --> 00:44:19.059
Now here's how you can achieve that in ES2 using the shader.

00:44:19.059 --> 00:44:20.380
So for starters the vertex shader.

00:44:20.380 --> 00:44:26.400
Now you can see at the top there I have an
attribute coming in which is the normal.

00:44:26.400 --> 00:44:30.539
I also have a Uniform defined which
is that environment matrix.

00:44:30.539 --> 00:44:35.050
Now this matrix is calculated by the
application during every framed animation

00:44:35.050 --> 00:44:38.269
to match the current rotation of the
object as its being moved around.

00:44:38.269 --> 00:44:42.539
That way the normals are transformed the
same way that the object is rotating.

00:44:42.539 --> 00:44:45.119
And the body of the shader you can is pretty simple.

00:44:45.119 --> 00:44:48.859
The first line of code is simply using
that matrix to transform the normal,

00:44:48.860 --> 00:44:53.039
and it's passing it out as a texture
coordinate to be used in the fragment stage.

00:44:53.039 --> 00:44:54.599
The rest of this is very trivial.

00:44:54.599 --> 00:44:58.759
It's simply passing through the vertex
color that was defined in the model.

00:44:58.760 --> 00:45:05.440
And it's doing the standard transformation on the
position to go through eye space and clip space.

00:45:05.440 --> 00:45:07.829
Here's the fragment shader.

00:45:07.829 --> 00:45:12.210
Now start out with the model is completely
reflective, so this is very simple.

00:45:12.210 --> 00:45:16.490
You have the texture coordinate coming in which is
just computed in the vertex shader.

00:45:16.489 --> 00:45:20.500
And you can see that I used the texture sheeting function
to look up that environment color in the texture,

00:45:20.500 --> 00:45:23.449
and I simply assign it to the output and I'm done.

00:45:23.449 --> 00:45:27.409
The entire model is reflected using an environment map.

00:45:27.409 --> 00:45:30.349
Now the slight improvement on this is to add a fresnel term.

00:45:30.349 --> 00:45:37.989
In this case I'm using the mix function which is built
into GLSL to interpolate between that environment color

00:45:37.989 --> 00:45:40.509
and the original vertex color of the model.

00:45:40.510 --> 00:45:45.280
And I interpolate in here by the alpha
channel of the texture that I just looked up.

00:45:45.280 --> 00:45:49.350
In this case the application has repaired
the alpha channel with the fresnel term,

00:45:49.349 --> 00:45:52.860
which is simply a gradient ramp
that falls off from black to white.

00:45:52.860 --> 00:45:57.829
So that's how you can achieve this
kind of effect in ES2 using shaders.

00:45:57.829 --> 00:45:59.509
You can do the same thing in ES1.

00:45:59.510 --> 00:46:02.240
Just a little trickier.

00:46:02.239 --> 00:46:08.539
So going back to this partially the pipeline
that I touched on look at the vertex attributes.

00:46:08.539 --> 00:46:12.380
Now normally when you have texture
coordinates you tell OpenGL

00:46:12.380 --> 00:46:15.700
to point the texture coordinate pointer
at that texture coordinate data.

00:46:15.699 --> 00:46:17.579
Now here's a trick.

00:46:17.579 --> 00:46:19.829
Don't do that.

00:46:19.829 --> 00:46:25.179
Instead, point texture coordinate pointer at the
normals which are already defined in your vertex data.

00:46:25.179 --> 00:46:28.859
Now those normals can be treated
as if they were texture coordinates

00:46:28.860 --> 00:46:32.960
and you can transform them by the texture matrix.

00:46:32.960 --> 00:46:35.730
So here's the texture matrix stage.

00:46:35.730 --> 00:46:39.510
And the idea here is that the normals
were defined in unit space

00:46:39.510 --> 00:46:42.730
so their 3D normal is pointing in
all directions on the unit's sphere.

00:46:42.730 --> 00:46:48.490
The first thing that's going to happen to this is
they're going to be rotated by the modelview matrix,

00:46:48.489 --> 00:46:53.199
so the thing matched the orientation of the
object for the current frame of animation.

00:46:53.199 --> 00:46:59.569
Additionally we need to scale and bias that normal
data to fit in the range 0 to 1 so that we can use it

00:46:59.570 --> 00:47:02.880
as a texture coordinate to look on the 2D environment map.

00:47:02.880 --> 00:47:04.630
Here's the code in ES1 that sets that up.

00:47:04.630 --> 00:47:09.539
Now you can see the first thing that happens
is I set the matrix mode to the texture.

00:47:09.539 --> 00:47:15.650
After that it's using the same API that you're already used
to, doing some translates and scales and matrix multiplies,

00:47:15.650 --> 00:47:18.090
but they're going into the texture matrix.

00:47:18.090 --> 00:47:22.660
And in the simple case where the model is completely
reflective, the texture combiners are simply set

00:47:22.659 --> 00:47:26.710
up to completely replace the color with that texture.

00:47:26.710 --> 00:47:31.170
A small additional improvement of the fresnel
term changes a couple lines of code here to set

00:47:31.170 --> 00:47:33.570
up an interpolation operator in the fragment stage.

00:47:33.570 --> 00:47:39.980
And here again you can see that it's interpolating between
that environment texture and the primary vertex color.

00:47:39.980 --> 00:47:43.579
And it's interpolating by the alpha
channel of that same texture.

00:47:43.579 --> 00:47:49.759
So this is a pretty simple effect,
but it ends up looking good.

00:47:49.760 --> 00:47:54.010
Now to really drive this home, let's go back
to the iPhone and build this up step by step.

00:47:54.010 --> 00:48:01.640
[ Silence ]

00:48:01.639 --> 00:48:02.980
So here we are back in the 3D scene.

00:48:02.980 --> 00:48:10.159
And if I back up a couple of steps here you
can see now that I'm visualizing the normals

00:48:10.159 --> 00:48:12.920
which are defining this object as colors.

00:48:12.920 --> 00:48:18.670
And in these two this kind of a debug visualization is
really easy to do, because you have the normals coming

00:48:18.670 --> 00:48:22.610
in as attributes and you can simply
assign them directly to the color.

00:48:22.610 --> 00:48:27.220
It's really easy to visualize the data and how
it's coming in before you do any operations on it.

00:48:27.219 --> 00:48:33.969
In ES1 this is a little harder, but it basically uses the
same tricks that I just showed you using the texture matrix.

00:48:33.969 --> 00:48:41.189
To do that in ES1 you can define a couple of special debug
textures like this which are simply ramps to go from black

00:48:41.190 --> 00:48:43.550
to red and black to green and black to blue.

00:48:43.550 --> 00:48:51.360
Now you can see how the normal data defined in
the model here is mapping to the texture colors.

00:48:51.360 --> 00:48:55.320
So for example, all the normals are pointing
downwards on this plane are being mapped

00:48:55.320 --> 00:48:57.700
to the green at the bottom of this first texture.

00:48:57.699 --> 00:48:59.369
And all the normals that are blue on the right side

00:48:59.369 --> 00:49:04.039
of the plane are being mapped to the
right side of the second texture.

00:49:04.039 --> 00:49:06.570
So that's the basic setup.

00:49:06.570 --> 00:49:10.380
The next step of this effect was to transform
the normals by modelview matrix to keep them

00:49:10.380 --> 00:49:13.690
in the same orientation relative to the camera.

00:49:13.690 --> 00:49:17.250
So if I go there you see the coloration
has changed a little bit.

00:49:17.250 --> 00:49:22.340
Now regardless of how I rotate the object around you see
the normals are always pointing in the same direction.

00:49:22.340 --> 00:49:27.460
In this case blue is always pointing towards
the camera, and green is always pointing

00:49:27.460 --> 00:49:31.230
down regardless of how the object is being rotated.

00:49:31.230 --> 00:49:36.730
Once the state is set up, either in the shader or
using the texture matrix that I've just shown you,

00:49:36.730 --> 00:49:41.079
all you have to do is replace these
textures with the real environment map.

00:49:41.079 --> 00:49:46.869
Now the object looks like its completely reflective.

00:49:46.869 --> 00:49:51.170
Small, simple addition to use in the fresnel
term in the alpha channel looks like this.

00:49:51.170 --> 00:49:56.780
In here, you can see the alpha mask and the alpha channel
in the same texture is simply the gradient in the sphere

00:49:56.780 --> 00:50:00.730
which goes from dark in the middle
where the object needs to be using more

00:50:00.730 --> 00:50:03.820
of the original vertex color as
on the parts that are facing you.

00:50:03.820 --> 00:50:08.330
To lighter and then actually white on the edges
of that sphere for the edge parts of the model

00:50:08.329 --> 00:50:11.949
that are perpendicular to the camera
are going to be completely reflective.

00:50:11.949 --> 00:50:17.929
Now with a little more work it's possible to
dynamically change the context of this texture

00:50:17.929 --> 00:50:20.989
to change how the environment mapping is happening.

00:50:20.989 --> 00:50:26.439
I make it completely reflective again, or I can change the
falloff term to get a wide variety of artistic effects,

00:50:26.440 --> 00:50:30.450
depending on the type of object and
the type of an effect you're going for.

00:50:31.630 --> 00:50:37.150
So that's an environment map using a fresnel term.

00:50:37.150 --> 00:50:38.010
Now. Thank you.

00:50:38.010 --> 00:50:44.210
[ Clapping ]

00:50:44.210 --> 00:50:48.970
Now we don't have enough time in this session to go
through this much detail on all the other effects.

00:50:48.969 --> 00:50:54.259
But I want to go through them again to show you how these
basic concepts can be built upon and expanded to build

00:50:54.260 --> 00:50:57.040
up a variety of other interesting effects.

00:50:57.039 --> 00:50:59.929
So if you look at just the fresnel term again,

00:50:59.929 --> 00:51:04.029
here again you can see that it's kind
of highlighting the edges of the model.

00:51:04.030 --> 00:51:10.640
And if you combine that with something else that's not an
environment map, for example a regular vertex lighting,

00:51:10.639 --> 00:51:13.670
you can get kind of this backlighting
or room lighting effect.

00:51:13.670 --> 00:51:17.170
Here you can see it's kind of highlighting the
edges of the model regardless of the orientation.

00:51:17.170 --> 00:51:20.970
And this kind of backlighting effect has
been popularized recently in a couple

00:51:20.969 --> 00:51:23.939
of console games you guys may be familiar with

00:51:23.940 --> 00:51:29.010
Or another idea is use the same kind of
fresnel term for something other than lighting.

00:51:29.010 --> 00:51:32.670
And again you could use it as a blending factor.

00:51:32.670 --> 00:51:37.950
So here you can see that the parts of the card
that are directly facing you are transparent,

00:51:37.949 --> 00:51:41.029
while the parts that are perpendicular
are being dynamically blended together.

00:51:41.030 --> 00:51:46.269
And again you could dynamically change the content
of the texture to change how the blending looks

00:51:46.269 --> 00:51:49.119
and build up a variety of interesting effects.

00:51:50.710 --> 00:51:54.909
Now the same type of technique using the texture
matrix can get you these kind

00:51:54.909 --> 00:51:57.629
of effects like toon shading.

00:51:57.630 --> 00:52:02.450
Again here, you know, I can interact with this
a little bit to move the light source around.

00:52:02.449 --> 00:52:09.429
Luc showed you earlier the very basic lighting technique
of n.l. That's a normal dot product with a light.

00:52:09.429 --> 00:52:12.089
Well, you can do that with the texture matrix.

00:52:12.090 --> 00:52:15.780
You're feeding in the normals of attributes you
can put the light vector into the first column

00:52:15.780 --> 00:52:19.610
of the texture matrix and have
it do that dot product for you.

00:52:19.610 --> 00:52:23.980
Once you have that lighting term, that can be used to
lookup in this kind of compared texture with a couple

00:52:23.980 --> 00:52:27.340
of grayscale ramps in it and make this
kind of none but realistic effect.

00:52:27.340 --> 00:52:30.329
And of course it's all hardware accelerated.

00:52:30.329 --> 00:52:36.529
The more advanced variation on that is to do both
diffuse lighting term and spectral lighting term.

00:52:36.530 --> 00:52:43.340
So it's n.l, nn.h, where h is the halving the
vector between the light vector and the eye vector.

00:52:43.340 --> 00:52:50.329
So here again with a specially prepared texture you can
achieve a wide variety of anisotropic lighting effects.

00:52:50.329 --> 00:52:54.869
Now take a second and compare this
to the vanilla OpenGL lighting.

00:52:54.869 --> 00:52:59.239
Here's what that looks like with just
the diffuse and spectral lighting terms.

00:52:59.239 --> 00:53:02.539
Now what do you want your application to look like?

00:53:04.429 --> 00:53:08.039
So hopefully you can see how if
you use the features that are built

00:53:08.039 --> 00:53:13.789
into the API you can really dynamically increase
the quality of the rendering in your application.

00:53:13.789 --> 00:53:15.820
This is what we want you to be able to do with OpenGL.

00:53:15.820 --> 00:53:24.100
Now so far all these techniques that I've shown you
are implementable both in ES2 with shaders and in ES1.1.

00:53:24.099 --> 00:53:27.599
And of course with ES2 you can go much further than this.

00:53:27.599 --> 00:53:34.929
You have shaders, so let's take a look at an example
of a couple of effects that you need shaders to do.

00:53:34.929 --> 00:53:42.250
So here, and now deforming the teapot, and this is
doing a custom transformation of the vertex shader.

00:53:42.250 --> 00:53:45.579
As Luc pointed out there are a lot of map
functions built into the shading language.

00:53:45.579 --> 00:53:47.279
Things like sine and cosine.

00:53:47.280 --> 00:53:50.700
So it's actually quite easy to make
this kind of custom transformation.

00:53:50.699 --> 00:53:54.329
This actually looks pretty good on the car model.

00:53:54.329 --> 00:54:00.079
And if I change the environment terms there you
can see how it's deforming both the vertex position

00:54:00.079 --> 00:54:04.469
and also the normals, so the environment
map track the positions correctly.

00:54:07.159 --> 00:54:11.359
So, very easy to write with GLSL and the ES2.

00:54:11.360 --> 00:54:16.550
Here's another example using the fragment shader.

00:54:16.550 --> 00:54:21.570
So here this is the same environment map
effect, except at the end of the shader

00:54:21.570 --> 00:54:26.780
where I have the color calculated I'm going to use
that color as a texture coordinate into a special kind

00:54:26.780 --> 00:54:29.950
of texture like this which contains a palette.

00:54:29.949 --> 00:54:33.089
And again, a Uniform could be used
to animate this coordinate

00:54:33.090 --> 00:54:38.820
around to change the values a little bit every single
frame to make this kind of thermal imaging effect.

00:54:38.820 --> 00:54:43.769
Now this is what we call an independent
textual lookup or a dependent texture read.

00:54:43.769 --> 00:54:46.009
This type of thing cannot be done in ES1.1.

00:54:46.010 --> 00:54:51.490
You have to have ES2 for the shaders
to do this kind of effect.

00:54:51.489 --> 00:54:55.289
So that's about all I'm going to talk
about on the 3D section of this talk.

00:54:55.289 --> 00:54:57.429
We'll go back to the slides.

00:54:59.250 --> 00:55:03.840
So I showed you a bunch of different effects,
a lot of which can be done both in ES2 and ES1.

00:55:03.840 --> 00:55:05.190
There's lots of more examples.

00:55:05.190 --> 00:55:08.300
You can come up with your own by
combining all these techniques together.

00:55:08.300 --> 00:55:10.410
In ES2 there's even more.

00:55:10.409 --> 00:55:15.279
You have all the power of GLSL to you, and I'm really
interested to see what you can do in this next year

00:55:15.280 --> 00:55:18.170
when you get your hands on the iPhone 3GS.

00:55:18.170 --> 00:55:23.470
And to change topics let's talk
about 2D and image processing.

00:55:24.860 --> 00:55:27.280
These iPhones all have cameras built into them.

00:55:27.280 --> 00:55:32.769
It's pretty natural that you might want to take a photograph
and then manipulate the pixels in the image a little bit.

00:55:32.769 --> 00:55:35.829
For example, maybe you want to make a grayscale version

00:55:35.829 --> 00:55:40.099
or change some brightness or contrast,
or rotate the user round.

00:55:40.099 --> 00:55:43.949
These types of simple image processing
can be accelerated with OpenGL.

00:55:43.949 --> 00:55:50.349
Again, both in ES2 using shaders
and it turns out also in ES1.1.

00:55:50.349 --> 00:55:55.699
So let's take a look at a simpler
filter which is a grayscale conversion.

00:55:55.699 --> 00:55:58.919
There are a couple different ways you could do
grayscale conversion, but the simplest version is

00:55:58.920 --> 00:56:02.250
to just simply make an average of
the red, green and blue channels.

00:56:02.250 --> 00:56:07.610
So if you multiplied them all by .33 and add them
together, you get the average illuminance value.

00:56:07.610 --> 00:56:11.490
And here you're looking at GLSL fragment
shader to do that kind of effect.

00:56:11.489 --> 00:56:15.819
And the key part of it here is this dot product operation.

00:56:15.820 --> 00:56:18.450
That dot product is doing its multiplies and add's.

00:56:18.449 --> 00:56:23.549
And you can see that I first took a sample out of the
texture and I'm doing a dot product with these weights

00:56:23.550 --> 00:56:26.370
which are just simply constant values like .33.

00:56:26.369 --> 00:56:27.829
It's a very simple shader.

00:56:27.829 --> 00:56:31.319
You just use grayscale in this processing effect.

00:56:31.320 --> 00:56:37.160
Now you can also do this in ES1.1,
although again it's a little trickier.

00:56:37.159 --> 00:56:44.679
And here the texture environment gives you an operator
which is a Dot3 to do these kinds of dot products.

00:56:44.679 --> 00:56:49.230
But that operator is really designed
to do bump mapping using normal maps.

00:56:49.230 --> 00:56:54.360
So if you want to use it to process regular
colors and image, like a photograph,

00:56:54.360 --> 00:56:57.809
you first have to bias the data into the proper range.

00:56:57.809 --> 00:57:00.429
Now you can do this by using an interpolation.

00:57:00.429 --> 00:57:03.230
So you'd have your original image there.

00:57:03.230 --> 00:57:09.320
You can use an interpolation towards white to
squish the data into the proper range of .5 to 1.

00:57:09.320 --> 00:57:13.920
Once you have done that you can then use
an additional unit to do a Dot3 operator

00:57:13.920 --> 00:57:18.420
and find the average color converting
the image to grayscale.

00:57:18.420 --> 00:57:22.430
So that works into our accelerated
and actually runs pretty quickly.

00:57:23.570 --> 00:57:27.780
Here's the code showing you how to set up in
ES1 and I'm not going to go through all this.

00:57:27.780 --> 00:57:31.920
But you can see the basic idea is that
the first unit is doing interpolation.

00:57:31.920 --> 00:57:34.409
The second unit is doing the dot product.

00:57:34.409 --> 00:57:40.710
And you notice there on the top the weights that are being
used have also been biased and scaled into the proper range.

00:57:40.710 --> 00:57:44.980
Instead of being .33 they end up being .667.

00:57:46.210 --> 00:57:47.980
Now that's one filter.

00:57:47.980 --> 00:57:54.130
For a little more advanced image processing theory
there's a nice little set out there, a Graphic Obscura,

00:57:54.130 --> 00:57:55.720
with a couple articles that I thought were pretty good.

00:57:55.719 --> 00:58:00.969
And one of them points out that you can
do a variety of imaging processing effects

00:58:00.969 --> 00:58:04.589
by using simple interpolation and extrapolation operations.

00:58:04.590 --> 00:58:09.010
So in this table you take the center
1.0 column as the original image.

00:58:09.010 --> 00:58:12.660
You could interpolate towards a degenerate
version of the image, like a grayscale copy.

00:58:12.659 --> 00:58:18.230
And you could achieve all the intermediate
desaturative values as you interpolate towards it.

00:58:18.230 --> 00:58:21.710
Or if you extrapolate away from
it you get the opposite effect,

00:58:21.710 --> 00:58:25.949
increasing the saturation and making
the colors more vibrant.

00:58:25.949 --> 00:58:31.419
Or another example, if your degenerate image was a blurred
copy you can get all the intermediate and blurred values

00:58:31.420 --> 00:58:37.309
for the interpolation, or get the opposite
effect of sharpening the image by extrapolation.

00:58:37.309 --> 00:58:41.449
Now this is an interesting topic because it's
not immediately obvious how to map this acronym

00:58:41.449 --> 00:58:45.899
to OpenGL, especially in the confines of ES1.1.

00:58:45.900 --> 00:58:50.809
The left-hand side of the table is just interpolation
which turns out it does map really directly

00:58:50.809 --> 00:58:54.389
to the interpolate operator which
you can do in texture environment.

00:58:54.389 --> 00:59:00.289
But as I pointed out earlier all those terms in this
texture combiner have to be in the range of 0 to 1.

00:59:00.289 --> 00:59:05.860
So that includes not just the pixels and the texture,
but also this interpolator value T here that we're using.

00:59:05.860 --> 00:59:11.890
So how to you deal with this if you want
to extrapolate where T is bigger than 1?

00:59:11.889 --> 00:59:14.000
Well, it's actually pretty easy.

00:59:14.000 --> 00:59:16.389
You could use a little bit of algebra.

00:59:16.389 --> 00:59:19.349
You can substitute in 2T for example.

00:59:19.349 --> 00:59:23.110
And then factor out that 2 to redefine this equation.

00:59:23.110 --> 00:59:26.960
Now all of the terms including T
are back in the proper range 0 to 1.

00:59:26.960 --> 00:59:32.690
Now remember the texture environment can
multiply the result of an operation by 1, 2 or 4.

00:59:32.690 --> 00:59:36.409
So this all maps to the hardware
to be accelerated, even in ES1.1.

00:59:36.409 --> 00:59:42.009
Now let's go back to the phone and take
a look at that to see how it performs.

00:59:42.010 --> 00:59:49.000
[ Silence ]

00:59:49.000 --> 00:59:52.789
So here you can see I have a pretty
looking butterfly wallpaper

00:59:52.789 --> 00:59:54.789
with a couple of modes at the bottom of the slider.

00:59:54.789 --> 00:59:57.969
And it works pretty much just as you expect.

00:59:57.969 --> 01:00:00.599
I drive my finger on the slider and the effect updates.

01:00:00.599 --> 01:00:05.710
So I'm going to change the brightness
here or other effects like the contrast.

01:00:05.710 --> 01:00:07.240
Decreasing contrast or increasing it.

01:00:07.239 --> 01:00:13.719
And hopefully you notice here that this
is completely fluid and interactive.

01:00:13.719 --> 01:00:18.579
This is being accelerated with OpenGL, and the image updates
just as fast as I can move my finger around the slider.

01:00:18.579 --> 01:00:22.559
This is running full screen at 60 frames a sec`ond.

01:00:22.559 --> 01:00:24.329
Here's a saturation operation.

01:00:24.329 --> 01:00:30.019
Desaturating to grey or increasing the
saturation to increase the vibrancy of the colors.

01:00:30.019 --> 01:00:33.739
You can do this in both ES2, of course, or in ES1.1.

01:00:33.739 --> 01:00:38.429
And it turns out that you can do this in
ES1.1 even on the first generation iPhones

01:00:38.429 --> 01:00:42.529
at completely fluid frame rates if you use OpenGL.

01:00:43.949 --> 01:00:47.819
Here's another effect which we haven't
talked about which texture rotation.

01:00:47.820 --> 01:00:53.600
Now rotating colors in OpenGL is
really just like rotating vectors.

01:00:53.599 --> 01:00:58.299
It's the same math of the matrix side of the vector,
except that instead of XYZ for position it's RGB.

01:00:58.300 --> 01:01:05.410
Well, matrix multiplies nothing more than a couple of dot
products, and those dot products map to the Dot3 operator

01:01:05.409 --> 01:01:07.329
which is available in a texture environment.

01:01:07.329 --> 01:01:09.980
So again this can all be accelerated.

01:01:09.980 --> 01:01:15.820
And finally, another example interpolating towards
a blurred version image we're extrapolating away

01:01:15.820 --> 01:01:18.150
from a desharpening image.

01:01:18.150 --> 01:01:25.789
And again, this is all completely fluid and interactive,
and a full screen 60 frames a second even in OpenGL ES 1.1

01:01:27.090 --> 01:01:29.700
So there's an image processing on static 2D data.

01:01:29.699 --> 01:01:38.250
But if we stay on the phone here for a second it turns
out that we can do the same types of things in 3D.

01:01:38.250 --> 01:01:41.639
So here we're back in the 3D screen with this object again.

01:01:41.639 --> 01:01:43.309
Now watch this.

01:01:45.210 --> 01:01:49.550
Now I've run a full screen image
processing filter on my dynamic 3D scene.

01:01:49.550 --> 01:01:51.330
And you'll see it's still nice and interactive.

01:01:51.329 --> 01:01:57.469
So what's happening here is I'm doing the first
pass rendering the 3D geometry into a texture.

01:01:57.469 --> 01:01:59.349
And then additional processing is happening.

01:01:59.349 --> 01:02:03.739
So you do that exact same grayscale
conversion filter that I just showed you in 2D.

01:02:03.739 --> 01:02:07.419
And of course there's a whole huge
variety of effects we could do here.

01:02:07.420 --> 01:02:12.099
For example, here's a bloom filter.

01:02:12.099 --> 01:02:14.710
Everybody's favorite filter maybe.

01:02:14.710 --> 01:02:19.050
Where a blurred version of the image is
being added back on top of the original scene

01:02:19.050 --> 01:02:23.539
to get that kind of dreamy, bloomy, glowy feel.

01:02:24.639 --> 01:02:30.839
Or you can do more in mass processing which use the 3D
depth information of the scene that you've just rendered.

01:02:30.840 --> 01:02:32.590
For example, here's depth of field.

01:02:32.590 --> 01:02:38.390
Now here you can see that as I move the object
off into the distance it becomes blurry.

01:02:38.389 --> 01:02:41.099
And in the midground it's in focus.

01:02:41.099 --> 01:02:44.789
And in the very close foreground it becomes blurry again.

01:02:44.789 --> 01:02:48.989
And this is being done by using all the tricks
that I've just shown you in this session.

01:02:48.989 --> 01:02:53.439
In this case I'm transforming the
window coordinate position, the Z value,

01:02:53.440 --> 01:02:56.929
by using the texture matrix transforming
into texture coordinate.

01:02:56.929 --> 01:03:00.199
And I'm looking up into this specially
formatted texture which contains a focal point.

01:03:00.199 --> 01:03:06.159
And again, I can animate what's in that texture to
dynamically change the focal point of the scene.

01:03:06.159 --> 01:03:11.420
I can bring the near part of the plane
in focus, or the midground or foreground.

01:03:11.420 --> 01:03:16.869
So there's some advanced image processing techniques.

01:03:16.869 --> 01:03:19.659
And of course you can combine all these things.

01:03:19.659 --> 01:03:23.329
So you can go through all these effect
with image processing turned on.

01:03:23.329 --> 01:03:26.759
And then you do the most complicated version in this demo,

01:03:26.760 --> 01:03:30.810
combining the vertex deformation using
the shader with a full screen processing.

01:03:30.809 --> 01:03:33.009
And you can see it still runs just fine.

01:03:33.010 --> 01:03:41.110
[ Clapping ]

01:03:41.110 --> 01:03:43.440
So go back to the slides.

01:03:43.440 --> 01:03:48.990
Let's talk just a little bit about
image processing in full screen.

01:03:48.989 --> 01:03:51.619
And the trick there is really to use framebuffer objects.

01:03:51.619 --> 01:03:55.679
As I pointed out earlier you can do rendering
texture operations with framebuffer objects.

01:03:55.679 --> 01:04:00.299
And the basic idea is to render the 3D scene
in that first pass into a temporary texture.

01:04:00.300 --> 01:04:03.600
That texture should test the framebuffer object.

01:04:03.599 --> 01:04:09.559
Secondly, after the texture has a content in it we
can use that texture as input to additional passes

01:04:09.559 --> 01:04:12.380
of processing such as post-screen imaging processing.

01:04:12.380 --> 01:04:15.000
And the final result gets written into the framebuffer.

01:04:16.239 --> 01:04:21.039
Now it turns out that you already
know how to use framebuffer objects.

01:04:21.039 --> 01:04:24.119
You're using them all the time, any
time you draw anything on an iPhone.

01:04:24.119 --> 01:04:28.849
And as was shown in the first session this diagram
is showing how framebuffer objects interact

01:04:28.849 --> 01:04:33.139
with the EAGL windowing system, just to get it kind
of on the screen on the screen in the first place.

01:04:33.139 --> 01:04:36.539
The only change to this setup you
have to make to render to texture,

01:04:36.539 --> 01:04:40.829
is instead of using a color render
buffer, you use a color texture.

01:04:40.829 --> 01:04:44.119
And this texture is just like any
other texture that you already use.

01:04:44.119 --> 01:04:49.569
You gen it, you bind it, you define the format
and the width and height with GL tech image.

01:04:49.570 --> 01:04:53.920
And after you have the texture created you attach is
to the framebuffer object with GL framebuffer texture.

01:04:53.920 --> 01:05:00.019
At that point that FBO is ready for you
to render that first pass of content into.

01:05:01.159 --> 01:05:04.019
So here's an example of how that bloom effect is built up.

01:05:04.019 --> 01:05:06.590
Is using multipass of render to texture.

01:05:06.590 --> 01:05:10.870
And that first set was to render a
3D scene into a texture with an FBO.

01:05:10.869 --> 01:05:12.569
And then additional processing is done to it.

01:05:12.570 --> 01:05:16.750
And the first step I did was to
downsample it, and this does two things.

01:05:16.750 --> 01:05:21.510
First, it blurs that scene a little
bit which is good for bloom.

01:05:21.510 --> 01:05:26.050
It also reduces the number of pixels that we're going to
be processing, because the more and more steps that we have

01:05:26.050 --> 01:05:28.380
of course there are performance overhead there.

01:05:28.380 --> 01:05:31.690
So downsampling is good to reduce the flow rate.

01:05:31.690 --> 01:05:37.269
Secondly, I can do a real blur operation to really
fuzz that image out, and also darken it a little bit

01:05:37.269 --> 01:05:43.289
so that only the bright parts of the original scene
will end up contributing to the overall bloom effect.

01:05:43.289 --> 01:05:48.449
Finally, once I have that version of the image I
can simply add it back on top of the original frame.

01:05:48.449 --> 01:05:52.049
And that combines to form the final
bloom effect that you saw.

01:05:53.510 --> 01:05:55.860
Now there are a lot of other examples here.

01:05:55.860 --> 01:05:59.960
I showed you depth of field, probably the
most complicated one using all these tricks

01:05:59.960 --> 01:06:02.389
to change the focal point interactively.

01:06:04.159 --> 01:06:07.000
And that's really about the end of this session.

01:06:07.000 --> 01:06:13.769
So to wrap this up the key points here are that to get
the most of OpenGL you're going to have to learn OpenGL.

01:06:13.769 --> 01:06:19.009
There's a lot of functionality here, and we
touched on some key points which in ES2 is all

01:06:19.010 --> 01:06:22.200
about using the vertex and fragment shaders.

01:06:22.199 --> 01:06:24.889
In ES1 it's about using the capability you have.

01:06:24.889 --> 01:06:29.529
The attributes that you have and the fixed
function transformations you have doing things

01:06:29.530 --> 01:06:33.360
such as using the texture meters to give a
little more flexibility to that pipeline.

01:06:33.360 --> 01:06:38.170
You can also use texture combine to combine
multiple textures together in interesting ways.

01:06:38.170 --> 01:06:40.970
And we talked about breaking down
complicated rendering techniques

01:06:40.969 --> 01:06:44.759
in the multiple stages by using
things like render to texture.

01:06:46.340 --> 01:06:49.480
Now there's a whole bunch of tutorials
out there on the Internet

01:06:49.480 --> 01:06:51.949
where it can teach you all these
types of things about OpenGL.

01:06:51.949 --> 01:06:55.909
But I want to point out the one that's
been there all along which is OpenGL.org.

01:06:55.909 --> 01:07:00.649
There's a section there on OpenGL.org
which has tutorials and sample code.

01:07:00.650 --> 01:07:06.110
And in particular they've collected a bunch of these
scene graph presentations from previous years which are

01:07:06.110 --> 01:07:08.900
about the advanced OpenGL rendering techniques.

01:07:08.900 --> 01:07:11.990
Now those sessions predate OpenGL
ES, so they won't work directly

01:07:11.989 --> 01:07:14.699
on your iPhone, but the concepts there are still good.

01:07:14.699 --> 01:07:21.039
And with a little work you can port those
examples onto the phone at OpenGL ES.

01:07:21.039 --> 01:07:23.739
Also for more information about programmability and the ES2,

01:07:23.739 --> 01:07:27.189
there are a couple of good books
which have come out recently.

01:07:27.190 --> 01:07:33.579
There's the new OpenGL ES 2.0 guide which is the gold
book, although it's supposed to purple and not gold.

01:07:33.579 --> 01:07:36.710
There's also the big orange book, the
Open GL Shading Language reference.

01:07:36.710 --> 01:07:41.150
Both of these have a lot of information
about GLSL and the programmable pipeline.

01:07:41.150 --> 01:07:42.980
So if you have interest in that please check these out.