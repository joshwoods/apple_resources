WEBVTT

00:00:07.516 --> 00:00:16.516
[ Music ]

00:00:17.516 --> 00:00:24.946
[ Applause ]

00:00:25.446 --> 00:00:27.606
>> Good afternoon, and welcome

00:00:27.606 --> 00:00:28.036
to WWDC.

00:00:28.416 --> 00:00:29.756
I know I'm competing now with

00:00:29.826 --> 00:00:31.606
the coffee and cookies, but I

00:00:31.606 --> 00:00:32.606
don't know if the coffee is

00:00:32.606 --> 00:00:33.976
gluten free and the cookies are

00:00:33.976 --> 00:00:35.456
actually caffeine free, so stick

00:00:35.456 --> 00:00:35.896
with me.

00:00:36.256 --> 00:00:37.606
My name is Frank Doepke and I'm

00:00:37.606 --> 00:00:38.696
going to talk about some

00:00:38.696 --> 00:00:39.906
interesting stuff that you can

00:00:39.906 --> 00:00:41.606
do with Computer Vision using

00:00:41.606 --> 00:00:43.186
Core ML and Division Framework.

00:00:44.396 --> 00:00:45.236
So, what are we going to talk

00:00:45.236 --> 00:00:45.716
about today?

00:00:46.676 --> 00:00:47.826
First, you might have heard that

00:00:47.826 --> 00:00:49.046
we have something special for

00:00:49.046 --> 00:00:51.186
you in terms of custom image

00:00:51.186 --> 00:00:52.136
classification.

00:00:53.306 --> 00:00:54.256
Then we're going to do some

00:00:54.256 --> 00:00:55.226
object recognition.

00:00:55.226 --> 00:00:57.596
And last but not least, I'm

00:00:57.596 --> 00:00:59.116
going to raise your level of

00:00:59.116 --> 00:01:00.536
Vision awareness by diving into

00:01:00.536 --> 00:01:01.576
some of the fundamentals.

00:01:04.245 --> 00:01:05.116
Now, Custom Image

00:01:05.116 --> 00:01:08.396
Classification, we've seen the

00:01:08.396 --> 00:01:10.156
advantages already in some of

00:01:10.156 --> 00:01:12.176
the presentations earlier, and

00:01:12.176 --> 00:01:13.176
we see like what we can do with

00:01:13.176 --> 00:01:15.206
flowers and fruits and I like

00:01:15.206 --> 00:01:16.476
flowers and fruits as much as

00:01:16.476 --> 00:01:17.256
everybody else.

00:01:17.526 --> 00:01:18.566
Sorry, Lizzie, but I thought

00:01:18.566 --> 00:01:19.426
we'd do something a bit more

00:01:19.426 --> 00:01:20.216
technical here.

00:01:20.946 --> 00:01:23.346
So, the idea is, what can we do

00:01:23.346 --> 00:01:24.886
if we create a shop and we are

00:01:24.886 --> 00:01:26.286
all geeks, so let's build a shop

00:01:26.336 --> 00:01:27.416
where we can build robots.

00:01:27.596 --> 00:01:28.626
So, there are some parts that we

00:01:28.626 --> 00:01:29.586
need to identify.

00:01:30.376 --> 00:01:31.756
And I thought it would be great

00:01:31.756 --> 00:01:33.016
if I have an app that actually

00:01:33.016 --> 00:01:35.096
can help customers in my store

00:01:35.096 --> 00:01:36.716
identify what these objects are.

00:01:38.336 --> 00:01:39.446
So, we've got to train a

00:01:39.446 --> 00:01:41.726
customer classifier for that.

00:01:41.726 --> 00:01:44.136
Then, once we have our

00:01:44.136 --> 00:01:46.306
classifier, we build an iOS app

00:01:46.306 --> 00:01:47.736
around that, that we can

00:01:47.736 --> 00:01:49.056
actually run on all devices.

00:01:50.126 --> 00:01:52.186
And when going through this, I'm

00:01:52.186 --> 00:01:53.186
going to go through some of the

00:01:53.426 --> 00:01:54.596
common pitfalls when you

00:01:54.596 --> 00:01:55.696
actually want to do any of this

00:01:55.766 --> 00:01:57.466
stuff and try to guide you

00:01:57.466 --> 00:01:58.646
through that.

00:01:59.376 --> 00:02:02.276
Let's start with our training.

00:02:03.426 --> 00:02:04.216
So, how do we train?

00:02:04.216 --> 00:02:05.446
We use of course, Create ML.

00:02:06.586 --> 00:02:08.235
The first step of course we have

00:02:08.235 --> 00:02:09.596
to do, is we have to take

00:02:09.596 --> 00:02:10.036
pictures.

00:02:11.426 --> 00:02:13.816
Then we put them in folders and

00:02:13.816 --> 00:02:15.426
we use the folder names as our

00:02:15.426 --> 00:02:16.616
classification labels.

00:02:18.876 --> 00:02:20.586
Now, the biggest question that

00:02:20.586 --> 00:02:22.256
everybody has, "How much data do

00:02:22.256 --> 00:02:22.576
I need?"

00:02:23.426 --> 00:02:25.646
The first thing is, well, we

00:02:25.646 --> 00:02:28.126
need a minimum of about 10

00:02:28.456 --> 00:02:31.456
images per category, but that's

00:02:31.456 --> 00:02:32.266
on the low side.

00:02:32.266 --> 00:02:33.026
You definitely want to have

00:02:33.076 --> 00:02:33.426
more.

00:02:33.646 --> 00:02:34.846
The more, the better, actually

00:02:34.846 --> 00:02:36.306
your classifier will perform

00:02:36.306 --> 00:02:36.546
better.

00:02:38.406 --> 00:02:39.966
Another thing to look out for is

00:02:40.076 --> 00:02:41.586
highly imbalanced data sets.

00:02:41.656 --> 00:02:42.546
What do I mean by that?

00:02:43.016 --> 00:02:44.196
When a data set has like

00:02:44.196 --> 00:02:45.656
thousands of images in one

00:02:45.656 --> 00:02:46.976
category, and only ten in the

00:02:46.976 --> 00:02:48.776
other one, this model will not

00:02:48.836 --> 00:02:49.586
train really well.

00:02:49.586 --> 00:02:50.746
So, you want to have like an

00:02:50.746 --> 00:02:52.626
equal distribution between most

00:02:52.626 --> 00:02:53.366
of your categories.

00:02:55.696 --> 00:02:57.496
Another thing that we actually

00:02:57.756 --> 00:02:59.356
introduce, is augmentation.

00:03:00.146 --> 00:03:01.436
Augmentation will help you to

00:03:01.436 --> 00:03:04.216
make this model more robust, but

00:03:04.216 --> 00:03:05.396
it doesn't really replace the

00:03:05.396 --> 00:03:06.016
variety.

00:03:06.016 --> 00:03:07.856
So, you still want to have lots

00:03:07.856 --> 00:03:09.736
of images of your objects that

00:03:09.736 --> 00:03:10.616
you want to classify.

00:03:11.326 --> 00:03:12.966
But, with the augmentation, what

00:03:12.966 --> 00:03:14.336
we're going to do is, we take an

00:03:14.336 --> 00:03:15.496
image and we perturb it.

00:03:15.496 --> 00:03:17.936
So, we have noised it, we blur

00:03:17.936 --> 00:03:19.766
it, we rotate it, flip it, so it

00:03:19.766 --> 00:03:20.676
looks different to the

00:03:20.676 --> 00:03:21.886
classifier actually when we

00:03:21.886 --> 00:03:22.926
train it.

00:03:24.096 --> 00:03:25.616
Let's look a little bit under

00:03:25.616 --> 00:03:26.776
the hood of how our training

00:03:26.776 --> 00:03:28.186
actually works.

00:03:29.426 --> 00:03:30.496
You might have already heard it,

00:03:30.576 --> 00:03:32.076
the term, transfer learning.

00:03:32.076 --> 00:03:32.966
And this is what we're going to

00:03:32.966 --> 00:03:34.626
use in Create ML when we train

00:03:34.626 --> 00:03:35.376
our classifier.

00:03:36.366 --> 00:03:37.716
So, we start with a pretrained

00:03:37.716 --> 00:03:39.266
model, and that's where all the

00:03:39.266 --> 00:03:40.676
heavy lifting actually happens.

00:03:40.676 --> 00:03:42.386
These models train normally for

00:03:42.386 --> 00:03:44.216
weeks, and with millions of

00:03:44.256 --> 00:03:46.136
images, and that is the first

00:03:46.136 --> 00:03:47.476
starting point that you need to

00:03:47.476 --> 00:03:49.696
actually work with this.

00:03:50.306 --> 00:03:52.136
Out of this model, we can use

00:03:52.136 --> 00:03:53.496
this as a feature extractor.

00:03:53.496 --> 00:03:54.866
This gives us a feature vector

00:03:54.866 --> 00:03:56.186
which is pretty much a numerical

00:03:56.186 --> 00:03:57.586
description of what we have in

00:03:57.586 --> 00:03:58.246
our image.

00:03:59.446 --> 00:04:01.446
Now, you bring in your data and

00:04:01.446 --> 00:04:02.956
we train the set, what we call

00:04:02.956 --> 00:04:04.026
the last layer, which is the

00:04:04.026 --> 00:04:06.366
real classifier, on your label

00:04:06.366 --> 00:04:08.636
data and out comes your custom

00:04:08.636 --> 00:04:08.976
model.

00:04:09.746 --> 00:04:12.786
Now, I mentioned already this

00:04:12.786 --> 00:04:14.506
large, first pretrained model.

00:04:15.406 --> 00:04:16.426
And we have something new in

00:04:16.426 --> 00:04:17.396
Vision for this [inaudible].

00:04:17.396 --> 00:04:18.596
This is what we call the Vision

00:04:18.596 --> 00:04:19.815
FeaturePrint for Scenes.

00:04:21.055 --> 00:04:22.676
It's available through Create ML

00:04:23.406 --> 00:04:24.896
and it allows you to train an

00:04:24.896 --> 00:04:25.796
image classifier.

00:04:27.766 --> 00:04:29.236
It has been trained on a very

00:04:29.236 --> 00:04:31.836
large data set, and it is

00:04:31.836 --> 00:04:33.766
capable of categorizing over a

00:04:33.766 --> 00:04:34.936
thousand categories.

00:04:35.386 --> 00:04:37.296
That's a pretty good

00:04:37.296 --> 00:04:38.206
distribution that you can

00:04:38.206 --> 00:04:38.726
actually use [inaudible].

00:04:39.756 --> 00:04:41.866
And we've already used it.

00:04:41.866 --> 00:04:43.036
Over the last few years, through

00:04:43.036 --> 00:04:44.006
some of the user [inaudible]

00:04:44.006 --> 00:04:45.216
pictures that you've seen in

00:04:45.216 --> 00:04:47.056
photos, have been actually using

00:04:47.436 --> 00:04:48.366
this model underneath.

00:04:49.976 --> 00:04:51.036
We're also going to continuously

00:04:51.036 --> 00:04:52.676
improve on that model, but

00:04:52.676 --> 00:04:53.776
there's a small caveat that I

00:04:53.776 --> 00:04:54.966
would like to kind of highlight

00:04:54.966 --> 00:04:55.186
here.

00:04:56.336 --> 00:04:57.856
When we come out with a new

00:04:57.856 --> 00:04:59.766
version of that model, you will

00:04:59.766 --> 00:05:00.986
not necessarily automatically

00:05:00.986 --> 00:05:02.536
get the benefits unless you

00:05:02.536 --> 00:05:03.996
retrain [inaudible] new model.

00:05:04.666 --> 00:05:06.096
So, if you start developing with

00:05:06.186 --> 00:05:07.536
this, this year, and you want to

00:05:07.676 --> 00:05:08.666
you know, take advantage of

00:05:08.756 --> 00:05:09.866
whatever we come out over the

00:05:09.866 --> 00:05:11.876
next years, hold onto your data

00:05:11.876 --> 00:05:14.036
sets so you can actually retrain

00:05:14.036 --> 00:05:15.046
[inaudible].

00:05:15.046 --> 00:05:18.896
A few more things about our

00:05:18.896 --> 00:05:21.986
feature extractor.

00:05:21.986 --> 00:05:23.656
It's already on the device, and

00:05:23.656 --> 00:05:24.816
that was kind of an important

00:05:24.816 --> 00:05:27.716
decision for us, because it

00:05:27.716 --> 00:05:29.306
makes the disc footprint for

00:05:29.306 --> 00:05:30.776
your models significantly

00:05:30.776 --> 00:05:31.276
smaller.

00:05:32.136 --> 00:05:33.286
So, let's compare a little bit.

00:05:34.106 --> 00:05:36.136
So, I chose some common, you

00:05:36.136 --> 00:05:37.806
know, available models that we

00:05:37.806 --> 00:05:38.486
use today.

00:05:38.926 --> 00:05:40.156
The first thing would be Resnet.

00:05:40.156 --> 00:05:42.106
So, if I train my classifier on

00:05:42.106 --> 00:05:43.446
top of Resnet, how big is my

00:05:43.446 --> 00:05:43.816
model?

00:05:44.486 --> 00:05:45.496
Ninety-eight megabytes.

00:05:47.386 --> 00:05:48.486
If I use Squeezenet, so

00:05:48.486 --> 00:05:49.806
Squeezenet is a much smaller

00:05:49.806 --> 00:05:50.146
model.

00:05:50.146 --> 00:05:51.216
It's not capable of

00:05:51.266 --> 00:05:52.306
differentiating as many

00:05:52.306 --> 00:05:54.876
categories, and that's 5

00:05:54.916 --> 00:05:55.406
megabytes.

00:05:55.406 --> 00:05:57.176
So, it's about saving there, but

00:05:57.636 --> 00:05:58.806
it will not be as versatile.

00:05:58.806 --> 00:06:00.316
Now, how about Vision?

00:06:01.806 --> 00:06:03.116
It's less than a megabyte in

00:06:03.116 --> 00:06:03.726
most cases.

00:06:04.356 --> 00:06:07.506
The other thing of course why we

00:06:07.506 --> 00:06:08.406
believe that this is a good

00:06:08.406 --> 00:06:10.586
choice for use, it's already

00:06:10.586 --> 00:06:11.276
optimized.

00:06:11.706 --> 00:06:13.116
And we know a few things about

00:06:13.116 --> 00:06:15.546
our hardware or GPUs and CPUS

00:06:15.546 --> 00:06:18.746
and we really optimized a lot on

00:06:18.746 --> 00:06:20.026
that model so that it performs

00:06:20.026 --> 00:06:21.296
best on our devices.

00:06:21.906 --> 00:06:25.246
So, how do we train [inaudible]?

00:06:27.036 --> 00:06:28.206
We start with some labeled

00:06:28.206 --> 00:06:30.106
images, and bring them into

00:06:30.106 --> 00:06:32.566
Create ML, and Create ML knows

00:06:32.566 --> 00:06:33.876
how to extract [inaudible]

00:06:33.876 --> 00:06:35.216
Vision Feature Print.

00:06:36.636 --> 00:06:38.776
It trains our classifier and

00:06:38.776 --> 00:06:40.506
that classifier is all what

00:06:40.506 --> 00:06:41.616
[inaudible] will go into our

00:06:41.616 --> 00:06:42.386
Core ML model.

00:06:42.546 --> 00:06:43.786
That's why it is so small.

00:06:43.786 --> 00:06:46.136
Now, when it comes time that I

00:06:46.136 --> 00:06:47.676
actually want to analyze an

00:06:47.676 --> 00:06:50.416
image, all I have to do is use

00:06:50.416 --> 00:06:53.336
my image and model, and now in

00:06:53.336 --> 00:06:56.036
Vision or in Core ML, it knows

00:06:56.036 --> 00:06:57.166
another [inaudible] again how to

00:06:57.166 --> 00:06:58.276
train -- sorry.

00:06:58.426 --> 00:06:59.036
Not train.

00:06:59.036 --> 00:07:00.936
In this case, use our Vision

00:07:00.936 --> 00:07:02.686
Feature Print and we'll

00:07:02.686 --> 00:07:04.036
[inaudible] the classification.

00:07:04.786 --> 00:07:08.636
So, that was everything we

00:07:08.636 --> 00:07:09.456
needed to know about the

00:07:09.456 --> 00:07:09.926
training.

00:07:11.206 --> 00:07:12.616
But, I said there was some

00:07:12.766 --> 00:07:13.976
caveats that you want to kind of

00:07:13.976 --> 00:07:15.186
look at when we deal with the

00:07:16.326 --> 00:07:16.866
app.

00:07:16.866 --> 00:07:20.326
So, first thing, we only want to

00:07:20.326 --> 00:07:21.826
actually run our classifier when

00:07:21.826 --> 00:07:22.606
we really have to.

00:07:24.526 --> 00:07:25.666
Classifiers are deep

00:07:25.666 --> 00:07:26.966
convolutional networks that are

00:07:26.966 --> 00:07:28.426
pretty computational intensive.

00:07:28.696 --> 00:07:30.996
So, when we run those, it will

00:07:30.996 --> 00:07:32.646
definitely use up kind of you

00:07:32.646 --> 00:07:33.996
know, some electrons running on

00:07:33.996 --> 00:07:35.116
the CPU and GPU.

00:07:35.116 --> 00:07:36.546
So, you don't want to use this

00:07:36.846 --> 00:07:37.956
unless you really have to.

00:07:38.776 --> 00:07:40.326
In the example that I'm going to

00:07:40.326 --> 00:07:43.116
show in my demo laters, I really

00:07:43.116 --> 00:07:44.206
only want to classify if

00:07:44.206 --> 00:07:45.816
actually the person looks really

00:07:45.816 --> 00:07:47.026
at an item and not when just a

00:07:47.026 --> 00:07:48.086
camera moves around.

00:07:49.816 --> 00:07:52.186
So, I'm asking the question, "Am

00:07:52.186 --> 00:07:53.006
I holding still?"

00:07:53.066 --> 00:07:54.216
and then I'm going to run my

00:07:54.216 --> 00:07:54.846
classifier.

00:07:56.106 --> 00:07:56.846
How do I do this?

00:07:56.846 --> 00:07:59.096
By using Vision, I can use

00:07:59.096 --> 00:07:59.906
Registration.

00:08:00.156 --> 00:08:01.496
Registration means I can take

00:08:01.536 --> 00:08:03.696
two images and align them with

00:08:03.696 --> 00:08:04.006
each other.

00:08:04.006 --> 00:08:04.836
And you're going to tell me,

00:08:04.836 --> 00:08:06.026
"Okay, if you shift it by this

00:08:06.026 --> 00:08:07.566
amount of pixels, this is

00:08:07.566 --> 00:08:08.306
actually in how they would

00:08:08.306 --> 00:08:08.946
actually match."

00:08:09.606 --> 00:08:11.116
This is a pretty cheap and fast

00:08:11.116 --> 00:08:13.626
algorithm, and it will tell me

00:08:13.626 --> 00:08:15.376
if I hold the camera still or if

00:08:15.376 --> 00:08:16.976
anything is moving in front of

00:08:17.696 --> 00:08:19.816
the camera.

00:08:19.816 --> 00:08:21.616
I used VN Translational Image

00:08:21.616 --> 00:08:22.696
Registration Request.

00:08:22.696 --> 00:08:23.736
I know that is a mouthful.

00:08:25.106 --> 00:08:26.976
But that will give me all this

00:08:26.976 --> 00:08:27.606
information.

00:08:28.186 --> 00:08:29.666
So, to visualize this first,

00:08:29.666 --> 00:08:31.006
let's look at the little video.

00:08:31.436 --> 00:08:33.025
What I'm doing in this video is

00:08:33.025 --> 00:08:34.616
I show basically a little yellow

00:08:34.616 --> 00:08:36.515
line that shows me how basically

00:08:36.566 --> 00:08:38.196
my camera has moved or the

00:08:38.246 --> 00:08:39.556
Registration requests have moved

00:08:39.556 --> 00:08:41.446
over the last couple of frames.

00:08:41.956 --> 00:08:42.946
So, what out for that yellow

00:08:42.946 --> 00:08:44.546
line and see if it's long, then

00:08:44.546 --> 00:08:45.766
I have moved the camera around

00:08:45.766 --> 00:08:46.606
quite a bit, and when I'm

00:08:46.606 --> 00:08:47.736
holding it still, it should

00:08:47.736 --> 00:08:48.866
actually be a very small line.

00:08:49.546 --> 00:08:51.866
So, you see the camera is

00:08:51.866 --> 00:08:53.446
moving, and now I'm focusing on

00:08:53.446 --> 00:08:55.496
this, and it gets very short.

00:08:57.016 --> 00:08:58.026
So, that's just a good idea.

00:08:58.026 --> 00:08:58.846
It's like, "Okay, now I'm

00:08:58.846 --> 00:08:59.366
holding still.

00:08:59.366 --> 00:09:00.346
Now, I want to run my

00:09:00.346 --> 00:09:00.976
classifier."

00:09:01.426 --> 00:09:05.106
Next thing to keep in mind is,

00:09:06.056 --> 00:09:06.976
have a backup plan.

00:09:07.666 --> 00:09:08.446
It's always good to have a

00:09:08.446 --> 00:09:08.996
backup plan.

00:09:09.816 --> 00:09:11.786
Classifications can be wrong.

00:09:12.956 --> 00:09:15.296
And what that means, even if my

00:09:15.296 --> 00:09:16.636
classification actually has a

00:09:16.636 --> 00:09:18.416
high confidence, I need to kind

00:09:18.416 --> 00:09:19.676
of plan for sometimes that it

00:09:19.676 --> 00:09:20.936
doesn't work quite correctly.

00:09:22.526 --> 00:09:23.776
The one thing that I did in my

00:09:23.776 --> 00:09:25.186
example here, as you will see

00:09:25.186 --> 00:09:26.376
later on, I have something

00:09:26.376 --> 00:09:27.216
wherefore which I don't have a

00:09:27.216 --> 00:09:28.046
physical object.

00:09:28.046 --> 00:09:29.156
So, how do I solve that?

00:09:29.676 --> 00:09:31.006
In my example, I'm using our

00:09:31.006 --> 00:09:32.326
backward detector that we have

00:09:32.326 --> 00:09:34.046
in the Vision Framework to read

00:09:34.046 --> 00:09:35.356
some data backward label to

00:09:35.356 --> 00:09:36.156
identify this.

00:09:37.256 --> 00:09:38.406
Alright, enough of slides.

00:09:39.226 --> 00:09:41.946
Who wants to see the demo?

00:09:42.516 --> 00:09:52.586
[ Applause ]

00:09:53.086 --> 00:09:54.006
Okay, what you see on the

00:09:54.006 --> 00:09:55.746
right-hand side of the screen is

00:09:55.746 --> 00:09:56.776
my device.

00:09:57.536 --> 00:09:58.746
I'm going to start now my little

00:09:59.446 --> 00:10:00.716
robot shop application.

00:10:01.276 --> 00:10:02.826
And when you see I'm moving

00:10:02.826 --> 00:10:03.876
around, there's nothing

00:10:03.876 --> 00:10:04.406
happening.

00:10:04.826 --> 00:10:06.626
When I hold still, and I point

00:10:06.626 --> 00:10:08.246
it at something, I should see a

00:10:08.246 --> 00:10:10.246
yellow line and then voila, yes

00:10:10.306 --> 00:10:11.366
step is a stepper motor.

00:10:12.176 --> 00:10:13.336
Okay? Let's see what else do we

00:10:13.336 --> 00:10:14.316
have here on this table?

00:10:14.876 --> 00:10:19.916
That is my micro controller.

00:10:20.586 --> 00:10:24.846
That's a stepper motor driver.

00:10:25.186 --> 00:10:26.196
We can also like you know, pick

00:10:26.196 --> 00:10:27.486
something up and hold it.

00:10:28.426 --> 00:10:31.266
Yes, this is a closed loop belt.

00:10:35.336 --> 00:10:36.496
What do we have here?

00:10:36.496 --> 00:10:37.116
Lead screw.

00:10:37.626 --> 00:10:39.446
And as I said, you can also look

00:10:39.446 --> 00:10:42.076
at the barcode here, if I get my

00:10:42.076 --> 00:10:43.086
cable [inaudible] long enough.

00:10:44.416 --> 00:10:47.846
And that is my training course.

00:10:48.446 --> 00:10:48.986
>> Hey, Frank?

00:10:48.986 --> 00:10:51.426
>> Of course, for that I

00:10:51.426 --> 00:10:51.626
didn't--

00:10:51.746 --> 00:10:51.976
>> Frank?

00:10:52.066 --> 00:10:56.106
>> What's going on?

00:10:56.226 --> 00:10:57.706
>> Frank, yes, I'm going to need

00:10:57.706 --> 00:10:59.286
you to add another robot part to

00:10:59.286 --> 00:10:59.876
your demo.

00:11:00.156 --> 00:11:00.746
>> This is Brett.

00:11:00.746 --> 00:11:01.546
That's my manager.

00:11:02.556 --> 00:11:05.046
>> That'd be great.

00:11:09.066 --> 00:11:10.356
>> As usual, management, last

00:11:10.356 --> 00:11:12.016
minute requests.

00:11:12.236 --> 00:11:12.996
>> I'll make sure you get

00:11:12.996 --> 00:11:14.126
another copy of that memo.

00:11:14.376 --> 00:11:16.326
>> I'm not going to come in on

00:11:16.326 --> 00:11:17.366
Saturday for this.

00:11:18.296 --> 00:11:19.296
Alright, well what do we have

00:11:19.356 --> 00:11:19.496
here?

00:11:19.496 --> 00:11:20.876
We have a [inaudible] motor.

00:11:20.876 --> 00:11:23.016
Alright, let's see.

00:11:23.016 --> 00:11:23.876
It might just work.

00:11:23.876 --> 00:11:26.606
Let me try this.

00:11:28.146 --> 00:11:29.156
Do I get away with that?

00:11:29.396 --> 00:11:31.976
No, it can't really read this

00:11:31.976 --> 00:11:32.416
object.

00:11:32.416 --> 00:11:33.156
Perhaps so?

00:11:33.636 --> 00:11:34.856
It's -- no, it's not a stepper

00:11:34.856 --> 00:11:35.206
motor.

00:11:35.956 --> 00:11:36.576
So, that's a bug.

00:11:37.136 --> 00:11:39.086
I guess we need to fix that.

00:11:39.896 --> 00:11:40.836
Who wants to fix this?

00:11:41.786 --> 00:11:46.176
Who wants to fix this?

00:11:46.556 --> 00:11:47.256
Alright.

00:11:49.476 --> 00:11:51.486
So, what I have to do now is I

00:11:51.486 --> 00:11:52.656
have to take some pictures of

00:11:53.276 --> 00:11:54.006
the aforementioned, [inaudible]

00:11:54.136 --> 00:11:54.856
motor.

00:11:55.006 --> 00:11:57.206
So, I need to go to the studio

00:11:57.206 --> 00:11:59.276
and you know, set up the lights,

00:11:59.916 --> 00:12:03.086
or I use my favorite camera that

00:12:03.086 --> 00:12:03.916
I already have here.

00:12:05.326 --> 00:12:06.716
Now, let's see.

00:12:06.916 --> 00:12:07.836
We're going to take a bunch of

00:12:07.836 --> 00:12:08.916
pictures of our [inaudible]

00:12:08.986 --> 00:12:09.526
motor.

00:12:09.526 --> 00:12:13.406
And it's kind of important to

00:12:13.406 --> 00:12:14.816
just kind of vary it and don't

00:12:14.816 --> 00:12:16.186
have anything else really in the

00:12:16.186 --> 00:12:16.716
frame.

00:12:21.426 --> 00:12:24.316
So, I'm going for a [inaudible].

00:12:24.316 --> 00:12:26.116
I need to have at least ten

00:12:26.116 --> 00:12:26.926
different images.

00:12:27.526 --> 00:12:28.066
Good choices.

00:12:28.066 --> 00:12:29.626
I always just like to put it on

00:12:29.626 --> 00:12:30.576
a different background.

00:12:31.376 --> 00:12:36.306
And make sure that we get a few

00:12:36.306 --> 00:12:37.036
captured here.

00:12:37.776 --> 00:12:39.116
Perhaps I'm going to hold it a

00:12:39.496 --> 00:12:46.996
little bit in my hand.

00:12:46.996 --> 00:12:48.906
Okay, so we have now a number of

00:12:48.906 --> 00:12:49.326
images.

00:12:51.366 --> 00:12:52.346
Now, I'm going to go over to my

00:12:52.346 --> 00:12:53.726
Mac and actually show you how to

00:12:53.726 --> 00:12:54.736
actually do then the training

00:12:54.736 --> 00:12:56.876
work for that.

00:12:57.276 --> 00:13:01.196
Okay, I'm bringing up my image

00:13:01.196 --> 00:13:02.656
capture application and let me

00:13:02.656 --> 00:13:06.016
for a moment just hide my

00:13:06.016 --> 00:13:06.083
[inaudible].

00:13:09.196 --> 00:13:10.976
If I now look in my Finder, you

00:13:10.976 --> 00:13:12.036
can actually see I have my

00:13:12.036 --> 00:13:13.496
training set, which I used

00:13:13.496 --> 00:13:14.846
already earlier to train and

00:13:14.846 --> 00:13:16.276
model that I've been using in my

00:13:16.276 --> 00:13:16.976
application.

00:13:17.826 --> 00:13:18.936
And I need to create now a new

00:13:18.936 --> 00:13:23.346
folder, and let's call that

00:13:25.516 --> 00:13:25.686
Servo.

00:13:25.816 --> 00:13:27.186
And from Image Capture, I can

00:13:27.186 --> 00:13:29.616
now simply take all the pictures

00:13:29.616 --> 00:13:35.156
that I just captured and drag

00:13:35.216 --> 00:13:40.996
them into my Servo.

00:13:41.176 --> 00:13:43.596
Alright, so now we have that

00:13:43.596 --> 00:13:44.016
added.

00:13:44.626 --> 00:13:45.836
Now, I need to train my model

00:13:45.836 --> 00:13:48.716
again since my manager just

00:13:48.716 --> 00:13:49.856
ruined what I've done earlier.

00:13:50.586 --> 00:13:50.936
Okay.

00:13:52.296 --> 00:13:53.956
I used a simple scripting

00:13:53.956 --> 00:13:55.136
playground here.

00:13:55.136 --> 00:13:57.216
Not the UI, just because well,

00:13:57.596 --> 00:13:58.616
this might be something I want

00:13:58.616 --> 00:13:59.666
to later on incorporate as a

00:13:59.666 --> 00:14:01.406
build step into my application.

00:14:02.436 --> 00:14:03.526
So, I'm pointing it simply at

00:14:03.526 --> 00:14:05.066
the data set that we just added

00:14:05.066 --> 00:14:07.416
our folder to, and I'm just

00:14:07.416 --> 00:14:08.236
simply going to train my

00:14:08.236 --> 00:14:09.986
classifier, and in the end,

00:14:10.136 --> 00:14:11.176
write out my model.

00:14:12.246 --> 00:14:14.396
So, what's going to happen now

00:14:14.396 --> 00:14:16.266
as you can see, we're off to the

00:14:16.266 --> 00:14:16.636
races.

00:14:17.416 --> 00:14:18.766
It's going to go through all

00:14:18.766 --> 00:14:21.626
these images that we've already

00:14:22.306 --> 00:14:23.546
put into our folders and

00:14:23.546 --> 00:14:25.096
extracts the scene print from

00:14:25.096 --> 00:14:25.376
that.

00:14:25.626 --> 00:14:26.946
It does all the scaling down

00:14:26.946 --> 00:14:29.906
that has to happen and will then

00:14:29.906 --> 00:14:31.196
in the end, train and model

00:14:31.196 --> 00:14:32.026
based on that.

00:14:32.216 --> 00:14:33.506
So, it's a pretty complex task,

00:14:33.506 --> 00:14:35.076
but you see for you, it's really

00:14:35.166 --> 00:14:37.086
just one line of code, and in

00:14:37.086 --> 00:14:38.236
the end, you should get out of

00:14:38.236 --> 00:14:39.686
it, a model that you can

00:14:39.686 --> 00:14:40.406
actually use in your

00:14:40.406 --> 00:14:40.976
application.

00:14:41.806 --> 00:14:43.076
Let's see as it just finishes.

00:14:43.756 --> 00:14:45.696
We're almost there.

00:14:46.156 --> 00:14:48.776
And voila, we have our model.

00:14:51.106 --> 00:14:54.936
Now, that model, I've already

00:14:54.936 --> 00:14:56.936
referenced in my robot shop

00:14:56.936 --> 00:14:57.696
application.

00:14:57.696 --> 00:14:58.896
This is what we see here now.

00:14:59.526 --> 00:15:01.306
As you can see, this is my image

00:15:01.306 --> 00:15:01.916
classifier.

00:15:01.916 --> 00:15:03.826
It's 148 kilobytes.

00:15:04.506 --> 00:15:06.206
That's smaller than the little

00:15:06.206 --> 00:15:07.566
startup screen that I actually

00:15:08.816 --> 00:15:08.906
have.

00:15:09.516 --> 00:15:15.496
[ Applause ]

00:15:15.996 --> 00:15:16.726
So, one thing I want to

00:15:16.726 --> 00:15:17.666
highlight here already, and

00:15:17.666 --> 00:15:18.616
we're going to go into that a

00:15:18.616 --> 00:15:19.706
little bit later.

00:15:19.706 --> 00:15:21.836
So, this image, that I need to

00:15:21.836 --> 00:15:23.206
pass into this has to be of a--

00:15:23.266 --> 00:15:26.196
a color image and a 299 by 299

00:15:26.196 --> 00:15:26.606
pixels.

00:15:26.816 --> 00:15:28.026
Strange layout but this is

00:15:28.026 --> 00:15:29.466
actually what a lot of these

00:15:29.466 --> 00:15:30.366
classifiers will do.

00:15:31.406 --> 00:15:31.786
Alright.

00:15:32.596 --> 00:15:34.406
So, now I have hopefully a model

00:15:34.406 --> 00:15:35.486
that will understand it.

00:15:36.006 --> 00:15:37.026
Now, I need to go into my

00:15:37.416 --> 00:15:39.226
sophisticated product database

00:15:39.226 --> 00:15:40.606
which is just a key list.

00:15:42.186 --> 00:15:43.906
And I'm going to add my Servo to

00:15:44.636 --> 00:15:45.086
that.

00:15:47.816 --> 00:15:49.436
So, I'm going to rename this one

00:15:49.436 --> 00:15:49.676
here.

00:15:49.676 --> 00:15:50.676
This is Servo.

00:15:51.376 --> 00:15:54.306
I'm giving it a label.

00:15:54.306 --> 00:15:55.176
This is actually what we're

00:15:55.176 --> 00:15:55.876
going to see.

00:15:56.416 --> 00:16:01.396
This is a servo motor and let's

00:16:01.396 --> 00:16:06.606
say this is a motor that goes

00:16:07.386 --> 00:16:10.286
swish, swish.

00:16:11.706 --> 00:16:12.946
Very technical.

00:16:13.296 --> 00:16:13.596
Alright.

00:16:14.826 --> 00:16:15.726
Let's see if this works.

00:16:17.236 --> 00:16:18.636
I'm going to run my application

00:16:19.406 --> 00:16:19.496
now.

00:16:21.316 --> 00:16:28.776
That's -- okay.

00:16:30.046 --> 00:16:32.136
Let's try it.

00:16:32.836 --> 00:16:33.956
There's our servo motor.

00:16:34.516 --> 00:16:41.266
[ Applause ]

00:16:41.766 --> 00:16:43.676
Just to put this in perspective.

00:16:43.676 --> 00:16:44.956
This was a world first that you

00:16:44.956 --> 00:16:45.356
saw.

00:16:45.406 --> 00:16:47.066
A classifier being trained live

00:16:47.066 --> 00:16:48.516
on stage, from photos, all the

00:16:48.516 --> 00:16:49.886
way into the final application.

00:16:50.586 --> 00:16:51.896
I was a bit sweating about this

00:16:51.896 --> 00:16:52.176
demo [laughter].

00:16:55.686 --> 00:16:55.996
Thank you.

00:17:01.866 --> 00:17:04.006
Now we've seen how it works.

00:17:04.006 --> 00:17:05.136
There's a few things I want to

00:17:05.136 --> 00:17:06.326
highlight actually when we

00:17:06.326 --> 00:17:08.786
actually go through the code.

00:17:09.016 --> 00:17:09.796
So, I promise, we're going to

00:17:09.796 --> 00:17:11.465
live code here a little bit.

00:17:12.006 --> 00:17:15.165
Okay, let me take everything

00:17:15.165 --> 00:17:16.146
away that we don't need to look

00:17:16.146 --> 00:17:16.606
at right now.

00:17:16.606 --> 00:17:21.496
And make this a bit bigger.

00:17:22.185 --> 00:17:24.685
Okay, so, how did I solve all

00:17:24.685 --> 00:17:24.915
this?

00:17:25.445 --> 00:17:26.906
So, we started, we actually

00:17:27.226 --> 00:17:28.666
created a Sequence Request

00:17:28.666 --> 00:17:28.906
Handler.

00:17:29.076 --> 00:17:30.106
This is the one that I'm going

00:17:30.106 --> 00:17:31.816
to use for my registration work,

00:17:32.126 --> 00:17:33.696
just as Sergei already explained

00:17:33.696 --> 00:17:35.446
in the earlier session, this is

00:17:35.446 --> 00:17:36.646
good for tracking objects.

00:17:38.016 --> 00:17:39.956
I will create my request, put

00:17:39.956 --> 00:17:41.676
them into one array, and now

00:17:41.676 --> 00:17:42.686
what do you see here for the

00:17:42.686 --> 00:17:43.336
registration?

00:17:43.336 --> 00:17:45.146
Just keeping like the last 15

00:17:45.146 --> 00:17:47.106
registration results, and then

00:17:47.106 --> 00:17:48.466
I'm going to do some analysis on

00:17:48.466 --> 00:17:49.496
that and see if actually I'm

00:17:49.496 --> 00:17:50.076
holding still.

00:17:51.316 --> 00:17:52.616
I'm going to keep one buffer

00:17:52.616 --> 00:17:54.456
that I'm holding onto while I'm

00:17:54.456 --> 00:17:55.346
analyzing this.

00:17:55.346 --> 00:17:56.316
This is actually when I run my

00:17:56.316 --> 00:17:57.326
classification.

00:17:58.746 --> 00:18:00.406
And since this can be a longer

00:18:00.406 --> 00:18:01.716
running task, I'm actually going

00:18:01.716 --> 00:18:03.086
to run this on a separate queue.

00:18:03.566 --> 00:18:06.926
Alright, here's some code that I

00:18:06.926 --> 00:18:09.046
actually just used to open.

00:18:09.096 --> 00:18:10.646
This is actually like the little

00:18:10.646 --> 00:18:11.296
panel that we saw.

00:18:11.546 --> 00:18:12.636
But the important part is

00:18:12.636 --> 00:18:13.806
actually, "So, how do I setup my

00:18:13.806 --> 00:18:14.216
Vision task?"

00:18:14.216 --> 00:18:16.266
So, I'm going to do two tasks.

00:18:16.266 --> 00:18:17.716
I'm going to do a barcode

00:18:17.716 --> 00:18:19.546
request and I'm going to do my

00:18:19.546 --> 00:18:20.816
classification request.

00:18:21.346 --> 00:18:22.916
So, I set up my barcode request.

00:18:23.946 --> 00:18:25.596
And in my completion handler, I

00:18:25.596 --> 00:18:27.176
simple look at, "Do I get

00:18:27.176 --> 00:18:29.376
something back?"

00:18:29.616 --> 00:18:31.176
and also just since I'm only

00:18:31.176 --> 00:18:32.756
expecting one barcode, I only

00:18:32.756 --> 00:18:34.036
look at the very first one.

00:18:35.086 --> 00:18:35.936
Can I decode it?

00:18:36.106 --> 00:18:37.296
If I get a string out of it, I

00:18:37.296 --> 00:18:38.596
use that actually to look up --

00:18:38.636 --> 00:18:39.616
that's actually how it worked

00:18:39.616 --> 00:18:40.866
with my barcodes to see then --

00:18:40.966 --> 00:18:42.146
oh, yes, that is my training

00:18:42.146 --> 00:18:42.213
[inaudible].

00:18:42.213 --> 00:18:44.786
Alright, so I add that as one of

00:18:44.816 --> 00:18:46.906
the requests that I want to run.

00:18:47.496 --> 00:18:48.596
Now, I'm setting up my

00:18:48.596 --> 00:18:49.466
classification.

00:18:50.036 --> 00:18:51.006
So, in this case, what I've

00:18:51.076 --> 00:18:53.586
done, I used my classifier and

00:18:53.586 --> 00:18:55.196
I'm loading simply this from my

00:18:55.776 --> 00:18:58.906
bundle and create my model from

00:18:58.906 --> 00:18:59.136
there.

00:18:59.416 --> 00:19:00.566
Now, I'm not using the code

00:19:00.566 --> 00:19:02.036
completion from Core ML in this

00:19:02.036 --> 00:19:03.946
case, because this is the only

00:19:03.946 --> 00:19:05.136
line of Core ML that I'm

00:19:05.136 --> 00:19:05.916
actually using my whole

00:19:05.916 --> 00:19:07.536
application, and it allows me to

00:19:07.536 --> 00:19:08.936
do my custom kind of error

00:19:08.936 --> 00:19:09.276
handling.

00:19:09.396 --> 00:19:10.866
But, you can choose also to use

00:19:10.866 --> 00:19:12.226
the code completion already from

00:19:12.226 --> 00:19:12.676
Core ML.

00:19:12.776 --> 00:19:13.936
Both are absolutely valid.

00:19:14.866 --> 00:19:16.316
Now, I create my Vision model

00:19:16.316 --> 00:19:17.196
from that.

00:19:17.196 --> 00:19:19.826
My Vision Core ML Model, and my

00:19:19.826 --> 00:19:20.416
request.

00:19:20.816 --> 00:19:22.736
And again, simply when the

00:19:22.736 --> 00:19:24.576
request returns, meaning I'm

00:19:24.576 --> 00:19:26.236
executing my completion handler.

00:19:26.756 --> 00:19:29.046
I simply look, "What kind of

00:19:29.266 --> 00:19:30.626
specifications did I get back?"

00:19:31.786 --> 00:19:33.386
And then I set this threshold

00:19:33.386 --> 00:19:33.676
here.

00:19:34.236 --> 00:19:35.396
Now, this is one that I

00:19:35.396 --> 00:19:36.676
empirically set against a

00:19:36.676 --> 00:19:37.396
confidence goal.

00:19:37.396 --> 00:19:38.876
I'm using 0.98.

00:19:39.026 --> 00:19:41.466
So, a 98% confidence that this

00:19:41.466 --> 00:19:43.496
is actually correct.

00:19:43.496 --> 00:19:44.506
Why am I doing that?

00:19:45.156 --> 00:19:46.766
That allows me to filter out

00:19:46.766 --> 00:19:47.516
actually when I'm looking at

00:19:47.516 --> 00:19:48.646
something, and maybe not quite

00:19:48.646 --> 00:19:49.426
sure what that is.

00:19:49.426 --> 00:19:50.146
Maybe we'll see that in a

00:19:50.146 --> 00:19:51.036
moment, actually what that

00:19:51.036 --> 00:19:51.376
means.

00:19:52.606 --> 00:19:54.516
So now, I have all my requests.

00:19:55.556 --> 00:19:56.916
When it comes to the time that I

00:19:56.916 --> 00:19:57.996
actually want to execute them, I

00:19:57.996 --> 00:19:59.366
created a little function here

00:19:59.366 --> 00:20:01.036
that actually mean, "analyze on

00:20:01.036 --> 00:20:01.836
the current image."

00:20:02.516 --> 00:20:04.496
So, when it's time to analyze

00:20:04.496 --> 00:20:07.446
it, I get my device orientation,

00:20:07.446 --> 00:20:09.326
which is important to know how

00:20:09.326 --> 00:20:10.936
am I holding my phone.

00:20:11.886 --> 00:20:13.116
I create an image request

00:20:13.116 --> 00:20:14.966
handler on that buffer that we

00:20:15.536 --> 00:20:16.626
currently want to process.

00:20:17.936 --> 00:20:21.016
And asynchronously, I let it

00:20:21.046 --> 00:20:22.586
perform its work.

00:20:24.056 --> 00:20:25.226
That's all I have to do

00:20:25.226 --> 00:20:26.476
basically for actually doing the

00:20:26.476 --> 00:20:28.706
processing with Core ML and

00:20:28.706 --> 00:20:29.506
barcode reading.

00:20:30.326 --> 00:20:32.556
Now, a few things, just okay.

00:20:32.556 --> 00:20:33.976
How do I do the scene stability

00:20:33.976 --> 00:20:34.306
part?

00:20:34.766 --> 00:20:36.076
So, I have a queue that I can

00:20:36.076 --> 00:20:36.536
reset.

00:20:36.766 --> 00:20:38.916
I can add my points into that.

00:20:39.966 --> 00:20:41.376
And then simply I had created a

00:20:41.376 --> 00:20:43.396
function that allows me to look

00:20:43.396 --> 00:20:44.776
basically through the queue of

00:20:44.856 --> 00:20:46.096
points that I've recorded.

00:20:46.526 --> 00:20:47.806
And then setting like, "Well, if

00:20:47.806 --> 00:20:49.986
they all sum together, only show

00:20:49.986 --> 00:20:51.576
a distance of like 20 pixels."

00:20:51.576 --> 00:20:52.876
Again, that's an empirical value

00:20:52.876 --> 00:20:53.546
that I chose.

00:20:53.876 --> 00:20:55.376
Then I know the scene is stable.

00:20:55.376 --> 00:20:56.366
So, I'm holding stable.

00:20:56.366 --> 00:20:57.646
Nothing is moving in front of my

00:20:57.646 --> 00:20:58.076
camera.

00:20:58.866 --> 00:21:01.326
And then comes our part of catch

00:21:01.326 --> 00:21:01.766
the output.

00:21:01.766 --> 00:21:02.786
So, this is the call that

00:21:02.786 --> 00:21:04.746
actually AV Foundation calls

00:21:04.746 --> 00:21:05.416
[inaudible] buffers from the

00:21:05.416 --> 00:21:05.866
camera.

00:21:06.726 --> 00:21:08.056
I'm making sure that I you know,

00:21:08.056 --> 00:21:09.486
hold onto the previous pixel

00:21:09.486 --> 00:21:11.026
buffer because that's what I'm

00:21:11.026 --> 00:21:12.486
going to compare against for my

00:21:12.636 --> 00:21:15.996
registration, and swap those out

00:21:15.996 --> 00:21:17.006
after I'm done with that.

00:21:17.956 --> 00:21:19.196
So, I create my Translational

00:21:19.196 --> 00:21:20.646
Image Registration Request with

00:21:20.646 --> 00:21:21.416
my current buffer.

00:21:21.416 --> 00:21:24.136
And then on the Sequence Request

00:21:24.136 --> 00:21:25.916
Handler, I simply perform my

00:21:25.916 --> 00:21:26.496
request.

00:21:27.376 --> 00:21:28.956
Now, I get my observations back.

00:21:29.616 --> 00:21:30.546
I can check if they are all

00:21:30.546 --> 00:21:30.956
okay.

00:21:31.716 --> 00:21:33.146
And add them into my array.

00:21:34.496 --> 00:21:36.476
And last but not least, I check

00:21:36.796 --> 00:21:37.786
if the scene's stable.

00:21:38.566 --> 00:21:39.966
Then I bring up my little,

00:21:39.966 --> 00:21:41.856
yellow box which is [inaudible]

00:21:42.326 --> 00:21:43.216
detection overlay.

00:21:44.466 --> 00:21:45.946
I know this is my currently

00:21:45.946 --> 00:21:46.866
analyzed buffer.

00:21:47.766 --> 00:21:51.296
And simply ask it to form its

00:21:51.296 --> 00:21:52.276
analysis on that.

00:21:52.906 --> 00:21:55.746
The one thing that you saw that

00:21:55.746 --> 00:21:57.936
I did at the end of the

00:21:58.426 --> 00:22:00.056
asynchronous call, in the

00:22:00.056 --> 00:22:01.266
currently analyzed buffer, I

00:22:01.266 --> 00:22:02.206
released that buffer.

00:22:02.816 --> 00:22:04.736
And you see here that I check if

00:22:04.776 --> 00:22:05.856
there is a buffer currently

00:22:05.856 --> 00:22:06.486
being used.

00:22:06.896 --> 00:22:08.496
Now, that allows me to make sure

00:22:08.496 --> 00:22:09.916
that I'm only really working on

00:22:09.916 --> 00:22:10.736
one buffer, and I'm not

00:22:10.736 --> 00:22:12.036
constantly queueing up more and

00:22:12.036 --> 00:22:13.156
more buffers while they're still

00:22:13.156 --> 00:22:13.936
running in the background,

00:22:13.936 --> 00:22:15.036
because that will starve the

00:22:15.036 --> 00:22:15.986
camera from frames.

00:22:17.436 --> 00:22:18.756
Alright, so when we run this,

00:22:18.856 --> 00:22:19.896
there's a few things I want to

00:22:19.896 --> 00:22:20.756
highlight actually.

00:22:20.946 --> 00:22:23.046
So, let me bring up Number 1,

00:22:24.446 --> 00:22:25.856
our console here a little bit on

00:22:25.856 --> 00:22:26.336
the bottom.

00:22:26.736 --> 00:22:28.176
And you can actually see, when

00:22:28.176 --> 00:22:30.146
I'm running this at first, and

00:22:30.146 --> 00:22:32.226
so, I'm going to run this right

00:22:32.226 --> 00:22:32.736
now here.

00:22:33.466 --> 00:22:36.566
Hopefully you should actually

00:22:36.566 --> 00:22:37.136
see something.

00:22:38.406 --> 00:22:39.786
You see that the confidence

00:22:39.786 --> 00:22:41.056
scores are pretty low because

00:22:41.056 --> 00:22:42.606
I'm actually [inaudible] over

00:22:42.606 --> 00:22:42.746
the [inaudible].

00:22:42.746 --> 00:22:44.116
It's not really sure what I'm

00:22:44.116 --> 00:22:44.856
really looking at.

00:22:45.576 --> 00:22:46.816
The moment actually I point it

00:22:46.816 --> 00:22:47.736
at something that it should

00:22:47.736 --> 00:22:50.986
identify, boom, our confidence

00:22:50.986 --> 00:22:52.176
score goes really high and

00:22:52.176 --> 00:22:53.566
that's actually how I'm sure

00:22:53.566 --> 00:22:54.826
that this is really the object I

00:22:54.826 --> 00:22:55.416
want to show.

00:22:56.906 --> 00:22:58.016
Now, another thing I wanted to

00:22:58.076 --> 00:23:02.666
demo, let's look actually what

00:23:02.666 --> 00:23:04.836
happens in terms of the CPU.

00:23:05.256 --> 00:23:08.206
Alright, so right now, I'm not

00:23:08.206 --> 00:23:08.846
doing anything.

00:23:08.846 --> 00:23:11.466
I'm just showing my screen.

00:23:12.256 --> 00:23:13.656
So, when I'm just moving the

00:23:13.656 --> 00:23:16.366
camera around, scene is not

00:23:16.366 --> 00:23:18.976
stable, I'm using about 22% of

00:23:18.976 --> 00:23:19.476
the CPU.

00:23:19.476 --> 00:23:21.326
Now, if I hold it stable and

00:23:21.326 --> 00:23:22.506
actually the classifier runs,

00:23:22.506 --> 00:23:23.916
you see how the CPU goes up.

00:23:24.486 --> 00:23:25.686
And that's why I always

00:23:25.686 --> 00:23:27.736
recommend only run these tasks

00:23:27.736 --> 00:23:28.486
when you really need.

00:23:29.046 --> 00:23:33.466
Alright, that was a lot to take

00:23:33.466 --> 00:23:33.756
in.

00:23:34.146 --> 00:23:36.256
Let's go back to the slides and

00:23:36.256 --> 00:23:37.376
recap a little bit what we have

00:23:37.376 --> 00:23:38.306
just seen to now.

00:23:39.846 --> 00:23:40.926
So, go right to the slides.

00:23:41.516 --> 00:23:47.736
[ Applause ]

00:23:48.236 --> 00:23:49.076
Okay, recap.

00:23:49.586 --> 00:23:51.566
First thing, how did we achieve

00:23:51.566 --> 00:23:52.556
our scene stability?

00:23:53.296 --> 00:23:55.206
We used a sequence request

00:23:55.206 --> 00:23:56.706
handler together with the VN

00:23:56.706 --> 00:23:58.166
Translational Image Registration

00:23:58.166 --> 00:24:01.186
Request, to compare against the

00:24:01.186 --> 00:24:02.026
previous frame.

00:24:03.436 --> 00:24:04.916
Out of that, we get our

00:24:04.916 --> 00:24:07.406
translation as of terms of an

00:24:07.406 --> 00:24:08.826
alignment transform which tells

00:24:08.826 --> 00:24:10.296
me the X and Y of like how the

00:24:10.296 --> 00:24:13.116
previous frame has shifted to

00:24:13.116 --> 00:24:13.966
[inaudible] the current one.

00:24:15.986 --> 00:24:17.126
Then we talked about that we

00:24:17.126 --> 00:24:18.596
want to only analyze the scene

00:24:18.596 --> 00:24:19.326
when it's stable.

00:24:20.266 --> 00:24:22.896
And for that, we created our VN

00:24:22.896 --> 00:24:24.156
Image Request Handler off the

00:24:24.156 --> 00:24:24.986
current buffer.

00:24:25.396 --> 00:24:28.116
And we passed in together both

00:24:28.116 --> 00:24:30.636
the barcode detection and the

00:24:30.636 --> 00:24:31.586
classification.

00:24:32.206 --> 00:24:34.086
So, that allows Vision to do its

00:24:34.086 --> 00:24:35.956
optimization underneath the

00:24:35.956 --> 00:24:37.936
covers and can actually perform

00:24:37.936 --> 00:24:39.056
much faster than if you would

00:24:39.236 --> 00:24:40.536
run them as separate requests.

00:24:41.006 --> 00:24:44.606
Next was the part about thinking

00:24:44.606 --> 00:24:46.636
about how many buffers do I hold

00:24:46.636 --> 00:24:47.166
in flight?

00:24:47.636 --> 00:24:48.976
And that's why I say manage your

00:24:48.976 --> 00:24:49.436
buffers.

00:24:50.966 --> 00:24:52.396
Some Vision requests, like these

00:24:52.816 --> 00:24:54.696
convolutional networks, can take

00:24:54.696 --> 00:24:55.316
a bit longer.

00:24:55.966 --> 00:24:57.396
And these longer running tasks

00:24:57.396 --> 00:24:59.016
are better to perform on a

00:24:59.016 --> 00:25:01.216
background queue, so that

00:25:01.216 --> 00:25:02.366
[inaudible] or whatever you do

00:25:02.366 --> 00:25:03.176
in the camera, can actually

00:25:03.176 --> 00:25:04.306
continuously running.

00:25:05.036 --> 00:25:06.256
But to do this particularly with

00:25:06.256 --> 00:25:07.656
the camera, you do not want to

00:25:07.656 --> 00:25:08.866
continuously queue up the

00:25:08.866 --> 00:25:10.266
buffers coming from the camera.

00:25:10.266 --> 00:25:11.336
So, you want to drop busy

00:25:11.336 --> 00:25:11.826
buffers.

00:25:12.216 --> 00:25:14.006
In this case, I said I only work

00:25:14.006 --> 00:25:14.526
with one.

00:25:14.526 --> 00:25:15.756
That's actually in my use case

00:25:15.756 --> 00:25:16.816
scenario works pretty well.

00:25:17.286 --> 00:25:18.586
So, I have a queue of 1, and

00:25:18.586 --> 00:25:19.666
that's why I simply held onto

00:25:19.666 --> 00:25:21.156
one buffer and check, as long as

00:25:21.156 --> 00:25:22.506
that one is running, I'm not

00:25:22.506 --> 00:25:23.536
queuing new buffers up.

00:25:23.956 --> 00:25:25.906
Once I'm done with it, I can

00:25:25.906 --> 00:25:30.266
reset and work on the next

00:25:30.876 --> 00:25:31.056
buffer.

00:25:31.206 --> 00:25:33.336
Now, you might ask, "Why am I

00:25:33.336 --> 00:25:34.906
using Vision when I can run this

00:25:34.906 --> 00:25:35.696
model in Core ML?

00:25:35.696 --> 00:25:36.646
It's a Core ML model."

00:25:38.206 --> 00:25:40.196
Well, there is one thing why

00:25:40.196 --> 00:25:41.236
this is important to actually

00:25:41.236 --> 00:25:41.746
use Vision.

00:25:42.316 --> 00:25:43.676
Let's go back and look what we

00:25:43.676 --> 00:25:45.196
saw when we looked at our model.

00:25:45.646 --> 00:25:47.616
It was the strange number of 299

00:25:47.616 --> 00:25:48.936
by 299 pixels.

00:25:49.626 --> 00:25:50.886
Now, this is simply how this

00:25:50.886 --> 00:25:51.666
model is trained.

00:25:51.666 --> 00:25:53.036
This is what it wants to ingest.

00:25:53.886 --> 00:25:54.996
But our camera gives us

00:25:54.996 --> 00:25:57.206
something like 640 by 480 or

00:25:57.206 --> 00:25:58.746
larger resolutions if you want.

00:25:59.876 --> 00:26:02.156
Now, Vision is going to do all

00:26:02.156 --> 00:26:03.766
the work by taking these

00:26:03.766 --> 00:26:04.646
[inaudible] buffers as they come

00:26:04.646 --> 00:26:05.976
from the camera, converts it

00:26:05.976 --> 00:26:07.466
into RGB and scales it down and

00:26:07.466 --> 00:26:08.606
you don't have to write any code

00:26:08.606 --> 00:26:09.836
for that.

00:26:10.326 --> 00:26:11.506
That makes it much easier to

00:26:11.576 --> 00:26:13.026
drive these Core ML models for

00:26:13.026 --> 00:26:14.436
image requests through Vision.

00:26:15.056 --> 00:26:18.146
So, that was image

00:26:18.146 --> 00:26:19.106
classification.

00:26:19.346 --> 00:26:20.996
Next, we talk about object

00:26:20.996 --> 00:26:21.546
recognition.

00:26:22.186 --> 00:26:25.406
Now, a little warning.

00:26:25.406 --> 00:26:26.726
In this demo, actually a live

00:26:26.726 --> 00:26:27.876
croissant might actually get

00:26:27.876 --> 00:26:28.506
hurt on stage.

00:26:28.506 --> 00:26:29.796
So, for the squeamish ones,

00:26:29.796 --> 00:26:32.466
please look away.

00:26:34.726 --> 00:26:36.966
So, what we're using for our

00:26:36.966 --> 00:26:38.826
object recognition is a model

00:26:38.826 --> 00:26:40.926
that is based on this YOLO

00:26:40.926 --> 00:26:42.676
technique, You Only Look Once.

00:26:43.096 --> 00:26:44.786
That is a pretty fast-running

00:26:44.786 --> 00:26:46.646
model that allows us to get the

00:26:46.646 --> 00:26:49.326
bounding boxes off objects and a

00:26:49.326 --> 00:26:50.856
label for that.

00:26:50.906 --> 00:26:52.346
And it finds multiple of them in

00:26:52.346 --> 00:26:52.676
the screen.

00:26:52.676 --> 00:26:53.906
As you see in the screenshots.

00:26:56.256 --> 00:26:59.626
The advantage of those is that I

00:26:59.626 --> 00:27:00.726
get actually like where they

00:27:00.726 --> 00:27:02.216
are, but I won't get as many

00:27:02.216 --> 00:27:03.816
classifications as I can do with

00:27:03.816 --> 00:27:05.306
like our overall image

00:27:05.306 --> 00:27:05.946
classifier.

00:27:06.556 --> 00:27:08.666
The training is also a little

00:27:08.666 --> 00:27:10.286
bit more involved, and with

00:27:10.356 --> 00:27:11.576
that, I would like to actually

00:27:11.576 --> 00:27:13.466
refer you to the Turi Create

00:27:13.466 --> 00:27:14.826
session that was, I believe,

00:27:14.876 --> 00:27:16.286
yesterday, where they actually

00:27:16.286 --> 00:27:17.716
showed you how to train these

00:27:17.746 --> 00:27:18.436
kind of models.

00:27:18.746 --> 00:27:20.106
These models are also a little

00:27:20.686 --> 00:27:21.646
bit bigger.

00:27:21.836 --> 00:27:24.066
So, how does this look?

00:27:24.066 --> 00:27:31.006
Let's go over to our demo.

00:27:31.606 --> 00:27:35.946
Robot shop is closed.

00:27:39.466 --> 00:27:40.846
Time for breakfast.

00:27:42.296 --> 00:27:42.706
Alright.

00:27:43.626 --> 00:27:45.196
Let me bring up my quick

00:27:45.196 --> 00:27:46.726
template here and I have my new

00:27:46.726 --> 00:27:47.876
little application.

00:27:47.876 --> 00:27:49.406
It is my Breakfast Finder.

00:27:49.976 --> 00:27:53.186
And what do we see?

00:27:53.536 --> 00:27:55.446
Oh, we have a croissant, we have

00:27:55.446 --> 00:27:57.616
a bagel, and we can identify the

00:27:57.616 --> 00:27:58.356
banana.

00:28:00.196 --> 00:28:01.436
And see, they can all be kind of

00:28:01.436 --> 00:28:02.466
like in the frame.

00:28:02.566 --> 00:28:03.626
I'm going to detect them.

00:28:04.916 --> 00:28:06.616
So, some mention in these

00:28:06.616 --> 00:28:07.736
cooking shows, normally they

00:28:07.736 --> 00:28:09.476
show you how to do it, but then

00:28:09.476 --> 00:28:10.876
pull the prebaked stuff out of

00:28:10.876 --> 00:28:11.356
the oven.

00:28:12.546 --> 00:28:15.016
Well, this model, actually has

00:28:15.046 --> 00:28:16.916
been baked way before this

00:28:16.916 --> 00:28:18.356
croissant has been baked, and I

00:28:18.356 --> 00:28:19.026
can prove this.

00:28:21.766 --> 00:28:22.456
It's fresh.

00:28:22.656 --> 00:28:24.916
And still a croissant.

00:28:25.516 --> 00:28:33.926
[ Applause ]

00:28:34.426 --> 00:28:34.816
Alright.

00:28:35.706 --> 00:28:40.426
It's fresh but still, got to

00:28:41.056 --> 00:28:41.146
chew.

00:28:43.306 --> 00:28:46.766
Let's look quickly how this

00:28:46.766 --> 00:28:52.666
looks in the code.

00:28:53.266 --> 00:28:54.736
So, what did I do differently?

00:28:55.916 --> 00:28:57.116
[Inaudible] actually in the

00:28:57.116 --> 00:28:58.296
terms of like setting up my

00:28:58.296 --> 00:28:58.956
request.

00:28:59.746 --> 00:29:02.726
All I have to do is use my Core

00:29:02.726 --> 00:29:04.376
ML model, just as I did in the

00:29:04.466 --> 00:29:06.596
previous example, create my Core

00:29:06.596 --> 00:29:09.276
ML request, and afterwards, I'm

00:29:09.356 --> 00:29:10.906
looking actually at simply, "How

00:29:10.906 --> 00:29:12.026
do I draw my results?"

00:29:13.066 --> 00:29:17.856
Now this is where we have

00:29:17.856 --> 00:29:20.076
something new to make this

00:29:20.076 --> 00:29:21.096
[inaudible] a little bit easier.

00:29:21.876 --> 00:29:24.066
And when we look at all of this,

00:29:24.776 --> 00:29:27.066
we get a new object that is the

00:29:27.066 --> 00:29:28.106
[inaudible] recognized --

00:29:28.816 --> 00:29:30.886
Recognized Object Observation,

00:29:31.626 --> 00:29:33.256
and out of that, I get my

00:29:33.256 --> 00:29:35.786
bounding box, and my observation

00:29:35.786 --> 00:29:36.766
of like the labels.

00:29:38.006 --> 00:29:38.826
Now, that's one thing I would

00:29:38.826 --> 00:29:39.736
like to show you here.

00:29:40.936 --> 00:29:42.276
Let's run our application from

00:29:42.276 --> 00:29:43.506
here and I put a break point.

00:29:51.066 --> 00:29:51.796
Okay.

00:29:52.726 --> 00:29:55.206
Alright, we are now on our break

00:29:55.206 --> 00:29:55.476
point.

00:29:56.276 --> 00:29:57.956
So that I only look at the first

00:29:57.956 --> 00:29:58.226
label.

00:29:58.226 --> 00:29:59.886
So, what we are doing when we

00:29:59.886 --> 00:30:01.456
actually process these results,

00:30:02.036 --> 00:30:11.676
I'm going to take this, let's

00:30:11.876 --> 00:30:17.116
try object observation, labels.

00:30:17.156 --> 00:30:21.076
So, what you actually see is

00:30:21.076 --> 00:30:22.826
that I get more than one back.

00:30:23.376 --> 00:30:25.336
I get my bagel, my banana,

00:30:25.566 --> 00:30:26.576
coffee -- I didn't bring any

00:30:26.576 --> 00:30:27.096
coffee today.

00:30:27.096 --> 00:30:28.266
Sorry about that.

00:30:28.266 --> 00:30:30.726
And croissant, egg, and waffle.

00:30:30.946 --> 00:30:32.786
Now, they are sorted in the

00:30:32.786 --> 00:30:33.856
order of like the highest

00:30:33.856 --> 00:30:34.866
confidence on the top.

00:30:35.036 --> 00:30:36.536
Usually, this is the one that

00:30:36.536 --> 00:30:37.226
you're interested in.

00:30:37.226 --> 00:30:38.006
That's why I'm taking the

00:30:38.006 --> 00:30:39.306
shortcut here and just looking

00:30:39.306 --> 00:30:40.046
at the first one.

00:30:40.316 --> 00:30:41.856
But you always get all of the

00:30:41.856 --> 00:30:43.686
classifications back in terms of

00:30:43.686 --> 00:30:45.586
an array of the ones that we

00:30:45.586 --> 00:30:46.876
actually support in the model.

00:30:48.576 --> 00:30:48.986
Alright.

00:30:49.966 --> 00:30:51.396
That was our Breakfast Finder.

00:30:51.396 --> 00:30:52.786
Let's go back to the slides, and

00:30:52.786 --> 00:30:53.566
this time, I'm pushing the

00:30:53.566 --> 00:30:53.886
button.

00:30:54.146 --> 00:30:54.286
Good.

00:30:58.536 --> 00:31:00.346
So, we made this possible

00:31:00.736 --> 00:31:02.826
through a new API and that is

00:31:02.826 --> 00:31:04.376
our VN Recognized Object

00:31:04.376 --> 00:31:04.986
Observation.

00:31:06.486 --> 00:31:08.896
It comes automatically when we

00:31:08.986 --> 00:31:11.336
perform a Core ML model request,

00:31:11.476 --> 00:31:13.776
and if that model is actually

00:31:13.776 --> 00:31:16.586
using an object detector as a

00:31:16.586 --> 00:31:17.086
space.

00:31:18.666 --> 00:31:22.486
Like in this example, it is

00:31:22.486 --> 00:31:23.786
based on the YOLO based models.

00:31:23.966 --> 00:31:25.236
Now, you might say, "Well, I

00:31:25.236 --> 00:31:26.896
could have already run YOLO like

00:31:26.896 --> 00:31:27.306
last year.

00:31:27.306 --> 00:31:28.376
There were a bunch of articles

00:31:28.376 --> 00:31:29.106
that I saw on the web."

00:31:29.896 --> 00:31:31.206
But look at how much code they

00:31:31.206 --> 00:31:33.056
actually had to write to take

00:31:33.056 --> 00:31:34.776
the output of this model, to

00:31:34.776 --> 00:31:35.936
then put it into something that

00:31:35.936 --> 00:31:36.526
you can use.

00:31:36.666 --> 00:31:38.086
And here, we only had a few

00:31:38.086 --> 00:31:38.696
lines of code.

00:31:38.816 --> 00:31:40.346
So, it makes YOLO models really,

00:31:40.346 --> 00:31:41.256
really easy to use now.

00:31:41.256 --> 00:31:43.336
Let's go once more over this in

00:31:43.336 --> 00:31:43.746
the code.

00:31:44.316 --> 00:31:45.536
So, I create my model.

00:31:46.336 --> 00:31:47.426
From the model, I create my

00:31:47.426 --> 00:31:48.006
request.

00:31:48.986 --> 00:31:51.196
And in my completion handler, I

00:31:51.196 --> 00:31:52.606
can simply look at the area of

00:31:52.606 --> 00:31:54.066
objects, because we saw we can

00:31:54.066 --> 00:31:55.366
get multiple objects back.

00:31:55.996 --> 00:31:57.396
I get my labels from that, my

00:31:57.396 --> 00:31:59.546
bounding box, and I can show my

00:31:59.546 --> 00:32:00.286
Breakfast Finder.

00:32:00.926 --> 00:32:04.966
Now, there's one more thing I

00:32:04.966 --> 00:32:06.216
would like to highlight in this

00:32:06.216 --> 00:32:06.756
example.

00:32:08.426 --> 00:32:09.646
You saw how these boxes were a

00:32:09.646 --> 00:32:10.666
little bit jittering around

00:32:10.666 --> 00:32:11.496
because I was running the

00:32:11.496 --> 00:32:12.896
detector frame by frame, by

00:32:12.896 --> 00:32:13.636
frame, by frame.

00:32:14.346 --> 00:32:16.506
Tracking can often be a better

00:32:16.506 --> 00:32:17.086
choice here.

00:32:17.376 --> 00:32:20.216
Why? Tracking is much faster

00:32:20.216 --> 00:32:21.646
even in terms of like running,

00:32:21.646 --> 00:32:22.936
than actually these models would

00:32:22.936 --> 00:32:23.116
run.

00:32:25.276 --> 00:32:27.136
So, redetection takes more time

00:32:27.136 --> 00:32:28.976
than actually running a tracking

00:32:28.976 --> 00:32:29.566
request.

00:32:31.306 --> 00:32:33.056
I can use the tracker basically

00:32:33.056 --> 00:32:34.306
if I want to follow now an

00:32:34.306 --> 00:32:37.416
object on the screen because

00:32:37.416 --> 00:32:38.376
it's a lighter algorithm.

00:32:38.376 --> 00:32:39.306
It runs faster.

00:32:39.906 --> 00:32:41.846
And on top of it, we have

00:32:41.906 --> 00:32:43.666
temporal smoothing so that these

00:32:43.716 --> 00:32:44.896
boxes will not jitter around

00:32:44.896 --> 00:32:46.616
anymore and if you see some of

00:32:46.616 --> 00:32:47.836
our tracking examples, they

00:32:47.836 --> 00:32:48.946
actually move nicely and

00:32:48.946 --> 00:32:50.046
smoothly across the screen.

00:32:50.966 --> 00:32:52.156
If you want to learn more about

00:32:52.156 --> 00:32:54.996
tracking, the previous session

00:32:54.996 --> 00:32:56.106
from my colleague Sergei,

00:32:56.106 --> 00:32:58.216
actually talks about how to do

00:32:58.216 --> 00:33:00.546
all the implementation work of

00:33:01.216 --> 00:33:01.386
that.

00:33:02.076 --> 00:33:04.426
Alright, last but not least,

00:33:04.426 --> 00:33:06.006
let's enhance our Vision mastery

00:33:06.006 --> 00:33:06.876
and go into some of our

00:33:06.876 --> 00:33:07.586
fundamentals.

00:33:08.556 --> 00:33:10.256
Few things are important to know

00:33:10.256 --> 00:33:11.246
when dealing with the Vision

00:33:11.246 --> 00:33:11.756
framework.

00:33:12.976 --> 00:33:14.206
First and foremost, and this is

00:33:14.206 --> 00:33:16.006
a common source of problems,

00:33:17.056 --> 00:33:18.066
image orientation.

00:33:20.016 --> 00:33:21.546
Now, not all of our Vision

00:33:21.546 --> 00:33:22.916
algorithms are orientation

00:33:22.916 --> 00:33:23.496
agnostic.

00:33:24.096 --> 00:33:25.106
You might have heard early that

00:33:25.106 --> 00:33:26.436
we have a new face detector that

00:33:26.436 --> 00:33:28.436
is orientation agnostic.

00:33:29.136 --> 00:33:30.656
But the previous one was not.

00:33:32.156 --> 00:33:33.636
This means we need to know what

00:33:33.636 --> 00:33:35.016
is the upright position of the

00:33:35.016 --> 00:33:35.406
image?

00:33:36.296 --> 00:33:38.436
And it can be deceiving because

00:33:38.436 --> 00:33:39.866
if you look at it and preview on

00:33:39.866 --> 00:33:41.376
the final, my image looks

00:33:41.376 --> 00:33:43.046
upright, but that is not how it

00:33:43.046 --> 00:33:43.906
is stored on disk.

00:33:45.026 --> 00:33:46.466
There is something that tells us

00:33:46.466 --> 00:33:48.206
how the device is oriented, and

00:33:48.206 --> 00:33:49.086
this is called the EXIF

00:33:49.086 --> 00:33:49.896
Orientation.

00:33:50.976 --> 00:33:53.856
So, if an image is captured,

00:33:53.856 --> 00:33:54.866
that's normally in the sensor

00:33:54.866 --> 00:33:56.346
orientation, with the EXIF, we

00:33:56.346 --> 00:33:57.716
know what is actually upright

00:33:57.906 --> 00:34:00.096
and if you pass an URL into

00:34:00.096 --> 00:34:03.176
Vision as our input, Vision is

00:34:03.176 --> 00:34:04.306
actually going to do all that

00:34:04.306 --> 00:34:05.446
work basically for you and

00:34:05.446 --> 00:34:06.456
actually read this EXIF

00:34:06.456 --> 00:34:07.786
information from the file.

00:34:09.246 --> 00:34:10.746
But like when -- as we showed in

00:34:10.746 --> 00:34:12.496
the demos earlier, if I use my

00:34:12.496 --> 00:34:14.335
live capture feed, I need to

00:34:14.335 --> 00:34:15.585
actually pass this information

00:34:15.585 --> 00:34:15.775
in.

00:34:16.335 --> 00:34:17.996
So, I have to look at what does

00:34:17.996 --> 00:34:20.036
my orientation from my UI device

00:34:20.096 --> 00:34:22.286
current orientation and convert

00:34:22.286 --> 00:34:23.456
this [inaudible] to CG Image

00:34:23.516 --> 00:34:24.666
Property Orientation because we

00:34:24.666 --> 00:34:26.126
need it in the form of an EXIF

00:34:26.126 --> 00:34:26.755
orientation.

00:34:27.356 --> 00:34:30.536
Next, let's talk a little bit

00:34:30.536 --> 00:34:31.946
about our coordinate system.

00:34:33.485 --> 00:34:35.295
For Vision, the origin is always

00:34:35.295 --> 00:34:37.706
in the lower, left corner.

00:34:37.806 --> 00:34:40.206
And all processing is done in

00:34:40.206 --> 00:34:41.646
the up right -- if the image

00:34:41.646 --> 00:34:42.996
would be in an upright position,

00:34:43.446 --> 00:34:44.585
hence the orientation is

00:34:44.585 --> 00:34:45.106
important.

00:34:47.266 --> 00:34:48.576
All our processing is really

00:34:48.576 --> 00:34:49.996
done in a normalized coordinate

00:34:49.996 --> 00:34:52.266
space, except the registration

00:34:52.266 --> 00:34:52.996
where we actually need to know

00:34:52.996 --> 00:34:54.216
how many pixels [inaudible].

00:34:54.896 --> 00:34:56.406
So, normalized coordinates means

00:34:56.856 --> 00:34:58.166
our coordinates go from zero,

00:34:58.166 --> 00:35:00.306
zero, to 1,1, in the upper right

00:35:00.336 --> 00:35:00.626
corner.

00:35:02.406 --> 00:35:04.016
Now what you see here is to that

00:35:04.116 --> 00:35:05.896
performed face and landmark

00:35:05.896 --> 00:35:06.916
detection request.

00:35:07.326 --> 00:35:09.036
And you will see that I get the

00:35:09.036 --> 00:35:10.496
bounding box for my face, and

00:35:10.496 --> 00:35:11.956
the landmarks are actually

00:35:11.956 --> 00:35:14.196
reported in relative coordinates

00:35:14.236 --> 00:35:17.106
to that bounding box.

00:35:17.296 --> 00:35:18.526
If you need to go back into the

00:35:18.526 --> 00:35:19.996
image coordinate space, we have

00:35:20.096 --> 00:35:22.006
utility functions and VNUtils

00:35:22.006 --> 00:35:22.946
like the VN Image [inaudible]

00:35:22.946 --> 00:35:25.476
from normalized way to convert

00:35:25.606 --> 00:35:28.006
back and forth between those

00:35:29.676 --> 00:35:30.056
coordinates.

00:35:31.416 --> 00:35:32.336
Next, let's talk about

00:35:32.336 --> 00:35:33.156
confidence scores.

00:35:33.156 --> 00:35:34.376
We touched a little bit on this

00:35:34.426 --> 00:35:36.076
already during our robot shot

00:35:36.076 --> 00:35:36.626
example.

00:35:36.626 --> 00:35:40.186
A lot of our algorithms can

00:35:40.186 --> 00:35:42.006
express how confident they are

00:35:42.006 --> 00:35:42.796
in their results.

00:35:43.746 --> 00:35:46.436
And that is kind of an important

00:35:46.436 --> 00:35:47.886
part to know when I want to

00:35:48.226 --> 00:35:49.706
analyze later on what I get out

00:35:49.706 --> 00:35:50.446
of these results.

00:35:50.536 --> 00:35:51.716
So, if I have a low confidence

00:35:51.716 --> 00:35:53.216
of zero, or do I have a high

00:35:53.216 --> 00:35:56.566
confidence of 1?

00:35:57.576 --> 00:36:02.676
Clicker. Here we go.

00:36:02.856 --> 00:36:03.086
Alright.

00:36:03.646 --> 00:36:05.606
Unfortunately, not all

00:36:05.606 --> 00:36:06.936
algorithms will have the same

00:36:06.936 --> 00:36:08.736
scale in terms of like how they

00:36:08.736 --> 00:36:10.156
report their confidence scores.

00:36:10.316 --> 00:36:12.356
For instance, if we look at our

00:36:12.356 --> 00:36:14.096
text detector, it pretty much

00:36:14.096 --> 00:36:15.336
always returns a confidence

00:36:15.336 --> 00:36:17.256
score of 1 because if it doesn't

00:36:17.256 --> 00:36:18.356
think there's text, it's not

00:36:18.356 --> 00:36:19.476
going to return the bounding box

00:36:19.476 --> 00:36:20.306
in the first place.

00:36:21.296 --> 00:36:23.646
But as we saw, the classifiers

00:36:23.856 --> 00:36:25.436
have a very large range actually

00:36:25.506 --> 00:36:26.736
of what this confidence score

00:36:26.736 --> 00:36:27.146
could be.

00:36:27.646 --> 00:36:28.866
Let's look at a few examples.

00:36:30.056 --> 00:36:33.356
In my first example, I used an

00:36:33.356 --> 00:36:34.696
image from our robot shop

00:36:34.696 --> 00:36:37.356
example and I ran my own model

00:36:37.356 --> 00:36:37.606
on it.

00:36:38.356 --> 00:36:40.076
And sure enough, it had a very

00:36:40.076 --> 00:36:41.326
high confidence, this is a

00:36:41.326 --> 00:36:42.006
stepper motor.

00:36:43.756 --> 00:36:45.996
Now, on this next examples, I'm

00:36:45.996 --> 00:36:47.296
going to use some of the models

00:36:47.296 --> 00:36:48.326
that we have in our model

00:36:48.326 --> 00:36:48.786
gallery.

00:36:49.836 --> 00:36:51.076
So, don't get me wrong.

00:36:51.076 --> 00:36:52.166
I don't want to compare the

00:36:52.166 --> 00:36:53.296
quality of the models.

00:36:53.296 --> 00:36:54.406
It's about like actually what

00:36:54.406 --> 00:36:56.126
did confidence they return and

00:36:56.126 --> 00:36:57.106
what actually want to do with

00:36:57.196 --> 00:36:57.436
this.

00:36:58.616 --> 00:36:59.836
So, what did this tell us

00:36:59.836 --> 00:37:00.966
basically when we want to

00:37:01.016 --> 00:37:02.536
classify this image?

00:37:03.176 --> 00:37:05.916
Well, it's not that bad, but

00:37:06.046 --> 00:37:07.376
it's really sure about it

00:37:07.376 --> 00:37:07.646
either.

00:37:08.166 --> 00:37:11.116
The confidence score of 0.395 is

00:37:11.116 --> 00:37:12.666
not particularly high, but yes,

00:37:12.696 --> 00:37:14.076
it has a sand part, there's some

00:37:14.076 --> 00:37:14.806
beach involved.

00:37:15.566 --> 00:37:18.336
So, that's usable basically as a

00:37:18.336 --> 00:37:19.616
result when I want to search for

00:37:19.616 --> 00:37:21.006
it, but might I label the image

00:37:21.046 --> 00:37:21.396
with that?

00:37:21.586 --> 00:37:22.756
It's probably questionable.

00:37:23.096 --> 00:37:25.536
Let's look at this next example.

00:37:27.076 --> 00:37:27.886
Girl on a scooter.

00:37:28.606 --> 00:37:29.716
What did the classifier do with

00:37:29.766 --> 00:37:30.036
this?

00:37:31.786 --> 00:37:32.766
Well, I'm not sure she's so

00:37:32.766 --> 00:37:33.796
happy to be called a sweet

00:37:33.796 --> 00:37:34.276
potato.

00:37:34.786 --> 00:37:40.916
Let's look at one more example.

00:37:41.416 --> 00:37:42.716
So, here's a screen shot of my

00:37:42.716 --> 00:37:43.066
code.

00:37:44.206 --> 00:37:45.476
What does the classifier do with

00:37:45.726 --> 00:37:46.966
that?

00:37:47.366 --> 00:37:48.786
It thinks it's a website.

00:37:48.936 --> 00:37:49.976
Computers are so dumb.

00:37:53.626 --> 00:37:55.376
So, some conclusions about our

00:37:55.376 --> 00:37:56.186
confidence scores.

00:37:58.306 --> 00:38:00.626
Does 1.0 always mean it's a 100%

00:38:00.626 --> 00:38:00.976
correct?

00:38:01.366 --> 00:38:02.456
Not necessarily.

00:38:02.896 --> 00:38:04.326
It will fill the criteria of the

00:38:04.326 --> 00:38:06.486
algorithm, but our perception,

00:38:06.486 --> 00:38:07.766
as we saw particularly with the

00:38:07.766 --> 00:38:09.666
sweet potato is quite different.

00:38:10.586 --> 00:38:12.646
So, when you create an

00:38:12.646 --> 00:38:13.966
application that wants to take

00:38:13.966 --> 00:38:15.736
advantage of that, please keep

00:38:15.736 --> 00:38:16.376
that in mind.

00:38:16.916 --> 00:38:17.316
Think of it.

00:38:17.316 --> 00:38:18.396
If you would write a medical

00:38:18.396 --> 00:38:19.606
application and saying, "Oh, you

00:38:19.606 --> 00:38:21.906
have cancer," that might be a

00:38:21.906 --> 00:38:23.626
very strong argument where you

00:38:23.626 --> 00:38:25.036
want to probably soften that a

00:38:25.036 --> 00:38:26.196
little bit depending on like how

00:38:26.196 --> 00:38:27.346
sure you can really be on the

00:38:27.346 --> 00:38:27.796
results.

00:38:29.326 --> 00:38:31.676
So, there are two techniques

00:38:31.676 --> 00:38:32.896
that you can use for this.

00:38:33.506 --> 00:38:35.016
As we saw in the robot shot

00:38:35.016 --> 00:38:36.776
example, I used a threshold on

00:38:36.776 --> 00:38:37.916
the confidence score because I

00:38:37.916 --> 00:38:39.766
really label the image and I you

00:38:39.946 --> 00:38:40.926
know, when it's actually

00:38:40.926 --> 00:38:41.746
filtering everything out that

00:38:41.746 --> 00:38:42.956
had a low confidence score.

00:38:43.676 --> 00:38:44.646
If on the other hand, I want to

00:38:44.646 --> 00:38:46.126
create a search application, I

00:38:46.126 --> 00:38:47.686
might actually use some of the

00:38:47.686 --> 00:38:50.856
images that I had and still show

00:38:50.856 --> 00:38:52.506
them, probably on the bottom of

00:38:52.546 --> 00:38:53.586
the search because there's still

00:38:53.586 --> 00:38:55.326
a valid choice, perhaps in the

00:38:55.326 --> 00:38:56.016
search results.

00:38:59.916 --> 00:39:03.186
As usual, we find some more

00:39:03.186 --> 00:39:04.486
information on our website.

00:39:04.946 --> 00:39:06.626
And we have our lab tomorrow at

00:39:06.626 --> 00:39:08.396
3 p.m. Please stop by.

00:39:08.576 --> 00:39:09.736
Ask your questions.

00:39:09.736 --> 00:39:10.556
We're there to help you.

00:39:10.596 --> 00:39:12.916
And with that, I would first of

00:39:12.916 --> 00:39:14.686
all like to thank you all for

00:39:14.686 --> 00:39:15.846
these great application that you

00:39:15.846 --> 00:39:17.046
create with our technology.

00:39:17.116 --> 00:39:18.756
I'm looking forward to see what

00:39:18.756 --> 00:39:19.536
you can do with this.

00:39:19.936 --> 00:39:21.256
And thank you all for coming to

00:39:21.256 --> 00:39:21.676
WWDC.

00:39:21.676 --> 00:39:22.696
Have a great rest of the show.

00:39:22.696 --> 00:39:23.296
Thank you.

00:39:24.516 --> 00:39:32.050
[ Applause ]