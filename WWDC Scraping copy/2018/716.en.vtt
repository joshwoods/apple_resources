WEBVTT

00:00:07.016 --> 00:00:14.500
[ Music ]

00:00:20.516 --> 00:00:27.186
[ Applause ]

00:00:27.686 --> 00:00:28.656
>> Good afternoon, everybody,

00:00:28.656 --> 00:00:30.936
and welcome to Object Tracking

00:00:30.936 --> 00:00:31.636
in Vision session.

00:00:32.375 --> 00:00:34.186
Do you ever need to face and

00:00:34.186 --> 00:00:35.316
solve various computer vision

00:00:35.316 --> 00:00:35.796
problems?

00:00:36.716 --> 00:00:38.726
If you do, and whether your Mac

00:00:39.406 --> 00:00:40.956
and iOS, or each of you as

00:00:40.996 --> 00:00:42.416
developer, you're in the right

00:00:42.416 --> 00:00:42.816
place.

00:00:43.426 --> 00:00:44.586
My name is Sergey Kamensky.

00:00:44.866 --> 00:00:46.186
I'm excited to share with you

00:00:46.496 --> 00:00:47.646
how Vision Framework can help.

00:00:51.356 --> 00:00:52.836
Our agenda today consists of

00:00:52.836 --> 00:00:53.456
four items.

00:00:53.836 --> 00:00:54.946
First, we're going to talk about

00:00:54.946 --> 00:00:55.396
Why Vision?

00:00:56.326 --> 00:00:57.596
Second, we're going to look

00:00:57.596 --> 00:00:58.966
about what's new that we're

00:00:58.966 --> 00:00:59.796
introducing this year.

00:01:00.866 --> 00:01:02.016
Third, we're going to have a

00:01:02.016 --> 00:01:03.506
deeper dive into helping

00:01:03.506 --> 00:01:04.456
throughout this Vision API.

00:01:04.906 --> 00:01:06.696
And then, finally, we're going

00:01:06.696 --> 00:01:07.816
to get to the main topic of our

00:01:07.816 --> 00:01:09.766
presentation, which is Tracking

00:01:09.886 --> 00:01:11.006
in Vision.

00:01:13.676 --> 00:01:15.626
So, why Vision?

00:01:17.616 --> 00:01:19.166
When we designed our framework,

00:01:19.416 --> 00:01:20.806
we wanted it to be one central

00:01:20.806 --> 00:01:22.186
stop to solve all of your

00:01:22.186 --> 00:01:24.366
computer vision problems while

00:01:24.366 --> 00:01:26.026
first in simple and consistent

00:01:26.026 --> 00:01:28.466
interface, one multi-platform;

00:01:28.776 --> 00:01:31.336
our framework runs on iOS,

00:01:31.676 --> 00:01:33.036
macOS, and tvOS.

00:01:34.226 --> 00:01:35.296
We're privacy oriented.

00:01:35.976 --> 00:01:37.376
What that means is that your

00:01:37.376 --> 00:01:39.056
data never leaves the device.

00:01:39.596 --> 00:01:40.496
All the [inaudible] sync is

00:01:40.496 --> 00:01:43.206
local, and we're continuously

00:01:43.206 --> 00:01:43.576
working.

00:01:44.586 --> 00:01:46.006
We're enhancing our existing

00:01:46.006 --> 00:01:48.246
algorithms, and we're developing

00:01:48.326 --> 00:01:49.746
new ones.

00:01:51.236 --> 00:01:52.786
Let's look at the Vision basics.

00:01:53.526 --> 00:01:55.736
When you think about how to

00:01:55.736 --> 00:01:57.526
interact with Vision API, I want

00:01:57.526 --> 00:01:59.086
you to think about in these

00:01:59.086 --> 00:02:01.686
terms, what to process, how to

00:02:01.686 --> 00:02:03.016
process, and where to look for

00:02:03.016 --> 00:02:03.326
results.

00:02:04.776 --> 00:02:06.076
What to process is about a

00:02:06.076 --> 00:02:07.056
family of requests.

00:02:07.826 --> 00:02:09.006
That is how you tell us what you

00:02:09.006 --> 00:02:09.395
want to do.

00:02:10.476 --> 00:02:12.986
How is about our request

00:02:12.986 --> 00:02:14.506
handlers or engines-- our

00:02:14.506 --> 00:02:16.246
request handlers, they're used

00:02:16.246 --> 00:02:18.156
to process our requests.

00:02:19.146 --> 00:02:20.906
And finally, the results; the

00:02:20.906 --> 00:02:22.546
results in Vision come in forms

00:02:22.546 --> 00:02:23.406
of observations.

00:02:24.556 --> 00:02:25.316
Please take a look at this

00:02:25.316 --> 00:02:25.576
slide.

00:02:26.296 --> 00:02:27.546
If you were to remember anything

00:02:27.546 --> 00:02:28.986
from this presentation, this

00:02:28.986 --> 00:02:29.956
slide is probably one of the

00:02:29.956 --> 00:02:30.876
more important ones.

00:02:31.326 --> 00:02:32.536
This slide presents a

00:02:32.536 --> 00:02:33.866
philosophy, how to interact with

00:02:33.866 --> 00:02:36.076
Vision, requests, request

00:02:36.706 --> 00:02:37.346
handlers,

00:02:38.236 --> 00:02:41.096
and observations.

00:02:42.356 --> 00:02:43.186
Let's look at the requests

00:02:43.186 --> 00:02:43.566
first.

00:02:44.276 --> 00:02:46.126
This is a collection of requests

00:02:46.126 --> 00:02:46.866
that we offer today.

00:02:46.866 --> 00:02:49.386
As you can see, we have various

00:02:49.386 --> 00:02:49.936
detectors.

00:02:50.536 --> 00:02:51.696
We have Image Registration

00:02:51.696 --> 00:02:52.096
Request.

00:02:52.806 --> 00:02:54.626
We have two trackers, and we

00:02:54.626 --> 00:02:55.826
have a CoreML request.

00:02:56.366 --> 00:02:57.426
If you're interested to learn

00:02:57.426 --> 00:02:59.116
more about integration of Vision

00:02:59.116 --> 00:03:00.956
and CoreML, I invite you to come

00:03:00.956 --> 00:03:02.246
to the next session in this room

00:03:02.516 --> 00:03:03.756
where Fran, my colleague, will

00:03:03.756 --> 00:03:05.246
cover details of that

00:03:05.246 --> 00:03:05.786
integration.

00:03:07.426 --> 00:03:09.546
Let's take a look at the request

00:03:09.546 --> 00:03:09.956
handlers.

00:03:10.936 --> 00:03:12.226
In Vision, we have two.

00:03:12.506 --> 00:03:13.896
We have Image Request Handler,

00:03:13.896 --> 00:03:15.766
and we have Sequence Request

00:03:15.766 --> 00:03:16.046
Handler.

00:03:16.646 --> 00:03:18.446
Let's compare the two using this

00:03:18.446 --> 00:03:18.826
criteria.

00:03:20.066 --> 00:03:21.196
First, we'll look at the Image

00:03:21.196 --> 00:03:21.736
Request Handler.

00:03:23.796 --> 00:03:25.326
Image request handler is used to

00:03:25.326 --> 00:03:27.996
process one or more requests on

00:03:27.996 --> 00:03:28.666
the same image.

00:03:30.126 --> 00:03:31.676
What it doesn't say, it caches

00:03:31.676 --> 00:03:33.066
certain information like image

00:03:33.066 --> 00:03:34.796
derivatives and results of

00:03:34.796 --> 00:03:35.636
posting requests.

00:03:35.956 --> 00:03:37.216
So, other requests in the

00:03:37.216 --> 00:03:38.416
pipeline can use that

00:03:38.416 --> 00:03:39.006
information.

00:03:39.666 --> 00:03:40.526
I'm going to give you an

00:03:40.526 --> 00:03:41.036
example.

00:03:41.396 --> 00:03:43.116
If a request depends on running

00:03:43.116 --> 00:03:44.606
neural network, as you know,

00:03:44.606 --> 00:03:46.436
neural network expects images in

00:03:46.436 --> 00:03:47.876
certain sizes and certain colors

00:03:47.876 --> 00:03:48.276
schemes.

00:03:48.606 --> 00:03:49.926
Let's say your neural network

00:03:50.076 --> 00:03:52.706
expects 500 by 500 black and

00:03:52.706 --> 00:03:52.906
white.

00:03:53.926 --> 00:03:55.446
It's very rare that you'll get

00:03:55.446 --> 00:03:57.006
user input just in that format.

00:03:57.236 --> 00:03:58.786
So, what we'll do inside, we'll

00:03:58.786 --> 00:03:59.626
convert the image.

00:03:59.856 --> 00:04:01.066
We'll feed it into that neural

00:04:01.066 --> 00:04:02.186
network to get results for the

00:04:02.186 --> 00:04:03.606
current request, but we will

00:04:03.606 --> 00:04:05.286
also cache that information on

00:04:05.286 --> 00:04:06.266
the request handler object.

00:04:06.706 --> 00:04:07.916
So, the next request, when it

00:04:07.916 --> 00:04:09.366
comes, if it needs to use the

00:04:09.366 --> 00:04:10.946
same format, it's already there,

00:04:11.016 --> 00:04:11.816
and it doesn't need to be

00:04:11.816 --> 00:04:12.356
recomputed.

00:04:13.246 --> 00:04:14.866
We'll also cache results that we

00:04:14.866 --> 00:04:16.386
get from the requests so other

00:04:16.386 --> 00:04:17.296
requests can use it in

00:04:17.296 --> 00:04:18.416
pipelines, and we're going to

00:04:18.416 --> 00:04:20.176
look at pipelines going forward

00:04:20.176 --> 00:04:21.036
in this presentation.

00:04:21.766 --> 00:04:23.636
Let's take a look at the

00:04:23.636 --> 00:04:24.536
Sequence Request Handler.

00:04:25.626 --> 00:04:26.906
Sequence request handler is used

00:04:27.196 --> 00:04:28.366
to process a particular

00:04:28.366 --> 00:04:30.626
operation like tracking in a

00:04:30.626 --> 00:04:31.566
sequence of frames.

00:04:32.506 --> 00:04:34.256
What it does inside, it caches

00:04:34.256 --> 00:04:35.886
the state of that operation from

00:04:35.886 --> 00:04:37.506
frame to frame to frame for the

00:04:37.506 --> 00:04:38.256
entire sequence.

00:04:39.656 --> 00:04:41.106
In Vision, it's used to process

00:04:41.506 --> 00:04:43.016
tracking and image registration

00:04:43.016 --> 00:04:43.476
requests.

00:04:43.866 --> 00:04:45.516
All other requests are processed

00:04:45.516 --> 00:04:46.576
with our Image Request Handler.

00:04:50.856 --> 00:04:52.196
Let's look at the results.

00:04:52.776 --> 00:04:53.996
Results in Vision coming from

00:04:54.146 --> 00:04:54.876
observations.

00:04:55.406 --> 00:04:57.186
Observations is a collection of

00:04:57.236 --> 00:04:59.336
classes derived from

00:04:59.946 --> 00:05:01.026
VNObservation class.

00:05:01.616 --> 00:05:02.746
How do we get an observation?

00:05:03.616 --> 00:05:04.886
Well, first, the most natural

00:05:04.886 --> 00:05:06.566
way is when the request is

00:05:06.566 --> 00:05:07.746
processed, you're going to look

00:05:07.746 --> 00:05:08.886
at the results property of that

00:05:08.886 --> 00:05:10.256
request, and that results

00:05:10.256 --> 00:05:11.356
property is a collection of

00:05:11.356 --> 00:05:11.966
observations.

00:05:11.966 --> 00:05:13.516
That's how we tell you results

00:05:13.726 --> 00:05:14.306
of processing.

00:05:14.976 --> 00:05:18.606
The second way is you create it

00:05:18.606 --> 00:05:18.996
manually.

00:05:19.696 --> 00:05:20.866
We're going to look at examples

00:05:20.866 --> 00:05:22.006
for other presentations how to

00:05:22.006 --> 00:05:22.336
do both.

00:05:26.636 --> 00:05:28.886
Let's now look at what's new

00:05:28.886 --> 00:05:29.636
coming this year.

00:05:30.476 --> 00:05:32.286
First, we have our new face

00:05:32.286 --> 00:05:32.706
detector.

00:05:33.206 --> 00:05:36.336
Now, we can detect more faces,

00:05:37.196 --> 00:05:37.986
and we're now

00:05:38.096 --> 00:05:39.096
orientation-agnostic.

00:05:39.886 --> 00:05:40.726
Let's look at example.

00:05:41.186 --> 00:05:42.256
On the left-hand side, you can

00:05:42.256 --> 00:05:43.776
see an image with seven faces in

00:05:43.776 --> 00:05:45.806
it, and we could process that

00:05:45.806 --> 00:05:46.906
image with the detector from

00:05:46.906 --> 00:05:48.236
last year, we can detect only

00:05:48.236 --> 00:05:50.206
three faces, and those faces are

00:05:50.406 --> 00:05:51.746
the ones that are close to the

00:05:51.746 --> 00:05:52.596
upright position.

00:05:53.966 --> 00:05:55.216
If you process the same image

00:05:55.216 --> 00:05:56.596
with the face detector that's

00:05:57.016 --> 00:05:58.426
coming this year, as you can

00:05:58.426 --> 00:05:59.866
see, all faces can be detected,

00:05:59.996 --> 00:06:01.256
and orientation is not a problem

00:06:01.256 --> 00:06:01.556
anymore.

00:06:01.556 --> 00:06:04.516
Let's look a little bit more

00:06:04.516 --> 00:06:04.966
into details.

00:06:05.136 --> 00:06:06.096
Thank you.

00:06:07.176 --> 00:06:09.500
[ Applause ]

00:06:15.186 --> 00:06:17.976
So, first, our new face detector

00:06:18.356 --> 00:06:20.226
uses the same API as from last

00:06:20.226 --> 00:06:20.456
year.

00:06:20.836 --> 00:06:22.196
The only difference is if you

00:06:22.196 --> 00:06:23.426
want to specify revision, you

00:06:23.426 --> 00:06:24.636
need to overwrite a revision

00:06:24.636 --> 00:06:26.236
property of that request and set

00:06:26.236 --> 00:06:28.056
it explicitly to User Vision #2.

00:06:28.496 --> 00:06:29.196
Again, I'll talk about the

00:06:29.196 --> 00:06:30.336
reasons right on the next slide.

00:06:31.556 --> 00:06:33.466
We're also introducing two new

00:06:33.466 --> 00:06:34.116
properties.

00:06:34.566 --> 00:06:36.516
One is roll, which is when the

00:06:36.516 --> 00:06:38.126
head rotates like this, and the

00:06:38.126 --> 00:06:39.856
other one is yaw, which when the

00:06:39.856 --> 00:06:41.500
head rotates around the neck.

00:06:45.116 --> 00:06:45.676
Revisions.

00:06:46.616 --> 00:06:47.676
What happens with Vision where

00:06:47.676 --> 00:06:48.696
when we need to introducing a

00:06:48.696 --> 00:06:50.156
new algorithm, we don't

00:06:50.156 --> 00:06:51.246
deprecate the old one right

00:06:51.246 --> 00:06:51.516
away.

00:06:52.146 --> 00:06:53.486
Instead, we're going to keep for

00:06:53.486 --> 00:06:55.026
some time both revisions or,

00:06:55.026 --> 00:06:56.396
maybe going forward, even more,

00:06:56.956 --> 00:06:57.696
simultaneously.

00:06:58.496 --> 00:06:59.896
You tell us which one you want

00:06:59.896 --> 00:07:01.186
to work with by specifying

00:07:01.186 --> 00:07:02.256
revision property of the

00:07:02.256 --> 00:07:02.696
request.

00:07:04.066 --> 00:07:04.966
So, that's the explicit

00:07:04.966 --> 00:07:05.376
behavior.

00:07:05.866 --> 00:07:06.936
But we also have a default

00:07:06.936 --> 00:07:07.376
behavior.

00:07:07.876 --> 00:07:09.156
If you create a request object,

00:07:09.336 --> 00:07:10.566
and you don't tell us anything

00:07:10.566 --> 00:07:12.326
at all, and you start processing

00:07:12.326 --> 00:07:13.556
that request, here's what's

00:07:13.556 --> 00:07:14.916
going to happen.

00:07:14.916 --> 00:07:17.076
By default, you're getting the

00:07:17.076 --> 00:07:18.956
latest revision of the request

00:07:19.376 --> 00:07:20.436
that your app is linked

00:07:20.436 --> 00:07:22.516
against-- of the SDK that your

00:07:22.516 --> 00:07:23.596
app is linked against.

00:07:23.986 --> 00:07:25.376
This is important to understand,

00:07:25.376 --> 00:07:26.276
and I'll give you an example.

00:07:27.116 --> 00:07:28.386
Let's say your app is linked

00:07:28.386 --> 00:07:29.546
against there's the SDK from the

00:07:29.546 --> 00:07:30.056
last year.

00:07:30.696 --> 00:07:32.306
Last year, we had only single

00:07:32.306 --> 00:07:32.746
detector.

00:07:33.316 --> 00:07:34.406
So, this is the detector you're

00:07:34.406 --> 00:07:36.436
going to get, even if you take

00:07:36.436 --> 00:07:37.506
that app and without a

00:07:37.506 --> 00:07:38.676
compilation, run it on the

00:07:38.676 --> 00:07:39.366
current OS.

00:07:40.586 --> 00:07:42.456
If, on the other hand, you

00:07:42.456 --> 00:07:44.026
recompile your app with the

00:07:44.026 --> 00:07:45.756
current SDK without changing a

00:07:45.756 --> 00:07:47.466
single line or coordinate, and

00:07:47.466 --> 00:07:48.806
you run it on the current OS,

00:07:48.926 --> 00:07:49.986
you're going to get by default

00:07:49.986 --> 00:07:51.436
revision #2 because this is the

00:07:51.436 --> 00:07:54.716
way this from the current SDK.

00:07:54.946 --> 00:07:56.016
We highly recommend you to

00:07:56.016 --> 00:07:57.646
future-proof your apps, but

00:07:57.646 --> 00:07:58.906
again it's exclusive to Vision.

00:07:59.436 --> 00:08:01.246
What you get is, first, you get

00:08:01.246 --> 00:08:02.416
the deterministic behavior.

00:08:03.026 --> 00:08:04.846
You know performance of the

00:08:04.846 --> 00:08:06.636
algorithm that you're quoting

00:08:06.636 --> 00:08:06.976
against.

00:08:07.356 --> 00:08:08.356
You know what to expect.

00:08:08.846 --> 00:08:10.526
We also can be-- you can get

00:08:10.526 --> 00:08:12.596
your app to be future-proof from

00:08:12.596 --> 00:08:14.106
the errors like, for example, if

00:08:14.106 --> 00:08:15.606
we deprecate certain revision

00:08:15.796 --> 00:08:16.956
going forward, like a couple of

00:08:16.956 --> 00:08:18.766
years from now, then you can

00:08:18.836 --> 00:08:21.186
[inaudible]against that

00:08:22.156 --> 00:08:22.306
[inaudible] today.

00:08:25.176 --> 00:08:26.996
Let's have a deeper dive into

00:08:27.106 --> 00:08:31.916
how to interact with Vision API.

00:08:32.066 --> 00:08:32.866
First, we're going to look at

00:08:32.866 --> 00:08:33.986
the example with Image Request

00:08:33.986 --> 00:08:34.226
Handler.

00:08:35.676 --> 00:08:36.716
So, as you remember, image

00:08:36.716 --> 00:08:37.706
request handler is used to

00:08:37.706 --> 00:08:39.996
process one or more requests on

00:08:39.996 --> 00:08:40.676
the same image.

00:08:41.316 --> 00:08:44.516
It's optimized by caching some

00:08:44.516 --> 00:08:45.446
information like image

00:08:45.446 --> 00:08:46.956
derivatives and request results.

00:08:47.316 --> 00:08:49.206
So, the consecutive requests

00:08:49.286 --> 00:08:50.636
that are coming to be processed

00:08:51.136 --> 00:08:52.236
can use this information.

00:08:53.446 --> 00:08:57.026
Let's look at code sample.

00:08:57.026 --> 00:08:58.216
Before we dive into the code

00:08:58.216 --> 00:08:59.286
sample, I just want to emphasize

00:08:59.286 --> 00:09:00.546
a couple of points about the

00:09:01.126 --> 00:09:01.866
code samples in this

00:09:01.866 --> 00:09:02.506
presentation.

00:09:03.376 --> 00:09:04.956
The error handling is not a good

00:09:04.956 --> 00:09:06.136
example how errors should be

00:09:06.136 --> 00:09:06.526
handled.

00:09:06.526 --> 00:09:07.796
I use a short version of try,

00:09:07.876 --> 00:09:09.026
and I use [inaudible].

00:09:09.746 --> 00:09:11.136
This is just to simplify the

00:09:11.136 --> 00:09:11.686
examples.

00:09:11.996 --> 00:09:12.906
When you code your apps, you

00:09:12.906 --> 00:09:14.356
probably should use guards to

00:09:14.356 --> 00:09:15.526
protect against unwanted

00:09:15.526 --> 00:09:15.946
behavior.

00:09:17.186 --> 00:09:20.086
I also use Image URL when I

00:09:20.256 --> 00:09:22.346
create my image request handler

00:09:22.346 --> 00:09:24.416
objects, and that is just a

00:09:24.416 --> 00:09:26.716
place on the SSD where the file

00:09:26.716 --> 00:09:27.236
is located.

00:09:28.516 --> 00:09:29.416
Now, let's look at example.

00:09:30.746 --> 00:09:32.046
First, I'm going to create my

00:09:32.206 --> 00:09:34.346
detect faces request object.

00:09:35.136 --> 00:09:36.476
Then, I'm going to create my

00:09:36.476 --> 00:09:38.036
image request handler passing

00:09:38.036 --> 00:09:40.036
the image URL with the file of

00:09:40.036 --> 00:09:41.866
the image where the faces should

00:09:41.866 --> 00:09:42.336
be located.

00:09:43.246 --> 00:09:44.526
Then, I'm going to ask my

00:09:44.526 --> 00:09:45.716
request handler to process my

00:09:45.716 --> 00:09:46.186
request.

00:09:46.706 --> 00:09:47.796
And finally, I'm going to look

00:09:47.796 --> 00:09:48.500
at the results.

00:09:50.046 --> 00:09:50.506
Very simple.

00:09:51.016 --> 00:09:52.276
If I had an image with a single

00:09:52.276 --> 00:09:54.036
face in it, my results would

00:09:54.036 --> 00:09:55.330
look something like this.

00:10:00.136 --> 00:10:01.076
So, what I get back?

00:10:01.076 --> 00:10:02.626
I get back a face observation

00:10:02.626 --> 00:10:04.116
object, and the one of the more

00:10:04.116 --> 00:10:05.496
important fields in that object

00:10:05.496 --> 00:10:06.576
is the bounding box where the

00:10:06.576 --> 00:10:07.336
face is located.

00:10:09.116 --> 00:10:10.836
Let's take a look at this slide

00:10:10.836 --> 00:10:11.156
again.

00:10:11.156 --> 00:10:12.976
The first three lines is pretty

00:10:12.976 --> 00:10:14.446
much all you need to find all

00:10:14.446 --> 00:10:15.426
the faces in the image.

00:10:15.636 --> 00:10:16.296
Isn't that cool?

00:10:18.516 --> 00:10:22.306
[ Applause ]

00:10:22.806 --> 00:10:23.656
Let's now take a look at the

00:10:23.656 --> 00:10:25.246
Sequence Request Handler.

00:10:27.636 --> 00:10:28.956
Well, sequence request handler,

00:10:28.956 --> 00:10:29.846
as you remember, is used to

00:10:29.846 --> 00:10:31.726
process a particular operation

00:10:31.726 --> 00:10:33.566
like tracking on a sequence of

00:10:33.566 --> 00:10:34.006
frames.

00:10:35.486 --> 00:10:36.646
Let's look at code sample, and

00:10:36.646 --> 00:10:38.406
this code sample is pretty much

00:10:38.406 --> 00:10:40.646
the simplest tracking sequence

00:10:40.646 --> 00:10:42.246
we can imagine with Vision API.

00:10:43.556 --> 00:10:45.056
First, I'm going to create my

00:10:45.226 --> 00:10:46.096
Sequence Request Handler.

00:10:47.416 --> 00:10:49.116
Then, I need to specify which

00:10:49.116 --> 00:10:50.436
object I want to track, and I'm

00:10:50.436 --> 00:10:52.126
going to do that by creating a

00:10:52.126 --> 00:10:53.926
detected object observation,

00:10:53.926 --> 00:10:55.536
which gets us a parameter

00:10:55.876 --> 00:10:57.496
location, a bounding box.

00:10:58.806 --> 00:11:00.256
Then, I'm going to start my

00:11:00.256 --> 00:11:01.056
tracking signals.

00:11:01.786 --> 00:11:03.486
In this example, I'm going to

00:11:03.486 --> 00:11:04.676
track my object for five

00:11:04.676 --> 00:11:05.626
consecutive frames.

00:11:06.896 --> 00:11:07.876
Let's look how the sequence

00:11:07.876 --> 00:11:08.236
works.

00:11:08.826 --> 00:11:10.636
First, I have a frame feeder

00:11:10.636 --> 00:11:11.946
object, which in your case could

00:11:11.946 --> 00:11:13.206
be like camera feed, for

00:11:13.206 --> 00:11:13.566
example.

00:11:14.326 --> 00:11:15.546
This is where I get my frames.

00:11:15.546 --> 00:11:18.416
I get my frame, I create my

00:11:18.416 --> 00:11:19.666
request object, passing the

00:11:19.666 --> 00:11:21.456
detected object observation as a

00:11:21.456 --> 00:11:23.886
parameter with its initializer.

00:11:24.326 --> 00:11:25.706
And that's something that I just

00:11:25.706 --> 00:11:26.876
created before the loop started.

00:11:27.496 --> 00:11:29.596
Then, I'm going to ask my

00:11:29.596 --> 00:11:31.296
request handler to process

00:11:31.296 --> 00:11:31.666
request.

00:11:32.296 --> 00:11:34.396
I'm going to look at the

00:11:34.396 --> 00:11:35.646
results, and this is the place

00:11:35.646 --> 00:11:37.166
where I should be analyzing

00:11:37.166 --> 00:11:38.376
results and doing something with

00:11:38.376 --> 00:11:38.626
them.

00:11:39.246 --> 00:11:41.766
And the last step, which is very

00:11:41.766 --> 00:11:43.426
important, what I'm doing here,

00:11:43.776 --> 00:11:44.956
I'm taking the results from the

00:11:44.956 --> 00:11:46.196
current iteration, and I'm

00:11:46.236 --> 00:11:47.376
passing it to the next

00:11:47.376 --> 00:11:48.026
iteration.

00:11:48.356 --> 00:11:49.426
So, when the next iteration

00:11:49.426 --> 00:11:50.846
request is created, I want to

00:11:50.846 --> 00:11:51.846
see those results inside.

00:11:51.846 --> 00:11:53.456
If I were to want it in a

00:11:53.606 --> 00:11:54.786
sequence of five frames, my

00:11:54.786 --> 00:11:55.756
results would look something

00:11:55.756 --> 00:11:55.976
like this.

00:12:06.196 --> 00:12:07.726
How to create a request object.

00:12:07.726 --> 00:12:10.616
Well, first, it's important to

00:12:10.616 --> 00:12:11.846
understand that our requests

00:12:11.846 --> 00:12:13.066
have two types of properties.

00:12:13.416 --> 00:12:14.706
There are mandatory properties

00:12:14.816 --> 00:12:15.766
and there are optional

00:12:15.766 --> 00:12:16.346
properties.

00:12:16.696 --> 00:12:18.406
And mandatory properties, as the

00:12:18.406 --> 00:12:20.066
name suggests, they need to be

00:12:20.066 --> 00:12:21.826
provided via initializer in

00:12:21.826 --> 00:12:23.696
order to be able to create a

00:12:23.696 --> 00:12:24.436
request object.

00:12:24.436 --> 00:12:26.826
Let's look at the example.

00:12:28.216 --> 00:12:29.766
There is something that would

00:12:29.766 --> 00:12:30.926
just go in the previous slide.

00:12:31.636 --> 00:12:33.046
I detected object observation

00:12:33.046 --> 00:12:34.366
that is passed into the

00:12:34.536 --> 00:12:35.686
initializer of the [inaudible]

00:12:35.686 --> 00:12:37.676
object request is an example of

00:12:37.676 --> 00:12:39.396
a mandatory property.

00:12:40.356 --> 00:12:41.486
We also have optional

00:12:41.486 --> 00:12:42.066
properties.

00:12:43.466 --> 00:12:44.276
By the way, both types of

00:12:44.276 --> 00:12:45.396
properties are declared.

00:12:45.866 --> 00:12:47.026
You can find them in the place

00:12:47.026 --> 00:12:49.906
where the request object is

00:12:50.696 --> 00:12:50.946
declared.

00:12:51.016 --> 00:12:53.076
Optional properties is separate

00:12:53.076 --> 00:12:54.306
properties where we have

00:12:54.336 --> 00:12:55.506
meaningful defaults for them.

00:12:55.976 --> 00:12:57.306
So, we'll initialize them for

00:12:57.306 --> 00:12:58.776
you, but you can override them

00:12:58.776 --> 00:12:59.656
later if you need to.

00:13:00.546 --> 00:13:05.906
Let's look at the example.

00:13:05.906 --> 00:13:06.776
What I'm doing here, I'm

00:13:06.776 --> 00:13:08.106
breaking my detect barcodes

00:13:08.106 --> 00:13:08.756
request object.

00:13:09.616 --> 00:13:11.256
If I were to do nothing else and

00:13:11.256 --> 00:13:12.856
just took my request object and

00:13:12.856 --> 00:13:15.256
fed it into request handler, I

00:13:15.256 --> 00:13:16.586
would be working on the entire

00:13:16.586 --> 00:13:18.416
image, looking for my barcodes.

00:13:19.176 --> 00:13:20.066
What I'm going to do here

00:13:20.066 --> 00:13:22.316
instead, I'm going to specify a

00:13:22.316 --> 00:13:23.746
small portion like a central

00:13:23.746 --> 00:13:24.516
property image.

00:13:24.966 --> 00:13:25.716
There's this where I want to

00:13:25.716 --> 00:13:27.506
focus to look for my barcodes,

00:13:27.556 --> 00:13:29.186
and I'm going to overwrite my

00:13:29.186 --> 00:13:30.466
region of interest property with

00:13:30.466 --> 00:13:30.696
that.

00:13:31.476 --> 00:13:32.886
If I take my request object now

00:13:32.886 --> 00:13:33.976
and feed it into request

00:13:33.976 --> 00:13:35.046
handler, I'm going to be

00:13:35.046 --> 00:13:36.406
focusing on the smaller portion

00:13:36.406 --> 00:13:37.116
of the image only.

00:13:38.166 --> 00:13:39.586
A region of interest property

00:13:39.776 --> 00:13:41.496
here is an example of the

00:13:41.496 --> 00:13:42.646
optional property that we have.

00:13:43.776 --> 00:13:45.026
What's important to understand

00:13:45.026 --> 00:13:47.896
here also that once you get a

00:13:47.896 --> 00:13:49.186
request object in your hands,

00:13:49.436 --> 00:13:50.956
it's a fully constructed object.

00:13:51.656 --> 00:13:52.546
It's the object that you can

00:13:52.546 --> 00:13:54.226
start working with whenever you

00:13:54.226 --> 00:13:55.366
have constructed objects.

00:13:55.716 --> 00:13:56.736
If you decide to overwrite

00:13:56.736 --> 00:13:58.396
certain properties later on,

00:13:58.716 --> 00:13:59.766
you're welcome to do so.

00:14:00.036 --> 00:14:01.076
But whenever you have the

00:14:01.076 --> 00:14:02.816
object, it's the object that you

00:14:02.816 --> 00:14:04.500
can work with.

00:14:07.536 --> 00:14:08.526
One thing that's not maybe on

00:14:08.526 --> 00:14:09.776
this slide is, which will be

00:14:09.776 --> 00:14:10.866
covered in more details in the

00:14:10.866 --> 00:14:14.556
next session, is to look at the

00:14:14.556 --> 00:14:15.406
bounding boxes.

00:14:16.046 --> 00:14:18.456
As you can see, the coordinates

00:14:18.456 --> 00:14:20.306
that we receive are normalized.

00:14:20.856 --> 00:14:22.576
They are from 0 to 1 and they're

00:14:22.576 --> 00:14:23.976
always relative to the lower

00:14:23.976 --> 00:14:24.446
left corner.

00:14:25.146 --> 00:14:26.166
The next session, which is

00:14:26.166 --> 00:14:27.506
CoreML integration with Vision,

00:14:27.716 --> 00:14:29.196
will cover this aspect in more

00:14:29.196 --> 00:14:29.686
details.

00:14:33.336 --> 00:14:34.806
Let's look at how to understand

00:14:34.806 --> 00:14:35.256
results.

00:14:35.906 --> 00:14:38.616
As we said, results in Vision

00:14:38.616 --> 00:14:40.266
come in forms of observations.

00:14:41.766 --> 00:14:43.726
Observations are populated

00:14:43.726 --> 00:14:45.046
through results property of the

00:14:45.046 --> 00:14:45.696
request object.

00:14:46.466 --> 00:14:47.526
How many observations can you

00:14:47.526 --> 00:14:47.806
get?

00:14:48.396 --> 00:14:51.726
All the collection be 0 to N.

00:14:52.596 --> 00:14:53.726
There's one more aspect here.

00:14:54.046 --> 00:14:55.796
If you get results set to nil,

00:14:55.796 --> 00:14:57.096
that means that the [inaudible]

00:14:57.096 --> 00:14:58.286
single request failed.

00:14:58.806 --> 00:15:00.516
This is different than getting 0

00:15:00.516 --> 00:15:01.256
observations met.

00:15:01.956 --> 00:15:03.666
Getting 0 observations met means

00:15:03.666 --> 00:15:04.736
that whatever you were looking

00:15:04.736 --> 00:15:05.946
for is just not there.

00:15:05.946 --> 00:15:08.796
As an example, let's say you run

00:15:08.796 --> 00:15:09.526
a face detector.

00:15:10.816 --> 00:15:11.846
If you feed an image with no

00:15:11.846 --> 00:15:13.306
faces in it, naturally, you will

00:15:13.306 --> 00:15:14.476
get 0 observations met.

00:15:15.416 --> 00:15:16.596
On the other hand, if you feed

00:15:16.596 --> 00:15:18.336
the image with one or more faces

00:15:18.726 --> 00:15:20.896
in it, you'll get appropriate

00:15:20.896 --> 00:15:22.606
number of observations met.

00:15:24.036 --> 00:15:25.506
Another important property of

00:15:25.506 --> 00:15:27.196
observations is that

00:15:27.326 --> 00:15:28.446
observations are immutable.

00:15:28.446 --> 00:15:30.016
We will look at the example

00:15:30.576 --> 00:15:31.696
where it's used.

00:15:32.196 --> 00:15:34.286
There are two more properties

00:15:34.286 --> 00:15:34.996
that I want to pay your

00:15:34.996 --> 00:15:36.406
attention to, and they are both

00:15:36.406 --> 00:15:37.566
declared in the base [inaudible]

00:15:37.566 --> 00:15:38.846
for all observations.

00:15:39.286 --> 00:15:40.416
One is the unique ID.

00:15:41.056 --> 00:15:42.586
This unique ID identifies the

00:15:42.586 --> 00:15:44.326
processing step for this

00:15:44.326 --> 00:15:45.226
particular-- where this

00:15:45.226 --> 00:15:46.666
particular result was created.

00:15:47.576 --> 00:15:48.836
Another one is the confidence

00:15:48.836 --> 00:15:49.136
level.

00:15:50.376 --> 00:15:51.756
Confidence level tells you how

00:15:51.756 --> 00:15:53.126
confident the algorithm was

00:15:53.376 --> 00:15:54.316
producing the results.

00:15:55.596 --> 00:15:57.756
The confidence is in the range

00:15:57.756 --> 00:15:58.526
from 0 to 1.

00:15:59.176 --> 00:16:00.646
Again, this topic also will be

00:16:00.646 --> 00:16:02.166
covered in the next session in

00:16:02.166 --> 00:16:03.366
more details.

00:16:06.876 --> 00:16:08.086
Let's look at the request

00:16:08.086 --> 00:16:08.706
pipelines.

00:16:09.786 --> 00:16:10.666
So, what is a pipeline?

00:16:11.736 --> 00:16:13.286
Let's say I have three requests,

00:16:13.286 --> 00:16:14.266
and it happens to be that

00:16:14.266 --> 00:16:16.476
request #1 depends on execution

00:16:16.476 --> 00:16:18.136
of request #2, which in turn

00:16:18.396 --> 00:16:20.226
depends on execution of request

00:16:20.826 --> 00:16:21.936
#3.

00:16:22.126 --> 00:16:23.456
How do we process the sequence

00:16:23.966 --> 00:16:25.456
while the processing is done in

00:16:25.456 --> 00:16:26.246
the opposite order?

00:16:26.806 --> 00:16:27.676
What I'm going to do here,

00:16:27.846 --> 00:16:29.246
first, I'm going to process my

00:16:29.246 --> 00:16:30.106
request #3.

00:16:30.476 --> 00:16:31.456
I'm going to get the results

00:16:31.456 --> 00:16:32.876
from that request and feed it

00:16:32.876 --> 00:16:33.876
into request #2.

00:16:34.086 --> 00:16:35.556
I'm going to do exactly the same

00:16:35.556 --> 00:16:36.516
with request #2.

00:16:36.786 --> 00:16:38.316
And finally, I will process my

00:16:38.316 --> 00:16:39.116
request #1.

00:16:41.296 --> 00:16:43.036
Let's look at the examples of

00:16:43.036 --> 00:16:45.976
how to run request pipeline in

00:16:45.976 --> 00:16:47.636
implicit and explicit order.

00:16:48.326 --> 00:16:49.196
We're going to look at the next

00:16:49.196 --> 00:16:50.426
two slides in these two use

00:16:50.426 --> 00:16:52.126
cases, and we're going to run

00:16:52.126 --> 00:16:53.746
our face landmarks detector.

00:16:54.386 --> 00:16:55.936
As you probably know, landmarks,

00:16:55.996 --> 00:16:58.026
face landmarks are the features

00:16:58.026 --> 00:16:58.526
on the face.

00:16:58.526 --> 00:17:00.236
It's both your eyes, eyebrows,

00:17:00.236 --> 00:17:01.726
nose, and mouth location on your

00:17:01.726 --> 00:17:02.016
face.

00:17:02.996 --> 00:17:05.425
Let's first look at how to do it

00:17:05.425 --> 00:17:05.955
implicitly.

00:17:13.675 --> 00:17:14.955
I have a simple [inaudible] a

00:17:14.955 --> 00:17:16.266
bit similar to what we have seen

00:17:16.266 --> 00:17:16.646
already.

00:17:17.195 --> 00:17:18.205
First, I'm going to create my

00:17:18.205 --> 00:17:19.316
face landmarks request.

00:17:20.566 --> 00:17:22.036
Then, I'm going to create my

00:17:22.036 --> 00:17:22.846
image request handler.

00:17:23.836 --> 00:17:25.006
Then, I'm going to process my

00:17:25.006 --> 00:17:25.415
request.

00:17:26.246 --> 00:17:27.256
And finally, I'm going to look

00:17:27.256 --> 00:17:27.836
at the results.

00:17:28.936 --> 00:17:30.136
If I had an image with a single

00:17:30.136 --> 00:17:31.976
face in it, my results would

00:17:31.976 --> 00:17:35.276
look something like this.

00:17:35.406 --> 00:17:35.716
Sorry.

00:17:36.066 --> 00:17:39.076
N is for the sequence, and the

00:17:39.306 --> 00:17:39.836
results.

00:17:40.846 --> 00:17:42.046
So, I get the bounding box of

00:17:42.046 --> 00:17:42.536
the face.

00:17:43.036 --> 00:17:43.866
That's the location for the

00:17:43.866 --> 00:17:46.436
face, and I get the landmarks

00:17:46.686 --> 00:17:47.166
for the face.

00:17:48.576 --> 00:17:49.786
What's important to understand

00:17:49.786 --> 00:17:51.376
here is that when the processing

00:17:51.376 --> 00:17:52.726
of the face landmark request

00:17:52.726 --> 00:17:54.776
starts, face landmarks request

00:17:55.136 --> 00:17:56.906
figures out that faces have not

00:17:56.906 --> 00:17:59.316
been detected yet, and it runs

00:17:59.316 --> 00:18:01.136
on our behalf inside face

00:18:01.136 --> 00:18:01.546
detector.

00:18:02.106 --> 00:18:03.686
It gets results from that face

00:18:03.686 --> 00:18:05.306
detector, and that's where

00:18:05.306 --> 00:18:06.536
landmarks are being searched

00:18:06.536 --> 00:18:06.716
for.

00:18:08.716 --> 00:18:10.896
On the right-hand side, you can

00:18:11.306 --> 00:18:14.186
see a snippet of what face

00:18:14.186 --> 00:18:15.386
observation object would look

00:18:15.386 --> 00:18:15.566
like.

00:18:15.816 --> 00:18:16.576
These are just a couple of

00:18:16.576 --> 00:18:17.446
fields from that object.

00:18:17.806 --> 00:18:19.296
One is a unique ID that we

00:18:19.296 --> 00:18:20.376
discussed that is set to some

00:18:20.376 --> 00:18:20.956
unique number.

00:18:21.656 --> 00:18:23.316
Then, the bounding box, that's

00:18:23.316 --> 00:18:25.216
where the face is located, and

00:18:25.216 --> 00:18:26.436
then, finally, the landmarks

00:18:26.436 --> 00:18:27.936
field, which points to some

00:18:27.936 --> 00:18:29.216
object where the landmarks are

00:18:29.216 --> 00:18:29.656
described.

00:18:33.526 --> 00:18:35.236
Now, let's take a look at the

00:18:35.236 --> 00:18:37.716
same use case but now done

00:18:37.716 --> 00:18:38.336
explicitly.

00:18:40.416 --> 00:18:41.556
What I'm going to do here

00:18:41.556 --> 00:18:42.876
first-- first, I'm going to

00:18:42.876 --> 00:18:44.486
explicitly run my face detector.

00:18:45.116 --> 00:18:47.516
You've seen these four lines of

00:18:47.516 --> 00:18:49.076
code already several times in

00:18:49.076 --> 00:18:49.796
the presentation.

00:18:49.856 --> 00:18:51.346
When I run it, I get my bounding

00:18:51.346 --> 00:18:51.786
box back.

00:18:52.606 --> 00:18:54.376
As you can see, the results are

00:18:54.376 --> 00:18:56.016
returned in the same type, face

00:18:56.016 --> 00:18:56.616
observation.

00:18:57.276 --> 00:18:58.796
The fields that we saw on the

00:18:58.796 --> 00:18:59.946
previous slide may look like

00:18:59.946 --> 00:19:01.176
this, so you get some unique

00:19:01.176 --> 00:19:02.226
number to identify this

00:19:02.226 --> 00:19:03.386
particular processing step.

00:19:04.146 --> 00:19:05.326
Then, you get the bounding box

00:19:05.326 --> 00:19:06.476
location, which is the main

00:19:06.476 --> 00:19:08.326
outcome of processing this

00:19:08.326 --> 00:19:08.716
request.

00:19:08.946 --> 00:19:10.616
And the landmarks field is set

00:19:10.616 --> 00:19:11.916
to nil because face detector

00:19:11.916 --> 00:19:12.986
doesn't know anything about

00:19:12.986 --> 00:19:13.496
landmarks.

00:19:14.856 --> 00:19:16.246
What I'm going to do next is I'm

00:19:16.336 --> 00:19:17.526
going to create my landmarks

00:19:17.526 --> 00:19:19.266
request, and then I'm going to

00:19:19.266 --> 00:19:20.096
take the results from the

00:19:20.096 --> 00:19:22.166
previous step and feed it into

00:19:22.166 --> 00:19:23.446
the input object observation

00:19:23.496 --> 00:19:24.556
property of that request.

00:19:25.996 --> 00:19:26.866
Then, I'm going to ask my

00:19:27.066 --> 00:19:28.336
request handler to process it.

00:19:29.306 --> 00:19:30.206
And finally, I'm going to look

00:19:30.206 --> 00:19:30.836
at the results.

00:19:31.726 --> 00:19:33.396
If I run it in the same image, I

00:19:33.396 --> 00:19:35.146
get exactly the same results as

00:19:35.146 --> 00:19:37.786
I would on the previous slide.

00:19:38.726 --> 00:19:39.836
But let's see what happens with

00:19:39.836 --> 00:19:40.486
observations.

00:19:40.996 --> 00:19:41.826
Remember, we said that

00:19:41.826 --> 00:19:43.906
observations are immutable even

00:19:43.906 --> 00:19:45.876
though both face detector and

00:19:45.876 --> 00:19:48.136
face landmarks detector return

00:19:48.136 --> 00:19:50.006
the same type, but we don't

00:19:50.036 --> 00:19:51.766
override the observation that

00:19:51.976 --> 00:19:52.656
was fed in.

00:19:53.296 --> 00:19:54.716
What we do instead, we take the

00:19:54.716 --> 00:19:56.696
first two fields and copy it

00:19:56.696 --> 00:19:58.776
into a new object, and then we

00:19:58.776 --> 00:20:00.326
calculate landmarks and populate

00:20:00.326 --> 00:20:01.036
the landmarks field.

00:20:02.246 --> 00:20:03.726
Now, if you look now, you will

00:20:03.726 --> 00:20:05.246
notice that the UID in most

00:20:05.246 --> 00:20:06.356
cases is the same.

00:20:07.286 --> 00:20:07.796
Why is that?

00:20:08.266 --> 00:20:09.366
Because we're talking about the

00:20:09.366 --> 00:20:10.026
same face.

00:20:10.026 --> 00:20:11.916
It's the same processing step,

00:20:11.956 --> 00:20:14.046
if you will.

00:20:14.266 --> 00:20:15.526
Where would you use implicit

00:20:15.526 --> 00:20:16.326
versus explicit?

00:20:17.406 --> 00:20:18.516
Well, if your application is

00:20:18.516 --> 00:20:20.566
very simple, you would probably

00:20:20.726 --> 00:20:22.006
want to opt for implicit way.

00:20:22.406 --> 00:20:23.046
It's very simple.

00:20:23.046 --> 00:20:24.106
You create a single request;

00:20:24.106 --> 00:20:25.466
everything else is done on your

00:20:25.466 --> 00:20:26.606
behalf.

00:20:28.706 --> 00:20:30.236
If, on the other hand, your

00:20:30.236 --> 00:20:31.686
application is more complex, for

00:20:31.686 --> 00:20:33.106
example, you want to process

00:20:33.106 --> 00:20:35.076
faces first, detect them, then

00:20:35.076 --> 00:20:35.916
do some filtering.

00:20:36.006 --> 00:20:37.186
Let's say you don't care about

00:20:37.186 --> 00:20:38.366
faces on the periphery, or you

00:20:38.366 --> 00:20:39.986
want to just focus on the ones

00:20:39.986 --> 00:20:42.046
that are in the center, you can

00:20:42.046 --> 00:20:44.026
do that step, and then you can

00:20:44.026 --> 00:20:45.576
do landmarks on the remaining

00:20:45.576 --> 00:20:46.436
set of faces.

00:20:47.276 --> 00:20:48.476
In this case, you probably want

00:20:48.476 --> 00:20:49.566
to use the explicit version

00:20:50.626 --> 00:20:52.566
because, in this case, landmarks

00:20:52.656 --> 00:20:54.236
detector is not going to rerun

00:20:54.306 --> 00:20:54.936
face detector inside.

00:21:02.566 --> 00:21:03.616
We want your apps to have

00:21:03.866 --> 00:21:05.136
optimal performance both in

00:21:05.136 --> 00:21:06.576
terms of memory usage and

00:21:06.576 --> 00:21:07.356
execution speed.

00:21:07.466 --> 00:21:08.486
That's why it's important to

00:21:08.486 --> 00:21:09.586
look at the next two slides.

00:21:11.696 --> 00:21:12.956
How long should you keep your

00:21:12.956 --> 00:21:14.346
objects in memory?

00:21:16.756 --> 00:21:17.956
Well, for the image request

00:21:17.956 --> 00:21:19.356
handler, you should keep it as

00:21:19.416 --> 00:21:21.066
long as the image needs

00:21:21.066 --> 00:21:21.486
processing.

00:21:22.356 --> 00:21:23.716
This may sound like a very

00:21:23.716 --> 00:21:24.936
innocent and simple statement,

00:21:25.296 --> 00:21:26.496
but it is very important that

00:21:26.496 --> 00:21:28.296
you do just that.

00:21:28.296 --> 00:21:29.736
If you release the object early,

00:21:29.736 --> 00:21:31.066
and you still have outstanding

00:21:31.066 --> 00:21:32.446
requests to be processed, you

00:21:32.446 --> 00:21:33.716
will have to recreate your image

00:21:33.716 --> 00:21:34.386
to request handler.

00:21:34.716 --> 00:21:36.346
But now you have lost all the

00:21:36.346 --> 00:21:37.676
cache that was associated with

00:21:37.676 --> 00:21:39.066
the previous object, and you'll

00:21:39.066 --> 00:21:40.636
have to pay this performance to

00:21:40.636 --> 00:21:42.036
recalculate these derivatives.

00:21:42.666 --> 00:21:45.386
If you release it too late, on

00:21:45.386 --> 00:21:47.546
the other hand, then, first

00:21:47.546 --> 00:21:48.486
you're going to start causing

00:21:48.486 --> 00:21:50.196
memory fragmentation, and then

00:21:50.196 --> 00:21:51.416
the memory is not going to be

00:21:51.416 --> 00:21:53.006
reclaimed by your app for other

00:21:53.006 --> 00:21:54.606
meaningful things that you want

00:21:54.606 --> 00:21:55.500
to do.

00:21:56.156 --> 00:21:57.696
So, it's important to release

00:21:57.696 --> 00:21:59.236
it, use it as long as you need

00:21:59.236 --> 00:22:00.176
and release it right after.

00:22:00.826 --> 00:22:02.316
Remember, it caches the image

00:22:02.386 --> 00:22:03.896
and multiple image derivatives

00:22:03.896 --> 00:22:04.226
inside.

00:22:06.156 --> 00:22:08.116
The situation with sequence

00:22:08.116 --> 00:22:09.396
request handler is very similar

00:22:09.736 --> 00:22:11.196
with the only difference is if

00:22:11.196 --> 00:22:12.526
you release it too early, you

00:22:12.526 --> 00:22:13.536
pretty much kill the entire

00:22:13.536 --> 00:22:14.846
sequence because the entire

00:22:14.846 --> 00:22:18.176
cache is gone by now.

00:22:18.406 --> 00:22:20.076
What about requests and

00:22:20.076 --> 00:22:20.806
observations?

00:22:21.686 --> 00:22:23.516
Well, requests and observations

00:22:23.996 --> 00:22:25.206
are very lightweight objects.

00:22:25.576 --> 00:22:26.656
You can create them and release

00:22:26.656 --> 00:22:27.256
them as needed.

00:22:27.556 --> 00:22:28.426
There's no need to cache them.

00:22:35.596 --> 00:22:36.876
Where should we process your

00:22:37.976 --> 00:22:38.236
requests?

00:22:39.636 --> 00:22:41.366
Well many requests in Vision

00:22:41.366 --> 00:22:42.856
rely on running neural networks

00:22:42.856 --> 00:22:43.436
on the device.

00:22:44.266 --> 00:22:45.996
And, as we know, running neural

00:22:45.996 --> 00:22:47.616
networks is usually faster on

00:22:47.616 --> 00:22:49.216
GPU versus the CPU.

00:22:49.926 --> 00:22:53.066
So, the natural question is

00:22:53.176 --> 00:22:54.706
where should we run it?

00:22:55.476 --> 00:22:56.756
Here's what we do in Vision.

00:22:57.716 --> 00:22:59.636
If request is runnable in GPU,

00:22:59.636 --> 00:23:01.236
we will try to do that first.

00:23:01.996 --> 00:23:03.346
If GPU is not available for

00:23:03.346 --> 00:23:04.616
whatever reason at that point in

00:23:04.616 --> 00:23:06.176
time, we will switch to CPU

00:23:06.766 --> 00:23:08.896
because that's our default

00:23:08.896 --> 00:23:09.306
behavior.

00:23:09.946 --> 00:23:12.846
But let's say your application

00:23:13.326 --> 00:23:14.876
is dependent on displaying a lot

00:23:14.876 --> 00:23:16.306
of graphics on the screen, so

00:23:16.306 --> 00:23:18.276
you may want to save the GPU for

00:23:18.276 --> 00:23:19.446
that particular job.

00:23:20.176 --> 00:23:21.386
In this case, you can override

00:23:21.766 --> 00:23:23.526
user CPU on the property and set

00:23:23.526 --> 00:23:24.736
it to true on the request

00:23:24.736 --> 00:23:25.036
object.

00:23:25.576 --> 00:23:26.886
This will tell us to process

00:23:26.886 --> 00:23:28.856
your request directly on the

00:23:28.856 --> 00:23:29.000
CPU.

00:23:35.316 --> 00:23:37.176
Now that we've covered basic how

00:23:37.176 --> 00:23:39.236
to interact with Vision, Vision

00:23:39.236 --> 00:23:41.276
API, in particular, we've seen a

00:23:41.276 --> 00:23:43.136
couple of examples, let's switch

00:23:43.136 --> 00:23:44.016
to the main topic of our

00:23:44.016 --> 00:23:45.916
presentation, which is tracking

00:23:46.046 --> 00:23:47.166
in Vision.

00:23:48.616 --> 00:23:49.636
So, what is tracking?

00:23:50.986 --> 00:23:52.746
Tracking is defined as a problem

00:23:52.746 --> 00:23:54.406
of finding an object of interest

00:23:54.756 --> 00:23:55.716
in a sequence of frames.

00:23:56.166 --> 00:23:57.466
Usually, you find that object in

00:23:57.466 --> 00:23:59.256
the first frame, and you try to

00:23:59.426 --> 00:24:00.846
look for it in the sequence of

00:24:00.846 --> 00:24:01.206
frames.

00:24:02.256 --> 00:24:03.356
What are the examples of such

00:24:03.356 --> 00:24:03.956
application?

00:24:04.606 --> 00:24:06.036
You will probably see many of

00:24:06.036 --> 00:24:06.206
them.

00:24:06.946 --> 00:24:10.056
It's live annotational sports

00:24:10.056 --> 00:24:11.136
events, focus tracking with

00:24:11.136 --> 00:24:15.266
camera, many, many others.

00:24:15.466 --> 00:24:16.976
You may say why should they use

00:24:16.976 --> 00:24:18.496
tracking if I can do detection

00:24:18.816 --> 00:24:20.006
on every frame in the sequence?

00:24:20.826 --> 00:24:22.116
Well, there are multiple reasons

00:24:22.116 --> 00:24:22.426
for that.

00:24:23.196 --> 00:24:25.156
First, you probably don't have a

00:24:25.156 --> 00:24:26.396
specific tracker for every

00:24:26.396 --> 00:24:27.576
single type of object that you

00:24:27.576 --> 00:24:29.056
want to track.

00:24:29.056 --> 00:24:29.846
Let's say if you're tracking

00:24:29.846 --> 00:24:31.296
faces, you're lucky.

00:24:31.866 --> 00:24:32.866
You have a face detector for

00:24:32.866 --> 00:24:33.436
that purpose.

00:24:34.076 --> 00:24:35.306
But if you need, for example, to

00:24:35.306 --> 00:24:37.126
track a specific type of bird,

00:24:37.916 --> 00:24:39.236
you probably don't have that

00:24:39.236 --> 00:24:40.306
detector, and now you're in the

00:24:40.306 --> 00:24:41.516
business to create that

00:24:41.516 --> 00:24:43.306
particular detector, which you

00:24:43.306 --> 00:24:44.706
may not want to do because of

00:24:44.706 --> 00:24:46.886
the other things that you want

00:24:47.036 --> 00:24:48.036
to have done with your

00:24:48.036 --> 00:24:48.456
application.

00:24:49.106 --> 00:24:51.696
But let's say you are lucky, and

00:24:51.696 --> 00:24:53.366
you're tracking faces, should

00:24:53.366 --> 00:24:54.396
you use detector then?

00:24:55.136 --> 00:24:56.966
Well, probably not in this case

00:24:57.076 --> 00:24:57.196
either.

00:24:58.176 --> 00:24:59.106
So, let's look an example.

00:25:00.616 --> 00:25:01.406
You start your tracking

00:25:01.406 --> 00:25:02.546
sequence, and you run your face

00:25:02.546 --> 00:25:03.576
detector on the first frame.

00:25:04.266 --> 00:25:05.236
You get five faces back.

00:25:06.136 --> 00:25:07.146
Then, you run it in the second

00:25:07.146 --> 00:25:08.516
frame; you get another five

00:25:08.516 --> 00:25:08.976
faces back.

00:25:09.676 --> 00:25:11.506
How do you know that the faces

00:25:11.506 --> 00:25:12.546
from the second frame are

00:25:12.546 --> 00:25:14.096
exactly the same faces as from

00:25:14.096 --> 00:25:14.596
the first frame?

00:25:15.306 --> 00:25:16.276
One person could have stepped

00:25:16.276 --> 00:25:18.166
out; another one showed up.

00:25:18.956 --> 00:25:20.446
So, now, you're in the business

00:25:20.446 --> 00:25:22.316
of matching objects that you

00:25:22.316 --> 00:25:23.736
found, which is a completely

00:25:23.736 --> 00:25:25.326
different task that you may not

00:25:25.326 --> 00:25:25.876
want to deal with.

00:25:27.166 --> 00:25:30.716
Trackers, on the other hand, use

00:25:30.716 --> 00:25:31.956
[inaudible] information to match

00:25:31.956 --> 00:25:32.346
objects.

00:25:32.516 --> 00:25:33.866
They know the trajectory how the

00:25:33.866 --> 00:25:35.136
objects move, and they can

00:25:35.136 --> 00:25:36.336
slightly predict where they

00:25:36.336 --> 00:25:38.286
would be moving in the next

00:25:38.546 --> 00:25:38.660
frame.

00:25:39.336 --> 00:25:40.656
But let's say you're lucky

00:25:40.656 --> 00:25:40.856
again.

00:25:41.536 --> 00:25:43.296
You're tracking faces, and your

00:25:43.296 --> 00:25:45.076
use case is limited to a single

00:25:45.076 --> 00:25:45.806
face in the frame.

00:25:46.196 --> 00:25:47.416
Should you use detectors then?

00:25:48.376 --> 00:25:50.036
Well, maybe not even in this

00:25:50.696 --> 00:25:51.000
case.

00:25:56.556 --> 00:25:57.666
Now, speed is a problem.

00:25:58.126 --> 00:26:00.116
Trackers are usually lightweight

00:26:00.116 --> 00:26:01.706
algorithms, while detectors

00:26:01.946 --> 00:26:03.586
usually run your [inaudible],

00:26:03.676 --> 00:26:04.416
which is much longer.

00:26:05.136 --> 00:26:07.146
In addition, if you need to

00:26:07.146 --> 00:26:08.976
display your tracking

00:26:08.976 --> 00:26:10.306
information on a graphical user

00:26:10.306 --> 00:26:11.716
interface, you may find that

00:26:11.976 --> 00:26:13.356
trackers are smoother and not as

00:26:13.386 --> 00:26:14.000
jittery.

00:26:17.366 --> 00:26:18.416
Remember, in one of the first

00:26:18.416 --> 00:26:19.746
slides, I asked you to remember

00:26:21.386 --> 00:26:24.476
these three terms, what, how,

00:26:24.476 --> 00:26:25.016
and results.

00:26:25.976 --> 00:26:28.206
Let's see how this maps into the

00:26:28.206 --> 00:26:30.000
track and use case.

00:26:31.046 --> 00:26:33.646
First, request.

00:26:34.456 --> 00:26:36.156
So, in Vision, we have two types

00:26:36.156 --> 00:26:37.736
of requests for tracking.

00:26:38.226 --> 00:26:39.236
There is a general purpose

00:26:39.236 --> 00:26:40.786
object tracker, and there is a

00:26:40.786 --> 00:26:41.936
rectangular object tracker.

00:26:43.046 --> 00:26:43.576
How?

00:26:44.686 --> 00:26:45.556
As you should have guessed by

00:26:45.556 --> 00:26:46.696
now, we're going to use our

00:26:47.046 --> 00:26:49.836
sequence request handler.

00:26:49.866 --> 00:26:50.386
Results.

00:26:51.716 --> 00:26:52.556
There are two types that are

00:26:52.556 --> 00:26:53.196
important here.

00:26:53.306 --> 00:26:54.366
There is a detected object

00:26:54.366 --> 00:26:55.766
observation, which has an

00:26:55.766 --> 00:26:56.826
important property in it,

00:26:57.096 --> 00:26:58.346
bounding box, which tells you

00:26:58.346 --> 00:27:00.396
where the object is located, and

00:27:00.396 --> 00:27:01.806
there is a rectangular

00:27:01.806 --> 00:27:03.726
observation, which has four

00:27:03.726 --> 00:27:04.926
additional properties telling

00:27:04.926 --> 00:27:06.066
you where the vertices of the

00:27:06.066 --> 00:27:07.136
rectangle are.

00:27:07.956 --> 00:27:08.886
Now, you say if I had my

00:27:08.886 --> 00:27:10.136
bounding box, why do I need the

00:27:10.136 --> 00:27:11.166
vertices of the rectangle?

00:27:12.406 --> 00:27:13.536
Well, when you draw up

00:27:13.536 --> 00:27:15.626
rectangles, they are rectangular

00:27:15.626 --> 00:27:16.716
objects in the real life.

00:27:16.996 --> 00:27:18.106
The way they are projected in

00:27:18.106 --> 00:27:19.116
the frame, they may look

00:27:19.116 --> 00:27:19.586
differently.

00:27:20.136 --> 00:27:21.556
They may look like trapezoid,

00:27:21.556 --> 00:27:22.086
for example.

00:27:22.666 --> 00:27:24.966
So, the bounding box in this

00:27:24.966 --> 00:27:26.456
case is not the rectangle

00:27:26.456 --> 00:27:26.926
itself.

00:27:26.926 --> 00:27:28.206
It [inaudible] the minimal box

00:27:28.206 --> 00:27:29.546
that includes all the vertices

00:27:29.546 --> 00:27:32.026
of the rectangle.

00:27:33.526 --> 00:27:36.000
Let's look at the demo now.

00:27:47.466 --> 00:27:48.916
So, what I have here, I have a

00:27:48.916 --> 00:27:50.116
sample app that you, by the way,

00:27:50.116 --> 00:27:52.656
can download from WWDC website

00:27:52.856 --> 00:27:54.136
and the link is right next to

00:27:54.136 --> 00:27:54.616
this session.

00:27:55.506 --> 00:27:57.456
What the app does is it takes

00:27:57.456 --> 00:28:00.586
the movie; it parses that movie

00:28:00.586 --> 00:28:01.246
into frames.

00:28:02.106 --> 00:28:03.186
In the first frame, you select

00:28:03.186 --> 00:28:03.576
an object.

00:28:03.696 --> 00:28:04.716
You want to track a multiple

00:28:04.716 --> 00:28:06.276
objects or you want to track,

00:28:06.276 --> 00:28:08.526
and it does the tracking.

00:28:08.656 --> 00:28:10.446
So, let's first use this movie.

00:28:11.516 --> 00:28:13.006
The user interface is simple.

00:28:13.466 --> 00:28:14.436
First, you can choose between

00:28:14.436 --> 00:28:15.956
objects or rectangles, and

00:28:15.956 --> 00:28:17.526
second, you can choose which

00:28:17.526 --> 00:28:19.016
algorithm you want to use, fast

00:28:19.016 --> 00:28:19.486
or accurate.

00:28:19.926 --> 00:28:21.056
What happens in Vision that we

00:28:21.056 --> 00:28:23.586
support two types, fast and

00:28:23.586 --> 00:28:24.756
accurate, and this is a

00:28:24.756 --> 00:28:26.536
trade-off between the speed and

00:28:26.536 --> 00:28:27.016
the accuracy.

00:28:27.676 --> 00:28:29.776
I'm going to show objects in

00:28:29.776 --> 00:28:30.926
this case, and I'm going to use

00:28:30.926 --> 00:28:31.856
my fast algorithm.

00:28:32.946 --> 00:28:33.766
Let's select objects.

00:28:33.766 --> 00:28:36.026
So, I'm going to track this

00:28:36.026 --> 00:28:38.436
person under the red umbrella,

00:28:38.736 --> 00:28:40.136
and I'm going to try to track

00:28:40.136 --> 00:28:41.000
this group of people here.

00:28:46.156 --> 00:28:48.000
Let's run it.

00:28:54.436 --> 00:28:55.856
As you can see, we can

00:28:55.856 --> 00:28:58.706
successfully track the object

00:28:58.706 --> 00:29:00.000
that we selected.

00:29:06.756 --> 00:29:08.926
Let's look at the more complex

00:29:08.926 --> 00:29:09.306
example.

00:29:10.716 --> 00:29:12.066
What I want to track here, I

00:29:12.066 --> 00:29:13.186
want to track this wakeboarder

00:29:13.186 --> 00:29:15.616
guy, and in this case, I'm going

00:29:15.616 --> 00:29:16.636
to use my accurate algorithm.

00:29:17.966 --> 00:29:18.756
So, I'm going to select my

00:29:18.756 --> 00:29:19.500
object,

00:29:23.156 --> 00:29:25.000
and I'm going to run it.

00:29:30.136 --> 00:29:31.566
As you can see, this object

00:29:31.686 --> 00:29:33.626
changes pretty much everything

00:29:33.626 --> 00:29:35.316
about itself, its shape, the

00:29:35.316 --> 00:29:37.006
location, the colors, everything

00:29:37.006 --> 00:29:37.316
comes.

00:29:37.316 --> 00:29:38.686
We're still able to track it.

00:29:39.156 --> 00:29:39.976
I think this is pretty cool.

00:29:40.516 --> 00:29:46.686
[ Applause ]

00:29:47.186 --> 00:29:48.736
Now, we're going to switch to my

00:29:48.736 --> 00:29:50.086
demo machine and see how the

00:29:50.086 --> 00:29:51.366
actual tracking sequence is

00:29:51.366 --> 00:29:53.000
implemented in this app.

00:30:01.236 --> 00:30:02.426
So, I have the Xcode running,

00:30:02.706 --> 00:30:03.626
and I have my headphones

00:30:03.626 --> 00:30:05.546
connected to it, which is

00:30:05.546 --> 00:30:07.516
running the same app as we just

00:30:07.516 --> 00:30:07.696
saw.

00:30:08.356 --> 00:30:10.356
I'm going to run it in the

00:30:10.356 --> 00:30:11.000
debugger,

00:30:16.656 --> 00:30:18.446
going to select my objects, and

00:30:19.006 --> 00:30:20.896
it's not important what I select

00:30:20.896 --> 00:30:21.846
because we just want to look at

00:30:21.846 --> 00:30:22.416
the sequence.

00:30:23.396 --> 00:30:26.676
And I'm going to run it.

00:30:26.806 --> 00:30:29.096
So, I have a breakpoint set up

00:30:29.096 --> 00:30:30.256
here and it breaks in the

00:30:30.256 --> 00:30:32.226
perform tracking function, which

00:30:32.226 --> 00:30:33.536
is the most important function

00:30:33.536 --> 00:30:34.056
of this app.

00:30:34.746 --> 00:30:35.596
That's the function that

00:30:35.596 --> 00:30:36.826
implements the actual sequence.

00:30:37.396 --> 00:30:39.716
Let's see what we do here.

00:30:40.466 --> 00:30:42.986
First, we're creating our video

00:30:42.986 --> 00:30:43.236
reader.

00:30:44.086 --> 00:30:45.216
Then, we are reading first

00:30:45.216 --> 00:30:46.596
frame, and we're discarding that

00:30:46.596 --> 00:30:47.836
frame because that frame was

00:30:47.836 --> 00:30:48.916
used to select the objects.

00:30:50.396 --> 00:30:51.436
There's the cancellation flag

00:30:51.436 --> 00:30:51.676
here.

00:30:52.466 --> 00:30:54.256
Then, I'm going to initialize

00:30:54.256 --> 00:30:55.686
the collection of my input

00:30:55.686 --> 00:30:56.406
observations.

00:30:56.526 --> 00:30:57.716
Remember, as we saw an example

00:30:57.716 --> 00:30:58.206
in the slides.

00:31:01.016 --> 00:31:02.536
Then, I have my bookkeeping to

00:31:02.536 --> 00:31:04.366
be able to display results in a

00:31:04.366 --> 00:31:06.756
graphical user interface, which

00:31:06.756 --> 00:31:09.566
are kept in the trackedPolyRect

00:31:10.086 --> 00:31:10.186
type.

00:31:10.776 --> 00:31:12.716
Then, I'm going to run the

00:31:12.716 --> 00:31:14.686
switch on the type, and the type

00:31:14.686 --> 00:31:15.766
is something that comes from the

00:31:15.766 --> 00:31:16.896
user interface, and in this

00:31:16.896 --> 00:31:17.816
case, we're working with

00:31:17.996 --> 00:31:18.426
objects.

00:31:19.856 --> 00:31:22.126
Now, we selected two objects.

00:31:23.436 --> 00:31:24.676
So, this is the information

00:31:24.676 --> 00:31:26.136
coming from the user interface.

00:31:26.556 --> 00:31:27.936
We should see these two objects

00:31:27.936 --> 00:31:28.330
here.

00:31:32.046 --> 00:31:33.326
Okay, there are two of them.

00:31:33.476 --> 00:31:35.656
So, this loop will run two

00:31:35.656 --> 00:31:36.096
times.

00:31:36.426 --> 00:31:37.676
It will initialize input

00:31:37.676 --> 00:31:38.436
observations.

00:31:38.716 --> 00:31:39.936
It'll create detected object

00:31:39.936 --> 00:31:41.526
observation as also shown in the

00:31:41.526 --> 00:31:44.766
slides by passing bounding box

00:31:44.766 --> 00:31:44.926
in.

00:31:46.316 --> 00:31:47.556
And we initialize our

00:31:47.556 --> 00:31:49.536
bookkeeping structures.

00:31:50.116 --> 00:31:51.266
Let's run it.

00:31:58.116 --> 00:31:59.526
Let's look at the observation

00:31:59.746 --> 00:32:00.826
object.

00:32:07.576 --> 00:32:09.006
There are a couple of fields

00:32:09.006 --> 00:32:09.866
that are important here.

00:32:10.106 --> 00:32:11.406
This is the unique ID that we

00:32:11.406 --> 00:32:11.866
discussed.

00:32:11.966 --> 00:32:14.236
And then it's our bounding box

00:32:14.476 --> 00:32:15.606
in normalize organize.

00:32:18.076 --> 00:32:19.716
Now, if I run through, I'm going

00:32:19.716 --> 00:32:21.486
to hit this breakpoint because

00:32:21.486 --> 00:32:23.256
this case we're not using

00:32:23.286 --> 00:32:24.426
[inaudible] rectangles.

00:32:26.116 --> 00:32:27.756
This is where I create my

00:32:27.756 --> 00:32:28.726
sequence request handler.

00:32:29.246 --> 00:32:32.126
Now, I have my frame counter,

00:32:32.806 --> 00:32:35.276
I have my flag if something has

00:32:35.276 --> 00:32:37.486
failed, and I'm finally going to

00:32:37.486 --> 00:32:38.916
start my tracking sequence.

00:32:39.226 --> 00:32:40.636
As you can see, this is an

00:32:40.636 --> 00:32:42.006
infinite loop, and the

00:32:42.006 --> 00:32:43.256
conditions to get out of that

00:32:43.256 --> 00:32:44.656
loop is if the cancellation was

00:32:44.656 --> 00:32:46.676
requested, or if the movie has

00:32:46.676 --> 00:32:47.000
ended.

00:32:51.046 --> 00:32:53.566
I'm going to initialize my rect

00:32:54.976 --> 00:32:56.766
structure to keep the

00:32:56.766 --> 00:32:57.876
information for the graphical

00:32:57.876 --> 00:32:59.246
user in this interface to be

00:32:59.246 --> 00:33:01.846
displayed later, and I'm going

00:33:01.846 --> 00:33:04.066
to start iterating over my input

00:33:04.066 --> 00:33:05.606
observations, which we have to.

00:33:06.396 --> 00:33:07.306
For each one, I'm going to

00:33:07.306 --> 00:33:08.766
create a track object request.

00:33:15.106 --> 00:33:16.676
I'm going to advance my request

00:33:16.676 --> 00:33:17.486
to the collection of all

00:33:17.486 --> 00:33:19.576
requests, and we have to in this

00:33:19.916 --> 00:33:20.000
case.

00:33:22.236 --> 00:33:24.606
Going to break off the loop, and

00:33:24.606 --> 00:33:26.176
finally, I'm ready to process my

00:33:26.176 --> 00:33:26.716
requests.

00:33:27.346 --> 00:33:28.476
Now, if you can see the

00:33:28.476 --> 00:33:29.676
performed request, the perform

00:33:29.956 --> 00:33:31.986
function accepts a collection of

00:33:31.986 --> 00:33:32.446
requests.

00:33:33.206 --> 00:33:35.176
In the slides, we only used a

00:33:35.176 --> 00:33:37.326
single request to be passed into

00:33:37.326 --> 00:33:38.476
that collection, but here we're

00:33:38.476 --> 00:33:39.916
going to track two requests at

00:33:39.916 --> 00:33:40.446
the same time.

00:33:40.876 --> 00:33:44.486
I'm going to perform it.

00:33:44.756 --> 00:33:46.156
Now, since the requests are

00:33:46.156 --> 00:33:48.186
performed, I'm going to start

00:33:48.186 --> 00:33:49.596
looking at the results, and I'm

00:33:49.596 --> 00:33:50.706
going to do that by looking at

00:33:50.706 --> 00:33:52.606
the results property of each

00:33:54.776 --> 00:33:54.896
one.

00:33:55.096 --> 00:33:55.916
So, I'm going to get results

00:33:55.916 --> 00:33:56.406
property.

00:33:56.626 --> 00:33:57.876
I'm going to get the first

00:33:57.876 --> 00:33:59.206
object in that property because

00:33:59.206 --> 00:34:00.396
we expect them, the single one

00:34:00.396 --> 00:34:02.766
in there as an observation.

00:34:03.806 --> 00:34:04.926
What I'm going to do here, I'm

00:34:04.926 --> 00:34:06.936
going to look at the confidence

00:34:06.936 --> 00:34:08.976
property of my observation, and

00:34:08.976 --> 00:34:10.406
I set an arbitrary threshold to

00:34:10.406 --> 00:34:11.036
0.5.

00:34:12.156 --> 00:34:13.315
So, if it's above the threshold,

00:34:13.596 --> 00:34:15.585
I'm going to paint the bounding

00:34:15.585 --> 00:34:17.616
box with solid line, and if it's

00:34:17.616 --> 00:34:18.846
below the threshold, I'm going

00:34:18.846 --> 00:34:19.866
to paint it with a dashed line.

00:34:19.866 --> 00:34:21.196
So, I have, so I can have an

00:34:21.196 --> 00:34:22.856
indication if something is going

00:34:23.036 --> 00:34:23.255
wrong.

00:34:26.116 --> 00:34:27.616
The rest is simple bookkeeping.

00:34:27.716 --> 00:34:30.216
I'm just going to populate my

00:34:30.216 --> 00:34:32.636
rect structure, and this is the

00:34:32.636 --> 00:34:33.795
last step, which is very

00:34:33.795 --> 00:34:34.966
important where I take the

00:34:34.966 --> 00:34:36.076
observation from the current

00:34:36.076 --> 00:34:38.916
iteration, and I assign it for

00:34:38.916 --> 00:34:39.686
the next iteration.

00:34:43.596 --> 00:34:44.866
I'm going to do it a second

00:34:44.866 --> 00:34:45.136
time.

00:34:46.085 --> 00:34:47.106
I'm going to get to this

00:34:47.106 --> 00:34:47.746
breakpoint.

00:34:49.146 --> 00:34:50.346
Going to display my frame.

00:34:51.946 --> 00:34:53.136
I'm going to sleep for the frame

00:34:53.136 --> 00:34:54.966
rate in seconds time to simulate

00:34:54.966 --> 00:34:55.746
the actual movie.

00:34:56.186 --> 00:34:58.096
And then, before you know it,

00:34:58.296 --> 00:34:59.816
you're in the second iteration

00:35:00.176 --> 00:35:01.766
of your tracking sequence.

00:35:03.736 --> 00:35:05.276
So, let's get back to the slides

00:35:05.946 --> 00:35:06.000
now.

00:35:11.516 --> 00:35:11.776
Thank you.

00:35:12.516 --> 00:35:16.000
[ Applause ]

00:35:18.636 --> 00:35:19.846
So, let's look at what's

00:35:19.846 --> 00:35:21.096
important to remember from what

00:35:21.096 --> 00:35:21.786
we have just seen.

00:35:23.186 --> 00:35:25.966
First, how to initialize initial

00:35:25.966 --> 00:35:28.416
object for tracking, and we saw

00:35:28.416 --> 00:35:28.936
two ways.

00:35:28.976 --> 00:35:30.266
There's automatic way, which is

00:35:30.266 --> 00:35:31.666
usually done by running certain

00:35:31.666 --> 00:35:33.356
detectors and getting bounding

00:35:33.356 --> 00:35:33.946
boxes out.

00:35:34.776 --> 00:35:36.056
And the second is manual, which

00:35:36.056 --> 00:35:37.256
usually comes from the user

00:35:37.256 --> 00:35:38.000
input.

00:35:52.916 --> 00:35:54.926
We also saw that we used a

00:35:54.926 --> 00:35:57.646
single tracking request per

00:35:57.816 --> 00:35:58.456
tracked object.

00:35:58.856 --> 00:35:59.966
The relationship here is

00:35:59.966 --> 00:36:00.466
one-to-one.

00:36:03.396 --> 00:36:04.656
We also saw that there are two

00:36:04.656 --> 00:36:05.506
types of trackers.

00:36:05.806 --> 00:36:06.916
One is the general purpose

00:36:06.916 --> 00:36:08.396
tracker, and another one is

00:36:08.396 --> 00:36:10.216
rectangular object tracker.

00:36:12.396 --> 00:36:13.576
We also learned that there are

00:36:13.576 --> 00:36:15.636
two algorithms for each tracker

00:36:15.636 --> 00:36:15.906
type.

00:36:16.356 --> 00:36:18.116
There is fast and accurate, and

00:36:18.116 --> 00:36:20.366
this represents the tradeoff

00:36:20.366 --> 00:36:21.646
between speed and accuracy.

00:36:21.966 --> 00:36:24.766
And last but not least, we

00:36:24.866 --> 00:36:25.946
looked at how to use a

00:36:25.946 --> 00:36:28.116
confidence level property to

00:36:28.116 --> 00:36:29.586
judge whether we should or

00:36:29.586 --> 00:36:30.716
should not trust our results.

00:36:34.516 --> 00:36:35.796
What are the limits of

00:36:35.796 --> 00:36:37.046
implementing tracking sequence

00:36:37.046 --> 00:36:37.446
in Vision?

00:36:38.006 --> 00:36:42.406
First, let's talk about number

00:36:42.496 --> 00:36:43.646
of trackers.

00:36:45.136 --> 00:36:46.866
How many objects can you track

00:36:46.866 --> 00:36:47.546
simultaneously?

00:36:48.446 --> 00:36:49.796
Well, in Vision we have a limit

00:36:50.066 --> 00:36:53.186
that is set to 16 trackers for

00:36:53.186 --> 00:36:53.666
each type.

00:36:54.006 --> 00:36:55.346
So, you can have 16 general

00:36:55.346 --> 00:36:57.446
purpose object trackers and 16

00:36:58.076 --> 00:36:59.206
rectangular object trackers.

00:37:00.306 --> 00:37:01.826
If you try to allocate more,

00:37:01.826 --> 00:37:02.806
you'll get an error back.

00:37:03.976 --> 00:37:06.556
So, if it happens, you probably

00:37:06.556 --> 00:37:07.526
need to release some of the

00:37:07.526 --> 00:37:08.446
trackers that you're already

00:37:08.446 --> 00:37:08.776
using.

00:37:09.506 --> 00:37:12.576
How to do that?

00:37:12.576 --> 00:37:14.426
First way is you can set a last

00:37:14.426 --> 00:37:16.576
frame property under request and

00:37:16.576 --> 00:37:18.366
feed that request into the

00:37:18.366 --> 00:37:19.716
request handler for processing.

00:37:20.186 --> 00:37:21.436
That way, the request handler

00:37:21.436 --> 00:37:23.006
will know that the tracker

00:37:23.006 --> 00:37:24.206
associated with this request

00:37:24.206 --> 00:37:25.416
object should be released.

00:37:26.286 --> 00:37:27.936
Another way is to release the

00:37:27.936 --> 00:37:29.196
entire sequence request handler;

00:37:29.466 --> 00:37:31.136
in this case, all the trackers

00:37:31.136 --> 00:37:32.396
associated with that request

00:37:32.396 --> 00:37:34.000
handler will be released.

00:37:38.086 --> 00:37:39.646
Now, let's say you've

00:37:39.646 --> 00:37:40.566
implemented the tracking

00:37:40.566 --> 00:37:41.046
signals.

00:37:41.356 --> 00:37:42.206
What are the potential

00:37:42.206 --> 00:37:43.456
challenges that you may face?

00:37:44.486 --> 00:37:46.666
Well, as you've seen, objects in

00:37:46.666 --> 00:37:47.836
tracking sequence can change

00:37:47.836 --> 00:37:49.276
pretty much everything about

00:37:49.276 --> 00:37:49.836
themselves.

00:37:50.076 --> 00:37:50.966
They can change their shape,

00:37:50.966 --> 00:37:53.616
appearance, color, location, and

00:37:53.616 --> 00:37:54.566
that represents a great

00:37:54.566 --> 00:37:55.606
challenge for the algorithm.

00:37:56.606 --> 00:37:57.546
So, what can you do here?

00:37:58.536 --> 00:38:00.066
Well, one unfortunate answer is

00:38:00.066 --> 00:38:01.246
that there's no one size that

00:38:01.246 --> 00:38:02.916
fits all solution here, but you

00:38:02.916 --> 00:38:03.846
can try a couple of things.

00:38:04.326 --> 00:38:05.536
First, you can play with fast or

00:38:05.536 --> 00:38:06.986
accurate, and you can figure out

00:38:06.986 --> 00:38:09.186
that your particular use case

00:38:09.266 --> 00:38:10.736
works better with a particular

00:38:10.736 --> 00:38:11.176
algorithm.

00:38:14.956 --> 00:38:16.546
If you're in charge of selecting

00:38:16.546 --> 00:38:18.966
bounding box, try to find a

00:38:18.966 --> 00:38:21.486
select salient object in the

00:38:22.636 --> 00:38:22.766
same.

00:38:22.976 --> 00:38:23.956
Which confidence threshold to

00:38:23.956 --> 00:38:24.236
use?

00:38:25.386 --> 00:38:26.676
Again, there is no single answer

00:38:26.676 --> 00:38:26.936
here.

00:38:27.266 --> 00:38:28.286
You will find that some use

00:38:28.286 --> 00:38:29.366
cases work with certain

00:38:29.366 --> 00:38:30.816
thresholds while other use cases

00:38:30.816 --> 00:38:32.746
work with other thresholds.

00:38:34.656 --> 00:38:36.106
There's one more technique that

00:38:36.106 --> 00:38:36.836
I could recommend.

00:38:37.146 --> 00:38:37.996
Let's say you have a long

00:38:37.996 --> 00:38:39.086
tracking sequence, and for the

00:38:39.086 --> 00:38:40.556
sake of this example, 1,000

00:38:40.556 --> 00:38:40.936
frames.

00:38:42.266 --> 00:38:43.616
If you start that tracking

00:38:43.616 --> 00:38:45.486
sequence, your object that you

00:38:45.486 --> 00:38:46.976
selected in the first frame will

00:38:46.976 --> 00:38:48.236
start deviating, and it'll

00:38:48.236 --> 00:38:50.496
change everything about itself

00:38:50.996 --> 00:38:52.756
the more you go off of that

00:38:52.756 --> 00:38:53.376
initial frame.

00:38:54.356 --> 00:38:55.786
What you can do instead, you can

00:38:55.786 --> 00:38:57.186
break that sequence into smaller

00:38:57.186 --> 00:38:58.606
subsequences, let's say 50

00:38:58.606 --> 00:38:59.136
frames each.

00:38:59.706 --> 00:39:01.576
You run your detector, you track

00:39:01.576 --> 00:39:02.946
that object for 50 frames.

00:39:03.356 --> 00:39:05.186
You rerun the detector; you run

00:39:05.186 --> 00:39:06.546
it again for 50 frames, and you

00:39:06.546 --> 00:39:08.766
keep doing just like that.

00:39:08.886 --> 00:39:10.176
From the end user point of view,

00:39:10.466 --> 00:39:12.036
it'll look like you're tracking

00:39:12.086 --> 00:39:12.786
a single object.

00:39:13.726 --> 00:39:15.336
But what you do instead, what

00:39:15.336 --> 00:39:16.846
you do inside instead, you're

00:39:16.846 --> 00:39:18.416
tracking smaller sequences, and

00:39:18.416 --> 00:39:20.586
that's a smarter way of running

00:39:20.586 --> 00:39:21.500
and tracking sequence.

00:39:27.336 --> 00:39:28.356
Let's summarize what we have

00:39:28.356 --> 00:39:28.756
seen today.

00:39:30.306 --> 00:39:31.846
First, we talked about why you'd

00:39:31.846 --> 00:39:33.526
use Vision, and we talked about

00:39:33.526 --> 00:39:34.716
a multi-platform framework,

00:39:35.346 --> 00:39:36.876
privacy-oriented, which offers

00:39:36.876 --> 00:39:38.756
simple and consistent interface.

00:39:41.176 --> 00:39:42.796
Second, we talked about what's

00:39:42.796 --> 00:39:45.076
new, and we introduced a new

00:39:45.386 --> 00:39:46.756
orientation-agnostic face

00:39:46.756 --> 00:39:47.166
detector.

00:39:48.126 --> 00:39:49.556
We talked also about revisions.

00:39:50.976 --> 00:39:52.826
Then, we talked about how to

00:39:52.826 --> 00:39:54.796
interact with Vision API, and we

00:39:54.796 --> 00:39:56.546
discussed requests, request

00:39:56.546 --> 00:39:58.446
handlers, and observations.

00:39:58.656 --> 00:40:01.626
And finally, we looked at how to

00:40:01.626 --> 00:40:03.396
implement tracking sequence in

00:40:03.856 --> 00:40:04.000
Vision.

00:40:05.436 --> 00:40:06.886
For more information, I

00:40:06.886 --> 00:40:08.046
recommend you to refer to this

00:40:08.046 --> 00:40:09.976
link on the slide.

00:40:10.556 --> 00:40:12.176
I can also recommend you to stay

00:40:12.176 --> 00:40:13.226
for the next session, which will

00:40:13.226 --> 00:40:14.396
be at 3 o'clock in this room

00:40:14.646 --> 00:40:16.026
where Frank will cover details

00:40:16.026 --> 00:40:17.116
of integration of Vision and

00:40:17.116 --> 00:40:17.566
CoreML.

00:40:17.896 --> 00:40:19.226
This is especially important if

00:40:19.226 --> 00:40:20.086
you want to deploy your own

00:40:20.086 --> 00:40:20.546
models.

00:40:21.246 --> 00:40:22.396
That session will also cover

00:40:22.396 --> 00:40:24.576
some details about Vision

00:40:24.576 --> 00:40:25.736
Framework that were not covered

00:40:25.736 --> 00:40:26.296
by this session.

00:40:27.636 --> 00:40:28.676
And we'll also have Vison Lab

00:40:28.706 --> 00:40:30.166
tomorrow, which is 3 to 5.

00:40:31.176 --> 00:40:33.056
Thank you and have a great rest

00:40:33.056 --> 00:40:34.000
of your WWDC.

00:40:34.846 --> 00:40:38.500
[ Applause ]