WEBVTT

00:00:06.516 --> 00:00:15.500
[ Music ]

00:00:21.836 --> 00:00:23.076
>> [Applause] Hey, everyone.

00:00:25.266 --> 00:00:25.736
[Applause] Thank you.

00:00:25.736 --> 00:00:27.126
Good afternoon, and welcome to

00:00:27.126 --> 00:00:28.726
our session on Turi Create.

00:00:30.286 --> 00:00:31.676
This session builds upon

00:00:31.676 --> 00:00:33.236
yesterday's session on Create

00:00:33.236 --> 00:00:33.586
ML.

00:00:34.076 --> 00:00:35.316
That session covered many of the

00:00:35.316 --> 00:00:36.826
foundations of machine learning

00:00:36.826 --> 00:00:37.336
in Swift.

00:00:37.336 --> 00:00:38.596
So if you didn't catch that

00:00:38.596 --> 00:00:40.006
session I do recommend you add

00:00:40.006 --> 00:00:40.916
it to your watch list.

00:00:42.486 --> 00:00:44.396
The goal of Turi Create is to

00:00:44.396 --> 00:00:46.236
help you add intelligent user

00:00:46.236 --> 00:00:48.866
experiences to your apps.

00:00:49.516 --> 00:00:51.516
For example, you might want to

00:00:51.516 --> 00:00:52.606
be able to take a picture of

00:00:52.606 --> 00:00:53.266
your breakfast.

00:00:53.526 --> 00:00:54.916
And tap on the different food

00:00:54.916 --> 00:00:56.726
items to see how many calories

00:00:56.726 --> 00:00:57.386
you're consuming.

00:00:59.076 --> 00:01:01.136
Or maybe you want to control a

00:01:01.136 --> 00:01:03.496
lightbulb using your iPhone and

00:01:03.496 --> 00:01:04.486
simple gestures.

00:01:07.356 --> 00:01:08.736
Maybe you want to track an

00:01:08.736 --> 00:01:11.096
object in real time like a dog

00:01:11.156 --> 00:01:12.866
or a picture of a dog if you

00:01:12.866 --> 00:01:13.976
don't have dogs in the office.

00:01:14.516 --> 00:01:17.266
[ Laughter ]

00:01:17.766 --> 00:01:20.116
Maybe you have custom avatars in

00:01:20.116 --> 00:01:21.566
your game, and you want to

00:01:21.696 --> 00:01:22.516
provide personalized

00:01:22.516 --> 00:01:24.136
recommendations like hairstyles

00:01:24.496 --> 00:01:26.186
based on the beard that the user

00:01:26.186 --> 00:01:26.826
has selected.

00:01:28.216 --> 00:01:29.676
Or maybe you want to let your

00:01:29.676 --> 00:01:31.846
users apply artistic styles or

00:01:31.846 --> 00:01:33.756
filters to their own photos.

00:01:35.096 --> 00:01:37.056
These are very different user

00:01:37.056 --> 00:01:37.806
experiences.

00:01:38.256 --> 00:01:39.756
But they have several things in

00:01:39.756 --> 00:01:40.136
common.

00:01:41.046 --> 00:01:42.836
First and foremost, they use

00:01:42.836 --> 00:01:43.536
machine learning.

00:01:44.846 --> 00:01:46.556
These experiences all require

00:01:46.556 --> 00:01:49.906
very little data to create.

00:01:50.036 --> 00:01:51.516
All these models were made with

00:01:51.516 --> 00:01:53.646
Turi Create and deployed with

00:01:53.646 --> 00:01:54.186
Core ML.

00:01:55.656 --> 00:01:57.176
They all follow the five, the

00:01:57.176 --> 00:01:59.096
same five-step recipe that we'll

00:01:59.096 --> 00:02:00.226
go over today.

00:02:01.776 --> 00:02:02.906
And all these demo apps will

00:02:02.906 --> 00:02:04.366
also be available in our labs.

00:02:04.366 --> 00:02:06.056
So please join us today or

00:02:06.056 --> 00:02:08.326
Friday for the ML labs to get

00:02:08.326 --> 00:02:09.376
hands-on experience.

00:02:11.696 --> 00:02:14.026
Turi Create is a Python package

00:02:14.436 --> 00:02:15.846
that helps you create Core ML

00:02:15.846 --> 00:02:16.186
models.

00:02:17.436 --> 00:02:19.446
It's easy to use, so you don't

00:02:19.446 --> 00:02:20.816
need to be an ML expert or even

00:02:20.816 --> 00:02:22.066
have a background in machine

00:02:22.066 --> 00:02:23.326
learning to create these

00:02:23.326 --> 00:02:24.676
exciting user experiences.

00:02:25.626 --> 00:02:27.366
We make it easy to use by

00:02:27.366 --> 00:02:29.646
focusing on tasks first and

00:02:29.646 --> 00:02:30.206
foremost.

00:02:30.206 --> 00:02:31.576
What we do is we abstract away

00:02:31.576 --> 00:02:32.906
the complicated machine-learning

00:02:32.906 --> 00:02:34.776
algorithms so you can just focus

00:02:34.776 --> 00:02:35.866
on the user experience that

00:02:35.866 --> 00:02:36.746
you're trying to create.

00:02:38.056 --> 00:02:39.796
Turi Create is cross platform so

00:02:39.796 --> 00:02:41.836
you can use it both on Mac and

00:02:41.836 --> 00:02:42.226
Linux.

00:02:43.066 --> 00:02:44.436
And it's also open source.

00:02:45.726 --> 00:02:47.446
We have a repo on GitHub and we

00:02:47.446 --> 00:02:48.056
hope you'll visit.

00:02:48.056 --> 00:02:49.406
There's a lot of great resources

00:02:49.406 --> 00:02:50.186
to get started.

00:02:51.456 --> 00:02:52.786
And we look forward to working

00:02:52.786 --> 00:02:54.156
with you and the rest of the

00:02:54.156 --> 00:02:55.716
developer community to make Turi

00:02:55.716 --> 00:02:57.856
Create even better over time.

00:02:58.676 --> 00:03:00.276
Today we're excited to announce

00:03:00.276 --> 00:03:01.886
that the beta release of Turi

00:03:01.886 --> 00:03:04.216
Create 5.0 is now available.

00:03:04.986 --> 00:03:06.026
This has some powerful new

00:03:06.026 --> 00:03:06.576
features.

00:03:06.896 --> 00:03:08.336
Like GPU acceleration.

00:03:08.556 --> 00:03:09.846
And we'll go into these features

00:03:09.846 --> 00:03:11.396
in detail later on today.

00:03:12.776 --> 00:03:14.756
The main focus today is going to

00:03:14.756 --> 00:03:17.086
be the five-step recipe for

00:03:17.086 --> 00:03:18.366
creating Core ML models.

00:03:18.746 --> 00:03:20.306
I'm going to start by going over

00:03:20.306 --> 00:03:21.676
these steps at a high level.

00:03:22.086 --> 00:03:23.196
And then we'll dive into some

00:03:23.196 --> 00:03:24.486
demos and code.

00:03:25.026 --> 00:03:28.746
So the first step you need is to

00:03:28.746 --> 00:03:30.166
understand the task you're

00:03:30.166 --> 00:03:31.126
trying to accomplish.

00:03:31.566 --> 00:03:33.276
And how we refer to that task in

00:03:33.276 --> 00:03:34.316
machine learning terms.

00:03:35.686 --> 00:03:37.536
Second, you need to understand

00:03:37.866 --> 00:03:39.656
the type of data you need for

00:03:39.656 --> 00:03:40.616
this task.

00:03:41.026 --> 00:03:42.526
And how much of it.

00:03:43.696 --> 00:03:45.876
Third, you need to create your

00:03:45.876 --> 00:03:46.156
model.

00:03:48.056 --> 00:03:50.096
Fourth, you need to evaluate

00:03:50.096 --> 00:03:50.626
that model.

00:03:50.766 --> 00:03:52.066
That means understanding the

00:03:52.066 --> 00:03:53.536
quality of the model and wheth--

00:03:53.536 --> 00:03:54.416
whether it's ready for

00:03:54.416 --> 00:03:54.926
production.

00:03:56.106 --> 00:03:57.946
And finally, when your model's

00:03:57.946 --> 00:03:59.566
ready to deploy, it's really

00:03:59.566 --> 00:04:00.856
easy using Core ML.

00:04:02.356 --> 00:04:04.066
Let's dig a bit deeper into each

00:04:04.066 --> 00:04:04.786
of these steps.

00:04:06.076 --> 00:04:07.656
Turi Create lets you accomplish

00:04:07.656 --> 00:04:09.816
a wide variety of common machine

00:04:09.816 --> 00:04:10.566
learning tasks.

00:04:10.836 --> 00:04:11.976
And you can work with many

00:04:11.976 --> 00:04:13.306
different types of data.

00:04:13.926 --> 00:04:16.296
For example, if you have images,

00:04:16.616 --> 00:04:17.796
you might be interested in image

00:04:17.796 --> 00:04:18.646
classification.

00:04:18.805 --> 00:04:19.815
Or object detection.

00:04:20.856 --> 00:04:21.805
You might want to provide

00:04:21.805 --> 00:04:23.216
personalized recommendations for

00:04:23.216 --> 00:04:23.796
your users.

00:04:24.976 --> 00:04:25.876
You might want to be able to

00:04:25.876 --> 00:04:27.756
detect automatically activities

00:04:27.756 --> 00:04:30.226
like walking or jumping jacks.

00:04:30.416 --> 00:04:33.056
You might want to understand

00:04:33.056 --> 00:04:34.986
user sentiment given a block of

00:04:35.016 --> 00:04:35.426
text.

00:04:36.256 --> 00:04:37.606
Or you might be interested in

00:04:37.606 --> 00:04:39.006
more traditional machine

00:04:39.006 --> 00:04:40.306
learning algorithms like

00:04:40.306 --> 00:04:42.316
classification and regression.

00:04:44.636 --> 00:04:46.316
Now we know this can get really

00:04:46.316 --> 00:04:47.806
confusing to those of you who

00:04:47.806 --> 00:04:49.236
are new to machine learning.

00:04:49.696 --> 00:04:51.906
So we've taken a stab at making

00:04:51.906 --> 00:04:52.976
this really easy for you in our

00:04:52.976 --> 00:04:53.866
documentation.

00:04:54.266 --> 00:04:55.496
We begin by helping you

00:04:55.496 --> 00:04:56.986
understand the types of tasks

00:04:57.286 --> 00:04:59.156
that are possible and then how

00:04:59.156 --> 00:05:00.436
we reference them in machine

00:05:00.436 --> 00:05:01.176
learning terms.

00:05:01.716 --> 00:05:03.196
So what we can do now is revisit

00:05:03.196 --> 00:05:04.596
those intelligent experiences

00:05:04.596 --> 00:05:05.326
that we walked through at the

00:05:05.326 --> 00:05:06.606
beginning of this presentation

00:05:06.956 --> 00:05:08.176
and assign them to these machine

00:05:08.176 --> 00:05:09.026
learning tasks.

00:05:09.626 --> 00:05:10.856
For example, if you want to

00:05:10.856 --> 00:05:12.616
recognize different types of

00:05:12.616 --> 00:05:14.676
flowers in photos we call that

00:05:14.676 --> 00:05:15.826
image classification.

00:05:17.236 --> 00:05:19.136
If you want to take pictures of

00:05:19.406 --> 00:05:20.766
your breakfast and understand

00:05:20.766 --> 00:05:22.096
the different food objects

00:05:22.096 --> 00:05:24.066
within them, we call them, that

00:05:24.066 --> 00:05:24.876
object detection.

00:05:25.436 --> 00:05:27.986
If you want to apply artistic

00:05:27.986 --> 00:05:30.246
styles to your own photos, we

00:05:30.246 --> 00:05:31.546
call that style transfer.

00:05:33.606 --> 00:05:35.256
And if you want to recognize

00:05:35.356 --> 00:05:37.046
gestures or motions or different

00:05:37.046 --> 00:05:38.816
activities using sensors of

00:05:38.816 --> 00:05:40.556
different devices, we call that

00:05:40.556 --> 00:05:41.896
activity classification.

00:05:43.996 --> 00:05:45.616
Finally, if you want to make

00:05:45.656 --> 00:05:46.906
personalized recommendations to

00:05:46.906 --> 00:05:48.886
your users, we call this task

00:05:49.106 --> 00:05:50.086
recommender systems.

00:05:50.766 --> 00:05:53.936
Now the great thing is that the

00:05:53.936 --> 00:05:55.756
same five-step recipe we just

00:05:55.756 --> 00:05:57.596
walked through also applies to

00:05:57.596 --> 00:05:58.106
your code.

00:05:59.156 --> 00:06:00.786
We begin by importing Turi

00:06:00.786 --> 00:06:01.236
Create.

00:06:02.526 --> 00:06:04.796
We proceed to load our data into

00:06:04.796 --> 00:06:06.046
a data structure called an

00:06:06.046 --> 00:06:06.466
SFrame.

00:06:06.816 --> 00:06:07.796
And we'll go into a bit more

00:06:07.796 --> 00:06:09.156
detail on the SFrame data

00:06:09.156 --> 00:06:10.006
structure shortly.

00:06:10.486 --> 00:06:13.106
We'll proceed to create our

00:06:13.106 --> 00:06:14.736
model with a simple function,

00:06:14.816 --> 00:06:15.446
.create.

00:06:15.966 --> 00:06:18.116
This, this function extracts

00:06:18.116 --> 00:06:19.336
away the complicated machine

00:06:19.336 --> 00:06:22.066
learning behind the scenes.

00:06:22.956 --> 00:06:24.966
We proceed to evaluate our model

00:06:24.966 --> 00:06:25.956
with the simple function

00:06:26.176 --> 00:06:26.916
.evaluate.

00:06:27.476 --> 00:06:30.266
And finally we can export the

00:06:30.266 --> 00:06:32.586
resulting model to Core ML's

00:06:32.626 --> 00:06:34.396
ML-model format to be easily

00:06:34.396 --> 00:06:36.686
dragged and dropped into Xcode.

00:06:37.356 --> 00:06:39.226
Now I mentioned that this same

00:06:39.226 --> 00:06:41.166
five-step template applies to

00:06:41.166 --> 00:06:42.866
all the different tasks within

00:06:42.866 --> 00:06:43.506
Turi Create.

00:06:44.296 --> 00:06:45.146
So whether you're working on

00:06:45.146 --> 00:06:47.186
object detection, image

00:06:47.186 --> 00:06:49.716
classification or activity

00:06:49.716 --> 00:06:51.896
classification, the same code

00:06:51.896 --> 00:06:52.806
template applies.

00:06:52.806 --> 00:06:56.826
For our first demo today, we're

00:06:57.066 --> 00:06:58.016
going to walk through a

00:06:58.016 --> 00:06:59.846
calorie-counting app that uses

00:06:59.846 --> 00:07:01.196
an object detection model.

00:07:01.746 --> 00:07:02.866
So we'll want to recognize

00:07:03.186 --> 00:07:04.486
different foods within an image.

00:07:04.726 --> 00:07:05.636
And we'll need to know where

00:07:05.636 --> 00:07:07.046
those, where in the image those

00:07:07.046 --> 00:07:08.396
foods are so that we could tap

00:07:08.396 --> 00:07:09.346
on them to see the different

00:07:09.346 --> 00:07:10.000
calorie counts.

00:07:13.196 --> 00:07:14.636
So let's take a look at the type

00:07:14.636 --> 00:07:16.036
of data that we'll need to

00:07:16.036 --> 00:07:17.576
create this machine learning

00:07:17.576 --> 00:07:17.846
model.

00:07:18.436 --> 00:07:20.906
Of course we need images.

00:07:20.906 --> 00:07:21.866
And if we were just building a

00:07:21.866 --> 00:07:24.006
simple image classifier model,

00:07:24.306 --> 00:07:25.286
we would just need our set of

00:07:25.286 --> 00:07:27.316
images and labels that describe

00:07:27.316 --> 00:07:28.356
the images overall.

00:07:29.366 --> 00:07:30.506
But because we're performing

00:07:30.746 --> 00:07:32.506
object detection, we need a bit

00:07:32.506 --> 00:07:33.316
more information.

00:07:33.956 --> 00:07:35.416
We need to understand not just

00:07:35.416 --> 00:07:36.226
what's in the image.

00:07:36.496 --> 00:07:37.766
But where those objects are.

00:07:38.146 --> 00:07:40.126
Now if we zoom in a bit closer

00:07:40.126 --> 00:07:42.596
to one example, we see a red box

00:07:42.646 --> 00:07:43.756
around a cup of coffee.

00:07:44.616 --> 00:07:45.866
And a green box around a

00:07:45.866 --> 00:07:46.376
croissant.

00:07:47.336 --> 00:07:48.916
We call those boxes bounding

00:07:48.916 --> 00:07:50.996
boxes and we represent those in

00:07:50.996 --> 00:07:51.936
JSON format.

00:07:52.296 --> 00:07:53.806
With a label, and then with

00:07:53.806 --> 00:07:55.796
coordinates x, y, width and

00:07:55.796 --> 00:07:56.086
height.

00:07:56.656 --> 00:07:58.186
Where x and y refer to the

00:07:58.186 --> 00:07:59.926
center of that bounding box.

00:08:00.216 --> 00:08:01.426
So it's also worth noting that

00:08:01.426 --> 00:08:03.066
with object detection, you can

00:08:03.066 --> 00:08:05.196
reference or detect multiple

00:08:05.196 --> 00:08:07.486
images, multiple objects within

00:08:07.486 --> 00:08:07.996
each image.

00:08:07.996 --> 00:08:11.086
So I mentioned that we'd be

00:08:11.086 --> 00:08:12.816
loading our data into this

00:08:12.816 --> 00:08:14.246
tabular data structure called an

00:08:14.246 --> 00:08:14.686
SFrame.

00:08:15.406 --> 00:08:16.716
And in this example, we will end

00:08:16.716 --> 00:08:17.926
up with two columns.

00:08:18.136 --> 00:08:19.326
The first column will contain

00:08:19.326 --> 00:08:19.836
your images.

00:08:20.466 --> 00:08:22.086
The second column will contain

00:08:22.086 --> 00:08:24.000
your annotations in JSON format.

00:08:27.476 --> 00:08:29.306
Let's or by now you're probably

00:08:29.306 --> 00:08:30.886
wondering what is an SFrame?

00:08:30.886 --> 00:08:32.506
So let's take a step back and,

00:08:32.506 --> 00:08:34.706
and learn more about it.

00:08:34.706 --> 00:08:36.596
SFrame is a [inaudible] tabular

00:08:36.596 --> 00:08:37.376
data structure.

00:08:37.566 --> 00:08:39.006
And what this means is you can

00:08:39.395 --> 00:08:40.976
create machine learning models

00:08:40.976 --> 00:08:41.806
on your laptop.

00:08:41.966 --> 00:08:43.015
Even if you have enormous

00:08:43.015 --> 00:08:45.226
amounts of data.

00:08:45.366 --> 00:08:46.656
SFrame allows you to perform

00:08:46.656 --> 00:08:48.676
common data manipulation tasks.

00:08:49.026 --> 00:08:50.816
Like joining two SFrames or

00:08:50.816 --> 00:08:52.686
filtering to specific rows or

00:08:52.686 --> 00:08:53.476
columns of data.

00:08:55.296 --> 00:08:57.046
SFrames let you work with all

00:08:57.046 --> 00:08:57.976
different data types.

00:08:58.926 --> 00:08:59.986
And once you have your data

00:09:00.046 --> 00:09:02.486
loaded into an SFrame, it's easy

00:09:02.486 --> 00:09:04.446
to visually explore and inspect

00:09:04.446 --> 00:09:05.000
your data.

00:09:08.936 --> 00:09:10.426
Let's zoom in a bit more on

00:09:10.426 --> 00:09:11.796
what's possible with SFrame.

00:09:12.796 --> 00:09:13.946
With our object detector

00:09:13.946 --> 00:09:14.396
example.

00:09:15.446 --> 00:09:17.026
So after we import Turi Create,

00:09:17.426 --> 00:09:18.436
in the case of our object

00:09:18.436 --> 00:09:20.206
detector, we're actually going

00:09:20.276 --> 00:09:21.606
to load two different SFrames.

00:09:22.086 --> 00:09:23.406
The first containing our

00:09:23.406 --> 00:09:25.526
annotations, and the second

00:09:26.036 --> 00:09:27.166
containing our images.

00:09:27.896 --> 00:09:29.556
We have a simple function

00:09:29.556 --> 00:09:31.526
.explore that will allow you to

00:09:31.526 --> 00:09:32.806
visually inspect the data you've

00:09:32.806 --> 00:09:33.276
imported.

00:09:34.276 --> 00:09:35.876
We can do things like access

00:09:35.876 --> 00:09:36.896
specific rows.

00:09:37.386 --> 00:09:38.496
Or columns of our data.

00:09:39.866 --> 00:09:40.976
And of course we can do common

00:09:40.976 --> 00:09:43.266
operations like joining our two

00:09:43.266 --> 00:09:44.286
SFrames into one.

00:09:44.826 --> 00:09:46.546
And saving the resulting SFrame

00:09:46.986 --> 00:09:49.476
for later use or to share with a

00:09:51.176 --> 00:09:51.356
colleague.

00:09:51.486 --> 00:09:52.746
Next we create our model.

00:09:53.146 --> 00:09:54.306
So I mentioned we have this

00:09:54.396 --> 00:09:56.746
simple function .create that

00:09:56.746 --> 00:09:58.126
does all the heavy lifting for

00:09:58.126 --> 00:09:59.236
the creation of the actual

00:09:59.236 --> 00:09:59.576
model.

00:10:00.016 --> 00:10:01.486
And what we do behind the scenes

00:10:01.486 --> 00:10:03.026
is we ensure that the model we

00:10:03.026 --> 00:10:04.546
create for you is customized to

00:10:04.546 --> 00:10:06.076
the task and that it's state of

00:10:06.076 --> 00:10:06.496
the art.

00:10:06.496 --> 00:10:07.916
Meaning it's as high quality and

00:10:07.956 --> 00:10:10.016
high accuracy as we can get.

00:10:10.016 --> 00:10:11.206
And we're able to do this

00:10:11.206 --> 00:10:12.256
whether you have large amounts

00:10:12.256 --> 00:10:13.956
of data or small amounts of

00:10:13.956 --> 00:10:14.206
data.

00:10:14.516 --> 00:10:16.336
It's very important for us that

00:10:16.386 --> 00:10:17.926
all of our tasks work whether

00:10:17.926 --> 00:10:19.846
you have even a small amount of

00:10:19.846 --> 00:10:22.116
data as small as about 40 images

00:10:22.176 --> 00:10:23.266
per item that you're trying to

00:10:23.266 --> 00:10:24.676
detect in the class of object.

00:10:25.106 --> 00:10:26.276
In the case of object detection.

00:10:26.826 --> 00:10:30.866
Let's move on to evaluation.

00:10:31.236 --> 00:10:32.446
So I mentioned we have a simple

00:10:32.446 --> 00:10:34.936
function .evaluate that will

00:10:34.936 --> 00:10:36.566
give you an idea of the quality

00:10:36.566 --> 00:10:37.106
of your model.

00:10:38.216 --> 00:10:40.006
In the case of object detectors.

00:10:40.416 --> 00:10:42.086
We have two factors to consider.

00:10:42.406 --> 00:10:43.846
First, we want to know did we

00:10:43.846 --> 00:10:44.766
get the label right?

00:10:45.386 --> 00:10:46.966
But we also have to know if we

00:10:46.966 --> 00:10:48.306
got that bounding box right

00:10:48.666 --> 00:10:49.476
around the object.

00:10:50.616 --> 00:10:51.876
So we can establish a simple

00:10:51.876 --> 00:10:53.846
metric with these two factors

00:10:53.846 --> 00:10:55.906
and go through a test data set

00:10:55.906 --> 00:10:57.696
scoring predictions against

00:10:57.696 --> 00:10:59.996
known what we call ground-truth

00:11:00.316 --> 00:11:00.616
data.

00:11:01.446 --> 00:11:02.726
And so we want to make sure that

00:11:02.726 --> 00:11:04.026
we have correct labels.

00:11:04.506 --> 00:11:07.046
And then a standard metric is at

00:11:07.046 --> 00:11:08.906
least 50% overlap in the

00:11:08.906 --> 00:11:10.616
predicted bounding box when

00:11:10.616 --> 00:11:11.296
compared with to the

00:11:11.296 --> 00:11:12.756
ground-truth bounding box.

00:11:13.206 --> 00:11:14.676
Let's look at a few examples.

00:11:15.236 --> 00:11:18.296
In this prediction we see that

00:11:18.296 --> 00:11:19.806
the model got the label right

00:11:20.336 --> 00:11:21.316
with a cup of coffee.

00:11:21.906 --> 00:11:23.316
But that bounding box is not

00:11:23.316 --> 00:11:24.676
really covering the whole cup of

00:11:24.676 --> 00:11:25.016
coffee.

00:11:25.016 --> 00:11:26.066
It's only about ten percent

00:11:26.066 --> 00:11:27.286
overlapping the ground truth.

00:11:27.726 --> 00:11:29.256
So we're going to consider that

00:11:29.666 --> 00:11:31.676
a bad prediction.

00:11:31.676 --> 00:11:33.136
Here we see a highly accurate

00:11:33.136 --> 00:11:35.106
bounding box, but we got the

00:11:35.106 --> 00:11:35.816
label wrong.

00:11:35.896 --> 00:11:36.786
That's not a banana.

00:11:37.206 --> 00:11:38.706
So let's not consider that a

00:11:38.706 --> 00:11:39.896
successful prediction either.

00:11:41.006 --> 00:11:42.236
Now this middle example's what

00:11:42.236 --> 00:11:42.866
we want to see.

00:11:43.336 --> 00:11:44.906
We have 70% overlap of our

00:11:44.906 --> 00:11:46.836
bounding box, and the correct

00:11:46.836 --> 00:11:47.896
label, coffee.

00:11:48.796 --> 00:11:49.776
So what we can do is

00:11:49.776 --> 00:11:51.416
systematically go through all of

00:11:51.416 --> 00:11:52.806
our predictions with a test data

00:11:52.806 --> 00:11:53.066
set.

00:11:53.656 --> 00:11:55.026
And get an overall accuracy

00:11:55.026 --> 00:11:56.806
score for a new model.

00:11:57.356 --> 00:12:00.676
And finally, we move to

00:12:00.676 --> 00:12:01.196
deployment.

00:12:01.896 --> 00:12:03.146
We have an export to Core ML

00:12:03.146 --> 00:12:04.556
function that saves your model

00:12:04.626 --> 00:12:06.386
to Core ML's ML model format.

00:12:06.816 --> 00:12:08.056
So you can then drag and drop

00:12:08.056 --> 00:12:09.486
that model in to Xcode.

00:12:10.696 --> 00:12:12.046
This week we've actually some

00:12:12.046 --> 00:12:13.806
exciting new features related to

00:12:13.806 --> 00:12:15.296
object detection specifically.

00:12:15.856 --> 00:12:16.876
So I encourage you to attend

00:12:16.876 --> 00:12:18.716
tomorrow's Vision with Core ML

00:12:18.716 --> 00:12:20.506
session to learn more.

00:12:20.876 --> 00:12:21.886
In that session, the speaker

00:12:21.886 --> 00:12:23.076
will actually take the object

00:12:23.076 --> 00:12:24.036
detection model that we're

00:12:24.036 --> 00:12:26.146
building today and go into more

00:12:26.146 --> 00:12:27.706
detail about deployment options.

00:12:28.316 --> 00:12:30.996
And there you have it!

00:12:31.536 --> 00:12:33.486
The five-step recipe for Turi

00:12:33.486 --> 00:12:33.826
Create.

00:12:35.516 --> 00:12:38.946
[ Applause ]

00:12:39.446 --> 00:12:40.036
Thank you.

00:12:40.316 --> 00:12:41.256
So with that, I'm going to hand

00:12:41.256 --> 00:12:42.896
off to my colleague Zach Nation,

00:12:42.896 --> 00:12:43.426
for a demo.

00:12:45.516 --> 00:12:50.436
[ Applause ]

00:12:50.936 --> 00:12:51.536
>> Thanks, Aaron.

00:12:52.466 --> 00:12:54.126
I think let's just jump straight

00:12:54.126 --> 00:12:54.616
into code.

00:12:54.616 --> 00:12:55.616
Who wants to write some code

00:12:55.616 --> 00:12:56.516
live today?

00:12:56.946 --> 00:12:58.096
We're going to go ahead and

00:12:58.096 --> 00:12:59.496
build an object detector model

00:12:59.496 --> 00:13:00.000
right now.

00:13:10.046 --> 00:13:11.416
So I'm going to start out in

00:13:11.416 --> 00:13:11.956
Finder.

00:13:12.336 --> 00:13:14.216
Here I've got a folder of images

00:13:14.596 --> 00:13:15.906
that I want to use to train a

00:13:15.906 --> 00:13:16.266
model.

00:13:17.206 --> 00:13:18.546
We can see this folder's named

00:13:18.546 --> 00:13:21.476
Data, and it's full of images of

00:13:21.506 --> 00:13:22.296
breakfast foods.

00:13:22.786 --> 00:13:25.046
I've got a croissant, some eggs,

00:13:25.396 --> 00:13:25.936
and so on.

00:13:26.516 --> 00:13:29.006
This is, this is a good data set

00:13:29.006 --> 00:13:29.736
for breakfast food.

00:13:29.736 --> 00:13:31.086
I think let's go ahead and write

00:13:31.086 --> 00:13:31.746
some code with it.

00:13:33.016 --> 00:13:34.806
I'm going to switch over to an

00:13:34.806 --> 00:13:35.986
environment called Jupyter

00:13:35.986 --> 00:13:36.466
notebook.

00:13:37.096 --> 00:13:38.546
This is an interactive Python

00:13:38.546 --> 00:13:40.576
environment where you can run

00:13:40.576 --> 00:13:42.026
snippets of Python code and

00:13:42.026 --> 00:13:43.256
immediately see the output.

00:13:43.526 --> 00:13:45.126
So this is a great way to

00:13:45.126 --> 00:13:46.526
interactively work with a model.

00:13:46.776 --> 00:13:48.616
And it's very similar in concept

00:13:48.816 --> 00:13:50.066
to Xcode Playgrounds.

00:13:51.056 --> 00:13:52.116
The first thing we're going to

00:13:52.116 --> 00:13:55.996
do is import Turi Create as TC.

00:13:56.396 --> 00:14:00.376
And that we way we can refer to

00:14:00.376 --> 00:14:01.946
it as TC throughout the rest of

00:14:01.946 --> 00:14:02.416
the script.

00:14:03.576 --> 00:14:05.326
Now, the first task we want to

00:14:06.166 --> 00:14:07.336
do is load data.

00:14:07.916 --> 00:14:12.086
And we're going to load it up

00:14:12.086 --> 00:14:13.356
into SFrame format.

00:14:14.256 --> 00:14:15.846
So first we can say images

00:14:15.846 --> 00:14:18.046
equals TC.loadimages.

00:14:18.536 --> 00:14:19.386
And we're going to give it that

00:14:19.386 --> 00:14:21.216
folder day that I just showed in

00:14:21.216 --> 00:14:21.616
Finder.

00:14:22.166 --> 00:14:26.476
And Turi Create provides

00:14:26.476 --> 00:14:28.206
utilities to interactively

00:14:28.206 --> 00:14:29.766
explore and visualize our data.

00:14:30.006 --> 00:14:31.346
So let's make sure those images

00:14:31.346 --> 00:14:32.866
loaded correctly and we got the

00:14:32.866 --> 00:14:34.016
resulting SFrame that we

00:14:34.016 --> 00:14:34.496
expected.

00:14:35.216 --> 00:14:36.696
I'm just going to call .explore,

00:14:37.456 --> 00:14:38.826
and this is going to open up a

00:14:38.826 --> 00:14:40.346
visualization window where we

00:14:40.346 --> 00:14:41.976
can see that we have two columns

00:14:41.976 --> 00:14:42.696
in our SFrame.

00:14:43.166 --> 00:14:44.746
The first is called path, and

00:14:44.746 --> 00:14:46.256
it's the relative path to that

00:14:46.256 --> 00:14:47.106
image on disk.

00:14:47.536 --> 00:14:48.816
And the second column is called

00:14:48.816 --> 00:14:49.296
image.

00:14:49.566 --> 00:14:50.876
And that's actually the contents

00:14:50.876 --> 00:14:51.866
of the image itself.

00:14:52.096 --> 00:14:53.166
And we can see our breakfast

00:14:53.206 --> 00:14:53.906
foods right here.

00:14:54.676 --> 00:14:55.586
It looks like these loaded

00:14:55.586 --> 00:14:56.956
correctly, so I'm going to

00:14:56.956 --> 00:14:57.356
proceed.

00:14:57.906 --> 00:15:01.026
Back in Jupyter notebook.

00:15:01.416 --> 00:15:02.786
Now I'm also going to load up a

00:15:02.786 --> 00:15:04.196
second SFrame called

00:15:04.196 --> 00:15:04.996
annotations.

00:15:05.536 --> 00:15:09.416
And this I'm just going to call

00:15:09.416 --> 00:15:11.066
the SFrame instructor and

00:15:11.066 --> 00:15:12.346
provide a file name to

00:15:12.346 --> 00:15:13.896
annotations.csv.

00:15:14.326 --> 00:15:16.286
This is a CSV file containing

00:15:16.286 --> 00:15:17.776
the annotations that correspond

00:15:17.776 --> 00:15:18.546
to those images.

00:15:19.236 --> 00:15:23.256
And let's take a look at that.

00:15:23.876 --> 00:15:25.206
Right in Jupyter notebook, we

00:15:25.206 --> 00:15:26.296
can see that this SFrame

00:15:26.296 --> 00:15:28.146
contains a path column, again

00:15:28.146 --> 00:15:29.476
pointing to that relative path

00:15:29.476 --> 00:15:30.706
on disk of the image.

00:15:31.206 --> 00:15:32.926
And an annotation column

00:15:33.156 --> 00:15:34.606
containing a JSON object

00:15:34.806 --> 00:15:36.326
describing the bounding box and

00:15:36.326 --> 00:15:37.966
labels associated with that

00:15:37.966 --> 00:15:38.366
image.

00:15:39.806 --> 00:15:40.866
But now we have two different

00:15:40.866 --> 00:15:42.636
data sources and we need to

00:15:42.826 --> 00:15:44.286
provide one data source to train

00:15:44.286 --> 00:15:44.776
our model.

00:15:45.316 --> 00:15:46.406
Let's join them together.

00:15:47.096 --> 00:15:48.986
In Turi Create, this is as easy

00:15:48.986 --> 00:15:50.186
as calling the join method.

00:15:50.616 --> 00:15:52.626
I'm going to say data equals

00:15:52.956 --> 00:15:57.946
images.joinannotations and now

00:15:58.066 --> 00:15:59.916
we can see we have a single

00:16:00.036 --> 00:16:01.656
SFrame with three columns.

00:16:02.216 --> 00:16:03.766
It joined on that path column.

00:16:04.016 --> 00:16:05.956
So for each image with a path,

00:16:06.206 --> 00:16:07.766
it combined the annotations for

00:16:07.766 --> 00:16:08.246
that path.

00:16:09.006 --> 00:16:10.566
And so now for each image, we

00:16:10.566 --> 00:16:11.806
have annotations available.

00:16:12.656 --> 00:16:13.486
Now we're ready to train a

00:16:13.486 --> 00:16:13.786
model.

00:16:14.386 --> 00:16:17.936
So I'm going to create a new

00:16:17.936 --> 00:16:20.396
section here called train a

00:16:20.396 --> 00:16:20.716
model.

00:16:23.406 --> 00:16:26.006
And that's just one line of code

00:16:26.006 --> 00:16:26.276
here.

00:16:26.276 --> 00:16:28.096
I'm going to say model equals

00:16:28.426 --> 00:16:30.606
TC.objectdetector.create.

00:16:30.936 --> 00:16:31.896
And this is our simple

00:16:31.896 --> 00:16:33.636
task-focused API for object

00:16:33.636 --> 00:16:35.166
detection that expects data in

00:16:35.166 --> 00:16:35.696
this format.

00:16:36.476 --> 00:16:37.906
I'm going to pass in that data

00:16:37.906 --> 00:16:39.226
SFrame that I just created.

00:16:39.686 --> 00:16:41.126
And for the purposes of today's

00:16:41.126 --> 00:16:42.816
demo, I'm going to pass another

00:16:42.816 --> 00:16:44.686
parameter called max iterations

00:16:45.136 --> 00:16:46.706
and normally you wouldn't need

00:16:46.706 --> 00:16:48.046
to pass this parameter because

00:16:48.086 --> 00:16:49.366
Turi Create will pick the

00:16:49.366 --> 00:16:50.846
correct number of iterations for

00:16:50.846 --> 00:16:51.076
you.

00:16:51.226 --> 00:16:52.206
Based on the data that you

00:16:52.206 --> 00:16:52.676
provide.

00:16:53.456 --> 00:16:54.916
In this case, I'm going to say

00:16:54.916 --> 00:16:56.876
max iterations equals one just

00:16:56.876 --> 00:16:58.216
to give an example of what

00:16:58.216 --> 00:16:59.076
training would look like.

00:16:59.886 --> 00:17:01.216
And the reason this is going to

00:17:01.216 --> 00:17:02.556
take a minute is it actually

00:17:02.556 --> 00:17:03.856
goes through and resizes all of

00:17:03.856 --> 00:17:05.445
those images in order to get

00:17:05.445 --> 00:17:06.856
them ready to run through the

00:17:06.856 --> 00:17:07.435
neural network.

00:17:07.435 --> 00:17:08.836
That is under the hood of this

00:17:08.836 --> 00:17:09.665
object detector.

00:17:10.465 --> 00:17:12.036
And then it will perform just

00:17:12.036 --> 00:17:14.856
one iteration on this Mac GPO.

00:17:16.116 --> 00:17:17.965
But this is probably not the

00:17:17.965 --> 00:17:19.435
best model we could get because

00:17:19.435 --> 00:17:20.496
I just wanted to train it in a

00:17:20.496 --> 00:17:21.306
couple of seconds.

00:17:21.656 --> 00:17:22.906
So I'm going to go ahead and

00:17:22.906 --> 00:17:24.685
switch over to like cooking show

00:17:24.685 --> 00:17:25.016
mode.

00:17:25.056 --> 00:17:26.406
And I'm going to take one out of

00:17:26.406 --> 00:17:27.445
the oven that we've had in there

00:17:27.445 --> 00:17:28.036
for an hour [laughter].

00:17:28.726 --> 00:17:30.826
[Applause] So I'm going to say

00:17:30.826 --> 00:17:34.676
TC.loadmodel and it's called

00:17:34.796 --> 00:17:36.696
breakfastmodel.model.

00:17:36.696 --> 00:17:39.546
And this is one that I've had an

00:17:39.546 --> 00:17:40.896
opportunity to train for a bit

00:17:40.896 --> 00:17:41.316
longer.

00:17:41.806 --> 00:17:43.466
So let's inspect that right here

00:17:43.466 --> 00:17:44.026
in the notebook.

00:17:44.266 --> 00:17:45.396
And we can see that it's an

00:17:45.396 --> 00:17:46.576
object detector model.

00:17:47.226 --> 00:17:48.356
It's been trained on six

00:17:48.386 --> 00:17:50.336
classes, and we trained it for

00:17:50.336 --> 00:17:51.486
55 minutes.

00:17:52.026 --> 00:17:53.006
This is means, this means you

00:17:53.006 --> 00:17:54.296
can train a useful

00:17:54.296 --> 00:17:55.966
object-detector model in under

00:17:55.966 --> 00:17:58.000
an hour on your Mac.

00:18:01.096 --> 00:18:02.866
Next, let's test the predictions

00:18:02.866 --> 00:18:04.336
of this model and see if it's

00:18:04.336 --> 00:18:05.000
any good.

00:18:11.046 --> 00:18:11.876
So I'm going to make a new

00:18:11.876 --> 00:18:13.096
section here called inspect

00:18:13.166 --> 00:18:13.676
predictions.

00:18:14.056 --> 00:18:15.506
And we're going to go ahead and

00:18:15.716 --> 00:18:17.436
load up a test data set.

00:18:18.026 --> 00:18:19.496
And here I've already prepared

00:18:19.496 --> 00:18:20.676
one in SFrame format.

00:18:20.676 --> 00:18:21.716
So I'm just going to load it,

00:18:22.436 --> 00:18:23.266
and I called it

00:18:23.266 --> 00:18:25.046
testbreakfastdata.sframe.

00:18:25.666 --> 00:18:26.606
There are two important

00:18:26.606 --> 00:18:28.756
properties of this test SFrame.

00:18:29.146 --> 00:18:31.126
One is that it contains the same

00:18:31.126 --> 00:18:33.256
types of images that the model

00:18:33.366 --> 00:18:34.316
would have trained on.

00:18:34.656 --> 00:18:36.216
But the second important

00:18:36.216 --> 00:18:37.756
property is the model has never

00:18:37.756 --> 00:18:39.266
seen these images before.

00:18:39.556 --> 00:18:41.136
So this is a good test for

00:18:41.136 --> 00:18:42.126
whether that model can

00:18:42.126 --> 00:18:44.176
generalize to users' real data.

00:18:44.756 --> 00:18:48.466
I'm going to make predictions

00:18:48.566 --> 00:18:50.176
from that whole test set by

00:18:50.176 --> 00:18:52.016
calling model.predict and

00:18:52.016 --> 00:18:54.196
providing that test SFrame.

00:18:54.396 --> 00:18:55.626
And we'll get a batch prediction

00:18:55.626 --> 00:18:56.546
for the whole SFrame.

00:18:57.096 --> 00:19:00.656
And that'll just take a few

00:19:00.656 --> 00:19:01.136
seconds.

00:19:01.996 --> 00:19:04.306
And then we're going to inspect.

00:19:04.516 --> 00:19:05.556
I'm just going to pick a random

00:19:05.556 --> 00:19:06.346
prediction here.

00:19:06.626 --> 00:19:08.856
Let's say index two.

00:19:09.606 --> 00:19:11.676
Here we can see the JSON object

00:19:11.676 --> 00:19:13.346
that was predicted in just the

00:19:13.346 --> 00:19:14.966
same format that the training

00:19:14.966 --> 00:19:16.106
data is provided in.

00:19:16.446 --> 00:19:18.316
So here we have coordinates,

00:19:18.486 --> 00:19:19.776
height, width, x and y.

00:19:20.056 --> 00:19:21.196
And a label, banana.

00:19:21.796 --> 00:19:23.116
And we get a confidence score

00:19:23.116 --> 00:19:23.816
from the model.

00:19:23.966 --> 00:19:25.876
In this case about .87.

00:19:26.886 --> 00:19:28.466
This is a little bit hard for me

00:19:28.466 --> 00:19:29.976
as a human to interpret though.

00:19:30.436 --> 00:19:32.516
I can't really tell if this

00:19:32.516 --> 00:19:33.786
image is really supposed to be a

00:19:33.786 --> 00:19:35.446
banana or whether these

00:19:35.446 --> 00:19:36.866
coordinates are where the banana

00:19:36.866 --> 00:19:38.526
would appear in that image.

00:19:39.686 --> 00:19:41.526
Turi Create produces a function

00:19:41.706 --> 00:19:42.996
to take the predicted bounding

00:19:42.996 --> 00:19:44.476
boxes or the ground-truth

00:19:44.476 --> 00:19:46.036
bounding boxes and draw them

00:19:46.066 --> 00:19:47.096
right onto the images.

00:19:47.576 --> 00:19:48.836
So let's go and do that.

00:19:49.516 --> 00:19:50.976
I'm going to create a new column

00:19:51.046 --> 00:19:52.846
in my test SFrame called

00:19:52.906 --> 00:19:53.856
predicted image.

00:19:54.936 --> 00:19:56.926
And I'm going to assign it the

00:19:56.926 --> 00:19:58.906
output of the object detector

00:19:58.906 --> 00:20:00.406
utility called draw bounding

00:20:00.406 --> 00:20:00.896
boxes.

00:20:01.756 --> 00:20:03.736
And I'm going to pass into draw

00:20:03.736 --> 00:20:06.536
bounding boxes that test image

00:20:06.536 --> 00:20:06.946
column.

00:20:07.016 --> 00:20:09.176
So that's the image itself and

00:20:09.176 --> 00:20:11.616
then I'm also going to pass the

00:20:11.616 --> 00:20:13.226
predictions that I just got from

00:20:13.226 --> 00:20:13.626
the model.

00:20:13.766 --> 00:20:15.616
That's going to draw those

00:20:15.656 --> 00:20:17.316
predicted bounding boxes onto

00:20:17.316 --> 00:20:18.126
each image.

00:20:18.656 --> 00:20:19.996
Now let's take a look at that

00:20:19.996 --> 00:20:21.286
number two prediction again.

00:20:21.566 --> 00:20:23.096
This time in image form.

00:20:24.676 --> 00:20:25.586
So I can say

00:20:25.586 --> 00:20:28.396
testpredictedimage2.show.

00:20:28.836 --> 00:20:30.296
And it will render right here in

00:20:30.296 --> 00:20:30.786
the notebook.

00:20:31.516 --> 00:20:38.016
[ Applause ]

00:20:38.516 --> 00:20:39.946
And this is great as a spot

00:20:39.946 --> 00:20:41.596
check because at least for one

00:20:41.596 --> 00:20:42.396
picture, we know that the

00:20:42.396 --> 00:20:43.146
model's working.

00:20:43.616 --> 00:20:44.706
But this doesn't tell us if

00:20:44.706 --> 00:20:45.996
it'll work for say the next

00:20:45.996 --> 00:20:47.786
50,000 images that we pass in.

00:20:48.636 --> 00:20:49.986
So for that, we're going to

00:20:49.986 --> 00:20:50.916
evaluate the model

00:20:50.976 --> 00:20:51.846
quantitatively.

00:20:52.446 --> 00:20:53.966
And I'm going to start a new

00:20:53.966 --> 00:20:55.106
section here in the notebook

00:20:55.106 --> 00:20:56.326
called evaluate the model.

00:20:56.426 --> 00:20:58.286
And what we're going to do is

00:20:58.286 --> 00:21:01.226
call model.evaluate and once

00:21:01.226 --> 00:21:02.436
again, I'm going to pass in just

00:21:02.436 --> 00:21:04.186
that whole test data set.

00:21:05.936 --> 00:21:08.096
Here the evaluation function is

00:21:08.096 --> 00:21:09.436
going to run the metric that

00:21:09.436 --> 00:21:11.526
Aaron described, testing whether

00:21:11.526 --> 00:21:12.546
the bounding boxes are

00:21:12.546 --> 00:21:14.556
overlapping at least 50% and

00:21:14.556 --> 00:21:15.586
have a correct label.

00:21:15.586 --> 00:21:17.226
And it's going to give us that

00:21:17.226 --> 00:21:18.756
result across each of the six

00:21:18.756 --> 00:21:19.926
classes that we trained on.

00:21:20.516 --> 00:21:22.036
So here we can see that our

00:21:22.356 --> 00:21:24.096
overlapping bounding boxes with

00:21:24.096 --> 00:21:25.636
the correct label are happening

00:21:25.736 --> 00:21:27.696
about 80% of the time for bagel.

00:21:28.106 --> 00:21:29.946
About 67% of the time for

00:21:29.946 --> 00:21:30.416
banana.

00:21:30.706 --> 00:21:31.276
And so on.

00:21:32.456 --> 00:21:34.016
That's pretty good, so I think

00:21:34.096 --> 00:21:35.616
let's, let's see if this model's

00:21:35.616 --> 00:21:36.966
actually going to work in a real

00:21:36.966 --> 00:21:37.226
app.

00:21:37.866 --> 00:21:39.526
I'm going to go ahead and call

00:21:39.806 --> 00:21:42.366
exportcoreml to create a Core ML

00:21:42.366 --> 00:21:43.806
model from the model we just

00:21:43.806 --> 00:21:44.076
trained.

00:21:44.226 --> 00:21:45.666
And I'm going to call it

00:21:45.666 --> 00:21:47.536
breakfastmodel.mlmodel.

00:21:47.826 --> 00:21:49.036
And then as soon as that's done

00:21:49.036 --> 00:21:50.546
training, I'm going to go ahead

00:21:50.546 --> 00:21:51.656
and open it in finder.

00:21:52.236 --> 00:21:55.206
Or sorry. As soon as that's done

00:21:55.206 --> 00:21:56.000
exporting.

00:22:00.046 --> 00:22:01.686
So here in finder, I've got my

00:22:01.686 --> 00:22:03.316
breakfastmodel.mlmodel.

00:22:03.316 --> 00:22:05.636
And when I open it in Xcode, I

00:22:05.636 --> 00:22:07.106
can see that it looks just like

00:22:07.106 --> 00:22:08.306
any Core ML model.

00:22:08.896 --> 00:22:12.176
It takes an input image, and as

00:22:12.176 --> 00:22:14.526
output we get confidence and

00:22:14.526 --> 00:22:15.206
coordinates.

00:22:15.616 --> 00:22:16.706
And that's going to tell us the

00:22:16.706 --> 00:22:18.336
predicted bounding box and label

00:22:18.336 --> 00:22:19.436
for the image that we have.

00:22:20.376 --> 00:22:22.206
Now let's switch over to the

00:22:22.246 --> 00:22:23.646
iPhone app where we're going to

00:22:23.646 --> 00:22:24.616
consume this model.

00:22:25.186 --> 00:22:30.306
So here on my iPhone, I've got

00:22:30.306 --> 00:22:31.716
an app called Food Predictor.

00:22:32.356 --> 00:22:33.336
And this is going to use the

00:22:33.336 --> 00:22:34.456
model that we just trained.

00:22:35.356 --> 00:22:36.646
Here I'm going to choose from

00:22:36.646 --> 00:22:37.096
photos.

00:22:37.416 --> 00:22:39.026
And I've got a picture of this

00:22:39.026 --> 00:22:40.036
morning's breakfast.

00:22:40.546 --> 00:22:41.506
This is a pretty typical

00:22:41.506 --> 00:22:42.916
breakfast for me: coffee and a

00:22:42.916 --> 00:22:43.326
banana.

00:22:43.796 --> 00:22:45.546
Well, often I skip the banana.

00:22:46.316 --> 00:22:48.856
But suppose I ate a banana this

00:22:48.856 --> 00:22:49.346
morning.

00:22:50.456 --> 00:22:53.316
We can just tap right on the

00:22:53.316 --> 00:22:53.796
image.

00:22:53.796 --> 00:22:54.976
And because we know the bounding

00:22:54.976 --> 00:22:57.196
box, we can identify the object

00:22:57.196 --> 00:22:58.386
within that bounding box.

00:22:58.386 --> 00:22:59.716
And here we see the model tells

00:22:59.716 --> 00:23:02.296
us this is a banana, and this is

00:23:02.296 --> 00:23:02.976
a cup of coffee.

00:23:03.516 --> 00:23:09.500
[ Applause ]

00:23:16.136 --> 00:23:17.886
So let's recap what we just saw.

00:23:19.886 --> 00:23:21.756
First, we loaded images and

00:23:21.756 --> 00:23:23.896
annotations into SFrame format

00:23:24.146 --> 00:23:25.626
and joined them together with a

00:23:25.626 --> 00:23:26.556
simple function call.

00:23:27.296 --> 00:23:28.976
We interactively explored that

00:23:28.976 --> 00:23:30.786
data using the explore method.

00:23:31.826 --> 00:23:33.616
We created a model just with a

00:23:33.616 --> 00:23:35.606
simple high-level API< passing

00:23:35.606 --> 00:23:37.286
in that data object containing

00:23:37.286 --> 00:23:38.756
both the images and the bounding

00:23:38.756 --> 00:23:39.936
boxes and labels.

00:23:40.906 --> 00:23:42.676
We then evaluated that model

00:23:42.836 --> 00:23:43.956
both qualitatively,

00:23:44.026 --> 00:23:45.596
spot-checking the output as a

00:23:45.596 --> 00:23:46.176
human would.

00:23:46.556 --> 00:23:48.566
And quantitatively, asking for a

00:23:48.566 --> 00:23:50.486
specific metric that applies to

00:23:50.486 --> 00:23:51.526
the task that we're doing.

00:23:52.326 --> 00:23:54.206
Then we exported that model to

00:23:54.206 --> 00:23:56.886
Core ML format for use in an

00:23:58.366 --> 00:23:58.446
app.

00:23:58.726 --> 00:24:00.306
Next, I'd like to switch gears

00:24:00.576 --> 00:24:01.976
and talk about some exciting new

00:24:01.976 --> 00:24:04.836
features in Turi Create 5.0.

00:24:06.776 --> 00:24:09.806
Turi Create 5.0 has a new task

00:24:10.076 --> 00:24:11.186
called style transfer.

00:24:12.556 --> 00:24:13.716
We have major performance

00:24:13.716 --> 00:24:16.126
improvements from native GPU

00:24:16.126 --> 00:24:18.166
acceleration on your Mac.

00:24:19.016 --> 00:24:20.626
And we have new deployment

00:24:20.626 --> 00:24:22.516
options including recommender

00:24:22.516 --> 00:24:24.626
models for personalization and

00:24:24.676 --> 00:24:25.956
vision feature print-powered

00:24:25.956 --> 00:24:27.466
models so that you can reduce

00:24:27.466 --> 00:24:28.386
the size of your app.

00:24:28.676 --> 00:24:29.956
Taking advantage of models that

00:24:29.956 --> 00:24:30.986
are already in the operating

00:24:30.986 --> 00:24:31.386
system.

00:24:31.906 --> 00:24:34.696
Let's talk a little bit more

00:24:34.696 --> 00:24:36.176
about that style transfer task.

00:24:37.116 --> 00:24:39.186
Imagine we've got some style

00:24:39.186 --> 00:24:41.296
images and these are really cool

00:24:41.296 --> 00:24:43.836
looking recognizable stylistic

00:24:43.836 --> 00:24:44.376
images.

00:24:45.016 --> 00:24:46.826
Here we've got sort of a light

00:24:46.826 --> 00:24:48.156
honeycomb pattern and a very

00:24:48.156 --> 00:24:49.426
colorful flower pattern.

00:24:49.666 --> 00:24:51.406
And we want apply those as

00:24:51.406 --> 00:24:53.416
filters to our own images that

00:24:53.416 --> 00:24:54.246
we take with a camera.

00:24:54.836 --> 00:24:57.846
We've got a dog photo here and

00:24:57.896 --> 00:24:59.186
what it would look like to apply

00:24:59.186 --> 00:25:01.496
those styles to that dog is

00:25:01.496 --> 00:25:02.236
something like that.

00:25:02.586 --> 00:25:05.006
And with a style transfer model,

00:25:05.196 --> 00:25:06.956
we can take the same styles and

00:25:06.956 --> 00:25:08.296
apply them to more photos.

00:25:08.646 --> 00:25:10.246
Let's say a cat and another dog.

00:25:10.916 --> 00:25:12.046
And that's the sort of effect we

00:25:12.046 --> 00:25:13.000
would get.

00:25:16.046 --> 00:25:17.566
Here's an example of an app that

00:25:17.566 --> 00:25:19.646
uses style transfer for filters

00:25:19.816 --> 00:25:21.216
on photos that a user would

00:25:21.846 --> 00:25:21.946
take.

00:25:24.556 --> 00:25:26.526
The code to create the style

00:25:26.526 --> 00:25:28.386
transfer model follows the same

00:25:28.516 --> 00:25:30.466
five-step recipe as any other

00:25:30.466 --> 00:25:32.046
high-level task in Turi Create.

00:25:32.296 --> 00:25:33.956
So you can start by importing

00:25:33.956 --> 00:25:36.076
Turi Create, loading data into

00:25:36.076 --> 00:25:38.166
the SFrame format, creating the

00:25:38.166 --> 00:25:39.906
model with a simple high-level

00:25:39.906 --> 00:25:40.176
API.

00:25:41.326 --> 00:25:42.906
Then we make predictions, in

00:25:42.906 --> 00:25:44.166
this case with a function called

00:25:44.166 --> 00:25:46.186
stylize to take an image and

00:25:46.186 --> 00:25:47.536
apply that style filter.

00:25:48.166 --> 00:25:49.746
Finally, we can export it for

00:25:49.746 --> 00:25:51.576
deployment into Core ML format,

00:25:51.576 --> 00:25:52.726
just like any other model in

00:25:52.726 --> 00:25:53.000
Turi Create.

00:25:56.266 --> 00:25:57.506
So let's take a look at another

00:25:57.506 --> 00:25:57.926
demo.

00:25:58.146 --> 00:26:00.106
This time, we're going to build

00:26:00.106 --> 00:26:02.000
a style-transfer model.

00:26:14.476 --> 00:26:15.926
So switching back over to that

00:26:15.926 --> 00:26:17.196
Jupyter notebook environment.

00:26:17.546 --> 00:26:19.386
I'm going to start once again by

00:26:19.386 --> 00:26:23.476
importing Turi Create.

00:26:23.936 --> 00:26:25.000
As TC.

00:26:29.056 --> 00:26:30.556
Then, I'm going to load up two

00:26:30.556 --> 00:26:32.836
SFrames, each containing images.

00:26:33.276 --> 00:26:35.236
One, is the style images I'm

00:26:35.236 --> 00:26:36.766
going to call tc.loadimages, and

00:26:36.766 --> 00:26:37.766
I'm going to give it a directory

00:26:37.766 --> 00:26:38.416
name, styles.

00:26:39.106 --> 00:26:40.876
And then the other is content

00:26:40.876 --> 00:26:41.466
images.

00:26:42.956 --> 00:26:44.226
And the way that this works is

00:26:44.266 --> 00:26:46.106
the style images are the styles

00:26:46.106 --> 00:26:47.236
that you want to turn into

00:26:47.236 --> 00:26:48.376
filters you can apply.

00:26:48.376 --> 00:26:50.586
And the content images can be

00:26:50.686 --> 00:26:51.596
any images that are

00:26:51.596 --> 00:26:53.286
representative of the types of

00:26:53.286 --> 00:26:54.346
photograph that you would want

00:26:54.346 --> 00:26:55.836
to apply those filters to.

00:26:56.266 --> 00:26:57.596
So in this case, it's just a

00:26:57.596 --> 00:26:58.896
variety of photographs.

00:26:59.796 --> 00:27:01.776
We're going to load a folder

00:27:01.776 --> 00:27:03.546
called content into an SFrame

00:27:03.546 --> 00:27:04.146
for that one.

00:27:05.226 --> 00:27:06.786
And then we're ready to go ahead

00:27:06.786 --> 00:27:07.556
and train a model.

00:27:08.386 --> 00:27:10.276
So I'm going to say model equals

00:27:10.846 --> 00:27:13.366
tc.styletransfer.create.

00:27:13.786 --> 00:27:15.986
And I'm going to pass in style

00:27:16.226 --> 00:27:18.886
and content and that's all we

00:27:18.886 --> 00:27:19.116
need.

00:27:19.486 --> 00:27:21.096
But that's going to take a bit

00:27:21.096 --> 00:27:22.446
too long to train for today's

00:27:22.446 --> 00:27:22.806
demo.

00:27:23.276 --> 00:27:24.796
So once again, I'm going to do

00:27:24.796 --> 00:27:25.746
it like a cooking show, and

00:27:25.746 --> 00:27:26.596
we're going to load up one that

00:27:26.596 --> 00:27:27.766
we've had in the oven already.

00:27:28.526 --> 00:27:29.936
I'm going to say model equals

00:27:29.936 --> 00:27:32.426
tc.loadmodel and I'm going to

00:27:32.426 --> 00:27:34.576
load up my already trained style

00:27:34.576 --> 00:27:35.296
transfer model.

00:27:35.826 --> 00:27:38.546
Let's take a look at some of

00:27:38.546 --> 00:27:40.026
these style images to see what

00:27:40.026 --> 00:27:41.306
we should expect this model to

00:27:41.306 --> 00:27:41.876
produce.

00:27:42.876 --> 00:27:45.516
We have a style image col-- we

00:27:45.516 --> 00:27:46.476
have an image column in our

00:27:46.476 --> 00:27:47.336
style SFrame.

00:27:47.746 --> 00:27:49.026
And let's take a look at just

00:27:49.026 --> 00:27:50.336
style number three and see what

00:27:50.336 --> 00:27:50.946
that looks like.

00:27:51.796 --> 00:27:53.486
It-- sort of like a pile of

00:27:53.486 --> 00:27:54.056
firewood.

00:27:54.416 --> 00:27:57.036
And this is pretty stylistic.

00:27:57.266 --> 00:27:57.966
I think this would be

00:27:57.966 --> 00:27:59.626
recognizable if we were to apply

00:27:59.626 --> 00:28:01.326
it as a filter to another image.

00:28:02.676 --> 00:28:04.666
Now let's take a look at some

00:28:04.666 --> 00:28:05.566
content images.

00:28:06.016 --> 00:28:07.616
I'm going to load up a test data

00:28:07.616 --> 00:28:07.916
set.

00:28:08.126 --> 00:28:10.566
And once again this is a data

00:28:10.566 --> 00:28:12.096
set that is representative of

00:28:12.156 --> 00:28:13.936
the types of images that users

00:28:13.936 --> 00:28:15.136
will have at runtime in your

00:28:15.136 --> 00:28:15.326
app.

00:28:15.776 --> 00:28:16.906
And the important thing is that

00:28:16.906 --> 00:28:18.606
the model never saw these at

00:28:18.606 --> 00:28:19.346
training time.

00:28:19.656 --> 00:28:21.366
So by evaluating with the test

00:28:21.366 --> 00:28:22.836
images, we'll know whether the

00:28:22.836 --> 00:28:24.786
model can generalize to users'

00:28:24.786 --> 00:28:25.096
data.

00:28:26.206 --> 00:28:28.636
I'm going to load up a test data

00:28:29.166 --> 00:28:30.496
set now.

00:28:30.606 --> 00:28:32.746
With tc.loadimages function once

00:28:32.746 --> 00:28:33.086
again.

00:28:33.656 --> 00:28:34.906
And we're going to call that

00:28:34.906 --> 00:28:36.006
folder test.

00:28:37.046 --> 00:28:38.406
And I'm going to pull out one

00:28:38.406 --> 00:28:39.696
image from the test data set

00:28:39.696 --> 00:28:40.736
called ample image.

00:28:41.216 --> 00:28:43.666
And I'm just going to take the

00:28:43.666 --> 00:28:44.576
first image there.

00:28:45.156 --> 00:28:48.016
And I'm going to call .show.

00:28:48.016 --> 00:28:51.446
So that we can we see what that

00:28:51.446 --> 00:28:52.526
image looks like without any

00:28:52.526 --> 00:28:53.256
filters applied.

00:28:54.016 --> 00:28:58.216
That's my cat, seven of nine.

00:28:59.046 --> 00:29:02.306
She always looks like that.

00:29:02.306 --> 00:29:04.546
And we're going to go ahead and

00:29:04.546 --> 00:29:06.096
stylize that image using the

00:29:06.096 --> 00:29:07.036
model that we just trained.

00:29:08.516 --> 00:29:10.526
So I'm going to say stylized

00:29:10.526 --> 00:29:13.236
image equals model.stylize.

00:29:13.956 --> 00:29:15.876
And in this case, the function

00:29:15.876 --> 00:29:17.486
is called stylize because the

00:29:17.486 --> 00:29:19.386
model is specific to the task of

00:29:19.386 --> 00:29:20.186
style transfer.

00:29:20.416 --> 00:29:22.806
And we're going to pass in that

00:29:22.806 --> 00:29:23.606
sample image.

00:29:23.956 --> 00:29:25.416
And I'm going to say style

00:29:25.416 --> 00:29:27.206
equals three because that's the

00:29:27.206 --> 00:29:28.956
style that we picked earlier

00:29:28.956 --> 00:29:30.146
that looks like firewood here.

00:29:32.116 --> 00:29:33.956
So let's see what that stylized

00:29:33.956 --> 00:29:34.656
image looks like.

00:29:35.196 --> 00:29:38.646
I can call .show on that, and

00:29:38.646 --> 00:29:39.976
here is my cat looking like a

00:29:39.976 --> 00:29:40.746
pile of firewood.

00:29:41.516 --> 00:29:46.426
[ Applause ]

00:29:46.926 --> 00:29:48.376
Let's make sure this works on

00:29:48.376 --> 00:29:49.256
other styles, too.

00:29:49.946 --> 00:29:52.336
I'm going to go ahead and make a

00:29:52.336 --> 00:29:58.496
stylized image out of that

00:29:58.496 --> 00:29:59.256
sample image.

00:29:59.576 --> 00:30:02.276
And I'm going to specify a style

00:30:02.276 --> 00:30:02.966
equals seven.

00:30:03.556 --> 00:30:05.986
And then let's see what that

00:30:05.986 --> 00:30:07.000
looks like.

00:30:13.056 --> 00:30:13.896
That looks pretty good.

00:30:13.896 --> 00:30:15.236
I wonder what the style was that

00:30:15.236 --> 00:30:16.236
we just applied to that.

00:30:16.716 --> 00:30:18.496
Let's take a look at style

00:30:20.826 --> 00:30:21.000
images.

00:30:25.306 --> 00:30:26.516
Style image seven.

00:30:27.046 --> 00:30:30.066
And once again we can just call

00:30:30.066 --> 00:30:31.436
.show to see what that style

00:30:31.436 --> 00:30:33.496
image looks like and yeah, that

00:30:33.496 --> 00:30:34.736
looks like the filter that we

00:30:34.736 --> 00:30:35.746
just applied to my cat.

00:30:36.426 --> 00:30:38.696
Now that we've got a good style

00:30:38.696 --> 00:30:40.886
transfer model, we can just call

00:30:41.216 --> 00:30:43.716
model.exportcoreml exactly the

00:30:43.716 --> 00:30:45.206
same as any other model, and

00:30:45.206 --> 00:30:47.000
save it into Core ML format.

00:30:52.296 --> 00:30:54.126
Now, let's switch over to the

00:30:54.126 --> 00:30:55.436
iPhone where we have a style

00:30:55.436 --> 00:30:57.306
transfer app ready to apply the

00:30:57.306 --> 00:30:58.306
filters in this model.

00:30:58.886 --> 00:31:03.446
So here I've got my iPhone once

00:31:03.446 --> 00:31:03.726
again.

00:31:03.726 --> 00:31:05.426
And I have an app called style

00:31:05.426 --> 00:31:05.936
transfer.

00:31:06.696 --> 00:31:08.066
I'm going to choose a photo from

00:31:08.066 --> 00:31:09.946
my photo library to apply these

00:31:09.946 --> 00:31:11.256
styles to.

00:31:11.796 --> 00:31:13.846
These are my dogs.

00:31:16.136 --> 00:31:19.696
This is Ryker and we're going to

00:31:19.696 --> 00:31:20.656
see what styles we have

00:31:20.656 --> 00:31:21.696
available in this app.

00:31:22.206 --> 00:31:23.706
We can scroll through all of the

00:31:23.706 --> 00:31:26.126
styles here and what's important

00:31:26.126 --> 00:31:27.766
to note is that a single style

00:31:27.766 --> 00:31:29.596
transfer model was trained on

00:31:29.596 --> 00:31:30.636
all of these files.

00:31:30.976 --> 00:31:32.836
And one model can include any

00:31:32.836 --> 00:31:33.676
number of styles.

00:31:34.126 --> 00:31:35.636
So to have multiple filters, you

00:31:35.636 --> 00:31:37.116
don't need to greatly increase

00:31:37.166 --> 00:31:37.976
the size of your app.

00:31:39.156 --> 00:31:40.376
Let's see what those styles look

00:31:40.376 --> 00:31:43.036
like applied to Ryker.

00:31:43.716 --> 00:31:46.000
Pretty cool.

00:31:52.646 --> 00:31:52.976
So--

00:31:53.516 --> 00:31:58.316
[ Applause ]

00:31:58.816 --> 00:32:01.266
So to recap what we just saw, we

00:32:01.266 --> 00:32:02.886
loaded images into SFrame

00:32:02.886 --> 00:32:03.336
format.

00:32:03.646 --> 00:32:05.576
This time style and content

00:32:05.576 --> 00:32:07.346
images into two SFrames.

00:32:07.836 --> 00:32:09.656
We created a model using a

00:32:09.656 --> 00:32:10.966
high-level API for style

00:32:10.966 --> 00:32:12.816
transfer that operates directly

00:32:12.946 --> 00:32:14.576
on a set of style images and a

00:32:14.576 --> 00:32:15.646
set of content images.

00:32:16.436 --> 00:32:18.956
We then stylize images to check

00:32:19.256 --> 00:32:20.546
whether the model is performing

00:32:20.546 --> 00:32:20.836
well.

00:32:21.356 --> 00:32:22.876
We visualized those predictions

00:32:22.876 --> 00:32:23.706
in Turi Create.

00:32:24.226 --> 00:32:25.686
And finally we exported the

00:32:25.686 --> 00:32:27.566
model in Core ML format for use

00:32:27.566 --> 00:32:29.996
in our app.

00:32:30.636 --> 00:32:31.566
Switching gears a bit.

00:32:31.616 --> 00:32:32.656
I want to talk about some other

00:32:32.656 --> 00:32:34.336
features in Turi Create 5.0.

00:32:35.066 --> 00:32:37.186
We now have Mac GPU acceleration

00:32:37.536 --> 00:32:39.626
offering up to a 12x performance

00:32:39.626 --> 00:32:40.726
increase in image

00:32:40.726 --> 00:32:41.586
classification.

00:32:41.756 --> 00:32:43.966
And 9x in object detection, and

00:32:43.966 --> 00:32:45.226
that's on an iMac Pro.

00:32:46.516 --> 00:32:50.586
[ Applause ]

00:32:51.086 --> 00:32:53.096
We have a new task available for

00:32:53.096 --> 00:32:54.616
export into Core ML format.

00:32:54.876 --> 00:32:55.776
Personalization.

00:32:56.466 --> 00:32:58.096
The task here is to recommend

00:32:58.096 --> 00:33:00.496
items for users based on user's

00:33:00.496 --> 00:33:01.686
historical preferences.

00:33:02.896 --> 00:33:04.636
This type of model is deployed

00:33:04.636 --> 00:33:06.506
using Core ML's new custom model

00:33:06.506 --> 00:33:08.586
support that's available on

00:33:08.586 --> 00:33:11.026
macOS Mojave and on iOS 12.

00:33:11.686 --> 00:33:12.966
This has been a top community

00:33:12.966 --> 00:33:14.576
feature request since we open

00:33:14.576 --> 00:33:15.546
sourced Turi Create.

00:33:15.806 --> 00:33:16.956
So I'm really excited to bring

00:33:16.956 --> 00:33:17.576
it to you today.

00:33:18.516 --> 00:33:23.546
[ Applause ]

00:33:24.046 --> 00:33:25.846
The recommender model in Core ML

00:33:26.076 --> 00:33:27.376
looks just like any other Core

00:33:27.376 --> 00:33:27.956
ML model.

00:33:28.266 --> 00:33:29.656
But what's worth noting is

00:33:29.656 --> 00:33:30.876
there's a section at the bottom

00:33:30.876 --> 00:33:32.496
here called Dependencies.

00:33:33.046 --> 00:33:34.416
And in this section, you can see

00:33:34.416 --> 00:33:36.156
that this model uses a custom

00:33:36.156 --> 00:33:37.986
model and that model is called

00:33:37.986 --> 00:33:39.006
TC recommender.

00:33:39.506 --> 00:33:40.886
And this is just Turi Create

00:33:41.036 --> 00:33:42.056
providing support for

00:33:42.056 --> 00:33:44.206
recommenders in Core ML through

00:33:44.206 --> 00:33:45.346
that custom model API.

00:33:46.016 --> 00:33:49.476
Using that model in Core ML look

00:33:49.536 --> 00:33:50.916
very similar to any other Core

00:33:50.916 --> 00:33:51.776
ML model as well.

00:33:52.316 --> 00:33:53.506
You can just instantiate the

00:33:53.506 --> 00:33:55.696
model, create your input.

00:33:55.776 --> 00:33:57.696
So in this case, we've got that

00:33:57.696 --> 00:33:59.046
avatar creation app.

00:33:59.386 --> 00:34:01.066
And a user might have picked a

00:34:01.066 --> 00:34:02.626
brown beard and a brown

00:34:02.626 --> 00:34:04.276
handlebar moustache and brown

00:34:04.276 --> 00:34:05.966
long hair for their avatar.

00:34:06.346 --> 00:34:07.956
And we can make predictions from

00:34:07.956 --> 00:34:08.426
the model.

00:34:08.626 --> 00:34:10.246
By providing those interactions

00:34:10.246 --> 00:34:10.886
as input.

00:34:11.315 --> 00:34:13.416
And where we say k10 means we'll

00:34:13.416 --> 00:34:14.996
get the top ten predictions

00:34:15.346 --> 00:34:16.426
given those inputs.

00:34:17.045 --> 00:34:20.686
So to recap what we've learned

00:34:20.686 --> 00:34:21.116
today.

00:34:22.286 --> 00:34:24.255
Turi Create allows you to create

00:34:24.255 --> 00:34:26.196
Core ML models to power

00:34:26.196 --> 00:34:27.755
intelligent features in your

00:34:27.985 --> 00:34:28.286
apps.

00:34:28.606 --> 00:34:30.775
It uses a simple five-step

00:34:30.775 --> 00:34:33.235
recipe starting with identifying

00:34:33.235 --> 00:34:34.275
the task that you're doing.

00:34:34.485 --> 00:34:35.735
And mapping it to a machine

00:34:35.735 --> 00:34:36.496
learning task.

00:34:37.025 --> 00:34:39.045
Gathering and annotating data

00:34:39.226 --> 00:34:41.126
for use in training that model.

00:34:42.146 --> 00:34:43.946
Training the model itself using

00:34:43.946 --> 00:34:45.246
a simple, high-level API

00:34:45.755 --> 00:34:47.096
specific to the task that you're

00:34:47.096 --> 00:34:47.505
doing.

00:34:48.466 --> 00:34:50.235
Evaluating that model in Turi

00:34:50.235 --> 00:34:51.996
Create both qualitatively and

00:34:51.996 --> 00:34:52.826
quantitatively.

00:34:53.366 --> 00:34:55.755
And finally, deploying in Core

00:34:55.755 --> 00:34:56.406
ML format.

00:34:58.936 --> 00:35:01.196
That five-step recipe maps to

00:35:01.196 --> 00:35:03.266
code starting with import Turi

00:35:03.266 --> 00:35:03.646
Create.

00:35:04.406 --> 00:35:05.726
You can load data into the

00:35:05.726 --> 00:35:06.526
SFrame format.

00:35:07.026 --> 00:35:08.566
Create a model using that

00:35:08.596 --> 00:35:10.026
task-specific API.

00:35:11.126 --> 00:35:12.726
Evaluate the model with an

00:35:12.726 --> 00:35:14.076
evaluate function that's once

00:35:14.076 --> 00:35:15.576
again specific to the task that

00:35:15.576 --> 00:35:16.086
you're doing.

00:35:16.646 --> 00:35:18.096
And export for deployment,

00:35:18.356 --> 00:35:19.666
calling the export Core ML

00:35:19.666 --> 00:35:20.066
function.

00:35:20.536 --> 00:35:23.576
Turi Create supports a broad

00:35:23.576 --> 00:35:24.736
variety of machine learning

00:35:24.736 --> 00:35:25.296
tasks.

00:35:25.736 --> 00:35:27.196
Ranging from high-level tasks

00:35:27.196 --> 00:35:29.286
like image classification and

00:35:29.286 --> 00:35:31.296
text classification, all the way

00:35:31.296 --> 00:35:32.896
to low-level machine learning

00:35:32.896 --> 00:35:33.436
essentials.

00:35:33.436 --> 00:35:34.186
Like regression and

00:35:34.186 --> 00:35:35.976
classification on any type of

00:35:35.976 --> 00:35:36.246
data.

00:35:38.006 --> 00:35:39.806
And using the resulting models,

00:35:40.106 --> 00:35:41.266
you can power intelligent

00:35:41.266 --> 00:35:42.986
features in your apps like

00:35:42.986 --> 00:35:45.036
object detection or style

00:35:45.036 --> 00:35:47.196
transfer for use as a filter.

00:35:48.216 --> 00:35:50.306
For more information, please see

00:35:50.306 --> 00:35:52.606
the Developer.Apple.com session

00:35:52.806 --> 00:35:53.306
URL.

00:35:53.716 --> 00:35:55.316
And please come to our labs.

00:35:55.316 --> 00:35:56.736
We've got a lab this afternoon

00:35:56.886 --> 00:35:58.056
and Friday afternoon.

00:35:58.306 --> 00:35:59.726
And we welcome your feedback.

00:36:00.096 --> 00:36:01.276
We're happy to answer any

00:36:01.276 --> 00:36:02.126
questions you have.

00:36:02.386 --> 00:36:04.136
And we'll have all of the demos

00:36:04.136 --> 00:36:05.936
we showed today available to

00:36:05.936 --> 00:36:06.376
explore.

00:36:07.186 --> 00:36:07.506
Thank you.

00:36:08.516 --> 00:36:11.500
[ Applause ]