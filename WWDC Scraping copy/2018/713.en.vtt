WEBVTT

00:00:07.016 --> 00:00:15.500
[ Music ]

00:00:20.516 --> 00:00:25.636
[ Applause ]

00:00:26.136 --> 00:00:26.966
>> Hello and good afternoon

00:00:26.966 --> 00:00:27.406
everyone.

00:00:27.806 --> 00:00:29.096
Welcome to our session on

00:00:29.096 --> 00:00:30.336
natural language processing.

00:00:30.486 --> 00:00:32.226
I'm delighted to see so many of

00:00:32.226 --> 00:00:33.836
you here today, and I'm really

00:00:33.836 --> 00:00:35.356
excited to tell you about some

00:00:35.356 --> 00:00:36.896
of the new and cool features

00:00:37.126 --> 00:00:38.206
we've been working in the NLP

00:00:38.206 --> 00:00:39.526
space for you.

00:00:40.206 --> 00:00:42.066
I'm Vivek, and I'll be jointly

00:00:42.066 --> 00:00:43.526
presenting this session with my

00:00:43.526 --> 00:00:44.676
colleague, Doug Davidson.

00:00:45.176 --> 00:00:47.756
Let's get started.

00:00:47.756 --> 00:00:49.646
Last year, we placed your app

00:00:49.646 --> 00:00:52.166
center stage and told you how

00:00:52.166 --> 00:00:53.336
you could harness the power of

00:00:53.416 --> 00:00:56.426
NLP to make your apps smarter

00:00:56.426 --> 00:00:57.186
and more intelligent.

00:00:57.586 --> 00:00:59.926
We did this by walking you

00:01:00.236 --> 00:01:02.206
through the NLP APIs available

00:01:02.506 --> 00:01:03.736
in NSLinguisticTagger.

00:01:04.976 --> 00:01:06.706
NSLinguisticTagger, as most of

00:01:06.706 --> 00:01:07.906
you are familiar with or have

00:01:07.906 --> 00:01:10.426
used at some point, is a class

00:01:10.426 --> 00:01:12.266
and foundation that provides the

00:01:12.336 --> 00:01:13.636
fundamental building blocks for

00:01:13.676 --> 00:01:13.916
NLP.

00:01:14.676 --> 00:01:15.646
Everything from language

00:01:15.646 --> 00:01:17.376
identification to organization,

00:01:17.376 --> 00:01:19.306
part of speech tagging, and so

00:01:19.906 --> 00:01:19.973
on.

00:01:20.406 --> 00:01:21.426
We achieve this in

00:01:21.476 --> 00:01:23.546
NSLinguisticTagger by seamlessly

00:01:23.546 --> 00:01:25.346
blending linguistics and machine

00:01:25.346 --> 00:01:26.386
learning behind the scenes.

00:01:26.736 --> 00:01:28.996
So you, as a developer, can just

00:01:28.996 --> 00:01:30.856
focus on using these APIs and

00:01:30.856 --> 00:01:33.206
focus on your task.

00:01:33.206 --> 00:01:34.066
All that's great.

00:01:34.586 --> 00:01:36.016
So what's new in NLP for this

00:01:36.016 --> 00:01:36.216
year?

00:01:36.916 --> 00:01:38.346
Well, we are delighted to

00:01:38.346 --> 00:01:39.356
announce that we have a

00:01:39.356 --> 00:01:40.816
brand-new framework for NLP

00:01:40.816 --> 00:01:42.446
called Natural Language.

00:01:43.216 --> 00:01:44.736
Natural Language is now going to

00:01:44.736 --> 00:01:47.116
be a one-stop shop for doing all

00:01:47.116 --> 00:01:49.536
things NLP on device across all

00:01:49.536 --> 00:01:50.486
Apple platforms.

00:01:51.176 --> 00:01:52.856
Natural Language has some really

00:01:52.856 --> 00:01:54.496
cool features, and let me talk

00:01:54.496 --> 00:01:55.396
about each of those.

00:01:55.846 --> 00:01:58.846
First, it has a completely

00:01:58.846 --> 00:02:01.476
redesigned API surface, so it

00:02:01.476 --> 00:02:02.936
supports all the functionalities

00:02:02.936 --> 00:02:04.496
that NSLinguisticTagger used to

00:02:04.496 --> 00:02:07.206
and still does but with really,

00:02:07.296 --> 00:02:08.376
really Swift APIs.

00:02:09.326 --> 00:02:10.446
But that's not it.

00:02:11.026 --> 00:02:12.746
We now have support for custom

00:02:12.866 --> 00:02:13.716
NLP models.

00:02:14.056 --> 00:02:15.136
These are models that you can

00:02:15.136 --> 00:02:17.226
create using Create ML and

00:02:17.226 --> 00:02:18.856
deploy the model either using

00:02:18.856 --> 00:02:20.576
Code ML API or through Natural

00:02:20.576 --> 00:02:20.976
Language.

00:02:22.396 --> 00:02:23.716
Everything that we support in

00:02:23.716 --> 00:02:24.886
Natural Language, all of the

00:02:24.886 --> 00:02:26.956
machine learning NLP is high

00:02:27.026 --> 00:02:27.566
performed.

00:02:27.776 --> 00:02:29.076
It is optimized for Apple

00:02:29.076 --> 00:02:30.586
hardware and also for model

00:02:30.586 --> 00:02:30.946
size.

00:02:32.366 --> 00:02:35.106
And finally, everything is

00:02:35.106 --> 00:02:35.966
completely private.

00:02:36.186 --> 00:02:37.566
All of the machine learning in

00:02:37.566 --> 00:02:39.326
NLP that is powered in Natural

00:02:39.326 --> 00:02:41.256
Language is done on device to

00:02:41.256 --> 00:02:42.486
protect user's privacy.

00:02:42.906 --> 00:02:44.626
This is the very same technology

00:02:44.626 --> 00:02:46.776
that we use at Apple to bring

00:02:46.776 --> 00:02:48.916
NLP on device for our own

00:02:48.916 --> 00:02:49.446
features.

00:02:50.306 --> 00:02:51.716
So let me talk about each of

00:02:51.716 --> 00:02:53.336
these features of Natural

00:02:53.336 --> 00:02:53.686
Language.

00:02:54.026 --> 00:02:55.756
Let's start with the Swift APIs.

00:02:56.286 --> 00:02:59.996
As I mentioned, Natural Language

00:02:59.996 --> 00:03:01.136
supports all the fundamental

00:03:01.136 --> 00:03:01.966
building blocks that

00:03:01.966 --> 00:03:03.866
NSLinguisticTagger does but with

00:03:04.176 --> 00:03:05.976
significantly better and easier

00:03:05.976 --> 00:03:07.516
to use APIs.

00:03:08.056 --> 00:03:09.726
In order to provide some of

00:03:09.726 --> 00:03:11.336
these APIs and go over them, I'm

00:03:11.336 --> 00:03:12.346
going to illustrate them with

00:03:12.346 --> 00:03:13.506
hypothetical apps.

00:03:14.066 --> 00:03:16.396
So the first app that we have

00:03:16.396 --> 00:03:18.356
here is an app that you wrote,

00:03:19.656 --> 00:03:20.976
and as part of the app, you

00:03:20.976 --> 00:03:22.656
enable a social messaging or

00:03:22.656 --> 00:03:23.936
peer-to-peer messaging feature.

00:03:24.426 --> 00:03:26.586
And an add-on feature in this

00:03:26.586 --> 00:03:28.586
app that you've created is the

00:03:28.586 --> 00:03:30.446
ability to show the right

00:03:30.446 --> 00:03:30.966
stickers.

00:03:31.526 --> 00:03:33.046
So based on the content of the

00:03:33.136 --> 00:03:34.936
message, which in this case is

00:03:34.936 --> 00:03:36.116
"It's getting late, I'm tired,

00:03:36.456 --> 00:03:37.216
we'll pick it up tomorrow

00:03:37.216 --> 00:03:38.076
morning, good night."

00:03:38.406 --> 00:03:39.866
Your app shows the appropriate

00:03:39.866 --> 00:03:40.116
sticker.

00:03:40.116 --> 00:03:41.706
You parsed this text, and you

00:03:41.706 --> 00:03:42.596
bring up the sticker.

00:03:42.796 --> 00:03:44.166
The user can attach it and send

00:03:44.166 --> 00:03:44.976
it as a response.

00:03:45.476 --> 00:03:46.286
So all of this is great.

00:03:46.286 --> 00:03:47.376
This app has been doing really

00:03:47.376 --> 00:03:47.626
well.

00:03:47.626 --> 00:03:48.426
You've been getting rave

00:03:48.426 --> 00:03:48.936
reviews.

00:03:49.926 --> 00:03:51.436
But you also get feedback that

00:03:51.436 --> 00:03:52.776
your app is not multilingual.

00:03:53.186 --> 00:03:55.266
So it so happens that users are

00:03:55.416 --> 00:03:56.426
bilingual these days.

00:03:56.426 --> 00:03:57.546
They tend to communicate in

00:03:57.546 --> 00:03:59.186
several different languages, and

00:03:59.186 --> 00:04:00.226
your app, when it gets the

00:04:00.226 --> 00:04:01.886
message in Chinese, simply

00:04:01.886 --> 00:04:03.886
doesn't know what to do with it.

00:04:04.086 --> 00:04:05.246
So how can we use natural

00:04:05.246 --> 00:04:06.346
language to overcome this

00:04:06.346 --> 00:04:06.756
problem?

00:04:06.926 --> 00:04:09.816
Well, we can do this with two

00:04:09.816 --> 00:04:11.266
simple calls to two different

00:04:11.266 --> 00:04:11.636
APIs.

00:04:12.216 --> 00:04:13.256
The first is language

00:04:13.256 --> 00:04:13.986
identification.

00:04:14.326 --> 00:04:16.106
With the new Natural Language

00:04:16.106 --> 00:04:17.396
framework, you start off by

00:04:17.456 --> 00:04:18.696
importing Natural Language.

00:04:19.836 --> 00:04:21.226
You create an instance of

00:04:21.226 --> 00:04:23.146
NLLanguageRecognizer class.

00:04:24.006 --> 00:04:25.456
You attach the string that you

00:04:25.456 --> 00:04:27.476
would like to process, and you

00:04:27.476 --> 00:04:28.676
simply call the dominant

00:04:28.676 --> 00:04:29.436
language API.

00:04:30.036 --> 00:04:32.256
Now this will return the single

00:04:32.256 --> 00:04:34.596
best hypothesis in terms of

00:04:34.596 --> 00:04:35.746
language for the string.

00:04:36.806 --> 00:04:38.036
So the output here is

00:04:38.036 --> 00:04:39.446
essentially simplified Chinese.

00:04:40.466 --> 00:04:41.856
Now in Natural Language, we also

00:04:41.856 --> 00:04:42.906
support a new API.

00:04:43.496 --> 00:04:44.766
There are instances where you

00:04:44.766 --> 00:04:46.046
would like to know the top-end

00:04:46.046 --> 00:04:47.506
hypothesis for a particular

00:04:47.506 --> 00:04:47.876
string.

00:04:48.146 --> 00:04:49.996
So you'd like to know what are

00:04:49.996 --> 00:04:51.396
the top languages along with

00:04:51.396 --> 00:04:52.796
their associated probabilities.

00:04:52.836 --> 00:04:54.776
So you can envision using this

00:04:54.776 --> 00:04:55.476
in several different

00:04:55.476 --> 00:04:56.906
applications where there's a lot

00:04:56.906 --> 00:04:58.636
of multilinguality, and you want

00:04:58.636 --> 00:05:00.066
that leeway in terms of what

00:05:00.066 --> 00:05:01.366
could be the top hypothesis.

00:05:02.126 --> 00:05:03.636
So you can do this with a new

00:05:03.636 --> 00:05:05.856
API called Language Hypotheses.

00:05:06.176 --> 00:05:07.336
You can specify the maximum

00:05:07.336 --> 00:05:08.306
number of languages that you

00:05:08.306 --> 00:05:09.866
want, and what you get back is

00:05:09.866 --> 00:05:11.126
an object with the top-end

00:05:11.126 --> 00:05:12.706
languages and their associated

00:05:12.706 --> 00:05:13.446
probabilities.

00:05:14.596 --> 00:05:15.836
Now in order to tokenize this

00:05:15.836 --> 00:05:17.816
Chinese text, you can again see

00:05:17.816 --> 00:05:19.186
the pattern is very similar.

00:05:20.066 --> 00:05:21.196
You again import Natural

00:05:21.196 --> 00:05:21.646
Language.

00:05:22.316 --> 00:05:23.616
You create an instance of the

00:05:23.616 --> 00:05:25.856
NLTokenizer, and in this

00:05:25.856 --> 00:05:27.576
particular instance, you specify

00:05:27.576 --> 00:05:28.856
the unit to be word because you

00:05:28.856 --> 00:05:30.126
want to tokenize the string into

00:05:30.126 --> 00:05:30.666
words.

00:05:31.176 --> 00:05:34.776
You attach the string, and you

00:05:34.776 --> 00:05:36.486
simply call the tokens method on

00:05:36.486 --> 00:05:38.006
the string, on the object.

00:05:39.006 --> 00:05:40.446
And what you get is an array of

00:05:40.516 --> 00:05:41.096
tokens here.

00:05:41.526 --> 00:05:43.296
Now with this array of tokens,

00:05:43.546 --> 00:05:44.896
you can look up the particular

00:05:45.136 --> 00:05:47.756
token here is goodnight, and lo

00:05:47.756 --> 00:05:48.676
and behold, you have

00:05:48.676 --> 00:05:50.256
multilingual support in your

00:05:50.716 --> 00:05:50.783
app.

00:05:51.026 --> 00:05:52.746
So your app can now support

00:05:52.746 --> 00:05:54.626
Chinese with simple calls to

00:05:54.626 --> 00:05:56.446
language identification and

00:05:56.636 --> 00:05:58.966
tokenization APIs.

00:05:59.026 --> 00:06:00.456
Now let's look at a different

00:06:00.456 --> 00:06:01.046
sort of an API.

00:06:01.046 --> 00:06:02.206
I mean language identification

00:06:02.206 --> 00:06:03.586
and tokenization are good, but

00:06:03.586 --> 00:06:05.406
we would also like to use auto

00:06:05.406 --> 00:06:06.636
speech tagging, named entity

00:06:06.636 --> 00:06:07.746
recognition, and so on.

00:06:08.066 --> 00:06:09.616
So let me illustrate how to use

00:06:09.616 --> 00:06:10.936
named entity recognition API

00:06:11.356 --> 00:06:14.106
again with the hypothetical app.

00:06:14.346 --> 00:06:15.276
So here's an app.

00:06:15.506 --> 00:06:17.026
It's a news recommendation app.

00:06:17.646 --> 00:06:18.906
So as part of this app, your

00:06:18.906 --> 00:06:20.576
user has been going and reading

00:06:20.576 --> 00:06:21.906
a lot of things about the royal

00:06:21.906 --> 00:06:23.206
wedding, so a really curious

00:06:23.206 --> 00:06:23.456
user.

00:06:23.456 --> 00:06:24.326
They want to find everything

00:06:24.326 --> 00:06:25.076
about the royal wedding.

00:06:25.466 --> 00:06:26.806
So they've perused a lot of

00:06:26.806 --> 00:06:28.886
pages in your app, and then they

00:06:28.886 --> 00:06:30.556
go on to the search bar, and

00:06:30.556 --> 00:06:31.556
they type Harry.

00:06:32.276 --> 00:06:34.406
And what they see is completely

00:06:34.686 --> 00:06:35.756
things that are not pertinent to

00:06:35.756 --> 00:06:37.026
what they've been looking for.

00:06:37.286 --> 00:06:38.686
You get Harry Potter and so on

00:06:38.686 --> 00:06:39.246
and so forth.

00:06:39.616 --> 00:06:42.376
What you'd like to see is Prince

00:06:42.376 --> 00:06:44.036
Harry, something related to the

00:06:44.116 --> 00:06:44.716
royal wedding.

00:06:45.296 --> 00:06:46.656
So now you can overcome this

00:06:46.656 --> 00:06:48.436
issue in your app by using the

00:06:48.436 --> 00:06:50.056
name entity recognition API.

00:06:51.376 --> 00:06:52.776
Again, as I mentioned, the

00:06:52.776 --> 00:06:54.346
syntax here is very familiar.

00:06:54.586 --> 00:06:56.006
Those of you who have been used

00:06:56.006 --> 00:06:57.506
to using NSLinguisticTagger,

00:06:57.776 --> 00:06:58.836
they should look familiar and

00:06:58.836 --> 00:07:00.276
feel familiar, but it's much

00:07:00.276 --> 00:07:01.656
easier to remember and to use.

00:07:02.126 --> 00:07:03.986
You import Natural Language.

00:07:04.866 --> 00:07:06.246
You now create an instance of

00:07:06.306 --> 00:07:08.516
NLTagger, and you specify the

00:07:08.516 --> 00:07:09.996
scheme type to be name type.

00:07:10.926 --> 00:07:11.896
If you want part of speech

00:07:11.896 --> 00:07:13.076
tagging, then you would specify

00:07:13.076 --> 00:07:14.426
the scheme type to be lexical

00:07:14.426 --> 00:07:14.906
class.

00:07:15.656 --> 00:07:17.556
You again specify the string

00:07:17.556 --> 00:07:18.546
that you want to process.

00:07:19.466 --> 00:07:21.336
In this particular instance, you

00:07:21.336 --> 00:07:23.446
specify the language, so you set

00:07:23.446 --> 00:07:24.636
the language to be English.

00:07:24.866 --> 00:07:27.016
So if you were not familiar or

00:07:27.016 --> 00:07:28.026
if you're not sure about what

00:07:28.026 --> 00:07:29.646
the language is, Natural

00:07:29.646 --> 00:07:30.956
Language will automatically

00:07:30.956 --> 00:07:32.726
recognize the language using the

00:07:32.726 --> 00:07:34.076
language identification API

00:07:34.076 --> 00:07:34.886
under the hood.

00:07:35.116 --> 00:07:37.816
And finally, you call the tags

00:07:38.296 --> 00:07:39.936
method on this object that you

00:07:39.936 --> 00:07:40.556
just created.

00:07:40.836 --> 00:07:42.456
You specify the unit to be word

00:07:42.456 --> 00:07:44.026
and the scheme to be name type.

00:07:44.536 --> 00:07:46.826
And what you get as an output is

00:07:47.166 --> 00:07:49.006
the person names here, Prince

00:07:49.006 --> 00:07:50.426
Harry and Meghan Markle, and the

00:07:50.426 --> 00:07:51.526
location to be Windsor.

00:07:51.776 --> 00:07:53.376
Now if the user were to go back

00:07:53.376 --> 00:07:55.246
to the search bar, based on the

00:07:55.246 --> 00:07:56.596
contextual information of what

00:07:56.596 --> 00:07:58.006
the user has been browsing, you

00:07:58.006 --> 00:07:59.326
can significantly enhance the

00:07:59.326 --> 00:08:01.386
search experience in your app.

00:08:03.526 --> 00:08:04.976
So there's a lot more

00:08:04.976 --> 00:08:06.256
information about how to use

00:08:06.256 --> 00:08:06.666
these APIs.

00:08:06.666 --> 00:08:07.906
You can go to the developer

00:08:07.906 --> 00:08:09.326
documentation and find more

00:08:09.326 --> 00:08:09.936
information.

00:08:10.376 --> 00:08:11.926
What I'd like to emphasize here

00:08:11.976 --> 00:08:15.106
is NSLinguisticTagger is still

00:08:15.106 --> 00:08:17.006
supported, but the future of NLP

00:08:17.006 --> 00:08:18.596
is in Natural Language.

00:08:18.596 --> 00:08:20.296
So we recommend that and

00:08:20.296 --> 00:08:22.026
encourage you to move to Natural

00:08:22.026 --> 00:08:23.566
Language so that you can get all

00:08:23.566 --> 00:08:24.896
the latest functionalities of

00:08:24.946 --> 00:08:26.226
NLP in this framework.

00:08:26.996 --> 00:08:29.616
Now let's shift gears and look

00:08:29.616 --> 00:08:31.996
at a situation where you have an

00:08:31.996 --> 00:08:34.525
idea for an app, or you need a

00:08:34.525 --> 00:08:36.376
functionality within your app

00:08:36.376 --> 00:08:37.666
that Natural Language does not

00:08:37.666 --> 00:08:38.076
support.

00:08:38.506 --> 00:08:40.106
What do you do?

00:08:40.106 --> 00:08:42.876
So you can certainly create

00:08:42.876 --> 00:08:44.936
something, which will be great,

00:08:45.306 --> 00:08:46.356
but what if we gave you the

00:08:46.356 --> 00:08:48.176
tools to make that much easier?

00:08:50.756 --> 00:08:53.376
To talk about custom NLP models

00:08:53.376 --> 00:08:54.656
and how to build custom NLP

00:08:54.656 --> 00:08:56.766
models using Create ML and use

00:08:56.766 --> 00:08:58.706
the subsequent models, which are

00:08:58.706 --> 00:09:00.126
essentially Code ML models in

00:09:00.126 --> 00:09:01.496
Natural Language, I'm going to

00:09:01.576 --> 00:09:02.816
hand it over to Doug Davidson.

00:09:03.516 --> 00:09:09.206
[ Applause ]

00:09:09.706 --> 00:09:10.366
>> Thanks Vivek.

00:09:11.146 --> 00:09:13.816
So I'm really excited about the

00:09:13.816 --> 00:09:15.386
new Natural Language framework,

00:09:15.736 --> 00:09:17.226
but the part I'm most excited

00:09:17.226 --> 00:09:19.586
about is support for portraying

00:09:19.586 --> 00:09:21.226
and using custom models.

00:09:21.536 --> 00:09:22.526
And why is that?

00:09:23.426 --> 00:09:24.576
I'd just like you to think for a

00:09:24.576 --> 00:09:27.636
second about your apps, maybe

00:09:27.636 --> 00:09:29.366
the apps you've written or the

00:09:29.366 --> 00:09:31.606
apps that you want to write, and

00:09:31.606 --> 00:09:32.856
think about how they could

00:09:33.336 --> 00:09:35.166
improve the user experience if

00:09:35.166 --> 00:09:36.756
they just knew a little more

00:09:37.536 --> 00:09:39.116
about the text that they deal

00:09:39.116 --> 00:09:39.286
with.

00:09:40.356 --> 00:09:42.206
And then think for a second

00:09:42.646 --> 00:09:44.756
about how you analyze text.

00:09:44.996 --> 00:09:46.756
So maybe you look at some

00:09:46.756 --> 00:09:49.446
examples of text, and you learn

00:09:49.446 --> 00:09:51.816
from them, and then you

00:09:52.266 --> 00:09:53.876
understand what's going on, and

00:09:53.876 --> 00:09:54.836
then you can look at a piece of

00:09:54.836 --> 00:09:56.346
text, and at a glance, you can

00:09:56.346 --> 00:09:57.476
figure out something about

00:09:57.476 --> 00:09:58.386
what's going on with it.

00:09:59.366 --> 00:10:01.306
Well, if that's the case, then

00:10:01.356 --> 00:10:02.566
there's at least a reasonable

00:10:02.566 --> 00:10:05.746
chance that you can train a

00:10:05.966 --> 00:10:08.216
machine learning model to do

00:10:08.216 --> 00:10:09.686
that sort of analysis in your

00:10:09.686 --> 00:10:11.206
app automatically for you,

00:10:11.646 --> 00:10:14.166
giving it examples that it can

00:10:14.166 --> 00:10:16.576
train and learn from and produce

00:10:16.576 --> 00:10:18.396
a model that can do that

00:10:18.396 --> 00:10:19.156
analysis.

00:10:19.966 --> 00:10:23.316
Now, there are many, many types

00:10:23.346 --> 00:10:24.776
of machine learning models for

00:10:24.826 --> 00:10:26.176
NLP, and there are many

00:10:26.176 --> 00:10:27.206
different ways of training it.

00:10:27.206 --> 00:10:28.606
Probably many of you are already

00:10:28.606 --> 00:10:29.546
training machine learning

00:10:29.546 --> 00:10:32.516
models, but our task here has

00:10:32.516 --> 00:10:35.286
been to produce ways to make

00:10:35.286 --> 00:10:36.806
this sort of training really,

00:10:36.806 --> 00:10:39.056
really easy and to make it

00:10:39.056 --> 00:10:41.036
integrate really well with the

00:10:41.036 --> 00:10:42.696
Natural Language framework and

00:10:42.696 --> 00:10:43.146
APIs.

00:10:43.556 --> 00:10:45.626
So with that in mind, we are

00:10:45.626 --> 00:10:47.826
supporting two types of models

00:10:48.366 --> 00:10:50.776
that we think support a broad

00:10:50.776 --> 00:10:53.016
range of functionality and that

00:10:53.016 --> 00:10:55.216
work well with our paradigm in

00:10:55.216 --> 00:10:57.386
NLTagger of applying labels to

00:10:57.386 --> 00:10:58.476
pieces of text.

00:10:58.796 --> 00:11:00.016
So the first of model we're

00:11:00.016 --> 00:11:02.366
supporting is a text classifier.

00:11:02.896 --> 00:11:05.376
A text classifier takes a chunk

00:11:05.376 --> 00:11:07.146
of text, maybe it's a sentence

00:11:07.146 --> 00:11:09.126
or a paragraph or an entire

00:11:09.126 --> 00:11:11.226
document, and applies a label to

00:11:11.226 --> 00:11:11.366
it.

00:11:11.786 --> 00:11:13.376
Examples of this in our existing

00:11:13.376 --> 00:11:15.286
APIs are things like language

00:11:15.286 --> 00:11:16.466
identification, script

00:11:16.466 --> 00:11:17.216
identification.

00:11:18.276 --> 00:11:19.436
The second type of model we

00:11:19.436 --> 00:11:21.846
support is a word tagger, and a

00:11:21.846 --> 00:11:23.836
word tagger takes a sentence

00:11:23.886 --> 00:11:25.856
considered as a sequence of

00:11:25.856 --> 00:11:28.196
words, and then applies a label

00:11:28.196 --> 00:11:30.386
to each word in a sentence in

00:11:30.386 --> 00:11:32.366
context, and examples of

00:11:32.366 --> 00:11:34.916
existing APIs are things like

00:11:34.916 --> 00:11:36.576
speech tagging and named entity

00:11:36.576 --> 00:11:37.116
recognition.

00:11:37.636 --> 00:11:39.316
But those are sort of general

00:11:39.396 --> 00:11:42.656
purpose examples of these kinds

00:11:42.656 --> 00:11:43.336
of models.

00:11:44.006 --> 00:11:45.616
You can do a lot more with them

00:11:46.026 --> 00:11:47.236
if you have a special purpose

00:11:47.236 --> 00:11:48.446
model for your specific

00:11:48.446 --> 00:11:49.006
application.

00:11:49.006 --> 00:11:50.036
Let me give you some

00:11:50.036 --> 00:11:51.366
hypothetical examples.

00:11:51.956 --> 00:11:53.576
So, for text classification,

00:11:53.946 --> 00:11:55.556
suppose you're dealing with user

00:11:55.556 --> 00:11:57.066
reviews, and you want to know

00:11:57.066 --> 00:11:59.406
automatically whether a given

00:11:59.406 --> 00:12:02.016
review is a positive review or a

00:12:02.016 --> 00:12:03.356
negative review or somewhere in

00:12:03.356 --> 00:12:03.816
between.

00:12:04.296 --> 00:12:05.216
Well, this is the sort of thing

00:12:05.216 --> 00:12:06.256
you could train a text

00:12:06.286 --> 00:12:07.066
classifier to do.

00:12:07.066 --> 00:12:07.746
This is sentiment

00:12:07.816 --> 00:12:08.536
classification.

00:12:10.516 --> 00:12:12.556
Or suppose you have articles or

00:12:12.556 --> 00:12:14.206
just article summaries or maybe

00:12:14.206 --> 00:12:15.596
even just article headlines, and

00:12:15.596 --> 00:12:16.376
you want to determine

00:12:16.376 --> 00:12:18.486
automatically what topic they

00:12:18.486 --> 00:12:19.726
belong to according to your

00:12:19.726 --> 00:12:21.866
favorite topic classification

00:12:21.866 --> 00:12:22.266
scheme.

00:12:22.746 --> 00:12:23.836
This again is the sort of thing

00:12:23.836 --> 00:12:26.596
that you can train a text

00:12:26.596 --> 00:12:28.096
classifier to do for you.

00:12:28.656 --> 00:12:31.246
Or going a little further,

00:12:31.246 --> 00:12:32.486
suppose you're writing an

00:12:32.486 --> 00:12:35.286
automated travel agent, and when

00:12:35.286 --> 00:12:36.976
you get a request from a client,

00:12:37.246 --> 00:12:38.426
the first thing you want to know

00:12:38.426 --> 00:12:40.216
probably is what are they asking

00:12:40.216 --> 00:12:40.526
about?

00:12:40.796 --> 00:12:42.506
Is it hotels or restaurants or

00:12:42.506 --> 00:12:43.746
flights or whatever else that

00:12:43.746 --> 00:12:44.266
you handle.

00:12:44.886 --> 00:12:46.056
This is the sort of thing that

00:12:46.056 --> 00:12:47.576
you could train a text

00:12:47.636 --> 00:12:49.316
classifier to answer for you.

00:12:50.946 --> 00:12:52.566
Going on to word tagging.

00:12:53.106 --> 00:12:56.586
So we provide word taggers that

00:12:56.586 --> 00:12:58.166
do part of speech tagging for a

00:12:58.166 --> 00:12:59.326
number of different languages,

00:12:59.696 --> 00:13:01.646
but suppose you happen to need

00:13:01.646 --> 00:13:03.066
to do part of speech tagging for

00:13:03.066 --> 00:13:04.296
some language that we don't

00:13:04.296 --> 00:13:05.686
happen to support quite yet.

00:13:06.426 --> 00:13:07.956
Well, with custom model support,

00:13:07.956 --> 00:13:10.006
you could train a word tagger to

00:13:10.006 --> 00:13:10.906
do that for you.

00:13:12.266 --> 00:13:14.206
Or named entity recognition.

00:13:14.746 --> 00:13:16.056
So we provide built-in named

00:13:16.056 --> 00:13:16.976
entity recognition that

00:13:16.976 --> 00:13:19.106
recognizes names of people and

00:13:19.106 --> 00:13:21.516
places and organizations, but

00:13:21.516 --> 00:13:22.766
suppose you had some other kind

00:13:22.766 --> 00:13:23.356
of name that you were

00:13:23.356 --> 00:13:24.686
particularly interested in that

00:13:24.686 --> 00:13:25.906
we don't happen to support right

00:13:25.906 --> 00:13:26.166
now.

00:13:26.506 --> 00:13:28.136
So, like for example, product

00:13:28.136 --> 00:13:28.456
names.

00:13:28.456 --> 00:13:30.146
So you could train your own

00:13:30.146 --> 00:13:31.876
custom named entity recognizer

00:13:32.036 --> 00:13:33.656
as a word tagger that would

00:13:33.656 --> 00:13:36.456
recognize names or other terms

00:13:36.496 --> 00:13:37.526
of whatever sort you are

00:13:37.526 --> 00:13:39.426
particularly interested in.

00:13:40.616 --> 00:13:42.956
Even further, for your automated

00:13:42.956 --> 00:13:44.356
travel agent, once you know what

00:13:44.356 --> 00:13:45.646
the user is asking about,

00:13:46.166 --> 00:13:47.326
probably the next thing you want

00:13:47.326 --> 00:13:49.106
to know is what are the relevant

00:13:49.106 --> 00:13:50.566
terms in their request.

00:13:50.626 --> 00:13:51.816
For example, if it's a flight

00:13:51.816 --> 00:13:52.416
request.

00:13:52.676 --> 00:13:53.856
Where do they want to go from

00:13:53.856 --> 00:13:54.386
and to?

00:13:55.546 --> 00:13:57.566
So a word tagger can identify

00:13:58.216 --> 00:14:01.386
various kinds of terms in a

00:14:01.996 --> 00:14:02.236
sentence.

00:14:02.326 --> 00:14:04.766
Or another application, if you

00:14:04.766 --> 00:14:06.086
need to take a sentence and

00:14:06.086 --> 00:14:07.966
divide it up into phrases, noun

00:14:07.966 --> 00:14:09.356
phrases, verb phrases,

00:14:09.426 --> 00:14:10.596
propositional phrases.

00:14:10.996 --> 00:14:11.906
With the appropriate sort of

00:14:11.906 --> 00:14:14.186
labeling, you could train a word

00:14:14.186 --> 00:14:16.206
tagger to do this, and many,

00:14:16.206 --> 00:14:19.556
many other kinds of tasks can be

00:14:19.556 --> 00:14:21.796
phrased in terms of labeling,

00:14:22.136 --> 00:14:23.946
applying labels to portions of

00:14:23.946 --> 00:14:26.346
text, either words in sequence

00:14:26.696 --> 00:14:29.176
or chunks of text in the text

00:14:29.176 --> 00:14:29.756
classifier.

00:14:33.676 --> 00:14:36.246
So these are supervised machine

00:14:36.246 --> 00:14:37.526
learning models, so there are

00:14:37.526 --> 00:14:39.946
two phases always involved.

00:14:40.266 --> 00:14:41.806
The first phase is training, and

00:14:41.996 --> 00:14:43.506
the second phase is inference.

00:14:43.786 --> 00:14:46.016
So training is what you do in

00:14:46.016 --> 00:14:46.996
part of your development

00:14:46.996 --> 00:14:47.726
process.

00:14:48.256 --> 00:14:50.926
You take labeled training data,

00:14:51.936 --> 00:14:54.356
and you feed it into Create ML

00:14:54.606 --> 00:14:55.806
and produce a model.

00:14:57.266 --> 00:14:59.266
Inference is then what happens

00:14:59.336 --> 00:15:01.246
in your app when you incorporate

00:15:01.486 --> 00:15:03.036
that model into your application

00:15:03.486 --> 00:15:05.406
at run time when it encounters

00:15:05.406 --> 00:15:06.956
some piece of data from the

00:15:06.956 --> 00:15:08.986
user, and then it analyzes that

00:15:08.986 --> 00:15:09.976
data and predicts the

00:15:09.976 --> 00:15:11.346
appropriate labels for it.

00:15:11.806 --> 00:15:13.396
So let's see how these phases

00:15:13.396 --> 00:15:13.676
work.

00:15:14.936 --> 00:15:16.246
So let's start with training,

00:15:17.076 --> 00:15:18.366
and training always starts with

00:15:18.426 --> 00:15:18.786
data.

00:15:19.406 --> 00:15:22.056
You take your training data, and

00:15:22.056 --> 00:15:23.856
then you feed it in to in this

00:15:23.856 --> 00:15:26.956
case Create ML in a playground

00:15:26.956 --> 00:15:29.236
let us say or a script

00:15:30.286 --> 00:15:30.986
[inaudible] as you may have seen

00:15:30.986 --> 00:15:32.066
in the Create ML session.

00:15:32.616 --> 00:15:34.606
Create ML calls the Natural

00:15:34.606 --> 00:15:35.446
Language framework under the

00:15:35.446 --> 00:15:38.196
hood to do the training, and

00:15:38.196 --> 00:15:40.806
what comes out is a core ML

00:15:40.806 --> 00:15:43.726
model that's optimized for use

00:15:43.766 --> 00:15:44.586
on device.

00:15:45.956 --> 00:15:47.616
So let's look at what this data

00:15:47.616 --> 00:15:49.416
might look like.

00:15:49.786 --> 00:15:51.396
So Create ML supports a number

00:15:51.396 --> 00:15:52.856
of different data formats.

00:15:53.276 --> 00:15:55.376
Right here we're showing our

00:15:55.376 --> 00:15:57.666
data in JSON because JSON makes

00:15:57.666 --> 00:16:00.946
things perfectly clear, and this

00:16:00.946 --> 00:16:04.436
is a piece of training data for

00:16:04.816 --> 00:16:06.516
a text classifier that's a

00:16:06.516 --> 00:16:07.666
sediment classifier.

00:16:07.916 --> 00:16:11.396
So each training example, like

00:16:11.396 --> 00:16:13.546
this one, consists of two parts,

00:16:13.856 --> 00:16:16.686
a chunk of text, and the

00:16:16.686 --> 00:16:17.986
appropriate label for it.

00:16:18.676 --> 00:16:20.696
And so this for example is a

00:16:20.696 --> 00:16:22.056
positive sentence, so the label

00:16:22.056 --> 00:16:23.206
is positive, but you can pick

00:16:23.246 --> 00:16:27.636
whatever label set you want.

00:16:27.816 --> 00:16:29.896
Now, then when you start using

00:16:29.896 --> 00:16:31.806
Create ML, the Create ML

00:16:32.476 --> 00:16:34.066
provides a very, very simple way

00:16:34.156 --> 00:16:36.296
to train models in just a few

00:16:36.296 --> 00:16:36.986
lines of code.

00:16:36.986 --> 00:16:40.046
First line, we just load our

00:16:40.146 --> 00:16:42.446
training data from our JSON

00:16:42.446 --> 00:16:42.846
file.

00:16:42.886 --> 00:16:44.676
So we give it a URL to the JSON

00:16:44.676 --> 00:16:48.116
file, create a Create ML data

00:16:48.116 --> 00:16:48.836
table from it.

00:16:49.996 --> 00:16:52.216
Then in one line of code, create

00:16:52.216 --> 00:16:55.046
and train a text classifier from

00:16:55.046 --> 00:16:55.586
this data.

00:16:55.806 --> 00:16:57.086
All you have to tell it is what

00:16:57.086 --> 00:16:58.456
the names of the fields are,

00:16:58.866 --> 00:17:02.046
text and label, and then once

00:17:02.046 --> 00:17:03.536
you have it, one line of code

00:17:03.536 --> 00:17:07.116
writes that model out to disk.

00:17:07.286 --> 00:17:08.675
Now for training a Word Tagger,

00:17:08.776 --> 00:17:09.556
it's very similar.

00:17:09.976 --> 00:17:11.286
The data is just a little more

00:17:11.286 --> 00:17:13.526
complicated because each example

00:17:13.526 --> 00:17:15.076
is not a single piece of text.

00:17:15.306 --> 00:17:18.226
It's a sequence of tokens, and

00:17:18.786 --> 00:17:20.316
the labels are, again, a

00:17:20.316 --> 00:17:21.726
sequence of labels, the same

00:17:21.726 --> 00:17:23.955
number of labels, one label for

00:17:23.955 --> 00:17:24.546
each token.

00:17:24.935 --> 00:17:26.776
So this, for example, is

00:17:26.826 --> 00:17:29.976
training data for a Word Tagger

00:17:29.976 --> 00:17:31.236
that does name identity

00:17:31.236 --> 00:17:34.526
recognition, and each word, each

00:17:34.526 --> 00:17:36.836
token, has a label, either none,

00:17:36.836 --> 00:17:39.696
it's not a name, or org, it's an

00:17:39.696 --> 00:17:42.376
organization name or prod, it's

00:17:42.376 --> 00:17:44.296
product name, or a number of

00:17:44.326 --> 00:17:45.856
different other labels for

00:17:45.856 --> 00:17:47.146
whatever kinds of names you're

00:17:47.146 --> 00:17:47.806
recognizing.

00:17:48.236 --> 00:17:51.016
So each token has a label, and

00:17:51.016 --> 00:17:54.306
each sample consists of one

00:17:54.456 --> 00:17:55.906
sequence of tokens and their

00:17:55.906 --> 00:17:56.986
corresponding labels.

00:17:58.606 --> 00:18:01.066
And then the Create ML to train

00:18:01.066 --> 00:18:02.886
this is almost identical.

00:18:03.996 --> 00:18:06.276
You load the training data into

00:18:06.276 --> 00:18:08.346
a data table from the JSON.

00:18:09.896 --> 00:18:12.996
Then you create and train a Word

00:18:12.996 --> 00:18:14.336
Tagger, in this case instead of

00:18:14.336 --> 00:18:16.426
a text classifier, and then you

00:18:16.426 --> 00:18:17.806
write it out to disk.

00:18:18.306 --> 00:18:20.576
Now, there are a number of other

00:18:20.576 --> 00:18:23.026
options and APIs available in

00:18:23.026 --> 00:18:23.626
Create ML.

00:18:23.626 --> 00:18:24.906
I encourage you to, if you

00:18:24.906 --> 00:18:26.026
haven't already, take a look at

00:18:26.026 --> 00:18:27.826
the Create ML session, which

00:18:27.826 --> 00:18:29.696
happened yesterday, and Create

00:18:29.696 --> 00:18:31.306
ML documentation for more

00:18:31.306 --> 00:18:32.236
information on that.

00:18:33.066 --> 00:18:35.086
Now, once you have your model,

00:18:35.276 --> 00:18:36.236
we then go to the inference

00:18:36.236 --> 00:18:36.506
part.

00:18:36.696 --> 00:18:38.406
So you take your model, you drag

00:18:38.406 --> 00:18:39.796
it into your Xcode project.

00:18:40.186 --> 00:18:41.846
Xcode compiles it and includes

00:18:41.846 --> 00:18:43.126
it in your applications

00:18:43.226 --> 00:18:45.156
resources, and then what do you

00:18:45.156 --> 00:18:45.996
do at run time?

00:18:46.686 --> 00:18:49.056
Well, it's a Core ML model.

00:18:49.056 --> 00:18:50.136
You could use it like any other

00:18:50.136 --> 00:18:51.736
Core ML model, but the

00:18:51.736 --> 00:18:53.626
interesting thing is that these

00:18:53.626 --> 00:18:56.216
models are able to work well

00:18:56.596 --> 00:18:58.706
with the Natural Language APIs

00:18:59.356 --> 00:19:01.566
just like our built-in models

00:19:01.566 --> 00:19:02.826
that provide the existing

00:19:02.826 --> 00:19:04.956
functionality for NLP.

00:19:06.666 --> 00:19:09.696
So what will happen is data

00:19:09.696 --> 00:19:10.306
comes in.

00:19:11.296 --> 00:19:12.976
You pass it to Natural Language,

00:19:14.126 --> 00:19:16.226
which will use that model and do

00:19:16.226 --> 00:19:18.936
everything necessary to get all

00:19:18.936 --> 00:19:20.806
of the labels out and then pass

00:19:20.856 --> 00:19:22.706
back either a label, single

00:19:22.706 --> 00:19:24.196
label for a classifier or a

00:19:24.196 --> 00:19:27.106
sequence of labels for a tagger.

00:19:27.656 --> 00:19:32.316
And so how do you do this in

00:19:32.316 --> 00:19:33.296
Natural Language API?

00:19:34.326 --> 00:19:36.176
First thing you have to do is

00:19:36.176 --> 00:19:38.366
just locate that model in your

00:19:38.366 --> 00:19:40.296
application's resources, and

00:19:40.296 --> 00:19:41.636
then you create an instance of a

00:19:41.636 --> 00:19:43.406
class in Natural Language called

00:19:43.456 --> 00:19:45.626
ML Model from it.

00:19:46.026 --> 00:19:48.026
And then, well, the simplest

00:19:48.026 --> 00:19:49.036
thing you can do with it, at

00:19:49.076 --> 00:19:51.396
least for a classifier, is just

00:19:51.396 --> 00:19:52.976
pass it in a chunk of text and

00:19:52.976 --> 00:19:53.756
get a label out.

00:19:54.696 --> 00:19:55.886
But the more interesting thing

00:19:55.936 --> 00:19:59.116
is that you can use these models

00:19:59.116 --> 00:20:02.226
with NLTagger in exactly the

00:20:02.226 --> 00:20:03.866
same way that you use our

00:20:03.866 --> 00:20:06.976
built-in models for an existing

00:20:06.976 --> 00:20:07.716
functionality.

00:20:08.176 --> 00:20:09.036
So let me show you how that

00:20:09.036 --> 00:20:09.466
works.

00:20:10.366 --> 00:20:12.326
In addition to the existing tag

00:20:12.326 --> 00:20:13.776
schemes that we have for things

00:20:13.776 --> 00:20:15.336
like named identity recognition

00:20:15.336 --> 00:20:17.136
part of speech tagging, you can

00:20:17.136 --> 00:20:18.676
create your own custom tag

00:20:18.676 --> 00:20:22.446
scheme, give it a name, and then

00:20:22.516 --> 00:20:24.636
you can create a tagger that

00:20:24.636 --> 00:20:26.066
includes any number of different

00:20:26.066 --> 00:20:26.776
tag schemes.

00:20:27.146 --> 00:20:28.826
Your custom tag scheme or any of

00:20:28.826 --> 00:20:30.426
our built-in tag schemes or all

00:20:31.086 --> 00:20:33.086
of them, and then all you have

00:20:33.086 --> 00:20:35.496
to do is to tell the tagger to

00:20:35.496 --> 00:20:37.136
use your custom model for your

00:20:37.136 --> 00:20:38.146
custom tag scheme.

00:20:38.686 --> 00:20:40.886
And then you just use it

00:20:42.186 --> 00:20:42.706
normally.

00:20:43.246 --> 00:20:44.776
You attach a string to the

00:20:44.776 --> 00:20:46.756
tagger, and you can go through

00:20:46.756 --> 00:20:49.256
and look at the tags for

00:20:49.706 --> 00:20:51.736
whatever unit of text is

00:20:51.736 --> 00:20:52.996
appropriate for your particular

00:20:52.996 --> 00:20:56.296
model, and the tagger will

00:20:56.296 --> 00:20:58.246
automatically call the model as

00:20:58.246 --> 00:20:59.886
necessary to get the tags and

00:20:59.886 --> 00:21:01.436
return the tags to you and will

00:21:01.436 --> 00:21:03.616
do all the other things that

00:21:03.616 --> 00:21:05.116
NLTagger does automatically,

00:21:05.476 --> 00:21:06.886
like language identification,

00:21:06.886 --> 00:21:08.246
tokenization and so on and so

00:21:08.246 --> 00:21:08.526
forth.

00:21:08.526 --> 00:21:12.386
So I want to show this to you in

00:21:12.386 --> 00:21:14.016
a simple hypothetical example.

00:21:14.606 --> 00:21:16.686
And this hypothetical example is

00:21:17.726 --> 00:21:21.266
an app that users will use to

00:21:21.266 --> 00:21:23.076
store bookmarks to articles they

00:21:23.076 --> 00:21:24.526
may have run across and then

00:21:24.596 --> 00:21:26.056
might be intending to read later

00:21:26.056 --> 00:21:26.296
on.

00:21:27.236 --> 00:21:28.836
But the problem with this

00:21:28.836 --> 00:21:29.866
application as it currently

00:21:29.866 --> 00:21:32.066
stands is that the list of

00:21:32.066 --> 00:21:33.626
bookmarks is just one long list

00:21:33.626 --> 00:21:34.996
with no organization to it.

00:21:35.566 --> 00:21:37.176
Wouldn't it be nice if we could

00:21:37.336 --> 00:21:39.056
automatically classify these

00:21:39.056 --> 00:21:41.046
articles and put them into some

00:21:41.046 --> 00:21:42.726
organization according to topic?

00:21:43.316 --> 00:21:45.376
Well, we can train a classifier

00:21:45.376 --> 00:21:46.276
to do that for us.

00:21:47.066 --> 00:21:48.346
And the other thing is that the

00:21:48.346 --> 00:21:49.526
articles, when we look at them,

00:21:49.856 --> 00:21:51.346
it's a long stream of text.

00:21:52.386 --> 00:21:53.666
Maybe we'd like to highlight

00:21:53.666 --> 00:21:55.966
some interesting things in those

00:21:55.966 --> 00:21:58.286
articles like for example names.

00:21:58.796 --> 00:22:01.596
Well, we have provided built-in

00:22:01.596 --> 00:22:03.156
name identity recognition for

00:22:03.156 --> 00:22:04.666
names of people, places, and

00:22:04.666 --> 00:22:07.406
organizations, but maybe we also

00:22:07.406 --> 00:22:08.426
want to highlight names of

00:22:08.426 --> 00:22:10.016
products, so we could train a

00:22:10.076 --> 00:22:12.366
custom word tagger to identify

00:22:12.366 --> 00:22:14.086
those names for us.

00:22:15.036 --> 00:22:16.726
So let me go over to the demo

00:22:16.726 --> 00:22:17.086
machine.

00:22:20.736 --> 00:22:25.746
And so here's our application as

00:22:25.746 --> 00:22:27.586
it stands before we apply any

00:22:27.856 --> 00:22:29.116
natural language processing.

00:22:29.406 --> 00:22:30.706
As you can see, even just one

00:22:30.706 --> 00:22:32.736
long list of articles on the

00:22:32.736 --> 00:22:35.456
side and a big chunk of text for

00:22:35.456 --> 00:22:36.606
our article on the right.

00:22:36.606 --> 00:22:37.486
Well let's fix that.

00:22:38.716 --> 00:22:42.506
So, let's go into -- so the

00:22:42.506 --> 00:22:44.996
first part of training a model

00:22:45.516 --> 00:22:48.776
is data, and fortunately, I have

00:22:48.776 --> 00:22:49.576
some very hard-working

00:22:49.576 --> 00:22:50.976
colleagues at Apple who have

00:22:50.976 --> 00:22:52.696
collected for me some training

00:22:52.696 --> 00:22:54.446
data to train two models.

00:22:54.776 --> 00:22:57.066
The first model is a text

00:22:57.066 --> 00:22:59.026
classifier that will classify

00:22:59.026 --> 00:23:00.446
articles according to topic.

00:23:00.856 --> 00:23:01.896
So this is some of what the

00:23:01.896 --> 00:23:03.136
training data looks like.

00:23:03.716 --> 00:23:05.466
Each training example is a chunk

00:23:05.466 --> 00:23:07.106
of text and the appropriate

00:23:07.106 --> 00:23:10.386
label by topic, entertainment,

00:23:10.386 --> 00:23:12.016
politics, sports, and so on and

00:23:12.016 --> 00:23:13.026
so forth.

00:23:15.196 --> 00:23:18.436
And I also have some training

00:23:18.436 --> 00:23:21.486
data to train a word tagger that

00:23:21.486 --> 00:23:25.136
will recognize product names in

00:23:25.136 --> 00:23:25.836
sentences.

00:23:26.256 --> 00:23:27.766
So this training data is pretty

00:23:27.766 --> 00:23:28.106
simple.

00:23:28.666 --> 00:23:31.486
Each example consists of a

00:23:31.486 --> 00:23:32.736
sentence considered as a

00:23:32.736 --> 00:23:34.326
sequence of tokens and then a

00:23:34.326 --> 00:23:35.936
sequence of labels, and each

00:23:35.936 --> 00:23:38.456
label is either none, it's not a

00:23:38.456 --> 00:23:40.716
product name, or prod, it is a

00:23:40.716 --> 00:23:43.436
product name.

00:23:43.696 --> 00:23:46.066
So, let's try to train with

00:23:46.106 --> 00:23:46.436
these.

00:23:47.186 --> 00:23:50.406
So first thing I want to do is

00:23:50.926 --> 00:23:52.726
bring up a playground that I

00:23:52.726 --> 00:23:55.786
have using Create ML, and this

00:23:55.826 --> 00:23:58.576
playground will just load.

00:23:58.646 --> 00:24:00.826
In this case, this is my product

00:24:00.826 --> 00:24:01.496
word tagger.

00:24:01.716 --> 00:24:02.886
It'll load the training data,

00:24:03.796 --> 00:24:05.206
create a word tagger from it,

00:24:05.886 --> 00:24:07.036
and write it out to disk.

00:24:07.036 --> 00:24:08.356
So let me just fire that off,

00:24:09.476 --> 00:24:10.626
and let it start running.

00:24:11.206 --> 00:24:14.326
It's loaded the data, and so

00:24:14.326 --> 00:24:16.176
under the hood, we automatically

00:24:16.176 --> 00:24:17.966
handle all of the tokenization,

00:24:17.966 --> 00:24:19.086
the feature extraction.

00:24:19.466 --> 00:24:20.316
We do the training.

00:24:20.316 --> 00:24:22.596
This is a fairly small model, so

00:24:22.596 --> 00:24:24.116
it doesn't take all that long to

00:24:24.116 --> 00:24:27.796
train, and I have it set to

00:24:27.796 --> 00:24:29.366
automatically write my model out

00:24:29.366 --> 00:24:35.956
to my desktop, and there it is.

00:24:36.196 --> 00:24:36.486
All right.

00:24:36.486 --> 00:24:37.436
So that's one model.

00:24:38.636 --> 00:24:40.636
Now I have another playground

00:24:40.636 --> 00:24:41.876
here that's set up to train my

00:24:41.876 --> 00:24:42.786
text classifier.

00:24:43.136 --> 00:24:44.076
As you can see, it looks very

00:24:44.076 --> 00:24:44.516
similar.

00:24:45.046 --> 00:24:47.836
Load the training data, create a

00:24:47.836 --> 00:24:49.396
text classifier from it, and

00:24:49.396 --> 00:24:50.266
write it out to disk.

00:24:51.716 --> 00:24:52.786
So I start that off.

00:24:53.426 --> 00:24:56.876
And again, automatically natural

00:24:56.876 --> 00:24:58.006
language is loading all the

00:24:58.006 --> 00:25:00.126
data, tokenizing it, extracting

00:25:00.126 --> 00:25:00.856
features from it.

00:25:01.266 --> 00:25:03.226
This one is a bit larger model.

00:25:03.226 --> 00:25:04.226
It takes a couple minutes to

00:25:04.226 --> 00:25:04.556
train.

00:25:04.556 --> 00:25:06.746
So let's just let that go, and

00:25:06.746 --> 00:25:08.696
in the meantime, take a look at

00:25:08.696 --> 00:25:10.966
some of the code we have to use

00:25:10.966 --> 00:25:12.026
these at run time.

00:25:12.546 --> 00:25:14.166
So I've written two very small

00:25:14.166 --> 00:25:16.106
classes to do what I need to do

00:25:16.106 --> 00:25:16.576
at run time.

00:25:17.106 --> 00:25:18.546
The first one uses the text

00:25:18.546 --> 00:25:22.136
classifier by finding that model

00:25:22.386 --> 00:25:24.386
in my apps resources and

00:25:24.386 --> 00:25:25.826
creating an NL model for it.

00:25:26.856 --> 00:25:28.656
And then when I run across an

00:25:28.656 --> 00:25:32.016
article, I just ask the model

00:25:32.016 --> 00:25:33.616
for a predicted label for that

00:25:33.616 --> 00:25:35.856
article, and that's really all

00:25:35.856 --> 00:25:38.246
there is to it.

00:25:38.506 --> 00:25:42.726
Slightly more code for use of my

00:25:42.726 --> 00:25:43.486
word tagger.

00:25:44.176 --> 00:25:46.006
So as you saw before, I have a

00:25:46.006 --> 00:25:49.026
custom tag scheme for my product

00:25:49.196 --> 00:25:51.616
name recognition, and the only

00:25:51.616 --> 00:25:53.566
tag I'm really interested in is

00:25:53.566 --> 00:25:54.546
the product tag.

00:25:54.716 --> 00:25:57.416
So I create a custom tag for

00:25:58.036 --> 00:25:58.146
that.

00:25:58.366 --> 00:26:00.396
Again, I have to find the model

00:26:00.546 --> 00:26:03.366
in my bundles resources, create

00:26:03.366 --> 00:26:05.536
an NL model for it, and then

00:26:05.536 --> 00:26:07.586
create an NLTagger, and this

00:26:07.736 --> 00:26:09.826
NLTagger I'm specifying two

00:26:09.826 --> 00:26:10.376
schemes.

00:26:10.416 --> 00:26:11.986
The first is the built-in name

00:26:11.986 --> 00:26:14.876
type scheme to do name identity

00:26:14.876 --> 00:26:16.426
recognition, and the second one

00:26:16.426 --> 00:26:18.176
is my custom product tag scheme,

00:26:18.516 --> 00:26:19.486
and they'll both function in

00:26:19.486 --> 00:26:20.576
exactly the same way.

00:26:21.546 --> 00:26:23.006
And then I just have to tell

00:26:23.096 --> 00:26:24.766
that tagger to use my custom

00:26:24.766 --> 00:26:26.866
model for my custom scheme.

00:26:27.716 --> 00:26:29.176
Now if I supported multiple

00:26:29.176 --> 00:26:30.286
languages, I might have more

00:26:30.286 --> 00:26:31.956
than one model in here for this

00:26:31.956 --> 00:26:32.216
scheme.

00:26:32.806 --> 00:26:38.426
And then what I'm going to do is

00:26:38.426 --> 00:26:40.306
highlight text in this article

00:26:40.716 --> 00:26:42.466
that is located, determined to

00:26:42.466 --> 00:26:43.896
be a name of one sort or

00:26:43.896 --> 00:26:44.266
another.

00:26:44.566 --> 00:26:46.586
So I'm going to get a mutable

00:26:46.586 --> 00:26:47.716
attributed string, and I'm going

00:26:47.716 --> 00:26:49.026
to add some attributes to it.

00:26:50.106 --> 00:26:51.996
So I'll take this string of that

00:26:52.206 --> 00:26:53.246
mutable attributed string,

00:26:53.246 --> 00:26:56.196
attach that to my tagger, and

00:26:56.196 --> 00:26:57.496
then I'm going to do a couple of

00:26:57.496 --> 00:26:59.216
enumerations over tags.

00:26:59.676 --> 00:27:01.916
The first one uses the built-in

00:27:01.916 --> 00:27:03.926
name-type scheme for name

00:27:03.926 --> 00:27:05.576
identity recognition of people,

00:27:05.576 --> 00:27:07.576
places, and organizations, and

00:27:07.576 --> 00:27:08.686
if I find something that's

00:27:08.686 --> 00:27:11.436
tagged as a person or place or

00:27:11.436 --> 00:27:13.226
organization, then I'm going to

00:27:13.226 --> 00:27:14.946
add an attribute to the

00:27:14.946 --> 00:27:17.326
attributed string that will give

00:27:17.326 --> 00:27:17.976
it some color.

00:27:20.256 --> 00:27:21.576
And then we can do exactly the

00:27:21.576 --> 00:27:23.696
same thing with our custom

00:27:23.696 --> 00:27:24.046
model.

00:27:24.846 --> 00:27:26.336
We're going to enumerate using

00:27:26.336 --> 00:27:28.176
our custom product tag scheme,

00:27:29.586 --> 00:27:31.386
and in that case, if we find

00:27:31.386 --> 00:27:32.516
something that's labeled with

00:27:32.516 --> 00:27:34.586
our custom product tag, then I

00:27:34.586 --> 00:27:37.106
can add color to it in exactly

00:27:37.106 --> 00:27:37.786
the same way.

00:27:39.106 --> 00:27:41.026
So you can use custom models

00:27:41.626 --> 00:27:44.326
with Natural Language API just

00:27:44.516 --> 00:27:45.916
in the same way that you use

00:27:45.916 --> 00:27:46.916
built-in models.

00:27:47.566 --> 00:27:48.736
Now, let's go back to our

00:27:48.736 --> 00:27:50.936
playground, and we see that the

00:27:50.936 --> 00:27:52.986
model training has finished, and

00:27:52.986 --> 00:27:54.496
in fact there are now two models

00:27:54.496 --> 00:27:55.996
showing up on my desktop.

00:27:57.776 --> 00:27:59.936
So all I need to do is drag

00:27:59.936 --> 00:28:01.176
those into my application.

00:28:02.116 --> 00:28:05.286
Let's take this one and drag it

00:28:05.286 --> 00:28:06.146
right in.

00:28:08.026 --> 00:28:14.676
Okay. And let's take this one

00:28:15.226 --> 00:28:19.786
and drag it in, and Xcode will

00:28:19.786 --> 00:28:21.116
automatically compile these and

00:28:21.116 --> 00:28:22.546
include them in my application.

00:28:22.846 --> 00:28:25.656
So all I have to do is build and

00:28:25.656 --> 00:28:25.946
run it.

00:28:31.386 --> 00:28:34.336
And let's hide that.

00:28:34.926 --> 00:28:36.796
Here's my new application, and

00:28:36.796 --> 00:28:38.096
you'll notice that my list of

00:28:38.096 --> 00:28:40.386
articles is all neatly sorted

00:28:40.506 --> 00:28:47.166
automatically by topic, and if I

00:28:47.166 --> 00:28:49.596
go in and take a look at one of

00:28:49.596 --> 00:28:51.396
these articles, you'll notice

00:28:51.396 --> 00:28:53.556
that names are highlighted in

00:28:53.556 --> 00:28:55.296
it, and you can see, using our

00:28:55.296 --> 00:28:56.566
built-in name identity

00:28:56.566 --> 00:28:57.976
recognition, we highlight names

00:28:57.976 --> 00:28:59.026
of people, places, and

00:28:59.026 --> 00:29:00.806
organizations, but if you look a

00:29:00.806 --> 00:29:03.456
little further, you can see that

00:29:03.496 --> 00:29:05.696
it has used our custom product

00:29:05.696 --> 00:29:07.546
tagger to highlight the names of

00:29:07.546 --> 00:29:10.056
products like iPad, MacBook,

00:29:10.356 --> 00:29:12.386
iPad mini, and so forth.

00:29:13.256 --> 00:29:16.606
So this shows how easy it is to

00:29:16.606 --> 00:29:18.966
train your own custom models and

00:29:18.966 --> 00:29:21.346
to use them with the natural

00:29:21.346 --> 00:29:22.866
language APIs.

00:29:24.516 --> 00:29:30.546
[ Applause ]

00:29:31.046 --> 00:29:32.836
So now I'm going to turn things

00:29:32.886 --> 00:29:34.486
back over to Vivek to talk about

00:29:34.486 --> 00:29:36.236
some important considerations

00:29:36.286 --> 00:29:37.646
for training models.

00:29:40.516 --> 00:29:43.506
[ Applause ]

00:29:44.006 --> 00:29:45.316
Thank you, Doug, for telling us

00:29:45.316 --> 00:29:46.536
how to use these custom NLP

00:29:46.536 --> 00:29:46.966
models.

00:29:46.966 --> 00:29:48.646
We are really excited to sort of

00:29:48.646 --> 00:29:50.646
have a very tight integration of

00:29:50.646 --> 00:29:52.686
natural language with Create ML

00:29:52.686 --> 00:29:54.146
and the Core ML [inaudible], and

00:29:54.146 --> 00:29:55.246
we hope that you do some really

00:29:55.246 --> 00:29:56.416
unbelievable things with this

00:29:56.416 --> 00:29:57.316
new API.

00:29:57.316 --> 00:30:00.156
So I'd like to shift attention

00:30:00.156 --> 00:30:01.406
now again and talk about

00:30:01.406 --> 00:30:01.996
performance.

00:30:02.446 --> 00:30:04.106
So as I mentioned before,

00:30:04.106 --> 00:30:05.656
Natural Language is available

00:30:05.936 --> 00:30:08.166
across all Apple platforms, and

00:30:08.166 --> 00:30:10.226
it also offers you what we call

00:30:10.226 --> 00:30:12.296
as standardized text processing.

00:30:12.646 --> 00:30:14.296
So let's take a moment again to

00:30:14.296 --> 00:30:15.636
understand what we mean by this.

00:30:16.426 --> 00:30:17.686
Now if you were to look at a

00:30:17.686 --> 00:30:18.876
conventional machine learning

00:30:18.876 --> 00:30:20.786
pipeline that didn't use Create

00:30:20.786 --> 00:30:22.236
ML, where would you start?

00:30:22.346 --> 00:30:23.526
You would start with some amount

00:30:23.526 --> 00:30:24.336
of training data.

00:30:25.346 --> 00:30:26.136
You would take this training

00:30:26.136 --> 00:30:26.426
data.

00:30:26.426 --> 00:30:27.436
You would tokenize this data.

00:30:27.436 --> 00:30:28.716
You'd probably extract some

00:30:28.716 --> 00:30:29.246
features.

00:30:29.506 --> 00:30:30.896
This is really important for

00:30:30.896 --> 00:30:32.076
languages like Chinese and

00:30:32.076 --> 00:30:33.676
Japanese where tokenization is

00:30:33.676 --> 00:30:34.286
very important.

00:30:34.926 --> 00:30:36.386
You would throw that into your

00:30:36.386 --> 00:30:37.236
favorite machine learning

00:30:37.236 --> 00:30:40.236
toolkit, and you'd get a machine

00:30:40.236 --> 00:30:41.516
learning model out of it.

00:30:41.966 --> 00:30:43.226
Now in order to use that machine

00:30:43.226 --> 00:30:44.196
learning model on an Apple

00:30:44.196 --> 00:30:45.756
device, you'd have to convert

00:30:45.756 --> 00:30:47.146
that into a Core ML model.

00:30:47.606 --> 00:30:48.736
So what would you do?

00:30:48.906 --> 00:30:49.716
You would use a Core ML

00:30:49.716 --> 00:30:50.746
converter to do this.

00:30:51.376 --> 00:30:53.176
This is sort of the training

00:30:53.176 --> 00:30:55.426
procedure in order to get from

00:30:55.426 --> 00:30:57.386
data to a model and deploy it on

00:30:57.386 --> 00:30:59.896
an Apple device.

00:30:59.896 --> 00:31:02.486
Now, at inference time, what you

00:31:02.486 --> 00:31:04.876
do is you drop the model in your

00:31:05.186 --> 00:31:06.266
app, but that's not it.

00:31:07.216 --> 00:31:09.406
You also have to make sure that

00:31:09.406 --> 00:31:10.386
you write the code for

00:31:10.386 --> 00:31:11.586
tokenization and feature

00:31:11.586 --> 00:31:13.336
extraction that is consistent

00:31:13.336 --> 00:31:14.626
with what happened at training

00:31:15.996 --> 00:31:16.136
time.

00:31:16.596 --> 00:31:17.956
It's a lot of effort because you

00:31:17.956 --> 00:31:19.686
have to think about maximizing

00:31:19.686 --> 00:31:20.836
the fidelity of your model.

00:31:20.836 --> 00:31:22.776
It's absolutely important that

00:31:22.776 --> 00:31:24.086
the tokenization featured

00:31:24.086 --> 00:31:26.066
extraction is identical at both

00:31:26.066 --> 00:31:26.996
training and inference time.

00:31:27.916 --> 00:31:29.486
But now with the use of Natural

00:31:29.486 --> 00:31:30.506
Language, you can completely

00:31:30.506 --> 00:31:31.246
obviate this.

00:31:31.516 --> 00:31:34.096
So if you look at the sequence

00:31:34.096 --> 00:31:35.216
at training time, you have

00:31:35.216 --> 00:31:35.886
training data.

00:31:37.276 --> 00:31:38.526
You just pass it to Create ML

00:31:38.596 --> 00:31:39.506
through the APIs that we've

00:31:39.506 --> 00:31:40.276
discussed so far.

00:31:41.176 --> 00:31:42.916
Create ML calls Natural Language

00:31:42.956 --> 00:31:44.136
under the hood, which does the

00:31:44.136 --> 00:31:45.986
tokenization feature extraction,

00:31:46.356 --> 00:31:47.316
chooses the machine learning

00:31:47.316 --> 00:31:49.456
library, does all the work, and

00:31:49.456 --> 00:31:51.456
returns a model which is a Core

00:31:51.456 --> 00:31:52.866
ML model.

00:31:53.076 --> 00:31:54.366
Now at inference time, what you

00:31:54.366 --> 00:31:56.236
do is you still drop this model

00:31:56.236 --> 00:31:58.876
in your app, but you don't have

00:31:58.876 --> 00:32:00.146
to worry about tokenization

00:32:00.146 --> 00:32:01.286
feature extraction or anything

00:32:01.286 --> 00:32:01.496
else.

00:32:01.706 --> 00:32:03.236
In fact, you don't have to write

00:32:03.236 --> 00:32:04.376
a single line of code because

00:32:04.636 --> 00:32:06.446
Natural Language does all of

00:32:06.446 --> 00:32:07.036
that for you.

00:32:07.356 --> 00:32:08.916
You just focus on your app and

00:32:08.916 --> 00:32:10.296
your task and simply drag and

00:32:10.296 --> 00:32:11.176
drop the model in.

00:32:11.636 --> 00:32:15.026
The other aspect of Natural

00:32:15.026 --> 00:32:16.226
Language as I mentioned before

00:32:16.296 --> 00:32:17.856
is it's optimized for Apple

00:32:17.856 --> 00:32:19.916
hardware and for model sizes.

00:32:20.036 --> 00:32:21.626
So let's look at this through a

00:32:21.626 --> 00:32:22.586
couple of examples.

00:32:23.276 --> 00:32:25.066
So Doug talked about named

00:32:25.066 --> 00:32:26.556
entity recognition and chunking,

00:32:27.096 --> 00:32:28.146
and here are two different

00:32:28.146 --> 00:32:28.746
benchmarks.

00:32:28.746 --> 00:32:30.876
So these are models that we

00:32:30.876 --> 00:32:32.726
built using an open source tool

00:32:32.726 --> 00:32:34.396
kit called CRF Suite, and

00:32:34.396 --> 00:32:35.336
through Natural Language.

00:32:35.716 --> 00:32:36.706
The models were built from

00:32:36.776 --> 00:32:38.856
identical training data and

00:32:38.856 --> 00:32:40.346
tested on identical test data.

00:32:40.856 --> 00:32:41.906
The same sort of features were

00:32:41.906 --> 00:32:42.306
used.

00:32:42.496 --> 00:32:43.836
The accuracy obtained by both

00:32:43.836 --> 00:32:45.066
these models is the same.

00:32:45.546 --> 00:32:47.316
But you look at the model sizes

00:32:47.316 --> 00:32:48.496
that Natural Language is able to

00:32:48.496 --> 00:32:48.886
generate.

00:32:49.446 --> 00:32:50.926
It's simply just about 1.4

00:32:50.926 --> 00:32:53.076
megabytes of data size, model

00:32:53.076 --> 00:32:53.936
size for named entity

00:32:53.936 --> 00:32:55.576
recognition and 1.8 megabytes

00:32:55.576 --> 00:32:56.076
for chunking.

00:32:56.576 --> 00:32:57.916
That saves you an enormous

00:32:57.916 --> 00:32:59.296
amount of space within your app

00:32:59.296 --> 00:33:00.056
to do other things.

00:33:00.596 --> 00:33:03.976
In terms of machine learning

00:33:03.976 --> 00:33:06.586
algorithms, we support two

00:33:06.586 --> 00:33:07.516
different options.

00:33:07.966 --> 00:33:09.636
We can specify this for text

00:33:09.636 --> 00:33:10.216
classification.

00:33:10.216 --> 00:33:11.416
So for text classification, we

00:33:11.416 --> 00:33:12.486
have two different choices.

00:33:12.966 --> 00:33:14.326
One is maxEnt, which is an

00:33:14.326 --> 00:33:15.506
abbreviation for Maximum

00:33:15.506 --> 00:33:15.956
Entropy.

00:33:16.586 --> 00:33:18.596
In NLP, we call maxEnt is

00:33:18.596 --> 00:33:19.576
essentially a multinomial

00:33:19.576 --> 00:33:20.666
logistic regression model.

00:33:20.906 --> 00:33:22.326
We just call it Maximum Entropy

00:33:22.326 --> 00:33:22.986
in NLP feed.

00:33:23.836 --> 00:33:25.666
The other one is CRF, which is

00:33:25.666 --> 00:33:27.046
an abbreviation for Conditional

00:33:27.046 --> 00:33:27.546
Random Feed.

00:33:28.336 --> 00:33:29.606
The choice of these two

00:33:29.606 --> 00:33:30.916
algorithms really depends upon

00:33:30.916 --> 00:33:31.496
your task.

00:33:31.946 --> 00:33:34.026
So we encourage you to try both

00:33:34.026 --> 00:33:35.426
these options, build the models.

00:33:35.426 --> 00:33:38.556
Now in terms of word tagging,

00:33:38.966 --> 00:33:40.316
that is one default option,

00:33:40.346 --> 00:33:41.386
which is a conditional random

00:33:41.386 --> 00:33:41.626
feed.

00:33:41.996 --> 00:33:43.496
When you instantiate an ML word

00:33:43.566 --> 00:33:46.146
tagger, specify data to it, the

00:33:46.146 --> 00:33:48.176
default model that you get is a

00:33:48.176 --> 00:33:49.096
conditional random feed.

00:33:49.956 --> 00:33:51.686
Now as I mentioned, the choice

00:33:51.686 --> 00:33:52.736
of these algorithms really

00:33:52.736 --> 00:33:54.626
depends on your task, but what

00:33:54.626 --> 00:33:56.626
I'd like to emphasize is sort of

00:33:56.626 --> 00:33:58.196
draw [inaudible] between your

00:33:58.196 --> 00:33:59.536
conventional development

00:33:59.536 --> 00:33:59.996
process.

00:34:00.316 --> 00:34:01.496
So when you have an idea for an

00:34:01.496 --> 00:34:02.836
app, you go through a

00:34:02.836 --> 00:34:04.136
development cycle, right.

00:34:04.226 --> 00:34:05.676
So you can think of machine

00:34:05.676 --> 00:34:07.196
learning to be a very similar

00:34:07.246 --> 00:34:08.136
sort of a work flow.

00:34:08.235 --> 00:34:10.166
Where do you start, you start

00:34:10.166 --> 00:34:12.416
with data, and then you have

00:34:12.416 --> 00:34:14.196
data, you have to ask a couple

00:34:14.196 --> 00:34:14.876
of questions.

00:34:14.876 --> 00:34:16.565
You have to validate your

00:34:16.565 --> 00:34:17.186
training data.

00:34:17.315 --> 00:34:18.735
You have to make sure that there

00:34:18.735 --> 00:34:20.166
are no spurious examples in your

00:34:20.166 --> 00:34:21.315
data, and it's not tainted.

00:34:22.275 --> 00:34:23.666
Once you do that, you can

00:34:23.666 --> 00:34:24.896
inspect the number of training

00:34:24.966 --> 00:34:26.315
instances per class.

00:34:26.626 --> 00:34:27.735
Let's say that your training a

00:34:27.735 --> 00:34:29.206
sentiment classification model,

00:34:29.416 --> 00:34:30.646
and you have a thousand examples

00:34:30.646 --> 00:34:31.775
for positive sentiment, you have

00:34:31.856 --> 00:34:32.926
five examples for negative

00:34:32.926 --> 00:34:33.406
sentiment.

00:34:33.916 --> 00:34:36.606
You can't train a robust model

00:34:36.606 --> 00:34:37.556
that can determine or

00:34:37.556 --> 00:34:38.616
distinguish between those two

00:34:38.616 --> 00:34:39.196
classes.

00:34:39.565 --> 00:34:40.896
You have to make sure that the

00:34:40.896 --> 00:34:42.146
training samples for each of

00:34:42.146 --> 00:34:43.226
those classes are reasonably

00:34:43.226 --> 00:34:43.775
balanced.

00:34:44.585 --> 00:34:46.436
So once you do that with data,

00:34:46.706 --> 00:34:48.226
the next step is training.

00:34:48.536 --> 00:34:50.025
As I mentioned before, our

00:34:50.025 --> 00:34:51.446
recommendation is that you run

00:34:51.446 --> 00:34:52.396
the different options that are

00:34:52.396 --> 00:34:54.525
available and figure out what is

00:34:54.525 --> 00:34:56.866
good, but how do you define what

00:34:56.866 --> 00:34:57.246
is good?

00:34:57.686 --> 00:34:59.566
You have to evaluate the model

00:34:59.766 --> 00:35:00.776
in order to figure out what

00:35:00.776 --> 00:35:01.856
suits your application.

00:35:01.926 --> 00:35:03.376
So the next step here in the

00:35:03.376 --> 00:35:05.236
work flow is evaluation.

00:35:06.956 --> 00:35:09.466
Evaluation in convention

00:35:09.466 --> 00:35:10.356
[inaudible] for machine learning

00:35:10.356 --> 00:35:11.366
is that when you procure your

00:35:11.366 --> 00:35:13.326
training data, you split your

00:35:13.326 --> 00:35:15.366
data into training set, into a

00:35:15.366 --> 00:35:17.056
validation set, and into a test

00:35:17.056 --> 00:35:18.836
set, and you typically tune the

00:35:18.836 --> 00:35:20.106
parameters of the algorithm

00:35:20.106 --> 00:35:21.566
using the validation set, and

00:35:21.566 --> 00:35:22.686
you test it on the test set.

00:35:22.956 --> 00:35:24.126
So we encourage you to do the

00:35:24.126 --> 00:35:25.606
same thing, apply the same sort

00:35:25.606 --> 00:35:27.166
of guidelines that have stood

00:35:27.166 --> 00:35:28.286
machine learning in good stead

00:35:28.286 --> 00:35:29.016
for a long time.

00:35:29.556 --> 00:35:31.026
The other thing that we also

00:35:31.026 --> 00:35:32.866
encourage you to do is test on

00:35:32.866 --> 00:35:33.796
out-of-domain data.

00:35:34.126 --> 00:35:35.066
What do I mean by this?

00:35:35.496 --> 00:35:37.156
So when you have an idea for an

00:35:37.156 --> 00:35:38.586
app, you think of a certain type

00:35:38.586 --> 00:35:39.756
of data that is going to be

00:35:39.826 --> 00:35:41.246
ingested by your machine

00:35:41.246 --> 00:35:42.496
learning model.

00:35:42.496 --> 00:35:43.836
Now let's say you're building an

00:35:43.836 --> 00:35:46.056
app for hotel reviews, and you

00:35:46.056 --> 00:35:48.806
want to classify hotel reviews

00:35:48.806 --> 00:35:50.466
into different sorts of ratings.

00:35:50.706 --> 00:35:53.186
And the user throws a data that

00:35:53.186 --> 00:35:54.926
is completely out of domain.

00:35:54.926 --> 00:35:56.106
Perhaps it's something to do

00:35:56.106 --> 00:35:57.856
with a restaurant review or a

00:35:57.856 --> 00:35:59.446
movie review, is your model

00:35:59.446 --> 00:36:01.306
robust enough to handle it.

00:36:01.646 --> 00:36:02.646
That's a question that you ought

00:36:02.646 --> 00:36:03.366
to ask yourself.

00:36:04.006 --> 00:36:06.066
And the final step is well in a

00:36:06.166 --> 00:36:07.156
conventional development

00:36:07.156 --> 00:36:09.086
workflow you write patches, you

00:36:09.086 --> 00:36:11.516
fix bugs, and you update your

00:36:11.516 --> 00:36:11.656
app.

00:36:12.406 --> 00:36:13.576
How do you do that with machine

00:36:13.576 --> 00:36:13.846
learning?

00:36:14.096 --> 00:36:17.686
Well, the way to do that or fix

00:36:17.956 --> 00:36:19.416
issues with machine learning is

00:36:19.416 --> 00:36:21.276
to find out where your models do

00:36:21.276 --> 00:36:22.876
not perform well, and you have

00:36:22.876 --> 00:36:24.076
to supplement it with the right

00:36:24.076 --> 00:36:24.706
sort of data.

00:36:25.206 --> 00:36:26.776
By adding data and retraining

00:36:26.776 --> 00:36:28.346
your model, you can essentially

00:36:28.346 --> 00:36:29.716
get a new model out.

00:36:29.716 --> 00:36:31.046
So it's, as I mentioned, it's

00:36:31.046 --> 00:36:32.266
very similar to sort of the

00:36:32.266 --> 00:36:34.196
development workflow, and they

00:36:34.266 --> 00:36:34.676
are very [inaudible].

00:36:34.676 --> 00:36:36.306
So you can think of it as part

00:36:36.306 --> 00:36:37.786
of your fabric if you're

00:36:38.176 --> 00:36:39.466
employing machine learning

00:36:39.466 --> 00:36:40.906
models as part of your app, you

00:36:40.906 --> 00:36:42.596
can just combine it with the

00:36:42.596 --> 00:36:43.506
word process itself.

00:36:44.006 --> 00:36:46.876
The last thing I'd like to

00:36:46.876 --> 00:36:48.736
emphasize here is privacy.

00:36:49.526 --> 00:36:50.706
So everything that you saw in

00:36:50.706 --> 00:36:53.086
this session, all of the machine

00:36:53.086 --> 00:36:54.576
learning and Natural Language

00:36:54.576 --> 00:36:56.726
processing happens completely on

00:36:56.726 --> 00:36:57.146
device.

00:36:57.946 --> 00:36:59.246
So we at Apple take privacy

00:36:59.246 --> 00:37:01.516
really seriously, and this is a

00:37:01.516 --> 00:37:03.216
remarkable opportunity to use

00:37:03.216 --> 00:37:04.456
machine learning completely on

00:37:04.456 --> 00:37:05.546
device to protect user's

00:37:05.546 --> 00:37:05.996
privacy.

00:37:06.226 --> 00:37:09.126
So in that vein, Natural

00:37:09.126 --> 00:37:10.716
Language is another step towards

00:37:10.716 --> 00:37:11.976
privacy preserving machine

00:37:11.976 --> 00:37:13.556
learning but in this case apply

00:37:13.556 --> 00:37:14.846
to NLP.

00:37:15.916 --> 00:37:19.266
So in summary, we talked about a

00:37:19.266 --> 00:37:20.986
new framework called Natural

00:37:20.986 --> 00:37:21.746
Language framework.

00:37:22.126 --> 00:37:23.726
It's tightly integrated with the

00:37:23.726 --> 00:37:24.936
Apple machine learning

00:37:24.936 --> 00:37:25.626
[inaudible].

00:37:25.626 --> 00:37:27.196
You can now train models using

00:37:27.196 --> 00:37:29.536
Create ML and then use those

00:37:29.536 --> 00:37:30.906
models either with the Core ML

00:37:30.906 --> 00:37:32.816
APIs or with Natural Language.

00:37:33.826 --> 00:37:35.446
The models that we generate

00:37:35.446 --> 00:37:36.996
using Natural Language and the

00:37:36.996 --> 00:37:38.386
APIs are highly performed and

00:37:38.386 --> 00:37:40.226
optimized on Apple hardware

00:37:40.326 --> 00:37:41.516
across all the platforms.

00:37:41.976 --> 00:37:44.866
And finally, it supports privacy

00:37:45.026 --> 00:37:46.066
because all of the machine

00:37:46.066 --> 00:37:47.706
learning in NLP happens on

00:37:47.706 --> 00:37:48.296
user's device.

00:37:48.916 --> 00:37:52.076
So there's more information

00:37:52.076 --> 00:37:52.376
here.

00:37:52.376 --> 00:37:53.836
We have a Natural Language lab

00:37:53.836 --> 00:37:55.396
tomorrow, so we encourage you to

00:37:55.396 --> 00:37:57.016
try out these APIs and come talk

00:37:57.016 --> 00:37:58.726
to us and ask us questions about

00:37:58.726 --> 00:38:00.096
where you'd like enhancements or

00:38:00.096 --> 00:38:01.136
perhaps some sort of

00:38:01.136 --> 00:38:02.256
consultation with respect to

00:38:02.256 --> 00:38:03.156
your app.

00:38:03.666 --> 00:38:04.766
We also have a machine learning

00:38:04.766 --> 00:38:06.596
get together, and there's a

00:38:06.936 --> 00:38:08.406
subsequent [inaudible] Create ML

00:38:08.406 --> 00:38:09.666
lab that's happening right now.

00:38:10.046 --> 00:38:11.476
So you can continue coming and

00:38:11.476 --> 00:38:12.856
talking to us as part of that

00:38:12.856 --> 00:38:13.126
lab.

00:38:13.766 --> 00:38:15.466
Thank you for your attention.

00:38:15.566 --> 00:38:15.746
Thanks.

00:38:16.016 --> 00:38:18.000
[ Applause ]