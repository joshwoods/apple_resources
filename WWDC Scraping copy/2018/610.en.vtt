WEBVTT

00:00:07.516 --> 00:00:16.500
[ Music ]

00:00:19.516 --> 00:00:25.500
[ Applause ]

00:00:26.456 --> 00:00:27.606
>> Hello, everybody.

00:00:27.986 --> 00:00:29.526
I'm very excited to be here

00:00:29.526 --> 00:00:31.446
today to talk about

00:00:31.446 --> 00:00:34.326
understanding ARKit Tracking and

00:00:34.326 --> 00:00:36.496
Detection to empower you to

00:00:36.496 --> 00:00:38.796
create great augmented reality

00:00:38.796 --> 00:00:39.576
experiences.

00:00:40.596 --> 00:00:42.316
My name is Marion and I'm from

00:00:42.346 --> 00:00:43.266
the ARKit Team.

00:00:43.266 --> 00:00:44.756
And what about you?

00:00:46.126 --> 00:00:47.786
Are you an experienced ARKit

00:00:47.786 --> 00:00:49.206
developer, already, but you are

00:00:49.206 --> 00:00:50.736
interested in what's going on

00:00:50.736 --> 00:00:51.276
under the hood?

00:00:51.896 --> 00:00:53.316
Then, this talk is for you.

00:00:53.316 --> 00:00:56.596
Or you may be new to ARKit.

00:00:57.546 --> 00:00:59.606
Then, you'll learn different

00:00:59.606 --> 00:01:01.046
kind of tracking technologies,

00:01:01.206 --> 00:01:02.876
as well as some basics and

00:01:02.966 --> 00:01:04.676
terminology used in augmented

00:01:04.676 --> 00:01:06.756
reality, which will then help

00:01:06.756 --> 00:01:08.176
you to create your very own

00:01:08.176 --> 00:01:09.416
first augmented reality

00:01:09.416 --> 00:01:10.016
experience.

00:01:10.726 --> 00:01:14.586
So, let's get started.

00:01:15.106 --> 00:01:17.926
What's tracking?

00:01:18.066 --> 00:01:19.536
Tracking provides your camera

00:01:19.836 --> 00:01:22.906
viewing position and orientation

00:01:23.156 --> 00:01:24.956
into your physical environment,

00:01:25.376 --> 00:01:26.806
which will then allow you to

00:01:26.806 --> 00:01:29.036
augment virtual content into

00:01:29.036 --> 00:01:30.096
your camera's view.

00:01:31.146 --> 00:01:33.656
In this video, for example, the

00:01:33.696 --> 00:01:35.836
front table and the chairs is

00:01:35.836 --> 00:01:39.206
virtual content augmented on top

00:01:39.926 --> 00:01:41.416
of the real physical terrace.

00:01:42.756 --> 00:01:44.006
This, by the way, is Ikea.

00:01:45.296 --> 00:01:47.186
And the virtual content will

00:01:47.186 --> 00:01:48.926
appear always virtually correct.

00:01:49.746 --> 00:01:52.086
Correct placement, correct size,

00:01:52.686 --> 00:01:53.816
and correct perspective

00:01:53.816 --> 00:01:54.516
appearance.

00:01:55.066 --> 00:01:56.836
So, different tracking

00:01:56.836 --> 00:01:58.906
technologies are just providing

00:01:59.076 --> 00:02:00.606
a difference reference system

00:02:00.906 --> 00:02:01.586
for the camera.

00:02:01.816 --> 00:02:03.556
Meaning the camera with respect

00:02:03.556 --> 00:02:05.246
to your world, the camera with

00:02:05.246 --> 00:02:07.106
respect to an image, or maybe, a

00:02:07.106 --> 00:02:07.916
3D object.

00:02:09.086 --> 00:02:11.186
And we'll talk about those

00:02:11.296 --> 00:02:12.396
different kind of tracking

00:02:12.396 --> 00:02:14.116
technologies in the next hour,

00:02:14.936 --> 00:02:16.476
such that you'll be able to make

00:02:16.476 --> 00:02:17.626
the right choice for your

00:02:17.626 --> 00:02:18.796
specific use case.

00:02:19.216 --> 00:02:22.296
We'll talk about the already

00:02:22.296 --> 00:02:24.196
existing AR technologies'

00:02:24.486 --> 00:02:26.726
Orientation Tracking, World

00:02:26.866 --> 00:02:28.876
Tracking, and Plane Detection.

00:02:29.616 --> 00:02:31.376
Before we then have a close look

00:02:31.496 --> 00:02:33.466
at our new tracking and

00:02:33.466 --> 00:02:36.536
detection technologies which

00:02:36.536 --> 00:02:38.076
came out now with ARKit 2.

00:02:38.696 --> 00:02:40.316
Which are saving and loading

00:02:40.316 --> 00:02:43.126
maps, image tracking, and object

00:02:43.186 --> 00:02:43.776
detection.

00:02:45.266 --> 00:02:46.926
But before diving deep into

00:02:46.926 --> 00:02:48.886
those technologies, let's start

00:02:48.946 --> 00:02:51.416
with a very short recap of ARKit

00:02:51.416 --> 00:02:52.646
like on a high level.

00:02:53.176 --> 00:02:54.166
This is, specifically,

00:02:54.166 --> 00:02:55.936
interesting if you are new to

00:02:55.936 --> 00:02:56.276
ARKit.

00:02:56.786 --> 00:03:00.556
So, the first thing you'll do is

00:03:00.556 --> 00:03:01.826
create an ARSession.

00:03:02.496 --> 00:03:04.576
An ARSession is the object that

00:03:04.576 --> 00:03:06.946
handles everything from

00:03:06.946 --> 00:03:09.686
configuring to running the AR

00:03:09.686 --> 00:03:11.226
technologies.

00:03:11.476 --> 00:03:14.226
And also, returning the results

00:03:14.226 --> 00:03:15.696
of the AR technologies.

00:03:16.196 --> 00:03:19.406
You then, have to describe what

00:03:19.496 --> 00:03:20.796
kind of technologies you

00:03:20.856 --> 00:03:21.866
actually want to run.

00:03:22.266 --> 00:03:23.256
Like, what kind of tracking

00:03:23.256 --> 00:03:25.136
technologies and what kind of

00:03:25.136 --> 00:03:26.376
features should be enabled, like

00:03:26.436 --> 00:03:28.096
Plane Detection, for example.

00:03:28.966 --> 00:03:32.506
You'll then, take this specific

00:03:32.506 --> 00:03:35.406
ARConfiguration and call run

00:03:36.256 --> 00:03:39.476
method on your instance of the

00:03:39.476 --> 00:03:40.116
ARSession.

00:03:41.576 --> 00:03:43.206
Then, the ARSession, internally,

00:03:44.306 --> 00:03:47.336
will start configuring an

00:03:47.336 --> 00:03:49.596
AVCaptureSession to start

00:03:50.096 --> 00:03:52.716
receiving the images, as well as

00:03:52.716 --> 00:03:55.096
a Core Motion  manager to begin

00:03:55.096 --> 00:03:56.816
receiving the motion sensor, so,

00:03:57.326 --> 00:03:57.616
data.

00:03:57.616 --> 00:03:58.626
So, this is, basically, the

00:03:58.626 --> 00:04:01.496
built-in input system from your

00:04:01.496 --> 00:04:02.666
device for ARKit.

00:04:04.066 --> 00:04:07.066
Now, after processing the

00:04:07.066 --> 00:04:09.306
results are returned in ARFrames

00:04:09.306 --> 00:04:10.926
at 60 frames per second.

00:04:12.126 --> 00:04:14.226
An ARFrame is a snapshot in time

00:04:14.226 --> 00:04:15.396
which gives you everything you

00:04:15.396 --> 00:04:17.055
need to render your augmented

00:04:17.055 --> 00:04:17.875
reality scene.

00:04:18.366 --> 00:04:20.776
Like, the captured camera image,

00:04:20.776 --> 00:04:22.326
which would then be, which will

00:04:22.326 --> 00:04:23.576
be rendered in the background of

00:04:23.576 --> 00:04:25.176
your augmented reality scenario.

00:04:25.826 --> 00:04:27.136
As well as a track camera

00:04:27.136 --> 00:04:29.456
motion, which will then be

00:04:29.456 --> 00:04:31.256
applied to your virtual camera

00:04:31.706 --> 00:04:34.406
to render the virtual content

00:04:34.446 --> 00:04:36.746
from the same perspective as the

00:04:36.746 --> 00:04:37.586
physical camera.

00:04:38.766 --> 00:04:40.426
It also contains information

00:04:40.876 --> 00:04:42.086
about the environment.

00:04:42.086 --> 00:04:43.146
Like, for example, detected

00:04:43.146 --> 00:04:43.536
planes.

00:04:43.536 --> 00:04:46.806
So, let's now start with our

00:04:46.806 --> 00:04:48.436
first tracking technology and

00:04:48.436 --> 00:04:49.216
build up from there.

00:04:51.586 --> 00:04:53.176
Orientation Tracking.

00:04:54.386 --> 00:04:56.396
Orientation Tracking tracks,

00:04:56.536 --> 00:04:56.976
guess what?

00:04:57.176 --> 00:04:58.156
Orientation.

00:04:58.676 --> 00:05:00.746
Meaning it tracks the rotation,

00:05:00.746 --> 00:05:01.226
only.

00:05:02.136 --> 00:05:03.206
You can think about it as you

00:05:03.206 --> 00:05:05.456
can only use your hat to view

00:05:05.456 --> 00:05:06.916
virtual content, which also,

00:05:07.156 --> 00:05:09.046
only allows rotation.

00:05:09.966 --> 00:05:11.716
Meaning you can experience the

00:05:11.866 --> 00:05:13.406
virtual content from the same

00:05:13.406 --> 00:05:15.656
positional point of view, but no

00:05:15.656 --> 00:05:17.276
change in the position is going

00:05:17.276 --> 00:05:17.856
to be tracked.

00:05:19.596 --> 00:05:21.546
The rotation data is tracked

00:05:21.546 --> 00:05:22.836
around three axles.

00:05:22.946 --> 00:05:24.276
That's why it's also, sometimes,

00:05:24.316 --> 00:05:25.676
called the three degrees of

00:05:25.676 --> 00:05:26.416
freedom tracking.

00:05:26.416 --> 00:05:28.926
You can use it, for example, in

00:05:28.926 --> 00:05:30.846
a spherical virtual environment.

00:05:30.846 --> 00:05:32.256
Like, for example, experience a

00:05:32.256 --> 00:05:35.066
360-degree video, in which the

00:05:35.066 --> 00:05:36.496
virtual content can be viewed

00:05:36.496 --> 00:05:38.116
from the same positional point.

00:05:39.346 --> 00:05:41.226
You can also, use it to augment

00:05:41.226 --> 00:05:43.196
objects that are very far away.

00:05:44.336 --> 00:05:46.296
Orientation Tracking is not

00:05:46.396 --> 00:05:48.236
suited for physical world

00:05:48.236 --> 00:05:49.746
augmentation, in which you want

00:05:49.746 --> 00:05:50.886
to view the content from

00:05:50.886 --> 00:05:52.666
different points of views.

00:05:54.226 --> 00:05:56.416
So, let's now have a look at

00:05:56.556 --> 00:05:58.016
what happens under the hood when

00:05:58.016 --> 00:05:59.486
Orientation Tracking is running.

00:06:00.036 --> 00:06:02.676
It is, actually, quite simple.

00:06:03.106 --> 00:06:05.016
It only uses the rotation data

00:06:05.016 --> 00:06:07.166
from core motion, which applies

00:06:07.326 --> 00:06:09.146
sensor fusion to the motion

00:06:09.146 --> 00:06:09.986
sensors data.

00:06:11.426 --> 00:06:13.626
As motion data is provided at a

00:06:13.756 --> 00:06:15.696
higher frequency than the camera

00:06:15.696 --> 00:06:17.936
image, Orientation Tracking

00:06:18.206 --> 00:06:20.736
takes the latest motion data

00:06:20.736 --> 00:06:22.616
from Core Motion, once the camera

00:06:22.616 --> 00:06:23.636
image is available.

00:06:23.776 --> 00:06:25.766
And then, returns both results

00:06:26.086 --> 00:06:27.206
in an ARFrame.

00:06:27.526 --> 00:06:28.066
So, that's it.

00:06:28.126 --> 00:06:28.956
Very simple.

00:06:29.686 --> 00:06:31.726
So, please note that the camera

00:06:31.726 --> 00:06:33.266
feed is not processed in

00:06:33.266 --> 00:06:34.526
Orientation Tracking.

00:06:34.856 --> 00:06:35.956
Meaning there's no computer

00:06:35.956 --> 00:06:37.036
version under the hood here.

00:06:38.286 --> 00:06:40.376
Now, to run Orientation Tracking

00:06:40.986 --> 00:06:43.096
you only need to configure your

00:06:43.286 --> 00:06:45.876
ARSession with an AROrientation

00:06:45.876 --> 00:06:47.256
TrackingConfiguration.

00:06:48.266 --> 00:06:49.686
The results will then be

00:06:49.686 --> 00:06:52.216
returned in an ARCamera object

00:06:52.996 --> 00:06:55.116
provided by the ARFrames.

00:06:55.116 --> 00:06:57.926
Now, an ARCamera object always

00:06:57.926 --> 00:06:59.826
contains the transform, which in

00:06:59.826 --> 00:07:01.106
this case of Orientation

00:07:01.106 --> 00:07:02.936
Tracking, only contains the

00:07:02.936 --> 00:07:05.006
rotation data of your tracked

00:07:05.116 --> 00:07:06.016
physical camera.

00:07:07.096 --> 00:07:09.616
Alternatively, the rotation is

00:07:09.666 --> 00:07:11.596
also represented in eulerAngles.

00:07:12.276 --> 00:07:13.956
You can use whatever fits best

00:07:14.066 --> 00:07:14.306
to you.

00:07:16.866 --> 00:07:18.686
Let's now move over to more

00:07:18.686 --> 00:07:20.326
advanced tracking technologies.

00:07:21.156 --> 00:07:22.546
We'll start with World Tracking.

00:07:23.076 --> 00:07:25.406
World Tracking tracks your

00:07:25.676 --> 00:07:28.186
camera viewing orientation, and

00:07:28.186 --> 00:07:30.096
also, the change in position

00:07:30.316 --> 00:07:32.056
into your physical environment

00:07:32.326 --> 00:07:34.196
without any prior information

00:07:34.196 --> 00:07:35.226
about your environment.

00:07:36.266 --> 00:07:37.656
Here, you can see on the left

00:07:37.656 --> 00:07:41.316
side the real camera's view into

00:07:41.316 --> 00:07:42.766
the environment, while on the

00:07:42.766 --> 00:07:45.416
right side you see the tracked

00:07:45.546 --> 00:07:47.466
camera motion while exploring

00:07:47.466 --> 00:07:50.506
the world represented in the

00:07:50.506 --> 00:07:51.756
coordinate system.

00:07:52.986 --> 00:07:54.406
Let's now explain better, what

00:07:54.506 --> 00:07:55.466
happens here, when World

00:07:55.536 --> 00:07:56.376
Tracking is running.

00:07:56.896 --> 00:08:00.406
World Tracking uses a motion

00:08:00.406 --> 00:08:03.236
sensor, the motion data of your

00:08:03.236 --> 00:08:05.436
device's accelerometer and

00:08:05.436 --> 00:08:08.376
gyroscope to compute its change

00:08:08.376 --> 00:08:10.796
in orientation and translation

00:08:11.116 --> 00:08:12.436
on a high frequency.

00:08:14.706 --> 00:08:16.926
It also provides its information

00:08:17.116 --> 00:08:19.276
in correct scale in meters.

00:08:20.656 --> 00:08:23.056
In literature, just this part of

00:08:23.106 --> 00:08:24.306
the tracking system is also

00:08:24.306 --> 00:08:25.976
called Inertial Odometry.

00:08:27.076 --> 00:08:29.046
While this motion data provides

00:08:29.106 --> 00:08:31.026
good motion information for

00:08:31.026 --> 00:08:32.826
movement across small time

00:08:32.826 --> 00:08:34.226
intervals and whenever there's

00:08:34.275 --> 00:08:36.566
like, sudden movement, it does

00:08:36.645 --> 00:08:38.635
drift over larger time intervals

00:08:39.015 --> 00:08:40.456
as the data is not ideally

00:08:40.616 --> 00:08:42.126
precise and subject to

00:08:42.126 --> 00:08:43.296
cumulative errors.

00:08:44.496 --> 00:08:45.616
That's why it cannot be used

00:08:45.906 --> 00:08:47.446
just by its own for tracking.

00:08:48.036 --> 00:08:51.456
Now, to compensate this drift,

00:08:51.696 --> 00:08:53.416
World Tracking, additionally,

00:08:53.516 --> 00:08:55.506
applies a computer vision

00:08:55.506 --> 00:08:58.656
process in which it uses the

00:08:58.656 --> 00:08:59.606
camera frames.

00:09:00.706 --> 00:09:02.426
This technology provides a

00:09:02.506 --> 00:09:05.276
higher accuracy, but at the cost

00:09:05.276 --> 00:09:06.546
of computation time.

00:09:08.056 --> 00:09:10.176
Also, this technology is

00:09:10.226 --> 00:09:12.596
sensitive to fast camera motions

00:09:12.666 --> 00:09:14.396
and this results in motion blur

00:09:14.396 --> 00:09:15.296
in the camera frames.

00:09:16.516 --> 00:09:18.626
Now, this vision only part of

00:09:18.626 --> 00:09:20.926
the system is also called Visual

00:09:20.926 --> 00:09:21.666
Odometry.

00:09:22.016 --> 00:09:24.276
Now, by fusing those both

00:09:24.276 --> 00:09:26.576
systems, computer vision and

00:09:26.576 --> 00:09:28.916
motion, ARKit takes the best of

00:09:28.986 --> 00:09:30.016
those both systems.

00:09:30.646 --> 00:09:32.086
From computer vision, it takes

00:09:32.086 --> 00:09:34.116
a high accuracy over the larger

00:09:34.116 --> 00:09:34.946
time intervals.

00:09:35.566 --> 00:09:37.576
And from the motion data it

00:09:37.576 --> 00:09:39.586
takes the high update rates and

00:09:39.586 --> 00:09:41.356
good precision for the smaller

00:09:41.356 --> 00:09:43.446
time intervals, as well as the

00:09:43.446 --> 00:09:44.276
metric scale.

00:09:44.856 --> 00:09:47.456
Now, by combining those both

00:09:47.456 --> 00:09:49.446
systems World Tracking can skip

00:09:49.586 --> 00:09:51.036
the computer vision processing

00:09:51.246 --> 00:09:52.886
for some of those frames, while

00:09:52.886 --> 00:09:54.736
still keeping an efficient and

00:09:54.776 --> 00:09:55.966
responsive tracking.

00:09:56.956 --> 00:09:58.856
This frees CPU resources, which

00:09:58.856 --> 00:10:00.356
you can then, additionally, use

00:10:00.356 --> 00:10:00.956
for your apps.

00:10:02.876 --> 00:10:04.376
In Literature, this combined

00:10:04.376 --> 00:10:06.456
technology is also called Visual

00:10:06.506 --> 00:10:07.696
Inertial Odometry.

00:10:08.916 --> 00:10:11.456
Let's have a closer look at the

00:10:11.456 --> 00:10:13.306
visual part of it.

00:10:14.116 --> 00:10:15.926
So, within the computer version

00:10:15.926 --> 00:10:19.286
process interesting regions in

00:10:19.286 --> 00:10:21.096
the camera images are extracted,

00:10:21.356 --> 00:10:22.696
like here, the blue and the

00:10:22.696 --> 00:10:23.526
orange dot.

00:10:24.406 --> 00:10:26.006
And they are extracted such that

00:10:26.006 --> 00:10:27.496
they can robustly all to be

00:10:27.946 --> 00:10:30.246
extracted and other images of

00:10:30.286 --> 00:10:31.516
the same environment.

00:10:33.016 --> 00:10:34.096
Those interesting regions are

00:10:34.096 --> 00:10:35.166
also called features.

00:10:36.496 --> 00:10:37.616
Now, those features are then

00:10:37.616 --> 00:10:39.996
matched between multiple images

00:10:40.196 --> 00:10:42.326
over the camera stream based on

00:10:42.326 --> 00:10:43.686
their similarity and their

00:10:43.686 --> 00:10:44.326
appearance.

00:10:45.176 --> 00:10:46.716
And what then happens is pretty

00:10:46.716 --> 00:10:48.566
much how you are able to see 3D

00:10:48.566 --> 00:10:49.286
with your eyes.

00:10:50.176 --> 00:10:51.576
You have two of them and they

00:10:51.576 --> 00:10:53.516
are within the sidewise small

00:10:53.516 --> 00:10:54.226
distance.

00:10:55.056 --> 00:10:56.976
And this parallax between the

00:10:56.976 --> 00:10:58.796
eyes is important as this

00:10:58.796 --> 00:11:00.636
results in slightly different

00:11:00.636 --> 00:11:02.236
views into the environment,

00:11:02.606 --> 00:11:04.706
which allows you to see stereo

00:11:04.816 --> 00:11:06.056
and perceive the depth.

00:11:07.106 --> 00:11:08.406
And this is what ARKit now,

00:11:08.406 --> 00:11:10.176
also, does with the different

00:11:10.176 --> 00:11:12.076
views of the same camera stream

00:11:12.076 --> 00:11:12.956
during the process of

00:11:13.026 --> 00:11:14.156
triangulation.

00:11:14.736 --> 00:11:16.206
And it does it once there's

00:11:16.256 --> 00:11:18.046
enough parallax present.

00:11:18.896 --> 00:11:20.786
It computes the missing depth

00:11:20.786 --> 00:11:22.736
information for those matched

00:11:22.816 --> 00:11:23.306
features.

00:11:23.706 --> 00:11:26.826
Meaning those 2D features from

00:11:26.826 --> 00:11:28.556
the image are now reconstructed

00:11:28.556 --> 00:11:29.316
in 3D.

00:11:30.806 --> 00:11:32.066
Please, note that this

00:11:32.066 --> 00:11:34.476
reconstruction to be successful,

00:11:35.706 --> 00:11:37.536
the camera position must have

00:11:37.676 --> 00:11:39.776
changed by a translation to

00:11:39.776 --> 00:11:41.316
provide enough parallax.

00:11:42.356 --> 00:11:44.086
For example, with the sidewise

00:11:44.086 --> 00:11:44.626
movement.

00:11:44.966 --> 00:11:47.746
The pure rotation does not give

00:11:47.746 --> 00:11:48.856
enough information here.

00:11:50.536 --> 00:11:52.606
So, this is your first small map

00:11:52.606 --> 00:11:53.646
of your environment.

00:11:53.646 --> 00:11:55.826
In ARKit we call this a World

00:11:55.906 --> 00:11:56.136
map.

00:11:57.396 --> 00:11:59.826
In this same moment, also, the

00:11:59.826 --> 00:12:01.626
camera's positions and

00:12:01.626 --> 00:12:04.226
orientations of your sequences

00:12:04.226 --> 00:12:06.546
are computed, denoted with a C

00:12:06.546 --> 00:12:06.766
here.

00:12:07.476 --> 00:12:08.546
Meaning, your World Tracking

00:12:08.546 --> 00:12:09.396
just initialized.

00:12:09.396 --> 00:12:10.496
This is the moment of

00:12:10.526 --> 00:12:12.496
initialization of the tracking

00:12:12.496 --> 00:12:12.746
system.

00:12:12.746 --> 00:12:15.886
Please note that also in this

00:12:15.886 --> 00:12:17.326
moment of this initial

00:12:17.326 --> 00:12:19.216
reconstruction of the World map,

00:12:19.406 --> 00:12:21.246
the world origin was defined.

00:12:21.986 --> 00:12:23.676
And it is set to the first

00:12:23.886 --> 00:12:25.846
camera's origin of the

00:12:25.846 --> 00:12:27.326
triangulated frames.

00:12:28.046 --> 00:12:29.896
And it is also set to be gravity

00:12:29.896 --> 00:12:30.296
aligned.

00:12:31.056 --> 00:12:33.446
It's denoted with a W in the

00:12:34.096 --> 00:12:34.286
slides.

00:12:34.906 --> 00:12:35.786
So, you now have a small

00:12:35.786 --> 00:12:37.246
representation of your real

00:12:37.246 --> 00:12:39.366
environment reconstructed as a

00:12:39.366 --> 00:12:40.896
World map in its own world

00:12:40.896 --> 00:12:42.046
coordinates system.

00:12:42.836 --> 00:12:44.446
And you have your current camera

00:12:44.596 --> 00:12:46.646
tracked with respect to the same

00:12:46.646 --> 00:12:48.646
world coordinate system.

00:12:50.896 --> 00:12:53.186
You can now start adding virtual

00:12:53.186 --> 00:12:56.436
content to augment them into the

00:12:56.436 --> 00:12:57.056
camera's view.

00:12:58.656 --> 00:13:01.016
Now, to place virtual content

00:13:01.066 --> 00:13:03.416
correctly to an ARSession, you

00:13:03.416 --> 00:13:06.256
should use ARAnchors from ARKit,

00:13:06.636 --> 00:13:07.826
which are denoted with an A

00:13:07.826 --> 00:13:08.096
here.

00:13:09.536 --> 00:13:12.326
ARAnchors are reference points

00:13:12.536 --> 00:13:14.076
within this World map, within

00:13:14.076 --> 00:13:15.816
this world coordinates system.

00:13:16.486 --> 00:13:18.386
And you should use them because

00:13:18.386 --> 00:13:20.686
the World Tracking might update

00:13:20.686 --> 00:13:22.206
them during the tracking.

00:13:22.206 --> 00:13:23.636
Meaning that, also, all the

00:13:23.636 --> 00:13:25.336
virtual content that is assigned

00:13:25.336 --> 00:13:27.776
to it will be updated and

00:13:27.886 --> 00:13:31.626
correctly augmented into the

00:13:32.456 --> 00:13:32.746
camera's view.

00:13:32.746 --> 00:13:34.446
So, now that you've used the

00:13:34.446 --> 00:13:36.436
ARAnchors you can add virtual

00:13:36.466 --> 00:13:38.356
content to the anchor, which

00:13:38.386 --> 00:13:40.496
will them be augmented correctly

00:13:40.886 --> 00:13:44.116
into the current camera's view.

00:13:45.576 --> 00:13:48.676
From now on, this created 3D

00:13:48.676 --> 00:13:51.026
World map of your environment is

00:13:51.026 --> 00:13:52.526
your reference system for the

00:13:52.526 --> 00:13:53.236
World Tracking.

00:13:54.046 --> 00:13:55.506
It is used to reference new

00:13:55.506 --> 00:13:56.456
images against.

00:13:57.076 --> 00:13:58.796
And features are matched from

00:13:58.796 --> 00:14:01.806
image to image and triangulated.

00:14:02.666 --> 00:14:04.216
And at the same time, also, new

00:14:04.216 --> 00:14:05.776
robust features are extracted,

00:14:06.106 --> 00:14:08.246
matched, and triangulated, which

00:14:08.246 --> 00:14:10.496
are then extending your World

00:14:10.556 --> 00:14:10.786
map.

00:14:11.286 --> 00:14:13.346
Meaning ARKit is learning your

00:14:13.346 --> 00:14:14.036
environment.

00:14:15.926 --> 00:14:17.006
This then allows, again, the

00:14:17.006 --> 00:14:18.686
computation of tracking updates

00:14:18.946 --> 00:14:20.936
of the current camera's position

00:14:20.936 --> 00:14:21.956
and orientation.

00:14:23.086 --> 00:14:24.986
And finally, the correct

00:14:24.986 --> 00:14:26.796
augmentation into the current

00:14:26.796 --> 00:14:27.426
camera's view.

00:14:27.946 --> 00:14:31.966
While you continue to explore

00:14:31.966 --> 00:14:33.786
the world, World Tracking will

00:14:33.786 --> 00:14:35.706
continue to track your physical

00:14:35.706 --> 00:14:37.826
camera and continue to learn

00:14:38.076 --> 00:14:39.426
your physical environment.

00:14:40.506 --> 00:14:42.866
But over time, the augmentation

00:14:42.866 --> 00:14:45.506
might drift slightly, which can

00:14:45.506 --> 00:14:47.366
be noticed like you can see in

00:14:47.366 --> 00:14:49.096
the left image, in a small

00:14:49.096 --> 00:14:51.086
offset of the augmentation.

00:14:52.366 --> 00:14:54.736
This is because even small

00:14:55.216 --> 00:14:58.016
offsets, even small errors will

00:14:58.016 --> 00:14:59.786
become noticeable when

00:14:59.786 --> 00:15:01.496
accumulated over time.

00:15:03.486 --> 00:15:05.286
Now, when the device comes back

00:15:05.426 --> 00:15:07.216
to a similar view, which was

00:15:07.216 --> 00:15:09.036
already explored before, like

00:15:09.086 --> 00:15:10.956
for example, the starting point

00:15:10.956 --> 00:15:11.756
where we started the

00:15:11.756 --> 00:15:14.116
exploration, ARKit can perform

00:15:14.116 --> 00:15:15.846
another optimization step.

00:15:16.546 --> 00:15:18.086
And this addition makes, a

00:15:18.086 --> 00:15:19.496
Visual Intertial Odometry

00:15:19.496 --> 00:15:21.986
system, makes the system that

00:15:21.986 --> 00:15:24.176
ARKit supplies to a Visual

00:15:24.286 --> 00:15:26.206
Inertial SLAM System.

00:15:27.376 --> 00:15:28.826
So, let's bring back this first

00:15:28.916 --> 00:15:30.726
image where the World Tracking

00:15:30.726 --> 00:15:32.476
started the exploration.

00:15:33.956 --> 00:15:35.136
So, what happens now is that

00:15:35.136 --> 00:15:37.166
World Tracking will check how

00:15:37.166 --> 00:15:39.246
well the tracking information

00:15:39.446 --> 00:15:41.076
and the World map of the current

00:15:41.076 --> 00:15:43.666
view aligns with the past views,

00:15:43.926 --> 00:15:45.276
like the one from the beginning.

00:15:45.276 --> 00:15:48.586
And will then perform the

00:15:48.586 --> 00:15:51.886
optimization step and align the

00:15:52.066 --> 00:15:54.316
current information and the

00:15:54.316 --> 00:15:56.306
current World map with your real

00:15:56.306 --> 00:15:57.666
physical environment.

00:15:58.816 --> 00:16:00.256
Have you noticed that during

00:16:00.256 --> 00:16:01.946
this step, also the ARAnchor was

00:16:01.946 --> 00:16:02.536
updated?

00:16:03.006 --> 00:16:04.476
And that is the reason why you

00:16:04.476 --> 00:16:07.036
should use ARAnchors when adding

00:16:07.036 --> 00:16:08.426
virtual content to your

00:16:08.826 --> 00:16:09.436
scenario.

00:16:09.956 --> 00:16:14.396
In this video, you can see the

00:16:14.396 --> 00:16:16.956
same step again with a real

00:16:16.956 --> 00:16:17.716
camera feed.

00:16:18.116 --> 00:16:19.396
On the left side you see the

00:16:19.396 --> 00:16:20.736
camera's view into the

00:16:20.736 --> 00:16:22.596
environment, and also, features

00:16:22.596 --> 00:16:25.026
which are tracked in the images.

00:16:25.406 --> 00:16:26.986
And on the right side, you see a

00:16:26.986 --> 00:16:28.356
bird eye's view onto the

00:16:28.356 --> 00:16:30.596
scenario, showing what ARKit

00:16:30.596 --> 00:16:33.166
knows about it and showing the

00:16:34.016 --> 00:16:35.726
3D reconstruction of the

00:16:35.726 --> 00:16:36.386
environment.

00:16:36.996 --> 00:16:39.506
The colors of the points are

00:16:39.506 --> 00:16:41.346
just encoding the height of the

00:16:41.346 --> 00:16:43.306
reconstructed points with blue

00:16:43.306 --> 00:16:45.036
being the ground floor and red

00:16:45.096 --> 00:16:46.746
being the table and the chairs.

00:16:47.376 --> 00:16:51.216
Once the camera returns back to

00:16:51.216 --> 00:16:52.576
a similar view it has seen

00:16:52.576 --> 00:16:54.546
before, like here the starting

00:16:54.546 --> 00:16:56.636
point, ARKit will now apply this

00:16:56.636 --> 00:16:57.896
optimization step.

00:16:57.996 --> 00:16:59.436
So, just pay attention to the

00:16:59.436 --> 00:17:00.716
point cloud and the camera

00:17:00.796 --> 00:17:01.416
trajectory.

00:17:02.826 --> 00:17:04.106
Have you noticed the update?

00:17:04.556 --> 00:17:05.506
Let me show you, once more.

00:17:05.996 --> 00:17:10.866
This update aligns the ARKit

00:17:10.866 --> 00:17:12.175
knowledge with your real

00:17:12.286 --> 00:17:15.016
physical world, and also, the

00:17:15.016 --> 00:17:17.536
camera movement and results in

00:17:17.536 --> 00:17:19.425
the better augmentation for the

00:17:19.425 --> 00:17:20.626
coming camera frames.

00:17:21.955 --> 00:17:23.306
By the way, all those

00:17:23.306 --> 00:17:24.935
computations of World Tracking,

00:17:25.435 --> 00:17:27.425
and also, all this information

00:17:27.425 --> 00:17:28.886
about your learned environment,

00:17:29.346 --> 00:17:31.076
everything is done on your

00:17:31.076 --> 00:17:31.996
device only.

00:17:32.136 --> 00:17:33.496
And all this information, also,

00:17:33.496 --> 00:17:35.096
stays on your device only.

00:17:35.096 --> 00:17:37.836
So, how can you use this complex

00:17:37.836 --> 00:17:40.566
technology, now, in your app?

00:17:41.926 --> 00:17:45.606
It is actually quite simple.

00:17:45.716 --> 00:17:47.486
To run World Tracking you just

00:17:47.526 --> 00:17:49.766
configure your ARSession with an

00:17:49.816 --> 00:17:51.896
ARWorldTrackingConfiguration.

00:17:52.976 --> 00:17:55.376
Again, its results are returned

00:17:55.376 --> 00:17:57.336
in an ARCamera object of the

00:17:57.336 --> 00:17:57.956
ARFrame.

00:18:00.216 --> 00:18:03.636
An ARCamera object, again,

00:18:03.636 --> 00:18:05.626
contains the transform, which in

00:18:05.626 --> 00:18:06.946
this case of World Tracking

00:18:07.496 --> 00:18:08.806
contains, additionally, to the

00:18:08.806 --> 00:18:11.016
rotation, also, the translation

00:18:11.016 --> 00:18:12.116
of the track camera.

00:18:13.286 --> 00:18:15.106
Additionally, the ARCamera also

00:18:15.106 --> 00:18:16.886
contains information about the

00:18:16.886 --> 00:18:18.556
tracking state and

00:18:18.556 --> 00:18:19.746
trackingStateReason.

00:18:20.166 --> 00:18:22.366
This will provide some

00:18:22.366 --> 00:18:24.206
information about the current

00:18:24.306 --> 00:18:25.216
tracking quality.

00:18:26.736 --> 00:18:27.976
So, tracking quality.

00:18:28.516 --> 00:18:29.906
Have you ever experienced

00:18:30.016 --> 00:18:32.376
opening an AR app and the

00:18:32.376 --> 00:18:34.476
tracking worked very poorly or

00:18:34.476 --> 00:18:35.646
maybe it didn't work at all?

00:18:36.276 --> 00:18:37.346
How did that feel?

00:18:38.446 --> 00:18:39.846
Maybe frustrating?

00:18:39.846 --> 00:18:40.796
You might not open the app,

00:18:40.796 --> 00:18:41.166
again.

00:18:42.026 --> 00:18:43.566
So, how can you get a higher

00:18:43.566 --> 00:18:45.326
tracking quality for your app?

00:18:46.726 --> 00:18:48.626
For this, we need to understand

00:18:48.626 --> 00:18:49.846
the main factors that are

00:18:49.846 --> 00:18:51.016
influencing the tracking

00:18:51.016 --> 00:18:51.646
quality.

00:18:52.156 --> 00:18:53.436
And I want to highlight three of

00:18:53.476 --> 00:18:53.856
them here.

00:18:55.056 --> 00:18:56.756
First of all, World Tracking

00:18:56.756 --> 00:18:58.996
relies on a constant stream of

00:18:59.056 --> 00:19:01.136
camera images and sensor data.

00:19:01.556 --> 00:19:02.876
If this is interrupted for too

00:19:02.876 --> 00:19:04.996
long, tracking will become

00:19:04.996 --> 00:19:05.456
limited.

00:19:06.926 --> 00:19:08.676
Second, World Tracking also

00:19:08.676 --> 00:19:10.326
works best in textured and

00:19:10.326 --> 00:19:12.306
well-lit environments because

00:19:12.646 --> 00:19:14.656
World Tracking uses those

00:19:14.656 --> 00:19:16.726
visually robust points to map

00:19:16.726 --> 00:19:18.256
and finally triangulate its

00:19:18.316 --> 00:19:18.916
location.

00:19:18.916 --> 00:19:20.976
It is important that there is

00:19:20.976 --> 00:19:23.136
enough visual complexity in the

00:19:23.136 --> 00:19:23.686
environment.

00:19:24.706 --> 00:19:26.216
If this is not the case because

00:19:26.466 --> 00:19:28.046
it's, for example, too dark or

00:19:28.046 --> 00:19:29.666
you're looking against a white

00:19:29.666 --> 00:19:31.606
wall, then also, the tracking

00:19:31.606 --> 00:19:32.656
will perform poorly.

00:19:33.166 --> 00:19:36.936
And third, also, World Tracking

00:19:36.936 --> 00:19:38.646
works best in static

00:19:38.646 --> 00:19:39.366
environments.

00:19:40.326 --> 00:19:42.026
If too much of what your camera

00:19:42.106 --> 00:19:45.166
sees is moving, then the visual

00:19:45.166 --> 00:19:47.036
data won't correspond with the

00:19:47.036 --> 00:19:50.526
motion data, which might result

00:19:50.526 --> 00:19:51.776
in the potential drift.

00:19:52.846 --> 00:19:54.706
Also, device itself should not

00:19:54.706 --> 00:19:55.936
be on a moving platform like a

00:19:55.936 --> 00:19:57.456
bus or an elevator.

00:19:58.326 --> 00:19:59.726
Because in those moments the

00:19:59.726 --> 00:20:01.176
motion sensor would actually

00:20:01.176 --> 00:20:02.706
sense a motion like going up or

00:20:02.706 --> 00:20:04.476
down in the elevator while,

00:20:04.476 --> 00:20:06.766
visually, your environment had

00:20:06.816 --> 00:20:07.566
not changed.

00:20:08.066 --> 00:20:11.846
So, how can you get notified

00:20:11.846 --> 00:20:13.966
about the tracking quality that

00:20:14.036 --> 00:20:15.036
the user is currently

00:20:15.036 --> 00:20:16.926
experiencing with your app?

00:20:18.236 --> 00:20:19.916
ARKit monitors its tracking

00:20:19.916 --> 00:20:20.586
performance.

00:20:21.186 --> 00:20:22.776
We applied machine learning,

00:20:23.076 --> 00:20:24.536
which was trained on thousands

00:20:24.536 --> 00:20:26.546
of data sets to which we had the

00:20:26.546 --> 00:20:28.706
information how well tracking

00:20:28.706 --> 00:20:30.266
performed in those situations.

00:20:31.776 --> 00:20:33.276
To train a classifier, which

00:20:33.276 --> 00:20:35.036
tells you how tracking performs,

00:20:35.036 --> 00:20:36.846
we used annotations like the

00:20:36.846 --> 00:20:39.486
number of visual-- visible

00:20:39.566 --> 00:20:41.136
features tracked in the image

00:20:41.936 --> 00:20:43.576
and also, the current velocity

00:20:43.576 --> 00:20:44.346
of the device.

00:20:45.496 --> 00:20:47.866
Now, during runtime, the health

00:20:47.866 --> 00:20:50.636
of tracking is determined based

00:20:50.636 --> 00:20:51.746
on those parameters.

00:20:52.616 --> 00:20:55.116
In this video, we can see how

00:20:55.116 --> 00:20:57.026
the health estimate, which can

00:20:57.026 --> 00:20:58.406
be seen-- which, is reported in

00:20:58.406 --> 00:21:00.846
the lower left, gets worse when

00:21:00.846 --> 00:21:03.926
the camera is covered while we

00:21:03.926 --> 00:21:05.576
are still moving and exploring

00:21:05.576 --> 00:21:06.296
the environment.

00:21:07.796 --> 00:21:09.596
It also shows how it returns

00:21:09.596 --> 00:21:11.336
back to normal after the camera

00:21:11.336 --> 00:21:12.496
view is uncovered.

00:21:14.036 --> 00:21:16.066
Now, ARKit simplifies its

00:21:16.066 --> 00:21:18.586
information for you by providing

00:21:18.586 --> 00:21:19.596
a tracking state.

00:21:20.466 --> 00:21:22.186
And the tracking state can have

00:21:22.316 --> 00:21:23.426
three different values.

00:21:23.426 --> 00:21:26.776
It can be normal, which is the

00:21:26.856 --> 00:21:29.676
healthy state and is the case in

00:21:29.676 --> 00:21:30.546
most of the time.

00:21:30.546 --> 00:21:31.566
It's the case in most of the

00:21:31.566 --> 00:21:31.956
times.

00:21:32.506 --> 00:21:34.096
And it can also be limited,

00:21:34.236 --> 00:21:35.396
which is whenever tracking

00:21:35.396 --> 00:21:36.426
performs poorly.

00:21:37.486 --> 00:21:40.116
If that's the case, then the

00:21:40.116 --> 00:21:42.056
limited state will also come

00:21:42.056 --> 00:21:43.786
along with the reason, like

00:21:43.946 --> 00:21:45.406
insufficient features or

00:21:45.406 --> 00:21:47.766
excessive motion or being

00:21:47.806 --> 00:21:49.606
currently in the initialization

00:21:49.606 --> 00:21:49.966
phase.

00:21:50.716 --> 00:21:53.496
It can also be not available,

00:21:53.496 --> 00:21:55.256
which means that tracking did

00:21:55.256 --> 00:21:56.086
not start yet.

00:21:57.116 --> 00:21:58.826
Now, whenever the tracking state

00:21:58.916 --> 00:22:01.146
changes, a delegate is called.

00:22:01.416 --> 00:22:03.636
The camera did change tracking

00:22:03.636 --> 00:22:04.076
state.

00:22:05.216 --> 00:22:06.116
And this gives you the

00:22:06.116 --> 00:22:08.666
opportunity to notify the user

00:22:08.896 --> 00:22:10.346
when a limited state has been

00:22:10.346 --> 00:22:11.096
encountered.

00:22:12.116 --> 00:22:13.226
You should, then, give

00:22:13.426 --> 00:22:15.426
informative and actionable

00:22:15.776 --> 00:22:17.936
feedback what the user can do to

00:22:17.936 --> 00:22:19.626
improve his tracking situation,

00:22:20.136 --> 00:22:22.566
as most of it is actually in the

00:22:22.566 --> 00:22:23.396
user's hand.

00:22:23.776 --> 00:22:25.706
Like for example, as we learned

00:22:25.706 --> 00:22:27.996
before, like a sidewise movement

00:22:28.096 --> 00:22:30.656
to allow initialization or

00:22:31.206 --> 00:22:32.236
making sure there's enough

00:22:32.236 --> 00:22:34.316
adequate lighting for enough

00:22:34.416 --> 00:22:35.646
visual complexity.

00:22:36.236 --> 00:22:39.646
So, let me wrap up the World

00:22:39.646 --> 00:22:40.446
Tracking for you.

00:22:42.136 --> 00:22:46.156
World Tracking tracks your

00:22:46.156 --> 00:22:48.046
camera 6 degree of freedom

00:22:48.276 --> 00:22:51.556
orientation and position with

00:22:51.556 --> 00:22:53.356
respect to your surrounding

00:22:53.356 --> 00:22:55.286
environment and without any

00:22:55.286 --> 00:22:56.916
prior information about your

00:22:56.916 --> 00:22:59.066
environment, which then allows

00:22:59.606 --> 00:23:01.866
the physical world augmentation

00:23:01.866 --> 00:23:02.836
in which the content can

00:23:02.836 --> 00:23:04.776
actually be viewed from any kind

00:23:04.776 --> 00:23:05.166
of view.

00:23:06.636 --> 00:23:08.676
Also, World Tracking creates a

00:23:08.676 --> 00:23:11.196
World map, which becomes the

00:23:11.196 --> 00:23:13.206
tracking's reference system to

00:23:13.206 --> 00:23:14.876
localize new camera images

00:23:14.916 --> 00:23:15.416
against.

00:23:17.266 --> 00:23:18.386
To create a great user

00:23:18.386 --> 00:23:20.466
experience, the tracking quality

00:23:20.466 --> 00:23:22.696
should be monitored and feedback

00:23:22.786 --> 00:23:24.476
and guidance should be provided

00:23:24.476 --> 00:23:25.196
to your user.

00:23:25.736 --> 00:23:28.676
And World Tracking runs on your

00:23:28.676 --> 00:23:29.606
device only.

00:23:30.056 --> 00:23:31.516
And all results stay on your

00:23:31.516 --> 00:23:31.926
device.

00:23:33.446 --> 00:23:34.716
If you have not done it already,

00:23:35.576 --> 00:23:37.206
try out one of our developer

00:23:37.206 --> 00:23:37.836
examples.

00:23:37.936 --> 00:23:39.116
For example, the Build Your

00:23:39.116 --> 00:23:41.546
First AR Experience, and play a

00:23:41.546 --> 00:23:43.726
bit around, just 15 minutes with

00:23:43.726 --> 00:23:44.866
the tracking quality in

00:23:44.866 --> 00:23:46.536
different situations; light

00:23:46.616 --> 00:23:48.036
situations or movements.

00:23:48.536 --> 00:23:50.476
And always remember to guide the

00:23:50.476 --> 00:23:53.596
user whenever he encounters a

00:23:53.826 --> 00:23:56.696
limited tracking situation to

00:23:56.696 --> 00:23:58.646
guarantee that he has a great

00:23:58.886 --> 00:24:00.036
tracking experience.

00:24:01.456 --> 00:24:04.586
So, World Tracking is about the

00:24:04.586 --> 00:24:06.566
camera-- where your camera is

00:24:06.566 --> 00:24:08.526
with respect to your physical

00:24:08.526 --> 00:24:09.186
environment.

00:24:10.156 --> 00:24:13.026
Let's now talk about how the

00:24:13.026 --> 00:24:14.536
virtual content can interact

00:24:14.836 --> 00:24:16.776
with the physical environment.

00:24:17.136 --> 00:24:19.156
And this is possible with Plane

00:24:19.156 --> 00:24:19.726
Detection.

00:24:22.916 --> 00:24:24.876
The following video, again, from

00:24:24.876 --> 00:24:26.576
the Ikea app, shows a great use

00:24:26.576 --> 00:24:28.146
case for the Plane Detection,

00:24:28.466 --> 00:24:30.626
placing virtual objects into

00:24:30.626 --> 00:24:32.566
your physical environment, and

00:24:32.566 --> 00:24:34.426
then interacting with it.

00:24:35.296 --> 00:24:37.786
So first, please note how, also,

00:24:37.786 --> 00:24:39.256
in the Ikea app the user is

00:24:39.256 --> 00:24:41.156
guided to make some movement.

00:24:42.296 --> 00:24:44.326
Then, once a horizontal plane is

00:24:44.376 --> 00:24:46.796
detected, the virtual table set

00:24:46.796 --> 00:24:48.836
is displayed and is waiting to

00:24:48.836 --> 00:24:49.916
be placed by you.

00:24:51.256 --> 00:24:52.856
Once you position it, rotate it

00:24:52.856 --> 00:24:54.646
as you want it, you can lock the

00:24:54.646 --> 00:24:55.886
object in its environment.

00:24:56.126 --> 00:24:56.976
And did you notice the

00:24:56.976 --> 00:24:59.206
interaction between the detected

00:24:59.256 --> 00:25:01.156
ground plane and the table set

00:25:01.376 --> 00:25:02.196
in the moment of locking?

00:25:02.196 --> 00:25:04.166
It kind of bounces shortly on

00:25:04.166 --> 00:25:04.916
the ground plane.

00:25:05.276 --> 00:25:06.986
And this is possible because we

00:25:06.986 --> 00:25:08.416
know where the ground plane is.

00:25:09.556 --> 00:25:10.996
So, let's have a look at what

00:25:10.996 --> 00:25:12.696
happened under the hood here.

00:25:14.016 --> 00:25:16.086
Plane Detection uses the World

00:25:16.166 --> 00:25:18.726
map provided by the world I just

00:25:18.726 --> 00:25:20.656
talked about, just talked about

00:25:20.656 --> 00:25:22.726
a moment ago, which is

00:25:22.726 --> 00:25:24.246
represented here in those yellow

00:25:24.246 --> 00:25:24.716
points.

00:25:25.176 --> 00:25:28.446
And then, it uses them to detect

00:25:28.446 --> 00:25:30.966
surfaces that are horizontal or

00:25:30.966 --> 00:25:32.936
vertical, like the ground, the

00:25:32.936 --> 00:25:34.586
bench, and the small wall.

00:25:35.386 --> 00:25:36.946
It does this by accumulating

00:25:36.946 --> 00:25:38.746
information over multiple

00:25:38.746 --> 00:25:39.266
ARFrames.

00:25:40.096 --> 00:25:42.496
So, as the user moves around the

00:25:42.596 --> 00:25:44.316
scene, more and more information

00:25:44.316 --> 00:25:45.416
about the real surface is

00:25:45.416 --> 00:25:46.026
acquired.

00:25:46.896 --> 00:25:48.086
It also allows the Plane

00:25:48.086 --> 00:25:49.966
Detection to provide and like

00:25:50.296 --> 00:25:52.056
extent the surface, like a

00:25:52.056 --> 00:25:52.916
convex hull.

00:25:53.386 --> 00:25:58.006
If multiple planes belonging to

00:25:58.006 --> 00:26:00.676
the same physical surface are

00:26:00.676 --> 00:26:02.876
detected, like in this part now,

00:26:02.876 --> 00:26:04.636
the green and the purple one,

00:26:05.226 --> 00:26:06.726
then they will be merged once

00:26:06.726 --> 00:26:07.926
they start overlapping.

00:26:08.596 --> 00:26:11.356
If horizontal and vertical

00:26:11.356 --> 00:26:13.026
planes intersect they are

00:26:13.026 --> 00:26:14.366
clipped at the line of

00:26:14.366 --> 00:26:15.666
intersection, which is actually

00:26:15.666 --> 00:26:18.156
a new feature in ARKit 2.

00:26:19.876 --> 00:26:21.776
Plane Detection is designed to

00:26:21.776 --> 00:26:24.686
have very little overhead as it

00:26:24.766 --> 00:26:27.166
repurposes the mapped 3D points

00:26:27.166 --> 00:26:28.296
from the World Tracking.

00:26:29.086 --> 00:26:31.166
And then it fits planes into

00:26:31.166 --> 00:26:33.386
those point clouds and over time

00:26:33.696 --> 00:26:36.346
continuously aggregates more and

00:26:36.346 --> 00:26:38.326
more points and merge the planes

00:26:38.606 --> 00:26:40.286
that start to overlap.

00:26:40.936 --> 00:26:42.516
Therefore, it takes some time

00:26:42.516 --> 00:26:44.156
until the first planes are

00:26:44.156 --> 00:26:44.806
detected.

00:26:46.096 --> 00:26:47.276
What does that mean for you?

00:26:48.856 --> 00:26:50.726
If your app is started, there

00:26:50.726 --> 00:26:53.036
might not directly be planes to

00:26:53.036 --> 00:26:55.516
place objects on or to interact

00:26:55.626 --> 00:26:55.846
with.

00:26:57.266 --> 00:26:58.786
If the detection of a plane is

00:26:58.876 --> 00:27:01.496
mandatory for your experience,

00:27:01.786 --> 00:27:04.006
you should again guide the user

00:27:04.426 --> 00:27:06.006
to move the camera with enough

00:27:06.106 --> 00:27:08.956
translation to ensure a dense

00:27:08.956 --> 00:27:11.616
reconstruction based on the

00:27:11.616 --> 00:27:13.396
parallax, and also, enough

00:27:13.396 --> 00:27:15.086
visual complexity in the scene.

00:27:15.976 --> 00:27:18.096
Again, for the reconstruction, a

00:27:18.096 --> 00:27:20.416
rotation only is not enough.

00:27:20.946 --> 00:27:23.856
Now, how can you enable the

00:27:23.856 --> 00:27:24.796
Plane Detection?

00:27:25.786 --> 00:27:26.966
It's, again, very simple.

00:27:27.116 --> 00:27:28.676
As the Plane Detection reuses

00:27:28.676 --> 00:27:30.286
the 3D map from the World

00:27:30.286 --> 00:27:32.486
Tracking, it can be configured

00:27:32.646 --> 00:27:33.316
by using the

00:27:33.316 --> 00:27:35.126
ARWorldTrackingConfiguration.

00:27:35.646 --> 00:27:38.346
Then, the property

00:27:38.346 --> 00:27:40.706
planeDetection just needs to be

00:27:40.706 --> 00:27:41.986
set to either horizontal,

00:27:41.986 --> 00:27:43.626
vertical, or like in this case,

00:27:43.706 --> 00:27:43.926
both.

00:27:45.116 --> 00:27:47.446
And then, just call your

00:27:47.446 --> 00:27:49.046
ARSession with this

00:27:49.106 --> 00:27:50.226
configuration.

00:27:50.476 --> 00:27:52.146
And the detection of the planes

00:27:52.146 --> 00:27:52.856
will be started.

00:27:53.526 --> 00:27:56.086
Now, how are those, the results

00:27:56.086 --> 00:27:57.686
of the detected planes returned

00:27:57.686 --> 00:27:58.576
to you?

00:28:01.496 --> 00:28:03.216
The detected planes are returned

00:28:03.216 --> 00:28:05.006
as an ARPlaneAnchor.

00:28:05.936 --> 00:28:07.996
An ARPlaneAnchor is a subclass

00:28:07.996 --> 00:28:08.946
of an ARAnchor.

00:28:10.106 --> 00:28:11.696
Each ARAnchor provides a

00:28:11.876 --> 00:28:14.476
transform containing the

00:28:14.476 --> 00:28:16.326
information where the anchor is

00:28:16.606 --> 00:28:17.566
in your World map.

00:28:18.126 --> 00:28:20.216
Now, a plane anchor,

00:28:20.216 --> 00:28:21.436
specifically, also has

00:28:21.436 --> 00:28:24.026
information about the geometry

00:28:24.026 --> 00:28:25.886
of the surface of the plane,

00:28:26.816 --> 00:28:27.856
which is represented in two

00:28:27.856 --> 00:28:28.976
alternative ways.

00:28:29.316 --> 00:28:31.256
Either like a bounding box with

00:28:31.256 --> 00:28:35.096
a center and an extent, or as a

00:28:35.096 --> 00:28:37.306
3D mesh describing the shape of

00:28:37.356 --> 00:28:39.336
the convex hull of the detected

00:28:39.386 --> 00:28:41.306
plane and its geometry property.

00:28:42.636 --> 00:28:44.646
To get notified about detected

00:28:44.736 --> 00:28:48.266
planes, delegates are going to

00:28:48.266 --> 00:28:51.266
be called whenever planes are

00:28:51.266 --> 00:28:53.676
added, updated, or removed.

00:28:54.656 --> 00:28:57.086
This will then allow you to use

00:28:57.086 --> 00:28:59.566
those planes, as well as react

00:28:59.686 --> 00:29:01.486
to any updates.

00:29:01.666 --> 00:29:02.926
Now, what can you do with

00:29:03.006 --> 00:29:03.366
planes?

00:29:04.866 --> 00:29:05.956
Like what we've seen before on

00:29:05.956 --> 00:29:07.296
the Ikea app, these are great

00:29:07.296 --> 00:29:07.796
examples.

00:29:08.026 --> 00:29:09.496
Place virtual objects, for

00:29:09.496 --> 00:29:10.916
example, with hit testing.

00:29:12.046 --> 00:29:13.606
Or you can interact with some,

00:29:13.606 --> 00:29:15.186
for example, physically.

00:29:15.286 --> 00:29:17.846
Like we've seen bouncing is a

00:29:17.846 --> 00:29:18.706
possibility.

00:29:19.816 --> 00:29:21.966
Or you can also use it by adding

00:29:21.966 --> 00:29:23.226
an occlusion plane into the

00:29:23.226 --> 00:29:25.346
detected plane, which will then

00:29:25.496 --> 00:29:27.286
hide all the virtual content

00:29:27.336 --> 00:29:30.036
below or behind the added

00:29:30.036 --> 00:29:30.916
occlusion plane.

00:29:32.616 --> 00:29:34.436
So, let me summarize what we've

00:29:34.436 --> 00:29:35.386
already gone through.

00:29:36.536 --> 00:29:37.756
We've had a look at the

00:29:37.816 --> 00:29:41.176
Orientation Tracking, the World

00:29:41.286 --> 00:29:43.816
Tracking, and the Plane

00:29:43.816 --> 00:29:44.386
Detection.

00:29:45.306 --> 00:29:47.666
Next, Michele will explain, in

00:29:47.666 --> 00:29:48.986
depth, our new tracking

00:29:48.986 --> 00:29:50.316
technologies, which were

00:29:50.386 --> 00:29:52.976
introduced in ARKit 2.

00:29:53.046 --> 00:29:54.246
So, welcome Michele.

00:29:55.176 --> 00:29:57.500
[ Applause ]

00:29:58.396 --> 00:29:59.186
>> Thank you, Marion.

00:30:00.506 --> 00:30:01.766
My name is Michele, and it's a

00:30:01.766 --> 00:30:02.766
pleasure to continue with the

00:30:02.766 --> 00:30:03.636
remaining topics of this

00:30:03.636 --> 00:30:03.886
session.

00:30:05.136 --> 00:30:07.886
Next up is saving and loading

00:30:07.886 --> 00:30:08.326
maps.

00:30:08.936 --> 00:30:10.486
This is a feature that allows to

00:30:10.486 --> 00:30:11.816
store all the information that

00:30:11.816 --> 00:30:12.906
are required in a session.

00:30:13.336 --> 00:30:14.256
So, that it can literally be

00:30:14.256 --> 00:30:16.216
restored in another session at a

00:30:16.216 --> 00:30:18.116
later point in time to create

00:30:18.336 --> 00:30:19.706
augmented reality experiences

00:30:19.706 --> 00:30:21.146
that persist to a particular

00:30:21.146 --> 00:30:21.486
place.

00:30:22.406 --> 00:30:23.566
Or that could, also, be stored

00:30:23.566 --> 00:30:25.416
by another device to create

00:30:25.606 --> 00:30:27.296
multiple user augmented reality

00:30:27.296 --> 00:30:27.906
experiences.

00:30:28.646 --> 00:30:30.000
Let's take a look at an example.

00:30:37.076 --> 00:30:38.876
What you see here is a guy;

00:30:38.876 --> 00:30:40.906
let's name him Andre, that's

00:30:40.906 --> 00:30:41.956
walking around the table with

00:30:41.956 --> 00:30:43.506
his device having an augmented

00:30:43.506 --> 00:30:44.416
reality experience.

00:30:45.366 --> 00:30:47.596
And you can see his device now

00:30:47.986 --> 00:30:48.856
is making this seem more

00:30:48.856 --> 00:30:50.766
interesting by adding a virtual

00:30:50.766 --> 00:30:52.506
vase on the table.

00:30:54.556 --> 00:30:56.746
A few minutes later his friends

00:30:56.986 --> 00:30:58.126
arrive at the same scene.

00:30:58.366 --> 00:31:00.116
And now, they're both looking at

00:31:00.116 --> 00:31:00.576
the scene.

00:31:00.656 --> 00:31:01.926
You're going to see Andre's

00:31:02.446 --> 00:31:04.196
device on the left and his

00:31:04.196 --> 00:31:05.126
friend on the right now.

00:31:06.546 --> 00:31:07.446
So, you can see that they're

00:31:07.706 --> 00:31:08.836
looking at the same space.

00:31:08.926 --> 00:31:09.886
They can see each other.

00:31:10.266 --> 00:31:11.806
But most importantly, they see

00:31:11.806 --> 00:31:13.386
the same virtual content.

00:31:14.286 --> 00:31:15.446
They're having a shared

00:31:15.446 --> 00:31:19.246
augmented reality experience.

00:31:19.246 --> 00:31:21.456
So, what we have seen in these

00:31:21.456 --> 00:31:23.126
examples can be discovered in

00:31:23.186 --> 00:31:23.916
three stages.

00:31:24.266 --> 00:31:25.816
First, Andre went around the

00:31:25.816 --> 00:31:27.416
table and acquired the World

00:31:27.416 --> 00:31:27.616
map.

00:31:28.886 --> 00:31:30.246
Then, the World map was shared

00:31:30.536 --> 00:31:31.506
across devices.

00:31:32.276 --> 00:31:34.346
And then, his friend's device

00:31:34.496 --> 00:31:36.056
re-localized to the World map.

00:31:37.496 --> 00:31:38.986
This means that ARKit was

00:31:38.986 --> 00:31:40.536
able to understand in the new

00:31:40.536 --> 00:31:41.646
device that this was the same

00:31:41.646 --> 00:31:42.936
place as the other device,

00:31:43.586 --> 00:31:45.406
computed the precise position of

00:31:45.406 --> 00:31:46.556
the device with respect to the

00:31:46.556 --> 00:31:48.356
map, and then, started tracking

00:31:48.356 --> 00:31:50.106
from there just like the new

00:31:50.106 --> 00:31:51.346
device acquired the World map

00:31:51.346 --> 00:31:51.746
itself.

00:31:52.376 --> 00:31:54.956
We're going to go into more

00:31:54.956 --> 00:31:56.196
detail about these three phases.

00:31:56.866 --> 00:31:59.246
But first, let's review what's

00:31:59.246 --> 00:32:00.426
in the World map.

00:32:01.156 --> 00:32:02.866
The World map includes all the

00:32:02.866 --> 00:32:04.966
tracking data that are needed

00:32:04.966 --> 00:32:06.476
for the system to be localized,

00:32:06.986 --> 00:32:08.546
which includes the feature

00:32:08.546 --> 00:32:09.866
points as Marion greatly

00:32:09.866 --> 00:32:10.506
explained before.

00:32:10.876 --> 00:32:12.596
As well as local appearance for

00:32:12.596 --> 00:32:13.000
this point.

00:32:17.046 --> 00:32:18.496
They also contain all the

00:32:18.496 --> 00:32:19.826
anchors that were added to the

00:32:19.826 --> 00:32:21.806
session, either by the users,

00:32:21.916 --> 00:32:23.636
like planes, for example.

00:32:24.896 --> 00:32:26.126
I mean by the system-- like

00:32:26.126 --> 00:32:26.456
planes.

00:32:26.456 --> 00:32:28.126
Or by the users, like the vase,

00:32:28.446 --> 00:32:29.646
as we have seen in the example.

00:32:30.746 --> 00:32:33.786
This data is serializable and

00:32:33.786 --> 00:32:35.536
available to you so that you can

00:32:35.536 --> 00:32:37.346
create compelling persistent or

00:32:37.826 --> 00:32:39.326
multiple user augmented reality

00:32:39.326 --> 00:32:39.966
experiences.

00:32:40.326 --> 00:32:41.486
So, now let's take a look at the

00:32:41.486 --> 00:32:43.526
first stage, which is acquiring

00:32:43.526 --> 00:32:44.006
the World map.

00:32:44.756 --> 00:32:47.576
We can play back the first video

00:32:48.056 --> 00:32:49.396
where Andre went around the

00:32:49.396 --> 00:32:51.026
table that you can see his

00:32:51.026 --> 00:32:52.596
device on the left, here.

00:32:53.256 --> 00:32:57.216
And on the right, you see the

00:32:57.216 --> 00:32:59.126
World map from a top view as

00:32:59.126 --> 00:33:00.426
acquired by the tracking system.

00:33:00.776 --> 00:33:02.516
You can recognize the circle is the table

00:33:03.096 --> 00:33:04.566
and the chair around it.

00:33:05.136 --> 00:33:06.956
There's a few things to pay

00:33:06.956 --> 00:33:08.106
attention to during this

00:33:08.186 --> 00:33:09.276
acquisition process.

00:33:10.076 --> 00:33:11.986
First, everything that Marion

00:33:11.986 --> 00:33:13.396
said during tracking also

00:33:13.396 --> 00:33:13.946
applies here.

00:33:14.456 --> 00:33:15.606
So, we want enough visual

00:33:15.606 --> 00:33:17.356
complexity on the scene to get

00:33:17.446 --> 00:33:18.626
dense feature points on the map.

00:33:19.546 --> 00:33:21.276
And the scene must be static.

00:33:22.086 --> 00:33:22.856
Of course, we can deal with

00:33:22.856 --> 00:33:24.276
minor changes, as you have seen

00:33:24.276 --> 00:33:25.466
the tablecloth moving by the

00:33:25.466 --> 00:33:25.716
wind.

00:33:26.026 --> 00:33:27.216
But the scene must be mostly

00:33:27.566 --> 00:33:27.956
static.

00:33:29.036 --> 00:33:30.606
In addition, when we are

00:33:30.606 --> 00:33:31.936
specifically acquiring a World

00:33:31.936 --> 00:33:33.856
map for sharing we want to go

00:33:33.856 --> 00:33:35.316
around the environment from

00:33:35.316 --> 00:33:36.636
multiple points of view.

00:33:37.516 --> 00:33:38.746
In particular, we want to cover

00:33:38.746 --> 00:33:41.046
all the direction from which we

00:33:41.106 --> 00:33:42.786
want to later be localized from.

00:33:45.366 --> 00:33:46.926
To make this easy, we also made

00:33:47.356 --> 00:33:50.296
available a world mapping status

00:33:50.296 --> 00:33:51.736
which gives you information

00:33:51.736 --> 00:33:52.566
about the World map.

00:33:53.446 --> 00:33:54.816
If you guys have been to the

00:33:54.816 --> 00:33:56.066
What's New in ARKit talk,

00:33:56.636 --> 00:33:57.506
Arsalan greatly expand this

00:33:57.546 --> 00:33:58.936
to quickly recap.

00:33:59.576 --> 00:34:00.766
When you start the session the

00:34:00.766 --> 00:34:02.196
World map status will start

00:34:02.336 --> 00:34:02.776
limited.

00:34:02.776 --> 00:34:03.936
And then, will switch to

00:34:04.056 --> 00:34:06.746
extending as more of the scene is

00:34:06.746 --> 00:34:07.616
learned by the device.

00:34:08.036 --> 00:34:09.176
And then, finally, we go to

00:34:09.176 --> 00:34:10.856
mapped when the system is

00:34:10.856 --> 00:34:12.156
confident you're staying in the

00:34:12.156 --> 00:34:12.766
same place.

00:34:13.726 --> 00:34:15.206
And that's when you want to save

00:34:15.206 --> 00:34:16.976
the map in the mapped state.

00:34:17.626 --> 00:34:20.315
So, that's good information.

00:34:20.315 --> 00:34:22.056
But this is mostly on the user

00:34:22.056 --> 00:34:24.326
side applied to acquire the

00:34:24.326 --> 00:34:24.746
session.

00:34:24.966 --> 00:34:26.076
So, what does this mean to you

00:34:26.156 --> 00:34:26.926
as a developer?

00:34:27.505 --> 00:34:29.085
That you need to guide the user.

00:34:30.275 --> 00:34:32.255
So, we can indicate the mapping

00:34:32.326 --> 00:34:33.985
status and even disabling the

00:34:33.985 --> 00:34:35.835
saving or sharing of the World

00:34:35.835 --> 00:34:37.886
map until the mapping status

00:34:37.926 --> 00:34:39.476
goes to the mapped state.

00:34:39.996 --> 00:34:44.255
We can also, monitor the

00:34:44.326 --> 00:34:45.576
tracking quality during the

00:34:45.576 --> 00:34:48.696
acquisition session and report

00:34:48.926 --> 00:34:50.045
to the user if the tracking

00:34:50.045 --> 00:34:51.356
state has been limited for more

00:34:51.356 --> 00:34:52.146
than a few seconds.

00:34:53.056 --> 00:34:54.356
And maybe even give an option to

00:34:54.356 --> 00:34:56.036
restart the acquisition session.

00:34:56.476 --> 00:34:58.496
On the receiving end of the

00:34:58.496 --> 00:35:00.726
device, we can also guide the

00:35:00.726 --> 00:35:01.956
user to better localization

00:35:01.956 --> 00:35:02.346
process.

00:35:03.116 --> 00:35:04.856
So, when we are, again, in the

00:35:04.856 --> 00:35:06.776
acquisition device, when we are

00:35:06.776 --> 00:35:08.196
in the map state we can take a

00:35:08.196 --> 00:35:10.296
picture of the scene and then,

00:35:10.396 --> 00:35:11.496
ship that together with the

00:35:11.496 --> 00:35:11.946
World map.

00:35:11.986 --> 00:35:13.596
And on the receiving end we can

00:35:13.596 --> 00:35:16.026
ask the user find this view to

00:35:16.026 --> 00:35:17.766
start your shared experience.

00:35:18.386 --> 00:35:20.946
That was how to acquire the

00:35:20.946 --> 00:35:21.336
World map.

00:35:21.506 --> 00:35:22.876
Now, let's see how you can share

00:35:22.876 --> 00:35:24.666
the World map.

00:35:24.966 --> 00:35:26.366
First, you can get the World map

00:35:26.366 --> 00:35:27.386
by simply calling the

00:35:27.496 --> 00:35:29.926
getCurrentWorldMap method in the

00:35:29.926 --> 00:35:30.536
ARSession.

00:35:30.896 --> 00:35:32.596
And this will give you the World

00:35:33.186 --> 00:35:33.286
map.

00:35:34.376 --> 00:35:37.156
The World map is a serializable

00:35:37.156 --> 00:35:37.476
class.

00:35:37.566 --> 00:35:38.856
So, then we can simply use

00:35:38.956 --> 00:35:40.576
NSKeyedArchiver utility to

00:35:40.576 --> 00:35:42.106
serialize it to a binary stream

00:35:42.106 --> 00:35:44.446
of data, which then, you can

00:35:44.446 --> 00:35:46.276
either save to disk in case of a

00:35:46.276 --> 00:35:48.086
single user persistent

00:35:48.166 --> 00:35:48.946
application.

00:35:49.706 --> 00:35:52.126
Or you can share it across

00:35:52.156 --> 00:35:52.636
devices.

00:35:52.906 --> 00:35:54.626
And for that, you can use the

00:35:54.626 --> 00:35:56.176
MultiPeerConnectivity framework,

00:35:56.936 --> 00:35:58.196
which has great feature like

00:35:58.196 --> 00:36:00.186
automatic device, nearby device

00:36:00.186 --> 00:36:01.856
discovery, and allows efficient

00:36:01.856 --> 00:36:04.356
communication of data between

00:36:04.356 --> 00:36:04.876
devices.

00:36:05.626 --> 00:36:06.996
We also, have an example of how

00:36:06.996 --> 00:36:09.396
to use that in ARKit called

00:36:09.396 --> 00:36:11.036
Creating a Multiuser AR

00:36:11.036 --> 00:36:12.126
Experience that you can check

00:36:12.126 --> 00:36:13.516
out on our developer website.

00:36:14.076 --> 00:36:16.836
On the receiving end of the

00:36:16.836 --> 00:36:18.086
device, once you've got the

00:36:18.086 --> 00:36:20.096
World map let's see how you can

00:36:20.096 --> 00:36:21.046
set up the World Tracking

00:36:21.046 --> 00:36:22.126
configuration to use it.

00:36:22.426 --> 00:36:22.986
Very simple.

00:36:22.986 --> 00:36:24.916
You just set the initial World

00:36:24.916 --> 00:36:27.366
map property to that World map.

00:36:28.266 --> 00:36:29.986
When you run the session, the

00:36:29.986 --> 00:36:31.426
system will try to find that

00:36:31.526 --> 00:36:32.376
previous World map.

00:36:33.636 --> 00:36:35.336
But it may take some time, even

00:36:35.336 --> 00:36:36.366
because the user may not be

00:36:36.366 --> 00:36:37.546
pointing at the same scene as

00:36:37.546 --> 00:36:37.906
before.

00:36:38.756 --> 00:36:39.656
So, how do we know when

00:36:39.656 --> 00:36:40.606
localization happen?

00:36:41.686 --> 00:36:43.776
That information is available in

00:36:43.776 --> 00:36:44.666
the tracking state.

00:36:44.666 --> 00:36:45.896
So, as soon as you start the

00:36:45.896 --> 00:36:47.596
session with the initial World

00:36:47.596 --> 00:36:49.256
map, the tracking state will be

00:36:49.256 --> 00:36:50.326
limited with reason

00:36:50.536 --> 00:36:51.366
Relocalizing.

00:36:51.906 --> 00:36:54.226
Note that you will still get the

00:36:54.226 --> 00:36:55.816
tracking data available here,

00:36:56.176 --> 00:36:58.726
but the world origin will be the

00:36:58.726 --> 00:37:00.376
first camera, just like a new

00:37:00.376 --> 00:37:00.826
session.

00:37:01.336 --> 00:37:04.156
As soon as the user points the

00:37:04.156 --> 00:37:05.606
device to the same scene, the

00:37:05.606 --> 00:37:06.616
system will localize.

00:37:07.076 --> 00:37:08.136
The tracking state will go to

00:37:08.136 --> 00:37:09.866
normal and the world origin will

00:37:09.866 --> 00:37:11.576
be the same as the recorded

00:37:11.616 --> 00:37:12.036
World map.

00:37:13.046 --> 00:37:15.496
At this point, all your previous

00:37:15.496 --> 00:37:16.856
anchors are also available in

00:37:16.856 --> 00:37:17.916
your session, so you can put

00:37:17.976 --> 00:37:19.226
back the virtual content.

00:37:21.816 --> 00:37:23.506
Note here that because of what's

00:37:23.506 --> 00:37:24.986
happening behind the hood,

00:37:25.206 --> 00:37:26.806
behind the scenes, is that we're

00:37:26.806 --> 00:37:28.206
matching those feature points,

00:37:28.616 --> 00:37:29.996
there needs to be enough visual

00:37:29.996 --> 00:37:32.306
similarity between the scenes

00:37:32.306 --> 00:37:33.326
where you acquired the World map

00:37:33.536 --> 00:37:34.666
and the scene where you want to

00:37:34.666 --> 00:37:35.146
relocalize.

00:37:36.116 --> 00:37:37.406
So, if you go back to this table

00:37:37.406 --> 00:37:38.696
at night, chances are it's not

00:37:38.696 --> 00:37:41.946
going to work very well.

00:37:42.206 --> 00:37:44.116
And that was how you can create

00:37:44.506 --> 00:37:46.516
multiple user experiences or

00:37:46.516 --> 00:37:47.686
persistent experiences using the

00:37:47.686 --> 00:37:49.526
saving and loading map.

00:37:50.536 --> 00:37:54.846
Next, image tracking.

00:37:54.846 --> 00:37:56.306
So, augmented reality is all

00:37:56.306 --> 00:37:59.186
about adding visual content on

00:37:59.186 --> 00:38:00.306
top of the physical world.

00:38:00.536 --> 00:38:01.686
And on the physical world,

00:38:01.686 --> 00:38:02.866
images are found everywhere.

00:38:02.866 --> 00:38:05.226
Think about art pieces, pieces of art hanging on the wall the

00:38:05.226 --> 00:38:07.086
world, magazine covers,

00:38:07.426 --> 00:38:08.336
advertisements.

00:38:08.816 --> 00:38:10.136
Image tracking is a tool that

00:38:10.136 --> 00:38:11.506
allows you to recognize those

00:38:11.506 --> 00:38:13.976
physical images and build

00:38:14.216 --> 00:38:15.366
augmented reality experiences

00:38:15.366 --> 00:38:15.876
around them.

00:38:17.876 --> 00:38:18.746
Let's see an example.

00:38:20.006 --> 00:38:21.896
You can see here; two images

00:38:21.896 --> 00:38:23.356
being tracked simultaneously.

00:38:24.426 --> 00:38:26.766
On the left, a beautiful

00:38:27.206 --> 00:38:29.376
elephant is put on top of the

00:38:29.376 --> 00:38:30.716
physical image of the elephant.

00:38:31.606 --> 00:38:32.896
On the right, the physical image

00:38:32.896 --> 00:38:35.116
turned into a virtual screen.

00:38:36.186 --> 00:38:37.626
Note also, that the images can

00:38:37.626 --> 00:38:39.016
freely move around the

00:38:39.016 --> 00:38:40.966
environment as tracking around

00:38:40.966 --> 00:38:42.146
at 60 frames per second.

00:38:43.306 --> 00:38:45.146
Let's talk about looking at

00:38:45.146 --> 00:38:46.866
what's happening behind the

00:38:47.156 --> 00:38:47.476
scenes.

00:38:47.476 --> 00:38:48.996
So, let's say you have an image

00:38:48.996 --> 00:38:50.526
like this one of the elephant

00:38:50.896 --> 00:38:52.186
and you want to find it in a

00:38:52.236 --> 00:38:52.876
scene like this.

00:38:54.266 --> 00:38:55.556
We're using grayscale for this.

00:38:55.556 --> 00:38:56.956
And the first type is pretty

00:38:56.956 --> 00:38:58.426
similar to what we do in

00:38:58.426 --> 00:38:58.836
tracking.

00:38:58.936 --> 00:38:59.956
So, we'll track those

00:39:00.046 --> 00:39:01.526
interesting points from both the

00:39:01.526 --> 00:39:03.256
reference image and the current

00:39:03.316 --> 00:39:03.566
scene.

00:39:04.676 --> 00:39:05.996
And then, we try to go in the

00:39:05.996 --> 00:39:07.356
current scene and match those

00:39:07.356 --> 00:39:08.616
features to the one on the

00:39:08.616 --> 00:39:09.346
reference image.

00:39:10.436 --> 00:39:11.696
By applying some projected

00:39:11.696 --> 00:39:12.866
geometry and linear algebra,

00:39:13.186 --> 00:39:14.366
this is enough to give an

00:39:14.456 --> 00:39:16.126
initial estimation of the

00:39:16.126 --> 00:39:17.286
position orientation of the

00:39:17.286 --> 00:39:18.556
image with respect to the

00:39:18.556 --> 00:39:19.156
current scene.

00:39:20.516 --> 00:39:21.386
But we don't stop here.

00:39:22.566 --> 00:39:23.486
In order to give you a really

00:39:23.486 --> 00:39:25.836
precise pose and track at 60

00:39:25.836 --> 00:39:27.846
frames per second, we then do a

00:39:27.846 --> 00:39:29.276
dense tracking stage.

00:39:29.986 --> 00:39:31.316
So, with that initial estimate

00:39:31.976 --> 00:39:33.136
we take the pixels from the

00:39:33.136 --> 00:39:36.486
current scene and warp them back

00:39:36.566 --> 00:39:38.266
to a rectangular shape like you

00:39:38.266 --> 00:39:40.616
see on the right-- top right

00:39:40.696 --> 00:39:40.916
there.

00:39:41.306 --> 00:39:42.776
So, that's a reconstructed image

00:39:43.536 --> 00:39:45.296
by warping the pixels of the

00:39:45.296 --> 00:39:46.576
current image into the

00:39:46.576 --> 00:39:46.986
rectangle.

00:39:47.916 --> 00:39:48.766
We can then compare the

00:39:48.766 --> 00:39:50.456
reconstructed image with a

00:39:50.506 --> 00:39:51.726
reference image that we have

00:39:51.726 --> 00:39:54.056
available to create an error

00:39:54.056 --> 00:39:55.106
image like the one you see

00:39:55.106 --> 00:39:55.436
below.

00:39:56.636 --> 00:39:58.296
We then optimize the position

00:39:58.296 --> 00:39:59.836
orientation of the image, such

00:39:59.906 --> 00:40:00.976
that that error is minimized.

00:40:03.366 --> 00:40:04.786
So, what this means to you that

00:40:04.786 --> 00:40:06.796
the pose would be really

00:40:06.796 --> 00:40:07.266
accurate.

00:40:08.146 --> 00:40:09.706
Thank you.

00:40:10.526 --> 00:40:12.076
And will still track at 60

00:40:12.076 --> 00:40:12.826
frames per second.

00:40:15.296 --> 00:40:16.906
So, let's see how we can do all

00:40:16.906 --> 00:40:18.126
of this in ARKit.

00:40:18.916 --> 00:40:21.856
As usual, the ARKit API is

00:40:21.856 --> 00:40:22.506
really simple.

00:40:22.566 --> 00:40:24.566
We have three simple steps.

00:40:24.606 --> 00:40:26.686
First, we want to collect all

00:40:26.686 --> 00:40:27.596
the reference images.

00:40:28.486 --> 00:40:30.616
Then, we set up the AR Session

00:40:30.616 --> 00:40:31.346
Configuration.

00:40:31.606 --> 00:40:32.646
There are two options here.

00:40:33.166 --> 00:40:34.306
One is the World Tracking

00:40:34.306 --> 00:40:35.756
configuration that gives, also,

00:40:35.756 --> 00:40:37.426
the device position.

00:40:37.426 --> 00:40:38.316
And this is the one we have

00:40:38.406 --> 00:40:39.296
talked, so far.

00:40:39.856 --> 00:40:41.506
And in iOS12, introduced a new

00:40:41.506 --> 00:40:42.576
configuration, which is a

00:40:42.576 --> 00:40:43.766
standalone image tracking

00:40:43.766 --> 00:40:44.476
configuration.

00:40:44.936 --> 00:40:47.906
Once you start the session you

00:40:47.906 --> 00:40:49.896
will start receiving the results

00:40:49.896 --> 00:40:52.326
in the form of an ARImageAnchor.

00:40:53.296 --> 00:40:54.306
We're now going into more

00:40:54.306 --> 00:40:55.626
details of these three steps,

00:40:56.036 --> 00:40:57.456
starting from the reference

00:40:57.456 --> 00:40:57.886
images.

00:40:58.426 --> 00:41:01.286
The easiest way to add reference

00:41:01.286 --> 00:41:02.836
images to your application is

00:41:02.896 --> 00:41:04.746
through the, Xcode asset

00:41:04.746 --> 00:41:05.106
catalog.

00:41:06.146 --> 00:41:08.066
You simply create an AR Resource

00:41:08.066 --> 00:41:09.646
Groups and drag and drop your

00:41:09.646 --> 00:41:10.386
images in there.

00:41:11.566 --> 00:41:13.026
Next, you have to set the

00:41:13.026 --> 00:41:14.446
physical dimension of the image,

00:41:14.556 --> 00:41:16.196
which you can do on the property

00:41:16.196 --> 00:41:17.436
window on the top right.

00:41:17.946 --> 00:41:20.656
Setting the physical dimension

00:41:21.096 --> 00:41:22.336
is a requirement and there's a

00:41:22.336 --> 00:41:23.126
few reason for that.

00:41:24.466 --> 00:41:26.126
First, it allows the pose of the

00:41:26.126 --> 00:41:27.816
image to be in physical scale.

00:41:28.386 --> 00:41:29.776
Which means, also, your content

00:41:29.816 --> 00:41:31.076
will be in physical scale.

00:41:31.186 --> 00:41:32.666
In ARKit, everything is in

00:41:32.666 --> 00:41:33.986
meters, so also, your visual

00:41:33.986 --> 00:41:36.226
content will be in meters.

00:41:37.056 --> 00:41:38.626
In addition, it's especially

00:41:38.626 --> 00:41:40.266
important to set the correct

00:41:40.266 --> 00:41:41.586
physical dimension of the image

00:41:41.946 --> 00:41:43.166
in case we combine the image

00:41:43.216 --> 00:41:44.046
tracking with the World

00:41:44.046 --> 00:41:44.476
Tracking.

00:41:44.936 --> 00:41:46.206
As this will give immediately

00:41:46.526 --> 00:41:48.616
consistent pose between the

00:41:48.616 --> 00:41:51.196
image and the world.

00:41:51.196 --> 00:41:52.826
Let's see some example of this

00:41:53.256 --> 00:41:54.166
reference images.

00:41:54.816 --> 00:41:57.366
You can see here, two beautiful

00:41:57.366 --> 00:41:57.806
images.

00:41:58.476 --> 00:41:59.776
These images will work really

00:41:59.776 --> 00:42:01.066
great with image tracking.

00:42:01.156 --> 00:42:03.426
They have high texture, high

00:42:03.426 --> 00:42:04.956
level of contrast, well

00:42:04.956 --> 00:42:06.376
distributed histograms, as well

00:42:06.376 --> 00:42:07.356
as they do not contain

00:42:07.356 --> 00:42:08.416
repetitive structures.

00:42:08.536 --> 00:42:10.486
There are, also, other kinds of

00:42:10.486 --> 00:42:12.316
images that will work less good

00:42:12.316 --> 00:42:12.936
with the system.

00:42:13.436 --> 00:42:14.726
You can see an example of this

00:42:15.456 --> 00:42:16.176
on the right.

00:42:17.116 --> 00:42:19.606
And if we take a look at these

00:42:19.696 --> 00:42:21.596
top two examples, you can see

00:42:21.596 --> 00:42:23.466
that the good image we have a

00:42:23.466 --> 00:42:25.036
lot of those interesting points.

00:42:25.536 --> 00:42:26.306
And you can see that the

00:42:26.306 --> 00:42:27.716
histogram is well distributed

00:42:27.716 --> 00:42:28.686
across the whole range.

00:42:29.316 --> 00:42:30.126
While on the Snow image,

00:42:30.126 --> 00:42:33.096
there's only a few of those

00:42:33.096 --> 00:42:34.286
interesting points and the

00:42:34.286 --> 00:42:36.116
histogram is all skewed toward

00:42:36.116 --> 00:42:36.536
the whites.

00:42:37.236 --> 00:42:40.536
You can get an estimation of how

00:42:40.536 --> 00:42:42.066
good an image will be directly

00:42:42.066 --> 00:42:42.916
in Xcode.

00:42:44.076 --> 00:42:46.066
As soon as you drag an image in

00:42:46.066 --> 00:42:48.396
there, the image is analyzed and

00:42:48.576 --> 00:42:50.316
problems are reported to you in the form

00:42:50.316 --> 00:42:52.206
of warnings to give you early

00:42:52.276 --> 00:42:53.826
feedback, even before you run

00:42:53.826 --> 00:42:54.516
your application.

00:42:55.646 --> 00:42:56.666
For example, if you click on

00:42:56.666 --> 00:42:59.086
this bottom image that could be

00:42:59.086 --> 00:43:01.836
a magazine page, for example, we

00:43:01.836 --> 00:43:04.396
can see that the Xcode says that

00:43:04.556 --> 00:43:05.776
the histogram is not well

00:43:05.776 --> 00:43:06.436
distributed.

00:43:06.676 --> 00:43:07.626
In fact, you can see there's a

00:43:07.626 --> 00:43:09.326
lot of whites in the image.

00:43:09.476 --> 00:43:10.626
And it would also say that this

00:43:10.626 --> 00:43:11.716
image contains repetitive

00:43:11.716 --> 00:43:14.486
structures, mainly caused by the

00:43:15.476 --> 00:43:15.636
text.

00:43:15.776 --> 00:43:18.076
Another example, if you have two

00:43:18.076 --> 00:43:20.126
images which are too similar and

00:43:20.126 --> 00:43:22.176
are at risk of being confused at

00:43:22.506 --> 00:43:24.366
detection time, also, Xcode

00:43:24.366 --> 00:43:25.166
warns you about that.

00:43:25.906 --> 00:43:26.986
You can see an example of these

00:43:26.986 --> 00:43:28.906
two images of the same mountain

00:43:28.906 --> 00:43:29.756
range, the Sierra.

00:43:30.156 --> 00:43:32.446
There's a few things that we can

00:43:32.446 --> 00:43:33.506
do to deal with this warning.

00:43:33.936 --> 00:43:34.956
For example, let's go back to

00:43:34.956 --> 00:43:38.236
this image that had repetitive

00:43:38.236 --> 00:43:40.746
structures and not well

00:43:40.746 --> 00:43:41.746
distributed histograms.

00:43:42.516 --> 00:43:44.186
You can try to identify a region

00:43:44.186 --> 00:43:45.126
of this image which is

00:43:45.126 --> 00:43:46.596
distinctive enough, like in this

00:43:46.596 --> 00:43:48.736
case, for example, the actual

00:43:48.736 --> 00:43:49.536
image of the page.

00:43:50.106 --> 00:43:51.276
And then, you can crop that out

00:43:51.276 --> 00:43:52.756
and use this as the reference

00:43:52.756 --> 00:43:53.556
image, instead.

00:43:53.876 --> 00:43:55.126
Which will give you, of course,

00:43:55.476 --> 00:43:56.756
all the warnings are going to be

00:43:56.756 --> 00:43:58.296
removed and will give you better

00:43:58.946 --> 00:43:59.716
tracking quality.

00:44:00.026 --> 00:44:03.106
Another thing that we can do is

00:44:03.436 --> 00:44:06.376
use multiple AR Resource Groups.

00:44:07.496 --> 00:44:09.176
This allow many more images to

00:44:09.396 --> 00:44:10.146
be detected.

00:44:10.416 --> 00:44:11.726
As we recommend to have a

00:44:11.726 --> 00:44:13.816
maximum of 25 images per group

00:44:14.236 --> 00:44:15.296
to keep your experience

00:44:15.296 --> 00:44:16.736
efficient and responsive.

00:44:17.936 --> 00:44:19.016
But you can have as many groups

00:44:19.246 --> 00:44:19.826
as you want.

00:44:20.036 --> 00:44:21.896
And then, you can switch between

00:44:21.896 --> 00:44:23.156
groups programmatically.

00:44:23.376 --> 00:44:26.076
For example, if you are want to

00:44:26.076 --> 00:44:27.076
create an augmented reality

00:44:27.076 --> 00:44:28.846
experience in a museum that may

00:44:28.846 --> 00:44:30.646
have hundreds of images.

00:44:31.816 --> 00:44:33.396
Usually though, those images are

00:44:33.396 --> 00:44:34.586
actually physically located in

00:44:34.586 --> 00:44:35.336
different rooms.

00:44:35.646 --> 00:44:37.646
So, what you can do is put the

00:44:38.246 --> 00:44:39.756
images that physically will be

00:44:39.756 --> 00:44:41.146
present in the room into a

00:44:41.146 --> 00:44:41.476
group.

00:44:41.686 --> 00:44:43.036
And images of another room into

00:44:43.036 --> 00:44:43.596
another group.

00:44:44.246 --> 00:44:45.806
And then use, for example, core

00:44:45.806 --> 00:44:47.586
location to switch between

00:44:48.306 --> 00:44:48.686
rooms.

00:44:49.186 --> 00:44:52.116
Note also, that you can have

00:44:52.446 --> 00:44:53.906
similar images, now, as long as

00:44:53.946 --> 00:44:55.126
they are in different groups.

00:44:55.896 --> 00:44:57.716
So, that was all about reference

00:44:57.746 --> 00:44:58.266
images.

00:44:58.266 --> 00:45:00.606
Let's now, see our two

00:45:01.166 --> 00:45:01.916
configurations.

00:45:03.006 --> 00:45:05.286
The ARImageTrackingConfiguration

00:45:05.416 --> 00:45:06.876
is a new standalone image

00:45:06.876 --> 00:45:07.836
tracking configuration, which

00:45:07.866 --> 00:45:09.256
means it doesn't run the World

00:45:09.256 --> 00:45:09.646
Tracking.

00:45:10.636 --> 00:45:11.846
Which also, means there is no

00:45:12.136 --> 00:45:12.916
world origin.

00:45:13.216 --> 00:45:14.676
So, every image will be given to

00:45:14.676 --> 00:45:15.976
you with respect to the current

00:45:15.976 --> 00:45:16.526
camera view.

00:45:18.246 --> 00:45:19.346
You can also combine image

00:45:19.406 --> 00:45:20.906
tracking with a World Tracking

00:45:20.906 --> 00:45:21.646
configuration.

00:45:22.466 --> 00:45:24.536
And in this case, you will have

00:45:24.536 --> 00:45:25.636
all the scene understanding

00:45:25.636 --> 00:45:27.506
capability available like Plane

00:45:27.506 --> 00:45:29.356
Detection, light estimation,

00:45:29.356 --> 00:45:30.026
everything else.

00:45:31.066 --> 00:45:32.796
So, what is more appropriate to

00:45:32.796 --> 00:45:34.376
use which configurations?

00:45:35.066 --> 00:45:35.536
Let's see.

00:45:35.626 --> 00:45:37.106
So, in the

00:45:37.516 --> 00:45:39.916
ARImageTrackingConfigurations is

00:45:39.916 --> 00:45:41.226
really tailored for use cases

00:45:41.226 --> 00:45:42.906
which are built around images.

00:45:43.196 --> 00:45:44.286
We can see an example on the

00:45:44.286 --> 00:45:44.826
left here.

00:45:46.606 --> 00:45:48.516
We can have an image that could

00:45:48.516 --> 00:45:49.666
be a page of a textbook.

00:45:50.506 --> 00:45:51.576
And to make the experience more

00:45:51.576 --> 00:45:53.976
engaging, we are overlaying

00:45:54.286 --> 00:45:54.746
dynamic graph.

00:45:54.746 --> 00:45:55.846
In this case, on how to build an

00:45:55.846 --> 00:45:56.796
equilateral triangle.

00:45:57.866 --> 00:45:58.746
So, you can see that this

00:45:58.746 --> 00:46:00.256
experience is really tailored

00:46:00.256 --> 00:46:00.966
around an image.

00:46:01.116 --> 00:46:03.046
If you have, let's see this

00:46:03.046 --> 00:46:03.826
other example.

00:46:04.546 --> 00:46:05.516
Image tracking is used to

00:46:05.606 --> 00:46:07.266
trigger some content that then

00:46:07.266 --> 00:46:09.326
goes beyond the extent of the

00:46:09.326 --> 00:46:09.496
image.

00:46:09.496 --> 00:46:12.086
In this case, you want to use

00:46:12.086 --> 00:46:13.726
the ARWorldTrackingConfiguration

00:46:13.806 --> 00:46:14.906
as you will need the device

00:46:14.906 --> 00:46:16.506
position to keep track of that

00:46:16.506 --> 00:46:19.856
content outside the image.

00:46:20.076 --> 00:46:21.146
Also, note that the image

00:46:21.246 --> 00:46:23.576
tracking doesn't use the motion

00:46:23.576 --> 00:46:24.676
data, which means it can also be

00:46:24.676 --> 00:46:26.506
used on a bus or an elevator,

00:46:27.076 --> 00:46:28.146
where the motion data don't

00:46:28.146 --> 00:46:29.896
agree with the visual data.

00:46:30.916 --> 00:46:33.036
So, let's see now, how we can do

00:46:33.036 --> 00:46:33.756
this in code.

00:46:35.236 --> 00:46:36.916
You can easily recognize those

00:46:36.946 --> 00:46:37.716
three steps here.

00:46:37.936 --> 00:46:39.836
The first one is to gather all

00:46:39.836 --> 00:46:40.476
the images.

00:46:40.876 --> 00:46:41.796
And there's a convenience

00:46:41.796 --> 00:46:43.396
function for that in the

00:46:43.566 --> 00:46:45.436
ARReferenceImage class that

00:46:45.436 --> 00:46:47.436
gathers all the images that are

00:46:47.436 --> 00:46:48.366
in a particular group.

00:46:48.556 --> 00:46:50.226
In this case, it's named Room1.

00:46:51.896 --> 00:46:53.256
We can then simply set the

00:46:53.256 --> 00:46:55.626
trackingImages property to those

00:46:55.626 --> 00:46:56.306
images in the

00:46:56.306 --> 00:46:58.156
ARImageTrackingConfigurations.

00:46:58.586 --> 00:46:59.516
And run the session.

00:47:00.866 --> 00:47:02.766
You will then start receiving

00:47:02.766 --> 00:47:04.306
the results, for example, to the

00:47:04.306 --> 00:47:06.346
session:didUpdate anchors

00:47:06.466 --> 00:47:08.266
delegate method, where you can

00:47:08.266 --> 00:47:10.096
check if the anchors is of type

00:47:10.146 --> 00:47:11.156
ARImageAnchor.

00:47:12.606 --> 00:47:14.186
In the anchor, you will find, of

00:47:14.246 --> 00:47:15.386
course, the position and

00:47:15.386 --> 00:47:17.336
orientation of the image, as

00:47:17.336 --> 00:47:18.216
well as the reference image

00:47:18.216 --> 00:47:18.656
itself.

00:47:18.716 --> 00:47:19.856
Where you can find, for example,

00:47:19.856 --> 00:47:21.836
the name of the image as you

00:47:21.836 --> 00:47:23.156
named it in the asset catalog so

00:47:23.156 --> 00:47:24.126
that you know which image has

00:47:24.126 --> 00:47:24.746
been detected.

00:47:25.986 --> 00:47:26.966
There's also another Boolean

00:47:26.966 --> 00:47:28.936
property, which tells you if

00:47:28.936 --> 00:47:30.086
this image is currently being

00:47:30.086 --> 00:47:33.666
tracked in the frame.

00:47:33.866 --> 00:47:35.306
Note here that other than these

00:47:35.306 --> 00:47:36.496
use cases that we have seen so

00:47:36.496 --> 00:47:38.576
far when you build experiences

00:47:38.576 --> 00:47:40.546
around images, image detection

00:47:40.546 --> 00:47:43.196
and tracking allows a few more

00:47:43.976 --> 00:47:44.126
things.

00:47:45.226 --> 00:47:47.496
For example, if two devices are

00:47:47.496 --> 00:47:48.866
looking at the same physical

00:47:48.866 --> 00:47:51.446
image, you can detect this image

00:47:51.446 --> 00:47:52.416
from both devices.

00:47:52.846 --> 00:47:54.586
And this will give you a shared

00:47:54.586 --> 00:47:56.066
coordinate system that you can

00:47:56.066 --> 00:47:57.626
then use as an alternative way

00:47:58.106 --> 00:47:59.386
to have a shared experience.

00:48:01.476 --> 00:48:03.846
Another example, if you happen

00:48:03.846 --> 00:48:05.226
to know where an image is

00:48:05.346 --> 00:48:06.916
physically located in the world,

00:48:08.296 --> 00:48:09.826
like for example, you know that

00:48:09.826 --> 00:48:11.446
the map of this park is in the

00:48:11.446 --> 00:48:12.076
physical world.

00:48:12.456 --> 00:48:14.446
You can use image tracking to

00:48:14.446 --> 00:48:15.956
get the position of the device

00:48:15.956 --> 00:48:17.576
with respect to the image and,

00:48:17.576 --> 00:48:19.636
therefore, also the position of

00:48:19.636 --> 00:48:20.656
the device with respect to the

00:48:20.656 --> 00:48:21.946
world, which, you can then use,

00:48:21.946 --> 00:48:23.956
for example, to overlay

00:48:24.196 --> 00:48:26.396
directions really attached to

00:48:26.396 --> 00:48:27.086
the physical world.

00:48:27.646 --> 00:48:31.376
So, that concludes the image

00:48:31.436 --> 00:48:31.836
tracking.

00:48:31.836 --> 00:48:34.006
Let's now go and look at the

00:48:34.066 --> 00:48:35.266
Object Detection.

00:48:38.016 --> 00:48:39.546
So, with image tracking we have

00:48:39.546 --> 00:48:41.716
seen how we can detect images,

00:48:41.716 --> 00:48:43.676
which are planar objects in the

00:48:43.676 --> 00:48:44.406
physical world.

00:48:45.376 --> 00:48:46.786
Object detection extends this

00:48:46.786 --> 00:48:48.256
concept to the third dimension

00:48:48.346 --> 00:48:49.806
allowing the detection of more

00:48:49.806 --> 00:48:50.586
generic objects.

00:48:51.046 --> 00:48:53.626
Note, though, that this object

00:48:53.816 --> 00:48:55.826
will be assumed to be static in

00:48:55.826 --> 00:48:57.086
the scene, unlike images that

00:48:57.086 --> 00:48:57.676
can move around.

00:48:58.866 --> 00:49:00.046
We can see an example here.

00:49:00.046 --> 00:49:02.566
That's the Nefertiti bust.

00:49:02.716 --> 00:49:04.266
It's a statue that could be

00:49:04.266 --> 00:49:05.326
present in a museum.

00:49:05.636 --> 00:49:07.166
And now, you can detect it with

00:49:07.166 --> 00:49:07.576
ARKit.

00:49:08.216 --> 00:49:10.376
And then, for example, display

00:49:10.376 --> 00:49:12.296
some information on top of the

00:49:12.296 --> 00:49:14.476
physical object.

00:49:15.466 --> 00:49:17.536
Note also that in the object

00:49:17.736 --> 00:49:18.936
detection in ARKit, we are

00:49:18.936 --> 00:49:20.516
talking about specific instances

00:49:20.516 --> 00:49:21.116
of an object.

00:49:21.646 --> 00:49:22.506
So, we're not talking about

00:49:22.506 --> 00:49:23.986
detecting statues in general,

00:49:24.346 --> 00:49:26.406
but this particular instance of

00:49:26.406 --> 00:49:27.456
the Nefertiti statue.

00:49:28.836 --> 00:49:29.986
So, how do we represent these

00:49:29.986 --> 00:49:31.006
objects in ARKit?

00:49:31.626 --> 00:49:33.366
You first need to scan the

00:49:33.366 --> 00:49:33.736
object.

00:49:33.806 --> 00:49:35.086
So, really, there's two steps to

00:49:35.086 --> 00:49:35.196
it.

00:49:35.316 --> 00:49:36.936
First, you scan the object and

00:49:36.936 --> 00:49:38.336
then you can detect it.

00:49:39.096 --> 00:49:40.546
Let's talk about the scanning

00:49:40.546 --> 00:49:42.446
part, which mostly is going to

00:49:42.446 --> 00:49:44.166
be on your side as a developer,

00:49:44.886 --> 00:49:46.016
to basically, create that

00:49:46.016 --> 00:49:47.296
representation of the object

00:49:47.406 --> 00:49:49.176
that can be used for detection.

00:49:51.276 --> 00:49:53.716
Internally, an object is

00:49:53.716 --> 00:49:55.616
represented in a similar way as

00:49:55.616 --> 00:49:56.196
the world map.

00:49:56.776 --> 00:49:58.576
You can see an example of the 3D

00:49:58.916 --> 00:50:00.456
feature points of the Nefertiti

00:50:00.456 --> 00:50:01.886
statue there on the left.

00:50:03.056 --> 00:50:04.876
And to scan the object, you can

00:50:05.006 --> 00:50:06.516
use the Scanning and Detecting

00:50:06.516 --> 00:50:08.496
3D Objects developer sample

00:50:08.496 --> 00:50:10.416
that's available on the website.

00:50:11.706 --> 00:50:13.136
And note here, that the

00:50:13.136 --> 00:50:14.766
detection quality that you will

00:50:14.766 --> 00:50:17.306
get at runtime, later, is highly

00:50:17.306 --> 00:50:18.616
affected by the quality of the

00:50:18.616 --> 00:50:18.986
scan.

00:50:19.776 --> 00:50:21.826
So, let's spend a few moments to

00:50:21.826 --> 00:50:23.266
see how we can get the best

00:50:23.336 --> 00:50:27.386
quality during the scanning.

00:50:27.546 --> 00:50:29.066
Once you build and run this

00:50:29.066 --> 00:50:30.666
developer sample you will see

00:50:30.786 --> 00:50:31.916
something like this on your

00:50:31.916 --> 00:50:32.406
device.

00:50:33.286 --> 00:50:35.976
The first step is to find the

00:50:35.976 --> 00:50:37.566
region of space around your

00:50:37.566 --> 00:50:37.926
object.

00:50:39.036 --> 00:50:40.066
The application will try to

00:50:40.066 --> 00:50:41.556
automatically estimate this

00:50:41.586 --> 00:50:42.946
bounding box, exploiting

00:50:42.946 --> 00:50:43.946
different feature points.

00:50:44.896 --> 00:50:46.206
But you can always adjust this

00:50:46.256 --> 00:50:48.856
box by dragging on a side to

00:50:49.066 --> 00:50:50.726
shrink it or make it larger.

00:50:52.876 --> 00:50:54.506
Note here, that what is really

00:50:54.506 --> 00:50:55.766
important that when you go

00:50:55.766 --> 00:50:57.266
around the object you make sure

00:50:57.266 --> 00:50:58.796
that you don't cut any of the

00:50:58.796 --> 00:51:00.806
interesting points of the

00:51:00.806 --> 00:51:01.166
object.

00:51:01.856 --> 00:51:03.606
You can also, rotate the box

00:51:03.606 --> 00:51:04.956
with a two-finger gesture from

00:51:04.996 --> 00:51:05.146
top.

00:51:05.856 --> 00:51:08.406
So, make sure that this box is

00:51:08.606 --> 00:51:09.666
around the object and not

00:51:09.696 --> 00:51:11.286
cutting any interesting part of

00:51:11.916 --> 00:51:11.986
it.

00:51:13.016 --> 00:51:14.746
The next part is the actual

00:51:14.746 --> 00:51:15.246
scanning.

00:51:16.376 --> 00:51:19.356
In this phase what we want to do

00:51:19.356 --> 00:51:21.426
is really go around the objects

00:51:21.736 --> 00:51:23.486
from all the points of view that

00:51:23.486 --> 00:51:24.846
you think your users will want

00:51:24.846 --> 00:51:25.806
to detect it later.

00:51:27.056 --> 00:51:28.386
In order to make it easy for you

00:51:28.386 --> 00:51:30.096
to understand which part of the

00:51:30.096 --> 00:51:31.656
objects have been, already,

00:51:31.656 --> 00:51:33.376
acquired like this beautiful

00:51:33.376 --> 00:51:34.356
tile representation.

00:51:34.726 --> 00:51:36.046
And you also can see a

00:51:36.456 --> 00:51:37.676
percentage on top which tells

00:51:37.676 --> 00:51:38.786
you how many tiles have already

00:51:38.786 --> 00:51:39.366
been acquired.

00:51:40.406 --> 00:51:41.786
And it's really important in

00:51:41.786 --> 00:51:43.716
this phase that you spend time

00:51:43.716 --> 00:51:45.126
on the regions of the object

00:51:45.126 --> 00:51:46.546
which have a lot of features

00:51:46.726 --> 00:51:47.726
that are distinctive enough.

00:51:47.726 --> 00:51:49.446
And you go close enough to

00:51:49.446 --> 00:51:50.346
capture all the details.

00:51:50.686 --> 00:51:52.046
And again, that you really go

00:51:52.046 --> 00:51:56.246
around from all the sides.

00:51:56.436 --> 00:51:59.456
Like you see here.

00:51:59.686 --> 00:52:01.186
Once you're happy with the

00:52:01.186 --> 00:52:02.996
coverage of your objects, you

00:52:02.996 --> 00:52:04.476
can go to the next step, which

00:52:04.476 --> 00:52:06.656
is allows you to adjust the

00:52:06.656 --> 00:52:09.166
origin by simply dragging on the

00:52:09.166 --> 00:52:10.026
coordinate system.

00:52:10.536 --> 00:52:12.496
And this will be the coordinate

00:52:12.496 --> 00:52:13.886
system that will be later given

00:52:13.886 --> 00:52:16.206
to you at detection time in the

00:52:16.206 --> 00:52:16.506
anchor.

00:52:16.506 --> 00:52:17.766
So, make sure that you put it in

00:52:17.766 --> 00:52:19.316
a place which makes sense for

00:52:19.316 --> 00:52:20.606
your virtual content.

00:52:20.676 --> 00:52:25.526
So, at this point, you have a

00:52:25.676 --> 00:52:27.286
full representation of your

00:52:27.286 --> 00:52:30.176
object, which you can use for

00:52:30.176 --> 00:52:30.686
detection.

00:52:30.686 --> 00:52:33.106
And the application will now

00:52:33.106 --> 00:52:34.976
switch to a detection mode.

00:52:36.106 --> 00:52:37.386
We encourage you to use this

00:52:37.386 --> 00:52:39.966
mode to get early feedback about

00:52:39.966 --> 00:52:41.046
the detection quality.

00:52:41.866 --> 00:52:44.776
So, you may want to go around

00:52:44.776 --> 00:52:46.126
the object from different points

00:52:46.126 --> 00:52:47.796
of view and verify that the

00:52:47.796 --> 00:52:49.776
object is detected from all

00:52:50.336 --> 00:52:51.696
these different point of view.

00:52:51.696 --> 00:52:53.816
You can point your device away,

00:52:53.816 --> 00:52:55.086
come back from another angle,

00:52:55.836 --> 00:52:58.386
and make sure that the scan was

00:52:58.386 --> 00:53:00.006
good to detect the object.

00:53:00.526 --> 00:53:03.106
You can also, move these objects

00:53:03.276 --> 00:53:04.506
around so that the light

00:53:04.506 --> 00:53:05.866
condition will be different.

00:53:06.836 --> 00:53:08.216
And you want to make sure that

00:53:08.216 --> 00:53:09.196
those are still detected.

00:53:09.196 --> 00:53:10.316
This is particularly important

00:53:10.366 --> 00:53:12.536
for objects like toys that you

00:53:12.536 --> 00:53:13.646
don't know where they're

00:53:13.646 --> 00:53:14.986
actually going to be physically

00:53:15.106 --> 00:53:15.546
located.

00:53:17.096 --> 00:53:18.776
We, also, suggest that you take

00:53:18.776 --> 00:53:20.176
the object and put it in a

00:53:20.176 --> 00:53:21.556
completely different environment

00:53:22.016 --> 00:53:24.036
and still make sure that it is

00:53:24.076 --> 00:53:24.576
detected.

00:53:25.666 --> 00:53:27.756
In case this is not detected you

00:53:27.756 --> 00:53:28.806
may want to go back to the

00:53:28.806 --> 00:53:31.406
scanning and make sure that your

00:53:31.406 --> 00:53:32.506
environment is well lit.

00:53:33.786 --> 00:53:35.956
We really like, well lit

00:53:35.956 --> 00:53:37.156
environment during the scanning

00:53:37.266 --> 00:53:37.916
is very important.

00:53:38.506 --> 00:53:39.776
If if you have a lux meter, it will

00:53:39.776 --> 00:53:41.916
be about 500 lux will be best.

00:53:43.046 --> 00:53:45.006
And if that is still not enough,

00:53:45.166 --> 00:53:46.556
you may want to keep different

00:53:46.556 --> 00:53:50.446
versions of the scans.

00:53:50.576 --> 00:53:51.826
So, at this point, once you're

00:53:51.826 --> 00:53:53.266
happy with the detection quality

00:53:53.266 --> 00:53:55.136
you can simply drop the model to

00:53:55.136 --> 00:53:57.846
your Mac and add it to the AR

00:53:57.846 --> 00:53:59.656
Resource Groups, just like you

00:53:59.746 --> 00:54:03.016
did for the images.

00:54:03.016 --> 00:54:04.526
Also note that there are some

00:54:04.526 --> 00:54:05.886
objects that will work really

00:54:05.886 --> 00:54:07.366
great with this system.

00:54:07.586 --> 00:54:08.706
Object like you can see on the

00:54:08.706 --> 00:54:08.986
left.

00:54:09.586 --> 00:54:10.956
First of all, they are rigid

00:54:10.956 --> 00:54:13.206
objects and they are, also, rich

00:54:13.206 --> 00:54:14.696
of texture, distinctive enough.

00:54:15.436 --> 00:54:16.416
But there are also certain kinds

00:54:16.416 --> 00:54:17.526
of object that will not work

00:54:17.686 --> 00:54:18.506
well with the system.

00:54:19.066 --> 00:54:21.256
You can see an example of this

00:54:21.256 --> 00:54:22.136
on the right.

00:54:22.686 --> 00:54:24.756
And for example, metallic,

00:54:24.826 --> 00:54:26.606
transparent, or metallic or

00:54:26.606 --> 00:54:27.796
reflective objects will not

00:54:27.856 --> 00:54:28.096
work.

00:54:29.206 --> 00:54:31.496
Or transparent objects like

00:54:31.576 --> 00:54:32.796
glass material object will also

00:54:32.796 --> 00:54:34.376
not work because the appearance

00:54:34.376 --> 00:54:35.236
of these objects will really

00:54:35.236 --> 00:54:37.766
depend on where they are in the

00:54:38.816 --> 00:54:38.936
scene.

00:54:39.756 --> 00:54:41.076
So, that was how to scan the

00:54:41.076 --> 00:54:41.506
objects.

00:54:41.706 --> 00:54:43.126
Again, make sure that you have

00:54:43.126 --> 00:54:44.026
well-lit environment.

00:54:44.996 --> 00:54:46.596
Let's now see how we can detect

00:54:46.646 --> 00:54:48.056
this in ARKit.

00:54:50.046 --> 00:54:51.956
If this looks familiar to you,

00:54:51.956 --> 00:54:53.606
it's because the API is pretty

00:54:53.606 --> 00:54:54.536
similar to the one of the

00:54:54.536 --> 00:54:55.006
images.

00:54:55.586 --> 00:54:56.716
We have a convenience method

00:54:56.816 --> 00:54:58.586
to gather all the objects in a

00:54:58.586 --> 00:54:58.896
group.

00:54:59.506 --> 00:55:00.656
This time is in the

00:55:00.656 --> 00:55:01.916
ARReferenceObjects class.

00:55:02.806 --> 00:55:05.136
And to configure your

00:55:05.136 --> 00:55:07.056
ARWorldTracking configuration,

00:55:07.056 --> 00:55:08.516
you simply pass this object to

00:55:08.516 --> 00:55:10.876
the detectionObjects property.

00:55:13.206 --> 00:55:15.566
Once you run the session, again,

00:55:15.566 --> 00:55:17.236
you will find your results.

00:55:18.306 --> 00:55:19.356
And in this case, you want to

00:55:19.356 --> 00:55:21.656
check for the ARObjectAnchor,

00:55:22.386 --> 00:55:23.656
which will give you the position

00:55:23.786 --> 00:55:25.436
and orientation of the object

00:55:25.436 --> 00:55:27.866
with respect to the world.

00:55:28.716 --> 00:55:30.346
And also, the name of the object

00:55:30.346 --> 00:55:33.086
as was given in the asset

00:55:35.016 --> 00:55:35.246
catalog.

00:55:35.246 --> 00:55:36.516
So, you guys may have noticed

00:55:36.706 --> 00:55:38.316
some similarities between the

00:55:38.316 --> 00:55:40.506
object detection and the world

00:55:40.506 --> 00:55:42.726
mapping relocalization.

00:55:43.426 --> 00:55:44.206
But there's also few

00:55:44.206 --> 00:55:44.806
differences.

00:55:44.856 --> 00:55:46.316
So, in the case of the object

00:55:46.316 --> 00:55:48.406
detection we are always giving

00:55:48.746 --> 00:55:50.446
the object position with respect

00:55:50.446 --> 00:55:50.946
to the world.

00:55:51.506 --> 00:55:52.426
While in the world map

00:55:52.426 --> 00:55:53.966
relocalization is the camera

00:55:53.966 --> 00:55:56.066
itself that adjusts to the

00:55:56.066 --> 00:55:56.816
previous world map.

00:55:58.286 --> 00:56:00.306
In addition, you can detect

00:56:00.536 --> 00:56:01.336
multiple objects.

00:56:01.966 --> 00:56:03.626
And object detection works best

00:56:03.736 --> 00:56:05.306
for objects which are tabletop,

00:56:05.496 --> 00:56:06.376
furniture sized.

00:56:07.146 --> 00:56:08.446
While, the world map is really

00:56:08.446 --> 00:56:09.536
the whole scene that's been

00:56:09.776 --> 00:56:10.266
acquired.

00:56:10.776 --> 00:56:13.756
With this insight, we conclude the

00:56:13.756 --> 00:56:14.576
object detection.

00:56:14.686 --> 00:56:16.266
Let's summarize what you have

00:56:17.796 --> 00:56:19.336
seen, today.

00:56:19.516 --> 00:56:21.876
Orientation tracking tracks only

00:56:21.876 --> 00:56:23.696
the rotation of the device and

00:56:23.696 --> 00:56:25.756
can be used to explore statical

00:56:25.756 --> 00:56:26.416
environments.

00:56:27.946 --> 00:56:29.266
World Tracking is the fully

00:56:29.266 --> 00:56:30.776
featured position and

00:56:30.776 --> 00:56:32.246
orientation tracking, which will

00:56:32.246 --> 00:56:33.926
give you the device position

00:56:33.926 --> 00:56:36.286
with respect to a world origin.

00:56:37.016 --> 00:56:38.776
And enables all the scene

00:56:38.776 --> 00:56:40.486
understanding capabilities like

00:56:41.166 --> 00:56:43.366
the Plane Detection, which will

00:56:44.476 --> 00:56:46.256
make you able to interact with

00:56:46.256 --> 00:56:48.546
the physical, horizontal, and

00:56:48.546 --> 00:56:50.226
vertical planes where you can

00:56:50.226 --> 00:56:51.636
then put virtual objects.

00:56:51.996 --> 00:56:55.306
We have seen how you can create

00:56:55.656 --> 00:56:57.036
persistent or multiuser

00:56:57.036 --> 00:56:58.926
experiences with the saving and

00:56:58.926 --> 00:57:00.116
loading map features in the

00:57:00.116 --> 00:57:00.566
ARKit2.

00:57:01.516 --> 00:57:03.036
And how you can detect physical

00:57:03.036 --> 00:57:04.816
images and track them at 60

00:57:04.816 --> 00:57:06.096
frames per second with the image

00:57:06.096 --> 00:57:08.596
tracking and how you can detect

00:57:08.596 --> 00:57:09.916
more generic objects with the

00:57:09.916 --> 00:57:11.176
object detections.

00:57:12.576 --> 00:57:15.216
And with this, I really hope you

00:57:15.216 --> 00:57:15.946
guys have a better

00:57:15.946 --> 00:57:17.496
understanding, now, of all the

00:57:17.496 --> 00:57:19.126
different tracking technology

00:57:19.586 --> 00:57:20.816
that are present in ARKit and

00:57:20.816 --> 00:57:22.016
how they work behind the scenes.

00:57:23.006 --> 00:57:24.666
And how you can get the best

00:57:24.806 --> 00:57:25.976
quality out of it.

00:57:26.436 --> 00:57:28.106
And we're really looking forward

00:57:28.106 --> 00:57:29.226
to see what you guys are going

00:57:29.226 --> 00:57:29.656
to do with that.

00:57:30.976 --> 00:57:32.416
More information can be found at

00:57:32.486 --> 00:57:33.636
the session link in the

00:57:33.636 --> 00:57:34.496
developer website.

00:57:34.496 --> 00:57:36.226
And we have an ARKit Lab

00:57:36.536 --> 00:57:37.586
tomorrow, 9 a.m.

00:57:38.356 --> 00:57:39.806
We will both, me and Marion will

00:57:39.806 --> 00:57:41.786
be there answering any question

00:57:41.786 --> 00:57:42.666
on ARKit you may have.

00:57:43.756 --> 00:57:44.976
And with that, thank you, very

00:57:44.976 --> 00:57:46.976
much and enjoy the bash.

00:57:47.516 --> 00:57:53.506
[ Applause ]