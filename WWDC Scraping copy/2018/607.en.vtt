WEBVTT

00:00:07.516 --> 00:00:15.500
[ Music ]

00:00:21.516 --> 00:00:26.466
[ Applause ]

00:00:26.966 --> 00:00:27.686
>> Welcome.

00:00:28.626 --> 00:00:30.496
Last year, we introduced Metal

00:00:30.616 --> 00:00:32.996
2, which includes new ways for

00:00:32.996 --> 00:00:34.426
the GPU to drive the rendering

00:00:34.426 --> 00:00:34.936
pipeline.

00:00:36.036 --> 00:00:37.526
This year, we're introducing

00:00:37.526 --> 00:00:39.046
even more new and exciting

00:00:39.046 --> 00:00:41.046
features to solve common game

00:00:41.046 --> 00:00:42.026
development challenges.

00:00:43.086 --> 00:00:44.556
My name is Brian Ross, and

00:00:44.556 --> 00:00:45.676
together with my colleague,

00:00:46.096 --> 00:00:48.016
Michael Imbrogno, we'll explore

00:00:48.016 --> 00:00:49.416
new ways to make your

00:00:49.416 --> 00:00:52.606
applications better, faster, and

00:00:52.606 --> 00:00:53.266
more efficient.

00:00:54.776 --> 00:00:57.016
But first, I want to talk about

00:00:57.016 --> 00:00:58.336
some of the challenges that I'm

00:00:58.336 --> 00:00:59.426
trying to help you solve.

00:01:00.806 --> 00:01:02.086
Your games are using an

00:01:02.086 --> 00:01:03.176
ever-increasing number of

00:01:03.176 --> 00:01:05.896
objects, materials, and lights.

00:01:07.056 --> 00:01:08.706
Games like Inside, for example,

00:01:09.156 --> 00:01:10.696
use a great deal of special

00:01:10.696 --> 00:01:12.956
effects to capture and support

00:01:13.006 --> 00:01:14.316
the mood of the game.

00:01:16.296 --> 00:01:17.486
Making games like this that

00:01:17.586 --> 00:01:19.606
truly draw you in is challenging

00:01:19.606 --> 00:01:21.836
because it can require efficient

00:01:22.006 --> 00:01:23.196
GPU utilization.

00:01:23.756 --> 00:01:27.176
At the same time, games are

00:01:27.176 --> 00:01:28.886
requiring more and more CPU

00:01:28.886 --> 00:01:30.436
cycles for exciting gameplay.

00:01:31.026 --> 00:01:33.116
For example, games like Tomb

00:01:33.116 --> 00:01:34.336
Raider that features

00:01:34.336 --> 00:01:36.256
breathtaking vistas and

00:01:36.256 --> 00:01:38.466
highly-detailed terrain, but, at

00:01:38.526 --> 00:01:40.116
the same time, they're also

00:01:40.116 --> 00:01:41.946
managing complex physics

00:01:41.946 --> 00:01:43.056
simulations in AI.

00:01:44.066 --> 00:01:45.166
This is challenging because it

00:01:45.166 --> 00:01:47.396
leaves less CPU time for

00:01:47.396 --> 00:01:47.846
rendering.

00:01:49.556 --> 00:01:52.206
And finally, developers are

00:01:52.206 --> 00:01:55.076
taking AAA titles like Fortnite

00:01:55.076 --> 00:01:57.456
from Epic Games, importing them

00:01:57.456 --> 00:01:59.606
to iOS so you can run a

00:01:59.606 --> 00:02:01.716
console-level game in the palm

00:02:01.716 --> 00:02:02.326
of your hand.

00:02:02.976 --> 00:02:04.746
This is a truly amazing feat,

00:02:05.496 --> 00:02:06.956
but this also leaves us with

00:02:06.956 --> 00:02:09.336
even more challenges, like how

00:02:09.336 --> 00:02:11.456
to balance battery life with a

00:02:11.456 --> 00:02:12.326
great frame rate.

00:02:12.896 --> 00:02:14.686
So now, let's look at how Metal

00:02:14.906 --> 00:02:16.316
can help you solve these

00:02:16.316 --> 00:02:17.056
challenges.

00:02:18.656 --> 00:02:21.076
Today, I'm going to show you how

00:02:21.076 --> 00:02:22.996
to harness parallelism on both

00:02:22.996 --> 00:02:25.806
the CPU and the GPU to draw more

00:02:25.806 --> 00:02:26.756
complex scenes.

00:02:29.466 --> 00:02:31.386
We'll also talk about ways to

00:02:31.386 --> 00:02:33.456
maximize performance using more

00:02:33.456 --> 00:02:35.306
explicit control with heaps,

00:02:35.596 --> 00:02:36.946
fences, and events.

00:02:37.386 --> 00:02:41.116
And then, I'm going to show you

00:02:41.116 --> 00:02:43.366
how to build GPU-driven

00:02:43.366 --> 00:02:44.816
pipelines using our latest

00:02:44.816 --> 00:02:46.656
features, argument buffers and

00:02:46.656 --> 00:02:47.896
indirect command buffers.

00:02:48.306 --> 00:02:49.656
Now, while all these API

00:02:49.656 --> 00:02:51.606
improvements are key, it's

00:02:51.606 --> 00:02:53.446
equally important to understand

00:02:53.446 --> 00:02:54.776
the underlying hardware they run

00:02:54.776 --> 00:02:55.026
on.

00:02:55.866 --> 00:02:57.776
So the next section, my

00:02:57.776 --> 00:02:59.226
colleague Michael is going to

00:02:59.226 --> 00:03:01.126
show you how to optimize for the

00:03:01.126 --> 00:03:03.086
A11 to improve performance

00:03:03.246 --> 00:03:04.286
extend playtime.

00:03:05.176 --> 00:03:08.616
And finally, I'm really excited

00:03:08.616 --> 00:03:09.756
that we're going to be joined by

00:03:09.756 --> 00:03:12.386
Nick Penwarden from Epic Games.

00:03:12.736 --> 00:03:14.366
He is going to show us how

00:03:14.366 --> 00:03:15.836
they've used Metal to bring

00:03:15.836 --> 00:03:17.736
console-level games to our

00:03:17.736 --> 00:03:18.206
devices.

00:03:19.216 --> 00:03:23.286
So let's get started.

00:03:23.286 --> 00:03:25.176
Harnessing both CPU and GPU

00:03:25.176 --> 00:03:27.526
parallelism is probably the most

00:03:27.526 --> 00:03:28.816
important and easiest

00:03:28.816 --> 00:03:32.116
optimization you can make.

00:03:32.116 --> 00:03:33.346
Building a command stream on a

00:03:33.346 --> 00:03:34.996
single thread is not sufficient

00:03:34.996 --> 00:03:35.476
anymore.

00:03:36.266 --> 00:03:38.076
The latest iPhone has 6 cores,

00:03:38.356 --> 00:03:39.836
and the iMac Pro can have up to

00:03:39.876 --> 00:03:40.476
18.

00:03:41.186 --> 00:03:42.876
So scalable, multithreaded

00:03:42.876 --> 00:03:45.856
architecture is key to great

00:03:45.856 --> 00:03:48.396
performance on all of our

00:03:49.576 --> 00:03:49.896
devices.

00:03:49.896 --> 00:03:51.286
Metal is designed for

00:03:51.286 --> 00:03:51.936
multithreading.

00:03:51.936 --> 00:03:53.736
I'm going to show you 2 ways how

00:03:53.736 --> 00:03:55.966
to parallelize on the CPU, and

00:03:55.966 --> 00:03:56.826
then I'm going to close this

00:03:56.826 --> 00:03:58.526
section by showing you how Metal

00:03:58.526 --> 00:04:00.036
could automatically parallelize

00:04:00.036 --> 00:04:01.346
for you on the GPU.

00:04:02.606 --> 00:04:04.426
So let's set up an example of a

00:04:04.466 --> 00:04:05.726
typical game frame.

00:04:06.816 --> 00:04:08.486
With a classic, single-threaded

00:04:08.486 --> 00:04:10.026
rendering, you'd [inaudible]

00:04:10.156 --> 00:04:13.146
build GPU commands and GPU

00:04:13.146 --> 00:04:14.826
execution order into a single

00:04:14.826 --> 00:04:15.446
command buffer.

00:04:16.446 --> 00:04:17.596
Typically, you're then having to

00:04:17.596 --> 00:04:18.995
fit this into some small

00:04:18.995 --> 00:04:20.266
fraction of your frame time.

00:04:21.016 --> 00:04:22.766
And, of course, you're going to

00:04:22.766 --> 00:04:24.486
have maximum latency because the

00:04:24.486 --> 00:04:26.096
entire command buffer must be

00:04:26.096 --> 00:04:28.036
encoded before the GPU can

00:04:28.036 --> 00:04:29.086
consume it.

00:04:29.436 --> 00:04:30.586
Obviously, there's a better way

00:04:30.586 --> 00:04:32.366
to do this, so what we're going

00:04:32.366 --> 00:04:34.346
to do is we're going to start by

00:04:34.346 --> 00:04:35.976
building in parallelism with the

00:04:36.056 --> 00:04:36.546
CPU.

00:04:37.036 --> 00:04:41.766
Render and compute passes are

00:04:41.766 --> 00:04:43.156
the basic granularity of

00:04:43.156 --> 00:04:44.146
multithread in Metal.

00:04:45.046 --> 00:04:46.376
All you need to do is create

00:04:46.376 --> 00:04:48.616
multiple command buffers and

00:04:48.616 --> 00:04:50.326
start encoding each into

00:04:50.326 --> 00:04:51.536
separate passes on a separate

00:04:51.536 --> 00:04:51.806
thread.

00:04:52.356 --> 00:04:55.226
You can encode them in any order

00:04:55.226 --> 00:04:55.806
you wish.

00:04:56.236 --> 00:04:57.856
The final order of execution is

00:04:57.856 --> 00:04:59.156
determined by the order they're

00:04:59.156 --> 00:05:00.216
added to the command queue.

00:05:01.026 --> 00:05:02.696
So now, let's take a look at how

00:05:02.696 --> 00:05:04.316
easy this is to do in your code.

00:05:04.316 --> 00:05:09.176
So you can see this is not a lot

00:05:09.176 --> 00:05:09.606
of code.

00:05:10.136 --> 00:05:11.016
The first thing that you're

00:05:11.016 --> 00:05:13.816
going to do is create any number

00:05:13.816 --> 00:05:14.856
of command buffers from the

00:05:14.856 --> 00:05:15.146
queue.

00:05:16.346 --> 00:05:19.126
Next, we're going to define the

00:05:19.126 --> 00:05:21.456
GPU execution order upfront by

00:05:21.456 --> 00:05:22.846
using the enqueue interface.

00:05:23.366 --> 00:05:25.526
This is great because you can do

00:05:25.526 --> 00:05:27.076
all this without waiting for the

00:05:27.076 --> 00:05:28.276
command buffer to be encoded

00:05:28.276 --> 00:05:28.746
first.

00:05:29.436 --> 00:05:31.906
And finally, we're going to

00:05:31.906 --> 00:05:33.696
create separate threads and

00:05:33.696 --> 00:05:35.096
caller encoding functions for

00:05:35.096 --> 00:05:35.536
each.

00:05:35.826 --> 00:05:36.506
And that's it.

00:05:36.966 --> 00:05:37.996
That's all you have to do.

00:05:38.566 --> 00:05:40.186
It's really fast, it's really

00:05:40.186 --> 00:05:41.046
efficient, and it's really

00:05:41.046 --> 00:05:41.446
simple.

00:05:42.136 --> 00:05:43.516
So now, let's go back to the

00:05:43.516 --> 00:05:45.136
previous diagram and look at

00:05:45.136 --> 00:05:45.896
another example.

00:05:46.246 --> 00:05:49.166
So as you can see, we did a

00:05:49.166 --> 00:05:51.356
pretty good job parallelizing

00:05:51.356 --> 00:05:54.196
these on the CPU, but what if

00:05:54.196 --> 00:05:56.146
you have 1 really long rendering

00:05:58.116 --> 00:05:58.826
pass?

00:05:58.826 --> 00:06:01.036
So in cases like this, Metal has

00:06:01.036 --> 00:06:02.726
a dedicated parallel encoder

00:06:02.766 --> 00:06:04.986
that allows you to encode on

00:06:04.986 --> 00:06:06.586
multiple threads without

00:06:06.586 --> 00:06:08.266
explicitly dividing up the

00:06:08.266 --> 00:06:09.646
render pass or the command

00:06:09.646 --> 00:06:10.026
buffer.

00:06:10.686 --> 00:06:12.286
So now, let's look at how simple

00:06:12.286 --> 00:06:13.786
this is in your code.

00:06:14.866 --> 00:06:16.546
It looks a lot like the previous

00:06:16.546 --> 00:06:17.106
example.

00:06:17.776 --> 00:06:18.956
The first thing you're going to

00:06:18.956 --> 00:06:21.066
do is create a parallel encoder.

00:06:21.606 --> 00:06:23.776
And from that, you create any

00:06:23.776 --> 00:06:25.386
number of subordinate encoders.

00:06:25.436 --> 00:06:27.066
And it's important to realize

00:06:27.066 --> 00:06:28.146
that this is actually where you

00:06:28.146 --> 00:06:29.976
define the GPU execution order.

00:06:32.026 --> 00:06:35.356
Next, we're going to create

00:06:35.356 --> 00:06:37.736
separate threads and encode each

00:06:37.776 --> 00:06:39.126
of our G-buffer functions

00:06:39.866 --> 00:06:40.406
separately.

00:06:40.966 --> 00:06:44.956
And finally, we set up a

00:06:44.956 --> 00:06:46.286
notification so that when the

00:06:46.286 --> 00:06:48.726
threads are complete, we call

00:06:48.726 --> 00:06:49.866
end encoding on the parallel

00:06:49.866 --> 00:06:50.296
encoder.

00:06:50.296 --> 00:06:50.926
And that is it.

00:06:51.186 --> 00:06:52.866
That's all you have to do to

00:06:52.866 --> 00:06:54.416
parallelize a render pass.

00:06:54.486 --> 00:06:55.606
It's really fast, and it's

00:06:55.606 --> 00:06:56.206
really easy.

00:06:56.206 --> 00:06:58.126
So now that I've shown you 2

00:06:58.126 --> 00:06:59.886
ways to parallelize on the CPU,

00:07:00.836 --> 00:07:01.986
now let's see how Metal can

00:07:01.986 --> 00:07:02.766
parallelize for you

00:07:02.766 --> 00:07:04.366
automatically on the GPU.

00:07:04.946 --> 00:07:07.316
So let's look at the frame

00:07:07.316 --> 00:07:10.176
example from the beginning and

00:07:10.176 --> 00:07:11.916
see how the GPU executes the

00:07:11.916 --> 00:07:12.316
frame.

00:07:13.296 --> 00:07:14.546
Based on the capabilities of

00:07:14.546 --> 00:07:17.006
your platform, Metal can extract

00:07:17.006 --> 00:07:19.376
parallelism automatically by

00:07:19.376 --> 00:07:20.326
analyzing your data

00:07:20.326 --> 00:07:20.956
dependencies.

00:07:21.576 --> 00:07:22.746
Let's look at just 2 of these

00:07:22.746 --> 00:07:23.376
dependencies.

00:07:24.726 --> 00:07:26.436
So in this example, the particle

00:07:26.436 --> 00:07:28.416
simulation writes data, which is

00:07:28.416 --> 00:07:30.116
later used by the effects pass

00:07:30.316 --> 00:07:31.456
to render the particles.

00:07:32.816 --> 00:07:35.586
Similarly, the G-buffer pass

00:07:36.106 --> 00:07:37.796
generates geometry, which is

00:07:37.796 --> 00:07:38.916
later used by the deferred

00:07:38.916 --> 00:07:41.096
shading pass to compute material

00:07:43.096 --> 00:07:43.256
lighting.

00:07:43.486 --> 00:07:45.216
All this information allows

00:07:45.216 --> 00:07:46.686
Metal to automatically and

00:07:46.686 --> 00:07:49.276
cheaply identify entire passes

00:07:49.816 --> 00:07:51.236
that can run in parallel, such

00:07:51.236 --> 00:07:52.416
as using async compute.

00:07:55.616 --> 00:07:57.896
So you can achieve parallelism

00:07:57.936 --> 00:08:00.166
and async compute for free on

00:08:00.166 --> 00:08:00.786
the GPU.

00:08:01.256 --> 00:08:02.436
It's free because Metal doesn't

00:08:02.436 --> 00:08:03.446
require you to do anything

00:08:03.446 --> 00:08:04.486
special on your part.

00:08:04.486 --> 00:08:07.366
So I think we all love getting

00:08:07.366 --> 00:08:09.096
free optimizations on the GPU,

00:08:09.726 --> 00:08:10.896
but sometimes you as a

00:08:10.896 --> 00:08:13.346
developer, you may need to dive

00:08:13.346 --> 00:08:14.136
a little bit deeper.

00:08:14.786 --> 00:08:16.506
For the most critical parts of

00:08:16.506 --> 00:08:18.286
your code, Metal allows you to

00:08:18.316 --> 00:08:20.006
incrementally dive deeper with

00:08:20.006 --> 00:08:20.646
more control.

00:08:21.126 --> 00:08:23.546
For example, you could disable

00:08:23.546 --> 00:08:25.056
automatic reference counting and

00:08:25.056 --> 00:08:27.006
do it yourself to save on CPU

00:08:27.006 --> 00:08:27.286
time.

00:08:28.116 --> 00:08:30.266
You could also use Metal heaps

00:08:30.626 --> 00:08:32.395
to tightly control allocations

00:08:32.626 --> 00:08:33.466
really cheaply.

00:08:33.956 --> 00:08:36.616
And Metal heaps are complemented

00:08:36.616 --> 00:08:39.025
by fences and events, which

00:08:39.025 --> 00:08:41.126
allow you to explicitly control

00:08:41.126 --> 00:08:42.316
the GPU parallelism.

00:08:44.376 --> 00:08:46.736
Many of your games are using a

00:08:46.736 --> 00:08:48.316
lot of resources, which can be

00:08:48.316 --> 00:08:48.906
costly.

00:08:49.476 --> 00:08:51.526
Allocations require a round trip

00:08:51.526 --> 00:08:54.076
to the OS, which has to map and

00:08:54.076 --> 00:08:55.536
initialize memory on each

00:08:55.576 --> 00:08:56.096
request.

00:08:56.876 --> 00:08:58.066
If your game uses temporary

00:08:58.066 --> 00:08:59.606
render targets, these

00:08:59.606 --> 00:09:00.796
allocations can happen in the

00:09:00.796 --> 00:09:02.146
middle of your frame, causing

00:09:02.146 --> 00:09:02.866
stutters.

00:09:03.726 --> 00:09:05.156
Resource heaps are a great

00:09:05.256 --> 00:09:06.396
solution to this problem.

00:09:07.556 --> 00:09:08.786
Heaps also let you allocate

00:09:09.386 --> 00:09:11.246
large slabs of memory from the

00:09:11.246 --> 00:09:12.196
system upfront.

00:09:12.456 --> 00:09:13.566
And from those, you can later

00:09:13.606 --> 00:09:14.966
add or remove textures and

00:09:14.966 --> 00:09:16.546
buffers from those slabs without

00:09:16.546 --> 00:09:18.286
any costly round trip.

00:09:18.836 --> 00:09:20.836
So starting from a case where

00:09:20.836 --> 00:09:22.996
you allocate 3 normal textures,

00:09:23.866 --> 00:09:25.406
Metal typically places these in

00:09:25.406 --> 00:09:27.876
3 separate allocations, but

00:09:27.986 --> 00:09:29.776
putting these all instead into a

00:09:29.776 --> 00:09:31.976
single heap lets you perform all

00:09:31.976 --> 00:09:34.396
memory allocation upfront at

00:09:34.396 --> 00:09:35.286
heap creation time.

00:09:35.696 --> 00:09:37.456
So then, the act of creating

00:09:37.456 --> 00:09:38.926
textures becomes extremely

00:09:38.926 --> 00:09:39.296
cheap.

00:09:40.506 --> 00:09:42.956
Also, heaps can sometimes let us

00:09:42.956 --> 00:09:44.836
use the space more efficiently

00:09:45.206 --> 00:09:46.856
by packing allocations closer

00:09:46.856 --> 00:09:47.286
together.

00:09:48.396 --> 00:09:50.696
So with a traditional model, you

00:09:50.696 --> 00:09:51.886
would deallocate textures,

00:09:52.736 --> 00:09:53.836
releasing pages back to the

00:09:53.836 --> 00:09:55.836
system, and then reallocate,

00:09:56.536 --> 00:09:57.796
which will allocate a new set of

00:09:57.796 --> 00:09:58.976
textures all over again.

00:09:59.476 --> 00:10:02.006
With heaps, you deallocate and

00:10:02.006 --> 00:10:04.436
reallocate without any costly

00:10:04.436 --> 00:10:06.226
round trip to the OS.

00:10:08.156 --> 00:10:09.846
Finally, heaps also let you

00:10:09.846 --> 00:10:11.776
alias different memory resources

00:10:11.776 --> 00:10:12.406
with each other.

00:10:14.086 --> 00:10:15.376
This is really helpful if your

00:10:15.376 --> 00:10:16.916
game frame has a lot of

00:10:16.916 --> 00:10:18.166
temporary render targets.

00:10:18.686 --> 00:10:19.846
There's no reason for these to

00:10:19.846 --> 00:10:21.276
occupy a different memory all

00:10:21.276 --> 00:10:23.696
the time, so you could alias and

00:10:23.696 --> 00:10:25.546
save hundreds of megabytes.

00:10:26.236 --> 00:10:28.376
Now, the faster allocations in

00:10:28.376 --> 00:10:30.666
aliasing are great, but it's not

00:10:30.666 --> 00:10:31.996
entirely free when it comes to

00:10:31.996 --> 00:10:32.946
dependency tracking.

00:10:33.466 --> 00:10:34.536
Let's return to our frame

00:10:34.536 --> 00:10:35.546
example for a better

00:10:35.546 --> 00:10:36.306
explanation.

00:10:38.356 --> 00:10:40.786
With heaps, Metal no longer sees

00:10:40.786 --> 00:10:42.556
individual resources, so

00:10:42.556 --> 00:10:43.346
therefore, it can't

00:10:43.586 --> 00:10:44.956
automatically identify the read

00:10:44.956 --> 00:10:46.236
and write dependencies between

00:10:46.236 --> 00:10:48.366
passes, such as the G-buffer and

00:10:48.366 --> 00:10:49.516
deferred shading pass in our

00:10:49.516 --> 00:10:49.946
example.

00:10:51.056 --> 00:10:53.516
So you have to use fences to

00:10:53.516 --> 00:10:55.076
explicitly signal which pass

00:10:55.136 --> 00:10:57.276
produces data and which pass

00:10:57.386 --> 00:10:58.286
consumes the data.

00:10:58.906 --> 00:11:00.856
So in this example, the G-buffer

00:11:00.856 --> 00:11:02.576
updates the fence, and the

00:11:02.576 --> 00:11:03.766
deferred shading waits for it.

00:11:04.686 --> 00:11:08.266
So now, let's take a look at how

00:11:08.266 --> 00:11:09.406
we could apply these basic

00:11:09.406 --> 00:11:10.966
concepts in your code.

00:11:12.856 --> 00:11:15.206
So the first thing that we're

00:11:15.206 --> 00:11:16.006
going to do is we're going to

00:11:16.006 --> 00:11:17.456
apply this to our G-buffer and

00:11:17.456 --> 00:11:18.676
deferred shading example.

00:11:19.966 --> 00:11:21.356
First, we're going to allocate

00:11:21.356 --> 00:11:23.046
our temporary render target from

00:11:23.046 --> 00:11:23.436
the heap.

00:11:23.806 --> 00:11:24.866
This looks just like what you're

00:11:24.866 --> 00:11:26.046
probably already doing today

00:11:26.046 --> 00:11:28.706
when you allocate a texture.

00:11:28.846 --> 00:11:31.056
Next, we're going to render into

00:11:31.056 --> 00:11:32.246
that temporary render target.

00:11:33.166 --> 00:11:35.646
And finally, update the fence

00:11:36.316 --> 00:11:37.566
after the fragment stage

00:11:37.566 --> 00:11:38.216
completes.

00:11:38.386 --> 00:11:39.526
This will ensure that all the

00:11:39.526 --> 00:11:41.656
data is produced before the next

00:11:41.656 --> 00:11:42.956
pass consumes it.

00:11:43.706 --> 00:11:45.876
So now, let's switch gears over

00:11:45.876 --> 00:11:47.356
to the deferred shading pass.

00:11:48.156 --> 00:11:49.936
Now, we're going to use this

00:11:49.936 --> 00:11:51.346
temporary render target to

00:11:51.346 --> 00:11:52.606
compute material lighting.

00:11:54.836 --> 00:11:56.196
Then, we're going to wait for

00:11:56.196 --> 00:11:57.986
the fence to make sure that it's

00:11:58.046 --> 00:11:59.476
been produced before we consume

00:11:59.476 --> 00:11:59.566
it.

00:12:00.486 --> 00:12:03.486
And finally, market is aliasable

00:12:03.486 --> 00:12:05.046
so that we can reuse this for

00:12:05.046 --> 00:12:06.456
other operations, saving

00:12:06.456 --> 00:12:07.816
hundreds of megabytes.

00:12:08.916 --> 00:12:09.886
So now that we've talked about

00:12:09.886 --> 00:12:11.866
how to parallelize and optimize

00:12:11.906 --> 00:12:13.196
performance with explicit

00:12:13.196 --> 00:12:16.126
control, this is great, but what

00:12:16.126 --> 00:12:18.696
if you want to put the GPU more

00:12:18.696 --> 00:12:19.526
into the driving seat?

00:12:20.936 --> 00:12:23.276
So let's talk about GPU-driven

00:12:25.316 --> 00:12:25.566
pipelines.

00:12:25.626 --> 00:12:27.356
Your games are moving more and

00:12:27.356 --> 00:12:29.816
more of the decision logic onto

00:12:30.356 --> 00:12:32.556
the GPU, especially when it

00:12:32.556 --> 00:12:34.036
comes to processing extremely

00:12:34.036 --> 00:12:36.046
large data sets or scene graphs

00:12:36.046 --> 00:12:37.556
with thousands of objects.

00:12:38.666 --> 00:12:41.376
With Metal 2, we've made another

00:12:41.496 --> 00:12:43.226
really important step forward in

00:12:43.226 --> 00:12:44.656
our focus on GPU-driven

00:12:44.656 --> 00:12:45.236
pipelines.

00:12:46.236 --> 00:12:47.506
Last year, we introduced

00:12:47.606 --> 00:12:49.086
indirect argument buffers,

00:12:49.516 --> 00:12:51.386
allowing you to further decrease

00:12:51.386 --> 00:12:53.336
CPU usage and move a large

00:12:53.336 --> 00:12:54.646
portion of the workload to the

00:12:54.646 --> 00:12:55.166
GPU.

00:12:56.046 --> 00:12:57.056
This year, we're also

00:12:57.056 --> 00:12:59.346
introducing indirect command

00:12:59.346 --> 00:13:02.566
buffers, and this will allow you

00:13:02.566 --> 00:13:04.686
to move entire rendering loops

00:13:04.686 --> 00:13:05.526
onto the GPU.

00:13:06.776 --> 00:13:09.046
So first, let's briefly recap

00:13:09.146 --> 00:13:10.236
the argument buffer feature.

00:13:11.076 --> 00:13:12.826
An argument buffer is simply a

00:13:12.826 --> 00:13:16.386
structure represented like this.

00:13:17.756 --> 00:13:18.946
Previously, these would have

00:13:18.946 --> 00:13:20.026
only constants, but with

00:13:20.026 --> 00:13:21.256
argument buffers, we can have

00:13:21.326 --> 00:13:22.916
textures and samplers.

00:13:23.606 --> 00:13:24.716
Before, these would have to have

00:13:24.716 --> 00:13:26.646
separate shader bind points.

00:13:27.666 --> 00:13:30.226
So since this structure, you

00:13:30.226 --> 00:13:31.366
have all the features of the

00:13:31.366 --> 00:13:32.646
Metal shading language at your

00:13:32.646 --> 00:13:34.216
disposal, so it's really

00:13:34.216 --> 00:13:35.906
flexible and really easy.

00:13:36.196 --> 00:13:37.156
You could do things like add

00:13:37.156 --> 00:13:39.476
substructures, or arrays, or

00:13:39.476 --> 00:13:40.986
even pointers to other argument

00:13:40.986 --> 00:13:41.476
buffers.

00:13:43.156 --> 00:13:44.556
You could modify textures and

00:13:44.556 --> 00:13:46.856
samplers, creating new materials

00:13:46.856 --> 00:13:49.026
on a GPU without any CPU

00:13:49.026 --> 00:13:49.516
involvement.

00:13:50.766 --> 00:13:52.746
Or you can make giant arrays of

00:13:52.746 --> 00:13:54.446
materials and use a

00:13:54.446 --> 00:13:56.886
single-instance draw call to

00:13:56.886 --> 00:13:58.276
render many objects with unique

00:13:58.276 --> 00:13:58.956
properties.

00:14:00.466 --> 00:14:02.346
So argument buffers allow you to

00:14:02.986 --> 00:14:04.536
offload the material management

00:14:05.176 --> 00:14:07.036
onto the GPU and save valuable

00:14:07.146 --> 00:14:08.366
CPU resources.

00:14:08.916 --> 00:14:10.206
But this year, we're putting it

00:14:10.206 --> 00:14:11.546
a little bit, extending it a

00:14:11.546 --> 00:14:13.436
little bit more.

00:14:13.926 --> 00:14:15.506
We started by adding 2 new

00:14:15.506 --> 00:14:16.516
argument types.

00:14:17.426 --> 00:14:19.046
This includes pipeline states

00:14:19.156 --> 00:14:20.126
and command buffers.

00:14:21.056 --> 00:14:22.646
Now, these are used to support

00:14:22.646 --> 00:14:24.226
our brand-new indirect command

00:14:24.226 --> 00:14:24.836
buffer feature.

00:14:26.116 --> 00:14:27.916
With indirect command buffers,

00:14:27.916 --> 00:14:30.266
you could encode entire scenes

00:14:30.266 --> 00:14:30.956
on the GPU.

00:14:31.506 --> 00:14:33.066
On the CPU, you only have a few

00:14:33.066 --> 00:14:34.426
threads available for rendering,

00:14:34.866 --> 00:14:35.936
but on the GPU, you have

00:14:35.936 --> 00:14:37.986
hundreds or even thousands of

00:14:37.986 --> 00:14:40.036
threads all running at the same

00:14:40.886 --> 00:14:40.976
time.

00:14:41.716 --> 00:14:42.856
With indirect command buffers,

00:14:42.856 --> 00:14:44.416
you can fully utilize this

00:14:44.416 --> 00:14:45.916
massively parallel nature.

00:14:47.236 --> 00:14:49.186
Also, indirect command buffers

00:14:49.186 --> 00:14:51.376
are completely reusable, so you

00:14:51.376 --> 00:14:52.556
could spend the encoding cost

00:14:52.556 --> 00:14:54.866
once and reuse it again and

00:14:54.866 --> 00:14:55.196
again.

00:14:55.886 --> 00:14:57.626
And since an ICB is a directly

00:14:57.716 --> 00:15:00.276
accessible buffer, you can

00:15:00.276 --> 00:15:01.836
modify its contents at any time,

00:15:02.086 --> 00:15:03.976
like change the shader type, or

00:15:03.976 --> 00:15:05.276
the camera matrix, or anything

00:15:05.276 --> 00:15:06.056
else that you might need to

00:15:06.056 --> 00:15:06.606
change.

00:15:07.036 --> 00:15:09.476
And of course, by moving your

00:15:09.476 --> 00:15:11.566
rendering to the GPU, you remove

00:15:11.566 --> 00:15:13.886
expensive CPU and GPU

00:15:13.886 --> 00:15:15.216
synchronization points that are

00:15:15.216 --> 00:15:16.756
normally required to hand over

00:15:16.756 --> 00:15:17.126
the data.

00:15:18.346 --> 00:15:19.156
So let's take a look at an

00:15:19.156 --> 00:15:19.636
example.

00:15:20.706 --> 00:15:23.186
Here is a typical game frame.

00:15:23.646 --> 00:15:24.856
The usual rendering loop has a

00:15:24.856 --> 00:15:26.366
few common stages.

00:15:27.046 --> 00:15:29.066
First, you walk your scene graph

00:15:29.246 --> 00:15:30.806
to determine which objects you

00:15:30.806 --> 00:15:31.456
need to render.

00:15:32.016 --> 00:15:34.836
You probably use frustum culling

00:15:34.886 --> 00:15:36.226
to determine what objects are

00:15:36.226 --> 00:15:37.236
within the view frustum.

00:15:38.016 --> 00:15:39.266
Some of you might use a more

00:15:39.266 --> 00:15:41.486
complex solution that accounts

00:15:41.486 --> 00:15:42.206
for occlusion.

00:15:42.576 --> 00:15:44.956
Also, level of detail selection

00:15:45.056 --> 00:15:46.816
naturally occurs at this stage.

00:15:47.576 --> 00:15:49.326
Only once you encode and submit

00:15:49.326 --> 00:15:51.176
your command buffer will the GPU

00:15:51.176 --> 00:15:55.136
start to consume it.

00:15:55.816 --> 00:15:57.356
More and more games are moving

00:15:57.356 --> 00:15:58.776
the process of determining

00:15:58.776 --> 00:16:00.496
visible objects onto the GPU.

00:16:01.306 --> 00:16:03.236
GPUs are just better at handling

00:16:03.476 --> 00:16:04.906
the growing scene complexity of

00:16:04.906 --> 00:16:05.796
the latest games.

00:16:06.936 --> 00:16:09.526
Unfortunately, this creates a

00:16:09.526 --> 00:16:10.816
sync point in your frame.

00:16:12.456 --> 00:16:14.486
And the, it makes it so that the

00:16:14.486 --> 00:16:16.266
CPU cannot encode draw calls

00:16:16.266 --> 00:16:17.996
until the GPU produces the data.

00:16:18.466 --> 00:16:19.826
It's extremely difficult to get

00:16:19.826 --> 00:16:21.436
this right without wasting

00:16:21.436 --> 00:16:23.766
valuable CPU and GPU time on

00:16:23.766 --> 00:16:24.636
synchronization.

00:16:25.716 --> 00:16:27.566
With ICBs, the benefits are

00:16:27.566 --> 00:16:28.216
immense.

00:16:28.726 --> 00:16:30.176
Not only can you move the final

00:16:30.176 --> 00:16:32.086
bits of processing to the GPU,

00:16:32.646 --> 00:16:34.176
you naturally remove any sync

00:16:34.176 --> 00:16:35.426
points required to hand over the

00:16:35.426 --> 00:16:37.766
data and you improve your CPU

00:16:37.806 --> 00:16:39.076
and GPU utilization.

00:16:39.706 --> 00:16:42.116
At the same time, you reduce

00:16:42.116 --> 00:16:43.886
your CPU overhead to a constant.

00:16:44.566 --> 00:16:47.086
So let's look at the encoding in

00:16:47.086 --> 00:16:48.136
a little bit more detail.

00:16:49.166 --> 00:16:51.806
I'm going to start by expanding

00:16:51.806 --> 00:16:53.566
on our previous example and look

00:16:53.566 --> 00:16:55.316
at the massively parallel nature

00:16:55.316 --> 00:16:57.216
that only the GPU can provide.

00:16:57.876 --> 00:16:59.736
We could begin with the list of

00:16:59.736 --> 00:17:01.846
visible objects and LODs coming

00:17:01.846 --> 00:17:03.076
from our culling dispatch.

00:17:03.796 --> 00:17:05.165
Also, keep in mind that we're

00:17:05.165 --> 00:17:06.526
utilizing the power of argument

00:17:06.526 --> 00:17:07.066
buffers here.

00:17:07.896 --> 00:17:09.866
So in this case, each element

00:17:10.266 --> 00:17:12.816
has a pointer to the actual

00:17:12.816 --> 00:17:14.165
properties, so we don't need to

00:17:14.165 --> 00:17:15.496
store everything in the same

00:17:15.496 --> 00:17:15.896
buffer.

00:17:17.736 --> 00:17:20.136
This solution saves us a lot of

00:17:20.136 --> 00:17:21.906
memory and performance, and it's

00:17:22.116 --> 00:17:23.726
because we only build a very

00:17:23.726 --> 00:17:25.126
small list of information.

00:17:25.896 --> 00:17:27.026
The actual argument buffer

00:17:27.026 --> 00:17:28.786
contains several levels of

00:17:28.786 --> 00:17:29.866
detail for geometry.

00:17:30.936 --> 00:17:33.726
This includes position, vertex

00:17:33.726 --> 00:17:35.406
buffer, index buffer, and a

00:17:35.406 --> 00:17:36.626
material argument buffer.

00:17:37.256 --> 00:17:39.486
For rendering, we only select 1

00:17:39.876 --> 00:17:41.206
of these LODs per object.

00:17:41.836 --> 00:17:45.026
The actual encoding happens in a

00:17:45.026 --> 00:17:47.126
compute kernel, and we encode

00:17:47.126 --> 00:17:48.716
into an indirect command buffer.

00:17:49.826 --> 00:17:51.716
Each thread of the compute

00:17:51.716 --> 00:17:53.466
kernel encodes a single draw

00:17:53.466 --> 00:17:53.756
call.

00:17:54.226 --> 00:17:55.976
So we read the object with all

00:17:55.976 --> 00:17:58.756
of its properties, and we encode

00:17:58.756 --> 00:18:00.526
these into the ICB.

00:18:01.336 --> 00:18:03.216
There's a couple of details

00:18:03.216 --> 00:18:03.936
worth noting.

00:18:04.336 --> 00:18:06.036
You can think of an ICB as an

00:18:06.036 --> 00:18:07.196
array of render commands.

00:18:07.796 --> 00:18:09.156
A render command consists of a

00:18:09.156 --> 00:18:10.716
pipeline object with shaders,

00:18:11.136 --> 00:18:12.846
any number of buffers, and a

00:18:12.846 --> 00:18:14.466
draw call.

00:18:14.736 --> 00:18:16.366
Next, an ICB is built for

00:18:16.366 --> 00:18:18.446
parallelism, so you could encode

00:18:18.446 --> 00:18:20.256
concurrently and out of order.

00:18:20.756 --> 00:18:23.316
And lastly, we kept the API very

00:18:23.316 --> 00:18:25.126
simple, so it's just like what

00:18:25.126 --> 00:18:26.356
you might be doing today on the

00:18:26.356 --> 00:18:26.836
CPU.

00:18:28.116 --> 00:18:29.886
Another thing -- each command

00:18:29.886 --> 00:18:31.196
could have different properties

00:18:31.196 --> 00:18:32.306
and even draw types.

00:18:32.566 --> 00:18:35.116
So this is a really, really

00:18:35.116 --> 00:18:36.486
significant step forward from

00:18:36.486 --> 00:18:37.876
all the flavors of indirect

00:18:37.876 --> 00:18:38.996
rendering that many of you may

00:18:38.996 --> 00:18:39.886
have seen elsewhere.

00:18:40.976 --> 00:18:42.096
Now, let's take a look at how we

00:18:42.096 --> 00:18:43.036
can do this in your code.

00:18:44.416 --> 00:18:46.476
So this is how easy it is to

00:18:46.476 --> 00:18:47.526
encode a draw call.

00:18:48.436 --> 00:18:49.616
The first thing you're going to

00:18:49.616 --> 00:18:51.096
do is select the render command

00:18:51.096 --> 00:18:53.666
by index using your thread ID.

00:18:54.816 --> 00:18:56.576
Then, we're going to set the

00:18:56.576 --> 00:18:57.296
properties.

00:18:57.586 --> 00:18:58.906
So in this example, we're

00:18:58.906 --> 00:19:00.286
setting a shader with a pipeline

00:19:00.286 --> 00:19:03.396
state and then a separate buffer

00:19:03.396 --> 00:19:04.976
for the geometry and material.

00:19:05.886 --> 00:19:07.646
And finally, this is how you

00:19:07.646 --> 00:19:08.566
encode a draw call.

00:19:09.096 --> 00:19:10.126
Thanks to the Metal shading

00:19:10.126 --> 00:19:11.826
language, encoding on the GPU is

00:19:11.996 --> 00:19:13.136
really, really simple.

00:19:13.906 --> 00:19:15.486
Even though this is in a compute

00:19:15.486 --> 00:19:17.146
shader, this looks just like

00:19:17.146 --> 00:19:18.106
what you're already doing on the

00:19:18.106 --> 00:19:18.786
CPU today.

00:19:18.786 --> 00:19:21.196
Now, let's look at 1 more

00:19:21.196 --> 00:19:21.636
sample.

00:19:23.116 --> 00:19:24.336
Here are some of the basic

00:19:24.946 --> 00:19:26.706
things you need to do to create,

00:19:26.896 --> 00:19:28.746
encode, and execute an ICB.

00:19:29.956 --> 00:19:31.846
To create it, you first fill out

00:19:31.846 --> 00:19:32.576
a descriptor.

00:19:33.016 --> 00:19:34.646
The descriptor contains things

00:19:34.646 --> 00:19:38.136
like draw types, and inheritance

00:19:38.136 --> 00:19:39.836
properties, and per-stage bind

00:19:39.836 --> 00:19:40.346
counts.

00:19:40.596 --> 00:19:42.306
This describes the way that the

00:19:42.306 --> 00:19:43.446
indirect buffer will behave.

00:19:44.116 --> 00:19:47.726
When it's time to encode the

00:19:47.726 --> 00:19:49.506
ICB, you simply create compute

00:19:49.506 --> 00:19:50.996
encoder and call dispatch just

00:19:50.996 --> 00:19:51.806
like what you've been doing

00:19:51.806 --> 00:19:52.276
already.

00:19:54.046 --> 00:19:55.786
Once the ICB is encoded, you can

00:19:55.786 --> 00:19:57.306
optionally decide if you want to

00:19:57.306 --> 00:19:58.116
optimize it.

00:19:58.486 --> 00:19:59.786
When you optimize it, you remove

00:19:59.886 --> 00:20:01.526
all the redundant state, and the

00:20:01.526 --> 00:20:03.036
end result is a lean and

00:20:03.036 --> 00:20:04.536
highly-efficient set of GPU

00:20:04.536 --> 00:20:05.196
commands.

00:20:06.226 --> 00:20:08.876
Now, once the ICB is encoded and

00:20:08.876 --> 00:20:10.416
optimized, it's time to schedule

00:20:10.416 --> 00:20:11.286
it for execution.

00:20:11.776 --> 00:20:12.986
You notice here that you could

00:20:12.986 --> 00:20:14.996
actually specify the exact range

00:20:14.996 --> 00:20:16.396
of commands that you execute.

00:20:17.316 --> 00:20:18.736
Also in this example, we use an

00:20:18.736 --> 00:20:20.666
indirect buffer, which itself

00:20:21.076 --> 00:20:22.476
can be encoded with a GPU.

00:20:25.586 --> 00:20:28.066
So once the ICB is encoded, it

00:20:28.066 --> 00:20:29.746
could be reused again and again,

00:20:29.746 --> 00:20:31.526
and the overhead is completely

00:20:31.526 --> 00:20:32.146
negligible.

00:20:32.856 --> 00:20:33.966
So I'm really excited, but we

00:20:33.966 --> 00:20:35.236
actually went ahead and we put

00:20:35.236 --> 00:20:36.686
together a sample so you could

00:20:36.686 --> 00:20:37.206
take a look.

00:20:39.216 --> 00:20:41.066
So here you could see a number

00:20:41.066 --> 00:20:42.346
of school buses in the middle of

00:20:42.346 --> 00:20:42.756
a city.

00:20:43.996 --> 00:20:46.766
Each bus is composed of 500,000

00:20:46.766 --> 00:20:49.726
polygons and 2000 individual

00:20:49.726 --> 00:20:50.326
parts.

00:20:50.866 --> 00:20:53.446
Each part requires a separate

00:20:53.446 --> 00:20:55.116
draw call, its own material

00:20:55.116 --> 00:20:56.836
argument buffer, index buffer,

00:20:56.836 --> 00:20:57.636
and vertex buffer.

00:20:58.606 --> 00:21:00.006
As you could imagine, this would

00:21:00.006 --> 00:21:01.966
be a lot of API calls on the

00:21:02.036 --> 00:21:04.116
CPU, but we are using indirect

00:21:04.116 --> 00:21:05.106
command buffers here, so

00:21:05.156 --> 00:21:06.806
everything is being encoded on

00:21:06.806 --> 00:21:07.356
the GPU.

00:21:09.276 --> 00:21:10.786
We're also selecting the

00:21:10.926 --> 00:21:12.926
appropriate level of detail, and

00:21:12.926 --> 00:21:13.906
therefore, we're able to render

00:21:13.906 --> 00:21:16.676
multiple objects without

00:21:16.676 --> 00:21:19.046
increasing the CPU or GPU cost.

00:21:19.736 --> 00:21:20.966
So on the left, you could see a

00:21:20.966 --> 00:21:22.486
view of the regular camera.

00:21:22.776 --> 00:21:23.906
And on the right, we've zoomed

00:21:23.906 --> 00:21:25.786
in to a single bus, so you could

00:21:25.786 --> 00:21:27.316
see the level of detail actually

00:21:27.316 --> 00:21:27.916
changing.

00:21:29.126 --> 00:21:31.346
ICBs enabled us to introduce

00:21:31.346 --> 00:21:32.936
another really incredible

00:21:32.936 --> 00:21:33.746
optimization.

00:21:35.886 --> 00:21:37.456
We're able to split the geometry

00:21:37.456 --> 00:21:39.036
into chunks of a few hundred

00:21:39.036 --> 00:21:40.356
triangles and analyze those

00:21:40.356 --> 00:21:41.766
chunks in a separate compute

00:21:41.766 --> 00:21:42.126
kernel.

00:21:43.366 --> 00:21:44.466
You could see the chunks in

00:21:44.466 --> 00:21:45.706
different colors on the screen.

00:21:47.106 --> 00:21:48.236
Each thread of the kernel

00:21:48.236 --> 00:21:49.796
determines whether triangles are

00:21:49.796 --> 00:21:51.456
facing away from the camera or

00:21:51.456 --> 00:21:52.696
if they're obscured by other

00:21:52.696 --> 00:21:54.456
objects or geometry in the

00:21:54.456 --> 00:21:54.906
scene.

00:21:55.756 --> 00:21:57.566
This is all really, really fast

00:21:57.566 --> 00:21:58.386
because we've performed the

00:21:58.386 --> 00:22:00.526
calculation for a chunk only and

00:22:00.526 --> 00:22:02.356
not on each individual triangle.

00:22:03.576 --> 00:22:05.496
We then tell the GPU to only

00:22:05.496 --> 00:22:06.536
render the chunks that are

00:22:06.536 --> 00:22:07.416
actually visible.

00:22:07.916 --> 00:22:11.956
And again, let's see the

00:22:11.956 --> 00:22:13.016
side-by-side view.

00:22:13.406 --> 00:22:14.566
The left side is your camera

00:22:14.566 --> 00:22:16.376
view, and the right side is

00:22:16.376 --> 00:22:17.556
another view of the bus.

00:22:18.466 --> 00:22:20.346
You could see the red and

00:22:20.346 --> 00:22:21.326
pinkish tint there.

00:22:21.326 --> 00:22:22.846
That is what our compute shaders

00:22:22.846 --> 00:22:24.306
determined is invisible.

00:22:25.536 --> 00:22:27.606
We never actually send this work

00:22:27.606 --> 00:22:30.216
to the GPU, so it saves us 50%

00:22:30.216 --> 00:22:31.636
or more of the geometry

00:22:31.706 --> 00:22:32.536
rendering cost.

00:22:35.896 --> 00:22:38.316
Here's 1 last view showing

00:22:38.316 --> 00:22:40.046
which, how much this technique

00:22:40.046 --> 00:22:40.666
could save you.

00:22:41.846 --> 00:22:43.516
So notice on the right, many of

00:22:43.516 --> 00:22:44.876
the buses and ambulances are

00:22:44.876 --> 00:22:45.976
actually invisible.

00:22:50.516 --> 00:22:52.036
This is really amazing.

00:22:52.036 --> 00:22:52.866
I love this.

00:22:53.556 --> 00:22:55.156
So please take a chance to

00:22:55.156 --> 00:22:56.996
explore the code, and I hope

00:22:57.136 --> 00:22:58.776
I'll see this technology in some

00:22:58.776 --> 00:22:59.986
of your games in the future.

00:23:00.366 --> 00:23:02.496
I think if utilized, ICBs can

00:23:02.496 --> 00:23:03.746
really push your games to the

00:23:03.746 --> 00:23:04.396
next level.

00:23:05.356 --> 00:23:07.726
So now, I'm pleased to introduce

00:23:07.726 --> 00:23:09.346
Michael, who will show you how

00:23:09.346 --> 00:23:11.596
to optimize for the A11, improve

00:23:11.596 --> 00:23:12.716
performance, and extend

00:23:12.746 --> 00:23:13.226
playtime.

00:23:13.466 --> 00:23:14.266
Thank you very much.

00:23:15.516 --> 00:23:20.156
[ Applause ]

00:23:20.656 --> 00:23:21.196
>> Thanks, Brian.

00:23:22.306 --> 00:23:23.386
So everything Brian's just

00:23:23.386 --> 00:23:24.996
showed you is available for iOS,

00:23:25.296 --> 00:23:27.196
tvOS, and macOS.

00:23:27.976 --> 00:23:29.226
Next, I'm going to dive into

00:23:29.226 --> 00:23:30.696
some of the new Metal 2 features

00:23:30.696 --> 00:23:32.706
for Apple's latest GPU, the A11

00:23:32.706 --> 00:23:34.296
Bionic, designed to help you

00:23:34.296 --> 00:23:35.806
maximize your game's performance

00:23:35.866 --> 00:23:37.656
and extend your playtime by

00:23:37.656 --> 00:23:39.106
reducing system memory bandwidth

00:23:39.256 --> 00:23:40.696
and reducing power consumption.

00:23:45.046 --> 00:23:46.556
So Apple-designed GPUs have a

00:23:46.556 --> 00:23:47.896
tile-based deferred rendering

00:23:47.896 --> 00:23:49.506
architecture designed for both

00:23:49.506 --> 00:23:51.506
high performance and low power.

00:23:52.336 --> 00:23:53.446
This architecture takes

00:23:53.446 --> 00:23:54.746
advantage of a high bandwidth,

00:23:54.936 --> 00:23:56.766
low-latency tile memory that

00:23:57.036 --> 00:23:58.686
eliminates overdraw and

00:23:58.686 --> 00:23:59.876
unnecessary memory traffic.

00:24:02.606 --> 00:24:03.796
Now, Metal is designed to take

00:24:03.796 --> 00:24:05.036
advantage of the TBDR

00:24:05.036 --> 00:24:06.636
architecture automatically

00:24:06.636 --> 00:24:08.796
within each render pass, load

00:24:08.796 --> 00:24:10.636
and store actions, make explicit

00:24:10.636 --> 00:24:11.936
how render pass attachments move

00:24:11.996 --> 00:24:13.226
in and out of tile memory.

00:24:16.386 --> 00:24:18.266
But the A11 GPU takes the TBDR

00:24:18.266 --> 00:24:19.706
architecture even further.

00:24:20.306 --> 00:24:21.656
We added new capabilities to our

00:24:21.656 --> 00:24:23.046
tile memory and added an

00:24:23.046 --> 00:24:24.656
entirely new programmable stage.

00:24:25.556 --> 00:24:27.456
This opens up new optimization

00:24:27.456 --> 00:24:28.826
opportunities critical to

00:24:28.826 --> 00:24:30.056
advanced rendering techniques,

00:24:30.456 --> 00:24:31.706
such as deferred shading,

00:24:32.246 --> 00:24:33.546
order-independent transparency,

00:24:34.086 --> 00:24:35.726
tiled forward shading, and

00:24:35.726 --> 00:24:36.426
particle rendering.

00:24:37.676 --> 00:24:39.096
So let's start by taking a look

00:24:39.096 --> 00:24:40.346
at the architecture of the A11

00:24:40.346 --> 00:24:40.796
GPU.

00:24:44.066 --> 00:24:44.356
All right.

00:24:44.826 --> 00:24:46.236
So on the left, we have a block

00:24:46.236 --> 00:24:47.846
representation of the A11 GPU.

00:24:47.956 --> 00:24:49.246
And on the right, we have system

00:24:49.246 --> 00:24:49.586
memory.

00:24:51.486 --> 00:24:53.736
Now, the A11 GPU first processes

00:24:53.736 --> 00:24:54.866
all the geometry of a render

00:24:54.866 --> 00:24:56.596
pass in the vertex stage.

00:24:57.096 --> 00:24:58.646
It transforms and bends your

00:24:58.646 --> 00:25:00.136
geometry into screen-aligned,

00:25:00.526 --> 00:25:01.796
tiled vertex buffers.

00:25:02.416 --> 00:25:03.766
These tiled vertex buffers are

00:25:03.766 --> 00:25:04.606
then stored in the system

00:25:04.606 --> 00:25:04.886
memory.

00:25:07.606 --> 00:25:08.876
Now, each tiled vertex buffer is

00:25:08.876 --> 00:25:10.876
then processed entirely on ship

00:25:10.976 --> 00:25:12.476
as part of the fragment stage.

00:25:13.606 --> 00:25:15.026
This tiled architecture enables

00:25:15.026 --> 00:25:16.586
2 major optimizations that your

00:25:16.586 --> 00:25:18.436
games get for free.

00:25:19.596 --> 00:25:22.156
First, the GPU rasterizes all

00:25:22.156 --> 00:25:23.306
primitives in a tile before

00:25:23.306 --> 00:25:25.476
shading any pixels using fast,

00:25:25.476 --> 00:25:26.176
on-ship memory.

00:25:26.846 --> 00:25:28.606
This eliminates overdraw, which

00:25:28.606 --> 00:25:30.386
improves performance and reduces

00:25:30.386 --> 00:25:30.756
power.

00:25:32.436 --> 00:25:35.356
Second, a larger, more flexible

00:25:35.356 --> 00:25:36.886
tile memory is used to store the

00:25:36.886 --> 00:25:37.726
shaded fragments.

00:25:38.366 --> 00:25:39.766
Blending operations are fast

00:25:39.766 --> 00:25:40.796
because all the data is stored

00:25:40.796 --> 00:25:42.416
on ship next to the shading

00:25:42.416 --> 00:25:42.806
cores.

00:25:43.326 --> 00:25:46.096
Now, tile memory is written to

00:25:46.096 --> 00:25:48.266
system memory only once for each

00:25:48.266 --> 00:25:49.946
tile after all fragments have

00:25:49.946 --> 00:25:50.476
been shaded.

00:25:51.216 --> 00:25:52.946
This reduces bandwidth, which

00:25:52.946 --> 00:25:54.256
also improves your performance

00:25:54.296 --> 00:25:56.696
and reduces your power.

00:25:56.826 --> 00:25:59.126
Now, these optimizations happen

00:25:59.126 --> 00:25:59.896
underneath the hood.

00:26:00.456 --> 00:26:01.736
You get them just by using Metal

00:26:01.736 --> 00:26:02.306
on iOS.

00:26:03.106 --> 00:26:04.866
But Metal also lets you optimize

00:26:04.866 --> 00:26:06.036
rendering techniques by taking

00:26:06.036 --> 00:26:07.796
explicit control of the A11's

00:26:07.796 --> 00:26:08.596
tile memory.

00:26:09.186 --> 00:26:12.166
Now, during the development of

00:26:12.166 --> 00:26:13.866
the A11 GPU, the hardware and

00:26:13.866 --> 00:26:15.346
software teams at Apple analyzed

00:26:15.346 --> 00:26:16.946
a number of important modern

00:26:16.946 --> 00:26:17.846
rendering techniques.

00:26:18.696 --> 00:26:20.406
We accelerated, we noticed many

00:26:20.406 --> 00:26:22.166
common themes, and we found that

00:26:22.166 --> 00:26:23.476
explicit control of our tile

00:26:23.476 --> 00:26:26.906
memory accelerated all of them.

00:26:27.026 --> 00:26:28.036
We then developed the hardware

00:26:28.036 --> 00:26:29.656
and software features together

00:26:29.656 --> 00:26:30.946
around this idea of explicit

00:26:30.946 --> 00:26:31.416
control.

00:26:32.656 --> 00:26:33.626
So let's talk about these

00:26:34.806 --> 00:26:34.976
features.

00:26:41.656 --> 00:26:42.796
So programmable blending lets

00:26:42.796 --> 00:26:43.676
you write custom blend

00:26:43.676 --> 00:26:44.976
operations in your shaders.

00:26:45.386 --> 00:26:46.686
It's also a powerful tool you

00:26:46.686 --> 00:26:48.146
can use to merge render passes,

00:26:48.406 --> 00:26:49.396
and it's actually made available

00:26:49.396 --> 00:26:51.446
across all iOS GPUs.

00:26:52.136 --> 00:26:53.726
Imageblocks are new for A11.

00:26:53.996 --> 00:26:55.046
They let you maximize your use

00:26:55.046 --> 00:26:56.756
of tile memory by controlling

00:26:56.756 --> 00:26:58.116
pixel layouts directly in the

00:26:58.116 --> 00:26:58.936
shading language.

00:26:59.466 --> 00:27:02.076
And tile shading is our

00:27:02.076 --> 00:27:03.336
brand-new programmable stage

00:27:03.336 --> 00:27:04.326
designed for techniques that

00:27:04.326 --> 00:27:05.526
require mixing graphics and

00:27:05.526 --> 00:27:06.446
compute processing.

00:27:08.216 --> 00:27:09.856
Persistent threadgroup memory is

00:27:09.856 --> 00:27:11.106
an important tool for combining

00:27:11.106 --> 00:27:12.456
render and compute that allows

00:27:12.456 --> 00:27:13.556
you to communicate across both

00:27:13.596 --> 00:27:14.556
draws and dispatches.

00:27:15.076 --> 00:27:18.276
And multi-sample color coverage

00:27:18.276 --> 00:27:20.026
control lets you perform resolve

00:27:20.026 --> 00:27:21.576
operations directly in tile

00:27:21.576 --> 00:27:23.446
memory using tile shaders.

00:27:25.016 --> 00:27:26.036
So I'm going to talk to you

00:27:26.036 --> 00:27:27.066
about all these features, so

00:27:27.066 --> 00:27:27.976
let's start with programmable

00:27:27.976 --> 00:27:28.336
blending.

00:27:28.866 --> 00:27:33.006
With programmable blending, your

00:27:33.006 --> 00:27:34.056
fragment shader has read and

00:27:34.056 --> 00:27:35.436
write access to pixels and tile

00:27:35.436 --> 00:27:35.796
memory.

00:27:36.466 --> 00:27:37.486
This lets you write custom

00:27:37.486 --> 00:27:38.666
blending operations.

00:27:40.436 --> 00:27:42.256
But programmable blending also

00:27:42.256 --> 00:27:43.626
lets you eliminate system memory

00:27:43.626 --> 00:27:45.476
bandwidth by combining multiple

00:27:45.476 --> 00:27:46.656
render passes that read and

00:27:46.656 --> 00:27:47.826
write the same attachments.

00:27:49.916 --> 00:27:50.906
Now, deferred shading is a

00:27:50.906 --> 00:27:52.166
particularly good fit for

00:27:52.166 --> 00:27:53.466
programmable blending, so let's

00:27:53.466 --> 00:27:58.016
take a closer look at that.

00:27:58.496 --> 00:27:59.506
So deferred shading is a

00:27:59.506 --> 00:28:00.456
many-light technique

00:28:00.456 --> 00:28:01.666
traditionally implemented using

00:28:01.666 --> 00:28:02.446
2 passes.

00:28:03.046 --> 00:28:04.916
In the first pass, multiple

00:28:04.916 --> 00:28:05.866
attachments are filled with

00:28:05.906 --> 00:28:07.366
geometry attributes visible at

00:28:07.366 --> 00:28:09.426
each pixel, such as normal,

00:28:09.886 --> 00:28:11.316
albedo, and roughness.

00:28:12.136 --> 00:28:13.296
And in the second pass,

00:28:13.296 --> 00:28:14.776
fragments are shaded by sampling

00:28:14.776 --> 00:28:15.856
those G-buffer attachments.

00:28:16.456 --> 00:28:20.396
Now, the G-buffers are stored in

00:28:20.396 --> 00:28:21.766
the system memory before being

00:28:21.766 --> 00:28:23.146
read again in the lighting pass,

00:28:23.686 --> 00:28:24.976
and this round trip from tile

00:28:24.976 --> 00:28:26.516
memory to system memory and back

00:28:26.516 --> 00:28:28.046
again can really bottleneck your

00:28:28.046 --> 00:28:29.546
game because the G-buffer track

00:28:29.546 --> 00:28:30.566
consumes a large amount of

00:28:30.566 --> 00:28:30.986
bandwidth.

00:28:31.566 --> 00:28:33.626
Now, programmable blending

00:28:33.626 --> 00:28:35.206
instead lets you skip that round

00:28:35.206 --> 00:28:36.646
trip to memory by reading the

00:28:36.646 --> 00:28:38.636
current pixel's data directly

00:28:38.636 --> 00:28:40.916
from tile memory.

00:28:42.586 --> 00:28:43.506
This also means that we no

00:28:43.506 --> 00:28:44.666
longer need 2 passes.

00:28:44.966 --> 00:28:46.486
Our G-buffer fill and lighting

00:28:46.486 --> 00:28:48.096
steps are now encoded and

00:28:48.096 --> 00:28:49.796
executed in a single render

00:28:49.796 --> 00:28:50.226
pass.

00:28:51.536 --> 00:28:52.896
It also means that we no longer

00:28:52.896 --> 00:28:54.206
need a copy of the G-buffer

00:28:54.206 --> 00:28:55.856
attachments in system memory.

00:28:56.376 --> 00:28:59.166
And with memory, Metal's

00:28:59.166 --> 00:29:00.216
memoryless render target

00:29:00.216 --> 00:29:02.066
feature, saving that memory is

00:29:02.066 --> 00:29:03.066
really, really simple.

00:29:03.616 --> 00:29:04.846
You just create a texture with a

00:29:04.846 --> 00:29:06.776
memoryless flag set, and Metal's

00:29:06.776 --> 00:29:08.246
only going to let you use it as

00:29:08.246 --> 00:29:09.416
an attachment without load or

00:29:09.416 --> 00:29:10.176
store actions.

00:29:10.746 --> 00:29:13.376
So now, let's take a look at how

00:29:13.376 --> 00:29:14.476
easy it is to adopt programmable

00:29:14.476 --> 00:29:15.606
blending in your shaders.

00:29:16.156 --> 00:29:20.056
Okay, so here's what the

00:29:20.056 --> 00:29:21.236
fragment shader of your lighting

00:29:21.236 --> 00:29:22.516
pass would look like with

00:29:22.516 --> 00:29:23.366
programmable blending.

00:29:24.196 --> 00:29:25.786
Programmable blending is enabled

00:29:25.786 --> 00:29:26.856
when you both read and write

00:29:26.856 --> 00:29:27.606
your attachments.

00:29:27.986 --> 00:29:29.526
And in this example, we see that

00:29:29.526 --> 00:29:30.666
the G-buffer attachments are

00:29:30.666 --> 00:29:32.306
both inputs and outputs to our

00:29:32.306 --> 00:29:32.856
functions.

00:29:32.956 --> 00:29:36.826
We first calculate our lighting

00:29:36.826 --> 00:29:38.146
using our G-buffer properties.

00:29:38.856 --> 00:29:39.886
As you can see here, we're

00:29:39.886 --> 00:29:41.006
reading our attachments and

00:29:41.006 --> 00:29:41.866
we're not sampling them as

00:29:41.866 --> 00:29:42.376
textures.

00:29:42.916 --> 00:29:45.676
We then accumulate our lighting

00:29:45.676 --> 00:29:47.186
result back into the G-buffer,

00:29:47.186 --> 00:29:48.126
and, in this step, we're both

00:29:48.126 --> 00:29:49.306
reading and writing our

00:29:49.306 --> 00:29:50.226
accumulation attachments.

00:29:50.616 --> 00:29:52.156
So that's it.

00:29:52.406 --> 00:29:53.946
Programmable blending is really

00:29:53.946 --> 00:29:55.256
that easy, and you should it

00:29:55.256 --> 00:29:56.516
where, whenever you have

00:29:56.516 --> 00:29:58.176
multiple render passes that read

00:29:58.176 --> 00:29:59.356
and write the same attachments.

00:30:00.556 --> 00:30:02.416
So now, let's talk about

00:30:02.416 --> 00:30:04.376
imageblocks, which allow you to

00:30:04.376 --> 00:30:05.936
merge render passes in even more

00:30:05.936 --> 00:30:06.696
circumstances.

00:30:12.476 --> 00:30:13.546
Imageblocks give you full

00:30:13.546 --> 00:30:14.736
control of your data in tile

00:30:14.736 --> 00:30:15.116
memory.

00:30:15.536 --> 00:30:17.196
Instead of describing pixels as

00:30:17.196 --> 00:30:18.506
arrays of render pass

00:30:18.506 --> 00:30:20.486
attachments in the Metal API,

00:30:21.456 --> 00:30:22.696
imageblocks let you declare your

00:30:22.696 --> 00:30:24.006
pixel layouts directly in the

00:30:24.006 --> 00:30:25.816
shading language as structs.

00:30:28.056 --> 00:30:29.336
It adds new pack data types to

00:30:29.336 --> 00:30:30.556
the shading language that match

00:30:30.556 --> 00:30:31.856
the texture formats you already

00:30:31.856 --> 00:30:33.446
use, and these types are

00:30:33.446 --> 00:30:35.116
transparently packed and

00:30:35.116 --> 00:30:36.296
unpacked when accessing the

00:30:36.296 --> 00:30:36.666
shader.

00:30:37.646 --> 00:30:39.196
In fact, you can also use these

00:30:39.196 --> 00:30:40.676
new pack data types in your

00:30:40.676 --> 00:30:42.216
vertex buffers and constant

00:30:42.216 --> 00:30:43.976
buffers to more tightly pack all

00:30:43.976 --> 00:30:44.476
of your data.

00:30:46.736 --> 00:30:47.946
Imageblocks also let you

00:30:47.946 --> 00:30:49.996
describe more complex per-pixel

00:30:49.996 --> 00:30:50.826
data structures.

00:30:51.176 --> 00:30:52.806
You can use arrays, nested

00:30:52.806 --> 00:30:54.276
structs, or combinations

00:30:54.276 --> 00:30:54.616
thereof.

00:30:55.126 --> 00:30:56.586
It all just works.

00:30:59.096 --> 00:31:01.016
Now, direct control of your

00:31:01.016 --> 00:31:02.176
pixel layout means that you can

00:31:02.176 --> 00:31:03.666
now change the layout within a

00:31:03.666 --> 00:31:04.186
pass.

00:31:04.796 --> 00:31:06.136
This lets you combine render

00:31:06.136 --> 00:31:07.336
passes to eliminate system

00:31:07.336 --> 00:31:08.796
memory bandwidth in ways that

00:31:08.796 --> 00:31:09.766
just weren't possible with

00:31:09.766 --> 00:31:11.656
programmable blending alone.

00:31:11.656 --> 00:31:12.666
Let's take a look at an example.

00:31:15.156 --> 00:31:16.966
So in our previous example, we

00:31:16.966 --> 00:31:18.056
used programmable blending to

00:31:18.056 --> 00:31:19.476
implement single-pass deferred

00:31:19.476 --> 00:31:19.846
shading.

00:31:20.836 --> 00:31:21.756
You can also implement

00:31:21.756 --> 00:31:22.926
single-pass deferred shading

00:31:22.926 --> 00:31:23.906
using imageblocks.

00:31:25.346 --> 00:31:26.726
Imageblocks only exist in tile

00:31:26.726 --> 00:31:27.816
memory, so there's no render

00:31:27.816 --> 00:31:28.966
pass attachments to deal with.

00:31:29.716 --> 00:31:31.066
Not only is this a more natural

00:31:31.066 --> 00:31:32.406
way to express the algorithm,

00:31:32.716 --> 00:31:34.386
but now you're free to reuse the

00:31:34.386 --> 00:31:35.926
tile memory once you're finished

00:31:35.926 --> 00:31:37.406
reading the G-buffer after your

00:31:37.406 --> 00:31:37.756
lighting.

00:31:38.786 --> 00:31:39.996
So let's go ahead and do that.

00:31:39.996 --> 00:31:41.396
Let's reuse the tile memory to

00:31:41.396 --> 00:31:43.006
add an order-independent

00:31:43.196 --> 00:31:44.856
transparency technique called

00:31:44.896 --> 00:31:46.236
multi-layer alpha blending.

00:31:51.466 --> 00:31:52.816
So multi-layer alpha blending,

00:31:52.816 --> 00:31:55.676
or MLAB, maintains a per-pixel,

00:31:55.676 --> 00:31:57.346
fixed-size array of translucent

00:31:57.346 --> 00:31:57.896
fragments.

00:31:58.556 --> 00:32:00.136
Each incoming fragment is sorted

00:32:00.136 --> 00:32:01.326
by depth into the array.

00:32:02.186 --> 00:32:03.706
If a fragment's depth lies

00:32:03.706 --> 00:32:04.916
beyond the last element of the

00:32:04.916 --> 00:32:06.246
array, then those elements are

00:32:06.246 --> 00:32:07.536
merged, so it's really an

00:32:07.536 --> 00:32:09.126
approximation, approximate

00:32:09.566 --> 00:32:09.766
technique.

00:32:11.376 --> 00:32:12.976
Now, sorting the MLAB array is

00:32:12.976 --> 00:32:14.136
really fast because it lives in

00:32:14.136 --> 00:32:14.746
tile memory.

00:32:15.556 --> 00:32:16.796
Doing the same off chip would be

00:32:16.796 --> 00:32:18.186
really expensive because of the

00:32:18.186 --> 00:32:19.356
extra bandwidth and

00:32:19.356 --> 00:32:20.346
synchronization overhead.

00:32:20.856 --> 00:32:25.326
Now, the A11 actually doubles

00:32:25.326 --> 00:32:26.826
the maximum supported pixel size

00:32:26.826 --> 00:32:28.096
over your previous generation,

00:32:28.866 --> 00:32:30.466
but that's still not going to be

00:32:30.466 --> 00:32:31.596
enough to contain both the

00:32:31.596 --> 00:32:33.026
G-buffer and MLAB data

00:32:33.026 --> 00:32:34.606
structures simultaneously.

00:32:35.396 --> 00:32:37.366
Fortunately, you don't need both

00:32:37.366 --> 00:32:38.106
at the same time.

00:32:38.916 --> 00:32:40.076
Imageblocks let you change your

00:32:40.076 --> 00:32:41.896
pixel layouts inside the render

00:32:41.896 --> 00:32:43.216
pass to match your current

00:32:43.916 --> 00:32:44.036
needs.

00:32:44.956 --> 00:32:47.296
So changing pixel layouts

00:32:47.296 --> 00:32:48.926
actually requires tile shading,

00:32:48.926 --> 00:32:50.846
so let's talk about that next.

00:32:56.256 --> 00:32:58.036
So tile shading is the new

00:32:58.036 --> 00:32:59.516
programmable stage that provides

00:32:59.516 --> 00:33:01.246
compute capabilities directly in

00:33:01.246 --> 00:33:02.036
the render pass.

00:33:02.656 --> 00:33:04.016
This stage is going to execute a

00:33:04.016 --> 00:33:05.606
configurable threadgroup for

00:33:05.606 --> 00:33:06.216
each tile.

00:33:06.756 --> 00:33:07.936
For example, you can launch a

00:33:07.936 --> 00:33:09.626
single thread per tile, or you

00:33:09.626 --> 00:33:10.846
can launch a thread per pixel.

00:33:14.286 --> 00:33:15.296
Now, tile shading lets you

00:33:15.336 --> 00:33:16.526
interleave draw calls and

00:33:16.526 --> 00:33:17.916
threadgroup dispatches that

00:33:17.916 --> 00:33:19.156
operate on the same data.

00:33:19.496 --> 00:33:21.796
Tile shaders have access to all

00:33:21.796 --> 00:33:23.066
of tile memory, so they can read

00:33:23.066 --> 00:33:24.016
and write any pixel of the

00:33:24.016 --> 00:33:24.446
imageblock.

00:33:26.196 --> 00:33:27.696
So let's look at how tile

00:33:27.696 --> 00:33:29.306
shading can optimize techniques

00:33:29.486 --> 00:33:31.286
such as tiled forward shading.

00:33:34.536 --> 00:33:36.406
So like deferred shading, tiled

00:33:36.406 --> 00:33:37.046
forward shading is a

00:33:37.046 --> 00:33:37.866
many-layered technique.

00:33:38.616 --> 00:33:39.986
It's often used when MSA is

00:33:39.986 --> 00:33:41.406
important or when a variety of

00:33:41.406 --> 00:33:43.356
materials are needed and works

00:33:43.356 --> 00:33:44.676
equally well for both opaque and

00:33:44.676 --> 00:33:45.566
translucent geometry.

00:33:46.166 --> 00:33:48.476
Now, tiled forward shading

00:33:48.476 --> 00:33:49.916
traditionally consists of 3

00:33:49.916 --> 00:33:50.546
passes.

00:33:51.226 --> 00:33:53.436
First, a render pass generates a

00:33:53.436 --> 00:33:54.256
scene depth buffer.

00:33:55.136 --> 00:33:56.626
Second, a compute pass

00:33:56.626 --> 00:33:58.806
generates, calculates per-tile

00:33:58.806 --> 00:34:00.716
depth bounds and per-tile light

00:34:00.716 --> 00:34:02.106
lists using that scene depth

00:34:02.106 --> 00:34:02.446
buffer.

00:34:03.326 --> 00:34:04.886
And finally, another render pass

00:34:04.886 --> 00:34:05.956
is going to shade the pixels in

00:34:05.956 --> 00:34:07.096
each tile using the

00:34:07.096 --> 00:34:08.096
corresponding light list.

00:34:08.706 --> 00:34:13.235
Now, this pattern of mixing

00:34:13.235 --> 00:34:14.386
render with compute occurs

00:34:14.386 --> 00:34:14.976
frequently.

00:34:14.976 --> 00:34:17.366
And prior to A11, communicating

00:34:17.366 --> 00:34:18.585
across these passes required

00:34:18.585 --> 00:34:19.226
system memory.

00:34:19.936 --> 00:34:21.755
But with tile shading, we can

00:34:21.755 --> 00:34:22.856
inline the compute so that the

00:34:22.856 --> 00:34:24.036
render passes can be merged.

00:34:26.396 --> 00:34:28.356
Here the depth bounds and light

00:34:28.356 --> 00:34:29.476
culling steps are now

00:34:29.476 --> 00:34:31.036
implemented as tile shaders and

00:34:31.036 --> 00:34:32.076
inlined into a single render

00:34:32.076 --> 00:34:32.576
pass.

00:34:33.496 --> 00:34:34.735
Depth is now only stored in the

00:34:34.735 --> 00:34:36.426
imageblock and, but is

00:34:36.525 --> 00:34:37.966
accessible across the entire

00:34:42.596 --> 00:34:42.706
pass.

00:34:42.906 --> 00:34:44.496
So, now, tile shading is going

00:34:44.496 --> 00:34:45.696
to help you eliminate a lot of

00:34:45.696 --> 00:34:47.626
bandwidth, but these tile shader

00:34:47.626 --> 00:34:48.876
outputs are still being stored

00:34:48.876 --> 00:34:49.545
to system memory.

00:34:50.545 --> 00:34:51.826
Tile shader dispatches are

00:34:51.826 --> 00:34:53.226
synchronized with draws, so

00:34:53.226 --> 00:34:54.286
that's completely safe to do,

00:34:54.656 --> 00:34:55.606
but I think we could still do

00:34:55.606 --> 00:34:57.136
better using our next feature,

00:34:57.706 --> 00:34:59.426
persistent threadgroup memory.

00:35:05.336 --> 00:35:06.846
Okay, so threadgroup memory is a

00:35:06.846 --> 00:35:07.786
well-known feature of Metal

00:35:07.786 --> 00:35:08.206
compute.

00:35:08.826 --> 00:35:09.856
It lets threads within a

00:35:09.856 --> 00:35:11.766
threadgroup share data using

00:35:11.766 --> 00:35:12.636
fast, on-ship memory.

00:35:13.736 --> 00:35:14.886
Now, thanks to tile shading,

00:35:14.936 --> 00:35:16.096
threadgroup memory is now also

00:35:16.096 --> 00:35:17.396
available in the render pass.

00:35:18.446 --> 00:35:19.586
But threadgroup memory in the

00:35:19.586 --> 00:35:20.756
render pass has 2 new

00:35:20.756 --> 00:35:21.946
capabilities not traditionally

00:35:21.946 --> 00:35:22.766
available to compute.

00:35:23.376 --> 00:35:25.286
First, a fragment shader now

00:35:25.286 --> 00:35:26.756
also has access to the same

00:35:26.756 --> 00:35:27.446
threadgroup memory.

00:35:28.126 --> 00:35:29.366
And second, the contents of

00:35:29.366 --> 00:35:30.496
threadgroup memory persist

00:35:30.496 --> 00:35:31.656
across the entire life of a

00:35:31.656 --> 00:35:32.116
tile.

00:35:33.476 --> 00:35:35.706
Taken together, this makes a

00:35:35.756 --> 00:35:37.146
powerful tool for sharing data

00:35:37.146 --> 00:35:38.676
across both draws and

00:35:38.676 --> 00:35:39.286
dispatches.

00:35:40.486 --> 00:35:41.646
In fact, we believe it's so

00:35:41.646 --> 00:35:42.666
useful that we've actually

00:35:42.666 --> 00:35:43.916
doubled the maximum size of

00:35:43.916 --> 00:35:44.876
threadgroup memory over our

00:35:44.876 --> 00:35:46.466
previous generation so that you

00:35:46.466 --> 00:35:47.326
can store more of your

00:35:47.326 --> 00:35:50.606
intermediate data on ship.

00:35:50.786 --> 00:35:51.546
Okay, so now, let's use

00:35:51.546 --> 00:35:52.956
threadgroup persistence to

00:35:52.956 --> 00:35:54.176
further optimize our tiled

00:35:54.176 --> 00:35:55.106
forward shading example.

00:35:55.686 --> 00:36:00.576
So with persistence, tile, the

00:36:00.706 --> 00:36:02.116
tile shading stage can now write

00:36:02.116 --> 00:36:03.716
both the depth bounds and the

00:36:03.716 --> 00:36:05.086
culled light lists into

00:36:05.086 --> 00:36:06.416
threadgroup memory for later

00:36:06.416 --> 00:36:07.766
draws to use.

00:36:08.716 --> 00:36:09.996
This means that now all our

00:36:09.996 --> 00:36:11.256
intermediate data stays on ship

00:36:11.766 --> 00:36:13.056
and never leaves the GPU.

00:36:13.056 --> 00:36:14.506
Only the final image is stored

00:36:14.506 --> 00:36:15.186
at system memory.

00:36:16.556 --> 00:36:17.876
Minimizing bandwidth to system

00:36:17.876 --> 00:36:19.516
memory is, again, very important

00:36:19.516 --> 00:36:21.316
for your game's performance and

00:36:21.316 --> 00:36:21.596
playtime.

00:36:21.676 --> 00:36:24.546
Now, let's take a look at how

00:36:24.546 --> 00:36:25.616
easy it is to make use of

00:36:25.616 --> 00:36:27.006
persistence in the shading

00:36:27.006 --> 00:36:27.466
language.

00:36:31.336 --> 00:36:33.166
Okay, so the top function here

00:36:33.166 --> 00:36:34.376
is our tile shader, and it's

00:36:34.376 --> 00:36:35.036
going to perform our light

00:36:35.036 --> 00:36:35.426
culling.

00:36:35.726 --> 00:36:37.396
It intersects each light with a

00:36:37.396 --> 00:36:39.276
per-tile frustum to compute an

00:36:39.276 --> 00:36:41.026
active light mask.

00:36:41.876 --> 00:36:43.096
The bottom function is our

00:36:43.096 --> 00:36:44.376
fragment shader that performs

00:36:44.376 --> 00:36:45.206
our forward shading.

00:36:45.696 --> 00:36:46.846
It shades only the lights

00:36:46.846 --> 00:36:48.486
intersecting the tile using that

00:36:48.486 --> 00:36:49.806
active light mask.

00:36:51.456 --> 00:36:53.256
Now, sharing threadgroup memory

00:36:53.256 --> 00:36:54.766
across these functions is

00:36:54.766 --> 00:36:56.116
achieved by using the same type

00:36:56.406 --> 00:36:58.586
and bind point across both

00:36:58.586 --> 00:36:59.116
shaders.

00:37:00.296 --> 00:37:01.606
That's how easy it is to take

00:37:01.606 --> 00:37:02.286
advantage of threadgroup

00:37:02.286 --> 00:37:02.826
persistence.

00:37:05.806 --> 00:37:07.806
Okay, so now that you've seen

00:37:07.806 --> 00:37:08.686
tile shading and threadgroup

00:37:08.686 --> 00:37:10.206
persistence, let's revisit our

00:37:10.206 --> 00:37:11.436
order-independent transparency

00:37:11.436 --> 00:37:11.876
example.

00:37:14.166 --> 00:37:15.446
Okay, so remember how I said

00:37:15.446 --> 00:37:17.126
that changing imageblock layouts

00:37:17.126 --> 00:37:18.116
requires tile shading?

00:37:18.916 --> 00:37:20.106
That's because tile shading

00:37:20.106 --> 00:37:22.336
provides the synchronization we

00:37:22.336 --> 00:37:24.176
need to safely change layouts.

00:37:24.686 --> 00:37:26.276
This means we actually have to

00:37:26.276 --> 00:37:27.926
insert a tile shade between the

00:37:27.926 --> 00:37:29.316
lighting and the MLAB steps.

00:37:33.226 --> 00:37:34.436
So tile shading is going to wait

00:37:34.516 --> 00:37:35.406
for the lighting stage to

00:37:35.406 --> 00:37:36.576
complete before transitioning

00:37:36.576 --> 00:37:38.436
from G-buffer layout to MLAB

00:37:38.436 --> 00:37:40.426
layout, and it's also going to

00:37:40.426 --> 00:37:41.466
carry forward the accumulated

00:37:41.466 --> 00:37:42.646
lighting value from the lighting

00:37:42.646 --> 00:37:44.106
step into the MLAB step for

00:37:44.106 --> 00:37:44.776
final blending.

00:37:49.146 --> 00:37:50.706
Okay, so now that we've covered

00:37:50.706 --> 00:37:52.496
imageblocks, tile shading, and

00:37:52.496 --> 00:37:53.576
threadgroup persistence, it's

00:37:53.576 --> 00:37:54.736
time to move on to our final

00:37:54.736 --> 00:37:56.376
topic, multi-sample

00:37:56.376 --> 00:37:58.066
anti-aliasing and sample

00:37:58.066 --> 00:37:58.676
coverage control.

00:38:03.286 --> 00:38:04.676
So multi-sample anti-aliasing

00:38:04.676 --> 00:38:06.016
improves image quality by

00:38:06.016 --> 00:38:08.396
supersampling depth, stencil,

00:38:08.766 --> 00:38:10.026
and blending, but shades only

00:38:10.026 --> 00:38:10.676
once per pixel.

00:38:11.816 --> 00:38:13.026
Multiple samples are later

00:38:13.026 --> 00:38:14.716
resolved into a final image

00:38:14.896 --> 00:38:15.836
using simple averaging.

00:38:18.166 --> 00:38:19.676
Now, multi-sampling is efficient

00:38:19.676 --> 00:38:21.696
on all A series GPUs because

00:38:21.746 --> 00:38:23.196
samples are stored in tile

00:38:23.196 --> 00:38:24.546
memory, where blending and

00:38:24.546 --> 00:38:25.946
resolve operations have fast

00:38:25.946 --> 00:38:26.986
access to the samples.

00:38:29.236 --> 00:38:31.436
The A11 GPU optimizes

00:38:31.436 --> 00:38:33.356
multi-sampling even further by

00:38:33.356 --> 00:38:34.616
tracking the unique colors

00:38:34.616 --> 00:38:35.346
within each pixel.

00:38:36.036 --> 00:38:37.416
So blending operations that

00:38:37.416 --> 00:38:38.386
previously operated on each

00:38:38.386 --> 00:38:40.206
sample now only operate on each

00:38:40.246 --> 00:38:40.746
color.

00:38:41.616 --> 00:38:42.636
This could be a significant

00:38:42.636 --> 00:38:44.036
savings because the interior of

00:38:44.036 --> 00:38:45.756
every triangle only contains 1

00:38:45.756 --> 00:38:46.386
unique color.

00:38:49.186 --> 00:38:50.246
Now, this mapping of unique

00:38:50.276 --> 00:38:53.406
color to samples is called color

00:38:53.406 --> 00:38:54.606
coverage control, and it's

00:38:54.606 --> 00:38:55.576
managed by the GPU.

00:38:56.206 --> 00:38:57.966
But tile shaders can also read

00:38:57.966 --> 00:38:59.506
and modify this color coverage.

00:39:00.806 --> 00:39:02.176
And we can use this to perform

00:39:02.216 --> 00:39:04.566
custom resolves in place and in

00:39:04.566 --> 00:39:05.406
fast tile memory.

00:39:06.186 --> 00:39:07.466
Now, to see why this is useful,

00:39:07.696 --> 00:39:08.516
let's take a look at a

00:39:08.516 --> 00:39:10.316
multi-sampled scene that also

00:39:10.316 --> 00:39:11.166
renders particles.

00:39:14.196 --> 00:39:15.766
Now, particles are transparent,

00:39:15.766 --> 00:39:17.356
so we blend them after rendering

00:39:17.356 --> 00:39:18.646
our opaque scene geometry.

00:39:19.306 --> 00:39:20.706
But particle rendering doesn't

00:39:20.706 --> 00:39:21.886
benefit from multi-sampling

00:39:21.886 --> 00:39:22.806
because it doesn't really have

00:39:22.806 --> 00:39:23.716
any visible edges.

00:39:24.766 --> 00:39:26.236
So to avoid the extra cost of

00:39:26.236 --> 00:39:27.496
blending per sample for no good

00:39:27.496 --> 00:39:29.256
reason, a game would render

00:39:29.256 --> 00:39:30.236
using 2 passes.

00:39:30.956 --> 00:39:32.546
In the first pass, your opaque

00:39:32.546 --> 00:39:33.956
scene geometry is rendered using

00:39:33.956 --> 00:39:35.156
multi-sampling to reduce

00:39:35.156 --> 00:39:35.756
aliasing.

00:39:36.666 --> 00:39:37.536
And then, you're going to

00:39:37.536 --> 00:39:38.696
resolve your color and depth to

00:39:38.696 --> 00:39:40.036
system memory, and we're

00:39:40.036 --> 00:39:41.506
resolving depth because

00:39:41.506 --> 00:39:42.846
particles can later be included.

00:39:43.916 --> 00:39:45.696
Then in the second pass, the

00:39:45.696 --> 00:39:47.496
resolve color and depth are used

00:39:47.636 --> 00:39:48.626
in rendering the particles

00:39:48.626 --> 00:39:49.576
without multi-sampling.

00:39:51.256 --> 00:39:52.466
Now, as you probably guessed by

00:39:52.466 --> 00:39:54.326
now, our goal is to eliminate

00:39:54.326 --> 00:39:55.396
the intermediate system memory

00:39:55.396 --> 00:39:56.876
traffic using tile shading to

00:39:56.876 --> 00:39:58.646
combine these 2 passes.

00:40:01.126 --> 00:40:02.386
But tile shading alone isn't

00:40:02.386 --> 00:40:02.716
enough.

00:40:02.956 --> 00:40:04.266
We need color coverage control

00:40:04.266 --> 00:40:05.566
to change the multi-sampling

00:40:05.566 --> 00:40:06.586
rate in place.

00:40:07.576 --> 00:40:08.876
Using color coverage control is

00:40:08.996 --> 00:40:10.996
really powerful and really easy.

00:40:11.526 --> 00:40:12.496
Let's take a look at the shader.

00:40:16.176 --> 00:40:17.976
Okay, so remember that our goal

00:40:17.976 --> 00:40:19.336
here is to average the samples

00:40:19.336 --> 00:40:20.766
of each pixel and then store

00:40:20.766 --> 00:40:22.126
that result back into the image

00:40:22.236 --> 00:40:23.756
block as the overall pixel

00:40:23.756 --> 00:40:24.106
value.

00:40:25.616 --> 00:40:27.276
Now, instead of looping through

00:40:27.276 --> 00:40:29.686
each color, through each sample,

00:40:29.826 --> 00:40:30.776
we're going to take advantage of

00:40:30.776 --> 00:40:32.146
the color rate capabilities of

00:40:32.146 --> 00:40:33.916
the A11 and only loop through

00:40:33.916 --> 00:40:34.916
unique colors.

00:40:36.836 --> 00:40:38.726
To properly average across all

00:40:38.726 --> 00:40:40.066
samples, we need to weigh each

00:40:40.066 --> 00:40:41.416
color by the number of samples

00:40:41.416 --> 00:40:43.166
associated with it, and we do

00:40:43.166 --> 00:40:46.436
this by counting the bit set in

00:40:46.436 --> 00:40:47.866
the color coverage mask.

00:40:49.186 --> 00:40:50.426
We then complete our averaging

00:40:50.426 --> 00:40:51.606
by dividing by the total number

00:40:51.606 --> 00:40:54.766
of samples and, finally, write

00:40:54.766 --> 00:40:56.106
the result back into the

00:40:56.106 --> 00:40:56.616
imageblock.

00:40:57.136 --> 00:40:58.526
The output sample mask tells

00:40:58.526 --> 00:41:00.126
Metal to apply the results to

00:41:00.126 --> 00:41:01.136
all samples of the pixel.

00:41:01.986 --> 00:41:03.876
And since all samples now share

00:41:03.876 --> 00:41:05.486
the same value, the later

00:41:05.486 --> 00:41:06.426
particle draws are going to

00:41:06.426 --> 00:41:08.276
blend per pixel rather than per

00:41:08.276 --> 00:41:08.646
sample.

00:41:11.096 --> 00:41:12.696
So that's it for sample coverage

00:41:12.696 --> 00:41:13.056
control.

00:41:15.736 --> 00:41:18.216
Now, optimizing for Apple GPUs

00:41:18.216 --> 00:41:19.306
is really important for

00:41:19.306 --> 00:41:20.556
maximizing your game's

00:41:20.586 --> 00:41:21.926
performance and extending its

00:41:21.966 --> 00:41:23.806
playtime, but there's a lot more

00:41:23.806 --> 00:41:25.236
work that goes into shipping a

00:41:25.236 --> 00:41:27.036
tile in iOS, especially one

00:41:27.036 --> 00:41:27.946
that's originally designed for

00:41:27.946 --> 00:41:28.986
desktops and consoles.

00:41:29.476 --> 00:41:31.266
To talk about that now and to

00:41:31.266 --> 00:41:32.456
put into practice what we just

00:41:32.456 --> 00:41:34.036
discussed, I'd like to bring on

00:41:34.036 --> 00:41:35.716
Nick Penwarden from Epic Games.

00:41:36.146 --> 00:41:36.386
Nick?

00:41:38.516 --> 00:41:40.566
[ Applause ]

00:41:41.066 --> 00:41:41.736
>> Thank you, Michael.

00:41:42.876 --> 00:41:44.086
So, yeah. I'd like to talk a

00:41:44.086 --> 00:41:46.236
little bit about how we took a

00:41:46.236 --> 00:41:47.906
game that was originally made

00:41:47.986 --> 00:41:50.786
for desktop and console

00:41:50.786 --> 00:41:52.826
platforms and brought it to iOS

00:41:52.826 --> 00:41:53.326
using Metal.

00:41:53.906 --> 00:41:56.126
So some of the technical

00:41:56.126 --> 00:41:57.206
challenges we faced.

00:41:57.206 --> 00:42:00.556
The Battle Royale map is 1 map.

00:42:00.556 --> 00:42:01.936
It's larger than 6 kilometers

00:42:01.936 --> 00:42:02.426
squared.

00:42:02.946 --> 00:42:04.976
That means that it will not all

00:42:04.976 --> 00:42:05.856
fit into memory.

00:42:06.466 --> 00:42:07.726
We also have dynamic time of

00:42:07.726 --> 00:42:09.266
day, destruction.

00:42:09.266 --> 00:42:10.476
Players can destroy just about

00:42:10.476 --> 00:42:11.866
any object in the scene.

00:42:12.286 --> 00:42:13.776
Players can also build their own

00:42:13.776 --> 00:42:14.386
structures.

00:42:14.726 --> 00:42:15.896
So the map is very dynamic,

00:42:15.956 --> 00:42:16.916
meaning we can't do a lot of

00:42:16.996 --> 00:42:17.856
precomputation.

00:42:18.286 --> 00:42:21.846
We have 100 players in the map,

00:42:21.846 --> 00:42:24.166
and the map has over 50,000

00:42:24.166 --> 00:42:25.506
replicating actors that are

00:42:25.506 --> 00:42:27.286
simulated on the server and

00:42:27.286 --> 00:42:28.506
replicated down to the client.

00:42:29.806 --> 00:42:31.216
Finally, we wanted to support

00:42:31.216 --> 00:42:33.246
crossplay between console and

00:42:33.246 --> 00:42:34.866
desktop players along with

00:42:34.866 --> 00:42:35.336
mobile.

00:42:36.126 --> 00:42:37.206
And that's actually a really

00:42:37.206 --> 00:42:38.396
important point because it

00:42:38.396 --> 00:42:39.926
limited the amount that we could

00:42:39.926 --> 00:42:42.546
scale back the game in order to

00:42:42.546 --> 00:42:45.486
fit into the performance

00:42:45.486 --> 00:42:46.686
constraints of the device.

00:42:47.096 --> 00:42:48.776
Basically, if something affected

00:42:48.776 --> 00:42:50.496
gameplay, we couldn't change it.

00:42:50.756 --> 00:42:52.016
So if there's an object and it's

00:42:52.016 --> 00:42:53.186
really small, it's really far

00:42:53.186 --> 00:42:55.166
away, maybe normally you would

00:42:55.316 --> 00:42:57.306
cull it, but in this case, we

00:42:57.306 --> 00:42:58.836
can't because if a player can

00:42:58.836 --> 00:43:00.306
hide behind it, we need to

00:43:00.306 --> 00:43:02.666
render it.

00:43:02.936 --> 00:43:04.906
So want to talk a little bit

00:43:04.906 --> 00:43:05.906
about Metal.

00:43:05.906 --> 00:43:07.306
Metal is really important in

00:43:07.306 --> 00:43:09.946
terms of allowing us to ship the

00:43:09.946 --> 00:43:12.086
game as fast as we did and at

00:43:12.116 --> 00:43:13.396
the quality that we were able to

00:43:13.396 --> 00:43:13.816
achieve.

00:43:14.486 --> 00:43:15.876
Draw call performance was key to

00:43:15.876 --> 00:43:17.626
this because, again, we have a

00:43:17.626 --> 00:43:20.776
really complicated scene and we

00:43:20.776 --> 00:43:22.066
need the performance to render

00:43:22.066 --> 00:43:23.406
it, and Metal gave us that

00:43:23.446 --> 00:43:24.116
performance.

00:43:24.696 --> 00:43:26.196
Metal also gave us access to a

00:43:26.196 --> 00:43:27.386
number of hardware features,

00:43:27.386 --> 00:43:28.636
such as programmable blending,

00:43:28.636 --> 00:43:30.486
that we used to get important

00:43:30.486 --> 00:43:31.566
GPU performance back.

00:43:32.286 --> 00:43:33.546
It also has a feature set that

00:43:33.546 --> 00:43:34.866
allowed us to use all of the

00:43:34.866 --> 00:43:36.316
rendering techniques we need to

00:43:36.316 --> 00:43:38.506
bring Fortnite to iOS.

00:43:38.856 --> 00:43:40.236
In terms of rendering features,

00:43:40.676 --> 00:43:42.056
we use a movable directional

00:43:42.056 --> 00:43:43.446
light for the sun with cascaded

00:43:43.446 --> 00:43:44.226
shadow maps.

00:43:44.226 --> 00:43:45.386
We have a movable skylight

00:43:45.386 --> 00:43:46.356
because the sky changes

00:43:46.356 --> 00:43:47.016
throughout the day.

00:43:47.786 --> 00:43:49.176
We use physically-based

00:43:49.176 --> 00:43:49.936
materials.

00:43:51.436 --> 00:43:52.936
We render in HDR and have a

00:43:52.936 --> 00:43:54.306
tone-mapping pass at the end.

00:43:55.476 --> 00:43:57.286
We allow particle simulation on

00:43:57.286 --> 00:43:58.036
the GPU.

00:43:58.076 --> 00:43:59.456
And we also support all of our

00:43:59.456 --> 00:44:00.806
artist-authored materials.

00:44:01.416 --> 00:44:03.616
It's actually a pretty important

00:44:03.646 --> 00:44:05.796
point because some of our

00:44:05.796 --> 00:44:07.536
materials are actually very

00:44:07.596 --> 00:44:08.316
complicated.

00:44:08.316 --> 00:44:10.786
For instance, the imposters that

00:44:10.786 --> 00:44:12.006
we use to render trees in the

00:44:12.006 --> 00:44:13.496
distance efficiently were

00:44:13.496 --> 00:44:14.996
entirely created by a technical

00:44:14.996 --> 00:44:16.636
artist at Epic using a

00:44:16.636 --> 00:44:18.976
combination of blueprints and

00:44:19.066 --> 00:44:20.796
the material shader graph.

00:44:22.676 --> 00:44:24.086
So in terms of where we ended

00:44:24.086 --> 00:44:25.896
up, here is an image of Fortnite

00:44:25.896 --> 00:44:27.696
running on a Mac at high

00:44:27.696 --> 00:44:28.806
scalability settings.

00:44:30.016 --> 00:44:31.506
Here it is running on a Mac at

00:44:31.506 --> 00:44:33.716
medium scalability settings.

00:44:34.826 --> 00:44:36.296
And here it is on an iPhone 8

00:44:36.336 --> 00:44:36.826
Plus.

00:44:37.296 --> 00:44:38.706
So we were able to faithfully

00:44:38.706 --> 00:44:41.136
represent the game on an iPhone

00:44:41.556 --> 00:44:42.836
about at the quality that we

00:44:42.836 --> 00:44:44.276
achieve on a mid-range Mac.

00:44:44.816 --> 00:44:48.016
So let's talk a little bit about

00:44:48.016 --> 00:44:48.796
scalability.

00:44:49.526 --> 00:44:50.736
We deal with scalability both

00:44:50.736 --> 00:44:52.156
across platforms as well as

00:44:52.156 --> 00:44:53.616
within the iOS ecosystem.

00:44:54.216 --> 00:44:55.986
So across platform, this is

00:44:55.986 --> 00:44:57.616
stuff that we need to fit on the

00:44:57.616 --> 00:44:59.936
platform at all, like removing

00:44:59.936 --> 00:45:01.456
LODs from meshes that will never

00:45:01.456 --> 00:45:03.016
display so we can fit in memory

00:45:03.466 --> 00:45:06.096
or changing the number of

00:45:06.096 --> 00:45:08.866
characters that we animate at a

00:45:08.866 --> 00:45:10.226
particular quality level in

00:45:10.226 --> 00:45:11.696
order to reduce CPU costs.

00:45:12.736 --> 00:45:14.776
Within iOS, we also defined 3

00:45:14.776 --> 00:45:17.116
buckets for scalability -- low,

00:45:17.116 --> 00:45:19.056
mid, and high -- and these were

00:45:19.056 --> 00:45:20.136
generally correlated with the

00:45:20.136 --> 00:45:21.736
different generations of

00:45:21.806 --> 00:45:24.116
iPhones, so iPhone 6s on the low

00:45:24.116 --> 00:45:26.046
end, iPhone 7 was our mid-range

00:45:26.046 --> 00:45:27.806
target, and the iPhone 8 and

00:45:27.806 --> 00:45:31.366
iPhone X on the high end.

00:45:31.366 --> 00:45:34.226
Resolution was obviously the

00:45:34.226 --> 00:45:36.356
simplest and best scalability

00:45:36.516 --> 00:45:37.446
option that we had.

00:45:37.786 --> 00:45:38.836
We ended up tuning this per

00:45:38.836 --> 00:45:39.266
device.

00:45:39.766 --> 00:45:41.186
We preferred to use backbuffer

00:45:41.186 --> 00:45:42.456
resolution where possible --

00:45:42.456 --> 00:45:43.836
this is what the UI renders at

00:45:44.346 --> 00:45:45.996
-- because if we do this, then

00:45:45.996 --> 00:45:47.676
we don't have to pay a separate

00:45:47.676 --> 00:45:48.726
upsampling cost.

00:45:49.196 --> 00:45:50.746
However, we do support rendering

00:45:50.786 --> 00:45:52.736
3D resolution at a lower

00:45:52.736 --> 00:45:54.566
resolution, and we do so in some

00:45:54.566 --> 00:45:56.826
cases where we needed a crisp UI

00:45:56.826 --> 00:45:58.886
but had to reduce 3D render

00:45:58.886 --> 00:46:00.746
resolution lower than that in

00:46:00.746 --> 00:46:01.866
order to meet our performance

00:46:01.866 --> 00:46:03.976
goals -- the iPhone 6s, for

00:46:03.976 --> 00:46:04.456
example.

00:46:06.176 --> 00:46:07.846
Shadows were another axis of

00:46:07.846 --> 00:46:09.296
scalability and actually really

00:46:09.296 --> 00:46:10.576
important because they impact

00:46:10.686 --> 00:46:12.376
both the CPU and the GPU.

00:46:13.056 --> 00:46:15.076
On low-end devices, we don't

00:46:15.076 --> 00:46:16.276
render any shadows at all.

00:46:16.586 --> 00:46:17.956
On our mid-range target, we have

00:46:17.956 --> 00:46:21.016
1 cascade, 1024 by 1024.

00:46:21.506 --> 00:46:22.726
We set the distance to be about

00:46:22.726 --> 00:46:24.006
the size of a building, so if

00:46:24.006 --> 00:46:25.136
you're inside of a structure,

00:46:25.426 --> 00:46:26.276
you're not going to see light

00:46:26.276 --> 00:46:28.056
leaking on the other side.

00:46:28.736 --> 00:46:29.936
High-end phones add a second

00:46:29.936 --> 00:46:31.246
cascade, which gives crisper

00:46:31.246 --> 00:46:32.586
character shadows as well as

00:46:32.586 --> 00:46:34.096
lets us push out the shadowing

00:46:34.096 --> 00:46:35.966
distance a little further.

00:46:37.406 --> 00:46:38.956
Foliage was another axis of

00:46:38.956 --> 00:46:39.646
scalability.

00:46:39.996 --> 00:46:41.426
On low-end devices, we simply

00:46:41.426 --> 00:46:42.486
don't render foliage.

00:46:42.756 --> 00:46:43.656
On the mid range, we render

00:46:43.656 --> 00:46:45.556
about 30% of the density we

00:46:45.556 --> 00:46:46.516
support on console.

00:46:46.816 --> 00:46:47.936
And on high-end devices, we

00:46:47.936 --> 00:46:49.716
actually render 100% of the

00:46:49.716 --> 00:46:50.836
density that we support on

00:46:50.836 --> 00:46:51.266
console.

00:46:53.956 --> 00:46:55.666
Memory is interesting in terms

00:46:55.666 --> 00:46:57.006
of scalability because it

00:46:57.006 --> 00:46:58.296
doesn't always correlate with

00:46:58.336 --> 00:46:59.006
performance.

00:46:59.456 --> 00:47:00.866
For instance, an iPhone 8 is

00:47:00.866 --> 00:47:02.336
faster than an iPhone 7 Plus,

00:47:02.336 --> 00:47:03.796
but it has less physical memory.

00:47:04.256 --> 00:47:05.146
This means when you're taking

00:47:05.146 --> 00:47:06.506
into account scalability, you

00:47:06.506 --> 00:47:07.316
need to treat memory

00:47:07.316 --> 00:47:07.936
differently.

00:47:07.936 --> 00:47:09.786
We ended up treating it as an

00:47:09.786 --> 00:47:11.616
orthogonal axis of scalability

00:47:12.226 --> 00:47:14.256
and just had 2 buckets, low

00:47:14.256 --> 00:47:15.226
memory and high memory.

00:47:16.046 --> 00:47:17.506
For low-memory devices, we

00:47:17.506 --> 00:47:18.926
disabled foliage and shadows.

00:47:19.446 --> 00:47:20.956
We also reduced some of the

00:47:20.956 --> 00:47:21.656
memory pool.

00:47:21.656 --> 00:47:23.296
So for instance, we limited GPU

00:47:23.296 --> 00:47:25.396
particles to a total of 16,000

00:47:25.846 --> 00:47:27.416
and reduced the pool use for

00:47:27.416 --> 00:47:29.246
cosmetics and texture memory.

00:47:29.816 --> 00:47:32.926
We still need to do quite a bit

00:47:32.926 --> 00:47:34.266
of memory optimization in order

00:47:34.266 --> 00:47:35.346
to get the game to fit on the

00:47:35.346 --> 00:47:35.846
device.

00:47:36.366 --> 00:47:37.816
The most important was level

00:47:37.816 --> 00:47:38.936
streaming -- basically, just

00:47:38.936 --> 00:47:40.046
making sure that nothing is in

00:47:40.046 --> 00:47:41.176
memory that is not around the

00:47:41.176 --> 00:47:41.566
player.

00:47:42.356 --> 00:47:44.606
We also used ASTC texture

00:47:44.606 --> 00:47:46.116
compression and tend to prefer

00:47:46.416 --> 00:47:48.776
compressing for size rather than

00:47:48.836 --> 00:47:50.476
quality in most cases.

00:47:50.846 --> 00:47:52.236
And we also gave our artists a

00:47:52.236 --> 00:47:54.106
lot of tools for being able to

00:47:54.506 --> 00:47:57.426
cook out different LODs that

00:47:57.426 --> 00:47:59.946
aren't needed or reduce audio

00:47:59.946 --> 00:48:01.766
variations on a per-platform

00:48:01.766 --> 00:48:02.326
basis.

00:48:04.926 --> 00:48:05.936
Want to talk a little bit about

00:48:05.936 --> 00:48:06.736
frame rate targets.

00:48:07.156 --> 00:48:08.566
So on iOS, we wanted to target

00:48:08.566 --> 00:48:10.546
30 fps at the highest visual

00:48:10.546 --> 00:48:11.626
fidelity possible.

00:48:12.176 --> 00:48:13.886
However, you can't just max out

00:48:13.916 --> 00:48:14.426
the device.

00:48:14.426 --> 00:48:15.766
If we were maxing out the CPU

00:48:15.766 --> 00:48:17.676
and the GPU the entire time, the

00:48:17.676 --> 00:48:19.466
operating system would end up

00:48:19.526 --> 00:48:21.206
downclocking us, then we'd no

00:48:21.206 --> 00:48:22.486
longer hit our frame rates.

00:48:22.486 --> 00:48:24.756
We also want to conserve battery

00:48:24.756 --> 00:48:25.126
life.

00:48:25.476 --> 00:48:26.776
If players are playing several

00:48:26.776 --> 00:48:27.786
games in a row during their

00:48:27.786 --> 00:48:30.336
commute, we want to support that

00:48:30.336 --> 00:48:31.806
rather than their device dying

00:48:31.806 --> 00:48:32.676
before they even make it to

00:48:32.676 --> 00:48:32.916
work.

00:48:33.766 --> 00:48:36.716
So for this, what we decided to

00:48:36.716 --> 00:48:38.216
do was to target 60 frames per

00:48:38.216 --> 00:48:39.686
second for the environment, but

00:48:39.686 --> 00:48:41.796
vsync at 30, which means most of

00:48:41.796 --> 00:48:42.936
the time when you're exploring

00:48:43.106 --> 00:48:45.306
the map in Fortnite, your phone

00:48:45.306 --> 00:48:47.146
is idle about 50% of the time.

00:48:47.216 --> 00:48:48.236
Using that time to conserve

00:48:48.236 --> 00:48:49.986
battery life and keep cool.

00:48:52.476 --> 00:48:53.916
To make sure that we hit those

00:48:53.916 --> 00:48:56.006
targets, we track performance

00:48:56.006 --> 00:48:56.896
every day.

00:48:57.396 --> 00:48:58.546
So every day, we have an

00:48:58.546 --> 00:49:00.096
automation pass that goes

00:49:00.096 --> 00:49:00.496
through.

00:49:00.976 --> 00:49:04.106
We look at key locations in the

00:49:04.106 --> 00:49:06.056
map, and we capture performance.

00:49:06.056 --> 00:49:08.126
So for instance, Tilted Towers,

00:49:08.126 --> 00:49:09.616
and Shifty Shafts, and all of

00:49:09.616 --> 00:49:11.396
the usual POIs that you're

00:49:11.396 --> 00:49:12.756
familiar with in Battle Royale.

00:49:13.356 --> 00:49:15.126
When one goes over budget, we

00:49:15.126 --> 00:49:16.506
know we need to dive in, figure

00:49:16.506 --> 00:49:17.676
out where performance is going,

00:49:17.676 --> 00:49:18.356
and optimize.

00:49:18.966 --> 00:49:20.486
We also have daily 100-player

00:49:20.486 --> 00:49:22.346
playtests where we capture the

00:49:22.346 --> 00:49:23.566
dynamic performance that you'll

00:49:23.566 --> 00:49:24.696
only see during a game.

00:49:25.246 --> 00:49:26.436
We track key performance over

00:49:26.436 --> 00:49:29.376
time for the match, and then we

00:49:29.376 --> 00:49:30.116
can take a look at this

00:49:30.116 --> 00:49:32.176
afterwards and see how it

00:49:32.176 --> 00:49:34.566
performed, look for hitches,

00:49:34.566 --> 00:49:35.296
stuff like that.

00:49:35.806 --> 00:49:37.966
And if something looks off, we

00:49:37.966 --> 00:49:39.596
can pull an instrumented profile

00:49:39.596 --> 00:49:41.256
off of the device, take a look

00:49:41.256 --> 00:49:42.686
at where time was going, and

00:49:42.686 --> 00:49:43.496
figure out where we need to

00:49:43.496 --> 00:49:44.106
optimize.

00:49:45.086 --> 00:49:46.336
We also support replays.

00:49:46.336 --> 00:49:48.956
This is a feature in Unreal that

00:49:48.956 --> 00:49:50.546
allow us to go and replay that

00:49:50.546 --> 00:49:51.986
match from a client perspective.

00:49:51.986 --> 00:49:53.266
So we can play it over and over,

00:49:53.266 --> 00:49:55.706
analyze it, profile it, and even

00:49:55.706 --> 00:49:57.306
see how optimizations would have

00:49:57.306 --> 00:49:59.746
affected the client in that play

00:49:59.746 --> 00:50:00.206
session.

00:50:01.976 --> 00:50:03.726
Going to talk a little bit about

00:50:03.726 --> 00:50:04.896
metal specifically.

00:50:05.716 --> 00:50:09.006
So we, on most devices, we have

00:50:09.006 --> 00:50:11.786
2 cores, right, and so the way

00:50:11.786 --> 00:50:13.626
we utilize that is we have a

00:50:14.206 --> 00:50:14.966
traditional game

00:50:14.966 --> 00:50:16.196
thread/rendering thread split.

00:50:16.576 --> 00:50:17.676
On the game thread, we're doing

00:50:17.676 --> 00:50:19.086
networking, simulation,

00:50:19.086 --> 00:50:20.746
animation, physics, and so on.

00:50:21.316 --> 00:50:22.546
The rendering thread does all of

00:50:22.546 --> 00:50:24.576
scene traversal, culling, and

00:50:24.576 --> 00:50:25.796
issues all of the Metal API

00:50:25.796 --> 00:50:26.316
calls.

00:50:26.646 --> 00:50:29.316
We also have an async thread.

00:50:29.626 --> 00:50:31.026
Mostly, it's handling streaming

00:50:31.026 --> 00:50:32.796
tasks -- texture streaming as

00:50:32.796 --> 00:50:34.386
well as level streaming.

00:50:36.006 --> 00:50:37.726
On newer devices where we have 2

00:50:37.726 --> 00:50:39.996
fast and 4 efficient cores, we

00:50:39.996 --> 00:50:41.456
add 3 more task threads and

00:50:41.456 --> 00:50:42.656
enable some of the parallel

00:50:42.656 --> 00:50:44.186
algorithms available in Unreal.

00:50:44.796 --> 00:50:47.476
So we take animation, put it,

00:50:47.476 --> 00:50:48.526
simulate it over on multiple

00:50:48.526 --> 00:50:51.126
frames, CPU particles, physics,

00:50:51.126 --> 00:50:53.926
and so on, scene culling, a

00:50:53.926 --> 00:50:55.056
couple other tasks.

00:50:57.376 --> 00:50:59.166
I mentioned draw calls earlier.

00:50:59.296 --> 00:51:00.916
Draw calls were our main

00:51:00.916 --> 00:51:02.586
performance bottleneck, and this

00:51:02.586 --> 00:51:03.836
is actually where Metal really

00:51:03.836 --> 00:51:04.536
helped us out.

00:51:05.516 --> 00:51:07.346
We found Metal to be somewhere

00:51:07.346 --> 00:51:08.606
on the order of 3 to 4 times

00:51:08.606 --> 00:51:10.666
faster than OpenGL for what we

00:51:10.666 --> 00:51:12.876
were doing, and that allowed us

00:51:12.876 --> 00:51:14.206
to ship without doing a lot of

00:51:14.206 --> 00:51:15.386
aggressive work trying to reduce

00:51:15.386 --> 00:51:15.876
draw calls.

00:51:16.186 --> 00:51:17.276
We did stuff to reduce draw

00:51:17.276 --> 00:51:19.116
calls, mostly pulling in cull

00:51:19.116 --> 00:51:20.946
distance on decorative objects

00:51:20.946 --> 00:51:23.236
as well as leveraging the

00:51:23.236 --> 00:51:24.696
hierarchical level of detail

00:51:24.696 --> 00:51:25.236
system.

00:51:27.696 --> 00:51:29.066
So here's an example.

00:51:29.066 --> 00:51:30.656
This is one of those POIs that

00:51:30.656 --> 00:51:31.726
we tracked over time.

00:51:32.176 --> 00:51:33.006
If you're familiar with the

00:51:33.006 --> 00:51:34.216
game, this is looking down on

00:51:34.216 --> 00:51:38.386
Tilted Towers from a cliff and

00:51:38.386 --> 00:51:40.016
was kind of our draw call hot

00:51:40.016 --> 00:51:40.866
spot in the map.

00:51:41.396 --> 00:51:42.686
As you can see, it takes about

00:51:42.686 --> 00:51:45.056
1300 draw calls to render this.

00:51:45.196 --> 00:51:46.476
This is just for the main pass.

00:51:46.476 --> 00:51:47.896
It doesn't include shadows, UI,

00:51:48.776 --> 00:51:50.126
anything else that consumed draw

00:51:50.126 --> 00:51:50.686
call time.

00:51:51.196 --> 00:51:52.606
But Metal's really fast here.

00:51:52.606 --> 00:51:53.766
On an iPhone 8 Plus, we were

00:51:53.766 --> 00:51:55.136
able to chew through that in

00:51:55.136 --> 00:51:56.266
under 5 milliseconds.

00:51:58.456 --> 00:51:59.946
I mentioned hierarchical LOD.

00:51:59.946 --> 00:52:01.446
This is a feature we have in

00:52:01.486 --> 00:52:02.806
Unreal where we can take

00:52:03.276 --> 00:52:04.976
multiple draw calls and generate

00:52:04.976 --> 00:52:06.226
a simplified version, a

00:52:06.226 --> 00:52:08.426
simplified mesh, as well as a

00:52:08.426 --> 00:52:09.466
material so that we can

00:52:09.466 --> 00:52:10.286
basically render a

00:52:10.286 --> 00:52:14.176
representation of that area in a

00:52:14.176 --> 00:52:15.036
single draw call.

00:52:15.526 --> 00:52:18.116
We use this for taking POIs and

00:52:18.356 --> 00:52:19.566
generating the simplified

00:52:19.566 --> 00:52:20.906
versions for rendering very,

00:52:20.906 --> 00:52:21.646
very far away.

00:52:22.056 --> 00:52:22.816
For instance, during the

00:52:22.816 --> 00:52:24.386
skydive, you can see the entire

00:52:24.386 --> 00:52:24.696
map.

00:52:25.166 --> 00:52:26.296
In fact, when you're on the map,

00:52:26.296 --> 00:52:28.086
you can get on a cliff or just

00:52:28.166 --> 00:52:29.606
build a very high tower of your

00:52:29.606 --> 00:52:32.096
own and see points of interest

00:52:32.096 --> 00:52:33.616
from up to 2 kilometers away.

00:52:35.936 --> 00:52:38.056
Digging into some of the other

00:52:38.056 --> 00:52:40.476
details on the Metal side, I

00:52:40.476 --> 00:52:41.376
want to talk a little bit about

00:52:41.376 --> 00:52:42.366
pipeline state objects.

00:52:42.366 --> 00:52:43.546
This was something that took us

00:52:43.546 --> 00:52:44.706
a little bit of time to get into

00:52:44.706 --> 00:52:46.146
a shippable state for Fortnite.

00:52:46.796 --> 00:52:48.116
You really want to minimize how

00:52:48.116 --> 00:52:50.446
many PSOs you're creating while

00:52:50.446 --> 00:52:51.576
you're simulating the game

00:52:51.576 --> 00:52:52.286
during the frame.

00:52:52.586 --> 00:52:53.816
If you create too many, it's

00:52:53.816 --> 00:52:55.396
very easy to hitch and create a

00:52:55.396 --> 00:52:56.686
poor player experience.

00:52:57.236 --> 00:52:58.606
So first of all, follow best

00:52:58.606 --> 00:52:59.456
practices, right.

00:52:59.846 --> 00:53:01.266
Compile your functions offline,

00:53:01.266 --> 00:53:03.426
build your library offline, and

00:53:03.476 --> 00:53:04.566
pull all of your functions into

00:53:04.566 --> 00:53:05.326
a single library.

00:53:05.846 --> 00:53:07.056
But you really want to make sure

00:53:07.056 --> 00:53:08.656
you create all of your PSOs at

00:53:08.656 --> 00:53:09.146
load time.

00:53:09.556 --> 00:53:10.986
But what do you do if you can't

00:53:10.986 --> 00:53:11.346
do that?

00:53:11.786 --> 00:53:12.966
So for us, the permutation

00:53:12.966 --> 00:53:14.086
matrix is just crazy.

00:53:14.136 --> 00:53:15.516
There's way too many for us to

00:53:15.516 --> 00:53:16.826
realistically create at load

00:53:17.576 --> 00:53:18.016
time.

00:53:18.076 --> 00:53:20.586
We have multiple artist-authored

00:53:20.586 --> 00:53:22.286
shaders -- thousands of them --

00:53:22.846 --> 00:53:24.306
multiple lighting scenarios

00:53:24.306 --> 00:53:26.356
based on number of shadow

00:53:26.356 --> 00:53:28.926
cascades and so on, different

00:53:28.926 --> 00:53:30.546
render target formats, MSAA.

00:53:30.776 --> 00:53:31.516
The list goes on.

00:53:32.726 --> 00:53:33.576
We tried to minimize

00:53:33.576 --> 00:53:35.116
permutations where we could, and

00:53:35.116 --> 00:53:35.776
this does help.

00:53:35.776 --> 00:53:37.136
Sometimes a dynamic branch is

00:53:37.136 --> 00:53:38.626
good enough and better than

00:53:38.626 --> 00:53:40.046
creating a static permutation,

00:53:40.646 --> 00:53:42.356
but sometimes not.

00:53:42.736 --> 00:53:44.716
What we had to do is we decided

00:53:44.716 --> 00:53:45.966
to identify the most common

00:53:45.966 --> 00:53:47.186
subset that we're likely to

00:53:47.186 --> 00:53:48.816
need, and we create those at

00:53:48.816 --> 00:53:49.196
load.

00:53:49.566 --> 00:53:50.346
We don't try to create

00:53:50.346 --> 00:53:50.856
everything.

00:53:51.306 --> 00:53:52.576
The way we achieved this is we

00:53:52.576 --> 00:53:54.116
created an automation pass where

00:53:54.116 --> 00:53:55.296
we basically flew a camera

00:53:55.296 --> 00:53:56.716
through the environment and

00:53:56.716 --> 00:53:58.116
recorded all of the PSOs that we

00:53:58.116 --> 00:53:59.286
actually needed to render the

00:53:59.286 --> 00:53:59.876
environment.

00:54:00.316 --> 00:54:01.226
Then, during our daily

00:54:01.226 --> 00:54:03.396
playtests, we harvested any PSOs

00:54:03.396 --> 00:54:06.106
that were created that were not

00:54:06.106 --> 00:54:07.576
caught by that automation pass.

00:54:07.966 --> 00:54:09.276
The automation pass also

00:54:09.756 --> 00:54:12.476
catches, like, cosmetics, and

00:54:12.896 --> 00:54:14.176
effects from firing different

00:54:14.176 --> 00:54:15.136
weapons, and so on.

00:54:16.556 --> 00:54:18.056
We take all of that information

00:54:18.056 --> 00:54:19.126
from automation and from the

00:54:19.126 --> 00:54:20.276
playtest, combine it into a

00:54:20.276 --> 00:54:20.666
list.

00:54:20.856 --> 00:54:22.486
That's what we create at load

00:54:22.486 --> 00:54:23.856
time, and that's what we ship

00:54:23.856 --> 00:54:24.416
with the game.

00:54:24.956 --> 00:54:26.266
It's not perfect, but we find

00:54:26.266 --> 00:54:27.556
that the number of PSOs we

00:54:27.556 --> 00:54:28.686
create at runtime is in the

00:54:28.686 --> 00:54:30.136
single digits for any given play

00:54:30.136 --> 00:54:31.146
session, on average.

00:54:31.516 --> 00:54:32.926
And so players don't experience

00:54:32.926 --> 00:54:34.846
any hitching from PSO creation.

00:54:37.356 --> 00:54:39.096
Resource allocation.

00:54:39.196 --> 00:54:43.216
So basically, creating and

00:54:43.366 --> 00:54:46.466
deleting resources is expensive

00:54:46.466 --> 00:54:47.326
or can be expensive.

00:54:47.326 --> 00:54:50.046
It's kind of like, think of

00:54:50.046 --> 00:54:50.113
[inaudible].

00:54:50.113 --> 00:54:51.166
You really want to minimize the

00:54:51.166 --> 00:54:52.276
number of [inaudible] you're

00:54:52.276 --> 00:54:53.036
making per frame.

00:54:53.436 --> 00:54:54.246
You really don't want to be

00:54:54.246 --> 00:54:55.416
creating and destroying a lot of

00:54:55.416 --> 00:54:57.246
resources on the fly, but when

00:54:57.246 --> 00:54:58.476
you're streaming in content

00:54:58.656 --> 00:55:00.606
dynamically, when you have a lot

00:55:00.606 --> 00:55:02.746
of movable objects, some of this

00:55:02.866 --> 00:55:05.026
just isn't possible to avoid.

00:55:05.646 --> 00:55:09.636
So what we did for buffers is we

00:55:09.806 --> 00:55:11.276
just used buffer suballocation

00:55:11.276 --> 00:55:12.446
-- basically, a bend allocation

00:55:12.446 --> 00:55:13.006
strategy.

00:55:13.346 --> 00:55:14.476
Upfront, we allocate a big

00:55:14.476 --> 00:55:15.996
buffer, and then we suballocate

00:55:16.606 --> 00:55:19.146
small chunks back to the engine

00:55:19.146 --> 00:55:20.906
to avoid asking Metal for new

00:55:20.906 --> 00:55:22.776
buffers all the time.

00:55:23.056 --> 00:55:24.446
And this ended up helping a lot.

00:55:25.976 --> 00:55:27.636
We also leveraged programmable

00:55:27.636 --> 00:55:30.186
blending to reduce the number of

00:55:30.186 --> 00:55:31.906
resolves and restores and the

00:55:31.906 --> 00:55:33.446
amount of memory bandwidth we

00:55:33.446 --> 00:55:33.786
use.

00:55:34.356 --> 00:55:36.596
Specifically, the main use case

00:55:36.596 --> 00:55:38.536
we have for this is anywhere we

00:55:38.536 --> 00:55:40.336
need access to scene depth, so

00:55:40.336 --> 00:55:41.416
things like soft particle

00:55:41.416 --> 00:55:43.286
blending or projected decals.

00:55:43.286 --> 00:55:45.036
What we do is during the forward

00:55:45.036 --> 00:55:46.586
pass, we write our linear depth

00:55:46.586 --> 00:55:47.546
to the alpha channel.

00:55:47.946 --> 00:55:49.126
And then, during our decal and

00:55:49.126 --> 00:55:50.546
translucent passes, all we need

00:55:50.546 --> 00:55:52.246
to do is use programmable

00:55:52.246 --> 00:55:53.266
blending to read that alpha

00:55:53.266 --> 00:55:55.146
channel back, and we can use

00:55:55.146 --> 00:55:57.796
depth without having ever had to

00:55:57.916 --> 00:55:59.846
resolve the depth buffer to main

00:55:59.846 --> 00:56:00.186
memory.

00:56:01.916 --> 00:56:03.006
We also use it to improve the

00:56:03.006 --> 00:56:04.286
quality of MSAA.

00:56:04.806 --> 00:56:06.356
As I mentioned, we do HDR

00:56:06.356 --> 00:56:08.316
rendering, and a-- just an MSAA

00:56:08.316 --> 00:56:10.906
resolve of HDR can still lead to

00:56:10.906 --> 00:56:12.116
very aliased edges.

00:56:12.506 --> 00:56:13.556
Think of cases where you have a

00:56:13.556 --> 00:56:15.226
very, very bright sky and a

00:56:15.226 --> 00:56:16.636
very, very dark foreground.

00:56:17.126 --> 00:56:19.616
Just doing a box filter over

00:56:19.616 --> 00:56:22.526
that is, basically, if 1 of

00:56:22.526 --> 00:56:24.396
those subsamples is incredibly

00:56:24.576 --> 00:56:25.876
bright and the others are

00:56:25.876 --> 00:56:27.516
incredibly dark, the result is

00:56:27.516 --> 00:56:28.606
going to be an incredibly bright

00:56:28.606 --> 00:56:29.106
pixel.

00:56:29.106 --> 00:56:30.066
And when tone mapped, it'll be

00:56:30.066 --> 00:56:31.136
something close to white.

00:56:31.516 --> 00:56:32.656
You end up with edges that don't

00:56:32.656 --> 00:56:33.766
look anti-aliased at all.

00:56:33.766 --> 00:56:36.436
So our solution to this was to

00:56:36.436 --> 00:56:38.866
do a pre tone map over all of

00:56:38.866 --> 00:56:41.686
the MSAA samples, then perform

00:56:41.686 --> 00:56:43.606
the normal MSAA resolve, and

00:56:43.606 --> 00:56:44.766
then the first postprocessing

00:56:44.766 --> 00:56:46.356
pass just reverses that pre tone

00:56:46.356 --> 00:56:46.576
map.

00:56:47.486 --> 00:56:49.026
We use programmable blending for

00:56:49.026 --> 00:56:50.116
the pre tone map pass.

00:56:50.746 --> 00:56:51.946
Otherwise, we'd have to resolve

00:56:51.946 --> 00:56:53.576
the entire MSAA color buffer to

00:56:53.576 --> 00:56:55.366
memory and read it back in,

00:56:55.366 --> 00:56:56.796
which would be unaffordable.

00:56:58.676 --> 00:57:00.316
Looking forward to some of the

00:57:00.316 --> 00:57:01.546
work we'd like to do in the

00:57:01.546 --> 00:57:04.066
future with Metal, parallel

00:57:04.066 --> 00:57:04.556
rendering.

00:57:04.556 --> 00:57:06.996
So on macOS, we do support

00:57:07.416 --> 00:57:08.626
creating command buffers in

00:57:08.626 --> 00:57:09.216
parallel.

00:57:09.756 --> 00:57:12.186
On iOS, we'd really need to

00:57:12.186 --> 00:57:13.266
support parallel command

00:57:13.266 --> 00:57:14.256
encoders for this to be

00:57:14.256 --> 00:57:14.876
practical.

00:57:15.176 --> 00:57:16.476
A lot of our drawing ends up

00:57:16.476 --> 00:57:17.646
happening in the main forward

00:57:17.646 --> 00:57:19.376
pass, and so it's important to

00:57:20.176 --> 00:57:21.546
parallelize that.

00:57:22.206 --> 00:57:23.436
I think it would be very

00:57:23.436 --> 00:57:25.076
interesting to sort of see the

00:57:25.076 --> 00:57:27.876
effects of parallel rendering on

00:57:28.006 --> 00:57:30.786
a monolithic, fast core versus

00:57:30.896 --> 00:57:33.156
what we had for parallel command

00:57:33.156 --> 00:57:34.616
encoders on the efficient cores

00:57:34.616 --> 00:57:35.626
on higher-end devices.

00:57:35.946 --> 00:57:36.616
Could be some interesting

00:57:36.616 --> 00:57:38.416
results in terms of battery

00:57:38.416 --> 00:57:38.896
usage.

00:57:40.656 --> 00:57:41.696
Metal heaps.

00:57:41.786 --> 00:57:42.736
So we'd like to replace our

00:57:42.736 --> 00:57:44.276
buffer suballocation with Metal

00:57:44.276 --> 00:57:46.396
heaps -- first, because it'll

00:57:46.396 --> 00:57:47.586
just simply our code, but

00:57:47.586 --> 00:57:49.246
second, because we can also use

00:57:49.246 --> 00:57:50.056
it for textures.

00:57:50.366 --> 00:57:51.576
We still see an occasional hitch

00:57:51.576 --> 00:57:52.746
due to texture streaming because

00:57:52.746 --> 00:57:54.546
we're obviously creating and

00:57:54.546 --> 00:57:55.736
destroying textures on the fly

00:57:55.736 --> 00:57:57.046
as we bring textures in and out

00:57:57.046 --> 00:57:57.586
of memory.

00:57:58.146 --> 00:57:59.946
Being able to use heaps for this

00:57:59.946 --> 00:58:01.516
will get rid of those hitches.

00:58:01.516 --> 00:58:05.016
For us, we just, it's, the work

00:58:05.016 --> 00:58:05.976
we have in front of us to make

00:58:05.976 --> 00:58:08.226
that possible is setting up

00:58:08.276 --> 00:58:09.486
precise fencing between the

00:58:09.486 --> 00:58:10.636
different passes, right.

00:58:10.986 --> 00:58:13.266
So we need to know explicitly if

00:58:13.266 --> 00:58:14.786
a resource is being read or

00:58:14.786 --> 00:58:16.146
written by a vertex or pixel

00:58:16.146 --> 00:58:18.266
shader across different passes,

00:58:18.266 --> 00:58:19.776
and it requires some reworking

00:58:19.776 --> 00:58:21.866
of some of our renderer to make

00:58:21.866 --> 00:58:22.406
that happen.

00:58:22.936 --> 00:58:25.236
And of course, continue to push

00:58:25.236 --> 00:58:26.616
the high end of graphics on iOS.

00:58:27.456 --> 00:58:29.686
Last year at WWDC, we showed

00:58:29.736 --> 00:58:31.106
what was possible by bringing

00:58:31.106 --> 00:58:32.436
our desktop-class forward

00:58:32.436 --> 00:58:33.966
renderer to high-end iOS

00:58:33.966 --> 00:58:35.916
devices, and we continue, we

00:58:35.916 --> 00:58:37.126
want to continue pushing that

00:58:37.126 --> 00:58:39.656
bar on iOS, continuing to bring

00:58:39.656 --> 00:58:43.016
desktop-class features to iOS

00:58:43.936 --> 00:58:47.026
and looking for opportunities to

00:58:47.026 --> 00:58:49.756
unify our desktop renderer with

00:58:49.896 --> 00:58:51.506
the iOS renderer.

00:58:52.046 --> 00:58:55.396
And with that, I'll hand it back

00:58:55.466 --> 00:58:55.846
to Michael.

00:58:57.516 --> 00:58:59.716
[ Applause ]

00:59:00.216 --> 00:59:01.596
>> So Metal is low overhead out

00:59:01.596 --> 00:59:03.696
of the box, but rendering many

00:59:03.696 --> 00:59:05.106
objects efficiently can require

00:59:05.106 --> 00:59:05.836
multithreading.

00:59:06.246 --> 00:59:07.736
Metal is built to take advantage

00:59:07.736 --> 00:59:09.736
of all the GPU, all the CPUs in

00:59:09.736 --> 00:59:10.366
our systems.

00:59:11.326 --> 00:59:13.156
Metal is also really accessible,

00:59:13.156 --> 00:59:14.776
but advanced rendering sometimes

00:59:14.776 --> 00:59:16.106
requires explicit control.

00:59:16.856 --> 00:59:18.386
Metal provides this control when

00:59:18.386 --> 00:59:19.226
you need it for memory

00:59:19.226 --> 00:59:21.306
management and GPU parallelism.

00:59:22.526 --> 00:59:23.816
We also introduced indirect

00:59:23.816 --> 00:59:25.026
command buffers, our brand-new

00:59:25.026 --> 00:59:26.116
feature that lets you move

00:59:26.116 --> 00:59:27.616
command generation entirely to

00:59:27.616 --> 00:59:29.666
the GPU, freeing the CPU for

00:59:29.666 --> 00:59:30.276
other tasks.

00:59:31.106 --> 00:59:32.666
Together with argument buffers,

00:59:32.906 --> 00:59:33.816
these features provide a

00:59:33.816 --> 00:59:35.616
complete solution to GPU-driven

00:59:35.616 --> 00:59:36.216
pipelines.

00:59:37.306 --> 00:59:39.236
And finally, Metal lets you

00:59:39.236 --> 00:59:40.086
leverage the advanced

00:59:40.086 --> 00:59:42.256
architecture of the A11 GPU to

00:59:42.256 --> 00:59:43.426
optimize many rendering

00:59:43.426 --> 00:59:44.796
techniques for both maximum

00:59:44.796 --> 00:59:46.566
performance and extended

00:59:47.216 --> 00:59:47.396
playtime.

00:59:49.126 --> 00:59:50.896
For more information, please

00:59:50.896 --> 00:59:52.656
visit our website, and be sure

00:59:52.736 --> 00:59:54.256
to visit us in tomorrow's lab.

00:59:55.136 --> 00:59:55.446
Thank you.

00:59:56.516 --> 01:00:04.010
[ Applause ]