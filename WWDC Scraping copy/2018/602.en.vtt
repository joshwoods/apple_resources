WEBVTT

00:00:07.516 --> 00:00:17.500
[ Music ]

00:00:22.516 --> 00:00:26.086
[ Applause ]

00:00:26.586 --> 00:00:27.746
>> So, good morning.

00:00:29.806 --> 00:00:31.406
Welcome to our session on What's

00:00:31.476 --> 00:00:34.516
New in ARKit 2.

00:00:34.806 --> 00:00:36.736
My name is Arsalan, and I am an

00:00:36.736 --> 00:00:41.276
engineer from ARKit team.

00:00:41.616 --> 00:00:42.906
Last year, we were really

00:00:42.906 --> 00:00:45.536
excited to give ARKit in your

00:00:45.536 --> 00:00:48.976
hands as part of iOS 11 update.

00:00:49.386 --> 00:00:53.496
ARKit has been deployed to

00:00:53.496 --> 00:00:55.266
hundreds of millions of devices,

00:00:56.086 --> 00:00:58.296
making iOS the biggest and most

00:00:58.296 --> 00:00:59.816
advanced AR platform.

00:01:03.226 --> 00:01:05.206
ARKit gives you simple to use

00:01:05.266 --> 00:01:06.986
interface for powerful set of

00:01:07.016 --> 00:01:07.476
features.

00:01:10.136 --> 00:01:12.416
We have been truly amazed by

00:01:12.416 --> 00:01:14.396
what you have created with ARKit

00:01:14.396 --> 00:01:15.286
so far.

00:01:15.486 --> 00:01:17.456
So let's see some examples from

00:01:17.456 --> 00:01:17.876
App Store.

00:01:20.386 --> 00:01:23.156
Civilisations is an AR app that

00:01:23.156 --> 00:01:25.066
brings historical artifacts in

00:01:25.066 --> 00:01:25.536
front of you.

00:01:26.296 --> 00:01:27.966
You can view them from every

00:01:27.966 --> 00:01:28.326
angle.

00:01:28.816 --> 00:01:32.206
You can also enable x-ray modes

00:01:32.436 --> 00:01:33.746
to have mode interaction.

00:01:35.206 --> 00:01:36.906
You can bring them in your

00:01:37.086 --> 00:01:40.226
backyard, and you can even bring

00:01:40.226 --> 00:01:42.336
them to life exactly they look

00:01:42.336 --> 00:01:43.596
like hundreds of years ago.

00:01:45.096 --> 00:01:46.416
So this is a great tool to

00:01:46.416 --> 00:01:48.016
browse historical artifacts.

00:01:50.356 --> 00:01:52.376
Boulevard AR is an all right app

00:01:52.516 --> 00:01:55.346
that lets you browse the work of

00:01:55.346 --> 00:01:57.446
arts in a way that's never been

00:01:57.446 --> 00:01:58.176
possible before.

00:01:58.796 --> 00:02:00.486
You can put them on ground or

00:02:00.486 --> 00:02:02.736
wall, and you can really go

00:02:02.736 --> 00:02:04.456
close to them, and you can see

00:02:04.456 --> 00:02:04.996
all the details.

00:02:04.996 --> 00:02:07.756
It's just a great way to tell

00:02:07.756 --> 00:02:09.386
you story of arts.

00:02:16.316 --> 00:02:18.216
ARKit is a fun way to educate

00:02:18.216 --> 00:02:19.326
everyone.

00:02:19.976 --> 00:02:21.936
Free reverse is an app that

00:02:22.126 --> 00:02:24.246
places immersive landscape in

00:02:24.246 --> 00:02:24.726
front of you.

00:02:25.586 --> 00:02:27.336
You can follow a flow of a river

00:02:27.336 --> 00:02:29.786
going through landscape and see

00:02:30.046 --> 00:02:31.276
communities and wild life.

00:02:32.146 --> 00:02:34.006
You can see how human activity

00:02:35.006 --> 00:02:37.506
impacts those communities and

00:02:37.836 --> 00:02:40.056
wildlife by constructions.

00:02:42.386 --> 00:02:43.966
So it's a great way to educate

00:02:43.966 --> 00:02:45.726
everyone about keeping the

00:02:45.726 --> 00:02:48.046
environment green and through

00:02:48.046 --> 00:02:48.966
sustainable development.

00:02:49.836 --> 00:02:51.016
So those were some of the

00:02:51.016 --> 00:02:51.936
examples.

00:02:52.246 --> 00:02:54.516
Do check a lot more examples

00:02:54.626 --> 00:02:57.546
from App Store.

00:02:57.886 --> 00:02:59.926
So some of you are new to ARKit,

00:03:00.446 --> 00:03:01.666
so let me give you a quick

00:03:02.016 --> 00:03:04.286
overview of what ARKit is.

00:03:08.336 --> 00:03:10.376
Tracking is the core component

00:03:10.376 --> 00:03:10.806
of ARKit.

00:03:11.586 --> 00:03:12.886
It gives you position and

00:03:12.886 --> 00:03:14.556
orientation of your device in

00:03:14.556 --> 00:03:15.326
physical world.

00:03:15.796 --> 00:03:22.216
It can also track objects such

00:03:22.216 --> 00:03:23.126
as human faces.

00:03:23.796 --> 00:03:29.046
Scene understanding enhances

00:03:29.106 --> 00:03:30.066
tracking by learning more

00:03:30.066 --> 00:03:31.036
attributes about the

00:03:31.036 --> 00:03:31.596
environment.

00:03:32.256 --> 00:03:35.666
So we can detect horizontal

00:03:35.666 --> 00:03:37.976
planes such as ground planes or

00:03:37.976 --> 00:03:39.006
tabletops.

00:03:39.736 --> 00:03:41.116
We can also detect vertical

00:03:41.116 --> 00:03:41.466
planes.

00:03:41.836 --> 00:03:43.646
So this lets you place your

00:03:43.646 --> 00:03:45.466
virtual objects in the scene.

00:03:51.366 --> 00:03:53.576
Scene understanding also learns

00:03:53.806 --> 00:03:56.096
about lighting conditions in the

00:03:56.096 --> 00:03:56.636
environment.

00:03:57.736 --> 00:04:00.386
So you can use lighting to

00:04:00.386 --> 00:04:02.156
accurately reflect the real

00:04:02.156 --> 00:04:03.566
environment in your virtual

00:04:03.646 --> 00:04:03.906
scene.

00:04:04.216 --> 00:04:06.736
So your objects don't look too

00:04:06.736 --> 00:04:07.746
bright or too dark.

00:04:09.736 --> 00:04:11.276
Rendering is what actually a

00:04:11.276 --> 00:04:12.986
user sees on the device and

00:04:12.986 --> 00:04:15.076
interacts with the augmented

00:04:15.076 --> 00:04:15.986
reality scene.

00:04:16.416 --> 00:04:18.926
So ARKit makes it very easy for

00:04:18.926 --> 00:04:21.366
you to integrate any rendering

00:04:21.366 --> 00:04:22.125
engine of your choice.

00:04:25.936 --> 00:04:29.166
ARKit offers built-in views for

00:04:29.336 --> 00:04:30.716
SceneKit and SpriteKit.

00:04:31.196 --> 00:04:35.106
In Xcode, we also have a

00:04:35.106 --> 00:04:36.606
Metal template for you to

00:04:36.606 --> 00:04:38.246
quickly get started with your

00:04:38.246 --> 00:04:39.666
own augmented reality

00:04:41.326 --> 00:04:41.706
experience.

00:04:41.706 --> 00:04:43.936
Note also that Unity and Unreal

00:04:43.936 --> 00:04:46.116
have integrated full feature set

00:04:46.116 --> 00:04:48.016
of ARKit into their popular

00:04:48.016 --> 00:04:48.606
gaming engines.

00:04:49.006 --> 00:04:51.006
So you have all these rendering

00:04:51.006 --> 00:04:53.286
technologies available to you to

00:04:53.286 --> 00:04:54.866
get started with ARKit.

00:04:58.696 --> 00:05:00.416
So let's see, what is new this

00:05:00.446 --> 00:05:02.316
year in ARKit 2.

00:05:07.836 --> 00:05:09.436
Okay. So we have saving and

00:05:09.436 --> 00:05:11.566
loading maps that enables

00:05:11.566 --> 00:05:13.156
powerful new features of

00:05:13.356 --> 00:05:15.426
persistence and multiuser

00:05:15.426 --> 00:05:16.206
experiences.

00:05:16.796 --> 00:05:21.026
We are also giving you

00:05:21.246 --> 00:05:22.906
environment texturing so you can

00:05:22.906 --> 00:05:24.246
realistically render your

00:05:24.246 --> 00:05:25.526
augmented reality scene.

00:05:25.986 --> 00:05:30.376
ARKit can now track 2D images in

00:05:30.376 --> 00:05:31.516
real-time.

00:05:33.116 --> 00:05:34.836
We are not limited to 2D.

00:05:35.076 --> 00:05:37.466
We can also detect 3D objects in

00:05:38.046 --> 00:05:41.316
a scene.

00:05:41.536 --> 00:05:43.146
And last, we have some fun

00:05:43.146 --> 00:05:44.756
enhancements for face tracking.

00:05:47.916 --> 00:05:50.136
So let's start with saving and

00:05:50.136 --> 00:05:51.696
loading maps.

00:05:56.316 --> 00:05:58.616
Saving and loading maps is part

00:05:58.616 --> 00:05:59.656
of world tracking.

00:06:00.446 --> 00:06:01.576
World tracking gives you

00:06:01.576 --> 00:06:03.296
position and orientation of your

00:06:03.296 --> 00:06:05.616
device as our six degrees of

00:06:05.616 --> 00:06:07.666
freedom pose in real world.

00:06:08.156 --> 00:06:11.476
This lets you place objects in

00:06:11.476 --> 00:06:14.456
the scene such as this table and

00:06:14.456 --> 00:06:16.226
chair you can see in this video.

00:06:16.736 --> 00:06:20.066
World tracking also gives you

00:06:20.066 --> 00:06:21.906
accurate physical scale so you

00:06:21.906 --> 00:06:24.946
can place your objects up to the

00:06:24.946 --> 00:06:25.566
correct scale.

00:06:26.186 --> 00:06:28.006
So your objects don't look too

00:06:28.006 --> 00:06:28.976
big or too small.

00:06:34.086 --> 00:06:36.126
This can also be used to

00:06:36.126 --> 00:06:38.696
implement accurate measurements,

00:06:39.406 --> 00:06:40.666
such as the Measure app we saw

00:06:40.666 --> 00:06:41.126
yesterday.

00:06:41.696 --> 00:06:46.296
World tracking also gives you 3D

00:06:46.296 --> 00:06:48.016
feature points so you can, you

00:06:48.096 --> 00:06:50.446
can, you know some physical

00:06:50.446 --> 00:06:51.636
structure of the environment,

00:06:52.116 --> 00:06:54.076
and this can be used to perform

00:06:54.076 --> 00:06:56.486
hit testing to place objects in

00:06:56.996 --> 00:07:00.236
the scene.

00:07:00.446 --> 00:07:02.886
In iOS 11.3, we introduced

00:07:02.886 --> 00:07:03.876
relocalization.

00:07:04.776 --> 00:07:07.226
This feature lets you restore

00:07:07.226 --> 00:07:08.816
your tracking state after AR

00:07:09.526 --> 00:07:11.436
session was interrupted.

00:07:11.946 --> 00:07:13.806
So this could happen, for

00:07:13.806 --> 00:07:14.766
example, your app is

00:07:14.866 --> 00:07:17.186
backgrounded or you're using

00:07:17.236 --> 00:07:23.886
picture in picture mode on iPad.

00:07:24.086 --> 00:07:29.326
So relocalization works with a

00:07:29.326 --> 00:07:32.086
map that is continuously built

00:07:32.086 --> 00:07:32.966
by world tracking.

00:07:34.066 --> 00:07:35.966
So the more we move around the

00:07:35.966 --> 00:07:39.566
environment, the more it is able

00:07:39.566 --> 00:07:41.116
to extend and learn about

00:07:41.286 --> 00:07:42.126
different features of the

00:07:42.126 --> 00:07:43.216
environment.

00:07:48.186 --> 00:07:51.536
So this map was only available

00:07:51.656 --> 00:07:53.336
as long as your AR session was

00:07:53.336 --> 00:07:56.306
alive, but not we are giving

00:07:56.306 --> 00:08:00.026
this map available to you.

00:08:00.256 --> 00:08:03.066
In ARKit API, this map is given

00:08:03.066 --> 00:08:05.396
to you as ARWorldMap object.

00:08:14.426 --> 00:08:16.406
ARWorldMap represents mapping of

00:08:16.446 --> 00:08:19.346
physical 3D space, similar to

00:08:19.346 --> 00:08:22.036
what we see in this, on the

00:08:22.036 --> 00:08:25.676
visual, on the right.

00:08:25.886 --> 00:08:27.436
We also know that anchors are

00:08:27.436 --> 00:08:29.046
important points in physical

00:08:29.076 --> 00:08:29.376
space.

00:08:30.066 --> 00:08:31.286
So these are the places where

00:08:31.286 --> 00:08:33.306
you want to place your virtual

00:08:33.306 --> 00:08:33.666
objects.

00:08:34.576 --> 00:08:36.535
So we have also included plain

00:08:36.535 --> 00:08:38.566
anchors by default in

00:08:38.566 --> 00:08:39.746
ARWorldMap.

00:08:40.716 --> 00:08:42.895
Moreover, you can also add your

00:08:42.895 --> 00:08:44.646
custom anchors to this list

00:08:45.276 --> 00:08:46.546
since it is mutable list.

00:08:46.546 --> 00:08:48.866
So you can create your custom

00:08:48.866 --> 00:08:50.016
anchors in the scene and add

00:08:50.016 --> 00:08:51.726
them to World Map.

00:08:57.546 --> 00:08:59.236
For your visualization and

00:08:59.236 --> 00:09:01.776
debugging, World Map also give

00:09:01.776 --> 00:09:03.596
you raw feature points and

00:09:03.596 --> 00:09:06.116
extend, so you know the real

00:09:06.216 --> 00:09:12.856
physical space you just scanned.

00:09:12.856 --> 00:09:15.636
More importantly, World Map is a

00:09:15.636 --> 00:09:18.056
serializable object, so it can

00:09:18.056 --> 00:09:20.356
be serialized to any data stream

00:09:20.356 --> 00:09:22.546
of your choice, such as file on

00:09:22.546 --> 00:09:25.756
local system or to a shared

00:09:25.806 --> 00:09:27.126
network place.

00:09:28.336 --> 00:09:33.636
So this ARWorldMap object enable

00:09:33.636 --> 00:09:34.976
two powerful set of new

00:09:34.976 --> 00:09:37.116
experiences in ARKit.

00:09:37.116 --> 00:09:41.376
The first is persistence.

00:09:44.076 --> 00:09:46.526
So just to show you an example

00:09:46.526 --> 00:09:49.816
how it works, we have a user

00:09:49.816 --> 00:09:52.376
starting world tracking, and he

00:09:52.426 --> 00:09:53.956
places an object in the scene

00:09:54.626 --> 00:09:56.126
through ARKit hit testing.

00:09:56.646 --> 00:10:00.956
And before leaves the scene, he

00:10:00.956 --> 00:10:03.896
will save World Map on the

00:10:04.436 --> 00:10:04.686
device.

00:10:09.046 --> 00:10:12.066
So some point, sometime later,

00:10:12.066 --> 00:10:15.866
the user comes back, and he is

00:10:15.866 --> 00:10:17.846
able to load the same World Map,

00:10:17.846 --> 00:10:20.686
and he will find the same

00:10:20.726 --> 00:10:22.086
augmented reality experience.

00:10:22.696 --> 00:10:24.616
So he can repeat this experience

00:10:24.616 --> 00:10:26.946
as many times he wants, and he

00:10:27.026 --> 00:10:28.546
will find these objects on the

00:10:28.586 --> 00:10:30.386
table every time he will start

00:10:30.386 --> 00:10:31.006
his experience.

00:10:31.566 --> 00:10:34.376
So this is persistence in world

00:10:34.376 --> 00:10:34.716
tracking

00:10:36.016 --> 00:10:37.626
[applause].

00:10:37.626 --> 00:10:37.956
Thank you.

00:10:38.508 --> 00:10:40.508
[applause]

00:10:44.346 --> 00:10:45.946
ARWorldMap also enables

00:10:45.946 --> 00:10:47.506
multiuser experiences.

00:10:49.336 --> 00:10:51.016
Now your augmented reality

00:10:51.016 --> 00:10:52.236
experience is not limited to a

00:10:52.306 --> 00:10:53.616
single device or single user.

00:10:54.936 --> 00:10:56.956
It can be shared with many

00:10:56.956 --> 00:10:57.426
users.

00:10:59.996 --> 00:11:03.766
One user can create World Map

00:11:03.826 --> 00:11:05.986
and share with one or more

00:11:06.186 --> 00:11:06.716
users.

00:11:07.226 --> 00:11:10.866
Note that World Map represents a

00:11:10.916 --> 00:11:13.876
single coordinate system in real

00:11:13.876 --> 00:11:14.176
world.

00:11:15.126 --> 00:11:17.226
So what it means that every user

00:11:17.606 --> 00:11:18.946
will share the same working

00:11:19.006 --> 00:11:19.356
space.

00:11:20.426 --> 00:11:22.326
They are able to experience the

00:11:22.396 --> 00:11:23.506
same augmented reality

00:11:23.506 --> 00:11:25.416
experience from different point

00:11:25.936 --> 00:11:27.436
of view.

00:11:27.676 --> 00:11:29.106
So this is a great new feature.

00:11:29.716 --> 00:11:33.346
You can use World Map to enable

00:11:33.346 --> 00:11:36.476
multiuser games, such as the one

00:11:36.476 --> 00:11:37.406
we saw yesterday.

00:11:37.976 --> 00:11:42.756
We can also use ARWorldMap to

00:11:42.756 --> 00:11:44.426
create multiuser shared

00:11:44.426 --> 00:11:45.626
educational experiences.

00:11:49.856 --> 00:11:51.536
Note that we are giving

00:11:51.536 --> 00:11:53.366
ARWorldMap object in your hands,

00:11:53.906 --> 00:11:55.856
so you are free to choose any

00:11:56.636 --> 00:12:00.076
technology to share with every

00:12:00.076 --> 00:12:00.436
user.

00:12:02.156 --> 00:12:04.336
For example, for sharing you can

00:12:04.406 --> 00:12:06.706
use air drop or multipeer

00:12:06.706 --> 00:12:08.336
connectivity that relies on

00:12:08.336 --> 00:12:10.136
local Bluetooth or WiFi

00:12:10.136 --> 00:12:10.636
connection.

00:12:10.636 --> 00:12:13.186
So it means that you don't

00:12:13.186 --> 00:12:14.296
really need an internet

00:12:14.296 --> 00:12:16.226
connection for this feature to

00:12:16.746 --> 00:12:16.846
work.

00:12:22.416 --> 00:12:24.226
:15 So let's see how ARKit API

00:12:24.226 --> 00:12:25.856
makes it very easy for you to

00:12:26.406 --> 00:12:28.606
retrieve and load World Map.

00:12:30.736 --> 00:12:33.516
On your AR session object, you

00:12:33.516 --> 00:12:35.576
will need to call get current

00:12:35.576 --> 00:12:39.666
world map at any point in time.

00:12:39.836 --> 00:12:41.146
This method comes with a

00:12:41.146 --> 00:12:43.846
completion handler in which it

00:12:43.846 --> 00:12:46.586
will return you and ARWorldMap

00:12:48.446 --> 00:12:48.656
object.

00:12:49.006 --> 00:12:50.676
Note also that it can also

00:12:50.676 --> 00:12:52.746
return and other in case World

00:12:52.746 --> 00:12:53.846
Map is not available.

00:12:54.186 --> 00:12:55.676
So it's important to handle this

00:12:55.676 --> 00:12:57.486
error in your application code.

00:12:59.116 --> 00:13:03.146
So once you have ARWorldMap, you

00:13:03.146 --> 00:13:08.946
can simply set initial World Map

00:13:08.946 --> 00:13:10.686
property in world tracking

00:13:10.686 --> 00:13:13.596
configuration and run your

00:13:13.596 --> 00:13:13.966
session.

00:13:14.566 --> 00:13:17.356
Note that this can be

00:13:17.356 --> 00:13:18.976
dynamically changed as well, so

00:13:18.976 --> 00:13:20.646
you can also reconfigure AR

00:13:20.986 --> 00:13:22.466
session by running a new

00:13:22.466 --> 00:13:23.046
configuration.

00:13:23.626 --> 00:13:27.606
So once AR session is started

00:13:27.696 --> 00:13:31.266
with ARWorldMap, it will follow

00:13:31.266 --> 00:13:33.086
the exact same behavior of

00:13:33.086 --> 00:13:34.526
relocalization that we

00:13:34.526 --> 00:13:36.976
introduced in iOS 11.3.

00:13:44.086 --> 00:13:46.276
It is important for your

00:13:46.906 --> 00:13:49.946
experience that relocalization

00:13:49.946 --> 00:13:50.836
works reliably.

00:13:50.836 --> 00:13:54.076
So it is good to, it is

00:13:54.076 --> 00:13:55.296
important to acquire good World

00:13:55.296 --> 00:13:55.626
Maps.

00:13:56.406 --> 00:13:57.996
Note that you can call get a

00:13:57.996 --> 00:13:59.906
current world map at any point

00:14:00.646 --> 00:14:02.526
in time.

00:14:02.526 --> 00:14:04.976
So, it's important to scan your

00:14:04.976 --> 00:14:07.626
physical space from multiple

00:14:07.666 --> 00:14:09.226
point of views.

00:14:09.256 --> 00:14:11.266
So tracking system can really

00:14:11.266 --> 00:14:12.516
learn about physical structure

00:14:12.516 --> 00:14:13.316
of the environment.

00:14:14.956 --> 00:14:17.996
The environment should be static

00:14:17.996 --> 00:14:19.976
and well textured so we can

00:14:19.976 --> 00:14:22.326
learn, extract more features of

00:14:22.326 --> 00:14:23.936
it and learn more about the

00:14:23.936 --> 00:14:24.376
environment.

00:14:27.596 --> 00:14:30.116
And also, it's important to have

00:14:30.116 --> 00:14:31.986
dense feature points on the map,

00:14:32.296 --> 00:14:34.936
so it can reliably relocalize.

00:14:37.076 --> 00:14:38.716
But you don't have to worry

00:14:38.716 --> 00:14:40.256
about all those points.

00:14:41.676 --> 00:14:43.916
In ARKit, API really makes

00:14:43.976 --> 00:14:46.076
things easier for you by giving

00:14:46.076 --> 00:14:47.776
you WorldMappingStatus on

00:14:47.776 --> 00:14:48.186
ARFrame.

00:14:49.366 --> 00:14:51.516
WorldMappingStatus is updated in

00:14:51.516 --> 00:14:53.856
every ARFrame and can be

00:14:53.856 --> 00:14:55.776
retrieved by WorldMappingStatus

00:14:55.956 --> 00:14:56.376
property.

00:14:56.896 --> 00:14:58.456
So let's see how this works.

00:14:59.106 --> 00:15:02.866
So when we start world tracking,

00:15:02.866 --> 00:15:04.186
WorldMappingStatus will be not

00:15:04.186 --> 00:15:04.666
available.

00:15:05.056 --> 00:15:06.936
As soon as we start scanning the

00:15:06.936 --> 00:15:08.156
physical space, it will be

00:15:08.266 --> 00:15:08.786
limited.

00:15:10.356 --> 00:15:12.786
The more we move in the physical

00:15:12.786 --> 00:15:14.526
world, world tracking will

00:15:14.526 --> 00:15:19.406
continue to extend the map.

00:15:19.546 --> 00:15:21.196
And if we have scanned enough

00:15:21.336 --> 00:15:23.656
physical world from current

00:15:23.656 --> 00:15:24.206
point of view,

00:15:24.366 --> 00:15:25.586
WorldMappingStatus will be

00:15:25.756 --> 00:15:26.096
mapped.

00:15:34.236 --> 00:15:36.486
So note that if you point away

00:15:36.486 --> 00:15:39.356
from a map physical space,

00:15:39.926 --> 00:15:41.766
WorldMappingStatus may go back

00:15:41.766 --> 00:15:42.526
to limited.

00:15:43.126 --> 00:15:44.756
So it will start to learn more

00:15:44.756 --> 00:15:46.996
about the new environment that

00:15:46.996 --> 00:15:51.076
we are starting to see.

00:15:51.306 --> 00:15:52.196
So how you can use

00:15:52.196 --> 00:15:53.386
WorldMappingStatus in your

00:15:53.386 --> 00:15:54.096
application code.

00:15:54.586 --> 00:15:58.076
Let's say you have an app that

00:15:58.076 --> 00:15:59.806
lets you share your World Map

00:15:59.876 --> 00:16:02.346
with another user, and you have

00:16:02.346 --> 00:16:04.906
a shared map button on your user

00:16:04.906 --> 00:16:05.356
interface.

00:16:05.896 --> 00:16:09.096
It's a good practice to disable

00:16:09.096 --> 00:16:10.046
this button when

00:16:10.046 --> 00:16:11.146
WorldMappingStatus is not

00:16:11.146 --> 00:16:12.576
available or limited.

00:16:13.096 --> 00:16:16.166
And when WorldMappingStatus is

00:16:16.196 --> 00:16:19.386
extending, you may want to show

00:16:19.386 --> 00:16:21.446
an activity indicator on UI.

00:16:22.046 --> 00:16:23.936
So this encourages your end user

00:16:24.426 --> 00:16:25.786
to continue moving in the

00:16:25.786 --> 00:16:27.476
physical world and continue

00:16:27.546 --> 00:16:29.526
scanning it and extending the

00:16:29.526 --> 00:16:31.446
map, because you need that for

00:16:31.446 --> 00:16:32.146
relocalization.

00:16:36.256 --> 00:16:38.416
Once WorldMappingStatus is fully

00:16:38.446 --> 00:16:42.476
mapped, you may enable your

00:16:42.476 --> 00:16:44.346
share map button and hide your

00:16:44.466 --> 00:16:45.366
activity indicator.

00:16:46.096 --> 00:16:47.886
So this will let your user to

00:16:47.886 --> 00:16:49.046
share the map.

00:16:53.716 --> 00:16:55.676
So let's see a demo of saving

00:16:55.676 --> 00:16:57.146
and loading World Map.

00:16:58.516 --> 00:17:06.546
[ Applause ]

00:17:07.046 --> 00:17:11.036
Okay. So can we switch to AR 1.

00:17:13.306 --> 00:17:15.976
Okay. So for this demo, I have

00:17:16.116 --> 00:17:16.955
two apps.

00:17:17.665 --> 00:17:20.586
In one app I will retrieve and

00:17:20.616 --> 00:17:22.576
save World Map to a local file,

00:17:23.366 --> 00:17:26.046
and in my second app, I will

00:17:26.046 --> 00:17:28.406
load the same World Map to

00:17:28.406 --> 00:17:30.096
restore the same augmented

00:17:30.096 --> 00:17:31.146
reality experience.

00:17:31.626 --> 00:17:32.266
So let's start.

00:17:32.266 --> 00:17:36.896
So as you can see,

00:17:36.896 --> 00:17:38.886
WorldMappingStatus on top right

00:17:38.886 --> 00:17:39.376
corner.

00:17:39.876 --> 00:17:41.466
It was not available.

00:17:41.826 --> 00:17:43.476
As soon as I start to move in

00:17:43.476 --> 00:17:46.416
the environment, it is now

00:17:46.416 --> 00:17:47.846
extending my World Map.

00:17:47.846 --> 00:17:50.666
So if I continue to map and move

00:17:50.666 --> 00:17:53.476
in this environment, the

00:17:53.476 --> 00:17:55.336
WorldMappingStatus will go

00:17:55.336 --> 00:17:56.016
mapped.

00:17:57.206 --> 00:17:58.956
So it means that it has seen

00:17:58.956 --> 00:18:01.356
enough features from this point

00:18:01.356 --> 00:18:03.216
of view for relocalization to

00:18:03.216 --> 00:18:03.446
work.

00:18:03.876 --> 00:18:06.406
So it is a good time to retrieve

00:18:06.486 --> 00:18:08.326
and serialize World Map object.

00:18:09.956 --> 00:18:12.546
But let's make this augmented

00:18:12.546 --> 00:18:14.576
reality scene more interesting

00:18:14.636 --> 00:18:16.116
by placing a custom anchor.

00:18:17.176 --> 00:18:19.466
So through hit testing, I have

00:18:19.466 --> 00:18:21.816
created a custom anchor, and I

00:18:21.816 --> 00:18:23.926
am overlaying this object,

00:18:23.926 --> 00:18:27.266
basically it's a old TV.

00:18:27.936 --> 00:18:29.116
I think most of you may have

00:18:29.166 --> 00:18:30.586
seen in the past.

00:18:33.136 --> 00:18:34.806
So of course I can still

00:18:34.806 --> 00:18:38.156
continue mapping the world, and

00:18:38.156 --> 00:18:40.276
let's save the World Map.

00:18:41.426 --> 00:18:44.246
So when I saved my World Map, I

00:18:44.246 --> 00:18:45.916
could also show raw feature

00:18:45.916 --> 00:18:47.136
points that belongs to this

00:18:47.136 --> 00:18:47.586
World Map.

00:18:47.866 --> 00:18:49.416
So those blue dots that you see,

00:18:49.756 --> 00:18:52.126
they are all part of my World

00:18:52.736 --> 00:18:52.866
Map.

00:18:55.236 --> 00:18:58.926
And also as a good practice, I

00:18:58.926 --> 00:19:02.036
saved a screen shot of my point

00:19:02.036 --> 00:19:04.346
of view where I saved World Map.

00:19:07.096 --> 00:19:09.696
So now we have serialized World

00:19:09.696 --> 00:19:11.276
Map to our file.

00:19:12.216 --> 00:19:13.986
We can now restore the same

00:19:13.986 --> 00:19:15.636
augmented reality experience in

00:19:15.696 --> 00:19:16.226
another app.

00:19:17.096 --> 00:19:18.096
So let's try that.

00:19:18.836 --> 00:19:20.126
I will start this app from a

00:19:20.126 --> 00:19:24.516
different position, and you can

00:19:24.516 --> 00:19:26.806
see this is my world origin.

00:19:26.806 --> 00:19:28.526
It is defined on this side of

00:19:28.526 --> 00:19:30.606
the table, and my world tracking

00:19:30.606 --> 00:19:32.506
is now in relocalizing state.

00:19:33.216 --> 00:19:34.526
So this is the same opening

00:19:34.526 --> 00:19:36.366
relocalization behavior that we

00:19:36.426 --> 00:19:40.296
introduced in iOS 11.3.

00:19:40.296 --> 00:19:44.366
So let me point my device to the

00:19:44.446 --> 00:19:46.496
physical place where I created

00:19:46.496 --> 00:19:47.526
World Map.

00:19:48.416 --> 00:19:50.706
So as soon as I point to that

00:19:50.776 --> 00:19:53.126
same space, it restored my world

00:19:53.126 --> 00:19:57.016
origin back to where it was, and

00:19:57.016 --> 00:19:59.306
at the same time it also

00:19:59.306 --> 00:20:00.636
restored my custom anchor.

00:20:00.986 --> 00:20:02.596
So I have the exact same AR

00:20:02.596 --> 00:20:03.026
experience.

00:20:04.016 --> 00:20:08.916
[ Applause ]

00:20:09.416 --> 00:20:09.916
Thank you.

00:20:11.586 --> 00:20:13.176
So now note that I can start

00:20:13.176 --> 00:20:15.276
this app as many times I want,

00:20:15.776 --> 00:20:17.456
and it will show me the same

00:20:17.456 --> 00:20:18.936
experience every time I start.

00:20:19.556 --> 00:20:20.696
So this is persistence.

00:20:21.306 --> 00:20:23.566
And of course, this can be

00:20:23.566 --> 00:20:25.146
shared with another device.

00:20:25.826 --> 00:20:28.756
So back to slides.

00:20:34.196 --> 00:20:36.616
So this was saving and loading

00:20:36.746 --> 00:20:37.046
map.

00:20:38.036 --> 00:20:39.726
It's a powerful new feature in

00:20:39.726 --> 00:20:43.006
ARKit 2 that enables persistence

00:20:43.516 --> 00:20:44.766
and multiuser shared

00:20:44.766 --> 00:20:45.856
experiences.

00:20:49.766 --> 00:20:51.426
In ARKit 2, we have faster

00:20:51.426 --> 00:20:53.326
initialization and plane

00:20:53.326 --> 00:20:53.806
detection.

00:20:54.296 --> 00:20:58.226
World tracking is now more

00:20:58.226 --> 00:21:00.536
robust, and we can detect planes

00:21:00.656 --> 00:21:02.276
in more difficult environments.

00:21:07.396 --> 00:21:09.286
Both horizontal and vertical

00:21:09.286 --> 00:21:11.506
planes have more accurate extent

00:21:11.506 --> 00:21:13.416
and boundaries, so it means that

00:21:13.416 --> 00:21:14.816
you can accurately place your

00:21:14.816 --> 00:21:15.846
objects in the scene.

00:21:19.916 --> 00:21:22.576
In iOS 11.3, we introduced

00:21:22.776 --> 00:21:25.436
continuous autofocus for your

00:21:25.436 --> 00:21:26.866
augmented reality experiences.

00:21:27.346 --> 00:21:31.326
IOS 12 comes with even more

00:21:31.326 --> 00:21:33.816
optimizations specifically for

00:21:33.816 --> 00:21:35.146
augmented reality experiences.

00:21:38.816 --> 00:21:41.466
We are also introducing 4 by 3

00:21:41.466 --> 00:21:44.176
video formats in ARKit.

00:21:44.606 --> 00:21:49.346
Four by three is a -angle video

00:21:49.346 --> 00:21:51.896
format that greatly enhances

00:21:51.896 --> 00:21:54.766
your visualization on iPad

00:21:54.766 --> 00:21:56.496
because iPad also have 4 by 3

00:21:56.626 --> 00:21:57.826
display aspect ratios.

00:21:58.346 --> 00:22:01.676
Note that 4 by 3 video format

00:22:01.676 --> 00:22:03.606
will be the default video format

00:22:03.606 --> 00:22:06.556
in ARKit 2.

00:22:06.816 --> 00:22:08.326
So all of these enhancements,

00:22:08.966 --> 00:22:10.896
they will be applied to all

00:22:10.896 --> 00:22:12.486
existing apps in the App Store

00:22:13.176 --> 00:22:15.406
except 4 by 3 video format.

00:22:15.536 --> 00:22:18.176
For that, you will have to build

00:22:18.176 --> 00:22:20.086
your app with the new STK.

00:22:21.776 --> 00:22:26.506
So coming back to improving

00:22:26.506 --> 00:22:30.636
end-user experience, we are

00:22:30.876 --> 00:22:32.316
introducing environment

00:22:32.316 --> 00:22:32.806
texturing.

00:22:33.876 --> 00:22:36.116
So this greatly enhances your

00:22:36.116 --> 00:22:38.176
rendering for end-user

00:22:38.176 --> 00:22:38.876
experiences.

00:22:40.976 --> 00:22:43.826
So let's say your designer have

00:22:44.016 --> 00:22:45.496
worked really hard to create

00:22:45.496 --> 00:22:47.486
these virtual objects for you,

00:22:47.776 --> 00:22:49.156
for your augmented reality

00:22:49.696 --> 00:22:49.786
scene.

00:22:50.616 --> 00:22:53.466
This looks really great, but you

00:22:53.466 --> 00:22:56.226
need to do more for your

00:22:56.226 --> 00:22:57.316
augmented reality scene.

00:22:57.316 --> 00:23:03.046
You need to have position and

00:23:03.046 --> 00:23:05.026
orientation correct in your AR

00:23:05.436 --> 00:23:08.376
scene so that object really

00:23:08.376 --> 00:23:10.716
looks like it is placed in the

00:23:10.716 --> 00:23:11.746
real world.

00:23:13.366 --> 00:23:15.256
It is also important to get the

00:23:15.256 --> 00:23:17.106
scale right so your object is

00:23:17.106 --> 00:23:18.666
not too big or not too small.

00:23:19.176 --> 00:23:21.236
So ARKit helps you by giving you

00:23:21.236 --> 00:23:22.876
the correct transform in world

00:23:23.106 --> 00:23:24.606
tracking.

00:23:28.456 --> 00:23:30.386
For realistic rendering, it is

00:23:30.386 --> 00:23:31.886
important to also consider

00:23:32.346 --> 00:23:33.496
lighting in the environment.

00:23:33.916 --> 00:23:38.836
ARKit gives you ambient light

00:23:38.836 --> 00:23:40.296
estimator that you can use in

00:23:40.296 --> 00:23:43.576
your rendering to correct the

00:23:43.576 --> 00:23:45.066
brightness of your objects.

00:23:45.436 --> 00:23:47.136
So your objects don't look too

00:23:47.136 --> 00:23:48.776
bright or too dark.

00:23:49.386 --> 00:23:51.746
They just blend into the

00:23:54.676 --> 00:23:55.056
environment.

00:23:55.056 --> 00:23:56.966
If you are placing your objects

00:23:56.966 --> 00:23:58.716
on physical surfaces such as

00:23:58.716 --> 00:24:01.076
horizontal planes, it is also

00:24:01.076 --> 00:24:03.416
important to add a shadow for

00:24:03.416 --> 00:24:03.866
the object.

00:24:04.506 --> 00:24:06.916
So this greatly improves human

00:24:06.916 --> 00:24:07.776
visual perception.

00:24:08.036 --> 00:24:09.106
They can really perceive that

00:24:09.106 --> 00:24:13.256
objection is on the surface.

00:24:13.426 --> 00:24:16.876
And last, in case of reflective

00:24:16.876 --> 00:24:20.156
objects, humans wants to see

00:24:20.916 --> 00:24:22.576
reflection of the environment

00:24:22.716 --> 00:24:24.376
from the surface of the virtual

00:24:24.376 --> 00:24:24.696
objects.

00:24:25.886 --> 00:24:28.166
So this is what environment

00:24:28.166 --> 00:24:28.946
texturing enables.

00:24:29.006 --> 00:24:32.496
So let's see how this object

00:24:32.496 --> 00:24:34.866
looks like in an augmented

00:24:34.866 --> 00:24:37.976
reality scene.

00:24:38.196 --> 00:24:39.426
So I created this scene

00:24:39.426 --> 00:24:41.076
yesterday evening when I was

00:24:41.156 --> 00:24:42.696
preparing for this presentation.

00:24:43.246 --> 00:24:47.186
So while eating those fruits, I

00:24:47.186 --> 00:24:48.346
also wanted to place this

00:24:48.346 --> 00:24:49.606
virtual object.

00:24:49.606 --> 00:24:54.886
And you can see, it is correct

00:24:54.996 --> 00:24:57.486
to scale, and you can see more

00:24:57.486 --> 00:24:59.356
importantly you can see a

00:24:59.356 --> 00:25:00.956
reflection of the environment in

00:25:01.476 --> 00:25:02.336
the object.

00:25:02.496 --> 00:25:04.326
On your right side of this

00:25:04.326 --> 00:25:06.766
object, you can see this yellow

00:25:06.766 --> 00:25:09.376
and orange reflection of those

00:25:09.376 --> 00:25:11.386
fruits on the right, and on the

00:25:11.386 --> 00:25:13.646
left, you can notice the green

00:25:13.646 --> 00:25:14.596
texture from the leaves.

00:25:15.906 --> 00:25:17.196
And in the middle, you can also

00:25:17.196 --> 00:25:19.336
see reflection of the surface of

00:25:20.136 --> 00:25:21.386
the bench.

00:25:21.616 --> 00:25:23.286
So this is enabled by

00:25:23.286 --> 00:25:25.366
environment texturing in ARKit

00:25:25.906 --> 00:25:25.976
2.

00:25:29.336 --> 00:25:29.606
Thank you.

00:25:30.476 --> 00:25:33.636
[ Applause ]

00:25:34.136 --> 00:25:35.826
So environment texturing gathers

00:25:35.906 --> 00:25:37.456
scene texture information.

00:25:40.616 --> 00:25:43.176
Usually it is represented as a

00:25:43.176 --> 00:25:44.666
cube map, but there are other

00:25:44.666 --> 00:25:48.956
representations as well.

00:25:49.036 --> 00:25:51.426
Environment texture or this cube

00:25:51.426 --> 00:25:53.746
map can be used as a reflection

00:25:53.746 --> 00:25:56.146
probe in your rendering engines.

00:25:58.636 --> 00:26:01.696
This reflection probe can apply

00:26:01.696 --> 00:26:03.646
this as texture information onto

00:26:03.646 --> 00:26:05.426
virtual objects, such as the one

00:26:05.426 --> 00:26:06.476
we saw in the last slide.

00:26:07.286 --> 00:26:10.146
So it greatly improves

00:26:11.326 --> 00:26:13.156
visualization of reflective

00:26:13.156 --> 00:26:13.626
objects.

00:26:14.936 --> 00:26:16.996
So let's see how this works in

00:26:18.136 --> 00:26:20.026
this short video clip.

00:26:22.076 --> 00:26:24.796
So ARKit, while running world

00:26:24.796 --> 00:26:25.816
tracking and scene

00:26:25.816 --> 00:26:27.596
understanding, continues to

00:26:27.596 --> 00:26:28.506
learn more about the

00:26:28.506 --> 00:26:29.036
environment.

00:26:30.226 --> 00:26:32.706
Using computer vision, it can

00:26:33.066 --> 00:26:35.676
extract textured information and

00:26:35.676 --> 00:26:37.646
start to fill this cube map.

00:26:38.136 --> 00:26:41.676
And this cube map is accurately

00:26:41.676 --> 00:26:42.636
placed in the scene.

00:26:43.166 --> 00:26:46.456
Note that this cube map is

00:26:46.456 --> 00:26:50.456
partially filled, and to set up

00:26:50.506 --> 00:26:52.186
reflection probes, we need to

00:26:52.186 --> 00:26:53.926
have a fully completed cube map.

00:26:54.486 --> 00:26:58.756
To have a fully completed cube

00:26:58.756 --> 00:27:01.396
map, you will need to scan your

00:27:01.466 --> 00:27:03.966
full physical space, something

00:27:03.966 --> 00:27:06.286
like a 360-degree scan you do

00:27:06.286 --> 00:27:07.376
with your panoramas.

00:27:08.586 --> 00:27:10.856
But this is not practical for

00:27:10.956 --> 00:27:11.516
end-users.

00:27:13.296 --> 00:27:15.526
So ARKit makes it very easy for

00:27:15.526 --> 00:27:18.626
you by automatically completing

00:27:18.626 --> 00:27:20.756
this cube map using advanced

00:27:20.756 --> 00:27:21.946
machine learning algorithms.

00:27:24.016 --> 00:27:29.460
[ Applause ]

00:27:31.536 --> 00:27:33.446
Note also that all of this

00:27:33.446 --> 00:27:35.296
processing happens locally on

00:27:35.296 --> 00:27:37.416
your device in real-time.

00:27:39.556 --> 00:27:41.666
So once we have a cube map, we

00:27:41.666 --> 00:27:44.116
can set up reflection probe and

00:27:44.116 --> 00:27:46.066
as soon as we place virtual

00:27:46.066 --> 00:27:48.186
objects in the scene, they start

00:27:48.186 --> 00:27:49.506
to reflect the real environment.

00:27:50.006 --> 00:27:52.726
So this was a quick overview of

00:27:52.726 --> 00:27:54.416
how this environment texturing

00:27:54.416 --> 00:27:55.116
process works.

00:27:55.116 --> 00:28:00.286
Let's see how ARKit API makes it

00:28:00.286 --> 00:28:03.446
very easy for you to enable this

00:28:07.516 --> 00:28:07.686
feature.

00:28:07.836 --> 00:28:09.966
So all you have to do in your

00:28:09.966 --> 00:28:12.516
world tracking configuration to

00:28:12.516 --> 00:28:14.006
set environment texturing

00:28:14.006 --> 00:28:17.776
property to automatic and run

00:28:17.776 --> 00:28:18.206
the session.

00:28:19.196 --> 00:28:21.206
So this is as simple as this.

00:28:22.516 --> 00:28:28.576
[ Applause ]

00:28:29.076 --> 00:28:31.186
AR session will automatically

00:28:31.186 --> 00:28:32.946
run this environment texturing

00:28:32.946 --> 00:28:34.976
process in the background and

00:28:34.976 --> 00:28:36.326
will give you environment

00:28:36.546 --> 00:28:39.316
texture as an environment probe

00:28:39.316 --> 00:28:39.616
anchor.

00:28:40.996 --> 00:28:43.416
AREnvironmentProbeAnchor is an

00:28:43.416 --> 00:28:45.226
extension of AR anchor, so it

00:28:45.226 --> 00:28:46.916
means it has a six degrees of

00:28:46.916 --> 00:28:48.496
freedom position and orientation

00:28:48.496 --> 00:28:49.066
transform.

00:28:50.716 --> 00:28:53.346
Moreover, it has a cube map in

00:28:53.346 --> 00:28:58.596
the form of metal texture.

00:28:58.596 --> 00:29:00.336
ARKit also gives you physical

00:29:00.336 --> 00:29:02.356
extent of the cube map.

00:29:02.846 --> 00:29:04.546
So this is area of the influence

00:29:04.836 --> 00:29:08.176
of the reflection probe, and it

00:29:08.176 --> 00:29:10.786
can be used by rendering agents

00:29:11.246 --> 00:29:12.846
to correct for parallels.

00:29:12.846 --> 00:29:14.176
So such as in case your object

00:29:14.176 --> 00:29:16.186
is moving in the scene, it will

00:29:16.186 --> 00:29:18.636
automatically adapt to new

00:29:18.636 --> 00:29:21.226
position and new texture will be

00:29:21.226 --> 00:29:22.226
reflected in the environment.

00:29:22.686 --> 00:29:26.666
Note that this follows same

00:29:26.666 --> 00:29:28.476
lifecycle as every other anchor

00:29:29.036 --> 00:29:31.166
such as AR plane anchor or AR

00:29:31.166 --> 00:29:31.676
image anchor.

00:29:36.676 --> 00:29:38.396
Furthermore, it is fully

00:29:38.396 --> 00:29:40.566
integrated into ARSCNView.

00:29:41.016 --> 00:29:42.396
So in case you are using

00:29:42.646 --> 00:29:44.216
SceneKit as your rendering

00:29:44.216 --> 00:29:47.136
technology, you just need to

00:29:47.136 --> 00:29:49.586
enable this feature in world

00:29:49.586 --> 00:29:50.486
tracking configuration.

00:29:51.056 --> 00:29:52.706
The rest is done automatically

00:29:52.796 --> 00:29:54.076
by ARSCNView.

00:29:58.996 --> 00:30:02.146
Note that for advanced use

00:30:02.146 --> 00:30:04.496
cases, you may want to place

00:30:04.496 --> 00:30:05.666
environment probe anchors

00:30:05.876 --> 00:30:11.406
manually in the scene.

00:30:11.726 --> 00:30:13.246
So for this, you will need to

00:30:13.246 --> 00:30:14.796
set environment texturing mode

00:30:14.856 --> 00:30:18.626
to manual, and then you can

00:30:18.626 --> 00:30:20.366
create environment probe anchors

00:30:21.086 --> 00:30:23.066
at your desired position and

00:30:23.066 --> 00:30:24.836
orientation and add them to AR

00:30:24.836 --> 00:30:25.476
session object.

00:30:25.886 --> 00:30:30.306
Note that this only enables you

00:30:30.306 --> 00:30:32.936
to place the probe anchors in

00:30:33.516 --> 00:30:34.006
the scene.

00:30:34.006 --> 00:30:35.666
AR session will automatically

00:30:35.666 --> 00:30:37.606
update its texture as soon as it

00:30:37.656 --> 00:30:39.596
gets more information about the

00:30:39.596 --> 00:30:39.996
environment.

00:30:42.016 --> 00:30:45.906
So you may use this mode in case

00:30:45.906 --> 00:30:48.306
your augmented reality scene has

00:30:48.306 --> 00:30:49.136
a single object.

00:30:49.296 --> 00:30:51.176
You don't want to overload

00:30:51.576 --> 00:30:53.346
system with too many environment

00:30:53.916 --> 00:30:57.046
probe anchors.

00:30:57.246 --> 00:30:59.306
So let's see a quick demo of

00:30:59.306 --> 00:31:00.926
environment texturing and see

00:31:01.426 --> 00:31:03.506
how we can realistically render

00:31:03.866 --> 00:31:05.806
augmented reality scene.

00:31:06.516 --> 00:31:10.500
[ Applause ]

00:31:16.316 --> 00:31:18.646
So we can switch to AR 1.

00:31:23.626 --> 00:31:25.916
Okay. So for this demo, I am

00:31:26.116 --> 00:31:27.856
running world tracking

00:31:27.856 --> 00:31:29.986
configuration without

00:31:29.986 --> 00:31:31.516
environment texturing feature

00:31:31.516 --> 00:31:31.896
enabled.

00:31:33.176 --> 00:31:37.656
So as you can see on the bottom

00:31:37.706 --> 00:31:39.626
switch controller, it's just

00:31:39.626 --> 00:31:41.026
using ambient light estimate.

00:31:41.456 --> 00:31:44.146
And let's place the same object

00:31:44.146 --> 00:31:45.856
that we have seen before.

00:31:47.116 --> 00:31:52.376
And you can see it is, it looks

00:31:52.376 --> 00:31:52.746
okay.

00:31:52.746 --> 00:31:53.766
I mean you can see this on the

00:31:53.766 --> 00:31:54.056
table.

00:31:54.056 --> 00:31:55.656
You can see the shadow of it,

00:31:56.096 --> 00:31:57.886
and it looks like a really good

00:31:57.886 --> 00:31:58.356
AR scene.

00:31:59.686 --> 00:32:01.536
But what we are missing is that

00:32:01.536 --> 00:32:03.776
it does not reflect wooden

00:32:03.776 --> 00:32:06.786
surface of the table.

00:32:06.916 --> 00:32:08.286
So moreover, if I place

00:32:08.286 --> 00:32:11.526
something in the scene such as

00:32:11.526 --> 00:32:17.516
real fruit, we don't see a

00:32:17.516 --> 00:32:20.516
reflection of it in the virtual

00:32:20.936 --> 00:32:21.126
object.

00:32:21.656 --> 00:32:23.616
So let's enable environment

00:32:23.616 --> 00:32:25.896
texturing and see how it can

00:32:26.206 --> 00:32:29.156
realistically represent this

00:32:29.216 --> 00:32:29.576
texture.

00:32:30.636 --> 00:32:32.326
So as you can see, as soon as I

00:32:32.326 --> 00:32:33.766
enable environment texturing,

00:32:34.526 --> 00:32:36.366
the object started to reflect

00:32:36.366 --> 00:32:38.616
the wooden surface of the table

00:32:39.016 --> 00:32:41.686
as well as the texture from this

00:32:41.746 --> 00:32:42.176
banana.

00:32:43.516 --> 00:32:50.546
[ Applause ]

00:32:51.046 --> 00:32:51.266
Thank you.

00:32:52.626 --> 00:32:55.326
So this greatly enhances you

00:32:55.326 --> 00:32:56.706
augmented reality scene.

00:32:57.346 --> 00:32:59.586
So it looks as real as possible,

00:33:00.776 --> 00:33:04.726
as if it is really on the table.

00:33:05.056 --> 00:33:06.796
Okay. Back to slides.

00:33:12.806 --> 00:33:14.086
So this was environment

00:33:14.206 --> 00:33:14.686
texturing.

00:33:14.866 --> 00:33:17.116
It's a powerful new feature in

00:33:17.116 --> 00:33:20.616
ARKit 2 that lets you create

00:33:20.616 --> 00:33:22.436
your augmented reality scene as

00:33:22.436 --> 00:33:26.256
realistic as possible.

00:33:26.256 --> 00:33:28.116
Now, to continue with the rest

00:33:28.116 --> 00:33:30.296
of the great new features, I

00:33:30.296 --> 00:33:32.376
will invite Reinhard on stage.

00:33:34.476 --> 00:33:38.660
[ Applause ]

00:33:42.226 --> 00:33:42.866
>> It's working?

00:33:43.206 --> 00:33:43.856
Oh, okay, great.

00:33:46.066 --> 00:33:46.496
Good morning.

00:33:47.376 --> 00:33:48.936
My name is Reinhard, and I'm an

00:33:48.936 --> 00:33:50.336
engineer on the ARKit team.

00:33:50.746 --> 00:33:52.446
So next let's talk about image

00:33:52.446 --> 00:33:52.816
tracking.

00:33:52.816 --> 00:33:56.566
In iOS 11.3, we introduced image

00:33:56.566 --> 00:33:58.116
detection as part of world

00:33:58.116 --> 00:33:58.536
tracking.

00:33:59.646 --> 00:34:01.326
Image detection searches for

00:34:01.326 --> 00:34:03.086
known 2D images in the scene.

00:34:03.776 --> 00:34:05.836
The term detection here implies

00:34:05.996 --> 00:34:07.996
that these images are static and

00:34:07.996 --> 00:34:09.126
are therefore not supposed to

00:34:09.126 --> 00:34:09.396
move.

00:34:10.326 --> 00:34:11.626
Great examples for such images

00:34:11.626 --> 00:34:13.576
could be movie posters or

00:34:13.576 --> 00:34:14.746
paintings in a museum.

00:34:16.416 --> 00:34:18.536
ARKit will estimate the position

00:34:18.636 --> 00:34:20.156
and orientation of such an image

00:34:20.466 --> 00:34:22.216
in six degrees of freedom once

00:34:22.216 --> 00:34:23.416
an image has been detected.

00:34:24.536 --> 00:34:26.446
This pose can be used to trigger

00:34:26.446 --> 00:34:28.005
content in your rendered scene.

00:34:28.525 --> 00:34:31.576
As I mentioned earlier, all this

00:34:31.626 --> 00:34:33.065
is fully integrated world

00:34:33.065 --> 00:34:33.505
tracking.

00:34:34.065 --> 00:34:35.065
So all you need to do is set

00:34:35.065 --> 00:34:37.626
once in your property to set it

00:34:38.666 --> 00:34:38.746
up.

00:34:39.025 --> 00:34:40.255
In order to load images to be

00:34:40.255 --> 00:34:42.386
used for image detection, you

00:34:42.386 --> 00:34:44.275
made load them from file or use

00:34:44.346 --> 00:34:46.196
Xcode's asset catalog, which

00:34:46.196 --> 00:34:47.946
also gives you the detection

00:34:47.946 --> 00:34:49.056
quality for an image.

00:34:50.406 --> 00:34:51.496
So image detection is already

00:34:51.496 --> 00:34:54.275
great, but now in iOS 12, we can

00:34:54.275 --> 00:34:54.735
do better.

00:34:54.926 --> 00:34:56.636
So let's talk about image

00:34:56.636 --> 00:34:56.976
tracking.

00:34:57.846 --> 00:34:59.636
Image tracking is an extension

00:34:59.636 --> 00:35:01.546
to image detection with a big

00:35:01.546 --> 00:35:03.776
advantage that images no longer

00:35:03.776 --> 00:35:07.406
need to be static and may move.

00:35:07.616 --> 00:35:09.036
ARKit will now estimate the

00:35:09.036 --> 00:35:10.806
position and orientation for

00:35:10.806 --> 00:35:12.516
every frame at 60 frames per

00:35:12.516 --> 00:35:12.886
second.

00:35:13.706 --> 00:35:15.206
This allows you to accurately

00:35:15.466 --> 00:35:18.316
augment 2D images, say

00:35:18.906 --> 00:35:20.626
magazines, board games, or

00:35:20.626 --> 00:35:21.856
pretty much anything that

00:35:21.856 --> 00:35:23.396
features a real image.

00:35:24.986 --> 00:35:27.136
And ARKit can also track

00:35:27.516 --> 00:35:29.066
multiple images simultaneously.

00:35:30.886 --> 00:35:32.356
By default it only selects 1,

00:35:32.646 --> 00:35:34.596
but in cases, for example, the

00:35:34.596 --> 00:35:36.166
cover of a magazine, you may

00:35:36.166 --> 00:35:39.156
want to keep this set to 1, or

00:35:39.156 --> 00:35:41.046
in case of a double-page

00:35:41.046 --> 00:35:42.866
magazine inside a magazine, you

00:35:42.866 --> 00:35:43.716
want to set this to 2.

00:35:45.416 --> 00:35:49.496
And in ARKit 2 on iOS 12, we

00:35:49.736 --> 00:35:51.086
have a brand-new configuration

00:35:51.086 --> 00:35:52.556
called the AR Image Tracking

00:35:52.556 --> 00:35:54.626
Configuration that lets you do

00:35:55.076 --> 00:35:56.546
stand-alone image tracking.

00:35:57.356 --> 00:35:58.596
So let's see how to set it up.

00:36:00.016 --> 00:36:01.566
We start by loading a set of

00:36:01.656 --> 00:36:02.736
reference images, either from

00:36:02.736 --> 00:36:04.456
file or from the asset catalog.

00:36:05.676 --> 00:36:07.246
Once I'm done loading such a set

00:36:07.246 --> 00:36:09.276
of reference images, I use this

00:36:09.966 --> 00:36:11.596
to set up my session that can be

00:36:11.676 --> 00:36:13.726
of type world tracking by

00:36:13.806 --> 00:36:15.226
specifying its detection images

00:36:15.286 --> 00:36:17.026
property or of type

00:36:17.026 --> 00:36:19.386
ARImageTrackingConfiguration by

00:36:19.386 --> 00:36:20.786
specifying the tracking images

00:36:20.826 --> 00:36:20.986
one.

00:36:22.406 --> 00:36:24.036
Once I'm done setting up my

00:36:24.036 --> 00:36:26.316
configuration, I use this to run

00:36:26.316 --> 00:36:26.846
my session.

00:36:28.296 --> 00:36:30.276
And just as usual, once the

00:36:30.326 --> 00:36:31.966
session is running, I'll get an

00:36:31.966 --> 00:36:33.496
ARFrame at every update.

00:36:34.476 --> 00:36:35.776
And such and ARFrame will

00:36:35.776 --> 00:36:37.486
continue an object of type

00:36:37.676 --> 00:36:40.116
ARImageAnchor, once an image has

00:36:40.156 --> 00:36:40.676
been detected.

00:36:41.036 --> 00:36:44.086
Such an ARImageAnchor is now a

00:36:44.086 --> 00:36:45.066
trackable object.

00:36:45.406 --> 00:36:46.836
I can see this by conforming to

00:36:46.836 --> 00:36:48.086
the AR trackable protocol.

00:36:48.786 --> 00:36:51.346
This means it comes as a boolean

00:36:51.546 --> 00:36:55.036
isTracked, which informs you about

00:36:55.036 --> 00:36:56.466
the tracking state of the image.

00:36:56.976 --> 00:36:58.566
It's true if it's tracked and

00:36:58.566 --> 00:36:59.246
false otherwise.

00:37:00.516 --> 00:37:01.956
It also informs about which

00:37:01.956 --> 00:37:03.566
image has been detected and

00:37:03.566 --> 00:37:06.176
where it is by giving me it's

00:37:06.406 --> 00:37:08.536
position and orientation as a 4

00:37:08.536 --> 00:37:09.956
by 4 matrix.

00:37:11.496 --> 00:37:13.326
So in order to get such image

00:37:13.326 --> 00:37:14.896
anchors, it all starts by

00:37:14.896 --> 00:37:15.646
loading images.

00:37:15.726 --> 00:37:16.676
So that's good.

00:37:16.906 --> 00:37:18.176
Let's have a look at what good

00:37:18.216 --> 00:37:19.096
images could be.

00:37:19.846 --> 00:37:21.426
This image here could be found

00:37:21.486 --> 00:37:23.476
in a book for children, and in

00:37:23.476 --> 00:37:25.686
fact, it works great for image

00:37:25.686 --> 00:37:26.066
tracking.

00:37:26.436 --> 00:37:27.976
It has a lot of distinct visual

00:37:27.976 --> 00:37:28.496
features.

00:37:28.806 --> 00:37:30.346
It's we'll textured and shows

00:37:30.346 --> 00:37:31.096
really good contrast.

00:37:32.566 --> 00:37:34.236
On the other hand, an image like

00:37:34.236 --> 00:37:36.076
this, which could also be found

00:37:36.076 --> 00:37:39.446
in a textbook for kids, is not

00:37:39.446 --> 00:37:39.986
recommended.

00:37:40.756 --> 00:37:41.646
It has a lot of repetitive

00:37:41.646 --> 00:37:43.326
structures, uniform color

00:37:43.326 --> 00:37:44.876
regions, and a pretty narrow

00:37:44.876 --> 00:37:46.666
histogram once converted to gray

00:37:46.666 --> 00:37:46.946
scale.

00:37:48.436 --> 00:37:49.586
But you don't have to identify

00:37:49.586 --> 00:37:50.966
these statistics yourself as

00:37:51.066 --> 00:37:52.066
Xcode is here to help.

00:37:52.926 --> 00:37:54.716
So if I import these two images

00:37:54.716 --> 00:37:57.286
to Xcode, I see the sea life one

00:37:57.586 --> 00:37:59.216
without any warning, which means

00:37:59.216 --> 00:38:01.296
it's recommended, and the one

00:38:01.296 --> 00:38:02.346
about the three kids reading

00:38:02.346 --> 00:38:03.676
showing a warning icon, meaning

00:38:03.886 --> 00:38:04.776
it's not recommended.

00:38:06.096 --> 00:38:07.756
If I click this icon, I get a

00:38:07.756 --> 00:38:09.856
precise description why this

00:38:09.886 --> 00:38:13.046
image is not recommended to use

00:38:13.046 --> 00:38:13.676
image tracking.

00:38:14.186 --> 00:38:15.556
I get information about the

00:38:15.556 --> 00:38:17.236
histogram, uniform color

00:38:17.236 --> 00:38:19.206
regions, as well as the

00:38:19.676 --> 00:38:19.946
histogram.

00:38:21.136 --> 00:38:23.866
So once I'm done loading images,

00:38:23.866 --> 00:38:25.326
I'm left with two choices of

00:38:25.376 --> 00:38:26.226
configurations.

00:38:26.766 --> 00:38:27.646
First one is

00:38:27.646 --> 00:38:29.416
ARWorldTrackingConfiguration.

00:38:29.596 --> 00:38:31.826
So let's talk about that.

00:38:32.816 --> 00:38:34.656
When we use image tracking with

00:38:34.656 --> 00:38:36.726
world tracking, image anchors

00:38:36.726 --> 00:38:38.056
are represented in a world

00:38:38.056 --> 00:38:38.816
coordinates system.

00:38:39.346 --> 00:38:41.426
This means that image anchors

00:38:41.476 --> 00:38:43.016
optionally plane anchors.

00:38:44.186 --> 00:38:45.946
The camera and the world origin

00:38:46.116 --> 00:38:48.516
itself all appear in the same

00:38:48.516 --> 00:38:49.276
coordinate system.

00:38:49.826 --> 00:38:51.256
This makes their interaction

00:38:51.346 --> 00:38:54.286
very easy and intuitive, and

00:38:54.286 --> 00:38:57.676
what's new in iOS 12 now images

00:38:57.676 --> 00:38:58.666
that could previously only be

00:38:58.666 --> 00:39:00.286
detected can now be tracked.

00:39:00.726 --> 00:39:03.626
And we have a new configuration,

00:39:03.626 --> 00:39:03.746
the

00:39:03.746 --> 00:39:05.486
ARImageTrackingConfiguration,

00:39:05.846 --> 00:39:07.456
which performs stand-alone image

00:39:07.456 --> 00:39:07.836
tracking.

00:39:09.086 --> 00:39:10.396
This means it's independent from

00:39:10.396 --> 00:39:12.636
world tracking and does not rely

00:39:12.706 --> 00:39:14.906
on the motion sensor to perform

00:39:14.906 --> 00:39:15.406
the tracking.

00:39:16.206 --> 00:39:18.386
This means this configuration is

00:39:18.386 --> 00:39:20.966
not to initialize before it

00:39:20.966 --> 00:39:23.306
starts to identify images and

00:39:23.306 --> 00:39:25.046
could also succeed in scenarios

00:39:25.046 --> 00:39:26.696
in which world tracking fails,

00:39:26.856 --> 00:39:28.776
such as moving platform like an

00:39:28.816 --> 00:39:30.076
elevator or a train.

00:39:31.336 --> 00:39:33.766
I think in this case ARKit would

00:39:33.816 --> 00:39:35.276
estimate the position and

00:39:35.276 --> 00:39:36.946
orientation for every frame at

00:39:37.036 --> 00:39:39.286
60 frames per second.

00:39:39.406 --> 00:39:40.696
And implementing this can be

00:39:40.696 --> 00:39:42.546
done in four simple lines of

00:39:42.586 --> 00:39:43.126
code.

00:39:44.096 --> 00:39:46.026
So all you need to do, I create

00:39:46.026 --> 00:39:46.916
a configuration type

00:39:47.096 --> 00:39:49.566
ARImageTrackingConfiguration and

00:39:49.566 --> 00:39:52.006
specify a set of images I'd like

00:39:52.006 --> 00:39:52.396
to track.

00:39:53.146 --> 00:39:54.836
In this case, I specified a

00:39:54.836 --> 00:39:56.806
photo of a cat, a dog, and a

00:39:56.806 --> 00:39:57.076
bird.

00:39:59.556 --> 00:40:00.816
I tell the configuration how

00:40:00.816 --> 00:40:02.426
many images I'd like to track.

00:40:03.016 --> 00:40:04.236
In this case, I specified this

00:40:04.276 --> 00:40:04.816
to be 2.

00:40:05.576 --> 00:40:08.126
In my use case, I imagined only

00:40:08.126 --> 00:40:10.676
2 images will interact but not 3

00:40:10.676 --> 00:40:11.496
at the same time.

00:40:12.526 --> 00:40:14.116
Note that if I'm tracking 2

00:40:14.226 --> 00:40:16.076
images and a third comes into

00:40:16.246 --> 00:40:19.076
its view, it won't be tracked,

00:40:19.076 --> 00:40:20.856
but it will still get a

00:40:20.856 --> 00:40:21.666
detection update.

00:40:23.096 --> 00:40:24.266
And then I use this

00:40:24.266 --> 00:40:26.016
configuration to run my session.

00:40:26.596 --> 00:40:28.926
And as I mentioned earlier, you

00:40:29.146 --> 00:40:30.906
can also do this using world

00:40:30.906 --> 00:40:32.796
tracking by simply switching out

00:40:33.136 --> 00:40:33.786
these two lines.

00:40:34.596 --> 00:40:36.216
The only difference between

00:40:36.216 --> 00:40:38.266
image detection and tracking is

00:40:38.266 --> 00:40:39.466
the maximum number of tracking

00:40:39.466 --> 00:40:39.946
images.

00:40:40.786 --> 00:40:44.616
So if you have an app that uses

00:40:44.616 --> 00:40:46.066
image detection, you could

00:40:46.066 --> 00:40:47.856
simply add this, recompile, and

00:40:47.856 --> 00:40:49.686
your app may use tracking.

00:40:51.026 --> 00:40:52.866
So in order to show you how easy

00:40:52.866 --> 00:40:54.376
this really is, let's do a demo

00:40:54.486 --> 00:40:55.046
in Xcode.

00:40:56.676 --> 00:41:02.236
[ Applause ]

00:41:02.736 --> 00:41:04.056
Can we go to AR 2?

00:41:04.266 --> 00:41:07.346
Yes. So for this demo I'd like

00:41:07.416 --> 00:41:10.656
to build a AR photo frame, and

00:41:10.656 --> 00:41:12.176
for this, I brought a photo of

00:41:12.176 --> 00:41:13.036
my cat from home.

00:41:13.846 --> 00:41:15.346
So let's build this using Xcode.

00:41:16.256 --> 00:41:19.996
So I started by creating a iOS

00:41:20.936 --> 00:41:22.666
app template using Xcode.

00:41:23.056 --> 00:41:24.796
As you can see by now it's

00:41:24.796 --> 00:41:26.396
pretty empty.

00:41:26.776 --> 00:41:28.496
Next, I need to specify which

00:41:28.526 --> 00:41:29.736
image I'd like to attach.

00:41:30.596 --> 00:41:32.266
For this I imported the photo of

00:41:32.266 --> 00:41:33.456
my cat, Daisy.

00:41:33.456 --> 00:41:36.436
Let's open her up here.

00:41:37.056 --> 00:41:37.606
That's my cat.

00:41:37.606 --> 00:41:41.176
I need to specify a name.

00:41:41.256 --> 00:41:43.576
I give it the name Daisy, which

00:41:43.576 --> 00:41:45.016
is the name of my cat, and I

00:41:45.016 --> 00:41:47.816
specify here the physical width

00:41:48.176 --> 00:41:49.576
of the image found in the real

00:41:49.576 --> 00:41:50.756
world, which is my photo frame.

00:41:52.296 --> 00:41:55.156
I also loaded a movie of my cat.

00:41:55.956 --> 00:41:56.986
So let's bring this all

00:41:56.986 --> 00:41:57.326
together.

00:41:58.456 --> 00:42:00.696
First, I will create a

00:42:00.696 --> 00:42:03.176
configuration, which will be a

00:42:03.176 --> 00:42:04.166
configuration of type

00:42:04.756 --> 00:42:06.406
ARImageTrackingConfiguration.

00:42:07.426 --> 00:42:08.976
I load a set of tracking images

00:42:08.976 --> 00:42:11.426
from the asset catalog by using

00:42:11.556 --> 00:42:13.176
the group name photos.

00:42:13.836 --> 00:42:15.086
This will contain only one

00:42:15.086 --> 00:42:17.146
image, which is the photo of my

00:42:17.146 --> 00:42:17.736
cat, Daisy.

00:42:18.936 --> 00:42:22.066
Next, I set up the configuration

00:42:22.066 --> 00:42:23.616
image tracking by specifying the

00:42:23.616 --> 00:42:25.486
tracking images property here,

00:42:26.236 --> 00:42:28.106
and I specify the max number of

00:42:28.156 --> 00:42:30.066
tracked images that we want.

00:42:30.446 --> 00:42:31.556
At this point, the app will

00:42:31.556 --> 00:42:34.126
already start an AR session and

00:42:34.126 --> 00:42:35.356
provide you with image anchors

00:42:35.466 --> 00:42:36.596
once an image has been detected.

00:42:37.096 --> 00:42:38.106
But let's add some content.

00:42:38.936 --> 00:42:40.716
I will load the video

00:42:41.916 --> 00:42:45.586
by trading a AV player from the

00:42:46.106 --> 00:42:47.046
video by loading it from the

00:42:47.046 --> 00:42:47.656
resource panel.

00:42:49.136 --> 00:42:51.016
Now let's add it on top of the

00:42:51.016 --> 00:42:52.016
real image.

00:42:52.586 --> 00:42:56.296
So for this, I'm checking

00:42:56.296 --> 00:42:57.636
whether the anchor is of type

00:42:57.686 --> 00:43:00.616
image anchor, and I create an

00:43:00.716 --> 00:43:02.296
SCN plane having the same

00:43:02.366 --> 00:43:04.106
physical dimension as the image

00:43:04.166 --> 00:43:04.876
found in the scene.

00:43:06.256 --> 00:43:08.136
I assign the video player as the

00:43:08.176 --> 00:43:10.796
texture to my plane, and I start

00:43:10.796 --> 00:43:11.766
playing my video player.

00:43:12.356 --> 00:43:15.446
I create an SCN note from

00:43:15.446 --> 00:43:17.356
geometry, and I counter rotate

00:43:17.666 --> 00:43:20.646
to match the anchor's coordinate

00:43:20.866 --> 00:43:21.116
system.

00:43:21.906 --> 00:43:22.896
So that's it.

00:43:22.896 --> 00:43:24.026
This will run.

00:43:24.446 --> 00:43:26.086
Let's see it live.

00:43:27.716 --> 00:43:32.086
So once I bring the frame of my

00:43:32.086 --> 00:43:33.936
cat into the camera's view, the

00:43:34.146 --> 00:43:36.036
video starts playing, and I can

00:43:36.096 --> 00:43:37.126
see my cat interact.

00:43:37.676 --> 00:43:43.946
[ Applause ]

00:43:44.446 --> 00:43:46.516
Since ARKit estimates position

00:43:46.516 --> 00:43:48.186
in real-time, I can move my

00:43:48.186 --> 00:43:50.156
device freely, or I can move the

00:43:50.156 --> 00:43:50.616
object.

00:43:50.616 --> 00:43:52.546
So I can really see that there's

00:43:52.546 --> 00:43:54.056
an update at every frame.

00:43:54.056 --> 00:43:56.626
Oh, oh, she just left.

00:43:56.966 --> 00:43:59.176
I guess it's the end of the

00:43:59.176 --> 00:44:00.316
demo, let's go back to the

00:44:00.316 --> 00:44:00.676
slides.

00:44:02.016 --> 00:44:07.936
[ Applause ]

00:44:08.436 --> 00:44:09.876
So as you can see, it's really

00:44:09.876 --> 00:44:12.106
easy to use image tracking in

00:44:12.106 --> 00:44:12.546
ARKit.

00:44:13.216 --> 00:44:14.626
In fact, it's much harder to

00:44:14.626 --> 00:44:15.696
make a video of your cat.

00:44:18.136 --> 00:44:20.306
So image tracking is great at

00:44:20.306 --> 00:44:22.476
interacting with 2D objects, but

00:44:22.476 --> 00:44:24.476
we're not limited to plainer 2D

00:44:24.476 --> 00:44:28.286
objects, so let's talk next

00:44:28.856 --> 00:44:31.326
about object detection.

00:44:32.036 --> 00:44:35.576
Object detection can be used to

00:44:35.576 --> 00:44:38.236
detect known 3D objects in the

00:44:38.346 --> 00:44:38.636
scene.

00:44:39.916 --> 00:44:41.216
Just like image detection here,

00:44:41.216 --> 00:44:42.906
the term detection means that

00:44:42.906 --> 00:44:44.716
this object needs to be static

00:44:44.906 --> 00:44:46.176
and can therefore, or should

00:44:46.176 --> 00:44:47.186
therefore not move.

00:44:48.366 --> 00:44:50.156
Great examples of such objects

00:44:50.156 --> 00:44:51.946
could be exhibits in a museum,

00:44:52.196 --> 00:44:53.496
certain toys, or household

00:44:53.496 --> 00:44:53.836
items.

00:44:56.586 --> 00:44:57.656
And like image detection,

00:44:58.096 --> 00:44:59.636
objects need to be scanned first

00:44:59.636 --> 00:45:01.756
using an iOS app running ARKit.

00:45:02.686 --> 00:45:05.016
For this we offered the full

00:45:05.016 --> 00:45:06.666
source code of a full-featured

00:45:07.036 --> 00:45:09.256
iOS app that allows you to scan

00:45:09.256 --> 00:45:10.296
your own 3D objects.

00:45:11.436 --> 00:45:13.006
Such objects have a few

00:45:13.096 --> 00:45:15.236
properties such that they need

00:45:15.236 --> 00:45:17.336
to be well textured, rigid, and

00:45:17.376 --> 00:45:18.056
nonreflective.

00:45:18.576 --> 00:45:20.396
And they need to have roughly

00:45:20.396 --> 00:45:23.866
the size of a tabletop.

00:45:23.866 --> 00:45:25.586
ARKit can be used to estimate

00:45:25.586 --> 00:45:27.356
the position and orientation of

00:45:27.356 --> 00:45:28.796
such objects in six degrees of

00:45:28.796 --> 00:45:29.166
freedom.

00:45:29.726 --> 00:45:33.716
And all of this is fully

00:45:33.716 --> 00:45:34.936
integrated into world tracking.

00:45:35.396 --> 00:45:37.026
So all you need to do is set one

00:45:37.026 --> 00:45:38.726
single property to get started

00:45:38.726 --> 00:45:39.526
with object detection.

00:45:40.296 --> 00:45:41.976
So let's have a look how it can

00:45:41.976 --> 00:45:42.356
be set up.

00:45:42.406 --> 00:45:45.206
I load a set of AR reference

00:45:45.296 --> 00:45:47.486
images from file or from Xcode

00:45:47.486 --> 00:45:48.166
asset catalog.

00:45:49.066 --> 00:45:50.726
I will talk about the reference

00:45:50.726 --> 00:45:51.506
objects in a second.

00:45:52.496 --> 00:45:53.586
Once I'm done loading these

00:45:53.586 --> 00:45:54.926
reference objects, I used them

00:45:55.776 --> 00:45:59.716
to set up my configuration of

00:45:59.716 --> 00:46:00.056
type

00:46:00.226 --> 00:46:02.096
ARWorldTrackingConfiguration by

00:46:02.096 --> 00:46:03.776
specifying the detection objects

00:46:03.806 --> 00:46:04.196
property.

00:46:04.706 --> 00:46:07.166
When I'm done setting up my

00:46:07.236 --> 00:46:09.706
configuration, again I run my

00:46:09.786 --> 00:46:10.346
session with it.

00:46:11.406 --> 00:46:12.696
And just as image detection,

00:46:13.326 --> 00:46:14.466
once the AR session is running,

00:46:14.466 --> 00:46:15.496
I get an ARFrame with every

00:46:15.496 --> 00:46:18.936
update, and in this case, once

00:46:18.936 --> 00:46:20.386
an object has been detected in

00:46:20.386 --> 00:46:22.606
the scene, I will find an AR

00:46:23.106 --> 00:46:25.966
object anchor as part of my AR

00:46:25.966 --> 00:46:26.336
frame.

00:46:28.926 --> 00:46:30.866
Such an AR object is a simple

00:46:30.866 --> 00:46:32.506
subclass of AR anchor.

00:46:33.156 --> 00:46:34.336
So it comes with a transform,

00:46:34.336 --> 00:46:35.606
which represents its position

00:46:35.796 --> 00:46:37.016
and orientation and six degrees

00:46:37.016 --> 00:46:39.656
of freedom as well as it tells

00:46:39.656 --> 00:46:41.706
me which objects has been

00:46:41.706 --> 00:46:43.056
detected by giving me a

00:46:43.056 --> 00:46:44.296
reference to the AR reference

00:46:44.296 --> 00:46:44.676
object.

00:46:46.326 --> 00:46:49.596
And implementing this can be

00:46:49.596 --> 00:46:51.866
done with three simple lines of

00:46:51.936 --> 00:46:52.186
code.

00:46:52.976 --> 00:46:54.286
I create a configuration of type

00:46:54.486 --> 00:46:56.876
ARWorldTrackingConfiguration and

00:46:56.876 --> 00:46:59.116
specify a set of objects I'd

00:46:59.116 --> 00:46:59.756
like to detect.

00:47:00.596 --> 00:47:01.936
In this case, I envision to

00:47:01.936 --> 00:47:04.896
build a simple AR museum app by

00:47:04.896 --> 00:47:07.016
detecting an ancient bust and a

00:47:07.016 --> 00:47:07.546
clay pot.

00:47:07.546 --> 00:47:10.726
And I use this to run my

00:47:10.806 --> 00:47:11.126
session.

00:47:12.436 --> 00:47:14.696
So in fact, at the office, we

00:47:14.696 --> 00:47:16.616
build a very simple AR museum

00:47:16.616 --> 00:47:18.556
app, so let's have a look.

00:47:19.126 --> 00:47:23.166
So once this bust gets into view

00:47:23.166 --> 00:47:25.456
of my iOS app, I get a six

00:47:25.456 --> 00:47:26.996
degrees of freedom pose and can

00:47:26.996 --> 00:47:29.426
use this to show the scene, very

00:47:29.426 --> 00:47:31.246
simple infographics floating

00:47:31.246 --> 00:47:32.026
about the statue.

00:47:32.906 --> 00:47:33.926
In this case, we have simply

00:47:33.926 --> 00:47:36.366
added date of birth, the name of

00:47:36.366 --> 00:47:37.496
this Egyptian queen, which was

00:47:37.496 --> 00:47:39.906
Nefertiti, but you could add any

00:47:39.906 --> 00:47:40.956
content that your rendering

00:47:40.956 --> 00:47:43.576
engine allows you to use.

00:47:43.956 --> 00:47:45.846
In order to build this app, I

00:47:45.896 --> 00:47:47.386
had to scan the object first.

00:47:48.066 --> 00:47:49.266
So let's talk about object

00:47:49.266 --> 00:47:49.756
scanning.

00:47:50.236 --> 00:47:53.306
Object scanning extracts

00:47:53.426 --> 00:47:54.956
accumulated scene information

00:47:55.216 --> 00:47:55.736
from the world.

00:47:56.636 --> 00:47:58.506
This is very much related to

00:47:58.506 --> 00:48:00.736
plane estimation in which we use

00:48:00.776 --> 00:48:02.186
accumulated scene information to

00:48:02.516 --> 00:48:03.566
estimate the position of a

00:48:03.566 --> 00:48:05.106
horizontal or vertical plane.

00:48:06.046 --> 00:48:07.556
In this case, we use this

00:48:08.326 --> 00:48:11.606
information to gather

00:48:11.606 --> 00:48:13.286
information about the 3D object.

00:48:13.776 --> 00:48:17.556
In order to specify which area

00:48:17.556 --> 00:48:19.086
to look for the object, I just

00:48:19.086 --> 00:48:21.326
specify a transform and extend

00:48:21.366 --> 00:48:21.986
in the center.

00:48:22.796 --> 00:48:24.036
This is essentially a bounding

00:48:24.036 --> 00:48:25.746
box around the object just to

00:48:25.846 --> 00:48:29.696
define where it is in the scene.

00:48:29.876 --> 00:48:31.266
Extracted objects are fully

00:48:31.266 --> 00:48:33.126
supported by Xcode's asset

00:48:33.126 --> 00:48:34.736
catalog, so it makes it really

00:48:34.736 --> 00:48:38.486
easy to port them to a new app

00:48:38.556 --> 00:48:40.756
and reuse them as many times as

00:48:40.756 --> 00:48:41.116
you want.

00:48:42.606 --> 00:48:43.986
And for scanning, we added a new

00:48:43.986 --> 00:48:45.266
configuration, the

00:48:45.266 --> 00:48:46.696
ARObjectScanningConfiguration.

00:48:48.156 --> 00:48:49.896
But you do not need to go ahead

00:48:49.896 --> 00:48:51.246
and implement your own scanning

00:48:51.246 --> 00:48:53.826
app as the full sample code is

00:48:53.826 --> 00:48:55.386
available for full-featured

00:48:55.486 --> 00:48:57.616
scanning app called Scanning and

00:48:57.616 --> 00:48:58.746
Detecting 3D Objects.

00:49:00.186 --> 00:49:01.356
So let's have a look how this

00:49:01.396 --> 00:49:02.066
app works.

00:49:02.756 --> 00:49:04.396
I start by creating a bounding

00:49:04.396 --> 00:49:05.786
box around the object of

00:49:05.786 --> 00:49:07.136
interest, in this case, the

00:49:07.136 --> 00:49:07.976
statue of Nefertiti.

00:49:07.976 --> 00:49:10.486
Note that the bounding box does

00:49:10.486 --> 00:49:11.856
not need to be really strict

00:49:11.856 --> 00:49:12.616
around the object.

00:49:12.896 --> 00:49:14.806
All we care is that the most

00:49:14.806 --> 00:49:16.626
important feature points are

00:49:16.766 --> 00:49:17.716
within its bounds.

00:49:19.226 --> 00:49:20.166
When I'm satisfied with the

00:49:20.166 --> 00:49:23.366
bounding box, I can click press

00:49:23.516 --> 00:49:26.056
scan, and we start scanning the

00:49:26.056 --> 00:49:26.416
object.

00:49:27.106 --> 00:49:28.326
I can see the progress going up

00:49:28.326 --> 00:49:30.216
and this tile representation

00:49:30.916 --> 00:49:32.446
indicating how much of the

00:49:32.446 --> 00:49:33.976
object has been scanned in a

00:49:33.976 --> 00:49:34.736
spatial manner.

00:49:35.946 --> 00:49:37.066
Note that you do not have to

00:49:37.166 --> 00:49:38.566
scan the object from all sides.

00:49:39.546 --> 00:49:41.336
For example, if you know that a

00:49:41.436 --> 00:49:43.496
statue will be facing a wall in

00:49:43.496 --> 00:49:46.426
a museum, and there is no way

00:49:46.426 --> 00:49:47.626
that you could detect it from

00:49:47.626 --> 00:49:49.546
one specific viewpoint, you do

00:49:49.546 --> 00:49:51.626
not need to scan it from that

00:49:52.636 --> 00:49:52.756
side.

00:49:53.426 --> 00:49:55.156
Once you're satisfied with the

00:49:55.226 --> 00:50:00.126
scan, you can adjust the center

00:50:00.226 --> 00:50:02.186
of the extent which corresponds

00:50:02.186 --> 00:50:03.336
to the origin of the object.

00:50:04.346 --> 00:50:05.516
The only requirement here is

00:50:05.516 --> 00:50:07.446
that the center stays within the

00:50:07.446 --> 00:50:08.336
object's extent.

00:50:09.006 --> 00:50:12.026
And lastly, the scanning app

00:50:12.026 --> 00:50:13.736
lets you perform detection

00:50:13.736 --> 00:50:13.886
tests.

00:50:14.216 --> 00:50:16.696
So in this case, detection was

00:50:16.696 --> 00:50:18.286
successful from various

00:50:18.286 --> 00:50:19.906
viewpoints, which means it's a

00:50:19.906 --> 00:50:20.406
good scan.

00:50:21.766 --> 00:50:22.796
And our recommendation here is

00:50:22.796 --> 00:50:24.796
also to move the object to

00:50:24.796 --> 00:50:27.186
different location to test

00:50:27.186 --> 00:50:29.676
whether detection works with

00:50:29.676 --> 00:50:31.046
different texture and under

00:50:31.046 --> 00:50:32.046
different lighting conditions.

00:50:34.476 --> 00:50:35.926
Once you're done scanning, you

00:50:35.926 --> 00:50:37.186
will obtain an object of type

00:50:37.296 --> 00:50:39.926
ARReferenceObject, which we have

00:50:40.286 --> 00:50:41.306
seen earlier in the diagram.

00:50:42.296 --> 00:50:44.816
This object can be serialized to

00:50:44.816 --> 00:50:46.286
usually and AR object file

00:50:46.286 --> 00:50:46.956
extension type.

00:50:47.636 --> 00:50:49.306
It has a name, which will also

00:50:49.306 --> 00:50:51.856
be visible in your asset catalog

00:50:52.386 --> 00:50:53.576
as well as the center and the

00:50:53.576 --> 00:50:55.236
extent used for scanning it.

00:50:56.146 --> 00:50:57.666
And you will also get all the

00:50:57.666 --> 00:51:00.016
raw feature points found within

00:51:00.016 --> 00:51:02.236
the area when you performed your

00:51:02.326 --> 00:51:02.486
scan.

00:51:05.386 --> 00:51:06.686
So this was object detection.

00:51:07.256 --> 00:51:08.896
Keep in mind, before detection

00:51:08.896 --> 00:51:10.616
object, you need to scan them,

00:51:10.616 --> 00:51:11.956
but there is the full source

00:51:11.956 --> 00:51:13.196
code available for you to

00:51:13.196 --> 00:51:16.286
download it right now.

00:51:16.406 --> 00:51:18.926
So let's talk next about face

00:51:18.926 --> 00:51:19.266
tracking.

00:51:24.546 --> 00:51:26.296
When we released the iPhone X

00:51:26.296 --> 00:51:28.166
last year, we added robust face

00:51:28.166 --> 00:51:29.776
detection and tracking to ARKit.

00:51:30.746 --> 00:51:32.276
Here, ARKit estimates the

00:51:32.276 --> 00:51:33.816
position and orientation of a

00:51:33.876 --> 00:51:36.186
face for every frame at 60

00:51:36.186 --> 00:51:37.006
frames per second.

00:51:37.826 --> 00:51:39.586
Here we can use the, this pose

00:51:39.586 --> 00:51:41.576
can be used to augment a user's

00:51:41.576 --> 00:51:44.206
face by adding masks, hats, or

00:51:44.206 --> 00:51:45.746
replace the full texture of a

00:51:46.776 --> 00:51:46.906
face.

00:51:47.816 --> 00:51:48.956
ARKit also provides you with a

00:51:48.956 --> 00:51:50.536
fitted triangle mesh coming to

00:51:50.536 --> 00:51:52.016
form of the ARFaceGeometry.

00:51:52.566 --> 00:51:56.136
This type, the ARFaceGeometry,

00:51:56.136 --> 00:51:57.636
contains all the information

00:51:57.636 --> 00:51:59.326
needed to render this facial

00:51:59.326 --> 00:52:01.916
mesh, and it comes in the form

00:52:01.976 --> 00:52:05.566
of all vertices, triangles, as

00:52:05.566 --> 00:52:07.296
well as detection coordinates.

00:52:08.556 --> 00:52:10.356
The main anchor type of face

00:52:10.356 --> 00:52:12.186
tracking is ARFaceAnchor, which

00:52:12.186 --> 00:52:13.876
contains all information needed

00:52:13.876 --> 00:52:15.266
to perform face tracking.

00:52:16.666 --> 00:52:18.486
And in order to render such

00:52:18.486 --> 00:52:20.886
geometry realistically, we added

00:52:20.956 --> 00:52:22.506
a directional light estimate.

00:52:23.616 --> 00:52:25.426
Here, ARKit uses your light as a

00:52:25.426 --> 00:52:27.786
light probe and estimates this

00:52:28.616 --> 00:52:30.986
ARDirectionLightEstimate, which

00:52:31.316 --> 00:52:33.026
consists of the light intensity,

00:52:33.176 --> 00:52:34.696
direction, as well as the color

00:52:34.696 --> 00:52:35.096
temperature.

00:52:36.086 --> 00:52:39.066
This estimate will be sufficient

00:52:39.346 --> 00:52:41.406
to make most apps already look

00:52:41.506 --> 00:52:43.456
great, but if your app has more

00:52:43.456 --> 00:52:45.896
sophisticated needs, we also

00:52:45.896 --> 00:52:47.686
provide the second-degree

00:52:47.686 --> 00:52:48.986
spherical harmonics coefficients

00:52:49.396 --> 00:52:51.046
that gather lighting conditions

00:52:51.086 --> 00:52:53.266
throughout the entire scene for

00:52:53.356 --> 00:52:55.606
you to make your content even

00:52:56.216 --> 00:52:57.726
look better.

00:52:57.926 --> 00:52:59.106
And ARKit can also track

00:52:59.106 --> 00:53:00.426
expressions in real-time.

00:53:01.176 --> 00:53:02.436
These expressions are so-called

00:53:02.806 --> 00:53:05.236
blend shapes, and there's 50 or

00:53:05.306 --> 00:53:06.616
more of them.

00:53:08.186 --> 00:53:09.296
Such a blend shape assume a

00:53:09.296 --> 00:53:10.516
value between 0 and 1.

00:53:11.236 --> 00:53:12.356
One means there's full

00:53:12.356 --> 00:53:13.116
activation.

00:53:13.116 --> 00:53:13.856
Zero means there is none.

00:53:14.386 --> 00:53:15.666
For example, the jaw

00:53:15.666 --> 00:53:17.836
open coefficient will assume a

00:53:17.836 --> 00:53:19.156
value close to 1 if I open my

00:53:19.156 --> 00:53:20.796
mouth and a value close to 0 if

00:53:20.796 --> 00:53:21.236
I close it.

00:53:22.106 --> 00:53:24.456
And this is great to animate

00:53:24.456 --> 00:53:25.416
your own virtual character.

00:53:26.186 --> 00:53:27.706
This example here, I've used the

00:53:27.706 --> 00:53:29.466
jaw open and eye blink left and

00:53:29.466 --> 00:53:31.236
eye blink right to animate this

00:53:31.236 --> 00:53:32.276
really simple box face

00:53:32.276 --> 00:53:32.616
character.

00:53:34.156 --> 00:53:35.276
But it can do better than that.

00:53:36.286 --> 00:53:38.156
In fact, when we built Animoji,

00:53:38.156 --> 00:53:39.856
we used a handful more of such

00:53:39.856 --> 00:53:40.406
blend shapes.

00:53:41.176 --> 00:53:42.256
So all the blue bars you see

00:53:42.256 --> 00:53:44.446
moving here were used to get

00:53:44.446 --> 00:53:46.106
over the head post to map my

00:53:46.106 --> 00:53:47.856
facial expressions on the panda

00:53:47.856 --> 00:53:48.076
bear.

00:53:49.706 --> 00:53:50.986
Note that ARKit offers

00:53:51.056 --> 00:53:52.616
everything needed for you to

00:53:52.616 --> 00:53:54.896
animate your own character just

00:53:54.896 --> 00:53:56.086
like we did with Animoji.

00:53:56.696 --> 00:53:58.036
Thank you.

00:53:59.516 --> 00:54:04.276
[ Applause ]

00:54:04.776 --> 00:54:06.196
So let's see what's new for face

00:54:06.196 --> 00:54:07.736
tracking in ARKit 2.

00:54:08.736 --> 00:54:11.106
We added gaze tracking that will

00:54:11.106 --> 00:54:12.826
track the left and the right eye

00:54:12.966 --> 00:54:15.326
both in six degrees of freedom.

00:54:16.516 --> 00:54:21.046
[ Applause ]

00:54:21.546 --> 00:54:22.646
You will find these properties

00:54:22.646 --> 00:54:24.956
as members of ARFaceAnchor as

00:54:24.956 --> 00:54:26.516
well as a look-at point, this

00:54:26.516 --> 00:54:28.346
corresponds to reintersection of

00:54:28.346 --> 00:54:29.316
the two gaze directions.

00:54:30.326 --> 00:54:32.256
You may use this information to

00:54:32.296 --> 00:54:34.076
animate again your own character

00:54:34.496 --> 00:54:36.456
or of any other form of input to

00:54:36.456 --> 00:54:36.796
your app.

00:54:36.796 --> 00:54:38.446
And there's more.

00:54:39.716 --> 00:54:40.816
We added support for tongue,

00:54:42.176 --> 00:54:43.186
which comes in the form of a new

00:54:43.186 --> 00:54:43.746
blend shape.

00:54:44.636 --> 00:54:45.566
This blend shape will assume a

00:54:45.566 --> 00:54:47.786
value of 1 if my tongue is out 0

00:54:48.096 --> 00:54:48.516
if not.

00:54:49.516 --> 00:54:51.276
Again, you could use this to

00:54:51.276 --> 00:54:53.086
animate your own character or

00:54:53.086 --> 00:54:55.896
use this as a form of input to

00:54:55.896 --> 00:54:56.946
your app.

00:55:00.636 --> 00:55:01.086
Thank you.

00:55:01.821 --> 00:55:03.821
[ Applause ]

00:55:04.126 --> 00:55:05.216
So seeing myself sticking my

00:55:05.216 --> 00:55:06.766
tongue out over and over is a

00:55:06.766 --> 00:55:07.936
good time for summary.

00:55:09.086 --> 00:55:11.796
So, what's new in ARKit 2.

00:55:11.796 --> 00:55:12.966
Let's have a look.

00:55:13.816 --> 00:55:15.306
We've seen saving and loading

00:55:15.306 --> 00:55:16.606
maps, which are powerful new

00:55:16.606 --> 00:55:18.016
features for persistence and

00:55:18.206 --> 00:55:20.436
multiuser collaboration.

00:55:21.726 --> 00:55:23.086
World tracking enhancements

00:55:23.506 --> 00:55:25.236
simply shows better and fasting

00:55:25.236 --> 00:55:27.746
plane detection as well as new

00:55:27.746 --> 00:55:29.356
video formats.

00:55:29.566 --> 00:55:31.056
And with environment texturing,

00:55:31.726 --> 00:55:34.256
we can make the content really

00:55:34.506 --> 00:55:35.876
look as if it was really in the

00:55:35.976 --> 00:55:38.526
scene by gathering texture of

00:55:38.526 --> 00:55:39.876
the scene and applying it as a

00:55:39.906 --> 00:55:40.616
textured object.

00:55:41.846 --> 00:55:44.136
And with image tracking, with

00:55:44.836 --> 00:55:48.196
image tracking, we are now able

00:55:48.196 --> 00:55:50.516
to track 2D objects in the form

00:55:50.516 --> 00:55:50.986
of images.

00:55:51.506 --> 00:55:53.236
But ARKit can also detect 3D

00:55:53.236 --> 00:55:53.586
objects.

00:55:54.576 --> 00:55:56.386
And for face tracking, we have

00:55:56.916 --> 00:55:59.116
gaze and tongue.

00:55:59.926 --> 00:56:01.226
All of this is made available

00:56:01.226 --> 00:56:02.736
for you in the form of the

00:56:02.736 --> 00:56:04.256
building blocks of ARKit.

00:56:05.336 --> 00:56:08.016
In iOS 12, ARKit features five

00:56:08.066 --> 00:56:09.456
different configurations with

00:56:09.456 --> 00:56:10.876
two new additions, the

00:56:10.876 --> 00:56:12.556
ARImageTrackingConfiguration for

00:56:12.556 --> 00:56:15.116
stand-alone image tracking and

00:56:15.196 --> 00:56:15.306
the

00:56:15.306 --> 00:56:16.766
ARObjectScanningConfiguration.

00:56:18.056 --> 00:56:19.146
And there's a series of

00:56:19.746 --> 00:56:21.456
supplementary types used to

00:56:21.456 --> 00:56:22.716
interact with the AR session.

00:56:23.426 --> 00:56:25.036
The ARFrame, the ARCamera, for

00:56:25.166 --> 00:56:25.486
example.

00:56:26.686 --> 00:56:27.906
And this got two new additions,

00:56:27.996 --> 00:56:29.546
the ARReferenceObject for object

00:56:29.546 --> 00:56:31.706
detection and the ARWorldMap for

00:56:31.766 --> 00:56:33.366
persistence and multiuser.

00:56:33.896 --> 00:56:36.306
And the AR anchors, which

00:56:36.306 --> 00:56:37.836
represent positions in the real

00:56:37.836 --> 00:56:39.276
world, the anchor types.

00:56:39.586 --> 00:56:41.166
Got two new additions, the

00:56:41.166 --> 00:56:43.016
ARObjectAnchor and the

00:56:43.016 --> 00:56:44.176
AREnvironmentProbeAnchor.

00:56:45.236 --> 00:56:46.976
I'm really excited to see what

00:56:46.976 --> 00:56:48.156
you guys will build with all

00:56:48.156 --> 00:56:49.226
these building blocks in the

00:56:49.226 --> 00:56:51.886
ARKit available in iOS 12 as of

00:56:51.936 --> 00:56:52.176
today.

00:56:54.516 --> 00:57:00.506
[ Applause ]

00:57:01.006 --> 00:57:01.846
There's another real cool

00:57:01.906 --> 00:57:03.286
session about integrating

00:57:03.286 --> 00:57:04.656
ARQuickLook into your own

00:57:04.656 --> 00:57:06.596
application to make your content

00:57:06.596 --> 00:57:07.396
look simply great.

00:57:09.026 --> 00:57:11.396
With this, thanks a lot, and

00:57:11.396 --> 00:57:11.906
enjoy the rest of the

00:57:11.906 --> 00:57:12.256
conference.

00:57:13.508 --> 00:57:15.508
[ Applause ]