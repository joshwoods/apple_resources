<!--
Downloaded via https://llm.codes by @steipete on June 19, 2025 at 04:36 PM
Source URL: https://developer.apple.com/documentation/avfoundation
Total pages processed: 278
URLs filtered: No
Content de-duplicated: Yes
Availability strings filtered: Yes
Code blocks only: No
-->

# https://developer.apple.com/documentation/avfoundation/streaming-and-airplay

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Streaming and AirPlay

API Collection

# Streaming and AirPlay

Stream content wirelessly to other devices using AirPlay, and handle requests involving FairPlay-protected assets.

## [Topics](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay\#topics)

### [Essentials](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay\#Essentials)

[Supporting AirPlay in your app](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app)

Set up your app to use AirPlay to send content wirelessly.

### [Route selection](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay\#Route-selection)

[`class AVRouteDetector`](https://developer.apple.com/documentation/avfoundation/avroutedetector)

An object that detects available media playback routes.

### [Buffered playback](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay\#Buffered-playback)

[Implementing simple enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-simple-enhanced-buffering-for-your-content)

Configure your app for simple enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.

[Implementing flexible enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content)

Configure your app for flexible enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.

[Integrating AirPlay for Long-Form Video Apps](https://developer.apple.com/documentation/avfoundation/integrating-airplay-for-long-form-video-apps)

Integrate AirPlay features and implement a dedicated external playback experience by preparing the routing system for long-form video playback.

### [Resource loading](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay\#Resource-loading)

[`class AVAssetResourceLoader`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader)

An object that mediates resource requests from a URL asset.

[`protocol AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate)

Methods you can implement to handle resource-loading requests coming from a URL asset.

[`class AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest)

An object that encapsulates information about a resource request from a resource loader object.

[`class AVAssetResourceRenewalRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourcerenewalrequest)

An object that encapsulates information about a resource request from a resource loader to renew a previously issued request.

[`class AVAssetResourceLoadingRequestor`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor)

An object that contains information about the originator of a resource-loading request.

[`class AVAssetResourceLoadingDataRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest)

An object for requesting data from a resource that an asset resource-loading request references.

[`class AVAssetResourceLoadingContentInformationRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest)

A query for retrieving essential information about a resource that an asset resource-loading request references.

### [FairPlay Streaming](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay\#FairPlay-Streaming)

[`class AVContentKeySession`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession)

An object that creates and tracks decryption keys for media data.

[`protocol AVContentKeySessionDelegate`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)

A protocol that handles content key requests.

[`class AVContentKey`](https://developer.apple.com/documentation/avfoundation/avcontentkey)

An object that represents the content key decryptor.

[`class AVContentKeySpecifier`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier)

An object that uniquely identifies a content key.

[`class AVContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)

An object that encapsulates information about a content decryption key request issued from a content key session object.

[`class AVPersistableContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest)

An object that encapsulates information about a persistable content decryption key request issued from a content key session.

[`class AVContentKeyResponse`](https://developer.apple.com/documentation/avfoundation/avcontentkeyresponse)

An object that encapsulates information about a response to a content decryption key request.

[`enum AVExternalContentProtectionStatus`](https://developer.apple.com/documentation/avfoundation/avexternalcontentprotectionstatus)

Constants that specify whether sufficient protection exists to display the content.

Attaches a content key to a sample buffer for the purpose of content decryption.

## [See Also](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay\#see-also)

### [Playback](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay\#Playback)

Manage the playback of media assets and interstitial content, independent of how you present that content in your interface.

Download streamed content to disk to allow offline playback, and define policies to automatically remove downloaded assets.

Create custom controllers to play and synchronize the timing of sample buffer streams.

---

# https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
- [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos)
- Capturing a Bracketed Photo Sequence

Article

# Capturing a Bracketed Photo Sequence

Capture several photos at once, varying parameters like exposure duration or light sensitivity.

## [Overview](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence\#overview)

Bracketing is a well-known photographic technique in which a sequence of shots is rapidly taken of the same scene, usually varying only in a single parameter such as aperture or shutter speed (exposure length). Experienced photographers use this technique to help them choose the best photos after shooting, or to apply offline post-processing that fuses multiple images together to create extended dynamic range or other special effects.

In iOS, you can use [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) and [`AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings) to automatically capture a bracket of photos for each [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) call. Once you’ve built a single-exposure camera in your app (see [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos)), follow these steps to add multi-image bracket support.

### [Choose Bracket Settings](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence\#Choose-Bracket-Settings)

You specify a multi-exposure bracket by providing an array of bracket settings obejcts. iOS offers two types of automatic bracketing:

- Use [`AVCaptureAutoExposureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings) to create a bracket that varies exposure-compensation values relative to automatic exposure.

- Use [`AVCaptureManualExposureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings) to create a bracket with custom exposure durations and ISO sensitivity values for each photo in the bracket.

To define a bracket, create an array of one of these types, with values that describe the settings variations you want to capture. For example, the code below defines a bracket that captures three images at three different exposure values.

// Get AVCaptureBracketedStillImageSettings for a set of exposure values.
let exposureValues: [Float] = [-2, 0, +2]
let makeAutoExposureSettings = AVCaptureAutoExposureBracketedStillImageSettings.autoExposureSettings(exposureTargetBias:)
let exposureSettings = exposureValues.map(makeAutoExposureSettings)

### [Create Photo Settings and Shoot](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence\#Create-Photo-Settings-and-Shoot)

Instead of the [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object you create when shooting a single photo, to shoot a bracketed capture you’ll need an [`AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings) object. This object combines the general settings that apply to all photos in the bracket with your bracket settings that specify how each photo differs from the rest of the bracket.

As with single-image capture, you create a photo settings object by choosing the image codec and file format for the resulting photos, but you also provide the bracket settings you’ve chosen.

// Create photo settings for HEIF/HEVC capture and no RAW output
// and enable cross-bracket image stabilization.
let photoSettings = AVCapturePhotoBracketSettings(rawPixelFormatType: 0,
processedFormat: [AVVideoCodecKey : AVVideoCodecType.hevc],
bracketedSettings: exposureSettings)
photoSettings.isLensStabilizationEnabled =
self.photoOutput.isLensStabilizationDuringBracketedCaptureSupported

// Shoot the bracket, using a custom class to handle capture delegate callbacks.
let captureProcessor = PhotoCaptureProcessor()
self.photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)

### [Handle Bracketed Capture Results](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence\#Handle-Bracketed-Capture-Results)

The photo output calls your delegate’s [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method at least once for each exposure in the bracket, and possibly additional times depending on your capture settings. For example, if you request RAW+HEIF capture in a three-exposure bracket, the photo output calls your delegate’s `didFinishProcessingPhoto` method six times (2 formats × 3 exposures), providing six [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) objects.

To keep track of multiple results, compare the [`photoCount`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount) from each photo to the [`expectedPhotoCount`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/expectedphotocount) of your resolved settings. When those numbers are equal, you’ve received all results from the capture.

## [See Also](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence\#see-also)

### [More Capture Options](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence\#More-Capture-Options)

[Capturing Photos with Depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)

Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).

[Capturing Uncompressed Image Data](https://developer.apple.com/documentation/avfoundation/capturing-uncompressed-image-data)

Get processed image data without compression to use for filtering or lossless output.

[Capturing Thumbnail and Preview Images](https://developer.apple.com/documentation/avfoundation/capturing-thumbnail-and-preview-images)

Enable delivery of reduced-size images with the main image in a photo capture.

---

# https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Streaming and AirPlay](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay)
- Supporting AirPlay in your app

Article

# Supporting AirPlay in your app

Set up your app to use AirPlay to send content wirelessly.

## [Overview](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app\#overview)

AirPlay enables you to send content wirelessly from an Apple device to an Apple TV or AirPlay-enabled speaker. AirPlay provides enhanced support for wireless audio distribution, including the ability to send content to multiple AirPlay-enabled speakers.

### [Identify the audio type the app plays](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app\#Identify-the-audio-type-the-app-plays)

In iOS, tvOS, and watchOS, set your audio session’s route-sharing policy to `.longForm`. Long-form audio is anything other than system sounds, such as music, audiobooks, or podcasts. This setting identifies the audio that an app plays, such as in the following example.

let audioSession = AVAudioSession.sharedInstance()
try audioSession.setCategory(.playback,
mode: .default,
policy: .longFormAudio)

### [Add an AirPlay picker](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app\#Add-an-AirPlay-picker)

Add [`AVRoutePickerView`](https://developer.apple.com/documentation/AVKit/AVRoutePickerView) to your view hierarchy to include an AirPlay picker in your app. The picker provides users with a list of potential AirPlay devices they can use with your app. To control when to show the picker, use [`AVRouteDetector`](https://developer.apple.com/documentation/avfoundation/avroutedetector) to identify the state of the route detector.

### [Add a media player](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app\#Add-a-media-player)

Use APIs to customize your AirPlay adoption with Media Player integration. If you use [`MPRemoteCommandCenter`](https://developer.apple.com/documentation/MediaPlayer/MPRemoteCommandCenter), you can receive remote commands. If you use [`MPNowPlayingInfoCenter`](https://developer.apple.com/documentation/MediaPlayer/MPNowPlayingInfoCenter), you can inform the system metadata about the track that’s playing on the device.

### [Configure an app for fast streaming](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app\#Configure-an-app-for-fast-streaming)

Adopt one of two playback API sets that take advantage of the enhanced buffering in AirPlay:

- For simple enhanced buffering, use [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) or [`AVQueuePlayer`](https://developer.apple.com/documentation/avfoundation/avqueueplayer). This works well for video content. For more information, see [Implementing simple enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-simple-enhanced-buffering-for-your-content).

- For more flexibility with enhanced buffering, use [`AVSampleBufferAudioRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer) and [`AVSampleBufferRenderSynchronizer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer). This option is better for apps that require control over I/O, perform preprocessing on their media data, or have a DRM model that [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) doesn’t support. For more information, see [Implementing flexible enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content).

---

# https://developer.apple.com/documentation/avfoundation/media-assets

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Media assets

API Collection

# Media assets

Load media assets from files and streams to inspect their attributes, tracks, and embedded metadata.

## [Topics](https://developer.apple.com/documentation/avfoundation/media-assets\#topics)

### [Essentials](https://developer.apple.com/documentation/avfoundation/media-assets\#Essentials)

[Loading media data asynchronously](https://developer.apple.com/documentation/avfoundation/loading-media-data-asynchronously)

Build responsive apps by using language-level concurrency features to efficiently load media data.

### [Assets](https://developer.apple.com/documentation/avfoundation/media-assets\#Assets)

[`class AVAsset`](https://developer.apple.com/documentation/avfoundation/avasset)

An object that models timed audiovisual media.

[`class AVURLAsset`](https://developer.apple.com/documentation/avfoundation/avurlasset)

An asset that represents media at a local or remote URL.

[`class AVAssetTrack`](https://developer.apple.com/documentation/avfoundation/avassettrack)

An object that models a track of media that an asset contains.

[`class AVAssetTrackSegment`](https://developer.apple.com/documentation/avfoundation/avassettracksegment)

An object that represents a time range segment of an asset track.

[`class AVAssetTrackGroup`](https://developer.apple.com/documentation/avfoundation/avassettrackgroup)

A group of related tracks in an asset.

### [Metadata](https://developer.apple.com/documentation/avfoundation/media-assets\#Metadata)

[Retrieving media metadata](https://developer.apple.com/documentation/avfoundation/retrieving-media-metadata)

Load descriptive metadata for media assets and their tracks.

[`class AVMetadataItem`](https://developer.apple.com/documentation/avfoundation/avmetadataitem)

A metadata item for an audiovisual asset or one of its tracks.

[`class AVMutableMetadataItem`](https://developer.apple.com/documentation/avfoundation/avmutablemetadataitem)

A mutable metadata item for an audiovisual asset or for one of its tracks.

[`struct AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)

A structure that defines identifiers for metadata formats.

[`struct AVMetadataKey`](https://developer.apple.com/documentation/avfoundation/avmetadatakey)

A structure that defines a metadata key.

[`struct AVMetadataKeySpace`](https://developer.apple.com/documentation/avfoundation/avmetadatakeyspace)

A structure that defines a metadata key space.

[`struct AVMetadataExtraAttributeKey`](https://developer.apple.com/documentation/avfoundation/avmetadataextraattributekey)

A structure that defines keys for extra metadata attributes.

[`struct AVMetadataFormat`](https://developer.apple.com/documentation/avfoundation/avmetadataformat)

A structure that defines metadata formats.

[`class AVMetadataItemFilter`](https://developer.apple.com/documentation/avfoundation/avmetadataitemfilter)

An object that filters selected information from a metadata item.

### [Property loading](https://developer.apple.com/documentation/avfoundation/media-assets\#Property-loading)

[`protocol AVAsynchronousKeyValueLoading`](https://developer.apple.com/documentation/avfoundation/avasynchronouskeyvalueloading)

A protocol that defines the interface to load media data asynchronously.

[`class AVAsyncProperty`](https://developer.apple.com/documentation/avfoundation/avasyncproperty)

An asynchronous property that constrains its type and value.

[`class AVPartialAsyncProperty`](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty)

An asynchronous property that constrains its type.

[`class AVAnyAsyncProperty`](https://developer.apple.com/documentation/avfoundation/avanyasyncproperty)

A base class for asynchronous properties.

### [Fragmented assets](https://developer.apple.com/documentation/avfoundation/media-assets\#Fragmented-assets)

[`class AVFragmentedAsset`](https://developer.apple.com/documentation/avfoundation/avfragmentedasset)

An asset with a duration that the system can extend without modifying its existing media data.

[`class AVFragmentedAssetTrack`](https://developer.apple.com/documentation/avfoundation/avfragmentedassettrack)

An object that provides the track-level interface to inspect a fragmented asset’s media tracks.

[`class AVFragmentedAssetMinder`](https://developer.apple.com/documentation/avfoundation/avfragmentedassetminder)

An object that periodically checks whether the system adds new fragments to a fragmented asset.

[`protocol AVFragmentMinding`](https://developer.apple.com/documentation/avfoundation/avfragmentminding)

A protocol that defines whether an asset supports fragment minding.

## [See Also](https://developer.apple.com/documentation/avfoundation/media-assets\#see-also)

### [Common](https://developer.apple.com/documentation/avfoundation/media-assets\#Common)

Read images from video, export to alternative formats, and perform sample-level reading and writing of media data.

Identify the types of content and file formats that AVFoundation supports.

Configure video processing settings using standard key and value constants.

Configure audio processing settings using standard key and value constants.

---

# https://developer.apple.com/documentation/avfoundation/media-types-and-utilities

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Media types and utilities

API Collection

# Media types and utilities

Identify the types of content and file formats that AVFoundation supports.

## [Topics](https://developer.apple.com/documentation/avfoundation/media-types-and-utilities\#topics)

### [Media types](https://developer.apple.com/documentation/avfoundation/media-types-and-utilities\#Media-types)

[`struct AVMediaType`](https://developer.apple.com/documentation/avfoundation/avmediatype)

An identifier for various media types.

[`struct AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic)

A structure that defines media data characteristics.

### [File types](https://developer.apple.com/documentation/avfoundation/media-types-and-utilities\#File-types)

[`struct AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype)

The uniform type identifiers for various file formats.

[`struct AVFileTypeProfile`](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile)

File type profiles for streaming formats.

### [Utilities](https://developer.apple.com/documentation/avfoundation/media-types-and-utilities\#Utilities)

Returns a scaled rectangle that maintains the specified aspect ratio within a bounding rectangle.

## [See Also](https://developer.apple.com/documentation/avfoundation/media-types-and-utilities\#see-also)

### [Common](https://developer.apple.com/documentation/avfoundation/media-types-and-utilities\#Common)

Load media assets from files and streams to inspect their attributes, tracks, and embedded metadata.

Read images from video, export to alternative formats, and perform sample-level reading and writing of media data.

Configure video processing settings using standard key and value constants.

Configure audio processing settings using standard key and value constants.

---

# https://developer.apple.com/documentation/avfoundation/offline-playback-and-storage

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Offline playback and storage

API Collection

# Offline playback and storage

Download streamed content to disk to allow offline playback, and define policies to automatically remove downloaded assets.

## [Topics](https://developer.apple.com/documentation/avfoundation/offline-playback-and-storage\#topics)

### [Asset downloading](https://developer.apple.com/documentation/avfoundation/offline-playback-and-storage\#Asset-downloading)

[Using AVFoundation to play and persist HTTP Live Streams](https://developer.apple.com/documentation/avfoundation/using-avfoundation-to-play-and-persist-http-live-streams)

Play HTTP Live Streams and persist streams on disk for offline playback using AVFoundation.

[`class AVAssetDownloadURLSession`](https://developer.apple.com/documentation/avfoundation/avassetdownloadurlsession)

A URL session that creates and executes asset download tasks.

[`class AVAssetDownloadTask`](https://developer.apple.com/documentation/avfoundation/avassetdownloadtask)

A session used to download HTTP Live Streaming assets.

[`class AVAggregateAssetDownloadTask`](https://developer.apple.com/documentation/avfoundation/avaggregateassetdownloadtask)

A task that downloads multiple media selections for an asset.

### [Offline storage management](https://developer.apple.com/documentation/avfoundation/offline-playback-and-storage\#Offline-storage-management)

[`class AVAssetDownloadStorageManager`](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager)

An object that manages policies to automatically purge downloaded assets.

[`class AVAssetDownloadStorageManagementPolicy`](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanagementpolicy)

An object that defines a policy to automatically manage the storage of downloaded assets.

[`class AVMutableAssetDownloadStorageManagementPolicy`](https://developer.apple.com/documentation/avfoundation/avmutableassetdownloadstoragemanagementpolicy)

A mutable object that you use to create a new storage management policy.

### [Cache monitoring](https://developer.apple.com/documentation/avfoundation/offline-playback-and-storage\#Cache-monitoring)

[`class AVAssetCache`](https://developer.apple.com/documentation/avfoundation/avassetcache)

An object that you use to inspect locally cached media data.

## [See Also](https://developer.apple.com/documentation/avfoundation/offline-playback-and-storage\#see-also)

### [Playback](https://developer.apple.com/documentation/avfoundation/offline-playback-and-storage\#Playback)

Manage the playback of media assets and interstitial content, independent of how you present that content in your interface.

Stream content wirelessly to other devices using AirPlay, and handle requests involving FairPlay-protected assets.

Create custom controllers to play and synchronize the timing of sample buffer streams.

---

# https://developer.apple.com/documentation/avfoundation/photo-capture

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Photo capture

API Collection

# Photo capture

Capture high-quality still images, Live Photos, and supporting photo data.

## [Topics](https://developer.apple.com/documentation/avfoundation/photo-capture\#topics)

### [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture\#Photo-capture)

[Capturing consistent color images](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images)

Add the power of a photography studio and lighting rig to your app with the new Constant Color API.

Configure and capture single or multiple still images, Live Photos, and other forms of photography.

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

Support professional photography workflows by enabling minimally processed image capture in your camera app.

[Supporting Continuity Camera in Your Mac App](https://developer.apple.com/documentation/AppKit/supporting-continuity-camera-in-your-mac-app)

Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.

[`class AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto)

A container for image data from a photo capture output.

[`class AVCaptureDeferredPhotoProxy`](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy)

A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.

[`class AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)

A capture output for still image, Live Photos, and other photography workflows.

[`protocol AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)

Methods for monitoring progress and receiving results from a photo capture output.

[`class AVCapturePhotoOutputReadinessCoordinator`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinator)

An object that monitors changes to a photo output’s capture readiness.

[`protocol AVCapturePhotoOutputReadinessCoordinatorDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinatordelegate)

A delegate protocol to receive updates about a photo output’s capture readiness.

[`class AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput)

A capture output for capturing still photos.

Deprecated

### [Photo settings](https://developer.apple.com/documentation/avfoundation/photo-capture\#Photo-settings)

[`class AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)

A specification of the features and settings to use for a single photo capture request.

[`class AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings)

A specification of the features and settings to use for a photo capture request that captures multiple images with varied settings.

[`class AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings)

A description of the features and settings in use for an in-progress or complete photo capture request.

### [Matte data](https://developer.apple.com/documentation/avfoundation/photo-capture\#Matte-data)

[`class AVPortraitEffectsMatte`](https://developer.apple.com/documentation/avfoundation/avportraiteffectsmatte)

An auxiliary image used to separate foreground from background with high resolution.

[`class AVSemanticSegmentationMatte`](https://developer.apple.com/documentation/avfoundation/avsemanticsegmentationmatte)

An object that wraps a matting image for a particular semantic segmentation.

## [See Also](https://developer.apple.com/documentation/avfoundation/photo-capture\#see-also)

### [Capture](https://developer.apple.com/documentation/avfoundation/photo-capture\#Capture)

Configure built-in cameras and microphones, and external capture devices, for media capture.

Capture audio and video directly to media files, or capture streams of media for direct access to media sample buffers.

Capture additional data including depth and metadata, and synchronize capture from multiple outputs.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVContentKeyRequest

Class

# AVContentKeyRequest

An object that encapsulates information about a content decryption key request issued from a content key session object.

class AVContentKeyRequest

## [Topics](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#topics)

### [Getting Content Key Request Data](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#Getting-Content-Key-Request-Data)

Obtains encrypted key request data for a specific combination of app and content.

[`let AVContentKeyRequestProtocolVersionsKey: String`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequestprotocolversionskey)

A key that specifies the versions of the content protection protocol supported by the application.

[`let AVContentKeyRequestRequiresValidationDataInSecureTokenKey: String`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequestrequiresvalidationdatainsecuretokenkey)

A key that requires the secure token to have extended validation data.

### [Responding to the Content Key Request](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#Responding-to-the-Content-Key-Request)

[`func respondByRequestingPersistableContentKeyRequest()`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/respondbyrequestingpersistablecontentkeyrequest()-1ci4q)

Tells the receiver that the app requires a persistable content key request object for processing.

Deprecated

[`func processContentKeyResponse(AVContentKeyResponse)`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/processcontentkeyresponse(_:))

Sends the specified content key response to the receiver for processing.

[`func processContentKeyResponseError(any Error)`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/processcontentkeyresponseerror(_:))

Tells the receiver that the app was unable to obtain a content key response.

### [Getting Content Key Request Properties](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#Getting-Content-Key-Request-Properties)

[`var identifier: (any Sendable)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/identifier)

The identifier for the content key.

[`var canProvidePersistableContentKey: Bool`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/canprovidepersistablecontentkey)

The content key request used to create a persistable content key or respond to a previous request with a persistable content key.

[`var error: (any Error)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/error)

The error description for a failed key request.

[`var initializationData: Data?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/initializationdata)

The data used to obtain a key response.

[`var renewsExpiringResponseData: Bool`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/renewsexpiringresponsedata)

A Boolean value that indicates whether the content key request renews previously provided response data.

[`var status: AVContentKeyRequest.Status`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.property)

The current state of the content key request.

[`enum Status`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.enum)

The status for a content key request.

### [Inspecting a Request](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#Inspecting-a-Request)

[`var contentKey: AVContentKey?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/contentkey)

The generated content key.

[`var contentKeySpecifier: AVContentKeySpecifier`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/contentkeyspecifier)

The requested content key specifier.

[`var options: [String : any Sendable]`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/options)

A dictionary of options used to initialize key loading.

[`struct RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason)

The reason for asking the client to retry a content key request.

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#Instance-Properties)

[`var originatingRecipient: (any AVContentKeyRecipient)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/originatingrecipient)

The AVContentKeyRecipient which initiated this request, if any.

### [Instance Methods](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#Instance-Methods)

[`func respondByRequestingPersistableContentKeyRequestAndReturnError() throws`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/respondbyrequestingpersistablecontentkeyrequest()-7i2pw)

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#inherited-by)

- [`AVPersistableContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#see-also)

### [FairPlay Streaming](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest\#FairPlay-Streaming)

[`class AVContentKeySession`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession)

An object that creates and tracks decryption keys for media data.

[`protocol AVContentKeySessionDelegate`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)

A protocol that handles content key requests.

[`class AVContentKey`](https://developer.apple.com/documentation/avfoundation/avcontentkey)

An object that represents the content key decryptor.

[`class AVContentKeySpecifier`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier)

An object that uniquely identifies a content key.

[`class AVPersistableContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest)

An object that encapsulates information about a persistable content decryption key request issued from a content key session.

[`class AVContentKeyResponse`](https://developer.apple.com/documentation/avfoundation/avcontentkeyresponse)

An object that encapsulates information about a response to a content decryption key request.

[`enum AVExternalContentProtectionStatus`](https://developer.apple.com/documentation/avfoundation/avexternalcontentprotectionstatus)

Constants that specify whether sufficient protection exists to display the content.

Attaches a content key to a sample buffer for the purpose of content decryption.

---

# https://developer.apple.com/documentation/avfoundation/composite-assets

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Composite assets

API Collection

# Composite assets

Combine tracks and segments of tracks from multiple assets into a composite asset that you can play or process.

## [Topics](https://developer.apple.com/documentation/avfoundation/composite-assets\#topics)

### [Compositions](https://developer.apple.com/documentation/avfoundation/composite-assets\#Compositions)

[`class AVComposition`](https://developer.apple.com/documentation/avfoundation/avcomposition)

An object that combines and arranges media from multiple assets into a single composite asset that you can play or process.

[`class AVCompositionTrack`](https://developer.apple.com/documentation/avfoundation/avcompositiontrack)

A track in a composition that presents media of a uniform type.

[`class AVCompositionTrackSegment`](https://developer.apple.com/documentation/avfoundation/avcompositiontracksegment)

A track segment that maps a time from the source media track to the composition track.

### [Mutable compositions](https://developer.apple.com/documentation/avfoundation/composite-assets\#Mutable-compositions)

[`class AVMutableComposition`](https://developer.apple.com/documentation/avfoundation/avmutablecomposition)

An object that you use to create a new composition from existing assets.

[`class AVMutableCompositionTrack`](https://developer.apple.com/documentation/avfoundation/avmutablecompositiontrack)

A mutable track in a composition that you use to insert, remove, and scale track segments without affecting their low-level representation.

## [See Also](https://developer.apple.com/documentation/avfoundation/composite-assets\#see-also)

### [Editing](https://developer.apple.com/documentation/avfoundation/composite-assets\#Editing)

Access the contents of a QuickTime movie file, and perform sample-level edits of its media tracks.

Define standard video transition effects, synchronize layer animations with media timing, and create custom video compositors.

Define how to mix the audio levels from multiple audio tracks over an asset’s duration.

---

# https://developer.apple.com/documentation/avfoundation/audio-settings

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Audio settings

# Audio settings

Configure audio processing settings using standard key and value constants.

## [Topics](https://developer.apple.com/documentation/avfoundation/audio-settings\#topics)

### [Formats](https://developer.apple.com/documentation/avfoundation/audio-settings\#Formats)

[`class AVAudioFormat`](https://developer.apple.com/documentation/AVFAudio/AVAudioFormat)

An object that describes the representation of an audio format.

[`class AVAudioChannelLayout`](https://developer.apple.com/documentation/AVFAudio/AVAudioChannelLayout)

An object that describes the roles of a set of audio channels.

[`let AVChannelLayoutKey: String`](https://developer.apple.com/documentation/AVFAudio/AVChannelLayoutKey)

The audio settings that apply to linear PCM audio formats.

The audio settings that apply to all audio formats that the audio player and recorder classes support.

### [Settings](https://developer.apple.com/documentation/avfoundation/audio-settings\#Settings)

The constants that define sample rate converter audio quality settings.

[`enum AVAudioQuality`](https://developer.apple.com/documentation/AVFAudio/AVAudioQuality)

The values that specify the sample rate audio quality for encoding and conversion.

The constants that define the audio encoder settings for the audio recorder class.

The constants that define the values for the time pitch algorithms.

### [Constants](https://developer.apple.com/documentation/avfoundation/audio-settings\#Constants)

The constants that represent the possible bit rate strategy values.

[`var AVAUDIOENGINE_HAVE_AUAUDIOUNIT: Int32 { get }`](https://developer.apple.com/documentation/AVFAudio/AVAUDIOENGINE_HAVE_AUAUDIOUNIT)

## [See Also](https://developer.apple.com/documentation/avfoundation/audio-settings\#see-also)

### [Common](https://developer.apple.com/documentation/avfoundation/audio-settings\#Common)

Load media assets from files and streams to inspect their attributes, tracks, and embedded metadata.

Read images from video, export to alternative formats, and perform sample-level reading and writing of media data.

Identify the types of content and file formats that AVFoundation supports.

Configure video processing settings using standard key and value constants.

---

# https://developer.apple.com/documentation/avfoundation/avmetadatacatheadobject

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMetadataCatHeadObject Beta

Class

# AVMetadataCatHeadObject

class AVMetadataCatHeadObject

## [Overview](https://developer.apple.com/documentation/avfoundation/avmetadatacatheadobject\#overview)

AVMetadataCatHeadObject is a concrete subclass of AVMetadataObject representing a cat head.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmetadatacatheadobject\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmetadatacatheadobject\#inherits-from)

- [`AVMetadataObject`](https://developer.apple.com/documentation/avfoundation/avmetadataobject)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmetadatacatheadobject\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloader

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetResourceLoader

Class

# AVAssetResourceLoader

An object that mediates resource requests from a URL asset.

class AVAssetResourceLoader

## [Overview](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#overview)

You do not create resource loader objects yourself. Instead, you retrieve a resource loader from the [`resourceLoader`](https://developer.apple.com/documentation/avfoundation/avurlasset/resourceloader) property of an [`AVURLAsset`](https://developer.apple.com/documentation/avfoundation/avurlasset) object and use it to assign your custom delegate object.

The delegate you associate with this object must adopt the [`AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate) protocol. For more information, see [`AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate).

## [Topics](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#topics)

### [Accessing the Delegate](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#Accessing-the-Delegate)

[`func setDelegate((any AVAssetResourceLoaderDelegate)?, queue: dispatch_queue_t?)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader/setdelegate(_:queue:))

Sets the delegate and dispatch queue to use with the resource loader.

[`var delegate: (any AVAssetResourceLoaderDelegate)?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader/delegate)

The delegate object to use when handling resource requests.

[`protocol AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate)

Methods you can implement to handle resource-loading requests coming from a URL asset.

[`var delegateQueue: dispatch_queue_t?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader/delegatequeue)

The dispatch queue to use when handling resource requests.

### [Loading Content Keys](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#Loading-Content-Keys)

[`var preloadsEligibleContentKeys: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader/preloadseligiblecontentkeys)

A Boolean value that indicates whether content keys will be loaded as quickly as possible.

### [Supporting Common Media Client Data](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#Supporting-Common-Media-Client-Data)

[`var sendsCommonMediaClientDataAsHTTPHeaders: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader/sendscommonmediaclientdataashttpheaders)

A Boolean value that indicates whether to enable attaching Common Media Client Data as HTTP request headers.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#see-also)

### [Resource loading](https://developer.apple.com/documentation/avfoundation/avassetresourceloader\#Resource-loading)

[`class AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest)

An object that encapsulates information about a resource request from a resource loader object.

[`class AVAssetResourceRenewalRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourcerenewalrequest)

An object that encapsulates information about a resource request from a resource loader to renew a previously issued request.

[`class AVAssetResourceLoadingRequestor`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor)

An object that contains information about the originator of a resource-loading request.

[`class AVAssetResourceLoadingDataRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest)

An object for requesting data from a resource that an asset resource-loading request references.

[`class AVAssetResourceLoadingContentInformationRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest)

A query for retrieving essential information about a resource that an asset resource-loading request references.

---

# https://developer.apple.com/documentation/avfoundation/video-effects

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Video effects

API Collection

# Video effects

Define standard video transition effects, synchronize layer animations with media timing, and create custom video compositors.

## [Topics](https://developer.apple.com/documentation/avfoundation/video-effects\#topics)

### [Core Animation integration](https://developer.apple.com/documentation/avfoundation/video-effects\#Core-Animation-integration)

[`class AVVideoCompositionCoreAnimationTool`](https://developer.apple.com/documentation/avfoundation/avvideocompositioncoreanimationtool)

An object used to incorporate Core Animation into a video composition.

### [Built-in video compositing](https://developer.apple.com/documentation/avfoundation/video-effects\#Built-in-video-compositing)

[Editing and Playing HDR Video](https://developer.apple.com/documentation/avfoundation/editing-and-playing-hdr-video)

Support high-dynamic-range (HDR) video content in your app by using the HDR editing and playback capabilities of AVFoundation.

[Debugging AVFoundation audio mixes, compositions, and video compositions](https://developer.apple.com/documentation/avfoundation/debugging-avfoundation-audio-mixes-compositions-and-video-compositions)

Resolve common problems when creating compositions, video compositions, and audio mixes.

[`class AVVideoComposition`](https://developer.apple.com/documentation/avfoundation/avvideocomposition)

An object that describes how to compose video frames at particular points in time.

[`class AVMutableVideoComposition`](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition)

A mutable video composition subclass.

[`class AVVideoCompositionInstruction`](https://developer.apple.com/documentation/avfoundation/avvideocompositioninstruction-swift.class)

An operation that a compositor performs.

[`class AVMutableVideoCompositionInstruction`](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositioninstruction)

A mutable video composition instruction subclass.

[`class AVVideoCompositionLayerInstruction`](https://developer.apple.com/documentation/avfoundation/avvideocompositionlayerinstruction)

An object used to modify the transform, cropping, and opacity ramps applied to a given track in a composition.

[`class AVMutableVideoCompositionLayerInstruction`](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction)

An object used to modify the transform, cropping, and opacity ramps applied to a given track in a mutable composition.

### [Custom video compositing](https://developer.apple.com/documentation/avfoundation/video-effects\#Custom-video-compositing)

[`protocol AVVideoCompositing`](https://developer.apple.com/documentation/avfoundation/avvideocompositing)

A protocol that defines the methods custom video compositors must implement.

## [See Also](https://developer.apple.com/documentation/avfoundation/video-effects\#see-also)

### [Editing](https://developer.apple.com/documentation/avfoundation/video-effects\#Editing)

Combine tracks and segments of tracks from multiple assets into a composite asset that you can play or process.

Access the contents of a QuickTime movie file, and perform sample-level edits of its media tracks.

Define how to mix the audio levels from multiple audio tracks over an asset’s duration.

---

# https://developer.apple.com/documentation/avfoundation/avfoundation-macros

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Macros

API Collection

# Macros

## [Topics](https://developer.apple.com/documentation/avfoundation/avfoundation-macros\#topics)

### [Macros](https://developer.apple.com/documentation/avfoundation/avfoundation-macros\#Macros)

[`var AVF_DEPLOYING_TO_2022_RELEASES_AND_LATER: Int32`](https://developer.apple.com/documentation/avfoundation/avf_deploying_to_2022_releases_and_later)

---

# https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPersistableContentKeyRequest

Class

# AVPersistableContentKeyRequest

An object that encapsulates information about a persistable content decryption key request issued from a content key session.

class AVPersistableContentKeyRequest

## [Overview](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest\#overview)

This class allows clients to create and use persistable content keys.

## [Topics](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest\#topics)

### [Requesting Persistable Content Key Data](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest\#Requesting-Persistable-Content-Key-Data)

Creates a persistable content key from the content key context data.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest\#inherits-from)

- [`AVContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest\#see-also)

### [FairPlay Streaming](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest\#FairPlay-Streaming)

[`class AVContentKeySession`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession)

An object that creates and tracks decryption keys for media data.

[`protocol AVContentKeySessionDelegate`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)

A protocol that handles content key requests.

[`class AVContentKey`](https://developer.apple.com/documentation/avfoundation/avcontentkey)

An object that represents the content key decryptor.

[`class AVContentKeySpecifier`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier)

An object that uniquely identifies a content key.

[`class AVContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)

An object that encapsulates information about a content decryption key request issued from a content key session object.

[`class AVContentKeyResponse`](https://developer.apple.com/documentation/avfoundation/avcontentkeyresponse)

An object that encapsulates information about a response to a content decryption key request.

[`enum AVExternalContentProtectionStatus`](https://developer.apple.com/documentation/avfoundation/avexternalcontentprotectionstatus)

Constants that specify whether sufficient protection exists to display the content.

Attaches a content key to a sample buffer for the purpose of content decryption.

---

# https://developer.apple.com/documentation/avfoundation/quicktime-movies

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- QuickTime movies

API Collection

# QuickTime movies

Access the contents of a QuickTime movie file, and perform sample-level edits of its media tracks.

## [Topics](https://developer.apple.com/documentation/avfoundation/quicktime-movies\#topics)

### [Movies](https://developer.apple.com/documentation/avfoundation/quicktime-movies\#Movies)

[`class AVMovie`](https://developer.apple.com/documentation/avfoundation/avmovie)

An object that represents an audiovisual container that conforms to the QuickTime movie file format or a related format like MPEG-4.

[`class AVMovieTrack`](https://developer.apple.com/documentation/avfoundation/avmovietrack)

A track in a movie that conforms to the QuickTime or ISO base media file format.

### [Mutable movies](https://developer.apple.com/documentation/avfoundation/quicktime-movies\#Mutable-movies)

[`class AVMutableMovie`](https://developer.apple.com/documentation/avfoundation/avmutablemovie)

A mutable object that represents an audiovisual container that conforms to the QuickTime movie file format or a related format like MPEG-4.

[`class AVMutableMovieTrack`](https://developer.apple.com/documentation/avfoundation/avmutablemovietrack)

A mutable track that conforms to the QuickTime or ISO base media file format.

### [Fragmented movies](https://developer.apple.com/documentation/avfoundation/quicktime-movies\#Fragmented-movies)

[`class AVFragmentedMovie`](https://developer.apple.com/documentation/avfoundation/avfragmentedmovie)

An object that represents a fragmented movie file.

[`class AVFragmentedMovieTrack`](https://developer.apple.com/documentation/avfoundation/avfragmentedmovietrack)

An object that represents a track in a fragmented movie.

[`class AVFragmentedMovieMinder`](https://developer.apple.com/documentation/avfoundation/avfragmentedmovieminder)

An object that checks whether a fragmented movie appends additional movie fragments.

[`protocol AVFragmentMinding`](https://developer.apple.com/documentation/avfoundation/avfragmentminding)

A protocol that defines whether an asset supports fragment minding.

### [Sample cursors](https://developer.apple.com/documentation/avfoundation/quicktime-movies\#Sample-cursors)

[`class AVSampleCursor`](https://developer.apple.com/documentation/avfoundation/avsamplecursor)

An object that provides information about the media sample at the cursor’s current position.

[`struct AVSampleCursorSyncInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo)

A structure that describes the attributes of media samples to consider when resynchronizing a decoder.

[`struct AVSampleCursorDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo)

A value for describing dependencies between a media sample and other media samples in the same sample sequence.

[`struct AVSampleCursorAudioDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo)

A structure that describes the independent decodability of audio samples.

[`struct AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursorstoragerange)

A structure that indicates the offset and length of storage for a media sample or its chunk.

[`struct AVSampleCursorChunkInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorchunkinfo)

A value that provides information about a chunk of media samples.

### [Media data storage](https://developer.apple.com/documentation/avfoundation/quicktime-movies\#Media-data-storage)

[`class AVMediaDataStorage`](https://developer.apple.com/documentation/avfoundation/avmediadatastorage)

An object that represents the media sample data storage file.

## [See Also](https://developer.apple.com/documentation/avfoundation/quicktime-movies\#see-also)

### [Editing](https://developer.apple.com/documentation/avfoundation/quicktime-movies\#Editing)

Combine tracks and segments of tracks from multiple assets into a composite asset that you can play or process.

Define standard video transition effects, synchronize layer animations with media timing, and create custom video compositors.

Define how to mix the audio levels from multiple audio tracks over an asset’s duration.

---

# https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureSpatialAudioMetadataSampleGenerator Beta

Class

# AVCaptureSpatialAudioMetadataSampleGenerator

class AVCaptureSpatialAudioMetadataSampleGenerator

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator\#overview)

Defines an interface for generating a spatial audio timed metadata sample.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator\#topics)

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator\#Instance-Properties)

[`var timedMetadataSampleBufferFormatDescription: CMFormatDescription`](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator/timedmetadatasamplebufferformatdescription)

### [Instance Methods](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator\#Instance-Methods)

[`func resetAnalyzer()`](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator/resetanalyzer())

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturespatialaudiometadatasamplegenerator\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Streaming and AirPlay](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay)
- Implementing flexible enhanced buffering for your content

Article

# Implementing flexible enhanced buffering for your content

Configure your app for flexible enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.

## [Overview](https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content\#overview)

If you’re working with content that requires flexibility with buffering, use the [`AVSampleBufferAudioRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer) and [`AVSampleBufferRenderSynchronizer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer) classes.

To implement flexible enhanced buffering, complete the following steps.

1. Create a serialization queue to perform all playback operations on, and create the audio renderer and the render synchronizer to establish the media timeline.

let serializationQueue = DispatchQueue(label: "sample.buffer.player.serialization.queue")
let audioRenderer = AVSampleBufferAudioRenderer()
let renderSynchronizer = AVSampleBufferRenderSynchronizer()

2. Observe when the renderer has flushed enqueued audio, such as when the rate of playback increases or decreases, and re-enqueue audio data starting from the time the flush occurred.

automaticFlushObserver = NotificationCenter.default.addObserver(forName: .AVSampleBufferAudioRendererWasFlushedAutomatically,
object: audioRenderer,
queue: nil) { [weak self] notification in
self?.serializationQueue.async { [weak self] in
guard let self = self else { return }
// Restart from the point where the flush interrupts the audio.
let restartTime = (notification.userInfo?[AVSampleBufferAudioRendererFlushTimeKey] as? NSValue)?.timeValue
self.autoflushPlayback(restartingAt: restartTime)
}
}

3. Add the audio renderer to the render synchronizer, to tell the audio renderer to follow the media timeline.

renderSynchronizer.addRenderer(audioRenderer)

4. Tell the audio renderer to start processing audio data, and set the render synchronizer’s rate to `1` to start playback.

serializationQueue.async { [weak self] in
guard let self = self else { return }
// Start processing audio data and stop when there's no more data.
self.audioRenderer.requestMediaDataWhenReady(on: serializationQueue) { [weak self] in
guard let self = self else { return }
while self.audioRenderer.isReadyForMoreMediaData {
let sampleBuffer = self.nextSampleBuffer() // Returns nil at end of data.
if let sampleBuffer = sampleBuffer {
self.audioRenderer.enqueue(sampleBuffer)
} else {
// Tell the renderer to stop requesting audio data.
audioRenderer.stopRequestingMediaData()
}
}
}

// Start playback at the natural rate of the media.
self.renderSynchronizer.rate = 1.0
}

## [See Also](https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content\#see-also)

### [Buffered playback](https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content\#Buffered-playback)

[Implementing simple enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-simple-enhanced-buffering-for-your-content)

Configure your app for simple enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.

[Integrating AirPlay for Long-Form Video Apps](https://developer.apple.com/documentation/avfoundation/integrating-airplay-for-long-form-video-apps)

Integrate AirPlay features and implement a dedicated external playback experience by preparing the routing system for long-form video playback.

---

# https://developer.apple.com/documentation/avfoundation/avmetadatadogheadobject

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMetadataDogHeadObject Beta

Class

# AVMetadataDogHeadObject

class AVMetadataDogHeadObject

## [Overview](https://developer.apple.com/documentation/avfoundation/avmetadatadogheadobject\#overview)

AVMetadataDogHeadObject is a concrete subclass of AVMetadataObject representing a dog head.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmetadatadogheadobject\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmetadatadogheadobject\#inherits-from)

- [`AVMetadataObject`](https://developer.apple.com/documentation/avfoundation/avmetadataobject)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmetadatadogheadobject\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/speech-synthesis

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Speech synthesis

# Speech synthesis

Configure voices to speak strings of text.

## [Overview](https://developer.apple.com/documentation/avfoundation/speech-synthesis\#overview)

The Speech Synthesis framework manages voice and speech synthesis, and requires two primary tasks:

Create an [`AVSpeechUtterance`](https://developer.apple.com/documentation/AVFAudio/AVSpeechUtterance) instance that contains the text to speak. Optionally, configure speech parameters, such as voice and rate, for each utterance.

// Create an utterance.
let utterance = AVSpeechUtterance(string: "The quick brown fox jumped over the lazy dog.")

// Configure the utterance.
utterance.rate = 0.57
utterance.pitchMultiplier = 0.8
utterance.postUtteranceDelay = 0.2
utterance.volume = 0.8

// Retrieve the British English voice.
let voice = AVSpeechSynthesisVoice(language: "en-GB")

// Assign the voice to the utterance.
utterance.voice = voice

Pass the utterance to an [`AVSpeechSynthesizer`](https://developer.apple.com/documentation/AVFAudio/AVSpeechSynthesizer) instance to produce spoken audio.

// Create a speech synthesizer.
let synthesizer = AVSpeechSynthesizer()

// Tell the synthesizer to speak the utterance.
synthesizer.speak(utterance)

Optionally, use the speech synthesizer instance to control or respond to ongoing speech; for example, assign its [`delegate`](https://developer.apple.com/documentation/AVFAudio/AVSpeechSynthesizer/delegate) to receive speech event notifications.

## [Topics](https://developer.apple.com/documentation/avfoundation/speech-synthesis\#topics)

### [Spoken text attributes](https://developer.apple.com/documentation/avfoundation/speech-synthesis\#Spoken-text-attributes)

[`class AVSpeechUtterance`](https://developer.apple.com/documentation/AVFAudio/AVSpeechUtterance)

An object that encapsulates the text for speech synthesis and parameters that affect the speech.

[`class AVSpeechSynthesisVoice`](https://developer.apple.com/documentation/AVFAudio/AVSpeechSynthesisVoice)

A distinct voice for use in speech synthesis.

### [Speech synthesis controls](https://developer.apple.com/documentation/avfoundation/speech-synthesis\#Speech-synthesis-controls)

[`class AVSpeechSynthesizer`](https://developer.apple.com/documentation/AVFAudio/AVSpeechSynthesizer)

An object that produces synthesized speech from text utterances and enables monitoring or controlling of ongoing speech.

### [Speech synthesis audio unit](https://developer.apple.com/documentation/avfoundation/speech-synthesis\#Speech-synthesis-audio-unit)

[`class AVSpeechSynthesisProviderAudioUnit`](https://developer.apple.com/documentation/AVFAudio/AVSpeechSynthesisProviderAudioUnit)

An object that generates speech from text.

## [See Also](https://developer.apple.com/documentation/avfoundation/speech-synthesis\#see-also)

### [Audio](https://developer.apple.com/documentation/avfoundation/speech-synthesis\#Audio)

Play, record, and process audio; configure your app’s system audio behavior.

---

# https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMediaPresentationSetting Beta

Class

# AVMediaPresentationSetting

For content that has been authored with the express intent of offering an alternative selection interface for AVMediaSelectionOptions, AVMediaPresentationSetting represents a selectable setting for controlling the presentation of the media.

class AVMediaPresentationSetting

## [Overview](https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting\#overview)

Each selectable setting is associated with a media characteristic that one or more of the AVMediaSelectionOptions in the AVMediaSelectionGroup possesses. By selecting a setting in a user interface that offers AVMediaPresentationSettings, users are essentially indicating a preference for the media characteristic of the selected setting. Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.

## [Topics](https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting\#topics)

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting\#Instance-Properties)

[`var mediaCharacteristic: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting/mediacharacteristic)

Provides the media characteristic that corresponds to the selectable setting.

### [Instance Methods](https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting\#Instance-Methods)

Returns the display name for the selectable setting that best matches the specified locale identifier.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmediapresentationsetting\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVContentKeySpecifier

Class

# AVContentKeySpecifier

An object that uniquely identifies a content key.

class AVContentKeySpecifier

## [Topics](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier\#topics)

### [Creating a Specifier](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier\#Creating-a-Specifier)

[`init(forKeySystem: AVContentKeySystem, identifier: Any, options: [String : Any])`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier/init(forkeysystem:identifier:options:))

Creates a content key specifier.

### [Inspecting a Specifier](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier\#Inspecting-a-Specifier)

[`var identifier: any Sendable`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier/identifier)

The container and protocol-specific key identifier.

[`var keySystem: AVContentKeySystem`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier/keysystem)

The key system that generates content keys.

[`var options: [String : any Sendable]`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier/options)

A dictionary of options with which you initialized the specifier.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier\#see-also)

### [FairPlay Streaming](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier\#FairPlay-Streaming)

[`class AVContentKeySession`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession)

An object that creates and tracks decryption keys for media data.

[`protocol AVContentKeySessionDelegate`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)

A protocol that handles content key requests.

[`class AVContentKey`](https://developer.apple.com/documentation/avfoundation/avcontentkey)

An object that represents the content key decryptor.

[`class AVContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)

An object that encapsulates information about a content decryption key request issued from a content key session object.

[`class AVPersistableContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest)

An object that encapsulates information about a persistable content decryption key request issued from a content key session.

[`class AVContentKeyResponse`](https://developer.apple.com/documentation/avfoundation/avcontentkeyresponse)

An object that encapsulates information about a response to a content decryption key request.

[`enum AVExternalContentProtectionStatus`](https://developer.apple.com/documentation/avfoundation/avexternalcontentprotectionstatus)

Constants that specify whether sufficient protection exists to display the content.

Attaches a content key to a sample buffer for the purpose of content decryption.

---

# https://developer.apple.com/documentation/avfoundation/audio-playback-recording-and-processing

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Audio playback, recording, and processing

# Audio playback, recording, and processing

Play, record, and process audio; configure your app’s system audio behavior.

## [Topics](https://developer.apple.com/documentation/avfoundation/audio-playback-recording-and-processing\#topics)

### [System audio](https://developer.apple.com/documentation/avfoundation/audio-playback-recording-and-processing\#System-audio)

[Handling audio interruptions](https://developer.apple.com/documentation/AVFAudio/handling-audio-interruptions)

Observe audio session notifications to ensure that your app responds appropriately to interruptions.

[Responding to audio route changes](https://developer.apple.com/documentation/AVFAudio/responding-to-audio-route-changes)

Observe audio session notifications to ensure that your app responds appropriately to route changes.

[Capturing stereo audio from built-In microphones](https://developer.apple.com/documentation/AVFAudio/capturing-stereo-audio-from-built-in-microphones)

Configure an iOS device’s built-in microphones to add stereo recording capabilities to your app.

[`class AVAudioSession`](https://developer.apple.com/documentation/AVFAudio/AVAudioSession)

An object that communicates to the system how you intend to use audio in your app.

[`class AVAudioApplication`](https://developer.apple.com/documentation/AVFAudio/AVAudioApplication)

An object that manages one or more audio sessions that belong to an app.

[`class AVAudioRoutingArbiter`](https://developer.apple.com/documentation/AVFAudio/AVAudioRoutingArbiter)

An object for configuring macOS apps to participate in AirPods Automatic Switching.

### [Basic playback and recording](https://developer.apple.com/documentation/avfoundation/audio-playback-recording-and-processing\#Basic-playback-and-recording)

[`class AVAudioPlayer`](https://developer.apple.com/documentation/AVFAudio/AVAudioPlayer)

An object that plays audio data from a file or buffer.

[`class AVAudioRecorder`](https://developer.apple.com/documentation/AVFAudio/AVAudioRecorder)

An object that records audio data to a file.

[`class AVMIDIPlayer`](https://developer.apple.com/documentation/AVFAudio/AVMIDIPlayer)

An object that plays MIDI data through a system sound module.

### [Advanced audio processing](https://developer.apple.com/documentation/avfoundation/audio-playback-recording-and-processing\#Advanced-audio-processing)

[Audio Engine](https://developer.apple.com/documentation/AVFAudio/audio-engine)

Perform advanced real-time and offline audio processing, implement 3D spatialization, and work with MIDI and samplers.

## [See Also](https://developer.apple.com/documentation/avfoundation/audio-playback-recording-and-processing\#see-also)

### [Audio](https://developer.apple.com/documentation/avfoundation/audio-playback-recording-and-processing\#Audio)

Configure voices to speak strings of text.

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetResourceLoadingContentInformationRequest

Class

# AVAssetResourceLoadingContentInformationRequest

A query for retrieving essential information about a resource that an asset resource-loading request references.

class AVAssetResourceLoadingContentInformationRequest

## [Overview](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest\#overview)

When a resource loading delegate, which must implement the [`AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate) protocol, receives an instance of [`AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest) when the [`resourceLoader(_:shouldWaitForLoadingOfRequestedResource:)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)) is invoked and accepts responsibility for loading the resource, it must check whether the [`contentInformationRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/contentinformationrequest) property of the [`AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest) is not `nil`. Whenever the value is not `nil`, the request includes a query for the information that `AVAssetResourceLoadingContentInformationRequest` encapsulates. In response to such queries, the resource loading delegate should set the values of the content information request’s properties appropriately before invoking the [`AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest) method [`finishLoading()`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading()).

When [`finishLoading()`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading()) is invoked, the values of the properties of its [`contentInformationRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/contentinformationrequest) property will, in part, determine how the requested resource is processed. For example, if the requested resource’s URL is the URL of an [`AVURLAsset`](https://developer.apple.com/documentation/avfoundation/avurlasset) and [`contentType`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/contenttype) is set by the resource loading delegate to a value that the underlying media system doesn’t recognize as a supported media file type, operations on the `AVURLAsset`, such as playback, are likely to fail.

## [Topics](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest\#topics)

### [Configuring Content Information](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest\#Configuring-Content-Information)

[`var allowedContentTypes: [String]?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/allowedcontenttypes)

The types of data that are accepted as a valid response for the requested resource.

[`var contentType: String?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/contenttype)

The UTI that specifies the type of data contained by the requested resource.

[`var contentLength: Int64`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/contentlength)

The length, in bytes, of the requested resource.

[`var isByteRangeAccessSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/isbyterangeaccesssupported)

A Boolean value that indicates whether random access to arbitrary ranges of bytes of the resource is supported.

[`var renewalDate: Date?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/renewaldate)

The date at which a new resource loading request will be issued for resources that expire, if the media system still requires it.

[`var isEntireLengthAvailableOnDemand: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/isentirelengthavailableondemand)

A Boolean value that indicates whether asset data loading can expect data immediately.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest\#see-also)

### [Resource loading](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest\#Resource-loading)

[`class AVAssetResourceLoader`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader)

An object that mediates resource requests from a URL asset.

[`protocol AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate)

Methods you can implement to handle resource-loading requests coming from a URL asset.

[`class AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest)

An object that encapsulates information about a resource request from a resource loader object.

[`class AVAssetResourceRenewalRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourcerenewalrequest)

An object that encapsulates information about a resource request from a resource loader to renew a previously issued request.

[`class AVAssetResourceLoadingRequestor`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor)

An object that contains information about the originator of a resource-loading request.

[`class AVAssetResourceLoadingDataRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest)

An object for requesting data from a resource that an asset resource-loading request references.

---

# https://developer.apple.com/documentation/avfoundation/sample-buffer-playback

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Sample buffer playback

API Collection

# Sample buffer playback

Create custom controllers to play and synchronize the timing of sample buffer streams.

## [Topics](https://developer.apple.com/documentation/avfoundation/sample-buffer-playback\#topics)

### [Sample buffer generation](https://developer.apple.com/documentation/avfoundation/sample-buffer-playback\#Sample-buffer-generation)

[Playing custom audio with your own player](https://developer.apple.com/documentation/AVFAudio/playing-custom-audio-with-your-own-player)

Construct an audio player to play your custom audio data, and optionally take advantage of the advanced features of AirPlay 2.

[`class AVSampleBufferRequest`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrequest)

An object that describes a sample buffer creation request.

[`class AVSampleBufferGenerator`](https://developer.apple.com/documentation/avfoundation/avsamplebuffergenerator)

An object that creates sample buffers.

[`class AVSampleBufferGeneratorBatch`](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch)

An object that generates sample buffers in a batch.

### [Presentation](https://developer.apple.com/documentation/avfoundation/sample-buffer-playback\#Presentation)

[`protocol AVQueuedSampleBufferRendering`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrendering)

Methods you can implement to enqueue sample buffers for presentation.

[`class AVSampleBufferRenderSynchronizer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer)

An object used to synchronize multiple queued sample buffers to a single timeline.

[`class AVSampleBufferDisplayLayer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer)

An object that displays compressed or uncompressed video frames.

[`class AVSampleBufferVideoRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebuffervideorenderer)

An object that enqueues video sample buffers for rendering.

[`class AVSampleBufferAudioRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer)

An object used to decompress audio and play compressed or uncompressed audio.

## [See Also](https://developer.apple.com/documentation/avfoundation/sample-buffer-playback\#see-also)

### [Playback](https://developer.apple.com/documentation/avfoundation/sample-buffer-playback\#Playback)

Manage the playback of media assets and interstitial content, independent of how you present that content in your interface.

Download streamed content to disk to allow offline playback, and define policies to automatically remove downloaded assets.

Stream content wirelessly to other devices using AirPlay, and handle requests involving FairPlay-protected assets.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVContentKeySessionDelegate

Protocol

# AVContentKeySessionDelegate

A protocol that handles content key requests.

protocol AVContentKeySessionDelegate : NSObjectProtocol, Sendable

## [Topics](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate\#topics)

### [Providing New Content Key Requests](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate\#Providing-New-Content-Key-Requests)

[`func contentKeySession(AVContentKeySession, didProvide: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-3coq5)

Provides the receiver with a new content key request object.

**Required**

[`func contentKeySession(AVContentKeySession, didProvideRenewingContentKeyRequest: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didproviderenewingcontentkeyrequest:))

Provides the receiver with a new content key request object for the renewal of an existing content key.

[`func contentKeySession(AVContentKeySession, didProvide: AVPersistableContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-2wdgz)

Provides the receiver with a new content key request object to process a persistable content key.

### [Updating and Retrying Content Key Requests](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate\#Updating-and-Retrying-Content-Key-Requests)

[`func contentKeySession(AVContentKeySession, didProvide: [AVContentKeyRequest], forInitializationData: Data?)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:forinitializationdata:))

[`func contentKeySession(AVContentKeySession, externalProtectionStatusDidChangeFor: AVContentKey)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:externalprotectionstatusdidchangefor:))

Tells the delegate when external protection state has changed.

[`func contentKeySession(AVContentKeySession, didUpdatePersistableContentKey: Data, forContentKeyIdentifier: Any)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didupdatepersistablecontentkey:forcontentkeyidentifier:))

Provides the receiver with an updated persistable content key for a specific key request.

Provides the receiver with a content key request object to retry.

[`struct RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason)

The reason for asking the client to retry a content key request.

[`func contentKeySessionContentProtectionSessionIdentifierDidChange(AVContentKeySession)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysessioncontentprotectionsessionidentifierdidchange(_:))

Tells the receiver the content protection session identifier changed.

[`func contentKeySession(AVContentKeySession, contentKeyRequest: AVContentKeyRequest, didFailWithError: any Error)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:contentkeyrequest:didfailwitherror:))

Tells the receiver that the content key request failed.

[`func contentKeySession(AVContentKeySession, contentKeyRequestDidSucceed: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:contentkeyrequestdidsucceed:))

Tells the content key session that the response to a content key requeset was successfully processed.

[`func contentKeySessionDidGenerateExpiredSessionReport(AVContentKeySession)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysessiondidgenerateexpiredsessionreport(_:))

Notifies the sender that an expired session report has been generated.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate\#inherits-from)

- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate\#see-also)

### [FairPlay Streaming](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate\#FairPlay-Streaming)

[`class AVContentKeySession`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession)

An object that creates and tracks decryption keys for media data.

[`class AVContentKey`](https://developer.apple.com/documentation/avfoundation/avcontentkey)

An object that represents the content key decryptor.

[`class AVContentKeySpecifier`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier)

An object that uniquely identifies a content key.

[`class AVContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)

An object that encapsulates information about a content decryption key request issued from a content key session object.

[`class AVPersistableContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest)

An object that encapsulates information about a persistable content decryption key request issued from a content key session.

[`class AVContentKeyResponse`](https://developer.apple.com/documentation/avfoundation/avcontentkeyresponse)

An object that encapsulates information about a response to a content decryption key request.

[`enum AVExternalContentProtectionStatus`](https://developer.apple.com/documentation/avfoundation/avexternalcontentprotectionstatus)

Constants that specify whether sufficient protection exists to display the content.

Attaches a content key to a sample buffer for the purpose of content decryption.

---

# https://developer.apple.com/documentation/avfoundation/avciimagefilteringparameters

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCIImageFilteringParameters

Structure

# AVCIImageFilteringParameters

Mac Catalyst

struct AVCIImageFilteringParameters

## [Topics](https://developer.apple.com/documentation/avfoundation/avciimagefilteringparameters\#topics)

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avciimagefilteringparameters\#Instance-Properties)

[`let compositionTime: CMTime`](https://developer.apple.com/documentation/avfoundation/avciimagefilteringparameters/compositiontime)

The time in the video composition corresponding to the frame being processed.

[`let renderSize: CGSize`](https://developer.apple.com/documentation/avfoundation/avciimagefilteringparameters/rendersize)

The width and height, in pixels, of the frame being processed.

[`let sourceImage: CIImage`](https://developer.apple.com/documentation/avfoundation/avciimagefilteringparameters/sourceimage)

The current video frame image.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureSceneMonitoringStatus Beta

Structure

# AVCaptureSceneMonitoringStatus

struct AVCaptureSceneMonitoringStatus

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus\#overview)

Some features have certain requirements on the scene (lighting condition for Cinematic Video, for example) to produce optimal results; these AVCaptureSceneMonitoringStatus string constants are used to represent such scene statuses for a given feature.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus\#topics)

### [Initializers](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus\#Initializers)

[`init(rawValue: String)`](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus/init(rawvalue:))

### [Type Properties](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus\#Type-Properties)

[`static let notEnoughLight: AVCaptureSceneMonitoringStatus`](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus/notenoughlight)

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus\#conforms-to)

- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/capture-setup

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Capture setup

API Collection

# Capture setup

Configure built-in cameras and microphones, and external capture devices, for media capture.

## [Overview](https://developer.apple.com/documentation/avfoundation/capture-setup\#overview)

The AVFoundation Capture subsystem provides a common high-level architecture for video, photo, and audio capture services in iOS and macOS. Use this system if you want to:

- Build a custom camera UI to integrate shooting photos or videos into your app’s user experience.

- Give users more direct control over photo and video capture, such as focus, exposure, and stabilization options.

- Produce different results than the system camera UI, such as RAW format photos, depth maps, or videos with custom timed metadata.

- Get live access to pixel or audio data streaming directly from a capture device.

The main parts of the capture architecture are sessions, inputs, and outputs: Capture sessions connect one or more inputs to one or more outputs. Inputs are sources of media, including capture devices like the cameras and microphones built into an iOS device or Mac. Outputs acquire media from inputs to produce useful data, such as movie files written to disk or raw pixel buffers available for live processing.

## [Topics](https://developer.apple.com/documentation/avfoundation/capture-setup\#topics)

### [Essentials](https://developer.apple.com/documentation/avfoundation/capture-setup\#Essentials)

[Requesting authorization to capture and save media](https://developer.apple.com/documentation/avfoundation/requesting-authorization-to-capture-and-save-media)

Prompt the user to authorize access to the camera, microphone, and photo library.

### [Capture sessions](https://developer.apple.com/documentation/avfoundation/capture-setup\#Capture-sessions)

[Setting Up a Capture Session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session)

Configure input devices, output media, preview views, and basic settings before capturing photos or video.

[Accessing the camera while multitasking on iPad](https://developer.apple.com/documentation/AVKit/accessing-the-camera-while-multitasking-on-ipad)

Operate the camera in Split View, Slide Over, Picture in Picture, and Stage Manager modes.

[AVCam: Building a camera app](https://developer.apple.com/documentation/avfoundation/avcam-building-a-camera-app)

Capture photos and record video using the front and rear iPhone and iPad cameras.

[Capturing cinematic video](https://developer.apple.com/documentation/avfoundation/capturing-cinematic-video)

Capture video with an adjustable depth of field and focus points.

[AVMultiCamPiP: Capturing from Multiple Cameras](https://developer.apple.com/documentation/avfoundation/avmulticampip-capturing-from-multiple-cameras)

Simultaneously record the output from the front and back cameras into a single movie file by using a multi-camera capture session.

[AVCamBarcode: Detecting Barcodes and Faces](https://developer.apple.com/documentation/avfoundation/avcambarcode-detecting-barcodes-and-faces)

Identify machine readable codes or faces by using the camera.

[`class AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession)

An object that configures capture behavior and coordinates the flow of data from input devices to capture outputs.

[`class AVCaptureMultiCamSession`](https://developer.apple.com/documentation/avfoundation/avcapturemulticamsession)

A capture session that supports simultaneous capture from multiple inputs of the same media type.

[`class AVCaptureInput`](https://developer.apple.com/documentation/avfoundation/avcaptureinput)

An abstract superclass for objects that provide input data to a capture session.

[`class AVCaptureOutput`](https://developer.apple.com/documentation/avfoundation/avcaptureoutput)

An abstract superclass for objects that provide media output destinations for a capture session.

[`class AVCaptureConnection`](https://developer.apple.com/documentation/avfoundation/avcaptureconnection)

An object that represents a connection from a capture input to a capture output.

### [Capture devices](https://developer.apple.com/documentation/avfoundation/capture-setup\#Capture-devices)

[Choosing a Capture Device](https://developer.apple.com/documentation/avfoundation/choosing-a-capture-device)

Select the front or back camera, or use advanced features like the TrueDepth camera or dual camera.

[`class AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice)

An object that represents a hardware or virtual capture device like a camera or microphone.

[`class AVCaptureDeviceInput`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput)

An object that provides media input from a capture device to a capture session.

[`class AVContinuityDevice`](https://developer.apple.com/documentation/avfoundation/avcontinuitydevice)

A class that represents a physical iOS device that’s nearby and can provide access to its cameras and microphones.

[`class AVExternalStorageDevice`](https://developer.apple.com/documentation/avfoundation/avexternalstoragedevice)

Represents a physical external storage device that stores media assets.

[`class AVExternalStorageDeviceDiscoverySession`](https://developer.apple.com/documentation/avfoundation/avexternalstoragedevicediscoverysession)

Informs your app when the external storage devices connect to and disconnect from the system.

### [Capture preview](https://developer.apple.com/documentation/avfoundation/capture-setup\#Capture-preview)

[`class AVCaptureVideoPreviewLayer`](https://developer.apple.com/documentation/avfoundation/avcapturevideopreviewlayer)

A Core Animation layer that displays video from a camera device.

[`class AVCaptureAudioPreviewOutput`](https://developer.apple.com/documentation/avfoundation/avcaptureaudiopreviewoutput)

A capture output that provides a preview of the captured audio.

### [Continuity camera](https://developer.apple.com/documentation/avfoundation/capture-setup\#Continuity-camera)

[Supporting Continuity Camera in your tvOS app](https://developer.apple.com/documentation/AVKit/supporting-continuity-camera-in-your-tvos-app)

Capture high-quality photos, video, and audio in your Apple TV app by connecting an iPhone or iPad as a continuity device.

[Supporting Continuity Camera in your macOS app](https://developer.apple.com/documentation/avfoundation/supporting-continuity-camera-in-your-macos-app)

Enable high-quality photo and video capture by using an iPhone camera as an external capture device.

[`class AVCaptureDeskViewApplication`](https://developer.apple.com/documentation/avfoundation/avcapturedeskviewapplication)

An object that programmatically presents Desk View.

### [Capture controls](https://developer.apple.com/documentation/avfoundation/capture-setup\#Capture-controls)

[Enhancing your app experience with the Camera Control](https://developer.apple.com/documentation/avfoundation/enhancing-your-app-experience-with-the-camera-control)

Provide direct access to your camera app’s features to help people quickly capture the perfect shot.

[`class AVCaptureControl`](https://developer.apple.com/documentation/avfoundation/avcapturecontrol)

An abstract base class for controls that interact with the camera system.

[`class AVCaptureSystemZoomSlider`](https://developer.apple.com/documentation/avfoundation/avcapturesystemzoomslider)

A control that adjusts the video zoom factor of a capture device within the system-recommended range.

[`class AVCaptureSystemExposureBiasSlider`](https://developer.apple.com/documentation/avfoundation/avcapturesystemexposurebiasslider)

A control that adjusts the exposure bias of a capture device within the system-recommended range.

[`class AVCaptureSlider`](https://developer.apple.com/documentation/avfoundation/avcaptureslider)

A slider control that selects a value from a bounded range.

[`class AVCaptureIndexPicker`](https://developer.apple.com/documentation/avfoundation/avcaptureindexpicker)

A control for selecting from a set of mutually exclusive values by index.

## [See Also](https://developer.apple.com/documentation/avfoundation/capture-setup\#see-also)

### [Capture](https://developer.apple.com/documentation/avfoundation/capture-setup\#Capture)

Capture high-quality still images, Live Photos, and supporting photo data.

Capture audio and video directly to media files, or capture streams of media for direct access to media sample buffers.

Capture additional data including depth and metadata, and synchronize capture from multiple outputs.

---

# https://developer.apple.com/documentation/avfoundation/additional-data-capture

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Additional data capture

API Collection

# Additional data capture

Capture additional data including depth and metadata, and synchronize capture from multiple outputs.

## [Topics](https://developer.apple.com/documentation/avfoundation/additional-data-capture\#topics)

### [Depth data capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture\#Depth-data-capture)

[Capturing Photos with Depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)

Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).

[Creating Auxiliary Depth Data Manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)

Generate a depth image and attach it to your own image.

[Capturing depth using the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)

Access the LiDAR camera on supporting devices to capture precise depth data.

[AVCamFilter: Applying Filters to a Capture Stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)

Render a capture stream with rose-colored filtering and depth effects.

[Streaming Depth Data from the TrueDepth Camera](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)

Visualize depth data in 2D and 3D from the TrueDepth camera.

[Enhancing Live Video by Leveraging TrueDepth Camera Data](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)

Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.

[`class AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)

A capture output that records scene depth information on compatible camera devices.

[`class AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata)

A container for per-pixel distance or disparity information captured by compatible camera devices.

[`class AVCameraCalibrationData`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)

Information about the camera characteristics used to capture images and depth data.

### [Metadata capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture\#Metadata-capture)

[`class AVCaptureMetadataInput`](https://developer.apple.com/documentation/avfoundation/avcapturemetadatainput)

A capture input for providing timed metadata to a capture session.

[`class AVCaptureMetadataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturemetadataoutput)

A capture output for processing timed metadata produced by a capture session.

[`class AVMetadataObject`](https://developer.apple.com/documentation/avfoundation/avmetadataobject)

The abstract superclass for objects provided by a metadata capture output.

Inspect the supported metadata object types that the framework supports.

### [Synchronized capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture\#Synchronized-capture)

[`class AVCaptureDataOutputSynchronizer`](https://developer.apple.com/documentation/avfoundation/avcapturedataoutputsynchronizer)

An object that coordinates time-matched delivery of data from multiple capture outputs.

[`class AVCaptureSynchronizedDataCollection`](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddatacollection)

A set of data samples collected simultaneously from multiple capture outputs.

[`class AVCaptureSynchronizedSampleBufferData`](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizedsamplebufferdata)

A container for video or audio samples collected using synchronized capture.

[`class AVCaptureSynchronizedMetadataObjectData`](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizedmetadataobjectdata)

A container for metadata objects collected using synchronized capture.

[`class AVCaptureSynchronizedDepthData`](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddepthdata)

A container for scene depth information collected using synchronized capture.

[`class AVCaptureSynchronizedData`](https://developer.apple.com/documentation/avfoundation/avcapturesynchronizeddata)

The abstract superclass for media samples collected using synchronized capture.

## [See Also](https://developer.apple.com/documentation/avfoundation/additional-data-capture\#see-also)

### [Capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture\#Capture)

Configure built-in cameras and microphones, and external capture devices, for media capture.

Capture high-quality still images, Live Photos, and supporting photo data.

Capture audio and video directly to media files, or capture streams of media for direct access to media sample buffers.

---

# https://developer.apple.com/documentation/avfoundation/avfoundationerrordomain

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVFoundationErrorDomain

Global Variable

# AVFoundationErrorDomain

The error domain of AVFoundation errors.

let AVFoundationErrorDomain: String

## [See Also](https://developer.apple.com/documentation/avfoundation/avfoundationerrordomain\#see-also)

### [Errors](https://developer.apple.com/documentation/avfoundation/avfoundationerrordomain\#Errors)

[`struct AVError`](https://developer.apple.com/documentation/avfoundation/averror-swift.struct)

A structure that defines the errors that framework operations can generate.

---

# https://developer.apple.com/documentation/avfoundation/avciimagefilteringresult

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCIImageFilteringResult

Structure

# AVCIImageFilteringResult

An output video frame processed with Core Image filtering.

Mac Catalyst

struct AVCIImageFilteringResult

## [Topics](https://developer.apple.com/documentation/avfoundation/avciimagefilteringresult\#topics)

### [Initializers](https://developer.apple.com/documentation/avfoundation/avciimagefilteringresult\#Initializers)

[`init(resultImage: CIImage, ciContext: CIContext?)`](https://developer.apple.com/documentation/avfoundation/avciimagefilteringresult/init(resultimage:cicontext:))

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avciimagefilteringresult\#Instance-Properties)

[`let ciContext: CIContext?`](https://developer.apple.com/documentation/avfoundation/avciimagefilteringresult/cicontext)

The core image context used to render the image

[`let resultImage: CIImage`](https://developer.apple.com/documentation/avfoundation/avciimagefilteringresult/resultimage)

Provides the filtered video frame image to AVFoundation for further processing or display.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMetricDownloadSummaryEvent

Class

# AVMetricDownloadSummaryEvent

Represents a summary metric event with aggregated metrics for the entire download task.

class AVMetricDownloadSummaryEvent

## [Overview](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent\#overview)

Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.

## [Topics](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent\#topics)

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent\#Instance-Properties)

[`var bytesDownloadedCount: Int`](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent/bytesdownloadedcount)

Returns the total number of bytes downloaded by the download task.

[`var downloadDuration: TimeInterval`](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent/downloadduration)

Returns the total duration of the download in seconds.

[`var errorEvent: AVMetricErrorEvent?`](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent/errorevent)

Returns the error event if any. If no value is available, returns nil.

[`var mediaResourceRequestCount: Int`](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent/mediaresourcerequestcount)

Returns the total number of media requests performed by the download task. This includes playlist requests, media segment requests, and content key requests.

[`var recoverableErrorCount: Int`](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent/recoverableerrorcount)

Returns the total count of recoverable errors encountered during the download. If no errors were encountered, returns 0.

[`var variants: [AVAssetVariant]`](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent/variants)

Returns the variants that were downloaded.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent\#inherits-from)

- [`AVMetricEvent`](https://developer.apple.com/documentation/avfoundation/avmetricevent)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCoding`](https://developer.apple.com/documentation/Foundation/NSCoding)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`NSSecureCoding`](https://developer.apple.com/documentation/Foundation/NSSecureCoding)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequestrandomdeviceidentifierseedkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVContentKeyRequestRandomDeviceIdentifierSeedKey Beta

Global Variable

# AVContentKeyRequestRandomDeviceIdentifierSeedKey

Value is an NSData containing a 16-byte seed to randomize the user’s deviceID contained in the SPC blob during FairPlay key exchange

let AVContentKeyRequestRandomDeviceIdentifierSeedKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequestrandomdeviceidentifierseedkey\#discussion)

This property must be used in conjunction with AVContentKeyRequestShouldRandomizeDeviceIdentifierKey. Use a RND function to generate a 16 byte seed. This seed will be used to randomize the user’s anonymized device ID if AVContentKeyRequestShouldRandomizeDeviceIdentifierKey is true. Content providers use the SPC to distinguish the playback device from other devices, typically to enforce per-screen business rule limits. If the app developer, in cooperation with the content vendor, does not require to distinguish the playback device, they can further enhance user privacy by making this identifier non-constant, using this option. In either case, apps are not allowed to store or use the FairPlay anonymized device ID for anything other than to enforce business rule limits. App developers must use the AppTrackingTransparency framework to disclose to users if the application or the related FairPlay Key Server collect data about end users and share it with other companies for purposes of tracking across apps and web sites.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlaybackCoordinationMedium

Class

# AVPlaybackCoordinationMedium

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

class AVPlaybackCoordinationMedium

## [Topics](https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium\#topics)

### [Initializers](https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium\#Initializers)

[`init()`](https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium/init())

Initializes an AVPlaybackCoordinationMedium

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium\#Instance-Properties)

[`var connectedPlaybackCoordinators: [AVPlayerPlaybackCoordinator]`](https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium/connectedplaybackcoordinators)

All playback coordinators that are connected to the coordination medium.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avplaybackcoordinationmedium\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

---

# https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCustomMediaSelectionScheme Beta

Class

# AVCustomMediaSelectionScheme

For content that has been authored with the express intent of offering an alternative selection interface for AVMediaSelectionOptions, AVCustomMediaSelectionScheme provides a collection of custom settings for controlling the presentation of the media.

class AVCustomMediaSelectionScheme

## [Overview](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme\#overview)

Each selectable setting is associated with a media characteristic that one or more of the AVMediaSelectionOptions in the AVMediaSelectionGroup possesses. By selecting a setting in a user interface based on an AVCustomMediaSelectionScheme, users are essentially indicating a preference for the media characteristic of the selected setting. Selection of a specific AVMediaSelectionOption in the AVMediaSelectionGroup is then derived from the user’s indicated preferences. Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme\#topics)

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme\#Instance-Properties)

[`var availableLanguages: [String]`](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme/availablelanguages)

Provides available language choices.

[`var selectors: [AVMediaPresentationSelector]`](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme/selectors)

Provides custom settings.

[`var shouldOfferLanguageSelection: Bool`](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme/shouldofferlanguageselection)

Indicates whether an alternative selection interface should provide a menu of language choices.

### [Instance Methods](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme\#Instance-Methods)

Provides an array of media presentation settings that can be effective at the same time as the specified language and settings for other selectors of the receiver.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avassetexportpresethevc4320x2160

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetExportPresetHEVC4320x2160 Beta

Global Variable

# AVAssetExportPresetHEVC4320x2160

let AVAssetExportPresetHEVC4320x2160: String

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorcurrenteventskippablestatedidchangeeventkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeEventKey Beta

Global Variable

# AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeEventKey

The dictionary key for the AVPlayerInterstitial event that had its skippable event state changed in the payload of the AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeNotification.

let AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeEventKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorcurrenteventskippablestatedidchangeeventkey\#discussion)

The value corresponding to this key is of type AVPlayerInterstitialEvent.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorinterstitialeventdidfinisheventkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerInterstitialEventMonitorInterstitialEventDidFinishEventKey Beta

Global Variable

# AVPlayerInterstitialEventMonitorInterstitialEventDidFinishEventKey

The dictionary key for the AVPlayerInterstitialEvent that finished playing in the payload of the AVPlayerInterstitialEventMonitorInterstitialEventDidFinishNotification.

let AVPlayerInterstitialEventMonitorInterstitialEventDidFinishEventKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorinterstitialeventdidfinisheventkey\#discussion)

The value corresponding to this key is of type AVPlayerInterstitialEvent.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorcurrenteventskippablestatedidchangestatekey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeStateKey Beta

Global Variable

# AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeStateKey

The dictionary key for the skippable event state in the payload of the AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeNotification.

let AVPlayerInterstitialEventMonitorCurrentEventSkippableStateDidChangeStateKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorcurrenteventskippablestatedidchangestatekey\#discussion)

The value corresponding to this key is an NSNumber containing type AVPlayerInterstitialEventSkippableEventState.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequestshouldrandomizedeviceidentifierkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVContentKeyRequestShouldRandomizeDeviceIdentifierKey Beta

Global Variable

# AVContentKeyRequestShouldRandomizeDeviceIdentifierKey

Value is an Boolean indicating whether the user’s deviceID contained in the SPC blob during FairPlay key exchange should be randomized using a system generated seed

let AVContentKeyRequestShouldRandomizeDeviceIdentifierKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequestshouldrandomizedeviceidentifierkey\#discussion)

Content providers use the SPC to distinguish the playback device from other devices, typically to enforce per-screen business rule limits. If the app developer, in cooperation with the content vendor, does not require to distinguish the playback device, they can further enhance user privacy by making this identifier non-constant, using this option. In either case, apps are not allowed to store or use the FairPlay anonymized device ID for anything other than to enforce business rule limits. App developers must use the AppTrackingTransparency framework to disclose to users if the application or the related FairPlay Key Server collect data about end users and share it with other companies for purposes of tracking across apps and web sites. When true, the system generates a random seed with which the device id will be randomized. To override the seed used; use this property in conjunction with AVContentKeyRequestRandomDeviceIdentifierSeedKey to provide a seed generated by your application.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorinterstitialeventwasunscheduledeventkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerInterstitialEventMonitorInterstitialEventWasUnscheduledEventKey Beta

Global Variable

# AVPlayerInterstitialEventMonitorInterstitialEventWasUnscheduledEventKey

The dictionary key for the AVPlayerInterstitialEvent that was unscheduled in the payload of the AVPlayerInterstitialEventMonitorInterstitialEventWasUnscheduledNotification.

let AVPlayerInterstitialEventMonitorInterstitialEventWasUnscheduledEventKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorinterstitialeventwasunscheduledeventkey\#discussion)

The value corresponding to this key is of type AVPlayerInterstitialEvent.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorinterstitialeventdidfinishplayouttimekey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerInterstitialEventMonitorInterstitialEventDidFinishPlayoutTimeKey Beta

Global Variable

# AVPlayerInterstitialEventMonitorInterstitialEventDidFinishPlayoutTimeKey

The dictionary key for the playout time of the event that finished playing in the payload of the AVPlayerInterstitialEventMonitorInterstitialEventDidFinishNotification.

let AVPlayerInterstitialEventMonitorInterstitialEventDidFinishPlayoutTimeKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorinterstitialeventdidfinishplayouttimekey\#discussion)

The value corresponding to this key is of type CMTime as a NSDictionary.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorinterstitialeventdidfinishdidplayentireeventkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerInterstitialEventMonitorInterstitialEventDidFinishDidPlayEntireEventKey Beta

Global Variable

# AVPlayerInterstitialEventMonitorInterstitialEventDidFinishDidPlayEntireEventKey

The dictionary key to indicate whether the event that finished playing was fully played out in the payload of the AVPlayerInterstitialEventMonitorInterstitialEventDidFinishNotification.

let AVPlayerInterstitialEventMonitorInterstitialEventDidFinishDidPlayEntireEventKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorinterstitialeventdidfinishdidplayentireeventkey\#discussion)

The value corresponding to this key is of type NSNumber with a BOOL value.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/audio-mixing

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Audio mixing

API Collection

# Audio mixing

Define how to mix the audio levels from multiple audio tracks over an asset’s duration.

## [Topics](https://developer.apple.com/documentation/avfoundation/audio-mixing\#topics)

### [Mixing](https://developer.apple.com/documentation/avfoundation/audio-mixing\#Mixing)

[`class AVAudioMix`](https://developer.apple.com/documentation/avfoundation/avaudiomix)

An object that manages the input parameters for mixing audio tracks.

[`class AVMutableAudioMix`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomix)

[`class AVAudioMixInputParameters`](https://developer.apple.com/documentation/avfoundation/avaudiomixinputparameters)

An object that represents the parameters that you apply when adding an audio track to a mix.

[`class AVMutableAudioMixInputParameters`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters)

The parameters you use when adding an audio track to a mix.

## [See Also](https://developer.apple.com/documentation/avfoundation/audio-mixing\#see-also)

### [Editing](https://developer.apple.com/documentation/avfoundation/audio-mixing\#Editing)

Combine tracks and segments of tracks from multiple assets into a composite asset that you can play or process.

Access the contents of a QuickTime movie file, and perform sample-level edits of its media tracks.

Define standard video transition effects, synchronize layer animations with media timing, and create custom video compositors.

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetResourceLoadingRequestor

Class

# AVAssetResourceLoadingRequestor

An object that contains information about the originator of a resource-loading request.

class AVAssetResourceLoadingRequestor

## [Topics](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor\#topics)

### [Retrieving Expired Session Reports](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor\#Retrieving-Expired-Session-Reports)

[`var providesExpiredSessionReports: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor/providesexpiredsessionreports)

A Boolean value that indicates whether the requestor provides expired session reports.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor\#see-also)

### [Resource loading](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor\#Resource-loading)

[`class AVAssetResourceLoader`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader)

An object that mediates resource requests from a URL asset.

[`protocol AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate)

Methods you can implement to handle resource-loading requests coming from a URL asset.

[`class AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest)

An object that encapsulates information about a resource request from a resource loader object.

[`class AVAssetResourceRenewalRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourcerenewalrequest)

An object that encapsulates information about a resource request from a resource loader to renew a previously issued request.

[`class AVAssetResourceLoadingDataRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest)

An object for requesting data from a resource that an asset resource-loading request references.

[`class AVAssetResourceLoadingContentInformationRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest)

A query for retrieving essential information about a resource that an asset resource-loading request references.

---

# https://developer.apple.com/documentation/avfoundation/avassetexportpresetmvhevc7680x7680

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetExportPresetMVHEVC7680x7680 Beta

Global Variable

# AVAssetExportPresetMVHEVC7680x7680

let AVAssetExportPresetMVHEVC7680x7680: String

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/integrating-airplay-for-long-form-video-apps

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Streaming and AirPlay](https://developer.apple.com/documentation/avfoundation/streaming-and-airplay)
- Integrating AirPlay for Long-Form Video Apps

Sample Code

# Integrating AirPlay for Long-Form Video Apps

Integrate AirPlay features and implement a dedicated external playback experience by preparing the routing system for long-form video playback.

[Download](https://docs-assets.developer.apple.com/published/a687ba227f31/IntegratingAirPlayForLongFormVideoApps.zip)

Xcode 11.0+

## [Overview](https://developer.apple.com/documentation/avfoundation/integrating-airplay-for-long-form-video-apps\#Overview)

## [See Also](https://developer.apple.com/documentation/avfoundation/integrating-airplay-for-long-form-video-apps\#see-also)

### [Buffered playback](https://developer.apple.com/documentation/avfoundation/integrating-airplay-for-long-form-video-apps\#Buffered-playback)

[Implementing simple enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-simple-enhanced-buffering-for-your-content)

Configure your app for simple enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.

[Implementing flexible enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content)

Configure your app for flexible enhanced buffering to stream content faster to AirPlay-enabled devices and supported CarPlay vehicles.

---

# https://developer.apple.com/documentation/avfoundation/avassetexportpresetmvhevc4320x4320

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetExportPresetMVHEVC4320x4320 Beta

Global Variable

# AVAssetExportPresetMVHEVC4320x4320

let AVAssetExportPresetMVHEVC4320x4320: String

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
- Capturing consistent color images

Sample Code

# Capturing consistent color images

Add the power of a photography studio and lighting rig to your app with the new Constant Color API.

[Download](https://docs-assets.developer.apple.com/published/abe78d7af292/CapturingConsistentColorImages.zip)

Xcode 16.0+

## [Overview](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images\#Overview)

### [Configure the sample code project](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images\#Configure-the-sample-code-project)

Run this sample code on a device that provides the required flash module, such as the following:

- iPhone 14 or later

- iPhone 14 Pro or later

- iPad Pro 11-inch (M4) or later

- iPad Pro 13-inch (M4) or later

## [See Also](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images\#see-also)

### [Photo capture](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images\#Photo-capture)

Configure and capture single or multiple still images, Live Photos, and other forms of photography.

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

Support professional photography workflows by enabling minimally processed image capture in your camera app.

[Supporting Continuity Camera in Your Mac App](https://developer.apple.com/documentation/AppKit/supporting-continuity-camera-in-your-mac-app)

Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.

[`class AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto)

A container for image data from a photo capture output.

[`class AVCaptureDeferredPhotoProxy`](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy)

A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.

[`class AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)

A capture output for still image, Live Photos, and other photography workflows.

[`protocol AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)

Methods for monitoring progress and receiving results from a photo capture output.

[`class AVCapturePhotoOutputReadinessCoordinator`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinator)

An object that monitors changes to a photo output’s capture readiness.

[`protocol AVCapturePhotoOutputReadinessCoordinatorDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinatordelegate)

A delegate protocol to receive updates about a photo output’s capture readiness.

[`class AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput)

A capture output for capturing still photos.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/media-reading-and-writing

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Media reading and writing

API Collection

# Media reading and writing

Read images from video, export to alternative formats, and perform sample-level reading and writing of media data.

## [Topics](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing\#topics)

### [Media export](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing\#Media-export)

[Exporting video to alternative formats](https://developer.apple.com/documentation/avfoundation/exporting-video-to-alternative-formats)

Convert an existing movie file to a different format.

[`class AVAssetExportSession`](https://developer.apple.com/documentation/avfoundation/avassetexportsession)

An object that exports assets in a format that you specify using an export preset.

### [Image generation](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing\#Image-generation)

[Creating images from a video asset](https://developer.apple.com/documentation/avfoundation/creating-images-from-a-video-asset)

Display images for specific times within the media timeline by generating images from a video’s frames.

[`class AVAssetImageGenerator`](https://developer.apple.com/documentation/avfoundation/avassetimagegenerator)

An object that generates images from a video asset.

### [Media reading](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing\#Media-reading)

[Reading multiview 3D video files](https://developer.apple.com/documentation/avfoundation/reading-multiview-3d-video-files)

Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.

[`class AVAssetReader`](https://developer.apple.com/documentation/avfoundation/avassetreader)

An object that reads media data from an asset.

[`class AVAssetReaderOutput`](https://developer.apple.com/documentation/avfoundation/avassetreaderoutput)

An abstract class that defines the interface to read media samples from an asset reader.

[`class AVAssetReaderTrackOutput`](https://developer.apple.com/documentation/avfoundation/avassetreadertrackoutput)

An object that reads media data from a single track of an asset.

[`class AVAssetReaderAudioMixOutput`](https://developer.apple.com/documentation/avfoundation/avassetreaderaudiomixoutput)

An object that reads audio samples that result from mixing audio from one or more tracks.

[`class AVAssetReaderVideoCompositionOutput`](https://developer.apple.com/documentation/avfoundation/avassetreadervideocompositionoutput)

An object that reads composited video frames from one or more tracks of an asset.

[`class AVAssetReaderSampleReferenceOutput`](https://developer.apple.com/documentation/avfoundation/avassetreadersamplereferenceoutput)

An object that reads sample references from an asset track.

[`class AVAssetReaderOutputMetadataAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetreaderoutputmetadataadaptor)

An object that creates timed metadata group objects for an asset track.

### [Media writing](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing\#Media-writing)

[Converting projected video to Apple Projected Media Profile](https://developer.apple.com/documentation/avfoundation/converting-projected-video-to-apple-projected-media-profile)

Convert content with equirectangular or half-equirectangular projection to APMP.

[Converting side-by-side 3D video to multiview HEVC and spatial video](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video)

Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.

[Writing Fragmented MPEG-4 Files for HTTP Live Streaming](https://developer.apple.com/documentation/avfoundation/writing-fragmented-mpeg-4-files-for-http-live-streaming)

Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.

[Creating spatial photos and videos with spatial metadata](https://developer.apple.com/documentation/ImageIO/Creating-spatial-photos-and-videos-with-spatial-metadata)

Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.

[Tagging Media with Video Color Information](https://developer.apple.com/documentation/avfoundation/tagging-media-with-video-color-information)

Inspect and set video color space information when writing and transcoding media.

Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.

[`class AVOutputSettingsAssistant`](https://developer.apple.com/documentation/avfoundation/avoutputsettingsassistant)

An object that builds audio and video output settings dictionaries.

[`class AVAssetWriter`](https://developer.apple.com/documentation/avfoundation/avassetwriter)

An object that writes media data to a container file.

[`class AVAssetWriterInput`](https://developer.apple.com/documentation/avfoundation/avassetwriterinput)

An object that appends media samples to a track in an asset writer’s output file.

[`class AVAssetWriterInputPixelBufferAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputpixelbufferadaptor)

An object that appends video samples to an asset writer input.

[`class AVAssetWriterInputTaggedPixelBufferGroupAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputtaggedpixelbuffergroupadaptor)

An object that appends tagged buffer groups to an asset writer input.

[`class AVAssetWriterInputMetadataAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor)

An object that appends timed metadata groups to an asset writer input.

[`class AVAssetWriterInputGroup`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputgroup)

A group of inputs with tracks that are mutually exclusive to each other for playback or processing.

### [Captions](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing\#Captions)

Create captions and subtitles in industry-standard formats.

## [See Also](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing\#see-also)

### [Common](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing\#Common)

Load media assets from files and streams to inspect their attributes, tracks, and embedded metadata.

Identify the types of content and file formats that AVFoundation supports.

Configure video processing settings using standard key and value constants.

Configure audio processing settings using standard key and value constants.

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetResourceLoadingDataRequest

Class

# AVAssetResourceLoadingDataRequest

An object for requesting data from a resource that an asset resource-loading request references.

class AVAssetResourceLoadingDataRequest

## [Overview](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest\#overview)

The [`AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate) uses the `AVAssetResourceLoadingDataRequest` class to do the actual data reading, and its methods will be invoked, as necessary, to acquire data for the [`AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest) instance.

When the resource loading delegate, which implements the [`AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate) protocol, receives an instance of [`AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest) as the second parameter of the delegate’s [`resourceLoader(_:shouldWaitForLoadingOfRequestedResource:)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)) method, it has the option of accepting responsibility for loading the referenced resource. If it accepts that responsibility, by returning [`true`](https://developer.apple.com/documentation/swift/true), it must check whether the [`dataRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/datarequest) property of the [`AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest) instance is not `nil`. If it is not `nil`, the resource loading delegate is informed of the range of bytes within the resource that are required by the underlying media system. In response, the data is provided by one or more invocations of [`respond(with:)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest/respond(with:)) as required to provide the requested data. The data can be provided in increments determined by the resource loading delegate according to convenience or efficiency.

When the [`AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest) method [`finishLoading()`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading()) is invoked, the data request is considered fully satisfied. If the entire range of bytes requested has not yet been provided, the underlying media system assumes that the resource’s length is limited to the provided content.

## [Topics](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest\#topics)

### [Providing Data to a Request](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest\#Providing-Data-to-a-Request)

[`func respond(with: Data)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest/respond(with:))

Provides data to the loading request.

[`var requestedLength: Int`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest/requestedlength)

The length, in bytes, of the data requested.

[`var requestedOffset: Int64`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest/requestedoffset)

The position within the resource of the first byte requested.

[`var currentOffset: Int64`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest/currentoffset)

The position within the resource of the next byte.

[`var requestsAllDataToEndOfResource: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest/requestsalldatatoendofresource)

A Boolean value that indicates the entire remaining length of the resource from the offest to the end of the resource is being requested.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest\#see-also)

### [Resource loading](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest\#Resource-loading)

[`class AVAssetResourceLoader`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader)

An object that mediates resource requests from a URL asset.

[`protocol AVAssetResourceLoaderDelegate`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate)

Methods you can implement to handle resource-loading requests coming from a URL asset.

[`class AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest)

An object that encapsulates information about a resource request from a resource loader object.

[`class AVAssetResourceRenewalRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourcerenewalrequest)

An object that encapsulates information about a resource request from a resource loader to renew a previously issued request.

[`class AVAssetResourceLoadingRequestor`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor)

An object that contains information about the originator of a resource-loading request.

[`class AVAssetResourceLoadingContentInformationRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest)

A query for retrieving essential information about a resource that an asset resource-loading request references.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysession

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVContentKeySession

Class

# AVContentKeySession

An object that creates and tracks decryption keys for media data.

class AVContentKeySession

## [Topics](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#topics)

### [Creating a Session](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#Creating-a-Session)

[`convenience init(keySystem: AVContentKeySystem)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/init(keysystem:))

Creates a content key session to manage a collection of content decryption keys.

[`convenience init(keySystem: AVContentKeySystem, storageDirectoryAt: URL)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/init(keysystem:storagedirectoryat:))

Creates a content key session to manage a collection of content decryption keys; points to a directory that stores abnormal session termination reports.

### [Inspecting the Session](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#Inspecting-the-Session)

[`var keySystem: AVContentKeySystem`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/keysystem)

The type of key system used to retrieve keys.

[`struct AVContentKeySystem`](https://developer.apple.com/documentation/avfoundation/avcontentkeysystem)

A key-delivery method for a content key session.

[`var storageURL: URL?`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/storageurl)

A URL that points to a writable storage directory.

### [Managing the Delegate Object](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#Managing-the-Delegate-Object)

[`func setDelegate((any AVContentKeySessionDelegate)?, queue: dispatch_queue_t?)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/setdelegate(_:queue:))

Sets the session’s delegate object and the dispatch queue on which to call the delegate’s methods.

[`var delegate: (any AVContentKeySessionDelegate)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/delegate)

The content key session’s delegate object.

[`var delegateQueue: dispatch_queue_t?`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/delegatequeue)

The dispatch queue the session uses to invoke delegate callbacks.

### [Managing Content Key Recipients](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#Managing-Content-Key-Recipients)

[`var contentKeyRecipients: [any AVContentKeyRecipient]`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/contentkeyrecipients)

An array of content key recipients.

[`protocol AVContentKeyRecipient`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrecipient)

A protocol for requiring decryption keys for media data.

[`func addContentKeyRecipient(any AVContentKeyRecipient)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/addcontentkeyrecipient(_:))

Tells the delegate that the specified recipient should have access to the decryption keys loaded with the session.

[`func removeContentKeyRecipient(any AVContentKeyRecipient)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/removecontentkeyrecipient(_:))

Tells the delegate to remove the specified recipient.

### [Processing Requests](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#Processing-Requests)

[`func processContentKeyRequest(withIdentifier: (any Sendable)?, initializationData: Data?, options: [String : any Sendable]?)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/processcontentkeyrequest(withidentifier:initializationdata:options:))

Tells the delegate to start loading the content decryption key with the specified identifier and initialization data.

### [Managing Expiration](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#Managing-Expiration)

[`func expire()`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/expire())

Tells the delegate that the session expired as the result of normal, intentional processes.

Creates a secure server playback context that the client sends to the key server to get an expiration date for the given persistable content key data.

[`func renewExpiringResponseData(for: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/renewexpiringresponsedata(for:))

Tells the delegate that previously provided response data for a content key request is about to expire.

[`var contentProtectionSessionIdentifier: Data?`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/contentprotectionsessionidentifier)

The identifier for the current content protection session.

### [Invalidating Content Keys](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#Invalidating-Content-Keys)

Invalidates the persistable content key and creates a secure server playback context (SPC) to verify the outcome of an invalidation request.

Invalidates all of an app’s persistable content keys and creates a secure server playback context (SPC) to verify the outcome of an invalidation request.

[`struct AVContentKeySessionServerPlaybackContextOption`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption)

Options for specifying additional information for generating server playback context (SPC).

### [Handling Expired Session Reports](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#Handling-Expired-Session-Reports)

Returns the expired session reports for content key sessions created with the specified app identifier.

[`class func removePendingExpiredSessionReports([Data], withAppIdentifier: Data, storageDirectoryAt: URL)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/removependingexpiredsessionreports(_:withappidentifier:storagedirectoryat:))

Removes expired session reports from storage.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#see-also)

### [FairPlay Streaming](https://developer.apple.com/documentation/avfoundation/avcontentkeysession\#FairPlay-Streaming)

[`protocol AVContentKeySessionDelegate`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)

A protocol that handles content key requests.

[`class AVContentKey`](https://developer.apple.com/documentation/avfoundation/avcontentkey)

An object that represents the content key decryptor.

[`class AVContentKeySpecifier`](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier)

An object that uniquely identifies a content key.

[`class AVContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)

An object that encapsulates information about a content decryption key request issued from a content key session object.

[`class AVPersistableContentKeyRequest`](https://developer.apple.com/documentation/avfoundation/avpersistablecontentkeyrequest)

An object that encapsulates information about a persistable content decryption key request issued from a content key session.

[`class AVContentKeyResponse`](https://developer.apple.com/documentation/avfoundation/avcontentkeyresponse)

An object that encapsulates information about a response to a content decryption key request.

[`enum AVExternalContentProtectionStatus`](https://developer.apple.com/documentation/avfoundation/avexternalcontentprotectionstatus)

Constants that specify whether sufficient protection exists to display the content.

Attaches a content key to a sample buffer for the purpose of content decryption.

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetResourceLoaderDelegate

Protocol

# AVAssetResourceLoaderDelegate

Methods you can implement to handle resource-loading requests coming from a URL asset.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

protocol AVAssetResourceLoaderDelegate : NSObjectProtocol

## [Overview](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate\#overview)

A class should adopt this protocol when associated with the asset’s resource loader—that is, an instance of the [`AVAssetResourceLoader`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader) class. The resource loader works with your delegate to process the request.

## [Topics](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate\#topics)

### [Processing Resource Requests](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate\#Processing-Resource-Requests)

Asks the delegate if it wants to load the requested resource.

Tells the delegate when assistance is required of the application to renew a resource.

[`func resourceLoader(AVAssetResourceLoader, didCancel: AVAssetResourceLoadingRequest)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:didcancel:)-3nl51)

Informs the delegate that a prior loading request has been cancelled.

### [Processing Authentication Challenges](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate\#Processing-Authentication-Challenges)

Tells the delegate that assistance is required of the application to respond to an authentication challenge.

[`func resourceLoader(AVAssetResourceLoader, didCancel: URLAuthenticationChallenge)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:didcancel:)-1wqin)

Informs the delegate that a prior authentication challenge has been cancelled.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate\#inherits-from)

- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate\#see-also)

### [Resource loading](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate\#Resource-loading)

[`class AVAssetResourceLoader`](https://developer.apple.com/documentation/avfoundation/avassetresourceloader)

An object that mediates resource requests from a URL asset.

[`class AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest)

An object that encapsulates information about a resource request from a resource loader object.

[`class AVAssetResourceRenewalRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourcerenewalrequest)

An object that encapsulates information about a resource request from a resource loader to renew a previously issued request.

[`class AVAssetResourceLoadingRequestor`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequestor)

An object that contains information about the originator of a resource-loading request.

[`class AVAssetResourceLoadingDataRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingdatarequest)

An object for requesting data from a resource that an asset resource-loading request references.

[`class AVAssetResourceLoadingContentInformationRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest)

A query for retrieving essential information about a resource that an asset resource-loading request references.

---

# https://developer.apple.com/documentation/avfoundation/avurlassettrack-4rdw0

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVURLAssetTrack

Type Alias

# AVURLAssetTrack

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

typealias AVURLAssetTrack = AVAssetTrack

---

# https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
- Capturing Photos in RAW and Apple ProRAW Formats

Article

# Capturing Photos in RAW and Apple ProRAW Formats

Support professional photography workflows by enabling minimally processed image capture in your camera app.

## [Overview](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats\#overview)

By default, the image-capture pipeline uses advanced computational photography techniques to achieve the highest quality images, and delivers the processed result to your app in a compressed format for efficient storage and display. Processed formats are a great choice in many cases, but RAW formats contain minimally processed image data from the camera sensor, which gives your app users more creative control.

Capturing images in RAW formats results in much larger files than compressed formats, but greatly expands editing capabilities in post-production. One draw

To determine whether your app’s photo output supports the Apple ProRAW format in the current environment, add the output to a capture session that has a connected video source, and query its [`isAppleProRAWSupported`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isappleprorawsupported) property. If the current environment supports the Apple ProRAW format, you can enable the photo output to use it by setting its [`isAppleProRAWEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isappleprorawenabled) property to [`true`](https://developer.apple.com/documentation/swift/true) as the example below shows:

private let captureSession = AVCaptureSession()
private let photoOutput = AVCapturePhotoOutput()

private func setupSession() throws {

// Start the capture session configuration.
captureSession.beginConfiguration()

// Configure the session for photo capture.
captureSession.sessionPreset = .photo

// Connect the default video device.
let videoInput = try AVCaptureDeviceInput(device: defaultVideoDevice)
if captureSession.canAddInput(videoInput) {
captureSession.addInput(videoInput)
currentVideoInput = videoInput
} else {
throw CameraError.setupFailed
}

// Connect and configure the capture output.
if captureSession.canAddOutput(photoOutput) {
captureSession.addOutput(photoOutput)

// Use the Apple ProRAW format when the environment supports it.
photoOutput.isAppleProRAWEnabled = photoOutput.isAppleProRAWSupported
} else {
throw CameraError.setupFailed
}

// Session configuration is complete. Commit the configuration.
captureSession.commitConfiguration()
}

Enabling use of the Apple ProRAW format adds an entry to the photo output’s [`availableRawPhotoPixelFormatTypes`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablerawphotopixelformattypes-5fatm) array. You can determine whether a particular format in the array is an Apple ProRAW or a Bayer RAW format by querying the output’s [`isAppleProRAWPixelFormat(_:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isappleprorawpixelformat(_:)) or [`isBayerRAWPixelFormat(_:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isbayerrawpixelformat(_:)) methods.

### [Capture RAW and Apple ProRAW Photos](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats\#Capture-RAW-and-Apple-ProRAW-Photos)

Capturing photos in RAW and Apple ProRAW formats requires only minor changes to the basic photography workflow in [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos). Begin by creating an [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object that specifies the RAW format to capture, and optionally, a processed format to capture if your app supports creating RAW+JPEG files. The capture pipeline only supports the RAW formats in the photo output’s [`availableRawPhotoPixelFormatTypes`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablerawphotopixelformattypes-5fatm) array.

The example below finds the appropriate RAW format, choosing the Apple ProRAW format when it’s in an enabled state, and the Bayer RAW format when it’s not. It creates a photo settings object that specifies the RAW and processed formats, and a delegate object to monitor the capture progress. Finally, it calls the photo output’s [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method, passing it the photo settings and delegate objects.

let query = photoOutput.isAppleProRAWEnabled ?
{ AVCapturePhotoOutput.isAppleProRAWPixelFormat($0) } :
{ AVCapturePhotoOutput.isBayerRAWPixelFormat($0) }

// Retrieve the RAW format, favoring the Apple ProRAW format when it's in an enabled state.
guard let rawFormat =
photoOutput.availableRawPhotoPixelFormatTypes.first(where: query) else {
fatalError("No RAW format found.")
}

// Capture a RAW format photo, along with a processed format photo.
let processedFormat = [AVVideoCodecKey: AVVideoCodecType.hevc]
let photoSettings = AVCapturePhotoSettings(rawPixelFormatType: rawFormat,
processedFormat: processedFormat)

// Create a delegate to monitor the capture process.
let delegate = RAWCaptureDelegate()
captureDelegates[photoSettings.uniqueID] = delegate

// Remove the delegate reference when it finishes its processing.
delegate.didFinish = {
self.captureDelegates[photoSettings.uniqueID] = nil
}

// Tell the output to capture the photo.
photoOutput.capturePhoto(with: photoSettings, delegate: delegate)

The Apple ProRAW format supports capturing up to a full-resolution JPEG image to use as a thumbnail photo. Set [`rawEmbeddedThumbnailPhotoFormat`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawembeddedthumbnailphotoformat) on your photo settings object as the following example shows:

// Select the first available codec type, which is JPEG.
guard let thumbnailPhotoCodecType =
photoSettings.availableRawEmbeddedThumbnailPhotoCodecTypes.first else {
// Handle the failure to find an available thumbnail photo codec type.
}

// Select the maximum photo dimensions as thumbnail dimensions if a full-size thumbnail is desired.
// The system clamps these dimensions to the photo dimensions if the capture produces a photo with smaller than maximum dimensions.
let dimensions = photoSettings.maxPhotoDimensions

photoSettings.rawEmbeddedThumbnailPhotoFormat = [\
AVVideoCodecKey: thumbnailPhotoCodecType,\
AVVideoWidthKey: dimensions.width,\
AVVideoHeightKey: dimensions.height\
]

### [Handle the Captured Photos](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats\#Handle-the-Captured-Photos)

The photo output calls its delegate’s [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method at least once for each format you request, and possibly additional times, depending on your capture settings. Using the capture settings in the previous section results in the photo output calling this delegate method twice: once for the RAW or Apple ProRAW image, and again for the processed image. In each invocation, get the photo’s file data by calling its [`fileDataRepresentation()`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation()) method and store it as necessary. If you call this method on a RAW or Apple ProRAW photo, it returns the data in the industry-standard DNG file format. If you call it on processed images, it returns the compressed bitmap image data.

The following code shows an example implementation of the [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method. It writes the RAW file to disk and stores a reference to the processed photo’s compressed bitmap data for later use.

class RAWCaptureDelegate: NSObject, AVCapturePhotoCaptureDelegate {

private var rawFileURL: URL?
private var compressedData: Data?

// Store the RAW file and compressed photo data until the capture finishes.
func photoOutput(_ output: AVCapturePhotoOutput,
didFinishProcessingPhoto photo: AVCapturePhoto,
error: Error?) {

guard error == nil else {
print("Error capturing photo: \(error!)")
return
}

// Access the file data representation of this photo.
guard let photoData = photo.fileDataRepresentation() else {
print("No photo data to write.")
return
}

if photo.isRawPhoto {
// Generate a unique URL to write the RAW file.
rawFileURL = makeUniqueDNGFileURL()
do {
// Write the RAW (DNG) file data to a URL.
try photoData.write(to: rawFileURL!)
} catch {
fatalError("Couldn't write DNG file to the URL.")
}
} else {
// Store compressed bitmap data.
compressedData = photoData
}
}

let tempDir = FileManager.default.temporaryDirectory
let fileName = ProcessInfo.processInfo.globallyUniqueString
return tempDir.appendingPathComponent(fileName).appendingPathExtension("dng")
}
}

### [Customize the Apple ProRAW Output](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats\#Customize-the-Apple-ProRAW-Output)

By default, when you ask for the file data representation of an Apple ProRAW photo, you get the data in full lossless quality. If you’re willing to accept some lossy compression to achieve smaller file sizes, you can customize the compression settings by calling [`fileDataRepresentation(with:)`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation(with:)) and passing it a custom object that conforms to the [`AVCapturePhotoFileDataRepresentationCustomizer`](https://developer.apple.com/documentation/avfoundation/avcapturephotofiledatarepresentationcustomizer) protocol. The following code shows an example implementation of this protocol that applies minimal compression to the output image:

class AppleProRAWCustomizer: NSObject, AVCapturePhotoFileDataRepresentationCustomizer {

// Customize the compression settings.
func replacementAppleProRAWCompressionSettings(for photo: AVCapturePhoto,
defaultSettings: [String : Any],

// Reduce the bit depth and quality of the final file.
return [AVVideoAppleProRAWBitDepthKey: maximumBitDepth - 2,\
AVVideoQualityKey: 0.95]
}
}

To use this customizer when retrieving the file data representation of a ProRAW photo, create a new instance of your customizer and pass it to the [`fileDataRepresentation(with:)`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation(with:)) method as the example below shows:

// Get a minimally compressed representation of the file data.
let customizer = AppleProRAWCustomizer()
let photoData = photo.fileDataRepresentation(with: customizer)

### [Save the Photos to the Photos Library](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats\#Save-the-Photos-to-the-Photos-Library)

The photo output indicates when it finishes the capture request by calling the delegate’s [`photoOutput(_:didFinishCaptureFor:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:)) method. This callback provides an opportunity to save the captured photos to the user’s Photos library. For more information about configuring your app to access the user’s Photos library, see [Saving Captured Photos](https://developer.apple.com/documentation/avfoundation/saving-captured-photos).

To save the captured photos to the user’s Photos library, create a single Photos asset that associates the RAW or Apple ProRAW data with the processed data. Create an instance of [`PHAssetCreationRequest`](https://developer.apple.com/documentation/Photos/PHAssetCreationRequest), then specify the DNG version as the asset’s main [`PHAssetResourceType.photo`](https://developer.apple.com/documentation/Photos/PHAssetResourceType/photo) resource, and the processed image as an [`PHAssetResourceType.alternatePhoto`](https://developer.apple.com/documentation/Photos/PHAssetResourceType/alternatePhoto) resource. Perform the request inside a change block as the example below shows:

// After both RAW and compressed versions are complete, add them to the Photos library.
func photoOutput(_ output: AVCapturePhotoOutput,
didFinishCaptureFor resolvedSettings: AVCaptureResolvedPhotoSettings,
error: Error?) {

// Call the "finished" closure, if you set it.
defer { didFinish?() }

guard error == nil else {
print("Error capturing photo: \(error!)")
return
}

// Ensure the RAW and processed photo data exists.
guard let rawFileURL = rawFileURL,
let compressedData = compressedData else {
print("The expected photo data isn't available.")
return
}

// Request add-only access to the user's Photos library (if the user hasn't already granted that access).
PHPhotoLibrary.requestAuthorization(for: .addOnly) { status in

// Don't continue unless the user granted access.
guard status == .authorized else { return }

PHPhotoLibrary.shared().performChanges {

let creationRequest = PHAssetCreationRequest.forAsset()

// Save the RAW (DNG) file as the main resource for the Photos asset.
let options = PHAssetResourceCreationOptions()
options.shouldMoveFile = true
creationRequest.addResource(with: .photo,
fileURL: rawFileURL,
options: options)

// Add the compressed (HEIF) data as an alternative resource.
creationRequest.addResource(with: .alternatePhoto,
data: compressedData,
options: nil)

} completionHandler: { success, error in
// Process the Photos library error.
}
}
}

## [See Also](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats\#see-also)

### [Photo capture](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats\#Photo-capture)

[Capturing consistent color images](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images)

Add the power of a photography studio and lighting rig to your app with the new Constant Color API.

Configure and capture single or multiple still images, Live Photos, and other forms of photography.

[Supporting Continuity Camera in Your Mac App](https://developer.apple.com/documentation/AppKit/supporting-continuity-camera-in-your-mac-app)

Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.

[`class AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto)

A container for image data from a photo capture output.

[`class AVCaptureDeferredPhotoProxy`](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy)

A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.

[`class AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)

A capture output for still image, Live Photos, and other photography workflows.

[`protocol AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)

Methods for monitoring progress and receiving results from a photo capture output.

[`class AVCapturePhotoOutputReadinessCoordinator`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinator)

An object that monitors changes to a photo output’s capture readiness.

[`protocol AVCapturePhotoOutputReadinessCoordinatorDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinatordelegate)

A delegate protocol to receive updates about a photo output’s capture readiness.

[`class AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput)

A capture output for capturing still photos.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorcurrenteventskippedeventkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerInterstitialEventMonitorCurrentEventSkippedEventKey Beta

Global Variable

# AVPlayerInterstitialEventMonitorCurrentEventSkippedEventKey

The dictionary key for the AVPlayerInterstitialEvent that was skipped in the payload of the AVPlayerInterstitialEventMonitorCurrentEventSkippedNotification.

let AVPlayerInterstitialEventMonitorCurrentEventSkippedEventKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerinterstitialeventmonitorcurrenteventskippedeventkey\#discussion)

The value corresponding to this key is of type AVPlayerInterstitialEvent.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Additional data capture](https://developer.apple.com/documentation/avfoundation/additional-data-capture)
- Capturing Photos with Depth

Article

# Capturing Photos with Depth

Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).

## [Overview](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth\#overview)

On iOS devices with a back-facing dual camera or a front-facing TrueDepth camera, the capture system can record depth information. A depth map is like an image; however, instead of each pixel providing a color, it indicates distance from the camera to that part of the image (either in absolute terms, or relative to other pixels in the depth map).

You can use a depth map together with a photo to create image-processing effects that treat foreground and background elements of a photo differently, like the Portrait mode in the iOS Camera app. By saving color and depth data separately, you can even apply and change these effects long after a photo has been captured.

You can add depth capture to many of the other photography workflows covered in [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos) by adding the following steps.

### [Prepare for Depth Photo Capture](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth\#Prepare-for-Depth-Photo-Capture)

To capture depth maps, you’ll need to first select a [`builtInDualCamera`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/devicetype-swift.struct/builtindualcamera) or [`builtInTrueDepthCamera`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/devicetype-swift.struct/builtintruedepthcamera) capture device as your session’s video input. Even if an iOS device has a dual camera or TrueDepth camera, selecting the default back- or front-facing camera doesn’t enable depth capture.

Capturing depth also requires an internal reconfiguration of the capture pipeline, briefly delaying capture and interrupting any in-progress captures. Before shooting your first depth photo, make sure you configure the pipeline appropriately by enabling depth capture on your [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) object.

// Select a depth-capable capture device.
guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera,
for: .video, position: .unspecified)
else { fatalError("No dual camera.") }
guard let videoDeviceInput = try? AVCaptureDeviceInput(device: videoDevice),
self.captureSession.canAddInput(videoDeviceInput)
else { fatalError("Can't add video input.") }
self.captureSession.beginConfiguration()
self.captureSession.addInput(videoDeviceInput)

// Set up photo output for depth data capture.
let photoOutput = AVCapturePhotoOutput()
guard self.captureSession.canAddOutput(photoOutput)
else { fatalError("Can't add photo output.") }
self.captureSession.addOutput(photoOutput)
self.captureSession.sessionPreset = .photo
// Enable delivery of depth data after adding the output to the capture session.
photoOutput.isDepthDataDeliveryEnabled = photoOutput.isDepthDataDeliverySupported
self.captureSession.commitConfiguration()

### [Choose Settings](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth\#Choose-Settings)

Once your photo output is ready for depth capture, you can request that any individual photos capture a depth map along with the color image. Create an [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object, choosing the format for the color image. Then, enable depth capture and depth output (and any other settings you’d like for that photo) and call the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method.

let photoSettings = AVCapturePhotoSettings(format: [AVVideoCodecKey: AVVideoCodecType.hevc])
photoSettings.isDepthDataDeliveryEnabled = photoOutput.isDepthDataDeliverySupported

// Shoot the photo, using a custom class to handle capture delegate callbacks.
let captureProcessor = PhotoCaptureProcessor()
photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)

### [Handle Results](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth\#Handle-Results)

After a capture, the photo output calls your delegate’s [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method, providing the photo and captured depth data as an [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object.

If you plan to use the captured depth data immediately—for example, to display a preview of a depth-based image processing effect—you can find it in the photo object’s [`depthData`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/depthdata) property.

Otherwise, the capture output embeds depth data and depth-related metadata when you use the [`fileDataRepresentation()`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation()) method to produce file data for saving the photo. If you add the resulting file to the Photos library, other apps (including the system Photos app) automatically recognize the depth data within and can apply depth-based image processing effects. (If you need to disable this option, see the [`embedsDepthDataInPhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedsdepthdatainphoto) setting).

### [About Disparity, Depth, and Accuracy](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth\#About-Disparity-Depth-and-Accuracy)

When you enable depth capture with the back-facing dual camera on compatible devices (see [iOS Device Compatibility Reference](https://developer.apple.com/library/archive/documentation/DeviceInformation/Reference/iOSDeviceCompatibility/Introduction/Introduction.html#//apple_ref/doc/uid/TP40013599)), the system captures imagery using both cameras. Because the two parallel cameras are a small distance apart on the back of the device, similar features found in both images show a parallax shift: objects that are closer to the camera shift by a greater distance between the two images. The capture system uses this difference, or _disparity_, to infer the relative distances from the camera to objects in the image, as shown below.

Each point in a depth map captured by a dual camera device measures disparity units of 1/meters, and offers [`AVDepthData.Accuracy.relative`](https://developer.apple.com/documentation/avfoundation/avdepthdata/accuracy/relative) accuracy. An individual point isn’t a good estimate of real-world distance, but the variation between points is consistent enough to use for depth-based image processing effects.

The TrueDepth camera projects an infrared light pattern in front of the camera and images that pattern with an infrared camera. By observing how objects in the scene distorts the pattern, the capture system can calculate the distance rom the camera to each point in the image.

The TrueDepth camera produces disparity maps by default so that the resulting depth data is similar to that produced by a dual camera device. However, unlike a dual camera device, the TrueDepth camera can directly measure depth (in meters) with [`AVDepthData.Accuracy.absolute`](https://developer.apple.com/documentation/avfoundation/avdepthdata/accuracy/absolute) accuracy. To capture depth instead of disparity, set the [`activeDepthDataFormat`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activedepthdataformat) of the capture device before starting your capture session:

// Select a depth (not disparity) format that works with the active color format.
let availableFormats = captureDevice.activeFormat.supportedDepthDataFormats

let depthFormat = availableFormats.filter { format in
let pixelFormatType =
CMFormatDescriptionGetMediaSubType(format.formatDescription)

return (pixelFormatType == kCVPixelFormatType_DepthFloat16 ||
pixelFormatType == kCVPixelFormatType_DepthFloat32)
}.first

// Set the capture device to use that depth format.
captureSession.beginConfiguration()
captureDevice.activeDepthDataFormat = depthFormat
captureSession.commitConfiguration()

## [See Also](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth\#see-also)

### [Depth data capture](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth\#Depth-data-capture)

[Creating Auxiliary Depth Data Manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)

Generate a depth image and attach it to your own image.

[Capturing depth using the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)

Access the LiDAR camera on supporting devices to capture precise depth data.

[AVCamFilter: Applying Filters to a Capture Stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)

Render a capture stream with rose-colored filtering and depth effects.

[Streaming Depth Data from the TrueDepth Camera](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)

Visualize depth data in 2D and 3D from the TrueDepth camera.

[Enhancing Live Video by Leveraging TrueDepth Camera Data](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)

Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.

[`class AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)

A capture output that records scene depth information on compatible camera devices.

[`class AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata)

A container for per-pixel distance or disparity information captured by compatible camera devices.

[`class AVCameraCalibrationData`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)

Information about the camera characteristics used to capture images and depth data.

---

# https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureCameraLensSmudgeDetectionStatus Beta

Enumeration

# AVCaptureCameraLensSmudgeDetectionStatus

enum AVCaptureCameraLensSmudgeDetectionStatus

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus\#overview)

Constants indicating the current camera lens smudge detection status.

Indicates that the detection is not enabled.

Indicates that the most recent detection identifies smudge is not detected on camera lens.

Indicates that the most recent detection identifies camera lens is smudged.

Indicates that the detection result hasn’t settled, commonly caused by excessive camera movement or the content of image.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus\#topics)

### [Enumeration Cases](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus\#Enumeration-Cases)

[`case disabled`](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus/disabled)

[`case smudgeNotDetected`](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus/smudgenotdetected)

[`case smudged`](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus/smudged)

[`case unknown`](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus/unknown)

### [Initializers](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus\#Initializers)

[`init?(rawValue: Int)`](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus/init(rawvalue:))

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturecameralenssmudgedetectionstatus\#conforms-to)

- [`BitwiseCopyable`](https://developer.apple.com/documentation/Swift/BitwiseCopyable)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureDeferredPhotoProxy

Class

# AVCaptureDeferredPhotoProxy

A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.

class AVCaptureDeferredPhotoProxy

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy\#overview)

A photo proxy behaves like a normal [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto), and approximates the look of the final rendered image. This object represents intermediate data that the system can render into a final image and ingested into the user’s photo library using the [PhotoKit](https://developer.apple.com/documentation/PhotoKit) framework. The intermediate data aren’t accessible by the calling process.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy\#inherits-from)

- [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy\#see-also)

### [Photo capture](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy\#Photo-capture)

[Capturing consistent color images](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images)

Add the power of a photography studio and lighting rig to your app with the new Constant Color API.

Configure and capture single or multiple still images, Live Photos, and other forms of photography.

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

Support professional photography workflows by enabling minimally processed image capture in your camera app.

[Supporting Continuity Camera in Your Mac App](https://developer.apple.com/documentation/AppKit/supporting-continuity-camera-in-your-mac-app)

Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.

[`class AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto)

A container for image data from a photo capture output.

[`class AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)

A capture output for still image, Live Photos, and other photography workflows.

[`protocol AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)

Methods for monitoring progress and receiving results from a photo capture output.

[`class AVCapturePhotoOutputReadinessCoordinator`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinator)

An object that monitors changes to a photo output’s capture readiness.

[`protocol AVCapturePhotoOutputReadinessCoordinatorDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinatordelegate)

A delegate protocol to receive updates about a photo output’s capture readiness.

[`class AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput)

A capture output for capturing still photos.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/saving-captured-photos

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
- [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos)
- Saving Captured Photos

Article

# Saving Captured Photos

Add an image and other data from a photo capture to the photo library.

## [Overview](https://developer.apple.com/documentation/avfoundation/saving-captured-photos\#overview)

When you complete a photo capture with [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput), you receive an [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object that contains the image data, camera metadata, and any auxiliary images you requested, such as thumbnails or depth maps. You can retrieve this data individually from the [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object. Or you can call its [`fileDataRepresentation()`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation()) method to get a [`Data`](https://developer.apple.com/documentation/Foundation/Data) object that’s ready to save using the codec and file format you requested for that photo in [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings).

After capturing a photo, use [PhotoKit](https://developer.apple.com/documentation/PhotoKit) to add that data to the user’s photo library.

### [Configure properties and capabilities for your app targets](https://developer.apple.com/documentation/avfoundation/saving-captured-photos\#Configure-properties-and-capabilities-for-your-app-targets)

You can use [PhotoKit](https://developer.apple.com/documentation/PhotoKit) to enable read/write access to the user’s photo library. To do so, provide a static message for the [`NSPhotoLibraryUsageDescription`](https://developer.apple.com/documentation/BundleResources/Information-Property-List/NSPhotoLibraryUsageDescription) key in the `Info.plist` file to display to the user when your app requests access.

In macOS, you also need to enable the [`Photos Library Entitlement`](https://developer.apple.com/documentation/BundleResources/Entitlements/com.apple.security.personal-information.photos-library) in the Signing & Capabilities tab for your app targets.

### [Request permission to access the user’s photo library](https://developer.apple.com/documentation/avfoundation/saving-captured-photos\#Request-permission-to-access-the-users-photo-library)

Use the [`PHPhotoLibrary`](https://developer.apple.com/documentation/Photos/PHPhotoLibrary) [`requestAuthorization(for:handler:)`](https://developer.apple.com/documentation/Photos/PHPhotoLibrary/requestAuthorization(for:handler:)) to request access to the photo library at an appropriate time, such as when the user first opens your app’s camera feature. Here’s an example:

var isPhotoLibraryReadWriteAccessGranted: Bool {
get async {
let status = PHPhotoLibrary.authorizationStatus(for: .readWrite)

// Determine if the user previously authorized read/write access.
var isAuthorized = status == .authorized

// If the system hasn't determined the user's authorization status,
// explicitly prompt them for approval.
if status == .notDetermined {
isAuthorized = await PHPhotoLibrary.requestAuthorization(for: .readWrite) == .authorized
}

return isAuthorized
}
}

### [Use a Creation Request to add a photo asset](https://developer.apple.com/documentation/avfoundation/saving-captured-photos\#Use-a-Creation-Request-to-add-a-photo-asset)

Perform these steps to receive a captured photo and save it to the photo library:

1. Adopt the [`AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate) protocol and implement its [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method to receive a callback for each photo delivered in a capture request.

2. Call [`fileDataRepresentation()`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation()) on the [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object provided by the protocol method to receive a data object containing the photo image data and its attachments, such as camera metadata and auxilliary images.

3. Create a [`PHAssetCreationRequest`](https://developer.apple.com/documentation/Photos/PHAssetCreationRequest) to add the photo resource.

The following code provides an example of this workflow:

func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
if let error {
print("Error processing photo: \(error.localizedDescription)")
return
}

Task {
await save(photo: photo)
}
}

func save(photo: AVCapturePhoto) async {
// Confirm the user granted read/write access.
guard await isPhotoLibraryReadWriteAccessGranted else { return }

// Create a data representation of the photo and its attachments.
if let photoData = photo.fileDataRepresentation() {
PHPhotoLibrary.shared().performChanges {
// Save the photo data.
let creationRequest = PHAssetCreationRequest.forAsset()
creationRequest.addResource(with: .photo, data: photoData, options: nil)
} completionHandler: { success, error in
if let error {
print("Error saving photo: \(error.localizedDescription)")
return
}
}
}
}

## [See Also](https://developer.apple.com/documentation/avfoundation/saving-captured-photos\#see-also)

### [Next Steps](https://developer.apple.com/documentation/avfoundation/saving-captured-photos\#Next-Steps)

[Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress)

Monitor key events during capture to provide feedback in your camera UI.

[Capturing and Saving Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos)

Capture Live Photos like those created in the system Camera app and save them to the Photos library.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoCaptureDelegate](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)
- photoOutput(\_:didFinishProcessingPhoto:error:)

Instance Method

# photoOutput(\_:didFinishProcessingPhoto:error:)

Provides the delegate with the captured image and associated metadata resulting from a photo capture.

optional func photoOutput(
_ output: AVCapturePhotoOutput,
didFinishProcessingPhoto photo: AVCapturePhoto,
error: (any Error)?
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)\#parameters)

`output`

The photo output performing the capture.

`photo`

An object containing the captured image pixel buffer, along with any metadata and attachments captured along with the photo (such as a preview image or depth map).

This parameter is always non- `nil`: if an error prevented successful capture, this object still contains metadata for the intended capture.

`error`

If the capture process could not proceed successfully, an error object describing the failure; otherwise, `nil`.

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)\#mentions)

[Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress)

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

[Capturing Thumbnail and Preview Images](https://developer.apple.com/documentation/avfoundation/capturing-thumbnail-and-preview-images)

[Capturing Photos with Depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)\#Discussion)

Use this method to receive the results of photo capture regardless of format.

The photo output calls this method once for each primary image to be delivered in a capture request. If you request capture in both RAW and processed formats, this method fires once for each format. If you request a bracketed capture with multiple exposures, this method fires once for each exposure.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)\#see-also)

### [Receiving Capture Results](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)\#Receiving-Capture-Results)

[`func photoOutput(AVCapturePhotoOutput, didFinishRecordingLivePhotoMovieForEventualFileAt: URL, resolvedSettings: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishrecordinglivephotomovieforeventualfileat:resolvedsettings:))

Notifies the delegate that the movie content of a Live Photo has finished recording.

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingLivePhotoToMovieFileAt: URL, duration: CMTime, photoDisplayTime: CMTime, resolvedSettings: AVCaptureResolvedPhotoSettings, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessinglivephototomoviefileat:duration:photodisplaytime:resolvedsettings:error:))

Provides the delegate the movie file URL resulting from a Live Photo capture.

[`func photoOutput(AVCapturePhotoOutput, didFinishCapturingDeferredPhotoProxy: AVCaptureDeferredPhotoProxy?, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturingdeferredphotoproxy:error:))

Tells the delegate when the system finishes capturing the photo proxy.

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingPhoto: CMSampleBuffer?, previewPhoto: CMSampleBuffer?, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings?, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:previewphoto:resolvedsettings:bracketsettings:error:))

Provides the delegate a captured image in a processed format (such as JPEG).

Deprecated

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingRawPhoto: CMSampleBuffer?, previewPhoto: CMSampleBuffer?, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings?, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingrawphoto:previewphoto:resolvedsettings:bracketsettings:error:))

Provides the delegate a captured image in RAW format.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoBracketSettings](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings)
- isLensStabilizationEnabled

Instance Property

# isLensStabilizationEnabled

A Boolean value that specifies whether to stabilize the lens for the duration of the bracketed capture.

var isLensStabilizationEnabled: Bool { get set }

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled\#mentions)

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled\#Discussion)

When this setting is [`true`](https://developer.apple.com/documentation/swift/true), the photo output uses optical image stabilization to hold the lens steady for the duration of the bracketed capture, helping to counter hand shake and produce a sharper bracket of images. The default setting is [`false`](https://developer.apple.com/documentation/swift/false).

You can enable this setting only if the photo output’s [`isLensStabilizationDuringBracketedCaptureSupported`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islensstabilizationduringbracketedcapturesupported) property is [`true`](https://developer.apple.com/documentation/swift/true). The capture output validates this requirement when you call the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method. If your settings and delegate do not meet this requirement, that method raises an exception.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled\#see-also)

### [Working with Bracketed Settings](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled\#Working-with-Bracketed-Settings)

[`var bracketedSettings: [AVCaptureBracketedStillImageSettings]`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/bracketedsettings)

An array describing the number of and settings for images to produce in a bracketed capture.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCapturePhotoCaptureDelegate

Protocol

# AVCapturePhotoCaptureDelegate

Methods for monitoring progress and receiving results from a photo capture output.

protocol AVCapturePhotoCaptureDelegate : NSObjectProtocol

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#mentions)

[Saving Captured Photos](https://developer.apple.com/documentation/avfoundation/saving-captured-photos)

[Configuring Camera Capture to Collect a Portrait Effects Matte](https://developer.apple.com/documentation/avfoundation/configuring-camera-capture-to-collect-a-portrait-effects-matte)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#overview)

You implement methods in the [`AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate) protocol to be notified of progress and results when capturing photos with the [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) class.

To capture a photo, you pass an object implementing this protocol to the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method, along with a settings object that describes the capture to be performed. As the capture proceeds, the photo output calls several of the methods in this protocol on your delegate object, providing information about the capture’s progress and delivering the resulting photos.

Which delegate methods the photo output calls depends on the photo settings you initiate capture with. All methods in this protocol are optional at compile time, but at run time your delegate object must respond to certain methods depending on your photo settings:

- If you request a still photo capture (by specifying image formats or file types), your delegate either must implement the [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method, or must implement methods listed in `Receiving Capture Results (Deprecated)` corresponding to whether you request capture in RAW format, processed format, or both.

- If you request Live Photo capture (by setting the [`livePhotoMovieFileURL`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotomoviefileurl) property to a non- `nil` value), your delegate must implement the [`photoOutput(_:didFinishProcessingLivePhotoToMovieFileAt:duration:photoDisplayTime:resolvedSettings:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessinglivephototomoviefileat:duration:photodisplaytime:resolvedsettings:error:)) method.

The capture output validates these requirements when you call the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method. If your delegate does not meet these requirements, that method raises an exception.

You must use a unique [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object for each capture request. When the photo output calls your delegate methods, it provides an [`AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings) object whose [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid) property matches that of the photo settings you requested capture with. When making multiple captures, use this unique ID to determine which delegate method calls correspond to which requests.

The photo output always calls each method listed in Monitoring Capture Progress exactly once for each capture request. For methods listed in Receiving Capture Results, you may receive a call more than once, or not at all, depending on your photo settings. See the description of each method for details.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#topics)

### [Monitoring Capture Progress](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#Monitoring-Capture-Progress)

[`func photoOutput(AVCapturePhotoOutput, willBeginCaptureFor: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:willbegincapturefor:))

Notifies the delegate that the capture output has resolved settings and will soon begin its capture process.

[`func photoOutput(AVCapturePhotoOutput, willCapturePhotoFor: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:willcapturephotofor:))

Notifies the delegate that photo capture is about to occur.

[`func photoOutput(AVCapturePhotoOutput, didCapturePhotoFor: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didcapturephotofor:))

Notifies the delegate that the photo has been taken.

[`func photoOutput(AVCapturePhotoOutput, didFinishCaptureFor: AVCaptureResolvedPhotoSettings, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:))

Notifies the delegate that the capture process is complete.

### [Receiving Capture Results](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#Receiving-Capture-Results)

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingPhoto: AVCapturePhoto, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:))

Provides the delegate with the captured image and associated metadata resulting from a photo capture.

[`func photoOutput(AVCapturePhotoOutput, didFinishRecordingLivePhotoMovieForEventualFileAt: URL, resolvedSettings: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishrecordinglivephotomovieforeventualfileat:resolvedsettings:))

Notifies the delegate that the movie content of a Live Photo has finished recording.

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingLivePhotoToMovieFileAt: URL, duration: CMTime, photoDisplayTime: CMTime, resolvedSettings: AVCaptureResolvedPhotoSettings, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessinglivephototomoviefileat:duration:photodisplaytime:resolvedsettings:error:))

Provides the delegate the movie file URL resulting from a Live Photo capture.

[`func photoOutput(AVCapturePhotoOutput, didFinishCapturingDeferredPhotoProxy: AVCaptureDeferredPhotoProxy?, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturingdeferredphotoproxy:error:))

Tells the delegate when the system finishes capturing the photo proxy.

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingPhoto: CMSampleBuffer?, previewPhoto: CMSampleBuffer?, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings?, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:previewphoto:resolvedsettings:bracketsettings:error:))

Provides the delegate a captured image in a processed format (such as JPEG).

Deprecated

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingRawPhoto: CMSampleBuffer?, previewPhoto: CMSampleBuffer?, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings?, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingrawphoto:previewphoto:resolvedsettings:bracketsettings:error:))

Provides the delegate a captured image in RAW format.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#inherits-from)

- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#see-also)

### [Photo capture](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate\#Photo-capture)

[Capturing consistent color images](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images)

Add the power of a photography studio and lighting rig to your app with the new Constant Color API.

Configure and capture single or multiple still images, Live Photos, and other forms of photography.

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

Support professional photography workflows by enabling minimally processed image capture in your camera app.

[Supporting Continuity Camera in Your Mac App](https://developer.apple.com/documentation/AppKit/supporting-continuity-camera-in-your-mac-app)

Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.

[`class AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto)

A container for image data from a photo capture output.

[`class AVCaptureDeferredPhotoProxy`](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy)

A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.

[`class AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)

A capture output for still image, Live Photos, and other photography workflows.

[`class AVCapturePhotoOutputReadinessCoordinator`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinator)

An object that monitors changes to a photo output’s capture readiness.

[`protocol AVCapturePhotoOutputReadinessCoordinatorDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinatordelegate)

A delegate protocol to receive updates about a photo output’s capture readiness.

[`class AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput)

A capture output for capturing still photos.

---

# https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
- Capturing Still and Live Photos

# Capturing Still and Live Photos

Configure and capture single or multiple still images, Live Photos, and other forms of photography.

## [Overview](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#overview)

Video captured on the iPhone 8, iPhone 8 Plus, and iPhone X running iOS 11 or later uses the HEVC codec by default. If your app shares the captured video using a system share sheet, the video will be automatically converted to a format compatible with the destination device.

AVFoundation supports many ways to capture photos. You can simply capture still HEIF or JPEG images, capture in RAW format for custom processing, snap several images in one shot, create Live Photos with motion and sound, and much more. In iOS, all photography workflows use the [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) class.

### [Prepare for Photo Capture](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#Prepare-for-Photo-Capture)

First, set up an [`AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession) containing a supported camera device as one of its inputs and an [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) as one of its outputs. (For details, see [Choosing a Capture Device](https://developer.apple.com/documentation/avfoundation/choosing-a-capture-device) and [Setting Up a Capture Session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session).) Each camera device supports a wide range of resolution and frame rate settings. To easily get the best photo quality for the user’s device, you can use the [`photo`](https://developer.apple.com/documentation/avfoundation/avcapturesession/preset/photo) session preset instead of directly choosing individual settings.

Some capture options affect the internal configuration of the media capture pipeline. Because changing those options causes the pipeline to reconfigure itself, which takes time, enable them before offering the user the ability to shoot photos with those settings. Otherwise, the configuration delay could prevent the user from capturing a photo at the right moment.

For example, to configure the capture pipleline to support Live Photos, enable that property on the photo output, as shown below. After you’ve enabled Live Photo capture, you can choose for each individual shot whether to use still or Live Photo capture for each shot (see [Capturing and Saving Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos)).

self.captureSession.beginConfiguration()

let photoOutput = AVCapturePhotoOutput()
photoOutput.isHighResolutionCaptureEnabled = true
photoOutput.isLivePhotoCaptureEnabled = photoOutput.isLivePhotoCaptureSupported

guard self.captureSession.canAddOutput(photoOutput) else { return }
self.captureSession.sessionPreset = .photo
self.captureSession.addOutput(photoOutput)

self.previewView.session = captureSession

self.captureSession.commitConfiguration()
self.captureSession.startRunning()

### [Choose Settings](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#Choose-Settings)

To capture a photo, first create an [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object describing the settings you want to use for that shot and the data format for the resulting still photo. For example:

- On supported devices, you can use the HEIF/HEVC format for improved image quality at smaller file sizes: use [`init(format:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/init(format:)) and choose [`hevc`](https://developer.apple.com/documentation/avfoundation/avvideocodectype/hevc) for the video codec. On devices without HEVC support, use the default initializer [`init()`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class/init()) to fall ) with one of the [`availableRawPhotoPixelFormatTypes`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablerawphotopixelformattypes-5fatm) supported by the photo output.

After creating a photo settings object, you can choose other settings for the photo. For example, the code below creates a settings object for HEIF/HEVC shooting, with automatic flash and image stabilization.

let photoSettings: AVCapturePhotoSettings
if self.photoOutput.availablePhotoCodecTypes.contains(.hevc) {
photoSettings = AVCapturePhotoSettings(format:
[AVVideoCodecKey: AVVideoCodecType.hevc])
} else {
photoSettings = AVCapturePhotoSettings()
}
photoSettings.flashMode = .auto
photoSettings.isAutoStillImageStabilizationEnabled =
self.photoOutput.isStillImageStabilizationSupported

Other possible photo settings include Live Photos, depth data capture, and multi-image (bracketed) capture, as well as options for embedding preview or thumbnail images in output image files. For more information, see Next Steps and More Capture Options below.

### [Capture the Photo](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#Capture-the-Photo)

Pass your photo settings object to the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method to trigger photo capture with the settings you’ve chosen.

### [Handle Capture Results](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#Handle-Capture-Results)

The `delegate` you pass to the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method is an object to track the progress of and handle results from that photo capture. Capturing a photo is an asynchronous process with multiple steps that unfold over time. Because your app can trigger additional captures while earlier captures are still processing, your delegate implementation should be able to handle multiple captures at once. An easy way to handle concurrent captures is to define a class adopting the [`AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate) protocol and create a separate instance of that class for each capture:

class PhotoCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {
// ...
}

let captureProcessor = PhotoCaptureProcessor()
self.photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)

When your captured image data is ready for use, the photo output calls your delegate’s [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method. You can use the resulting [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object there to display, process or save the image.

## [Topics](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#topics)

### [Next Steps](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#Next-Steps)

[Saving Captured Photos](https://developer.apple.com/documentation/avfoundation/saving-captured-photos)

Add an image and other data from a photo capture to the photo library.

[Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress)

Monitor key events during capture to provide feedback in your camera UI.

[Capturing and Saving Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos)

Capture Live Photos like those created in the system Camera app and save them to the Photos library.

### [More Capture Options](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#More-Capture-Options)

[Capturing Photos with Depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)

Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

Capture several photos at once, varying parameters like exposure duration or light sensitivity.

[Capturing Uncompressed Image Data](https://developer.apple.com/documentation/avfoundation/capturing-uncompressed-image-data)

Get processed image data without compression to use for filtering or lossless output.

[Capturing Thumbnail and Preview Images](https://developer.apple.com/documentation/avfoundation/capturing-thumbnail-and-preview-images)

Enable delivery of reduced-size images with the main image in a photo capture.

## [See Also](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#see-also)

### [Photo capture](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos\#Photo-capture)

[Capturing consistent color images](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images)

Add the power of a photography studio and lighting rig to your app with the new Constant Color API.

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

Support professional photography workflows by enabling minimally processed image capture in your camera app.

[Supporting Continuity Camera in Your Mac App](https://developer.apple.com/documentation/AppKit/supporting-continuity-camera-in-your-mac-app)

Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.

[`class AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto)

A container for image data from a photo capture output.

[`class AVCaptureDeferredPhotoProxy`](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy)

A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.

[`class AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)

A capture output for still image, Live Photos, and other photography workflows.

[`protocol AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)

Methods for monitoring progress and receiving results from a photo capture output.

[`class AVCapturePhotoOutputReadinessCoordinator`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinator)

An object that monitors changes to a photo output’s capture readiness.

[`protocol AVCapturePhotoOutputReadinessCoordinatorDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinatordelegate)

A delegate protocol to receive updates about a photo output’s capture readiness.

[`class AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput)

A capture output for capturing still photos.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureResolvedPhotoSettings

Class

# AVCaptureResolvedPhotoSettings

A description of the features and settings in use for an in-progress or complete photo capture request.

class AVCaptureResolvedPhotoSettings

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#mentions)

[Configuring Camera Capture to Collect a Portrait Effects Matte](https://developer.apple.com/documentation/avfoundation/configuring-camera-capture-to-collect-a-portrait-effects-matte)

[Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#overview)

When you request a photo capture using the [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method, you describe the settings for that capture request in an [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object. When the capture begins, the photo output calls your delegate methods and provides an [`AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings) object detailing the settings that are in effect for that capture. Resolved photo settings objects are immutable; they describe a request that has already been made.

The [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/uniqueid) property of a resolved photo settings object passed to one of your [`AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate) methods matches the [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid) value of the [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object you passed when requesting capture. Use this value to determine which delegate method calls correspond to which capture requests.

Some photo capture settings are automatic, such as the [`flashMode`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/flashmode) property. For such settings, the photo output determines whether to use that feature at the moment of capture—you don’t know when requesting a capture whether the feature is active when the capture completes. When the photo output calls your delegate methods, the provided [`AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings) object details which automatic features have been set for that capture.

Likewise, the dimensions of an output image or movie may not be set until the moment of capture. For example, when you specify a thumbnail size with the [`previewPhotoFormat`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/previewphotoformat) setting, the photo output chooses dimensions that best match your requested size while preserving the aspect ratio of the captured photo. When the photo output calls your delegate methods, use the [`previewDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/previewdimensions) property of the resolved settings to find the actual preview image dimensions. See the methods listed in Examining Output Dimensions for other cases where output dimensions can change at capture time.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#topics)

### [Resolving Photo Capture Requests](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#Resolving-Photo-Capture-Requests)

[`var uniqueID: Int64`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/uniqueid)

The unique identifier for the photo capture this settings object corresponds to.

[`var expectedPhotoCount: Int`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/expectedphotocount)

The number of photo capture results in the capture request.

### [Examining Photo Capture Settings](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#Examining-Photo-Capture-Settings)

[`var isFlashEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isflashenabled)

A Boolean value indicating whether the camera flash fires for this capture.

[`var isRedEyeReductionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isredeyereductionenabled)

A Boolean value indicating whether the camera automatically reduces red-eye when capturing photos.

[`var isVirtualDeviceFusionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isvirtualdevicefusionenabled)

A Boolean value that specifies whether the system automatically uses virtual device image fusion.

[`var isFastCapturePrioritizationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isfastcaptureprioritizationenabled)

A Boolean value that indicates whether the system uses fast capture prioritization when capturing the photo.

[`var isContentAwareDistortionCorrectionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/iscontentawaredistortioncorrectionenabled)

A Boolean value that indicates whether the system applies content-aware distortion correction when capturing the photo.

[`var isStillImageStabilizationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isstillimagestabilizationenabled)

A Boolean value indicating whether this capture uses image stabilization.

Deprecated

[`var isDualCameraFusionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isdualcamerafusionenabled)

A Boolean value indicating whether this capture combines image data from a dual camera.

### [Examining Output Dimensions](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#Examining-Output-Dimensions)

[`var photoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/photodimensions)

The size, in pixels, of the photo image (in a processed format, such as JPEG) that the capture delivers.

[`var deferredPhotoProxyDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/deferredphotoproxydimensions)

The resolved dimensions of the photo proxy when using deferred photo delivery.

[`var rawPhotoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawphotodimensions)

The size, in pixels, of the RAW-format photo image that the capture delivers.

[`var previewDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/previewdimensions)

The size, in pixels, of the preview image that the system delivers with the capture.

[`var embeddedThumbnailDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/embeddedthumbnaildimensions)

The size, in pixels, of the thumbnail image that the capture delivers.

[`var rawEmbeddedThumbnailDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawembeddedthumbnaildimensions)

The size, in pixels, of the RAW-format embedded thumbnail image that the capture delivers.

[`var livePhotoMovieDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/livephotomoviedimensions)

The size, in pixels, of the Live Photo movie content that the capture delivers.

[`var portraitEffectsMatteDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/portraiteffectsmattedimensions)

The size, in pixels, of the portrait effects matte that the capture delivers.

Retrieves the resolved dimensions of the semantic segmentation mattes that the photo output delivers.

[`var photoProcessingTimeRange: CMTimeRange`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/photoprocessingtimerange)

The time range in which to expect the system to deliver the photo to the delegate.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#see-also)

### [Photo settings](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings\#Photo-settings)

[`class AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)

A specification of the features and settings to use for a single photo capture request.

[`class AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings)

A specification of the features and settings to use for a photo capture request that captures multiple images with varied settings.

---

# https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
- [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos)
- Capturing and Saving Live Photos

Article

# Capturing and Saving Live Photos

Capture Live Photos like those created in the system Camera app and save them to the Photos library.

## [Overview](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos\#overview)

A Live Photo is a picture that includes motion and sound from the moments just before and after its capture. Your app can capture and record Live Photos using the AVFoundation capture system and the [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) class.

### [Enable Live Photo Capture](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos\#Enable-Live-Photo-Capture)

For a still photo your capture session needs only a video input, but a Live Photo includes sound, so you’ll need to also connect an audio capture device to your session:

enum CameraError: Error {
case configurationFailed
// ... additional error cases ...
}

func configureSession() throws {
captureSession.beginConfiguration()

// ... add camera input and photo output ...

guard let audioDevice = AVCaptureDevice.default(for: .audio),
let audioDeviceInput = try? AVCaptureDeviceInput(device: audioDevice) else {
throw CameraError.configurationFailed
}

if captureSession.canAddInput(audioDeviceInput) {
captureSession.addInput(audioDeviceInput)
} else {
throw CameraError.configurationFailed
}

// ... configure photo output and start running ...

captureSession.commitConfiguration()
}

Because you’re already using a built-in camera device for video (see [Setting Up a Capture Session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session)), you can simply use the default audio capture device—the system automatically uses the best microphone configuration for the camera position.

Capturing Live Photos requires an internal reconfiguration of the capture pipeline, which takes time and interrupts any in-progress captures. Before shooting your first Live Photo, make sure you’ve configured the pipeline appropriately by enabling Live Photo capture on your [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) object:

let photoOutput = AVCapturePhotoOutput()

// Attempt to add the photo output to the session.
if captureSession.canAddOutput(photoOutput) {
captureSession.sessionPreset = .photo
captureSession.addOutput(photoOutput)
} else {
throw CameraError.configurationFailed
}

// Configure the photo output's behavior.
photoOutput.isHighResolutionCaptureEnabled = true
photoOutput.isLivePhotoCaptureEnabled = photoOutput.isLivePhotoCaptureSupported

// Start the capture session.
captureSession.startRunning()

### [Capture a Live Photo](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos\#Capture-a-Live-Photo)

Once your photo output is ready for Live Photos, you can choose still image or Live Photo capture for each shot. To capture a Live Photo, create an [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object, choosing the format for the still image portion of the Live Photo and providing a URL for writing the movie portion of the Live Photo. Then, call [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) to trigger capture:

let photoSettings = AVCapturePhotoSettings(format: [AVVideoCodecKey: AVVideoCodecType.hevc])
photoSettings.livePhotoMovieFileURL = // output url

// Shoot the Live Photo, using a custom class to handle capture delegate callbacks.
let captureProcessor = LivePhotoCaptureProcessor()
photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)

### [Handle Live Photo Results](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos\#Handle-Live-Photo-Results)

A Live Photo appears to users in the Photos app as a single asset, but it’s actually composed of separate files: the primary still image, and a movie file containing motion and sound from the moments before and after. The capture system delivers these results separately, as soon as each becomes available.

The [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method delivers the still image portion of the Live Photo as an [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object. Because you’ll need to save the still image and movie files together, it’s best to extract the image file data from the [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) and keep it until the movie file finishes recording, as shown below. (You can also use this method to indicate in your UI that the still image has been captured.)

func photoOutput(_ output: AVCapturePhotoOutput,
didFinishProcessingPhoto photo: AVCapturePhoto,
error: Error?) {
guard error != nil else {
print("Error capturing Live Photo still: \(error!)");
return
}

// Get and process the captured image data.
processImage(photo.fileDataRepresentation())
}

The [`photoOutput(_:didFinishProcessingLivePhotoToMovieFileAt:duration:photoDisplayTime:resolvedSettings:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessinglivephototomoviefileat:duration:photodisplaytime:resolvedsettings:error:)) method fires later, indicating that the URL you specified when triggering the capture now contains a complete movie file. Once you have both the still image and movie portions of your Live Photo, you can save them together:

func photoOutput(_ output: AVCapturePhotoOutput,
didFinishProcessingLivePhotoToMovieFileAt outputFileURL: URL,
duration: CMTime,
photoDisplayTime: CMTime,
resolvedSettings: AVCaptureResolvedPhotoSettings,
error: Error?) {

guard error != nil else {
print("Error capturing Live Photo movie: \(error!)");
return
}

guard let stillImageData = stillImageData else { return }

// Save Live Photo.
saveLivePhotoToPhotosLibrary(stillImageData: stillImageData,
livePhotoMovieURL: outputFileURL)
}

### [Save a Live Photo to the Photos Library](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos\#Save-a-Live-Photo-to-the-Photos-Library)

Use the [`PHAssetCreationRequest`](https://developer.apple.com/documentation/Photos/PHAssetCreationRequest) class to create a single Photos asset consisting of media from multiple files—in the case of a Live Photo, the still image and its paired video. As in [Saving Captured Photos](https://developer.apple.com/documentation/avfoundation/saving-captured-photos), you’ll need to wrap that request in a [`PHPhotoLibrary`](https://developer.apple.com/documentation/Photos/PHPhotoLibrary) change block, and first make sure that your app has the user’s permission to access Photos.

func saveLivePhotoToPhotosLibrary(stillImageData: Data, livePhotoMovieURL: URL) { PHPhotoLibrary.requestAuthorization { status in
guard status == .authorized else { return }

PHPhotoLibrary.shared().performChanges({
// Add the captured photo's file data as the main resource for the Photos asset.
let creationRequest = PHAssetCreationRequest.forAsset()
creationRequest.addResource(with: .photo, data: stillImageData, options: nil)

// Add the movie file URL as the Live Photo's paired video resource.
let options = PHAssetResourceCreationOptions()
options.shouldMoveFile = true
creationRequest.addResource(with: .pairedVideo, fileURL: livePhotoMovieURL, options: options)
}) { success, error in
// Handle completion.
}
}
}

### [Track Live Photo Progress](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos\#Track-Live-Photo-Progress)

Capturing Live Photos adds two additional steps to the process shown in [Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress): after delivery of the still photo result (step 4), the photo output notifies you of movie capture status (step 5) and delivers the movie result (step 6). (Final cleanup becomes step 7.)

When the user captures a Live Photo in the system Camera app, a “Live” indicator appears for a few seconds to let the user know that video and audio are still being recorded. To provide a similar interface in your app, implement these methods in your photo capture delegate:

- The [`photoOutput(_:willBeginCaptureFor:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:willbegincapturefor:)) method tells you that capture has started: implement this method to show a recording indicator.

- The [`photoOutput(_:didFinishRecordingLivePhotoMovieForEventualFileAt:resolvedSettings:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishrecordinglivephotomovieforeventualfileat:resolvedsettings:)) method tells you that a Live Photo movie is no longer recording: implement this method to hide the indicator. (Note that the movie file is not yet available at this time.)

You can have multiple Live Photo captures running at the same time, so it’s best to use these methods to keep track of the number of captures “in flight” and hide your indicator only when that number reaches zero:

class LivePhotoCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {
// ... other PhotoCaptureDelegate methods and supporting properties ...

// A handler to call when Live Photo capture begins and ends.

// A property for tracking in-progress captures and updating UI accordingly.
var livePhotosInProgress = 0 {
didSet {
// Update the UI accordingly based on the value of this property
}
}

// Call the handler when PhotoCaptureDelegate methods indicate Live Photo capture is in progress.
func photoOutput(_ output: AVCapturePhotoOutput,
willBeginCaptureFor resolvedSettings: AVCaptureResolvedPhotoSettings) {

livePhotoStatusHandler(capturingLivePhoto)
}

func photoOutput(_ output: AVCapturePhotoOutput,
didFinishRecordingLivePhotoMovieForEventualFileAt outputFileURL: URL,
resolvedSettings: AVCaptureResolvedPhotoSettings) {
livePhotoStatusHandler(false)
}
}

## [See Also](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos\#see-also)

### [Next Steps](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos\#Next-Steps)

[Saving Captured Photos](https://developer.apple.com/documentation/avfoundation/saving-captured-photos)

Add an image and other data from a photo capture to the photo library.

[Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress)

Monitor key events during capture to provide feedback in your camera UI.

---

# https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
- [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos)
- Tracking Photo Capture Progress

Article

# Tracking Photo Capture Progress

Monitor key events during capture to provide feedback in your camera UI.

## [Overview](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress\#overview)

Capturing a photo with an iOS device camera is a complex process involving physical camera mechanisms, image signal processing, the operating system, and your app. While it’s possible for your app to ignore many stages of this process and simply wait for a final result, you can create a more responsive camera interface by monitoring each step.

After you call [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)), your delegate object can follow along with five major steps in the process (or more, depending on your photo settings). Depending on your capture workflow and the capture UI you want to create, your delegate can handle some or all of these steps:

1. Settings resolved

2. Exposure started

3. Exposure complete

4. Result data delivery

5. Capture complete

The capture system provides an [`AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings) object at each step in this process. Because multiple captures can be in progress at the same time, each resolved photo settings object has a [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/uniqueid) whose value matches the [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid) of the [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) you used to take the photo.

### [Get Resolved Capture Settings](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress\#Get-Resolved-Capture-Settings)

When you specify the settings for a photo, some of the settings you choose can be automatic, left for the capture system to decide at precisely the moment of capture. For example, you can choose [`AVCaptureDevice.FlashMode.auto`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/flashmode-swift.enum/auto) flash mode, allowing the camera itself to determine based on scene lighting whether to fire the flash when exposing the photo.

Just before starting the exposure, the photo output calls your delegate’s [`photoOutput(_:willBeginCaptureFor:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:willbegincapturefor:)) method, whose `resolvedSettings` parameter tells you the actual settings for that capture. For example, if you chose [`AVCaptureDevice.FlashMode.auto`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/flashmode-swift.enum/auto) flash mode, the resolved settings object tells you whether the flash is in use for the current capture—you could use this information to show in your UI that the flash was used.

### [Handle Exposure Start](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress\#Handle-Exposure-Start)

When the exposure time begins, the photo output calls your delegate’s [`photoOutput(_:willCapturePhotoFor:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:willcapturephotofor:)) method. In traditional photography, this moment is equivalent to the opening of the camera shutter. The system also automatically plays a shutter sound at this time.

In your UI, you can respond to this method to display a shutter animation or some other indicator that the requested photo is being taken.

### [Handle Exposure End](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress\#Handle-Exposure-End)

The photo output calls your delegate’s [`photoOutput(_:didCapturePhotoFor:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didcapturephotofor:)) method as soon as the exposure time completes. The system still needs time to process camera data before providing an image to your app, but you can use this moment to display in your UI that the exposure is complete. For example, you can simulate a shutter effect by hiding the camera preview in the `willCapturePhoto` method and showing it again in the `didCapturePhoto` method.

### [Handle Photo Results](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress\#Handle-Photo-Results)

When the photo output has image data available for your app, it calls your delegate’s [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method. Depending on your photo settings, the photo output may call this method multiple times:

- If you request bracketed capture, this method fires (at least) once for each exposure in the bracket, providing the image for that exposure.

- If you request capture in both RAW and processed formats (such as HEIF/HEVC or JPEG), this method fires (at least) once for each format.

For example, if you request RAW+HEIF capture in a three-exposure bracket, the photo output calls your delegate’s `didFinishProcessingPhoto` method six times (2 formats × 3 exposures), providing six [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) objects. To keep track of multiple results, compare the [`photoCount`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount) from each photo to the [`expectedPhotoCount`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/expectedphotocount) of your resolved settings.

### [Clean Up When Capture Is Complete](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress\#Clean-Up-When-Capture-Is-Complete)

When all of the system’s work for a capture is complete, the photo output calls your delegate’s [`photoOutput(_:didFinishCaptureFor:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:)) method. You can use this moment to finish your app’s part of the capture process:

- If your capture expects multiple results, cache those in your [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) (and [`photoOutput(_:didFinishProcessingLivePhotoToMovieFileAt:duration:photoDisplayTime:resolvedSettings:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessinglivephototomoviefileat:duration:photodisplaytime:resolvedsettings:error:))) methods, then save results to local storage or add them to the Photos library in your `didFinishCapture` method.

- If your capture process manages other resources, clean up those resources in your `didFinishCapture` method. If you use a separate photo capture delegate object for each capture, this is a good time to remove any strong references to such objects.

The code below shows one way to manage multiple photo capture delegate objects:

class PhotoCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {

func photoOutput(_ output: AVCapturePhotoOutput, didFinishCaptureFor resolvedSettings: AVCaptureResolvedPhotoSettings, error: Error?) {
completionHandler()
}
// ... other delegate methods to handle capture results...
}

// Keep a set of in-progress capture delegates.

func shootPhoto() {
// Make a new capture delegate for each capture and add it to the set.
let captureProcessor = PhotoCaptureProcessor()
capturesInProgress.insert(captureProcessor)

// Schedule for the capture delegate to be removed from the set after capture.
captureProcessor.completionHandler = { [weak self] in
self?.capturesInProgress.remove(captureProcessor); return
}

self.photoOutput.capturePhoto(with: self.settingsForNextPhoto(), delegate: captureProcessor)
}

## [See Also](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress\#see-also)

### [Next Steps](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress\#Next-Steps)

[Saving Captured Photos](https://developer.apple.com/documentation/avfoundation/saving-captured-photos)

Add an image and other data from a photo capture to the photo library.

[Capturing and Saving Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos)

Capture Live Photos like those created in the system Camera app and save them to the Photos library.

---

# https://developer.apple.com/documentation/avfoundation/video-settings

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- Video settings

API Collection

# Video settings

Configure video processing settings using standard key and value constants.

## [Topics](https://developer.apple.com/documentation/avfoundation/video-settings\#topics)

### [Clean aperture](https://developer.apple.com/documentation/avfoundation/video-settings\#Clean-aperture)

[`let AVVideoCleanApertureKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocleanaperturekey)

A key that defines the region within the video dimension displayed during playback.

[`let AVVideoCleanApertureWidthKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocleanaperturewidthkey)

A key to access the width of video that’s free from transition artifacts caused by signal encoding.

[`let AVVideoCleanApertureHeightKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocleanapertureheightkey)

A key to access the height of video that’s free from transition artifacts caused by signal encoding.

[`let AVVideoCleanApertureVerticalOffsetKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocleanapertureverticaloffsetkey)

A key to access the vertical offset of video that’s free from transition artifacts caused by signal encoding.

[`let AVVideoCleanApertureHorizontalOffsetKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocleanaperturehorizontaloffsetkey)

A key to access the horizontal offset of video that’s free from transition artifacts caused by signal encoding.

### [Video codecs](https://developer.apple.com/documentation/avfoundation/video-settings\#Video-codecs)

[`let AVVideoCodecKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocodeckey)

A key to access the name of the codec for compressing video.

[`struct AVVideoCodecType`](https://developer.apple.com/documentation/avfoundation/avvideocodectype)

A set of constants that describe the codecs the system supports for video capture.

### [Color properties](https://developer.apple.com/documentation/avfoundation/video-settings\#Color-properties)

Keys specify video properties, and corresponding keys and values specify the color primary, transfer function, and Y’CbCr matrix.

[Setting Color Properties for a Specific Resolution](https://developer.apple.com/documentation/avfoundation/setting-color-properties-for-a-specific-resolution)

Choose the proper color property keys for the desired color range.

[`let AVVideoAllowWideColorKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowwidecolorkey)

The key for a dictionary that indicates whether the client can process wide color.

[`let AVVideoColorPrimariesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimarieskey)

The key to identify color primaries in a color properties dictionary.

[`let AVVideoColorPrimaries_EBU_3213: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_ebu_3213)

The color primary is in the EBU Tech. 3213 color space.

[`let AVVideoColorPrimaries_ITU_R_2020: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_2020)

The color primary is in the ITU\_R BT.2020 color space for ultra high definition television.

[`let AVVideoColorPrimaries_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_709_2)

The color primary is in the ITU\_R BT.709 color space.

[`let AVVideoColorPrimaries_P3_D65: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_p3_d65)

The color primary uses the DCI-P3 D65 color space.

[`let AVVideoColorPrimaries_SMPTE_C: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_smpte_c)

The color primary uses the SMPTE C color space.

[`let AVVideoColorPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorpropertieskey)

The key for a dictionary that contains properties specifying video color.

[`let AVVideoTransferFunctionKey: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunctionkey)

The key to identify the transfer function in a color properties dictionary.

[`let AVVideoTransferFunction_IEC_sRGB: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_iec_srgb)

The transfer function for the IEC sRGB color space.

[`let AVVideoTransferFunction_ITU_R_2100_HLG: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_2100_hlg)

The transfer function for the ITU\_R BT.2100 color space.

[`let AVVideoTransferFunction_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_709_2)

The transfer function for the ITU\_R BT.709 color space.

[`let AVVideoTransferFunction_Linear: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_linear)

The transfer function for the linear color space.

[`let AVVideoTransferFunction_SMPTE_240M_1995: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_smpte_240m_1995)

The transfer function for the SMPTE 240M color space.

[`let AVVideoTransferFunction_SMPTE_ST_2084_PQ: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_smpte_st_2084_pq)

The transfer function for the SMPTE 2084 color space.

[`let AVVideoYCbCrMatrixKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrixkey)

The key to identify the Y’CbCr matrix in a color properties dictionary.

[`let AVVideoYCbCrMatrix_ITU_R_2020: String`](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_2020)

The Y’CbCr color matrix for ITU-R BT.2020 conversion.

[`let AVVideoYCbCrMatrix_ITU_R_601_4: String`](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_601_4)

The Y’CbCr color matrix for ITU-R BT.601 conversion.

[`let AVVideoYCbCrMatrix_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_709_2)

The Y’CbCr color matrix for ITU-R BT.709 conversion.

[`let AVVideoYCbCrMatrix_SMPTE_240M_1995: String`](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_smpte_240m_1995)

The Y’CbCr color matrix for SMPTE 240M conversion.

### [Compression](https://developer.apple.com/documentation/avfoundation/video-settings\#Compression)

[`let AVVideoCompressionPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocompressionpropertieskey)

A key to access the dictionary of compression properties for a video asset.

[`let AVVideoDecompressionPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideodecompressionpropertieskey)

The key that indicates the video decompression properties to pass to the video decoder.

[`let AVVideoAverageBitRateKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoaveragebitratekey)

A key to access the average bit rate—as bits per second—used in compressing video.

[`let AVVideoQualityKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoqualitykey)

A key to set the JPEG compression quality of the video.

[`let AVVideoMaxKeyFrameIntervalKey: String`](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervalkey)

A key to access the maximum interval between keyframes.

[`let AVVideoMaxKeyFrameIntervalDurationKey: String`](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervaldurationkey)

A key to access the maximum interval duration between keyframes.

[`let AVVideoAllowFrameReorderingKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowframereorderingkey)

A key to access permission to reorder frames.

[`let AVVideoAppleProRAWBitDepthKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoappleprorawbitdepthkey)

A key to access the Apple ProRAW bit depth.

### [Entropy mode](https://developer.apple.com/documentation/avfoundation/video-settings\#Entropy-mode)

[`let AVVideoH264EntropyModeKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoh264entropymodekey)

The entropy encoding mode for H.264 compression.

[`let AVVideoH264EntropyModeCABAC: String`](https://developer.apple.com/documentation/avfoundation/avvideoh264entropymodecabac)

The encoder uses Context-based Adaptive Binary Arithmetic Coding.

[`let AVVideoH264EntropyModeCAVLC: String`](https://developer.apple.com/documentation/avfoundation/avvideoh264entropymodecavlc)

The encoder uses Context-based Adaptive Variable Length Coding.

### [FairPlay](https://developer.apple.com/documentation/avfoundation/video-settings\#FairPlay)

[`let AVStreamingKeyDeliveryContentKeyType: String`](https://developer.apple.com/documentation/avfoundation/avstreamingkeydeliverycontentkeytype)

A URL for a content key.

[`let AVStreamingKeyDeliveryPersistentContentKeyType: String`](https://developer.apple.com/documentation/avfoundation/avstreamingkeydeliverypersistentcontentkeytype)

A URL for a persistent content key.

### [Frame rate](https://developer.apple.com/documentation/avfoundation/video-settings\#Frame-rate)

[`let AVVideoExpectedSourceFrameRateKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoexpectedsourceframeratekey)

The expected source frame rate.

[`let AVVideoAverageNonDroppableFrameRateKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoaveragenondroppableframeratekey)

The desired average number of non-droppable frames to be encoded for each second of video.

### [Geometry](https://developer.apple.com/documentation/avfoundation/video-settings\#Geometry)

[`let AVVideoWidthKey: String`](https://developer.apple.com/documentation/avfoundation/avvideowidthkey)

A key to access the width of the video in pixels.

[`let AVVideoHeightKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoheightkey)

A key to access the height of the video in pixels.

[`let AVVideoPixelAspectRatioKey: String`](https://developer.apple.com/documentation/avfoundation/avvideopixelaspectratiokey)

A key to access the video’s pixel aspect ratio.

[`let AVVideoPixelAspectRatioVerticalSpacingKey: String`](https://developer.apple.com/documentation/avfoundation/avvideopixelaspectratioverticalspacingkey)

A key to access the pixel aspect ratio vertical spacing.

[`let AVVideoPixelAspectRatioHorizontalSpacingKey: String`](https://developer.apple.com/documentation/avfoundation/avvideopixelaspectratiohorizontalspacingkey)

A key to access the pixel aspect ratio horizontal spacing.

### [Profile level](https://developer.apple.com/documentation/avfoundation/video-settings\#Profile-level)

[`let AVVideoProfileLevelKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelkey)

A key to access the video profile.

[`let AVVideoProfileLevelH264High40: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264high40)

A high-level 4.0 profile.

[`let AVVideoProfileLevelH264High41: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264high41)

A high-level 4.1 profile.

[`let AVVideoProfileLevelH264Main30: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264main30)

A main-level 3.0 profile.

[`let AVVideoProfileLevelH264Main31: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264main31)

A main-level 3.1 profile.

[`let AVVideoProfileLevelH264Main32: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264main32)

A main-level 3.2 profile.

[`let AVVideoProfileLevelH264Main41: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264main41)

A main-level 4.1 profile.

[`let AVVideoProfileLevelH264Baseline30: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264baseline30)

A baseline-level 3.0 profile.

[`let AVVideoProfileLevelH264Baseline31: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264baseline31)

A baseline-level 3.1 profile.

[`let AVVideoProfileLevelH264Baseline41: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264baseline41)

A baseline-level 4.1 profile.

[`let AVVideoProfileLevelH264HighAutoLevel: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264highautolevel)

A high profile auto level profile.

[`let AVVideoProfileLevelH264MainAutoLevel: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264mainautolevel)

A main profile auto level profile.

[`let AVVideoProfileLevelH264BaselineAutoLevel: String`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelh264baselineautolevel)

A baseline auto level profile.

### [Scaling mode](https://developer.apple.com/documentation/avfoundation/video-settings\#Scaling-mode)

[`let AVVideoScalingModeFit: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmodefit)

The string identifier for scaling a video to fit the surrounding view’s dimensions.

[`let AVVideoScalingModeKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmodekey)

A key to retrieve the video scaling mode from a dictionary.

[`let AVVideoScalingModeResize: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmoderesize)

The string identifier for resizing a video to fit the surrounding view’s dimensions.

[`let AVVideoScalingModeResizeAspect: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmoderesizeaspect)

The string identifier for resizing a video to its surrounding view’s shorter dimension while preserving its aspect ratio.

[`let AVVideoScalingModeResizeAspectFill: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmoderesizeaspectfill)

The string identifier for resizing a video to fit the surrounding view’s longer dimension while preserving aspect ratio.

### [VideoToolbox options](https://developer.apple.com/documentation/avfoundation/video-settings\#VideoToolbox-options)

[`let AVVideoEncoderSpecificationKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoencoderspecificationkey)

The video encoder specification includes options for choosing a specific video encoder.

## [See Also](https://developer.apple.com/documentation/avfoundation/video-settings\#see-also)

### [Common](https://developer.apple.com/documentation/avfoundation/video-settings\#Common)

Load media assets from files and streams to inspect their attributes, tracks, and embedded metadata.

Read images from video, export to alternative formats, and perform sample-level reading and writing of media data.

Identify the types of content and file formats that AVFoundation supports.

Configure audio processing settings using standard key and value constants.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCapturePhotoBracketSettings

Class

# AVCapturePhotoBracketSettings

A specification of the features and settings to use for a photo capture request that captures multiple images with varied settings.

class AVCapturePhotoBracketSettings

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#mentions)

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#overview)

To take a bracketed capture, you create and configure an [`AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings) object, using [`AVCaptureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturebracketedstillimagesettings) objects to describe the individual captures in the bracket, and then pass it to the [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method.

To request a bracketed capture, follow these steps:

1. Create an array of [`AVCaptureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturebracketedstillimagesettings) objects describing the number of images to capture in the bracket and the variations on capture settings between them.

2. Create a bracketed photo settings object with the [`init(rawPixelFormatType:processedFormat:bracketedSettings:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/init(rawpixelformattype:processedformat:bracketedsettings:)) initializer, passing the array of bracketed still image settings, along with the processed format (such as JPEG) or RAW format to capture images in.

3. Configure other settings to share across all images in the bracket, such as the [`isLensStabilizationEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled) property and certain inherited properties.

4. Initiate capture by passing the bracketed photo settings object to your photo output’s [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method, along with a delegate object to receive messages about the progress and results of the capture.

5. The photo output calls your delegate’s [`photoOutput(_:didFinishProcessingPhoto:previewPhoto:resolvedSettings:bracketSettings:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:previewphoto:resolvedsettings:bracketsettings:error:)) or [`photoOutput(_:didFinishProcessingRawPhoto:previewPhoto:resolvedSettings:bracketSettings:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingrawphoto:previewphoto:resolvedsettings:bracketsettings:error:)) methods many times corresponding to the number of captures in the bracket. Each call provides the [`AVCaptureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturebracketedstillimagesettings) object indicating which capture in the bracket the captured image corresponds to.

The following code example illustrates capturing a bracket of three RAW images with varying exposure value settings.

Listing 1. Capturing a Multi-Exposure Bracket

func captureRAWAutoExposureBracket() {

// Specify a 3-shot bracket, where exposure compensation varies between each shot.
let makeSettings = AVCaptureAutoExposureBracketedStillImageSettings.autoExposureSettingsWithExposureTargetBias
let bracketedStillImageSettings = [-2, 0, 2].map { makeSettings(Float($0))! }
let rawFormat = myCapturePhotoOutput.availableRawPhotoCVPixelFormatTypes.first!.unsignedIntValue as OSType

let settings = AVCapturePhotoBracketSettings(format: nil, rawPixelFormatType: rawFormat, bracketedSettings: bracketedStillImageSettings)
settings.lensStabilizationEnabled = myCapturePhotoOutput.lensStabilizationDuringBracketedCaptureSupported

myCapturePhotoOutput.capturePhotoWithSettings(settings, delegate: self)
// Three RAW photos will be delivered.
}

- (void)captureRAWAutoExposureBracket {
if ( myCapturePhotoOutput.maxBracketedCapturePhotoCount < 3 ) { return; }

// Specify a 3-shot bracket, where exposure compensation varies between each shot.
NSArray *bracketedStillImageSettings = @[ [AVCaptureAutoExposureBracketedStillImageSettings autoExposureSettingsWithExposureTargetBias:-2.],\
[AVCaptureAutoExposureBracketedStillImageSettings autoExposureSettingsWithExposureTargetBias:0.],\
[AVCaptureAutoExposureBracketedStillImageSettings autoExposureSettingsWithExposureTargetBias:2.] ];
OSType rawFormat = [[myCapturePhotoOutput.availableRawPhotoCVPixelFormatTypes firstObject] intValue];

AVCapturePhotoBracketSettings *settings = [[AVCapturePhotoBracketSettings alloc] initWithFormat:nil rawPixelFormatType:rawFormat bracketedSettings:bracketedStillImageSettings];
settings.lensStabilizationEnabled = myCapturePhotoOutput.isLensStabilizationDuringBracketedCaptureSupported;

[myCapturePhotoOutput capturePhotoWithSettings:settings delegate:self];
// Three RAW photos will be delivered to the delegate.
}

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#topics)

### [Creating a Bracket Settings Object](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#Creating-a-Bracket-Settings-Object)

[`convenience init(rawPixelFormatType: OSType, rawFileType: AVFileType?, processedFormat: [String : Any]?, processedFileType: AVFileType?, bracketedSettings: [AVCaptureBracketedStillImageSettings])`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/init(rawpixelformattype:rawfiletype:processedformat:processedfiletype:bracketedsettings:))

Creates a photo settings object for capture in both RAW format and a processed format.

[`convenience init(rawPixelFormatType: OSType, processedFormat: [String : Any]?, bracketedSettings: [AVCaptureBracketedStillImageSettings])`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/init(rawpixelformattype:processedformat:bracketedsettings:))

Creates a photo settings object for the specified bracket of captures, in the specified formats.

### [Working with Bracketed Settings](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#Working-with-Bracketed-Settings)

[`var bracketedSettings: [AVCaptureBracketedStillImageSettings]`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/bracketedsettings)

An array describing the number of and settings for images to produce in a bracketed capture.

[`var isLensStabilizationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled)

A Boolean value that specifies whether to stabilize the lens for the duration of the bracketed capture.

### [Bracketed Settings Types](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#Bracketed-Settings-Types)

[`class AVCaptureAutoExposureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings)

A configuration for defining bracketed photo captures in terms of bias relative to automatic exposure.

[`class AVCaptureManualExposureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings)

A configuration for defining bracketed photo captures in terms of specific exposure and ISO values.

[`class AVCaptureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturebracketedstillimagesettings)

The abstract superclass for bracketed photo capture settings.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#inherits-from)

- [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#see-also)

### [Photo settings](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings\#Photo-settings)

[`class AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)

A specification of the features and settings to use for a single photo capture request.

[`class AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings)

A description of the features and settings in use for an in-progress or complete photo capture request.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotosettings

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCapturePhotoSettings

Class

# AVCapturePhotoSettings

A specification of the features and settings to use for a single photo capture request.

class AVCapturePhotoSettings

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#mentions)

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

[Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress)

[Capturing Thumbnail and Preview Images](https://developer.apple.com/documentation/avfoundation/capturing-thumbnail-and-preview-images)

[Capturing and Saving Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos)

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#overview)

To take a photo, you create and configure a [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object, then pass it to the [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method.

A [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) instance can include any combination of settings, regardless of whether that combination is valid for a given capture session. When you initiate a capture by passing a photo settings object to the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method, the photo capture output validates your settings to ensure deterministic behavior. For example, the [`flashMode`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/flashmode) setting must specify a value that’s present in the photo output’s [`supportedFlashModes`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedflashmodes-4u69s) array. For detailed validation rules, see each property description below.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#topics)

### [Creating photo settings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Creating-photo-settings)

[`convenience init(format: [String : Any]?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/init(format:))

Creates a photo settings object with the specified output format.

[`convenience init(rawPixelFormatType: OSType)`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/init(rawpixelformattype:))

Creates a photo settings object for RAW-format-only capture with the specified pixel format.

[`convenience init(rawPixelFormatType: OSType, processedFormat: [String : Any]?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/init(rawpixelformattype:processedformat:))

Creates a photo settings object for capture in both RAW format and a processed format.

[`convenience init(rawPixelFormatType: OSType, rawFileType: AVFileType?, processedFormat: [String : Any]?, processedFileType: AVFileType?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/init(rawpixelformattype:rawfiletype:processedformat:processedfiletype:))

Creates a photo settings object for capture in both RAW format and a processed format with the specified output file types.

[`convenience init(from: AVCapturePhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/init(from:))

Creates a unique photo settings object, copying all settings values from the specified photo settings object.

### [Inspecting settings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Inspecting-settings)

[`var uniqueID: Int64`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid)

A unique identifier for this photo settings instance.

[`var format: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/format)

A dictionary describing the processed format (for example, JPEG) to deliver captured photos in.

[`var processedFileType: AVFileType?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/processedfiletype)

The container file format for eventual output of the processed image.

[`var rawFileType: AVFileType?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawfiletype)

The container file format for eventual output of the RAW image.

[`var rawPhotoPixelFormatType: OSType`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawphotopixelformattype)

An identifier for the Bayer RAW pixel format to deliver captured RAW photos in.

### [Configuring photo settings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Configuring-photo-settings)

[`var flashMode: AVCaptureDevice.FlashMode`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/flashmode)

A setting for whether to fire the flash when capturing photos.

[`var isAutoRedEyeReductionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautoredeyereductionenabled)

A Boolean value that indicates whether to use auto red-eye reduction on flash captures.

[`var maxPhotoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/maxphotodimensions)

The maximum resolution of the photo to capture.

[`var photoQualityPrioritization: AVCapturePhotoOutput.QualityPrioritization`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/photoqualityprioritization)

A setting that indicates how to prioritize photo quality against speed of photo delivery.

[`var isCameraCalibrationDataDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/iscameracalibrationdatadeliveryenabled)

A Boolean value that determines whether a dual photo capture also delivers camera calibration data.

[`var isAutoContentAwareDistortionCorrectionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautocontentawaredistortioncorrectionenabled)

A Boolean value that specifies whether the photo output, at its discretion, uses content-aware distortion correction on this photo request.

[`var isAutoVirtualDeviceFusionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautovirtualdevicefusionenabled)

A Boolean value that specifies whether to use automatic virtual-device image fusion.

[`var virtualDeviceConstituentPhotoDeliveryEnabledDevices: [AVCaptureDevice]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/virtualdeviceconstituentphotodeliveryenableddevices)

The constituent devices for which the virtual device should deliver photos.

[`var isDualCameraDualPhotoDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isdualcameradualphotodeliveryenabled)

A Boolean value that determines whether a dual camera device delivers images from both cameras.

Deprecated

[`var isAutoDualCameraFusionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautodualcamerafusionenabled)

A Boolean value that specifies whether captures automatically combine data from a dual camera device.

[`var isAutoStillImageStabilizationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautostillimagestabilizationenabled)

A Boolean value that specifies whether captures use automatic image stabilization.

[`var isHighResolutionPhotoEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/ishighresolutionphotoenabled)

A Boolean value that specifies whether to capture still images at the highest resolution supported by the active device and format.

### [Suppressing the Shutter Sound](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Suppressing-the-Shutter-Sound)

[`var isShutterSoundSuppressionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isshuttersoundsuppressionenabled)

A Boolean value that indicates whether to suppress the built-in shutter sound when capturing a photo.

### [Enabling Preview and Thumbnail Delivery](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Enabling-Preview-and-Thumbnail-Delivery)

[`var previewPhotoFormat: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/previewphotoformat)

A dictionary describing the format for delivery of preview-sized images alongside the main photo.

[`var availablePreviewPhotoPixelFormatTypes: [OSType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/availablepreviewphotopixelformattypes-30d9)

An array of available of pixel format types available to specify a preview photo format.

[`var embeddedThumbnailPhotoFormat: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embeddedthumbnailphotoformat)

A dictionary describing the format for delivery of thumbnail images embedded in photo file output.

[`var availableRawEmbeddedThumbnailPhotoCodecTypes: [AVVideoCodecType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/availablerawembeddedthumbnailphotocodectypes)

An array of video codec types compatible with the photo settings for embedding raw thumbnail images in photo file output.

[`var rawEmbeddedThumbnailPhotoFormat: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawembeddedthumbnailphotoformat)

A dictionary describing the format for delivery of raw thumbnail images embedded in photo file output.

[`var availableEmbeddedThumbnailPhotoCodecTypes: [AVVideoCodecType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/availableembeddedthumbnailphotocodectypes)

An array of video codec types compatible with the photo settings for embedding thumbnail images in photo file output.

### [Configuring Live Photo Settings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Configuring-Live-Photo-Settings)

[`var livePhotoMovieFileURL: URL?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotomoviefileurl)

A URL at which to write Live Photo movie output.

[`var livePhotoMovieMetadata: [AVMetadataItem]!`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotomoviemetadata)

A dictionary of metadata to include in the Live Photo movie file.

[`var livePhotoVideoCodecType: AVVideoCodecType`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotovideocodectype)

The video codec to use for encoding the movie portion of Live Photo output.

### [Configuring Constant Color](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Configuring-Constant-Color)

[`var isConstantColorEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isconstantcolorenabled)

A Boolean value that indicates whether to capture the photo with constant color.

[`var isConstantColorFallbackPhotoDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isconstantcolorfallbackphotodeliveryenabled)

A Boolean value that indicates whether to deliver a fallback photo when taking a constant color capture.

### [Capturing Depth Data](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Capturing-Depth-Data)

[`var isDepthDataDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isdepthdatadeliveryenabled)

A Boolean value that determines whether the photo output captures depth data along with the photo.

[`var embedsDepthDataInPhoto: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedsdepthdatainphoto)

A Boolean value that determines whether any depth data captured with the photo is included when generating output file data.

[`var isDepthDataFiltered: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isdepthdatafiltered)

A Boolean value that determines whether to smooth noise and fill in missing values in depth data output.

### [Capturing Portrait Effects Matte](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Capturing-Portrait-Effects-Matte)

[`var isPortraitEffectsMatteDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isportraiteffectsmattedeliveryenabled)

Specifies whether a portrait effects matte should be captured along with the photo.

[`var embedsPortraitEffectsMatteInPhoto: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedsportraiteffectsmatteinphoto)

Specifies whether the portrait effects matte captured with ths photo should be written to the photo’s file structure.

### [Capturing Semantic Segmentation Mattes](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Capturing-Semantic-Segmentation-Mattes)

[`var embedsSemanticSegmentationMattesInPhoto: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedssemanticsegmentationmattesinphoto)

A Boolean value that specifies whether to write the enabled semantic segmentation matte types captured with this photo to the photo’s file structure.

[`var enabledSemanticSegmentationMatteTypes: [AVSemanticSegmentationMatte.MatteType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/enabledsemanticsegmentationmattetypes)

An array of semantic segmentation matte types that the photo render pipeline can deliver.

### [Embedding Metadata](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Embedding-Metadata)

[`var metadata: [String : Any]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/metadata)

A dictionary of metadata keys and values to embed in photo file output.

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Instance-Properties)

[`var rawFileFormat: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawfileformat)

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#inherited-by)

- [`AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#see-also)

### [Photo settings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings\#Photo-settings)

[`class AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings)

A specification of the features and settings to use for a photo capture request that captures multiple images with varied settings.

[`class AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings)

A description of the features and settings in use for an in-progress or complete photo capture request.

---

# https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureAutoExposureBracketedStillImageSettings

Class

# AVCaptureAutoExposureBracketedStillImageSettings

A configuration for defining bracketed photo captures in terms of bias relative to automatic exposure.

class AVCaptureAutoExposureBracketedStillImageSettings

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#mentions)

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#overview)

An [`AVCaptureAutoExposureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings) instance defines the exposure target bias setting that should be applied to one image in a bracket. An array of `AVCaptureAutoExposureBracketedStillImageSettings` objects is passed to `captureStillImageBracketAsynchronouslyFromConnection:withSettingsArray:completionHandler:` to specify the bracketing.

The minimum and maximum exposure target bias are properties of the [`AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice) instance supplying data to an [`AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput) instance. If you wish to leave [`exposureTargetBias`](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings/exposuretargetbias) unchanged for this bracketed still image, you may pass the value `AVCaptureExposureTargetBiasCurrent`.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#topics)

### [Creating an Auto Exposure Settings Instance](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#Creating-an-Auto-Exposure-Settings-Instance)

Creates an `AVCaptureAutoExposureBracketedStillImageSettings` using the specified exposure target bias.

### [Getting the Exposure Target Bias](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#Getting-the-Exposure-Target-Bias)

[`var exposureTargetBias: Float`](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings/exposuretargetbias)

The exposure bias for the auto exposure bracketed settings

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#inherits-from)

- [`AVCaptureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturebracketedstillimagesettings)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#see-also)

### [Bracketed Settings Types](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings\#Bracketed-Settings-Types)

[`class AVCaptureManualExposureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings)

A configuration for defining bracketed photo captures in terms of specific exposure and ISO values.

[`class AVCaptureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturebracketedstillimagesettings)

The abstract superclass for bracketed photo capture settings.

---

# https://developer.apple.com/documentation/avfoundation/capturing-uncompressed-image-data

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Photo capture](https://developer.apple.com/documentation/avfoundation/photo-capture)
- [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos)
- Capturing Uncompressed Image Data

Article

# Capturing Uncompressed Image Data

Get processed image data without compression to use for filtering or lossless output.

## [Overview](https://developer.apple.com/documentation/avfoundation/capturing-uncompressed-image-data\#overview)

Typical photography workflows save images in a compressed format such as HEIF/HEVC or JPEG. These formats use lossy compression to strike a balance between preserving noticeable details in the image and reducing its data storage requirements. However, sometimes it’s more helpful to work with uncompressed image data—for example, some image processing and analysis algorithms can be confused by the visual artifacts introduced by lossy compression.

In iOS, capturing uncompressed image data requires minor changes to the basic photography workflow covered in [Capturing Still and Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-still-and-live-photos).

### [Choose Uncompressed Format Settings](https://developer.apple.com/documentation/avfoundation/capturing-uncompressed-image-data\#Choose-Uncompressed-Format-Settings)

To capture in an uncompressed format, create a photo settings object with [`init(format:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/init(format:)). In the format dictionary, specify the [`kCVPixelBufferPixelFormatTypeKey`](https://developer.apple.com/documentation/CoreVideo/kCVPixelBufferPixelFormatTypeKey) with one of the values listed in the photo output’s [`availablePhotoPixelFormatTypes`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablephotopixelformattypes-6eyb) array. The example below chooses a 32-bit BGRA pixel format, which is useful in some GPU processing workflows:

// Choose a 32-bit BGRA pixel format and verify the camera supports it.
let pixelFormatType = kCVPixelFormatType_32BGRA
guard self.photoOutput.availablePhotoPixelFormatTypes.contains(pixelFormatType) else { return }
let photoSettings = AVCapturePhotoSettings(format:
[ kCVPixelBufferPixelFormatTypeKey as String : pixelFormatType ])

// Shoot the photo, using a custom class to handle capture delegate callbacks.
let layerOrientation = previewView.videoPreviewLayer.connection!.videoOrientation
let colorSpace = self.videoCaptureDevice.activeColorSpace
let captureProcessor = UncompressedCaptureProcessor(orientation: layerOrientation,
colorSpace: colorSpace)
self.photoOutput.capturePhoto(with: photoSettings, delegate: captureProcessor)

### [Handle Results](https://developer.apple.com/documentation/avfoundation/capturing-uncompressed-image-data\#Handle-Results)

As with other formats, you receive uncompressed data capture results to your delegate’s [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method as an [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object. To access the uncompressed pixel data directly, use the photo’s [`pixelBuffer`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/pixelbuffer) property.

For example, the following code applies a Core Image filter directly to the pixel buffer and writes the filtered image to a PNG file:

class UncompressedCaptureProcessor: NSObject, AVCapturePhotoCaptureDelegate {

// Hold on to the separately delivered RAW and compressed photo data until capture is finished.
func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
guard error != nil else { print("Error capturing photo: \(error!)"); return }

// Create a CIImage from the pixel buffer and apply a filter
let image = CIImage(cvPixelBuffer: photo.pixelBuffer!)
let imageOrientation = self.imageOrientation(for: videoOrientation)
let filteredImage = image.oriented(imageOrientation)
.applyingFilter("CIPhotoEffectNoir", parameters: [:])

let imageColorSpace = self.imageColorSpace(for: colorSpace)
guard let pngData = CIContext()
.pngRepresentation(of: filteredImage, format: kCIFormatBGRA8, colorSpace: imageColorSpace)
else { print("Error creating filtered PNG image"); return }
self.exportToFile(pngData)
}
}

Alternatively, to get an uncompressed photo ready for writing to a file, use the photo’s [`fileDataRepresentation()`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation()) method to get the data formatted as a TIFF file.

## [See Also](https://developer.apple.com/documentation/avfoundation/capturing-uncompressed-image-data\#see-also)

### [More Capture Options](https://developer.apple.com/documentation/avfoundation/capturing-uncompressed-image-data\#More-Capture-Options)

[Capturing Photos with Depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)

Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

Capture several photos at once, varying parameters like exposure duration or light sensitivity.

[Capturing Thumbnail and Preview Images](https://developer.apple.com/documentation/avfoundation/capturing-thumbnail-and-preview-images)

Enable delivery of reduced-size images with the main image in a photo capture.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhoto](https://developer.apple.com/documentation/avfoundation/avcapturephoto)
- photoCount

Instance Property

# photoCount

The 1-based index of this photo capture relative to other results from the same capture request.

var photoCount: Int { get }

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount\#mentions)

[Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress)

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount\#Discussion)

The [`expectedPhotoCount`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/expectedphotocount) property of this capture result’s [`resolvedSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/resolvedsettings) object indicates the total number of images that will be returned for a given capture request. When your delegate’s [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method receives a photo whose [`photoCount`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount) value matches the [`expectedPhotoCount`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/expectedphotocount) value, you know you’ve received the last one for the given capture request.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount\#see-also)

### [Resolving Photo Capture Requests](https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount\#Resolving-Photo-Capture-Requests)

[`var resolvedSettings: AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/resolvedsettings)

The settings object that was used to request this photo capture.

[`var timestamp: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/timestamp)

The time at which the image was captured.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephoto

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCapturePhoto

Class

# AVCapturePhoto

A container for image data from a photo capture output.

class AVCapturePhoto

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#mentions)

[Configuring Camera Capture to Collect a Portrait Effects Matte](https://developer.apple.com/documentation/avfoundation/configuring-camera-capture-to-collect-a-portrait-effects-matte)

[Saving Captured Photos](https://developer.apple.com/documentation/avfoundation/saving-captured-photos)

[Capturing and Saving Live Photos](https://developer.apple.com/documentation/avfoundation/capturing-and-saving-live-photos)

[Capturing Thumbnail and Preview Images](https://developer.apple.com/documentation/avfoundation/capturing-thumbnail-and-preview-images)

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#overview)

When you capture photos with the [`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) class, your delegate object receives each resulting image and related data in the form of an [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object. This object is an immutable wrapper from which you can retrieve various results of the photo capture.

In addition to the photo image pixel buffer, an AVCapturePhoto object can also contain a preview-sized pixel buffer, capture metadata, and, on supported devices, depth data and camera calibration data. From an [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object, you can generate data appropriate for writing to a file, such as HEVC encoded image data containerized in the HEIC file format and including a preview image, depth data and other attachments.

An [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) instance wraps a single image result. For example, if you request a bracketed capture of three images, your callback is called three times, each time delivering a single [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#topics)

### [Resolving Photo Capture Requests](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Resolving-Photo-Capture-Requests)

[`var resolvedSettings: AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/resolvedsettings)

The settings object that was used to request this photo capture.

[`var photoCount: Int`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/photocount)

The 1-based index of this photo capture relative to other results from the same capture request.

[`var timestamp: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/timestamp)

The time at which the image was captured.

### [Accessing Photo Pixel Data](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Accessing-Photo-Pixel-Data)

[`var isRawPhoto: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/israwphoto)

A Boolean value indicating whether this photo object contains RAW format data.

[`var pixelBuffer: CVPixelBuffer?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/pixelbuffer)

The uncompressed or RAW image sample buffer for the photo, if requested.

### [Accessing Preview Photo Data](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Accessing-Preview-Photo-Data)

[`var embeddedThumbnailPhotoFormat: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/embeddedthumbnailphotoformat)

A dictionary describing the data format for a preview-sized image accompanying the captured photo.

[`var previewPixelBuffer: CVPixelBuffer?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/previewpixelbuffer)

The pixel data for a preview-sized version of the photo, if requested.

### [Accessing Photo Metadata](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Accessing-Photo-Metadata)

[`var depthData: AVDepthData?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/depthdata)

Depth or disparity map data captured with the photo.

[`var cameraCalibrationData: AVCameraCalibrationData?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/cameracalibrationdata)

Calibration information for the camera device that captured the photo.

[`var sourceDeviceType: AVCaptureDevice.DeviceType?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/sourcedevicetype)

The type of device that captured the photo.

[`var metadata: [String : Any]`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/metadata)

A dictionary of metadata describing the captured image.

[`var portraitEffectsMatte: AVPortraitEffectsMatte?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/portraiteffectsmatte)

The portrait effects matte captured with the photo.

### [Packaging Data for File Output](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Packaging-Data-for-File-Output)

Gets a customized representation of the photo data.

[`protocol AVCapturePhotoFileDataRepresentationCustomizer`](https://developer.apple.com/documentation/avfoundation/avcapturephotofiledatarepresentationcustomizer)

A protocol that defines the methods to implement to customize the packaging of photo data.

Generates and returns a flat data representation of the photo and its attachments.

Extracts and returns the captured photo’s primary image as a Core Graphics image object.

Extracts and returns the captured photo’s preview image as a Core Graphics image object.

Generates and returns a flat data representation of the photo using the specified replacements for some or all of its attachments.

Deprecated

### [Enabling Constant Color](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Enabling-Constant-Color)

[`var constantColorCenterWeightedMeanConfidenceLevel: Float`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/constantcolorcenterweightedmeanconfidencelevel)

A score that summarizes the overall confidence level of a constant color photo.

[`var constantColorConfidenceMap: CVPixelBuffer?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/constantcolorconfidencemap)

A pixel buffer where each pixel value indicates how fully the system achieves the constant color effect in the corresponding region of the photo.

[`var isConstantColorFallbackPhoto: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/isconstantcolorfallbackphoto)

A Boolean value that Indicates whether this photo is a fallback photo for a constant color capture.

### [Examining Bracketed Capture Information](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Examining-Bracketed-Capture-Information)

[`var bracketSettings: AVCaptureBracketedStillImageSettings?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/bracketsettings)

The variations available for bracketed capture settings for this photo.

[`var sequenceCount: Int`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/sequencecount)

The 1-based index of this photo in a bracketed capture sequence.

[`var lensStabilizationStatus: AVCaptureDevice.LensStabilizationStatus`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/lensstabilizationstatus)

Information about the use of lens stabilization during bracketed photo capture.

[`enum LensStabilizationStatus`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus)

Constants that indicate the status of optical image stabilization hardware during a bracketed photo capture.

### [Accessing Segmentation Mattes](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Accessing-Segmentation-Mattes)

Retrieves the semantic segmentation matte associated with this photo.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#inherited-by)

- [`AVCaptureDeferredPhotoProxy`](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#see-also)

### [Photo capture](https://developer.apple.com/documentation/avfoundation/avcapturephoto\#Photo-capture)

[Capturing consistent color images](https://developer.apple.com/documentation/avfoundation/capturing-consistent-color-images)

Add the power of a photography studio and lighting rig to your app with the new Constant Color API.

Configure and capture single or multiple still images, Live Photos, and other forms of photography.

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

Support professional photography workflows by enabling minimally processed image capture in your camera app.

[Supporting Continuity Camera in Your Mac App](https://developer.apple.com/documentation/AppKit/supporting-continuity-camera-in-your-mac-app)

Incorporate scanned documents and pictures from a user’s iPhone, iPad, or iPod touch into your Mac app using Continuity Camera.

[`class AVCaptureDeferredPhotoProxy`](https://developer.apple.com/documentation/avfoundation/avcapturedeferredphotoproxy)

A lightly-processed photo with data that the system may use to process and fetch a higher-resolution asset at a later time.

[`class AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)

A capture output for still image, Live Photos, and other photography workflows.

[`protocol AVCapturePhotoCaptureDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)

Methods for monitoring progress and receiving results from a photo capture output.

[`class AVCapturePhotoOutputReadinessCoordinator`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinator)

An object that monitors changes to a photo output’s capture readiness.

[`protocol AVCapturePhotoOutputReadinessCoordinatorDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutputreadinesscoordinatordelegate)

A delegate protocol to receive updates about a photo output’s capture readiness.

[`class AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput)

A capture output for capturing still photos.

---

# https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVSampleBufferAudioRenderer

Class

# AVSampleBufferAudioRenderer

An object used to decompress audio and play compressed or uncompressed audio.

class AVSampleBufferAudioRenderer

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#mentions)

[Implementing flexible enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content)

[Supporting AirPlay in your app](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app)

## [Overview](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#overview)

You must add an instance of this class to an [`AVSampleBufferRenderSynchronizer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer) before queuing the first sample buffer.

## [Topics](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#topics)

### [Determining Rendering Status](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#Determining-Rendering-Status)

[`var status: AVQueuedSampleBufferRenderingStatus`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer/status)

The status of the audio renderer.

[`enum AVQueuedSampleBufferRenderingStatus`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus)

The statuses for sample buffer rendering.

### [Removing Queued Buffers](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#Removing-Queued-Buffers)

Flushes queued sample buffers with presentation time stamps later than or equal to the specified time.

[`let AVSampleBufferAudioRendererFlushTimeKey: String`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorendererflushtimekey)

The key that indicates the presentation timestamp of the first queued sample that was flushed.

### [Configuring Time and Pitch](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#Configuring-Time-and-Pitch)

[`var audioTimePitchAlgorithm: AVAudioTimePitchAlgorithm`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer/audiotimepitchalgorithm)

The processing algorithm used to manage audio pitch at different rates.

[`struct AVAudioTimePitchAlgorithm`](https://developer.apple.com/documentation/avfoundation/avaudiotimepitchalgorithm)

An algorithm used to set the audio pitch as the rate changes.

### [Configuring Audio Spatialization](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#Configuring-Audio-Spatialization)

[`var allowedAudioSpatializationFormats: AVAudioSpatializationFormats`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer/allowedaudiospatializationformats)

The source audio channel layouts the audio renderer supports for spatialization.

### [Managing Audio Output](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#Managing-Audio-Output)

[`var volume: Float`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer/volume)

The current audio volume for the audio renderer.

[`var isMuted: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer/ismuted)

A Boolean value that indicates whether audio for the renderer is in a muted state.

[`var audioOutputDeviceUniqueID: String?`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer/audiooutputdeviceuniqueid)

The unique identifier of the output device used to play audio.

### [Responding to Errors](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#Responding-to-Errors)

[`var error: (any Error)?`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer/error)

The error that caused the renderer to no longer render sample buffers.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#conforms-to)

- [`AVQueuedSampleBufferRendering`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrendering)
- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#see-also)

### [Presentation](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer\#Presentation)

[`protocol AVQueuedSampleBufferRendering`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrendering)

Methods you can implement to enqueue sample buffers for presentation.

[`class AVSampleBufferRenderSynchronizer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer)

An object used to synchronize multiple queued sample buffers to a single timeline.

[`class AVSampleBufferDisplayLayer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer)

An object that displays compressed or uncompressed video frames.

[`class AVSampleBufferVideoRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebuffervideorenderer)

An object that enqueues video sample buffers for rendering.

---

# https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureManualExposureBracketedStillImageSettings

Class

# AVCaptureManualExposureBracketedStillImageSettings

A configuration for defining bracketed photo captures in terms of specific exposure and ISO values.

class AVCaptureManualExposureBracketedStillImageSettings

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#mentions)

[Capturing a Bracketed Photo Sequence](https://developer.apple.com/documentation/avfoundation/capturing-a-bracketed-photo-sequence)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#overview)

The `AVCaptureManualExposureBracketedStillImageSettings` class is a concrete subclass of the `AVCaptureBracketedStillImageSettings` class used when bracketing exposure duration and ISO.

An `AVCaptureManualExposureBracketedStillImageSettings` instance defines exposure duration and ISO settings that should be applied to one image in a bracket. An array of `AVCaptureManualExposureBracketedStillImageSettings` objects is passed to `captureStillImageBracketAsynchronouslyFromConnection:withSettingsArray:completionHandler:` to specify the bracketing.

You can query the minimum and maximum duration and ISO properties of the [`AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice) instance supplying data to an [`AVCaptureStillImageOutput`](https://developer.apple.com/documentation/avfoundation/avcapturestillimageoutput) instance. If you wish to leave [`exposureDuration`](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings/exposureduration) unchanged for this bracketed still image, you pass the value `AVCaptureExposureDurationCurrent` when creating the instance. To keep the ISO unchanged, you pass `AVCaptureISOCurrent` when creating the instance.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#topics)

### [Creating a Manual Bracketed Exposure Settings Instance](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#Creating-a-Manual-Bracketed-Exposure-Settings-Instance)

Creates a configuration of still image settings using the specified exposure duration and ISO.

### [Getting Manual Exposure Setting Values](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#Getting-Manual-Exposure-Setting-Values)

[`var iso: Float`](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings/iso)

The ISO for the still image.

[`var exposureDuration: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings/exposureduration)

The exposure duration for the still image.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#inherits-from)

- [`AVCaptureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturebracketedstillimagesettings)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#see-also)

### [Bracketed Settings Types](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings\#Bracketed-Settings-Types)

[`class AVCaptureAutoExposureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureautoexposurebracketedstillimagesettings)

A configuration for defining bracketed photo captures in terms of bias relative to automatic exposure.

[`class AVCaptureBracketedStillImageSettings`](https://developer.apple.com/documentation/avfoundation/avcapturebracketedstillimagesettings)

The abstract superclass for bracketed photo capture settings.

---

# https://developer.apple.com/documentation/avfoundation/avplayer

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayer

Class

# AVPlayer

An object that provides the interface to control the player’s transport behavior.

@MainActor
class AVPlayer

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avplayer\#mentions)

[Controlling the transport behavior of a player](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player)

[Supporting AirPlay in your app](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app)

[Observing playback state in SwiftUI](https://developer.apple.com/documentation/avfoundation/observing-playback-state-in-swiftui)

[Selecting Subtitles and Alternative Audio Tracks](https://developer.apple.com/documentation/avfoundation/selecting-subtitles-and-alternative-audio-tracks)

[Monitoring playback progress in your app](https://developer.apple.com/documentation/avfoundation/monitoring-playback-progress-in-your-app)

## [Overview](https://developer.apple.com/documentation/avfoundation/avplayer\#overview)

A player is a controller object that manages the playback and timing of a media asset. Use an instance of [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) to play local and remote file-based media, such as QuickTime movies and MP3 audio files, as well as audiovisual media served using HTTP Live Streaming.

Use a player object to play a single media asset. You can reuse the player instance to play additional media assets using its [`replaceCurrentItem(with:)`](https://developer.apple.com/documentation/avfoundation/avplayer/replacecurrentitem(with:)) method, but it manages the playback of only a single media asset at a time. The framework also provides a subclass called [`AVQueuePlayer`](https://developer.apple.com/documentation/avfoundation/avqueueplayer) that you can use to manage the playback of a queue of media assets.

You use an [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) to play media assets, which AVFoundation represents using the [`AVAsset`](https://developer.apple.com/documentation/avfoundation/avasset) class. [`AVAsset`](https://developer.apple.com/documentation/avfoundation/avasset) only models the _static_ aspects of the media, such as its duration or creation date, and on its own, isn’t suitable for playback with an [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer). To play an asset, you create an instance of its _dynamic_ counterpart found in [`AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem). This object models the timing and presentation state of an asset played by an instance of [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer). See the [`AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem) reference for more details.

[`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) is a dynamic object whose state continuously changes. There are two approaches you can use to observe a player’s state:

- **General State Observations:** You can use key-value observing (KVO) to observe state changes to many of the player’s dynamic properties, such as its [`currentItem`](https://developer.apple.com/documentation/avfoundation/avplayer/currentitem) or its playback [`rate`](https://developer.apple.com/documentation/avfoundation/avplayer/rate).

- **Timed State Observations:** KVO works well for general state observations, but isn’t intended for observing continuously changing state like the player’s time. [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) provides two methods to observe time changes:

- [`addPeriodicTimeObserver(forInterval:queue:using:)`](https://developer.apple.com/documentation/avfoundation/avplayer/addperiodictimeobserver(forinterval:queue:using:))

- [`addBoundaryTimeObserver(forTimes:queue:using:)`](https://developer.apple.com/documentation/avfoundation/avplayer/addboundarytimeobserver(fortimes:queue:using:))

These methods let you observe time changes either periodically or by boundary, respectively. As changes occur, invoke the callback block or closure you supply to these methods to give you the opportunity to take some action such as updating the state of your player’s user interface.

[`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) and [`AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem) are nonvisual objects, meaning that on their own they’re unable to present an asset’s video onscreen. There are two primary approaches you use to present your video content onscreen:

- **AVKit:** The best way to present your video content is with the AVKit framework’s [`AVPlayerViewController`](https://developer.apple.com/documentation/AVKit/AVPlayerViewController) class in iOS and tvOS, or the [`AVPlayerView`](https://developer.apple.com/documentation/AVKit/AVPlayerView) class in macOS. These classes present the video content, along with playback controls and other media features giving you a full-featured playback experience.

- **AVPlayerLayer:** When building a custom interface for your player, use [`AVPlayerLayer`](https://developer.apple.com/documentation/avfoundation/avplayerlayer). You can set this layer a view’s backing layer or add it directly to the layer hierarchy. Unlike [`AVPlayerView`](https://developer.apple.com/documentation/AVKit/AVPlayerView) and [`AVPlayerViewController`](https://developer.apple.com/documentation/AVKit/AVPlayerViewController), a player layer doesn’t present any playback controls—it only presents the visual content onscreen. It’s up to you to build the playback transport controls to play, pause, and seek through the media.

Alongside the visual content presented with AVKit or [`AVPlayerLayer`](https://developer.apple.com/documentation/avfoundation/avplayerlayer), you can also present animated content synchronized with the player’s timing using [`AVSynchronizedLayer`](https://developer.apple.com/documentation/avfoundation/avsynchronizedlayer). Use a synchronized layer pass along player timing to its layer subtree. You can use [`AVSynchronizedLayer`](https://developer.apple.com/documentation/avfoundation/avsynchronizedlayer) to build custom effects in Core Animation, such as animated lower thirds or video transitions, and have them play in sync with the timing of the player’s current [`AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem).

## [Topics](https://developer.apple.com/documentation/avfoundation/avplayer\#topics)

### [Creating a Player](https://developer.apple.com/documentation/avfoundation/avplayer\#Creating-a-Player)

[`init(url: URL)`](https://developer.apple.com/documentation/avfoundation/avplayer/init(url:))

Creates a new player to play a single audiovisual resource referenced by a given URL.

[`init(playerItem: AVPlayerItem?)`](https://developer.apple.com/documentation/avfoundation/avplayer/init(playeritem:))

Creates a new player to play the specified player item.

[`init()`](https://developer.apple.com/documentation/avfoundation/avplayer/init())

Creates a player object.

### [Managing the Player Item](https://developer.apple.com/documentation/avfoundation/avplayer\#Managing-the-Player-Item)

[`var currentItem: AVPlayerItem?`](https://developer.apple.com/documentation/avfoundation/avplayer/currentitem)

The item for which the player is currently controlling playback.

[`func replaceCurrentItem(with: AVPlayerItem?)`](https://developer.apple.com/documentation/avfoundation/avplayer/replacecurrentitem(with:))

Replaces the current item with a new item.

### [Determining Player Readiness](https://developer.apple.com/documentation/avfoundation/avplayer\#Determining-Player-Readiness)

[`var status: AVPlayer.Status`](https://developer.apple.com/documentation/avfoundation/avplayer/status-swift.property)

A value that indicates the readiness of a player object for playback.

[`enum Status`](https://developer.apple.com/documentation/avfoundation/avplayer/status-swift.enum)

Status values that indicate whether a player can successfully play media.

[`var error: (any Error)?`](https://developer.apple.com/documentation/avfoundation/avplayer/error)

An error that caused a failure.

### [Controlling Playback](https://developer.apple.com/documentation/avfoundation/avplayer\#Controlling-Playback)

[`var defaultRate: Float`](https://developer.apple.com/documentation/avfoundation/avplayer/defaultrate)

A default rate at which to begin playback.

[`func play()`](https://developer.apple.com/documentation/avfoundation/avplayer/play())

Begins playback of the current item.

[`func pause()`](https://developer.apple.com/documentation/avfoundation/avplayer/pause())

Pauses playback of the current item.

[`var rate: Float`](https://developer.apple.com/documentation/avfoundation/avplayer/rate)

The current playback rate.

[`class let rateDidChangeNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avplayer/ratedidchangenotification)

A notification that a player posts when its rate changes.

### [Observing Playback Time](https://developer.apple.com/documentation/avfoundation/avplayer\#Observing-Playback-Time)

Returns the current time of the current player item.

Requests the invocation of a block when specified times are traversed during normal playback.

[`func removeTimeObserver(Any)`](https://developer.apple.com/documentation/avfoundation/avplayer/removetimeobserver(_:))

Cancels a previously registered periodic or boundary time observer.

### [Seeking Through Media](https://developer.apple.com/documentation/avfoundation/avplayer\#Seeking-Through-Media)

[`func seek(to: CMTime)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:)-87h2r)

Requests that the player seek to a specified time.

Requests that the player seek to a specified time, and to notify you when the seek is complete.

[`func seek(to: CMTime, toleranceBefore: CMTime, toleranceAfter: CMTime)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:tolerancebefore:toleranceafter:))

Requests that the player seek to a specified time with the amount of accuracy specified by the time tolerance values.

Requests that the player seek to a specified time with the amount of accuracy specified by the time tolerance values, and to notify you when the seek is complete.

[`func seek(to: Date)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:)-9h9qr)

Requests that the player seek to a specified date.

Requests that the player seek to a specified date, and to notify you when the seek is complete.

### [Configuring Waiting Behavior](https://developer.apple.com/documentation/avfoundation/avplayer\#Configuring-Waiting-Behavior)

[`var automaticallyWaitsToMinimizeStalling: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/automaticallywaitstominimizestalling)

A Boolean value that indicates whether the player should automatically delay playback in order to minimize stalling.

[`var reasonForWaitingToPlay: AVPlayer.WaitingReason?`](https://developer.apple.com/documentation/avfoundation/avplayer/reasonforwaitingtoplay)

The reason the player is currently waiting for play

The reasons a player is waiting to begin or resume playback.

[`var timeControlStatus: AVPlayer.TimeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.property)

A value that indicates whether playback is in progress, paused indefinitely, or waiting for network conditions to improve.

[`enum TimeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.enum)

Constants that indicate the state of playback control.

[`func playImmediately(atRate: Float)`](https://developer.apple.com/documentation/avfoundation/avplayer/playimmediately(atrate:))

Plays the available media data immediately, at the specified rate.

### [Responding When Playback Ends](https://developer.apple.com/documentation/avfoundation/avplayer\#Responding-When-Playback-Ends)

[`var actionAtItemEnd: AVPlayer.ActionAtItemEnd`](https://developer.apple.com/documentation/avfoundation/avplayer/actionatitemend-swift.property)

The action to perform when the current player item has finished playing.

[`enum ActionAtItemEnd`](https://developer.apple.com/documentation/avfoundation/avplayer/actionatitemend-swift.enum)

The actions a player can take when it finishes playing.

### [Configuring Media Selection Criteria](https://developer.apple.com/documentation/avfoundation/avplayer\#Configuring-Media-Selection-Criteria)

[`var appliesMediaSelectionCriteriaAutomatically: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/appliesmediaselectioncriteriaautomatically)

A Boolean value that indicates whether the receiver should apply the current selection criteria automatically to player items.

Returns the automatic selection criteria for media items with the specified media characteristic.

[`func setMediaSelectionCriteria(AVPlayerMediaSelectionCriteria?, forMediaCharacteristic: AVMediaCharacteristic)`](https://developer.apple.com/documentation/avfoundation/avplayer/setmediaselectioncriteria(_:formediacharacteristic:))

Applies automatic selection criteria for media that has the specified media characteristic.

### [Accessing Player Output](https://developer.apple.com/documentation/avfoundation/avplayer\#Accessing-Player-Output)

[`var videoOutput: AVPlayerVideoOutput?`](https://developer.apple.com/documentation/avfoundation/avplayer/videooutput)

The video output for this player.

### [Configuring Audio Behavior](https://developer.apple.com/documentation/avfoundation/avplayer\#Configuring-Audio-Behavior)

[`var volume: Float`](https://developer.apple.com/documentation/avfoundation/avplayer/volume)

The audio playback volume for the player.

[`var isMuted: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/ismuted)

A Boolean value that indicates whether the audio output of the player is muted.

[`var allowedAudioSpatializationFormats: AVAudioSpatializationFormats`](https://developer.apple.com/documentation/avfoundation/avplayeritem/allowedaudiospatializationformats)

The source audio channel layouts the player item supports for spatialization.

[`var isAudioSpatializationAllowed: Bool`](https://developer.apple.com/documentation/avfoundation/avplayeritem/isaudiospatializationallowed)

A Boolean value that indicates whether the player item allows spatialized audio playback.

Deprecated

### [Configuring Background Playback](https://developer.apple.com/documentation/avfoundation/avplayer\#Configuring-Background-Playback)

[`var audiovisualBackgroundPlaybackPolicy: AVPlayerAudiovisualBackgroundPlaybackPolicy`](https://developer.apple.com/documentation/avfoundation/avplayer/audiovisualbackgroundplaybackpolicy)

A policy that determines how playback of audiovisual media continues when the app transitions to the background.

[`enum AVPlayerAudiovisualBackgroundPlaybackPolicy`](https://developer.apple.com/documentation/avfoundation/avplayeraudiovisualbackgroundplaybackpolicy)

Policies that describe playback behavior when an app transitions to the background while playing video.

### [Managing External Playback](https://developer.apple.com/documentation/avfoundation/avplayer\#Managing-External-Playback)

[`var allowsExternalPlayback: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/allowsexternalplayback)

A Boolean value that indicates whether the player allows switching to external playback mode.

[`var isExternalPlaybackActive: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/isexternalplaybackactive)

A Boolean value that indicates whether the player is currently playing video in external playback mode.

[`var usesExternalPlaybackWhileExternalScreenIsActive: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/usesexternalplaybackwhileexternalscreenisactive)

A Boolean value that indicates whether the player should automatically switch to external playback mode while the external screen mode is active.

[`var externalPlaybackVideoGravity: AVLayerVideoGravity`](https://developer.apple.com/documentation/avfoundation/avplayer/externalplaybackvideogravity)

The video gravity of the player for external playback mode only.

### [Determining HDR Playback Eligibility](https://developer.apple.com/documentation/avfoundation/avplayer\#Determining-HDR-Playback-Eligibility)

[`class var eligibleForHDRPlayback: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/eligibleforhdrplayback)

A Boolean value that indicates whether the current device can present content to an HDR display.

[`class var availableHDRModes: AVPlayer.HDRMode`](https://developer.apple.com/documentation/avfoundation/avplayer/availablehdrmodes)

The HDR modes that are available for playback.

[`struct HDRMode`](https://developer.apple.com/documentation/avfoundation/avplayer/hdrmode)

A bitfield type that specifies an HDR mode.

[`class let eligibleForHDRPlaybackDidChangeNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avplayer/eligibleforhdrplaybackdidchangenotification)

A notification that’s posted whenever HDR playback eligibility changes.

### [Coordinating Playback](https://developer.apple.com/documentation/avfoundation/avplayer\#Coordinating-Playback)

[`var playbackCoordinator: AVPlayerPlaybackCoordinator`](https://developer.apple.com/documentation/avfoundation/avplayer/playbackcoordinator)

The playback coordinator for the player.

### [Synchronizing Multiple Players](https://developer.apple.com/documentation/avfoundation/avplayer\#Synchronizing-Multiple-Players)

The advanced synchronization and rate control methods in this section are currently only supported for file-based media and are not supported for media served using HTTP Live Streaming.

[`func setRate(Float, time: CMTime, atHostTime: CMTime)`](https://developer.apple.com/documentation/avfoundation/avplayer/setrate(_:time:athosttime:))

Synchronizes the playback rate and time of the current item with an external source.

Begins loading media data to prime the media pipelines for playback.

[`func cancelPendingPrerolls()`](https://developer.apple.com/documentation/avfoundation/avplayer/cancelpendingprerolls())

Cancels any pending preroll requests and invokes the corresponding completion handlers, if present.

[`var sourceClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avplayer/sourceclock)

A clock the player uses for item time bases.

[`var masterClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avplayer/masterclock)

The host clock for item time bases.

### [Preventing Sleep and Backgrounding](https://developer.apple.com/documentation/avfoundation/avplayer\#Preventing-Sleep-and-Backgrounding)

[`var preventsDisplaySleepDuringVideoPlayback: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/preventsdisplaysleepduringvideoplayback)

A Boolean value that indicates whether video playback prevents display and device sleep.

[`var preventsAutomaticBackgroundingDuringVideoPlayback: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/preventsautomaticbackgroundingduringvideoplayback)

A Boolean value that indicates whether video playback prevents the system from automatically backgrounding the app.

### [Determining Content Protections](https://developer.apple.com/documentation/avfoundation/avplayer\#Determining-Content-Protections)

[`var isOutputObscuredDueToInsufficientExternalProtection: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/isoutputobscuredduetoinsufficientexternalprotection)

A Boolean value that indicates whether output is being obscured because of insufficient external protection.

### [Configuring Audio and Video Devices](https://developer.apple.com/documentation/avfoundation/avplayer\#Configuring-Audio-and-Video-Devices)

[`var audioOutputDeviceUniqueID: String?`](https://developer.apple.com/documentation/avfoundation/avplayer/audiooutputdeviceuniqueid)

Specifies the unique ID of the Core Audio output device used to play audio.

[`var preferredVideoDecoderGPURegistryID: UInt64`](https://developer.apple.com/documentation/avfoundation/avplayer/preferredvideodecodergpuregistryid)

The registry identifier for the GPU used for video decoding.

### [Configuring AirPlay Behavior](https://developer.apple.com/documentation/avfoundation/avplayer\#Configuring-AirPlay-Behavior)

[`var allowsAirPlayVideo: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/allowsairplayvideo)

A Boolean value that indicates whether the player allows AirPlay video playback.

[`var isAirPlayVideoActive: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/isairplayvideoactive)

A Boolean value that indicates whether the player is playing video through AirPlay.

[`var usesAirPlayVideoWhileAirPlayScreenIsActive: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/usesairplayvideowhileairplayscreenisactive)

A Boolean value that indicates whether the player automatically switches to AirPlay Video while AirPlay Screen is active.

### [Displaying Closed Captions](https://developer.apple.com/documentation/avfoundation/avplayer\#Displaying-Closed-Captions)

[`var isClosedCaptionDisplayEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/isclosedcaptiondisplayenabled)

A Boolean value that indicates whether the player uses closed captioning.

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avplayer\#Instance-Properties)

[`var audioOutputSuppressedDueToNonMixableAudioRoute: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/audiooutputsuppressedduetononmixableaudioroute)

Whether the player’s audio output is suppressed due to being on a non-mixable audio route.

Beta

[`var intendedSpatialAudioExperience: any SpatialAudioExperience`](https://developer.apple.com/documentation/avfoundation/avplayer/intendedspatialaudioexperience-1bd87)

The AVPlayer’s intended spatial audio experience.

[`var networkResourcePriority: AVPlayer.NetworkResourcePriority`](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.property)

Indicates the priority of this player for network bandwidth resource distribution.

### [Type Properties](https://developer.apple.com/documentation/avfoundation/avplayer\#Type-Properties)

[`class var isObservationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/isobservationenabled)

AVPlayer and other AVFoundation types can optionally be observed using Swift Observation.

### [Enumerations](https://developer.apple.com/documentation/avfoundation/avplayer\#Enumerations)

[`enum NetworkResourcePriority`](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum)

This defines the network resource priority for a player.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avplayer\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avplayer\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avplayer\#inherited-by)

- [`AVQueuePlayer`](https://developer.apple.com/documentation/avfoundation/avqueueplayer)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avplayer\#conforms-to)

- [`AVRoutingPlaybackParticipant`](https://developer.apple.com/documentation/AVRouting/AVRoutingPlaybackParticipant)
- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`Copyable`](https://developer.apple.com/documentation/Swift/Copyable)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Observable`](https://developer.apple.com/documentation/Observation/Observable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer\#see-also)

### [Playback control](https://developer.apple.com/documentation/avfoundation/avplayer\#Playback-control)

Keep your user interface in sync with state changes from playback objects.

Play, pause, and seek through a media presentation.

[Creating a seamless multiview playback experience](https://developer.apple.com/documentation/avfoundation/creating-a-seamless-multiview-playback-experience)

Build advanced multiview playback experiences with the AVFoundation and AVRouting frameworks.

[`class AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem)

An object that models the timing and presentation state of an asset during playback.

[`class AVPlayerItemTrack`](https://developer.apple.com/documentation/avfoundation/avplayeritemtrack)

An object that represents the presentation state of an asset track during playback.

[`class AVQueuePlayer`](https://developer.apple.com/documentation/avfoundation/avqueueplayer)

An object that plays a sequence of player items.

[`class AVPlayerLooper`](https://developer.apple.com/documentation/avfoundation/avplayerlooper)

An object that loops media content using a queue player.

---

# https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVSampleBufferRenderSynchronizer

Class

# AVSampleBufferRenderSynchronizer

An object used to synchronize multiple queued sample buffers to a single timeline.

class AVSampleBufferRenderSynchronizer

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#mentions)

[Implementing flexible enhanced buffering for your content](https://developer.apple.com/documentation/avfoundation/implementing-flexible-enhanced-buffering-for-your-content)

[Supporting AirPlay in your app](https://developer.apple.com/documentation/avfoundation/supporting-airplay-in-your-app)

## [Overview](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#overview)

This class synchronizes multiple objects that conform to [`AVQueuedSampleBufferRendering`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrendering) to a single timeline.

## [Topics](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#topics)

### [Managing Renderers](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#Managing-Renderers)

[`var renderers: [any AVQueuedSampleBufferRendering]`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/renderers)

An array of queued sample buffer renderers currently attached to the synchronizer.

[`func addRenderer(any AVQueuedSampleBufferRendering)`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/addrenderer(_:))

Adds a renderer to the list of renderers under the synchronizer’s control.

Removes a renderer from the synchronizer.

### [Accessing Time Information](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#Accessing-Time-Information)

Returns the current time of the synchronizer.

[`var timebase: CMTimebase`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/timebase)

The synchronizer’s rendering timebase which determines how it interprets timestamps.

[`var rate: Float`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/rate)

The current playback rate.

[`func setRate(Float, time: CMTime)`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/setrate(_:time:))

Sets the renderer’s time and rate.

[`func setRate(Float, time: CMTime, atHostTime: CMTime)`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/setrate(_:time:athosttime:))

Sets the playback rate and the relationship between the current time and host time.

[`class let rateDidChangeNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/ratedidchangenotification)

The synchronizer’s rendering rate changed.

[`var delaysRateChangeUntilHasSufficientMediaData: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/delaysratechangeuntilhassufficientmediadata)

A Boolean value that Indicates whether the playback should start immediately on rate change requests.

### [Observing Time](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#Observing-Time)

Requests invocation of a block during rendering at specified time intervals.

Requests invocation of a block when specified times are traversed during normal rendering.

[`func removeTimeObserver(Any)`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/removetimeobserver(_:))

Cancels the specified time observer.

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#Instance-Properties)

[`var intendedSpatialAudioExperience: any SpatialAudioExperience`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer/intendedspatialaudioexperience-3z7d3)

The intended spatial audio experience applied to all `AVSampleBufferAudioRenderer`’s within this synchronizer.

Beta

## [Relationships](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#see-also)

### [Presentation](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer\#Presentation)

[`protocol AVQueuedSampleBufferRendering`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrendering)

Methods you can implement to enqueue sample buffers for presentation.

[`class AVSampleBufferDisplayLayer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer)

An object that displays compressed or uncompressed video frames.

[`class AVSampleBufferVideoRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebuffervideorenderer)

An object that enqueues video sample buffers for rendering.

[`class AVSampleBufferAudioRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer)

An object used to decompress audio and play compressed or uncompressed audio.

---

# https://developer.apple.com/documentation/avfoundation/avfiletypeprofile

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVFileTypeProfile

Structure

# AVFileTypeProfile

File type profiles for streaming formats.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

struct AVFileTypeProfile

## [Topics](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile\#topics)

### [File Type Profiles](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile\#File-Type-Profiles)

[`static let mpeg4AppleHLS: AVFileTypeProfile`](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile/mpeg4applehls)

A file type profile for Apple HTTP Live Streaming.

[`static let mpeg4CMAFCompliant: AVFileTypeProfile`](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile/mpeg4cmafcompliant)

A file type profile that complies with the Common Media Application Format (CMAF).

### [Initializers](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile\#Initializers)

[`init(rawValue: String)`](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile/init(rawvalue:))

Creates a file type profile from its raw string value.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile\#conforms-to)

- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile\#see-also)

### [File types](https://developer.apple.com/documentation/avfoundation/avfiletypeprofile\#File-types)

[`struct AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype)

The uniform type identifiers for various file formats.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/error

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeyRequest](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)
- error

Instance Property

# error

The error description for a failed key request.

var error: (any Error)? { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/error\#see-also)

### [Getting Content Key Request Properties](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/error\#Getting-Content-Key-Request-Properties)

[`var identifier: (any Sendable)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/identifier)

The identifier for the content key.

[`var canProvidePersistableContentKey: Bool`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/canprovidepersistablecontentkey)

The content key request used to create a persistable content key or respond to a previous request with a persistable content key.

[`var initializationData: Data?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/initializationdata)

The data used to obtain a key response.

[`var renewsExpiringResponseData: Bool`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/renewsexpiringresponsedata)

A Boolean value that indicates whether the content key request renews previously provided response data.

[`var status: AVContentKeyRequest.Status`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.property)

The current state of the content key request.

[`enum Status`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.enum)

The status for a content key request.

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVSampleCursorAudioDependencyInfo

Structure

# AVSampleCursorAudioDependencyInfo

A structure that describes the independent decodability of audio samples.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

struct AVSampleCursorAudioDependencyInfo

## [Topics](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo\#topics)

### [Querying Independent Decodability](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo\#Querying-Independent-Decodability)

[`var audioSampleIsIndependentlyDecodable: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/audiosampleisindependentlydecodable)

A Boolean value indicating whether the sample is independently decodable.

[`var audioSamplePacketRefreshCount: Int`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/audiosamplepacketrefreshcount)

The number of samples, starting at the current sample, that must be fed to the decoder to achieve full decoder refresh.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo\#Initializers)

[`init()`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/init())

Creates an audio sample decodability information structure.

[`init(audioSampleIsIndependentlyDecodable: ObjCBool, audioSamplePacketRefreshCount: Int)`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/init(audiosampleisindependentlydecodable:audiosamplepacketrefreshcount:))

Creates an audio sample decodability information structure with the specified values.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo\#conforms-to)

- [`BitwiseCopyable`](https://developer.apple.com/documentation/Swift/BitwiseCopyable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo\#see-also)

### [Sample cursors](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo\#Sample-cursors)

[`class AVSampleCursor`](https://developer.apple.com/documentation/avfoundation/avsamplecursor)

An object that provides information about the media sample at the cursor’s current position.

[`struct AVSampleCursorSyncInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo)

A structure that describes the attributes of media samples to consider when resynchronizing a decoder.

[`struct AVSampleCursorDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo)

A value for describing dependencies between a media sample and other media samples in the same sample sequence.

[`struct AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursorstoragerange)

A structure that indicates the offset and length of storage for a media sample or its chunk.

[`struct AVSampleCursorChunkInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorchunkinfo)

A value that provides information about a chunk of media samples.

---

# https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPartialAsyncProperty

Class

# AVPartialAsyncProperty

An asynchronous property that constrains its type.

Mac Catalyst

## [Overview](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#overview)

This class defines the [`AVAsyncProperty`](https://developer.apple.com/documentation/avfoundation/avasyncproperty) constants for various AVFoundation types, including [`AVAsset`](https://developer.apple.com/documentation/avfoundation/avasset), [`AVAssetTrack`](https://developer.apple.com/documentation/avfoundation/avassettrack), and [`AVMetadataItem`](https://developer.apple.com/documentation/avfoundation/avmetadataitem).

## [Topics](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#topics)

### [Loading Properties](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#Loading-Properties)

Asynchronous properties for assets.

Asynchronous properties for asset tracks.

Asynchronous properties for URL assets.

Asynchronous properties for fragmented assets.

Asynchronous properties for metadata items.

Asynchronous properties for compositions.

Asynchronous properties for mutable compositions.

Asynchronous properties for movies.

Asynchronous properties for mutable movies.

Asynchronous properties for fragmented movies.

### [Describing a Property](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#Describing-a-Property)

[`var description: String`](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty/description)

A description of the object.

### [Type Properties](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#Type-Properties)

The sidecar URL used by the MediaExtension. The sidecar URL is returned only if the MediaExtension format reader supports sidecar files, and implements this property \[MEFileInfo setSidecarFilename:\]. Will return nil otherwise.

Beta

## [Relationships](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#inherits-from)

- [`AVAnyAsyncProperty`](https://developer.apple.com/documentation/avfoundation/avanyasyncproperty)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#inherited-by)

- [`AVAsyncProperty`](https://developer.apple.com/documentation/avfoundation/avasyncproperty)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#conforms-to)

- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#see-also)

### [Property loading](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty\#Property-loading)

[`protocol AVAsynchronousKeyValueLoading`](https://developer.apple.com/documentation/avfoundation/avasynchronouskeyvalueloading)

A protocol that defines the interface to load media data asynchronously.

[`class AVAsyncProperty`](https://developer.apple.com/documentation/avfoundation/avasyncproperty)

An asynchronous property that constrains its type and value.

[`class AVAnyAsyncProperty`](https://developer.apple.com/documentation/avfoundation/avanyasyncproperty)

A base class for asynchronous properties.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier/init(forkeysystem:identifier:options:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeySpecifier](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier)
- init(forKeySystem:identifier:options:)

Initializer

# init(forKeySystem:identifier:options:)

Creates a content key specifier.

init(
forKeySystem keySystem: AVContentKeySystem,
identifier contentKeyIdentifier: Any,
options: [String : Any] = [:]
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcontentkeyspecifier/init(forkeysystem:identifier:options:)\#parameters)

`keySystem`

The key system to use to generate content keys.

`contentKeyIdentifier`

The container and protocol-specific key identifier.

`options`

Additional information necessary to obtain the key. Pass `nil` to indicate no additional options.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-2wdgz

-2wdgz#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeySessionDelegate](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)
- contentKeySession(\_:didProvide:)

Instance Method

# contentKeySession(\_:didProvide:)

Provides the receiver with a new content key request object to process a persistable content key.

optional func contentKeySession(
_ session: AVContentKeySession,
didProvide keyRequest: AVPersistableContentKeyRequest
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-2wdgz\#parameters)

`session`

The content key session that is providing the new persistable content key request.

`keyRequest`

The request for a new persistable content key.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-2wdgz\#see-also)

### [Providing New Content Key Requests](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-2wdgz\#Providing-New-Content-Key-Requests)

[`func contentKeySession(AVContentKeySession, didProvide: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-3coq5)

Provides the receiver with a new content key request object.

**Required**

[`func contentKeySession(AVContentKeySession, didProvideRenewingContentKeyRequest: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didproviderenewingcontentkeyrequest:))

Provides the receiver with a new content key request object for the renewal of an existing content key.

---

# https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetDownloadStorageManager

Class

# AVAssetDownloadStorageManager

An object that manages policies to automatically purge downloaded assets.

class AVAssetDownloadStorageManager

## [Topics](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager\#topics)

### [Accessing the Shared Manager](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager\#Accessing-the-Shared-Manager)

Returns the shared storage manager instance.

### [Setting the Storage Policy](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager\#Setting-the-Storage-Policy)

Returns the storage management policy for a downloaded asset.

[`func setStorageManagementPolicy(AVAssetDownloadStorageManagementPolicy, for: URL)`](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager/setstoragemanagementpolicy(_:for:))

Sets a storage policy for the downloaded asset.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager\#see-also)

### [Offline storage management](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager\#Offline-storage-management)

[`class AVAssetDownloadStorageManagementPolicy`](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanagementpolicy)

An object that defines a policy to automatically manage the storage of downloaded assets.

[`class AVMutableAssetDownloadStorageManagementPolicy`](https://developer.apple.com/documentation/avfoundation/avmutableassetdownloadstoragemanagementpolicy)

A mutable object that you use to create a new storage management policy.

---

# https://developer.apple.com/documentation/avfoundation/avmediacharacteristic

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMediaCharacteristic

Structure

# AVMediaCharacteristic

A structure that defines media data characteristics.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

struct AVMediaCharacteristic

## [Discussion](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#Discussion)

QuickTime Movie and MPEG-4 video files may contain tracks that provide tagged media characteristics to indicate a purpose, trait, or feature of the track’s media. For example, an audio track that mixes original program content with additional narrative descriptions of visual action may have the media characteristic `public.accessibility.describes-video` to distinguish it from other audio tracks stored in the same file that don’t contain additional narrative.

You inspect the tagged media characteristics of a track as shown below:

NSArray *userDataItems = [myAVAssetTrack metadataForFormat:AVMetadataFormatQuickTimeUserData];
NSArray *trackTaggedMediaCharacteristics = [AVMetadataItem metadataItemsFromArray: userDataItems\
withKey: AVMetadataQuickTimeUserDataKeyTaggedCharacteristic\
keySpace: AVMetadataKeySpaceQuickTimeUserData];
for (AVMetadataItem *metadataItem in trackTaggedMediaCharacteristics) {
NSString *thisTrackMediaCharacteristic = [metadataItem stringValue];
}

You write tagged media characteristics to files of type [`mov`](https://developer.apple.com/documentation/avfoundation/avfiletype/mov) and [`m4v`](https://developer.apple.com/documentation/avfoundation/avfiletype/m4v) by using an instance of [`AVAssetWriter`](https://developer.apple.com/documentation/avfoundation/avassetwriter). You indicate tagged characteristics for a track by setting metadata on its associated asset writer input as shown below:

AVMutableMetadataItem *myTaggedMediaCharacteristic = [[AVMutableMetadataItem alloc] init];
[myTaggedMediaCharacteristic setKey:AVMetadataQuickTimeUserDataKeyTaggedCharacteristic];
[myTaggedMediaCharacteristic setKeySpace:AVMetadataKeySpaceQuickTimeUserData];
[myTaggedMediaCharacteristic setValue:aMeaningfulCharacteristicAsNSString];
[myMutableArrayOfMetadata addObject:myTaggedMediaCharacteristic];
[myAssetWriterInput setMetadata:myMutableArrayOfMetadata];

## [Topics](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#topics)

### [Visual](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#Visual)

[`static let visual: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/visual)

A media characteristic that indicates that a track or media selection option includes visual content.

[`static let containsAlphaChannel: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/containsalphachannel)

A media characteristic that indicates that a track contains an alpha channel.

[`static let containsHDRVideo: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/containshdrvideo)

A media characteristic that indicates that a track contains HDR video.

[`static let frameBased: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/framebased)

A media characteristic that indicates that a track or media selection option includes frame-based content.

[`static let usesWideGamutColorSpace: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/useswidegamutcolorspace)

A media characteristic that indicates that a track uses a wide-gamut color space.

[`static let containsStereoMultiviewVideo: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/containsstereomultiviewvideo)

A media characteristic that indicates that a track contains stereoscopic video captured in a multiview compression format.

[`static let carriesVideoStereoMetadata: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/carriesvideostereometadata)

A media characteristic that indicates that the stereoscopic video track carries additional information related to the stereoscopic video.

[`static let indicatesHorizontalFieldOfView: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/indicateshorizontalfieldofview)

A media characteristic that indicates the video track carries information related to the horizontal field of view.

### [Audible](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#Audible)

[`static let audible: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/audible)

A media characteristic that indicates that a track or media selection option includes audible content.

[`static let dubbedTranslation: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/dubbedtranslation)

A media characteristic that indicates that a track or media selection option contains audio language or dialect translation of the original content.

[`static let voiceOverTranslation: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/voiceovertranslation)

A media characteristic that indicates that a track or media selection option contains a language translation and verbal interpretation of spoken dialog.

[`static let enhancesSpeechIntelligibility: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/enhancesspeechintelligibility)

A media characteristic that indicates a track or media selection option includes audio processed to enhance the intelligibility of speech.

[`static let describesMusicAndSoundForAccessibility: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/describesmusicandsoundforaccessibility)

A media characteristic that indicates that a track or media selection option includes legible content in the language of its specified locale.

[`static let tactileMinimal: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/tactileminimal)

A media characteristic that indicates that a track or media selection option includes haptic content.

### [Legible](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#Legible)

[`static let legible: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/legible)

A media characteristic that indicates that a track or media selection option includes legible content.

[`static let easyToRead: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/easytoread)

A media characteristic that indicates a track or media selection option provides legible content that’s edited for easy reading.

[`static let describesVideoForAccessibility: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/describesvideoforaccessibility)

A media characteristic that indicates the media includes audible content that describes the visual portion of the presentation.

[`static let containsOnlyForcedSubtitles: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/containsonlyforcedsubtitles)

A media characteristic that indicates that a track or media selection option presents only forced subtitles.

[`static let languageTranslation: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/languagetranslation)

A media characteristic that indicates that a track or media selection option contains a language or dialect translation of the original content.

[`static let transcribesSpokenDialogForAccessibility: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/transcribesspokendialogforaccessibility)

A media characteristic that indicates that a media selection option includes legible content that transcribes spoken dialog.

### [Content](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#Content)

[`static let isOriginalContent: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isoriginalcontent)

A media characteristic that indicates that a track or media selection option contains original content.

[`static let isMainProgramContent: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/ismainprogramcontent)

A media characteristic that indicates a track or media selection option includes content its author indicates is essential to the asset’s presentation.

[`static let isAuxiliaryContent: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isauxiliarycontent)

A media characteristic that indicates a track or media selection option includes content its author indicates is auxiliary to the asset’s presentation.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#Initializers)

[`init(String)`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/init(_:))

Creates a media characteristic.

[`init(rawValue: String)`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/init(rawvalue:))

Creates a media characteristic with a string value.

### [Type Properties](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#Type-Properties)

[`static let indicatesNonRectilinearProjection: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/indicatesnonrectilinearprojection)

A media characteristic that indicates the video track carries information related to how it should be projected for display.

Beta

[`static let machineGenerated: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/machinegenerated)

A media characteristic that indicates that a track was generated in an automated fashion by a machine.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#conforms-to)

- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#see-also)

### [Media types](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic\#Media-types)

[`struct AVMediaType`](https://developer.apple.com/documentation/avfoundation/avmediatype)

An identifier for various media types.

---

# https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVSampleBufferDisplayLayer

Class

# AVSampleBufferDisplayLayer

An object that displays compressed or uncompressed video frames.

class AVSampleBufferDisplayLayer

## [Topics](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#topics)

### [Accessing the video renderer](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#Accessing-the-video-renderer)

[`var sampleBufferRenderer: AVSampleBufferVideoRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/samplebufferrenderer)

An object that enqueues video sample buffers for rendering.

### [Configuring the layer](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#Configuring-the-layer)

[`var isReadyForDisplay: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/isreadyfordisplay)

A Boolean value that indicates whether the first video frame is ready for display.

[`var controlTimebase: CMTimebase?`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/controltimebase)

A timebase that determines how the layer interprets timestamps.

[`var videoGravity: AVLayerVideoGravity`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/videogravity)

A value that indicates how the layer displays video within its bounds.

[`struct AVLayerVideoGravity`](https://developer.apple.com/documentation/avfoundation/avlayervideogravity)

A structure that defines how a layer displays a player’s visual content within the layer’s bounds.

### [Protecting content](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#Protecting-content)

[`var preventsCapture: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventscapture)

A Boolean value that indicates whether the layer protects against screen capture.

[`var isOutputObscuredDueToInsufficientExternalProtection: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/isoutputobscuredduetoinsufficientexternalprotection)

A Boolean value that indicates whether the system obscures decoded output due to insufficient external protection on the current device.

### [Preventing backgrounding](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#Preventing-backgrounding)

[`var preventsDisplaySleepDuringVideoPlayback: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsdisplaysleepduringvideoplayback)

A Boolean value that indicates whether the layer prevents the system from sleeping during video playback.

[`var preventsAutomaticBackgroundingDuringVideoPlayback: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsautomaticbackgroundingduringvideoplayback)

A Boolean value that indicates whether video playback prevents the system from automatically backgrounding an app.

### [Handling errors](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#Handling-errors)

[`static let AVSampleBufferDisplayLayerFailedToDecode: NSNotification.Name`](https://developer.apple.com/documentation/Foundation/NSNotification/Name-swift.struct/AVSampleBufferDisplayLayerFailedToDecode)

A notification the system posts when a sample buffer display layer fails to decode.

[`let AVSampleBufferDisplayLayerFailedToDecodeNotificationErrorKey: String`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayerfailedtodecodenotificationerrorkey)

The key for the corresponding error.

### [Deprecated](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#Deprecated)

Review unsupported symbols and their replacements.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#inherits-from)

- [`CALayer`](https://developer.apple.com/documentation/QuartzCore/CALayer)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#conforms-to)

- [`AVQueuedSampleBufferRendering`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrendering)
- [`CAMediaTiming`](https://developer.apple.com/documentation/QuartzCore/CAMediaTiming)
- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`Copyable`](https://developer.apple.com/documentation/Swift/Copyable)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCoding`](https://developer.apple.com/documentation/Foundation/NSCoding)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`NSSecureCoding`](https://developer.apple.com/documentation/Foundation/NSSecureCoding)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#see-also)

### [Presentation](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer\#Presentation)

[`protocol AVQueuedSampleBufferRendering`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrendering)

Methods you can implement to enqueue sample buffers for presentation.

[`class AVSampleBufferRenderSynchronizer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrendersynchronizer)

An object used to synchronize multiple queued sample buffers to a single timeline.

[`class AVSampleBufferVideoRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebuffervideorenderer)

[`class AVSampleBufferAudioRenderer`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer)

An object used to decompress audio and play compressed or uncompressed audio.

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloader/preloadseligiblecontentkeys

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetResourceLoader](https://developer.apple.com/documentation/avfoundation/avassetresourceloader)
- preloadsEligibleContentKeys

Instance Property

# preloadsEligibleContentKeys

A Boolean value that indicates whether content keys will be loaded as quickly as possible.

var preloadsEligibleContentKeys: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetresourceloader/preloadseligiblecontentkeys\#Discussion)

Set this property to `true` to load eligible keys. This may result in network activity. All work done as a result of setting this property to `true` is performed asynchronously.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:forinitializationdata:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeySessionDelegate](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)
- contentKeySession(\_:didProvide:forInitializationData:)

Instance Method

# contentKeySession(\_:didProvide:forInitializationData:)

optional func contentKeySession(
_ session: AVContentKeySession,
didProvide keyRequests: [AVContentKeyRequest],
forInitializationData initializationData: Data?
)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:forinitializationdata:)\#see-also)

### [Updating and Retrying Content Key Requests](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:forinitializationdata:)\#Updating-and-Retrying-Content-Key-Requests)

[`func contentKeySession(AVContentKeySession, externalProtectionStatusDidChangeFor: AVContentKey)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:externalprotectionstatusdidchangefor:))

Tells the delegate when external protection state has changed.

[`func contentKeySession(AVContentKeySession, didUpdatePersistableContentKey: Data, forContentKeyIdentifier: Any)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didupdatepersistablecontentkey:forcontentkeyidentifier:))

Provides the receiver with an updated persistable content key for a specific key request.

Provides the receiver with a content key request object to retry.

[`struct RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason)

The reason for asking the client to retry a content key request.

[`func contentKeySessionContentProtectionSessionIdentifierDidChange(AVContentKeySession)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysessioncontentprotectionsessionidentifierdidchange(_:))

Tells the receiver the content protection session identifier changed.

[`func contentKeySession(AVContentKeySession, contentKeyRequest: AVContentKeyRequest, didFailWithError: any Error)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:contentkeyrequest:didfailwitherror:))

Tells the receiver that the content key request failed.

[`func contentKeySession(AVContentKeySession, contentKeyRequestDidSucceed: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:contentkeyrequestdidsucceed:))

Tells the content key session that the response to a content key requeset was successfully processed.

[`func contentKeySessionDidGenerateExpiredSessionReport(AVContentKeySession)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysessiondidgenerateexpiredsessionreport(_:))

Notifies the sender that an expired session report has been generated.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/initializationdata

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeyRequest](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)
- initializationData

Instance Property

# initializationData

The data used to obtain a key response.

var initializationData: Data? { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/initializationdata\#Discussion)

This property is specific to the container and the protocol.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/initializationdata\#see-also)

### [Getting Content Key Request Properties](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/initializationdata\#Getting-Content-Key-Request-Properties)

[`var identifier: (any Sendable)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/identifier)

The identifier for the content key.

[`var canProvidePersistableContentKey: Bool`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/canprovidepersistablecontentkey)

The content key request used to create a persistable content key or respond to a previous request with a persistable content key.

[`var error: (any Error)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/error)

The error description for a failed key request.

[`var renewsExpiringResponseData: Bool`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/renewsexpiringresponsedata)

A Boolean value that indicates whether the content key request renews previously provided response data.

[`var status: AVContentKeyRequest.Status`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.property)

The current state of the content key request.

[`enum Status`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.enum)

The status for a content key request.

---

# https://developer.apple.com/documentation/avfoundation/encoder-bit-rate-strategy-values

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Audio settings](https://developer.apple.com/documentation/avfoundation/audio-settings)
- Encoder Bit Rate Strategy Values

# Encoder Bit Rate Strategy Values

The constants that represent the possible bit rate strategy values.

## [Overview](https://developer.apple.com/documentation/avfoundation/encoder-bit-rate-strategy-values\#overview)

You use these values with [`AVEncoderBitRateStrategyKey`](https://developer.apple.com/documentation/AVFAudio/AVEncoderBitRateStrategyKey).

## [Topics](https://developer.apple.com/documentation/avfoundation/encoder-bit-rate-strategy-values\#topics)

### [Strategies](https://developer.apple.com/documentation/avfoundation/encoder-bit-rate-strategy-values\#Strategies)

[`let AVAudioBitRateStrategy_Constant: String`](https://developer.apple.com/documentation/AVFAudio/AVAudioBitRateStrategy_Constant)

A value that represents a constant bit rate strategy.

[`let AVAudioBitRateStrategy_LongTermAverage: String`](https://developer.apple.com/documentation/AVFAudio/AVAudioBitRateStrategy_LongTermAverage)

A value that represents an average bit rate strategy.

[`let AVAudioBitRateStrategy_VariableConstrained: String`](https://developer.apple.com/documentation/AVFAudio/AVAudioBitRateStrategy_VariableConstrained)

A value that represents a constrained variable bit rate strategy.

[`let AVAudioBitRateStrategy_Variable: String`](https://developer.apple.com/documentation/AVFAudio/AVAudioBitRateStrategy_Variable)

A value that represents a variable bit rate strategy.

## [See Also](https://developer.apple.com/documentation/avfoundation/encoder-bit-rate-strategy-values\#see-also)

### [Constants](https://developer.apple.com/documentation/avfoundation/encoder-bit-rate-strategy-values\#Constants)

[`var AVAUDIOENGINE_HAVE_AUAUDIOUNIT: Int32 { get }`](https://developer.apple.com/documentation/AVFAudio/AVAUDIOENGINE_HAVE_AUAUDIOUNIT)

---

# https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus/notenoughlight

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSceneMonitoringStatus](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus)
- notEnoughLight Beta

Type Property

# notEnoughLight

static let notEnoughLight: AVCaptureSceneMonitoringStatus

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturescenemonitoringstatus/notenoughlight\#discussion)

The lighting of the current scene is not bright enough.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetResourceLoaderDelegate](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate)
- resourceLoader(\_:shouldWaitForLoadingOfRequestedResource:)

Instance Method

# resourceLoader(\_:shouldWaitForLoadingOfRequestedResource:)

Asks the delegate if it wants to load the requested resource.

optional func resourceLoader(
_ resourceLoader: AVAssetResourceLoader,
shouldWaitForLoadingOfRequestedResource loadingRequest: AVAssetResourceLoadingRequest

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)\#parameters)

`resourceLoader`

The resource loader object that is making the request.

`loadingRequest`

The loading request object that contains information about the requested resource.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)\#return-value)

[`true`](https://developer.apple.com/documentation/swift/true) if your delegate can load the resource specified by the `loadingRequest` parameter or [`false`](https://developer.apple.com/documentation/swift/false) if it cannot.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)\#Discussion)

The resource loader object calls this method when assistance is required of your code to load the specified resource. For example, the resource loader might call this method to load decryption keys that have been specified using a custom URL scheme.

Returning [`true`](https://developer.apple.com/documentation/swift/true) from this method, implies only that the receiver will load, or at least attempt to load, the resource. In some implementations, the actual work of loading the resource might be initiated on another thread, running asynchronously to the resource loading delegate; whether the work begins immediately or merely soon is an implementation detail of the client application.

You can load the resource synchronously or asynchronously. In both cases, you must indicate success or failure of the operation by calling the [`finishLoading(with:data:redirect:)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:data:redirect:)) or [`finishLoading(with:)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:)) method of the request object when you finish. If you load the resource asynchronously, you must also store a strong reference to the object in the `loadingRequest` parameter before returning from this method.

If you return [`false`](https://developer.apple.com/documentation/swift/false) from this method, the resource loader treats the loading of the resource as having failed.

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)\#see-also)

### [Processing Resource Requests](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)\#Processing-Resource-Requests)

Tells the delegate when assistance is required of the application to renew a resource.

[`func resourceLoader(AVAssetResourceLoader, didCancel: AVAssetResourceLoadingRequest)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:didcancel:)-3nl51)

Informs the delegate that a prior loading request has been cancelled.

---

# https://developer.apple.com/documentation/avfoundation/avcapturecontrol

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureControl

Class

# AVCaptureControl

An abstract base class for controls that interact with the camera system.

class AVCaptureControl

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#mentions)

[Enhancing your app experience with the Camera Control](https://developer.apple.com/documentation/avfoundation/enhancing-your-app-experience-with-the-camera-control)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#overview)

Capture controls provide the interface for interacting with the camera system from the Camera Control button on iPhone 16 devices. The framework provides several concrete subclasses of this class that allow apps to access built-in functionality and define custom controls.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#topics)

### [Setting the enabled state](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#Setting-the-enabled-state)

[`var isEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturecontrol/isenabled)

A Boolean value that indicates whether this control supports user interaction.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#inherited-by)

- [`AVCaptureIndexPicker`](https://developer.apple.com/documentation/avfoundation/avcaptureindexpicker)
- [`AVCaptureSlider`](https://developer.apple.com/documentation/avfoundation/avcaptureslider)
- [`AVCaptureSystemExposureBiasSlider`](https://developer.apple.com/documentation/avfoundation/avcapturesystemexposurebiasslider)
- [`AVCaptureSystemZoomSlider`](https://developer.apple.com/documentation/avfoundation/avcapturesystemzoomslider)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#see-also)

### [Capture controls](https://developer.apple.com/documentation/avfoundation/avcapturecontrol\#Capture-controls)

Provide direct access to your camera app’s features to help people quickly capture the perfect shot.

[`class AVCaptureSystemZoomSlider`](https://developer.apple.com/documentation/avfoundation/avcapturesystemzoomslider)

A control that adjusts the video zoom factor of a capture device within the system-recommended range.

[`class AVCaptureSystemExposureBiasSlider`](https://developer.apple.com/documentation/avfoundation/avcapturesystemexposurebiasslider)

A control that adjusts the exposure bias of a capture device within the system-recommended range.

[`class AVCaptureSlider`](https://developer.apple.com/documentation/avfoundation/avcaptureslider)

A slider control that selects a value from a bounded range.

[`class AVCaptureIndexPicker`](https://developer.apple.com/documentation/avfoundation/avcaptureindexpicker)

A control for selecting from a set of mutually exclusive values by index.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.property

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeyRequest](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)
- status

Instance Property

# status

The current state of the content key request.

var status: AVContentKeyRequest.Status { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.property\#see-also)

### [Getting Content Key Request Properties](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.property\#Getting-Content-Key-Request-Properties)

[`var identifier: (any Sendable)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/identifier)

The identifier for the content key.

[`var canProvidePersistableContentKey: Bool`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/canprovidepersistablecontentkey)

The content key request used to create a persistable content key or respond to a previous request with a persistable content key.

[`var error: (any Error)?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/error)

The error description for a failed key request.

[`var initializationData: Data?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/initializationdata)

The data used to obtain a key response.

[`var renewsExpiringResponseData: Bool`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/renewsexpiringresponsedata)

A Boolean value that indicates whether the content key request renews previously provided response data.

[`enum Status`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/status-swift.enum)

The status for a content key request.

---

# https://developer.apple.com/documentation/avfoundation/avcaptureinput

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureInput

Class

# AVCaptureInput

An abstract superclass for objects that provide input data to a capture session.

class AVCaptureInput

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#mentions)

[Setting Up a Capture Session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#overview)

You create concrete instances of this class, such as [`AVCaptureDeviceInput`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput), to add inputs to a capture session. An input provides one or more streams of media data. For example, input devices can provide both audio and video data. The framework represents each media stream that an input provides as an [`AVCaptureInput.Port`](https://developer.apple.com/documentation/avfoundation/avcaptureinput/port) object.

A capture makes connections between capture inputs and capture outputs using a [`AVCaptureConnection`](https://developer.apple.com/documentation/avfoundation/avcaptureconnection) object. The connection defines the mapping between a set of port objects and an [`AVCaptureOutput`](https://developer.apple.com/documentation/avfoundation/avcaptureoutput).

## [Topics](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#topics)

### [Accessing Ports](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#Accessing-Ports)

[`var ports: [AVCaptureInput.Port]`](https://developer.apple.com/documentation/avfoundation/avcaptureinput/ports)

The ports available on a capture input.

[`class Port`](https://developer.apple.com/documentation/avfoundation/avcaptureinput/port)

An object that represents a stream of data that a capture input provides.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#inherited-by)

- [`AVCaptureDeviceInput`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput)
- [`AVCaptureMetadataInput`](https://developer.apple.com/documentation/avfoundation/avcapturemetadatainput)
- [`AVCaptureScreenInput`](https://developer.apple.com/documentation/avfoundation/avcapturescreeninput)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#see-also)

### [Capture sessions](https://developer.apple.com/documentation/avfoundation/avcaptureinput\#Capture-sessions)

Configure input devices, output media, preview views, and basic settings before capturing photos or video.

[Accessing the camera while multitasking on iPad](https://developer.apple.com/documentation/AVKit/accessing-the-camera-while-multitasking-on-ipad)

Operate the camera in Split View, Slide Over, Picture in Picture, and Stage Manager modes.

[AVCam: Building a camera app](https://developer.apple.com/documentation/avfoundation/avcam-building-a-camera-app)

Capture photos and record video using the front and rear iPhone and iPad cameras.

[Capturing cinematic video](https://developer.apple.com/documentation/avfoundation/capturing-cinematic-video)

Capture video with an adjustable depth of field and focus points.

[AVMultiCamPiP: Capturing from Multiple Cameras](https://developer.apple.com/documentation/avfoundation/avmulticampip-capturing-from-multiple-cameras)

Simultaneously record the output from the front and back cameras into a single movie file by using a multi-camera capture session.

[AVCamBarcode: Detecting Barcodes and Faces](https://developer.apple.com/documentation/avfoundation/avcambarcode-detecting-barcodes-and-faces)

Identify machine readable codes or faces by using the camera.

[`class AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession)

An object that configures capture behavior and coordinates the flow of data from input devices to capture outputs.

[`class AVCaptureMultiCamSession`](https://developer.apple.com/documentation/avfoundation/avcapturemulticamsession)

A capture session that supports simultaneous capture from multiple inputs of the same media type.

[`class AVCaptureOutput`](https://developer.apple.com/documentation/avfoundation/avcaptureoutput)

An abstract superclass for objects that provide media output destinations for a capture session.

[`class AVCaptureConnection`](https://developer.apple.com/documentation/avfoundation/avcaptureconnection)

An object that represents a connection from a capture input to a capture output.

---

# https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCameraCalibrationData

Class

# AVCameraCalibrationData

Information about the camera characteristics used to capture images and depth data.

class AVCameraCalibrationData

## [Overview](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#overview)

Information about the calibration of a camera—such as its pixel focal length, principal point, and lens distortion characteristics—helps to determine the geometric relationships between the camera device and the images it captures. You can use this information to accurately render visual effects into images produced by a camera or perform computer vision tasks such as correcting images for geometric distortions.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#topics)

### [Mapping Pixels to Scene Geometry](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#Mapping-Pixels-to-Scene-Geometry)

[`var intrinsicMatrix: matrix_float3x3`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/intrinsicmatrix)

A matrix that relates a camera’s internal properties to an ideal pinhole-camera model.

[`var intrinsicMatrixReferenceDimensions: CGSize`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/intrinsicmatrixreferencedimensions)

The image dimensions to which the camera’s intrinsic matrix values are relative.

[`var extrinsicMatrix: matrix_float4x3`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/extrinsicmatrix)

A matrix relating a camera’s position and orientation to a world or scene coordinate system.

[`var pixelSize: Float`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/pixelsize)

The size, in millimeters, of one image pixel.

### [Correcting for Lens Distortion](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#Correcting-for-Lens-Distortion)

[`var lensDistortionLookupTable: Data?`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/lensdistortionlookuptable)

A map of floating-point values describing radial distortions imparted by the camera lens, for use in rectifying camera images.

[`var inverseLensDistortionLookupTable: Data?`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/inverselensdistortionlookuptable)

A map of floating-point values describing radial distortions for use in reapplying camera geometry to a rectified image.

[`var lensDistortionCenter: CGPoint`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/lensdistortioncenter)

The offset of the distortion center of the camera lens from the top-left corner of the image.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#see-also)

### [Depth data capture](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata\#Depth-data-capture)

[Capturing Photos with Depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)

Get a depth map with a photo to create effects like the system camera’s Portrait mode (on compatible devices).

[Creating Auxiliary Depth Data Manually](https://developer.apple.com/documentation/avfoundation/creating-auxiliary-depth-data-manually)

Generate a depth image and attach it to your own image.

[Capturing depth using the LiDAR camera](https://developer.apple.com/documentation/avfoundation/capturing-depth-using-the-lidar-camera)

Access the LiDAR camera on supporting devices to capture precise depth data.

[AVCamFilter: Applying Filters to a Capture Stream](https://developer.apple.com/documentation/avfoundation/avcamfilter-applying-filters-to-a-capture-stream)

Render a capture stream with rose-colored filtering and depth effects.

[Streaming Depth Data from the TrueDepth Camera](https://developer.apple.com/documentation/avfoundation/streaming-depth-data-from-the-truedepth-camera)

Visualize depth data in 2D and 3D from the TrueDepth camera.

[Enhancing Live Video by Leveraging TrueDepth Camera Data](https://developer.apple.com/documentation/avfoundation/enhancing-live-video-by-leveraging-truedepth-camera-data)

Apply your own background to a live capture feed streamed from the front-facing TrueDepth camera.

[`class AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput)

A capture output that records scene depth information on compatible camera devices.

[`class AVDepthData`](https://developer.apple.com/documentation/avfoundation/avdepthdata)

A container for per-pixel distance or disparity information captured by compatible camera devices.

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/isbyterangeaccesssupported

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetResourceLoadingContentInformationRequest](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest)
- isByteRangeAccessSupported

Instance Property

# isByteRangeAccessSupported

A Boolean value that indicates whether random access to arbitrary ranges of bytes of the resource is supported.

var isByteRangeAccessSupported: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/isbyterangeaccesssupported\#Discussion)

Before finishing loading an [`AVAssetResourceLoadingRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest) instance, if its [`contentInformationRequest`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/contentinformationrequest) property is not `nil`, set the value of this property to [`true`](https://developer.apple.com/documentation/swift/true) if it supports random access to arbitrary ranges of bytes of the resource.

If this property is not [`true`](https://developer.apple.com/documentation/swift/true) for resources that must be loaded incrementally, loading of the resource may fail. Such resources include anything that contains media data.

If byte range access is supported portions of the resource can be requested more than once.

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/isbyterangeaccesssupported\#see-also)

### [Configuring Content Information](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/isbyterangeaccesssupported\#Configuring-Content-Information)

[`var allowedContentTypes: [String]?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/allowedcontenttypes)

The types of data that are accepted as a valid response for the requested resource.

[`var contentType: String?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/contenttype)

The UTI that specifies the type of data contained by the requested resource.

[`var contentLength: Int64`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/contentlength)

The length, in bytes, of the requested resource.

[`var renewalDate: Date?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/renewaldate)

The date at which a new resource loading request will be issued for resources that expire, if the media system still requires it.

[`var isEntireLengthAvailableOnDemand: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingcontentinformationrequest/isentirelengthavailableondemand)

A Boolean value that indicates whether asset data loading can expect data immediately.

---

# https://developer.apple.com/documentation/avfoundation/avaudiomix

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAudioMix

Class

# AVAudioMix

An object that manages the input parameters for mixing audio tracks.

class AVAudioMix

## [Topics](https://developer.apple.com/documentation/avfoundation/avaudiomix\#topics)

### [Retrieving Input Parameters](https://developer.apple.com/documentation/avfoundation/avaudiomix\#Retrieving-Input-Parameters)

[`var inputParameters: [AVAudioMixInputParameters]`](https://developer.apple.com/documentation/avfoundation/avaudiomix/inputparameters)

An array of input parameters for the mix.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avaudiomix\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avaudiomix\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avaudiomix\#inherited-by)

- [`AVMutableAudioMix`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomix)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avaudiomix\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSMutableCopying`](https://developer.apple.com/documentation/Foundation/NSMutableCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avaudiomix\#see-also)

### [Mixing](https://developer.apple.com/documentation/avfoundation/avaudiomix\#Mixing)

[`class AVMutableAudioMix`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomix)

[`class AVAudioMixInputParameters`](https://developer.apple.com/documentation/avfoundation/avaudiomixinputparameters)

An object that represents the parameters that you apply when adding an audio track to a mix.

[`class AVMutableAudioMixInputParameters`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters)

The parameters you use when adding an audio track to a mix.

---

# https://developer.apple.com/documentation/avfoundation/avmetricevent

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMetricEvent

Class

# AVMetricEvent

A base class that represents a metric event.

class AVMetricEvent

## [Topics](https://developer.apple.com/documentation/avfoundation/avmetricevent\#topics)

### [Inspecting an event](https://developer.apple.com/documentation/avfoundation/avmetricevent\#Inspecting-an-event)

[`var date: Date`](https://developer.apple.com/documentation/avfoundation/avmetricevent/date)

[`var mediaTime: CMTime`](https://developer.apple.com/documentation/avfoundation/avmetricevent/mediatime)

[`var sessionID: String?`](https://developer.apple.com/documentation/avfoundation/avmetricevent/sessionid)

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmetricevent\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmetricevent\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avmetricevent\#inherited-by)

- [`AVMetricContentKeyRequestEvent`](https://developer.apple.com/documentation/avfoundation/avmetriccontentkeyrequestevent)
- [`AVMetricDownloadSummaryEvent`](https://developer.apple.com/documentation/avfoundation/avmetricdownloadsummaryevent)
- [`AVMetricErrorEvent`](https://developer.apple.com/documentation/avfoundation/avmetricerrorevent)
- [`AVMetricHLSMediaSegmentRequestEvent`](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent)
- [`AVMetricHLSPlaylistRequestEvent`](https://developer.apple.com/documentation/avfoundation/avmetrichlsplaylistrequestevent)
- [`AVMetricMediaResourceRequestEvent`](https://developer.apple.com/documentation/avfoundation/avmetricmediaresourcerequestevent)
- [`AVMetricPlayerItemLikelyToKeepUpEvent`](https://developer.apple.com/documentation/avfoundation/avmetricplayeritemlikelytokeepupevent)
- [`AVMetricPlayerItemPlaybackSummaryEvent`](https://developer.apple.com/documentation/avfoundation/avmetricplayeritemplaybacksummaryevent)
- [`AVMetricPlayerItemRateChangeEvent`](https://developer.apple.com/documentation/avfoundation/avmetricplayeritemratechangeevent)
- [`AVMetricPlayerItemVariantSwitchEvent`](https://developer.apple.com/documentation/avfoundation/avmetricplayeritemvariantswitchevent)
- [`AVMetricPlayerItemVariantSwitchStartEvent`](https://developer.apple.com/documentation/avfoundation/avmetricplayeritemvariantswitchstartevent)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmetricevent\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCoding`](https://developer.apple.com/documentation/Foundation/NSCoding)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`NSSecureCoding`](https://developer.apple.com/documentation/Foundation/NSSecureCoding)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetricevent\#see-also)

### [Metrics](https://developer.apple.com/documentation/avfoundation/avmetricevent\#Metrics)

[`struct AVMetrics`](https://developer.apple.com/documentation/avfoundation/avmetrics)

An asynchronous stream of metric information.

[`struct AVMergedMetrics`](https://developer.apple.com/documentation/avfoundation/avmergedmetrics)

An asynchronous stream of metric information from different publishers.

[`class AVVideoPerformanceMetrics`](https://developer.apple.com/documentation/avfoundation/avvideoperformancemetrics)

An object that provides metrics related to video playback quality.

[`protocol AVMetricEventStreamPublisher`](https://developer.apple.com/documentation/avfoundation/avmetriceventstreampublisher)

A type for objects that publish metric events to the event stream.

[`class AVMetricErrorEvent`](https://developer.apple.com/documentation/avfoundation/avmetricerrorevent)

An object that represents a metric event when an error occurs.

---

# https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme/shouldofferlanguageselection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCustomMediaSelectionScheme](https://developer.apple.com/documentation/avfoundation/avcustommediaselectionscheme)
- shouldOfferLanguageSelection Beta

Instance Property

# shouldOfferLanguageSelection

Indicates whether an alternative selection interface should provide a menu of language choices.

var shouldOfferLanguageSelection: Bool { get }

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVSampleBufferGeneratorBatch

Class

# AVSampleBufferGeneratorBatch

An object that generates sample buffers in a batch.

class AVSampleBufferGeneratorBatch

## [Overview](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#overview)

The benefit of batching is it aggregates adjacent I/O requests and overlaps them when possible for all sample buffers within the batch.

## [Topics](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#topics)

### [Preparing a Batch](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#Preparing-a-Batch)

Loads sample data asynchronously for all sample buffers within a batch.

### [Canceling a Batch](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#Canceling-a-Batch)

[`func cancel()`](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch/cancel())

Cancels any I/O for this batch.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#see-also)

### [Sample buffer generation](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch\#Sample-buffer-generation)

[Playing custom audio with your own player](https://developer.apple.com/documentation/AVFAudio/playing-custom-audio-with-your-own-player)

Construct an audio player to play your custom audio data, and optionally take advantage of the advanced features of AirPlay 2.

[`class AVSampleBufferRequest`](https://developer.apple.com/documentation/avfoundation/avsamplebufferrequest)

An object that describes a sample buffer creation request.

[`class AVSampleBufferGenerator`](https://developer.apple.com/documentation/avfoundation/avsamplebuffergenerator)

An object that creates sample buffers.

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursor

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVSampleCursor

Class

# AVSampleCursor

An object that provides information about the media sample at the cursor’s current position.

class AVSampleCursor

## [Overview](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#overview)

You position a sample cursor at a specific media sample in a sequence of samples contained in a higher-level object, like an [`AVAssetTrack`](https://developer.apple.com/documentation/avfoundation/avassettrack). You can move it to a new position in that sequence either backwards or forwards, either in decode order or in presentation order. You can also request moving it according to a count of samples or a delta in time.

Use a sample cursor to get information about the media sample such as its duration, timestamps, dependency information, and so on. You can also use them to synchronously to perform I/O in order to load media data of one or more media samples into memory.

## [Topics](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#topics)

### [Navigating Samples](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#Navigating-Samples)

Moves the cursor by a given delta time on the decode timeline.

Moves the cursor by a given delta time on the presentation timeline.

Moves the cursor a given number of samples in decode order.

Moves the cursor a given number of samples in presentation order.

### [Getting Timestamps](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#Getting-Timestamps)

[`var decodeTimeStamp: CMTime`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/decodetimestamp)

The decode timestamp of the sample at the current position of the cursor.

[`var presentationTimeStamp: CMTime`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/presentationtimestamp)

The presentation timestamp of the sample at the current position of the cursor.

### [Getting Sample Information](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#Getting-Sample-Information)

[`var currentChunkInfo: AVSampleCursorChunkInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentchunkinfo)

A value that provides information about the chunk of samples to which the current sample belongs.

[`struct AVSampleCursorChunkInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorchunkinfo)

A value that provides information about a chunk of media samples.

[`var currentChunkStorageRange: AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentchunkstoragerange)

The sample range in the storage container to load together with the current sample as a chunk.

[`struct AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursorstoragerange)

A structure that indicates the offset and length of storage for a media sample or its chunk.

[`var currentChunkStorageURL: URL?`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentchunkstorageurl)

The URL of the storage container of the current sample and other samples to load in the same operation as a chunk.

[`var currentSampleDependencyInfo: AVSampleCursorDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampledependencyinfo)

The dependency information that describes relationships between a media sample and other media samples in the same sample sequence.

[`struct AVSampleCursorDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo)

A value for describing dependencies between a media sample and other media samples in the same sample sequence.

[`var currentSampleDuration: CMTime`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampleduration)

The decode duration of the sample at the cursor’s current position.

[`var currentSampleIndexInChunk: Int64`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampleindexinchunk)

The index of the current sample within the chunk to which it belongs.

[`var currentSampleStorageRange: AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsamplestoragerange)

The offset and length of the current sample in the current chunk storage URL.

[`var currentSampleSyncInfo: AVSampleCursorSyncInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsamplesyncinfo)

The synchronization information for the current sample for consideration when resynchronizing a decoder.

[`struct AVSampleCursorSyncInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo)

A structure that describes the attributes of media samples to consider when resynchronizing a decoder.

Returns the format description of the sample at the cursor’s current position.

[`var currentSampleAudioDependencyInfo: AVSampleCursorAudioDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampleaudiodependencyinfo)

The independent decodability information for the audio sample.

[`var currentSampleDependencyAttachments: [AnyHashable : Any]?`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampledependencyattachments)

A dictionary of dependency-related sample buffer attachments.

### [Accessing Samples](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#Accessing-Samples)

Determines whether a sample earlier in decode order can have a presentation timestamp later than that of the specified sample cursor.

Determines whether a sample later in decode order can have a presentation timestamp earlier than that of the specified sample cursor.

[`var samplesRequiredForDecoderRefresh: Int`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/samplesrequiredfordecoderrefresh)

The number of samples prior to the current sample, in decode order, the decoder requires to achieve a coherent output at the current decode time.

### [Comparing Sample Cursors](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#Comparing-Sample-Cursors)

Compares the relative positions of two sample cursors and returns their relative positions.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#see-also)

### [Sample cursors](https://developer.apple.com/documentation/avfoundation/avsamplecursor\#Sample-cursors)

[`struct AVSampleCursorAudioDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo)

A structure that describes the independent decodability of audio samples.

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVSampleCursorDependencyInfo

Structure

# AVSampleCursorDependencyInfo

A value for describing dependencies between a media sample and other media samples in the same sample sequence.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

struct AVSampleCursorDependencyInfo

## [Topics](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo\#topics)

### [Dependency Information](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo\#Dependency-Information)

[`var sampleIndicatesWhetherItHasDependentSamples: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasdependentsamples)

A Boolean value that determines whether the sample indicates if other samples depend on it.

[`var sampleHasDependentSamples: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/samplehasdependentsamples)

A Boolean value that determines whether the sample has dependent samples.

[`var sampleIndicatesWhetherItDependsOnOthers: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetheritdependsonothers)

A Boolean value that determines whether the sample indicates that it depends on other samples.

[`var sampleDependsOnOthers: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampledependsonothers)

A Boolean value that determines whether the sample depends on other samples.

[`var sampleIndicatesWhetherItHasRedundantCoding: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasredundantcoding)

A Boolean value that determines whether the sample indicates that it has redundant coding.

[`var sampleHasRedundantCoding: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/samplehasredundantcoding)

A Boolean value that determines whether the sample has redundant coding.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo\#Initializers)

[`init()`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/init())

Creates a sample cursor dependency information structure.

[`init(sampleIndicatesWhetherItHasDependentSamples: ObjCBool, sampleHasDependentSamples: ObjCBool, sampleIndicatesWhetherItDependsOnOthers: ObjCBool, sampleDependsOnOthers: ObjCBool, sampleIndicatesWhetherItHasRedundantCoding: ObjCBool, sampleHasRedundantCoding: ObjCBool)`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/init(sampleindicateswhetherithasdependentsamples:samplehasdependentsamples:sampleindicateswhetheritdependsonothers:sampledependsonothers:sampleindicateswhetherithasredundantcoding:samplehasredundantcoding:))

Creates a sample cursor dependency information structure with sample information.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo\#conforms-to)

- [`BitwiseCopyable`](https://developer.apple.com/documentation/Swift/BitwiseCopyable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo\#see-also)

### [Sample cursors](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo\#Sample-cursors)

[`class AVSampleCursor`](https://developer.apple.com/documentation/avfoundation/avsamplecursor)

An object that provides information about the media sample at the cursor’s current position.

[`struct AVSampleCursorSyncInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo)

A structure that describes the attributes of media samples to consider when resynchronizing a decoder.

[`struct AVSampleCursorAudioDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo)

A structure that describes the independent decodability of audio samples.

[`struct AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursorstoragerange)

A structure that indicates the offset and length of storage for a media sample or its chunk.

[`struct AVSampleCursorChunkInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorchunkinfo)

A value that provides information about a chunk of media samples.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-3coq5

-3coq5#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeySessionDelegate](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)
- contentKeySession(\_:didProvide:)

Instance Method

# contentKeySession(\_:didProvide:)

Provides the receiver with a new content key request object.

func contentKeySession(
_ session: AVContentKeySession,
didProvide keyRequest: AVContentKeyRequest
)

**Required**

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-3coq5\#parameters)

`session`

The content key session that is providing the new content key request.

`keyRequest`

The request for a new content key.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-3coq5\#see-also)

### [Providing New Content Key Requests](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-3coq5\#Providing-New-Content-Key-Requests)

[`func contentKeySession(AVContentKeySession, didProvideRenewingContentKeyRequest: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didproviderenewingcontentkeyrequest:))

Provides the receiver with a new content key request object for the renewal of an existing content key.

[`func contentKeySession(AVContentKeySession, didProvide: AVPersistableContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:)-2wdgz)

Provides the receiver with a new content key request object to process a persistable content key.

---

# https://developer.apple.com/documentation/avfoundation/setting-color-properties-for-a-specific-resolution

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Video settings](https://developer.apple.com/documentation/avfoundation/video-settings)
- Setting Color Properties for a Specific Resolution

Article

# Setting Color Properties for a Specific Resolution

Choose the proper color property keys for the desired color range.

## [Overview](https://developer.apple.com/documentation/avfoundation/setting-color-properties-for-a-specific-resolution\#overview)

After specifying the [`AVVideoColorPropertiesKey`](https://developer.apple.com/documentation/avfoundation/avvideocolorpropertieskey), you must specify a color primary, transfer function, and Y’CbCr matrix.

For HD colorimetry, specify:

- [`AVVideoColorPrimaries_ITU_R_709_2`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_709_2)

- [`AVVideoTransferFunction_ITU_R_709_2`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_709_2)

- [`AVVideoYCbCrMatrix_ITU_R_709_2`](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_709_2)

For SD colorimetry, specify:

- [`AVVideoColorPrimaries_SMPTE_C`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_smpte_c)

- [`AVVideoYCbCrMatrix_ITU_R_601_4`](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_601_4)

For wide gamut HD colorimetry, specify:

- [`AVVideoColorPrimaries_P3_D65`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_p3_d65)

If the source and destination color properties differ, AVFoundation matches the color. You must tag the source.

## [See Also](https://developer.apple.com/documentation/avfoundation/setting-color-properties-for-a-specific-resolution\#see-also)

### [Color properties](https://developer.apple.com/documentation/avfoundation/setting-color-properties-for-a-specific-resolution\#Color-properties)

[`let AVVideoAllowWideColorKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowwidecolorkey)

The key for a dictionary that indicates whether the client can process wide color.

[`let AVVideoColorPrimariesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimarieskey)

The key to identify color primaries in a color properties dictionary.

[`let AVVideoColorPrimaries_EBU_3213: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_ebu_3213)

The color primary is in the EBU Tech. 3213 color space.

[`let AVVideoColorPrimaries_ITU_R_2020: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_2020)

The color primary is in the ITU\_R BT.2020 color space for ultra high definition television.

[`let AVVideoColorPrimaries_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_709_2)

The color primary is in the ITU\_R BT.709 color space.

[`let AVVideoColorPrimaries_P3_D65: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_p3_d65)

The color primary uses the DCI-P3 D65 color space.

[`let AVVideoColorPrimaries_SMPTE_C: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_smpte_c)

The color primary uses the SMPTE C color space.

[`let AVVideoColorPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorpropertieskey)

The key for a dictionary that contains properties specifying video color.

[`let AVVideoTransferFunctionKey: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunctionkey)

The key to identify the transfer function in a color properties dictionary.

[`let AVVideoTransferFunction_IEC_sRGB: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_iec_srgb)

The transfer function for the IEC sRGB color space.

[`let AVVideoTransferFunction_ITU_R_2100_HLG: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_2100_hlg)

The transfer function for the ITU\_R BT.2100 color space.

[`let AVVideoTransferFunction_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_709_2)

The transfer function for the ITU\_R BT.709 color space.

[`let AVVideoTransferFunction_Linear: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_linear)

The transfer function for the linear color space.

[`let AVVideoTransferFunction_SMPTE_240M_1995: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_smpte_240m_1995)

The transfer function for the SMPTE 240M color space.

[`let AVVideoTransferFunction_SMPTE_ST_2084_PQ: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_smpte_st_2084_pq)

The transfer function for the SMPTE 2084 color space.

---

# https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMutableAudioMixInputParameters

Class

# AVMutableAudioMixInputParameters

The parameters you use when adding an audio track to a mix.

class AVMutableAudioMixInputParameters

## [Topics](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#topics)

### [Creating Input Parameters](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#Creating-Input-Parameters)

[`convenience init(track: AVAssetTrack?)`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/init(track:))

Creates a mutable input parameters object for a given track.

### [Managing the Track ID](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#Managing-the-Track-ID)

[`var trackID: CMPersistentTrackID`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/trackid)

The identifier of the audio track to which the parameters should be applied.

### [Setting the Volume](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#Setting-the-Volume)

[`func setVolume(Float, at: CMTime)`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/setvolume(_:at:))

Sets the value of the audio volume starting at the specified time.

[`func setVolumeRamp(fromStartVolume: Float, toEndVolume: Float, timeRange: CMTimeRange)`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/setvolumeramp(fromstartvolume:toendvolume:timerange:))

Sets a volume ramp to apply during a specified time range.

### [Getting an Audio Tap](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#Getting-an-Audio-Tap)

[`var audioTapProcessor: MTAudioProcessingTap?`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/audiotapprocessor)

The audio processing tap associated with the track.

### [Time Pitch Settings](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#Time-Pitch-Settings)

[`var audioTimePitchAlgorithm: AVAudioTimePitchAlgorithm?`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/audiotimepitchalgorithm)

The processing algorithm used to manage audio pitch for scaled audio edits.

[`struct AVAudioTimePitchAlgorithm`](https://developer.apple.com/documentation/avfoundation/avaudiotimepitchalgorithm)

An algorithm used to set the audio pitch as the rate changes.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#inherits-from)

- [`AVAudioMixInputParameters`](https://developer.apple.com/documentation/avfoundation/avaudiomixinputparameters)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSMutableCopying`](https://developer.apple.com/documentation/Foundation/NSMutableCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#see-also)

### [Mixing](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters\#Mixing)

[`class AVAudioMix`](https://developer.apple.com/documentation/avfoundation/avaudiomix)

An object that manages the input parameters for mixing audio tracks.

[`class AVMutableAudioMix`](https://developer.apple.com/documentation/avfoundation/avmutableaudiomix)

[`class AVAudioMixInputParameters`](https://developer.apple.com/documentation/avfoundation/avaudiomixinputparameters)

An object that represents the parameters that you apply when adding an audio track to a mix.

---

# https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Media reading and writing](https://developer.apple.com/documentation/avfoundation/media-reading-and-writing)
- Converting side-by-side 3D video to multiview HEVC and spatial video

Sample Code

# Converting side-by-side 3D video to multiview HEVC and spatial video

Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.

[Download](https://docs-assets.developer.apple.com/published/4a60632cecb7/ConvertingSideBySide3DVideoToMultiviewHEVCAndSpatialVideo.zip)

Xcode 16.0+

## [Overview](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Overview)

In visionOS, 3D video uses the _Multiview High Efficiency Video Encoding_ (MV-HEVC) format, supported by MPEG4 and QuickTime. Unlike other 3D media, MV-HEVC stores a single track containing multiple layers for the video, where the track and layers share a frame size. This track frame size is different from other 3D video types, such as _side-by-side video_. Side-by-side videos use a single track, and place the left- and right-eye images next to each other as part of a single video frame.

To convert side-by-side video to MV-HEVC, you load the source video, extract each frame, and then split the frame horizontally. Then copy the left and right sides of the split frame into the left- and right-eye layers, writing a frame containing both layers to the output.

This sample app demonstrates the process for converting side-by-side video files to MV-HEVC, encoding the output as a QuickTime file. The output is placed in the same directory as the input file, with `_MVHEVC` appended to the original filename.

For videos you capture with a consistent camera configuration, you can optionally add spatial metadata to the output file. _Spatial metadata_ describes properties of the left- and right-eye cameras that captured the stereo scene.

Adding spatial metadata to a stereo MV-HEVC video prompts Apple platforms to consider the video as _spatial_ instead of just stereo, and opts the video into visual treatments on Apple Vision Pro that can minimize common causes of stereo viewing discomfort.

To learn more about when to provide spatial metadata for a stereo MV-HEVC video and the metadata values to provide, see [Creating spatial photos and videos with spatial metadata](https://developer.apple.com/documentation/ImageIO/Creating-spatial-photos-and-videos-with-spatial-metadata).

You can verify this sample’s MV-HEVC output by opening it with the sample project from [Reading multiview 3D video files](https://developer.apple.com/documentation/avfoundation/reading-multiview-3d-video-files).

For the full details of the MV-HEVC format, see [Apple HEVC Stereo Video - Interoperability Profile (PDF)](https://developer.apple.com/av-foundation/HEVC-Stereo-Video-Profile.pdf) and [ISO Base Media File Format and Apple HEVC Stereo Video (PDF)](https://developer.apple.com/av-foundation/Stereo-Video-ISOBMFF-Extensions.pdf).

### [Configure the sample code project](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Configure-the-sample-code-project)

To also add spatial metadata to the file, add four additional arguments to Arguments Passed On Launch:

- `--spatial` (or `-s`) to indicate that you want to include spatial metadata

- `--baseline` (or `-b`) to provide a baseline in millimeters (for example, `--baseline 64.0` for a 64mm baseline)

- `--fov` (or `-f`) to provide a horizontal field of view in degrees (for example, `--fov 80.0` for an 80-degree field of view)

- `--disparityAdjustment` (or `-d`) to provide a disparity adjustment (for example, `--disparityAdjustment 0.02` for a 2% positive disparity shift)

By default, the project’s scheme loads a side-by-side video from the Xcode project folder named `Hummingbird.mov`. This video is a sequence of renders of a 3D scene, showing an animated hummingbird model. By default, the app converts this example video to a stereo MV-HEVC file, without spatial metadata.

The `--spatial` argument tells the app to write spatial metadata to the output video. The virtual cameras used to create these renders were positioned 64mm apart with a horizontal field of view of 80 degrees, and so the value for the `--baseline` argument is `64.0`, and the value of the `--fov` argument is `80.0`.

For this video, a disparity adjustment of +2% of the image width produces a comfortable depth effect when the spatial video is presented in a window on Apple Vision Pro. This 2% disparity adjustment value positions the nearest object in the spatial video — the hummingbird — just behind the front of the window, while still keeping an effective illusion of depth between the hummingbird and the background. The scheme’s arguments express the +2% disparity adjustment with a `--disparityAdjustment` value of `0.02`.

### [Load the side-by-side video](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Load-the-side-by-side-video)

The app starts by loading the side-by-side video, creating an [`AVAssetReader`](https://developer.apple.com/documentation/avfoundation/avassetreader). The app calls [`loadTracks(withMediaCharacteristic:completionHandler:)`](https://developer.apple.com/documentation/avfoundation/avasset/loadtracks(withmediacharacteristic:completionhandler:)) to load video tracks, and then selects the first track available as the side-by-side input.

let asset = AVURLAsset(url: url)
reader = try AVAssetReader(asset: asset)

// Get the side-by-side video track.
guard let videoTrack = try await asset.loadTracks(withMediaCharacteristic: .visual).first else {
fatalError("Error loading side-by-side video input")
}

The app also stores the frame size for the side-by-side video, and calculates the size of the output frames.

sideBySideFrameSize = try await videoTrack.load(.naturalSize)
eyeFrameSize = CGSize(width: sideBySideFrameSize.width / 2, height: sideBySideFrameSize.height)

To finish loading the video, the app creates an [`AVAssetReaderTrackOutput`](https://developer.apple.com/documentation/avfoundation/avassetreadertrackoutput) and then adds this output stream to the `AVAssetReader`.

let readerSettings: [String: Any] = [\
kCVPixelBufferIOSurfacePropertiesKey as String: [String: String]()\
]
sideBySideTrack = AVAssetReaderTrackOutput(track: videoTrack, outputSettings: readerSettings)

if reader.canAdd(sideBySideTrack) {
reader.add(sideBySideTrack)
}

if !reader.startReading() {
fatalError(reader.error?.localizedDescription ?? "Unknown error during track read start")
}

When creating the reader track output, the app specifies the file’s pixel format and [IOSurface](https://developer.apple.com/documentation/IOSurface) settings in the `readerSettings` dictionary. The app indicates that output goes to a 32-bit ARGB pixel buffer, using [`kCVPixelBufferPixelFormatTypeKey`](https://developer.apple.com/documentation/CoreVideo/kCVPixelBufferPixelFormatTypeKey) with a value of [`kCVPixelFormatType_32ARGB`](https://developer.apple.com/documentation/CoreVideo/kCVPixelFormatType_32ARGB). The sample app also manages its own pixel buffer allocations, passing an empty array as the value for [`kCVPixelBufferIOSurfacePropertiesKey`](https://developer.apple.com/documentation/CoreVideo/kCVPixelBufferIOSurfacePropertiesKey).

### [Configure the output MV-HEVC file](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Configure-the-output-MV-HEVC-file)

With the reader initialized, the app calls the `async` method `transcodeToMVHEVC(output:spatialMetadata:)` to generate the output file. First, the app creates a new [`AVAssetWriter`](https://developer.apple.com/documentation/avfoundation/avassetwriter) pointing to the video output location, and then configures the necessary information on the output to indicate that the file contains MV-HEVC video.

var multiviewCompressionProperties: [CFString: Any] = [\
kVTCompressionPropertyKey_MVHEVCVideoLayerIDs: MVHEVCVideoLayerIDs,\
kVTCompressionPropertyKey_MVHEVCViewIDs: MVHEVCViewIDs,\
kVTCompressionPropertyKey_MVHEVCLeftAndRightViewIDs: MVHEVCLeftAndRightViewIDs,\
kVTCompressionPropertyKey_HasLeftStereoEyeView: true,\
kVTCompressionPropertyKey_HasRightStereoEyeView: true\
]

[`kVTCompressionPropertyKey_HasLeftStereoEyeView`](https://developer.apple.com/documentation/VideoToolbox/kVTCompressionPropertyKey_HasLeftStereoEyeView) and [`kVTCompressionPropertyKey_HasRightStereoEyeView`](https://developer.apple.com/documentation/VideoToolbox/kVTCompressionPropertyKey_HasRightStereoEyeView) are `true`, because the output contains a layer for each eye. [`kVTCompressionPropertyKey_MVHEVCVideoLayerIDs`](https://developer.apple.com/documentation/VideoToolbox/kVTCompressionPropertyKey_MVHEVCVideoLayerIDs), [`kVTCompressionPropertyKey_MVHEVCViewIDs`](https://developer.apple.com/documentation/VideoToolbox/kVTCompressionPropertyKey_MVHEVCViewIDs), and [`kVTCompressionPropertyKey_MVHEVCLeftAndRightViewIDs`](https://developer.apple.com/documentation/VideoToolbox/kVTCompressionPropertyKey_MVHEVCLeftAndRightViewIDs) define the layer and view IDs to use for multiview HEVC encoding. In the sample app, these are all the same.

The sample app uses `0` for the left eye layer/view ID and `1` for the right eye layer/view ID.

let MVHEVCVideoLayerIDs = [0, 1]

// For simplicity, choose view IDs that match the layer IDs.
let MVHEVCViewIDs = [0, 1]

// The first element in this array is the view ID of the left eye.
let MVHEVCLeftAndRightViewIDs = [0, 1]

### [Include spatial metadata](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Include-spatial-metadata)

If the person calling this command-line app requested to add spatial metadata to the output file, and provided the necessary spatial metadata, the app converts that metadata to expected units and scales, and adds an additional compression property key for each metadata value. The app also specifies that the input uses a rectilinear projection, to indicate that it has the expected projection for spatial video.

if let spatialMetadata {

let baselineInMicrometers = UInt32(1000.0 * spatialMetadata.baselineInMillimeters)
let encodedHorizontalFOV = UInt32(1000.0 * spatialMetadata.horizontalFOV)
let encodedDisparityAdjustment = Int32(10_000.0 * spatialMetadata.disparityAdjustment)

multiviewCompressionProperties[kVTCompressionPropertyKey_ProjectionKind] = kCMFormatDescriptionProjectionKind_Rectilinear
multiviewCompressionProperties[kVTCompressionPropertyKey_StereoCameraBaseline] = baselineInMicrometers
multiviewCompressionProperties[kVTCompressionPropertyKey_HorizontalFieldOfView] = encodedHorizontalFOV
multiviewCompressionProperties[kVTCompressionPropertyKey_HorizontalDisparityAdjustment] = encodedDisparityAdjustment

}

### [Configure the MV-HEVC input source](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Configure-the-MV-HEVC-input-source)

The app transcodes video by directly copying pixels from the source frame. Writing track data to a video file requires an [`AVAssetWriterInput`](https://developer.apple.com/documentation/avfoundation/avassetwriterinput). The sample app uses an [`AVAssetWriterInputTaggedPixelBufferGroupAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputtaggedpixelbuffergroupadaptor) to provide pixel data from the source, writing to the output.

let multiviewSettings: [String: Any] = [\
AVVideoCodecKey: AVVideoCodecType.hevc,\
AVVideoWidthKey: self.eyeFrameSize.width,\
AVVideoHeightKey: self.eyeFrameSize.height,\
AVVideoCompressionPropertiesKey: multiviewCompressionProperties\
]

guard multiviewWriter.canApply(outputSettings: multiviewSettings, forMediaType: AVMediaType.video) else {
fatalError("Error applying output settings")
}

let frameInput = AVAssetWriterInput(mediaType: .video, outputSettings: multiviewSettings)

let sourcePixelAttributes: [String: Any] = [\
kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32ARGB,\
kCVPixelBufferWidthKey as String: self.sideBySideFrameSize.width,\
kCVPixelBufferHeightKey as String: self.sideBySideFrameSize.height\
]

let bufferInputAdapter = AVAssetWriterInputTaggedPixelBufferGroupAdaptor(assetWriterInput: frameInput, sourcePixelBufferAttributes: sourcePixelAttributes)

The `AVAssetWriterInput` source uses the same `outputSettings` as `videoWriter`, and the created pixel buffer adapter has the same frame size as the source. The app follows the best practice of calling [`canAdd(_:)`](https://developer.apple.com/documentation/avfoundation/avassetwriter/canadd(_:)-6al7j) to check the input adapter compatibility before calling [`add(_:)`](https://developer.apple.com/documentation/avfoundation/avassetwriter/add(_:)-4c4d0) to use it as a source.

guard multiviewWriter.canAdd(frameInput) else {
fatalError("Error adding side-by-side video frames as input")
}
multiviewWriter.add(frameInput)

### [Process input as it becomes available](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Process-input-as-it-becomes-available)

The app calls [`startWriting()`](https://developer.apple.com/documentation/avfoundation/avassetwriter/startwriting()) and [`startSession(atSourceTime:)`](https://developer.apple.com/documentation/avfoundation/avassetwriter/startsession(atsourcetime:)) in sequence to start the video writing process, and then iterates over available frame inputs with [`requestMediaDataWhenReady(on:using:)`](https://developer.apple.com/documentation/avfoundation/avassetwriterinput/requestmediadatawhenready(on:using:)).

guard multiviewWriter.startWriting() else {
fatalError("Failed to start writing multiview output file")
}
multiviewWriter.startSession(atSourceTime: CMTime.zero)

// The dispatch queue executes the closure when media reads from the input file are available.
frameInput.requestMediaDataWhenReady(on: DispatchQueue(label: "Multiview HEVC Writer")) {

The closure argument of `requestMediaDataWhenReady(on:using:)` runs on the provided [`DispatchQueue`](https://developer.apple.com/documentation/Dispatch/DispatchQueue) when the first data read is available. The closure itself is responsible for managing resources that process the media data, and running a loop to process data efficiently.

### [Create the video frame transfer session and output pixel buffer pool](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Create-the-video-frame-transfer-session-and-output-pixel-buffer-pool)

To perform the data transfer from the source track, the pixel input adapter requires a pixel buffer as a source. The app creates a [`VTPixelTransferSession`](https://developer.apple.com/documentation/VideoToolbox/VTPixelTransferSession) to allow for reading data from the video source, and uses the `AVAssetWriterInputTaggedPixelBufferGroupAdaptor`’s existing pixel buffer pool to allocate pixel buffers for the new multiview eye layers.

var session: VTPixelTransferSession? = nil
guard VTPixelTransferSessionCreate(allocator: kCFAllocatorDefault, pixelTransferSessionOut: &session) == noErr, let session else {
fatalError("Failed to create pixel transfer")
}
guard let pixelBufferPool = bufferInputAdapter.pixelBufferPool else {
fatalError("Failed to retrieve existing pixel buffer pool")
}

### [Copy frame images from input to output](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Copy-frame-images-from-input-to-output)

After preparing resources, the app then begins a loop to process frames until there’s no more data, or the input read has stopped to buffer data. The [`isReadyForMoreMediaData`](https://developer.apple.com/documentation/avfoundation/avassetwriterinput/isreadyformoremediadata) property of an input source is `true` if another frame is immediately available to process. When a frame is ready, a [`CVImageBuffer`](https://developer.apple.com/documentation/CoreVideo/CVImageBuffer) instance is created from it.

The app is now ready to handle sampling. If there’s an available sample, the app processes it in the `convertFrame` method, then calls [`appendTaggedBuffers(_:withPresentationTime:)`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputtaggedpixelbuffergroupadaptor/appendtaggedbuffers(_:withpresentationtime:)), copying the side-by-side sample buffer’s [`outputPresentationTimeStamp`](https://developer.apple.com/documentation/CoreMedia/CMSampleBuffer/outputPresentationTimeStamp) timestamp to the new multiview timestamp.

while frameInput.isReadyForMoreMediaData && bufferInputAdapter.assetWriterInput.isReadyForMoreMediaData {
if let sampleBuffer = self.sideBySideTrack.copyNextSampleBuffer() {
guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
fatalError("Failed to load source samples as an image buffer")
}
let taggedBuffers = self.convertFrame(fromSideBySide: imageBuffer, with: pixelBufferPool, in: session)
let newPTS = sampleBuffer.outputPresentationTimeStamp
if !bufferInputAdapter.appendTaggedBuffers(taggedBuffers, withPresentationTime: newPTS) {
fatalError("Failed to append tagged buffers to multiview output")
}

Input reading finishes when there are no more sample buffers to process from the input stream. The app calls [`markAsFinished()`](https://developer.apple.com/documentation/avfoundation/avassetwriterinput/markasfinished()) to close the stream, and [`finishWriting(completionHandler:)`](https://developer.apple.com/documentation/avfoundation/avassetwriter/finishwriting(completionhandler:)) to complete the multiview video write. The app also calls [`resume()`](https://developer.apple.com/documentation/Swift/CheckedContinuation/resume()) on its associated [`CheckedContinuation`](https://developer.apple.com/documentation/Swift/CheckedContinuation), to

In the `convertFrame` method, the app processes the left- and right-eye images for the frame by `layerID`, using `0` for the left eye and `1` for the right. First, the app creates a pixel buffer from the pool.

var pixelBuffer: CVPixelBuffer?
CVPixelBufferPoolCreatePixelBuffer(kCFAllocatorDefault, pixelBufferPool, &pixelBuffer)
guard let pixelBuffer else {
fatalError("Failed to create pixel buffer for layer \(layerID)")
}

The method then uses its passed `VTPixelTransferSession` to copy the pixels from the side-by-side source, placing them into the created output sample buffer by cropping the frame to include only one eye’s image.

// Crop the transfer region to the current eye.
let apertureOffset = -(self.eyeFrameSize.width / 2) + CGFloat(layerID) * self.eyeFrameSize.width
let cropRectDict = [\
kCVImageBufferCleanApertureHorizontalOffsetKey: apertureOffset,\
kCVImageBufferCleanApertureVerticalOffsetKey: 0,\
kCVImageBufferCleanApertureWidthKey: self.eyeFrameSize.width,\
kCVImageBufferCleanApertureHeightKey: self.eyeFrameSize.height\
]
CVBufferSetAttachment(imageBuffer, kCVImageBufferCleanApertureKey, cropRectDict as CFDictionary, CVAttachmentMode.shouldPropagate)
VTSessionSetProperty(session, key: kVTPixelTransferPropertyKey_ScalingMode, value: kVTScalingMode_CropSourceToCleanAperture)

// Transfer the image to the pixel buffer.
guard VTPixelTransferSessionTransferImage(session, from: imageBuffer, to: pixelBuffer) == noErr else {
fatalError("Error during pixel transfer session for layer \(layerID)")
}

Setting aperture view properties on [`CVBufferSetAttachment(_:_:_:_:)`](https://developer.apple.com/documentation/CoreVideo/CVBufferSetAttachment(_:_:_:_:)) defines how to capture and crop input images. The aperture here is the size of an eye image, and the center of the capture frame offset with [`kCVImageBufferCleanApertureHorizontalOffsetKey`](https://developer.apple.com/documentation/CoreVideo/kCVImageBufferCleanApertureHorizontalOffsetKey) by `-0.5 * width` for the left eye and `+0.5 * width` for the right eye, to capture the correct half of the side-by-side frame.

The app then calls [`VTSessionSetProperty(_:key:value:)`](https://developer.apple.com/documentation/VideoToolbox/VTSessionSetProperty(_:key:value:)) to crop the image to the aperture frame with [`kVTScalingMode_CropSourceToCleanAperture`](https://developer.apple.com/documentation/VideoToolbox/kVTScalingMode_CropSourceToCleanAperture). Next, the app calls [`VTPixelTransferSessionTransferImage(_:from:to:)`](https://developer.apple.com/documentation/VideoToolbox/VTPixelTransferSessionTransferImage(_:from:to:)) to copy source pixels to the destination buffer.

The final step is to create a [`CMTaggedBuffer`](https://developer.apple.com/documentation/CoreMedia/CMTaggedBuffer) for the eye image to

let tags: [CMTag] = [.videoLayerID(Int64(layerID)), .stereoView(eye)]
let buffer = CMTaggedBuffer(tags: tags, buffer: .pixelBuffer(pixelBuffer))
taggedBuffers.append(buffer)

## [See Also](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#see-also)

### [Media writing](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video\#Media-writing)

[Converting projected video to Apple Projected Media Profile](https://developer.apple.com/documentation/avfoundation/converting-projected-video-to-apple-projected-media-profile)

Convert content with equirectangular or half-equirectangular projection to APMP.

[Writing Fragmented MPEG-4 Files for HTTP Live Streaming](https://developer.apple.com/documentation/avfoundation/writing-fragmented-mpeg-4-files-for-http-live-streaming)

Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.

[Creating spatial photos and videos with spatial metadata](https://developer.apple.com/documentation/ImageIO/Creating-spatial-photos-and-videos-with-spatial-metadata)

Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.

[Tagging Media with Video Color Information](https://developer.apple.com/documentation/avfoundation/tagging-media-with-video-color-information)

Inspect and set video color space information when writing and transcoding media.

Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.

[`class AVOutputSettingsAssistant`](https://developer.apple.com/documentation/avfoundation/avoutputsettingsassistant)

An object that builds audio and video output settings dictionaries.

[`class AVAssetWriter`](https://developer.apple.com/documentation/avfoundation/avassetwriter)

An object that writes media data to a container file.

[`class AVAssetWriterInput`](https://developer.apple.com/documentation/avfoundation/avassetwriterinput)

An object that appends media samples to a track in an asset writer’s output file.

[`class AVAssetWriterInputPixelBufferAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputpixelbufferadaptor)

An object that appends video samples to an asset writer input.

[`class AVAssetWriterInputTaggedPixelBufferGroupAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputtaggedpixelbuffergroupadaptor)

An object that appends tagged buffer groups to an asset writer input.

[`class AVAssetWriterInputMetadataAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor)

An object that appends timed metadata groups to an asset writer input.

[`class AVAssetWriterInputGroup`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputgroup)

A group of inputs with tracks that are mutually exclusive to each other for playback or processing.

---

# https://developer.apple.com/documentation/avfoundation/avvideotransferfunctionkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoTransferFunctionKey

Global Variable

# AVVideoTransferFunctionKey

The key to identify the transfer function in a color properties dictionary.

let AVVideoTransferFunctionKey: String

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avvideotransferfunctionkey\#mentions)

[Tagging Media with Video Color Information](https://developer.apple.com/documentation/avfoundation/tagging-media-with-video-color-information)

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideotransferfunctionkey\#see-also)

### [Color properties](https://developer.apple.com/documentation/avfoundation/avvideotransferfunctionkey\#Color-properties)

[Setting Color Properties for a Specific Resolution](https://developer.apple.com/documentation/avfoundation/setting-color-properties-for-a-specific-resolution)

Choose the proper color property keys for the desired color range.

[`let AVVideoAllowWideColorKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowwidecolorkey)

The key for a dictionary that indicates whether the client can process wide color.

[`let AVVideoColorPrimariesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimarieskey)

The key to identify color primaries in a color properties dictionary.

[`let AVVideoColorPrimaries_EBU_3213: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_ebu_3213)

The color primary is in the EBU Tech. 3213 color space.

[`let AVVideoColorPrimaries_ITU_R_2020: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_2020)

The color primary is in the ITU\_R BT.2020 color space for ultra high definition television.

[`let AVVideoColorPrimaries_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_709_2)

The color primary is in the ITU\_R BT.709 color space.

[`let AVVideoColorPrimaries_P3_D65: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_p3_d65)

The color primary uses the DCI-P3 D65 color space.

[`let AVVideoColorPrimaries_SMPTE_C: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_smpte_c)

The color primary uses the SMPTE C color space.

[`let AVVideoColorPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorpropertieskey)

The key for a dictionary that contains properties specifying video color.

[`let AVVideoTransferFunction_IEC_sRGB: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_iec_srgb)

The transfer function for the IEC sRGB color space.

[`let AVVideoTransferFunction_ITU_R_2100_HLG: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_2100_hlg)

The transfer function for the ITU\_R BT.2100 color space.

[`let AVVideoTransferFunction_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_709_2)

The transfer function for the ITU\_R BT.709 color space.

[`let AVVideoTransferFunction_Linear: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_linear)

The transfer function for the linear color space.

[`let AVVideoTransferFunction_SMPTE_240M_1995: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_smpte_240m_1995)

The transfer function for the SMPTE 240M color space.

[`let AVVideoTransferFunction_SMPTE_ST_2084_PQ: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_smpte_st_2084_pq)

The transfer function for the SMPTE 2084 color space.

---

# https://developer.apple.com/documentation/avfoundation/avvideoheightkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoHeightKey

Global Variable

# AVVideoHeightKey

A key to access the height of the video in pixels.

let AVVideoHeightKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avvideoheightkey\#Discussion)

The corresponding value is an instance of `NSNumber`.

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideoheightkey\#see-also)

### [Geometry](https://developer.apple.com/documentation/avfoundation/avvideoheightkey\#Geometry)

[`let AVVideoWidthKey: String`](https://developer.apple.com/documentation/avfoundation/avvideowidthkey)

A key to access the width of the video in pixels.

[`let AVVideoPixelAspectRatioKey: String`](https://developer.apple.com/documentation/avfoundation/avvideopixelaspectratiokey)

A key to access the video’s pixel aspect ratio.

[`let AVVideoPixelAspectRatioVerticalSpacingKey: String`](https://developer.apple.com/documentation/avfoundation/avvideopixelaspectratioverticalspacingkey)

A key to access the pixel aspect ratio vertical spacing.

[`let AVVideoPixelAspectRatioHorizontalSpacingKey: String`](https://developer.apple.com/documentation/avfoundation/avvideopixelaspectratiohorizontalspacingkey)

A key to access the pixel aspect ratio horizontal spacing.

---

# https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetWriterInputMetadataAdaptor

Class

# AVAssetWriterInputMetadataAdaptor

An object that appends timed metadata groups to an asset writer input.

macOS 10.10–11.0DeprecatedtvOS 9.0–26.0Deprecated

class AVAssetWriterInputMetadataAdaptor

## [Overview](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#overview)

Use a metadata adaptor to append track-level metadata, packaged as instances of [`AVTimedMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avtimedmetadatagroup), to an asset writer input.

## [Topics](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#topics)

### [Creating an Input Metadata Adaptor](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#Creating-an-Input-Metadata-Adaptor)

[`init(assetWriterInput: AVAssetWriterInput)`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor/init(assetwriterinput:))

Creates a metadata group adaptor to append timed metadata groups to write to an output file.

### [Appending Timed Metadata](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#Appending-Timed-Metadata)

Appends a timed metadata group to the adaptor.

### [Accessing the Input](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#Accessing-the-Input)

[`var assetWriterInput: AVAssetWriterInput`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor/assetwriterinput)

The input for the metadata adaptor.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#see-also)

### [Media writing](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor\#Media-writing)

[Converting projected video to Apple Projected Media Profile](https://developer.apple.com/documentation/avfoundation/converting-projected-video-to-apple-projected-media-profile)

Convert content with equirectangular or half-equirectangular projection to APMP.

[Converting side-by-side 3D video to multiview HEVC and spatial video](https://developer.apple.com/documentation/avfoundation/converting-side-by-side-3d-video-to-multiview-hevc-and-spatial-video)

Create video content for visionOS by converting an existing 3D HEVC file to a multiview HEVC format, optionally adding spatial metadata to create a spatial video.

[Writing Fragmented MPEG-4 Files for HTTP Live Streaming](https://developer.apple.com/documentation/avfoundation/writing-fragmented-mpeg-4-files-for-http-live-streaming)

Create an HTTP Live Streaming presentation by turning a movie file into a sequence of fragmented MPEG-4 files.

[Creating spatial photos and videos with spatial metadata](https://developer.apple.com/documentation/ImageIO/Creating-spatial-photos-and-videos-with-spatial-metadata)

Add spatial metadata to stereo photos and videos to create spatial media for viewing on Apple Vision Pro.

[Tagging Media with Video Color Information](https://developer.apple.com/documentation/avfoundation/tagging-media-with-video-color-information)

Inspect and set video color space information when writing and transcoding media.

Check color reproduction for a video in your app by using test patterns, video test equipment, and light-measurement instruments.

[`class AVOutputSettingsAssistant`](https://developer.apple.com/documentation/avfoundation/avoutputsettingsassistant)

An object that builds audio and video output settings dictionaries.

[`class AVAssetWriter`](https://developer.apple.com/documentation/avfoundation/avassetwriter)

An object that writes media data to a container file.

[`class AVAssetWriterInput`](https://developer.apple.com/documentation/avfoundation/avassetwriterinput)

An object that appends media samples to a track in an asset writer’s output file.

[`class AVAssetWriterInputPixelBufferAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputpixelbufferadaptor)

An object that appends video samples to an asset writer input.

[`class AVAssetWriterInputTaggedPixelBufferGroupAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputtaggedpixelbuffergroupadaptor)

An object that appends tagged buffer groups to an asset writer input.

[`class AVAssetWriterInputGroup`](https://developer.apple.com/documentation/avfoundation/avassetwriterinputgroup)

A group of inputs with tracks that are mutually exclusive to each other for playback or processing.

---

# https://developer.apple.com/documentation/avfoundation/avassetreader

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVAssetReader

Class

# AVAssetReader

An object that reads media data from an asset.

class AVAssetReader

## [Overview](https://developer.apple.com/documentation/avfoundation/avassetreader\#overview)

Use an asset reader to read media data from instances of [`AVAsset`](https://developer.apple.com/documentation/avfoundation/avasset). The assets you read may represent file-based media like QuickTime movies or MPEG-4 files, or media that you compose from multiple sources using [`AVComposition`](https://developer.apple.com/documentation/avfoundation/avcomposition).

## [Topics](https://developer.apple.com/documentation/avfoundation/avassetreader\#topics)

### [Creating an Asset Reader](https://developer.apple.com/documentation/avfoundation/avassetreader\#Creating-an-Asset-Reader)

[`init(asset: AVAsset) throws`](https://developer.apple.com/documentation/avfoundation/avassetreader/init(asset:))

Creates an object to read media data from an asset.

### [Managing Outputs](https://developer.apple.com/documentation/avfoundation/avassetreader\#Managing-Outputs)

Determines whether you can add the output to the asset reader.

[`func add(AVAssetReaderOutput)`](https://developer.apple.com/documentation/avfoundation/avassetreader/add(_:))

Adds an output to the reader.

[`var outputs: [AVAssetReaderOutput]`](https://developer.apple.com/documentation/avfoundation/avassetreader/outputs)

The outputs from which you read media data.

### [Configuring Reading](https://developer.apple.com/documentation/avfoundation/avassetreader\#Configuring-Reading)

[`var timeRange: CMTimeRange`](https://developer.apple.com/documentation/avfoundation/avassetreader/timerange)

The time range within the asset to read.

[`var status: AVAssetReader.Status`](https://developer.apple.com/documentation/avfoundation/avassetreader/status-swift.property)

The status of reading sample buffers from the asset.

[`enum Status`](https://developer.apple.com/documentation/avfoundation/avassetreader/status-swift.enum)

Values that represent the possible states of an asset reader.

[`var error: (any Error)?`](https://developer.apple.com/documentation/avfoundation/avassetreader/error)

An error that describes the reason for a failure.

### [Controlling Reading](https://developer.apple.com/documentation/avfoundation/avassetreader\#Controlling-Reading)

Prepares the asset reader to start reading sample buffers from the asset.

[`func cancelReading()`](https://developer.apple.com/documentation/avfoundation/avassetreader/cancelreading())

Cancels any background work and stops the reader’s outputs from reading more samples.

### [Inspecting the Asset](https://developer.apple.com/documentation/avfoundation/avassetreader\#Inspecting-the-Asset)

[`var asset: AVAsset`](https://developer.apple.com/documentation/avfoundation/avassetreader/asset)

The asset from which to read media data.

### [Instance Methods](https://developer.apple.com/documentation/avfoundation/avassetreader\#Instance-Methods)

Attaches the output to the reader and returns an output provider for reading caption groups.

Attaches the output to the reader and returns a tuple with an output provider for reading caption groups, and an associated random access controller.

Attaches the output to the reader and returns an output provider for reading timed metadata groups.

Attaches the output to the reader and returns a tuple with an output provider for timed metadata groups buffers, and an associated random access controller.

[`func outputProvider(for: AVAssetReaderOutput) -> sending AVAssetReaderOutput.Provider<CMReadySampleBuffer<CMSampleBuffer.DynamicContent>>`](https://developer.apple.com/documentation/avfoundation/avassetreader/outputprovider(for:))

Attaches the output to the reader and returns an output provider for reading sample buffers.

[`func outputProviderWithRandomAccess(for: AVAssetReaderOutput) -> sending (AVAssetReaderOutput.Provider<CMReadySampleBuffer<CMSampleBuffer.DynamicContent>>, AVAssetReaderOutput.RandomAccessController)`](https://developer.apple.com/documentation/avfoundation/avassetreader/outputproviderwithrandomaccess(for:))

Attaches the output to the reader and returns a tuple with an output provider for reading sample buffers, and an associated random access controller.

[`func start() throws`](https://developer.apple.com/documentation/avfoundation/avassetreader/start())

Prepares the reader to read media data from the asset.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avassetreader\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avassetreader\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avassetreader\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetreader\#see-also)

### [Media reading](https://developer.apple.com/documentation/avfoundation/avassetreader\#Media-reading)

[Reading multiview 3D video files](https://developer.apple.com/documentation/avfoundation/reading-multiview-3d-video-files)

Render single images for the left eye and right eye from a multiview High Efficiency Video Coding format file by reading individual video frames.

[`class AVAssetReaderOutput`](https://developer.apple.com/documentation/avfoundation/avassetreaderoutput)

An abstract class that defines the interface to read media samples from an asset reader.

[`class AVAssetReaderTrackOutput`](https://developer.apple.com/documentation/avfoundation/avassetreadertrackoutput)

An object that reads media data from a single track of an asset.

[`class AVAssetReaderAudioMixOutput`](https://developer.apple.com/documentation/avfoundation/avassetreaderaudiomixoutput)

An object that reads audio samples that result from mixing audio from one or more tracks.

[`class AVAssetReaderVideoCompositionOutput`](https://developer.apple.com/documentation/avfoundation/avassetreadervideocompositionoutput)

An object that reads composited video frames from one or more tracks of an asset.

[`class AVAssetReaderSampleReferenceOutput`](https://developer.apple.com/documentation/avfoundation/avassetreadersamplereferenceoutput)

An object that reads sample references from an asset track.

[`class AVAssetReaderOutputMetadataAdaptor`](https://developer.apple.com/documentation/avfoundation/avassetreaderoutputmetadataadaptor)

An object that creates timed metadata group objects for an asset track.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeyRequest](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)
- AVContentKeyRequest.RetryReason

Structure

# AVContentKeyRequest.RetryReason

The reason for asking the client to retry a content key request.

struct RetryReason

## [Topics](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason\#topics)

### [Reasons for Content Key Request Retry](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason\#Reasons-for-Content-Key-Request-Retry)

[`static let receivedObsoleteContentKey: AVContentKeyRequest.RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedobsoletecontentkey)

An obsolete key response that was set on the previous content key request.

[`static let receivedResponseWithExpiredLease: AVContentKeyRequest.RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedresponsewithexpiredlease)

A key response with an expired lease that was set on the previous content key request.

[`static let timedOut: AVContentKeyRequest.RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/timedout)

A key response that wasn’t set soon enough.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason\#Initializers)

[`init(rawValue: String)`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/init(rawvalue:))

Creates a retry reason with a string.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason\#conforms-to)

- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason\#see-also)

### [Inspecting a Request](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason\#Inspecting-a-Request)

[`var contentKey: AVContentKey?`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/contentkey)

The generated content key.

[`var contentKeySpecifier: AVContentKeySpecifier`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/contentkeyspecifier)

The requested content key specifier.

[`var options: [String : any Sendable]`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/options)

A dictionary of options used to initialize key loading.

---

# https://developer.apple.com/documentation/avfoundation/avvideoexpectedsourceframeratekey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoExpectedSourceFrameRateKey

Global Variable

# AVVideoExpectedSourceFrameRateKey

The expected source frame rate.

let AVVideoExpectedSourceFrameRateKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avvideoexpectedsourceframeratekey\#Discussion)

This is not used to control the frame rate; it is provided as a hint to the video encoder so that it can set up internal configuration before compression begins. The actual frame rate depends on frame duration and may vary. This should be set if an auto level [`AVVideoProfileLevelKey`](https://developer.apple.com/documentation/avfoundation/avvideoprofilelevelkey) is used, or if the source content has a high frame rate higher than 30 fps. The encoder might have to drop frames to satisfy bit stream requirements if this key is not specified.

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideoexpectedsourceframeratekey\#see-also)

### [Frame rate](https://developer.apple.com/documentation/avfoundation/avvideoexpectedsourceframeratekey\#Frame-rate)

[`let AVVideoAverageNonDroppableFrameRateKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoaveragenondroppableframeratekey)

The desired average number of non-droppable frames to be encoded for each second of video.

---

# https://developer.apple.com/documentation/avfoundation/avvideoappleprorawbitdepthkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoAppleProRAWBitDepthKey

Global Variable

# AVVideoAppleProRAWBitDepthKey

A key to access the Apple ProRAW bit depth.

let AVVideoAppleProRAWBitDepthKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avvideoappleprorawbitdepthkey\#Discussion)

The value is an integer value from 8 to16 bits.

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideoappleprorawbitdepthkey\#see-also)

### [Compression](https://developer.apple.com/documentation/avfoundation/avvideoappleprorawbitdepthkey\#Compression)

[`let AVVideoCompressionPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocompressionpropertieskey)

A key to access the dictionary of compression properties for a video asset.

[`let AVVideoDecompressionPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideodecompressionpropertieskey)

The key that indicates the video decompression properties to pass to the video decoder.

[`let AVVideoAverageBitRateKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoaveragebitratekey)

A key to access the average bit rate—as bits per second—used in compressing video.

[`let AVVideoQualityKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoqualitykey)

A key to set the JPEG compression quality of the video.

[`let AVVideoMaxKeyFrameIntervalKey: String`](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervalkey)

A key to access the maximum interval between keyframes.

[`let AVVideoMaxKeyFrameIntervalDurationKey: String`](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervaldurationkey)

A key to access the maximum interval duration between keyframes.

[`let AVVideoAllowFrameReorderingKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowframereorderingkey)

A key to access permission to reorder frames.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysession/invalidatepersistablecontentkey(_:options:completionhandler:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeySession](https://developer.apple.com/documentation/avfoundation/avcontentkeysession)
- invalidatePersistableContentKey(\_:options:completionHandler:)

Instance Method

# invalidatePersistableContentKey(\_:options:completionHandler:)

Invalidates the persistable content key and creates a secure server playback context (SPC) to verify the outcome of an invalidation request.

func invalidatePersistableContentKey(
_ persistableContentKeyData: Data,
options: [AVContentKeySessionServerPlaybackContextOption : Any]? = nil,

)
func invalidatePersistableContentKey(
_ persistableContentKeyData: Data,
options: [AVContentKeySessionServerPlaybackContextOption : Any]? = nil

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/invalidatepersistablecontentkey(_:options:completionhandler:)\#parameters)

`persistableContentKeyData`

The persistable content key data to invalidate.

`options`

Additional options to use when generating the server playback context. Pass `nil` to indicate no additional options.

`handler`

The completion handler callback.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/invalidatepersistablecontentkey(_:options:completionhandler:)\#see-also)

### [Invalidating Content Keys](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/invalidatepersistablecontentkey(_:options:completionhandler:)\#Invalidating-Content-Keys)

Invalidates all of an app’s persistable content keys and creates a secure server playback context (SPC) to verify the outcome of an invalidation request.

[`struct AVContentKeySessionServerPlaybackContextOption`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption)

Options for specifying additional information for generating server playback context (SPC).

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysession/removecontentkeyrecipient(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeySession](https://developer.apple.com/documentation/avfoundation/avcontentkeysession)
- removeContentKeyRecipient(\_:)

Instance Method

# removeContentKeyRecipient(\_:)

Tells the delegate to remove the specified recipient.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

func removeContentKeyRecipient(_ recipient: any AVContentKeyRecipient)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/removecontentkeyrecipient(_:)\#parameters)

`recipient`

The content key recipient to remove.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/removecontentkeyrecipient(_:)\#see-also)

### [Managing Content Key Recipients](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/removecontentkeyrecipient(_:)\#Managing-Content-Key-Recipients)

[`var contentKeyRecipients: [any AVContentKeyRecipient]`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/contentkeyrecipients)

An array of content key recipients.

[`protocol AVContentKeyRecipient`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrecipient)

A protocol for requiring decryption keys for media data.

[`func addContentKeyRecipient(any AVContentKeyRecipient)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysession/addcontentkeyrecipient(_:))

Tells the delegate that the specified recipient should have access to the decryption keys loaded with the session.

---

# https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/previewdimensions

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureResolvedPhotoSettings](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings)
- previewDimensions

Instance Property

# previewDimensions

The size, in pixels, of the preview image that the system delivers with the capture.

var previewDimensions: CMVideoDimensions { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/previewdimensions\#Discussion)

Use the [`previewPhotoFormat`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/previewphotoformat) property in your photo settings object to request delivery of a preview image alongside the main photo output from the capture. When you request a preview, the photo output chooses dimensions that best match your requested size while preserving the aspect ratio of the captured photo. Aspect ratio is determined by capture format and by device orientation at the moment of capture.

This property provides the dimensions of the requested preview image, which is delivered in the [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method. Use this property in earlier delegate methods to find the size of the image before delivery.

If you do not request a preview image, this property’s value has zero width and zero height.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/previewdimensions\#see-also)

### [Examining Output Dimensions](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/previewdimensions\#Examining-Output-Dimensions)

[`var photoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/photodimensions)

The size, in pixels, of the photo image (in a processed format, such as JPEG) that the capture delivers.

[`var deferredPhotoProxyDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/deferredphotoproxydimensions)

The resolved dimensions of the photo proxy when using deferred photo delivery.

[`var rawPhotoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawphotodimensions)

The size, in pixels, of the RAW-format photo image that the capture delivers.

[`var embeddedThumbnailDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/embeddedthumbnaildimensions)

The size, in pixels, of the thumbnail image that the capture delivers.

[`var rawEmbeddedThumbnailDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawembeddedthumbnaildimensions)

The size, in pixels, of the RAW-format embedded thumbnail image that the capture delivers.

[`var livePhotoMovieDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/livephotomoviedimensions)

The size, in pixels, of the Live Photo movie content that the capture delivers.

[`var portraitEffectsMatteDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/portraiteffectsmattedimensions)

The size, in pixels, of the portrait effects matte that the capture delivers.

Retrieves the resolved dimensions of the semantic segmentation mattes that the photo output delivers.

[`var photoProcessingTimeRange: CMTimeRange`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/photoprocessingtimerange)

The time range in which to expect the system to deliver the photo to the delegate.

---

# https://developer.apple.com/documentation/avfoundation/avassetreadertrackoutput/audiotimepitchalgorithm

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetReaderTrackOutput](https://developer.apple.com/documentation/avfoundation/avassetreadertrackoutput)
- audioTimePitchAlgorithm

Instance Property

# audioTimePitchAlgorithm

The processing algorithm to use for scaled audio edits.

var audioTimePitchAlgorithm: AVAudioTimePitchAlgorithm { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetreadertrackoutput/audiotimepitchalgorithm\#Discussion)

See [Time Pitch Algorithm Settings](https://developer.apple.com/documentation/avfoundation/time-pitch-algorithm-settings) for possible values. The system throws an exception if you set this property to a value other than one of the defined constants.

---

# https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawphotodimensions

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureResolvedPhotoSettings](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings)
- rawPhotoDimensions

Instance Property

# rawPhotoDimensions

The size, in pixels, of the RAW-format photo image that the capture delivers.

var rawPhotoDimensions: CMVideoDimensions { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawphotodimensions\#Discussion)

The output dimensions of a captured image are set at the moment of capture, depending on device orientation and capture session configuration. (For example, when the capture session includes a video output and video stabilization is in use, captured photos are smaller.)

This property provides the dimensions of the image to be delivered in the [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method. Use this property in earlier delegate methods to find the size of the image before delivery.

If you do not request capture in RAW format, this property’s value has zero width and zero height.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawphotodimensions\#see-also)

### [Examining Output Dimensions](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawphotodimensions\#Examining-Output-Dimensions)

[`var photoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/photodimensions)

The size, in pixels, of the photo image (in a processed format, such as JPEG) that the capture delivers.

[`var deferredPhotoProxyDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/deferredphotoproxydimensions)

The resolved dimensions of the photo proxy when using deferred photo delivery.

[`var previewDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/previewdimensions)

The size, in pixels, of the preview image that the system delivers with the capture.

[`var embeddedThumbnailDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/embeddedthumbnaildimensions)

The size, in pixels, of the thumbnail image that the capture delivers.

[`var rawEmbeddedThumbnailDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawembeddedthumbnaildimensions)

The size, in pixels, of the RAW-format embedded thumbnail image that the capture delivers.

[`var livePhotoMovieDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/livephotomoviedimensions)

The size, in pixels, of the Live Photo movie content that the capture delivers.

[`var portraitEffectsMatteDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/portraiteffectsmattedimensions)

The size, in pixels, of the portrait effects matte that the capture delivers.

Retrieves the resolved dimensions of the semantic segmentation mattes that the photo output delivers.

[`var photoProcessingTimeRange: CMTimeRange`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/photoprocessingtimerange)

The time range in which to expect the system to deliver the photo to the delegate.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoCaptureDelegate](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)
- photoOutput(\_:didFinishCaptureFor:error:)

Instance Method

# photoOutput(\_:didFinishCaptureFor:error:)

Notifies the delegate that the capture process is complete.

optional func photoOutput(
_ output: AVCapturePhotoOutput,
didFinishCaptureFor resolvedSettings: AVCaptureResolvedPhotoSettings,
error: (any Error)?
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:)\#parameters)

`output`

The photo output performing the capture.

`resolvedSettings`

An object describing the settings used for this capture. Match this object’s [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid) value to the [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid) property of the photo settings object you initiated capture with to determine which capture request this delegate call corresponds to. You can also use this object to find out which values the photo output has chosen for automatic settings.

`error`

If the capture process did not complete successfully, an error object describing the failure; otherwise, `nil`.

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:)\#mentions)

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

[Tracking Photo Capture Progress](https://developer.apple.com/documentation/avfoundation/tracking-photo-capture-progress)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:)\#Discussion)

The photo output calls this method when the entire capture process has finished, and no more delegate messages will be sent for this capture request. Use this time to clean up any resources you’ve allocated that relate to this capture request.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:)\#see-also)

### [Monitoring Capture Progress](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturefor:error:)\#Monitoring-Capture-Progress)

[`func photoOutput(AVCapturePhotoOutput, willBeginCaptureFor: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:willbegincapturefor:))

Notifies the delegate that the capture output has resolved settings and will soon begin its capture process.

[`func photoOutput(AVCapturePhotoOutput, willCapturePhotoFor: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:willcapturephotofor:))

Notifies the delegate that photo capture is about to occur.

[`func photoOutput(AVCapturePhotoOutput, didCapturePhotoFor: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didcapturephotofor:))

Notifies the delegate that the photo has been taken.

---

# https://developer.apple.com/documentation/avfoundation/avvideoaveragenondroppableframeratekey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoAverageNonDroppableFrameRateKey

Global Variable

# AVVideoAverageNonDroppableFrameRateKey

The desired average number of non-droppable frames to be encoded for each second of video.

let AVVideoAverageNonDroppableFrameRateKey: String

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideoaveragenondroppableframeratekey\#see-also)

### [Frame rate](https://developer.apple.com/documentation/avfoundation/avvideoaveragenondroppableframeratekey\#Frame-rate)

[`let AVVideoExpectedSourceFrameRateKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoexpectedsourceframeratekey)

The expected source frame rate.

---

# https://developer.apple.com/documentation/avfoundation/avvideoscalingmodefit

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoScalingModeFit

Global Variable

# AVVideoScalingModeFit

The string identifier for scaling a video to fit the surrounding view’s dimensions.

let AVVideoScalingModeFit: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avvideoscalingmodefit\#Discussion)

This mode crops the video to remove the edge processing region, preserving the aspect ratio of the cropped source by reducing the specified width or height, if necessary. It doesn’t scale a small source up to larger dimensions.

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideoscalingmodefit\#see-also)

### [Scaling mode](https://developer.apple.com/documentation/avfoundation/avvideoscalingmodefit\#Scaling-mode)

[`let AVVideoScalingModeKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmodekey)

A key to retrieve the video scaling mode from a dictionary.

[`let AVVideoScalingModeResize: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmoderesize)

The string identifier for resizing a video to fit the surrounding view’s dimensions.

[`let AVVideoScalingModeResizeAspect: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmoderesizeaspect)

The string identifier for resizing a video to its surrounding view’s shorter dimension while preserving its aspect ratio.

[`let AVVideoScalingModeResizeAspectFill: String`](https://developer.apple.com/documentation/avfoundation/avvideoscalingmoderesizeaspectfill)

The string identifier for resizing a video to fit the surrounding view’s longer dimension while preserving aspect ratio.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/availablerawembeddedthumbnailphotocodectypes

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoSettings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)
- availableRawEmbeddedThumbnailPhotoCodecTypes

Instance Property

# availableRawEmbeddedThumbnailPhotoCodecTypes

An array of video codec types compatible with the photo settings for embedding raw thumbnail images in photo file output.

var availableRawEmbeddedThumbnailPhotoCodecTypes: [AVVideoCodecType] { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/availablerawembeddedthumbnailphotocodectypes\#see-also)

### [Enabling Preview and Thumbnail Delivery](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/availablerawembeddedthumbnailphotocodectypes\#Enabling-Preview-and-Thumbnail-Delivery)

[`var previewPhotoFormat: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/previewphotoformat)

A dictionary describing the format for delivery of preview-sized images alongside the main photo.

[`var availablePreviewPhotoPixelFormatTypes: [OSType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/availablepreviewphotopixelformattypes-30d9)

An array of available of pixel format types available to specify a preview photo format.

[`var embeddedThumbnailPhotoFormat: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embeddedthumbnailphotoformat)

A dictionary describing the format for delivery of thumbnail images embedded in photo file output.

[`var rawEmbeddedThumbnailPhotoFormat: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawembeddedthumbnailphotoformat)

A dictionary describing the format for delivery of raw thumbnail images embedded in photo file output.

[`var availableEmbeddedThumbnailPhotoCodecTypes: [AVVideoCodecType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/availableembeddedthumbnailphotocodectypes)

An array of video codec types compatible with the photo settings for embedding thumbnail images in photo file output.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVContentKeySessionServerPlaybackContextOption

Structure

# AVContentKeySessionServerPlaybackContextOption

Options for specifying additional information for generating server playback context (SPC).

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

struct AVContentKeySessionServerPlaybackContextOption

## [Topics](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption\#topics)

### [Server Playback Context Options](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption\#Server-Playback-Context-Options)

[`static let protocolVersions: AVContentKeySessionServerPlaybackContextOption`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption/protocolversions)

Specifies the versions of the content protection protocols supported by the application.

[`static let serverChallenge: AVContentKeySessionServerPlaybackContextOption`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption/serverchallenge)

Specifies a nonce to include in the secure server playback context (SPC) to prevent replay attacks.

### [Initializing an Options Structure](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption\#Initializing-an-Options-Structure)

[`init(rawValue: String)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption/init(rawvalue:))

Creates a playback context options structure with the specified raw value.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption\#conforms-to)

- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption\#see-also)

### [Invalidating Content Keys](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption\#Invalidating-Content-Keys)

Invalidates the persistable content key and creates a secure server playback context (SPC) to verify the outcome of an invalidation request.

Invalidates all of an app’s persistable content keys and creates a secure server playback context (SPC) to verify the outcome of an invalidation request.

---

# https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervaldurationkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoMaxKeyFrameIntervalDurationKey

Global Variable

# AVVideoMaxKeyFrameIntervalDurationKey

A key to access the maximum interval duration between keyframes.

let AVVideoMaxKeyFrameIntervalDurationKey: String

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervaldurationkey\#see-also)

### [Compression](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervaldurationkey\#Compression)

[`let AVVideoCompressionPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocompressionpropertieskey)

A key to access the dictionary of compression properties for a video asset.

[`let AVVideoDecompressionPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideodecompressionpropertieskey)

The key that indicates the video decompression properties to pass to the video decoder.

[`let AVVideoAverageBitRateKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoaveragebitratekey)

A key to access the average bit rate—as bits per second—used in compressing video.

[`let AVVideoQualityKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoqualitykey)

A key to set the JPEG compression quality of the video.

[`let AVVideoMaxKeyFrameIntervalKey: String`](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervalkey)

A key to access the maximum interval between keyframes.

[`let AVVideoAllowFrameReorderingKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowframereorderingkey)

A key to access permission to reorder frames.

[`let AVVideoAppleProRAWBitDepthKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoappleprorawbitdepthkey)

A key to access the Apple ProRAW bit depth.

---

# https://developer.apple.com/documentation/avfoundation/avvideodecompressionpropertieskey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoDecompressionPropertiesKey

Global Variable

# AVVideoDecompressionPropertiesKey

The key that indicates the video decompression properties to pass to the video decoder.

let AVVideoDecompressionPropertiesKey: String

## [Discussion](https://developer.apple.com/documentation/avfoundation/avvideodecompressionpropertieskey\#Discussion)

The value for this key is specified as an [`NSDictionary`](https://developer.apple.com/documentation/Foundation/NSDictionary) object containing other keys to pass to the video decoder.

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideodecompressionpropertieskey\#see-also)

### [Compression](https://developer.apple.com/documentation/avfoundation/avvideodecompressionpropertieskey\#Compression)

[`let AVVideoCompressionPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocompressionpropertieskey)

A key to access the dictionary of compression properties for a video asset.

[`let AVVideoAverageBitRateKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoaveragebitratekey)

A key to access the average bit rate—as bits per second—used in compressing video.

[`let AVVideoQualityKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoqualitykey)

A key to set the JPEG compression quality of the video.

[`let AVVideoMaxKeyFrameIntervalKey: String`](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervalkey)

A key to access the maximum interval between keyframes.

[`let AVVideoMaxKeyFrameIntervalDurationKey: String`](https://developer.apple.com/documentation/avfoundation/avvideomaxkeyframeintervaldurationkey)

A key to access the maximum interval duration between keyframes.

[`let AVVideoAllowFrameReorderingKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowframereorderingkey)

A key to access permission to reorder frames.

[`let AVVideoAppleProRAWBitDepthKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoappleprorawbitdepthkey)

A key to access the Apple ProRAW bit depth.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedsdepthdatainphoto

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoSettings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)
- embedsDepthDataInPhoto

Instance Property

# embedsDepthDataInPhoto

A Boolean value that determines whether any depth data captured with the photo is included when generating output file data.

var embedsDepthDataInPhoto: Bool { get set }

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedsdepthdatainphoto\#mentions)

[Capturing Photos with Depth](https://developer.apple.com/documentation/avfoundation/capturing-photos-with-depth)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedsdepthdatainphoto\#Discussion)

When this property is [`true`](https://developer.apple.com/documentation/swift/true) (the default), and depth data capture is enabled with the [`isDepthDataDeliveryEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isdepthdatadeliveryenabled) property, the [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) class includes the depth map as an embedded attachment when you flatten the photo data for output in compatible file formats.

Set this property to [`false`](https://developer.apple.com/documentation/swift/false) if you wish to capture depth data with a photo but not include depth data in output.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedsdepthdatainphoto\#see-also)

### [Capturing Depth Data](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embedsdepthdatainphoto\#Capturing-Depth-Data)

[`var isDepthDataDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isdepthdatadeliveryenabled)

A Boolean value that determines whether the photo output captures depth data along with the photo.

[`var isDepthDataFiltered: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isdepthdatafiltered)

A Boolean value that determines whether to smooth noise and fill in missing values in depth data output.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureSession

Class

# AVCaptureSession

An object that configures capture behavior and coordinates the flow of data from input devices to capture outputs.

class AVCaptureSession

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturesession\#mentions)

[Setting Up a Capture Session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session)

[Enhancing your app experience with the Camera Control](https://developer.apple.com/documentation/avfoundation/enhancing-your-app-experience-with-the-camera-control)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturesession\#overview)

To perform real-time capture, you instantiate a capture session and add appropriate inputs and outputs. The following code fragment illustrates how to configure a capture device to record audio.

// Create the capture session.
let captureSession = AVCaptureSession()

// Find the default audio device.
guard let audioDevice = AVCaptureDevice.default(for: .audio) else { return }

do {
// Wrap the audio device in a capture device input.
let audioInput = try AVCaptureDeviceInput(device: audioDevice)
// If the input can be added, add it to the session.
if captureSession.canAddInput(audioInput) {
captureSession.addInput(audioInput)
}
} catch {
// Configuration failed. Handle error.
}

Call the [`startRunning()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning()) method to start the flow of data from the inputs to the outputs, and call the [`stopRunning()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/stoprunning()) method to stop the flow.

You use the [`sessionPreset`](https://developer.apple.com/documentation/avfoundation/avcapturesession/sessionpreset) property to customize the quality level, bitrate, or other settings for the output. Most common capture configurations are available through session presets; however, some specialized options (such as high frame rate) require directly setting a capture format on an [`AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice) instance.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturesession\#topics)

### [Configuring a session](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Configuring-a-session)

[`func beginConfiguration()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/beginconfiguration())

Marks the beginning of changes to a running capture session’s configuration to perform in a single atomic update.

[`func commitConfiguration()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/commitconfiguration())

Commits one or more changes to a running capture session’s configuration in a single atomic update.

### [Setting a session preset](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Setting-a-session-preset)

[`struct Preset`](https://developer.apple.com/documentation/avfoundation/avcapturesession/preset)

Presets that define standard configurations for a capture session.

Determines whether you can configure a capture session with the specified preset.

[`var sessionPreset: AVCaptureSession.Preset`](https://developer.apple.com/documentation/avfoundation/avcapturesession/sessionpreset)

A preset value that indicates the quality level or bit rate of the output.

### [Configuring inputs](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Configuring-inputs)

[`var inputs: [AVCaptureInput]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/inputs)

The inputs that provide media data to a capture session.

Determines whether you can add an input to a session.

[`func addInput(AVCaptureInput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addinput(_:))

Adds a capture input to the session.

[`func removeInput(AVCaptureInput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeinput(_:))

Removes an input from the session.

### [Configuring outputs](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Configuring-outputs)

[`var outputs: [AVCaptureOutput]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/outputs)

The output destinations to which a captures session sends its data.

Determines whether you can add an output to a session.

[`func addOutput(AVCaptureOutput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutput(_:))

Adds an output to the capture session.

[`func removeOutput(AVCaptureOutput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeoutput(_:))

Removes an output from a capture session.

### [Connecting inputs and outputs](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Connecting-inputs-and-outputs)

[`var connections: [AVCaptureConnection]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/connections)

The connections between inputs and outputs that a capture session contains.

[`func addConnection(AVCaptureConnection)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addconnection(_:))

Adds a connection to the capture session.

Determines whether a you can add a connection to a capture session.

[`func addInputWithNoConnections(AVCaptureInput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addinputwithnoconnections(_:))

Adds a capture input to a session without forming any connections.

[`func addOutputWithNoConnections(AVCaptureOutput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutputwithnoconnections(_:))

Adds a capture output to the session without forming any connections.

[`func removeConnection(AVCaptureConnection)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeconnection(_:))

Removes a capture connection from the session.

[`class AVCaptureAudioChannel`](https://developer.apple.com/documentation/avfoundation/avcaptureaudiochannel)

An object that monitors average and peak power levels for an audio channel in a capture connection.

### [Configuring deferred start](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Configuring-deferred-start)

[`var isManualDeferredStartSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismanualdeferredstartsupported)

A Boolean value that indicates whether the session supports manually running deferred start.

Beta

[`var automaticallyRunsDeferredStart: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/automaticallyrunsdeferredstart)

A Boolean value that indicates whether deferred start runs automatically.

[`func runDeferredStartWhenNeeded()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/rundeferredstartwhenneeded())

Tells the session to run deferred start when appropriate.

[`var deferredStartDelegate: (any AVCaptureSessionDeferredStartDelegate)?`](https://developer.apple.com/documentation/avfoundation/avcapturesession/deferredstartdelegate)

A delegate object that observes events about deferred start.

[`var deferredStartDelegateCallbackQueue: dispatch_queue_t?`](https://developer.apple.com/documentation/avfoundation/avcapturesession/deferredstartdelegatecallbackqueue)

The dispatch queue on which the session calls deferred start delegate methods.

[`func setDeferredStartDelegate((any AVCaptureSessionDeferredStartDelegate)?, deferredStartDelegateCallbackQueue: dispatch_queue_t?)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/setdeferredstartdelegate(_:deferredstartdelegatecallbackqueue:))

Sets a delegate object for the session to call when performing deferred start.

[`protocol AVCaptureSessionDeferredStartDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturesessiondeferredstartdelegate)

A protocol that defines the interface to respond to events about a capture session’s deferred start.

### [Configuring capture controls](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Configuring-capture-controls)

[`var supportsControls: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/supportscontrols)

A Boolean value that indicates whether a capture session supports controls.

[`var maxControlsCount: Int`](https://developer.apple.com/documentation/avfoundation/avcapturesession/maxcontrolscount)

The maximum number of controls a capture session supports.

[`var controls: [AVCaptureControl]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/controls)

The controls that allow configuring the camera system from device hardware.

Returns a Boolean value that indicates whether a capture session add the specified control.

[`func addControl(AVCaptureControl)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addcontrol(_:))

Adds a control to a capture session.

[`func removeControl(AVCaptureControl)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removecontrol(_:))

Removes a control from a capture session.

[`func setControlsDelegate((any AVCaptureSessionControlsDelegate)?, queue: dispatch_queue_t?)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/setcontrolsdelegate(_:queue:))

Sets a delegate object for the system to call when it activates and presents controls.

[`protocol AVCaptureSessionControlsDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturesessioncontrolsdelegate)

A protocol that defines the interface to respond to capture control activation and presentation events.

[`var controlsDelegate: (any AVCaptureSessionControlsDelegate)?`](https://developer.apple.com/documentation/avfoundation/avcapturesession/controlsdelegate)

A delegate object that observes changes to the state of capture controls.

[`var controlsDelegateCallbackQueue: dispatch_queue_t?`](https://developer.apple.com/documentation/avfoundation/avcapturesession/controlsdelegatecallbackqueue)

The dispatch queue on which the system calls controls delegate methods.

### [Managing the session life cycle](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Managing-the-session-life-cycle)

[`func startRunning()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning())

Starts the flow of data through the capture pipeline.

[`func stopRunning()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/stoprunning())

Stops the flow of data through the capture pipeline.

### [Observing session state](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Observing-session-state)

[`var isRunning: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/isrunning)

A Boolean value that indicates whether the capture session is in a running state.

[`var isInterrupted: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/isinterrupted)

A Boolean value that indicates whether the capture session is in an interrupted state.

[`class let didStartRunningNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/didstartrunningnotification)

A notification the system posts when a capture session starts.

[`class let didStopRunningNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/didstoprunningnotification)

A notification the system posts when a capture session stops.

[`class let wasInterruptedNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification)

A notification the system posts when it interrupts a capture session.

[`class let interruptionEndedNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionendednotification)

A notification the system posts when an interruption to a capture session finishes.

[`class let runtimeErrorNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/runtimeerrornotification)

A notification the system posts when an error occurs during a capture session.

### [Configuring multitasking](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Configuring-multitasking)

[`var isMultitaskingCameraAccessSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccesssupported)

A Boolean value that indicates whether the capture session supports using the camera while multitasking.

[`var isMultitaskingCameraAccessEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccessenabled)

A Boolean value that indicates whether the capture session enables access to the camera while multitasking.

### [Monitoring performance](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Monitoring-performance)

[`var hardwareCost: Float`](https://developer.apple.com/documentation/avfoundation/avcapturesession/hardwarecost)

A value that indicates the percentage of the session’s available hardware budget in use.

### [Configuring the app’s audio session](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Configuring-the-apps-audio-session)

[`var usesApplicationAudioSession: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/usesapplicationaudiosession)

A Boolean value that indicates whether the capture session uses the app’s shared audio session.

[`var automaticallyConfiguresApplicationAudioSession: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/automaticallyconfiguresapplicationaudiosession)

A Boolean value that indicates whether the capture session automatically changes settings in the app’s shared audio session.

[`var configuresApplicationAudioSessionToMixWithOthers: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/configuresapplicationaudiosessiontomixwithothers)

A Boolean value that Indicates whether the capture session configures the app’s audio session to mix with others.

[`var configuresApplicationAudioSessionForBluetoothHighQualityRecording: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/configuresapplicationaudiosessionforbluetoothhighqualityrecording)

A Boolean value that indicates whether the capture session configures the app’s audio session for bluetooth high-quality recording.

### [Managing color spaces](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Managing-color-spaces)

[`var automaticallyConfiguresCaptureDeviceForWideColor: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/automaticallyconfigurescapturedeviceforwidecolor)

A Boolean value that specifies whether the session should automatically use wide-gamut color where available.

### [Synchronizing output](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Synchronizing-output)

[`var synchronizationClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avcapturesession/synchronizationclock)

A clock to use for output synchronization.

[`var masterClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avcapturesession/masterclock)

A clock object used for output synchronization.

Deprecated

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturesession\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturesession\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avcapturesession\#inherited-by)

- [`AVCaptureMultiCamSession`](https://developer.apple.com/documentation/avfoundation/avcapturemulticamsession)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturesession\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession\#see-also)

### [Capture sessions](https://developer.apple.com/documentation/avfoundation/avcapturesession\#Capture-sessions)

Configure input devices, output media, preview views, and basic settings before capturing photos or video.

[Accessing the camera while multitasking on iPad](https://developer.apple.com/documentation/AVKit/accessing-the-camera-while-multitasking-on-ipad)

Operate the camera in Split View, Slide Over, Picture in Picture, and Stage Manager modes.

[AVCam: Building a camera app](https://developer.apple.com/documentation/avfoundation/avcam-building-a-camera-app)

Capture photos and record video using the front and rear iPhone and iPad cameras.

[Capturing cinematic video](https://developer.apple.com/documentation/avfoundation/capturing-cinematic-video)

Capture video with an adjustable depth of field and focus points.

[AVMultiCamPiP: Capturing from Multiple Cameras](https://developer.apple.com/documentation/avfoundation/avmulticampip-capturing-from-multiple-cameras)

Simultaneously record the output from the front and back cameras into a single movie file by using a multi-camera capture session.

[AVCamBarcode: Detecting Barcodes and Faces](https://developer.apple.com/documentation/avfoundation/avcambarcode-detecting-barcodes-and-faces)

Identify machine readable codes or faces by using the camera.

[`class AVCaptureMultiCamSession`](https://developer.apple.com/documentation/avfoundation/avcapturemulticamsession)

A capture session that supports simultaneous capture from multiple inputs of the same media type.

[`class AVCaptureInput`](https://developer.apple.com/documentation/avfoundation/avcaptureinput)

An abstract superclass for objects that provide input data to a capture session.

[`class AVCaptureOutput`](https://developer.apple.com/documentation/avfoundation/avcaptureoutput)

An abstract superclass for objects that provide media output destinations for a capture session.

[`class AVCaptureConnection`](https://developer.apple.com/documentation/avfoundation/avcaptureconnection)

An object that represents a connection from a capture input to a capture output.

---

# https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/embeddedthumbnaildimensions

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureResolvedPhotoSettings](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings)
- embeddedThumbnailDimensions

Instance Property

# embeddedThumbnailDimensions

The size, in pixels, of the thumbnail image that the capture delivers.

var embeddedThumbnailDimensions: CMVideoDimensions { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/embeddedthumbnaildimensions\#Discussion)

Use the [`embeddedThumbnailPhotoFormat`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/embeddedthumbnailphotoformat) property in your photo settings object to request delivery of a thumbnail image alongside the main photo output from the capture. When you request a thumbnail, the photo output chooses dimensions that best match your requested size while preserving the aspect ratio of the captured photo. Aspect ratio is determined by capture format and by device orientation at the moment of capture.

This property provides the dimensions of the requested thumbnail image, which is delivered in the [`photoOutput(_:didFinishProcessingPhoto:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:)) method. Use this property in earlier delegate methods to find the size of the image before delivery.

If you do not request a thumbnail image, this property’s value has zero width and zero height.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/embeddedthumbnaildimensions\#see-also)

### [Examining Output Dimensions](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/embeddedthumbnaildimensions\#Examining-Output-Dimensions)

[`var photoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/photodimensions)

The size, in pixels, of the photo image (in a processed format, such as JPEG) that the capture delivers.

[`var deferredPhotoProxyDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/deferredphotoproxydimensions)

The resolved dimensions of the photo proxy when using deferred photo delivery.

[`var rawPhotoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawphotodimensions)

The size, in pixels, of the RAW-format photo image that the capture delivers.

[`var previewDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/previewdimensions)

The size, in pixels, of the preview image that the system delivers with the capture.

[`var rawEmbeddedThumbnailDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/rawembeddedthumbnaildimensions)

The size, in pixels, of the RAW-format embedded thumbnail image that the capture delivers.

[`var livePhotoMovieDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/livephotomoviedimensions)

The size, in pixels, of the Live Photo movie content that the capture delivers.

[`var portraitEffectsMatteDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/portraiteffectsmattedimensions)

The size, in pixels, of the portrait effects matte that the capture delivers.

Retrieves the resolved dimensions of the semantic segmentation mattes that the photo output delivers.

[`var photoProcessingTimeRange: CMTimeRange`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/photoprocessingtimerange)

The time range in which to expect the system to deliver the photo to the delegate.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephoto/sourcedevicetype

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhoto](https://developer.apple.com/documentation/avfoundation/avcapturephoto)
- sourceDeviceType

Instance Property

# sourceDeviceType

The type of device that captured the photo.

var sourceDeviceType: AVCaptureDevice.DeviceType? { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephoto/sourcedevicetype\#Discussion)

When you capture dual photos with a [`builtInDualCamera`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/devicetype-swift.struct/builtindualcamera) device and the [`isDualCameraDualPhotoDeliveryEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isdualcameradualphotodeliveryenabled) setting, use this property to determine which of the two resulting photo objects is from the [`builtInWideAngleCamera`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/devicetype-swift.struct/builtinwideanglecamera) or [`builtInTelephotoCamera`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/devicetype-swift.struct/builtintelephotocamera) device.

For all other captures, this property’s value is equal to the [`deviceType`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/devicetype-swift.property) property of the capture device to which the photo output is connected.

This property’s value can be `nil` if the [`AVCapturePhoto`](https://developer.apple.com/documentation/avfoundation/avcapturephoto) object did not come from an [`AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice) capture.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephoto/sourcedevicetype\#see-also)

### [Accessing Photo Metadata](https://developer.apple.com/documentation/avfoundation/avcapturephoto/sourcedevicetype\#Accessing-Photo-Metadata)

[`var depthData: AVDepthData?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/depthdata)

Depth or disparity map data captured with the photo.

[`var cameraCalibrationData: AVCameraCalibrationData?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/cameracalibrationdata)

Calibration information for the camera device that captured the photo.

[`var metadata: [String : Any]`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/metadata)

A dictionary of metadata describing the captured image.

[`var portraitEffectsMatte: AVPortraitEffectsMatte?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/portraiteffectsmatte)

The portrait effects matte captured with the photo.

---

# https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_601_4

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoYCbCrMatrix\_ITU\_R\_601\_4

Global Variable

# AVVideoYCbCrMatrix\_ITU\_R\_601\_4

The Y’CbCr color matrix for ITU-R BT.601 conversion.

let AVVideoYCbCrMatrix_ITU_R_601_4: String

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_601_4\#mentions)

[Setting Color Properties for a Specific Resolution](https://developer.apple.com/documentation/avfoundation/setting-color-properties-for-a-specific-resolution)

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_601_4\#see-also)

### [Color properties](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_itu_r_601_4\#Color-properties)

Choose the proper color property keys for the desired color range.

[`let AVVideoAllowWideColorKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowwidecolorkey)

The key for a dictionary that indicates whether the client can process wide color.

[`let AVVideoColorPrimariesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimarieskey)

The key to identify color primaries in a color properties dictionary.

[`let AVVideoColorPrimaries_EBU_3213: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_ebu_3213)

The color primary is in the EBU Tech. 3213 color space.

[`let AVVideoColorPrimaries_ITU_R_2020: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_2020)

The color primary is in the ITU\_R BT.2020 color space for ultra high definition television.

[`let AVVideoColorPrimaries_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_709_2)

The color primary is in the ITU\_R BT.709 color space.

[`let AVVideoColorPrimaries_P3_D65: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_p3_d65)

The color primary uses the DCI-P3 D65 color space.

[`let AVVideoColorPrimaries_SMPTE_C: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_smpte_c)

The color primary uses the SMPTE C color space.

[`let AVVideoColorPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorpropertieskey)

The key for a dictionary that contains properties specifying video color.

[`let AVVideoTransferFunctionKey: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunctionkey)

The key to identify the transfer function in a color properties dictionary.

[`let AVVideoTransferFunction_IEC_sRGB: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_iec_srgb)

The transfer function for the IEC sRGB color space.

[`let AVVideoTransferFunction_ITU_R_2100_HLG: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_2100_hlg)

The transfer function for the ITU\_R BT.2100 color space.

[`let AVVideoTransferFunction_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_709_2)

The transfer function for the ITU\_R BT.709 color space.

[`let AVVideoTransferFunction_Linear: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_linear)

The transfer function for the linear color space.

[`let AVVideoTransferFunction_SMPTE_240M_1995: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_smpte_240m_1995)

The transfer function for the SMPTE 240M color space.

---

# https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_smpte_240m_1995

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoYCbCrMatrix\_SMPTE\_240M\_1995

Global Variable

# AVVideoYCbCrMatrix\_SMPTE\_240M\_1995

The Y’CbCr color matrix for SMPTE 240M conversion.

let AVVideoYCbCrMatrix_SMPTE_240M_1995: String

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_smpte_240m_1995\#see-also)

### [Color properties](https://developer.apple.com/documentation/avfoundation/avvideoycbcrmatrix_smpte_240m_1995\#Color-properties)

[Setting Color Properties for a Specific Resolution](https://developer.apple.com/documentation/avfoundation/setting-color-properties-for-a-specific-resolution)

Choose the proper color property keys for the desired color range.

[`let AVVideoAllowWideColorKey: String`](https://developer.apple.com/documentation/avfoundation/avvideoallowwidecolorkey)

The key for a dictionary that indicates whether the client can process wide color.

[`let AVVideoColorPrimariesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimarieskey)

The key to identify color primaries in a color properties dictionary.

[`let AVVideoColorPrimaries_EBU_3213: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_ebu_3213)

The color primary is in the EBU Tech. 3213 color space.

[`let AVVideoColorPrimaries_ITU_R_2020: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_2020)

The color primary is in the ITU\_R BT.2020 color space for ultra high definition television.

[`let AVVideoColorPrimaries_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_itu_r_709_2)

The color primary is in the ITU\_R BT.709 color space.

[`let AVVideoColorPrimaries_P3_D65: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_p3_d65)

The color primary uses the DCI-P3 D65 color space.

[`let AVVideoColorPrimaries_SMPTE_C: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorprimaries_smpte_c)

The color primary uses the SMPTE C color space.

[`let AVVideoColorPropertiesKey: String`](https://developer.apple.com/documentation/avfoundation/avvideocolorpropertieskey)

The key for a dictionary that contains properties specifying video color.

[`let AVVideoTransferFunctionKey: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunctionkey)

The key to identify the transfer function in a color properties dictionary.

[`let AVVideoTransferFunction_IEC_sRGB: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_iec_srgb)

The transfer function for the IEC sRGB color space.

[`let AVVideoTransferFunction_ITU_R_2100_HLG: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_2100_hlg)

The transfer function for the ITU\_R BT.2100 color space.

[`let AVVideoTransferFunction_ITU_R_709_2: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_itu_r_709_2)

The transfer function for the ITU\_R BT.709 color space.

[`let AVVideoTransferFunction_Linear: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_linear)

The transfer function for the linear color space.

[`let AVVideoTransferFunction_SMPTE_240M_1995: String`](https://developer.apple.com/documentation/avfoundation/avvideotransferfunction_smpte_240m_1995)

The transfer function for the SMPTE 240M color space.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephoto/lensstabilizationstatus

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhoto](https://developer.apple.com/documentation/avfoundation/avcapturephoto)
- lensStabilizationStatus

Instance Property

# lensStabilizationStatus

Information about the use of lens stabilization during bracketed photo capture.

var lensStabilizationStatus: AVCaptureDevice.LensStabilizationStatus { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephoto/lensstabilizationstatus\#Discussion)

This property applies only to capture results for which you requested optical image stabilization (OIS) across all frames of a bracketed photo capture (using the [`AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings) [`isLensStabilizationEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled) property).

If the device configuration does not support OIS, this property’s value is [`AVCaptureDevice.LensStabilizationStatus.unsupported`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/unsupported). If OIS is supported, but this captured photo is not from a bracketed capture where OIS was requested, this property’s value is [`AVCaptureDevice.LensStabilizationStatus.off`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/off). Otherwise, this property indicates how the device applied OIS across the duration of the bracketed capture.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephoto/lensstabilizationstatus\#see-also)

### [Examining Bracketed Capture Information](https://developer.apple.com/documentation/avfoundation/avcapturephoto/lensstabilizationstatus\#Examining-Bracketed-Capture-Information)

[`var bracketSettings: AVCaptureBracketedStillImageSettings?`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/bracketsettings)

The variations available for bracketed capture settings for this photo.

[`var sequenceCount: Int`](https://developer.apple.com/documentation/avfoundation/avcapturephoto/sequencecount)

The 1-based index of this photo in a bracketed capture sequence.

[`enum LensStabilizationStatus`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus)

Constants that indicate the status of optical image stabilization hardware during a bracketed photo capture.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawfileformat

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoSettings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)
- rawFileFormat

Instance Property

# rawFileFormat

var rawFileFormat: [String : Any]? { get set }

---

# https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVCaptureDeviceInput

Class

# AVCaptureDeviceInput

An object that provides media input from a capture device to a capture session.

class AVCaptureDeviceInput

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#mentions)

[Setting Up a Capture Session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session)

## [Overview](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#overview)

This class is a concrete subclass of [`AVCaptureInput`](https://developer.apple.com/documentation/avfoundation/avcaptureinput) that you use to connect a capture device to a capture session.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#topics)

### [Creating an input](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#Creating-an-input)

[`init(device: AVCaptureDevice) throws`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/init(device:))

Creates an input for the specified capture device.

### [Configuring video properties](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#Configuring-video-properties)

[`var unifiedAutoExposureDefaultsEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/unifiedautoexposuredefaultsenabled)

A Boolean value that indicates whether the input enables unified auto-exposure defaults.

[`var videoMinFrameDurationOverride: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/videominframedurationoverride)

A time value that acts as a modifier to a capture device’s active video minimum frame duration.

### [Configuring audio properties](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#Configuring-audio-properties)

A Boolean value that indicates whether the input supports the specified multichannel audio mode.

[`var multichannelAudioMode: AVCaptureMultichannelAudioMode`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/multichannelaudiomode)

The multichannel audio mode to apply when recording audio.

[`enum AVCaptureMultichannelAudioMode`](https://developer.apple.com/documentation/avfoundation/avcapturemultichannelaudiomode)

Constants that indicate the modes of multichannel audio.

### [Accessing the Device](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#Accessing-the-Device)

[`var device: AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/device)

A capture device associated with this input.

Retrieves a virtual device’s constituent device ports for use in a multi-camera session.

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#Instance-Properties)

[`var isWindNoiseRemovalEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalenabled)

[`var isWindNoiseRemovalSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalsupported)

[`var isCinematicVideoCaptureEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iscinematicvideocaptureenabled) Beta

[`var isCinematicVideoCaptureSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iscinematicvideocapturesupported) Beta

[`var simulatedAperture: Float`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/simulatedaperture) Beta

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#inherits-from)

- [`AVCaptureInput`](https://developer.apple.com/documentation/avfoundation/avcaptureinput)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#see-also)

### [Capture devices](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput\#Capture-devices)

[Choosing a Capture Device](https://developer.apple.com/documentation/avfoundation/choosing-a-capture-device)

Select the front or back camera, or use advanced features like the TrueDepth camera or dual camera.

[`class AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice)

An object that represents a hardware or virtual capture device like a camera or microphone.

[`class AVContinuityDevice`](https://developer.apple.com/documentation/avfoundation/avcontinuitydevice)

A class that represents a physical iOS device that’s nearby and can provide access to its cameras and microphones.

[`class AVExternalStorageDevice`](https://developer.apple.com/documentation/avfoundation/avexternalstoragedevice)

Represents a physical external storage device that stores media assets.

[`class AVExternalStorageDeviceDiscoverySession`](https://developer.apple.com/documentation/avfoundation/avexternalstoragedevicediscoverysession)

Informs your app when the external storage devices connect to and disconnect from the system.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didupdatepersistablecontentkey:forcontentkeyidentifier:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeySessionDelegate](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate)
- contentKeySession(\_:didUpdatePersistableContentKey:forContentKeyIdentifier:)

Instance Method

# contentKeySession(\_:didUpdatePersistableContentKey:forContentKeyIdentifier:)

Provides the receiver with an updated persistable content key for a specific key request.

optional func contentKeySession(
_ session: AVContentKeySession,
didUpdatePersistableContentKey persistableContentKey: Data,
forContentKeyIdentifier keyIdentifier: Any
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didupdatepersistablecontentkey:forcontentkeyidentifier:)\#parameters)

`session`

The content key session that is providing the updated persistable content key.

`persistableContentKey`

The updated persistent content key data. This data can be stored offline and used to answer future content key requests with the matching key identifier.

`keyIdentifier`

A container- and protocol-specific identifier for the updated persistent content key.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didupdatepersistablecontentkey:forcontentkeyidentifier:)\#Discussion)

If the content key session provides updated persistable content key data, previous key data is no longer valid and cannot be used to answer future loading requests.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didupdatepersistablecontentkey:forcontentkeyidentifier:)\#see-also)

### [Updating and Retrying Content Key Requests](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didupdatepersistablecontentkey:forcontentkeyidentifier:)\#Updating-and-Retrying-Content-Key-Requests)

[`func contentKeySession(AVContentKeySession, didProvide: [AVContentKeyRequest], forInitializationData: Data?)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:didprovide:forinitializationdata:))

[`func contentKeySession(AVContentKeySession, externalProtectionStatusDidChangeFor: AVContentKey)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:externalprotectionstatusdidchangefor:))

Tells the delegate when external protection state has changed.

Provides the receiver with a content key request object to retry.

[`struct RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason)

The reason for asking the client to retry a content key request.

[`func contentKeySessionContentProtectionSessionIdentifierDidChange(AVContentKeySession)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysessioncontentprotectionsessionidentifierdidchange(_:))

Tells the receiver the content protection session identifier changed.

[`func contentKeySession(AVContentKeySession, contentKeyRequest: AVContentKeyRequest, didFailWithError: any Error)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:contentkeyrequest:didfailwitherror:))

Tells the receiver that the content key request failed.

[`func contentKeySession(AVContentKeySession, contentKeyRequestDidSucceed: AVContentKeyRequest)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysession(_:contentkeyrequestdidsucceed:))

Tells the content key session that the response to a content key requeset was successfully processed.

[`func contentKeySessionDidGenerateExpiredSessionReport(AVContentKeySession)`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessiondelegate/contentkeysessiondidgenerateexpiredsessionreport(_:))

Notifies the sender that an expired session report has been generated.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotomoviefileurl

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoSettings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)
- livePhotoMovieFileURL

Instance Property

# livePhotoMovieFileURL

A URL at which to write Live Photo movie output.

var livePhotoMovieFileURL: URL? { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotomoviefileurl\#Discussion)

Live Photos capture both a still image and a short movie, which the system presents together in user interfaces such as the Photos app. By default, this property’s value is `nil`, disabling Live Photo capture. Set this property to a file URL to capture Live Photos.

When you enable Live Photo capture, the following requirements apply:

- The photo output’s [`isLivePhotoCaptureEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotocaptureenabled) property must be [`true`](https://developer.apple.com/documentation/swift/true), and its and [`isLivePhotoCaptureSuspended`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotocapturesuspended) property must be [`false`](https://developer.apple.com/documentation/swift/false).

- The URL you specify must be a file URL to an accessible location in your app’s sandbox.

- Your delegate object must implement the [`photoOutput(_:didFinishProcessingLivePhotoToMovieFileAt:duration:photoDisplayTime:resolvedSettings:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessinglivephototomoviefileat:duration:photodisplaytime:resolvedsettings:error:)) method.

The capture output validates these requirements when you call the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method. If your settings and delegate don’t meet these requirements, that method raises an exception.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotomoviefileurl\#see-also)

### [Configuring Live Photo Settings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotomoviefileurl\#Configuring-Live-Photo-Settings)

[`var livePhotoMovieMetadata: [AVMetadataItem]!`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotomoviemetadata)

A dictionary of metadata to include in the Live Photo movie file.

[`var livePhotoVideoCodecType: AVVideoCodecType`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/livephotovideocodectype)

The video codec to use for encoding the movie portion of Live Photo output.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingrawphoto:previewphoto:resolvedsettings:bracketsettings:error:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoCaptureDelegate](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate)
- photoOutput(\_:didFinishProcessingRawPhoto:previewPhoto:resolvedSettings:bracketSettings:error:) Deprecated

Instance Method

# photoOutput(\_:didFinishProcessingRawPhoto:previewPhoto:resolvedSettings:bracketSettings:error:)

Provides the delegate a captured image in RAW format.

iOS 10.0–11.0DeprecatediPadOS 10.0–11.0DeprecatedMac Catalyst 13.1–13.1Deprecated

optional func photoOutput(
_ output: AVCapturePhotoOutput,
didFinishProcessingRawPhoto rawSampleBuffer: CMSampleBuffer?,
previewPhoto previewPhotoSampleBuffer: CMSampleBuffer?,
resolvedSettings: AVCaptureResolvedPhotoSettings,
bracketSettings: AVCaptureBracketedStillImageSettings?,
error: (any Error)?
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingrawphoto:previewphoto:resolvedsettings:bracketsettings:error:)\#parameters)

`output`

The photo output performing the capture.

`rawSampleBuffer`

A sample buffer containing the captured RAW image. The format of this buffer matches the format you requested for the RAW image (see the [`rawPhotoPixelFormatType`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawphotopixelformattype) property of your photo settings).

If an error prevented successful capture, this parameter is `nil`—see the `error` parameter for a description of the failure.

`previewPhotoSampleBuffer`

If you requested a thumbnail-sized version of the photo (with the [`previewPhotoFormat`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/previewphotoformat) property of your photo settings object), a sample buffer containing the thumbnail photo in the requested format. If you did not request preview delivery, or if an error prevented capture, this parameter is `nil`.

`resolvedSettings`

An object describing the settings used for this capture. Match this object’s [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid) value to the [`uniqueID`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid) property of the photo settings object you initiated capture with to determine which capture request this delegate call corresponds to. You can also use this object to find out which values the photo output has chosen for automatic settings.

`bracketSettings`

If you requested a bracketed capture of multiple images with a [`AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings), a bracketed still image settings object describing which image in the bracket this delegate call corresponds to. If you did not request bracketed capture, this parameter is `nil`.

`error`

If an the capture process could not proceed successfully, an error object describing the failure; otherwise, `nil`.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingrawphoto:previewphoto:resolvedsettings:bracketsettings:error:)\#Discussion)

Use this method to receive the results of a RAW format capture. (If you request capture in both RAW and a processed format, the photo output calls both this method and the [`photoOutput(_:didFinishProcessingPhoto:previewPhoto:resolvedSettings:bracketSettings:error:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:previewphoto:resolvedsettings:bracketsettings:error:)) method.)

If you request RAW format capture, the photo output calls this method once for each exposure in the capture request. If you request a single image capture, this method is called once. If you request a bracketed capture with multiple exposures, this method is called once for each exposure.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingrawphoto:previewphoto:resolvedsettings:bracketsettings:error:)\#see-also)

### [Receiving Capture Results](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingrawphoto:previewphoto:resolvedsettings:bracketsettings:error:)\#Receiving-Capture-Results)

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingPhoto: AVCapturePhoto, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:error:))

Provides the delegate with the captured image and associated metadata resulting from a photo capture.

[`func photoOutput(AVCapturePhotoOutput, didFinishRecordingLivePhotoMovieForEventualFileAt: URL, resolvedSettings: AVCaptureResolvedPhotoSettings)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishrecordinglivephotomovieforeventualfileat:resolvedsettings:))

Notifies the delegate that the movie content of a Live Photo has finished recording.

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingLivePhotoToMovieFileAt: URL, duration: CMTime, photoDisplayTime: CMTime, resolvedSettings: AVCaptureResolvedPhotoSettings, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessinglivephototomoviefileat:duration:photodisplaytime:resolvedsettings:error:))

Provides the delegate the movie file URL resulting from a Live Photo capture.

[`func photoOutput(AVCapturePhotoOutput, didFinishCapturingDeferredPhotoProxy: AVCaptureDeferredPhotoProxy?, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishcapturingdeferredphotoproxy:error:))

Tells the delegate when the system finishes capturing the photo proxy.

[`func photoOutput(AVCapturePhotoOutput, didFinishProcessingPhoto: CMSampleBuffer?, previewPhoto: CMSampleBuffer?, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings?, error: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:didfinishprocessingphoto:previewphoto:resolvedsettings:bracketsettings:error:))

Provides the delegate a captured image in a processed format (such as JPEG).

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVSampleCursorSyncInfo

Structure

# AVSampleCursorSyncInfo

A structure that describes the attributes of media samples to consider when resynchronizing a decoder.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

struct AVSampleCursorSyncInfo

## [Topics](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo\#topics)

### [Sync Information](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo\#Sync-Information)

[`var sampleIsFullSync: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo/sampleisfullsync)

A Boolean value that indicates whether a sample is a full sync sample.

[`var sampleIsPartialSync: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo/sampleispartialsync)

A Boolean value that indicates whether a sample is a partial sync sample.

[`var sampleIsDroppable: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo/sampleisdroppable)

A Boolean value that indicates whether a sample is droppable.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo\#Initializers)

[`init()`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo/init())

Creates a sample cursor sync information structure.

[`init(sampleIsFullSync: ObjCBool, sampleIsPartialSync: ObjCBool, sampleIsDroppable: ObjCBool)`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo/init(sampleisfullsync:sampleispartialsync:sampleisdroppable:))

Creates a sample cursor sync information structure with media sample information.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo\#conforms-to)

- [`BitwiseCopyable`](https://developer.apple.com/documentation/Swift/BitwiseCopyable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo\#see-also)

### [Sample cursors](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo\#Sample-cursors)

[`class AVSampleCursor`](https://developer.apple.com/documentation/avfoundation/avsamplecursor)

An object that provides information about the media sample at the cursor’s current position.

[`struct AVSampleCursorDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo)

A value for describing dependencies between a media sample and other media samples in the same sample sequence.

[`struct AVSampleCursorAudioDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo)

A structure that describes the independent decodability of audio samples.

[`struct AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursorstoragerange)

A structure that indicates the offset and length of storage for a media sample or its chunk.

[`struct AVSampleCursorChunkInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorchunkinfo)

A value that provides information about a chunk of media samples.

---

# https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVQueuedSampleBufferRenderingStatus

Enumeration

# AVQueuedSampleBufferRenderingStatus

The statuses for sample buffer rendering.

enum AVQueuedSampleBufferRenderingStatus

## [Topics](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus\#topics)

### [Status Values](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus\#Status-Values)

[`case unknown`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus/unknown)

The object doesn’t have any sample buffers enqueued.

[`case rendering`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus/rendering)

The object is rendering the sample buffer.

[`case failed`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus/failed)

The object can no longer render sample buffers because of an error.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus\#Initializers)

[`init?(rawValue: Int)`](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus/init(rawvalue:))

## [Relationships](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus\#conforms-to)

- [`BitwiseCopyable`](https://developer.apple.com/documentation/Swift/BitwiseCopyable)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus\#see-also)

### [Determining Rendering Status](https://developer.apple.com/documentation/avfoundation/avqueuedsamplebufferrenderingstatus\#Determining-Rendering-Status)

[`var status: AVQueuedSampleBufferRenderingStatus`](https://developer.apple.com/documentation/avfoundation/avsamplebufferaudiorenderer/status)

The status of the audio renderer.

---

# https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings/iso

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureManualExposureBracketedStillImageSettings](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings)
- iso

Instance Property

# iso

The ISO for the still image.

var iso: Float { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings/iso\#see-also)

### [Getting Manual Exposure Setting Values](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings/iso\#Getting-Manual-Exposure-Setting-Values)

[`var exposureDuration: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturemanualexposurebracketedstillimagesettings/exposureduration)

The exposure duration for the still image.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephoto/semanticsegmentationmatte(for:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhoto](https://developer.apple.com/documentation/avfoundation/avcapturephoto)
- semanticSegmentationMatte(for:)

Instance Method

# semanticSegmentationMatte(for:)

Retrieves the semantic segmentation matte associated with this photo.

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturephoto/semanticsegmentationmatte(for:)\#parameters)

`semanticSegmentationMatteType`

The type of semantic segmentation matte to retrieve from the photo.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avcapturephoto/semanticsegmentationmatte(for:)\#return-value)

An instance of [`AVSemanticSegmentationMatte`](https://developer.apple.com/documentation/avfoundation/avsemanticsegmentationmatte), or `nil` of you didn’t request semantic segmentation matte delivery or if no mattes of the specified type were found.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephoto/semanticsegmentationmatte(for:)\#Discussion)

If you requested one or more semantic segmentation mattes by calling [`enabledSemanticSegmentationMatteTypes`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/enabledsemanticsegmentationmattetypes) with a nonempty array of types, this property offers access to the resulting [`AVSemanticSegmentationMatte`](https://developer.apple.com/documentation/avfoundation/avsemanticsegmentationmatte) objects.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islensstabilizationduringbracketedcapturesupported

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- isLensStabilizationDuringBracketedCaptureSupported

Instance Property

# isLensStabilizationDuringBracketedCaptureSupported

A Boolean value indicating whether the capture output currently supports lens stabilization during bracketed image capture.

var isLensStabilizationDuringBracketedCaptureSupported: Bool { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islensstabilizationduringbracketedcapturesupported\#Discussion)

To make use of optical image stabilization across the entire duration of a bracketed capture, set the [`isLensStabilizationEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings/islensstabilizationenabled) property of your bracketed photo settings object.

This property supports key-value observing.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islensstabilizationduringbracketedcapturesupported\#see-also)

### [Determining Available Settings](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islensstabilizationduringbracketedcapturesupported\#Determining-Available-Settings)

[`var isContentAwareDistortionCorrectionSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionsupported)

A Boolean value that indicates whether the session’s current configuration supports content-aware distortion correction.

[`var isContentAwareDistortionCorrectionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionenabled)

A Boolean value that indicates whether the photo render pipeline can perform content-aware distortion correction.

[`var maxBracketedCapturePhotoCount: Int`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxbracketedcapturephotocount)

The maximum number of images that the photo capture output can support in a single bracketed capture.

[`var supportedFlashModes: [AVCaptureDevice.FlashMode]`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedflashmodes-1n6nm)

A Swift array of flash settings this capture output currently supports.

[`var isAutoRedEyeReductionSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isautoredeyereductionsupported)

A Boolean value indicating whether the capture output supports automatic red-eye reduction.

---

# https://developer.apple.com/documentation/avfoundation/avmediaselectionoption

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMediaSelectionOption

Class

# AVMediaSelectionOption

An object that represents a specific option for the presentation of media within a group of options.

class AVMediaSelectionOption

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#mentions)

[Selecting Subtitles and Alternative Audio Tracks](https://developer.apple.com/documentation/avfoundation/selecting-subtitles-and-alternative-audio-tracks)

## [Topics](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#topics)

### [Accessing Media Information](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#Accessing-Media-Information)

[`var mediaType: AVMediaType`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/mediatype)

The media type of the media data.

[`var mediaSubTypes: [NSNumber]`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/mediasubtypes)

The media sub-types of the media data associated with the option.

Returns a Boolean value that indicates whether the receiver has media with the given media characteristic.

### [Managing Metadata](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#Managing-Metadata)

[`var commonMetadata: [AVMetadataItem]`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/commonmetadata)

An array of metadata items for each common metadata key for which a value is available.

[`var availableMetadataFormats: [String]`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/availablemetadataformats)

The metadata formats that contain metadata associated with the option.

Returns an array of metadata items—one for each metadata item in the container of a given format.

### [Determining Playability](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#Determining-Playability)

[`var isPlayable: Bool`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/isplayable)

A Boolean value that indicates whether the media selection option is playable.

### [Getting the Language and Locale Settings](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#Getting-the-Language-and-Locale-Settings)

[`var displayName: String`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/displayname)

A string suitable for display using the current system locale.

Returns a string suitable for display using the specified locale.

[`var locale: Locale?`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/locale)

The locale for which the media option was authored.

[`var extendedLanguageTag: String?`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/extendedlanguagetag)

The IETF BCP 47 language tag associated with the option

### [Getting the Associated Media Selection Option](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#Getting-the-Associated-Media-Selection-Option)

Returns a media selection option associated with the receiver in a given group.

### [Creating a Now Playing Language Option](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#Creating-a-Now-Playing-Language-Option)

Creates a language option for a media selection option.

### [Creating a Property List Representation](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#Creating-a-Property-List-Representation)

Returns a serializable property list that’s sufficient to identify the option within its group.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#see-also)

### [Media selection](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption\#Media-selection)

Extend your app’s appeal to users by adding subtitles and alternative audio tracks in their native language.

[`class AVMediaSelection`](https://developer.apple.com/documentation/avfoundation/avmediaselection)

An object that represents a complete rendition of media selection options on an asset.

[`class AVMediaSelectionGroup`](https://developer.apple.com/documentation/avfoundation/avmediaselectiongroup)

An object that represents a collection of mutually exclusive options for the presentation of media within an asset.

[`class AVMutableMediaSelection`](https://developer.apple.com/documentation/avfoundation/avmutablemediaselection)

A mutable object that represents a complete rendition of media selection options on an asset.

[`class AVPlayerMediaSelectionCriteria`](https://developer.apple.com/documentation/avfoundation/avplayermediaselectioncriteria)

An object that specifies the preferred languages and media characteristics for a player.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMetadataIdentifier

Structure

# AVMetadataIdentifier

A structure that defines identifiers for metadata formats.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

struct AVMetadataIdentifier

## [Topics](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#topics)

### [Common Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#Common-Metadata-Identifiers)

[`static let commonIdentifierAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieraccessibilitydescription)

An identifier that represents the accessibility description for the media.

[`static let commonIdentifierAlbumName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieralbumname)

An identifier that represents the name of the album.

[`static let commonIdentifierArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartist)

An identifier that represents the name of the artist.

[`static let commonIdentifierArtwork: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartwork)

An identifier that represents an image relating to the album.

[`static let commonIdentifierAssetIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierassetidentifier)

An identifier that represents the asset ID for the media.

[`static let commonIdentifierAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierauthor)

An identifier that represents the name of the author.

[`static let commonIdentifierContributor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercontributor)

An identifier that represents the name of the contributor.

[`static let commonIdentifierCopyrights: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercopyrights)

An identifier that represents the copyright statement.

[`static let commonIdentifierCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreationdate)

An identifier that represents the date of the original recording.

[`static let commonIdentifierCreator: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreator)

An identifier that represents the name of the creator.

[`static let commonIdentifierDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierdescription)

An identifier that represents the description of the media.

[`static let commonIdentifierFormat: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierformat)

An identifier that represents the file format of the media content.

[`static let commonIdentifierLanguage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlanguage)

An identifier that represents the language of the text or lyrics spoken or sung in the audio.

[`static let commonIdentifierLastModifiedDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlastmodifieddate)

An identifier that represents the last modification date of the media.

[`static let commonIdentifierLocation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlocation)

An identifier that represents the location information for the media.

[`static let commonIdentifierMake: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiermake)

An identifier that represents the name of the camera maker.

[`static let commonIdentifierModel: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiermodel)

An identifier that represents the name of the camera model.

[`static let commonIdentifierPublisher: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierpublisher)

An identifier that represents the name of the publisher.

[`static let commonIdentifierRelation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierrelation)

An identifier that represents the relation information for the media.

[`static let commonIdentifierSoftware: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiersoftware)

An identifier that represents the name of the software used to create the media.

[`static let commonIdentifierSource: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiersource)

An identifier that represents the source information for the media.

[`static let commonIdentifierSubject: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiersubject)

An identifier that represents the subject information for the media.

[`static let commonIdentifierTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiertitle)

An identifier that represents the title of the media.

[`static let commonIdentifierType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiertype)

An identifier that represents the media type.

### [iTunes Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#iTunes-Metadata-Identifiers)

[`static let iTunesMetadataAccountKind: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataaccountkind)

An identifier that represents the kind of iTunes account.

[`static let iTunesMetadataAcknowledgement: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataacknowledgement)

An identifier that represents the acknowledgement information in iTunes.

[`static let iTunesMetadataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataalbum)

An identifier that represents the name of the album in iTunes.

[`static let iTunesMetadataAlbumArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataalbumartist)

An identifier that represents the artist for the album.

[`static let iTunesMetadataAppleID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataappleid)

An identifier that represents an Apple ID.

[`static let iTunesMetadataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataarranger)

An identifier that represents the name of the arranger.

[`static let iTunesMetadataArtDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartdirector)

An identifier that represents the name of the art director.

[`static let iTunesMetadataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartist)

[`static let iTunesMetadataArtistID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartistid)

An identifier that represents the ID for an artist.

[`static let iTunesMetadataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataauthor)

[`static let iTunesMetadataBeatsPerMin: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatabeatspermin)

An identifier that represents the beats per minute of a track in iTunes.

[`static let iTunesMetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacomposer)

An identifier that represents the name of the composer.

[`static let iTunesMetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataconductor)

An identifier that represents the name of the conductor.

[`static let iTunesMetadataContentRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacontentrating)

An identifier that represents the content rating in iTunes.

[`static let iTunesMetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacopyright)

An identifier that represents the copyright statement in iTunes.

[`static let iTunesMetadataCoverArt: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacoverart)

An identifier that represents an album cover image.

[`static let iTunesMetadataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacredits)

An identifier that represents the credits for the source content.

[`static let iTunesMetadataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatadescription)

An identifier that represents the description information in iTunes.

[`static let iTunesMetadataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatadirector)

An identifier that represents the name of the director.

[`static let iTunesMetadataDiscCompilation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatadisccompilation)

An identifier that represents whether an album is a compilation of tracks in iTunes.

[`static let iTunesMetadataDiscNumber: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatadiscnumber)

An identifier that represents the disc number of a multi-CD album in iTunes.

[`static let iTunesMetadataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataencodedby)

An identifier that represents the person or organization responsible for encoding the media.

[`static let iTunesMetadataEncodingTool: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataencodingtool)

An identifier that represents the software or hardware and settings used for encoding.

[`static let iTunesMetadataEQ: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataeq)

An identifier that represents the equalizer preset option in iTunes.

[`static let iTunesMetadataExecProducer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataexecproducer)

An identifier that represents the name of the executive producer.

[`static let iTunesMetadataGenreID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatagenreid)

An identifier that represents the genre ID.

[`static let iTunesMetadataGrouping: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatagrouping)

An identifier that represents additional grouping information for an album.

[`static let iTunesMetadataLinerNotes: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatalinernotes)

An identifier that represents the digital booklet for an album.

[`static let iTunesMetadataLyrics: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatalyrics)

An identifier that represents the lyrics in the recording.

[`static let iTunesMetadataOnlineExtras: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataonlineextras)

An identifier that represents the extra materials for an album.

[`static let iTunesMetadataOriginalArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataoriginalartist)

An identifier that represents the name of the original artist.

[`static let iTunesMetadataPerformer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataperformer)

An identifier that represents the name of the performer.

[`static let iTunesMetadataPhonogramRights: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataphonogramrights)

An identifier that represents the phonogram rights statement.

[`static let iTunesMetadataPlaylistID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataplaylistid)

An identifier that represents the playlist ID.

[`static let iTunesMetadataPredefinedGenre: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatapredefinedgenre)

An identifier that represents the predefined genre.

[`static let iTunesMetadataProducer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataproducer)

An identifier that represents the name of the producer.

[`static let iTunesMetadataPublisher: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatapublisher)

[`static let iTunesMetadataRecordCompany: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatarecordcompany)

An identifier that represents the name of the record company.

[`static let iTunesMetadataReleaseDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatareleasedate)

An identifier that represents the release date for the original recording.

[`static let iTunesMetadataSoloist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatasoloist)

An identifier that represents the name of the soloist.

[`static let iTunesMetadataSongID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatasongid)

An identifier that represents the song ID.

[`static let iTunesMetadataSongName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatasongname)

An identifier that represents the name of the song in iTunes.

[`static let iTunesMetadataSoundEngineer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatasoundengineer)

An identifier that represents the name of the sound engineer.

[`static let iTunesMetadataThanks: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatathanks)

An identifier that represents the thanks statement in iTunes.

[`static let iTunesMetadataTrackNumber: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatatracknumber)

An identifier that represents the order number in iTunes.

[`static let iTunesMetadataTrackSubTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatatracksubtitle)

An identifier that represents the information relating to the contents title.

[`static let iTunesMetadataUserComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatausercomment)

An identifier that represents a user comment regarding the content.

[`static let iTunesMetadataUserGenre: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatausergenre)

An identifier that represents the genre set by a user in iTunes.

### [QuickTime Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#QuickTime-Metadata-Identifiers)

[`static let quickTimeMetadataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeMetadataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataalbum)

An identifier that represents the name of the album or collection in QuickTime.

[`static let quickTimeMetadataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeMetadataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeMetadataArtwork: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataartwork)

An identifier that represents an image relating to the movie file content.

[`static let quickTimeMetadataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeMetadataAutoLivePhoto: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataautolivephoto)

An identifier that represents whether the live photo movie used auto mode.

[`static let quickTimeMetadataCameraFrameReadoutTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameraframereadouttime)

An identifier that represents the camera frame readout time in QuickTime.

[`static let quickTimeMetadataCameraIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameraidentifier)

An identifier that represents the camera identifier in QuickTime.

[`static let quickTimeMetadataCollectionUser: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacollectionuser)

An identifier that represents a name that indicates a user-defined collection.

[`static let quickTimeMetadataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeMetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeMetadataContentIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacontentidentifier)

An identifier that represents the content identifier in QuickTime.

[`static let quickTimeMetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacopyright)

An identifier that represents the copyright statement for the movie file content.

[`static let quickTimeMetadataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacreationdate)

An identifier that represents the creation date of the movie file content.

[`static let quickTimeMetadataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacredits)

An identifier that represents the credits of the movie source content.

[`static let quickTimeMetadataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadescription)

An identifier that represents the description of the movie file content.

[`static let quickTimeMetadataDetectedCatBody: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadetectedcatbody)

An identifier that represents a detected cat body in the movie file content.

[`static let quickTimeMetadataDetectedDogBody: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadetecteddogbody)

An identifier that represents a detected dog body in the movie file content.

[`static let quickTimeMetadataDetectedFace: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadetectedface)

An identifier that represents a detected face in the movie file content.

[`static let quickTimeMetadataDetectedHumanBody: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadetectedhumanbody)

An identifier that represents a detected human body in the movie file content.

[`static let quickTimeMetadataDetectedSalientObject: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadetectedsalientobject)

An identifier that represents a detected salient object in the movie file content.

[`static let quickTimeMetadataDirectionFacing: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadirectionfacing)

An identifier that represents the direction the camera is facing during the shot.

[`static let quickTimeMetadataDirectionMotion: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadirectionmotion)

An identifier that represents the direction the camera is moving during the shot.

[`static let quickTimeMetadataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadirector)

An identifier that represents the name of the director of the movie file content.

[`static let quickTimeMetadataDisplayName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadisplayname)

An identifier that represents the display name of the movie file content.

[`static let quickTimeMetadataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataencodedby)

An identifier that represents the name of the person or organization responsible for encoding the movie file content.

[`static let quickTimeMetadataFullFrameRatePlaybackIntent: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatafullframerateplaybackintent)

An identifier that represents whether this movie should play at full frame rate.

[`static let quickTimeMetadataGenre: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatagenre)

An identifier that represents the genre or genres to which the movie content conforms.

[`static let quickTimeMetadataInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatainformation)

An identifier that represents general information about the movie file content.

[`static let quickTimeMetadataiXML: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataixml)

An identifier that represents iXML information for the movie file content.

[`static let quickTimeMetadataKeywords: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatakeywords)

An identifier that represents the keywords for the movie file content.

[`static let quickTimeMetadataLivePhotoVitalityScore: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalivephotovitalityscore)

An identifier that represents the vitality score of the Live Photo movie.

[`static let quickTimeMetadataLivePhotoVitalityScoringVersion: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalivephotovitalityscoringversion)

An identifier that represents the version of the algorithm responsible for scoring the Live Photo movie for vitality.

[`static let quickTimeMetadataLocationBody: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalocationbody)

An identifier that represents the astronomical body for compatibility with the 3GPP format.

[`static let quickTimeMetadataLocationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalocationdate)

An identifier that represents a date and time using the extended format defined in ISO 8601:2004.

[`static let quickTimeMetadataLocationHorizontalAccuracyInMeters: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalocationhorizontalaccuracyinmeters)

An identifier that represents the horizontal accuracy of the location data.

[`static let quickTimeMetadataLocationISO6709: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalocationiso6709)

An identifier that represents the geographic point location by coordinates as defined in ISO 6709:2008.

[`static let quickTimeMetadataLocationName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalocationname)

An identifier that represents the name of the location.

[`static let quickTimeMetadataLocationNote: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalocationnote)

An identifier that represents a descriptive comment about the location.

[`static let quickTimeMetadataLocationRole: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatalocationrole)

An identifier that represents the single byte describing the movie location.

[`static let quickTimeMetadataMake: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatamake)

[`static let quickTimeMetadataModel: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatamodel)

[`static let quickTimeMetadataIsMontage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataismontage)

An identifier that represents that a movie is a montage of other media.

[`static let quickTimeMetadataOriginalArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataoriginalartist)

An identifier that represents the name of the original artist of the movie file content.

[`static let quickTimeMetadataPerformer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataperformer)

An identifier that represents the name of the performer in the movie file content.

[`static let quickTimeMetadataPhonogramRights: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataphonogramrights)

[`static let quickTimeMetadataPreferredAffineTransform: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatapreferredaffinetransform)

An identifier that represents the affine transform preference for the movie file content.

[`static let quickTimeMetadataProducer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataproducer)

An identifier that represents the name of the producer of the movie file content.

[`static let quickTimeMetadataPublisher: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatapublisher)

An identifier that represents the name of the publisher of the movie file content.

[`static let quickTimeMetadataRatingUser: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataratinguser)

An identifier that represents the rating or relative value of the movie.

[`static let quickTimeMetadataSoftware: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatasoftware)

An identifier that represents the name of software used to create the movie file content.

[`static let quickTimeMetadataSpatialOverCaptureQualityScore: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataspatialovercapturequalityscore)

An identifier that represents a score that indicates the quality of an asset.

[`static let quickTimeMetadataSpatialOverCaptureQualityScoringVersion: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataspatialovercapturequalityscoringversion)

An identifier that represents the version of the algorithm responsible for generating a score.

[`static let quickTimeMetadataTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatatitle)

An identifier that represents the title of the movie file content.

[`static let quickTimeMetadataVideoOrientation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatavideoorientation)

An identifier that represents the orientation of the movie file content.

[`static let quickTimeMetadataYear: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatayear)

An identifier that represents the recording year of the movie file content.

### [QuickTime User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#QuickTime-User-Metadata-Identifiers)

[`static let quickTimeUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataaccessibilitydescription)

[`static let quickTimeUserDataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum)

[`static let quickTimeUserDataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger)

[`static let quickTimeUserDataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataartist)

[`static let quickTimeUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataauthor)

[`static let quickTimeUserDataChapter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatachapter)

An identifier that represents the name of the chapter.

[`static let quickTimeUserDataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomment)

[`static let quickTimeUserDataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomposer)

[`static let quickTimeUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacopyright)

An identifier that represents the copyright statement in QuickTime.

[`static let quickTimeUserDataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacreationdate)

[`static let quickTimeUserDataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacredits)

An identifier that represents the credits of movie source content.

[`static let quickTimeUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadescription)

[`static let quickTimeUserDataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadirector)

[`static let quickTimeUserDataDisclaimer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadisclaimer)

An identifier that represents the disclaimer regarding the movie file content.

[`static let quickTimeUserDataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataencodedby)

[`static let quickTimeUserDataFullName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatafullname)

An identifier that represents the full name of the movie file content.

[`static let quickTimeUserDataGenre: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatagenre)

[`static let quickTimeUserDataHostComputer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatahostcomputer)

An identifier that represents the name of the host computer.

[`static let quickTimeUserDataInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatainformation)

[`static let quickTimeUserDataKeywords: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatakeywords)

[`static let quickTimeUserDataLocationISO6709: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatalocationiso6709)

[`static let quickTimeUserDataMake: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatamake)

[`static let quickTimeUserDataModel: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatamodel)

[`static let quickTimeUserDataOriginalArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataoriginalartist)

[`static let quickTimeUserDataOriginalFormat: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataoriginalformat)

An identifier that represents the original format of the movie file content.

[`static let quickTimeUserDataOriginalSource: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataoriginalsource)

An identifier that represents the original source of the movie file content.

[`static let quickTimeUserDataPerformers: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataperformers)

An identifier that represents the name of the performers in the movie file content.

[`static let quickTimeUserDataPhonogramRights: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataphonogramrights)

[`static let quickTimeUserDataProducer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataproducer)

[`static let quickTimeUserDataProduct: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataproduct)

An identifier that represents the name of the product.

[`static let quickTimeUserDataPublisher: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatapublisher)

[`static let quickTimeUserDataSoftware: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatasoftware)

[`static let quickTimeUserDataSpecialPlaybackRequirements: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataspecialplaybackrequirements)

An identifier that represents the special hardware and software requirements for playback.

[`static let quickTimeUserDataTaggedCharacteristic: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatataggedcharacteristic)

An identifier that represents the tagged characteristic.

[`static let quickTimeUserDataTrack: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatatrack)

An identifier that represents a track in the movie file content.

[`static let quickTimeUserDataTrackName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatatrackname)

An identifier that represents the name of a track in the movie file content.

[`static let quickTimeUserDataURLLink: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataurllink)

An identifier that represents the webpage for the movie file content.

[`static let quickTimeUserDataWarning: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatawarning)

An identifier that represents the warning text for the movie file content.

[`static let quickTimeUserDataWriter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatawriter)

An identifier that represents the name of the writer of the movie file content.

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

[`static let id3MetadataCopyrightInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyrightinformation)

An identifier that represents the webpage describing the and ownership.

[`static let id3MetadataDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatadate)

An identifier that represents the date for the recording.

[`static let id3MetadataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataencodedby)

[`static let id3MetadataEncodedWith: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataencodedwith)

[`static let id3MetadataEncodingTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataencodingtime)

An identifier that represents the encoding time of the audio.

[`static let id3MetadataEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataencryption)

An identifier that represents the encryption method used.

[`static let id3MetadataEqualization: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataequalization)

An identifier that represents the equalization curve within the audio file.

[`static let id3MetadataEqualization2: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataequalization2)

[`static let id3MetadataEventTimingCodes: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataeventtimingcodes)

An identifier that represents the timing codes used for synchronization with key events in a song or sound.

[`static let id3MetadataFileOwner: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatafileowner)

An identifier that represents the name of the owner or licensee of the file and it’s contents.

[`static let id3MetadataFileType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatafiletype)

An identifier that represents the file type of the audio.

[`static let id3MetadataGeneralEncapsulatedObject: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatageneralencapsulatedobject)

An identifier that represents the details of a file.

[`static let id3MetadataGroupIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatagroupidentifier)

An identifier that represents the grouping of distinct frames.

[`static let id3MetadataInitialKey: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatainitialkey)

An identifier that represents the musical key in which the sound starts.

[`static let id3MetadataInternationalStandardRecordingCode: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatainternationalstandardrecordingcode)

An identifier that represents the international standard recording code.

[`static let id3MetadataInternetRadioStationName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatainternetradiostationname)

An identifier that represents the name of the internet radio station streaming the audio.

[`static let id3MetadataInternetRadioStationOwner: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatainternetradiostationowner)

An identifier that represents the name of the owner of the internet radio station streaming the audio.

[`static let id3MetadataInvolvedPeopleList_v23: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatainvolvedpeoplelist_v23)

An identifier that represents the list of names of contributors to the media.

[`static let id3MetadataInvolvedPeopleList_v24: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatainvolvedpeoplelist_v24)

[`static let id3MetadataLanguage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatalanguage)

[`static let id3MetadataLeadPerformer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataleadperformer)

An identifier that represents the main artist of the recording.

[`static let id3MetadataLength: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatalength)

An identifier that represents the length of the audio file in milliseconds.

[`static let id3MetadataLink: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatalink)

An identifier that represents the link information from an ID3 tag that might reside in another audio file or alone in a binary file.

[`static let id3MetadataLyricist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatalyricist)

An identifier that represents the writer(s) of the text or lyrics in the recording.

[`static let id3MetadataMediaType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatamediatype)

An identifier that represents which media the sound originated from.

[`static let id3MetadataModifiedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatamodifiedby)

An identifier that represents the people behind a remix and similar interpretations of another existing piece.

[`static let id3MetadataMood: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatamood)

An identifier that represents the mood of the audio.

[`static let id3MetadataMPEGLocationLookupTable: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatampeglocationlookuptable)

An identifier that represents the lookup table used to increase performance and accuracy of jumps within an MPEG audio file.

[`static let id3MetadataMusicCDIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatamusiccdidentifier)

An identifier that represents the ID used to identify the CD in databases such as the Compact Disc Database.

[`static let id3MetadataMusicianCreditsList: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatamusiciancreditslist)

An identifier that represents the mapping between an instrument and the musician that played it.

[`static let id3MetadataOfficialArtistWebpage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataofficialartistwebpage)

An identifier that represents the artist’s official webpage.

[`static let id3MetadataOfficialAudioFileWebpage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataofficialaudiofilewebpage)

An identifier that represents the official webpage for the audio file.

[`static let id3MetadataOfficialAudioSourceWebpage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataofficialaudiosourcewebpage)

An identifier that represents the official webpage for the source of the audio file.

[`static let id3MetadataOfficialInternetRadioStationHomepage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataofficialinternetradiostationhomepage)

An identifier that represents the official homepage of the internet radio station.

[`static let id3MetadataOfficialPublisherWebpage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataofficialpublisherwebpage)

An identifier that represents the official webpage for the publisher.

[`static let id3MetadataOriginalAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataoriginalalbumtitle)

An identifier that represents the title of the original recording or source of sound.

[`static let id3MetadataOriginalArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataoriginalartist)

An identifier that represents the performer(s) of the original recording.

[`static let id3MetadataOriginalFilename: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataoriginalfilename)

An identifier that represents the original filename for the recording.

[`static let id3MetadataOriginalLyricist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataoriginallyricist)

An identifier that represents the text writer(s) of the original recording.

[`static let id3MetadataOriginalReleaseTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataoriginalreleasetime)

An identifier that represents the release time for the original recording.

[`static let id3MetadataOriginalReleaseYear: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataoriginalreleaseyear)

An identifier that represents the release year for the original recording.

[`static let id3MetadataOwnership: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataownership)

An identifier that represents the transaction details indicating proof of ownership if signed.

[`static let id3MetadataPartOfASet: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatapartofaset)

An identifier that represents the part of a set the audio came from.

[`static let id3MetadataPayment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatapayment)

An identifier that represents the webpage that handles the process of paying for the audio file.

[`static let id3MetadataPerformerSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataperformersortorder)

An identifier that represents the performer sort order.

[`static let id3MetadataPlayCounter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataplaycounter)

An identifier that represents the play count of the audio file.

[`static let id3MetadataPlaylistDelay: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataplaylistdelay)

An identifier that represents the number of milliseconds of silence between every song in a playlist.

[`static let id3MetadataPopularimeter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatapopularimeter)

An identifier that represents the rating for the audio file.

[`static let id3MetadataPositionSynchronization: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatapositionsynchronization)

An identifier that represents the time offset of the first frame in the stream.

[`static let id3MetadataPrivate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataprivate)

An identifier that represents the information from a software producer that its program uses.

[`static let id3MetadataProducedNotice: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataproducednotice)

An identifier that represents the produced notice.

[`static let id3MetadataPublisher: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatapublisher)

An identifier that represents the name of the label or publisher.

[`static let id3MetadataRecommendedBufferSize: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatarecommendedbuffersize)

An identifier that represents the buffer size the server recommends.

[`static let id3MetadataRecordingDates: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatarecordingdates)

An identifier that represents additional recording dates that complement year, date, and time identifiers.

[`static let id3MetadataRecordingTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatarecordingtime)

An identifier that represents the recording time.

[`static let id3MetadataRelativeVolumeAdjustment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatarelativevolumeadjustment)

An identifier that represents the increase or decrease of volume on each channel while the file plays.

[`static let id3MetadataRelativeVolumeAdjustment2: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatarelativevolumeadjustment2)

[`static let id3MetadataReleaseTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatareleasetime)

An identifier that represents the time of the first release.

[`static let id3MetadataReverb: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatareverb)

An identifier that represents the adjustments to echoes of different kinds.

[`static let id3MetadataSeek: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataseek)

An identifier that represents the location of other tags in a file or stream.

[`static let id3MetadataSetSubtitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatasetsubtitle)

An identifier that represents the set subtitle the track belongs to.

[`static let id3MetadataSignature: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatasignature)

An identifier that represents the group of frames to sign.

[`static let id3MetadataSize: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatasize)

An identifier that represents the size of the audio file in bytes.

[`static let id3MetadataSubTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatasubtitle)

[`static let id3MetadataSynchronizedLyric: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatasynchronizedlyric)

An identifier that represents the words in the audio file as text in sync with the audio.

[`static let id3MetadataSynchronizedTempoCodes: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatasynchronizedtempocodes)

An identifier that represents the tempo codes used for a more accurate description of the tempo of a musical piece.

[`static let id3MetadataTaggingTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatataggingtime)

An identifier that represents the time of tagging.

[`static let id3MetadataTermsOfUse: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatatermsofuse)

An identifier that represents the brief description of the and ownership of the file.

[`static let id3MetadataTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatatime)

An identifier that represents the time for the recording.

[`static let id3MetadataTitleDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatatitledescription)

An identifier that represents the name of the piece.

[`static let id3MetadataTitleSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatatitlesortorder)

An identifier that represents the title sort order.

[`static let id3MetadataTrackNumber: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatatracknumber)

An identifier that represents the order number of the audio file.

[`static let id3MetadataUniqueFileIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatauniquefileidentifier)

An identifier that represents the identifier used to indicate the audio file in a database.

[`static let id3MetadataUnsynchronizedLyric: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataunsynchronizedlyric)

An identifier that represents the lyrics of the song or a text transcription of other vocal activities.

[`static let id3MetadataUserText: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatausertext)

An identifier that represents the user text information frame.

[`static let id3MetadataUserURL: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatauserurl)

An identifier that represents the user webpage frame.

[`static let id3MetadataYear: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatayear)

An identifier that represents the year of the recording.

[`static let id3MetadataCommerical: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommerical)

An identifier that represents the commerical frame.

Deprecated

### [3GP User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#3GP-User-Metadata-Identifiers)

[`static let identifier3GPUserDataAlbumAndTrack: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataalbumandtrack)

An identifier that represents the text for the album and track titles.

[`static let identifier3GPUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataauthor)

An identifier that represents the author of the media.

[`static let identifier3GPUserDataCollection: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatacollection)

An identifier that represents the collection name for the media.

[`static let identifier3GPUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatacopyright)

[`static let identifier3GPUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatadescription)

An identifier that represents the description for the media.

[`static let identifier3GPUserDataGenre: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatagenre)

An identifier that represents the genre of the media.

[`static let identifier3GPUserDataKeywordList: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatakeywordlist)

An identifier that represents the list of keywords for the media.

[`static let identifier3GPUserDataLocation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatalocation)

[`static let identifier3GPUserDataMediaClassification: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatamediaclassification)

An identifier that represents the classification of the media content.

[`static let identifier3GPUserDataMediaRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatamediarating)

An identifier that represents the rating of the media content.

[`static let identifier3GPUserDataPerformer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataperformer)

An identifier that represents information about the performer.

[`static let identifier3GPUserDataRecordingYear: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatarecordingyear)

An identifier that represents the recording year for the media.

[`static let identifier3GPUserDataThumbnail: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatathumbnail)

An identifier that represents the media thumbnail.

[`static let identifier3GPUserDataTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatatitle)

An identifier that represents the title for the media.

[`static let identifier3GPUserDataUserRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatauserrating)

An identifier that represents the user rating.

### [ISO Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#ISO-Metadata-Identifiers)

[`static let isoUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdataaccessibilitydescription)

An identifier that represents the accessibility description for the media content.

[`static let isoUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdatacopyright)

[`static let isoUserDataDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdatadate)

An identifier that represents the date for the media content.

[`static let isoUserDataTaggedCharacteristic: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdatataggedcharacteristic)

An identifier that represents the tagged media characteristic used for identifying accessibility features.

### [ICY Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#ICY-Metadata-Identifiers)

[`static let icyMetadataStreamTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/icymetadatastreamtitle)

An identifier that represents the title of a stream.

[`static let icyMetadataStreamURL: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/icymetadatastreamurl)

An identifier that represents the web address of a stream.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#Initializers)

[`init(String)`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/init(_:))

Creates a metadata identifier.

[`init(rawValue: String)`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/init(rawvalue:))

Creates a metadata identifier with the specified raw value.

### [Type Properties](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#Type-Properties)

[`static let quickTimeMetadataAIMEData: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataaimedata)

A value of type kCMMetadataBaseDataType\_RawData

Beta

[`static let quickTimeMetadataCameraFocalLength35mmEquivalent: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacamerafocallength35mmequivalent)

A value of type kCMMetadataBaseDataType\_UTF8 indicating focal length normalized to the 35mm film equivalent value (e.g. “50.00mm”).

[`static let quickTimeMetadataCameraLensModel: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameralensmodel)

A value of type kCMMetadataBaseDataType\_UTF8 indicating the lens model (e.g. “iPhone 16 Pro back camera 6.765mm f/1.78”).

[`static let quickTimeMetadataCinematicVideoIntent: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacinematicvideointent)

A value of type `kCMMetadataBaseDataType_UInt8` indicating whether this movie is intended as a Cinematic Video (1) or not (0).

[`static let quickTimeMetadataPresentationImmersiveMedia: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatapresentationimmersivemedia)

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#conforms-to)

- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#see-also)

### [Metadata](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier\#Metadata)

[Retrieving media metadata](https://developer.apple.com/documentation/avfoundation/retrieving-media-metadata)

Load descriptive metadata for media assets and their tracks.

[`class AVMetadataItem`](https://developer.apple.com/documentation/avfoundation/avmetadataitem)

A metadata item for an audiovisual asset or one of its tracks.

[`class AVMutableMetadataItem`](https://developer.apple.com/documentation/avfoundation/avmutablemetadataitem)

A mutable metadata item for an audiovisual asset or for one of its tracks.

[`struct AVMetadataKey`](https://developer.apple.com/documentation/avfoundation/avmetadatakey)

A structure that defines a metadata key.

[`struct AVMetadataKeySpace`](https://developer.apple.com/documentation/avfoundation/avmetadatakeyspace)

A structure that defines a metadata key space.

[`struct AVMetadataExtraAttributeKey`](https://developer.apple.com/documentation/avfoundation/avmetadataextraattributekey)

A structure that defines keys for extra metadata attributes.

[`struct AVMetadataFormat`](https://developer.apple.com/documentation/avfoundation/avmetadataformat)

A structure that defines metadata formats.

[`class AVMetadataItemFilter`](https://developer.apple.com/documentation/avfoundation/avmetadataitemfilter)

An object that filters selected information from a metadata item.

---

# https://developer.apple.com/documentation/avfoundation/avplayer/sourceclock

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- sourceClock

Instance Property

# sourceClock

A clock the player uses for item time bases.

nonisolated
var sourceClock: CMClock? { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/sourceclock\#Discussion)

The default value is `nil`. Setting an explicit source clock is useful to synchronize video-only movies with audio that plays through a different audio device.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/sourceclock\#see-also)

### [Synchronizing Multiple Players](https://developer.apple.com/documentation/avfoundation/avplayer/sourceclock\#Synchronizing-Multiple-Players)

[`func setRate(Float, time: CMTime, atHostTime: CMTime)`](https://developer.apple.com/documentation/avfoundation/avplayer/setrate(_:time:athosttime:))

Synchronizes the playback rate and time of the current item with an external source.

Begins loading media data to prime the media pipelines for playback.

[`func cancelPendingPrerolls()`](https://developer.apple.com/documentation/avfoundation/avplayer/cancelpendingprerolls())

Cancels any pending preroll requests and invokes the corresponding completion handlers, if present.

[`var masterClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avplayer/masterclock)

The host clock for item time bases.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avplayer/playimmediately(atrate:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- playImmediately(atRate:)

Instance Method

# playImmediately(atRate:)

Plays the available media data immediately, at the specified rate.

nonisolated
func playImmediately(atRate rate: Float)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avplayer/playimmediately(atrate:)\#parameters)

`rate`

The specified playback rate.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/playimmediately(atrate:)\#Discussion)

This method plays the available media data at the specified `rate` regardless of whether there is sufficient media buffered to ensure smooth playback. If media data exists in the playback buffer, calling this method changes the player’s playback rate to the specified `rate` and its [`timeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.property) to a value of [`AVPlayer.TimeControlStatus.playing`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.enum/playing). If the player has insufficient media data buffered to begin playback, the player will behave as if it has encountered a stall during playback, except that no [`playbackStalledNotification`](https://developer.apple.com/documentation/avfoundation/avplayeritem/playbackstallednotification) will be posted.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/playimmediately(atrate:)\#see-also)

### [Configuring Waiting Behavior](https://developer.apple.com/documentation/avfoundation/avplayer/playimmediately(atrate:)\#Configuring-Waiting-Behavior)

[`var automaticallyWaitsToMinimizeStalling: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/automaticallywaitstominimizestalling)

A Boolean value that indicates whether the player should automatically delay playback in order to minimize stalling.

[`var reasonForWaitingToPlay: AVPlayer.WaitingReason?`](https://developer.apple.com/documentation/avfoundation/avplayer/reasonforwaitingtoplay)

The reason the player is currently waiting for play

The reasons a player is waiting to begin or resume playback.

[`var timeControlStatus: AVPlayer.TimeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.property)

A value that indicates whether playback is in progress, paused indefinitely, or waiting for network conditions to improve.

[`enum TimeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.enum)

Constants that indicate the state of playback control.

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforrenewalofrequestedresource:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetResourceLoaderDelegate](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate)
- resourceLoader(\_:shouldWaitForRenewalOfRequestedResource:)

Instance Method

# resourceLoader(\_:shouldWaitForRenewalOfRequestedResource:)

Tells the delegate when assistance is required of the application to renew a resource.

optional func resourceLoader(
_ resourceLoader: AVAssetResourceLoader,
shouldWaitForRenewalOfRequestedResource renewalRequest: AVAssetResourceRenewalRequest

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforrenewalofrequestedresource:)\#parameters)

`resourceLoader`

The resource loader.

`renewalRequest`

An instance of `AVAssetResourceRenewalRequest` that provides information about the requested resource.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforrenewalofrequestedresource:)\#return-value)

[`true`](https://developer.apple.com/documentation/swift/true) if the delegate can renew the resource; otherwise [`false`](https://developer.apple.com/documentation/swift/false).

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforrenewalofrequestedresource:)\#Discussion)

Delegates receive this message when assistance is required to renew a resource previously loaded by [`resourceLoader(_:shouldWaitForLoadingOfRequestedResource:)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)). For example, this method is invoked to for decryption keys that require renewal, as indicated in a response to a prior invocation of [`resourceLoader(_:shouldWaitForLoadingOfRequestedResource:)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforloadingofrequestedresource:)).

If the result is [`true`](https://developer.apple.com/documentation/swift/true), the resource loader expects invocation, either subsequently or immediately, of either the `AVAssetResourceRenewalRequest` method `finishLoading` or `finishLoadingWithError:`. If you intend to finish loading the resource after your handling of this message returns, you must retain the `renewalRequest` until after loading is finished.

If the result is [`false`](https://developer.apple.com/documentation/swift/false), the resource loader treats the loading of the resource as having failed.

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforrenewalofrequestedresource:)\#see-also)

### [Processing Resource Requests](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:shouldwaitforrenewalofrequestedresource:)\#Processing-Resource-Requests)

Asks the delegate if it wants to load the requested resource.

[`func resourceLoader(AVAssetResourceLoader, didCancel: AVAssetResourceLoadingRequest)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloaderdelegate/resourceloader(_:didcancel:)-3nl51)

Informs the delegate that a prior loading request has been cancelled.

---

# https://developer.apple.com/documentation/avfoundation/avplayerlooper

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerLooper

Class

# AVPlayerLooper

An object that loops media content using a queue player.

class AVPlayerLooper

## [Overview](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#overview)

You can manually implement looping playback in your app using [`AVQueuePlayer`](https://developer.apple.com/documentation/avfoundation/avqueueplayer), but `AVPlayerLooper` provides a much simpler interface to loop a single [`AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem). You create a player looper by passing it a reference to your [`AVQueuePlayer`](https://developer.apple.com/documentation/avfoundation/avqueueplayer) and a template [`AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem) and the looper automatically manages the looping playback of this content (see example).

let asset = // AVAsset with its 'duration' property value loaded
let playerItem = AVPlayerItem(asset: asset)

// Create a new player looper with the queue player and template item
playerLooper = AVPlayerLooper(player: queuePlayer, templateItem: playerItem)

// Begin looping playback
queuePlayer.play()

## [Topics](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#topics)

### [Creating a Player Looper](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#Creating-a-Player-Looper)

[`init(player: AVQueuePlayer, templateItem: AVPlayerItem, timeRange: CMTimeRange, existingItemsOrdering: AVPlayerLooper.ItemOrdering)`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:))

Creates a player looper that continuously plays the full duration of a player item while adhering to the specified ordering of existing items in the queue.

[`convenience init(player: AVQueuePlayer, templateItem: AVPlayerItem)`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:))

Creates a player looper that continuously plays the full duration of a player item.

[`convenience init(player: AVQueuePlayer, templateItem: AVPlayerItem, timeRange: CMTimeRange)`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:))

Creates a player looper that continuously plays the specified time range of a player item.

### [Configuring Looping](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#Configuring-Looping)

[`var loopingPlayerItems: [AVPlayerItem]`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/loopingplayeritems)

An array containing replicas of the template player item used to accomplish the looping.

[`func disableLooping()`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/disablelooping())

Disables looping for the player queue.

### [Observing Looping State](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#Observing-Looping-State)

[`var loopCount: Int`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/loopcount)

The number of times the object played the media.

[`var status: AVPlayerLooper.Status`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/status-swift.property)

A status that indicates the object’s ability to loop playback.

[`enum Status`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/status-swift.enum)

Status constants that indicate whether a looper can successfully perform looping playback.

### [Monitoring Errors](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#Monitoring-Errors)

[`var error: (any Error)?`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/error)

An error that describes the reason looping failed.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#see-also)

### [Playback control](https://developer.apple.com/documentation/avfoundation/avplayerlooper\#Playback-control)

[Observing playback state in SwiftUI](https://developer.apple.com/documentation/avfoundation/observing-playback-state-in-swiftui)

Keep your user interface in sync with state changes from playback objects.

[Controlling the transport behavior of a player](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player)

Play, pause, and seek through a media presentation.

[Creating a seamless multiview playback experience](https://developer.apple.com/documentation/avfoundation/creating-a-seamless-multiview-playback-experience)

Build advanced multiview playback experiences with the AVFoundation and AVRouting frameworks.

[`class AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer)

An object that provides the interface to control the player’s transport behavior.

[`class AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem)

An object that models the timing and presentation state of an asset during playback.

[`class AVPlayerItemTrack`](https://developer.apple.com/documentation/avfoundation/avplayeritemtrack)

An object that represents the presentation state of an asset track during playback.

[`class AVQueuePlayer`](https://developer.apple.com/documentation/avfoundation/avqueueplayer)

An object that plays a sequence of player items.

---

# https://developer.apple.com/documentation/avfoundation/avplayeritemmediadatacollector

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerItemMediaDataCollector

Class

# AVPlayerItemMediaDataCollector

The abstract base for media data collectors.

class AVPlayerItemMediaDataCollector

## [Relationships](https://developer.apple.com/documentation/avfoundation/avplayeritemmediadatacollector\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avplayeritemmediadatacollector\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avplayeritemmediadatacollector\#inherited-by)

- [`AVPlayerItemMetadataCollector`](https://developer.apple.com/documentation/avfoundation/avplayeritemmetadatacollector)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avplayeritemmediadatacollector\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayeritemmediadatacollector\#see-also)

### [Timed metadata](https://developer.apple.com/documentation/avfoundation/avplayeritemmediadatacollector\#Timed-metadata)

[Presenting Chapter Markers](https://developer.apple.com/documentation/avfoundation/presenting-chapter-markers)

Add chapter markers to enable users to quickly navigate your content.

[`class AVMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avmetadatagroup)

A collection of metadata items associated with a timeline segment.

[`class AVTimedMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avtimedmetadatagroup)

A collection of metadata items that are valid for use during a specific time range.

[`class AVMutableTimedMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avmutabletimedmetadatagroup)

A mutable collection of metadata items that are valid for use during a specific time range.

[`class AVDateRangeMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avdaterangemetadatagroup)

A collection of metadata items that are valid for use within a specific date range.

[`class AVMutableDateRangeMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup)

A mutable collection of metadata items that are valid for use within a specific range of dates.

[`class AVPlayerItemMetadataCollector`](https://developer.apple.com/documentation/avfoundation/avplayeritemmetadatacollector)

An object used to capture the date range metadata defined for an HTTP Live Streaming asset.

---

# https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- AVPlayer.NetworkResourcePriority Beta

Enumeration

# AVPlayer.NetworkResourcePriority

This defines the network resource priority for a player.

enum NetworkResourcePriority

## [Topics](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum\#topics)

### [Enumeration Cases](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum\#Enumeration-Cases)

[``case `default` ``](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum/default)

The default priority level given to a player for loading network resources. Use this when the player requires an optimal level of network resources and streaming in high-quality resolution is ideal. Players with AVPlayerNetworkResourcePriorityHigh will take precedence over this player. This player will take precedence over players with AVPlayerNetworkResourcePriorityLow.

[`case high`](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum/high)

Indicates a high priority level for loading network resources. Use this when the player requires a high level of network resources and streaming in high-quality resolution is crucial. This player will take precedence over other lower priority players.

[`case low`](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum/low)

Indicates a low priority level for loading network resources. Use this when the player requires minimal network bandwidth and streaming in high-quality resolution is not crucial. Other players with higher priority will take precedence over this player.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum\#Initializers)

[`init?(rawValue: Int)`](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum/init(rawvalue:))

## [Relationships](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avplayer/networkresourcepriority-swift.enum\#conforms-to)

- [`BitwiseCopyable`](https://developer.apple.com/documentation/Swift/BitwiseCopyable)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avplayer/play()

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- play()

Instance Method

# play()

Begins playback of the current item.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

nonisolated
func play()

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avplayer/play()\#mentions)

[Controlling the transport behavior of a player](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/play()\#Discussion)

Calling this method is the same as setting the [`rate`](https://developer.apple.com/documentation/avfoundation/avplayer/rate) to `1.0`.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/play()\#see-also)

### [Controlling Playback](https://developer.apple.com/documentation/avfoundation/avplayer/play()\#Controlling-Playback)

[`var defaultRate: Float`](https://developer.apple.com/documentation/avfoundation/avplayer/defaultrate)

A default rate at which to begin playback.

[`func pause()`](https://developer.apple.com/documentation/avfoundation/avplayer/pause())

Pauses playback of the current item.

[`var rate: Float`](https://developer.apple.com/documentation/avfoundation/avplayer/rate)

The current playback rate.

[`class let rateDidChangeNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avplayer/ratedidchangenotification)

A notification that a player posts when its rate changes.

---

# https://developer.apple.com/documentation/avfoundation/avplayer/automaticallywaitstominimizestalling

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- automaticallyWaitsToMinimizeStalling

Instance Property

# automaticallyWaitsToMinimizeStalling

A Boolean value that indicates whether the player should automatically delay playback in order to minimize stalling.

nonisolated
var automaticallyWaitsToMinimizeStalling: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/automaticallywaitstominimizestalling\#Discussion)

You will need to set this property to [`false`](https://developer.apple.com/documentation/swift/false) when you require precise control over playback start times, such as if you’re are synchronizing multiple player instances using the [`setRate(_:time:atHostTime:)`](https://developer.apple.com/documentation/avfoundation/avplayer/setrate(_:time:athosttime:)) method. If the value of this property is [`false`](https://developer.apple.com/documentation/swift/false), playback will start immediately when requested as long as the playback buffer is not empty. If the playback buffer becomes empty and playback stalls, the player’s [`timeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.property) will switch to [`AVPlayer.TimeControlStatus.paused`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.enum/paused) and the playback rate will change to `0.0`.

Changing the value of this property to [`false`](https://developer.apple.com/documentation/swift/false) while the player’s [`timeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.property) is [`AVPlayer.TimeControlStatus.waitingToPlayAtSpecifiedRate`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.enum/waitingtoplayatspecifiedrate) and its [`reasonForWaitingToPlay`](https://developer.apple.com/documentation/avfoundation/avplayer/reasonforwaitingtoplay) is [`toMinimizeStalls`](https://developer.apple.com/documentation/avfoundation/avplayer/waitingreason/tominimizestalls) will cause the player to immediately attempt playback at the specified rate.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/automaticallywaitstominimizestalling\#see-also)

### [Configuring Waiting Behavior](https://developer.apple.com/documentation/avfoundation/avplayer/automaticallywaitstominimizestalling\#Configuring-Waiting-Behavior)

[`var reasonForWaitingToPlay: AVPlayer.WaitingReason?`](https://developer.apple.com/documentation/avfoundation/avplayer/reasonforwaitingtoplay)

The reason the player is currently waiting for play

The reasons a player is waiting to begin or resume playback.

[`var timeControlStatus: AVPlayer.TimeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.property)

A value that indicates whether playback is in progress, paused indefinitely, or waiting for network conditions to improve.

[`enum TimeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.enum)

Constants that indicate the state of playback control.

[`func playImmediately(atRate: Float)`](https://developer.apple.com/documentation/avfoundation/avplayer/playimmediately(atrate:))

Plays the available media data immediately, at the specified rate.

---

# https://developer.apple.com/documentation/avfoundation/avmetrics

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMetrics

Structure

# AVMetrics

An asynchronous stream of metric information.

Mac Catalyst

## [Topics](https://developer.apple.com/documentation/avfoundation/avmetrics\#topics)

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmetrics\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmetrics\#conforms-to)

- [`AsyncSequence`](https://developer.apple.com/documentation/Swift/AsyncSequence)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetrics\#see-also)

### [Metrics](https://developer.apple.com/documentation/avfoundation/avmetrics\#Metrics)

[`struct AVMergedMetrics`](https://developer.apple.com/documentation/avfoundation/avmergedmetrics)

An asynchronous stream of metric information from different publishers.

[`class AVVideoPerformanceMetrics`](https://developer.apple.com/documentation/avfoundation/avvideoperformancemetrics)

An object that provides metrics related to video playback quality.

[`protocol AVMetricEventStreamPublisher`](https://developer.apple.com/documentation/avfoundation/avmetriceventstreampublisher)

A type for objects that publish metric events to the event stream.

[`class AVMetricEvent`](https://developer.apple.com/documentation/avfoundation/avmetricevent)

A base class that represents a metric event.

[`class AVMetricErrorEvent`](https://developer.apple.com/documentation/avfoundation/avmetricerrorevent)

An object that represents a metric event when an error occurs.

---

# https://developer.apple.com/documentation/avfoundation/avplayer/videooutput

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- videoOutput

Instance Property

# videoOutput

The video output for this player.

nonisolated
var videoOutput: AVPlayerVideoOutput? { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/videooutput\#Discussion)

The value of this property is `nil` by default.

---

# https://developer.apple.com/documentation/avfoundation/avplayer/audiooutputdeviceuniqueid

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- audioOutputDeviceUniqueID

Instance Property

# audioOutputDeviceUniqueID

Specifies the unique ID of the Core Audio output device used to play audio.

nonisolated
var audioOutputDeviceUniqueID: String? { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/audiooutputdeviceuniqueid\#Discussion)

The default value of this property is `nil`, indicating that the default audio output device is used. Otherwise the value of this property is a string containing the unique ID of the Core Audio output device to be used for audio output.

Core Audio’s [`kAudioDevicePropertyDeviceUID`](https://developer.apple.com/documentation/CoreAudio/kAudioDevicePropertyDeviceUID) is a suitable source of audio output device unique IDs.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/audiooutputdeviceuniqueid\#see-also)

### [Configuring Audio and Video Devices](https://developer.apple.com/documentation/avfoundation/avplayer/audiooutputdeviceuniqueid\#Configuring-Audio-and-Video-Devices)

[`var preferredVideoDecoderGPURegistryID: UInt64`](https://developer.apple.com/documentation/avfoundation/avplayer/preferredvideodecodergpuregistryid)

The registry identifier for the GPU used for video decoding.

---

# https://developer.apple.com/documentation/avfoundation/avvideooutputspecification

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVVideoOutputSpecification

Class

# AVVideoOutputSpecification

An object that specifies the pixel buffer attributes and tag collections handled by a player video output.

class AVVideoOutputSpecification

## [Topics](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification\#topics)

### [Creating a specification](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification\#Creating-a-specification)

[`convenience init(tagCollections: [[CMTag]])`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/init(tagcollections:))

### [Configuring the specification](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification\#Configuring-the-specification)

[`var defaultOutputSettings: [String : any Sendable]?`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/defaultoutputsettings)

[`func setOutputSettings([String : any Sendable]?, for: [CMTag])`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/setoutputsettings(_:for:))

[`var defaultPixelBufferAttributes: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/defaultpixelbufferattributes)

[`func setOutputPixelBufferAttributes([String : Any]?, for: [CMTag])`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/setoutputpixelbufferattributes(_:for:))

[`var preferredTagCollections: [[CMTag]]`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/preferredtagcollections-3gdo7)

## [Relationships](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification\#see-also)

### [Media output](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification\#Media-output)

[`class AVPlayerVideoOutput`](https://developer.apple.com/documentation/avfoundation/avplayervideooutput)

An object that receives video data from a player object.

[`class AVPlayerItemOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemoutput)

An abstract class that defines the common interface to output media data from a player item.

[`class AVPlayerItemVideoOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemvideooutput)

An object that outputs video frames from a player item.

[`class AVPlayerItemLegibleOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput)

An object that vends attributed strings for media with a legible characteristic.

[`class AVPlayerItemRenderedLegibleOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemrenderedlegibleoutput)

A player item output that vends media with a legible characteristic as rendered pixel buffers.

[`class AVRenderedCaptionImage`](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage)

An object that provides a rendered pixel buffer and its position in pixels.

[`class AVPlayerItemMetadataOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemmetadataoutput)

An object that vends collections of metadata items that a player item’s tracks carry.

[`protocol AVPlayerItemOutputPushDelegate`](https://developer.apple.com/documentation/avfoundation/avplayeritemoutputpushdelegate)

A protocol that defines the methods to implement to respond to changes in the media data sequence.

---

# https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVRenderedCaptionImage

Class

# AVRenderedCaptionImage

An object that provides a rendered pixel buffer and its position in pixels.

class AVRenderedCaptionImage

## [Topics](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage\#topics)

### [Inspecting the image](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage\#Inspecting-the-image)

[`var pixelBuffer: CVPixelBuffer`](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage/pixelbuffer)

An object that contains pixel data for the rendered caption.

[`var position: CGPoint`](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage/position)

A point that defines the position, in pixels, of the rendered caption image relative to the video frame.

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage\#Instance-Properties)

[`var readOnlyPixelBuffer: CVReadOnlyPixelBuffer`](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage/readonlypixelbuffer)

A CVReadOnlyPixelBuffer that contains pixel data for the rendered caption

## [Relationships](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage\#see-also)

### [Media output](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage\#Media-output)

[`class AVPlayerVideoOutput`](https://developer.apple.com/documentation/avfoundation/avplayervideooutput)

An object that receives video data from a player object.

[`class AVVideoOutputSpecification`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification)

An object that specifies the pixel buffer attributes and tag collections handled by a player video output.

[`class AVPlayerItemOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemoutput)

An abstract class that defines the common interface to output media data from a player item.

[`class AVPlayerItemVideoOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemvideooutput)

An object that outputs video frames from a player item.

[`class AVPlayerItemLegibleOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput)

An object that vends attributed strings for media with a legible characteristic.

[`class AVPlayerItemRenderedLegibleOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemrenderedlegibleoutput)

A player item output that vends media with a legible characteristic as rendered pixel buffers.

[`class AVPlayerItemMetadataOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemmetadataoutput)

An object that vends collections of metadata items that a player item’s tracks carry.

[`protocol AVPlayerItemOutputPushDelegate`](https://developer.apple.com/documentation/avfoundation/avplayeritemoutputpushdelegate)

A protocol that defines the methods to implement to respond to changes in the media data sequence.

---

# https://developer.apple.com/documentation/avfoundation/avplayer/cancelpendingprerolls()

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- cancelPendingPrerolls()

Instance Method

# cancelPendingPrerolls()

Cancels any pending preroll requests and invokes the corresponding completion handlers, if present.

nonisolated
func cancelPendingPrerolls()

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/cancelpendingprerolls()\#Discussion)

This method cancels and releases the completion handlers for any pending prerolls. The finished parameter of the completion handlers passed to [`preroll(atRate:completionHandler:)`](https://developer.apple.com/documentation/avfoundation/avplayer/preroll(atrate:completionhandler:)) will be set to `false`.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/cancelpendingprerolls()\#see-also)

### [Synchronizing Multiple Players](https://developer.apple.com/documentation/avfoundation/avplayer/cancelpendingprerolls()\#Synchronizing-Multiple-Players)

[`func setRate(Float, time: CMTime, atHostTime: CMTime)`](https://developer.apple.com/documentation/avfoundation/avplayer/setrate(_:time:athosttime:))

Synchronizes the playback rate and time of the current item with an external source.

Begins loading media data to prime the media pipelines for playback.

[`var sourceClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avplayer/sourceclock)

A clock the player uses for item time bases.

[`var masterClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avplayer/masterclock)

The host clock for item time bases.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avplayer/usesairplayvideowhileairplayscreenisactive

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- usesAirPlayVideoWhileAirPlayScreenIsActive Deprecated

Instance Property

# usesAirPlayVideoWhileAirPlayScreenIsActive

A Boolean value that indicates whether the player automatically switches to AirPlay Video while AirPlay Screen is active.

tvOS 9.0–9.0Deprecated

@MainActor
var usesAirPlayVideoWhileAirPlayScreenIsActive: Bool { get set }

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/usesairplayvideowhileairplayscreenisactive\#see-also)

### [Configuring AirPlay Behavior](https://developer.apple.com/documentation/avfoundation/avplayer/usesairplayvideowhileairplayscreenisactive\#Configuring-AirPlay-Behavior)

[`var allowsAirPlayVideo: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/allowsairplayvideo)

A Boolean value that indicates whether the player allows AirPlay video playback.

Deprecated

[`var isAirPlayVideoActive: Bool`](https://developer.apple.com/documentation/avfoundation/avplayer/isairplayvideoactive)

A Boolean value that indicates whether the player is playing video through AirPlay.

---

# https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMutableDateRangeMetadataGroup

Class

# AVMutableDateRangeMetadataGroup

A mutable collection of metadata items that are valid for use within a specific range of dates.

class AVMutableDateRangeMetadataGroup

## [Topics](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup\#topics)

### [Configuring the Metadata](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup\#Configuring-the-Metadata)

[`var items: [AVMetadataItem]`](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup/items)

An array of associated metadata items.

### [Configuring the Date Range](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup\#Configuring-the-Date-Range)

[`var startDate: Date`](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup/startdate)

The start date for the metadata date range group.

[`var endDate: Date?`](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup/enddate)

The end date for the metadata date range group.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup\#inherits-from)

- [`AVDateRangeMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avdaterangemetadatagroup)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSMutableCopying`](https://developer.apple.com/documentation/Foundation/NSMutableCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup\#see-also)

### [Timed metadata](https://developer.apple.com/documentation/avfoundation/avmutabledaterangemetadatagroup\#Timed-metadata)

[Presenting Chapter Markers](https://developer.apple.com/documentation/avfoundation/presenting-chapter-markers)

Add chapter markers to enable users to quickly navigate your content.

[`class AVMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avmetadatagroup)

A collection of metadata items associated with a timeline segment.

[`class AVTimedMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avtimedmetadatagroup)

A collection of metadata items that are valid for use during a specific time range.

[`class AVMutableTimedMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avmutabletimedmetadatagroup)

A mutable collection of metadata items that are valid for use during a specific time range.

[`class AVDateRangeMetadataGroup`](https://developer.apple.com/documentation/avfoundation/avdaterangemetadatagroup)

A collection of metadata items that are valid for use within a specific date range.

[`class AVPlayerItemMediaDataCollector`](https://developer.apple.com/documentation/avfoundation/avplayeritemmediadatacollector)

The abstract base for media data collectors.

[`class AVPlayerItemMetadataCollector`](https://developer.apple.com/documentation/avfoundation/avplayeritemmetadatacollector)

An object used to capture the date range metadata defined for an HTTP Live Streaming asset.

---

# https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:tolerancebefore:toleranceafter:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- seek(to:toleranceBefore:toleranceAfter:)

Instance Method

# seek(to:toleranceBefore:toleranceAfter:)

Requests that the player seek to a specified time with the amount of accuracy specified by the time tolerance values.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

nonisolated
func seek(
to time: CMTime,
toleranceBefore: CMTime,
toleranceAfter: CMTime
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:tolerancebefore:toleranceafter:)\#parameters)

`time`

A time to seek to.

`toleranceBefore`

A tolerance before the target time to allow.

`toleranceAfter`

A tolerance after the target time to allow.

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:tolerancebefore:toleranceafter:)\#mentions)

[Controlling the transport behavior of a player](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:tolerancebefore:toleranceafter:)\#Discussion)

The player seeks within the range `[time-beforeTolerance, time+afterTolerance]`, and may differ from the specified time for efficiency. You can request sample accurate seeking by passing a time value of `kCMTimeZero` for both `toleranceBefore` and `toleranceAfter`. Sample accurate seeking may incur additional decoding delay which can impact seeking performance.

Passing `kCMTimePositiveInfinity` for both `toleranceBefore` and `toleranceAfter` is the same as messaging [`seek(to:)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:)-87h2r) directly.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:tolerancebefore:toleranceafter:)\#see-also)

### [Seeking Through Media](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:tolerancebefore:toleranceafter:)\#Seeking-Through-Media)

[`func seek(to: CMTime)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:)-87h2r)

Requests that the player seek to a specified time.

Requests that the player seek to a specified time, and to notify you when the seek is complete.

Requests that the player seek to a specified time with the amount of accuracy specified by the time tolerance values, and to notify you when the seek is complete.

[`func seek(to: Date)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:)-9h9qr)

Requests that the player seek to a specified date.

Requests that the player seek to a specified date, and to notify you when the seek is complete.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawfiletype

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoSettings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)
- rawFileType

Instance Property

# rawFileType

The container file format for eventual output of the RAW image.

var rawFileType: AVFileType? { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawfiletype\#Discussion)

You specify a file format when creating capture settings with the [`init(rawPixelFormatType:rawFileType:processedFormat:processedFileType:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/init(rawpixelformattype:rawfiletype:processedformat:processedfiletype:)) initializer. If you didn’t specify a file format, this value is `nil`, and the photo output automatically choosea a default file format appropriate to the [`rawPhotoPixelFormatType`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawphotopixelformattype) property.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawfiletype\#see-also)

### [Inspecting settings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawfiletype\#Inspecting-settings)

[`var uniqueID: Int64`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/uniqueid)

A unique identifier for this photo settings instance.

[`var format: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/format)

A dictionary describing the processed format (for example, JPEG) to deliver captured photos in.

[`var processedFileType: AVFileType?`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/processedfiletype)

The container file format for eventual output of the processed image.

[`var rawPhotoPixelFormatType: OSType`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/rawphotopixelformattype)

An identifier for the Bayer RAW pixel format to deliver captured RAW photos in.

---

# https://developer.apple.com/documentation/avfoundation/avmediaselection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMediaSelection

Class

# AVMediaSelection

An object that represents a complete rendition of media selection options on an asset.

class AVMediaSelection

## [Topics](https://developer.apple.com/documentation/avfoundation/avmediaselection\#topics)

### [Inspecting the Media Selection](https://developer.apple.com/documentation/avfoundation/avmediaselection\#Inspecting-the-Media-Selection)

Returns the media selection option that’s currently selected in the specified group.

Indicates whether the specified media selection group is subject to automatic media selection.

### [Accessing the Asset](https://developer.apple.com/documentation/avfoundation/avmediaselection\#Accessing-the-Asset)

[`var asset: AVAsset?`](https://developer.apple.com/documentation/avfoundation/avmediaselection/asset)

The asset associated with the media selection.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmediaselection\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmediaselection\#inherits-from)

- [`NSObject`](https://developer.apple.com/documentation/ObjectiveC/NSObject-swift.class)

### [Inherited By](https://developer.apple.com/documentation/avfoundation/avmediaselection\#inherited-by)

- [`AVMutableMediaSelection`](https://developer.apple.com/documentation/avfoundation/avmutablemediaselection)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmediaselection\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCopying`](https://developer.apple.com/documentation/Foundation/NSCopying)
- [`NSMutableCopying`](https://developer.apple.com/documentation/Foundation/NSMutableCopying)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmediaselection\#see-also)

### [Media selection](https://developer.apple.com/documentation/avfoundation/avmediaselection\#Media-selection)

[Selecting Subtitles and Alternative Audio Tracks](https://developer.apple.com/documentation/avfoundation/selecting-subtitles-and-alternative-audio-tracks)

Extend your app’s appeal to users by adding subtitles and alternative audio tracks in their native language.

[`class AVMediaSelectionGroup`](https://developer.apple.com/documentation/avfoundation/avmediaselectiongroup)

An object that represents a collection of mutually exclusive options for the presentation of media within an asset.

[`class AVMediaSelectionOption`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption)

An object that represents a specific option for the presentation of media within a group of options.

[`class AVMutableMediaSelection`](https://developer.apple.com/documentation/avfoundation/avmutablemediaselection)

A mutable object that represents a complete rendition of media selection options on an asset.

[`class AVPlayerMediaSelectionCriteria`](https://developer.apple.com/documentation/avfoundation/avplayermediaselectioncriteria)

An object that specifies the preferred languages and media characteristics for a player.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/ishighresolutionphotoenabled

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoSettings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings)
- isHighResolutionPhotoEnabled Deprecated

Instance Property

# isHighResolutionPhotoEnabled

A Boolean value that specifies whether to capture still images at the highest resolution supported by the active device and format.

iOS 10.0–16.0DeprecatediPadOS 10.0–16.0DeprecatedMac Catalyst 14.0–16.0DeprecatedmacOS 10.15–13.0Deprecated

var isHighResolutionPhotoEnabled: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/ishighresolutionphotoenabled\#Discussion)

When this setting is [`false`](https://developer.apple.com/documentation/swift/false) (the default), a photo capture output delivers images with the dimensions specified by the [`formatDescription`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/format/formatdescription) property of the source [`AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice) object’s active capture format. However, some devices and capture formats allow for still image capture at resolutions higher than their video capture (and streaming photo preview) resolution. To capture the highest possible resolution for still photos (described by the capture format’s [`highResolutionStillImageDimensions`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/format/highresolutionstillimagedimensions) property), change this setting to [`true`](https://developer.apple.com/documentation/swift/true).

If any output connected to your capture session enables video stabilization (see the [`AVCaptureConnection`](https://developer.apple.com/documentation/avfoundation/avcaptureconnection) [`preferredVideoStabilizationMode`](https://developer.apple.com/documentation/avfoundation/avcaptureconnection/preferredvideostabilizationmode) property), captured images may be around 10% smaller than the maximum still image dimensions. (This size change is an effect of video stabilization, which works by cropping and rotating to find the stable region in a moving image). Examine the [`AVCaptureResolvedPhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings) object provided to your photo capture delegate to find the actual dimensions of each captured photo.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/ishighresolutionphotoenabled\#see-also)

### [Configuring photo settings](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/ishighresolutionphotoenabled\#Configuring-photo-settings)

[`var flashMode: AVCaptureDevice.FlashMode`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/flashmode)

A setting for whether to fire the flash when capturing photos.

[`var isAutoRedEyeReductionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautoredeyereductionenabled)

A Boolean value that indicates whether to use auto red-eye reduction on flash captures.

[`var maxPhotoDimensions: CMVideoDimensions`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/maxphotodimensions)

The maximum resolution of the photo to capture.

[`var photoQualityPrioritization: AVCapturePhotoOutput.QualityPrioritization`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/photoqualityprioritization)

A setting that indicates how to prioritize photo quality against speed of photo delivery.

[`var isCameraCalibrationDataDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/iscameracalibrationdatadeliveryenabled)

A Boolean value that determines whether a dual photo capture also delivers camera calibration data.

[`var isAutoContentAwareDistortionCorrectionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautocontentawaredistortioncorrectionenabled)

A Boolean value that specifies whether the photo output, at its discretion, uses content-aware distortion correction on this photo request.

[`var isAutoVirtualDeviceFusionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautovirtualdevicefusionenabled)

A Boolean value that specifies whether to use automatic virtual-device image fusion.

[`var virtualDeviceConstituentPhotoDeliveryEnabledDevices: [AVCaptureDevice]`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/virtualdeviceconstituentphotodeliveryenableddevices)

The constituent devices for which the virtual device should deliver photos.

[`var isDualCameraDualPhotoDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isdualcameradualphotodeliveryenabled)

A Boolean value that determines whether a dual camera device delivers images from both cameras.

Deprecated

[`var isAutoDualCameraFusionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautodualcamerafusionenabled)

A Boolean value that specifies whether captures automatically combine data from a dual camera device.

[`var isAutoStillImageStabilizationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautostillimagestabilizationenabled)

A Boolean value that specifies whether captures use automatic image stabilization.

---

# https://developer.apple.com/documentation/avfoundation/avplayer/preroll(atrate:completionhandler:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- preroll(atRate:completionHandler:)

Instance Method

# preroll(atRate:completionHandler:)

Begins loading media data to prime the media pipelines for playback.

nonisolated
func preroll(
atRate rate: Float,

)
nonisolated

## [Parameters](https://developer.apple.com/documentation/avfoundation/avplayer/preroll(atrate:completionhandler:)\#parameters)

`rate`

The playback rate to use when determining how much data to load.

`completionHandler`

A block to execute when the player finishes the load attempt. This block takes a single Boolean parameter that contains [`true`](https://developer.apple.com/documentation/swift/true) if the data was loaded or [`false`](https://developer.apple.com/documentation/swift/false) if there was a problem. For example, the value might be [`false`](https://developer.apple.com/documentation/swift/false) if the preroll was interrupted by a time change or incompatible rate change.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/preroll(atrate:completionhandler:)\#Discussion)

This method loads data starting at the item’s current playback time. The current rate for the playback item should always be 0 prior to calling this method. After the method calls the completion handler, you can change the item’s playback rate to begin playback.

If the player object is not ready to play (its [`status`](https://developer.apple.com/documentation/avfoundation/avplayer/status-swift.property) property is not [`AVPlayer.Status.readyToPlay`](https://developer.apple.com/documentation/avfoundation/avplayer/status-swift.enum/readytoplay)), this method throws an exception.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/preroll(atrate:completionhandler:)\#see-also)

### [Synchronizing Multiple Players](https://developer.apple.com/documentation/avfoundation/avplayer/preroll(atrate:completionhandler:)\#Synchronizing-Multiple-Players)

[`func setRate(Float, time: CMTime, atHostTime: CMTime)`](https://developer.apple.com/documentation/avfoundation/avplayer/setrate(_:time:athosttime:))

Synchronizes the playback rate and time of the current item with an external source.

[`func cancelPendingPrerolls()`](https://developer.apple.com/documentation/avfoundation/avplayer/cancelpendingprerolls())

Cancels any pending preroll requests and invokes the corresponding completion handlers, if present.

[`var sourceClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avplayer/sourceclock)

A clock the player uses for item time bases.

[`var masterClock: CMClock?`](https://developer.apple.com/documentation/avfoundation/avplayer/masterclock)

The host clock for item time bases.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avplayer/addboundarytimeobserver(fortimes:queue:using:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayer](https://developer.apple.com/documentation/avfoundation/avplayer)
- addBoundaryTimeObserver(forTimes:queue:using:)

Instance Method

# addBoundaryTimeObserver(forTimes:queue:using:)

Requests the invocation of a block when specified times are traversed during normal playback.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

nonisolated
func addBoundaryTimeObserver(
forTimes times: [NSValue],
queue: dispatch_queue_t?,

## [Parameters](https://developer.apple.com/documentation/avfoundation/avplayer/addboundarytimeobserver(fortimes:queue:using:)\#parameters)

`times`

An array of `NSValue` objects containing [`CMTime`](https://developer.apple.com/documentation/CoreMedia/CMTime) values that represent the times at which to invoke the callback. The system raises an exception if you pass an empty array.

`queue`

A _serial_ queue onto which `block` should be enqueued. Passing a concurrent queue is not supported and will result in undefined behavior.

If you pass `nil`, the main queue is used.

`block`

The block to be invoked when any of the times in `times` is crossed during normal playback.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avplayer/addboundarytimeobserver(fortimes:queue:using:)\#return-value)

An opaque object that you pass as the argument to [`removeTimeObserver(_:)`](https://developer.apple.com/documentation/avfoundation/avplayer/removetimeobserver(_:)) to stop observation.

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avplayer/addboundarytimeobserver(fortimes:queue:using:)\#mentions)

[Monitoring playback progress in your app](https://developer.apple.com/documentation/avfoundation/monitoring-playback-progress-in-your-app)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayer/addboundarytimeobserver(fortimes:queue:using:)\#Discussion)

Boundary times are arbitrary points of interest you define within the media timeline. As these times are traversed during normal playback, the block you provide to this method will be invoked. You must maintain a strong reference to the returned value as long as you want the time observer to be invoked by the player. Each invocation of this method should be paired with a corresponding call to [`removeTimeObserver(_:)`](https://developer.apple.com/documentation/avfoundation/avplayer/removetimeobserver(_:)).

The player does not guarantee the callback block will always be invoked for each boundary time. If your times are very close together along the timeline (close enough that the execution of the block for one takes longer than the difference between them) or if a seek causes time to jump over one or more boundary times, time observation for any specific boundary time may not occur. The best practice is therefore to implement the callback block so it always performs its necessary calculations based solely on the player’s [`currentTime()`](https://developer.apple.com/documentation/avfoundation/avplayer/currenttime()).

The following example shows how you could define boundary times for each quarter of playback.

func addBoundaryTimeObserver() {
var times = [NSValue]()
// Set initial time to zero
var currentTime = CMTime.zero
// Divide the asset's duration into quarters.
let interval = CMTimeMultiplyByFloat64(asset.duration, multiplier: 0.25)

// Build boundary times at 25%, 50%, 75%, 100%
while currentTime < asset.duration {
currentTime = currentTime + interval
times.append(NSValue(time: currentTime))
}

// Add time observer. Observe boundary time changes on the main queue.
timeObserverToken = player.addBoundaryTimeObserver(forTimes: times,
queue: .main) { [weak self] in
// Update UI
}
}

- (void)addBoundaryTimeObserver {
NSMutableArray *times = [NSMutableArray array];

// Set initial time to zero
CMTime currentTime = kCMTimeZero;
// Get asset duration
CMTime assetDuration = self.asset.duration;
// Divide the asset duration into quarters
CMTime interval = CMTimeMultiplyByFloat64(assetDuration, 0.25);

// Build boundary times at 25%, 50%, 75%, 100%
while (CMTIME_COMPARE_INLINE(currentTime, <, assetDuration)) {
currentTime = CMTimeAdd(currentTime, interval);
[times addObject:[NSValue valueWithCMTime:currentTime]];
}
// Add time observer
self.timeObserverToken =
[self.player addBoundaryTimeObserverForTimes:times\
queue:dispatch_get_main_queue()\
usingBlock:^{\
// Use weak reference to self\
// Update user interface state\
}];
}

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayer/addboundarytimeobserver(fortimes:queue:using:)\#see-also)

### [Observing Playback Time](https://developer.apple.com/documentation/avfoundation/avplayer/addboundarytimeobserver(fortimes:queue:using:)\#Observing-Playback-Time)

Returns the current time of the current player item.

Requests the periodic invocation of a given block during play)

Cancels a previously registered periodic or boundary time observer.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- AVCaptureDevice.LensStabilizationStatus

Enumeration

# AVCaptureDevice.LensStabilizationStatus

Constants that indicate the status of optical image stabilization hardware during a bracketed photo capture.

enum LensStabilizationStatus

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus\#topics)

### [Lens Stabilization Values](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus\#Lens-Stabilization-Values)

[`case unsupported`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/unsupported)

Lens stabilization isn’t available on the device or device configuration that captured this photo.

[`case off`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/off)

Lens stabilization isn’t specified for this photo capture.

[`case active`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/active)

Lens stabilization was active for the full duration of the photo capture.

[`case outOfRange`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/outofrange)

Lens stabilization was enabled for the photo capture, but device motion or capture duration exceeded the stabilization module’s correction limits.

[`case unavailable`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/unavailable)

Lens stabilization was temporarily unavailable during the photo capture.

### [Initializers](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus\#Initializers)

[`init?(rawValue: Int)`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/init(rawvalue:))

## [Relationships](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus\#relationships)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus\#conforms-to)

- [`BitwiseCopyable`](https://developer.apple.com/documentation/Swift/BitwiseCopyable)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`RawRepresentable`](https://developer.apple.com/documentation/Swift/RawRepresentable)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

---

# https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation(with:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhoto](https://developer.apple.com/documentation/avfoundation/avcapturephoto)
- fileDataRepresentation(with:)

Instance Method

# fileDataRepresentation(with:)

Gets a customized representation of the photo data.

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation(with:)\#parameters)

`customizer`

An object that customizes the returned metadata, image thumbnail, or depth data.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation(with:)\#return-value)

A data representation of the photo.

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation(with:)\#mentions)

[Capturing Photos in RAW and Apple ProRAW Formats](https://developer.apple.com/documentation/avfoundation/capturing-photos-in-raw-and-apple-proraw-formats)

[Configuring Camera Capture to Collect a Portrait Effects Matte](https://developer.apple.com/documentation/avfoundation/configuring-camera-capture-to-collect-a-portrait-effects-matte)

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation(with:)\#see-also)

### [Packaging Data for File Output](https://developer.apple.com/documentation/avfoundation/avcapturephoto/filedatarepresentation(with:)\#Packaging-Data-for-File-Output)

[`protocol AVCapturePhotoFileDataRepresentationCustomizer`](https://developer.apple.com/documentation/avfoundation/avcapturephotofiledatarepresentationcustomizer)

A protocol that defines the methods to implement to customize the packaging of photo data.

Generates and returns a flat data representation of the photo and its attachments.

Extracts and returns the captured photo’s primary image as a Core Graphics image object.

Extracts and returns the captured photo’s preview image as a Core Graphics image object.

Generates and returns a flat data representation of the photo using the specified replacements for some or all of its attachments.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/audiosamplepacketrefreshcount

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleCursorAudioDependencyInfo](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo)
- audioSamplePacketRefreshCount

Instance Property

# audioSamplePacketRefreshCount

The number of samples, starting at the current sample, that must be fed to the decoder to achieve full decoder refresh.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

var audioSamplePacketRefreshCount: Int

## [Discussion](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/audiosamplepacketrefreshcount\#Discussion)

The value of [`audioSampleIsIndependentlyDecodable`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/audiosampleisindependentlydecodable) must be [`true`](https://developer.apple.com/documentation/swift/true) for this value to take effect.

The value of this property is `0` for Immediate Playout Frames (IPFs).

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/audiosamplepacketrefreshcount\#see-also)

### [Querying Independent Decodability](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/audiosamplepacketrefreshcount\#Querying-Independent-Decodability)

[`var audioSampleIsIndependentlyDecodable: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursoraudiodependencyinfo/audiosampleisindependentlydecodable)

A Boolean value indicating whether the sample is independently decodable.

---

# https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/indicateshorizontalfieldofview

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMediaCharacteristic](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic)
- indicatesHorizontalFieldOfView

Type Property

# indicatesHorizontalFieldOfView

A media characteristic that indicates the video track carries information related to the horizontal field of view.

static let indicatesHorizontalFieldOfView: AVMediaCharacteristic

## [Discussion](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/indicateshorizontalfieldofview\#Discussion)

This media characteristic is present when the [`CMVideoFormatDescription`](https://developer.apple.com/documentation/CoreMedia/CMVideoFormatDescription) includes a [`kCMFormatDescriptionExtension_HorizontalFieldOfView`](https://developer.apple.com/documentation/CoreMedia/kCMFormatDescriptionExtension_HorizontalFieldOfView) extension. This is not an indication that the field of view is expanded beyond or more narrow than typical horizontal fields of view.

The value of this characteristic is `public.indicates-horizontal-field-of-view`.

## [See Also](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/indicateshorizontalfieldofview\#see-also)

### [Visual](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/indicateshorizontalfieldofview\#Visual)

[`static let visual: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/visual)

A media characteristic that indicates that a track or media selection option includes visual content.

[`static let containsAlphaChannel: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/containsalphachannel)

A media characteristic that indicates that a track contains an alpha channel.

[`static let containsHDRVideo: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/containshdrvideo)

A media characteristic that indicates that a track contains HDR video.

[`static let frameBased: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/framebased)

A media characteristic that indicates that a track or media selection option includes frame-based content.

[`static let usesWideGamutColorSpace: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/useswidegamutcolorspace)

A media characteristic that indicates that a track uses a wide-gamut color space.

[`static let containsStereoMultiviewVideo: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/containsstereomultiviewvideo)

A media characteristic that indicates that a track contains stereoscopic video captured in a multiview compression format.

[`static let carriesVideoStereoMetadata: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/carriesvideostereometadata)

A media characteristic that indicates that the stereoscopic video track carries additional information related to the stereoscopic video.

---

# https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isauxiliarycontent

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMediaCharacteristic](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic)
- isAuxiliaryContent

Type Property

# isAuxiliaryContent

A media characteristic that indicates a track or media selection option includes content its author indicates is auxiliary to the asset’s presentation.

static let isAuxiliaryContent: AVMediaCharacteristic

## [Discussion](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isauxiliarycontent\#Discussion)

An example of auxiliary content is audio commentary about the presentation.

The value of this characteristic is `public.auxiliary-content`.

For QuickTime movies and `.m4v` files, a media option has this characteristic only if the media’s author tags it that way, or if it belongs to an alternate track group that excludes its associated track from autoselection.

## [See Also](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isauxiliarycontent\#see-also)

### [Content](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isauxiliarycontent\#Content)

[`static let isOriginalContent: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isoriginalcontent)

A media characteristic that indicates that a track or media selection option contains original content.

[`static let isMainProgramContent: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/ismainprogramcontent)

A media characteristic that indicates a track or media selection option includes content its author indicates is essential to the asset’s presentation.

---

# https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsdisplaysleepduringvideoplayback

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleBufferDisplayLayer](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer)
- preventsDisplaySleepDuringVideoPlayback

Instance Property

# preventsDisplaySleepDuringVideoPlayback

A Boolean value that indicates whether the layer prevents the system from sleeping during video playback.

var preventsDisplaySleepDuringVideoPlayback: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsdisplaysleepduringvideoplayback\#Discussion)

Setting this property to [`false`](https://developer.apple.com/documentation/swift/false) doesn’t force the display to sleep; it only stops preventing display sleep. Other apps or frameworks within your app may still be preventing display sleep for various reasons.

The default value is [`true`](https://developer.apple.com/documentation/swift/true) in iOS, tvOS, and Mac Catalyst. The default value in macOS is [`false`](https://developer.apple.com/documentation/swift/false).

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsdisplaysleepduringvideoplayback\#see-also)

### [Preventing backgrounding](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsdisplaysleepduringvideoplayback\#Preventing-backgrounding)

[`var preventsAutomaticBackgroundingDuringVideoPlayback: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsautomaticbackgroundingduringvideoplayback)

A Boolean value that indicates whether video playback prevents the system from automatically backgrounding an app.

---

# https://developer.apple.com/documentation/avfoundation/avmetricevent/date

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetricEvent](https://developer.apple.com/documentation/avfoundation/avmetricevent)
- date

Instance Property

# date

var date: Date { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetricevent/date\#see-also)

### [Inspecting an event](https://developer.apple.com/documentation/avfoundation/avmetricevent/date\#Inspecting-an-event)

[`var mediaTime: CMTime`](https://developer.apple.com/documentation/avfoundation/avmetricevent/mediatime)

[`var sessionID: String?`](https://developer.apple.com/documentation/avfoundation/avmetricevent/sessionid)

---

# https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isoriginalcontent

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMediaCharacteristic](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic)
- isOriginalContent

Type Property

# isOriginalContent

A media characteristic that indicates that a track or media selection option contains original content.

static let isOriginalContent: AVMediaCharacteristic

## [Discussion](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isoriginalcontent\#Discussion)

This characteristic differentiates original content from supplementary or derivative content, such as a language translation.

## [See Also](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isoriginalcontent\#see-also)

### [Content](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isoriginalcontent\#Content)

[`static let isMainProgramContent: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/ismainprogramcontent)

A media characteristic that indicates a track or media selection option includes content its author indicates is essential to the asset’s presentation.

[`static let isAuxiliaryContent: AVMediaCharacteristic`](https://developer.apple.com/documentation/avfoundation/avmediacharacteristic/isauxiliarycontent)

A media characteristic that indicates a track or media selection option includes content its author indicates is auxiliary to the asset’s presentation.

---

# https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager/setstoragemanagementpolicy(_:for:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetDownloadStorageManager](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager)
- setStorageManagementPolicy(\_:for:)

Instance Method

# setStorageManagementPolicy(\_:for:)

Sets a storage policy for the downloaded asset.

func setStorageManagementPolicy(
_ storageManagementPolicy: AVAssetDownloadStorageManagementPolicy,
for downloadStorageURL: URL
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager/setstoragemanagementpolicy(_:for:)\#parameters)

`storageManagementPolicy`

The policy to set for the downloaded asset.

`downloadStorageURL`

The location of the downloaded asset.

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager/setstoragemanagementpolicy(_:for:)\#see-also)

### [Setting the Storage Policy](https://developer.apple.com/documentation/avfoundation/avassetdownloadstoragemanager/setstoragemanagementpolicy(_:for:)\#Setting-the-Storage-Policy)

Returns the storage management policy for a downloaded asset.

---

# https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty/sidecarurl

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPartialAsyncProperty](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty)
- sidecarURL Beta

Type Property

# sidecarURL

The sidecar URL used by the MediaExtension. The sidecar URL is returned only if the MediaExtension format reader supports sidecar files, and implements this property \[MEFileInfo setSidecarFilename:\]. Will return nil otherwise.

Available when `Root` inherits `AVURLAsset`.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avcomposition-async-properties

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Media assets](https://developer.apple.com/documentation/avfoundation/media-assets)
- [AVPartialAsyncProperty](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty)
- AVComposition

API Collection

# AVComposition

Asynchronous properties for compositions.

## [Topics](https://developer.apple.com/documentation/avfoundation/avcomposition-async-properties\#topics)

### [Loading Tracks](https://developer.apple.com/documentation/avfoundation/avcomposition-async-properties\#Loading-Tracks)

The tracks that a composition contains.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcomposition-async-properties\#see-also)

### [Loading Properties](https://developer.apple.com/documentation/avfoundation/avcomposition-async-properties\#Loading-Properties)

Asynchronous properties for assets.

Asynchronous properties for asset tracks.

Asynchronous properties for URL assets.

Asynchronous properties for fragmented assets.

Asynchronous properties for metadata items.

Asynchronous properties for mutable compositions.

Asynchronous properties for movies.

Asynchronous properties for mutable movies.

Asynchronous properties for fragmented movies.

---

# https://developer.apple.com/documentation/avfoundation/avfiletype/mov

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVFileType](https://developer.apple.com/documentation/avfoundation/avfiletype)
- mov

Type Property

# mov

The UTI for the QuickTime movie file format.

static let mov: AVFileType

## [Discussion](https://developer.apple.com/documentation/avfoundation/avfiletype/mov\#Discussion)

The value of this UTI is `com.apple.quicktime-movie`. Files of this type have a `.mov` or `.qt` extension.

## [See Also](https://developer.apple.com/documentation/avfoundation/avfiletype/mov\#see-also)

### [File Types](https://developer.apple.com/documentation/avfoundation/avfiletype/mov\#File-Types)

[`static let ac3: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/ac3)

The UTI for the AC3 audio file format.

[`static let aifc: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/aifc)

The UTI for the AIFC audio file format.

[`static let aiff: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/aiff)

The UTI for the AIFF audio file format.

[`static let AHAP: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/ahap)

The UTI for the Apple Haptics Audio Pattern file format.

[`static let amr: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/amr)

The UTI for the adaptive multirate audio file format.

[`static let appleiTT: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/appleitt)

The UTI for the Apple iTT caption file format.

[`static let au: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/au)

The UTI for the Sun/NeXT audio file format.

[`static let avci: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/avci)

The UTI for the high-efficiency image file format that contains H.264 compressed images.

[`static let caf: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/caf)

The UTI for the Core Audio Format.

[`static let dng: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/dng)

The UTI for the Adobe Digital Negative file format.

[`static let eac3: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/eac3)

The UTI for the enhanced AC3 audio file format.

[`static let heic: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/heic)

The UTI for the high-efficiency image file format that contains HEVC compressed images.

[`static let heif: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/heif)

The UTI for the high-efficiency image file format that contains compressed images from any codec.

[`static let jpg: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/jpg)

The UTI for the JPEG (JFIF) format.

[`static let m4a: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/m4a)

The UTI for the Apple m4a audio file format.

---

# https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/pixelsize

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCameraCalibrationData](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata)
- pixelSize

Instance Property

# pixelSize

The size, in millimeters, of one image pixel.

var pixelSize: Float { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/pixelsize\#see-also)

### [Mapping Pixels to Scene Geometry](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/pixelsize\#Mapping-Pixels-to-Scene-Geometry)

[`var intrinsicMatrix: matrix_float3x3`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/intrinsicmatrix)

A matrix that relates a camera’s internal properties to an ideal pinhole-camera model.

[`var intrinsicMatrixReferenceDimensions: CGSize`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/intrinsicmatrixreferencedimensions)

The image dimensions to which the camera’s intrinsic matrix values are relative.

[`var extrinsicMatrix: matrix_float4x3`](https://developer.apple.com/documentation/avfoundation/avcameracalibrationdata/extrinsicmatrix)

A matrix relating a camera’s position and orientation to a world or scene coordinate system.

---

# https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch/makedataready(completionhandler:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleBufferGeneratorBatch](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch)
- makeDataReady(completionHandler:)

Instance Method

# makeDataReady(completionHandler:)

Loads sample data asynchronously for all sample buffers within a batch.

func makeDataReady() async throws

## [Parameters](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch/makedataready(completionhandler:)\#parameters)

`completionHandler`

A callback the system invokes once when all sample buffers in the batch are data-ready, or when an error occurs.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avsamplebuffergeneratorbatch/makedataready(completionhandler:)\#Discussion)

Calling this method more than once on a batch generates an exception.

---

# https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVMetricHLSMediaSegmentRequestEvent

Class

# AVMetricHLSMediaSegmentRequestEvent

An event that represents a live streaming media segment resource request.

class AVMetricHLSMediaSegmentRequestEvent

## [Topics](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent\#topics)

### [Inspecting the event](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent\#Inspecting-the-event)

[`var byteRange: NSRange`](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent/byterange)

[`var isMapSegment: Bool`](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent/ismapsegment)

[`var mediaResourceRequestEvent: AVMetricMediaResourceRequestEvent?`](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent/mediaresourcerequestevent)

[`var mediaType: AVMediaType`](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent/mediatype)

[`var url: URL?`](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent/url)

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent\#Instance-Properties)

[`var indexFileURL: URL`](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent/indexfileurl)

## [Relationships](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent\#inherits-from)

- [`AVMetricEvent`](https://developer.apple.com/documentation/avfoundation/avmetricevent)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSCoding`](https://developer.apple.com/documentation/Foundation/NSCoding)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`NSSecureCoding`](https://developer.apple.com/documentation/Foundation/NSSecureCoding)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent\#see-also)

### [HTTP Live Streaming](https://developer.apple.com/documentation/avfoundation/avmetrichlsmediasegmentrequestevent\#HTTP-Live-Streaming)

[`class AVMetricMediaResourceRequestEvent`](https://developer.apple.com/documentation/avfoundation/avmetricmediaresourcerequestevent)

An event that represents a media resource request.

[`class AVMetricContentKeyRequestEvent`](https://developer.apple.com/documentation/avfoundation/avmetriccontentkeyrequestevent)

An event that represents a live streaming content key resource request.

[`class AVMetricHLSPlaylistRequestEvent`](https://developer.apple.com/documentation/avfoundation/avmetrichlsplaylistrequestevent)

An event that represents a live streaming playlist resource request.

[`class AVMetricPlayerItemVariantSwitchStartEvent`](https://developer.apple.com/documentation/avfoundation/avmetricplayeritemvariantswitchstartevent)

An event that represents when the player attempts a variant switch.

[`class AVMetricPlayerItemVariantSwitchEvent`](https://developer.apple.com/documentation/avfoundation/avmetricplayeritemvariantswitchevent)

An event that represents when the player completes a variant switch.

---

# https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Media playback](https://developer.apple.com/documentation/avfoundation/media-playback)
- Controlling the transport behavior of a player

Article

# Controlling the transport behavior of a player

Play, pause, and seek through a media presentation.

## [Overview](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player\#overview)

AVFoundation provides comprehensive support for playing media assets, including local and remote file-based media and also media streamed with HTTP Live Streaming. The framework models its media assets using the [`AVAsset`](https://developer.apple.com/documentation/avfoundation/avasset) class, which provides a consistent interface to load and inspect your media, regardless of its type or location. Use an [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) object to play media assets in the form of [`AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem) objects, which model the dynamic state of an asset such as its [`currentTime()`](https://developer.apple.com/documentation/avfoundation/avplayeritem/currenttime()).

Understanding how to effectively use [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) is essential for anyone building a custom player UI or otherwise requiring programmatic control of playback.

### [Observe playback readiness](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player\#Observe-playback-readiness)

When you create a player item, it starts with a status of [`AVPlayerItem.Status.unknown`](https://developer.apple.com/documentation/avfoundation/avplayeritem/status-swift.enum/unknown), which means the system hasn’t attempted to load its media for playback. Only when you associate the item with an [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) object does the system begin loading an asset’s media.

To know when the player item is ready for playback, observe the value of its [`status`](https://developer.apple.com/documentation/avfoundation/avplayeritem/status-swift.property) property. Add this observation before you call the player’s [`replaceCurrentItem(with:)`](https://developer.apple.com/documentation/avfoundation/avplayer/replacecurrentitem(with:)) method, because associating the player item with a player is the system’s cue to load the item’s media:

func playMedia(at url: URL) {
let asset = AVAsset(url: url)
let playerItem = AVPlayerItem(
asset: asset,
automaticallyLoadedAssetKeys: [.tracks, .duration, .commonMetadata]
)
// Register to observe the status property before associating with player.
playerItem.publisher(for: \.status)
.removeDuplicates()
.receive(on: DispatchQueue.main)
.sink { [weak self] status in
guard let self else { return }
switch status {
case .readyToPlay:
// Ready to play. Present playback UI.
case .failed:
// A failure while loading media occurred.
default:
break
}
}
.store(in: &subscriptions)

// Set the item as the player's current item.
player.replaceCurrentItem(with: playerItem)
}

When the player item reaches a [`AVPlayerItem.Status.readyToPlay`](https://developer.apple.com/documentation/avfoundation/avplayeritem/status-swift.enum/readytoplay) state, present or enable your playback UI. Alternatively, if a failure occurs, show the appropriate status in the player.

### [Control the playback rate](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player\#Control-the-playback-rate)

A player provides the [`play()`](https://developer.apple.com/documentation/avfoundation/avplayer/play()) and [`pause()`](https://developer.apple.com/documentation/avfoundation/avplayer/pause()) methods as its primary means of controlling its playback rate. When a player item is ready for playback, call the player’s [`play()`](https://developer.apple.com/documentation/avfoundation/avplayer/play()) method to request that playback begins at the [`defaultRate`](https://developer.apple.com/documentation/avfoundation/avplayer/defaultrate), which has an initial value of `1.0` (the natural rate). By default, a player automatically waits to start playback until it has sufficient media data available to minimize stalling. You can determine whether a player is in a paused, waiting to play, or playing state by observing its [`timeControlStatus`](https://developer.apple.com/documentation/avfoundation/avplayer/timecontrolstatus-swift.property) value:

@Published var isPlaying = false

private func observePlayingState() {
player.publisher(for: \.timeControlStatus)
.receive(on: DispatchQueue.main)
.map { $0 == .playing }
.assign(to: &$isPlaying)
}

Observe changes to the [`rate`](https://developer.apple.com/documentation/avfoundation/avplayer/rate) property by observing notifications of type [`rateDidChangeNotification`](https://developer.apple.com/documentation/avfoundation/avplayer/ratedidchangenotification). Observing this notification is similar to key-value observing the [`rate`](https://developer.apple.com/documentation/avfoundation/avplayer/rate) property, but provides additional information about the reason for the rate change. Retrieve the reason from the notification’s [`userInfo`](https://developer.apple.com/documentation/Foundation/Notification/userInfo) dictionary using the [`rateDidChangeReasonKey`](https://developer.apple.com/documentation/avfoundation/avplayer/ratedidchangereasonkey) constant:

// Observe changes to the playback rate asynchronously.
private func observeRateChanges() async {
let name = AVPlayer.rateDidChangeNotification
for await notification in NotificationCenter.default.notifications(named: name) {
guard let reason = notification.userInfo?[AVPlayer.rateDidChangeReasonKey] as? AVPlayer.RateDidChangeReason else {
continue
}
switch reason {
case .appBackgrounded:
// The app transitioned to the background.
case .audioSessionInterrupted:
// The system interrupts the app’s audio session.
case .setRateCalled:
// The app set the player’s rate.
case .setRateFailed:
// An attempt to change the player’s rate failed.
default:
break
}
}
}

### [Seek through the media timeline](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player\#Seek-through-the-media-timeline)

You can seek through a media timeline in several ways using the methods of [`AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer) and [`AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem). The most common way is to use the player’s [`seek(to:)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:)-87h2r) method, passing it a destination [`CMTime`](https://developer.apple.com/documentation/CoreMedia/CMTime) value. Call this method in an asynchronous context:

// Handle time update request from user interface.
func seek(to timeInterval: TimeInterval) async {
// Create a CMTime value for the passed in time interval.
let time = CMTime(seconds: timeInterval, preferredTimescale: 600)
await avPlayer.seek(to: time)
}

You can call this method a single time to seek to the location, but you can also call it continuously such as when you use a [`Slider`](https://developer.apple.com/documentation/SwiftUI/Slider) view.

The [`seek(to:)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:)-87h2r) method is a convenient way to quickly seek through your presentation, but it’s tuned for speed rather than precision. This means the actual time to which the player seeks may differ slightly from the time you request. If you need to implement precise seeking behavior, use the [`seek(to:toleranceBefore:toleranceAfter:)`](https://developer.apple.com/documentation/avfoundation/avplayer/seek(to:tolerancebefore:toleranceafter:)) method, which lets you indicate the tolerated amount of deviation from your target time (before and after). For example, if you need to provide sample-accurate seeking behavior, specify tolerance values of zero:

// Seek precisely to the specified time.
await avPlayer.seek(to: time, toleranceBefore: .zero, toleranceAfter: .zero)

## [See Also](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player\#see-also)

### [Playback control](https://developer.apple.com/documentation/avfoundation/controlling-the-transport-behavior-of-a-player\#Playback-control)

[Observing playback state in SwiftUI](https://developer.apple.com/documentation/avfoundation/observing-playback-state-in-swiftui)

Keep your user interface in sync with state changes from playback objects.

[Creating a seamless multiview playback experience](https://developer.apple.com/documentation/avfoundation/creating-a-seamless-multiview-playback-experience)

Build advanced multiview playback experiences with the AVFoundation and AVRouting frameworks.

[`class AVPlayer`](https://developer.apple.com/documentation/avfoundation/avplayer)

An object that provides the interface to control the player’s transport behavior.

[`class AVPlayerItem`](https://developer.apple.com/documentation/avfoundation/avplayeritem)

An object that models the timing and presentation state of an asset during playback.

[`class AVPlayerItemTrack`](https://developer.apple.com/documentation/avfoundation/avplayeritemtrack)

An object that represents the presentation state of an asset track during playback.

[`class AVQueuePlayer`](https://developer.apple.com/documentation/avfoundation/avqueueplayer)

An object that plays a sequence of player items.

[`class AVPlayerLooper`](https://developer.apple.com/documentation/avfoundation/avplayerlooper)

An object that loops media content using a queue player.

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasredundantcoding

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleCursorDependencyInfo](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo)
- sampleIndicatesWhetherItHasRedundantCoding

Instance Property

# sampleIndicatesWhetherItHasRedundantCoding

A Boolean value that determines whether the sample indicates that it has redundant coding.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

var sampleIndicatesWhetherItHasRedundantCoding: ObjCBool

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasredundantcoding\#see-also)

### [Dependency Information](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasredundantcoding\#Dependency-Information)

[`var sampleIndicatesWhetherItHasDependentSamples: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasdependentsamples)

A Boolean value that determines whether the sample indicates if other samples depend on it.

[`var sampleHasDependentSamples: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/samplehasdependentsamples)

A Boolean value that determines whether the sample has dependent samples.

[`var sampleIndicatesWhetherItDependsOnOthers: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetheritdependsonothers)

A Boolean value that determines whether the sample indicates that it depends on other samples.

[`var sampleDependsOnOthers: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampledependsonothers)

A Boolean value that determines whether the sample depends on other samples.

[`var sampleHasRedundantCoding: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/samplehasredundantcoding)

A Boolean value that determines whether the sample has redundant coding.

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursor/comparepositionindecodeorder(withpositionof:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleCursor](https://developer.apple.com/documentation/avfoundation/avsamplecursor)
- comparePositionInDecodeOrder(withPositionOf:)

Instance Method

# comparePositionInDecodeOrder(withPositionOf:)

Compares the relative positions of two sample cursors and returns their relative positions.

## [Parameters](https://developer.apple.com/documentation/avfoundation/avsamplecursor/comparepositionindecodeorder(withpositionof:)\#parameters)

`cursor`

An instance of `AVSampleCursor` with which to compare positions.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avsamplecursor/comparepositionindecodeorder(withpositionof:)\#return-value)

Returns a comparison result that indicates of this cursor points at a sample before, the same as, or after the sample pointed to by the specified cursor.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avsamplecursor/comparepositionindecodeorder(withpositionof:)\#Discussion)

Undefined results occur if this cursor and the passed in cursor reference different sequences of samples, such as when they’re created by different instances of [`AVAssetTrack`](https://developer.apple.com/documentation/avfoundation/avassettrack).

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetResourceLoadingRequest](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest)
- finishLoading(with:)

Instance Method

# finishLoading(with:)

Causes the receiver to handle the failure to load a resource for which a resource loader’s delegate took responsibility.

func finishLoading(with error: (any Error)?)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:)\#parameters)

`error`

An error object indicating the reason for the failure.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:)\#Discussion)

When a resource loader’s delegate takes responsibility for loading a resource, it calls this method when a failure occurred when loading the resource. This method marks the loading request as finished and notifies the resource loader object that the resource could not be loaded.

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:)\#see-also)

### [Reporting the Result of the Request](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:)\#Reporting-the-Result-of-the-Request)

[`var response: URLResponse?`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/response)

The URL response for the loading request.

[`func finishLoading()`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading())

Causes the receiver to treat the processing of the request as complete.

[`var isCancelled: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/iscancelled)

A Boolean value that indicates whether the request has been cancelled.

[`var isFinished: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/isfinished)

A Boolean value that indicates whether loading of the resource has finished.

[`func finishLoading(with: URLResponse?, data: Data?, redirect: URLRequest?)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:data:redirect:))

Causes the receiver to finish loading a resource for which a resource loader’s delegate took responsibility .

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- AVPlayerItemLegibleOutput

Class

# AVPlayerItemLegibleOutput

An object that vends attributed strings for media with a legible characteristic.

class AVPlayerItemLegibleOutput

## [Topics](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#topics)

### [Creating a Legible Output](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#Creating-a-Legible-Output)

[`init(mediaSubtypesForNativeRepresentation: [NSNumber])`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput/init(mediasubtypesfornativerepresentation:))

Creates an initialized legible-output object.

### [Configuring Text Styling](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#Configuring-Text-Styling)

[`var textStylingResolution: AVPlayerItemLegibleOutput.TextStylingResolution`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput/textstylingresolution-swift.property)

A string identifier indicating the degree of text styling to be applied to attributed strings vended by the object.

[`struct TextStylingResolution`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput/textstylingresolution-swift.struct)

A text styling resolution.

### [Configuring the Delegate](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#Configuring-the-Delegate)

[`var delegate: (any AVPlayerItemLegibleOutputPushDelegate)?`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput/delegate)

The delegate of the output class.

[`func setDelegate((any AVPlayerItemLegibleOutputPushDelegate)?, queue: dispatch_queue_t?)`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput/setdelegate(_:queue:))

Sets the receiver’s delegate and a dispatch queue on which the delegate is called.

[`protocol AVPlayerItemLegibleOutputPushDelegate`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutputpushdelegate)

Methods you can implement to provide alternative attributed-string output.

[`var advanceIntervalForDelegateInvocation: TimeInterval`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput/advanceintervalfordelegateinvocation)

The time interval, in seconds, that a player item legible output object messages its delegate earlier than normal.

[`var delegateQueue: dispatch_queue_t?`](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput/delegatequeue)

The dispatch queue on which the delegate is called.

## [Relationships](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#relationships)

### [Inherits From](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#inherits-from)

- [`AVPlayerItemOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemoutput)

### [Conforms To](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#conforms-to)

- [`CVarArg`](https://developer.apple.com/documentation/Swift/CVarArg)
- [`CustomDebugStringConvertible`](https://developer.apple.com/documentation/Swift/CustomDebugStringConvertible)
- [`CustomStringConvertible`](https://developer.apple.com/documentation/Swift/CustomStringConvertible)
- [`Equatable`](https://developer.apple.com/documentation/Swift/Equatable)
- [`Hashable`](https://developer.apple.com/documentation/Swift/Hashable)
- [`NSObjectProtocol`](https://developer.apple.com/documentation/ObjectiveC/NSObjectProtocol)
- [`Sendable`](https://developer.apple.com/documentation/Swift/Sendable)
- [`SendableMetatype`](https://developer.apple.com/documentation/Swift/SendableMetatype)

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#see-also)

### [Media output](https://developer.apple.com/documentation/avfoundation/avplayeritemlegibleoutput\#Media-output)

[`class AVPlayerVideoOutput`](https://developer.apple.com/documentation/avfoundation/avplayervideooutput)

An object that receives video data from a player object.

[`class AVVideoOutputSpecification`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification)

An object that specifies the pixel buffer attributes and tag collections handled by a player video output.

[`class AVPlayerItemOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemoutput)

An abstract class that defines the common interface to output media data from a player item.

[`class AVPlayerItemVideoOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemvideooutput)

An object that outputs video frames from a player item.

[`class AVPlayerItemRenderedLegibleOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemrenderedlegibleoutput)

A player item output that vends media with a legible characteristic as rendered pixel buffers.

[`class AVRenderedCaptionImage`](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage)

An object that provides a rendered pixel buffer and its position in pixels.

[`class AVPlayerItemMetadataOutput`](https://developer.apple.com/documentation/avfoundation/avplayeritemmetadataoutput)

An object that vends collections of metadata items that a player item’s tracks carry.

[`protocol AVPlayerItemOutputPushDelegate`](https://developer.apple.com/documentation/avfoundation/avplayeritemoutputpushdelegate)

A protocol that defines the methods to implement to respond to changes in the media data sequence.

---

# https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsautomaticbackgroundingduringvideoplayback

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleBufferDisplayLayer](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer)
- preventsAutomaticBackgroundingDuringVideoPlayback

Instance Property

# preventsAutomaticBackgroundingDuringVideoPlayback

A Boolean value that indicates whether video playback prevents the system from automatically backgrounding an app.

var preventsAutomaticBackgroundingDuringVideoPlayback: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsautomaticbackgroundingduringvideoplayback\#Discussion)

The default value is [`true`](https://developer.apple.com/documentation/swift/true), which indicates the system doesn’t automatically background an app while playing video. The value of this property doesn’t prevent the user from backgrounding an app.

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsautomaticbackgroundingduringvideoplayback\#see-also)

### [Preventing backgrounding](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsautomaticbackgroundingduringvideoplayback\#Preventing-backgrounding)

[`var preventsDisplaySleepDuringVideoPlayback: Bool`](https://developer.apple.com/documentation/avfoundation/avsamplebufferdisplaylayer/preventsdisplaysleepduringvideoplayback)

A Boolean value that indicates whether the layer prevents the system from sleeping during video playback.

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampledependencyattachments

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleCursor](https://developer.apple.com/documentation/avfoundation/avsamplecursor)
- currentSampleDependencyAttachments

Instance Property

# currentSampleDependencyAttachments

A dictionary of dependency-related sample buffer attachments.

var currentSampleDependencyAttachments: [AnyHashable : Any]? { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampledependencyattachments\#see-also)

### [Getting Sample Information](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampledependencyattachments\#Getting-Sample-Information)

[`var currentChunkInfo: AVSampleCursorChunkInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentchunkinfo)

A value that provides information about the chunk of samples to which the current sample belongs.

[`struct AVSampleCursorChunkInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorchunkinfo)

A value that provides information about a chunk of media samples.

[`var currentChunkStorageRange: AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentchunkstoragerange)

The sample range in the storage container to load together with the current sample as a chunk.

[`struct AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursorstoragerange)

A structure that indicates the offset and length of storage for a media sample or its chunk.

[`var currentChunkStorageURL: URL?`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentchunkstorageurl)

The URL of the storage container of the current sample and other samples to load in the same operation as a chunk.

[`var currentSampleDependencyInfo: AVSampleCursorDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampledependencyinfo)

The dependency information that describes relationships between a media sample and other media samples in the same sample sequence.

[`struct AVSampleCursorDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo)

A value for describing dependencies between a media sample and other media samples in the same sample sequence.

[`var currentSampleDuration: CMTime`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampleduration)

The decode duration of the sample at the cursor’s current position.

[`var currentSampleIndexInChunk: Int64`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampleindexinchunk)

The index of the current sample within the chunk to which it belongs.

[`var currentSampleStorageRange: AVSampleCursorStorageRange`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsamplestoragerange)

The offset and length of the current sample in the current chunk storage URL.

[`var currentSampleSyncInfo: AVSampleCursorSyncInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsamplesyncinfo)

The synchronization information for the current sample for consideration when resynchronizing a decoder.

[`struct AVSampleCursorSyncInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursorsyncinfo)

A structure that describes the attributes of media samples to consider when resynchronizing a decoder.

Returns the format description of the sample at the cursor’s current position.

[`var currentSampleAudioDependencyInfo: AVSampleCursorAudioDependencyInfo`](https://developer.apple.com/documentation/avfoundation/avsamplecursor/currentsampleaudiodependencyinfo)

The independent decodability information for the audio sample.

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursor/step(bydecodetime:waspinned:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleCursor](https://developer.apple.com/documentation/avfoundation/avsamplecursor)
- step(byDecodeTime:wasPinned:)

Instance Method

# step(byDecodeTime:wasPinned:)

Moves the cursor by a given delta time on the decode timeline.

func step(
byDecodeTime deltaDecodeTime: CMTime,

## [Parameters](https://developer.apple.com/documentation/avfoundation/avsamplecursor/step(bydecodetime:waspinned:)\#parameters)

`deltaDecodeTime`

The amount of time to move in the decode timeline.

`outWasPinned`

The system sets the value of this pointer to [`true`](https://developer.apple.com/documentation/swift/true) if the cursor reaches the beginning or the end of the sample sequence before it reaches the requested time. You may specify `nil` if you’re not interested in this information.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avsamplecursor/step(bydecodetime:waspinned:)\#return-value)

The amount of time the cursor was moved along the decode timeline. Because sample cursors snap to sample boundaries when stepped, this value may not be equal to the specified time delta even if the cursor wasn’t pinned.

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursor/step(bydecodetime:waspinned:)\#see-also)

### [Navigating Samples](https://developer.apple.com/documentation/avfoundation/avsamplecursor/step(bydecodetime:waspinned:)\#Navigating-Samples)

Moves the cursor by a given delta time on the presentation timeline.

Moves the cursor a given number of samples in decode order.

Moves the cursor a given number of samples in presentation order.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddinput(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- canAddInput(\_:)

Instance Method

# canAddInput(\_:)

Determines whether you can add an input to a session.

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddinput(_:)\#parameters)

`input`

An input to add to the session.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddinput(_:)\#return-value)

[`true`](https://developer.apple.com/documentation/swift/true) if you can add the input to the session; otherwise, [`false`](https://developer.apple.com/documentation/swift/false).

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddinput(_:)\#Discussion)

This method returns [`false`](https://developer.apple.com/documentation/swift/false) if you can’t add an input to a capture session. This occurs, for example, if you attempt to add the input to a session twice, or if the input already belongs to another capture session.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddinput(_:)\#see-also)

### [Configuring inputs](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddinput(_:)\#Configuring-inputs)

[`var inputs: [AVCaptureInput]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/inputs)

The inputs that provide media data to a capture session.

[`func addInput(AVCaptureInput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addinput(_:))

Adds a capture input to the session.

[`func removeInput(AVCaptureInput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeinput(_:))

Removes an input from the session.

---

# https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/audiotimepitchalgorithm

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMutableAudioMixInputParameters](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters)
- audioTimePitchAlgorithm

Instance Property

# audioTimePitchAlgorithm

The processing algorithm used to manage audio pitch for scaled audio edits.

var audioTimePitchAlgorithm: AVAudioTimePitchAlgorithm? { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/audiotimepitchalgorithm\#Discussion)

The supported constants are defined in Time Pitch Algorithm Settings. An [`invalidArgumentException`](https://developer.apple.com/documentation/Foundation/NSExceptionName/invalidArgumentException) is raised if this property is set to a value other than the defined constants.

## [See Also](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/audiotimepitchalgorithm\#see-also)

### [Time Pitch Settings](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters/audiotimepitchalgorithm\#Time-Pitch-Settings)

[`struct AVAudioTimePitchAlgorithm`](https://developer.apple.com/documentation/avfoundation/avaudiotimepitchalgorithm)

An algorithm used to set the audio pitch as the rate changes.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/removeoutput(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- removeOutput(\_:)

Instance Method

# removeOutput(\_:)

Removes an output from a capture session.

func removeOutput(_ output: AVCaptureOutput)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeoutput(_:)\#parameters)

`output`

An output to remove from the capture session.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeoutput(_:)\#Discussion)

You can call this method while the session is running.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeoutput(_:)\#see-also)

### [Configuring outputs](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeoutput(_:)\#Configuring-outputs)

[`var outputs: [AVCaptureOutput]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/outputs)

The output destinations to which a captures session sends its data.

Determines whether you can add an output to a session.

[`func addOutput(AVCaptureOutput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutput(_:))

Adds an output to the capture session.

---

# https://developer.apple.com/documentation/avfoundation/avurlasset-async-properties

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Media assets](https://developer.apple.com/documentation/avfoundation/media-assets)
- [AVPartialAsyncProperty](https://developer.apple.com/documentation/avfoundation/avpartialasyncproperty)
- AVURLAsset

API Collection

# AVURLAsset

Asynchronous properties for URL assets.

## [Topics](https://developer.apple.com/documentation/avfoundation/avurlasset-async-properties\#topics)

### [Loading Tracks and Variants](https://developer.apple.com/documentation/avfoundation/avurlasset-async-properties\#Loading-Tracks-and-Variants)

The tracks an asset contains.

An array of variants that an asset contains.

## [See Also](https://developer.apple.com/documentation/avfoundation/avurlasset-async-properties\#see-also)

### [Loading Properties](https://developer.apple.com/documentation/avfoundation/avurlasset-async-properties\#Loading-Properties)

Asynchronous properties for assets.

Asynchronous properties for asset tracks.

Asynchronous properties for fragmented assets.

Asynchronous properties for metadata items.

Asynchronous properties for compositions.

Asynchronous properties for mutable compositions.

Asynchronous properties for movies.

Asynchronous properties for mutable movies.

Asynchronous properties for fragmented movies.

---

# https://developer.apple.com/documentation/avfoundation/avassetreader/outputcaptionproviderwithrandomaccess(for:validationdelegate:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetReader](https://developer.apple.com/documentation/avfoundation/avassetreader)
- outputCaptionProviderWithRandomAccess(for:validationDelegate:)

Instance Method

# outputCaptionProviderWithRandomAccess(for:validationDelegate:)

Attaches the output to the reader and returns a tuple with an output provider for reading caption groups, and an associated random access controller.

Mac Catalyst

func outputCaptionProviderWithRandomAccess(
for output: AVAssetReaderTrackOutput,
validationDelegate: (any AVAssetReaderCaptionValidationHandling)? = nil

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetreader/outputcaptionproviderwithrandomaccess(for:validationdelegate:)\#parameters)

`output`

The output to be attached to the reader.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avassetreader/outputcaptionproviderwithrandomaccess(for:validationdelegate:)\#return-value)

A tuple with an output provider for reading caption groups, and an associated random access controller.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutputwithnoconnections(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- addOutputWithNoConnections(\_:)

Instance Method

# addOutputWithNoConnections(\_:)

Adds a capture output to the session without forming any connections.

func addOutputWithNoConnections(_ output: AVCaptureOutput)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutputwithnoconnections(_:)\#parameters)

`output`

The capture output to add to the session.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutputwithnoconnections(_:)\#Discussion)

You can call this method while the session is running.

In most cases, use the [`addOutput(_:)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutput(_:)) method to add new outputs to a session. Call this method if you require fine-grained control over which inputs connect to which outputs.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutputwithnoconnections(_:)\#see-also)

### [Connecting inputs and outputs](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutputwithnoconnections(_:)\#Connecting-inputs-and-outputs)

[`var connections: [AVCaptureConnection]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/connections)

The connections between inputs and outputs that a capture session contains.

[`func addConnection(AVCaptureConnection)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addconnection(_:))

Adds a connection to the capture session.

Determines whether a you can add a connection to a capture session.

[`func addInputWithNoConnections(AVCaptureInput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addinputwithnoconnections(_:))

Adds a capture input to a session without forming any connections.

[`func removeConnection(AVCaptureConnection)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeconnection(_:))

Removes a capture connection from the session.

[`class AVCaptureAudioChannel`](https://developer.apple.com/documentation/avfoundation/avcaptureaudiochannel)

An object that monitors average and peak power levels for an audio channel in a capture connection.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/isinterrupted

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- isInterrupted

Instance Property

# isInterrupted

A Boolean value that indicates whether the capture session is in an interrupted state.

var isInterrupted: Bool { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/isinterrupted\#Discussion)

This property is key-value observable.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/isinterrupted\#see-also)

### [Observing session state](https://developer.apple.com/documentation/avfoundation/avcapturesession/isinterrupted\#Observing-session-state)

[`var isRunning: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/isrunning)

A Boolean value that indicates whether the capture session is in a running state.

[`class let didStartRunningNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/didstartrunningnotification)

A notification the system posts when a capture session starts.

[`class let didStopRunningNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/didstoprunningnotification)

A notification the system posts when a capture session stops.

[`class let wasInterruptedNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification)

A notification the system posts when it interrupts a capture session.

[`class let interruptionEndedNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionendednotification)

A notification the system posts when an interruption to a capture session finishes.

[`class let runtimeErrorNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/runtimeerrornotification)

A notification the system posts when an error occurs during a capture session.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning()

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- startRunning()

Instance Method

# startRunning()

Starts the flow of data through the capture pipeline.

func startRunning()

## [Mentioned in](https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning()\#mentions)

[Setting Up a Capture Session](https://developer.apple.com/documentation/avfoundation/setting-up-a-capture-session)

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning()\#Discussion)

Call this method to start the flow of data from the capture session’s inputs to its outputs. This method is synchronous and blocks until the session starts running or it fails, which it reports by posting an [`runtimeErrorNotification`](https://developer.apple.com/documentation/avfoundation/avcapturesession/runtimeerrornotification) notification.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning()\#see-also)

### [Managing the session life cycle](https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning()\#Managing-the-session-life-cycle)

[`func stopRunning()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/stoprunning())

Stops the flow of data through the capture pipeline.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- wasInterruptedNotification

Type Property

# wasInterruptedNotification

A notification the system posts when it interrupts a capture session.

class let wasInterruptedNotification: NSNotification.Name

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification\#Discussion)

Retrieve the underlying error from the notification’s user information dictionary using the key [`AVCaptureSessionInterruptionReasonKey`](https://developer.apple.com/documentation/avfoundation/avcapturesessioninterruptionreasonkey).

## [Topics](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification\#topics)

### [User-Infomation Keys](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification\#User-Infomation-Keys)

[`let AVCaptureSessionInterruptionSystemPressureStateKey: String`](https://developer.apple.com/documentation/avfoundation/avcapturesessioninterruptionsystempressurestatekey)

A key to retrieve a state value that indicates the system pressure level and contributing factors that caused the interruption.

[`let AVCaptureSessionInterruptionReasonKey: String`](https://developer.apple.com/documentation/avfoundation/avcapturesessioninterruptionreasonkey)

Key to retrieve information about a capture interruption from a [`wasInterruptedNotification`](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification) user info dictionary.

[`enum InterruptionReason`](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason)

Constants identifying the reason a capture session was interrupted, found in an [`wasInterruptedNotification`](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification) user info dictionary.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification\#see-also)

### [Observing session state](https://developer.apple.com/documentation/avfoundation/avcapturesession/wasinterruptednotification\#Observing-session-state)

[`var isRunning: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/isrunning)

A Boolean value that indicates whether the capture session is in a running state.

[`var isInterrupted: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/isinterrupted)

A Boolean value that indicates whether the capture session is in an interrupted state.

[`class let didStartRunningNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/didstartrunningnotification)

A notification the system posts when a capture session starts.

[`class let didStopRunningNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/didstoprunningnotification)

A notification the system posts when a capture session stops.

[`class let interruptionEndedNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionendednotification)

A notification the system posts when an interruption to a capture session finishes.

[`class let runtimeErrorNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturesession/runtimeerrornotification)

A notification the system posts when an error occurs during a capture session.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedresponsewithexpiredlease

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeyRequest](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)
- [AVContentKeyRequest.RetryReason](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason)
- receivedResponseWithExpiredLease

Type Property

# receivedResponseWithExpiredLease

A key response with an expired lease that was set on the previous content key request.

static let receivedResponseWithExpiredLease: AVContentKeyRequest.RetryReason

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedresponsewithexpiredlease\#see-also)

### [Reasons for Content Key Request Retry](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedresponsewithexpiredlease\#Reasons-for-Content-Key-Request-Retry)

[`static let receivedObsoleteContentKey: AVContentKeyRequest.RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedobsoletecontentkey)

An obsolete key response that was set on the previous content key request.

[`static let timedOut: AVContentKeyRequest.RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/timedout)

A key response that wasn’t set soon enough.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccessenabled

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- isMultitaskingCameraAccessEnabled

Instance Property

# isMultitaskingCameraAccessEnabled

A Boolean value that indicates whether the capture session enables access to the camera while multitasking.

var isMultitaskingCameraAccessEnabled: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccessenabled\#Discussion)

The default value is [`false`](https://developer.apple.com/documentation/swift/false).

If the value of the [`isMultitaskingCameraAccessSupported`](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccesssupported) property is [`true`](https://developer.apple.com/documentation/swift/true), you can enable multitasking camera access by setting this value to [`true`](https://developer.apple.com/documentation/swift/true) prior to starting the capture session.

This property is key-value observable.

To learn about best practices for using the camera while multitasking, see [Accessing the camera while multitasking on iPad](https://developer.apple.com/documentation/AVKit/accessing-the-camera-while-multitasking-on-ipad).

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccessenabled\#see-also)

### [Configuring multitasking](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccessenabled\#Configuring-multitasking)

[`var isMultitaskingCameraAccessSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccesssupported)

A Boolean value that indicates whether the capture session supports using the camera while multitasking.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption/protocolversions

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeySessionServerPlaybackContextOption](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption)
- protocolVersions

Type Property

# protocolVersions

Specifies the versions of the content protection protocols supported by the application.

static let protocolVersions: AVContentKeySessionServerPlaybackContextOption

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption/protocolversions\#Discussion)

If you don’t specify a value for this key, the system assumes a default protocol version of `1`.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption/protocolversions\#see-also)

### [Server Playback Context Options](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption/protocolversions\#Server-Playback-Context-Options)

[`static let serverChallenge: AVContentKeySessionServerPlaybackContextOption`](https://developer.apple.com/documentation/avfoundation/avcontentkeysessionserverplaybackcontextoption/serverchallenge)

Specifies a nonce to include in the secure server playback context (SPC) to prevent replay attacks.

---

# https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor/append(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetWriterInputMetadataAdaptor](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor)
- append(\_:)

Instance Method

# append(\_:)

Appends a timed metadata group to the adaptor.

macOS 10.10–11.0DeprecatedtvOS 9.0–26.0Deprecated

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor/append(_:)\#parameters)

`timedMetadataGroup`

The timed metadata group to append.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor/append(_:)\#return-value)

[`true`](https://developer.apple.com/documentation/swift/true) if the adaptor appends the group; otherwise, [`false`](https://developer.apple.com/documentation/swift/false).

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetwriterinputmetadataadaptor/append(_:)\#Discussion)

The timing of metadata items in the output asset correspond to the time range of the timed metadata group, regardless of the values of their individual time and duration properties.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/controlsdelegatecallbackqueue

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- controlsDelegateCallbackQueue

Instance Property

# controlsDelegateCallbackQueue

The dispatch queue on which the system calls controls delegate methods.

var controlsDelegateCallbackQueue: dispatch_queue_t? { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/controlsdelegatecallbackqueue\#Discussion)

Call the [`setControlsDelegate(_:queue:)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/setcontrolsdelegate(_:queue:)) method to specify the dispatch queue on which to call the controls delegate methods.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/controlsdelegatecallbackqueue\#see-also)

### [Configuring capture controls](https://developer.apple.com/documentation/avfoundation/avcapturesession/controlsdelegatecallbackqueue\#Configuring-capture-controls)

[`var supportsControls: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturesession/supportscontrols)

A Boolean value that indicates whether a capture session supports controls.

[`var maxControlsCount: Int`](https://developer.apple.com/documentation/avfoundation/avcapturesession/maxcontrolscount)

The maximum number of controls a capture session supports.

[`var controls: [AVCaptureControl]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/controls)

The controls that allow configuring the camera system from device hardware.

Returns a Boolean value that indicates whether a capture session add the specified control.

[`func addControl(AVCaptureControl)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addcontrol(_:))

Adds a control to a capture session.

[`func removeControl(AVCaptureControl)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removecontrol(_:))

Removes a control from a capture session.

[`func setControlsDelegate((any AVCaptureSessionControlsDelegate)?, queue: dispatch_queue_t?)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/setcontrolsdelegate(_:queue:))

Sets a delegate object for the system to call when it activates and presents controls.

[`protocol AVCaptureSessionControlsDelegate`](https://developer.apple.com/documentation/avfoundation/avcapturesessioncontrolsdelegate)

A protocol that defines the interface to respond to capture control activation and presentation events.

[`var controlsDelegate: (any AVCaptureSessionControlsDelegate)?`](https://developer.apple.com/documentation/avfoundation/avcapturesession/controlsdelegate)

A delegate object that observes changes to the state of capture controls.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutput(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- addOutput(\_:)

Instance Method

# addOutput(\_:)

Adds an output to the capture session.

func addOutput(_ output: AVCaptureOutput)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutput(_:)\#parameters)

`output`

An output to add to the session.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutput(_:)\#Discussion)

You can only add an output to a session using this method if [`canAddOutput(_:)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddoutput(_:)) returns [`true`](https://developer.apple.com/documentation/swift/true).

You can invoke this method while the session is running.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutput(_:)\#see-also)

### [Configuring outputs](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutput(_:)\#Configuring-outputs)

[`var outputs: [AVCaptureOutput]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/outputs)

The output destinations to which a captures session sends its data.

Determines whether you can add an output to a session.

[`func removeOutput(AVCaptureOutput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeoutput(_:))

Removes an output from a capture session.

---

# https://developer.apple.com/documentation/avfoundation/avassetreader/status-swift.property

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetReader](https://developer.apple.com/documentation/avfoundation/avassetreader)
- status

Instance Property

# status

The status of reading sample buffers from the asset.

var status: AVAssetReader.Status { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetreader/status-swift.property\#Discussion)

Check the value of this property when the [`copyNextSampleBuffer()`](https://developer.apple.com/documentation/avfoundation/avassetreaderoutput/copynextsamplebuffer()) method on [`AVAssetReaderOutput`](https://developer.apple.com/documentation/avfoundation/avassetreaderoutput) returns `nil` to determine why the output can’t read more data.

This property is thread safe.

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetreader/status-swift.property\#see-also)

### [Configuring Reading](https://developer.apple.com/documentation/avfoundation/avassetreader/status-swift.property\#Configuring-Reading)

[`var timeRange: CMTimeRange`](https://developer.apple.com/documentation/avfoundation/avassetreader/timerange)

The time range within the asset to read.

[`enum Status`](https://developer.apple.com/documentation/avfoundation/avassetreader/status-swift.enum)

Values that represent the possible states of an asset reader.

[`var error: (any Error)?`](https://developer.apple.com/documentation/avfoundation/avassetreader/error)

An error that describes the reason for a failure.

---

# https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasdependentsamples

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVSampleCursorDependencyInfo](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo)
- sampleIndicatesWhetherItHasDependentSamples

Instance Property

# sampleIndicatesWhetherItHasDependentSamples

A Boolean value that determines whether the sample indicates if other samples depend on it.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

var sampleIndicatesWhetherItHasDependentSamples: ObjCBool

## [See Also](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasdependentsamples\#see-also)

### [Dependency Information](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasdependentsamples\#Dependency-Information)

[`var sampleHasDependentSamples: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/samplehasdependentsamples)

A Boolean value that determines whether the sample has dependent samples.

[`var sampleIndicatesWhetherItDependsOnOthers: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetheritdependsonothers)

A Boolean value that determines whether the sample indicates that it depends on other samples.

[`var sampleDependsOnOthers: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampledependsonothers)

A Boolean value that determines whether the sample depends on other samples.

[`var sampleIndicatesWhetherItHasRedundantCoding: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/sampleindicateswhetherithasredundantcoding)

A Boolean value that determines whether the sample indicates that it has redundant coding.

[`var sampleHasRedundantCoding: ObjCBool`](https://developer.apple.com/documentation/avfoundation/avsamplecursordependencyinfo/samplehasredundantcoding)

A Boolean value that determines whether the sample has redundant coding.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartwork

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- commonIdentifierArtwork

Type Property

# commonIdentifierArtwork

An identifier that represents an image relating to the album.

static let commonIdentifierArtwork: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartwork\#see-also)

### [Common Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartwork\#Common-Metadata-Identifiers)

[`static let commonIdentifierAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieraccessibilitydescription)

An identifier that represents the accessibility description for the media.

[`static let commonIdentifierAlbumName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieralbumname)

An identifier that represents the name of the album.

[`static let commonIdentifierArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartist)

An identifier that represents the name of the artist.

[`static let commonIdentifierAssetIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierassetidentifier)

An identifier that represents the asset ID for the media.

[`static let commonIdentifierAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierauthor)

An identifier that represents the name of the author.

[`static let commonIdentifierContributor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercontributor)

An identifier that represents the name of the contributor.

[`static let commonIdentifierCopyrights: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercopyrights)

An identifier that represents the copyright statement.

[`static let commonIdentifierCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreationdate)

An identifier that represents the date of the original recording.

[`static let commonIdentifierCreator: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreator)

An identifier that represents the name of the creator.

[`static let commonIdentifierDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierdescription)

An identifier that represents the description of the media.

[`static let commonIdentifierFormat: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierformat)

An identifier that represents the file format of the media content.

[`static let commonIdentifierLanguage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlanguage)

An identifier that represents the language of the text or lyrics spoken or sung in the audio.

[`static let commonIdentifierLastModifiedDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlastmodifieddate)

An identifier that represents the last modification date of the media.

[`static let commonIdentifierLocation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlocation)

An identifier that represents the location information for the media.

[`static let commonIdentifierMake: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiermake)

An identifier that represents the name of the camera maker.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddconnection(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- canAddConnection(\_:)

Instance Method

# canAddConnection(\_:)

Determines whether a you can add a connection to a capture session.

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddconnection(_:)\#parameters)

`connection`

A connect object to test.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddconnection(_:)\#return-value)

[`true`](https://developer.apple.com/documentation/swift/true) if you can add the connection; otherwise, [`false`](https://developer.apple.com/documentation/swift/false).

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddconnection(_:)\#see-also)

### [Connecting inputs and outputs](https://developer.apple.com/documentation/avfoundation/avcapturesession/canaddconnection(_:)\#Connecting-inputs-and-outputs)

[`var connections: [AVCaptureConnection]`](https://developer.apple.com/documentation/avfoundation/avcapturesession/connections)

The connections between inputs and outputs that a capture session contains.

[`func addConnection(AVCaptureConnection)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addconnection(_:))

Adds a connection to the capture session.

[`func addInputWithNoConnections(AVCaptureInput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addinputwithnoconnections(_:))

Adds a capture input to a session without forming any connections.

[`func addOutputWithNoConnections(AVCaptureOutput)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/addoutputwithnoconnections(_:))

Adds a capture output to the session without forming any connections.

[`func removeConnection(AVCaptureConnection)`](https://developer.apple.com/documentation/avfoundation/avcapturesession/removeconnection(_:))

Removes a capture connection from the session.

[`class AVCaptureAudioChannel`](https://developer.apple.com/documentation/avfoundation/avcaptureaudiochannel)

An object that monitors average and peak power levels for an audio channel in a capture connection.

---

# https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedobsoletecontentkey

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVContentKeyRequest](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest)
- [AVContentKeyRequest.RetryReason](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason)
- receivedObsoleteContentKey

Type Property

# receivedObsoleteContentKey

An obsolete key response that was set on the previous content key request.

static let receivedObsoleteContentKey: AVContentKeyRequest.RetryReason

## [See Also](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedobsoletecontentkey\#see-also)

### [Reasons for Content Key Request Retry](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedobsoletecontentkey\#Reasons-for-Content-Key-Request-Retry)

[`static let receivedResponseWithExpiredLease: AVContentKeyRequest.RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/receivedresponsewithexpiredlease)

A key response with an expired lease that was set on the previous content key request.

[`static let timedOut: AVContentKeyRequest.RetryReason`](https://developer.apple.com/documentation/avfoundation/avcontentkeyrequest/retryreason/timedout)

A key response that wasn’t set soon enough.

---

# https://developer.apple.com/documentation/avfoundation/avassetreader/canadd(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetReader](https://developer.apple.com/documentation/avfoundation/avassetreader)
- canAdd(\_:)

Instance Method

# canAdd(\_:)

Determines whether you can add the output to the asset reader.

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetreader/canadd(_:)\#parameters)

`output`

The asset reader output to test.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avassetreader/canadd(_:)\#return-value)

[`true`](https://developer.apple.com/documentation/swift/true) if you can add the output; otherwise, [`false`](https://developer.apple.com/documentation/swift/false).

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetreader/canadd(_:)\#Discussion)

You may only add outputs that retrieve media data from the asset that you associate with the asset reader.

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetreader/canadd(_:)\#see-also)

### [Managing Outputs](https://developer.apple.com/documentation/avfoundation/avassetreader/canadd(_:)\#Managing-Outputs)

[`func add(AVAssetReaderOutput)`](https://developer.apple.com/documentation/avfoundation/avassetreader/add(_:))

Adds an output to the reader.

[`var outputs: [AVAssetReaderOutput]`](https://developer.apple.com/documentation/avfoundation/avassetreader/outputs)

The outputs from which you read media data.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlastmodifieddate

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- commonIdentifierLastModifiedDate

Type Property

# commonIdentifierLastModifiedDate

An identifier that represents the last modification date of the media.

static let commonIdentifierLastModifiedDate: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlastmodifieddate\#see-also)

### [Common Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlastmodifieddate\#Common-Metadata-Identifiers)

[`static let commonIdentifierAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieraccessibilitydescription)

An identifier that represents the accessibility description for the media.

[`static let commonIdentifierAlbumName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieralbumname)

An identifier that represents the name of the album.

[`static let commonIdentifierArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartist)

An identifier that represents the name of the artist.

[`static let commonIdentifierArtwork: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartwork)

An identifier that represents an image relating to the album.

[`static let commonIdentifierAssetIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierassetidentifier)

An identifier that represents the asset ID for the media.

[`static let commonIdentifierAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierauthor)

An identifier that represents the name of the author.

[`static let commonIdentifierContributor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercontributor)

An identifier that represents the name of the contributor.

[`static let commonIdentifierCopyrights: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercopyrights)

An identifier that represents the copyright statement.

[`static let commonIdentifierCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreationdate)

An identifier that represents the date of the original recording.

[`static let commonIdentifierCreator: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreator)

An identifier that represents the name of the creator.

[`static let commonIdentifierDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierdescription)

An identifier that represents the description of the media.

[`static let commonIdentifierFormat: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierformat)

An identifier that represents the file format of the media content.

[`static let commonIdentifierLanguage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlanguage)

An identifier that represents the language of the text or lyrics spoken or sung in the audio.

[`static let commonIdentifierLocation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlocation)

An identifier that represents the location information for the media.

[`static let commonIdentifierMake: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiermake)

An identifier that represents the name of the camera maker.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieraccessibilitydescription

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- commonIdentifierAccessibilityDescription

Type Property

# commonIdentifierAccessibilityDescription

An identifier that represents the accessibility description for the media.

static let commonIdentifierAccessibilityDescription: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieraccessibilitydescription\#see-also)

### [Common Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieraccessibilitydescription\#Common-Metadata-Identifiers)

[`static let commonIdentifierAlbumName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieralbumname)

An identifier that represents the name of the album.

[`static let commonIdentifierArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartist)

An identifier that represents the name of the artist.

[`static let commonIdentifierArtwork: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartwork)

An identifier that represents an image relating to the album.

[`static let commonIdentifierAssetIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierassetidentifier)

An identifier that represents the asset ID for the media.

[`static let commonIdentifierAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierauthor)

An identifier that represents the name of the author.

[`static let commonIdentifierContributor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercontributor)

An identifier that represents the name of the contributor.

[`static let commonIdentifierCopyrights: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercopyrights)

An identifier that represents the copyright statement.

[`static let commonIdentifierCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreationdate)

An identifier that represents the date of the original recording.

[`static let commonIdentifierCreator: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreator)

An identifier that represents the name of the creator.

[`static let commonIdentifierDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierdescription)

An identifier that represents the description of the media.

[`static let commonIdentifierFormat: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierformat)

An identifier that represents the file format of the media content.

[`static let commonIdentifierLanguage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlanguage)

An identifier that represents the language of the text or lyrics spoken or sung in the audio.

[`static let commonIdentifierLastModifiedDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlastmodifieddate)

An identifier that represents the last modification date of the media.

[`static let commonIdentifierLocation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlocation)

An identifier that represents the location information for the media.

[`static let commonIdentifierMake: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiermake)

An identifier that represents the name of the camera maker.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataarranger

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- iTunesMetadataArranger

Type Property

# iTunesMetadataArranger

An identifier that represents the name of the arranger.

static let iTunesMetadataArranger: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataarranger\#see-also)

### [iTunes Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataarranger\#iTunes-Metadata-Identifiers)

[`static let iTunesMetadataAccountKind: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataaccountkind)

An identifier that represents the kind of iTunes account.

[`static let iTunesMetadataAcknowledgement: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataacknowledgement)

An identifier that represents the acknowledgement information in iTunes.

[`static let iTunesMetadataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataalbum)

An identifier that represents the name of the album in iTunes.

[`static let iTunesMetadataAlbumArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataalbumartist)

An identifier that represents the artist for the album.

[`static let iTunesMetadataAppleID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataappleid)

An identifier that represents an Apple ID.

[`static let iTunesMetadataArtDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartdirector)

An identifier that represents the name of the art director.

[`static let iTunesMetadataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartist)

An identifier that represents the name of the artist.

[`static let iTunesMetadataArtistID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartistid)

An identifier that represents the ID for an artist.

[`static let iTunesMetadataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataauthor)

An identifier that represents the name of the author.

[`static let iTunesMetadataBeatsPerMin: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatabeatspermin)

An identifier that represents the beats per minute of a track in iTunes.

[`static let iTunesMetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacomposer)

An identifier that represents the name of the composer.

[`static let iTunesMetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataconductor)

An identifier that represents the name of the conductor.

[`static let iTunesMetadataContentRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacontentrating)

An identifier that represents the content rating in iTunes.

[`static let iTunesMetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacopyright)

An identifier that represents the copyright statement in iTunes.

[`static let iTunesMetadataCoverArt: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacoverart)

An identifier that represents an album cover image.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatagrouping

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- iTunesMetadataGrouping

Type Property

# iTunesMetadataGrouping

An identifier that represents additional grouping information for an album.

static let iTunesMetadataGrouping: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatagrouping\#see-also)

### [iTunes Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatagrouping\#iTunes-Metadata-Identifiers)

[`static let iTunesMetadataAccountKind: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataaccountkind)

An identifier that represents the kind of iTunes account.

[`static let iTunesMetadataAcknowledgement: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataacknowledgement)

An identifier that represents the acknowledgement information in iTunes.

[`static let iTunesMetadataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataalbum)

An identifier that represents the name of the album in iTunes.

[`static let iTunesMetadataAlbumArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataalbumartist)

An identifier that represents the artist for the album.

[`static let iTunesMetadataAppleID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataappleid)

An identifier that represents an Apple ID.

[`static let iTunesMetadataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataarranger)

An identifier that represents the name of the arranger.

[`static let iTunesMetadataArtDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartdirector)

An identifier that represents the name of the art director.

[`static let iTunesMetadataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartist)

An identifier that represents the name of the artist.

[`static let iTunesMetadataArtistID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartistid)

An identifier that represents the ID for an artist.

[`static let iTunesMetadataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataauthor)

An identifier that represents the name of the author.

[`static let iTunesMetadataBeatsPerMin: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatabeatspermin)

An identifier that represents the beats per minute of a track in iTunes.

[`static let iTunesMetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacomposer)

An identifier that represents the name of the composer.

[`static let iTunesMetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataconductor)

An identifier that represents the name of the conductor.

[`static let iTunesMetadataContentRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacontentrating)

An identifier that represents the content rating in iTunes.

[`static let iTunesMetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacopyright)

An identifier that represents the copyright statement in iTunes.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataphonogramrights

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- iTunesMetadataPhonogramRights

Type Property

# iTunesMetadataPhonogramRights

An identifier that represents the phonogram rights statement.

static let iTunesMetadataPhonogramRights: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataphonogramrights\#see-also)

### [iTunes Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataphonogramrights\#iTunes-Metadata-Identifiers)

[`static let iTunesMetadataAccountKind: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataaccountkind)

An identifier that represents the kind of iTunes account.

[`static let iTunesMetadataAcknowledgement: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataacknowledgement)

An identifier that represents the acknowledgement information in iTunes.

[`static let iTunesMetadataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataalbum)

An identifier that represents the name of the album in iTunes.

[`static let iTunesMetadataAlbumArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataalbumartist)

An identifier that represents the artist for the album.

[`static let iTunesMetadataAppleID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataappleid)

An identifier that represents an Apple ID.

[`static let iTunesMetadataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataarranger)

An identifier that represents the name of the arranger.

[`static let iTunesMetadataArtDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartdirector)

An identifier that represents the name of the art director.

[`static let iTunesMetadataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartist)

An identifier that represents the name of the artist.

[`static let iTunesMetadataArtistID: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataartistid)

An identifier that represents the ID for an artist.

[`static let iTunesMetadataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataauthor)

An identifier that represents the name of the author.

[`static let iTunesMetadataBeatsPerMin: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatabeatspermin)

An identifier that represents the beats per minute of a track in iTunes.

[`static let iTunesMetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacomposer)

An identifier that represents the name of the composer.

[`static let iTunesMetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadataconductor)

An identifier that represents the name of the conductor.

[`static let iTunesMetadataContentRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacontentrating)

An identifier that represents the content rating in iTunes.

[`static let iTunesMetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/itunesmetadatacopyright)

An identifier that represents the copyright statement in iTunes.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/device

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDeviceInput](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput)
- device

Instance Property

# device

A capture device associated with this input.

var device: AVCaptureDevice { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/device\#see-also)

### [Accessing the Device](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/device\#Accessing-the-Device)

Retrieves a virtual device’s constituent device ports for use in a multi-camera session.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieralbumname

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- commonIdentifierAlbumName

Type Property

# commonIdentifierAlbumName

An identifier that represents the name of the album.

static let commonIdentifierAlbumName: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieralbumname\#see-also)

### [Common Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieralbumname\#Common-Metadata-Identifiers)

[`static let commonIdentifierAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifieraccessibilitydescription)

An identifier that represents the accessibility description for the media.

[`static let commonIdentifierArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartist)

An identifier that represents the name of the artist.

[`static let commonIdentifierArtwork: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierartwork)

An identifier that represents an image relating to the album.

[`static let commonIdentifierAssetIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierassetidentifier)

An identifier that represents the asset ID for the media.

[`static let commonIdentifierAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierauthor)

An identifier that represents the name of the author.

[`static let commonIdentifierContributor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercontributor)

An identifier that represents the name of the contributor.

[`static let commonIdentifierCopyrights: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercopyrights)

An identifier that represents the copyright statement.

[`static let commonIdentifierCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreationdate)

An identifier that represents the date of the original recording.

[`static let commonIdentifierCreator: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiercreator)

An identifier that represents the name of the creator.

[`static let commonIdentifierDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierdescription)

An identifier that represents the description of the media.

[`static let commonIdentifierFormat: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierformat)

An identifier that represents the file format of the media content.

[`static let commonIdentifierLanguage: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlanguage)

An identifier that represents the language of the text or lyrics spoken or sung in the audio.

[`static let commonIdentifierLastModifiedDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlastmodifieddate)

An identifier that represents the last modification date of the media.

[`static let commonIdentifierLocation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifierlocation)

An identifier that represents the location information for the media.

[`static let commonIdentifierMake: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/commonidentifiermake)

An identifier that represents the name of the camera maker.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalenabled

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDeviceInput](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput)
- isWindNoiseRemovalEnabled

Instance Property

# isWindNoiseRemovalEnabled

var isWindNoiseRemovalEnabled: Bool { get set }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalenabled\#see-also)

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalenabled\#Instance-Properties)

[`var isWindNoiseRemovalSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalsupported)

---

# https://developer.apple.com/documentation/avfoundation/avassetwriter/startsession(atsourcetime:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetWriter](https://developer.apple.com/documentation/avfoundation/avassetwriter)
- startSession(atSourceTime:)

Instance Method

# startSession(atSourceTime:)

Starts an asset-writing session.

func startSession(atSourceTime startTime: CMTime)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetwriter/startsession(atsourcetime:)\#parameters)

`startTime`

The starting asset time for the sample-writing session, in the timeline of the source samples.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetwriter/startsession(atsourcetime:)\#Discussion)

You must call this method after you call [`startWriting()`](https://developer.apple.com/documentation/avfoundation/avassetwriter/startwriting()), but before you append sample data to asset writer inputs.

Each writing session has a start time that, where allowed by the file format you’re writing, defines the mapping from the timeline of source samples to the timeline of the written file. In the case of the QuickTime movie file format, the first session begins at movie time `0`, so a sample you append with timestamp `T` plays at movie time ( `T-startTime`). The writer adds samples with timestamps earlier than the start time to the output file, but they don’t display during playback. If the earliest sample for an input has a timestamp later than the start time, the system inserts an empty edit to preserve synchronization between tracks of the output asset.

To end a session, call [`endSession(atSourceTime:)`](https://developer.apple.com/documentation/avfoundation/avassetwriter/endsession(atsourcetime:)) or [`finishWriting(completionHandler:)`](https://developer.apple.com/documentation/avfoundation/avassetwriter/finishwriting(completionhandler:))

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetwriter/startsession(atsourcetime:)\#see-also)

### [Managing Writing Sessions](https://developer.apple.com/documentation/avfoundation/avassetwriter/startsession(atsourcetime:)\#Managing-Writing-Sessions)

Tells the writer to start writing its output.

[`func endSession(atSourceTime: CMTime)`](https://developer.apple.com/documentation/avfoundation/avassetwriter/endsession(atsourcetime:))

Finishes an asset-writing session.

Marks all unfinished inputs as finished and completes the writing of the output file.

[`func cancelWriting()`](https://developer.apple.com/documentation/avfoundation/avassetwriter/cancelwriting())

Cancels the creation of the output file.

Completes the writing of the output file.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadescription

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeMetadataDescription

Type Property

# quickTimeMetadataDescription

An identifier that represents the description of the movie file content.

static let quickTimeMetadataDescription: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadescription\#see-also)

### [QuickTime Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatadescription\#QuickTime-Metadata-Identifiers)

[`static let quickTimeMetadataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeMetadataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataalbum)

An identifier that represents the name of the album or collection in QuickTime.

[`static let quickTimeMetadataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeMetadataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeMetadataArtwork: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataartwork)

An identifier that represents an image relating to the movie file content.

[`static let quickTimeMetadataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeMetadataAutoLivePhoto: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataautolivephoto)

An identifier that represents whether the live photo movie used auto mode.

[`static let quickTimeMetadataCameraFrameReadoutTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameraframereadouttime)

An identifier that represents the camera frame readout time in QuickTime.

[`static let quickTimeMetadataCameraIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameraidentifier)

An identifier that represents the camera identifier in QuickTime.

[`static let quickTimeMetadataCollectionUser: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacollectionuser)

An identifier that represents a name that indicates a user-defined collection.

[`static let quickTimeMetadataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeMetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeMetadataContentIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacontentidentifier)

An identifier that represents the content identifier in QuickTime.

[`static let quickTimeMetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacopyright)

An identifier that represents the copyright statement for the movie file content.

[`static let quickTimeMetadataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacreationdate)

An identifier that represents the creation date of the movie file content.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotocapturesuspended

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- isLivePhotoCaptureSuspended

Instance Property

# isLivePhotoCaptureSuspended

A Boolean value that indicates whether Live Photo capture is currently in a suspended state.

var isLivePhotoCaptureSuspended: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotocapturesuspended\#Discussion)

By default, this property’s value is [`false`](https://developer.apple.com/documentation/swift/false). Set this value to [`true`](https://developer.apple.com/documentation/swift/true) to stop any current Live Photo movie captures in progress. Doing this prevents recording additional actions in the Live Photo movie. For example, if you want to capture a still photo that makes a shutter sound, you can prevent recording that action.

When you change this value to [`true`](https://developer.apple.com/documentation/swift/true), the system trims any Live Photo movie captures in progress to the current time. Likewise, when you change this value from [`true`](https://developer.apple.com/documentation/swift/true) to [`false`](https://developer.apple.com/documentation/swift/false), subsequent Live Photo movie captures won’t contain any earlier recordings.

By default, this property resets to [`false`](https://developer.apple.com/documentation/swift/false) when the [`AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession) stops. You can prevent this behavior by setting [`preservesLivePhotoCaptureSuspendedOnSessionStop`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/preserveslivephotocapturesuspendedonsessionstop) to [`true`](https://developer.apple.com/documentation/swift/true) before stopping the session.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotocapturesuspended\#see-also)

### [Configuring Live Photo Capture](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotocapturesuspended\#Configuring-Live-Photo-Capture)

[`var isLivePhotoCaptureSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotocapturesupported)

A Boolean value that indicates whether the capture output currently supports Live Photo capture.

[`var isLivePhotoCaptureEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotocaptureenabled)

A Boolean value that indicates whether to configure the capture pipeline for Live Photo capture.

[`var preservesLivePhotoCaptureSuspendedOnSessionStop: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/preserveslivephotocapturesuspendedonsessionstop)

A Boolean value that indicates whether to preserve the suspended state of Live Photo capture when the session stops.

[`var isLivePhotoAutoTrimmingEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islivephotoautotrimmingenabled)

A Boolean value that indicates whether to automatically trim Live Photo movie captures to avoid excessive movement.

[`var availableLivePhotoVideoCodecTypes: [AVVideoCodecType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablelivephotovideocodectypes)

An array of video codecs currently available for Live Photo movie captures.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/preparedphotosettingsarray

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- preparedPhotoSettingsArray

Instance Property

# preparedPhotoSettingsArray

An array of photo settings for which the photo output has prepared capture resources.

var preparedPhotoSettingsArray: [AVCapturePhotoSettings] { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/preparedphotosettingsarray\#Discussion)

Some types of photo capture, such as bracketed captures and RAW captures, require the photo output to allocate additional buffers or prepare other resources. To prevent photo capture requests from executing slowly due to lazy resource allocation, you may call the [`setPreparedPhotoSettingsArray(_:completionHandler:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/setpreparedphotosettingsarray(_:completionhandler:)) method with an array of settings objects representative of the types of capture you will be performing (such as settings for a bracketed capture, RAW capture, or capture with still image stabilization).

By default, the photo output prepares sufficient resources to capture photos with default settings (as defined by the [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) default initializer).

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/preparedphotosettingsarray\#see-also)

### [Preparing for Resource-Intensive Captures](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/preparedphotosettingsarray\#Preparing-for-Resource-Intensive-Captures)

Tells the photo capture output to prepare resources for future capture requests with the specified settings.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatapopularimeter

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataPopularimeter

Type Property

# id3MetadataPopularimeter

An identifier that represents the rating for the audio file.

static let id3MetadataPopularimeter: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatapopularimeter\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatapopularimeter\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatalyricist

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataLyricist

Type Property

# id3MetadataLyricist

An identifier that represents the writer(s) of the text or lyrics in the recording.

static let id3MetadataLyricist: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatalyricist\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatalyricist\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/hardwarecost

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- hardwareCost

Instance Property

# hardwareCost

A value that indicates the percentage of the session’s available hardware budget in use.

var hardwareCost: Float { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/hardwarecost\#Discussion)

This property provides a floating-point value from `0.0` to `1.0` that indicates the percentage of a capture session’s hardware that it currently uses. When the value is greater than `1.0`, the capture session can’t run in its current configuration due to hardware constraints. Attempting to start the session while it’s in this state results in a runtime error.

Factors that contribute to the hardware cost include:

- The active formats of the source devices. Some formats use the full sensor (4:3) and others a crop (16:9). Cropped formats require lower hardware bandwidth, and therefore lower the cost.

- The maximum frame rate of the source devices’ active formats. The hardware cost increases when using high frame rates.

- Whether the source devices uses binned formats. Binned formats require substantially less hardware bandwidth, and therefore result in a lower cost.

- The number of sources configured to deliver streaming disparity and depth using [`AVCaptureDepthDataOutput`](https://developer.apple.com/documentation/avfoundation/avcapturedepthdataoutput). The higher the number of cameras configured to produce depth, the higher the cost.

To reduce the hardware cost, consider picking a sensor-cropped or binned [`activeFormat`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activeformat). You may also use a device input’s [`videoMinFrameDurationOverride`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/videominframedurationoverride) property to artificially limit the maximum frame rate of a source device to a lower value. By doing so, you only pay the hardware cost for the maximum frame rate you intend to use.

---

# https://developer.apple.com/documentation/avfoundation/avassetreader/init(asset:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetReader](https://developer.apple.com/documentation/avfoundation/avassetreader)
- init(asset:)

Initializer

# init(asset:)

Creates an object to read media data from an asset.

init(asset: AVAsset) throws

## [Parameters](https://developer.apple.com/documentation/avfoundation/avassetreader/init(asset:)\#parameters)

`asset`

The asset from which to read media data.

---

# https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isdualcamerafusionenabled

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureResolvedPhotoSettings](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings)
- isDualCameraFusionEnabled Deprecated

Instance Property

# isDualCameraFusionEnabled

A Boolean value indicating whether this capture combines image data from a dual camera.

iOS 10.2–13.0DeprecatediPadOS 10.2–13.0DeprecatedMac Catalyst 13.1–13.1Deprecated

var isDualCameraFusionEnabled: Bool { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isdualcamerafusionenabled\#Discussion)

This property corresponds to the [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) property [`isAutoDualCameraFusionEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings/isautodualcamerafusionenabled).

When this value is [`true`](https://developer.apple.com/documentation/swift/true), a dual-camera device automatically combines samples from both cameras to produce a higher quality image. This property applies only when using the [`builtInDualCamera`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/devicetype-swift.struct/builtindualcamera) device type on supported devices.

If you specify automatic image fusion when requesting a capture, the device automatically chooses whether to use image fusion based on the scene conditions at the moment of capture. Therefore, you don’t know whether the system uses image fusion until right before the moment of capture. When the photo output calls your [`photoOutput(_:willBeginCaptureFor:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotocapturedelegate/photooutput(_:willbegincapturefor:)) method (or other delegate methods that occur later in the capture process), you can use this property to determine whether image fusion is active.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isdualcamerafusionenabled\#see-also)

### [Examining Photo Capture Settings](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isdualcamerafusionenabled\#Examining-Photo-Capture-Settings)

[`var isFlashEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isflashenabled)

A Boolean value indicating whether the camera flash fires for this capture.

[`var isRedEyeReductionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isredeyereductionenabled)

A Boolean value indicating whether the camera automatically reduces red-eye when capturing photos.

[`var isVirtualDeviceFusionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isvirtualdevicefusionenabled)

A Boolean value that specifies whether the system automatically uses virtual device image fusion.

[`var isFastCapturePrioritizationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isfastcaptureprioritizationenabled)

A Boolean value that indicates whether the system uses fast capture prioritization when capturing the photo.

[`var isContentAwareDistortionCorrectionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/iscontentawaredistortioncorrectionenabled)

A Boolean value that indicates whether the system applies content-aware distortion correction when capturing the photo.

[`var isStillImageStabilizationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isstillimagestabilizationenabled)

A Boolean value indicating whether this capture uses image stabilization.

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataprivate

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataPrivate

Type Property

# id3MetadataPrivate

An identifier that represents the information from a software producer that its program uses.

static let id3MetadataPrivate: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataprivate\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataprivate\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxphotoqualityprioritization

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- maxPhotoQualityPrioritization

Instance Property

# maxPhotoQualityPrioritization

The highest quality the photo output should prepare to deliver on a capture-by-capture basis.

var maxPhotoQualityPrioritization: AVCapturePhotoOutput.QualityPrioritization { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxphotoqualityprioritization\#Discussion)

[`AVCapturePhotoOutput`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput) can apply a variety of techniques to improve photo quality, such as reducing noise, preserving detail in low light, freezing motion, and so on. Some techniques improve image quality at the expense of the shot-to-shot time. Before starting your session, you may set this property to indicate the highest quality prioritization you intend to request when calling the [`capturePhoto(with:delegate:)`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturephoto(with:delegate:)) method.

When configuring an [`AVCapturePhotoSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotosettings) object, you can’t exceed this quality prioritization level, but you may select a lower prioritization level that favors speed over quality.

When you attach the photo output to an [`AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession), the default value of this property is [`AVCapturePhotoOutput.QualityPrioritization.balanced`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/qualityprioritization/balanced). If you instead attach it to an [`AVCaptureMultiCamSession`](https://developer.apple.com/documentation/avfoundation/avcapturemulticamsession), the default value is [`AVCapturePhotoOutput.QualityPrioritization.speed`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/qualityprioritization/speed).

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxphotoqualityprioritization\#see-also)

### [Setting the Capture Prioritization](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxphotoqualityprioritization\#Setting-the-Capture-Prioritization)

[`enum QualityPrioritization`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/qualityprioritization)

Constants that indicate how to prioritize photo quality relative to capture speed.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isvirtualdevicefusionsupported

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- isVirtualDeviceFusionSupported

Instance Property

# isVirtualDeviceFusionSupported

A Boolean value that indicates whether the device supports virtual device image fusion.

var isVirtualDeviceFusionSupported: Bool { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isvirtualdevicefusionsupported\#Discussion)

When using a virtual capture device, the system can fuse the images from its constituent cameras to improve image quality.

If the current configuration doesn’t support virtual device fusion, your capture requests always resolve [`isVirtualDeviceFusionEnabled`](https://developer.apple.com/documentation/avfoundation/avcaptureresolvedphotosettings/isvirtualdevicefusionenabled) to [`false`](https://developer.apple.com/documentation/swift/false).

This property is key-value observable.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isvirtualdevicefusionsupported\#see-also)

### [Configuring Virtual Device Capture](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isvirtualdevicefusionsupported\#Configuring-Virtual-Device-Capture)

[`var isVirtualDeviceConstituentPhotoDeliverySupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isvirtualdeviceconstituentphotodeliverysupported)

A Boolean value that indicates whether the photo output configuration supports delivery of photos from constituent cameras of a virtual device.

[`var isVirtualDeviceConstituentPhotoDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isvirtualdeviceconstituentphotodeliveryenabled)

A Boolean value that indicates whether the photo output delivers photos from constituent cameras of a virtual device.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedrawphotopixelformattypes(for:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- supportedRawPhotoPixelFormatTypes(for:)

Instance Method

# supportedRawPhotoPixelFormatTypes(for:)

Returns the list of Bayer RAW pixel formats supported for photo data in the specified file type.

@nonobjc

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedrawphotopixelformattypes(for:)\#parameters)

`fileType`

The file type for which to obtain format information.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedrawphotopixelformattypes(for:)\#return-value)

An array of pixel format types supported for encoding in the specified file type.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedrawphotopixelformattypes(for:)\#Discussion)

When you issue a photo capture request, you can separately specify the format for capturing or encoding image data and the container format for producing output files containing that data. However, each file type supports only a specific set of image data types.

After choosing a file type from the [`availableRawPhotoFileTypes`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablerawphotofiletypes) array, use this method to find a compatible image data format before creating a photo settings object.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedrawphotopixelformattypes(for:)\#see-also)

### [Determining Supported Pixel Formats](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedrawphotopixelformattypes(for:)\#Determining-Supported-Pixel-Formats)

[`var availablePhotoPixelFormatTypes: [OSType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablephotopixelformattypes-3ydgm)

The pixel formats the capture output supports for photo capture.

[`var availableRawPhotoPixelFormatTypes: [OSType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablerawphotopixelformattypes-9t9k5)

The pixel formats the capture output supports for RAW photo capture.

Returns the list of uncompressed pixel formats supported for photo data in the specified file type.

Returns a Boolean value that indicates whether the pixel format is an Apple ProRAW format.

Returns a Boolean value that indicates whether the pixel format is a Bayer RAW format.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataencodedwith

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataEncodedWith

Type Property

# id3MetadataEncodedWith

An identifier that represents the software or hardware and settings used for encoding.

static let id3MetadataEncodedWith: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataencodedwith\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataencodedwith\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/init()

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- init()

Initializer

# init()

Creates a new photo capture output object.

init()

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeUserDataArranger

Type Property

# quickTimeUserDataArranger

An identifier that represents the name of the arranger of the movie file content.

static let quickTimeUserDataArranger: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger\#see-also)

### [QuickTime User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger\#QuickTime-User-Metadata-Identifiers)

[`static let quickTimeUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeUserDataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum)

An identifier that represents the name of the album or collection in QuickTime.

[`static let quickTimeUserDataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeUserDataChapter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatachapter)

An identifier that represents the name of the chapter.

[`static let quickTimeUserDataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeUserDataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacopyright)

An identifier that represents the copyright statement in QuickTime.

[`static let quickTimeUserDataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacreationdate)

An identifier that represents the creation date of the movie file content.

[`static let quickTimeUserDataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacredits)

An identifier that represents the credits of movie source content.

[`static let quickTimeUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadescription)

An identifier that represents the description of the movie file content.

[`static let quickTimeUserDataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadirector)

An identifier that represents the name of the director of the movie file content.

[`static let quickTimeUserDataDisclaimer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadisclaimer)

An identifier that represents the disclaimer regarding the movie file content.

[`static let quickTimeUserDataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataencodedby)

An identifier that represents the name of the person or organization responsible for encoding the movie file content.

[`static let quickTimeUserDataFullName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatafullname)

An identifier that represents the full name of the movie file content.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedphotocodectypes(for:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- supportedPhotoCodecTypes(for:)

Instance Method

# supportedPhotoCodecTypes(for:)

Returns the list of photo codecs (such as JPEG or HEVC) supported for photo data in the specified file type.

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedphotocodectypes(for:)\#parameters)

`fileType`

The file type (such as JFIF or HEIF) for which to obtain codec information.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedphotocodectypes(for:)\#return-value)

An array of video codec types supported for encoding in the specified file type.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedphotocodectypes(for:)\#Discussion)

When you issue a photo capture request, you can separately specify the format for capturing or encoding image data and the container format for producing output files containing that data. However, each file type supports only a specific set of image data types.

After choosing a file type from the [`availablePhotoFileTypes`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablephotofiletypes) array, use this method to find a compatible image data codec before creating a photo settings object.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedphotocodectypes(for:)\#see-also)

### [Determining Supported Codec Types](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedphotocodectypes(for:)\#Determining-Supported-Codec-Types)

[`var availablePhotoCodecTypes: [AVVideoCodecType]`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/availablephotocodectypes)

The compression codecs this capture output currently supports for photo capture.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatakeywordlist

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- identifier3GPUserDataKeywordList

Type Property

# identifier3GPUserDataKeywordList

An identifier that represents the list of keywords for the media.

static let identifier3GPUserDataKeywordList: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatakeywordlist\#see-also)

### [3GP User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatakeywordlist\#3GP-User-Metadata-Identifiers)

[`static let identifier3GPUserDataAlbumAndTrack: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataalbumandtrack)

An identifier that represents the text for the album and track titles.

[`static let identifier3GPUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataauthor)

An identifier that represents the author of the media.

[`static let identifier3GPUserDataCollection: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatacollection)

An identifier that represents the collection name for the media.

[`static let identifier3GPUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatacopyright)

An identifier that represents the copyright statement.

[`static let identifier3GPUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatadescription)

An identifier that represents the description for the media.

[`static let identifier3GPUserDataGenre: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatagenre)

An identifier that represents the genre of the media.

[`static let identifier3GPUserDataLocation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatalocation)

An identifier that represents the location information for the media.

[`static let identifier3GPUserDataMediaClassification: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatamediaclassification)

An identifier that represents the classification of the media content.

[`static let identifier3GPUserDataMediaRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatamediarating)

An identifier that represents the rating of the media content.

[`static let identifier3GPUserDataPerformer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataperformer)

An identifier that represents information about the performer.

[`static let identifier3GPUserDataRecordingYear: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatarecordingyear)

An identifier that represents the recording year for the media.

[`static let identifier3GPUserDataThumbnail: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatathumbnail)

An identifier that represents the media thumbnail.

[`static let identifier3GPUserDataTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatatitle)

An identifier that represents the title for the media.

[`static let identifier3GPUserDataUserRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatauserrating)

An identifier that represents the user rating.

---

# https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/mediasubtypes

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMediaSelectionOption](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption)
- mediaSubTypes

Instance Property

# mediaSubTypes

The media sub-types of the media data associated with the option.

var mediaSubTypes: [NSNumber] { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/mediasubtypes\#Discussion)

The value is an array of `NSNumber` objects carrying four character codes (of type FourCharCode) as defined in `CoreAudioTypes.h` for audio media and in `CMFormatDescription.h` for video media.

Also see [`CMFormatDescriptionGetMediaSubType(_:)`](https://developer.apple.com/documentation/CoreMedia/CMFormatDescriptionGetMediaSubType(_:)) for more information about media subtypes.

## [See Also](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/mediasubtypes\#see-also)

### [Accessing Media Information](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/mediasubtypes\#Accessing-Media-Information)

[`var mediaType: AVMediaType`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/mediatype)

The media type of the media data.

Returns a Boolean value that indicates whether the receiver has media with the given media characteristic.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeUserDataAlbum

Type Property

# quickTimeUserDataAlbum

An identifier that represents the name of the album or collection in QuickTime.

static let quickTimeUserDataAlbum: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum\#see-also)

### [QuickTime User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum\#QuickTime-User-Metadata-Identifiers)

[`static let quickTimeUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeUserDataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeUserDataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeUserDataChapter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatachapter)

An identifier that represents the name of the chapter.

[`static let quickTimeUserDataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeUserDataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacopyright)

An identifier that represents the copyright statement in QuickTime.

[`static let quickTimeUserDataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacreationdate)

An identifier that represents the creation date of the movie file content.

[`static let quickTimeUserDataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacredits)

An identifier that represents the credits of movie source content.

[`static let quickTimeUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadescription)

An identifier that represents the description of the movie file content.

[`static let quickTimeUserDataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadirector)

An identifier that represents the name of the director of the movie file content.

[`static let quickTimeUserDataDisclaimer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadisclaimer)

An identifier that represents the disclaimer regarding the movie file content.

[`static let quickTimeUserDataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataencodedby)

An identifier that represents the name of the person or organization responsible for encoding the movie file content.

[`static let quickTimeUserDataFullName: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatafullname)

An identifier that represents the full name of the movie file content.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameralensmodel

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeMetadataCameraLensModel Beta

Type Property

# quickTimeMetadataCameraLensModel

A value of type kCMMetadataBaseDataType\_UTF8 indicating the lens model (e.g. “iPhone 16 Pro back camera 6.765mm f/1.78”).

static let quickTimeMetadataCameraLensModel: AVMetadataIdentifier

## [Discussion](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameralensmodel\#discussion)

This is track-level metadata for video track that is associated with the camera.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/commonmetadata

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMediaSelectionOption](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption)
- commonMetadata

Instance Property

# commonMetadata

An array of metadata items for each common metadata key for which a value is available.

var commonMetadata: [AVMetadataItem] { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/commonmetadata\#Discussion)

You can filter the array of [`AVMetadataItem`](https://developer.apple.com/documentation/avfoundation/avmetadataitem) objects according to locale using [`metadataItems(from:with:)`](https://developer.apple.com/documentation/avfoundation/avmetadataitem/metadataitems(from:with:)), key using [`metadataItems(from:withKey:keySpace:)`](https://developer.apple.com/documentation/avfoundation/avmetadataitem/metadataitems(from:withkey:keyspace:)), or language using [`metadataItems(from:filteredAndSortedAccordingToPreferredLanguages:)`](https://developer.apple.com/documentation/avfoundation/avmetadataitem/metadataitems(from:filteredandsortedaccordingtopreferredlanguages:)).

Clients that are filtering media selection options by language should be prepared to handle cases in which the [`extendedLanguageTag`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/extendedlanguagetag) property value is `nil`. Further, they should be prepared to handle cases in which an `extendedLanguageTag` is present but indicates that the language is “undetermined” (a language value of @“und”, as defined in ISO 639-2).

## [See Also](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/commonmetadata\#see-also)

### [Managing Metadata](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/commonmetadata\#Managing-Metadata)

[`var availableMetadataFormats: [String]`](https://developer.apple.com/documentation/avfoundation/avmediaselectionoption/availablemetadataformats)

The metadata formats that contain metadata associated with the option.

Returns an array of metadata items—one for each metadata item in the container of a given format.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatafiletype

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataFileType

Type Property

# id3MetadataFileType

An identifier that represents the file type of the audio.

static let id3MetadataFileType: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatafiletype\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatafiletype\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/setoutputsettings(_:for:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVVideoOutputSpecification](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification)
- setOutputSettings(\_:for:)

Instance Method

# setOutputSettings(\_:for:)

Mac Catalyst

func setOutputSettings(
_ outputSettings: [String : any Sendable]?,
for tagCollection: [CMTag]
)

## [See Also](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/setoutputsettings(_:for:)\#see-also)

### [Configuring the specification](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/setoutputsettings(_:for:)\#Configuring-the-specification)

[`var defaultOutputSettings: [String : any Sendable]?`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/defaultoutputsettings)

[`var defaultPixelBufferAttributes: [String : Any]?`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/defaultpixelbufferattributes)

[`func setOutputPixelBufferAttributes([String : Any]?, for: [CMTag])`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/setoutputpixelbufferattributes(_:for:))

[`var preferredTagCollections: [[CMTag]]`](https://developer.apple.com/documentation/avfoundation/avvideooutputspecification/preferredtagcollections-3gdo7)

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataproduct

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeUserDataProduct

Type Property

# quickTimeUserDataProduct

An identifier that represents the name of the product.

static let quickTimeUserDataProduct: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataproduct\#see-also)

### [QuickTime User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataproduct\#QuickTime-User-Metadata-Identifiers)

[`static let quickTimeUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeUserDataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum)

An identifier that represents the name of the album or collection in QuickTime.

[`static let quickTimeUserDataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeUserDataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeUserDataChapter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatachapter)

An identifier that represents the name of the chapter.

[`static let quickTimeUserDataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeUserDataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacopyright)

An identifier that represents the copyright statement in QuickTime.

[`static let quickTimeUserDataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacreationdate)

An identifier that represents the creation date of the movie file content.

[`static let quickTimeUserDataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacredits)

An identifier that represents the credits of movie source content.

[`static let quickTimeUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadescription)

An identifier that represents the description of the movie file content.

[`static let quickTimeUserDataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadirector)

An identifier that represents the name of the director of the movie file content.

[`static let quickTimeUserDataDisclaimer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadisclaimer)

An identifier that represents the disclaimer regarding the movie file content.

[`static let quickTimeUserDataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataencodedby)

An identifier that represents the name of the person or organization responsible for encoding the movie file content.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalsupported

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDeviceInput](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput)
- isWindNoiseRemovalSupported

Instance Property

# isWindNoiseRemovalSupported

var isWindNoiseRemovalSupported: Bool { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalsupported\#see-also)

### [Instance Properties](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalsupported\#Instance-Properties)

[`var isWindNoiseRemovalEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/iswindnoiseremovalenabled)

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdatacopyright

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- isoUserDataCopyright

Type Property

# isoUserDataCopyright

An identifier that represents the copyright statement.

static let isoUserDataCopyright: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdatacopyright\#see-also)

### [ISO Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdatacopyright\#ISO-Metadata-Identifiers)

[`static let isoUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdataaccessibilitydescription)

An identifier that represents the accessibility description for the media content.

[`static let isoUserDataDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdatadate)

An identifier that represents the date for the media content.

[`static let isoUserDataTaggedCharacteristic: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/isouserdatataggedcharacteristic)

An identifier that represents the tagged media characteristic used for identifying accessibility features.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataoriginalformat

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeUserDataOriginalFormat

Type Property

# quickTimeUserDataOriginalFormat

An identifier that represents the original format of the movie file content.

static let quickTimeUserDataOriginalFormat: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataoriginalformat\#see-also)

### [QuickTime User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataoriginalformat\#QuickTime-User-Metadata-Identifiers)

[`static let quickTimeUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeUserDataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum)

An identifier that represents the name of the album or collection in QuickTime.

[`static let quickTimeUserDataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeUserDataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeUserDataChapter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatachapter)

An identifier that represents the name of the chapter.

[`static let quickTimeUserDataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeUserDataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacopyright)

An identifier that represents the copyright statement in QuickTime.

[`static let quickTimeUserDataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacreationdate)

An identifier that represents the creation date of the movie file content.

[`static let quickTimeUserDataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacredits)

An identifier that represents the credits of movie source content.

[`static let quickTimeUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadescription)

An identifier that represents the description of the movie file content.

[`static let quickTimeUserDataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadirector)

An identifier that represents the name of the director of the movie file content.

[`static let quickTimeUserDataDisclaimer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadisclaimer)

An identifier that represents the disclaimer regarding the movie file content.

[`static let quickTimeUserDataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataencodedby)

An identifier that represents the name of the person or organization responsible for encoding the movie file content.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatatime

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataTime

Type Property

# id3MetadataTime

An identifier that represents the time for the recording.

static let id3MetadataTime: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatatime\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatatime\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatainformation

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeMetadataInformation

Type Property

# quickTimeMetadataInformation

An identifier that represents general information about the movie file content.

static let quickTimeMetadataInformation: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatainformation\#see-also)

### [QuickTime Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatainformation\#QuickTime-Metadata-Identifiers)

[`static let quickTimeMetadataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeMetadataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataalbum)

An identifier that represents the name of the album or collection in QuickTime.

[`static let quickTimeMetadataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeMetadataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeMetadataArtwork: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataartwork)

An identifier that represents an image relating to the movie file content.

[`static let quickTimeMetadataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeMetadataAutoLivePhoto: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataautolivephoto)

An identifier that represents whether the live photo movie used auto mode.

[`static let quickTimeMetadataCameraFrameReadoutTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameraframereadouttime)

An identifier that represents the camera frame readout time in QuickTime.

[`static let quickTimeMetadataCameraIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameraidentifier)

An identifier that represents the camera identifier in QuickTime.

[`static let quickTimeMetadataCollectionUser: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacollectionuser)

An identifier that represents a name that indicates a user-defined collection.

[`static let quickTimeMetadataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeMetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeMetadataContentIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacontentidentifier)

An identifier that represents the content identifier in QuickTime.

[`static let quickTimeMetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacopyright)

An identifier that represents the copyright statement for the movie file content.

[`static let quickTimeMetadataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacreationdate)

An identifier that represents the creation date of the movie file content.

---

# https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayerLooper](https://developer.apple.com/documentation/avfoundation/avplayerlooper)
- init(player:templateItem:)

Initializer

# init(player:templateItem:)

Creates a player looper that continuously plays the full duration of a player item.

convenience init(
player: AVQueuePlayer,
templateItem itemToLoop: AVPlayerItem
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:)\#parameters)

`player`

The queue player to use for playback. The player must not be `nil`.

`itemToLoop`

The player item to loop, which must not be `nil`.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:)\#return-value)

An new instance of `AVPlayerLooper`.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:)\#Discussion)

Creating an instance of this class using this method is equivalent to calling [`init(player:templateItem:timeRange:)`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:)) and passing a value of [`invalid`](https://developer.apple.com/documentation/CoreMedia/CMTimeRange/invalid) for the `timeRange` parameter.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:)\#see-also)

### [Creating a Player Looper](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:)\#Creating-a-Player-Looper)

[`init(player: AVQueuePlayer, templateItem: AVPlayerItem, timeRange: CMTimeRange, existingItemsOrdering: AVPlayerLooper.ItemOrdering)`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:))

Creates a player looper that continuously plays the full duration of a player item while adhering to the specified ordering of existing items in the queue.

[`convenience init(player: AVQueuePlayer, templateItem: AVPlayerItem, timeRange: CMTimeRange)`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:))

Creates a player looper that continuously plays the specified time range of a player item.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatauserurl

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataUserURL

Type Property

# id3MetadataUserURL

An identifier that represents the user webpage frame.

static let id3MetadataUserURL: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatauserurl\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatauserurl\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatauniquefileidentifier

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataUniqueFileIdentifier

Type Property

# id3MetadataUniqueFileIdentifier

An identifier that represents the identifier used to indicate the audio file in a database.

static let id3MetadataUniqueFileIdentifier: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatauniquefileidentifier\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatauniquefileidentifier\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/capture-device-zoom

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Capture setup](https://developer.apple.com/documentation/avfoundation/capture-setup)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- Zoom

API Collection

# Zoom

Configure device zooming behavior and inspect hardware capabilities.

## [Topics](https://developer.apple.com/documentation/avfoundation/capture-device-zoom\#topics)

### [Adjusting Zoom](https://developer.apple.com/documentation/avfoundation/capture-device-zoom\#Adjusting-Zoom)

[`var videoZoomFactor: CGFloat`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/videozoomfactor)

A value that controls the cropping and enlargement of images captured by the device.

[`func ramp(toVideoZoomFactor: CGFloat, withRate: Float)`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/ramp(tovideozoomfactor:withrate:))

Begins a smooth transition from the current zoom factor to another.

[`func cancelVideoZoomRamp()`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/cancelvideozoomramp())

Smoothly ends a zoom transition in progress.

### [Observing Zoom](https://developer.apple.com/documentation/avfoundation/capture-device-zoom\#Observing-Zoom)

[`var isRampingVideoZoom: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/isrampingvideozoom)

A Boolean value that indicates whether a zoom transition is in progress.

### [Inspecting Zoom Factors](https://developer.apple.com/documentation/avfoundation/capture-device-zoom\#Inspecting-Zoom-Factors)

[`var minAvailableVideoZoomFactor: CGFloat`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/minavailablevideozoomfactor)

The minimum zoom factor allowed in the current capture configuration.

[`var maxAvailableVideoZoomFactor: CGFloat`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/maxavailablevideozoomfactor)

The maximum zoom factor allowed in the current capture configuration.

[`var virtualDeviceSwitchOverVideoZoomFactors: [NSNumber]`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/virtualdeviceswitchovervideozoomfactors)

An array of video zoom factors at or above which a virtual device, such as the dual camera, may switch to its next constituent device.

[`var dualCameraSwitchOverVideoZoomFactor: CGFloat`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/dualcameraswitchovervideozoomfactor)

The video zoom factor at which a dual camera device can automatically switch between cameras.

Deprecated

[`var displayVideoZoomFactorMultiplier: CGFloat`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/displayvideozoomfactormultiplier)

A video zoom factor multiplier to use when displaying zoom information in a user interface.

### [Enabling Geometric Distortion Correction](https://developer.apple.com/documentation/avfoundation/capture-device-zoom\#Enabling-Geometric-Distortion-Correction)

[`var isGeometricDistortionCorrectionSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/isgeometricdistortioncorrectionsupported)

A Boolean value that indicates whether this device supports geometric distortion correction.

[`var isGeometricDistortionCorrectionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/isgeometricdistortioncorrectionenabled)

A Boolean value that indicates whether geometric distortion correction is enabled for this device.

## [See Also](https://developer.apple.com/documentation/avfoundation/capture-device-zoom\#see-also)

### [Configuring Camera Hardware](https://developer.apple.com/documentation/avfoundation/capture-device-zoom\#Configuring-Camera-Hardware)

[`func lockForConfiguration() throws`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lockforconfiguration())

Requests exclusive access to configure device hardware properties.

[`func unlockForConfiguration()`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/unlockforconfiguration())

Releases exclusive control over device hardware properties.

[`var isSubjectAreaChangeMonitoringEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/issubjectareachangemonitoringenabled)

A Boolean value that indicates whether the device monitors the subject area for changes.

[`class let subjectAreaDidChangeNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/subjectareadidchangenotification)

A notification the system posts when a capture device detects a substantial change to the video subject area.

Configure capture formats and camera frame rates.

Configure the automatic focus behavior of a camera, or manually set its lens position.

Configure the automatic exposure behavior of a camera, or manually control its exposure settings.

Configure the automatic white balance behavior of a camera, or manually control white balance settings.

Configure the device flash, torch, and low light settings.

Manage HDR and color space settings for a device.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedevice/systempressurestate-swift.property

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- systemPressureState

Instance Property

# systemPressureState

A value that indicates the capture device’s current system pressure state.

var systemPressureState: AVCaptureDevice.SystemPressureState { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturedevice/systempressurestate-swift.property\#Discussion)

This property indicates whether the capture device is currently in an elevated system pressure condition. When system pressure reaches a [`shutdown`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/systempressurestate-swift.class/level-swift.struct/shutdown) state, the capture device can’t continue to provide input, and the capture session becomes interrupted until the pressured state abates.

You can effectively mitigate system pressure by lowering the device’s [`activeVideoMinFrameDuration`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activevideominframeduration) in response to changes in the system pressure state. Implement frame rate throttling to bring system pressure down if your capture use case can tolerate a reduced frame rate.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedevice/systempressurestate-swift.property\#see-also)

### [Monitoring System Pressure](https://developer.apple.com/documentation/avfoundation/avcapturedevice/systempressurestate-swift.property\#Monitoring-System-Pressure)

[`class SystemPressureState`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/systempressurestate-swift.class)

An object that provides information about OS and hardware status affecting capture system performance and availability.

[`let AVCaptureSessionInterruptionSystemPressureStateKey: String`](https://developer.apple.com/documentation/avfoundation/avcapturesessioninterruptionsystempressurestatekey)

A key to retrieve a state value that indicates the system pressure level and contributing factors that caused the interruption.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedevice/subjectareadidchangenotification

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- subjectAreaDidChangeNotification

Type Property

# subjectAreaDidChangeNotification

A notification the system posts when a capture device detects a substantial change to the video subject area.

class let subjectAreaDidChangeNotification: NSNotification.Name

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturedevice/subjectareadidchangenotification\#Discussion)

The system posts this notification only if the device’s [`isSubjectAreaChangeMonitoringEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/issubjectareachangemonitoringenabled) property value is [`true`](https://developer.apple.com/documentation/swift/true).

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedevice/subjectareadidchangenotification\#see-also)

### [Configuring Camera Hardware](https://developer.apple.com/documentation/avfoundation/avcapturedevice/subjectareadidchangenotification\#Configuring-Camera-Hardware)

[`func lockForConfiguration() throws`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lockforconfiguration())

Requests exclusive access to configure device hardware properties.

[`func unlockForConfiguration()`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/unlockforconfiguration())

Releases exclusive control over device hardware properties.

[`var isSubjectAreaChangeMonitoringEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/issubjectareachangemonitoringenabled)

A Boolean value that indicates whether the device monitors the subject area for changes.

Configure capture formats and camera frame rates.

Configure the automatic focus behavior of a camera, or manually set its lens position.

Configure the automatic exposure behavior of a camera, or manually control its exposure settings.

Configure the automatic white balance behavior of a camera, or manually control white balance settings.

Configure the device flash, torch, and low light settings.

Manage HDR and color space settings for a device.

Configure device zooming behavior and inspect hardware capabilities.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/unifiedautoexposuredefaultsenabled

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDeviceInput](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput)
- unifiedAutoExposureDefaultsEnabled

Instance Property

# unifiedAutoExposureDefaultsEnabled

A Boolean value that indicates whether the input enables unified auto-exposure defaults.

var unifiedAutoExposureDefaultsEnabled: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/unifiedautoexposuredefaultsenabled\#Discussion)

You may set the value of a capture device’s [`activeFormat`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activeformat) in two ways:

1. Set it directly using one of the formats in the device’s [`formats`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/formats) property.

2. The capture session sets it on your behalf when you set its [`sessionPreset`](https://developer.apple.com/documentation/avfoundation/avcapturesession/sessionpreset) property.

Depending on the device and format, you may configure the default auto exposure behavior differently when you use one method or the other, resulting in non-uniform auto exposure behavior. Auto exposure defaults include [`minFrameRate`](https://developer.apple.com/documentation/avfoundation/avframeraterange/minframerate), [`maxFrameRate`](https://developer.apple.com/documentation/avfoundation/avframeraterange/maxframerate), and [`maxExposureDuration`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/format/maxexposureduration). You can set this property to [`true`](https://developer.apple.com/documentation/swift/true) to ensure that the system applies consistent default behaviors to the device regardless of the way you set the active format.

The default value is [`false`](https://developer.apple.com/documentation/swift/false).

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/unifiedautoexposuredefaultsenabled\#see-also)

### [Configuring video properties](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/unifiedautoexposuredefaultsenabled\#Configuring-video-properties)

[`var videoMinFrameDurationOverride: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput/videominframedurationoverride)

A time value that acts as a modifier to a capture device’s active video minimum frame duration.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedevice/supportssessionpreset(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- supportsSessionPreset(\_:)

Instance Method

# supportsSessionPreset(\_:)

Returns a Boolean value that indicates whether you can use the device with capture session configured with the specified preset.

## [Parameters](https://developer.apple.com/documentation/avfoundation/avcapturedevice/supportssessionpreset(_:)\#parameters)

`preset`

A capture session preset.

## [Return Value](https://developer.apple.com/documentation/avfoundation/avcapturedevice/supportssessionpreset(_:)\#return-value)

[`true`](https://developer.apple.com/documentation/swift/true) if you can use the device; otherwise, [`false`](https://developer.apple.com/documentation/swift/false).

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturedevice/supportssessionpreset(_:)\#see-also)

### [Inspecting Device Characteristics](https://developer.apple.com/documentation/avfoundation/avcapturedevice/supportssessionpreset(_:)\#Inspecting-Device-Characteristics)

[`var isVirtualDevice: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/isvirtualdevice)

A Boolean value that indicates whether the device consists of two or more physical devices.

[`var constituentDevices: [AVCaptureDevice]`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/constituentdevices)

An array of physical devices that make up a virtual device.

Returns a Boolean value that indicates whether the device captures media of a particular type.

[`var transportType: Int32`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/transporttype)

The transport type of the device.

---

# https://developer.apple.com/documentation/avfoundation/avfiletype/avci

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVFileType](https://developer.apple.com/documentation/avfoundation/avfiletype)
- avci

Type Property

# avci

The UTI for the high-efficiency image file format that contains H.264 compressed images.

static let avci: AVFileType

## [Discussion](https://developer.apple.com/documentation/avfoundation/avfiletype/avci\#Discussion)

The value of this UTI is `public.avci`. Files of this type have an `.avci` extension.

## [See Also](https://developer.apple.com/documentation/avfoundation/avfiletype/avci\#see-also)

### [File Types](https://developer.apple.com/documentation/avfoundation/avfiletype/avci\#File-Types)

[`static let ac3: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/ac3)

The UTI for the AC3 audio file format.

[`static let aifc: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/aifc)

The UTI for the AIFC audio file format.

[`static let aiff: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/aiff)

The UTI for the AIFF audio file format.

[`static let AHAP: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/ahap)

The UTI for the Apple Haptics Audio Pattern file format.

[`static let amr: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/amr)

The UTI for the adaptive multirate audio file format.

[`static let appleiTT: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/appleitt)

The UTI for the Apple iTT caption file format.

[`static let au: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/au)

The UTI for the Sun/NeXT audio file format.

[`static let caf: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/caf)

The UTI for the Core Audio Format.

[`static let dng: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/dng)

The UTI for the Adobe Digital Negative file format.

[`static let eac3: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/eac3)

The UTI for the enhanced AC3 audio file format.

[`static let heic: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/heic)

The UTI for the high-efficiency image file format that contains HEVC compressed images.

[`static let heif: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/heif)

The UTI for the high-efficiency image file format that contains compressed images from any codec.

[`static let jpg: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/jpg)

The UTI for the JPEG (JFIF) format.

[`static let m4a: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/m4a)

The UTI for the Apple m4a audio file format.

[`static let m4v: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/m4v)

The UTI for the iTunes video file format.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus/init(rawvalue:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- [AVCaptureDevice.LensStabilizationStatus](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lensstabilizationstatus)
- init(rawValue:)

Initializer

# init(rawValue:)

init?(rawValue: Int)

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxbracketedcapturephotocount

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- maxBracketedCapturePhotoCount

Instance Property

# maxBracketedCapturePhotoCount

The maximum number of images that the photo capture output can support in a single bracketed capture.

var maxBracketedCapturePhotoCount: Int { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxbracketedcapturephotocount\#Discussion)

To perform a bracketed capture of multiple images with varied capture settings, create a [`AVCapturePhotoBracketSettings`](https://developer.apple.com/documentation/avfoundation/avcapturephotobracketsettings) instance containing the combination of settings and bracketed variations you want. The maximum number of photos per capture depends on the size and format of images to be captured.

This property supports key-value observing.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxbracketedcapturephotocount\#see-also)

### [Determining Available Settings](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxbracketedcapturephotocount\#Determining-Available-Settings)

[`var isContentAwareDistortionCorrectionSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionsupported)

A Boolean value that indicates whether the session’s current configuration supports content-aware distortion correction.

[`var isContentAwareDistortionCorrectionEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionenabled)

A Boolean value that indicates whether the photo render pipeline can perform content-aware distortion correction.

[`var isLensStabilizationDuringBracketedCaptureSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islensstabilizationduringbracketedcapturesupported)

A Boolean value indicating whether the capture output currently supports lens stabilization during bracketed image capture.

[`var supportedFlashModes: [AVCaptureDevice.FlashMode]`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedflashmodes-1n6nm)

A Swift array of flash settings this capture output currently supports.

[`var isAutoRedEyeReductionSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isautoredeyereductionsupported)

A Boolean value indicating whether the capture output supports automatic red-eye reduction.

---

# https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVPlayerLooper](https://developer.apple.com/documentation/avfoundation/avplayerlooper)
- init(player:templateItem:timeRange:existingItemsOrdering:)

Initializer

# init(player:templateItem:timeRange:existingItemsOrdering:)

Creates a player looper that continuously plays the full duration of a player item while adhering to the specified ordering of existing items in the queue.

init(
player: AVQueuePlayer,
templateItem itemToLoop: AVPlayerItem,
timeRange loopRange: CMTimeRange,
existingItemsOrdering itemOrdering: AVPlayerLooper.ItemOrdering
)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:)\#parameters)

`player`

A queue player to control playback.

`itemToLoop`

A player item to loop.

`loopRange`

The player item time range to loop. Passing a value of [`invalid`](https://developer.apple.com/documentation/CoreMedia/CMTimeRange/invalid) is equivalent to a time range of \[0, player item’s duration\].

`itemOrdering`

A value that indicates whether the looper inserts replica items before or after existing items in the specified queue player.

## [Discussion](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:)\#Discussion)

The player looper doesn’t use the player item you specify for playback, and instead uses it as a template to create at least three player item replicas that it uses for looping playback. Because the looper only uses the player item as a template, any changes that you make to it after initialization aren’t reflected in the looping playback.

## [Topics](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:)\#topics)

### [Item ordering](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:)\#Item-ordering)

[`enum ItemOrdering`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/itemordering)

Constants that define the ordering of items in a player looper.

## [See Also](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:)\#see-also)

### [Creating a Player Looper](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:existingitemsordering:)\#Creating-a-Player-Looper)

[`convenience init(player: AVQueuePlayer, templateItem: AVPlayerItem)`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:))

Creates a player looper that continuously plays the full duration of a player item.

[`convenience init(player: AVQueuePlayer, templateItem: AVPlayerItem, timeRange: CMTimeRange)`](https://developer.apple.com/documentation/avfoundation/avplayerlooper/init(player:templateitem:timerange:))

Creates a player looper that continuously plays the specified time range of a player item.

---

# https://developer.apple.com/documentation/avfoundation/avfiletype/heic

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVFileType](https://developer.apple.com/documentation/avfoundation/avfiletype)
- heic

Type Property

# heic

The UTI for the high-efficiency image file format that contains HEVC compressed images.

static let heic: AVFileType

## [Discussion](https://developer.apple.com/documentation/avfoundation/avfiletype/heic\#Discussion)

The value of this UTI is `public.heic`. Files of this type have an `.heic` extension.

## [See Also](https://developer.apple.com/documentation/avfoundation/avfiletype/heic\#see-also)

### [File Types](https://developer.apple.com/documentation/avfoundation/avfiletype/heic\#File-Types)

[`static let ac3: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/ac3)

The UTI for the AC3 audio file format.

[`static let aifc: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/aifc)

The UTI for the AIFC audio file format.

[`static let aiff: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/aiff)

The UTI for the AIFF audio file format.

[`static let AHAP: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/ahap)

The UTI for the Apple Haptics Audio Pattern file format.

[`static let amr: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/amr)

The UTI for the adaptive multirate audio file format.

[`static let appleiTT: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/appleitt)

The UTI for the Apple iTT caption file format.

[`static let au: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/au)

The UTI for the Sun/NeXT audio file format.

[`static let avci: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/avci)

The UTI for the high-efficiency image file format that contains H.264 compressed images.

[`static let caf: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/caf)

The UTI for the Core Audio Format.

[`static let dng: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/dng)

The UTI for the Adobe Digital Negative file format.

[`static let eac3: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/eac3)

The UTI for the enhanced AC3 audio file format.

[`static let heif: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/heif)

The UTI for the high-efficiency image file format that contains compressed images from any codec.

[`static let jpg: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/jpg)

The UTI for the JPEG (JFIF) format.

[`static let m4a: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/m4a)

The UTI for the Apple m4a audio file format.

[`static let m4v: AVFileType`](https://developer.apple.com/documentation/avfoundation/avfiletype/m4v)

The UTI for the iTunes video file format.

---

# https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/response

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVAssetResourceLoadingRequest](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest)
- response

Instance Property

# response

The URL response for the loading request.

@NSCopying
var response: URLResponse? { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/response\#Discussion)

The value of this property is an instance of [`URLResponse`](https://developer.apple.com/documentation/Foundation/URLResponse), indicating a response to the loading request. If no response is needed, the value of this property is `nil`.

## [See Also](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/response\#see-also)

### [Reporting the Result of the Request](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/response\#Reporting-the-Result-of-the-Request)

[`func finishLoading()`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading())

Causes the receiver to treat the processing of the request as complete.

[`var isCancelled: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/iscancelled)

A Boolean value that indicates whether the request has been cancelled.

[`func finishLoading(with: (any Error)?)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:))

Causes the receiver to handle the failure to load a resource for which a resource loader’s delegate took responsibility.

[`var isFinished: Bool`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/isfinished)

A Boolean value that indicates whether loading of the resource has finished.

[`func finishLoading(with: URLResponse?, data: Data?, redirect: URLRequest?)`](https://developer.apple.com/documentation/avfoundation/avassetresourceloadingrequest/finishloading(with:data:redirect:))

Causes the receiver to finish loading a resource for which a resource loader’s delegate took responsibility .

Deprecated

---

# https://developer.apple.com/documentation/avfoundation/avcapturedevice/minexposurerectofinterestsize

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- minExposureRectOfInterestSize Beta

Instance Property

# minExposureRectOfInterestSize

var minExposureRectOfInterestSize: CGSize { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturedevice/minexposurerectofinterestsize\#discussion)

Returns the minimum size that can be used when specifying a rectangle of interest.

The size returned is in normalized coordinates, and will depend on the current active format. If isExposureRectOfInterestSupported returns NO, this property will return { 0, 0 }.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatadate

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- id3MetadataDate

Type Property

# id3MetadataDate

An identifier that represents the date for the recording.

static let id3MetadataDate: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatadate\#see-also)

### [ID3 Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatadate\#ID3-Metadata-Identifiers)

[`static let id3MetadataAlbumSortOrder: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumsortorder)

An identifier that represents how to sort the album.

[`static let id3MetadataAlbumTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataalbumtitle)

An identifier that represents the title of the recording.

[`static let id3MetadataAttachedPicture: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataattachedpicture)

An identifier that represents an image relating to the audio file.

[`static let id3MetadataAudioEncryption: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioencryption)

An identifier that represents the encryption details of the audio stream.

[`static let id3MetadataAudioSeekPointIndex: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataaudioseekpointindex)

An identifier that represents the list of seek points within the audio file.

[`static let id3MetadataBand: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataband)

An identifier that represents additional information about the performers in the recording.

[`static let id3MetadataBeatsPerMinute: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatabeatsperminute)

An identifier that represents the beats per minute of the audio.

[`static let id3MetadataComments: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomments)

An identifier that represents additional text information for the media.

[`static let id3MetadataCommercial: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercial)

An identifier that represents the commercial details for the media.

[`static let id3MetadataCommercialInformation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacommercialinformation)

An identifier that represents the webpage containing purchasing information.

[`static let id3MetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacomposer)

An identifier that represents the name of the composer.

[`static let id3MetadataConductor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadataconductor)

An identifier that represents the name of the conductor.

[`static let id3MetadataContentGroupDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontentgroupdescription)

An identifier that indicates the sound belongs to a larger category of sounds or music.

[`static let id3MetadataContentType: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacontenttype)

An identifier that represents the media content type.

[`static let id3MetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/id3metadatacopyright)

An identifier that represents the copyright statement.

---

# https://developer.apple.com/documentation/avfoundation/avcapturedevice/isexposurerectofinterestsupported

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- isExposureRectOfInterestSupported Beta

Instance Property

# isExposureRectOfInterestSupported

var isExposureRectOfInterestSupported: Bool { get }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturedevice/isexposurerectofinterestsupported\#discussion)

Indicates whether the receiver supports exposure rectangles of interest.

The receiver’s exposureRectOfInterestSupported property can only be set if this property returns YES.

Beta Software

This documentation contains preliminary information about an API or technology in development. This information is subject to change, and software implemented according to this documentation should be tested with final operating system software.

[Learn more about using Apple's beta software](https://developer.apple.com/support/beta-software/)

---

# https://developer.apple.com/documentation/avfoundation/avfiletype/init(_:)

#app-main)

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVFileType](https://developer.apple.com/documentation/avfoundation/avfiletype)
- init(\_:)

Initializer

# init(\_:)

Creates a file type with a string.

iOSiPadOSMac CatalystmacOStvOSvisionOSwatchOS

init(_ rawValue: String)

## [Parameters](https://developer.apple.com/documentation/avfoundation/avfiletype/init(_:)\#parameters)

`rawValue`

The raw string value.

## [See Also](https://developer.apple.com/documentation/avfoundation/avfiletype/init(_:)\#see-also)

### [Initializers](https://developer.apple.com/documentation/avfoundation/avfiletype/init(_:)\#Initializers)

[`init(rawValue: String)`](https://developer.apple.com/documentation/avfoundation/avfiletype/init(rawvalue:))

Creates a file type from its raw string value.

---

# https://developer.apple.com/documentation/avfoundation/capture-device-formats

Collection

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [Capture setup](https://developer.apple.com/documentation/avfoundation/capture-setup)
- [AVCaptureDevice](https://developer.apple.com/documentation/avfoundation/avcapturedevice)
- Formats

API Collection

# Formats

Configure capture formats and camera frame rates.

## [Overview](https://developer.apple.com/documentation/avfoundation/capture-device-formats\#overview)

The following code example illustrates how to select an iOS device’s highest possible frame rate:

func configureCameraForHighestFrameRate(device: AVCaptureDevice) {

var bestFormat: AVCaptureDevice.Format?
var bestFrameRateRange: AVFrameRateRange?

for format in device.formats {
for range in format.videoSupportedFrameRateRanges {

bestFormat = format
bestFrameRateRange = range
}
}
}

if let bestFormat = bestFormat,
let bestFrameRateRange = bestFrameRateRange {
do {
try device.lockForConfiguration()

// Set the device's active format.
device.activeFormat = bestFormat

// Set the device's min/max frame duration.
let duration = bestFrameRateRange.minFrameDuration
device.activeVideoMinFrameDuration = duration
device.activeVideoMaxFrameDuration = duration

device.unlockForConfiguration()
} catch {
// Handle error.
}
}
}

Most common configurations of capture settings are available through the [`AVCaptureSession`](https://developer.apple.com/documentation/avfoundation/avcapturesession) object and its available presets. However, on iOS devices, some specialized options (such as high frame rate) require directly setting a capture format on an [`AVCaptureDevice`](https://developer.apple.com/documentation/avfoundation/avcapturedevice) instance.

## [Topics](https://developer.apple.com/documentation/avfoundation/capture-device-formats\#topics)

### [Configuring Capture Formats](https://developer.apple.com/documentation/avfoundation/capture-device-formats\#Configuring-Capture-Formats)

[`var formats: [AVCaptureDevice.Format]`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/formats)

The capture formats a device supports.

[`var activeFormat: AVCaptureDevice.Format`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activeformat)

The capture format in use by the device.

[`var activeDepthDataFormat: AVCaptureDevice.Format?`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activedepthdataformat)

The currently active depth data format of the capture device.

[`class Format`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/format)

A class that defines media formats and capture settings that capture devices support.

### [Configuring Frame Durations](https://developer.apple.com/documentation/avfoundation/capture-device-formats\#Configuring-Frame-Durations)

[`var activeVideoMinFrameDuration: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activevideominframeduration)

The currently active minimum frame duration.

[`var activeVideoMaxFrameDuration: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activevideomaxframeduration)

The currently active maximum frame duration.

[`var activeDepthDataMinFrameDuration: CMTime`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/activedepthdataminframeduration)

The minimum frame duration of depth data.

## [See Also](https://developer.apple.com/documentation/avfoundation/capture-device-formats\#see-also)

### [Configuring Camera Hardware](https://developer.apple.com/documentation/avfoundation/capture-device-formats\#Configuring-Camera-Hardware)

[`func lockForConfiguration() throws`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/lockforconfiguration())

Requests exclusive access to configure device hardware properties.

[`func unlockForConfiguration()`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/unlockforconfiguration())

Releases exclusive control over device hardware properties.

[`var isSubjectAreaChangeMonitoringEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/issubjectareachangemonitoringenabled)

A Boolean value that indicates whether the device monitors the subject area for changes.

[`class let subjectAreaDidChangeNotification: NSNotification.Name`](https://developer.apple.com/documentation/avfoundation/avcapturedevice/subjectareadidchangenotification)

A notification the system posts when a capture device detects a substantial change to the video subject area.

Configure the automatic focus behavior of a camera, or manually set its lens position.

Configure the automatic exposure behavior of a camera, or manually control its exposure settings.

Configure the automatic white balance behavior of a camera, or manually control white balance settings.

Configure the device flash, torch, and low light settings.

Manage HDR and color space settings for a device.

Configure device zooming behavior and inspect hardware capabilities.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataalbum

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeMetadataAlbum

Type Property

# quickTimeMetadataAlbum

An identifier that represents the name of the album or collection in QuickTime.

static let quickTimeMetadataAlbum: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataalbum\#see-also)

### [QuickTime Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataalbum\#QuickTime-Metadata-Identifiers)

[`static let quickTimeMetadataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeMetadataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeMetadataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeMetadataArtwork: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataartwork)

An identifier that represents an image relating to the movie file content.

[`static let quickTimeMetadataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeMetadataAutoLivePhoto: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadataautolivephoto)

An identifier that represents whether the live photo movie used auto mode.

[`static let quickTimeMetadataCameraFrameReadoutTime: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameraframereadouttime)

An identifier that represents the camera frame readout time in QuickTime.

[`static let quickTimeMetadataCameraIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacameraidentifier)

An identifier that represents the camera identifier in QuickTime.

[`static let quickTimeMetadataCollectionUser: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacollectionuser)

An identifier that represents a name that indicates a user-defined collection.

[`static let quickTimeMetadataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeMetadataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeMetadataContentIdentifier: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacontentidentifier)

An identifier that represents the content identifier in QuickTime.

[`static let quickTimeMetadataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacopyright)

An identifier that represents the copyright statement for the movie file content.

[`static let quickTimeMetadataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacreationdate)

An identifier that represents the creation date of the movie file content.

[`static let quickTimeMetadataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimemetadatacredits)

An identifier that represents the credits of the movie source content.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatamodel

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeUserDataModel

Type Property

# quickTimeUserDataModel

An identifier that represents the name of the camera model.

static let quickTimeUserDataModel: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatamodel\#see-also)

### [QuickTime User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatamodel\#QuickTime-User-Metadata-Identifiers)

[`static let quickTimeUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeUserDataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum)

An identifier that represents the name of the album or collection in QuickTime.

[`static let quickTimeUserDataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeUserDataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeUserDataChapter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatachapter)

An identifier that represents the name of the chapter.

[`static let quickTimeUserDataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeUserDataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacopyright)

An identifier that represents the copyright statement in QuickTime.

[`static let quickTimeUserDataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacreationdate)

An identifier that represents the creation date of the movie file content.

[`static let quickTimeUserDataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacredits)

An identifier that represents the credits of movie source content.

[`static let quickTimeUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadescription)

An identifier that represents the description of the movie file content.

[`static let quickTimeUserDataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadirector)

An identifier that represents the name of the director of the movie file content.

[`static let quickTimeUserDataDisclaimer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadisclaimer)

An identifier that represents the disclaimer regarding the movie file content.

[`static let quickTimeUserDataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataencodedby)

An identifier that represents the name of the person or organization responsible for encoding the movie file content.

---

# https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage/position

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVRenderedCaptionImage](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage)
- position

Instance Property

# position

A point that defines the position, in pixels, of the rendered caption image relative to the video frame.

var position: CGPoint { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage/position\#see-also)

### [Inspecting the image](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage/position\#Inspecting-the-image)

[`var pixelBuffer: CVPixelBuffer`](https://developer.apple.com/documentation/avfoundation/avrenderedcaptionimage/pixelbuffer)

An object that contains pixel data for the rendered caption.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatatrackname

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- quickTimeUserDataTrackName

Type Property

# quickTimeUserDataTrackName

An identifier that represents the name of a track in the movie file content.

static let quickTimeUserDataTrackName: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatatrackname\#see-also)

### [QuickTime User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatatrackname\#QuickTime-User-Metadata-Identifiers)

[`static let quickTimeUserDataAccessibilityDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataaccessibilitydescription)

An identifier that represents the accessibility description for the movie file content.

[`static let quickTimeUserDataAlbum: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataalbum)

An identifier that represents the name of the album or collection in QuickTime.

[`static let quickTimeUserDataArranger: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataarranger)

An identifier that represents the name of the arranger of the movie file content.

[`static let quickTimeUserDataArtist: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataartist)

An identifier that represents the name of the artist of the movie file content.

[`static let quickTimeUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataauthor)

An identifier that represents the name of the author of the movie file content.

[`static let quickTimeUserDataChapter: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatachapter)

An identifier that represents the name of the chapter.

[`static let quickTimeUserDataComment: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomment)

An identifier that represents a comment regarding the movie file content.

[`static let quickTimeUserDataComposer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacomposer)

An identifier that represents the name of the composer of the movie file content.

[`static let quickTimeUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacopyright)

An identifier that represents the copyright statement in QuickTime.

[`static let quickTimeUserDataCreationDate: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacreationdate)

An identifier that represents the creation date of the movie file content.

[`static let quickTimeUserDataCredits: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatacredits)

An identifier that represents the credits of movie source content.

[`static let quickTimeUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadescription)

An identifier that represents the description of the movie file content.

[`static let quickTimeUserDataDirector: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadirector)

An identifier that represents the name of the director of the movie file content.

[`static let quickTimeUserDataDisclaimer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdatadisclaimer)

An identifier that represents the disclaimer regarding the movie file content.

[`static let quickTimeUserDataEncodedBy: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/quicktimeuserdataencodedby)

An identifier that represents the name of the person or organization responsible for encoding the movie file content.

---

# https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatamediarating

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVMetadataIdentifier](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier)
- identifier3GPUserDataMediaRating

Type Property

# identifier3GPUserDataMediaRating

An identifier that represents the rating of the media content.

static let identifier3GPUserDataMediaRating: AVMetadataIdentifier

## [See Also](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatamediarating\#see-also)

### [3GP User Metadata Identifiers](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatamediarating\#3GP-User-Metadata-Identifiers)

[`static let identifier3GPUserDataAlbumAndTrack: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataalbumandtrack)

An identifier that represents the text for the album and track titles.

[`static let identifier3GPUserDataAuthor: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataauthor)

An identifier that represents the author of the media.

[`static let identifier3GPUserDataCollection: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatacollection)

An identifier that represents the collection name for the media.

[`static let identifier3GPUserDataCopyright: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatacopyright)

An identifier that represents the copyright statement.

[`static let identifier3GPUserDataDescription: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatadescription)

An identifier that represents the description for the media.

[`static let identifier3GPUserDataGenre: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatagenre)

An identifier that represents the genre of the media.

[`static let identifier3GPUserDataKeywordList: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatakeywordlist)

An identifier that represents the list of keywords for the media.

[`static let identifier3GPUserDataLocation: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatalocation)

An identifier that represents the location information for the media.

[`static let identifier3GPUserDataMediaClassification: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatamediaclassification)

An identifier that represents the classification of the media content.

[`static let identifier3GPUserDataPerformer: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdataperformer)

An identifier that represents information about the performer.

[`static let identifier3GPUserDataRecordingYear: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatarecordingyear)

An identifier that represents the recording year for the media.

[`static let identifier3GPUserDataThumbnail: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatathumbnail)

An identifier that represents the media thumbnail.

[`static let identifier3GPUserDataTitle: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatatitle)

An identifier that represents the title for the media.

[`static let identifier3GPUserDataUserRating: AVMetadataIdentifier`](https://developer.apple.com/documentation/avfoundation/avmetadataidentifier/identifier3gpuserdatauserrating)

An identifier that represents the user rating.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionenabled

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- isContentAwareDistortionCorrectionEnabled

Instance Property

# isContentAwareDistortionCorrectionEnabled

A Boolean value that indicates whether the photo render pipeline can perform content-aware distortion correction.

var isContentAwareDistortionCorrectionEnabled: Bool { get set }

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionenabled\#Discussion)

You can set this value to true only if [`isContentAwareDistortionCorrectionSupported`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionsupported) returns true.

Applying distortion correction to preserve natural-looking content may result in a small change in the field of view compared to what you see in [`AVCaptureVideoPreviewLayer`](https://developer.apple.com/documentation/avfoundation/avcapturevideopreviewlayer). The amount lost or gained is content specific and varies from photo to photo.

Enabling this property requires a lengthy reconfiguration of the capture render pipeline, so set this property to [`true`](https://developer.apple.com/documentation/swift/true) before calling [`startRunning()`](https://developer.apple.com/documentation/avfoundation/avcapturesession/startrunning()) on the capture session.

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionenabled\#see-also)

### [Determining Available Settings](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionenabled\#Determining-Available-Settings)

[`var isContentAwareDistortionCorrectionSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iscontentawaredistortioncorrectionsupported)

A Boolean value that indicates whether the session’s current configuration supports content-aware distortion correction.

[`var isLensStabilizationDuringBracketedCaptureSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/islensstabilizationduringbracketedcapturesupported)

A Boolean value indicating whether the capture output currently supports lens stabilization during bracketed image capture.

[`var maxBracketedCapturePhotoCount: Int`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/maxbracketedcapturephotocount)

The maximum number of images that the photo capture output can support in a single bracketed capture.

[`var supportedFlashModes: [AVCaptureDevice.FlashMode]`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/supportedflashmodes-1n6nm)

A Swift array of flash settings this capture output currently supports.

[`var isAutoRedEyeReductionSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isautoredeyereductionsupported)

A Boolean value indicating whether the capture output supports automatic red-eye reduction.

---

# https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isresponsivecapturesupported

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCapturePhotoOutput](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput)
- isResponsiveCaptureSupported

Instance Property

# isResponsiveCaptureSupported

A Boolean value that indicates whether the photo output supports responsive capture.

var isResponsiveCaptureSupported: Bool { get }

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isresponsivecapturesupported\#see-also)

### [Managing Responsive Capture](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isresponsivecapturesupported\#Managing-Responsive-Capture)

[`var captureReadiness: AVCapturePhotoOutput.CaptureReadiness`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturereadiness-swift.property)

A value that specifies whether the photo output is ready to respond to new capture requests in a timely manner.

[`enum CaptureReadiness`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/capturereadiness-swift.enum)

Constants that indicate whether the output is ready to receive capture requests.

[`var isAutoDeferredPhotoDeliveryEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isautodeferredphotodeliveryenabled)

A Boolean value that indicates the enabled state of automatic deferred photo delivery.

[`var isAutoDeferredPhotoDeliverySupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isautodeferredphotodeliverysupported)

A Boolean value that indicates whether the photo output supports deferred photo delivery.

[`var isFastCapturePrioritizationSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isfastcaptureprioritizationsupported)

A Boolean value that indicates whether the photo output supports fast capture prioritization.

[`var isFastCapturePrioritizationEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isfastcaptureprioritizationenabled)

A Boolean value that indicates whether the output enables fast capture prioritization.

[`var isResponsiveCaptureEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/isresponsivecaptureenabled)

A Boolean value that indicates whether the photo output configuration enables responsive capture.

[`var isZeroShutterLagSupported: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iszeroshutterlagsupported)

A Boolean value that indicates whether the photo output supports zero shutter lag.

[`var isZeroShutterLagEnabled: Bool`](https://developer.apple.com/documentation/avfoundation/avcapturephotooutput/iszeroshutterlagenabled)

A Boolean value that indicates whether the photo output configuration enables zero shutter lag.

---

# https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason/videodevicenotavailablewithmultipleforegroundapps

- [AVFoundation](https://developer.apple.com/documentation/avfoundation)
- [AVCaptureSession](https://developer.apple.com/documentation/avfoundation/avcapturesession)
- [AVCaptureSession.InterruptionReason](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason)
- AVCaptureSession.InterruptionReason.videoDeviceNotAvailableWithMultipleForegroundApps

Case

# AVCaptureSession.InterruptionReason.videoDeviceNotAvailableWithMultipleForegroundApps

An interruption caused when your app is running in Slide Over, Split View, or Picture in Picture mode on iPad.

case videoDeviceNotAvailableWithMultipleForegroundApps

## [Discussion](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason/videodevicenotavailablewithmultipleforegroundapps\#Discussion)

If your capture session configuration disallows accessing the camera while multitasking, the system interrupts it with this reason when a user switches to a multitasking mode like Split View. The system doesn’t interrupt your capture session with this reason if [`isMultitaskingCameraAccessEnabled`](https://developer.apple.com/documentation/avfoundation/avcapturesession/ismultitaskingcameraaccessenabled) is [`true`](https://developer.apple.com/documentation/swift/true).

## [See Also](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason/videodevicenotavailablewithmultipleforegroundapps\#see-also)

### [Constants](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason/videodevicenotavailablewithmultipleforegroundapps\#Constants)

[`case videoDeviceNotAvailableInBackground`](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason/videodevicenotavailableinbackground)

An interruption caused by the app being sent to the background while using a camera.

[`case audioDeviceInUseByAnotherClient`](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason/audiodeviceinusebyanotherclient)

An interruption caused by the audio hardware temporarily being made unavailable (for example, for a phone call or alarm).

[`case videoDeviceInUseByAnotherClient`](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason/videodeviceinusebyanotherclient)

An interruption caused by the video device temporarily being made unavailable (for example, when used by another capture session).

[`case videoDeviceNotAvailableDueToSystemPressure`](https://developer.apple.com/documentation/avfoundation/avcapturesession/interruptionreason/videodevicenotavailableduetosystempressure)

An interruption due to system pressure, such as thermal duress.

---

