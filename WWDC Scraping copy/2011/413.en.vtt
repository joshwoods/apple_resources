WEBVTT

00:00:10.460 --> 00:00:11.300
Good morning.

00:00:11.320 --> 00:00:14.790
How's everybody doing?

00:00:14.890 --> 00:00:17.300
Come on, a little more energy.

00:00:17.390 --> 00:00:18.930
All right.

00:00:18.940 --> 00:00:23.860
So today we're gonna be talking about
audio session management for iOS.

00:00:23.860 --> 00:00:28.230
And what this is really all about is
making sure that your applications use

00:00:28.250 --> 00:00:32.630
audio in a predictable way that users--

00:00:32.900 --> 00:00:38.110
The way they expect audio to work,
and to provide the best user experience.

00:00:38.800 --> 00:00:42.420
So we're going to be talking about
the managed audio experience on iOS

00:00:42.590 --> 00:00:45.140
and explaining what that's all about.

00:00:45.170 --> 00:00:49.340
And then the bulk of the talk is
going to be about using audio session.

00:00:49.340 --> 00:00:55.040
We're going to be talking about some new
things like modes that are new in iOS 5.

00:00:55.080 --> 00:01:01.810
We're going to be talking about
background audio and what it

00:01:01.810 --> 00:01:03.210
means for your application
to be mixable or non-mixable.

00:01:03.620 --> 00:01:06.840
We're also going to be talking
about some new routing properties

00:01:06.840 --> 00:01:10.170
that are available in iOS 5,
and one new behavior

00:01:10.220 --> 00:01:12.500
that's related to routing.

00:01:12.570 --> 00:01:16.610
And then we're going to be talking
about the voice processing audio unit in

00:01:16.610 --> 00:01:20.800
conjunction with one of the new modes,
and how we think that using the

00:01:20.800 --> 00:01:24.500
voice processing audio unit can make
your application that much better.

00:01:24.500 --> 00:01:26.660
And then finally,
I'm going to spend a few

00:01:26.740 --> 00:01:28.500
minutes talking about codecs.

00:01:28.790 --> 00:01:31.800
Codecs are not directly
related to audio session,

00:01:32.030 --> 00:01:35.330
but they're a really important
kind of bread and butter

00:01:35.330 --> 00:01:37.540
technology in digital audio.

00:01:38.820 --> 00:01:44.190
So before I get into the in-depth
discussion of audio session,

00:01:44.250 --> 00:01:46.230
it can be a little bit daunting.

00:01:46.240 --> 00:01:50.180
And so we wanted to talk about if
you're just wanting to do some basic

00:01:50.340 --> 00:01:54.320
playback or some basic recording,
what are the kind of bare

00:01:54.320 --> 00:01:57.380
minimum steps you need to know
about when using audio session?

00:01:57.450 --> 00:02:03.650
So we're going to look at a little
bit of code and try and help you

00:02:03.650 --> 00:02:03.650
feel like it's not that daunting.

00:02:04.090 --> 00:02:07.900
So for a basic application
that wants to do playback,

00:02:07.930 --> 00:02:10.520
there's three steps:
preparing your session,

00:02:10.520 --> 00:02:16.570
handling the beginning of interruptions,
and handling the end of interruptions.

00:02:17.190 --> 00:02:19.980
So preparing your session,
we can see that it's

00:02:20.000 --> 00:02:22.660
really not a lot of code.

00:02:22.800 --> 00:02:26.610
In the first line,
we're using an AV audio session class

00:02:26.730 --> 00:02:32.010
method called shared instance to
get a pointer to our application's

00:02:32.220 --> 00:02:35.810
global instance of AV audio session.

00:02:36.120 --> 00:02:38.270
Then we're choosing a category.

00:02:38.480 --> 00:02:42.550
For many applications that
want to do basic playback,

00:02:42.560 --> 00:02:45.580
Ambient is going to be a good
choice for things like mini

00:02:45.580 --> 00:02:47.000
games and productivity apps.

00:02:47.000 --> 00:02:51.990
And then once we've done that setup,
we're going to make our session active.

00:02:51.990 --> 00:02:56.230
I should note that if you're using
something like the AV Audio Player or

00:02:56.230 --> 00:03:00.520
AV Audio Recorder classes,
setting your session active may

00:03:00.610 --> 00:03:02.100
not be absolutely necessary.

00:03:02.100 --> 00:03:04.710
But it's a good idea to
go ahead and do it here,

00:03:04.950 --> 00:03:07.560
because some of the other
APIs like OpenEL will require

00:03:08.190 --> 00:03:10.070
you to set your session active.

00:03:10.100 --> 00:03:13.540
And then you're going to
get ready to play audio,

00:03:13.650 --> 00:03:18.110
and depending on which API you're using,
the steps are going to be

00:03:18.190 --> 00:03:20.220
a little bit different.

00:03:20.950 --> 00:03:24.240
So then once you're up and
using audio in your application,

00:03:24.240 --> 00:03:27.280
your session is active,
you want to be prepared

00:03:27.350 --> 00:03:29.040
to handle interruptions.

00:03:29.040 --> 00:03:32.460
The system is going to notify
you when your audio has stopped.

00:03:34.700 --> 00:03:36.190
So we're looking here at the code.

00:03:36.280 --> 00:03:43.120
This is a delegate method that's part of
the AV audio session delegate protocol.

00:03:43.150 --> 00:03:47.540
And so when the system notifies you
that an interruption has occurred,

00:03:47.610 --> 00:03:50.630
it's telling you that
playback has stopped and that

00:03:50.800 --> 00:03:52.320
your session is inactive.

00:03:53.020 --> 00:03:56.900
So if you had a user interface element,
something like a play button,

00:03:56.900 --> 00:04:01.380
this would be a good time to change that
to reflect that audio has been stopped.

00:04:02.940 --> 00:04:02.940
So we're looking here at the code.

00:04:02.940 --> 00:04:02.940
This is a delegate method that's part of
the AV audio session delegate protocol.

00:04:02.940 --> 00:04:02.940
And so when the system notifies you
that an interruption has occurred,

00:04:02.940 --> 00:04:02.940
it's telling you that
playback has stopped and that

00:04:02.940 --> 00:04:02.940
your session is inactive.

00:04:03.800 --> 00:04:08.170
If you're using an API like
OpenAL or using AudioQueues,

00:04:08.180 --> 00:04:13.860
AVAudioSession provides a global
notification for events like the

00:04:13.860 --> 00:04:17.600
beginning and ending of interruptions.

00:04:17.670 --> 00:04:21.870
If you're using AVAudioPlayer
or AVAudioRecorder,

00:04:22.070 --> 00:04:25.600
there are delegate methods,
and these are per instance.

00:04:25.600 --> 00:04:29.700
So if you had, say,
three or four AVAudioPlayer instances,

00:04:29.700 --> 00:04:34.610
each one can receive a begin
and end interruption event.

00:04:35.370 --> 00:04:39.730
When the interruption ends,
the system will notify you.

00:04:39.820 --> 00:04:43.160
So looking at the code,
this is an AV audio session

00:04:43.160 --> 00:04:47.900
delegate protocol method,
end interruption with flags.

00:04:47.940 --> 00:04:53.800
And here, this is a good chance to
resume recording or playback,

00:04:53.830 --> 00:04:55.480
to update your user interface.

00:04:55.630 --> 00:04:58.130
Again, so if you had something
like a play button,

00:04:58.200 --> 00:05:01.830
you would update your interface to
show that audio is playing again.

00:05:01.860 --> 00:05:05.280
And this is where you could
reactivate your session.

00:05:05.300 --> 00:05:06.530
Thank you.

00:05:06.960 --> 00:05:11.270
And again, AV Audio Session Delegate
provides a global notification

00:05:11.850 --> 00:05:15.430
for APIs like OpenAL or AudioQs.

00:05:15.640 --> 00:05:20.560
And then AV Audio Player and
AV Audio Recorder,

00:05:20.570 --> 00:05:22.810
each instance will get a notification.

00:05:22.950 --> 00:05:26.410
So those are the basic steps
if you want to do simple

00:05:26.410 --> 00:05:28.300
playback or simple recording.

00:05:28.300 --> 00:05:29.700
So it's not a lot of code.

00:05:29.700 --> 00:05:31.730
It's not too scary.

00:05:31.790 --> 00:05:35.570
But it's kind of hiding some --
quite a bit of that complexity that's

00:05:35.570 --> 00:05:37.700
actually going on in the system.

00:05:37.950 --> 00:05:41.180
And on iOS,
we have a managed audio experience.

00:05:41.320 --> 00:05:44.210
So let's talk about what that means.

00:05:44.950 --> 00:05:51.100
So the managed audio experience on iOS
is kind of comprised of a few parts.

00:05:51.300 --> 00:05:56.030
The main thing is that we know that
users carry their iOS devices everywhere.

00:05:56.100 --> 00:05:59.060
If you think about where you see
people with their iPod touches,

00:05:59.160 --> 00:06:01.900
their iPads and their iPhones,
you have them with you

00:06:01.900 --> 00:06:04.990
in business meetings,
when you're at home eating dinner,

00:06:04.990 --> 00:06:06.640
the phone's in your pocket.

00:06:06.640 --> 00:06:09.920
If you're at your place of worship
or on your morning commute,

00:06:10.030 --> 00:06:12.660
these devices are really
with us everywhere.

00:06:12.710 --> 00:06:16.800
And we know that audio
can be a disruptive thing.

00:06:16.970 --> 00:06:23.510
So users expect that things like the
ringer switch and the screen lock and the

00:06:23.510 --> 00:06:26.560
volume keys behave in a predictable way.

00:06:26.560 --> 00:06:28.100
So the system is helping
you to manage that.

00:06:29.650 --> 00:06:32.640
And the goal is to have a
consistent user experience,

00:06:32.710 --> 00:06:35.450
and the best user experience possible.

00:06:35.850 --> 00:06:40.940
Another aspect of this is that the mobile
device market is really fast moving.

00:06:41.180 --> 00:06:45.700
If you think about just in
the last year at WWDC 2010,

00:06:45.700 --> 00:06:49.140
we were talking about iOS 4 and iPhone 4.

00:06:49.140 --> 00:06:54.520
On the software side, we've seen 4.1, .2,
.3 updates,

00:06:54.520 --> 00:06:57.930
and we're talking about iOS 5 this week.

00:06:58.020 --> 00:07:03.100
On the hardware front,
we saw the Verizon iPhone 4 come along,

00:07:03.100 --> 00:07:06.150
a new iPod touch, and of course, iPad 2.

00:07:06.270 --> 00:07:11.340
So with these fast moving changes on
the hardware and the software side,

00:07:11.340 --> 00:07:16.150
part of the managed audio experience is
making sure that applications continue to

00:07:16.220 --> 00:07:20.110
behave the way that users expect them to.

00:07:20.840 --> 00:07:26.460
So our message for developers is that
we want you to choose the right APIs and

00:07:26.460 --> 00:07:32.210
use those APIs to communicate to the
system how you want to use audio.

00:07:34.240 --> 00:07:36.860
So let's get into audio
session management,

00:07:36.860 --> 00:07:38.850
the bulk of today's talk.

00:07:38.960 --> 00:07:44.580
Audio session is the primary way that you
communicate with the operating system to

00:07:44.750 --> 00:07:47.370
communicate how you want to use audio.

00:07:47.370 --> 00:07:51.700
So we're going to be talking about
how to make your app sounds behave

00:07:51.700 --> 00:07:56.670
according to users' expectations,
be consistent with built in applications,

00:07:56.740 --> 00:08:02.760
things like the iPod app, voice memos,
YouTube.

00:08:02.760 --> 00:08:05.590
We're going to be talking
about how to pick the best

00:08:05.710 --> 00:08:08.360
category for your application.

00:08:08.360 --> 00:08:11.090
We're going to be talking about
mixing with background audio

00:08:11.090 --> 00:08:14.100
and what that's all about.

00:08:14.100 --> 00:08:16.740
And as we saw earlier,
we're going to talk about responding

00:08:16.840 --> 00:08:20.660
to interruptions and I'm going
to talk about that in more depth.

00:08:20.700 --> 00:08:24.210
And we're going to talk about
handling routing changes.

00:08:26.130 --> 00:08:29.980
So audio session is actually two APIs.

00:08:30.260 --> 00:08:35.800
If we look at the bottom layer in green,
that's the audio session services part,

00:08:35.800 --> 00:08:38.200
and that's a C callable API.

00:08:38.240 --> 00:08:42.290
And this is where all of the
implementation for audio session lives.

00:08:42.430 --> 00:08:47.950
On top of that, in AV Foundation,
we have AV Audio Session.

00:08:48.060 --> 00:08:51.660
This is an Objective-C class
that provides a lot of

00:08:51.850 --> 00:08:54.340
the common functionality.

00:08:54.780 --> 00:08:58.460
Because AV Audio Session is built
on top of Audio Session Services,

00:08:58.510 --> 00:09:00.970
there's no loss in functionality.

00:09:01.020 --> 00:09:03.590
It's using Audio Session
Services directly.

00:09:03.720 --> 00:09:06.740
So we encourage you to
start with AV Audio Session,

00:09:06.920 --> 00:09:10.410
and then if you need a little
more control over your session,

00:09:10.500 --> 00:09:15.720
you can use the API that lives
in Audio Session Services.

00:09:15.890 --> 00:09:18.400
And it's perfectly okay to mix and match.

00:09:18.440 --> 00:09:21.600
They're designed to work together.

00:09:21.670 --> 00:09:24.750
So even if you need to use
some of the lower level details

00:09:24.800 --> 00:09:27.790
in Audio Session Services,
go ahead and use AV Audio Session

00:09:27.790 --> 00:09:30.150
for the things that you can.

00:09:30.310 --> 00:09:33.600
So there are five tasks that
you need to be aware of when

00:09:33.600 --> 00:09:35.500
you're using Audio Session.

00:09:35.750 --> 00:09:39.880
The first is to set up
the session and delegates.

00:09:40.190 --> 00:09:43.400
Next, you're going to choose
and set a category.

00:09:43.500 --> 00:09:45.900
In iOS 5,
there's a new optional step that

00:09:45.900 --> 00:09:49.930
goes along with setting the category,
and that is choosing and setting a mode.

00:09:50.100 --> 00:09:54.240
And we're going to be talking about
each of these steps in more detail.

00:09:54.520 --> 00:09:59.780
Once you've got your session configured,
you want to make your session active.

00:09:59.780 --> 00:10:02.570
And then once you're up
and running using audio,

00:10:02.610 --> 00:10:05.500
you want to be able to handle
interruptions and handle

00:10:05.500 --> 00:10:07.740
route changes appropriately.

00:10:08.510 --> 00:10:11.040
So the first step,
setting up the session.

00:10:11.040 --> 00:10:14.860
This is going to look really similar
to what we saw a few minutes ago.

00:10:14.900 --> 00:10:16.100
The first step is the same.

00:10:16.100 --> 00:10:20.400
We're using the shared instance
class method to get a pointer

00:10:20.400 --> 00:10:26.280
to the global single instance of
AV audio session in our application.

00:10:26.280 --> 00:10:30.860
If you're familiar with design patterns,
you can think of this as a singleton.

00:10:31.200 --> 00:10:34.700
The next step is setting a
delegate for notifications.

00:10:34.700 --> 00:10:40.690
So AVAudioSessionDelegate is a
protocol that provides several methods.

00:10:41.790 --> 00:10:45.340
The next step, step two,
is to choose and set a category.

00:10:45.410 --> 00:10:48.820
This is a really important step,
so we're going to explain what each of

00:10:48.940 --> 00:10:54.770
these categories are used for and help
you to decide which category is going

00:10:54.770 --> 00:10:57.440
to be the best for your application.

00:10:57.520 --> 00:11:02.270
In many cases, for many applications,
you're going to pick a single category,

00:11:02.560 --> 00:11:04.600
set it once, and forget about it.

00:11:04.920 --> 00:11:07.020
For some of you,
you may need to switch back and forth

00:11:07.180 --> 00:11:11.200
between two or possibly three categories.

00:11:11.510 --> 00:11:14.780
So the six categories that
we provide are playback,

00:11:14.820 --> 00:11:18.900
record, play and record,
audio processing,

00:11:18.930 --> 00:11:21.830
and then ambient and solo ambient.

00:11:23.230 --> 00:11:26.340
The first three we can kind
of group together and think of

00:11:26.340 --> 00:11:28.030
these for audio applications.

00:11:28.090 --> 00:11:31.240
That is,
applications where audio is really the

00:11:31.240 --> 00:11:35.060
forefront and a very important part
of what the application is all about.

00:11:35.170 --> 00:11:38.080
Things like audio players
and video players,

00:11:38.130 --> 00:11:41.980
voice over IP, voice chat,
audio recorders.

00:11:43.350 --> 00:11:48.060
What these categories have in common is
that they do not obey the screen lock,

00:11:48.190 --> 00:11:50.100
nor do they obey the ringer switch.

00:11:50.100 --> 00:11:53.100
Now,
that may seem a little counterintuitive,

00:11:53.100 --> 00:11:55.100
so let's talk about that.

00:11:55.190 --> 00:11:58.710
So if you think about something
like the built-in iPod application,

00:11:58.710 --> 00:12:01.100
it's going to use the playback category.

00:12:01.100 --> 00:12:05.070
And you really want users to be able
to start their music and then hit

00:12:05.070 --> 00:12:09.100
the lock screen to save battery life,
but continue to listen to their music.

00:12:10.100 --> 00:12:11.100
And likewise, with the ringer switch,
you can use the playback

00:12:11.100 --> 00:12:11.100
category to play music.

00:12:11.320 --> 00:12:12.100
And you really want users to be able
to start their music and then hit

00:12:12.100 --> 00:12:12.100
the lock screen to save battery life,
but continue to listen to their music.

00:12:12.100 --> 00:12:15.140
So if you think about this,
you want the user to be able to have

00:12:15.340 --> 00:12:19.040
that set to the silent position,
since they're not hearing ringtones.

00:12:19.290 --> 00:12:21.930
But since the user is in control,
it's the user who's

00:12:21.930 --> 00:12:24.940
pressing the play button,
we want them to be able to hear

00:12:25.070 --> 00:12:29.010
their music even though the ringer
switch is set to the silent position.

00:12:29.770 --> 00:12:33.580
These three categories also share
the property that they're allowed

00:12:33.580 --> 00:12:35.980
to be used in the background.

00:12:35.980 --> 00:12:39.690
So if you think about something, again,
like the iPod app,

00:12:39.830 --> 00:12:42.820
you want users to be able to
start playing their music,

00:12:43.010 --> 00:12:49.530
send iPod to the background,
and then bring up something like

00:12:49.530 --> 00:12:49.530
Safari so they can surf the web while
they're listening to their music.

00:12:50.480 --> 00:12:54.280
So the playback category
is used for output only.

00:12:54.300 --> 00:12:57.900
The record category is
used for input only.

00:12:57.920 --> 00:13:01.720
And it's important to note that
when you use the record category

00:13:01.730 --> 00:13:04.970
and your session is active,
all output audio in the

00:13:04.970 --> 00:13:06.970
system is going to be muted.

00:13:07.890 --> 00:13:10.640
The play and record category
combines the first two,

00:13:10.720 --> 00:13:13.430
so it allows you to do
playback or recording or

00:13:13.440 --> 00:13:16.370
simultaneous play and record.

00:13:17.200 --> 00:13:20.130
In the middle of the chart,
we see this Mix with Others column,

00:13:20.130 --> 00:13:22.790
and I'm going to be explaining
that more in detail,

00:13:22.940 --> 00:13:27.400
but let's just notice that the playback
and play and record categories,

00:13:27.570 --> 00:13:31.100
by default, they're not going to
mix with other audio,

00:13:31.150 --> 00:13:37.700
but there's an override you can set
to make them mix with other audio.

00:13:38.710 --> 00:13:43.510
The second grouping of categories
is for applications that are

00:13:43.510 --> 00:13:45.940
games and general applications.

00:13:45.940 --> 00:13:50.230
So these are the types of applications
where audio enhances the experience,

00:13:50.340 --> 00:13:52.000
but it's not critical.

00:13:52.170 --> 00:13:54.680
So if you think about something
like the yellow sticky notes

00:13:54.740 --> 00:13:58.850
application that is on every phone,
hearing those key clicks

00:13:58.850 --> 00:14:02.440
enhances the experience,
but if you have your ringer switch off

00:14:02.440 --> 00:14:06.020
and you're not hearing those key clicks,
it's not a big deal.

00:14:06.020 --> 00:14:07.320
You can still use the application.

00:14:08.620 --> 00:14:13.780
So these are the types of applications
where users are very hands on with them,

00:14:13.820 --> 00:14:18.280
or something like a video game where
again the audio enhances the experience,

00:14:18.280 --> 00:14:21.570
but you can still play the
game even without sound.

00:14:22.590 --> 00:14:26.400
So these categories do
obey the screen lock,

00:14:26.400 --> 00:14:29.310
and they do obey the ringer switch,
and they are not allowed to

00:14:29.310 --> 00:14:30.880
use audio in the background.

00:14:30.910 --> 00:14:34.370
And the reason that these categories
are not allowed to use audio in the

00:14:34.370 --> 00:14:39.000
background is because of the fact that
we expect users to be hands-on with them.

00:14:39.000 --> 00:14:43.860
So if you send this
application to the background,

00:14:43.960 --> 00:14:46.690
the user is no longer
interacting with it,

00:14:46.690 --> 00:14:46.690
so it makes sense that
the audio will stop.

00:14:47.880 --> 00:14:52.540
The difference between ambient and solo
ambient is that the ambient category

00:14:52.670 --> 00:14:54.300
will always mix with other audio.

00:14:54.300 --> 00:14:57.400
So this is for things like a
video game where you just have

00:14:57.400 --> 00:15:01.220
kind of incidental sound effects,
but you don't have your own music

00:15:01.220 --> 00:15:03.790
soundtrack playing in the background.

00:15:05.380 --> 00:15:08.990
The final category is
for offline processing.

00:15:09.090 --> 00:15:11.840
The name of this category
is audio processing,

00:15:11.900 --> 00:15:16.240
and it's for doing offline
conversions or offline processing.

00:15:16.300 --> 00:15:18.440
And looking at the chart,
we can see that it does

00:15:18.450 --> 00:15:21.360
neither input nor output.

00:15:21.680 --> 00:15:25.310
And this one also does not obey the
screen lock or the ringer switch,

00:15:25.530 --> 00:15:26.920
and it is allowed in the background.

00:15:27.050 --> 00:15:31.160
So for example, you want to be able to
continue processing audio

00:15:31.560 --> 00:15:33.740
even if the screen is locked.

00:15:34.610 --> 00:15:36.620
So those are the six categories.

00:15:36.620 --> 00:15:39.140
I just want to reiterate that you
really want to spend some time

00:15:39.140 --> 00:15:43.240
thinking about what is the best
category for your application,

00:15:43.380 --> 00:15:46.680
because that's a big part
of making sure that the user

00:15:46.680 --> 00:15:49.410
experience is the best possible.

00:15:51.210 --> 00:15:54.920
So looking at the code,
following along here,

00:15:54.920 --> 00:15:59.240
we saw that we got the pointer
to our AV audio session.

00:15:59.240 --> 00:16:02.600
We set up our delegate,
and now we are setting the category.

00:16:02.600 --> 00:16:07.350
In this example,
I'm showing the play and record category.

00:16:09.160 --> 00:16:12.610
So now in iOS 5,
we're introducing some new

00:16:12.610 --> 00:16:14.320
functionality that we call modes.

00:16:14.410 --> 00:16:18.690
Modes go along with categories,
and they're a way to specialize your

00:16:18.790 --> 00:16:24.970
category and tell the OS a little bit
more about how you want to use audio.

00:16:25.560 --> 00:16:29.420
And this is going to unlock some
capabilities to behave more like built-in

00:16:29.420 --> 00:16:34.100
applications and to do some things
that you just couldn't do in iOS 4.

00:16:34.600 --> 00:16:40.220
So we have four modes-- voice chat,
video recording, measurement,

00:16:40.220 --> 00:16:42.100
and then the default mode.

00:16:42.130 --> 00:16:44.480
And let's look at each one of these.

00:16:45.410 --> 00:16:49.140
Voice chat mode,
this is for things like voice

00:16:49.140 --> 00:16:52.770
over IP or video games where you
want players to be able to talk

00:16:52.770 --> 00:16:54.960
to each other over the network.

00:16:55.030 --> 00:16:59.390
Because it's a two-way communication,
we're going to, this works with the play

00:16:59.390 --> 00:17:01.150
and record category.

00:17:01.280 --> 00:17:03.790
So when you set this mode,
and you've set the play

00:17:03.790 --> 00:17:07.020
and record category,
the system is going to pick the best

00:17:07.020 --> 00:17:10.000
microphone choice for the current route.

00:17:10.430 --> 00:17:14.410
So let's look at the way that
people hold phones when they're on,

00:17:14.410 --> 00:17:16.130
say, voice over IP calls.

00:17:16.260 --> 00:17:19.490
The first orientation is to
hold the phone up to your ear.

00:17:19.680 --> 00:17:23.400
So at the top of the phone,
we have a speaker that we

00:17:23.400 --> 00:17:25.160
refer to as the receiver.

00:17:25.510 --> 00:17:28.770
And then at the bottom of the device,
we have a microphone.

00:17:28.910 --> 00:17:34.810
So this is the input and output routes
that we'll use in this orientation.

00:17:35.320 --> 00:17:39.160
The second common
orientation is speakerphone.

00:17:39.470 --> 00:17:43.060
So here we see a man who's
chatting with someone.

00:17:43.060 --> 00:17:46.620
He could be in a FaceTime call or
it could be a voice over IP call,

00:17:46.740 --> 00:17:49.800
but this is the speakerphone orientation.

00:17:49.980 --> 00:17:55.010
So here we're going to be playing
audio out of the bottom speaker and

00:17:55.010 --> 00:17:58.080
using the top microphone for input.

00:17:59.230 --> 00:18:04.760
We want to use the output and
input devices that are the farthest

00:18:04.800 --> 00:18:10.080
apart from each other to eliminate
feedback and those sorts of things.

00:18:13.380 --> 00:18:18.020
When you set the voice chat mode,
the system will also optimize the signal

00:18:18.020 --> 00:18:21.290
processing for voice applications.

00:18:21.670 --> 00:18:25.630
The system will also help to manage
routing by restricting the allowed

00:18:25.630 --> 00:18:30.500
routes to those that make sense for
voice chat types of applications.

00:18:30.720 --> 00:18:36.450
And it will automatically, by default,
the system will allow Bluetooth headsets

00:18:36.500 --> 00:18:38.500
to be used in your audio routes.

00:18:38.500 --> 00:18:42.770
So if you think about voice over
IP applications or video games where

00:18:42.770 --> 00:18:45.320
players are chatting with each other,
you want them to be able to

00:18:45.400 --> 00:18:47.500
use those Bluetooth headsets.

00:18:47.500 --> 00:18:53.240
If you decide that you don't want that,
you can set an override to turn that off.

00:18:53.580 --> 00:18:56.600
So the final thing I want to
mention about this mode is that

00:18:56.600 --> 00:19:00.700
we want to encourage you to use
the voice processing audio unit.

00:19:00.770 --> 00:19:02.660
In a few minutes,
I'm going to go and talk about

00:19:02.770 --> 00:19:05.140
the voice processing audio unit.

00:19:05.340 --> 00:19:08.200
The next mode is video recording mode.

00:19:08.200 --> 00:19:12.200
The use case for this is
actually pretty easy to explain.

00:19:12.210 --> 00:19:17.030
A lot of our new iOS devices
have great HD video cameras,

00:19:17.170 --> 00:19:21.000
and so this is for applications where you
want to have the best audio experience

00:19:21.050 --> 00:19:24.790
to go along with using that video camera.

00:19:24.940 --> 00:19:27.990
So there are two categories
that support this mode,

00:19:27.990 --> 00:19:31.430
play and record,
and then the record only category.

00:19:33.660 --> 00:19:36.040
And like with the voice chat mode,
the system is going to pick the best

00:19:36.110 --> 00:19:38.640
microphone choice for the current usage.

00:19:38.730 --> 00:19:42.440
So let's look at a typical way that
someone might be holding the phone

00:19:42.440 --> 00:19:45.100
when they're doing a video recording.

00:19:45.100 --> 00:19:49.250
We see, if we're looking at the
diagram of the iPhone 4,

00:19:49.370 --> 00:19:53.070
that the top microphone and
the camera lens are located

00:19:53.070 --> 00:19:55.100
pretty close to each other.

00:19:55.100 --> 00:19:57.190
So it makes sense that we'd
want to use the top microphone

00:19:57.190 --> 00:19:59.600
because it's close to that lens.

00:19:59.600 --> 00:20:02.560
And if you look at the way
she's holding the phone,

00:20:02.570 --> 00:20:07.600
oftentimes users will end up covering up
the bottom microphone with their hand.

00:20:07.700 --> 00:20:10.600
And so that's another reason
that we choose the top microphone

00:20:10.600 --> 00:20:13.600
for this type of application.

00:20:13.730 --> 00:20:17.010
And likewise,
the system is going to choose the best

00:20:17.010 --> 00:20:19.590
output route for the current usage.

00:20:19.680 --> 00:20:22.150
The third mode is Measurement Mode.

00:20:22.210 --> 00:20:27.230
This is for applications that want
to do calibration or measurements,

00:20:27.360 --> 00:20:31.210
things like SPL meters
or audio analysis tools.

00:20:31.270 --> 00:20:33.580
And then on the output side,
maybe applications that aren't

00:20:33.670 --> 00:20:37.860
so concerned about having
the nicest quality sound,

00:20:37.860 --> 00:20:43.260
but the simplest audio with the least
amount of signal processing applied.

00:20:43.670 --> 00:20:46.770
This mode, when you're in this mode,
the system is going to use

00:20:46.770 --> 00:20:48.200
the primary microphone.

00:20:48.260 --> 00:20:51.590
On iPhone 4, that's the bottom mic.

00:20:51.690 --> 00:20:57.280
And in terms of the signal path,
the system is going to apply some minimal

00:20:57.280 --> 00:21:01.320
EQ to create a flat EQ for microphones.

00:21:01.520 --> 00:21:05.080
And otherwise, it's going to provide very
minimal signal processing.

00:21:05.240 --> 00:21:07.740
And that's what this
mode is really all about.

00:21:07.810 --> 00:21:09.870
The final mode is default mode.

00:21:10.090 --> 00:21:14.740
And this is the mode you get if
you do not explicitly set one.

00:21:14.740 --> 00:21:16.600
This works with all categories.

00:21:16.670 --> 00:21:20.080
If you want to set it explicitly,
there are constants in

00:21:20.080 --> 00:21:21.600
the API for doing so.

00:21:22.690 --> 00:21:24.570
On the input side,
the system is going to select

00:21:24.840 --> 00:21:27.810
the primary microphone,
and the device is going to be

00:21:27.900 --> 00:21:29.600
configured for general usage.

00:21:29.600 --> 00:21:34.310
So it's just like what you would have
gotten in earlier versions of iOS.

00:21:35.440 --> 00:21:40.780
Okay, so looking at the code, we've,
in the previous step,

00:21:40.910 --> 00:21:45.890
we set plan record category,
and now we're choosing voice chat mode.

00:21:46.500 --> 00:21:49.640
So since we're setting the voice chat
mode in the play and record category,

00:21:49.770 --> 00:21:55.020
this is a good opportunity to talk
about the voice processing audio unit.

00:21:55.110 --> 00:21:57.420
So what is the voice
processing audio unit,

00:21:57.420 --> 00:21:59.390
and why should I use it?

00:21:59.900 --> 00:22:03.800
The Voice Processing Audio Unit,
as the name implies, it's an audio unit,

00:22:03.800 --> 00:22:08.660
so it's one of the lower audio
APIs in the software stack.

00:22:08.800 --> 00:22:13.870
It is an AU remote I/O with a
built-in acoustic echo canceler,

00:22:13.870 --> 00:22:16.650
and that's the important part that
we're going to be talking about today.

00:22:16.880 --> 00:22:21.800
It's designed for high-quality chat
with two configurations available:

00:22:21.800 --> 00:22:25.800
highest quality and lowest complexity.

00:22:25.930 --> 00:22:29.800
The word "complexity" here really
is talking about CPU usage.

00:22:29.800 --> 00:22:34.920
So if you know that your application
is really doing a lot of processing,

00:22:34.920 --> 00:22:38.500
and you need every last CPU cycle,
then you may want to choose the

00:22:38.570 --> 00:22:40.800
lowest complexity configuration.

00:22:40.800 --> 00:22:44.150
Otherwise,
why not choose the highest quality?

00:22:44.370 --> 00:22:45.870
So this is available on iOS.

00:22:45.880 --> 00:22:49.040
It's been on iOS since version 3.

00:22:49.040 --> 00:22:53.960
But it's new and available on OS X Lion.

00:22:55.380 --> 00:22:59.740
So let's look at what happens
in a voice chat scenario where

00:22:59.740 --> 00:23:04.560
you do not have an acoustic echo
canceler in the signal path.

00:23:04.710 --> 00:23:06.610
So let me explain the
diagram a little bit.

00:23:06.730 --> 00:23:11.780
On the left side in blue
is a user at the far end.

00:23:11.970 --> 00:23:15.000
So maybe they're in the next room,
or maybe they're on the

00:23:15.000 --> 00:23:16.470
other side of the world.

00:23:16.580 --> 00:23:20.280
That wavy line in the middle
represents the network.

00:23:20.510 --> 00:23:25.320
And then on the right side
in red is the near end user.

00:23:25.390 --> 00:23:30.070
And you can think of the near end user
as being the person using their device

00:23:30.190 --> 00:23:32.560
with your software running on it.

00:23:33.230 --> 00:23:35.360
So let's look at what happens here.

00:23:35.470 --> 00:23:38.540
So the far end talker,
the person in blue,

00:23:38.590 --> 00:23:40.640
speaks into his microphone.

00:23:40.680 --> 00:23:44.680
That signal goes into his iOS
device and goes across the network.

00:23:44.770 --> 00:23:50.330
And then that signal is played out of
the loudspeaker on the near end device.

00:23:51.960 --> 00:23:54.960
The near end user is going to
be talking at the same time.

00:23:54.970 --> 00:23:57.760
And so the sound that's coming
out of the speaker and then

00:23:57.950 --> 00:24:00.670
the near end user's voice,
they're going to be mixed

00:24:00.690 --> 00:24:02.200
together in the air.

00:24:02.200 --> 00:24:05.140
And so the signal that's being
fed into the microphone is a

00:24:05.140 --> 00:24:07.030
combination of those two signals.

00:24:07.080 --> 00:24:10.280
And that's what the purple
line at the bottom represents.

00:24:11.140 --> 00:24:14.720
So now this signal is going
to be sent across the network,

00:24:14.720 --> 00:24:17.770
and it's going to arrive
at the far end device.

00:24:18.690 --> 00:24:20.960
So the far end talker,
he's going to hear,

00:24:21.350 --> 00:24:26.680
his own voice being echoed back to him,
perhaps 100 to 200 milliseconds later.

00:24:26.720 --> 00:24:29.560
And that's going to be
a really annoying echo.

00:24:29.730 --> 00:24:33.890
It's just going to really
detract from the user experience.

00:24:34.340 --> 00:24:39.200
In reality, the situation is even a
little bit more complex.

00:24:39.200 --> 00:24:43.320
There are other applications
on the near-end device that can

00:24:43.370 --> 00:24:45.690
also be producing audio output.

00:24:45.730 --> 00:24:51.700
So perhaps the near-end user is
playing his iPod in the background,

00:24:51.710 --> 00:24:56.000
and things like SMS notifications
or a voicemail notification,

00:24:56.000 --> 00:24:59.490
all of those things can be making
sounds that are also gonna be

00:24:59.770 --> 00:25:01.990
coming out of the loudspeaker.

00:25:02.000 --> 00:25:05.100
So coming out of the loudspeaker
on the near-end device,

00:25:05.110 --> 00:25:10.440
that light blue line is a combination
of the voice signal coming over

00:25:10.440 --> 00:25:15.670
the network as well as any other
output audio on the near device.

00:25:16.080 --> 00:25:19.770
So now those sounds are going to
be mixed in the air with the voice

00:25:19.770 --> 00:25:23.480
signal from the near end speaker,
and that combined signal is

00:25:23.480 --> 00:25:24.880
going into the microphone.

00:25:24.920 --> 00:25:26.460
Again, it's being sent over the network.

00:25:26.550 --> 00:25:30.270
So now the far end user,
not only is he hearing

00:25:30.320 --> 00:25:32.560
an echo of his own voice,
which was irritating,

00:25:32.560 --> 00:25:36.920
but he's also hearing the music that
was playing on the near end device.

00:25:36.960 --> 00:25:39.640
And he's hearing those SMS notifications.

00:25:39.710 --> 00:25:42.680
So again,
that's just a bad user experience.

00:25:43.100 --> 00:27:27.800
[Transcript missing]

00:27:30.110 --> 00:27:33.110
So I'm just going to direct
your attention to the

00:27:33.140 --> 00:27:35.900
AudioUnitProperties.h header file.

00:27:35.970 --> 00:27:41.700
There are five properties here that you
can use to fine-tune and configure the

00:27:41.700 --> 00:27:44.650
use of the voice processing audio unit.

00:27:47.180 --> 00:27:50.260
Okay, so we've talked about
choosing a category,

00:27:50.350 --> 00:27:53.900
choosing a mode if it can
enhance your application.

00:27:54.360 --> 00:27:57.240
So now it's time to make
your session active.

00:27:57.240 --> 00:28:00.660
And so that's the code that
we're seeing here highlighted.

00:28:00.710 --> 00:28:04.700
Once you've activated your session,
there may be some additional setup,

00:28:04.700 --> 00:28:12.310
things like setting up your AV audio
players or OpenAL or audio cues.

00:28:13.730 --> 00:28:16.990
Okay, so now that we're at the point
where our application is active,

00:28:16.990 --> 00:28:21.450
it's up and using audio,
it's a good time to talk about background

00:28:21.450 --> 00:28:23.680
audio and what that's all about.

00:28:23.870 --> 00:28:27.700
So with the introduction
of iOS 4 last year,

00:28:27.760 --> 00:28:33.700
third-party applications were now
given the ability to do multitasking.

00:28:33.850 --> 00:28:36.920
This was a great thing,
and it introduced a way for

00:28:36.920 --> 00:28:41.850
third-party applications to
play audio in the background.

00:28:42.110 --> 00:28:46.000
So it gets interesting when you start
thinking about multiple applications that

00:28:46.000 --> 00:28:49.160
want to do playback at the same time.

00:28:50.700 --> 00:28:54.040
So before we get into that,
let's talk about how you

00:28:54.040 --> 00:28:55.720
enable background audio.

00:28:55.770 --> 00:29:00.140
So the first thing is to pick a
category that supports background audio.

00:29:00.150 --> 00:29:04.990
So that's going to be all of them,
except for ambient and solo ambient.

00:29:05.490 --> 00:29:08.720
Once you've selected a category
that supports background audio,

00:29:08.730 --> 00:29:14.440
you're going to go to your Info.plist,
and for required background modes,

00:29:14.450 --> 00:29:18.040
you're going to add the audio flag.

00:29:18.120 --> 00:29:21.710
So those are the two steps to get
started with background audio.

00:29:22.510 --> 00:29:25.400
So now let's talk about what happens
if there's more than one application

00:29:25.400 --> 00:29:28.670
that wants to play at the same time.

00:29:29.140 --> 00:29:31.960
So the question is,
what is going to be heard?

00:29:31.960 --> 00:29:35.790
And the answer is that it
depends on both applications,

00:29:35.800 --> 00:29:38.420
whether each application
is mixable or non-mixable.

00:29:38.420 --> 00:29:43.330
So looking at the chart here,
we see that the ambient category

00:29:43.440 --> 00:29:45.440
will always mix with others.

00:29:45.440 --> 00:29:48.190
The playback and play
and record categories,

00:29:48.300 --> 00:29:50.830
by default, will not mix with others.

00:29:50.840 --> 00:29:55.860
But there's an overriding that you can
set to allow them to mix with others.

00:29:56.080 --> 00:30:00.000
So that's what we refer to when
we're talking about mixable.

00:30:00.000 --> 00:30:03.670
Either your category automatically
supports mixing with others,

00:30:03.680 --> 00:30:05.880
or you've set that override
to make it mixable.

00:30:08.060 --> 00:30:11.350
A couple of notes about if your
application is non-mixable,

00:30:11.350 --> 00:30:14.760
which is, again,
going to be the default if you're using

00:30:14.760 --> 00:30:17.360
the playback category or play and record.

00:30:17.530 --> 00:30:21.000
If you're non-mixable,
your application is going to have

00:30:21.000 --> 00:30:24.080
access to hardware resources,
things like setting the sample

00:30:24.080 --> 00:30:27.800
rate or setting audio buffer sizes.

00:30:27.920 --> 00:30:32.210
Kind of going along with that, the modes,
when you apply a mode,

00:30:32.370 --> 00:30:35.600
that's kind of closely
related to hardware resources,

00:30:35.600 --> 00:30:38.190
because it's affecting
things like routing,

00:30:38.210 --> 00:30:39.870
like microphone selection.

00:30:40.100 --> 00:30:44.410
So you need to be a non-mixable
app to apply a mode.

00:30:44.640 --> 00:30:47.900
And then finally,
if your application is non-mixable,

00:30:47.910 --> 00:30:50.770
when you go active,
you may interrupt other audio.

00:30:50.930 --> 00:30:53.430
So let's look at that in more detail.

00:30:56.290 --> 00:31:00.740
So in the first scenario,
our application is in the foreground,

00:31:00.740 --> 00:31:04.070
and it's the only application
that wants to use audio.

00:31:04.520 --> 00:31:07.100
We've set that override
to make it mixable,

00:31:07.100 --> 00:31:09.730
and so we're happily streaming audio.

00:31:09.740 --> 00:31:14.700
It's being fed into the system's mixer
and then sent out to playback hardware.

00:31:15.200 --> 00:31:17.750
So now let's talk about if there
was another application that was

00:31:17.750 --> 00:31:21.490
already running in the background
using audio when your application

00:31:21.490 --> 00:31:24.490
launches and goes active.

00:31:24.640 --> 00:31:29.500
So in the first case,
the background app was also mixable,

00:31:29.590 --> 00:31:30.560
so there's no conflict.

00:31:30.670 --> 00:31:33.760
Both applications can continue to play.

00:31:33.760 --> 00:31:37.000
Both streams of audio will be
fed into the mixer and then

00:31:37.060 --> 00:31:39.610
sent to the playback hardware.

00:31:40.270 --> 00:31:43.400
If the background
application was non-mixable,

00:31:43.500 --> 00:31:47.070
recall that that application has
access to hardware resources,

00:31:47.190 --> 00:31:49.600
things like setting the sample rate.

00:31:49.600 --> 00:31:52.160
And there's no conflict
in this case either.

00:31:52.160 --> 00:31:56.710
Both applications can happily
play audio at the same time.

00:31:57.190 --> 00:32:03.220
Okay, so now let's kind of take a
step back and look at if our

00:32:03.300 --> 00:32:04.800
application was non-mixable.

00:32:04.800 --> 00:32:09.100
So we've set the playback category
and we did not set the override.

00:32:09.200 --> 00:32:12.730
So now this forefront application
is going to have access to

00:32:12.730 --> 00:32:17.890
those hardware resources,
the buffer size and the sample rate.

00:32:18.760 --> 00:32:21.030
So the question is,
what's going to happen with the

00:32:21.030 --> 00:32:25.350
audio in the background app when
our application goes active?

00:32:25.880 --> 00:32:28.590
Well, if the background
application was mixable,

00:32:28.590 --> 00:32:32.500
there's no conflict,
and both streams will continue to play.

00:32:32.570 --> 00:32:35.490
The more interesting case is
if the background application

00:32:35.540 --> 00:32:37.890
was also non-mixable.

00:32:38.150 --> 00:32:42.000
So the red X is telling us that
their audio has been interrupted now,

00:32:42.000 --> 00:32:45.100
so that background application
is going to stop playing.

00:32:45.100 --> 00:32:48.310
Don't be afraid of the red X.

00:32:48.400 --> 00:32:50.030
It doesn't mean that
anything has gone wrong.

00:32:50.040 --> 00:32:53.020
In many cases,
this is absolutely the right behavior.

00:32:53.020 --> 00:32:53.980
It's what you want.

00:32:54.020 --> 00:32:59.680
So if your, let's say your application
streams radio from the Internet,

00:32:59.680 --> 00:33:04.120
then you want it to interrupt
iPod when the user brings your

00:33:04.120 --> 00:33:05.440
application to the foreground.

00:33:05.440 --> 00:33:07.900
So this may be the
absolute right behavior.

00:33:08.000 --> 00:33:09.100
Thank you.

00:33:11.370 --> 00:33:17.380
Okay, so let's talk about,
for more specific types of applications,

00:33:17.410 --> 00:33:21.530
some kind of details about going active
and when you might want to go inactive.

00:33:21.540 --> 00:33:25.480
So for most applications,
you can just go active at the beginning,

00:33:25.480 --> 00:33:26.880
set it, and forget it.

00:33:27.000 --> 00:33:30.690
But there are a few classes of
applications where you want to kind of

00:33:30.690 --> 00:33:33.100
manage your active state a little more.

00:33:33.100 --> 00:33:38.840
So recorders, voice over IP applications,
turn-by-turn navigation apps,

00:33:38.870 --> 00:33:41.220
and then non-mixable apps.

00:33:41.300 --> 00:33:44.800
For recorders,
as I mentioned earlier when we

00:33:44.800 --> 00:33:48.580
were talking about categories,
if you've set the record-only category,

00:33:48.580 --> 00:33:52.940
all the output audio on the
system is going to be muted.

00:33:52.940 --> 00:33:56.870
So you only want to be active when
you're actually recording audio.

00:33:59.040 --> 00:34:02.310
As we just looked at with
non-mixable applications,

00:34:02.550 --> 00:34:06.300
your application can interrupt
other audio in the system.

00:34:06.330 --> 00:34:10.610
So you may want to think about managing
your active state to only use-- only be

00:34:10.610 --> 00:34:13.290
active when you're actually using audio.

00:34:13.640 --> 00:34:19.700
We're going to look more closely at voice
over IP and turn by turn navigation apps.

00:34:20.050 --> 00:34:24.780
So let's start with Voice over
IP or voice chat applications.

00:34:24.780 --> 00:34:30.340
So if we're a Voice over IP application
and a phone call comes in,

00:34:30.380 --> 00:34:32.730
that's when we want to go active.

00:34:32.840 --> 00:34:37.180
And that's going to interrupt other
audio that was playing on the system.

00:34:37.230 --> 00:34:42.420
When the call ends,
we want to go inactive to

00:34:42.420 --> 00:34:42.420
allow other audio to resume.

00:34:43.490 --> 00:34:48.110
So looking at the code here,
we have a callback method.

00:34:48.280 --> 00:34:49.340
My call did finish.

00:34:49.420 --> 00:34:53.350
So this is when the user is hung up.

00:34:53.500 --> 00:34:58.850
So we're going to be calling
setActiveWithFlagsError,

00:34:59.110 --> 00:35:01.630
and we're going to be
passing a no to deactivate.

00:35:01.800 --> 00:35:06.320
And we're going to be using the
notifyOthersOnDeactivation flag

00:35:06.320 --> 00:35:10.700
to let the system know that it can
tell the other audio that had been

00:35:10.850 --> 00:35:11.750
playing that it can now resume.

00:35:13.930 --> 00:35:18.800
Turn-by-turn GPS applications
are a really interesting case.

00:35:18.890 --> 00:35:23.660
So let's look at the setup first
when you're setting up your session.

00:35:23.690 --> 00:35:26.190
We're going to choose
the playback category,

00:35:26.250 --> 00:35:32.770
because we want to be able to play
audio if the screen has been locked

00:35:32.770 --> 00:35:32.770
or if the ringer switch is off.

00:35:33.600 --> 00:35:35.760
We're going to set the
mix with others flag,

00:35:35.760 --> 00:35:38.630
and this is that override that
I was talking about that can

00:35:38.730 --> 00:35:41.140
make your application mixable.

00:35:41.150 --> 00:35:46.880
Because if you're a
turn-by-turn GPS application,

00:35:47.070 --> 00:35:50.110
you're giving directions like
turn right in 500 meters,

00:35:50.230 --> 00:35:53.000
but you don't really need to
interrupt other audio on the system.

00:35:53.000 --> 00:35:55.450
You want it to mix in.

00:35:57.300 --> 00:36:01.470
There's another override called
other mixable audio should duck.

00:36:01.670 --> 00:36:05.440
And what this means is that when
you're giving those directions,

00:36:05.440 --> 00:36:09.000
like turn right in 500 meters,
that the other audio on the system is

00:36:09.000 --> 00:36:13.820
going to be lowered in volume so that
those directions stick out in the mix.

00:36:13.880 --> 00:36:16.460
So let's look at that.

00:36:17.570 --> 00:36:22.270
So if you're this type of application,
you want to be registered

00:36:22.330 --> 00:36:27.100
to receive location updates,
and you want to be registered

00:36:27.100 --> 00:36:29.090
to use background audio.

00:36:29.230 --> 00:36:31.400
So the user is in their car,
they're driving,

00:36:31.400 --> 00:36:36.470
and they've arrived at a new
location where you want to give

00:36:36.470 --> 00:36:39.490
them some directions to turn right.

00:36:39.630 --> 00:36:44.960
So we see our method getting called here,
play the preloaded instructions.

00:36:45.060 --> 00:36:47.400
So now we're going to
set our session active,

00:36:47.460 --> 00:36:50.760
and this is going to be the trigger
to the system that it should

00:36:50.760 --> 00:36:53.530
lower the volume of other audio.

00:36:53.730 --> 00:36:57.210
And then we're going to use
our AVAudioPlayer object

00:36:57.230 --> 00:36:59.120
here and tell it to play.

00:37:00.440 --> 00:37:05.650
When the AV audio player is
done playing the instruction,

00:37:05.850 --> 00:37:10.780
the audio player did finish playing
method is going to be called.

00:37:10.900 --> 00:37:14.380
And this is where you're going
to set your session inactive,

00:37:14.380 --> 00:37:17.400
and that's going to be the trigger
to the system that it can go

00:37:17.400 --> 00:37:21.670
ahead and raise the volume of the
other audio that had been playing.

00:37:24.320 --> 00:37:28.340
Okay,
so we've talked about when you're active,

00:37:28.340 --> 00:37:30.190
if you're doing certain
types of applications,

00:37:30.190 --> 00:37:32.920
how you may want to kind of manage
your active state a little bit more.

00:37:32.920 --> 00:37:35.830
So now let's assume that
we're up and running,

00:37:35.970 --> 00:37:38.940
we're using audio,
and we want to be prepared

00:37:38.940 --> 00:37:40.850
to handle interruptions.

00:37:40.850 --> 00:37:44.860
At the very beginning of the talk,
I just talked very briefly about this,

00:37:44.970 --> 00:37:47.380
so let's look at this in more detail now.

00:37:49.300 --> 00:37:52.910
So your session can be interrupted
by higher priority audio,

00:37:53.190 --> 00:37:59.220
things like a phone call, a clock alarm,
or a non-mixable other application

00:37:59.290 --> 00:38:02.280
coming into the foreground
and interrupting your session.

00:38:03.280 --> 00:38:06.740
The interruption makes
your session inactive,

00:38:06.740 --> 00:38:11.140
and any currently playing or recording
audio is going to be stopped.

00:38:11.640 --> 00:38:14.640
When the interruption is over,
it's a good time to

00:38:14.640 --> 00:38:17.650
reactivate certain state,
and that's going to depend on

00:38:17.730 --> 00:38:21.060
exactly which API you're using
for playback or recording,

00:38:21.150 --> 00:38:25.160
and then to become active again
if it's appropriate to do so.

00:38:27.720 --> 00:38:31.530
So let's look at the methods
that are part of the AV audio

00:38:31.530 --> 00:38:35.800
session delegate protocol that
are related to interruptions.

00:38:35.850 --> 00:38:39.280
On a begin interruption,
this is the system notifying you

00:38:39.280 --> 00:38:43.000
that audio has been stopped and
that your session is inactive.

00:38:43.030 --> 00:38:47.030
I should clarify that it's not the
system asking if you want to be inactive.

00:38:47.170 --> 00:38:48.900
It's telling you you're already inactive.

00:38:48.940 --> 00:38:51.300
You need to just deal with it.

00:38:51.360 --> 00:38:56.290
So this is a good opportunity
to change the state of your UI.

00:38:56.440 --> 00:38:59.520
So again,
if you had something like a play button,

00:38:59.720 --> 00:39:03.550
this is where you'd change it to
reflect that audio has stopped.

00:39:04.290 --> 00:39:07.340
When the interruption ends,
so this would be like if the

00:39:07.340 --> 00:39:10.900
user had taken a phone call and
they've now ended the phone call,

00:39:10.940 --> 00:39:12.500
that would be an end interruption.

00:39:12.500 --> 00:39:16.560
Or if an alarm went off and
the user pressed the OK button,

00:39:16.660 --> 00:39:17.920
that would be the end.

00:39:18.220 --> 00:39:21.040
Or if a phone call came in and
the user decided that they wanted

00:39:21.110 --> 00:39:24.650
to just decline the phone call,
that would also end the interruption.

00:39:24.760 --> 00:39:30.750
So the system is going to notify you
by one of these delegate methods.

00:39:31.410 --> 00:39:34.000
So this is when you would
make your session active,

00:39:34.000 --> 00:39:38.970
update your user interface,
and then resume playback or recording.

00:39:40.290 --> 00:39:44.540
Just quickly looking at if we
were using an AV audio player,

00:39:44.540 --> 00:39:50.740
the delegate protocol for AV audio
player has very similar methods for

00:39:50.880 --> 00:39:55.410
audio player begin interruption and
audio player end interruption with flags.

00:39:56.620 --> 00:40:00.340
As I noted earlier in the talk,
if you're using AV audio

00:40:00.340 --> 00:40:07.730
players or AV audio recorders,
each instance is going to

00:40:07.900 --> 00:40:15.010
receive these notifications.

00:40:15.010 --> 00:40:15.010
So again, if you had like four or five
or six AV audio players,

00:40:15.010 --> 00:40:15.010
each instance is going to
receive a notification.

00:40:17.330 --> 00:40:20.530
Okay,
so then the final step in dealing with

00:40:20.540 --> 00:40:23.400
audio session is to handle route changes.

00:40:23.470 --> 00:40:26.700
And this is all about
the user's expectations.

00:40:26.840 --> 00:40:30.080
On iOS, we have a rule that we
call the last in wins rule.

00:40:30.080 --> 00:40:34.400
So this means that if the user
plugs in a headset or headphones,

00:40:34.400 --> 00:40:38.230
the user expects that audio
is going to be automatically

00:40:38.280 --> 00:40:42.730
routed to the headphones,
and they expect that that audio is going

00:40:42.920 --> 00:40:46.820
to continue playing without pausing,
because they're, you know,

00:40:46.820 --> 00:40:47.180
they're putting the
audio in a different way.

00:40:47.200 --> 00:40:48.870
They're putting the
earbuds in their ears,

00:40:48.870 --> 00:40:50.050
and they can continue playing.

00:40:50.140 --> 00:40:52.340
It's not going to be
disturbing anyone else.

00:40:52.340 --> 00:40:54.890
On the other hand,
when you're unplugging,

00:40:54.890 --> 00:40:59.150
you're unplugging headphones or headset,
the user does expect that audio

00:40:59.150 --> 00:41:02.060
is going to be routed back
to wherever it was before,

00:41:02.150 --> 00:41:04.580
but they expect that
audio is going to pause,

00:41:04.660 --> 00:41:09.030
because they're, now they're going to be
broadcasting audio into the room,

00:41:09.030 --> 00:41:11.080
and that can be disruptive.

00:41:13.430 --> 00:41:17.890
So there's a new behavior in iOS 5
that we just want to make you aware of.

00:41:18.010 --> 00:41:21.940
The nice thing is that as a developer,
there's not really much you need to do,

00:41:21.940 --> 00:41:23.450
but we did want to
make you aware of this.

00:41:23.500 --> 00:41:28.600
So in this example,
we see that a person is using their iPod,

00:41:28.600 --> 00:41:32.850
and they've started their, sorry,
they're using iPad,

00:41:32.850 --> 00:41:35.500
and they've started their iPod music.

00:41:35.500 --> 00:41:39.660
It's playing in the background,
and they're taking advantage of AirPlay,

00:41:39.710 --> 00:41:42.380
and that audio is being
sent to their Apple TV,

00:41:42.380 --> 00:41:46.150
which is connected to a television set,
and so their music is playing.

00:41:46.160 --> 00:41:49.330
So they sent the iPod
application to the background,

00:41:49.330 --> 00:41:53.320
and their music continues to stream,
and they brought up the yellow

00:41:53.320 --> 00:41:56.830
sticky notes application,
and they're editing a recipe,

00:41:56.830 --> 00:41:58.730
a cookie recipe, I think it is.

00:41:58.740 --> 00:42:03.790
So the key click sounds now are
going to stay on the local device.

00:42:03.840 --> 00:42:05.180
They're going to stay with the iPad.

00:42:05.720 --> 00:42:10.140
Whereas the iPod audio is going
to be streamed to the television.

00:42:10.140 --> 00:42:13.440
So this is going to apply
when you're using AirPlay,

00:42:13.440 --> 00:42:16.080
or you are connected via an HDMI cable.

00:42:17.890 --> 00:42:20.970
The other type of audio,
aside from system sounds,

00:42:20.970 --> 00:42:23.930
that will stay on the
local device is voiceover.

00:42:23.940 --> 00:42:28.160
That's an accessibility feature
for visually impaired users.

00:42:29.240 --> 00:42:32.340
So what are the things that as
a developer you need to be aware

00:42:32.340 --> 00:42:34.980
of with regards to audio routing?

00:42:35.120 --> 00:42:37.810
So there's two things,
querying the route,

00:42:37.810 --> 00:42:40.420
and then listening for route changes.

00:42:41.530 --> 00:42:43.790
Querying the route is
asking the question,

00:42:43.790 --> 00:42:45.730
what is the current audio route?

00:42:45.730 --> 00:42:49.400
So in iOS 5, we have a new property.

00:42:49.400 --> 00:42:53.340
In previous versions of iOS,
you could do this, and the property was a

00:42:53.340 --> 00:42:54.900
little bit different.

00:42:54.900 --> 00:42:58.570
So take a look at videos from
previous years to hear about that.

00:42:58.620 --> 00:43:03.440
But in iOS 5, the new property,
audio route description,

00:43:03.660 --> 00:43:06.660
is going to give you a CFDictionary.

00:43:06.830 --> 00:43:10.760
And that CFDictionary is
going to have two keys,

00:43:10.760 --> 00:43:14.740
one for audio inputs and
one for audio outputs.

00:43:16.010 --> 00:43:19.230
In addition, in iOS 5,
we're now enumerating what all

00:43:19.230 --> 00:43:21.200
of the possible inputs are.

00:43:21.300 --> 00:43:24.950
So things like built-in
microphone or Bluetooth HFP.

00:43:25.050 --> 00:43:26.840
I see some applause here.

00:43:27.020 --> 00:43:29.840
And we're also enumerating
all of the possible outputs.

00:43:29.840 --> 00:43:37.130
You have a few more on the output side,
things like Bluetooth A2DP, headphones,

00:43:37.130 --> 00:43:38.760
AirPlay.

00:43:38.860 --> 00:43:41.760
So with the new property,
you'll be using these constants

00:43:41.760 --> 00:43:46.420
to tell which audio input
or output is being used.

00:43:48.410 --> 00:43:50.660
So the second question is,
where did the route go?

00:43:50.860 --> 00:43:55.380
So when a user plugs in an
accessory or unplugs an accessory,

00:43:55.380 --> 00:43:56.520
what happened?

00:43:56.600 --> 00:43:58.410
How did the route change?

00:43:58.540 --> 00:44:03.380
So for this, you're going to use
AudioSessionAddPropertyListener,

00:44:03.450 --> 00:44:08.580
and you're going to add a listener
for the AudioRouteChange property.

00:44:09.250 --> 00:44:12.700
So this is going to tell you the
reason why the route changed,

00:44:12.780 --> 00:44:15.800
what was the old route,
and in iOS 5 we're also telling

00:44:15.870 --> 00:44:17.710
you what's the new route.

00:44:18.160 --> 00:44:23.240
So in iOS 5, so sorry,
the reason has always been available

00:44:23.240 --> 00:44:25.200
on earlier versions of iOS.

00:44:25.200 --> 00:44:31.380
In iOS 5, we're giving you the
previous route description,

00:44:31.380 --> 00:44:35.060
and it's going to be the same format
as the property that we just looked

00:44:35.130 --> 00:44:37.100
at for getting the current route.

00:44:37.100 --> 00:44:39.990
It's going to give you separate
inputs and separate outputs,

00:44:40.050 --> 00:44:44.120
and we're enumerating what each of the
possibilities are for inputs and outputs.

00:44:44.120 --> 00:44:47.000
And then we're also giving you
the current route description.

00:44:50.760 --> 00:44:54.380
Okay, so we've been talking for a little
bit now about audio session.

00:44:54.380 --> 00:44:57.260
We've looked at the five steps.

00:44:57.380 --> 00:45:01.850
Setting up the session in delegate,
choosing a category,

00:45:01.930 --> 00:45:06.300
and setting a mode if you're doing
voice chat or video recording

00:45:06.470 --> 00:45:08.740
or some type of measurement.

00:45:09.990 --> 00:45:13.300
And then we talked about making the
session active and managing your active

00:45:13.300 --> 00:45:16.300
state for certain types of applications.

00:45:16.390 --> 00:45:18.770
And then we talked about once
your application was up and

00:45:18.770 --> 00:45:21.770
running and you're using audio,
that you want to handle interruptions

00:45:21.800 --> 00:45:24.190
and handle route changes.

00:45:24.370 --> 00:45:27.800
So the final topic today is audio codecs.

00:45:27.850 --> 00:45:31.100
Audio codecs are separate
from audio session,

00:45:31.170 --> 00:45:36.100
but they're a really critical technology
that many of you will be using,

00:45:36.100 --> 00:45:38.900
and so it's important to talk about it.

00:45:39.010 --> 00:45:40.320
So what is a codec?

00:45:40.610 --> 00:45:46.090
Well, the term codec comes
from encoder and decoder.

00:45:46.210 --> 00:45:51.200
It's all about taking linear PCM signals,
audio signals,

00:45:51.200 --> 00:45:55.640
and compressing them into some
sort of compressed format and then

00:45:55.720 --> 00:45:59.170
decompressing them back to linear PCM.

00:45:59.530 --> 00:46:02.730
There are two broad categories of codecs,
lossy and lossless,

00:46:02.740 --> 00:46:05.200
and we're going to go into each of those.

00:46:05.280 --> 00:46:07.270
And it's, like I said,
a core technology in

00:46:07.290 --> 00:46:09.510
digital audio these days.

00:46:10.220 --> 00:46:12.040
So lossless audio codecs.

00:46:12.040 --> 00:46:17.100
The beauty of a lossless audio codec
is that there's no loss of information.

00:46:17.130 --> 00:46:21.340
If you take an audio signal,
you compress it,

00:46:21.360 --> 00:46:24.720
and then later decompress it,
the signal that you get back is

00:46:24.720 --> 00:46:26.860
going to be bit for bit identical.

00:46:26.910 --> 00:46:31.150
The disadvantage is that the
compression factor is not all that high,

00:46:31.150 --> 00:46:33.110
typically 1.5 to 2.

00:46:33.270 --> 00:46:38.510
So that's why some really smart people
came up with lossy audio codecs.

00:46:39.440 --> 00:46:46.520
Many of the popular modern lossy codecs,
like MP3 and the AAC variants,

00:46:46.520 --> 00:46:53.030
rely on a perceptual model,
a psychoacoustic model of human hearing.

00:46:53.220 --> 00:46:58.820
The quality of lossy codecs are
going to vary with the bit rate,

00:46:58.820 --> 00:47:02.200
and the payoff is that you get a
much higher compression factor,

00:47:02.200 --> 00:47:05.000
typically 6 to 24.

00:47:06.130 --> 00:47:11.360
On iOS 5, we have many of the
popular codecs available,

00:47:11.360 --> 00:47:15.750
MP3, the Apple Lossless Audio Codec,
otherwise known as ALAC,

00:47:15.850 --> 00:47:19.310
and then various flavors of AAC.

00:47:19.330 --> 00:47:22.880
On the decoder side,
all of these are available,

00:47:23.180 --> 00:47:27.500
and on the encoder side,
with the exception of MP3 and AAC,

00:47:27.500 --> 00:47:32.120
the high-efficiency variants
encoders are available.

00:47:34.110 --> 00:47:37.680
And on iOS 5,
we're also adding AAC-enhanced

00:47:37.760 --> 00:47:40.170
low-delay plus SBR.

00:47:41.440 --> 00:47:43.990
Let's just take a quick
look at the AAC variants.

00:47:44.060 --> 00:47:48.070
AAC stands for Advanced Audio Codec.

00:47:48.130 --> 00:47:49.780
It's not Apple Codec.

00:47:49.840 --> 00:47:51.030
It's Advanced Audio Codec.

00:47:51.120 --> 00:47:56.540
So the first form of
AAC is AAC Low Complexity.

00:47:56.540 --> 00:48:00.400
And this is the core
technology for the AAC family,

00:48:00.400 --> 00:48:02.340
what all the other
variants are built upon.

00:48:03.090 --> 00:48:06.140
This provides very high quality audio.

00:48:06.160 --> 00:48:11.360
So the audio that users download
from the iTunes Music Store,

00:48:11.360 --> 00:48:12.900
that's all using AAC.

00:48:12.900 --> 00:48:15.980
And it's for general use.

00:48:16.940 --> 00:48:20.740
The high efficiency variants are
designed for streaming audio,

00:48:20.860 --> 00:48:23.380
and they provide lower bit rates.

00:48:23.630 --> 00:48:28.200
And then the low delay variants
of AAC are for voice over

00:48:28.200 --> 00:48:35.160
IP and conference applications,
and their key feature is the low delay.

00:48:36.540 --> 00:48:38.380
Okay, how do I use a codec?

00:48:38.770 --> 00:48:44.200
At the bottom layer of the software
stack are audio converters.

00:48:44.410 --> 00:48:48.170
Moving up a layer in the audio toolbox,
we have audio cues and the

00:48:48.350 --> 00:48:50.060
extended audio file API.

00:48:50.060 --> 00:48:55.030
And then moving up a layer
further into AV foundation,

00:48:55.030 --> 00:48:58.580
we have AV audio player
and AV audio recorder.

00:48:58.580 --> 00:49:01.330
So these are some of the
ways that you can use Codex.

00:49:01.340 --> 00:49:06.910
Each successive higher layer in the
software stack is going to wrapper

00:49:07.000 --> 00:49:12.140
some common functionality and make
it easier to use audio converters,

00:49:12.140 --> 00:49:13.900
which are at the base.

00:49:14.300 --> 00:49:15.380
Thank you.

00:49:17.390 --> 00:49:20.540
Okay, so thanks for putting up with
me for the last 50 minutes.

00:49:20.680 --> 00:49:22.100
We've talked about a lot of things.

00:49:22.100 --> 00:49:26.300
We've talked about the managed
audio experience on iOS,

00:49:26.300 --> 00:49:27.840
and we talked about what that means.

00:49:27.840 --> 00:49:30.920
We talked pretty extensively
about audio session,

00:49:30.920 --> 00:49:33.500
and we talked about the
new things in iOS 5,

00:49:33.600 --> 00:49:34.500
like modes.

00:49:34.540 --> 00:49:38.500
We talked about using background
audio and what it means for your

00:49:38.500 --> 00:49:41.380
application to be mixable or non-mixable.

00:49:42.430 --> 00:49:45.460
We looked at some of the new
properties that are available

00:49:45.490 --> 00:49:48.340
in iOS related to routing,
and we talked about a new

00:49:48.340 --> 00:49:50.040
behavior-related routing.

00:49:50.040 --> 00:49:54.770
And then we talked about how you can
use the voice processing audio unit

00:49:54.770 --> 00:49:59.500
if you're using the voice chat mode,
and why that's so important,

00:49:59.500 --> 00:50:01.780
and how it can take your
application to the next level.

00:50:01.780 --> 00:50:05.520
And then finally, we talked about codecs,
since they are a really

00:50:05.520 --> 00:50:07.580
important digital technology.

00:50:07.580 --> 00:50:11.720
For more information,
I want to direct you to Eric Verschen,

00:50:11.720 --> 00:50:14.860
who's our... Eric Verschen,
who's our Media Technologies Evangelist.

00:50:14.910 --> 00:50:19.880
Check out the programming guides that
are available on developer.apple.com.

00:50:19.880 --> 00:50:23.550
I recommend you just go and search
for audio and take a look at all the

00:50:23.620 --> 00:50:25.880
great documentation that's there.

00:50:25.960 --> 00:50:29.090
And then finally,
the Apple Developer Forums

00:50:29.090 --> 00:50:30.880
are always available.

00:50:30.880 --> 00:50:34.090
Thank you, and have a great week.