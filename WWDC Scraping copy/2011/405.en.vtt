WEBVTT

00:00:11.300 --> 00:00:12.640
Thank you.

00:00:12.740 --> 00:00:13.280
Good afternoon.

00:00:13.280 --> 00:00:15.360
Let's go exploring, shall we?

00:00:15.360 --> 00:00:19.620
But first, by way of introduction,
what is AV Foundation?

00:00:19.620 --> 00:00:24.150
AV Foundation is Apple's foundational
Objective-C framework for

00:00:24.150 --> 00:00:26.980
processing timed audiovisual media.

00:00:26.980 --> 00:00:30.570
It made its first
appearance in iPhone OS 2.2,

00:00:30.720 --> 00:00:35.180
at that time with classes for the
processing only of audio media.

00:00:35.180 --> 00:00:38.120
But even then,
you could tell by the name with the V in

00:00:38.120 --> 00:00:40.590
it that we had vast plans for expansion.

00:00:41.200 --> 00:00:45.870
And in fact, in iOS 4,
we did expand the framework vastly

00:00:45.870 --> 00:00:52.340
to cover timed audiovisual media,
not just audio media, including playback,

00:00:52.450 --> 00:00:57.690
capture, editing, export, re-encoding,
and even media sample

00:00:57.690 --> 00:01:00.350
processing at the low level.

00:01:00.730 --> 00:01:03.730
We've continued to enhance
the framework in iOS 5,

00:01:03.730 --> 00:01:06.800
and now we've brought it to
the desktop as well in Lion.

00:01:08.960 --> 00:01:12.940
One of the features of AV Foundation is
that it's well integrated with core

00:01:12.940 --> 00:01:16.220
technologies of both platforms,
iOS and Mac OS X.

00:01:16.600 --> 00:01:20.320
It's designed to fit snugly
on top of core audio,

00:01:20.420 --> 00:01:24.570
core media, core animation,
and foundation.

00:01:24.780 --> 00:01:29.240
And because its dependencies are
in common across the two platforms,

00:01:29.280 --> 00:01:33.840
its model is also in common
on both Mac OS X and iOS.

00:01:33.840 --> 00:01:38.390
It offers the same classes with only
a few minute differences between the

00:01:38.390 --> 00:01:42.920
two platforms and the same model for
dealing with timed audiovisual media.

00:01:43.060 --> 00:01:46.360
So you have the opportunity
by adopting AV Foundation,

00:01:46.400 --> 00:01:49.720
whether you build applications
for the desktop or for the

00:01:50.010 --> 00:01:53.140
mobile devices or for both,
for your code for dealing with

00:01:53.330 --> 00:01:57.550
timed audiovisual media to be in
common across the two platforms.

00:01:59.590 --> 00:02:02.040
Here's our proposition to you today.

00:02:02.170 --> 00:02:05.180
This is the media-centric
framework that we're putting

00:02:05.180 --> 00:02:06.640
the bulk of our effort into.

00:02:06.640 --> 00:02:11.730
And it's the set of APIs that the
majority of our apps are using.

00:02:11.740 --> 00:02:13.800
So here's a consideration for you.

00:02:13.800 --> 00:02:16.950
For your new applications,
adopting AV Foundation for

00:02:16.950 --> 00:02:20.620
timed audiovisual media,
and for your existing applications,

00:02:20.620 --> 00:02:23.500
making a transition to
this framework as well.

00:02:23.880 --> 00:02:27.150
We're going to cover the full breadth
of the framework in several sessions

00:02:27.150 --> 00:02:29.080
over the course of today and tomorrow.

00:02:29.080 --> 00:02:31.500
In this session,
we're going to cover primarily

00:02:31.500 --> 00:02:32.980
inspection and playback.

00:02:32.980 --> 00:02:35.320
And I'm going to turn
things over to my colleague,

00:02:35.320 --> 00:02:38.060
Simon Goldrei,
who's going to explore those with you.

00:02:38.510 --> 00:02:38.720
Thanks.

00:02:45.000 --> 00:02:46.970
Thanks, Kevin.

00:02:47.290 --> 00:02:52.340
Many of you here have been developing
on Mac OS X for some years now.

00:02:52.390 --> 00:02:55.800
You've both developed and
deployed wildly successful media

00:02:55.800 --> 00:02:58.370
applications for the platform.

00:02:58.930 --> 00:03:04.680
You've heard that AV Foundation is new,
back on the Mac, in Mac OS X Lion,

00:03:04.770 --> 00:03:10.830
and you've come here to discover its
suitability for your media application.

00:03:11.490 --> 00:03:18.180
The other half of you have been
developing for iOS these last few years.

00:03:18.530 --> 00:03:26.010
And you were here in this session
rediscovering AV Foundation last year.

00:03:26.400 --> 00:03:29.800
You too have developed
some really innovative,

00:03:29.890 --> 00:03:33.540
wonderful media applications
for this mobile platform.

00:03:33.670 --> 00:03:36.030
And now you'd like to learn
what the new features are,

00:03:36.280 --> 00:03:41.590
what's new in iOS 5 that we've
brought to AV Foundation.

00:03:42.860 --> 00:03:46.230
What we all strive for,
what we all desire from

00:03:46.230 --> 00:03:50.380
these applications is that
they remain responsive,

00:03:50.500 --> 00:03:53.510
robust, and efficient.

00:03:54.010 --> 00:03:59.300
I'm Simon Goldrei, and I'm part of the
Media Systems team at Apple.

00:03:59.410 --> 00:04:03.100
And over the next short 15
minutes that we have together,

00:04:03.150 --> 00:04:07.970
I would like to introduce to you one
of the core concepts of AV Foundation.

00:04:08.220 --> 00:04:16.230
How do we facilitate these goals of a
robust and efficient media application?

00:04:16.240 --> 00:04:20.950
What are the protocols and interfaces
that AV Foundation provides

00:04:20.950 --> 00:04:23.040
that support these goals?

00:04:23.040 --> 00:04:26.850
Now,
while we're going to survey the full set

00:04:26.850 --> 00:04:32.520
of classes that AV Foundation provides,
I'm going to only focus on those

00:04:32.650 --> 00:04:38.490
that provide media inspection and
discovery facilities and media playback.

00:04:38.580 --> 00:04:43.320
But last, and certainly not least,
I'll introduce you to some

00:04:43.320 --> 00:04:48.390
of the new APIs that we've
been able to provide in iOS 5,

00:04:48.390 --> 00:04:51.140
as well as the desktop.

00:04:51.390 --> 00:04:52.440
So let's begin.

00:04:52.700 --> 00:04:55.700
The first thing is
where is AV Foundation?

00:04:55.790 --> 00:05:00.840
AV Foundation on iOS sits above the
dependent frameworks of core audio,

00:05:00.920 --> 00:05:04.670
core media, and core animation,
but it sits below the

00:05:04.740 --> 00:05:09.410
application toolkits of
UIKit and Media Player Framework.

00:05:09.570 --> 00:05:13.310
At this foundational level,
AV Foundation is able to provide your

00:05:13.310 --> 00:05:18.280
media application a much richer set of
API than Media Player Framework can,

00:05:18.360 --> 00:05:23.360
as well as a much more tightly
integrated and greater opportunities

00:05:23.520 --> 00:05:25.750
for runtime efficiency.

00:05:25.860 --> 00:05:29.310
Of course,
the best efficiency that we now are

00:05:29.310 --> 00:05:35.200
able to provide is a common media
framework between the two platforms.

00:05:35.290 --> 00:05:39.220
For the first time,
we've got a common media playback API,

00:05:39.290 --> 00:05:44.450
as well as a rich set of API,
for both iOS and Mac OS X.

00:05:44.550 --> 00:05:48.460
And on Mac OS X, AV Foundation sits in
much the same place.

00:05:48.490 --> 00:05:54.420
Again, above the dependent frameworks,
but below the application toolkit.

00:05:58.270 --> 00:06:01.860
So when to use AV Foundation?

00:06:01.870 --> 00:06:07.040
AV Foundation provides this
really rich media API set.

00:06:07.050 --> 00:06:12.940
And we've covered the full gamut of
media operations that you may desire.

00:06:12.960 --> 00:06:15.990
And we've made it really easy for
you to adopt it in your application

00:06:16.330 --> 00:06:25.260
by providing separate interfaces for
each aspect of a media framework.

00:06:25.300 --> 00:06:28.800
In fact,
by providing separate interfaces,

00:06:28.830 --> 00:06:32.050
we've been able to separate
the operations for,

00:06:32.160 --> 00:06:37.660
say, just media inspection from
the much more involved,

00:06:37.680 --> 00:06:41.750
requiring much more overhead,
set of operations that require to

00:06:41.750 --> 00:06:45.040
prepare a media resource for playback.

00:06:45.460 --> 00:06:52.400
AV Foundation supports five key
areas of media play-- media playback.

00:06:52.560 --> 00:06:55.140
Oh, sorry, media API.

00:06:55.220 --> 00:06:58.850
The first key area is media inspection,
media discovery.

00:06:59.100 --> 00:07:02.290
What's inside your media resource?

00:07:03.040 --> 00:07:07.700
Next, there's a playback and
presentation set of classes.

00:07:07.760 --> 00:07:12.040
And these provide a really
customizable set of API.

00:07:12.080 --> 00:07:14.340
You get to control playback behavior.

00:07:14.400 --> 00:07:18.100
You get to control playback presentation.

00:07:19.060 --> 00:07:21.910
There exists a set of
composition classes.

00:07:22.060 --> 00:07:25.350
Composition classes
expose to you editing API,

00:07:25.360 --> 00:07:27.240
editing facilities.

00:07:27.380 --> 00:07:33.740
They allow you to combine segments
from multiple media resources,

00:07:34.540 --> 00:07:37.550
The goal is to create a new media
platform that can integrate different

00:07:37.590 --> 00:07:40.350
segments of media within those
resources and then compose them

00:07:40.430 --> 00:07:42.390
both temporally as well as spatially.

00:07:43.800 --> 00:07:47.740
There exists a set of export API.

00:07:47.760 --> 00:07:52.980
This allows you to transcode your
media and support a vast array of

00:07:52.980 --> 00:07:56.490
codexes output for your application.

00:07:57.410 --> 00:08:02.800
And lastly, and certainly not least,
there's a set of Capture API.

00:08:02.950 --> 00:08:08.590
And the Capture API allow you to provide
fine-grained control over the cameras

00:08:08.590 --> 00:08:14.160
in both your iOS handheld devices
as well as the desktop environment.

00:08:14.270 --> 00:08:19.030
We provide you the ability to control
image attributes about what you capture

00:08:19.720 --> 00:08:25.010
and persist this image stream to disk.

00:08:27.440 --> 00:08:33.390
So this rich media API that is
common to both iOS and Mac OS X.

00:08:33.500 --> 00:08:38.080
It's 64-bit native and hardware
acceleration comes standard.

00:08:38.160 --> 00:08:42.370
There's absolutely nothing
further for you to adopt.

00:08:42.460 --> 00:08:47.750
We have an advanced video render pipeline
that is GPU-backed from the time of

00:08:47.850 --> 00:08:51.120
decode all the way through to display.

00:08:51.180 --> 00:08:54.300
And to do this,
we've been tightly integrated

00:08:54.440 --> 00:08:56.190
with Core Animation.

00:08:56.910 --> 00:09:00.230
Before we go any further,
what are the challenges

00:09:00.840 --> 00:09:02.180
of using time media?

00:09:02.470 --> 00:09:05.110
What makes this so difficult?

00:09:06.070 --> 00:09:09.500
Time Media Resources,
as I'm sure you're now all very aware,

00:09:09.630 --> 00:09:12.200
are often gigabytes in size.

00:09:12.370 --> 00:09:17.730
They take time to download
from remote resources.

00:09:17.920 --> 00:09:21.320
They take time to decode and parse.

00:09:21.530 --> 00:09:25.970
In designing AV Foundation,
we've specifically sought not to

00:09:26.200 --> 00:09:29.520
obscure this reality from you,
the programmer.

00:09:29.800 --> 00:09:33.950
AV Foundation will only perform
the operations necessary to

00:09:34.020 --> 00:09:38.210
support your specific API requests.

00:09:38.500 --> 00:09:43.510
In addition to your requests,
we'll coordinate with a dynamic,

00:09:43.510 --> 00:09:50.170
lively playback environment that is able
to mutate objects beyond your control.

00:09:53.300 --> 00:09:58.540
And we do all this while providing
a set of protocols and interfaces,

00:09:58.540 --> 00:10:01.140
which we'll discuss in
more detail shortly,

00:10:01.160 --> 00:10:08.700
which support you and your development
in remaining responsive and efficient.

00:10:08.700 --> 00:10:10.940
Let me give you a concrete example.

00:10:10.980 --> 00:10:13.290
Suppose you're working with
a media resource that does

00:10:13.420 --> 00:10:15.540
contain summary information.

00:10:15.540 --> 00:10:19.790
In that case, it's all rather convenient.

00:10:20.670 --> 00:10:22.670
Ask for the duration of this resource.

00:10:22.870 --> 00:10:27.220
AV Foundation will download just enough
data to find the summary information

00:10:27.630 --> 00:10:31.160
and return to you the answer duration.

00:10:31.250 --> 00:10:34.230
But things are not
always this convenient.

00:10:34.710 --> 00:10:43.170
You may find that your media resource
does not contain summary information,

00:10:43.170 --> 00:10:43.170
in which case,
when you request the value of duration,

00:10:44.530 --> 00:10:49.360
AV Foundation needs to download the
entire media resource and only then

00:10:49.950 --> 00:10:52.590
return to you the value of duration.

00:10:52.770 --> 00:10:56.130
You do not want your media
application to be unresponsive

00:10:56.130 --> 00:10:58.500
during this lengthy period of time.

00:10:58.560 --> 00:11:03.480
In fact, you would like your media
API to help facilitate,

00:11:03.610 --> 00:11:09.590
to direct you towards a
responsive user experience.

00:11:10.770 --> 00:11:16.590
So, let me take this opportunity
with you together to explain,

00:11:16.850 --> 00:11:19.980
to introduce you to the
classes and protocols that we

00:11:19.980 --> 00:11:24.200
provide in AV Foundation that
help us meet these goals.

00:11:25.910 --> 00:11:29.250
Albert Einstein once quipped that
the only reason for time is so that

00:11:29.250 --> 00:11:31.340
everything doesn't happen at once.

00:11:31.360 --> 00:11:34.960
And while I don't disagree,
I really think that some things

00:11:34.960 --> 00:11:36.900
best happen concurrently.

00:11:37.220 --> 00:11:41.000
In AV Foundation,
we try to like to have these

00:11:41.050 --> 00:11:46.950
two notions of media models,
the static and dynamic.

00:11:47.320 --> 00:11:52.000
The static models are used for
media inspection and discovery.

00:11:52.110 --> 00:11:57.230
You make requests on them,
reload the data, and once they're loaded,

00:11:57.230 --> 00:12:00.510
the values of these
properties don't change.

00:12:00.860 --> 00:12:04.710
The dynamic objects, on the other hand,
are part of a lively

00:12:04.750 --> 00:12:06.530
playback environment.

00:12:06.640 --> 00:12:12.790
You observe them as they mutate
within the playback environment.

00:12:14.040 --> 00:12:17.980
To benefit from this useful
distinction of static versus dynamic,

00:12:18.120 --> 00:12:23.490
inspection versus playback,
you are to request values of

00:12:23.490 --> 00:12:29.140
static models and await loading
of values asynchronously.

00:12:29.300 --> 00:12:32.680
And for dynamic models,
you use key value observing

00:12:32.770 --> 00:12:34.370
where it's offered.

00:12:36.910 --> 00:12:40.300
On iOS,
there's an additional consideration.

00:12:40.450 --> 00:12:44.040
On iOS,
your media operations can be interrupted.

00:12:44.170 --> 00:12:45.800
They can be interrupted
by telephone calls,

00:12:45.800 --> 00:12:48.310
by FaceTime requests.

00:12:48.930 --> 00:12:51.800
So you need to be prepared.

00:12:51.820 --> 00:12:57.690
Additionally, the shared media services
on iOS can be reset.

00:12:58.340 --> 00:13:01.710
In order to avoid these
services being reset,

00:13:01.980 --> 00:13:04.040
you should be considerate.

00:13:04.150 --> 00:13:08.580
You need to share these media
resources in an asynchronous manner.

00:13:08.720 --> 00:13:12.660
Fortunately, to make this really easy,
there's a protocol for that.

00:13:13.530 --> 00:13:18.620
Let's now survey the core playback
classes present in AV Foundation.

00:13:18.850 --> 00:13:20.690
It starts...

00:13:21.100 --> 00:13:23.500
with the AVR set.

00:13:23.630 --> 00:13:28.990
The AVR set is a model for
the entire media resource.

00:13:29.330 --> 00:13:35.090
You request values on AV asset
using a protocol called

00:13:35.420 --> 00:13:39.160
AV asynchronous key value loading,
which I'll describe in

00:13:39.160 --> 00:13:40.780
more detail shortly.

00:13:41.280 --> 00:13:45.410
You might request of an AV asset
its collection of tracks,

00:13:45.410 --> 00:13:48.780
in which case AV Foundation will
download all the data necessary

00:13:49.170 --> 00:13:55.430
in order just to specify,
in order to just answer this one request.

00:13:55.550 --> 00:14:01.290
We'll populate the collection of
AV asset tracks and return this to you.

00:14:03.910 --> 00:14:09.100
and AV Asset Track is a static
model for the single media stream

00:14:09.250 --> 00:14:11.800
within a time media resource.

00:14:11.860 --> 00:14:14.290
All of these classes

00:14:15.000 --> 00:14:22.700
[Transcript missing]

00:14:24.160 --> 00:14:27.600
If your media application
intent is just to perform media

00:14:27.600 --> 00:14:31.190
inspection and media discovery,
these are all the classes

00:14:31.190 --> 00:14:32.830
you need to worry about.

00:14:33.540 --> 00:14:38.740
But let's now expand your application
scope to include playback.

00:14:38.890 --> 00:14:42.740
Let me introduce you to the AV Player.

00:14:42.850 --> 00:14:46.240
A sophisticated media
controller for playback.

00:14:46.300 --> 00:14:49.300
And by sophisticated,
I mean that it's customizable.

00:14:49.370 --> 00:14:53.680
You have control over playback behavior.

00:14:53.750 --> 00:14:58.240
But in and of itself,
AV Player and AV Asset are not

00:14:58.240 --> 00:15:01.930
all you need to achieve playback.

00:15:02.170 --> 00:15:05.900
You need a model for the
AV asset during playback.

00:15:05.960 --> 00:15:10.290
And for that, let me introduce you
to the AV player item.

00:15:11.440 --> 00:15:16.900
a model for the AV asset for the
entire media resource during playback.

00:15:18.030 --> 00:15:22.940
AV Player Item is an example of
one of these dynamic model objects.

00:15:23.090 --> 00:15:27.580
You add yourself as an observer
using foundations and a

00:15:27.720 --> 00:15:30.890
key-value observing interface.

00:15:31.450 --> 00:15:35.080
And you want to add yourself as
an observer to an AV player item

00:15:35.380 --> 00:15:39.440
before you associate it with an
AV player because as soon as you do,

00:15:39.490 --> 00:15:42.320
it's part of the active
playback environment.

00:15:42.380 --> 00:15:45.520
AV Foundation will again download
all the data necessary to

00:15:45.530 --> 00:15:48.900
prepare this item for playback,
populate the collection

00:15:48.900 --> 00:15:53.380
of AV player item tracks,
and finally make that player

00:15:53.700 --> 00:15:55.650
item ready for playback.

00:15:56.130 --> 00:15:59.000
You want to observe these changes.

00:15:59.080 --> 00:16:02.010
An AV player item track

00:16:02.220 --> 00:16:07.730
is a model for a single media stream,
or an AV asset track, during playback.

00:16:09.510 --> 00:16:13.640
Let's explore some more and take
a look at the first of these,

00:16:13.790 --> 00:16:15.920
the AV asset.

00:16:17.340 --> 00:16:20.170
The AV asset is inspectable
via the AV asynchronous

00:16:20.330 --> 00:16:22.670
key value loading protocol.

00:16:22.790 --> 00:16:26.220
It models the entire media resource.

00:16:26.480 --> 00:16:29.470
You don't instantiate
an AV asset directly,

00:16:29.470 --> 00:16:32.340
but rather you instantiate
one of its subclasses,

00:16:32.370 --> 00:16:34.720
the AV URL asset.

00:16:34.830 --> 00:16:38.300
And you can provide an
NSURL for this purpose.

00:16:38.910 --> 00:16:42.250
What's important to note is
that an AV asset in this state,

00:16:42.340 --> 00:16:45.930
in this newly initialized state,
is not ready for any particular task.

00:16:45.930 --> 00:16:52.360
You haven't loaded any of the
values for any of its properties.

00:16:53.720 --> 00:16:57.540
An AV asset provides lots of information
about the whole media resource,

00:16:57.570 --> 00:17:02.600
the collection of tracks, the lyrics,
possibly the duration,

00:17:02.670 --> 00:17:07.320
but it also provides four properties
which are particularly useful.

00:17:07.350 --> 00:17:09.580
It tells you what the
AV asset is good for,

00:17:09.620 --> 00:17:12.960
what you can do with it,
what its utility is.

00:17:13.320 --> 00:17:18.870
An AV asset may be exportable,
composable, readable, that is,

00:17:18.980 --> 00:17:25.030
can you get samples from it, and last,
playable.

00:17:25.370 --> 00:17:30.230
AV Foundation supports a rich set
of modern and relevant media codecs,

00:17:30.230 --> 00:17:34.600
and it's through the playable property
that you discover if AV Foundation is

00:17:34.730 --> 00:17:39.120
able to service this asset for playback.

00:17:39.830 --> 00:17:42.250
Let's take a look at an example
of how you would load the

00:17:42.370 --> 00:17:46.030
playable property on an AV asset.

00:17:47.850 --> 00:17:51.740
It starts off with allocating
a collection of properties that

00:17:51.740 --> 00:17:53.380
we're interested in loading.

00:17:53.520 --> 00:17:56.740
In this case, it's just one,
the playable property.

00:17:56.920 --> 00:17:59.660
We use the method from
the AV asynchronous key

00:17:59.660 --> 00:18:03.140
value loading protocol,
load values asynchronously for keys,

00:18:03.470 --> 00:18:07.690
provide this collection,
and then provide a completion handler,

00:18:07.690 --> 00:18:09.010
which is a block.

00:18:10.730 --> 00:18:13.200
Within the block,
when the loading operation

00:18:13.200 --> 00:18:19.440
has succeeded or progressed,
we get the value of the status

00:18:19.440 --> 00:18:21.380
for the loading operation.

00:18:22.840 --> 00:18:25.590
Then we switch over the possible values.

00:18:25.670 --> 00:18:31.330
Possible values may be loaded, failed,
or for the sake of brevity, canceled.

00:18:31.430 --> 00:18:34.820
Ideally, if everything worked out nicely
and the value of the playable

00:18:34.820 --> 00:18:37.630
property has indeed been loaded,
we end up here inside

00:18:37.750 --> 00:18:39.500
the switch statement.

00:18:39.590 --> 00:18:43.200
In which case,
all we need to do now is enable

00:18:43.200 --> 00:18:47.720
our UI for our user to select
that AV asset for playback.

00:18:47.940 --> 00:18:54.040
What is important to note here is
that this is an asynchronous loading.

00:18:54.070 --> 00:18:57.240
It's occurring on some arbitrary queue.

00:18:57.420 --> 00:19:01.430
If you want to perform
user interface operations,

00:19:01.650 --> 00:19:05.390
you need to move execution
back to the main queue.

00:19:07.360 --> 00:19:13.170
Let's return to our class
collection here and drop down one

00:19:13.170 --> 00:19:16.320
level into the AV asset track.

00:19:17.010 --> 00:19:19.530
The AV asset track,
another static model object,

00:19:19.530 --> 00:19:22.010
is also inspectable via
the AV asynchronous key

00:19:22.010 --> 00:19:24.130
value loading protocol.

00:19:24.330 --> 00:19:29.480
And it models the static state of a
single media stream within the resource.

00:19:29.770 --> 00:19:33.430
In this little coding example
for obtaining the collection of

00:19:33.450 --> 00:19:37.990
AV asset tracks within the resource,
I've chosen to first test the

00:19:37.990 --> 00:19:43.950
status and then progress further and
continue with the AV asynchronous

00:19:43.950 --> 00:19:46.840
key value loading protocol,
loading the values

00:19:46.900 --> 00:19:49.050
asynchronously for keys.

00:19:50.860 --> 00:19:55.100
Each AV asset track is
of a single media type.

00:19:55.220 --> 00:19:58.140
It details information such
as the format description,

00:19:58.140 --> 00:20:01.820
the frame rate of the media stream,
data rate, language tagging,

00:20:01.920 --> 00:20:04.200
and some sundry metadata.

00:20:06.430 --> 00:20:10.240
Returning to our class collection,
class diagram,

00:20:10.240 --> 00:20:14.960
let's jump to the other side and
focus on the media controller,

00:20:14.960 --> 00:20:16.210
the AV Player.

00:20:19.340 --> 00:20:23.500
The AV player, because it's part of the
dynamic playback environment,

00:20:23.550 --> 00:20:28.640
is observable via NSKValue observing.

00:20:28.750 --> 00:20:33.960
It's a media controller with just
a few AV player item conveniences.

00:20:34.130 --> 00:20:41.570
You instantiate an AV player by
typically providing an AV player item.

00:20:43.300 --> 00:20:47.740
AV Player is also the
object for observing time.

00:20:47.800 --> 00:20:51.620
You observe time to implement
a customized scrubber

00:20:51.630 --> 00:20:54.170
UI or transport control.

00:20:54.400 --> 00:20:58.960
But you don't use key value
observing for observing time,

00:20:58.960 --> 00:21:01.500
because time,
as it progresses through playback,

00:21:01.570 --> 00:21:03.940
is a constantly changing value.

00:21:04.060 --> 00:21:08.760
It's not a discrete transition
from value A to value B.

00:21:09.030 --> 00:21:11.910
So in AV Player,
we provide two interfaces

00:21:12.480 --> 00:21:14.400
for observing time.

00:21:14.400 --> 00:21:18.940
The first of which is the
periodic time observer,

00:21:18.960 --> 00:21:23.140
and the second of which is
the boundary time observer.

00:21:23.830 --> 00:21:29.330
The Periodic Time Observer allows you
to specify a single interval of time.

00:21:29.560 --> 00:21:38.030
As each single interval of
media time is progressed,

00:21:38.030 --> 00:21:38.030
or is traversed through normal playback,
you'll get a callback.

00:21:38.460 --> 00:21:41.300
The Boundary Time Observer
is a little different.

00:21:41.500 --> 00:21:44.700
Instead,
you provide a collection of points of

00:21:44.700 --> 00:21:47.300
media time within the media resource.

00:21:47.510 --> 00:21:51.470
And as each of these points in time
are traversed through normal playback,

00:21:51.540 --> 00:21:53.300
you'll get a callback.

00:21:53.520 --> 00:21:55.300
Your block will be invoked.

00:21:56.610 --> 00:22:00.470
Let's take a look now at a little
coding example of how you might

00:22:00.570 --> 00:22:06.670
implement a scrubber UI using
the periodic time observer.

00:22:07.650 --> 00:22:10.540
It starts off, well,
I've defined two methods,

00:22:10.540 --> 00:22:14.740
set up transport UI and a cleanup method.

00:22:14.740 --> 00:22:19.220
And it starts off with adding a
periodic time observer for an interval.

00:22:19.220 --> 00:22:24.120
And I provide a single interval,
a nominal one, of say half a second.

00:22:24.120 --> 00:22:24.960
That's reasonable.

00:22:24.960 --> 00:22:28.010
That gives us enough
fidelity in our scrubber UI.

00:22:28.020 --> 00:22:34.360
We provide a dispatch queue where
we want to get the call back on.

00:22:34.420 --> 00:22:36.390
In this case,
I'm going to be doing a lot of UI,

00:22:36.390 --> 00:22:38.020
so I've chosen the main queue.

00:22:38.020 --> 00:22:43.580
And then I provide a block that
is invoked after each successive

00:22:43.580 --> 00:22:45.200
time interval is traversed.

00:22:47.020 --> 00:22:50.950
In this nice, simple example,
we move the playhead over

00:22:50.950 --> 00:22:53.100
half a second's worth.

00:22:54.650 --> 00:22:58.600
And lest we forget,
we have a cleanup method which

00:22:58.840 --> 00:23:03.180
removes the time observer from the
player and releases the reference

00:23:03.270 --> 00:23:07.460
count that we have over the token
that was returned to us earlier.

00:23:11.480 --> 00:23:16.920
Returning to the classes again,
let's now look at the central object,

00:23:17.000 --> 00:23:19.330
the AV player item.

00:23:19.760 --> 00:23:23.640
AV Player Item.

00:23:23.640 --> 00:23:27.240
AV Player Item is one of
these dynamic model objects.

00:23:27.350 --> 00:23:35.530
It's your dynamic model of an entire
media resource during playback.

00:23:35.970 --> 00:23:38.940
What's useful to note is that
you can create many AV player

00:23:38.940 --> 00:23:41.970
items with a single AV asset.

00:23:42.560 --> 00:23:48.380
You can also instantiate an AV player
item with an NSURL instance directly.

00:23:49.000 --> 00:23:53.240
AV Player Item provides
a bunch of useful tools.

00:23:53.250 --> 00:23:55.930
The first of which is that
it gives you properties,

00:23:56.010 --> 00:23:59.200
property values about your
media resource that are only

00:23:59.200 --> 00:24:01.200
discernible during playback.

00:24:01.210 --> 00:24:05.070
For example, a streaming resource,
you can only learn about

00:24:05.070 --> 00:24:06.260
the duration at playback.

00:24:06.260 --> 00:24:12.240
It provides the collection of tracks,
the presentation size, and you in iOS 5,

00:24:12.240 --> 00:24:18.620
the ability of a player item to play
while fast-forwarding or fast-reversing.

00:24:20.940 --> 00:24:25.760
AV Player Item is also your
object for manipulating time.

00:24:25.780 --> 00:24:33.520
It's how you can seek to a specific time,
step by a count, that is step by a single

00:24:33.520 --> 00:24:37.770
frame or a single sample,
and specify a forward playback end

00:24:37.830 --> 00:24:43.340
time and a reverse playback end time,
that is when playback will cease

00:24:43.720 --> 00:24:48.480
when playing forward and when it
will cease playing in reverse.

00:24:50.850 --> 00:24:56.580
AV Player Item also provides hints,
indications on how playback is going,

00:24:56.580 --> 00:25:01.480
the ability or the likelihood
of playback likely to keep up,

00:25:01.530 --> 00:25:04.510
whether the playback
buffer is full or empty,

00:25:04.510 --> 00:25:08.520
and what the set of loadable
and syncable time ranges are.

00:25:09.540 --> 00:25:15.440
AV Player Item is also your guide to see
how the playback environment is going.

00:25:15.460 --> 00:25:19.300
It gives you information about services.

00:25:19.340 --> 00:25:24.980
It gives you access to the network
access log and the network error log.

00:25:25.020 --> 00:25:28.160
And it gives you a
property called status.

00:25:28.160 --> 00:25:32.820
And status is your indication
for the eligibility for a

00:25:32.820 --> 00:25:36.590
player item for playback,
whether AV Foundation is likely to

00:25:36.590 --> 00:25:39.240
service this player item for playback.

00:25:40.770 --> 00:25:44.970
It also gives you a hint as to
when the shared media services

00:25:45.040 --> 00:25:47.120
may have been terminated.

00:25:47.180 --> 00:25:53.560
Possible values for status are unknown,
ready for playback, or failed.

00:25:54.450 --> 00:25:59.020
Let's take a look now in code on
how you would add yourself as an

00:25:59.020 --> 00:26:03.890
observer and observe the status
property on an AV player item.

00:26:04.120 --> 00:26:08.760
It starts by adding observer
with an observation context.

00:26:08.790 --> 00:26:16.450
And we're interested in the new option,
the new value that we transition to.

00:26:17.120 --> 00:26:24.300
Next, we override the NSObject method,
observe value for keypath.

00:26:24.310 --> 00:26:26.780
We check to see if the
observation context is the same

00:26:26.780 --> 00:26:29.250
as the one we provided earlier.

00:26:29.690 --> 00:26:33.390
Get the reference to the item,
get a reference to the status,

00:26:33.550 --> 00:26:36.130
switch over the possible
values of status,

00:26:36.130 --> 00:26:41.590
and if everything worked out just fine,
we arrive here where the

00:26:41.590 --> 00:26:43.740
item is ready to play.

00:26:43.800 --> 00:26:46.710
The only thing left to do now that
we know that the item is eligible

00:26:46.810 --> 00:26:50.910
for playback is to message our
player with the message "Play."

00:26:54.060 --> 00:26:59.500
Let's drop down one level
into the AV Player Item track.

00:27:04.350 --> 00:27:10.450
AV Player Item Track is your model for
that single media stream during playback,

00:27:10.460 --> 00:27:12.810
the AV Asset Track during playback.

00:27:12.880 --> 00:27:16.360
It provides two properties,
the first of which,

00:27:16.400 --> 00:27:21.650
a mutable property called enabled,
gives you the ability to disable a

00:27:21.650 --> 00:27:25.150
single AV player item track for playback.

00:27:25.220 --> 00:27:27.960
We'll discuss why that
might be useful in a moment.

00:27:28.060 --> 00:27:32.300
It also provides a reference
to the AV asset track that

00:27:32.300 --> 00:27:35.000
backs the AV player item track.

00:27:35.830 --> 00:27:40.050
The enabled property is
useful for disabling a player

00:27:40.760 --> 00:27:42.740
item track for playback.

00:27:43.150 --> 00:27:46.460
For example,
if you have an audio-visual resource,

00:27:46.590 --> 00:27:51.730
you might want to disable the video
tracks so that the audio-visual

00:27:51.730 --> 00:27:54.600
resource plays back as audio only.

00:27:54.740 --> 00:27:59.540
And this is particularly useful on iOS so
that your audio-visual resource is still

00:27:59.540 --> 00:28:02.770
eligible for playback in the background.

00:28:02.910 --> 00:28:07.140
Let's take a look now at how
you might disable an AV player

00:28:07.140 --> 00:28:09.320
item track for playback.

00:28:11.390 --> 00:28:17.410
Again, it starts off with adding observer
for the tracks property on the

00:28:17.450 --> 00:28:22.110
AV player item so that we get
the full collection of tracks.

00:28:22.430 --> 00:28:27.100
We override the observe
value for key path method,

00:28:27.120 --> 00:28:29.270
check to see if the observation
context is the same,

00:28:29.410 --> 00:28:35.440
obtained the reference to the tracks
and iterate over each track in turn.

00:28:36.230 --> 00:28:41.690
As we iterate over each one,
we get the reference to the

00:28:41.690 --> 00:28:44.940
AV asset track that backs it,
ask for its media type,

00:28:44.980 --> 00:28:48.600
and check to see if the
media type is of type video.

00:28:48.680 --> 00:28:53.080
If it is, disable that AV player
item track for playback,

00:28:53.080 --> 00:28:56.920
and we end up with an audio
and audio-visual resource with

00:28:57.010 --> 00:29:03.780
just the potentially only audio
tracks eligible for playback.

00:29:05.750 --> 00:29:11.740
So, what's the recipe for playback
in just four easy steps?

00:29:12.360 --> 00:29:18.480
The first of which is create
your AV URL asset instance.

00:29:18.480 --> 00:29:22.800
Next, load asynchronously using
the AV asynchronous key value

00:29:22.800 --> 00:29:26.630
loading protocol the tracks.

00:29:26.860 --> 00:29:30.740
Now that you've done this,
you can create your AV player item.

00:29:30.850 --> 00:29:34.600
And finally,
you can either create your AV player

00:29:34.600 --> 00:29:39.300
with this item or replace the
current item with this item.

00:29:41.720 --> 00:29:45.660
Now,
I've shown you all the core classes for

00:29:45.780 --> 00:29:49.080
playback that AV Foundation provides.

00:29:49.870 --> 00:29:54.080
But since iOS 4,
we've introduced a new media controller,

00:29:54.130 --> 00:29:56.240
the AVQ Player.

00:29:56.300 --> 00:30:01.040
The AVQ Player, unlike an AV Player,
as you're probably guessing right now,

00:30:01.070 --> 00:30:08.930
not only lets you manage a single
AV Player item to AV Player relationship,

00:30:09.360 --> 00:30:15.700
But multiple AV player item to a
single controller relationship.

00:30:15.790 --> 00:30:20.830
Again, much like AV player,
any AV player items that are

00:30:20.840 --> 00:30:25.520
associated with the AV queue player
will be prepared for playback.

00:30:25.590 --> 00:30:28.140
As soon as you associate them,

00:30:28.690 --> 00:30:32.160
All the data necessary in order
to prepare those items for

00:30:32.280 --> 00:30:37.000
playback will be downloaded by
AV Foundation on your behalf.

00:30:37.250 --> 00:30:38.710
So...

00:30:39.280 --> 00:30:44.540
An AVQ player is not a playlist model.

00:30:44.590 --> 00:30:48.400
The AVQ player will prepare all
the media resources that are

00:30:48.400 --> 00:30:50.970
associated with it for playback.

00:30:52.150 --> 00:30:55.700
But what an AV cue player does
provide is a mechanism for

00:30:55.700 --> 00:30:58.380
gapless audio item transition.

00:30:58.420 --> 00:31:04.440
It's also your mechanism for obtaining
asset or AV player item looping.

00:31:04.490 --> 00:31:09.580
Remember, we can create many AV player
items with a single AV asset,

00:31:09.630 --> 00:31:13.010
and then looping is just enqueuing
multiple of these AV player items

00:31:13.070 --> 00:31:17.000
into a cue player and letting
it progress from item to item.

00:31:17.030 --> 00:31:19.960
You instantiate an AV cue player,
typically with a collection

00:31:19.960 --> 00:31:22.100
of AV player items.

00:31:22.100 --> 00:31:26.190
Now, I've told you that it's
not a playlist model.

00:31:26.380 --> 00:31:28.340
It's not a playlist controller.

00:31:28.430 --> 00:31:33.250
So how might you implement a
playlist using the AV cue player?

00:31:33.450 --> 00:31:36.240
Before we dive into the code,
let's have a look at a nice,

00:31:36.300 --> 00:31:40.750
simple graphical representation
of how this is all going to work.

00:31:41.380 --> 00:31:46.730
On the left-hand side,
we've got a collection of lifeless,

00:31:47.150 --> 00:31:49.180
Persistible AV Assets.

00:31:49.180 --> 00:31:49.880
They're gray.

00:31:49.880 --> 00:31:51.240
They don't have any color.

00:31:52.940 --> 00:31:54.640
Sorry, that was on the left-hand side.

00:31:54.710 --> 00:31:59.840
On the right-hand side,
we've got an AVQ player already

00:31:59.840 --> 00:32:05.090
populated with ready-to-play,
colorful AV player items.

00:32:05.170 --> 00:32:07.580
The story goes like this.

00:32:08.020 --> 00:32:11.030
An AV player item finishes playback.

00:32:11.150 --> 00:32:14.360
The current item is the one
that's underneath the triangle.

00:32:16.130 --> 00:32:19.570
The item finishes playback,
and we pop off the

00:32:19.570 --> 00:32:23.560
collection of AV assets,
the next AV asset that

00:32:23.560 --> 00:32:25.210
we want to enqueue.

00:32:25.890 --> 00:32:29.240
We load the value of tracks
using the AV asynchronous

00:32:29.390 --> 00:32:31.440
key value loading protocol.

00:32:31.540 --> 00:32:36.350
And once that's been done,
we can create our AV player item from it.

00:32:37.000 --> 00:32:40.940
We enqueue the AV player item,
and AV Foundation will download

00:32:40.940 --> 00:32:45.110
all the data necessary in order
to prepare that item for playback,

00:32:45.110 --> 00:32:47.860
and it becomes ready for playback.

00:32:47.920 --> 00:32:50.270
The lifecycle continues.

00:32:53.070 --> 00:32:55.780
An AV player item is finished playback.

00:32:55.780 --> 00:32:57.580
A new AV asset is dequeued.

00:32:57.690 --> 00:32:58.670
We ask for the tracks.

00:32:58.820 --> 00:33:00.140
We create an AV player item.

00:33:00.140 --> 00:33:01.540
We enqueue it.

00:33:01.590 --> 00:33:06.240
And AV Foundation prepares that
AV player item for playback.

00:33:08.320 --> 00:33:11.750
Now that you've got a good
graphical image in your minds and

00:33:11.840 --> 00:33:15.780
how this is all going to work,
let's take a look at the code.

00:33:16.950 --> 00:33:21.860
It starts off with our
resurrection from disk of the

00:33:21.860 --> 00:33:24.800
lifeless collection of AV assets.

00:33:25.020 --> 00:33:27.420
It's in an NSMutable array.

00:33:28.810 --> 00:33:32.970
We'd like to populate our
AVQ player with just enough items

00:33:33.160 --> 00:33:35.990
to maintain seamless playback.

00:33:36.680 --> 00:33:39.670
Of course,
the first thing that we have to

00:33:39.830 --> 00:33:45.070
do as we enqueue or dequeue an
AV asset is we check to see what the

00:33:45.600 --> 00:33:48.360
status of the tracks property is.

00:33:48.450 --> 00:33:51.650
Now, for brevity and keeping everything
nice and simple on my slide,

00:33:51.900 --> 00:33:54.750
I'm just going to check what the
status is of the tracks property.

00:33:55.060 --> 00:33:58.930
But in reality, in your code,
you'll have to use the

00:33:58.930 --> 00:34:02.960
AV asynchronous key value loading
protocol to load the tracks.

00:34:04.650 --> 00:34:09.030
I've chosen the number three here,
which will work in most cases,

00:34:09.030 --> 00:34:13.810
but is by no means a magic number.

00:34:15.270 --> 00:34:19.540
Next up,
we observe the current item because

00:34:19.540 --> 00:34:24.120
it's part of the playback environment,
and we provide an observation context.

00:34:27.510 --> 00:34:31.910
We observe value for keypath,
check to see the observation context is

00:34:32.010 --> 00:34:34.950
the same as the one we provided earlier.

00:34:35.310 --> 00:34:41.530
Obtain the last, or reference to the last
item in the AVQ player.

00:34:41.780 --> 00:34:45.500
pop off the next AV asset
from our collection.

00:34:45.540 --> 00:34:52.310
Again, check the status for tracks or,
in your code, you'll load asynchronously

00:34:52.310 --> 00:34:54.370
the value for keys tracks.

00:34:54.690 --> 00:34:58.040
Test to see if it actually
is loaded and if it is,

00:34:58.120 --> 00:35:00.380
create an AV player item with it.

00:35:00.470 --> 00:35:04.080
Finally,
we insert the AV player item we've

00:35:04.400 --> 00:35:08.710
just created into the AV queue
player because we have the last

00:35:08.710 --> 00:35:10.500
item reference that we had before.

00:35:10.510 --> 00:35:14.180
We can specify to enqueue after it.

00:35:16.110 --> 00:35:19.850
So I've shown you all the
classes used for playback,

00:35:19.850 --> 00:35:23.940
and I've introduced the new one
that we've introduced since iOS 4.

00:35:23.990 --> 00:35:28.040
But I haven't yet shown you how
to display any of this on screen.

00:35:28.090 --> 00:35:32.120
And, well, that's only because I didn't
have enough space in my slide.

00:35:32.160 --> 00:35:36.480
And so I'd now like to introduce
you to the AV Player Layer.

00:35:36.510 --> 00:35:38.780
The AV Player Layer

00:35:40.600 --> 00:35:44.030
is your presentation object.

00:35:44.100 --> 00:35:47.470
It's how you display stuff on screen.

00:35:48.120 --> 00:35:53.940
It's a part of the playback classes,
so it's observable.

00:35:53.980 --> 00:36:00.140
And you attach your AV player layer to,
on iOS, an instance of a UI view,

00:36:00.170 --> 00:36:05.060
on the desktop, on a Mac OS X,
an NS view that wants layer,

00:36:05.100 --> 00:36:07.680
or on either platform,

00:36:07.800 --> 00:36:11.700
An arbitrary CA layer
from some hierarchy.

00:36:11.700 --> 00:36:17.550
You typically instantiate an
AV player layer with an AV player.

00:36:19.220 --> 00:36:22.640
There are two properties that I'd
like to share with you to discuss

00:36:23.040 --> 00:36:26.340
with you about AV Player Layer.

00:36:26.490 --> 00:36:28.500
The first of which

00:36:30.060 --> 00:36:31.980
is ready for display.

00:36:32.310 --> 00:36:37.530
Ready for display is an observable
property which you observe to see

00:36:37.790 --> 00:36:43.140
when the first sample is populated
inside your AV player layer.

00:36:43.210 --> 00:36:46.070
When your AV player layer
has some contents that's

00:36:46.210 --> 00:36:51.250
worth displaying on screen,
you use ready for display to ensure that

00:36:51.340 --> 00:36:54.590
your AV player layer doesn't leave any,
you know, voids,

00:36:54.710 --> 00:36:58.090
black boxes inside your user interface.

00:36:58.720 --> 00:37:03.840
Once ready for display, achieves a value,
mutates to a value of yes,

00:37:03.960 --> 00:37:06.520
you're now ready to open the
red curtain on your content

00:37:07.030 --> 00:37:09.030
and display it to your user.

00:37:09.150 --> 00:37:13.740
No glitches, no black boxes.

00:37:13.870 --> 00:37:18.690
The next property I'd like
to show you is video gravity.

00:37:20.170 --> 00:37:24.610
There are many ways that you
can display your audiovisual

00:37:24.710 --> 00:37:29.220
content within an AV player layer.

00:37:30.270 --> 00:37:30.270
You can

00:37:31.290 --> 00:37:35.750
Maintain aspect ratio and keep
all the content inside the

00:37:35.750 --> 00:37:38.230
extents of the AV player layer.

00:37:39.030 --> 00:37:44.240
You can stretch your content so that
it fills the extent of your AV player

00:37:44.240 --> 00:37:47.790
layer but not maintain aspect ratio.

00:37:48.260 --> 00:37:52.430
And lastly, you can fill the extents
of your AV player layer

00:37:52.850 --> 00:37:58.500
and maintain aspect ratio,
but some content clipping may occur.

00:38:01.300 --> 00:38:06.020
Let me take this opportunity to
summarize the key points on how

00:38:06.020 --> 00:38:08.820
to use AV Foundation efficiently.

00:38:08.890 --> 00:38:13.190
How do you achieve our original
goals of building a robust,

00:38:13.300 --> 00:38:16.720
efficient,
and responsive media application

00:38:16.720 --> 00:38:18.700
using this framework?

00:38:21.460 --> 00:38:24.770
I introduce you to the
notion of the static model.

00:38:24.900 --> 00:38:28.750
It's used for media inspection
and media discovery.

00:38:29.220 --> 00:38:32.500
We perform loading
only upon your request,

00:38:32.550 --> 00:38:37.100
asynchronously,
and when the value is available,

00:38:37.130 --> 00:38:37.820
you'll get a callback.

00:38:37.940 --> 00:38:41.190
Once the value is loaded,
it does not change.

00:38:41.200 --> 00:38:46.900
This is not to say that you can't ask for
values synchronously on a static model.

00:38:46.900 --> 00:38:49.770
You just may be waiting
a really long time,

00:38:49.770 --> 00:38:53.820
and your application will be
perceived to be unresponsive,

00:38:53.880 --> 00:38:59.050
or on iOS,
you risk media services being terminated.

00:38:59.100 --> 00:39:00.330
Thank you.

00:39:01.040 --> 00:39:04.770
The two examples of objects that we
saw that adhere to the static model

00:39:05.070 --> 00:39:09.440
notion are AV Asset and AV Asset Track.

00:39:11.470 --> 00:39:16.520
I then introduce you to the
notion of a dynamic model,

00:39:16.520 --> 00:39:18.880
which is part of the lively
playback environment.

00:39:19.150 --> 00:39:25.640
The objects that I introduced
that adhere to this model are

00:39:25.640 --> 00:39:28.080
AVPlayerItem and AVPlayerItemTrack.

00:39:28.280 --> 00:39:34.120
You use Foundation's NSKey value
observing interface to observe as

00:39:34.230 --> 00:39:40.350
values mutate independently of your
requests inside a playback environment.

00:39:42.110 --> 00:39:45.760
These protocols are really important.

00:39:45.850 --> 00:39:48.910
They're part of a platform etiquette.

00:39:49.610 --> 00:39:53.250
On Mac OS X,
if you don't use these protocols,

00:39:53.250 --> 00:39:56.210
your application will
experience the spod,

00:39:56.210 --> 00:39:58.710
or the spinning pinwheel of death.

00:39:58.800 --> 00:40:01.950
Your application will appear
to be unresponsive and

00:40:01.950 --> 00:40:04.390
poor-performing by your users.

00:40:04.980 --> 00:40:09.170
On iOS, the situation's even more dire.

00:40:09.430 --> 00:40:12.190
If you don't use these protocols,

00:40:12.740 --> 00:40:16.220
You risk media service termination,
which will not only

00:40:16.400 --> 00:40:20.040
affect your application,
but all the other applications that are

00:40:20.200 --> 00:40:23.990
reliant on the shared media services.

00:40:24.450 --> 00:40:28.910
Again,
use the AV asynchronous key value loading

00:40:28.970 --> 00:40:37.390
protocol for static models and observe
dynamic models using key value observing.

00:40:38.610 --> 00:40:39.700
Right.

00:40:39.740 --> 00:40:43.560
Now I'd like to introduce you to
some of the new exciting API that

00:40:43.560 --> 00:40:47.130
we've provided since iOS 4.

00:40:47.260 --> 00:40:51.490
The first of which is AirPlay.

00:40:53.780 --> 00:40:57.000
AirPlay enables your media
application to stream your

00:40:57.000 --> 00:41:00.180
content wirelessly to an Apple TV.

00:41:00.300 --> 00:41:02.240
We've made it really simple.

00:41:02.350 --> 00:41:05.340
There's two methods and a property.

00:41:05.770 --> 00:41:09.070
To enable AirPlay,
message your AV player instance

00:41:09.480 --> 00:41:12.410
with set allowsAirPlay to yes.

00:41:12.840 --> 00:41:16.230
To observe if AirPlay is
currently active,

00:41:16.230 --> 00:41:19.560
observe the key value
observable property,

00:41:19.560 --> 00:41:21.210
AirPlayVideoActive.

00:41:21.570 --> 00:41:28.300
Now, to enhance the quality of your
transmission to your Apple TV while

00:41:28.300 --> 00:41:32.810
AirPlay Screen is active,
you can tell the AV player

00:41:32.810 --> 00:41:38.890
to set AirPlay Video to,
sorry, set User's AirPlay Video while

00:41:38.890 --> 00:41:41.750
AirPlay Screen is active to Yes.

00:41:42.160 --> 00:41:45.200
This will improve the
quality of the transmission.

00:41:45.290 --> 00:41:49.180
To learn more about AirPlay and
more about the displays

00:41:49.450 --> 00:41:53.140
that iOS devices offer,
stick around.

00:41:53.190 --> 00:41:54.340
Don't go anywhere.

00:41:54.390 --> 00:41:58.610
It's happening right here in
Presidio following this session.

00:42:00.110 --> 00:42:03.880
Next up are media options.

00:42:04.100 --> 00:42:10.750
There exist many ways to represent media
streams within a time media resource.

00:42:11.800 --> 00:42:16.830
You want to be able to localize
media streams for certain users that

00:42:16.830 --> 00:42:19.460
is inside their native language.

00:42:19.600 --> 00:42:24.530
You might also want to
provide alternative encodings,

00:42:24.590 --> 00:42:29.650
alternative representations
of time media for persons of

00:42:29.900 --> 00:42:33.130
hearing or visual disability.

00:42:33.860 --> 00:42:39.750
It's through these API that you can
provide these facilities to your user.

00:42:40.120 --> 00:42:43.820
You might want to provide a
user interface like this one,

00:42:43.820 --> 00:42:48.420
where you provide a set of
localized subtitles as well as a

00:42:48.420 --> 00:42:51.510
set of localized audio streams.

00:42:53.520 --> 00:42:56.700
This functionality is exposed
through the AV Media Selection group

00:42:57.140 --> 00:42:59.790
and the AV Media Selection option.

00:43:00.080 --> 00:43:06.390
These classes provide the
ability to both discover and

00:43:06.390 --> 00:43:06.390
select from these alternatives.

00:43:07.140 --> 00:43:12.440
Alternative audio language options
that are localized for your user.

00:43:12.650 --> 00:43:18.540
Alternative accessibility options
for the sight and hearing impaired.

00:43:18.770 --> 00:43:23.340
And alternative or alternate
visual media options.

00:43:23.480 --> 00:43:26.360
Different camera angles for, say,
a sporting event.

00:43:26.540 --> 00:43:30.810
You could provide a home stream
from a home camera angle and an

00:43:30.810 --> 00:43:33.490
away stream for the away team.

00:43:34.680 --> 00:43:38.250
Let's take a look at a graphical
representation of how you

00:43:38.250 --> 00:43:40.100
work with these objects.

00:43:42.360 --> 00:43:47.800
It starts with the good old AV asset.

00:43:47.830 --> 00:43:51.700
Using the AV asynchronous
key value loading protocol,

00:43:51.790 --> 00:43:54.850
You load the available
media characteristics with

00:43:54.850 --> 00:43:56.740
media selection options.

00:43:56.850 --> 00:44:02.770
To find out what your AV asset,
what alternatives does it provide?

00:44:03.480 --> 00:44:08.040
Once loaded, you have a collection of
AV media characteristics.

00:44:08.090 --> 00:44:11.250
And the values that
this may be are audible,

00:44:11.490 --> 00:44:13.890
legible, or visual.

00:44:14.940 --> 00:44:21.100
You select one of these characteristics
based on your application's logic.

00:44:21.280 --> 00:44:23.500
Say you choose Audible.

00:44:24.020 --> 00:44:30.400
And using the AV asset,
you obtain the AV Media Selection Group.

00:44:30.470 --> 00:44:35.290
In this case, we've chosen a group that
represents the Audible options.

00:44:37.780 --> 00:44:41.250
From the group,
you can ask for the collection

00:44:41.250 --> 00:44:45.960
of AV media selection options,
and you can use the group to help

00:44:46.530 --> 00:44:51.840
filter and hone in to the option
that you need for your user.

00:44:54.110 --> 00:44:58.280
So we saw that an AV Media Selection
Group provides a collection

00:44:58.280 --> 00:45:00.470
of AV Media Selection options.

00:45:00.720 --> 00:45:05.640
We saw that the AV Media Selection
Group provides the ability to filter,

00:45:05.800 --> 00:45:10.140
to hone in on a particular option,
whether the option has a particular

00:45:10.140 --> 00:45:13.320
characteristic or doesn't have
a particular characteristic,

00:45:13.320 --> 00:45:16.140
or whether the option's even playable.

00:45:16.540 --> 00:45:21.900
The option details specifics about,
or properties about,

00:45:21.920 --> 00:45:26.870
the single media stream,
such as its media type, whether it has a

00:45:26.870 --> 00:45:29.690
particular characteristic,
or whether it's even playable.

00:45:29.690 --> 00:45:33.930
It also details its locale.

00:45:34.750 --> 00:45:38.940
Finally, to nominate to select one of
these options at playback,

00:45:39.000 --> 00:45:44.810
message your AV player item with select
media option in media selection group.

00:45:45.300 --> 00:45:48.910
Let's take a look now at a
coding example on how you

00:45:48.910 --> 00:45:55.090
might select an audible stream,
an audible option,

00:45:55.150 --> 00:45:59.020
inside an audiovisual media
resource for playback.

00:46:01.330 --> 00:46:06.200
It starts with learning asynchronously
the available media characteristics

00:46:06.200 --> 00:46:08.810
with media selection options.

00:46:11.200 --> 00:46:14.580
Inside our completion handler,
we obtain the status for

00:46:14.580 --> 00:46:16.660
the loading operation.

00:46:17.600 --> 00:46:22.930
Switch over the possible values
of loading and move execution back

00:46:22.930 --> 00:46:27.480
to the main queue because this
is an asynchronous load occurring

00:46:27.600 --> 00:46:32.310
on some or returning execution
to you on some arbitrary queue.

00:46:33.200 --> 00:46:35.140
We're going to be performing some UI.

00:46:35.190 --> 00:46:38.780
We're going to be messaging the
AV Player item and AV Player.

00:46:38.920 --> 00:46:42.100
So we need to move
back to the main queue.

00:46:42.150 --> 00:46:46.720
We then call a helper method,
mySelectAudioOption.

00:46:46.750 --> 00:46:49.290
mySelectAudioOption

00:46:49.720 --> 00:46:55.590
obtains the collection of available
media characteristics within the asset,

00:46:55.590 --> 00:46:59.690
and we do a quick little check to
see whether the asset even has any

00:46:59.690 --> 00:47:02.200
audio ball options available to us.

00:47:02.400 --> 00:47:08.400
We obtained the group of audible
options if the group is non-zero.

00:47:08.410 --> 00:47:16.090
We then use the group to hone in,
to filter based on the options

00:47:16.190 --> 00:47:18.540
that match the user's locale.

00:47:18.590 --> 00:47:21.930
In your code,
you may not have a matching --

00:47:21.930 --> 00:47:24.550
you may not know the matching
locale and you'll have to get

00:47:24.550 --> 00:47:29.070
your user's preferred languages,
instantiate an NSLocale for each,

00:47:29.070 --> 00:47:32.300
and match what's authored
into the content.

00:47:33.220 --> 00:47:36.340
In my case, I've taken the easy out and
I happen to know what's there,

00:47:36.440 --> 00:47:38.730
so it's my matching locale.

00:47:40.610 --> 00:47:45.880
If the options are non-zero,
I select for playback the first of

00:47:46.640 --> 00:47:49.450
these by messaging the AVPlayer item.

00:47:51.080 --> 00:47:54.010
The next new API,
the next new feature set

00:47:54.010 --> 00:47:56.390
that we provide are chapters.

00:47:56.470 --> 00:47:59.840
Chapters are like bookmarks
in a time media resource.

00:47:59.970 --> 00:48:06.840
They allow your user to jump to a
pre-specified and authored in point

00:48:06.840 --> 00:48:10.770
in time within the media resource.

00:48:11.410 --> 00:48:15.540
You use chapters to implement
a user interface like this one,

00:48:15.540 --> 00:48:20.050
where you have a set of bookmarks,
a set of chapters,

00:48:20.050 --> 00:48:26.560
and allow your user to jump into the
program content at any of the options.

00:48:27.910 --> 00:48:32.000
This is exposed to the
AV Time Metadata Group class,

00:48:32.060 --> 00:48:35.240
which provides the facility to
not only discover these chapters,

00:48:35.360 --> 00:48:41.440
but also select from the chapters
and discover the associated artwork,

00:48:41.520 --> 00:48:46.610
each of which localized for your user.

00:48:48.470 --> 00:48:53.100
To use these classes,
it starts with the AV asset.

00:48:53.120 --> 00:48:58.900
And we load asynchronously the value
for key available chapter locales.

00:48:58.910 --> 00:49:05.020
This loads a collection of NSLocale.

00:49:05.030 --> 00:49:08.360
We select one of these NSLocales.

00:49:09.980 --> 00:49:15.620
and using the AV asset via the method
chapter metadata groups with title

00:49:15.750 --> 00:49:20.460
locale containing items with common keys,
we obtain a collection of

00:49:20.620 --> 00:49:22.950
AV time metadata groups.

00:49:24.000 --> 00:49:35.400
[Transcript missing]

00:49:38.100 --> 00:49:41.680
You can ask it for its items.

00:49:41.800 --> 00:49:45.290
This is a collection of AV metadata item.

00:49:46.340 --> 00:49:49.500
These are all static model objects.

00:49:49.580 --> 00:49:51.690
We know how to work with
static model objects.

00:49:51.830 --> 00:49:55.240
We use the AV asynchronous
key value loading protocol.

00:49:55.420 --> 00:50:01.120
And we use this protocol to load the
value or to load the property value.

00:50:01.160 --> 00:50:06.870
AV Foundation does just the work
necessary to provide you the value.

00:50:09.400 --> 00:50:14.560
Value may be a localized chapter string
in the case that the common key is

00:50:14.560 --> 00:50:20.420
equal to AV metadata common key title.

00:50:20.430 --> 00:50:23.180
We have very descriptive names,
as you can see.

00:50:23.200 --> 00:50:27.600
Or it may be the image data
itself for the chapter.

00:50:30.130 --> 00:50:35.980
AV Foundation provides on either
platform the ability to obtain

00:50:35.980 --> 00:50:41.440
resources from the network,
be they progressive download,

00:50:41.670 --> 00:50:48.620
like trailers, or HTTP live streams,
like the keynote address.

00:50:49.670 --> 00:50:53.780
AV Foundation also, on the desktop,
obviously allows you full

00:50:53.780 --> 00:50:55.940
access to the file system.

00:50:55.940 --> 00:51:00.730
And on iOS, you have access within
your application bundle.

00:51:00.950 --> 00:51:05.500
On iOS,
there's additional sources of content.

00:51:05.540 --> 00:51:12.190
You can access the camera roll of your
user to obtain videos that they may have

00:51:12.190 --> 00:51:19.070
captured using the iOS device camera,
as well as their iPod library.

00:51:19.320 --> 00:51:23.660
These are provided through the
Asset Library Framework and

00:51:23.660 --> 00:51:25.720
the Media Player Framework.

00:51:27.350 --> 00:51:31.590
To obtain references,
to obtain URLs from the

00:51:31.590 --> 00:51:36.570
user's iPod library,
it starts off with an MP Media query.

00:51:37.640 --> 00:51:40.820
Conveniently,
there's a convenience constructor for all

00:51:40.820 --> 00:51:44.770
the songs within the user's iPod library.

00:51:48.140 --> 00:51:53.470
We obtain the first item
within their library.

00:51:53.470 --> 00:51:59.520
And then we ask the item,
the MPMedia item, to provide to us the

00:51:59.740 --> 00:52:04.540
value for a property,
MPMedia item, property asset URL.

00:52:05.880 --> 00:52:09.020
Once we have the URL,
we follow the four-part

00:52:09.020 --> 00:52:11.680
recipe that we saw earlier.

00:52:14.210 --> 00:52:20.560
To obtain videos from the camera roll,
you use the asset library framework.

00:52:21.900 --> 00:52:27.490
It starts off with an instance
of the AL asset library object.

00:52:28.150 --> 00:52:33.560
We enumerate through the types
of assets that it provides.

00:52:33.610 --> 00:52:36.190
In this case,
we're interested in all the saved photos

00:52:36.300 --> 00:52:38.540
that they have in their camera roll.

00:52:38.600 --> 00:52:42.840
And we provide two blocks,
a block that performs the enumeration

00:52:43.440 --> 00:52:50.560
and a block in case the user denies
access to their personal camera roll.

00:52:51.630 --> 00:52:55.100
Looking at the first
block in more detail,

00:52:55.220 --> 00:52:58.820
for each group that is returned,
we apply a filter.

00:52:59.090 --> 00:53:03.890
We're not interested in all the saved
photos within our user's camera roll,

00:53:04.050 --> 00:53:06.350
but rather we're interested
in just the videos.

00:53:06.530 --> 00:53:10.970
So we apply an AL asset
filter for all the videos.

00:53:11.080 --> 00:53:15.170
We enumerate the remaining
items within the group.

00:53:16.300 --> 00:53:23.020
And for each AL asset that we traverse,
we ask for the default

00:53:23.020 --> 00:53:25.620
representation and its URL.

00:53:25.620 --> 00:53:28.460
Then it's as simple as
following the four-part recipe

00:53:28.460 --> 00:53:30.570
that we know from earlier.

00:53:34.500 --> 00:53:37.810
That's all the time that
I have with you today,

00:53:37.810 --> 00:53:43.140
but there are so many more sessions
available to you this week.

00:53:43.220 --> 00:53:47.740
It starts off right here in the
Presidio following this session

00:53:47.740 --> 00:53:51.940
with AirPlay and external devices,
external displays, I'm sorry.

00:53:52.020 --> 00:53:55.460
And later today with an
HTTP live streaming update.

00:53:55.610 --> 00:54:00.070
Tomorrow, you can learn about composition
and editing with Working with

00:54:00.070 --> 00:54:01.960
Media in AV Foundation.

00:54:02.030 --> 00:54:04.320
That's happening downstairs.

00:54:04.580 --> 00:54:11.030
There's two sessions on dealing with the
capture classes within AV Foundation.

00:54:11.110 --> 00:54:14.670
One for the desktop and one for iOS.

00:54:16.460 --> 00:54:20.540
For more information,
check out the documentation online.

00:54:20.610 --> 00:54:24.500
There's a developer forum where you can
share ideas with your fellow developers,

00:54:24.550 --> 00:54:28.040
as well as speak to a
few engineers from Apple.

00:54:28.080 --> 00:54:31.960
And if you have further
information that you want to glean,

00:54:32.070 --> 00:54:36.340
please email Eric Verschen,
our technology evangelist.

00:54:36.410 --> 00:54:39.630
Thank you very much for coming,
and I hope you're all able to

00:54:39.630 --> 00:54:45.610
develop really efficient and robust
applications using AV Foundation.