WEBVTT

00:00:09.190 --> 00:00:10.600
Good morning.

00:00:10.600 --> 00:00:15.040
My name is Kapil Krishnamurthy,
and I work in Core Audio Engineering.

00:00:15.170 --> 00:00:18.440
Today we're going to be talking
about audio development for games.

00:00:18.540 --> 00:00:20.550
So let's get started.

00:00:22.110 --> 00:00:26.960
Now the first thing on the agenda for
today is this notion of simple game.

00:00:27.040 --> 00:00:31.400
Under that, we're going to be taking
a look at AV Audio Player.

00:00:31.550 --> 00:00:35.810
After that, we're going to move and take
a look at how you can create

00:00:36.010 --> 00:00:38.200
and manage your audio assets.

00:00:38.380 --> 00:00:41.510
We're going to talk about a few
things that you can do here to

00:00:41.570 --> 00:00:44.490
prevent computational overhead.

00:00:44.830 --> 00:00:48.540
We'll then move on to
a more complex game.

00:00:48.670 --> 00:00:55.320
We'll take a look at spatial
or 3D audio and the OpenAL API.

00:00:55.820 --> 00:00:58.750
Finally,
we're going to take a look at audio

00:00:58.750 --> 00:01:02.460
session and how that ties in with games.

00:01:02.460 --> 00:01:04.450
So let's get started.

00:01:05.050 --> 00:01:08.940
All right, so what is a simple game?

00:01:09.020 --> 00:01:13.170
If I were to think of a simple game,
I would think of one with maybe

00:01:13.170 --> 00:01:17.520
a background score and some sound
effects triggered by objects in

00:01:17.520 --> 00:01:20.720
the game or characters in the game.

00:01:20.920 --> 00:01:25.330
Thinking of examples, maybe a board game,
like Scrabble, Monopoly,

00:01:25.330 --> 00:01:28.670
or maybe a classic game, like Tetris.

00:01:28.860 --> 00:01:32.940
So the control that you want here
is control over all of these sounds.

00:01:33.160 --> 00:01:35.720
You'd want to be able
to change the volume,

00:01:35.800 --> 00:01:39.640
pan the sounds left or right,
maybe loop some sounds.

00:01:39.690 --> 00:01:44.610
The API that we recommend for
all of this is AVAudioPlayer.

00:01:45.810 --> 00:01:49.710
So AV Audio Player is an audio
API that can play both compressed

00:01:49.900 --> 00:01:52.320
and uncompressed formats.

00:01:52.520 --> 00:01:59.430
It has four basic playback options: play,
pause, seek, and stop.

00:01:59.760 --> 00:02:04.190
These are quite similar to what you
would find on a traditional tape deck.

00:02:04.340 --> 00:02:06.810
If you want to play multiple
sounds in your game,

00:02:06.810 --> 00:02:10.040
you can use multiple
AV Audio Player objects.

00:02:10.090 --> 00:02:12.600
You also have the control
that I just talked about,

00:02:12.640 --> 00:02:17.480
that is volume, panning the sounds,
and looping the sounds.

00:02:18.950 --> 00:02:22.040
Let's take a look at how
you would create a player.

00:02:22.040 --> 00:02:26.300
So the first thing you do here
is you create a URL pointing

00:02:26.300 --> 00:02:28.740
to the file in your app bundle.

00:02:28.900 --> 00:02:32.030
What's convenient here is that you
don't need to worry about whether the

00:02:32.030 --> 00:02:34.800
file is compressed or uncompressed.

00:02:34.930 --> 00:02:37.560
AV Audio Player will handle this for you.

00:02:37.710 --> 00:02:41.150
So once you create your URL,
you use that to create an

00:02:41.150 --> 00:02:43.630
instance of AV Audio Player.

00:02:45.020 --> 00:02:47.520
Let's take a look at some
of the properties that

00:02:47.520 --> 00:02:49.550
AV Audio Player has to offer.

00:02:49.700 --> 00:02:53.160
You can set the volume
on a scale of 0 to 1,

00:02:53.310 --> 00:02:56.410
you can pan the sound left or right,
in this example,

00:02:56.510 --> 00:02:58.930
the sound is panned entirely to the left.

00:02:59.040 --> 00:03:02.490
You can set the number of loops,
or as I like to think of it,

00:03:02.720 --> 00:03:04.220
the number of repeats.

00:03:04.340 --> 00:03:07.320
So, if it's set to 3,
the sound plays through once

00:03:07.480 --> 00:03:09.800
and then loops three times.

00:03:09.910 --> 00:03:12.970
You can set the current time,
which is the offset from

00:03:12.970 --> 00:03:17.500
the beginning of the file,
and you can also set the delegate.

00:03:17.550 --> 00:03:21.200
AV Audio Player has a number of
read-only properties as well,

00:03:21.260 --> 00:03:25.410
such as the duration, number of channels,
and the play state.

00:03:26.830 --> 00:03:29.830
Now let's look at the playback controls.

00:03:29.960 --> 00:03:33.960
Prepare to Play basically allocates
the resources that the player

00:03:33.980 --> 00:03:37.200
needs and also performs priming.

00:03:37.320 --> 00:03:41.470
This improves the responsiveness of play,
and you would generally call

00:03:41.580 --> 00:03:45.830
Prepare to Play when you're
during the initialization phase.

00:03:46.520 --> 00:03:50.760
Play plays the sound and
it resumes playing if the

00:03:50.760 --> 00:03:53.790
sound is paused or stopped.

00:03:54.030 --> 00:03:57.830
What's important here is that
if your sound has been stopped,

00:03:58.010 --> 00:04:01.600
play will resume playback
exactly from where you left off.

00:04:01.760 --> 00:04:04.920
And if you wanted to start
playback from the beginning,

00:04:05.070 --> 00:04:07.530
you need to set the current time to zero.

00:04:08.390 --> 00:04:11.340
Pause will pause playback.

00:04:11.460 --> 00:04:15.860
What's important with respect
to pause is that the player's

00:04:15.880 --> 00:04:19.180
resources are still allocated.

00:04:19.180 --> 00:04:24.180
And this is the basic difference
between pause and stop.

00:04:24.300 --> 00:04:29.090
When you stop the player,
the resources are deallocated.

00:04:31.010 --> 00:04:34.080
Now I once again want
to go over current time.

00:04:34.180 --> 00:04:38.100
Current time is the property
that sets the time in seconds.

00:04:38.240 --> 00:04:43.870
If you pause or stop a player while
it is playing and you want to reset

00:04:44.000 --> 00:04:47.390
the playback from the beginning,
you need to explicitly

00:04:47.390 --> 00:04:49.580
set current time to zero.

00:04:51.620 --> 00:04:54.860
AV Audio Player also
has delegate methods.

00:04:54.990 --> 00:04:56.360
What are delegate methods?

00:04:56.650 --> 00:05:01.500
Delegate methods are methods that get
called when a certain event happens.

00:05:01.610 --> 00:05:04.430
For instance,
if your audio player finishes playing,

00:05:04.540 --> 00:05:09.480
if an interruption begins,
an interruption ends,

00:05:09.480 --> 00:05:09.480
or if there's a decode error.

00:05:11.230 --> 00:05:14.830
Now let's take a look at some
code as to what you need to

00:05:14.880 --> 00:05:17.100
do to prepare your player.

00:05:17.230 --> 00:05:20.900
The first thing I do here is
create an instance of the player.

00:05:21.040 --> 00:05:24.340
Once I do that, I set the delegate.

00:05:24.750 --> 00:05:28.180
And then just prepare the
player to play the sound.

00:05:28.180 --> 00:05:31.590
Then during game play time,
I go ahead and I call play

00:05:31.590 --> 00:05:33.940
and the sound plays instantly.

00:05:35.280 --> 00:05:39.000
All right, so that was an overview
of AV Audio Player.

00:05:39.050 --> 00:05:41.160
Let's move on to the next section.

00:05:41.210 --> 00:05:45.160
That's tuning your assets,
your audio assets for your game.

00:05:45.230 --> 00:05:48.900
We're going to look at a few things
here that you can do to prevent

00:05:49.230 --> 00:05:52.590
additional computational overhead.

00:05:53.190 --> 00:05:56.990
The first point here that I'd like to
make is that it is important to create

00:05:57.340 --> 00:06:01.090
game assets at the same sampling rate.

00:06:01.400 --> 00:06:05.330
Now,
sample rate conversions can be expensive,

00:06:05.330 --> 00:06:07.760
and you'd like to avoid
this as much as possible.

00:06:07.900 --> 00:07:25.900
[Transcript missing]

00:07:27.520 --> 00:07:30.500
Now let's talk about
sample rate conversions.

00:07:30.510 --> 00:07:34.870
I mentioned in my previous slide
that it's preferable-- or what we

00:07:34.980 --> 00:07:38.840
recommend is to have all of your
assets at the same sampling rate.

00:07:38.870 --> 00:07:44.210
Now consider an example here where
I have a number of several AV audio

00:07:44.340 --> 00:07:49.250
players and each of them playing a
source file at a different sampling rate.

00:07:49.650 --> 00:07:54.040
I have my output hardware rendering
at a particular sampling rate.

00:07:54.200 --> 00:07:57.020
In this example, it's 44K.

00:07:57.440 --> 00:08:01.790
Now, what needs to happen here is that
all of this input material needs

00:08:01.830 --> 00:08:06.380
to get rate converted and then
mixed to get to the output rate.

00:08:06.840 --> 00:08:11.040
But I need to use four
sample rate converters here.

00:08:11.040 --> 00:08:17.220
And how I could avoid this is to have all
of my assets at the same sampling rate.

00:08:17.260 --> 00:08:20.370
When I do that,
all of the source material can

00:08:20.380 --> 00:08:24.040
be mixed and just has to go
through one sample rate converter.

00:08:24.060 --> 00:08:30.090
And so by doing this one simple step,
you eliminate a lot of

00:08:30.090 --> 00:08:30.090
overhead computation.

00:08:31.870 --> 00:08:34.660
Now, how do you pick a sampling rate?

00:08:34.720 --> 00:08:36.800
Well,
this is a question that you can answer,

00:08:36.860 --> 00:08:41.100
because it really depends on the types of
sounds that you're playing in your game.

00:08:41.140 --> 00:08:43.790
Are you playing sounds with a
lot of low-frequency content,

00:08:44.020 --> 00:08:47.450
like maybe explosions,
or sounds with a lot of

00:08:47.580 --> 00:08:51.460
high-frequency content,
maybe glass shattering?

00:08:51.510 --> 00:08:55.280
Well, what you should do here
is you pick a sample rate,

00:08:55.400 --> 00:08:58.660
something that captures the
fidelity of all of these sounds,

00:08:58.740 --> 00:09:03.620
and you stick with that sampling
rate for all of your assets.

00:09:03.680 --> 00:09:09.660
Now, if you're using uncompressed files,
and you pick a sampling rate of 44K,

00:09:09.740 --> 00:09:14.290
then what could happen is your overall
asset size could get really large.

00:09:14.540 --> 00:09:19.840
And this brings me to my next point,
which is AAC decoding is inexpensive.

00:09:19.840 --> 00:09:24.860
So what we recommend doing in
such a case is encode all of

00:09:24.860 --> 00:09:29.210
your source material to AAC,
keep the quality high,

00:09:29.210 --> 00:09:31.610
and the asset size small.

00:09:33.650 --> 00:09:37.680
Now, to help you create,
manage your assets,

00:09:37.740 --> 00:09:41.040
we have some tools on Mac OS X.

00:09:41.070 --> 00:09:43.720
And one of these tools
is called AFConvert.

00:09:43.750 --> 00:09:46.540
It's a command line tool,
and you can use it to

00:09:46.540 --> 00:09:51.040
convert between data formats,
file formats, and sampling rates.

00:09:51.110 --> 00:09:56.130
Here's an example of me using AFConvert,
where I have a source

00:09:56.210 --> 00:09:57.940
file that has PCM data.

00:09:57.970 --> 00:10:06.300
I convert it to the MPEG-4
audio file format with AAC data.

00:10:07.010 --> 00:10:10.800
Accompanying AF Convert,
we have another tool called AF Info

00:10:10.820 --> 00:10:12.840
that displays file metadata.

00:10:12.970 --> 00:10:15.830
Running AF Info on this
file that I just created,

00:10:16.190 --> 00:10:19.110
I can see a whole lot of information.

00:10:19.300 --> 00:10:21.520
I have information like the file format.

00:10:21.680 --> 00:10:24.380
I can look at the data format,
which tells me that I have

00:10:24.380 --> 00:10:25.600
one channel of audio.

00:10:25.600 --> 00:10:30.170
It's at 44K sampling rate,
and the data is AAC.

00:10:30.320 --> 00:10:36.900
So we recommend that you use these tools
and create and manage your audio assets.

00:10:38.170 --> 00:10:41.070
Now to talk about the next section,
I'd like to invite

00:10:41.070 --> 00:10:43.410
James McCartney from Core Audio.

00:10:47.360 --> 00:10:48.300
Hello.

00:10:48.300 --> 00:10:53.240
I'm going to talk about working
with compressed audio in your game.

00:10:53.240 --> 00:10:56.770
So first I'm going to define a few
terms that we use in Core Audio,

00:10:56.770 --> 00:10:59.770
samples, frames, and packets,
so you'll know what we mean

00:10:59.770 --> 00:11:01.280
when we say these things.

00:11:01.480 --> 00:11:09.180
So a sample is the value of
the amplitude of a waveform at

00:11:09.180 --> 00:11:09.180
a particular moment in time.

00:11:09.180 --> 00:11:09.180
And the

00:11:09.570 --> 00:11:14.050
The samples that you get when you
sample a waveform is called linear

00:11:14.050 --> 00:11:18.450
pulse code modulation or linear PCM.

00:11:18.580 --> 00:11:22.240
So linear PCM means uncompressed audio.

00:11:22.570 --> 00:11:28.500
A frame is a sample per
channel at a particular time.

00:11:28.500 --> 00:11:33.130
And so when you have one frame of audio,
that's all the channels

00:11:33.130 --> 00:11:34.500
at a particular moment.

00:11:34.830 --> 00:11:40.210
Here you can see a left and right sample
from a stream of interleaved stereo.

00:11:40.500 --> 00:11:44.280
Then a packet is the smallest
cohesive unit of data for a format.

00:11:44.740 --> 00:11:47.500
For linear PCM,
one packet equals one frame.

00:11:47.500 --> 00:11:50.560
And for compressed formats,
a packet is some number of

00:11:50.560 --> 00:11:56.500
bytes that when you decode them,
you get a bunch of frames of linear PCM.

00:11:56.650 --> 00:12:00.560
So this graphic shows the
relationships between a packet of,

00:12:00.560 --> 00:12:03.500
in this case,
AAC or any compressed format,

00:12:03.500 --> 00:12:08.500
and a bunch of frames of linear PCM.

00:12:08.500 --> 00:12:12.570
When you decode the packet of AAC,
you get a bunch of frames of PCM,

00:12:12.570 --> 00:12:16.500
and then you can reverse
that and encode back to AAC.

00:12:17.510 --> 00:12:19.560
Now, when you're working
with compressed audio,

00:12:19.560 --> 00:12:22.750
there's one aspect you
need to be aware of,

00:12:22.870 --> 00:12:26.150
and that's leading and trailing frames,
which are also known as

00:12:26.150 --> 00:12:27.260
priming and remainder.

00:12:27.260 --> 00:12:31.760
Leading frames express the
processing latency of the codec.

00:12:31.830 --> 00:12:37.700
It's the amount of time that the codec
needs to build up a context of the audio.

00:12:37.700 --> 00:12:43.230
And then trailing frames are the excess
frames within the last packet that are

00:12:43.230 --> 00:12:45.780
not part of the audio you are encoding.

00:12:46.000 --> 00:12:49.390
They're just extra space
in the last packet.

00:12:49.910 --> 00:12:53.400
So here's an example of
what that looks like.

00:12:53.400 --> 00:12:57.480
In this example,
I'm compressing 2205 frames of audio,

00:12:57.480 --> 00:12:59.990
which is 50 milliseconds of audio.

00:13:00.000 --> 00:13:04.240
Now that extensively takes up
a little more than two packets,

00:13:04.350 --> 00:13:08.470
but we get five packets of audio
out due to the leading frames,

00:13:08.480 --> 00:13:11.040
and then there's extra
space in the last packet,

00:13:11.190 --> 00:13:13.100
and that becomes trailing frames.

00:13:13.100 --> 00:13:16.970
So AAC has 2,112 leading frames.

00:13:16.970 --> 00:13:22.500
Then you have your 2205 frames
of the audio data you encoded,

00:13:22.780 --> 00:13:26.740
and then you have 803 frames left over,
and that total is five times

00:13:26.780 --> 00:13:32.360
1,024 frames per packet,
or 5,120 frames.

00:13:32.360 --> 00:13:37.970
So now when you're decoding this,
this is what the process looks like.

00:13:38.070 --> 00:13:41.230
You put in your first packet,
you get 1,024 leading frames out.

00:13:42.150 --> 00:13:45.640
You put in your second packet,
you get more leading frames out.

00:13:45.650 --> 00:13:47.940
And then you put in your third packet,
and you get the last of

00:13:47.940 --> 00:13:50.680
the leading frames out,
and now you're starting

00:13:50.680 --> 00:13:52.070
to get your audio out.

00:13:52.310 --> 00:13:55.240
and to put in the fourth packet,
you get more of your audio.

00:13:55.310 --> 00:13:58.570
Then when you put the last packet in,
you get the rest of your audio

00:13:58.660 --> 00:14:01.800
plus whatever extra space
there was in the last packet.

00:14:01.850 --> 00:14:06.800
Now all this leading and trailing
frames are stuff to be thrown away.

00:14:06.850 --> 00:14:10.850
And then you're left with your
audio that you're encoding

00:14:10.850 --> 00:14:12.700
that you're interested in.

00:14:12.730 --> 00:14:18.050
And this also illustrates why
you can't butt splice together

00:14:18.170 --> 00:14:21.300
packets of compressed data
and expect it to sound okay.

00:14:21.310 --> 00:14:25.490
Because those two packets at the
beginning are required to build up

00:14:25.580 --> 00:14:31.300
the context for the decode process.

00:14:31.370 --> 00:14:34.270
And if you don't have them or if
you've chopped them off and just

00:14:34.540 --> 00:14:37.870
stuck some other audio there,
you're going to get like a little bleep

00:14:38.000 --> 00:14:40.090
or something when you play it back.

00:14:40.240 --> 00:14:43.950
So don't butt splice compressed audio.

00:14:44.080 --> 00:14:48.650
Now this is kind of a lot of bother and
you can get rid of having to deal with

00:14:48.650 --> 00:14:50.400
it at all by using AV Audio Player.

00:14:50.400 --> 00:14:55.520
It handles all the decoding
and getting rid of the leading

00:14:55.520 --> 00:14:58.050
and trailing frames for you.

00:14:58.280 --> 00:15:01.830
Another API you can use
is Extended Audio File,

00:15:01.840 --> 00:15:06.540
which allows you to ignore the
fact or ignore whatever format

00:15:06.540 --> 00:15:10.990
the file is in and just deal with
it like it's uncompressed data.

00:15:11.540 --> 00:15:16.710
If you were to, on that previous example,
if you were to run AF info on that file,

00:15:16.800 --> 00:15:19.200
you can see that there's
five packets in the file.

00:15:19.210 --> 00:15:22.300
And AF info will tell you
the number of valid frames,

00:15:22.300 --> 00:15:24.570
the number of priming frames,
and the number of remainder

00:15:24.680 --> 00:15:27.420
frames in the file,
and then the total number

00:15:27.420 --> 00:15:28.970
of frames in the file.

00:15:29.780 --> 00:15:35.360
So extended audio file combines an
audio file and an audio converter

00:15:35.360 --> 00:15:39.950
within a single object and allows
you to just deal with the file as if

00:15:40.000 --> 00:15:45.140
it were uncompressed even though it
might be in some compressed format.

00:15:45.140 --> 00:15:49.510
So you can just deal with it as
if it were uncompressed data and

00:15:49.510 --> 00:15:55.710
specify your reading and writing
file positions in sample frames.

00:15:56.370 --> 00:16:01.560
Okay, now I'm going to talk
about spatial audio.

00:16:01.730 --> 00:16:05.990
Kapil went over what a simple game might
be like where you're playing incidental

00:16:05.990 --> 00:16:10.970
sounds and a background soundtrack,
and that might have some spatial ambience

00:16:10.970 --> 00:16:13.860
baked into the sounds you are playing.

00:16:13.860 --> 00:16:17.020
But if you wanted a more
dynamic environment,

00:16:17.020 --> 00:16:19.380
spatial environment,
you might want to have a

00:16:19.380 --> 00:16:23.620
listener and multiple sources,
and you might want to have panning,

00:16:23.620 --> 00:16:26.280
directional cues, reverberation.

00:16:26.420 --> 00:16:30.160
And obstruction and occlusion filtering,
which simulates objects

00:16:30.160 --> 00:16:31.480
in the environment.

00:16:31.580 --> 00:16:33.640
And you'd like it to be low latency.

00:16:33.820 --> 00:16:37.900
So what are some spatial cues?

00:16:38.440 --> 00:16:43.050
When you hear a sound in an environment,
there are several things that

00:16:43.050 --> 00:16:47.460
your cognitive faculties -- you
have some built-in hardwired

00:16:47.470 --> 00:16:51.920
signal processing that allows you
to figure out where things are.

00:16:52.010 --> 00:16:56.280
And one of them is when you hear
something from one of the speakers,

00:16:56.280 --> 00:16:56.280
you can hear the sound of the speaker.

00:16:56.280 --> 00:16:57.460
And when you hear
something from one side,

00:16:57.460 --> 00:16:58.900
you hear an interaural
intensity difference.

00:16:58.900 --> 00:17:02.990
That just means that a sound is
louder in one ear than the other,

00:17:03.110 --> 00:17:06.500
and that your brain will
tell you it's over there.

00:17:06.550 --> 00:17:09.590
And there's an interaural time delay,
so you'll hear it first in

00:17:09.640 --> 00:17:11.300
this ear and then in this ear.

00:17:11.300 --> 00:17:16.430
And you can also use that cue
to determine where something is.

00:17:16.680 --> 00:17:21.870
Then there's filtering due to the head,
which your brain kind of knows when it

00:17:22.040 --> 00:17:26.260
hears certain spectral relationships
between your ears that something

00:17:26.260 --> 00:17:26.260
may be in a certain direction.

00:17:26.260 --> 00:17:29.790
Then there's also
filtering due to distance,

00:17:29.860 --> 00:17:36.980
which is as things get farther away,
they get -- there's some

00:17:36.980 --> 00:17:39.780
high frequency attenuation.

00:17:40.630 --> 00:17:43.270
There's also reverberation,
which simulates sound

00:17:43.270 --> 00:17:45.340
reflections in the environment.

00:17:45.380 --> 00:17:49.600
These will depend on the size of the
room and what the walls are made out of,

00:17:49.700 --> 00:17:56.110
which affects the decay time
and the high-frequency damping.

00:17:56.710 --> 00:18:00.260
Then there's obstruction and occlusion,
which simulate filtering of sound due

00:18:00.260 --> 00:18:04.780
to objects in the environment that
block the propagation of the sound.

00:18:04.780 --> 00:18:08.650
Obstruction is when the direct path of
the sound is blocked by a column like

00:18:08.650 --> 00:18:10.680
this one in the middle of the room.

00:18:10.680 --> 00:18:15.720
If the monster is behind the
column and he's screaming at you,

00:18:15.720 --> 00:18:19.540
then you're not going to hear his
direct scream perfectly clearly,

00:18:19.540 --> 00:18:22.680
but you'll hear the
reverberation unfiltered.

00:18:24.010 --> 00:18:28.300
Now in occlusion,
the sound source is in an adjacent space

00:18:28.300 --> 00:18:33.090
and you're hearing the reverberation
and the direct sound both being

00:18:33.230 --> 00:18:35.760
filtered by the occluding wall.

00:18:36.000 --> 00:18:42.400
So in Core Audio,
we implement all these spatial cues

00:18:42.400 --> 00:18:45.900
and effects by using a 3D mixer.

00:18:45.900 --> 00:18:51.400
And the 3D mixer supports several
spatialization modes and it

00:18:51.400 --> 00:18:51.400
supports reverb and filters
for occlusion and occlusion.

00:18:51.430 --> 00:18:55.790
It supports reverb and filters
for occlusion and obstruction.

00:18:56.490 --> 00:18:59.850
So on iOS, the 3D mixer supports
two specialization modes.

00:19:00.030 --> 00:19:03.070
One is equal power panning,
which is just intensity

00:19:03.090 --> 00:19:05.240
panning between speakers.

00:19:05.320 --> 00:19:08.240
And then there's also a spherical
head specialization mode,

00:19:08.240 --> 00:19:11.000
which simulates the interaural
intensity difference,

00:19:11.100 --> 00:19:15.450
the interaural time delay cues,
filtering due to the head,

00:19:15.450 --> 00:19:17.070
and distance filtering.

00:19:17.260 --> 00:19:21.080
Now on the Mac OS X 3D Mixer,
there's a few more spatialization modes.

00:19:21.160 --> 00:19:26.370
There's head-related transfer function,
which does spectral filtering of

00:19:26.460 --> 00:19:30.000
the sound based on a measured head.

00:19:30.050 --> 00:19:33.900
And then there's also for
multi-channel output hardware,

00:19:33.900 --> 00:19:35.900
you have sound field and
vector-based panning,

00:19:35.900 --> 00:19:42.990
which can give you spatialization
over multiple speakers.

00:19:43.940 --> 00:19:49.000
Now, new for iOS 5,
the 3D mixer has reverb,

00:19:49.000 --> 00:19:53.200
occlusion and obstruction support.

00:19:53.380 --> 00:19:57.590
And so this is the signal
path of the 3D mixer.

00:19:57.870 --> 00:20:01.060
There's the input signal,
goes through the occlusion filter,

00:20:01.060 --> 00:20:06.460
which is going to filter both
reverb and the direct path.

00:20:06.740 --> 00:20:09.160
Then there's a reverb send,
which has a blend control,

00:20:09.160 --> 00:20:13.590
which allows you to give a
wet-dry mix to every input source.

00:20:13.680 --> 00:20:17.400
Then there's an obstruction filter,
which is just operating

00:20:17.480 --> 00:20:18.900
on the direct sound.

00:20:18.900 --> 00:20:20.420
The reverb is on its own path now.

00:20:21.010 --> 00:20:24.080
Then there's the panner, which, um...

00:20:24.330 --> 00:20:25.320
and I are going to talk
about the 3D mixer.

00:20:25.320 --> 00:20:29.250
It implements the spatialization mode
for the input source and then there's a

00:20:29.320 --> 00:20:35.190
gain on the input source and then all the
inputs and the reverb are mixed together.

00:20:35.300 --> 00:20:40.180
So the 3D mixer is a
listener-centered coordinate system.

00:20:40.290 --> 00:20:45.350
You specify the location of
sound sources with azimuth,

00:20:45.350 --> 00:20:47.300
elevation and distance.

00:20:47.360 --> 00:20:51.300
Azimuth is an angle where zero is
directly in front of the listener.

00:20:51.310 --> 00:20:54.290
Positive angles are to the right
and negative angles are to the left.

00:20:54.300 --> 00:20:58.300
180 degrees is directly
behind the listener.

00:20:58.510 --> 00:21:03.780
And then distance is in
meters from the listener.

00:21:05.960 --> 00:21:12.180
Then you have elevation,
which is an angle above for

00:21:12.180 --> 00:21:16.300
positive numbers or below the
horizon for negative numbers.

00:21:16.300 --> 00:21:21.160
And you also have a distance attenuation
curve you can set on the mixer,

00:21:21.160 --> 00:21:25.060
which specifies how sound
attenuates over distance.

00:21:25.060 --> 00:21:29.760
There's a reference distance below
which the audio is unattenuated,

00:21:29.760 --> 00:21:33.400
and then it gets attenuated out to
the maximum distance above which

00:21:33.740 --> 00:21:35.540
there's no further attenuation.

00:21:35.900 --> 00:21:36.920
Thank you.

00:21:38.390 --> 00:21:41.760
So we hope that you use this stuff.

00:21:41.900 --> 00:21:47.260
It will give depth to your
game and make it more engaging.

00:21:47.260 --> 00:21:49.580
And the more you use it and
the more feedback we get,

00:21:49.580 --> 00:21:50.940
the better we can make it.

00:21:50.940 --> 00:21:52.310
So please use it.

00:21:52.400 --> 00:21:57.430
And now I'm going to bring Kapil
back up to talk about OpenAL.

00:22:02.500 --> 00:22:04.040
All right.

00:22:04.150 --> 00:22:06.700
So how do you get access
to all of this stuff?

00:22:06.850 --> 00:22:09.370
Well, the answer is OpenAL.

00:22:10.050 --> 00:22:11.740
What is OpenAL?

00:22:11.840 --> 00:22:17.900
OpenAL is an open standard audio
API for 3D or spatial audio.

00:22:17.970 --> 00:22:22.450
OpenAL was written,
designed to complement OpenGL,

00:22:22.450 --> 00:22:25.340
and they share the
same coordinate system.

00:22:25.520 --> 00:22:31.590
We have implementations of
OpenAL on both Mac OS X and on iOS.

00:22:32.320 --> 00:22:35.680
So let me run you through
the OpenAL coordinate system.

00:22:35.720 --> 00:22:39.040
OpenAL has a right-handed
Cartesian coordinate system.

00:22:39.110 --> 00:22:42.980
So if I hold my right hand up with
my thumb pointing to the right,

00:22:43.020 --> 00:22:45.300
that's the positive x-axis.

00:22:45.350 --> 00:22:49.660
My index finger pointing upwards,
that's the positive y-axis.

00:22:49.710 --> 00:22:54.080
And my middle finger pointing towards me,
that's the positive z-axis.

00:22:54.140 --> 00:22:58.180
The intersection of all
three of them is the origin.

00:22:58.830 --> 00:23:01.650
Now, in OpenAL,
you can not only set source

00:23:01.690 --> 00:23:05.830
coordinates and listener coordinates
as this three-dimensional coordinate,

00:23:05.990 --> 00:23:10.060
but you can also orient the listener,
which is like the direction and

00:23:10.070 --> 00:23:11.320
the rotation of the listener.

00:23:11.320 --> 00:23:16.390
What OpenAL does is that it
handles the panning of the sources

00:23:16.490 --> 00:23:19.360
when you reorient the listener.

00:23:19.360 --> 00:23:22.930
Now, take a look at this example here,
where the listener is

00:23:23.070 --> 00:23:27.020
looking straight ahead,
and there are two sources to the right.

00:23:27.660 --> 00:23:31.040
So if you were to listen to that audio,
it would sound like there

00:23:31.040 --> 00:23:32.870
are two sources to the right.

00:23:33.060 --> 00:23:38.880
Now if you reorient the listener like so,
one of the objects is straight on

00:23:38.930 --> 00:23:42.690
and the other object is to the left.

00:23:42.790 --> 00:23:44.640
So again,
if you were to listen to the audio,

00:23:44.640 --> 00:23:47.630
it should sound like one of the
objects is straight ahead of you

00:23:47.630 --> 00:23:49.350
and the other one is to the left.

00:23:49.480 --> 00:23:56.550
OpenAL handles the translation of
the source coordinates under the hood

00:23:56.550 --> 00:23:56.550
and pans these objects correctly.

00:23:57.260 --> 00:24:01.540
Now let's take a look
at OpenAL's API objects.

00:24:01.620 --> 00:24:06.660
There are four basic API objects,
and it starts off with the context.

00:24:06.740 --> 00:24:12.300
The context is basically the
environment that has the listener.

00:24:12.400 --> 00:24:17.300
The listener is implicit to the context,
and it also has sources.

00:24:17.520 --> 00:24:19.860
Now,
the OpenAL context is built on top of

00:24:19.860 --> 00:24:22.590
the 3D mixer that James had talked about.

00:24:22.750 --> 00:24:26.800
The 3D mixer has all of these
spatial audio capabilities.

00:24:26.970 --> 00:24:31.800
So the next API object are OpenAL sources
that are tied to a context.

00:24:31.970 --> 00:24:35.310
Each source has certain properties,
like for instance,

00:24:35.350 --> 00:24:40.100
you can set a 3D coordinate on a source,
and sources have sounds

00:24:40.100 --> 00:24:41.800
associated with them.

00:24:41.800 --> 00:24:43.800
Now, where are these sounds stored?

00:24:43.920 --> 00:24:47.300
They're stored in OpenAL buffer objects.

00:24:47.420 --> 00:24:53.800
What's important here is that you can
share a buffer with multiple sources.

00:24:53.840 --> 00:24:57.530
So if you had a particular sound,
like maybe a gunshot or something,

00:24:57.550 --> 00:25:00.280
and you wanted to play
it with multiple sources,

00:25:00.330 --> 00:25:04.580
you can associate that
buffer to multiple sources.

00:25:04.720 --> 00:25:08.480
The fourth API object
is the OpenAL device,

00:25:08.480 --> 00:25:10.100
or it's the output hardware.

00:25:10.260 --> 00:25:14.890
The context renders to a device,
and that's how that fits in.

00:25:15.860 --> 00:25:18.950
So let's take a look at some
code as to how we can get started

00:25:18.950 --> 00:25:20.710
playing a sound with OpenAL.

00:25:20.950 --> 00:25:24.370
The first thing I need to
do here is create a device.

00:25:24.510 --> 00:25:26.880
That's my output device.

00:25:26.960 --> 00:25:31.260
I then take the device ID and
I create a context because my context

00:25:31.270 --> 00:25:33.710
is going to render to the device.

00:25:34.400 --> 00:25:38.290
Only one context can be
rendering at any given time.

00:25:38.300 --> 00:25:42.870
So that's why I take this context
and I make it the current context.

00:25:43.400 --> 00:25:47.370
Next, I need to have a source
that's tied to my context.

00:25:47.370 --> 00:25:49.570
So I generate a source.

00:25:50.360 --> 00:25:53.340
I need to have a sound that
I associate with my source.

00:25:53.430 --> 00:25:57.010
So to do that, I then generate a buffer.

00:25:57.220 --> 00:26:02.600
Now, I need to get some audio data and
stick it into my OpenAL buffer.

00:26:02.760 --> 00:26:06.310
And I'm going to do that with the
help of the extended audio file

00:26:06.420 --> 00:26:08.800
API that James had mentioned.

00:26:08.950 --> 00:26:12.450
Once I do that,
I get this audio data and I stick

00:26:12.660 --> 00:26:17.700
it into my OpenAL buffer using
the AL buffer data static call.

00:26:17.840 --> 00:26:21.930
Let's take a look at how
we can get this audio data.

00:26:23.080 --> 00:26:27.030
So the first thing I do is once
again I create a URL pointing

00:26:27.160 --> 00:26:29.180
to the file in my app bundle.

00:26:29.200 --> 00:26:31.440
This file can be
compressed or uncompressed.

00:26:31.520 --> 00:26:32.760
It doesn't matter.

00:26:32.830 --> 00:26:36.000
A .exe audio file will
handle this for you.

00:26:36.120 --> 00:26:41.000
Once you open your file,
you now set up a client format.

00:26:41.030 --> 00:26:42.990
What is the client format?

00:26:43.100 --> 00:26:47.000
The client format is the format
that you want your data in.

00:26:47.210 --> 00:26:48.980
And why is that important?

00:26:49.020 --> 00:26:52.880
It's important because OpenAL only
accepts data in certain formats.

00:26:53.070 --> 00:26:55.910
Like, it doesn't accept compressed data.

00:26:56.120 --> 00:27:00.000
It requires the data that you
give it to be uncompressed.

00:27:00.190 --> 00:27:03.000
So I need to set up my client format.

00:27:03.030 --> 00:27:06.000
The first thing I do
is I set up some flags.

00:27:06.000 --> 00:27:09.700
I want my data to be sign integer.

00:27:09.700 --> 00:27:15.110
And the format that I want here
in this particular example is

00:27:15.110 --> 00:27:19.200
that I want it to be a 22K,
linear PCM data with the

00:27:19.200 --> 00:27:25.910
flags that I've set up,
mono or one channel of audio, and 16 bit.

00:27:26.160 --> 00:27:30.300
So once I set up this format,
I just set that property

00:27:30.400 --> 00:27:32.330
on the .exe audio file.

00:27:32.380 --> 00:27:34.790
Now I've defined my Client Format.

00:27:34.870 --> 00:27:37.860
So I am going to get
data in a certain format.

00:27:37.910 --> 00:27:39.050
What do I need to do next?

00:27:39.160 --> 00:27:41.570
I need to stick it into a buffer.

00:27:41.720 --> 00:27:45.380
For that, I have to allocate some space,
some chunk of memory.

00:27:45.450 --> 00:27:47.600
How much space do I allocate?

00:27:47.640 --> 00:27:52.690
Well, it's the number of frames times
the size of the data type that

00:27:52.980 --> 00:27:58.120
I set in my Client Format,
which is 16-bit sign integer.

00:27:58.210 --> 00:28:02.030
So once I have that data size,
I allocate that much space,

00:28:02.140 --> 00:28:05.600
I create an audio buffer list,
because that's what

00:28:05.600 --> 00:28:09.490
extAudioFile.read requires,
and I read this data

00:28:09.760 --> 00:28:11.630
into that buffer list.

00:28:11.740 --> 00:28:14.970
Now, in this particular example,
I'm reading all of my

00:28:14.970 --> 00:28:16.820
data into one buffer.

00:28:16.930 --> 00:28:20.170
But that's not what you would
do if you had a larger sound.

00:28:20.270 --> 00:28:23.640
What you should do there
is have multiple buffers,

00:28:23.710 --> 00:28:27.250
allocate space appropriately,
and load chunks of your sound

00:28:27.340 --> 00:28:30.090
into each one of these buffers.

00:28:30.700 --> 00:28:36.740
So now that I have the data in my buffer,
I go back to OpenAL and I stick

00:28:36.860 --> 00:28:39.290
that data into my OpenAL buffer.

00:28:39.360 --> 00:28:42.540
You can see now how all of this ties in.

00:28:42.580 --> 00:28:48.020
The format is mono, 16-bit sign integer.

00:28:48.070 --> 00:28:53.460
Data pointer is pointing to the location
and memory that contains my data.

00:28:53.520 --> 00:28:58.180
And data size is the
amount of size it takes.

00:28:59.370 --> 00:29:04.640
Once I've done that, I now attach this
OpenAL buffer to my source,

00:29:04.640 --> 00:29:08.140
and the source now has a
sound associated with it.

00:29:08.190 --> 00:29:09.540
That was the hard part.

00:29:09.580 --> 00:29:13.860
Now all we have to do is just set
some source and listener attributes.

00:29:13.950 --> 00:29:18.390
Here I set my source position,
I set a reference distance,

00:29:18.390 --> 00:29:22.070
which deals with distance attenuation,
and I want my source to

00:29:22.070 --> 00:29:23.730
be looping that sound.

00:29:23.850 --> 00:29:28.860
So if you loaded data
from a compressed file,

00:29:28.930 --> 00:29:33.200
you observe how easy it
is now to loop this sound.

00:29:33.280 --> 00:29:35.940
You didn't have to deal with
any of the complexities like

00:29:35.940 --> 00:29:40.500
the leading or trailing frames.

00:29:40.540 --> 00:29:43.900
You can just loop this sound,
and it's that easy.

00:29:44.350 --> 00:29:47.590
I can then go ahead and set some
listener attributes like the position,

00:29:47.680 --> 00:29:51.670
the orientation,
and I'm ready to start playing my sound.

00:29:51.850 --> 00:29:55.180
During gameplay,
I can go ahead and change the source

00:29:55.320 --> 00:29:57.990
position or the listener position.

00:29:58.190 --> 00:30:01.590
And that's an overview
of how you use OpenAL.

00:30:01.720 --> 00:30:04.500
This is how OpenAL natively works.

00:30:04.570 --> 00:30:08.970
Now we're going to take a
look at OpenAL extensions.

00:30:09.780 --> 00:30:11.840
What are OpenAL extensions?

00:30:11.990 --> 00:30:16.400
OpenAL extensions are a mechanism
for augmenting the existing API set.

00:30:16.400 --> 00:30:22.960
What you need to do is determine if
an extension is present at runtime,

00:30:23.120 --> 00:30:25.760
and then you get pointers for
the extension's functions,

00:30:25.930 --> 00:30:27.360
and you use those functions.

00:30:27.360 --> 00:30:31.510
So we're going to talk
about two extensions today.

00:30:31.670 --> 00:30:34.480
One of them is the
Apple Spatial Audio extension,

00:30:34.510 --> 00:30:37.650
or the ASA extension,
that has the reverb, occlusion,

00:30:37.660 --> 00:30:39.360
and obstruction effects.

00:30:39.360 --> 00:30:44.530
This is new to iOS 5 and is
already available on Mac OS X.

00:30:44.560 --> 00:30:47.470
The second extension that we're
going to talk about is the

00:30:47.480 --> 00:30:51.030
Source Notifications extension,
which is basically a callback

00:30:51.030 --> 00:30:52.540
mechanism for source state.

00:30:52.590 --> 00:30:57.850
This is new to both iOS 5 and Mac OS X.

00:30:58.510 --> 00:31:00.740
So first, the ASA extension.

00:31:00.890 --> 00:31:05.400
This comprises of three spatial effects,
the reverb, occlusion, and obstruction.

00:31:05.430 --> 00:31:09.960
I'm just going to briefly summarize
what James had talked about.

00:31:10.070 --> 00:31:14.030
Reverb is a simulation
of a room environment.

00:31:14.250 --> 00:31:18.400
Occlusion is an effect that
simulates a source being in a

00:31:18.520 --> 00:31:21.310
different space as the listener.

00:31:21.380 --> 00:31:25.100
An obstruction is an effect that
simulates an obstacle in between

00:31:25.220 --> 00:31:27.370
the source and the listener.

00:31:28.880 --> 00:31:32.680
So there are some listener
properties that you can set.

00:31:32.700 --> 00:31:35.160
You can turn the reverb on or off.

00:31:35.230 --> 00:31:36.640
It's off by default.

00:31:36.690 --> 00:31:43.320
And you can set a global level
from minus 40 dB to plus 40 dB.

00:31:43.990 --> 00:31:48.800
We also have a number of preset room
types that you can use in your game.

00:31:49.000 --> 00:31:52.420
For instance,
if your game is a first-person

00:31:52.420 --> 00:31:56.970
shooter and you go into a particular
environment like a medium chamber,

00:31:57.150 --> 00:32:00.040
then you could use the medium
chamber preset and have things

00:32:00.040 --> 00:32:01.200
sound the way they should.

00:32:01.220 --> 00:32:05.430
If you're looking for a particular sound,
maybe something we don't

00:32:05.560 --> 00:32:08.120
have here as a preset,
but that's something that you can tweak.

00:32:08.210 --> 00:32:14.180
For instance,
if your game involves an airport

00:32:14.730 --> 00:32:18.000
and you think an airport sounds
brighter than a large room,

00:32:18.000 --> 00:32:22.680
what you can do is set the large room
preset and then use the EQ that we've

00:32:22.680 --> 00:32:27.640
included after that to change the sound
or tweak it in a way that you want.

00:32:27.660 --> 00:32:31.020
This EQ is a standard parametric EQ.

00:32:31.410 --> 00:32:37.270
With a gain, bandwidth,
and center frequency control.

00:32:38.520 --> 00:32:40.980
Now you can also set
certain source properties,

00:32:40.990 --> 00:32:45.540
and these are properties you would set
on each source tied to the context.

00:32:45.640 --> 00:32:49.690
You can set a send level
that goes from 0 to 1.

00:32:49.980 --> 00:32:53.620
0 will be completely dry,
1 is completely wet.

00:32:53.780 --> 00:32:56.660
You can set an occlusion level,
which is basically a

00:32:56.660 --> 00:32:58.330
low-pass filter effect.

00:32:58.430 --> 00:33:03.400
Minus 100 dB is the maximum
amount of attenuation you can set.

00:33:03.400 --> 00:33:06.290
0 dB would be no attenuation.

00:33:06.560 --> 00:33:09.160
Similar control for the obstruction.

00:33:09.160 --> 00:33:10.900
Again, a low-pass filter effect.

00:33:10.920 --> 00:33:16.700
You can set an attenuation
level from 0 dB to minus 100 dB.

00:33:17.900 --> 00:33:22.090
Here's an example of me
using this extension.

00:33:22.490 --> 00:33:26.910
I'm setting a listener property here,
which is just turning the reverb on,

00:33:26.940 --> 00:33:31.470
and setting a source property,
which is setting a certain amount

00:33:31.480 --> 00:33:34.390
of send level for a source.

00:33:34.720 --> 00:33:38.910
Let's take a look at a quick
demo of the ASA extension.

00:33:46.730 --> 00:33:51.840
So what I have here is a particular
environment that has my source

00:33:52.230 --> 00:33:57.470
that's moving up here and a
listener that's moving down here.

00:33:58.160 --> 00:34:02.110
Now just to make things interesting,
I'm going to assume that

00:34:02.110 --> 00:34:06.700
my source is a demon or a
monster or something like that.

00:34:06.700 --> 00:34:10.250
And this is what it sounds like, dry.

00:34:12.300 --> 00:34:22.700
[Transcript missing]

00:34:26.960 --> 00:34:30.700
Now,
let's take the monster and the listener

00:34:31.300 --> 00:34:35.960
and put them in a medium-sized chamber.

00:34:36.100 --> 00:34:40.680
That's what the first preset is,
and let's hear what that sounds like.

00:34:50.200 --> 00:34:52.200
I can move the listener around as well.

00:34:52.200 --> 00:35:00.200
. . . Now you get an idea
of what that sounds like.

00:35:00.630 --> 00:35:04.200
Let's say that this is just a
little too close for comfort.

00:35:04.200 --> 00:35:08.140
So we're going to move all of
this to a bigger environment.

00:35:08.210 --> 00:35:11.820
Let's assume that I have a basement
below my house that's really

00:35:11.820 --> 00:35:14.060
massive and has no furniture.

00:35:14.200 --> 00:35:18.190
For an echoey environment simulation,
here's what that would sound like.

00:35:18.200 --> 00:35:20.400
*Loud Vibration*

00:35:27.500 --> 00:35:32.000
Now when you use the reverb,
you want it to be a subtle effect.

00:35:32.010 --> 00:35:34.590
It's not a very in-your-face effect.

00:35:34.590 --> 00:35:39.780
But this kind of gives you an
idea of what it sounds like.

00:35:40.310 --> 00:35:46.840
Now, let's assume that I get out of the
basement and I slam the door shut.

00:35:46.840 --> 00:35:49.770
And this is what it sounds like.

00:35:53.500 --> 00:35:58.600
So you can hear the source continue
to growl away in the basement.

00:35:58.650 --> 00:36:02.800
And as I move or walk up the
stairs away from the basement,

00:36:02.800 --> 00:36:07.320
this is what it sounds like.

00:36:13.890 --> 00:36:17.420
So what you're hearing here
is the occlusion filter.

00:36:17.430 --> 00:36:23.330
And what this simulates is the listener
being in a different space as the source.

00:36:23.550 --> 00:36:27.920
So that's a quick example of what
the ASA extension sounds like.

00:36:27.920 --> 00:36:29.630
And this is just scratching the surface.

00:36:29.720 --> 00:36:31.630
There's so much more you can do with it.

00:36:31.820 --> 00:36:36.290
So go ahead, try it,
and give us feedback.

00:36:44.430 --> 00:36:46.820
So let's move on to the next extension.

00:36:47.090 --> 00:36:52.060
The second extension that we have here is
a source state notifications extension.

00:36:52.160 --> 00:36:57.070
What this extension achieves is that it
eliminates the need for polling to check

00:36:57.630 --> 00:37:02.690
for a change in source state or a change
in the number of buffers processed.

00:37:02.810 --> 00:37:06.690
The user is notified via
a callback mechanism.

00:37:06.750 --> 00:37:10.000
Now, what are the notification
types that you can sign up for?

00:37:10.080 --> 00:37:11.940
One is the source state.

00:37:12.050 --> 00:37:14.930
There are four basic source
state types in OpenAL.

00:37:15.190 --> 00:37:18.340
They are initial, playing, paused,
and stopped.

00:37:18.440 --> 00:37:22.940
If you have a change in source state,
then you will be notified with

00:37:22.940 --> 00:37:25.380
the source ID and the new state.

00:37:25.600 --> 00:37:31.510
You can also be notified if
a new buffer is processed.

00:37:31.920 --> 00:37:36.460
Or if you've queued up several
buffers and that entire queue

00:37:36.470 --> 00:37:38.580
of buffers has looped over.

00:37:39.340 --> 00:37:43.140
Now here's how you do
things natively in OpenAL.

00:37:43.270 --> 00:37:48.560
It is a common practice to queue
up a number of buffers on a source.

00:37:48.660 --> 00:37:51.480
So let's assume that your
sound is divided into chunks,

00:37:51.550 --> 00:37:55.390
you put them into different buffers,
and then you queue that up on the source.

00:37:55.540 --> 00:37:59.920
As each buffer gets processed one by one,
you take that out,

00:37:59.960 --> 00:38:04.080
and then you load more data into it,
and then you queue that up once again.

00:38:04.200 --> 00:38:07.080
So in OpenAL,
what you are required to do is

00:38:07.080 --> 00:38:11.720
to poll continuously to check
the number of buffers processed.

00:38:11.830 --> 00:38:15.400
But this is expensive,
and we don't recommend this anymore.

00:38:15.490 --> 00:38:20.200
Instead, what you should do today is use
the extension that we've provided.

00:38:20.310 --> 00:38:24.600
You register for a notification
that is with a source ID.

00:38:24.670 --> 00:38:28.360
I want to be notified when
a new buffer is processed,

00:38:28.450 --> 00:38:32.950
and call me at my method,
which is handleNotification.

00:38:33.100 --> 00:38:37.220
And what happens is that every
time a new buffer gets processed,

00:38:37.220 --> 00:38:43.340
you get called there with your
source type and the notification.

00:38:43.430 --> 00:38:47.340
And you do something based on the
source type and the notification ID.

00:38:47.460 --> 00:38:51.240
You can sign up for any of the
notifications that I talked about,

00:38:51.240 --> 00:38:57.510
which is source state, buffers processed,
or if the entire queue has looped.

00:38:59.030 --> 00:39:04.110
So just to quickly summarize OpenAL,
we first talked about the coordinate

00:39:04.230 --> 00:39:07.320
system and the listener's orientation.

00:39:07.400 --> 00:39:12.120
I talked about the API objects,
which is the context, the sources,

00:39:12.200 --> 00:39:14.660
the buffers, and the device.

00:39:14.820 --> 00:39:18.510
We took a look at some code,
and then we moved on

00:39:18.510 --> 00:39:22.500
to OpenAL extensions,
where we talked about the

00:39:22.500 --> 00:39:25.260
Apple Spatial Audio extension and
the Source Notifications extension.

00:39:26.240 --> 00:39:29.780
Let's move on to the last
section in our talk today,

00:39:29.780 --> 00:39:33.100
which is audio session and games.

00:39:33.100 --> 00:39:37.800
Now audio session is an API that deals
with the application's interaction

00:39:37.800 --> 00:39:40.820
with this complex audio environment.

00:39:40.820 --> 00:39:43.860
But I'm just going to talk
about a section of it today.

00:39:43.860 --> 00:39:48.480
We have an entire talk on audio session
that's going to be held tomorrow morning,

00:39:48.500 --> 00:39:51.000
so I encourage you to
go and watch that one.

00:39:51.000 --> 00:39:53.750
But what I'm going to talk
about is certain things that

00:39:53.860 --> 00:39:56.040
are directly relevant to games.

00:39:56.100 --> 00:39:59.840
I'm going to talk about what
audio session category you pick,

00:39:59.910 --> 00:40:03.580
how you detect if
background audio is running,

00:40:03.670 --> 00:40:06.800
and how you respond to interruptions.

00:40:07.350 --> 00:40:11.060
So I'm going to start off by
talking about the ambient category.

00:40:11.120 --> 00:40:14.840
In the ambient category,
audio obeys the ringer switch

00:40:15.400 --> 00:40:18.010
and audio obeys the screen lock.

00:40:18.110 --> 00:40:22.740
What that means is that if a user is
playing your game and he's sitting in a

00:40:22.780 --> 00:40:27.740
public environment where he doesn't want
the game sounds to disturb other people,

00:40:27.740 --> 00:40:32.190
he goes and he turns off the ringer
switch and he continues to see

00:40:32.300 --> 00:40:37.280
the graphics and all the videos,
but there's no audio.

00:40:37.300 --> 00:40:42.600
How do you pick between this
ambient category or solo ambient?

00:40:42.600 --> 00:40:48.660
That brings us to our next topic,
which is, is your game's audio primary?

00:40:48.660 --> 00:40:52.860
Now, you could have a user who's
playing background audio

00:40:52.860 --> 00:40:56.980
like the iPod or Pandora,
and then he opens your game.

00:40:57.000 --> 00:40:59.610
So you're left with a
decision to make here,

00:40:59.690 --> 00:41:02.720
which is,
do you want to interrupt the background

00:41:02.720 --> 00:41:07.120
audio and play your game's soundtrack,
or do you not want to do that?

00:41:07.300 --> 00:41:08.350
Amen.

00:41:08.570 --> 00:41:13.390
What you could do here is
present the user with a

00:41:13.400 --> 00:41:17.560
prompt in your game that says,
Play game sounds.

00:41:17.600 --> 00:41:22.100
If the user picks yes,
then what he wants you to do is

00:41:22.210 --> 00:41:24.180
interrupt the background audio.

00:41:24.180 --> 00:41:29.090
So you pick the solo ambient category
and you play your game soundtrack.

00:41:29.090 --> 00:41:33.330
If the user picks no,
then don't play your soundtrack.

00:41:33.430 --> 00:41:37.780
You pick the ambient category
and don't play your soundtrack.

00:41:37.830 --> 00:41:41.390
Continue to let Pandora or the iPod play.

00:41:42.000 --> 00:41:44.750
Now,
why this doesn't always work is because

00:41:44.820 --> 00:41:48.780
in most cases users don't know what
you're talking about when you present

00:41:48.780 --> 00:41:50.780
them with a generic prompt like that.

00:41:50.780 --> 00:41:53.260
So we don't recommend
doing things this way.

00:41:53.400 --> 00:41:56.890
How you should approach this problem
is use the audio session property

00:41:57.010 --> 00:42:00.020
to check if other audio is playing.

00:42:00.140 --> 00:42:03.190
If other audio is playing,
you pick the ambient category.

00:42:03.330 --> 00:42:07.490
If other audio isn't playing,
you pick the solo ambient category.

00:42:08.650 --> 00:42:11.960
Now, what are interruptions?

00:42:12.010 --> 00:42:14.900
Interruptions can be
higher-priority audio,

00:42:14.970 --> 00:42:18.320
like a phone call or the
clock's alarm going off.

00:42:18.610 --> 00:42:24.120
And what this does to your application is
that it makes your session inactive and

00:42:24.120 --> 00:42:26.840
your currently playing audio is stopped.

00:42:26.980 --> 00:42:29.300
How do you recover from an interruption?

00:42:29.360 --> 00:42:32.860
Well, this really depends on
the API that you're using.

00:42:33.210 --> 00:42:36.350
But in general,
you reactivate some state.

00:42:36.490 --> 00:42:41.810
Now, we've talked about two APIs today,
AV Audio Player and OpenAIR.

00:42:42.000 --> 00:42:46.710
In AV Audio Player's case,
when you have an interruption,

00:42:46.710 --> 00:42:49.900
the AV Audio Players are all stopped.

00:42:50.020 --> 00:42:54.180
You need to override the
AV Audio Player's delegate methods

00:42:54.330 --> 00:43:03.720
if you want to show this in your
UI or if you want to restart playback

00:43:03.720 --> 00:43:03.720
once the interruption has gone away.

00:43:04.390 --> 00:43:07.460
So taking a look at that,
here's what it would look like.

00:43:07.470 --> 00:43:10.970
Begin interruption,
playback automatically stops.

00:43:11.080 --> 00:43:14.420
You can show it in the UI if you want to.

00:43:14.760 --> 00:43:18.220
And when the interruption goes away,
you can resume or restart

00:43:18.350 --> 00:43:21.700
playback of sounds if that's
what you desire in your game.

00:43:21.700 --> 00:43:24.770
And once again, you can update the UI.

00:43:25.170 --> 00:43:29.250
In the case of OpenAL,
you need to use the AV audio

00:43:29.250 --> 00:43:31.300
session delegate methods.

00:43:31.400 --> 00:43:36.260
And what you have to do here is first
invalidate the context when you're

00:43:36.270 --> 00:43:43.400
interrupted and make the context current
once again when the interruption ends.

00:43:43.590 --> 00:43:48.180
So taking a look at the AV audio
session delegate methods,

00:43:48.270 --> 00:43:53.530
when the interruption comes in or begins,
I make my current context equal null,

00:43:53.530 --> 00:43:56.490
or I'm invalidating the context.

00:43:56.600 --> 00:44:05.060
When the interruption goes away,
I set my session active once again,

00:44:05.060 --> 00:44:05.060
and I make my context
the current context.

00:44:05.540 --> 00:44:08.770
So to summarize that,
when you're using audio session

00:44:09.040 --> 00:44:12.130
and you're dealing with games,
you have to decide on what audio

00:44:12.130 --> 00:44:14.160
session category you want to use.

00:44:14.180 --> 00:44:18.200
And that's dependent on whether
background audio is playing or not.

00:44:18.330 --> 00:44:22.610
And you have to handle
interruptions in your application.

00:44:23.490 --> 00:44:26.880
So to sum all of this up,
we started off by talking

00:44:26.880 --> 00:44:30.080
about a simple game,
an AV audio player.

00:44:30.190 --> 00:44:31.940
We moved on to audio assets.

00:44:32.060 --> 00:44:35.570
We talked about sample rate conversions,
and we also talked

00:44:35.680 --> 00:44:37.400
about compressed files.

00:44:37.560 --> 00:44:42.480
We then moved on to a complex game where
we took a look at spatial audio and how

00:44:42.560 --> 00:44:46.190
you can use OpenAL and its extensions.

00:44:46.460 --> 00:44:50.590
And finally,
we talked about audio session and games.

00:44:52.020 --> 00:44:56.490
So a related session is audio
session management for iOS,

00:44:56.500 --> 00:45:00.580
which is tomorrow morning at 11:30 a.m.

00:45:00.580 --> 00:45:04.990
Alan and Eric are evangelists at Apple,
and you can contact them if

00:45:05.150 --> 00:45:07.460
you have questions again.

00:45:07.680 --> 00:45:13.040
There's a wealth of information
online at developer.apple.com.

00:45:13.040 --> 00:45:17.490
We also have the Apple Developer Forums
where you can post questions.

00:45:17.940 --> 00:45:21.430
So I hope all of this will help
you in your game development

00:45:21.540 --> 00:45:22.650
and we wish you good luck.

00:45:22.760 --> 00:45:24.190
Thank you.