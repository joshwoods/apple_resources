WEBVTT

00:00:11.150 --> 00:00:14.010
Good afternoon everyone
and welcome to session 417,

00:00:14.180 --> 00:00:16.560
introducing
AV Foundation Capture For Lion.

00:00:16.600 --> 00:00:20.220
My name is Brad Ford and I will be
your host for the next hour and maybe

00:00:20.580 --> 00:00:22.120
more if you choose to stay around.

00:00:23.790 --> 00:00:26.240
Here's what we're going
to talk about today.

00:00:26.280 --> 00:00:30.940
Why and when you should
use AV Foundation Capture,

00:00:31.010 --> 00:00:34.510
the AV Foundation Capture
programming model,

00:00:35.280 --> 00:00:37.910
and differences between
AV Foundation capture

00:00:38.100 --> 00:00:41.340
between Lion and iOS.

00:00:41.850 --> 00:00:44.300
Keep a close watch out for
those two badges there,

00:00:44.300 --> 00:00:48.100
the new and the only on Mac OS,
because you'll see a lot of that.

00:00:48.100 --> 00:00:51.960
Pretty much everything we
talk about here today is new,

00:00:51.960 --> 00:00:55.740
either new on Mac OS or new in general.

00:00:57.970 --> 00:01:01.620
The sample code for this session,
we have four sample apps,

00:01:01.620 --> 00:01:04.200
and last I checked,
three of them were published already.

00:01:04.200 --> 00:01:07.540
You can follow along
at that specified URL.

00:01:07.880 --> 00:01:10.630
The fourth should be up there shortly.

00:01:12.210 --> 00:01:15.810
Let's start by doing a brief
history of capture on Mac OS.

00:01:16.090 --> 00:01:20.280
Set your way back machine to classic Mac.

00:01:21.730 --> 00:01:26.300
Video digitizer components were
introduced in QuickTime 1.0.

00:01:26.470 --> 00:01:27.780
Does anyone know when that was?

00:01:27.910 --> 00:01:28.300
Anyone?

00:01:28.300 --> 00:01:30.940
This isn't stump the experts, but--

00:01:32.070 --> 00:01:36.300
That was December of 1991,
which was 20 years ago.

00:01:36.430 --> 00:01:38.280
And in case you're curious,
this is what engineers

00:01:38.350 --> 00:01:39.900
looked like in those days.

00:01:39.910 --> 00:01:49.300
Jim Batson: I'm Jim Batson and I've been
working in the QuickTime sleep

00:01:49.300 --> 00:01:49.300
deprivation experiment.

00:01:49.300 --> 00:01:49.300
Thanks.

00:01:51.050 --> 00:01:54.840
Video digitizer
components served us well.

00:01:55.170 --> 00:01:58.650
They still are the means for
third parties to deliver video

00:01:58.680 --> 00:02:01.260
device drivers on our OS.

00:02:01.330 --> 00:02:02.900
And they've been around for 20 years.

00:02:03.130 --> 00:02:07.860
Now that was a pretty hardcore,
low-level set of APIs to use.

00:02:07.860 --> 00:02:10.590
So shortly after,
we came up with the Sequence

00:02:10.660 --> 00:02:12.830
Grabber in QuickTime 1.5.

00:02:12.840 --> 00:02:16.960
These were considered high-level,
easy-to-use capture interfaces.

00:02:18.390 --> 00:02:20.960
These APIs still work today,
and the video quality

00:02:20.960 --> 00:02:24.910
was much improved in 1.5,
as you can see here.

00:02:29.200 --> 00:02:33.740
And curiously enough,
both of these men still work at Apple.

00:02:33.870 --> 00:02:39.340
Now let's push forward to Mac OS X,
the more recent history,

00:02:39.340 --> 00:02:45.990
where Qt Kit was introduced with modern
Objective-C capture APIs in 2005.

00:02:46.320 --> 00:02:49.440
We did this because we felt we
needed a simpler programming model,

00:02:49.440 --> 00:02:53.520
something that fit in better
with the rest of Mac OS X.

00:02:53.520 --> 00:02:56.860
And it sits atop core media,
or what we sometimes call

00:02:56.860 --> 00:03:00.740
in marketing QuickTime 10,
which is the more modern

00:03:00.750 --> 00:03:02.240
underpinnings for QuickTime.

00:03:02.240 --> 00:03:06.030
And it provides a legacy bridge
back to the 32-bit world,

00:03:06.030 --> 00:03:10.060
so it grandfathers in these
VDIG or video digitizer components.

00:03:12.130 --> 00:03:15.200
These APIs, as you might expect,
also still work today,

00:03:15.310 --> 00:03:19.790
and they are in fact the preferred
capture mechanism on Mac OS X.

00:03:20.240 --> 00:03:21.450
Until now.

00:03:21.580 --> 00:03:23.740
Let's talk about AV Foundation.

00:03:23.870 --> 00:03:28.960
It was introduced in iOS 4 for iPhone,
iPad, and iPod Touch.

00:03:28.960 --> 00:03:31.760
And by show of hands,
who here has used iOS

00:03:31.760 --> 00:03:34.200
AV Foundation Capture APIs?

00:03:34.200 --> 00:03:35.430
Okay, almost everybody.

00:03:35.430 --> 00:03:36.140
That's good.

00:03:38.260 --> 00:03:42.410
The ideas for AV Foundation Capture
were inspired by QtKit.

00:03:42.540 --> 00:03:43.480
We did this on purpose.

00:03:43.580 --> 00:03:45.980
We felt the interfaces
worked really well,

00:03:46.210 --> 00:03:48.460
so we wanted to keep the familiarity.

00:03:48.660 --> 00:03:52.410
They also sit atop
Core Media or QuickTime 10.

00:03:52.670 --> 00:03:56.140
And we felt that to get wide
developer adoption of these

00:03:56.140 --> 00:03:58.900
new AV Foundation capture APIs,
we couldn't deliver something

00:03:58.970 --> 00:04:01.990
that was feature hobbled.

00:04:02.120 --> 00:04:07.080
So we really worked hard to encompass
all of QtKit's capture features in

00:04:07.080 --> 00:04:09.120
our 1.0 release of AV Foundation.

00:04:09.120 --> 00:04:11.890
So we think we've done that,
encompassing all of the

00:04:11.890 --> 00:04:14.720
QtKit capture API features.

00:04:14.760 --> 00:04:17.790
We also provide new features
that were not available and

00:04:17.790 --> 00:04:20.680
will not be available in QtKit.

00:04:20.740 --> 00:04:23.780
And for the first time,
we're supporting third-party core

00:04:23.780 --> 00:04:25.690
media I/O video device drivers.

00:04:25.840 --> 00:04:29.070
This is an opportunity, finally.

00:04:30.010 --> 00:04:34.950
finally to write modern video
device drivers for Mac OS X.

00:04:35.150 --> 00:04:37.640
and it's available in Lion and Forward.

00:04:37.770 --> 00:04:39.480
So now you might be
scratching your head thinking,

00:04:39.500 --> 00:04:42.580
well, which am I supposed to use,
Qt Kit or AV Foundation?

00:04:42.780 --> 00:04:45.910
The answer is,

00:04:46.420 --> 00:04:47.180
AV Foundation.

00:04:47.600 --> 00:04:48.530
Really.

00:04:48.810 --> 00:04:51.740
All new development should
be using AV Foundation.

00:04:51.800 --> 00:04:54.810
The only caveat would be

00:04:55.540 --> 00:04:59.820
You need to continue to use QtKit if
you need legacy VDIG support.

00:04:59.920 --> 00:05:03.830
As I mentioned, we do not grandfather the
32-bit world into AV Foundation,

00:05:03.840 --> 00:05:07.270
so you'll need to stick
with QtKit for that.

00:05:07.480 --> 00:05:12.720
If you need legacy video encoder support,
when I say legacy encoders,

00:05:12.720 --> 00:05:19.070
I mean things like Sorenson Video, RLE,
some of these older encoders that don't

00:05:19.370 --> 00:05:24.040
have a place in the modern world when
we have very good replacements for them.

00:05:24.100 --> 00:05:27.300
Those also are not
supported in AV Foundation.

00:05:27.540 --> 00:05:29.750
And if you need to run on
Snow Leopard or earlier,

00:05:29.750 --> 00:05:32.900
you'll need to stick with
QtKit as AV Foundation capture

00:05:32.900 --> 00:05:36.390
APIs are not going backwards,
only forwards.

00:05:36.860 --> 00:05:39.190
Now let's look at where
AV Foundation sits in the

00:05:39.190 --> 00:05:41.270
technology framework hierarchy.

00:05:41.390 --> 00:05:43.860
As you see,
there are a lot of green boxes there,

00:05:44.130 --> 00:05:49.420
and AV Foundation is the top
one below the thin blue line.

00:05:49.580 --> 00:05:51.360
AV Foundation is the one
that we're talking about,

00:05:51.360 --> 00:05:54.740
but it relies heavily on CoreMediaIO,
CoreMedia.

00:05:54.740 --> 00:05:58.440
These are C-based frameworks
that do the heavy lifting.

00:05:58.440 --> 00:06:01.650
And above the thin blue line,
that's where you come in.

00:06:01.660 --> 00:06:05.360
You can write your apps using
AV Foundation and interface directly

00:06:05.430 --> 00:06:07.470
with those Objective-C APIs.

00:06:07.480 --> 00:06:11.360
And now for the first time,
you get to participate below

00:06:11.360 --> 00:06:13.340
the lower thin blue line.

00:06:13.860 --> 00:06:18.340
If you are a device driver writer,
we welcome you to come talk to us in the

00:06:18.340 --> 00:06:25.220
labs about how you can write your device
driver for Mac OS X using CoreMediaIO.

00:06:27.520 --> 00:06:32.090
So the theme for today is new in Lion,
more features, more flexibility.

00:06:32.150 --> 00:06:35.120
Especially if you're familiar
with AV Foundation on iOS,

00:06:35.190 --> 00:06:38.130
you'll be impressed with the
number of new features that

00:06:38.130 --> 00:06:39.750
we've introduced in Lion.

00:06:39.760 --> 00:06:43.380
First off,
AV Capture device enhancements.

00:06:43.380 --> 00:06:47.670
We support discovery and selection
of supported frame rates and formats,

00:06:47.700 --> 00:06:50.360
which is something we
couldn't do in QtKit.

00:06:51.760 --> 00:06:55.140
System-wide device sharing,
locking of shared devices

00:06:55.140 --> 00:06:59.130
for configuration,
and support for closed captions

00:06:59.130 --> 00:07:01.320
from real-time devices.

00:07:03.550 --> 00:07:06.020
Also on the output side,
we support compressed

00:07:06.120 --> 00:07:09.500
AV capture video data output,
which is a long sought

00:07:09.500 --> 00:07:11.880
after feature on the phone.

00:07:12.440 --> 00:07:15.620
and support for arbitrarily
complex AV capture sessions.

00:07:15.730 --> 00:07:19.700
If you've worked with
our APIs embedded on iOS,

00:07:20.060 --> 00:07:22.390
then you're familiar with some of
the restrictions we have there where

00:07:22.390 --> 00:07:25.720
you are not allowed to use certain
combinations of inputs and outputs.

00:07:25.840 --> 00:07:28.980
All of those restrictions are
lifted on the desktop where you can

00:07:29.080 --> 00:07:33.030
go crazy and make as complicated
a session as you would like.

00:07:33.660 --> 00:07:39.000
Lastly, three new classes,
which are only available on Lion.

00:07:39.000 --> 00:07:42.280
AV Capture screen input,
audio preview output,

00:07:42.280 --> 00:07:44.110
and audio file output.

00:07:44.150 --> 00:07:46.760
Audio preview output we
won't spend much time on.

00:07:46.760 --> 00:07:47.830
It does what you would expect.

00:07:47.930 --> 00:07:49.740
It previews the audio in real time.

00:07:49.740 --> 00:07:53.320
And it synchronizes it with a video
preview if you're showing one.

00:07:53.320 --> 00:07:56.640
And the audio file output also we
will not spend very much time on.

00:07:56.640 --> 00:08:01.070
But it allows for frame accurate writing
of audio files into the common formats,

00:08:01.140 --> 00:08:02.930
such as CAF, AIF, and WAV.

00:08:03.500 --> 00:08:04.840
From an AV Capture session.

00:08:04.840 --> 00:08:12.000
Time for our first slide
about the programming model.

00:08:13.900 --> 00:08:14.800
Capture basics.

00:08:15.020 --> 00:08:16.800
How do we look at the
world in AV Foundation?

00:08:16.800 --> 00:08:20.130
We look at the world
as inputs and outputs.

00:08:20.270 --> 00:08:22.280
When my mom asks me
what I do for a living,

00:08:22.330 --> 00:08:25.310
I usually tell her that
I'm a bit shoveler.

00:08:25.470 --> 00:08:28.480
Which means I just take the bits and
I put them from one place to the other.

00:08:28.510 --> 00:08:30.640
And that's what AV Foundation does too.

00:08:30.710 --> 00:08:33.680
It sees everything as
an input and an output.

00:08:33.770 --> 00:08:36.070
What I'm talking about here is,
let's say you've got a

00:08:36.100 --> 00:08:37.310
shiny new MacBook Pro.

00:08:37.320 --> 00:08:40.880
It's got a camera on it,
a FaceTime HD camera.

00:08:40.970 --> 00:08:46.880
And from that camera you might want to do
real-time previewing into a video layer,

00:08:46.880 --> 00:08:50.420
or perhaps capture still
images in high quality.

00:08:51.020 --> 00:08:54.900
Maybe you just want to get video frames
into a delegate call so that you can

00:08:54.900 --> 00:08:58.060
process them and look for patterns.

00:08:58.340 --> 00:09:01.150
or the traditional thing,
which would be to capture the

00:09:01.150 --> 00:09:03.460
output to a QuickTime movie.

00:09:03.630 --> 00:09:07.380
Likewise, all modern machines have
built-in audio microphones,

00:09:07.400 --> 00:09:11.220
and we support third-party
audio hardware as well.

00:09:11.280 --> 00:09:14.160
And from those, you might want to, again,
get the audio data into your

00:09:14.260 --> 00:09:18.700
process for manipulation or
write it to a QuickTime movie

00:09:19.160 --> 00:09:21.680
or preview it to the speakers.

00:09:22.440 --> 00:09:24.800
And then there's a third kind of
input that we support on Lion,

00:09:24.800 --> 00:09:26.060
which is the screen.

00:09:26.150 --> 00:09:28.050
If you have a screen or
any portion of the screen,

00:09:28.060 --> 00:09:31.780
you might want to grab some of
that and send it to all of these

00:09:31.930 --> 00:09:33.090
places we've just talked about.

00:09:33.300 --> 00:09:37.840
Still images, video output,
or a QuickTime movie.

00:09:38.230 --> 00:09:40.920
Here's what this looks
like to AV Foundation.

00:09:41.220 --> 00:09:43.250
There is an AV capture
session in the middle.

00:09:43.510 --> 00:09:46.000
This is the center of our universe.

00:09:46.080 --> 00:09:49.540
It's the place where you hook up the
inputs and you hook up the outputs,

00:09:49.540 --> 00:09:51.730
and it's the place where you
control the flow of data.

00:09:51.740 --> 00:09:55.790
You start the session running in order
to get the inputs producing input

00:09:56.050 --> 00:09:58.190
and the outputs consuming the data.

00:09:58.340 --> 00:10:02.650
On the top, we have AV capture inputs.

00:10:02.750 --> 00:10:05.780
On the bottom, AV capture outputs.

00:10:05.820 --> 00:10:08.340
And the preview for video
is a little bit different.

00:10:08.360 --> 00:10:13.330
Because it's a video preview layer,
it does not descend from a common

00:10:13.760 --> 00:10:15.360
parent class like the outputs.

00:10:15.470 --> 00:10:19.670
It descends from CA layer,
so it can fit right into a

00:10:19.670 --> 00:10:22.510
core animation layer tree.

00:10:23.710 --> 00:10:27.680
The rest of the talk will be
talking about four use cases,

00:10:27.700 --> 00:10:29.600
which you see here,
and we'll take these one by one,

00:10:29.600 --> 00:10:33.600
the first of which is controlling
the camera and recording movies.

00:10:33.710 --> 00:10:38.310
So let's switch over to the demo machine
and we'll look at our first demo.

00:10:41.520 --> 00:10:45.230
AV Recorder is an aptly
named application.

00:10:45.440 --> 00:10:48.630
It records A and V.

00:10:52.250 --> 00:10:54.250
Okay, AV Recorder,
the sample code you have,

00:10:54.300 --> 00:10:56.200
so you can follow along if you'd like to.

00:10:56.200 --> 00:10:59.200
Very simple application here that's
highlighting the kinds of things

00:10:59.200 --> 00:11:03.200
that we can do with the devices
that we could never do with Qt Kit.

00:11:03.200 --> 00:11:08.120
So you'll see on the top I've
got my video device or devices.

00:11:08.210 --> 00:11:11.940
I happen to have a DV camera hooked
up as well as my FaceTime HD camera.

00:11:12.200 --> 00:11:16.190
I also have some audio devices connected.

00:11:16.300 --> 00:12:38.000
[Transcript missing]

00:12:38.340 --> 00:12:41.140
Not all applications want
this automatic behavior.

00:12:41.140 --> 00:12:43.690
Sometimes you know exactly
the resolution that you want,

00:12:43.700 --> 00:12:47.060
exactly the frame rate that you want,
and you don't want it changing

00:12:47.060 --> 00:12:48.400
out from underneath you.

00:12:48.500 --> 00:12:52.240
And we support that using
this lock for configuration,

00:12:52.330 --> 00:12:54.200
which I'll talk more about in the slides.

00:12:54.290 --> 00:12:57.780
But when I lock video
device for configuration,

00:12:57.900 --> 00:13:02.170
let's say I go and try to
change my preset to something

00:13:02.170 --> 00:13:04.940
high like 1280 by 720.

00:13:05.070 --> 00:13:07.900
You'll notice that it changed
to a different preset,

00:13:07.920 --> 00:13:10.240
but the video device
stayed put where it was.

00:13:10.310 --> 00:13:13.200
That's because it is
locked for configuration.

00:13:13.250 --> 00:13:14.360
No one's allowed to touch it.

00:13:14.520 --> 00:13:21.320
And so if another process comes along
and tries to also do IO with the camera,

00:13:21.360 --> 00:13:25.060
they can get buffers from the camera,
but they're not allowed to configure it.

00:13:25.370 --> 00:13:26.990
You can probably see
where I'm going with this.

00:13:27.140 --> 00:13:29.400
Please be a good citizen on Mac OS X.

00:13:29.400 --> 00:13:35.660
Because these devices are shared,
it's a good idea to be accepting

00:13:35.660 --> 00:13:38.560
of many formats and not expect
that you'll be able to get exactly

00:13:38.560 --> 00:13:39.900
what you want all the time.

00:13:40.040 --> 00:13:45.640
I did not demo recording, but trust me,
it records movies.

00:13:45.700 --> 00:13:49.490
And if recording from a DV camera,
these transport controls also

00:13:49.850 --> 00:13:53.790
become enabled and you're able
to do device transport control.

00:13:53.900 --> 00:13:58.040
So we'll go back to slides and
talk about how we did that.

00:13:58.110 --> 00:14:01.860
Again, from the high level,
AV Recorder looks like this.

00:14:01.860 --> 00:14:06.180
It's using the FaceTime camera
or the DV camera.

00:14:07.050 --> 00:14:09.840
We saw a live video preview.

00:14:10.160 --> 00:14:13.010
It was capturing to QuickTime movies.

00:14:13.490 --> 00:14:18.880
It also was capturing from the built-in
microphone to a QuickTime movie and

00:14:19.220 --> 00:14:21.310
doing a real-time output to the speaker.

00:14:21.430 --> 00:14:24.220
I turned the volume far down
because I didn't want to hurt

00:14:24.220 --> 00:14:26.000
your ears with audio feedback.

00:14:27.650 --> 00:14:32.200
And in AV Capture parlance,
that looks like a session in the middle.

00:14:32.350 --> 00:14:35.260
An AV capture device for
each of those devices,

00:14:35.400 --> 00:14:39.790
but notice you do not plug a
device directly into a session.

00:14:39.900 --> 00:14:42.740
Sessions want inputs,
so you have to associate a device

00:14:42.740 --> 00:14:47.660
with a capture device input before
you can add it to the session.

00:14:47.870 --> 00:14:51.050
And then on the output side,
we had a movie file output

00:14:51.150 --> 00:14:53.030
and an audio preview output.

00:14:53.420 --> 00:14:56.840
And then for the video preview,
we used the AV Capture

00:14:56.850 --> 00:14:58.800
Video Preview layer.

00:15:00.790 --> 00:15:04.420
To create the AV Capture session,
it's just a few lines of code.

00:15:04.570 --> 00:15:07.770
Alloc and init your session and
specify the preset that you want.

00:15:08.000 --> 00:15:10.790
That determines the baseline
quality level that you want

00:15:10.910 --> 00:15:14.260
to receive in your outputs.

00:15:14.690 --> 00:15:16.990
Find a suitable AV capture device.

00:15:17.150 --> 00:15:21.710
Here I'm just using the default
device with media type video.

00:15:21.800 --> 00:15:25.000
As a hint,
the default device on any computer

00:15:25.000 --> 00:15:30.400
that you get is always going to be
a FaceTime camera if it has one.

00:15:31.460 --> 00:15:34.560
You then create and add an
AV capture device input.

00:15:34.690 --> 00:15:39.380
So you associate that device with an
input and then say session add input.

00:15:39.520 --> 00:15:41.520
Now you're done with the input side.

00:15:41.650 --> 00:15:44.210
For the output side,
it's also very simple.

00:15:44.390 --> 00:15:49.370
Create a movie file output,
add it to your session as an output,

00:15:49.530 --> 00:15:53.350
create the audio preview output,
and also add it to your session.

00:15:53.730 --> 00:15:57.630
To create the video preview layer,
you don't add it to the session.

00:15:57.910 --> 00:16:02.480
You associate it with the session
by calling layerWithSession.

00:16:02.600 --> 00:16:05.830
That's so that the layer owns
the session and not vice versa.

00:16:06.080 --> 00:16:09.410
You can put the layer into a rendering
tree and forget about the session,

00:16:09.410 --> 00:16:12.280
and it will just clean up
after itself when it's done.

00:16:12.490 --> 00:16:18.120
You set a frame to get an initial
rectangle and then add it to some

00:16:18.260 --> 00:16:21.500
parent layer of a view that you have.

00:16:22.620 --> 00:16:24.940
And then start the session running.

00:16:24.950 --> 00:16:26.000
And you're done.

00:16:26.020 --> 00:16:30.080
That's the guts of what we just
saw happening in AV Recorder.

00:16:30.540 --> 00:16:34.910
To enumerate AV capture device formats,
you can loop through the

00:16:35.070 --> 00:16:39.040
device's property formats,
and you'll get an array of

00:16:39.050 --> 00:16:40.420
AV capture device formats.

00:16:40.500 --> 00:16:45.720
Each one can tell you the media type,
be it video, audio, mux.

00:16:45.720 --> 00:16:48.280
And you can also get a
CM format description,

00:16:48.280 --> 00:16:51.920
which is a core media reference
counted object that gives you a lot

00:16:52.040 --> 00:16:56.450
of information about the format,
including any extensions involved.

00:16:57.260 --> 00:17:00.920
And then to find out about
the supported frame rates,

00:17:00.950 --> 00:17:05.250
you can iterate through the
format's video-supported frame

00:17:05.250 --> 00:17:08.350
rate ranges and find out exactly
which formats it supports.

00:17:10.530 --> 00:17:14.420
To select a device format,
you must lock the device

00:17:14.550 --> 00:17:18.840
for configuration first and
then set its active format.

00:17:20.480 --> 00:17:23.510
Now let's go through the important
AV capture device concepts,

00:17:23.590 --> 00:17:26.640
some of which I skimmed over in the demo.

00:17:26.710 --> 00:17:29.800
It allows you to set the
format and frame rate.

00:17:29.850 --> 00:17:33.140
But not all devices expose
formats and frame rates.

00:17:33.160 --> 00:17:34.150
Let me give you an example.

00:17:34.190 --> 00:17:38.410
An HDV camera or a DV camera,
they don't know,

00:17:38.530 --> 00:17:40.950
they can't let you set the
format because the format is

00:17:40.950 --> 00:17:42.320
dictated by what's on the tape.

00:17:42.370 --> 00:17:45.130
So you must accept
whatever format you get.

00:17:45.160 --> 00:17:48.380
So when you ask it for its list
of formats and frame rates,

00:17:48.380 --> 00:17:49.780
it doesn't have one.

00:17:51.640 --> 00:17:56.090
AV Capture Session will try to
configure the devices automatically

00:17:56.090 --> 00:18:00.900
for you so that you get the best
input for your desired output.

00:18:01.620 --> 00:18:04.230
And AV capture devices are
shared across the system,

00:18:04.230 --> 00:18:09.390
so be aware that when you ask for
a particular input from the device,

00:18:09.390 --> 00:18:12.700
you may be affecting other apps that are
sharing that camera at the same time,

00:18:12.700 --> 00:18:15.190
like Photo Booth or iChat.

00:18:16.170 --> 00:18:17.660
The last one in always wins.

00:18:17.660 --> 00:18:20.960
Unless someone is holding
that lock for configuration,

00:18:21.140 --> 00:18:26.040
the last person to ask for the
device to change formats always wins.

00:18:26.550 --> 00:18:29.810
You can use lock for configuration
to gain exclusive control,

00:18:29.940 --> 00:18:33.700
but please be judicious with that
use and unlock for configuration

00:18:33.700 --> 00:18:37.780
after you're done configuring
it to be a good OS X citizen.

00:18:37.900 --> 00:18:42.180
Lastly, since lock devices may still
be used in other processes,

00:18:42.260 --> 00:18:44.320
you need to code defensively.

00:18:44.390 --> 00:18:49.020
Don't assume that you'll be able to
lock for configuration successfully.

00:18:49.080 --> 00:18:52.730
You may not be able to because
it's already locked in another app.

00:18:54.360 --> 00:18:58.240
Switching cameras is equally
trivial in AV Foundation.

00:18:58.240 --> 00:19:01.350
What we did not want is for
people to have to write a lot of

00:19:01.480 --> 00:19:04.880
code where they stop a session,
do a lot of configuration,

00:19:04.880 --> 00:19:07.730
and then start the session again,
because then they would have

00:19:07.810 --> 00:19:10.310
to pay the penalty for all
the time it takes to stop,

00:19:10.310 --> 00:19:12.570
and then all the time
it takes to restart.

00:19:13.000 --> 00:19:15.560
So instead,
we encourage a model where you

00:19:15.560 --> 00:19:20.250
keep things running all the time,
and then you reconfigure while running.

00:19:20.270 --> 00:19:24.550
And you do that by using begin
configuration and commit configuration,

00:19:24.550 --> 00:19:27.340
which are methods on
the AV Capture session.

00:19:27.340 --> 00:19:28.750
Here's what the code would look like.

00:19:28.760 --> 00:19:32.310
So instead of stopping the
session to remove one camera

00:19:32.310 --> 00:19:36.630
and then add another camera,
you see here I begin configuration,

00:19:36.630 --> 00:19:39.320
then I remove the input
that I don't want,

00:19:39.320 --> 00:19:42.320
add the input that I do want, and commit.

00:19:43.340 --> 00:19:50.480
Only when the last commit pops off the
stack do I get the behavior where it

00:19:50.690 --> 00:19:54.990
performs all of my operations at once.

00:19:56.520 --> 00:19:58.220
Movie recording considerations.

00:19:58.350 --> 00:20:01.590
This is how you do a movie
recording with AV Foundation.

00:20:01.750 --> 00:20:07.400
You initiate a QuickTime movie recording
by supplying a file URL and a delegate.

00:20:07.920 --> 00:20:11.260
And in that recording delegate,
only one method is mandatory.

00:20:11.560 --> 00:20:14.300
You have to tell us what
to do when it finishes.

00:20:14.300 --> 00:20:18.140
So you must implement this
one delegate callback,

00:20:18.190 --> 00:20:22.120
did finish recording
to output file at URL,

00:20:22.120 --> 00:20:26.290
in which you will handle the success
or failure of the movie being recorded.

00:20:27.550 --> 00:20:29.740
This is a new feature in Lion only.

00:20:29.740 --> 00:20:33.500
AV Capture movie file output
supports frame accurate start and

00:20:33.500 --> 00:20:37.710
stop using a new delegate that
does not exist on iOS called the

00:20:37.750 --> 00:20:40.070
AV Capture File Output Delegate.

00:20:40.140 --> 00:20:43.750
This delegate receives frames all
the time when you're recording

00:20:44.140 --> 00:20:45.940
or when you're not recording.

00:20:45.980 --> 00:20:50.780
So every single buffer that would
conceivably be written to the file,

00:20:50.860 --> 00:20:52.450
you get to look at it.

00:20:53.240 --> 00:20:56.600
And so based on this one buffer,
you can look at its metadata

00:20:56.600 --> 00:20:58.940
or process it or figure out,
does this have the time

00:20:58.940 --> 00:21:00.120
code that I'm looking for?

00:21:00.120 --> 00:21:03.480
And start a capture from
within that callback.

00:21:03.540 --> 00:21:07.440
And you are guaranteed to have the movie
start exactly on that frame boundary.

00:21:07.440 --> 00:21:11.750
You can also stop, pause,
or resume within that callback.

00:21:11.820 --> 00:21:16.060
So it is possible to get exactly frame
accurate recordings on frame boundaries.

00:21:20.090 --> 00:21:21.300
It is, of course, optional.

00:21:21.300 --> 00:21:23.760
If you just need a simple start and stop,
you don't need to use

00:21:23.850 --> 00:21:25.950
this delegate method.

00:21:26.760 --> 00:21:30.310
Likewise,
we support pause and resume on Lion.

00:21:30.470 --> 00:21:34.780
You can get the frame accurate behavior
by using that same capture output,

00:21:34.830 --> 00:21:38.990
did output sample buffer from
connection call in which you would call

00:21:39.080 --> 00:21:41.410
pause recording or resume recording.

00:21:41.970 --> 00:21:46.680
You can also set limits with the
AV Capture movie file output.

00:21:46.960 --> 00:21:52.690
Set max recorded duration, file size,
or free disk space limit.

00:21:53.250 --> 00:21:58.010
If you set any of those parameters,
then your callback might be

00:21:58.120 --> 00:22:01.230
called spontaneously when
one of those limits is hit.

00:22:01.770 --> 00:22:03.460
Now you need to take care here.

00:22:03.540 --> 00:22:07.720
If you get an error in your did finish
recording to output file at URL,

00:22:07.720 --> 00:22:11.850
that doesn't necessarily mean
that the file is no good.

00:22:13.020 --> 00:22:14.030
See what I've highlighted here?

00:22:14.110 --> 00:22:17.340
You check the error and its
user info dictionary because it

00:22:17.470 --> 00:22:20.520
will come back with an error if
one of your conditions was met,

00:22:20.600 --> 00:22:24.200
such as the file size limit was exceeded.

00:22:24.470 --> 00:22:26.890
It will tell you that in the error,
but by looking at the

00:22:26.890 --> 00:22:29.900
user info dictionary,
you can find out whether the

00:22:30.440 --> 00:22:32.800
recording finished successfully.

00:22:34.240 --> 00:22:37.240
Early termination conditions
are enumerated here.

00:22:37.390 --> 00:22:39.920
The disk may have filled up,
or a device might have

00:22:39.920 --> 00:22:43.000
gotten disconnected because
someone kicked the cord,

00:22:43.000 --> 00:22:46.130
or duration reached or file size reached.

00:22:46.620 --> 00:22:47.500
Metadata.

00:22:47.580 --> 00:22:51.570
We allow you to insert custom
metadata into your movies,

00:22:51.570 --> 00:22:54.560
and unlike properties that need to be
set before you start the recording,

00:22:54.560 --> 00:23:00.000
you can set movie-level metadata at any
time while the recording is in progress.

00:23:00.000 --> 00:23:03.720
We did this because we recognize
that some metadata is not ready to

00:23:03.720 --> 00:23:07.040
go when you start the recording,
such as GPS location where

00:23:07.140 --> 00:23:08.780
it can be slow to come in.

00:23:09.700 --> 00:23:13.870
So if at any time while
you're recording a movie,

00:23:13.870 --> 00:23:17.740
you set the movie file
output's metadata property,

00:23:17.740 --> 00:23:20.040
it will still wind up in the movie.

00:23:20.250 --> 00:23:21.370
We reserve space for it.

00:23:21.420 --> 00:23:25.680
So there you see I'm setting
the location metadata to a

00:23:25.680 --> 00:23:30.080
given latitude and longitude,
adding it to the metadata array

00:23:30.080 --> 00:23:31.990
and then adding it to the movie.

00:23:32.020 --> 00:23:36.410
Movie fragments are a
really cool technology that

00:23:36.410 --> 00:23:39.170
help with crash protection.

00:23:40.720 --> 00:23:42.360
Here's how we record QuickTime movies.

00:23:42.450 --> 00:23:44.340
Normally a QuickTime movie
that you would find,

00:23:44.370 --> 00:23:46.690
say, on the web will look like this.

00:23:46.810 --> 00:23:49.140
It's got a movie header at the top.

00:23:49.220 --> 00:23:52.830
That's where it has all the
information about samples,

00:23:52.990 --> 00:23:56.010
formats, where they are located
in the rest of the movie.

00:23:56.350 --> 00:23:58.820
And then the big blue
part is the actual data.

00:23:58.940 --> 00:24:02.210
So you need the orange part at the
top to tell you where to find the

00:24:02.270 --> 00:24:04.250
sample offsets in that blue part.

00:24:04.460 --> 00:24:09.140
That's a well-formed,
fast start QuickTime movie.

00:24:09.560 --> 00:24:11.810
For the capture case,
we can't do that because we

00:24:11.820 --> 00:24:14.470
don't know how long the recording
is going to be up front.

00:24:14.480 --> 00:24:18.860
We allow you to start writing
to disk before we know how

00:24:18.860 --> 00:24:20.240
long you're going to record.

00:24:20.240 --> 00:24:24.360
So we actually put the movie header,
in this case a footer,

00:24:24.480 --> 00:24:27.700
at the back of the file and
the movie data is at the front.

00:24:27.720 --> 00:24:29.970
You see the problem
inherent with this strategy.

00:24:29.970 --> 00:24:34.150
If you crash in the middle before we
have a chance to write the movie header,

00:24:34.150 --> 00:24:36.330
you have a big file that's useless.

00:24:37.080 --> 00:24:39.910
So new in AV Foundation,
we have QuickTime movies with

00:24:39.910 --> 00:24:41.790
what's called movie fragments.

00:24:41.790 --> 00:24:44.600
And the default is to
have movie fragments on.

00:24:44.600 --> 00:24:48.870
We write a small header at the top
that accounts for the first N seconds.

00:24:48.870 --> 00:24:50.650
By default, it's 10.

00:24:50.650 --> 00:24:52.980
And then from there on out,
every 10 seconds,

00:24:53.080 --> 00:24:55.940
we'll lay down a movie fragment,
which are those little Fs.

00:24:55.940 --> 00:24:59.940
And they record the information
about the movie up to that point.

00:24:59.950 --> 00:25:03.500
So if at any point you crash,
you're good up to the last point

00:25:03.500 --> 00:25:05.680
where a fragment was written.

00:25:06.790 --> 00:25:09.270
The movie will,
if you have a two hour recording

00:25:09.270 --> 00:25:12.280
and then in two hours and one
minute someone kicks the cord,

00:25:12.320 --> 00:25:13.000
it's still good.

00:25:13.000 --> 00:25:15.190
So do use movie fragments.

00:25:15.190 --> 00:25:16.800
It gives you crash protection.

00:25:16.800 --> 00:25:20.760
And you are able to specify
the movie fragment interval

00:25:21.070 --> 00:25:24.910
at the movie file output.

00:25:25.580 --> 00:25:28.480
Let's move on to our second case,
which is AV Screen Shack,

00:25:28.480 --> 00:25:31.170
capturing the screen
to a QuickTime movie.

00:25:31.490 --> 00:25:35.760
AV Screen Shack is an equally
simple application that does

00:25:36.020 --> 00:25:38.230
little screen recordings.

00:25:38.630 --> 00:25:40.600
Ah, the eternal tunnel.

00:25:40.610 --> 00:25:41.760
I love this.

00:25:41.800 --> 00:25:46.090
This is the video equivalent
of an audio feedback loop.

00:25:46.480 --> 00:25:48.580
Don't look into the tunnel,
it goes back forever.

00:25:48.740 --> 00:25:50.620
You'll never get out.

00:25:52.420 --> 00:25:55.440
Yes, it is sort of like Inception.

00:25:55.560 --> 00:26:00.680
So you can see here that I'm
recording the full screen output.

00:26:00.970 --> 00:26:04.900
As I move the preview around,
you can see what kind of

00:26:04.900 --> 00:26:06.820
latency we're getting,
and that's because I've

00:26:06.820 --> 00:26:09.000
set a max frame rate of 15.

00:26:09.030 --> 00:26:11.700
This app exposes some of the
properties that you can play around

00:26:11.700 --> 00:26:15.500
with with the AV capture screen input.

00:26:15.840 --> 00:26:19.230
I'm going to do a crop rect
here by pushing the set button.

00:26:19.310 --> 00:26:22.450
When I do that, I can specify just a
subsection of the screen.

00:26:22.650 --> 00:26:25.630
I'll select the top left portion.

00:26:25.820 --> 00:26:28.920
And now what I'm going to be recording
is only that little bit there.

00:26:29.060 --> 00:26:31.290
So when I move my mouse around up here,
you'll see I'm just

00:26:31.360 --> 00:26:32.640
recording that section.

00:26:32.830 --> 00:26:37.000
I'm going to go ahead and buck up the
max frame rate to something like 35.

00:26:37.010 --> 00:26:41.760
And I'll say capture mouse clicks
and then push the start button.

00:26:42.040 --> 00:26:45.140
So we see that we are
capturing a movie over here.

00:26:45.170 --> 00:26:48.060
When I go up here and I move it around,

00:26:48.570 --> 00:26:50.870
Or when I click,
you'll see there's a little black

00:26:50.940 --> 00:26:53.540
circle drawn around the mouse.

00:26:53.620 --> 00:26:56.740
That's to indicate that
it's capturing mouse clicks.

00:26:56.810 --> 00:27:02.200
And when I stop, it'll go ahead and open
QuickTime Player and show me

00:27:02.200 --> 00:27:04.240
the movie that I captured.

00:27:04.360 --> 00:27:11.110
And indeed, it did capture a movie
to the specified format,

00:27:11.110 --> 00:27:15.260
and we can see it moving the
window around when it gets there.

00:27:15.260 --> 00:27:18.340
There we go.

00:27:18.540 --> 00:27:19.690
Okay.

00:27:20.100 --> 00:27:22.920
We'll go back to slides
and see how we did that.

00:27:25.260 --> 00:27:27.760
AV Screen Shack starts
with a single input,

00:27:27.760 --> 00:27:30.300
which is the screen.

00:27:30.360 --> 00:27:34.200
It previews the output from it to
a video preview layer and writes

00:27:34.290 --> 00:27:35.370
it out to a QuickTime movie.

00:27:35.540 --> 00:27:40.170
So a very simple application
that's available right now.

00:27:41.050 --> 00:27:43.300
You have instead of a
device with a device input,

00:27:43.300 --> 00:27:46.870
it's just an AV capture
screen input and a movie file

00:27:46.870 --> 00:27:49.440
output and the preview layer.

00:27:50.480 --> 00:27:54.160
So here are some of the features
that you saw me playing around with.

00:27:54.160 --> 00:27:55.480
Fast frame grabbing.

00:27:55.670 --> 00:27:59.930
It supports up to 60 frames
per second on recent hardware.

00:28:00.960 --> 00:28:03.840
It also does efficient color
space conversion to 2VUI

00:28:03.960 --> 00:28:05.060
for video applications.

00:28:05.170 --> 00:28:09.280
So by default,
it will be producing 2VUI data.

00:28:10.080 --> 00:28:19.170
It also respects protected content,
so if you have DRM content

00:28:19.170 --> 00:28:19.170
displaying on the screen,
it knows to black that rectangle out.

00:28:20.950 --> 00:28:22.620
Usage.

00:28:22.690 --> 00:28:26.300
It grabs frames from a
specified CG direct display ID.

00:28:26.300 --> 00:28:28.500
When you create the
AV capture screen input,

00:28:28.500 --> 00:28:30.580
you tell it which display
you want to capture from.

00:28:30.580 --> 00:28:34.580
It does not, however,
support capturing across

00:28:34.580 --> 00:28:36.540
two displays at once.

00:28:37.150 --> 00:28:42.410
You can use setCropRect to specify
just a subsection of the display.

00:28:42.740 --> 00:28:45.870
Set scale factor to capture and scale.

00:28:45.950 --> 00:28:47.840
If you want, say,
the whole screen but you don't

00:28:47.840 --> 00:28:50.920
want a screen-sized movie,
you can scale down and it will

00:28:50.920 --> 00:28:53.000
preserve the aspect ratio.

00:28:53.120 --> 00:28:55.540
You can use set min frame
duration to adjust the max

00:28:55.540 --> 00:28:57.390
frame rate that it will deliver.

00:28:57.400 --> 00:29:01.870
It's not like a capture device where it
has set frame rates that it can support,

00:29:02.010 --> 00:29:05.600
so you need to tell it what
kind of frame rate you want.

00:29:05.730 --> 00:29:08.110
Also,
you can set captures mouse clicks to

00:29:08.110 --> 00:29:10.300
draw a mouse ring around the mouse.

00:29:11.240 --> 00:29:14.420
All right, on to our third case,
which is processing

00:29:14.420 --> 00:29:16.040
frames from the camera.

00:29:16.140 --> 00:29:19.050
And to do this, we're going to use a
demo called Stop and Go.

00:29:19.360 --> 00:29:22.180
OK, Stop and Go.

00:29:22.210 --> 00:29:23.530
I'm actually going to show you code.

00:29:23.620 --> 00:29:25.380
I hope you're not afraid.

00:29:25.400 --> 00:29:27.760
Never done code on stage from Xcode.

00:29:27.890 --> 00:29:29.710
Let's see if it works.

00:29:30.170 --> 00:29:35.540
Stop and Go is an app that
does stop motion animations.

00:29:35.660 --> 00:29:41.580
So first I'll give you a preview
of the UI that we're creating here.

00:29:42.440 --> 00:29:44.920
So we get, again,
a little window that lets

00:29:45.020 --> 00:29:47.850
us start to take a movie.

00:29:50.800 --> 00:29:55.740
And when we start,
it asks us where we want to record it to.

00:29:55.760 --> 00:29:58.800
And then whenever I take a picture,
it's going to record that

00:29:58.800 --> 00:30:00.100
picture into the movie.

00:30:00.220 --> 00:30:02.570
So you can have fun with it like this.

00:30:13.400 --> 00:30:15.570
Stop.

00:30:15.710 --> 00:30:20.930
And then the movie we wind
up with... looks funny.

00:30:21.070 --> 00:30:23.240
Okay, so how did we do that?

00:30:23.310 --> 00:30:27.240
You'd be surprised how few lines
of code it actually requires.

00:30:27.300 --> 00:30:33.550
We set up AV Capture by selecting a
video device and making the input.

00:30:33.940 --> 00:30:35.890
In this case,
I could have chosen video from

00:30:35.890 --> 00:30:38.600
either a MUX input or a video input.

00:30:38.630 --> 00:30:41.670
I said,
choose a device that has the video type

00:30:41.750 --> 00:30:48.250
of input so that we'll only consider
the front-facing FaceTime HD camera.

00:30:48.410 --> 00:30:51.810
And then I made an input for
it and added it to the session.

00:30:52.140 --> 00:30:58.040
Then I created the still image
output and made my preview layer

00:30:58.470 --> 00:31:03.140
Telling it what kind of aspect
ratio to use by setting the video

00:31:03.140 --> 00:31:05.910
gravity and setting the frame.

00:31:06.050 --> 00:31:09.420
and then started the session running.

00:31:09.420 --> 00:31:11.700
That's it for the input side.

00:31:11.700 --> 00:31:14.030
Now,
I'm not capturing to an AVCapture movie

00:31:14.110 --> 00:31:17.640
file output because I want precise
control over when the frames get written.

00:31:17.640 --> 00:31:22.500
I only want a still image
per video frame in the movie.

00:31:22.620 --> 00:31:27.240
So instead, I'm using something called an
asset writer to do the writing.

00:31:27.240 --> 00:31:32.000
The only tricky part of this
application is that I restamp the video.

00:31:32.010 --> 00:31:36.960
When I get each buffer from the still
image output by calling capture still

00:31:37.700 --> 00:31:42.790
image asynchronously from connection,
I get a CM sample buffer

00:31:42.800 --> 00:31:44.720
with the image data in it.

00:31:44.720 --> 00:31:49.560
And it is timestamped with exactly
the time in which it was captured.

00:31:49.830 --> 00:31:52.560
But that's no good for my movie,
which I want to follow along

00:31:52.560 --> 00:31:54.060
on a different timeline.

00:31:54.150 --> 00:32:01.090
So I create a copy of it using CM sample
buffer create copy with new timing,

00:32:01.330 --> 00:32:02.600
which is not a deep copy.

00:32:02.600 --> 00:32:04.640
It's just making a new
wrapper with new timing.

00:32:05.120 --> 00:32:07.420
And I restart the timing at zero.

00:32:07.420 --> 00:32:09.840
And I increment it by whatever
the frame rate is supposed

00:32:09.920 --> 00:32:12.110
to be for the given movie.

00:32:12.160 --> 00:32:17.590
And then I call AV Asset Writer
Append Sample Buffer for each

00:32:17.590 --> 00:32:20.470
video frame that I want to append.

00:32:20.610 --> 00:32:26.270
The rest of the code in the app is
just some tear down of the asset

00:32:26.730 --> 00:32:29.600
writer and the UI to start and stop.

00:32:29.600 --> 00:32:33.600
My kids have been having a field day with
this application over the last few days.

00:32:33.600 --> 00:32:35.600
They're my beta testers.

00:32:35.960 --> 00:32:38.900
Here's one of the movies that they made.

00:32:49.100 --> 00:32:53.160
And here's my favorite.

00:32:53.160 --> 00:32:56.100
You guess whether a boy
or girl did this one.

00:32:56.100 --> 00:33:01.370
Hmm.

00:33:01.370 --> 00:33:06.370
So, fun with stop motion animation.

00:33:13.810 --> 00:33:17.090
Now I think would be an appropriate
time to talk about CM sample buffers

00:33:17.350 --> 00:33:23.300
since we were using one of those
low-level heavy lifting kind of objects.

00:33:23.700 --> 00:33:26.660
CM Sample Buffer, again,
is defined in core media,

00:33:26.660 --> 00:33:29.100
cmsamplebuffer.h.

00:33:29.240 --> 00:33:32.970
It's a reference-counted
core foundation object,

00:33:32.970 --> 00:33:36.580
which contains first and
foremost the sample data.

00:33:36.690 --> 00:33:40.220
If it's an uncompressed video frame,
you can get at that CV pixel

00:33:40.330 --> 00:33:45.000
buffer by calling get image buffer,
CM sample buffer get image buffer.

00:33:45.110 --> 00:33:47.780
And once you have that pixel buffer,
you can lock the base address

00:33:47.840 --> 00:33:52.270
and start actually looking at the
pixels in that CV pixel buffer.

00:33:52.520 --> 00:33:55.590
It also has timing information,
and that's what I was manipulating

00:33:55.600 --> 00:33:57.790
to get the stop motion effect.

00:33:57.960 --> 00:34:02.530
It has every CM sample buffer
has a presentation time,

00:34:02.570 --> 00:34:05.960
and it might optionally have a
decode time if the presentation

00:34:06.030 --> 00:34:08.400
and decode times are different.

00:34:08.470 --> 00:34:10.950
And it might also have a duration.

00:34:11.480 --> 00:34:13.700
And importantly,
it has a format description

00:34:13.700 --> 00:34:14.860
which travels along with it.

00:34:15.060 --> 00:34:19.620
This is another
Core Foundation reference counted object.

00:34:19.780 --> 00:34:23.060
So it's very cool that every buffer
that flows through the system

00:34:23.320 --> 00:34:26.150
always has the format attached
to it in a lightweight fashion.

00:34:26.150 --> 00:34:28.880
It's just a reference count being bumped.

00:34:29.010 --> 00:34:31.850
From that format description,
you can find out things about the video.

00:34:31.860 --> 00:34:34.560
For instance, its dimensions.

00:34:35.320 --> 00:34:39.440
Also traveling along with the sample
buffer will be interesting metadata.

00:34:39.670 --> 00:34:42.820
Metadata about the camera,
processing instructions

00:34:42.820 --> 00:34:46.520
about the CM sample buffer,
and you can attach your own

00:34:46.520 --> 00:34:50.750
metadata to a CM sample buffer
as it travels through a pipeline.

00:34:51.630 --> 00:34:55.440
Let's take an aside for a minute
and talk about output settings.

00:34:55.500 --> 00:34:58.250
Because I want to make it very
clear when and where format

00:34:58.250 --> 00:35:01.900
conversions happen within AV Capture.

00:35:03.050 --> 00:35:08.720
All file and data outputs in
Lion support customized output settings.

00:35:08.970 --> 00:35:10.250
This is something new.

00:35:10.410 --> 00:35:14.170
In iOS,
only the video data output and audio data

00:35:14.170 --> 00:35:20.580
output and still image output allow you
to kind of sort of override the output.

00:35:20.670 --> 00:35:23.200
They'll let you select
a different format.

00:35:23.250 --> 00:35:27.510
But in Lion,
we let you really configure the output.

00:35:28.140 --> 00:35:31.400
By default,
the AV capture session is going

00:35:31.400 --> 00:35:35.500
to determine the baseline output
settings for each output in your graph.

00:35:35.590 --> 00:35:38.570
It does that based on the session
preset that you've selected.

00:35:38.840 --> 00:35:43.420
So for a given session preset, say,
"Hi," it's going to determine that

00:35:43.540 --> 00:35:50.540
that should mean maybe 3.5 megabits
per second H.264 for the video data

00:35:50.540 --> 00:35:53.850
output or for the movie file output.

00:35:54.470 --> 00:35:59.200
You can set custom output settings
on each output to override

00:35:59.200 --> 00:36:02.040
the session's session preset.

00:36:02.460 --> 00:36:05.030
Once you've done that,
those output settings stick.

00:36:05.330 --> 00:36:09.700
So even if you change the capture session
preset or the input device to something

00:36:09.700 --> 00:36:14.690
other than what it was configured for
at the time you set the output settings,

00:36:15.000 --> 00:36:16.140
they will stick.

00:36:16.370 --> 00:36:21.000
So even if you've set a
higher quality on the input,

00:36:21.270 --> 00:36:25.130
we'll do additional format
conversions in order to satisfy what

00:36:25.200 --> 00:36:27.890
your output is currently set for.

00:36:28.350 --> 00:36:31.110
If you want to get pass-through,
you want to get exactly what

00:36:31.210 --> 00:36:34.790
the device is producing,
you can set an empty dictionary

00:36:35.090 --> 00:36:38.280
of output settings on your output.

00:36:39.400 --> 00:36:42.900
And to get back to the session
presets default behavior,

00:36:42.900 --> 00:36:46.650
the baseline,
you can set the output settings to nil.

00:36:46.650 --> 00:36:49.730
And then it will go back and
start choosing by default

00:36:49.730 --> 00:36:51.260
what it thinks is best.

00:36:52.130 --> 00:36:53.650
Here's what video settings look like.

00:36:53.710 --> 00:36:55.880
Again, it's a dictionary-based approach.

00:36:55.900 --> 00:37:00.670
You give it a dictionary of stuff that
you want it to apply to the output.

00:37:01.870 --> 00:37:06.650
You must at least have a video codec
specified or a CV pixel format if

00:37:06.730 --> 00:37:08.130
you're doing an uncompressed format.

00:37:08.230 --> 00:37:10.300
Here I chose H.264.

00:37:10.350 --> 00:37:11.600
You'll want a width and a height.

00:37:11.650 --> 00:37:14.080
Here I'm specifying 720p.

00:37:14.460 --> 00:37:17.350
And then optionally you
can choose to include some

00:37:18.120 --> 00:37:20.100
compressor-specific properties.

00:37:20.150 --> 00:37:21.910
H.264 has many of them.

00:37:22.110 --> 00:37:27.270
Here I chose bit rate to specify
a 10.5 megabits per second and a

00:37:27.270 --> 00:37:31.700
keyframe interval to specify that
I want it to insert keyframes.

00:37:31.710 --> 00:37:34.990
at least every second.

00:37:35.770 --> 00:37:38.860
The next part, the scaling mode,
is something that we're going to

00:37:38.950 --> 00:37:41.740
talk about in a minute in more depth.

00:37:42.130 --> 00:37:44.460
Once you've created your
dictionary of settings,

00:37:44.470 --> 00:37:48.680
you can call your output and say,
"Set output settings," and now you've

00:37:48.680 --> 00:37:51.590
overridden the session's default.

00:37:52.100 --> 00:37:54.970
Let's talk about the supported
video formats in AV Foundation.

00:37:55.050 --> 00:37:59.630
Of course, we support H.264,
which is our canonical compressed

00:37:59.760 --> 00:38:04.380
format for all kinds of applications.

00:38:04.510 --> 00:38:06.910
We also support JPEG.

00:38:07.190 --> 00:38:08.850
and ProRes in two flavors.

00:38:08.860 --> 00:38:13.740
The 44441 is a great format
as a mezzanine format.

00:38:13.740 --> 00:38:17.200
It preserves high bit depth
source up to 12 bits per channel.

00:38:17.200 --> 00:38:23.110
It has a mathematically lossless alpha
channel and does no subsamplings.

00:38:23.120 --> 00:38:26.450
This is a perfect one if you want
smaller files but really no quality loss.

00:38:26.450 --> 00:38:31.740
We also support Apple ProRes 422,
which produces slightly

00:38:31.860 --> 00:38:37.080
smaller files than the 4444,
but does do chroma subsampling.

00:38:37.100 --> 00:38:37.500
sampling.

00:38:39.380 --> 00:38:41.880
We also support lots and
lots of CVPixel formats,

00:38:41.880 --> 00:38:47.290
so pretty much every uncompressed
format that is supported by Core Video.

00:38:48.690 --> 00:38:50.870
Now let's delve into
these video scaling modes.

00:38:50.990 --> 00:38:54.150
This warrants some extra consideration.

00:38:54.560 --> 00:38:58.400
There are four video scaling
modes supported at the output.

00:38:58.540 --> 00:39:00.360
The first one is called Fit.

00:39:00.420 --> 00:39:05.880
It crops the source processing
region and scales down if necessary,

00:39:05.880 --> 00:39:10.190
always preserving aspect ratio,
but it will never ever upscale.

00:39:10.200 --> 00:39:13.130
So this is a good one
to use for like presets.

00:39:13.210 --> 00:39:15.820
If you don't know exactly
what the input is going to be,

00:39:15.820 --> 00:39:18.160
but you want to create a
preset that works across a

00:39:18.180 --> 00:39:21.670
lot of different applications,
the Fit mode is a good one to use.

00:39:22.540 --> 00:39:26.710
It is the default scaling mode for
most of our capture session presets.

00:39:26.960 --> 00:39:28.490
Let me give you a concrete example.

00:39:28.720 --> 00:39:31.130
When you're using the Fit mode,
let's say you're coming from

00:39:31.130 --> 00:39:37.670
a 1280x720 source and you've
specified a 640x640 output box,

00:39:37.670 --> 00:39:40.310
but you've also told it to
use the Fit scaling mode.

00:39:40.320 --> 00:39:44.000
Well, it's going to preserve the
aspect ratio and scale it down

00:39:44.180 --> 00:39:50.480
to fit inside that 640x640 box,
and what you wind up with is 640x360.

00:39:50.480 --> 00:39:57.480
If you have a smaller input source like
320x240 and you specify 640x640 with Fit,

00:39:57.490 --> 00:40:02.470
again, it never does any scaling up,
so you get exactly 320x240.

00:40:02.470 --> 00:40:04.060
This is why it's good for presets.

00:40:04.120 --> 00:40:07.930
If you know you don't want to upscale,
you can use this mode.

00:40:08.580 --> 00:40:13.450
The second one is called the resize mode,
or what I call funhouse mode.

00:40:13.740 --> 00:40:17.780
It crops the source to remove
any edge processing region,

00:40:17.840 --> 00:40:20.440
and then it scales the remainder
to the destination box.

00:40:20.510 --> 00:40:23.680
So it's going to stretch it or squish it,
whatever it has to do

00:40:23.680 --> 00:40:26.860
to fit within the box,
not preserving aspect ratio.

00:40:27.060 --> 00:40:31.770
So again, if we take our guy with the dog
and put him into 640 by 640,

00:40:31.770 --> 00:40:34.730
he's going to get squished.

00:40:35.160 --> 00:40:39.840
Likewise, if we have a 320x240 source,
it will be scaled up and

00:40:39.930 --> 00:40:42.770
also slightly squished.

00:40:43.360 --> 00:40:48.690
If you use the resize aspect mode,
or what I call the letterbox mode,

00:40:48.940 --> 00:40:54.580
it will do aspect ratio preservation
on the source and will fill the

00:40:54.580 --> 00:40:59.300
remainder of the destination box
with black bars if it needs to.

00:40:59.460 --> 00:41:01.300
So let's take our guy again.

00:41:01.300 --> 00:41:04.460
It's going to preserve the aspect ratio,
but it's going to honor that

00:41:04.460 --> 00:41:07.960
640 by 640 box you wanted,
so it's going to put black

00:41:08.020 --> 00:41:09.730
bars on top and bottom.

00:41:10.080 --> 00:41:13.770
Likewise with 320 by 240,
since that doesn't line

00:41:13.770 --> 00:41:15.900
up exactly with a square,
you're going to get some

00:41:15.900 --> 00:41:18.120
black bars on the sides.

00:41:19.250 --> 00:41:24.340
The last one is aspect fill,
or what I call the zoom mode.

00:41:24.380 --> 00:41:27.740
The zoom mode preserves source
aspect ratio while scaling,

00:41:27.800 --> 00:41:32.260
but it really wants to show some video
in the whole box that you've specified.

00:41:32.360 --> 00:41:36.170
So it's going to crop the picture
to fit within the destination box.

00:41:36.390 --> 00:41:40.680
So if the aspect of source and
destination are not exactly equal,

00:41:40.720 --> 00:41:43.860
you're going to lose some
pixels around the edge.

00:41:44.060 --> 00:41:45.540
Here's what I mean by that.

00:41:45.580 --> 00:41:50.440
We're going to see all of that
output box filled with video.

00:41:50.510 --> 00:41:52.590
But since they don't match,
we're going to lose some

00:41:52.780 --> 00:41:55.990
on the sides because it's
going to have to crop it out.

00:41:56.910 --> 00:42:00.630
Likewise,
if we have a 320x240 input source,

00:42:00.630 --> 00:42:05.950
it's going to scale up and make sure that
we see video in every part of the box

00:42:06.040 --> 00:42:09.140
so we lose a little bit on the sides.

00:42:10.710 --> 00:42:15.050
Okay, it's time for our fourth use case,
which is complex graphs,

00:42:15.050 --> 00:42:19.120
capture from multiple video
devices simultaneously.

00:42:19.260 --> 00:42:23.940
And to demo that, I'm going to use an app
called AV Video Wall.

00:42:25.220 --> 00:42:29.600
You might notice something
peculiar about this sample app.

00:42:29.680 --> 00:42:32.100
It's different than all the other
sample apps we've seen up to now

00:42:32.100 --> 00:42:35.590
because it's in all lowercase letters.

00:42:36.750 --> 00:42:40.600
The reason for that is that
it's a command line app.

00:42:40.680 --> 00:42:44.410
And this is another difference
between Lion and iOS.

00:42:44.620 --> 00:42:47.590
AV Foundation has no upward
dependencies on AppKit.

00:42:47.760 --> 00:42:54.600
It is perfectly legal and perfectly
safe to make AV Foundation tools apps,

00:42:54.600 --> 00:42:55.600
command line tools.

00:42:55.600 --> 00:42:58.600
We found it extremely useful to do so.

00:42:58.810 --> 00:43:02.600
And you could also do it for kiosks or
things where you don't really need a UI,

00:43:02.600 --> 00:43:06.090
just some video or some processing.

00:43:06.470 --> 00:43:10.980
AV Video Wall is going to make use of
all the cameras that I have connected.

00:43:11.250 --> 00:43:14.440
I happen to have two cameras connected.

00:43:14.580 --> 00:43:17.480
So when I run it,
it's going to find all the

00:43:17.570 --> 00:43:20.090
cameras that I have connected.

00:43:20.630 --> 00:43:23.590
And it's going to build
a square for each camera,

00:43:23.660 --> 00:43:26.950
and it's going to mirror the previews,
so it's building four previews in

00:43:27.040 --> 00:43:30.640
a square for each input device.

00:43:30.810 --> 00:43:34.380
Maybe I'll point this at something
more interesting like me.

00:43:35.330 --> 00:43:40.110
And once it's got all of
these video preview layers,

00:43:40.110 --> 00:43:44.250
you can press the space bar to
send them flying around the screen.

00:43:44.520 --> 00:43:48.100
So now we're doing mostly
core animation effects here,

00:43:48.100 --> 00:43:50.890
but it is live video,
so you can see I'm still talking,

00:43:50.900 --> 00:43:53.820
I'm still getting the frame
rate that I was before.

00:43:54.040 --> 00:43:57.140
And to send them back home,
you press the spacebar again,

00:43:57.140 --> 00:44:00.340
and then they go back to where
they were supposed to go.

00:44:00.410 --> 00:44:03.710
This is complex because we're
using multiple input sources,

00:44:03.810 --> 00:44:07.720
multiple input devices,
and we're going to multiple outputs.

00:44:07.960 --> 00:44:09.400
So this warrants some consideration.

00:44:09.400 --> 00:44:11.050
How are we doing this?

00:44:11.090 --> 00:44:13.450
Go back to slides.

00:44:16.740 --> 00:44:20.360
The way we're doing this is through
the magic of AV capture connections.

00:44:20.590 --> 00:44:26.390
AV capture connections are the glue
that holds inputs and outputs together.

00:44:26.750 --> 00:44:29.060
I consider this to be
sort of an advanced topic,

00:44:29.060 --> 00:44:33.510
so hang with me and hopefully
it'll all make sense at the end.

00:44:33.950 --> 00:44:37.860
I've shown a lot of slides
today that look like this.

00:44:37.950 --> 00:44:39.740
And this.

00:44:42.480 --> 00:44:44.360
And this.

00:44:44.360 --> 00:44:45.260
And this.

00:44:45.390 --> 00:44:47.540
But what I've neglected to
show you is the thing that's

00:44:47.680 --> 00:44:50.280
holding them all together,
which is these little

00:44:50.340 --> 00:44:51.900
AV capture connections.

00:44:52.100 --> 00:44:56.240
Every arrow that you see on screen
between an input and an output,

00:44:56.290 --> 00:44:59.980
that arrow is represented
by an AV capture connection.

00:45:00.110 --> 00:45:04.510
It describes the connectivity
between an input and an output

00:45:04.510 --> 00:45:06.590
or a video preview layer.

00:45:07.700 --> 00:45:11.930
The purpose of AV Capture
Connections is to,

00:45:12.370 --> 00:45:17.000
again, describe the connectivity
between an input and an output.

00:45:17.610 --> 00:45:22.940
Each AV capture input has an
array of AV capture input ports.

00:45:23.060 --> 00:45:28.440
So an input can give you
more than one type of media.

00:45:28.720 --> 00:45:33.610
An AV Capture connection ties a
specific input port to a specific

00:45:33.730 --> 00:45:37.170
AV Capture output or video preview layer.

00:45:37.830 --> 00:45:42.850
Also, AV capture connections can do neat
things like processing with the video or

00:45:42.850 --> 00:45:45.940
audio data along the way to the output.

00:45:46.070 --> 00:45:50.140
For video, AV capture connections let you
manipulate the video that's delivered

00:45:50.140 --> 00:45:57.490
to the output by either orientation,
so you can rotate the buffers, mirroring,

00:45:57.490 --> 00:46:04.760
so mirror them in the, I guess,
across the vertical plane, deinterlacing,

00:46:04.860 --> 00:46:07.490
or frame rate limiting.

00:46:08.910 --> 00:46:13.500
An audio AV capture connection
lets you manipulate or monitor the

00:46:13.500 --> 00:46:15.720
audio data delivered to the output.

00:46:15.910 --> 00:46:19.520
So this is where you can use your--
you can get audio level meters.

00:46:19.560 --> 00:46:22.080
This is the audio
traveling to the output.

00:46:22.100 --> 00:46:26.180
You can also enable or disable
individual source audio channels.

00:46:26.280 --> 00:46:31.280
So let's say you have a pro audio device
that delivers 24 channels of audio,

00:46:31.310 --> 00:46:34.000
and you only want the first two because
you know that your microphones are only

00:46:34.090 --> 00:46:36.020
plugged into the first two channels.

00:46:36.050 --> 00:46:39.130
You can use the AV capture
connection to disable all but the

00:46:39.220 --> 00:46:42.260
first two source audio channels.

00:46:42.280 --> 00:46:46.290
You can also adjust individual
audio channel levels using

00:46:46.300 --> 00:46:48.450
AV capture connection.

00:46:49.190 --> 00:46:52.880
Here's how you would use it as a status
monitor to do audio level metering.

00:46:53.060 --> 00:46:57.770
You find the connection that you want
and get its audio channels properties.

00:46:57.770 --> 00:47:01.520
And then for each audio channel,
get either its average power

00:47:01.520 --> 00:47:03.740
level or peak hold level.

00:47:03.770 --> 00:47:08.990
The average power levels tend to
jump around and the peak hold levels

00:47:08.990 --> 00:47:12.260
stay at a peak before subsiding.

00:47:14.040 --> 00:47:16.240
Here's how you find an
AV capture connection.

00:47:16.570 --> 00:47:18.900
They're owned by outputs.

00:47:19.030 --> 00:47:23.490
So an AV capture output
implements a connections property.

00:47:25.180 --> 00:47:28.800
So you could, for instance,
call movie file output connections

00:47:28.800 --> 00:47:32.100
to get its list of connections.

00:47:32.100 --> 00:47:34.500
And then once you have the connections,
you can use its properties

00:47:34.560 --> 00:47:36.010
or iterate through them.

00:47:36.110 --> 00:47:41.090
An AV Capture video preview
layer only has one connection.

00:47:42.290 --> 00:47:44.880
Now let's take the case that
I was talking about with multiple

00:47:44.960 --> 00:47:47.300
inputs and multiple outputs.

00:47:47.420 --> 00:47:52.970
The default behavior that AV Capture
uses is to greedily form connections

00:47:53.350 --> 00:47:58.890
implicitly between all eligible
inputs and all eligible outputs.

00:47:59.100 --> 00:48:02.080
So let's say I have a session
with no inputs or outputs,

00:48:02.200 --> 00:48:06.830
and then I add a video data output.

00:48:06.980 --> 00:48:12.020
If I then add a video camera
or a video device input,

00:48:12.340 --> 00:48:15.200
The session will look for
connections that it can form.

00:48:15.200 --> 00:48:19.000
You'll see this guy produces video,
this guy can accept video,

00:48:19.060 --> 00:48:22.100
I'll form a connection
on behalf of the caller.

00:48:22.100 --> 00:48:26.940
So every time you add input or add
output to an AV capture session,

00:48:26.940 --> 00:48:29.610
you're getting an AV capture
connection implicitly.

00:48:29.640 --> 00:48:34.330
Sometimes this breaks down though in
the desktop world where we have more

00:48:34.570 --> 00:48:37.240
complex scenarios than we do in iOS.

00:48:37.980 --> 00:48:40.380
Take this DV camera here.

00:48:40.600 --> 00:48:41.790
This DV camera

00:48:42.790 --> 00:48:48.240
produces a MUXed input stream,
and only once it is housed in

00:48:48.310 --> 00:48:52.240
an AV capture device input can
that MUX stream be separated

00:48:52.240 --> 00:48:54.660
into its component parts.

00:48:55.070 --> 00:48:58.930
Which are video, audio,
and closed captions.

00:48:59.300 --> 00:49:03.190
So if I have multiple
devices and multiple outputs,

00:49:04.000 --> 00:49:06.820
it's not clear what
AV Capture Session should do,

00:49:06.990 --> 00:49:09.800
which input it should try
to tie to which output.

00:49:09.800 --> 00:49:14.440
And in a lot of cases you might
get undesirable results because it

00:49:14.500 --> 00:49:17.440
implicitly tried to make connections
everywhere it could and connected

00:49:17.510 --> 00:49:19.150
the wrong input to the wrong output.

00:49:19.160 --> 00:49:23.470
So for complex situations like the
AV Video wall that I just showed you,

00:49:23.470 --> 00:49:26.390
we have some additional
APIs to help you out.

00:49:26.450 --> 00:49:31.490
Power users can avoid these implicit
connections by calling session

00:49:31.880 --> 00:49:34.400
add input with no connections.

00:49:34.650 --> 00:49:37.350
When you do that,
the input will be added to the session,

00:49:37.350 --> 00:49:40.400
but no implicit connections
are added on your behalf.

00:49:40.700 --> 00:49:45.200
Same goes for add output with
no connections or preview layer

00:49:45.480 --> 00:49:48.310
set session with no connections.

00:49:49.660 --> 00:49:54.480
If you've done that,
the input or output is not going to

00:49:54.480 --> 00:49:59.870
provide any data because there is no
connection describing the connectivity.

00:49:59.990 --> 00:50:03.600
So you're going to have to manually
create a connection between the desired

00:50:03.690 --> 00:50:08.350
input ports and output or preview layer.

00:50:08.510 --> 00:50:10.390
So in summary,

00:50:11.560 --> 00:50:14.760
Use AV Foundation Capture
for all new development.

00:50:14.850 --> 00:50:18.600
If your app is Lion and forward,
you absolutely should

00:50:18.600 --> 00:50:20.580
be using AV Foundation.

00:50:24.420 --> 00:50:27.750
AV Foundation Capture in
Lion provides more features,

00:50:28.030 --> 00:50:33.000
more functionality, new classes that are
specific to the desktop,

00:50:33.570 --> 00:50:38.610
including screen grabbing
and enhanced device control,

00:50:39.750 --> 00:50:43.590
and more flexible output with the
additional kinds of output I described.

00:50:43.600 --> 00:50:48.230
Also supported is
complex session support.

00:50:48.640 --> 00:50:52.730
You can have multiple sessions in
your process or one session with a

00:50:52.730 --> 00:50:55.760
very complex input and output graph.

00:50:56.920 --> 00:50:59.340
For more information,
contact Eric Verschen,

00:50:59.340 --> 00:51:04.810
who is our Media Technologies Evangelist,
and look online for the documentation

00:51:04.810 --> 00:51:07.800
in AV Foundation Programming Guide.

00:51:09.240 --> 00:51:12.010
Also, the developer forums,
devforums.apple.com,

00:51:12.010 --> 00:51:14.290
is a great place to go with questions.

00:51:14.450 --> 00:51:16.940
Sometimes we engineers,
although we're not paid to,

00:51:17.050 --> 00:51:20.610
we do lurk there and we answer
questions from time to time.

00:51:20.860 --> 00:51:23.900
Related sessions have
mostly passed already,

00:51:23.900 --> 00:51:28.480
but they'll be great to watch on
the iTunes feed after the show.

00:51:28.530 --> 00:51:32.410
There is one remaining
iOS-related capture session,

00:51:32.410 --> 00:51:36.320
and that's right after this
one in about 15 minutes.

00:51:36.320 --> 00:51:39.360
We welcome you to stay for that one.

00:51:39.420 --> 00:51:40.340
Thank you for coming.

00:51:40.360 --> 00:51:43.070
I hope you have a great rest of the show.

00:51:45.300 --> 00:51:48.230
And there is one more thing.

00:51:48.480 --> 00:51:52.400
Since we have a couple minutes remaining,
I thought we'd take this opportunity

00:51:52.400 --> 00:51:53.730
to show you something we cooked up.

00:51:53.830 --> 00:51:58.670
The QuickTime team for years and
years had a tradition of making a

00:51:58.670 --> 00:52:02.950
stupid movie that we show at WWDC,
and this year was no different.

00:52:03.100 --> 00:52:06.830
So without further ado,
here is this year's stupid movie.

00:52:25.300 --> 00:52:27.200
Hey everybody, I've got great news!

00:52:27.300 --> 00:52:29.280
What is it this time?

00:52:29.300 --> 00:52:36.170
Our omnomnomnom kitten of the day video
app has just sold a billion copies!

00:52:44.200 --> 00:52:48.510
I was able to buy my 40th car,
but now I need a second

00:52:48.510 --> 00:52:50.200
car to house it in.

00:52:50.580 --> 00:52:56.200
So I have decided that you need
to support our omnomnomnomkitten

00:52:56.200 --> 00:53:00.190
video of the day app,
Back to the Mac.

00:53:00.300 --> 00:53:15.000
[Transcript missing]

00:53:18.580 --> 00:53:20.500
You better get started now.

00:53:20.500 --> 00:53:25.280
Okay, you heard him.

00:53:40.600 --> 00:54:24.100
[Transcript missing]

00:55:02.600 --> 00:56:00.200
[Transcript missing]