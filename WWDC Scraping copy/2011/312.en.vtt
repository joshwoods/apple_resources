WEBVTT

00:00:16.400 --> 00:00:17.100
Hi, everyone.

00:00:17.100 --> 00:00:20.500
I'm Tim Lee from iOS Performance,
and today I'm proud to present to you the

00:00:20.500 --> 00:00:24.490
iOS Performance and Power Optimization
with Instruments session.

00:00:25.190 --> 00:00:28.390
So I just want to start off and
say that performance and power are

00:00:28.390 --> 00:00:31.840
extremely important to everyone at
Apple and hopefully everybody here.

00:00:31.840 --> 00:00:33.890
I probably am preaching
to the choir here.

00:00:33.900 --> 00:00:37.840
But these are two major features,
and we treat them as such,

00:00:37.840 --> 00:00:41.470
of our entire platform and
every app that we work on.

00:00:41.480 --> 00:00:44.130
They're a key aspect
of app store reviews.

00:00:44.160 --> 00:00:47.530
There are a lot of times when you go
through your app reviews and you see

00:00:47.620 --> 00:00:51.620
X and Y crashed on launch or something,
or it eats a lot of memory.

00:00:51.620 --> 00:00:53.580
And hopefully we'll deal with that today.

00:00:54.200 --> 00:00:56.990
You have the tools available
to you to fix these problems.

00:00:57.000 --> 00:00:59.870
You might not know it,
but by the end of this session,

00:01:00.020 --> 00:01:01.960
hopefully you'll have some idea.

00:01:01.960 --> 00:01:04.680
And to get more,
there's lots of resources available.

00:01:04.680 --> 00:01:08.810
But today in this session,
we're going to cover a couple of common

00:01:08.810 --> 00:01:12.730
cases and some general strategies
that you can use to optimize both

00:01:12.870 --> 00:01:15.680
power and performance of your apps.

00:01:17.300 --> 00:01:19.030
So an overview of what
you're going to learn.

00:01:19.100 --> 00:01:24.790
Two big main areas are, number one,
and the big takeaway is to

00:01:24.900 --> 00:01:29.410
how to measure the performance
of key aspects of your app.

00:01:29.580 --> 00:01:31.300
And measurement is king of the game.

00:01:31.300 --> 00:01:33.900
If you can measure
precisely and accurately,

00:01:33.930 --> 00:01:36.640
it makes your job 10 times easier.

00:01:36.860 --> 00:01:38.920
And the second part,
which you probably is

00:01:39.010 --> 00:01:42.810
why you're all here,
is how to improve key scenarios.

00:01:43.080 --> 00:01:48.010
So we're going to talk about a few that
apply to pretty much every app available.

00:01:48.260 --> 00:01:51.320
So the first is speedy interaction,
making sure that when the

00:01:51.360 --> 00:01:55.220
user is using the app,
it feels magical and there's no delays

00:01:55.220 --> 00:01:56.600
or waiting or anything like that.

00:01:56.600 --> 00:01:59.610
Everything moves along with the touch.

00:01:59.640 --> 00:02:02.280
The second is a slim memory footprint.

00:02:02.450 --> 00:02:08.140
We are still on very constrained devices,
and the key is to make

00:02:08.140 --> 00:02:10.320
them not feel that way.

00:02:10.320 --> 00:02:12.200
And in order to do that,
it takes some work.

00:02:12.360 --> 00:02:14.740
So we'll talk about how to
keep the memory footprint down,

00:02:14.760 --> 00:02:21.220
making multitasking feel great,
and your app will do the same.

00:02:21.270 --> 00:02:25.260
And finally,
we're going to have some tips about how

00:02:25.260 --> 00:02:30.240
to use the network and battery-specific
or power specific optimization,

00:02:30.240 --> 00:02:35.590
some tips and tricks that you can use to
effectively use the network and battery.

00:02:36.270 --> 00:02:40.020
So we're going to start off with, again,
number one, the big takeaway,

00:02:40.020 --> 00:02:42.210
measuring performance.

00:02:42.270 --> 00:02:46.530
And the big one here is to not guess.

00:02:46.720 --> 00:02:47.850
We do this all the time.

00:02:48.020 --> 00:02:48.880
We start writing some code.

00:02:48.880 --> 00:02:51.180
Maybe you design, oh,
I have this brilliant algorithm.

00:02:51.250 --> 00:02:54.180
And I know it's going to be slow here,
or my app is going to suck over here,

00:02:54.180 --> 00:02:56.660
but I'm going to have to
spend a lot of time on it.

00:02:56.710 --> 00:02:58.320
You're almost always wrong.

00:02:58.440 --> 00:02:59.630
We do this all the time.

00:02:59.640 --> 00:03:03.480
And I can let you know,
the first thing that everybody

00:03:03.480 --> 00:03:06.770
should do is to take measurements.

00:03:07.210 --> 00:03:10.980
And once you do that,
you will be surprised

00:03:11.120 --> 00:03:12.610
at where things are.

00:03:12.720 --> 00:03:17.190
And sometimes the optimization just
fall out immediately when the part that

00:03:17.370 --> 00:03:21.390
you thought was slow is actually fast,
and the part that you thought was

00:03:21.390 --> 00:03:23.500
fast is slow and is easy to fix.

00:03:23.500 --> 00:03:25.780
That's the ideal case.

00:03:27.260 --> 00:03:31.160
And even after you do that,
sometimes maybe you took a

00:03:31.200 --> 00:03:34.200
measurement in a way that was not

00:03:34.300 --> 00:03:46.700
[Transcript missing]

00:03:47.600 --> 00:03:49.750
In the end,
it's all about how the app feels.

00:03:49.960 --> 00:03:55.880
So measure, don't guess,
and use your app.

00:03:57.260 --> 00:04:01.100
Now we're going to focus
on individual scenarios.

00:04:01.150 --> 00:04:03.160
It's really hard to just
take a whole app and say,

00:04:03.160 --> 00:04:04.620
I'm going to optimize this whole thing.

00:04:04.680 --> 00:04:09.220
I'm just going to go through and line
by line go through and fix stuff.

00:04:09.300 --> 00:04:11.420
What you want to do is look
at key interaction points,

00:04:11.540 --> 00:04:15.700
key places where the user will
really notice your effort.

00:04:15.750 --> 00:04:18.540
Maybe when you're pushing a
new navigation controller on or

00:04:18.540 --> 00:04:22.860
when your app first launches,
when you switch tabs.

00:04:22.910 --> 00:04:24.600
These key individual interactions.

00:04:24.600 --> 00:04:26.390
It also makes it easier
for you to measure.

00:04:26.470 --> 00:04:28.410
Again, back to the key point.

00:04:28.540 --> 00:04:30.480
So you measure a single interaction.

00:04:30.530 --> 00:04:32.300
You make a code change.

00:04:32.300 --> 00:04:34.700
And then you measure again
to make sure what you think

00:04:35.020 --> 00:04:37.000
you fixed was actually fixed.

00:04:37.120 --> 00:04:39.750
So focus on key scenarios.

00:04:40.010 --> 00:04:44.620
And finally, in the strategy section,
focus on making sure that you

00:04:44.620 --> 00:04:45.660
have a realistic data set.

00:04:45.700 --> 00:04:49.700
We spend a pretty reasonable,
or maybe unreasonable amount of time,

00:04:49.700 --> 00:04:53.350
making sure that internally we
test with big photo libraries,

00:04:53.500 --> 00:04:58.930
big music libraries,
and various Wi-Fi cell characteristics,

00:04:59.020 --> 00:05:00.620
and you should definitely do the same.

00:05:00.700 --> 00:05:03.670
Your app will behave very
differently when it's loaded

00:05:03.670 --> 00:05:05.170
up with a lot of content.

00:05:05.240 --> 00:05:07.580
So make sure that you put on
some realistic content when

00:05:07.580 --> 00:05:08.880
you're testing your apps.

00:05:09.960 --> 00:05:12.110
On top of that,
you want to make sure you test with

00:05:12.400 --> 00:05:14.290
the devices that you plan to support.

00:05:14.400 --> 00:05:17.530
Now, I'm assuming a lot of people here
have the latest and greatest,

00:05:17.740 --> 00:05:20.030
but I know that not all of our users do.

00:05:20.320 --> 00:05:23.910
So on top of actually testing on
devices and not just in the simulator,

00:05:24.200 --> 00:05:28.090
make sure to test on the older
devices that you plan to support.

00:05:29.360 --> 00:05:31.200
All right, on to tools.

00:05:31.220 --> 00:05:34.530
So the ways that are available to you
to actually do these measurements.

00:05:34.540 --> 00:05:36.330
Number one is instruments.

00:05:36.360 --> 00:05:38.990
First thing I do whenever
I get a performance problem,

00:05:39.000 --> 00:05:41.160
fire up instruments, take a trace.

00:05:41.160 --> 00:05:45.450
And after that, if there are more issues,
and I've dug in a little bit,

00:05:45.680 --> 00:05:47.660
then there are some other
options that are available.

00:05:47.660 --> 00:05:54.160
There's the old standby, there's logging,
and there are cases where it's useful.

00:05:54.580 --> 00:05:58.450
You'll NSLog, say,
particular instances that

00:05:58.450 --> 00:06:01.450
maybe are very infrequent,
so they would be hard

00:06:01.550 --> 00:06:04.100
to find in a big trace,
or happen a lot, and you want to see,

00:06:04.100 --> 00:06:06.220
you know,
maybe there's a weird distribution

00:06:06.220 --> 00:06:07.340
that you want to graph.

00:06:07.440 --> 00:06:09.500
Use NSLog for that.

00:06:09.560 --> 00:06:12.950
And if you're going to
do a lot of logging,

00:06:12.950 --> 00:06:14.630
you know...

00:06:43.090 --> 00:06:43.110
So, if you're going to be
logging while scrolling,

00:06:43.110 --> 00:06:43.110
you want to be doing that to a file.

00:06:43.110 --> 00:06:43.110
Now, NSLog is great,
but it does do a lot of things for you.

00:06:43.110 --> 00:06:43.110
So,
there is some overhead incurred there.

00:06:43.110 --> 00:06:43.110
So,
if you're going to do a lot of logging,

00:06:43.110 --> 00:06:43.110
try logging to a file and take
some of that overhead off.

00:06:43.110 --> 00:06:43.110
And finally, you want to make it very,
very easy, if you have to resort to this,

00:06:43.110 --> 00:06:43.110
to turn it off.

00:06:43.110 --> 00:06:43.110
You can use pound define,
environment variables, user defaults,

00:06:43.110 --> 00:06:43.110
whatever you want.

00:06:43.110 --> 00:06:43.110
But make it really easy so that
when you build for release,

00:06:43.110 --> 00:06:43.110
it's gone.

00:06:44.520 --> 00:06:45.750
Now, a quick note about the simulator.

00:06:45.930 --> 00:06:49.470
It's really handy for development,
but it's completely useless,

00:06:49.620 --> 00:06:52.910
completely useless for performance.

00:06:53.080 --> 00:06:53.860
For speed.

00:06:54.240 --> 00:06:55.870
For memory, it's actually pretty good.

00:06:56.210 --> 00:06:59.400
So if you want to run leaks, allocations,
those sorts of things,

00:06:59.520 --> 00:07:00.990
you can do that on the simulator.

00:07:01.150 --> 00:07:05.050
But for anything that's time sensitive,
completely separate,

00:07:05.320 --> 00:07:06.770
run it on your device.

00:07:09.060 --> 00:07:13.530
Now, one other way to do
measurements is side by side.

00:07:14.000 --> 00:07:17.040
I'm assuming most people
have more than one device.

00:07:17.040 --> 00:07:22.340
An interesting way to go here
is that if you make some change,

00:07:22.340 --> 00:07:25.530
you might think,
maybe this doesn't quite look

00:07:25.950 --> 00:07:30.120
right or maybe it doesn't
behave as well as it used to.

00:07:30.120 --> 00:07:31.760
But it's a lot faster.

00:07:31.800 --> 00:07:33.250
Well, do a blind test.

00:07:33.260 --> 00:07:34.980
Do a side by side test with somebody.

00:07:35.070 --> 00:07:37.510
Give them a version of the old code,
a version of the new code,

00:07:37.510 --> 00:07:39.240
and have them play with it.

00:07:39.260 --> 00:07:42.160
And if the old is the same as the new,
you know, in terms of visual

00:07:42.160 --> 00:07:45.560
fidelity and everything,
then you're good to go.

00:07:47.290 --> 00:07:49.260
All right,
so let's talk a little bit about

00:07:49.620 --> 00:07:52.190
what we-- some general strategies
for improving performance.

00:07:52.300 --> 00:07:55.000
And we're going to start with
speed and responsiveness.

00:07:55.610 --> 00:07:59.130
So the importance of speed
and responsiveness shouldn't,

00:07:59.150 --> 00:08:00.250
you know,
I really shouldn't have to say this,

00:08:00.380 --> 00:08:03.140
but slow performance
is no good for anybody.

00:08:03.140 --> 00:08:05.380
And, you know, we go to some length.

00:08:05.440 --> 00:08:11.570
We have this system called the Watchdog
to make sure that a stray non-performant

00:08:11.570 --> 00:08:14.530
app doesn't take down the entire system.

00:08:14.540 --> 00:08:16.160
So we call this the Watchdog.

00:08:16.320 --> 00:08:19.420
And what it does is in some
key app lifecycle cases,

00:08:19.420 --> 00:08:21.880
if the app takes too long to, say,
launch,

00:08:21.880 --> 00:08:26.270
then the app will be terminated so that
the user can continue to use their phone.

00:08:26.280 --> 00:08:31.070
Now, the times here are for iOS 5,
and they are subject to change.

00:08:31.080 --> 00:08:34.350
They're also extremely conservative.

00:08:34.360 --> 00:08:37.780
I don't think anybody wants to wait
20 seconds for an app to launch.

00:08:37.780 --> 00:08:41.350
I start hitting the home
button once it's at 5 seconds.

00:08:41.420 --> 00:08:45.460
So don't take these as guidelines
for times to shoot for.

00:08:45.780 --> 00:08:48.480
So for launch or resume,
really one second or so is

00:08:48.540 --> 00:08:50.070
what you want to shoot for.

00:08:50.080 --> 00:08:54.320
And then the other key scenario,
smooth scrolling.

00:08:54.320 --> 00:08:55.870
We hear it all the time.

00:08:55.880 --> 00:08:58.030
What's iOS good at?

00:08:58.090 --> 00:08:59.990
What do we have that
everybody else doesn't?

00:09:00.000 --> 00:09:03.060
We have the smooth scrolling,
and we need everybody to work on it.

00:09:03.060 --> 00:09:04.660
We know it's not easy,
and there are lots of

00:09:04.660 --> 00:09:07.100
techniques available to you,
and we're here to help you

00:09:07.250 --> 00:09:08.760
to get that smooth scrolling.

00:09:08.760 --> 00:09:10.000
Hit that 60 frames a second.

00:09:12.400 --> 00:09:16.520
All right, so some general strategies
for improving speed.

00:09:16.580 --> 00:09:19.960
So the first one is to do less work.

00:09:19.960 --> 00:09:23.620
We see all the time that when
somebody loads up an app,

00:09:23.620 --> 00:09:27.500
a lot of apps just load
a lot of data at launch.

00:09:27.500 --> 00:09:32.160
Maybe they were testing with small
data sets and didn't anticipate it,

00:09:32.330 --> 00:09:37.190
but they might load the whole database
to show a table view that has 10 rows.

00:09:37.210 --> 00:09:38.340
Don't do that.

00:09:38.340 --> 00:09:40.080
You don't have to do that.

00:09:40.080 --> 00:09:44.180
Only load as much as you need to
show the next screen to the user.

00:09:44.180 --> 00:09:46.140
And this correlates very
much with the next one,

00:09:46.140 --> 00:09:48.360
which is to do work later.

00:09:48.360 --> 00:09:50.140
You can load as much
as you want right now,

00:09:50.140 --> 00:09:53.740
and then later,
when the user requests another

00:09:53.740 --> 00:09:59.690
screen or selects some detail view,
then fetch it and do whatever processing.

00:09:59.900 --> 00:10:02.360
And the third general
category is to do work faster,

00:10:02.360 --> 00:10:06.000
the one that's actually hard, right?

00:10:06.000 --> 00:10:11.340
And the name of the game here is to get
the most bang for your developer buck.

00:10:11.340 --> 00:10:15.780
Focus your energies on the
parts that are slowest first.

00:10:15.780 --> 00:10:17.810
And in the case that, you know,
there's just some

00:10:17.810 --> 00:10:20.570
inherently complex problem,
you're running some fancy algorithm

00:10:20.970 --> 00:10:22.680
and it's just going to take a while.

00:10:22.680 --> 00:10:26.390
Well, in that case, put a placeholder,
let the user continue to use your app

00:10:26.390 --> 00:10:28.540
in some way until that work is done.

00:10:28.540 --> 00:10:30.640
Do that work in the background.

00:10:33.960 --> 00:10:34.900
On to memory.

00:10:34.900 --> 00:10:39.700
So memory is now a pretty big deal now
that we added multitasking last year.

00:10:39.700 --> 00:10:45.460
And we need every app to do its fair
share to make the system behave well.

00:10:45.460 --> 00:10:49.170
So analogous to the WatchDoc system,
we have something called Jetsam.

00:10:49.200 --> 00:10:50.760
It's been around for a while.

00:10:50.760 --> 00:10:53.150
And what it does is it watches
around -- looks around the

00:10:53.150 --> 00:10:55.030
system for memory pressure.

00:10:55.030 --> 00:10:59.670
So it'll terminate, you know,
background apps and apps that are

00:10:59.920 --> 00:11:03.650
-- that are -- have been suspended
and not used for a while in order

00:11:03.650 --> 00:11:08.300
to provide more memory for the app
that the user is currently using.

00:11:08.300 --> 00:11:10.000
So this is Jetsam.

00:11:10.000 --> 00:11:12.730
It'll also, if necessary,
terminate the frontmost app if

00:11:12.730 --> 00:11:14.740
it's gone wildly out of control.

00:11:14.830 --> 00:11:17.020
So you really want to avoid
dealing with this thing.

00:11:17.230 --> 00:11:20.490
Hopefully,
you -- you just never hear about it.

00:11:20.680 --> 00:11:27.380
Additional benefit of keeping memory
down is that larger suspended apps in

00:11:27.380 --> 00:11:29.220
general are going to be jets on first.

00:11:29.370 --> 00:11:33.140
If I need a lot of memory for Safari,
I'm not going to go around

00:11:33.140 --> 00:11:37.370
killing a bunch of 10K apps,
if they were that small,

00:11:37.460 --> 00:11:40.190
as opposed to one 60 megabyte app.

00:11:40.530 --> 00:11:41.720
There's just no benefit.

00:11:41.780 --> 00:11:45.160
So if you keep yourself small,
then you'll stick around in memory.

00:11:45.160 --> 00:11:47.210
And so when the user
comes back to your app,

00:11:47.210 --> 00:11:48.700
it'll be quick and snappy.

00:11:48.700 --> 00:11:50.040
It won't have to start
from scratch again.

00:11:51.340 --> 00:11:55.300
New to iOS 5 is a new
revamped Jetsam system.

00:11:55.300 --> 00:12:00.330
We've taken feedback over the past
year and we've revamped the system

00:12:00.590 --> 00:12:04.500
such that memory warnings are really
now your last chance to save yourself.

00:12:04.560 --> 00:12:06.750
What that means is when
you get a memory warning,

00:12:06.750 --> 00:12:09.460
there are no more apps
available to terminate.

00:12:09.460 --> 00:12:13.250
So if nothing is done,
your app is going to be terminated.

00:12:13.490 --> 00:12:16.250
So be sure to respond to
memory warnings in iOS 5.

00:12:18.730 --> 00:12:21.800
All right,
so some key areas to focus on when

00:12:21.800 --> 00:12:24.990
you're debugging memory problems.

00:12:25.260 --> 00:12:26.410
Spikes.

00:12:26.460 --> 00:12:29.410
So a spike is when,
in a very brief period of time,

00:12:29.410 --> 00:12:33.290
less than one turn of the run loop,
so a very brief period of time,

00:12:33.290 --> 00:12:37.090
you allocate a bunch
of objects immediately.

00:12:37.100 --> 00:12:41.100
Generally this happens when you're
processing a large amount of data.

00:12:41.100 --> 00:12:43.940
You've downloaded a big chunk from
the network and you're doing some

00:12:43.940 --> 00:12:45.100
bunch of work on it to display.

00:12:45.100 --> 00:12:51.100
And, you know, it's pretty easy to
get caught up in this.

00:12:51.100 --> 00:12:54.100
It's a pretty simple fix, though,
which is good.

00:12:54.100 --> 00:12:59.100
All you need to do is break up your work
into small independent batches so that,

00:12:59.100 --> 00:13:01.100
you know,
you process the batch and the memory

00:13:01.100 --> 00:13:04.210
that you used for the processing you
can use again for the next batch over

00:13:04.210 --> 00:13:05.100
and over and over until you're done.

00:13:05.100 --> 00:13:08.660
I'll emphasize again that
if there's a lot of this,

00:13:08.660 --> 00:13:11.690
you do want to do this in the background.

00:13:12.350 --> 00:13:18.860
And another thing that contributes
to this is auto-release objects.

00:13:18.860 --> 00:13:23.570
You don't necessarily have complete
control over this all the time.

00:13:23.600 --> 00:13:27.760
So you want to be very careful about
these things and try to reduce the object

00:13:27.890 --> 00:13:30.340
lifetime of these auto-release objects.

00:13:30.400 --> 00:13:33.600
Now, I know a lot of people might
not know exactly what they are.

00:13:33.600 --> 00:13:34.400
They're new to the platform.

00:13:34.400 --> 00:13:36.320
So I'm going to talk a little
bit about what that really means.

00:13:36.410 --> 00:13:37.200
What is auto-release?

00:13:37.200 --> 00:13:39.030
Now, we've heard this before.

00:13:39.260 --> 00:13:39.820
Auto-release.

00:13:40.000 --> 00:13:43.200
It's used to avoid worrying
about retain and release.

00:13:43.200 --> 00:13:46.040
There's this, you know,
retain and release systems, Objective-C,

00:13:46.390 --> 00:13:46.900
what is this?

00:13:46.900 --> 00:13:48.290
Auto-release fixes my problems.

00:13:48.300 --> 00:13:51.700
That's not really a great
way to think about it.

00:13:51.700 --> 00:13:53.970
Really, the way to think about it,
and it's not too complicated,

00:13:53.970 --> 00:13:56.190
is it's a way for frameworks, you know,
the stuff Apple provides

00:13:56.200 --> 00:13:58.860
or a third party provides,
to manage object ownership.

00:13:59.000 --> 00:14:02.270
And I'll show you what that means
by comparing and contrasting it

00:14:02.270 --> 00:14:05.390
a little bit with the regular
retain and release system.

00:14:05.530 --> 00:14:09.100
So we've got... regular
retain and release.

00:14:09.100 --> 00:14:13.100
So, let's say we have our app,
and it asks for an object.

00:14:13.120 --> 00:14:16.200
You know, it does alloc init,
and we get our object,

00:14:16.510 --> 00:14:17.860
and it calls retain on it.

00:14:18.300 --> 00:14:21.100
So, now the app owns the object.

00:14:21.100 --> 00:14:25.100
Now, now that it owns it,
it is responsible for releasing it.

00:14:25.120 --> 00:14:28.230
So, you know, sometime later,
the app is done with the object,

00:14:28.230 --> 00:14:29.590
and it calls release.

00:14:29.830 --> 00:14:31.100
Object goes away.

00:14:31.100 --> 00:14:31.570
We're all in the clear.

00:14:31.770 --> 00:14:34.530
Memory's back in a good place.

00:14:34.910 --> 00:14:36.460
So how does auto-release work?

00:14:36.540 --> 00:14:41.030
So in the auto-release case,
it asks a framework for an object.

00:14:41.250 --> 00:14:44.120
So you'll see the telltale
sign is the object name.

00:14:44.140 --> 00:14:49.320
So NSArrayArray, NSStringStringWith,
or NSStringWhatever.

00:14:49.320 --> 00:14:54.010
And so the framework will make
an object and put it on this

00:14:54.270 --> 00:14:58.970
auto-release pool to release,
because it doesn't know when

00:14:58.970 --> 00:15:01.140
your app is done with it.

00:15:01.140 --> 00:15:06.870
And so your app has this non-owning
relationship with the object,

00:15:07.060 --> 00:15:08.050
unless you call retain on it.

00:15:08.120 --> 00:15:10.320
If you call retain on it,
then you'll get another solid line,

00:15:10.320 --> 00:15:12.300
and you're responsible
for calling release on it.

00:15:12.430 --> 00:15:14.150
But in this case,
only the auto-release has

00:15:14.220 --> 00:15:16.320
that owning relationship.

00:15:16.320 --> 00:15:20.120
And so sometime later,
your app is done with the object.

00:15:20.160 --> 00:15:23.680
Doesn't call release on it,
because it didn't call retain.

00:15:23.710 --> 00:15:25.350
Doesn't own the object.

00:15:25.430 --> 00:15:28.620
But the auto-release
pool will call release.

00:15:28.630 --> 00:15:30.920
And from there, the object goes away.

00:15:33.070 --> 00:15:38.330
Now, the problem here is that before the
auto-release pool does its thing,

00:15:38.330 --> 00:15:41.930
in the meantime, your app could have
allocated a few more objects,

00:15:42.070 --> 00:15:44.950
and this is a very common
source of memory spikes.

00:15:45.040 --> 00:15:51.440
Now, the new Arc system alleviates this
problem quite a bit by doing some tricks

00:15:51.440 --> 00:15:54.690
under the hood with object lifetime.

00:15:55.340 --> 00:15:59.320
But in case you haven't done that,
or in the case that it hasn't

00:15:59.320 --> 00:16:02.220
fully solved the problem,
the way around this is to use

00:16:02.220 --> 00:16:03.400
a nested auto-release pool.

00:16:03.400 --> 00:16:04.110
And what does that mean?

00:16:04.160 --> 00:16:07.050
That's basically when you make
your own NS auto-release pool,

00:16:07.070 --> 00:16:09.140
or use the new at
auto-release pool syntax,

00:16:09.140 --> 00:16:13.490
and that will attach any new object
that you create onto that pool.

00:16:13.500 --> 00:16:16.520
And then when you call drain,
or when you hit the end of that block,

00:16:16.520 --> 00:16:18.540
then all those objects will be released.

00:16:18.560 --> 00:16:22.900
So you can control the lifetime of
these objects with these nested pools.

00:16:24.450 --> 00:16:26.900
So that's spikes and auto-release pools.

00:16:26.920 --> 00:16:29.460
So the next big category
of memory is leaks.

00:16:29.460 --> 00:16:31.260
We've all heard about leaks.

00:16:31.260 --> 00:16:33.740
There's a whole
instrument named after it.

00:16:33.740 --> 00:16:35.480
And what it is, it's pretty simple.

00:16:35.480 --> 00:16:38.760
It's you've allocated some memory,
you used it, and then you just don't have

00:16:38.760 --> 00:16:39.920
a pointer to it anymore.

00:16:39.920 --> 00:16:41.900
You have no way of touching it.

00:16:41.950 --> 00:16:45.150
So it's completely gone,
and it's just taking up memory.

00:16:45.180 --> 00:16:46.220
And leaks is pretty smart.

00:16:46.220 --> 00:16:50.020
It can scan memory for these things.

00:16:50.040 --> 00:16:55.060
And it'll tell you where
these objects were allocated.

00:16:55.140 --> 00:16:57.900
So it doesn't know when it's
supposed to be released.

00:16:57.900 --> 00:16:59.680
It can't really read your mind.

00:16:59.680 --> 00:17:02.440
But it'll provide you context
for where to look in your code,

00:17:02.450 --> 00:17:05.250
for where the appropriate section
of code is to do the release.

00:17:05.270 --> 00:17:09.780
And the common mistakes with using
it is just retaining an extra

00:17:09.780 --> 00:17:11.680
time without a balanced release.

00:17:11.700 --> 00:17:13.860
So in the traditional system,
for every retain,

00:17:13.860 --> 00:17:16.210
you should have a release.

00:17:16.340 --> 00:17:20.570
The other very common leak is to-- uh

00:17:22.720 --> 00:17:26.090
Forget to release a property when
you're setting a new one on a setter.

00:17:26.580 --> 00:17:29.730
And so, you know,
these are things to look out for.

00:17:29.740 --> 00:17:31.820
Now,
Arc largely removes this problem as well.

00:17:32.070 --> 00:17:35.180
You're not even allowed to
call retain and release.

00:17:35.710 --> 00:17:39.700
There is some exception in
pure C frameworks for Graphics,

00:17:39.700 --> 00:17:40.720
AV Foundation, et cetera.

00:17:40.720 --> 00:17:43.100
But in general,
Arc will make this problem

00:17:43.100 --> 00:17:44.060
a lot harder to hit.

00:17:44.120 --> 00:17:46.440
So more incentive to convert.

00:17:46.440 --> 00:17:48.980
And finally,
the last category is abandoned memory.

00:17:49.000 --> 00:17:51.840
So abandoned memory is similar
to leaks in that you have memory

00:17:51.840 --> 00:17:55.380
that you allocated and used,
and you're not going to use it anymore.

00:17:55.380 --> 00:17:57.530
The only difference is you
still have a pointer to it.

00:17:57.580 --> 00:18:00.320
So in theory,
you could still access it and use it.

00:18:00.400 --> 00:18:02.720
This is a little bit trickier.

00:18:02.720 --> 00:18:06.330
Leaks, you can obviously go look around
and see what's residing out there,

00:18:06.330 --> 00:18:06.930
and nobody's touching it.

00:18:06.980 --> 00:18:09.740
In abandoned memory,
it's really up to the

00:18:09.740 --> 00:18:13.230
individual developer to know
what data is no longer used.

00:18:13.320 --> 00:18:18.930
And the way we generally find it is to,
you know, start from some baseline,

00:18:18.930 --> 00:18:22.230
do some interaction,
maybe go into the detail of a

00:18:22.300 --> 00:18:25.270
table view and come back out,
and then do a diff to see,

00:18:25.440 --> 00:18:26.870
is my memory state the same?

00:18:27.020 --> 00:18:30.240
So we have allocations and keep shot,
and you can take two snapshots.

00:18:30.320 --> 00:18:33.240
So you take a snapshot, go in and out,
take another snapshot.

00:18:33.380 --> 00:18:35.810
And memory should be about the same,
because you're looking at the same view.

00:18:35.820 --> 00:18:38.760
If there's stuff left over from
what you were doing in the meantime,

00:18:38.880 --> 00:18:41.580
that's probably abandoned memory,
and you want to go and look for a

00:18:41.580 --> 00:18:43.290
place where you can do a release on it.

00:18:43.300 --> 00:18:47.470
Unfortunately, Arc doesn't help you here,
because it doesn't know

00:18:47.550 --> 00:18:49.530
what stuff is available.

00:18:49.540 --> 00:18:52.740
What you want to be doing here,
is nilling out references to stuff

00:18:52.740 --> 00:18:53.800
you're not going to be using anymore.

00:18:53.800 --> 00:18:56.180
All right.

00:18:56.180 --> 00:18:59.290
So I'm going to demo a
couple of the instruments.

00:19:00.360 --> 00:19:07.200
So last year, at a similar talk,
we demoed an app called Compositions.

00:19:07.200 --> 00:19:12.930
And this time-- whoops.

00:19:15.500 --> 00:22:07.300
[Transcript missing]

00:22:07.460 --> 00:22:13.760
The next trace I'm going to show you
is a problem with a slow launch time.

00:22:13.760 --> 00:22:17.720
So when I first added the face detection,
there was a problem where

00:22:17.820 --> 00:22:20.720
after I launched up and
did all the face detection,

00:22:20.740 --> 00:22:22.840
it would just take a really
long time before it kicked in.

00:22:22.890 --> 00:22:24.600
And I wanted to see what was going on.

00:22:24.720 --> 00:22:26.600
So I took, again, time profile.

00:22:26.610 --> 00:22:28.050
And this is what showed up.

00:22:29.520 --> 00:22:32.030
So once again,
I go back into the CPU strategy view,

00:22:32.030 --> 00:22:34.060
because that's pretty much what I do.

00:22:34.060 --> 00:22:35.070
That's just step number one.

00:22:35.140 --> 00:22:37.580
And wow, look at that.

00:22:37.650 --> 00:22:43.240
This looks like a big waste of time,
right?

00:22:43.320 --> 00:22:44.720
Half our time is unused.

00:22:44.780 --> 00:22:48.540
So we can, if we're so interested,
we can drill in here.

00:22:48.540 --> 00:22:53.790
Another good time to show a new feature,
or a feature associated with this.

00:22:53.890 --> 00:22:54.740
We have the sample list.

00:22:54.780 --> 00:22:58.130
So what the sample list does
is it lets you pick some time.

00:22:58.140 --> 00:22:59.500
So I'm going to zoom in here
by holding down the arrow.

00:22:59.520 --> 00:23:01.220
shift.

00:23:01.600 --> 00:23:03.760
Let's see, let's pick one over here.

00:23:03.780 --> 00:23:04.620
Pick some time.

00:23:04.800 --> 00:23:08.940
And if you pick a certain sample,
you'll see the highlight.

00:23:08.960 --> 00:23:11.900
It'll take you to the
sample down in this list.

00:23:11.950 --> 00:23:15.360
And over in the detail view on the side,
which you access over here,

00:23:15.420 --> 00:23:18.720
you'll see the backtrace
of what your code is doing,

00:23:18.720 --> 00:23:19.760
so that's fantastic.

00:23:19.870 --> 00:23:23.680
What I usually do is I can go
and see what's taking a lot of

00:23:23.720 --> 00:23:25.000
time at certain periods of time.

00:23:25.000 --> 00:23:27.610
You can see what happened first,
what happened second.

00:23:27.670 --> 00:23:28.350
So this is fantastic.

00:23:28.360 --> 00:23:30.140
You can walk through a timeline.

00:23:30.190 --> 00:23:34.170
And so in this case,
you can see here I was spending a lot of

00:23:34.170 --> 00:23:38.360
time generating composition thumbnails,
and one quarter time.

00:23:38.360 --> 00:23:41.640
It's the same call here and down here.

00:23:41.660 --> 00:23:45.310
All right,
so what does a good case look like?

00:23:46.820 --> 00:23:47.170
Here we go.

00:23:47.280 --> 00:23:49.140
This looks more or less the same,
a bunch of purple.

00:23:49.140 --> 00:23:50.470
Go back.

00:23:50.830 --> 00:23:51.800
CPU Strategy.

00:23:51.970 --> 00:23:53.200
Always remember that one.

00:23:53.330 --> 00:23:54.470
And now we've got a good case.

00:23:54.470 --> 00:23:58.040
This is what you want to be
shooting for on an iPad 2.

00:23:58.040 --> 00:24:01.980
You want to see a big block of blue
when you're doing batch processing.

00:24:01.980 --> 00:24:04.580
And you can go in again,
go to the sample list,

00:24:04.580 --> 00:24:07.110
make sure you're doing the right thing.

00:24:07.110 --> 00:24:11.620
If you have multiple operations going on,
make sure that the priorities are right.

00:24:11.630 --> 00:24:12.790
You can look here.

00:24:14.060 --> 00:24:16.890
So that's it for CPU Strategy.

00:24:16.940 --> 00:24:20.920
And this is the one tool
that I use the most.

00:24:20.920 --> 00:24:22.720
So just remember to use this.

00:24:22.720 --> 00:24:24.970
It'll tell you exactly
what your app is doing.

00:24:27.120 --> 00:24:32.240
And finally,
I'm going to hop over to the memory side.

00:24:32.380 --> 00:24:33.630
So these we've had around for a while.

00:24:33.740 --> 00:24:35.840
We've called allocations, VMTracker,
and leaks.

00:24:35.840 --> 00:24:39.520
I put a custom template together
to run all three at the same time.

00:24:39.550 --> 00:24:44.960
And this is a profile of
the memory usage of the app.

00:24:44.980 --> 00:24:49.260
And I was seeing actually some
jetsamming as I was launching the app.

00:24:49.300 --> 00:24:51.970
Actually, what happened was a little
bit after launching the app,

00:24:51.970 --> 00:24:52.730
it would jetsam.

00:24:52.990 --> 00:24:54.470
So I took a memory trace.

00:24:54.660 --> 00:24:56.060
And this is what comes up.

00:24:56.100 --> 00:24:59.130
And this is somewhat-- it's kind of cool.

00:24:59.210 --> 00:24:59.940
It's kind of pretty.

00:24:59.950 --> 00:25:03.280
But it's not clear how
to interpret this thing.

00:25:03.330 --> 00:25:06.790
So I'm going to give you a few tips here.

00:25:07.040 --> 00:25:09.640
What I usually do is--this
is a statistics view,

00:25:09.640 --> 00:25:10.160
right?

00:25:10.240 --> 00:25:14.190
I'm gonna switch this and
switch to the object list.

00:25:14.600 --> 00:25:18.420
What I'm going to do
here is sort by size.

00:25:18.460 --> 00:25:21.840
After I sort by size,
I can look at the biggest things here.

00:25:21.880 --> 00:25:26.040
And I can see these
things are taking 45K.

00:25:26.040 --> 00:25:30.440
And a lot of time and a lot
of objects in face core light.

00:25:30.440 --> 00:25:33.080
I'm assuming you can
guess what that means.

00:25:33.110 --> 00:25:37.050
And actually what happened here--
I can show you in the detail

00:25:37.640 --> 00:25:40.090
view-- what happened here--

00:25:41.250 --> 00:25:46.210
is we have this CI phase score
detector in it with context.

00:25:46.300 --> 00:26:20.500
[Transcript missing]

00:26:20.760 --> 00:26:23.460
I'm going to show a few other
features while I'm here.

00:26:23.460 --> 00:26:26.670
Leaks, like I said, very, very simple.

00:26:26.750 --> 00:26:28.460
There's all these things that leaked.

00:26:28.460 --> 00:26:28.850
What were they?

00:26:28.870 --> 00:26:29.900
Oh, what do you know?

00:26:30.050 --> 00:26:31.730
CG objects.

00:26:31.900 --> 00:26:34.770
So these are not Objective-C.

00:26:34.770 --> 00:26:38.910
You call CG bitmap context create,
and you get a CG image,

00:26:38.910 --> 00:26:41.020
you have to call CG image release.

00:26:41.120 --> 00:26:43.120
And Arc doesn't do that for you.

00:26:43.260 --> 00:26:45.470
It really only covers
Objective-C retain and release.

00:26:45.640 --> 00:26:48.480
So this is how you can still get leaks.

00:26:48.670 --> 00:26:49.620
And it's very easy to find.

00:26:49.640 --> 00:26:52.230
You go over here,
you can see in my colorized

00:26:52.300 --> 00:26:55.810
image with color call,
I didn't release.

00:26:55.950 --> 00:26:57.900
So I go in there and I add the release.

00:26:57.940 --> 00:27:00.110
And finally, VM Tracker.

00:27:00.330 --> 00:27:04.060
So VM Tracker is great for knowing
overall how much memory is my app using

00:27:04.480 --> 00:27:06.770
and the numbers you want to focus on.

00:27:07.260 --> 00:27:08.500
Dirty.

00:27:08.520 --> 00:27:10.100
Dirty resident.

00:27:10.120 --> 00:27:13.010
What that is,
is memory that your app is using that

00:27:13.010 --> 00:27:15.100
the system can't reclaim if it needs it.

00:27:15.310 --> 00:27:19.510
So this is the number you
really want to target.

00:27:19.510 --> 00:27:19.510
And...

00:27:20.150 --> 00:27:25.100
You can break down and look
at the different regions here.

00:27:25.100 --> 00:27:27.140
And there's a lot of stuff to learn here.

00:27:27.140 --> 00:27:29.170
And actually,
there's a whole talk-- well,

00:27:29.290 --> 00:27:31.760
part of a talk that covers this
tomorrow at the exact same time.

00:27:31.860 --> 00:27:34.900
So if you want to know more about this,
come back tomorrow for this one.

00:27:35.190 --> 00:27:37.560
But what you want to
focus on is resident,

00:27:37.560 --> 00:27:39.100
and in particular, dirty resident.

00:27:39.170 --> 00:27:40.950
Now you can see here
there's some other things,

00:27:41.070 --> 00:27:43.630
CG image, which I was leaking.

00:27:43.730 --> 00:27:45.480
This makes a lot of sense.

00:27:45.550 --> 00:27:48.300
In this view, you won't get backtraces
like you do in the other two.

00:27:48.360 --> 00:27:50.640
But it'll give you a good idea of
overall how much your app is using.

00:27:50.640 --> 00:27:56.370
And rule of thumb, if you're using 100
megabytes of memory resident,

00:27:56.370 --> 00:27:58.300
that's way too much.

00:27:58.300 --> 00:28:03.160
So that's going to be a problem,
even on an iPad 2 or an iPhone 4.

00:28:03.700 --> 00:28:04.700
All right.

00:28:04.810 --> 00:28:06.880
So that's it for the demo.

00:28:19.130 --> 00:28:20.020
All right, so to review.

00:28:20.020 --> 00:28:23.780
For speed and responsiveness,
we have the system watchdog that

00:28:23.780 --> 00:28:26.730
will terminate your app if it's
not behaving well at key points.

00:28:26.820 --> 00:28:32.050
The overall strategies for speed
and responsiveness are to do less,

00:28:32.050 --> 00:28:34.220
do later, and do faster.

00:28:34.220 --> 00:28:35.490
The hard one.

00:28:35.540 --> 00:28:38.750
Do slow operations in the
background with placeholders,

00:28:38.750 --> 00:28:42.970
and spend your time where it matters,
on the things that are the slowest.

00:28:43.020 --> 00:28:45.070
It sounds obvious,
but a lot of times you might think, oh,

00:28:45.070 --> 00:28:46.710
do something fancy to
speed up this thing.

00:28:46.730 --> 00:28:47.460
Don't do that.

00:28:47.620 --> 00:28:48.750
Just work on the stuff that's slow.

00:28:49.000 --> 00:28:53.000
And finally, at launch,
the most important time,

00:28:53.000 --> 00:28:58.100
the first time somebody uses your app,
only load what you need at launch.

00:28:58.550 --> 00:29:01.600
And on the memory side,
the three big categories: spikes, leaks,

00:29:01.600 --> 00:29:02.380
abandonments.

00:29:02.560 --> 00:29:04.360
You might not remember the
details about all of them.

00:29:04.560 --> 00:29:06.490
Slides will be available.

00:29:06.770 --> 00:29:10.150
Jetsam will terminate your app,
just like the watchdog will.

00:29:10.230 --> 00:29:14.370
New in iOS 5,
memory warnings are your last chance.

00:29:14.430 --> 00:29:16.160
I just demoed some of the
instruments that are available.

00:29:16.160 --> 00:29:18.560
If you want some more help,
there's going to be labs tomorrow,

00:29:18.560 --> 00:29:21.720
and there's plenty of
developer documentation.

00:29:21.880 --> 00:29:26.130
The big one for spikes is to add
the nested auto-release pool.

00:29:26.140 --> 00:29:30.240
And finally, it's really not that hard,
convert to using Arc.

00:29:30.250 --> 00:29:33.800
It's very simple,
and it'll save you a lot of trouble.

00:29:33.870 --> 00:29:37.050
And with that,
I'm going to hand it off to Chad to

00:29:37.050 --> 00:29:39.580
talk about networking and power.

00:29:45.820 --> 00:29:47.500
Thanks, Tim.

00:29:47.590 --> 00:29:48.360
My name's Chad Woolf.

00:29:48.430 --> 00:29:50.670
I'm a Performance Tools Engineer for
Apple.

00:29:50.670 --> 00:29:53.700
And I'm going to talk to you guys now
about networking and power optimizations.

00:29:53.700 --> 00:29:56.970
Now, a lot of times when we think
about performance optimization,

00:29:56.970 --> 00:29:58.190
we think about speed.

00:29:58.270 --> 00:30:00.140
How do we make our code faster, right?

00:30:00.140 --> 00:30:04.230
And speed is a really important part of
our user experience for applications,

00:30:04.330 --> 00:30:04.900
right?

00:30:04.900 --> 00:30:08.560
But there's another important
part of the user experience,

00:30:08.560 --> 00:30:09.750
and that's battery life.

00:30:09.950 --> 00:30:13.570
It's not often that the two
are optimized at the same time.

00:30:13.700 --> 00:30:17.300
And so we really want to talk about
optimizing now for battery life.

00:30:17.400 --> 00:30:21.670
So really performance optimization
is about optimizing for efficiency.

00:30:21.920 --> 00:30:26.950
And faster code is usually better,
but it's also better on battery life.

00:30:27.560 --> 00:30:30.540
So when we look at network
and power optimizations,

00:30:30.540 --> 00:30:33.740
you're going to notice here that all
of the networking optimizations that

00:30:33.740 --> 00:30:36.960
I'm going to recommend today also have
a positive impact on battery life,

00:30:36.960 --> 00:30:38.630
meaning that they reduce power.

00:30:38.640 --> 00:30:41.100
So here's what we're going to talk
about in the second half of our session.

00:30:41.220 --> 00:30:43.860
First, we're going to talk about reducing
network traffic and bursting.

00:30:43.860 --> 00:30:45.360
Those are two networking topics.

00:30:45.360 --> 00:30:48.270
We're also going to talk
about core location accuracy,

00:30:48.270 --> 00:30:50.420
sleep/wake, and dynamic frame rates.

00:30:50.420 --> 00:30:52.740
And those will all help you save energy.

00:30:53.170 --> 00:30:56.360
So let's talk about that first one,
reducing network traffic.

00:30:56.390 --> 00:31:00.340
Now aside from reducing the
amount of drain on your battery

00:31:00.340 --> 00:31:03.110
for sending the network traffic,
reducing network traffic also

00:31:03.200 --> 00:31:04.420
has a couple of key benefits.

00:31:04.460 --> 00:31:07.620
First, it reduces network congestion,
and that makes everybody's

00:31:07.620 --> 00:31:09.920
networking applications,
including your own,

00:31:09.920 --> 00:31:11.720
run much smoother and much faster.

00:31:12.730 --> 00:31:14.780
But there's also a dollars
and cents argument here,

00:31:14.780 --> 00:31:17.300
because a lot of our customers
are actually paying by the

00:31:17.300 --> 00:31:19.370
byte for their data plans,
right?

00:31:19.450 --> 00:31:22.410
So if you're actually able to reduce
the amount of network traffic that

00:31:22.530 --> 00:31:25.480
your application is producing,
then you can actually save them a few

00:31:25.480 --> 00:31:27.410
dollars every month on their bill,
right?

00:31:29.110 --> 00:31:30.880
All right, but how do we measure traffic,
right?

00:31:30.880 --> 00:31:34.960
We have our happy application
over here on the left.

00:31:34.960 --> 00:31:39.580
And he's made a bunch of network
connections out there to the servers.

00:31:39.580 --> 00:31:41.920
But the key here is
always to measure first,

00:31:42.040 --> 00:31:42.540
right?

00:31:42.540 --> 00:31:44.380
So how do we measure network traffic?

00:31:44.380 --> 00:31:48.280
How do we go on about looking at which
connections our application's making,

00:31:48.280 --> 00:31:51.320
where they're going,
how much data's flowing to and from the

00:31:51.350 --> 00:31:54.700
server that they're being connected to,
and what's the health and

00:31:54.710 --> 00:31:56.450
status of these connections?

00:31:56.460 --> 00:31:58.970
Are they having any
retransmission problems?

00:31:59.000 --> 00:32:01.210
Or what's the average round trip times?

00:32:01.360 --> 00:32:02.680
That type of thing, right?

00:32:02.730 --> 00:32:05.510
We also might want to know,
is our application doing more

00:32:05.910 --> 00:32:07.460
networking in the beginning?

00:32:07.500 --> 00:32:08.600
Or is it maybe in the middle?

00:32:08.600 --> 00:32:12.100
Or is it maybe towards the end
here when we start to talk about

00:32:12.100 --> 00:32:14.110
switching out or multitasking,
right?

00:32:14.210 --> 00:32:18.920
Well, in iOS 5, we have a new instrument,
which we hope can shed

00:32:18.920 --> 00:32:20.200
some light on that for us.

00:32:20.200 --> 00:32:22.680
It's called the
Network Connections Instrument,

00:32:22.680 --> 00:32:25.270
and it basically does
everything I just said.

00:32:25.280 --> 00:32:28.650
It measures data volume,
it works for TCP IP,

00:32:28.770 --> 00:32:31.940
and it also works for UDP IP ports
if you have those open,

00:32:31.940 --> 00:32:34.120
and it collects those
important performance metrics

00:32:34.120 --> 00:32:35.400
that I wanted to talk about.

00:32:35.400 --> 00:32:37.740
Now,
let me show you that in a quick demo.

00:32:37.740 --> 00:32:41.740
Of course, I'm not going to commit the
cardinal sin here of trying to do

00:32:41.740 --> 00:32:44.000
a network demonstration at WWDC.

00:32:44.100 --> 00:32:45.450
Okay?

00:32:46.590 --> 00:32:48.990
But I do have a trace that
I recorded a little bit earlier

00:32:48.990 --> 00:32:53.470
in the week at the office.

00:32:53.720 --> 00:32:57.890
And it was on an application
out there that's demo code,

00:32:57.890 --> 00:33:00.020
or it's example code
on developer.apple.com,

00:33:00.020 --> 00:33:01.230
which you can get.

00:33:01.380 --> 00:33:02.440
It's called Lazy Table.

00:33:02.440 --> 00:33:05.690
And what it does is it shows you
how to use placeholder images and

00:33:05.690 --> 00:33:07.870
lazily load data over a network.

00:33:07.870 --> 00:33:14.230
It's actually a very good application,
and it's fairly well optimized.

00:33:14.230 --> 00:33:16.190
So it's a good target here for the
network connections instrument to see

00:33:16.190 --> 00:33:16.190
if we can find out any more about it.

00:33:16.370 --> 00:33:18.920
Now, if we go over here to our
network connections track,

00:33:19.040 --> 00:33:22.820
you'll see along the time axis,
these are periods of network activity.

00:33:22.820 --> 00:33:25.990
So you can see we have a little
bit more activity in the beginning.

00:33:25.990 --> 00:33:27.660
Let me zoom in here for you.

00:33:27.670 --> 00:33:30.900
And then we have some network activity
trailing out a little bit later.

00:33:30.950 --> 00:33:34.650
So we can see their application is doing
different things at different times.

00:33:35.140 --> 00:33:39.140
Now, here in the details view,
we also have some information.

00:33:39.140 --> 00:33:43.770
And this is the total,
all the connections and how much

00:33:43.770 --> 00:33:46.640
data they've sent and received
and to which IP address and port.

00:33:46.640 --> 00:33:48.340
So that's a lot of really
important information.

00:33:48.340 --> 00:33:50.850
Now, if you want to look
at just one bump here,

00:33:51.030 --> 00:33:54.180
you can hold down the option
key and select a time filter.

00:33:54.250 --> 00:33:57.620
And that will show you only the
network connections that were

00:33:57.740 --> 00:34:01.880
active and only the data totals
that were sent during that interval.

00:34:01.880 --> 00:34:05.020
So here we can see that we sent 11k.

00:34:05.140 --> 00:34:07.890
Or sorry,
we received 11k over eight packets.

00:34:07.940 --> 00:34:11.150
We sent 247 bytes with one packet.

00:34:11.220 --> 00:34:14.790
And some of those interesting
statistics like duplicate data,

00:34:14.790 --> 00:34:18.230
out of order retransmissions,
and the round trip times

00:34:18.230 --> 00:34:19.820
are also calculated here.

00:34:19.820 --> 00:34:24.170
So you can maybe use this information to
help troubleshoot your latency issues.

00:34:24.180 --> 00:34:28.840
So now that we have a fair
understanding of our data,

00:34:28.840 --> 00:34:32.530
sorry, of our application with this data,
let's talk about some of the

00:34:32.530 --> 00:34:34.320
optimizations that we can make.

00:34:35.140 --> 00:34:38.340
So let's talk about some of the
optimizations that we can make

00:34:38.460 --> 00:34:40.260
for network traffic reduction.

00:34:41.330 --> 00:34:45.140
All right, so the first one,
the big one here, is caching content.

00:34:45.260 --> 00:34:47.800
If you're using our URL loading
system in Foundation,

00:34:47.800 --> 00:34:50.700
you're going to get caching for free,
and it's on by default.

00:34:50.700 --> 00:34:55.580
So if you're using the URL loading
system to pull URLs from an HTTP server,

00:34:55.730 --> 00:34:59.530
it gets even better,
because the HTTP server can tell the

00:34:59.650 --> 00:35:04.540
cache which responses can I cache
and how long can I cache them for.

00:35:04.540 --> 00:35:06.730
And that's a lot of benefit,
and that's a lot of code

00:35:06.730 --> 00:35:08.060
that you don't have to write.

00:35:08.060 --> 00:35:10.910
And that can really seriously
reduce your network traffic.

00:35:11.300 --> 00:35:12.800
If you use it effectively.

00:35:12.930 --> 00:35:16.080
So that's the URL loading system.

00:35:16.080 --> 00:35:21.210
Now, the NSURLCache object,
which we had in iOS 4,

00:35:21.210 --> 00:35:24.580
used to cache things only in memory.

00:35:24.580 --> 00:35:26.700
So all of the responses
were cached in memory.

00:35:26.780 --> 00:35:29.580
When your application was terminated
and then you started it again,

00:35:29.630 --> 00:35:31.740
you were starting from a clean slate.

00:35:31.800 --> 00:35:37.130
But in iOS 5, we now have persistence,
which means that all that cached data --

00:35:37.760 --> 00:35:40.800
I'll be sure to pass that on.

00:35:40.800 --> 00:35:43.870
All of that cache data will be loaded
next time you load your application.

00:35:43.880 --> 00:35:45.940
And that's also on by default now.

00:35:46.060 --> 00:35:49.450
So you'll see a lot of network
applications just respond a little bit

00:35:49.770 --> 00:35:52.090
better not starting with a clean slate.

00:35:52.300 --> 00:35:54.090
All right,
the next topic here for reducing

00:35:54.090 --> 00:35:55.710
network traffic is compression.

00:35:55.960 --> 00:35:58.030
If you're starting with
your own network protocols,

00:35:58.030 --> 00:36:00.760
try to pick the most compact
data formats you can.

00:36:00.760 --> 00:36:05.620
And I would tend to prefer data
formats that are inherently compressed,

00:36:05.710 --> 00:36:09.160
such as MP3 or JPEG,
something that's inherently

00:36:09.160 --> 00:36:10.860
compressed like that.

00:36:10.860 --> 00:36:13.820
Now, if you're transferring data
that's not inherently compressed,

00:36:13.840 --> 00:36:17.920
like plain text or XML,
I would suggest maybe

00:36:17.960 --> 00:36:20.940
zipping it up on the server,
sending it over to your application,

00:36:21.060 --> 00:36:24.270
expanding it,
sending the reply also in a zip format.

00:36:24.530 --> 00:36:29.060
Try to use compression the best you
can to reduce your network traffic.

00:36:29.810 --> 00:36:32.540
Actually, there's one more thing.

00:36:32.550 --> 00:36:35.400
Not that kind of one more thing.

00:36:35.400 --> 00:36:40.400
And that's reducing--so if you're
downloading images over the web,

00:36:40.420 --> 00:36:45.050
try to pick the URL that has the
closest image size of pictures

00:36:45.170 --> 00:36:47.040
to the one that you need,
right?

00:36:47.040 --> 00:36:50.620
If you download the big
one and then scale it,

00:36:50.620 --> 00:36:54.110
you're essentially wasting a lot of time,
energy, and money transferring this

00:36:54.110 --> 00:36:54.110
data and then just scaling it.

00:36:55.340 --> 00:36:59.490
Now, the next one for reducing network
traffic is resumable transfers.

00:36:59.730 --> 00:37:03.300
On a mobile device,
we call it network connection volatility.

00:37:03.300 --> 00:37:04.700
It's a fact of life.

00:37:04.760 --> 00:37:07.360
When you move from
Wi-Fi hotspot to Wi-Fi hotspot,

00:37:07.360 --> 00:37:10.500
you'll be breaking connection
and reforming another one.

00:37:10.500 --> 00:37:11.930
You're going to get a
different IP address.

00:37:11.930 --> 00:37:14.790
Any sort of long-term running
transfers that you're executing,

00:37:14.790 --> 00:37:16.060
well, they'll be severed.

00:37:16.060 --> 00:37:17.730
The connections will be severed.

00:37:17.740 --> 00:37:18.740
Right?

00:37:18.740 --> 00:37:19.680
Also happens with cellular networks.

00:37:19.780 --> 00:37:22.090
When the user goes into an
elevator and the doors close

00:37:22.090 --> 00:37:25.480
or they enter a parking garage,
something like that,

00:37:25.490 --> 00:37:26.300
it'll break the connection.

00:37:26.300 --> 00:37:28.840
Now, if you're building your
own transfer protocols,

00:37:28.910 --> 00:37:30.660
make sure you support
resumable transfers.

00:37:30.660 --> 00:37:33.530
Do not try the big download
all the way from the beginning.

00:37:33.530 --> 00:37:34.580
Not a great idea.

00:37:34.580 --> 00:37:37.130
If you're using HTTP,
there's a range header.

00:37:37.130 --> 00:37:39.990
There's a field in the header
of the request that you can

00:37:40.100 --> 00:37:41.570
put a range specification.

00:37:41.570 --> 00:37:44.700
You can range extract the bytes
you need so you can continue a

00:37:44.700 --> 00:37:46.680
download if you're using HTTP.

00:37:46.680 --> 00:37:47.420
HTTP.

00:37:47.480 --> 00:37:51.040
Most servers will honor that.

00:37:51.720 --> 00:37:53.590
All right,
now the last one here for reducing

00:37:53.700 --> 00:37:55.820
network traffic is download profiling.

00:37:55.820 --> 00:37:59.610
Now, this is a little bit more abstract,
but the idea here is that you want

00:38:00.080 --> 00:38:04.580
to take your application and look
at the amount of data that's coming

00:38:04.580 --> 00:38:07.970
over through your network connections
and also track how much of that

00:38:07.970 --> 00:38:11.490
content that you've downloaded is
actually being viewed by your users.

00:38:11.490 --> 00:38:15.010
You might create logging and
send those statistics back,

00:38:15.140 --> 00:38:18.940
or you might be able to even look
at your server logs and see how many

00:38:18.940 --> 00:38:21.570
times you've had canceled transfers.

00:38:21.600 --> 00:38:25.710
So if you have some preview content
and you realize that 90% of your users

00:38:25.800 --> 00:38:29.080
are only getting through the first
third of the content before they cancel

00:38:29.080 --> 00:38:31.390
it and move on or make a purchase,
something like that,

00:38:31.460 --> 00:38:34.860
then you can actually make some
optimizations and only send that first

00:38:34.870 --> 00:38:38.780
third instead of sending a whole bunch
of bytes that aren't going to be used.

00:38:38.810 --> 00:38:41.170
So that's just something to
take home and think about.

00:38:41.180 --> 00:38:43.740
So reducing traffic, in summary,
measure first.

00:38:43.740 --> 00:38:46.590
We have a network connections
instrument for that now.

00:38:46.600 --> 00:38:50.300
Cache content when available,
when possible,

00:38:50.300 --> 00:38:51.580
and the NSURO loading system.

00:38:51.580 --> 00:38:57.770
It has some great advantages there,
and now we support persistence in iOS 5.

00:38:57.800 --> 00:39:02.000
Compress when possible,
resumable transfers, fact of life,

00:39:02.090 --> 00:39:03.980
you definitely need to support
them in your own protocols,

00:39:03.980 --> 00:39:08.340
and try to download only what's
statistically likely to be used.

00:39:10.070 --> 00:39:13.090
All right, next optimization, Bursting.

00:39:13.310 --> 00:39:15.900
Bursting is also network optimization.

00:39:15.900 --> 00:39:18.950
And the idea here is that
we take all the data that we

00:39:18.950 --> 00:39:21.870
want to send in one big block,
we send it,

00:39:22.050 --> 00:39:24.310
and we wait for a period of time,
and then we send the

00:39:24.310 --> 00:39:25.580
next big transaction.

00:39:25.660 --> 00:39:29.260
So period of activity, period of silence,
period of activity.

00:39:29.260 --> 00:39:30.260
That's Bursting.

00:39:30.490 --> 00:39:32.800
Now why do we do that?

00:39:32.800 --> 00:39:35.910
We do that primarily for energy reasons.

00:39:35.910 --> 00:39:35.910
And let me explain why.

00:39:36.060 --> 00:39:39.280
Sending and receiving data on
a cellular network requires a

00:39:39.280 --> 00:39:40.600
significant amount of energy.

00:39:40.600 --> 00:39:42.650
You can probably imagine.

00:39:42.890 --> 00:39:45.960
But beyond that,
when you use a cellular radio,

00:39:46.030 --> 00:39:49.340
the radio has to stay in a high power
state after that last byte of data that

00:39:49.340 --> 00:39:51.080
you transmitted for up to 10 seconds.

00:39:51.160 --> 00:39:55.000
And even if you only
send one byte after that,

00:39:55.060 --> 00:39:57.930
you're going to be resetting that timer
and it'll have to stay in a high power

00:39:58.080 --> 00:40:00.040
state for another potentially 10 seconds.

00:40:00.040 --> 00:40:02.410
So imagine this graphically.

00:40:02.420 --> 00:40:06.710
Here we have this area in yellow as
the energy it takes to send your data.

00:40:06.720 --> 00:40:10.400
Now after you finish sending your data,
the radio is still in that high power

00:40:10.400 --> 00:40:12.260
state before it comes back down.

00:40:12.510 --> 00:40:13.620
Now it's still consuming energy.

00:40:13.620 --> 00:40:17.530
Now you can think of this red as waste
because we're actually sending data,

00:40:17.530 --> 00:40:18.660
but we're consuming energy.

00:40:18.660 --> 00:40:23.330
Now if you send small bytes of data,
you can see exactly the effect.

00:40:23.400 --> 00:40:26.650
We have lots of waste and actually
very little data being sent.

00:40:28.590 --> 00:40:32.000
So how do we go about measuring bursting?

00:40:32.100 --> 00:40:35.110
Well, last year we introduced the
Energy Diagnostics template,

00:40:35.140 --> 00:40:37.670
and it was a major step in
the right direction here.

00:40:37.790 --> 00:40:40.260
Because we could measure the
energy coming from our battery,

00:40:40.260 --> 00:40:42.440
we could see different
statistics about our CPU,

00:40:42.500 --> 00:40:43.640
what they were doing.

00:40:43.640 --> 00:40:46.800
We could also see power states
of GPS and different radios.

00:40:47.600 --> 00:40:49.560
But this year,
we wanted to add the network

00:40:49.560 --> 00:40:51.390
activity instrument to that template.

00:40:51.550 --> 00:40:54.030
So now, in addition to these
various radio states,

00:40:54.030 --> 00:40:56.320
you can actually--or
various power states,

00:40:56.320 --> 00:40:59.420
you can actually see how many
bytes were being sent over your

00:40:59.420 --> 00:41:02.640
Wi-Fi and cellular interfaces,
along with your power data,

00:41:02.640 --> 00:41:05.390
and you can make those
correlations yourself.

00:41:07.200 --> 00:41:13.100
[Transcript missing]

00:41:13.380 --> 00:41:15.680
Possible slide malfunction here.

00:41:15.690 --> 00:41:18.860
Or I hit the wrong button,
which is totally possible.

00:41:19.130 --> 00:41:20.990
Because I'm on stage in
front of 1,500 people.

00:41:21.040 --> 00:41:26.760
Okay, the final one here is the energy
usage instrument at the top.

00:41:26.910 --> 00:41:28.690
Okay,
the energy usage instrument at the top

00:41:28.910 --> 00:41:30.740
used to sample in fairly large buckets.

00:41:30.760 --> 00:41:32.760
Now in iOS 5,
we're sampling every second.

00:41:32.760 --> 00:41:36.760
So you have a much higher fidelity
view of what is going on and how your

00:41:36.760 --> 00:41:39.670
code is impacting that energy usage.

00:41:41.490 --> 00:41:41.900
Right button.

00:41:41.900 --> 00:41:42.400
OK.

00:41:42.400 --> 00:41:46.720
So now let's talk about a demo for--
let me just show you a trace I recorded

00:41:46.720 --> 00:41:50.870
to demonstrate the effect that
bursting can have on an application.

00:41:55.070 --> 00:41:58.320
So here's a trace I took with the energy
diagnostics template with iOS 5 and the

00:41:58.320 --> 00:42:01.140
network activity instrument in place.

00:42:01.530 --> 00:42:05.950
And here we see our first scenario,
which is we're transferring

00:42:05.950 --> 00:42:07.560
a large file over time.

00:42:07.680 --> 00:42:09.840
And if I look at the
network activity instrument,

00:42:09.840 --> 00:42:12.790
we can see here,
if I expand the column here,

00:42:13.970 --> 00:42:19.000
That we're sending about
500K every 30 seconds.

00:42:19.020 --> 00:42:21.700
So that's about a megabyte per minute.

00:42:21.930 --> 00:42:24.940
Now you can see the corresponding
effect this is having on the radio.

00:42:24.950 --> 00:42:25.980
You see the energy usage.

00:42:26.040 --> 00:42:29.980
We have it spike, and then it sits down,
and then it spikes again during

00:42:29.980 --> 00:42:32.400
the next network transmission.

00:42:32.440 --> 00:42:35.730
Now also in this document,
I have a second run,

00:42:35.730 --> 00:42:38.280
which shows a completely
different result.

00:42:39.100 --> 00:42:42.800
In here, in the network track,
we'll see that we are sending

00:42:43.350 --> 00:42:46.100
100K every 10 seconds.

00:42:46.140 --> 00:42:48.020
Now, that's a different data rate.

00:42:48.080 --> 00:42:50.420
That's actually 600K per minute, right?

00:42:50.420 --> 00:42:52.050
So you'd expect this to
be more energy efficient.

00:42:52.060 --> 00:42:53.580
We're sending less data, right?

00:42:53.580 --> 00:42:56.130
But look at this track up top.

00:42:56.200 --> 00:42:59.150
If you look at this track,
you can see how those

00:42:59.200 --> 00:43:02.360
little bursts of data,
without very much time in between,

00:43:02.360 --> 00:43:04.450
is keeping that radio
on almost all the time.

00:43:04.460 --> 00:43:08.270
And if you look at the area here,
it almost looks like a 2X improvement.

00:43:08.760 --> 00:43:10.420
And we can actually confirm that.

00:43:10.420 --> 00:43:16.180
In the 1MB per minute transfer,
where we're transferring

00:43:16.180 --> 00:43:20.090
500K every 30 seconds,
we can do that for about 15 hours.

00:43:20.100 --> 00:43:24.420
Now, the other trace,
where we're downloading less data,

00:43:24.420 --> 00:43:28.050
but we're doing it every 10 seconds,
7 hours of battery life.

00:43:28.100 --> 00:43:29.800
So it's huge.

00:43:29.800 --> 00:43:31.020
It's a 2X improvement.

00:43:31.020 --> 00:43:35.590
Just by taking data and
going through bursting.

00:43:35.620 --> 00:43:39.700
All right, so let's go back to slides,
and we'll talk about maybe an example

00:43:39.760 --> 00:43:42.100
on how you might go about this.

00:43:44.300 --> 00:45:47.500
[Transcript missing]

00:45:47.780 --> 00:45:50.030
If you see the GPS on,
that means that core location

00:45:50.080 --> 00:45:51.070
is at the end of its rope.

00:45:51.490 --> 00:45:55.120
All of the energy efficient optimizations
it could make to find your location,

00:45:55.120 --> 00:45:57.100
they just won't work in this scenario.

00:45:57.100 --> 00:45:59.360
So that can happen in
two different cases.

00:45:59.360 --> 00:46:02.450
One, you're using best accuracy,
and the GPS is the only way

00:46:02.470 --> 00:46:04.000
to get the best accuracy.

00:46:04.000 --> 00:46:08.180
Or two, you're using maybe some very
low granularity accuracy,

00:46:08.180 --> 00:46:11.070
but there's no other
points of references.

00:46:11.160 --> 00:46:12.770
There's no other points of reference.

00:46:12.790 --> 00:46:16.820
There's no cell towers or
Wi-Fi hotspots in the area.

00:46:17.300 --> 00:46:19.820
and it has to turn the GPS on.

00:46:20.000 --> 00:46:22.700
So how do you go about
tuning core location code?

00:46:22.700 --> 00:46:25.520
So you have the core
location manager object,

00:46:25.520 --> 00:46:27.380
and it has an attribute
called desired accuracy.

00:46:27.380 --> 00:46:29.060
You can set it to one of these constants.

00:46:29.060 --> 00:46:31.790
By default, it's set to best,
which works great for

00:46:32.040 --> 00:46:34.830
our hiking application,
but it may not be appropriate

00:46:35.000 --> 00:46:38.560
for applications such as one that
might get the weather in the area,

00:46:38.560 --> 00:46:40.120
the forecast, right?

00:46:40.120 --> 00:46:42.920
You could probably get away with three
kilometer accuracy for that type of case.

00:46:43.700 --> 00:46:48.630
Now, the second one is optimization or
tuning that you can do for the core

00:46:48.630 --> 00:46:52.740
location manager is start updating
location and stop updating location.

00:46:52.760 --> 00:46:56.200
You want to call stop updating
location as soon as you possibly can,

00:46:56.200 --> 00:46:56.760
right?

00:46:56.760 --> 00:46:59.520
Now, in our hiking application,
we need to keep core location

00:46:59.520 --> 00:47:01.100
going and get all those updates.

00:47:01.140 --> 00:47:04.120
But in our weather application,
we can turn it off immediately as soon

00:47:04.120 --> 00:47:06.120
as we get our first location information.

00:47:06.120 --> 00:47:08.720
So try to turn it off whenever you can.

00:47:08.720 --> 00:47:13.260
If a user moves away from that panel
that is using the location information,

00:47:13.260 --> 00:47:13.650
you can turn it off immediately.

00:47:13.770 --> 00:47:14.130
Turn it off.

00:47:14.250 --> 00:47:16.280
That'll cause everything
else to idle back down.

00:47:16.340 --> 00:47:18.480
And you'll see that in the
energy diagnostics template.

00:47:18.480 --> 00:47:21.340
You see the effect in the
energy diagnostics template.

00:47:21.340 --> 00:47:22.450
All right.

00:47:22.450 --> 00:47:27.590
Our fourth optimization for power
here is going to be sleep wake.

00:47:29.310 --> 00:47:31.100
Okay,
optimizing for running battery life,

00:47:31.360 --> 00:47:35.170
like where we're showing how we can get
with bursting 15 hours versus 7 hours,

00:47:35.310 --> 00:47:36.260
that's great.

00:47:36.280 --> 00:47:39.960
But standby time is also a very
important part of the user experience

00:47:39.960 --> 00:47:41.680
when it comes to battery life.

00:47:41.760 --> 00:47:44.680
We want to try to make that
standby time as long as possible.

00:47:44.680 --> 00:47:47.320
The expectation here is when
I take my phone and I'm not using

00:47:47.320 --> 00:47:49.980
it and I put it in my pocket,
that I should be able to leave

00:47:50.250 --> 00:47:53.480
it there for a couple days
before I need to recharge it,

00:47:53.500 --> 00:47:54.150
right?

00:47:54.160 --> 00:47:57.620
So standby battery life is an
important part of that user experience.

00:47:58.190 --> 00:48:00.690
Now there's things that our applications
can do to keep the device awake,

00:48:00.730 --> 00:48:02.200
such as background activity.

00:48:02.200 --> 00:48:05.560
But there's also things that we can
do that will wake the device up.

00:48:05.660 --> 00:48:09.470
And those things include push
notification and voice over IP packets.

00:48:12.380 --> 00:48:17.940
So how do we measure if our
application is messing with sleep/wake?

00:48:18.060 --> 00:48:22.500
Well, in the energy diagnostics template,
there is a sleep/wake track.

00:48:22.570 --> 00:48:25.170
The dark areas show you when
you're sleeping and the light

00:48:25.170 --> 00:48:26.570
areas when you're awake.

00:48:26.570 --> 00:48:30.680
You want to try to make that as dark
as you can for as long as you can.

00:48:30.720 --> 00:48:35.440
Now, here's an example of how your
application could affect sleep/wake.

00:48:35.480 --> 00:48:41.100
What we did here is we took a device
and we put it to sleep--or we put it

00:48:41.140 --> 00:48:45.780
to sleep and then we woke it up every
30 seconds with a network packet,

00:48:45.780 --> 00:48:46.380
okay?

00:48:46.410 --> 00:48:47.500
Now, that does two things.

00:48:47.500 --> 00:48:50.560
First off, it turns the radios on,
but it also wakes the device up.

00:48:50.720 --> 00:48:52.750
And you can see here in the
sleep/wake track that it's

00:48:52.750 --> 00:48:54.180
actually staying awake for a while.

00:48:54.460 --> 00:48:57.150
Now, this can happen--this happens
because it takes a bit before

00:48:57.150 --> 00:49:00.040
the device will go back to sleep
just to make sure it doesn't have

00:49:00.080 --> 00:49:01.620
anything else it needs to do.

00:49:01.620 --> 00:49:04.100
Now,
our normal standby time is 300 hours.

00:49:04.100 --> 00:49:08.280
If we wake the device like this
with that type of a radioactivity,

00:49:08.280 --> 00:49:11.020
we have a standby life of 30 hours.

00:49:11.020 --> 00:49:14.620
Okay,
that's a 10x reduction just because we're

00:49:14.620 --> 00:49:17.580
pinging the device every 30 seconds.

00:49:19.320 --> 00:49:21.860
Obviously,
we don't want to continue doing that.

00:49:21.870 --> 00:49:24.120
OK, so what kind of optimizations
can we make here?

00:49:24.160 --> 00:49:28.320
Well, the first one I want to make
note is that push notifications.

00:49:28.420 --> 00:49:33.340
Push notifications and, to some extent,
voice over IP packets,

00:49:33.460 --> 00:49:34.520
they can wake the device.

00:49:34.550 --> 00:49:36.560
So you have to be careful
when you send them.

00:49:36.770 --> 00:49:38.250
Now, push notifications are great.

00:49:38.260 --> 00:49:39.230
We want you to use them.

00:49:39.360 --> 00:49:41.440
They're a lot better than
some of the alternatives.

00:49:41.440 --> 00:49:44.740
But you have to be careful that
when you do push a notification,

00:49:44.740 --> 00:49:46.860
you understand that when
you do push a notification,

00:49:46.860 --> 00:49:48.540
you are waking the customer's device.

00:49:48.800 --> 00:49:51.300
So if you're pushing notifications
and the customer hasn't

00:49:51.300 --> 00:49:53.960
responded back to your server,
probably is a good indication that

00:49:53.960 --> 00:49:56.050
their device is either in their
pocket and they can't get to it,

00:49:56.140 --> 00:49:58.220
or they're asleep, or some other thing.

00:49:58.380 --> 00:50:02.070
So it's probably a good time to
stop pushing those notifications.

00:50:02.220 --> 00:50:05.210
If you get into that pattern where you're
pushing a notification every 30 seconds,

00:50:05.240 --> 00:50:10.020
you're going to bring their battery down
to potentially 30 hours of standby time.

00:50:10.020 --> 00:50:11.220
You don't want to do that.

00:50:11.320 --> 00:50:13.060
So let the device sleep
as long as possible.

00:50:13.060 --> 00:50:13.860
That's the key here.

00:50:13.860 --> 00:50:16.120
So if you absolutely
have to ping the device,

00:50:16.170 --> 00:50:18.830
do it every 10, 30 minutes,
something as as long as

00:50:18.830 --> 00:50:20.730
you possibly can make it.

00:50:21.780 --> 00:50:26.080
All right, finally here,
dynamic frame rates.

00:50:26.100 --> 00:50:27.870
Now,
we know that the smoothest animations

00:50:27.920 --> 00:50:31.400
and the best looking games come
in at 60 frames per second,

00:50:31.730 --> 00:50:31.980
right?

00:50:31.980 --> 00:50:36.140
But is that true for
everything in all scenarios,

00:50:36.140 --> 00:50:37.240
right?

00:50:37.240 --> 00:50:40.020
As it turns out,
for scenes that maybe are

00:50:40.020 --> 00:50:42.390
a little bit more still or
there's not a lot of motion,

00:50:42.430 --> 00:50:45.000
you can get away with
maybe lower frame rates.

00:50:45.030 --> 00:50:49.670
Now, we're not saying across the board,
set your frame rate down and reduce

00:50:49.670 --> 00:50:52.930
the quality of your application,
but for certain scenes,

00:50:52.930 --> 00:50:56.200
you might be able to get away with
lower frame rates and not have too

00:50:56.200 --> 00:50:59.230
many people notice a difference,
and you'll get much better battery life.

00:51:01.180 --> 00:51:01.980
So how do we measure that?

00:51:02.030 --> 00:51:03.680
Again, energy diagnostics template.

00:51:03.680 --> 00:51:05.840
But we also have the
core animation template,

00:51:05.840 --> 00:51:08.540
and that will allow you to measure
the number of frames per second that

00:51:08.590 --> 00:51:10.180
you're actually pushing to the device.

00:51:10.180 --> 00:51:13.240
Now, if you're looking at the
energy diagnostics template,

00:51:13.240 --> 00:51:16.140
you want to look for foreground
activity and graphics activity.

00:51:16.140 --> 00:51:18.290
Those are going to be the big ones
that you want to try to reduce,

00:51:18.290 --> 00:51:20.100
and that's what usually
frame rate is driving.

00:51:20.520 --> 00:51:23.670
But ultimately,
the final say here is what the energy

00:51:23.730 --> 00:51:25.850
usage instrument is telling you.

00:51:25.850 --> 00:51:27.950
It's trying to tell you
that you're getting better

00:51:27.960 --> 00:51:31.460
or worse energy efficiency,
so watch that track above all else.

00:51:31.460 --> 00:51:34.890
So here we took a popular
gaming engine for iOS,

00:51:34.890 --> 00:51:38.150
and we ran it at a full
60 frames a second,

00:51:38.150 --> 00:51:41.720
and we got a 15 out of 20 energy level.

00:51:41.720 --> 00:51:46.520
Now, we took that same engine and set
it down to 15 frames a second,

00:51:46.520 --> 00:51:50.200
and we got about a 10
out of 15 energy level.

00:51:50.710 --> 00:51:53.820
Now, you'll see the reduction
here also in the CPU track.

00:51:53.820 --> 00:51:55.240
Everything came down universally.

00:51:55.240 --> 00:51:58.150
Now, we're not saying that everybody's
going to get a huge benefit by

00:51:58.150 --> 00:51:59.700
going to 15 frames a second.

00:51:59.700 --> 00:52:03.690
We're just saying that if you adjust
your frame rate and take an energy trace,

00:52:03.690 --> 00:52:06.620
you can see what that difference
is going to be and see if it's

00:52:06.750 --> 00:52:08.810
worthwhile to your application.

00:52:09.370 --> 00:52:12.650
So how can we do this
dynamic frame rate thing?

00:52:12.660 --> 00:52:15.940
Well, there's no big switch that you can
throw that turns on dynamic frame rates.

00:52:15.950 --> 00:52:18.580
It's kind of an application
engine type thing.

00:52:18.580 --> 00:52:21.460
The idea here is to draw only what's new.

00:52:21.460 --> 00:52:23.490
Don't draw redundant
frames if you can avoid it.

00:52:23.560 --> 00:52:25.780
Also experiment with
different frame rates.

00:52:25.890 --> 00:52:29.060
Maybe certain parts of your
application can get away with slower

00:52:29.060 --> 00:52:31.010
frame rates and nobody will notice.

00:52:31.520 --> 00:52:33.760
And as Tim was saying,
try double blind test.

00:52:33.800 --> 00:52:37.960
Try taking your game at one frame
rate and at another frame rate,

00:52:38.070 --> 00:52:40.160
handing it to different people,
see if they notice a difference.

00:52:40.160 --> 00:52:42.920
If they don't notice a difference,
then you're picking up free battery life.

00:52:43.000 --> 00:52:48.130
But the other goal here is, of course,
to reduce your CPU and GPU activity.

00:52:48.140 --> 00:52:53.020
So even if your game is running super
smooth and the animations are perfect,

00:52:53.020 --> 00:52:55.380
if you further optimize,
maybe make your geometry

00:52:55.380 --> 00:52:58.220
management a little better,
a little bit more efficient,

00:52:58.220 --> 00:53:01.500
even if it doesn't affect the frame rate,
it will keep the CPU.

00:53:01.530 --> 00:53:04.120
But make your CPU more idle,
and that will save you a

00:53:04.120 --> 00:53:05.050
significant amount of energy.

00:53:05.130 --> 00:53:07.210
So the more efficient
we can make our apps,

00:53:07.290 --> 00:53:11.110
the more energy we're going to be saving
and the longer our battery life will be.

00:53:11.120 --> 00:53:12.950
Same thing goes for GPU shaders.

00:53:13.000 --> 00:53:15.440
If you can make them more efficient,
you'll also see a positive

00:53:15.550 --> 00:53:18.420
impact on battery life,
which you'll see with the

00:53:18.420 --> 00:53:20.270
energy usage instrument.

00:53:21.060 --> 00:53:25.740
Okay,
so that's it for energy and networking.

00:53:25.740 --> 00:53:28.300
So let's talk about the session review.

00:53:28.300 --> 00:53:29.940
Measure, always measure first.

00:53:30.310 --> 00:53:32.280
Measurement will make
things a lot easier.

00:53:32.280 --> 00:53:34.410
Instruments has a lot
of tools in the toolbox,

00:53:34.490 --> 00:53:37.620
and it can do a really good job of
hooking into your application in pretty

00:53:37.830 --> 00:53:39.840
unique ways to find out what it's doing.

00:53:39.840 --> 00:53:40.830
So start there.

00:53:40.830 --> 00:53:43.860
Of course, for everything else,
there's logging.

00:53:43.860 --> 00:53:46.400
Try logging if you can't use instruments.

00:53:47.040 --> 00:53:51.780
Now, if you have some performance problem
that slips out into the wild,

00:53:51.780 --> 00:53:55.780
you're going to see that on
your iTunes Connect report.

00:53:55.780 --> 00:53:57.640
Jetsam notifications,
if your app has been

00:53:57.650 --> 00:54:00.360
terminated because of Jetsam,
or if your app has been terminated

00:54:00.430 --> 00:54:02.970
because of the Watchdog,
you'll see those logs accumulate

00:54:02.970 --> 00:54:04.620
in your iTunes Connect report.

00:54:04.620 --> 00:54:07.940
So take a look at those and make
sure that those are absolutely

00:54:07.940 --> 00:54:09.940
addressed at highest priority.

00:54:09.940 --> 00:54:12.380
Now,
the goal here for the whole session is

00:54:12.630 --> 00:54:15.120
really to talk about promoting lean apps.

00:54:15.120 --> 00:54:16.950
But it's not just fast apps.

00:54:17.040 --> 00:54:20.940
It's also apps that are more
efficient in terms of energy and more

00:54:20.940 --> 00:54:22.840
efficient in terms of networking.

00:54:22.840 --> 00:54:26.270
And also,

00:54:26.740 --> 00:54:27.800
Well, actually, those are the big ones.

00:54:28.020 --> 00:54:34.830
So if you make your apps leaner,
everything is much more pleasing.

00:54:34.990 --> 00:54:35.820
It's faster.

00:54:36.060 --> 00:54:38.520
Multitasking is faster if
you're more memory efficient.

00:54:38.670 --> 00:54:41.720
And you can get much more
life out of your battery.

00:54:41.720 --> 00:54:47.100
So the key here is performance.

00:54:47.100 --> 00:54:48.610
One aspect is speed,
but it's really about efficiency.

00:54:48.970 --> 00:54:50.940
So for more information,
you can contact Michael Jurowicz,

00:54:50.940 --> 00:54:53.630
who's our developer tools evangelist.

00:54:53.630 --> 00:54:57.000
For documentation,
there's the Instruments User's Guide.

00:54:57.000 --> 00:55:01.100
That will actually show you how to enable
the energy diagnostics instruments and be

00:55:01.100 --> 00:55:03.250
able to take your own power recordings.

00:55:03.250 --> 00:55:06.980
There's always the Apple Developer Forums
for questions and answers.

00:55:07.860 --> 00:55:11.450
For related sessions,
I would suggest taking a look at the

00:55:11.590 --> 00:55:13.280
ARC and What's New in Instruments.

00:55:13.340 --> 00:55:15.300
Unfortunately, they've already passed,
but they will be on video.

00:55:15.300 --> 00:55:21.120
And same time tomorrow in this room,
so 4:30 Thursday, Presidio,

00:55:21.530 --> 00:55:25.200
there is the iOS Performance In-Depth,
which is the sister session to this talk,

00:55:25.290 --> 00:55:27.860
and it'll be talking even
more about performance.

00:55:27.860 --> 00:55:30.750
Have a good rest of your day.