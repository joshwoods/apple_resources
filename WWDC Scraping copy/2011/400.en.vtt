WEBVTT

00:00:23.740 --> 00:00:26.790
Welcome and thank you for
coming to the Graphics,

00:00:26.790 --> 00:00:28.700
Media, and Games Kickoff.

00:00:28.820 --> 00:00:32.610
iOS and Mac OS give you
a wealth of graphics,

00:00:32.610 --> 00:00:37.200
media, and game technologies for you
to use in your application.

00:00:37.300 --> 00:00:40.910
And today what we're hoping to give
you a little bit of insight into are

00:00:41.330 --> 00:00:46.000
some of the sessions and some insight
into the technologies that we're going

00:00:46.000 --> 00:00:48.680
to be presenting this week at WWDC.

00:00:49.090 --> 00:00:51.520
So right now,
we're going to focus in a little

00:00:51.520 --> 00:00:56.320
bit on OpenGL and OpenGL ES,
our industry standard 3D graphics

00:00:56.320 --> 00:01:00.460
API for accessing the power of the GPU.

00:01:00.500 --> 00:01:04.830
We're going to talk about OpenAL,
the industry standard for building

00:01:04.830 --> 00:01:09.030
realistic 3D spatial audio environments.

00:01:09.160 --> 00:01:11.280
Then we're going to
talk about Game Center.

00:01:11.330 --> 00:01:15.300
Game Center is Apple's
social gaming network.

00:01:15.660 --> 00:01:19.590
and AV Foundation,
the framework you should

00:01:20.140 --> 00:01:22.190
use for all of your...

00:01:22.330 --> 00:01:25.740
All of your media editing
needs of your application.

00:01:25.800 --> 00:01:30.940
And then Core Image,
our powerful image processing library.

00:01:31.000 --> 00:01:32.980
And then we're going to touch on AirPlay.

00:01:33.020 --> 00:01:36.980
I think about giving you a unique
opportunity for you to stream audio

00:01:36.980 --> 00:01:39.190
and video from your application.

00:01:39.560 --> 00:01:41.360
So let's get started.

00:01:41.370 --> 00:01:46.410
OpenGL is an industry standard
available on Mac OS X.

00:01:46.550 --> 00:01:52.490
and iOS, we give you OpenGL ES,
both powerful APIs for accessing

00:01:52.490 --> 00:01:57.570
the GPU for leveraging the 3D
capabilities of the processor.

00:02:01.500 --> 00:02:05.500
Graphics processors today are
fundamentally built around shaders,

00:02:05.520 --> 00:02:09.890
the ability to write shaders and to
run them on the graphics processor.

00:02:10.090 --> 00:02:14.480
Shaders take geometry
and textures as inputs.

00:02:14.490 --> 00:02:18.970
They use those inputs to compute
the visual effect that you're after.

00:02:21.400 --> 00:02:24.270
This is what is at the heart of
the amazing visual effects you

00:02:24.290 --> 00:02:26.520
see in the applications today.

00:02:26.520 --> 00:02:29.340
And to get this session started,
I'm going to bring Geoff Staahl up,

00:02:29.340 --> 00:02:34.880
and he's going to show us what's
possible on the iPad using shaders.

00:02:35.800 --> 00:02:37.270
Thank you, John.

00:02:39.430 --> 00:02:45.400
What you're seeing is the latest game,
Shadowgun, from Madfinger Games,

00:02:45.480 --> 00:02:49.240
built on top of Unity Technologies,
running on iOS, iPad 2,

00:02:49.240 --> 00:02:51.360
60 frames per second.

00:02:51.490 --> 00:02:53.790
This is a beautiful game.

00:02:55.400 --> 00:03:14.700
[Transcript missing]

00:03:14.710 --> 00:03:18.050
We have a great reflectivity mask
to give these specular highlights,

00:03:18.140 --> 00:03:19.470
all computed on the GPU.

00:03:19.600 --> 00:03:24.110
In fact, every single pixel you see
is computed on the GPU.

00:03:24.460 --> 00:03:27.160
All of this real time,
60 frames per second.

00:03:27.160 --> 00:03:28.160
We have a cloth simulation.

00:03:28.160 --> 00:03:31.930
The flag itself is a cloth
simulation that's running on a

00:03:31.930 --> 00:03:35.940
vertex shader along with the wires,
are animated with vertex shaders.

00:03:35.960 --> 00:03:38.680
Over here,
you have this great HDR effect.

00:03:38.710 --> 00:03:43.050
That HDR effect and those god
rays are all optimized shaders.

00:03:43.710 --> 00:03:44.490
Fantastic visuals.

00:03:44.500 --> 00:03:47.660
Remember, this is on an iPad 2,
on the GPU.

00:03:47.660 --> 00:03:50.090
This is not just a technology demo.

00:03:50.100 --> 00:03:51.180
This is a full game level.

00:03:51.180 --> 00:03:55.180
This has your enemies, it has AI,
pathfinding.

00:03:55.180 --> 00:03:56.920
All those things are integrated here.

00:03:56.930 --> 00:03:58.940
It's not just the graphics technologies.

00:03:58.940 --> 00:04:02.240
Now let's take a look at another
part of the demonstration.

00:04:02.240 --> 00:04:06.860
If we look at the character himself,
look at a very, very realistic character.

00:04:06.860 --> 00:04:11.520
In fact, the character is run on
shaders that are BRDFs.

00:04:11.710 --> 00:04:15.260
They're Binary Reflectance
Direction Function.

00:04:15.260 --> 00:04:18.740
Basically what they do is they
define the way a material looks.

00:04:18.740 --> 00:04:21.550
For example,
if you look at the top of the shoulder,

00:04:21.550 --> 00:04:22.910
you see there's a cloth.

00:04:22.910 --> 00:04:26.400
That cloth has a different look
than the buckle or his skin.

00:04:26.400 --> 00:04:28.920
These functions can be encoded.

00:04:28.940 --> 00:04:34.580
You can run on the GPU to give you a
fantastic look for your application.

00:04:34.710 --> 00:04:38.380
Now let's watch as we
go into this green area.

00:04:39.050 --> 00:04:40.800
What you're seeing here,
you're seeing the character as it

00:04:40.800 --> 00:04:44.400
picks up this fantastic green glow
in the simulation or in the game.

00:04:44.400 --> 00:04:46.700
What that is,
is that's called a light probe.

00:04:46.700 --> 00:04:49.060
And this is, we believe,
the first time that anyone's used

00:04:49.060 --> 00:04:50.450
light probes in a mobile game.

00:04:50.460 --> 00:04:53.740
Light probes are usually used,
reserved for things like cinema,

00:04:53.740 --> 00:04:56.780
where Avatar used them to great effect,
or console type of games.

00:04:56.780 --> 00:05:01.760
In this case, what light probes are,
you take spherical samples

00:05:01.760 --> 00:05:03.880
around your game level.

00:05:03.880 --> 00:05:06.120
In this case, there's about 300 light
probes on this game level.

00:05:06.350 --> 00:05:08.940
Then in real time,
you actually take the coefficients

00:05:09.020 --> 00:05:11.650
from those light probes,
you can linear interpolate

00:05:11.650 --> 00:05:14.240
them on the GPU in a shader,
and get this lighting effect.

00:05:14.340 --> 00:05:17.130
And now if we watch,
as he transitions out of the green,

00:05:17.300 --> 00:05:21.060
into the dark, entering the elevator,
and back into this green area.

00:05:21.060 --> 00:05:24.370
Amazing effect of really bringing
the character into this 3D world.

00:05:28.200 --> 00:05:35.360
You can see some more HDR effects,
fantastic visuals, fully animated world.

00:05:36.900 --> 00:05:40.180
Madfinger Games built with
Unity technologies running on iOS,

00:05:40.330 --> 00:05:44.460
60 frames per second,
stencil shadow for the fans,

00:05:44.470 --> 00:05:49.550
more god rays, true to force in graphics,
running on mobile graphics.

00:05:49.650 --> 00:05:52.900
This really sets a new high
bar for mobile graphics today.

00:05:52.920 --> 00:05:53.210
Thank you.

00:06:01.800 --> 00:06:04.400
Thank you, Geoff.

00:06:04.440 --> 00:06:09.120
So shaders are critically important
for you to be able to build these

00:06:09.120 --> 00:06:10.630
amazing visual effects you see.

00:06:10.640 --> 00:06:13.440
It's absolutely incredible
what's possible.

00:06:13.460 --> 00:06:18.930
And with Lion and iOS 5,
shaders are everywhere they run.

00:06:19.260 --> 00:06:24.990
So everywhere Lion and iOS 5 run,
you have access to the power of shaders.

00:06:25.100 --> 00:06:28.550
So there's no reason for
you not to use them now.

00:06:30.320 --> 00:06:33.990
So as I said, the graphics processor has
fundamentally evolved over

00:06:33.990 --> 00:06:37.000
the years to be about shaders.

00:06:37.170 --> 00:06:40.620
You write shaders and
you run them on the GPU.

00:06:40.680 --> 00:06:43.820
And getting those shaders optimal

00:06:44.010 --> 00:06:47.690
And getting the syntax of those
shaders correct can be challenging.

00:06:47.900 --> 00:06:54.330
So in iOS 5, we've introduced a series of
tools to help you do that.

00:06:55.110 --> 00:06:58.660
The first tool is the
OpenGL ES Performance Detective.

00:06:58.680 --> 00:07:04.270
The OpenGL Performance Detective is an
expert application that automatically

00:07:04.270 --> 00:07:07.220
analyzes your use of OpenGL,
both in terms of

00:07:07.220 --> 00:07:10.930
performance and correctness,
and gives you suggestions about

00:07:11.000 --> 00:07:15.640
how you can correct those problems,
how you can optimize your use of OpenGL.

00:07:16.120 --> 00:07:19.280
The second tool is
OpenGL Analyzer Instrument.

00:07:19.380 --> 00:07:23.270
It's an Xcode instrument that gives you
that next level of information about

00:07:23.540 --> 00:07:27.680
the performance characteristics of
your application and its use of OpenGL,

00:07:27.860 --> 00:07:31.430
giving you that fine detail
of information that you can

00:07:31.540 --> 00:07:34.870
then act upon to improve the
performance of your application.

00:07:35.680 --> 00:07:40.060
Third is OpenGL ES Debugger,
and we've seen the demonstration from

00:07:40.170 --> 00:07:42.880
the Xcode team of OpenGL ES Debugger.

00:07:43.030 --> 00:07:45.750
It's a full-featured tool,
giving you frame-by-frame

00:07:45.930 --> 00:07:47.460
access to information.

00:07:47.460 --> 00:07:50.830
You can step through your program code,
your OpenGL code,

00:07:50.830 --> 00:07:53.930
accessing state information,
buffer information,

00:07:54.020 --> 00:07:57.640
giving you all the detailed
information you'll need to debug the

00:07:57.640 --> 00:08:00.230
hardest OpenGL problems you may have.

00:08:00.820 --> 00:08:05.030
And all of these tools are
available right within Xcode,

00:08:05.030 --> 00:08:10.370
making it so you can stay right
in Xcode and use the OpenGL tools

00:08:10.480 --> 00:08:13.900
to debug and optimize your
OpenGL implementation within your

00:08:14.000 --> 00:08:16.220
application development cycle.

00:08:16.940 --> 00:08:20.290
So to go into a demonstration
of some of these tools,

00:08:20.290 --> 00:08:23.710
I'm going to bring Geoff on stage
and we're going to look at these.

00:08:24.600 --> 00:08:27.140
What we're going to do is we're going
to take an application that we designed

00:08:27.420 --> 00:08:31.400
to be able to show the graphics power of
the iPad 2 and some interactive lighting.

00:08:31.400 --> 00:08:34.070
So if we go to the iPad here,

00:08:34.380 --> 00:08:35.260
We can see where we stand.

00:08:35.260 --> 00:08:38.810
And this is not quite
what I was looking for.

00:08:38.820 --> 00:08:42.190
It's a little dark, a little stuttery,
and the lights aren't really

00:08:42.190 --> 00:08:43.540
interacting with the world.

00:08:43.540 --> 00:08:46.270
Let's use our tools and
see if we can fix that.

00:08:46.430 --> 00:08:48.700
So I'm going to switch over
to the Mac and to Xcode.

00:08:48.700 --> 00:08:50.910
It's showing the standard
instrument state on the top,

00:08:50.910 --> 00:08:52.840
but what we want to focus
on is the area below here,

00:08:52.910 --> 00:08:54.170
which is really important.

00:08:54.180 --> 00:08:55.190
This is our expert area.

00:08:55.210 --> 00:08:58.600
And what you notice that there are
things that it's giving you that are,

00:08:58.600 --> 00:09:02.290
we've analyzed your API use of OpenGL and
we'll tell you some of the things that

00:09:02.290 --> 00:09:04.280
we think could be really important.

00:09:04.300 --> 00:09:07.590
So you can look at these things
and you can find redundant calls.

00:09:07.590 --> 00:09:11.040
And one of those things we talked
about here is shader compilation.

00:09:11.040 --> 00:09:13.330
It's telling me that
I'm compiling shaders.

00:09:13.330 --> 00:09:15.950
It turns out, if you see,
I have 105 frames and

00:09:16.060 --> 00:09:17.760
105 shader compilations.

00:09:17.830 --> 00:09:20.240
So I'm compiling my
shaders every single frame.

00:09:20.240 --> 00:09:22.780
Probably not what you want to do,
so that's a really

00:09:22.860 --> 00:09:24.540
interesting area to look at.

00:09:24.600 --> 00:09:28.090
Since this is integrated with Xcode,
what we can do, we'll stop here.

00:09:28.090 --> 00:09:30.380
We'll use this arrow key.

00:09:30.450 --> 00:09:33.300
It brings us up the stack trace.

00:09:35.260 --> 00:09:40.090
Go here, it shows us the area where the
instrument found that problem.

00:09:40.160 --> 00:09:42.120
Click this icon right
in this area right here,

00:09:42.120 --> 00:09:45.460
which is go back to Xcode,
and it'll open the file right in Xcode.

00:09:45.460 --> 00:09:47.800
Turns out when we're
setting up this demo,

00:09:47.810 --> 00:09:50.820
we add an extra code that
did a light reset every time,

00:09:50.820 --> 00:09:53.410
which is not needed for the way we're
running the demo here in the house.

00:09:53.530 --> 00:09:55.600
So I'll remove that,
and we'll try and run that again.

00:09:55.600 --> 00:09:59.190
So I'll remove that.

00:09:59.260 --> 00:10:01.320
We're going to do a build and run.

00:10:05.200 --> 00:10:14.500
And we are going to be
launching this momentarily.

00:10:29.870 --> 00:10:33.000
Okay, this is not looking very good.

00:10:33.010 --> 00:10:37.060
We will try one more time
and then we'll be done.

00:10:48.240 --> 00:10:50.200
Okay, now if we switch to the iPad.

00:10:50.200 --> 00:10:58.690
Can we switch to the iPad, please?

00:11:03.910 --> 00:11:05.400
You need to switch to the secondary iPad.

00:11:05.400 --> 00:11:13.460
So what you'll see is in a second
when the secondary iPad comes up,

00:11:13.560 --> 00:11:15.760
you'll see the simulation is
now running very smoothly,

00:11:15.760 --> 00:11:17.320
but we still don't have
the right lighting.

00:11:17.320 --> 00:11:19.320
So we fixed our performance problem.

00:11:19.320 --> 00:11:21.380
What we could use is the
performance detective will

00:11:21.420 --> 00:11:24.900
tell us basically where it is,
tell us the state problem,

00:11:24.900 --> 00:11:26.500
the shader compilation.

00:11:26.500 --> 00:11:28.380
We used the instrument
to drill down deeper.

00:11:28.380 --> 00:11:32.500
You could see that there was a
redundant shader compilation here.

00:11:32.520 --> 00:11:35.110
We remove that, and we get the smooth
running application.

00:11:35.120 --> 00:11:38.210
We're going to switch back to Xcode,
stopping our simulation,

00:11:38.220 --> 00:11:41.970
and we noticed there was a
lighting problem with it.

00:11:57.290 --> 00:11:59.200
That's the other machine.

00:11:59.220 --> 00:12:00.990
There you go.

00:12:01.080 --> 00:12:01.520
Here we go.

00:12:01.540 --> 00:12:02.950
Now we're on the right machine.

00:12:03.170 --> 00:12:04.200
Okay.

00:12:04.200 --> 00:12:05.870
What we've added,
as you saw in the last session,

00:12:05.910 --> 00:12:07.160
is the ability to take a snapshot.

00:12:07.160 --> 00:12:10.260
The interesting thing here, again,
is it's working on the iPad itself,

00:12:10.260 --> 00:12:12.010
and we've taken the snapshot in OpenGL.

00:12:12.010 --> 00:12:14.560
It's capturing the frame,
and we're going to show you how you

00:12:14.560 --> 00:12:17.560
can use some of those markers that
were introduced in the last session,

00:12:17.560 --> 00:12:20.000
and you can find kind of a
detailed lighting problem.

00:12:46.450 --> 00:12:49.100
I'm not sure why it didn't take
so long to capture the frame,

00:12:49.100 --> 00:12:50.670
but we're going to move on with the talk.

00:12:50.680 --> 00:12:55.730
And if you come down to the lab when
we do the OpenGL tools and there's

00:12:55.730 --> 00:12:58.380
OpenGL tools sessions later this week,
we'll show you more details on

00:12:58.430 --> 00:12:59.950
how to use the OpenGL debugger.

00:12:59.960 --> 00:13:00.290
Thank you.

00:13:08.240 --> 00:13:10.220
Thank you, Geoff.

00:13:10.480 --> 00:13:13.510
As you can see,
we have a powerful set of tools.

00:13:15.560 --> 00:13:17.900
Oh, that must have been the other demo.

00:13:17.990 --> 00:13:21.480
So, new in iOS 5,
we're also making it easier for you

00:13:21.480 --> 00:13:23.260
to use OpenGL in your application.

00:13:23.260 --> 00:13:27.760
We're offering a new
frame kit called GeoKit.

00:13:27.760 --> 00:13:34.140
GeoKit gives you a set of services
making the use of OpenGL easier for you.

00:13:34.140 --> 00:13:37.920
The first API is UIKit integration,
giving you some high-level

00:13:37.920 --> 00:13:42.120
Objective-C APIs that get you started
with creating OpenGL views and an

00:13:42.120 --> 00:13:44.520
OpenGL context in your application.

00:13:45.830 --> 00:13:51.680
Second is a math library,
giving you over 175 math

00:13:51.770 --> 00:13:55.570
routines commonly used in 3D
applications like linear algebra,

00:13:55.580 --> 00:13:56.840
matrix operations, and such.

00:13:56.890 --> 00:13:59.720
And these math routines
are optimized for iOS,

00:13:59.720 --> 00:14:03.840
giving you some high-performance
math routines that you can use.

00:14:04.580 --> 00:14:07.080
Next, easy texture loading routines.

00:14:07.150 --> 00:14:09.940
One function called to be able to
load a texture from file or memory

00:14:09.990 --> 00:14:13.390
directly into an OpenGL texture,
again, limiting the amount of

00:14:13.510 --> 00:14:14.990
code you have to write.

00:14:16.200 --> 00:14:17.410
and an effects library.

00:14:17.630 --> 00:14:20.880
An effects library to help you
start using OpenGL Shaders.

00:14:20.930 --> 00:14:23.000
Because again,
OpenGL Shaders is how you're

00:14:23.000 --> 00:14:26.400
going to get access to the
real capabilities of the GPU.

00:14:26.780 --> 00:14:31.600
We've also extended OpenGL ES for iOS 5,
giving you the ability to do

00:14:31.600 --> 00:14:35.880
HDR renderings with float buffers,
improved access to

00:14:35.890 --> 00:14:38.340
floating point textures,

00:14:39.780 --> 00:14:44.460
A new technique now available to
be able to do soft edge shadows.

00:14:44.510 --> 00:14:48.330
Occlusion queries for high performance
occlusion querying in detailed

00:14:48.330 --> 00:14:53.580
and complex 3D scenes and more
flexibility around shader objects.

00:14:54.330 --> 00:14:56.200
We've also improved Lion.

00:14:56.500 --> 00:15:00.800
Lion,
we've introduced a concept of profiles.

00:15:00.800 --> 00:15:05.650
What profiles allows you to do
is to focus your use of the API,

00:15:05.770 --> 00:15:10.160
the OpenGL API,
on the modern subset of the API.

00:15:11.130 --> 00:15:15.820
OpenGL has evolved over the years and
has taken on a number of API calls.

00:15:15.860 --> 00:15:19.520
The Core Profile lets you focus
that to the segment that's modern

00:15:19.520 --> 00:15:21.780
and efficient and shader-focused.

00:15:21.800 --> 00:15:25.580
So I encourage you to learn about
Core Profiles when you're writing

00:15:25.580 --> 00:15:27.480
OpenGL programs for Mac OS X.

00:15:30.710 --> 00:15:33.050
Now, a companion of OpenGL is OpenCL.

00:15:33.060 --> 00:15:37.340
OpenCL is our high-performance
data parallel computing API.

00:15:37.750 --> 00:15:41.810
It's also a programming interface
built off of a C-like language,

00:15:42.170 --> 00:15:45.810
giving you more flexibility
in how you can write programs

00:15:45.900 --> 00:15:47.780
and execute them on the GPU.

00:15:48.080 --> 00:15:52.130
It's good for operations like
physics operations and basic math

00:15:52.230 --> 00:15:54.960
operations or complex math operations.

00:15:55.080 --> 00:15:57.830
Combined with the tight integration
and high-performance sharing of

00:15:57.830 --> 00:16:01.120
data between OpenGL and OpenCL,
you can pick and choose between

00:16:01.120 --> 00:16:04.250
which API is right for the
mathematical or rendering

00:16:04.250 --> 00:16:06.490
effect you're trying to achieve.

00:16:08.640 --> 00:16:14.320
So that's OpenGL for
Mac OS X and OpenGL ES for iOS.

00:16:14.830 --> 00:16:16.880
Next, I want to talk about OpenALE.

00:16:17.000 --> 00:16:20.520
OpenALE is the industry standard

00:16:22.160 --> 00:16:26.120
and John Schultz have been working
with OpenGL for over a decade.

00:16:26.210 --> 00:16:30.830
They are working on a new open GL library
for building realistic 3D spatial

00:16:30.830 --> 00:16:33.320
audio effects into your application.

00:16:33.320 --> 00:16:36.700
It's modeled after OpenGL,
making it a perfect companion

00:16:36.930 --> 00:16:40.420
for your OpenGL applications,
making it great for games.

00:16:40.630 --> 00:16:45.580
So we encourage you to look at
OpenGL for your 3D spatial audio effects.

00:16:45.580 --> 00:16:45.580
Let's talk a little bit more
about what is a spatial audio

00:16:46.010 --> 00:16:52.530
Spatial audio is about having point
sounds in 3D space and a listener.

00:16:52.560 --> 00:16:57.020
And the sound the listener will hear will
be based on the position and the distance

00:16:57.110 --> 00:16:59.620
those sounds are to the listener.

00:16:59.740 --> 00:17:01.360
So as the sound moves
around the listener,

00:17:01.410 --> 00:17:03.650
the sounds will move from left
and right ear and such and

00:17:03.660 --> 00:17:06.500
give a spatial audio effect.

00:17:07.720 --> 00:17:13.520
So OpenAL gives you the
ability to simulate these

00:17:13.520 --> 00:17:15.790
spatial audio environments.

00:17:16.040 --> 00:17:19.780
And we've taken an open
AL and we've extended it.

00:17:19.790 --> 00:17:21.700
We've extended it to include reverb.

00:17:21.950 --> 00:17:26.690
Reverb is where these point source
sounds will reflect off of objects and

00:17:26.700 --> 00:17:29.530
obstructions within the environment.

00:17:30.090 --> 00:17:35.880
We've also extended it with obstructions.

00:17:36.700 --> 00:17:43.030
Obstructions are objects or walls
and such that are between this

00:17:43.060 --> 00:17:48.520
point source sound and the listener,
muffling the high-frequency sounds

00:17:48.660 --> 00:17:51.030
but letting the reverb through.

00:17:51.750 --> 00:17:53.820
And we've added Occlusion.

00:17:53.850 --> 00:17:56.490
Occlusion is where the sound
sources in the listener are in

00:17:56.500 --> 00:17:58.990
different spaces or a different room.

00:17:59.120 --> 00:18:02.780
This will muffle the high-frequency
sounds and the reverb.

00:18:02.870 --> 00:18:06.450
So combined with these three extensions,
we've enhanced the ability for

00:18:06.450 --> 00:18:10.230
you to build even more realistic
3D spatial audio environments

00:18:10.750 --> 00:18:13.200
for your games and applications.

00:18:13.720 --> 00:18:16.770
OpenAL is built on top of Core Audio.

00:18:16.900 --> 00:18:22.200
Core Audio is our professional-grade
audio processing framework.

00:18:22.360 --> 00:18:26.220
Core Audio gives you access to
things like MIDI devices and a

00:18:26.410 --> 00:18:30.340
full feature set for building
the most complex audio editing

00:18:30.420 --> 00:18:33.310
applications and music applications.

00:18:34.810 --> 00:18:37.840
So that's OpenAL, OpenAL,
the industry standard

00:18:37.940 --> 00:18:42.440
for 3D spatial audio,
based after OpenGL,

00:18:42.470 --> 00:18:46.340
and we really encourage you
to use OpenAL for your games.

00:18:47.400 --> 00:18:55.700
[Transcript missing]

00:18:56.110 --> 00:19:05.510
We introduced Game Center last year,
last September, and now we have over 50

00:19:05.630 --> 00:19:10.140
million registered users,
making it an incredible success.

00:19:10.550 --> 00:19:14.000
Game Center is basically three
components to Game Center.

00:19:14.050 --> 00:19:17.420
There's the application,
which gets installed in iOS.

00:19:17.470 --> 00:19:21.500
Game Center is where players
will go to build friend networks,

00:19:21.500 --> 00:19:22.500
look at leaderboards.

00:19:22.500 --> 00:19:26.500
It's also where they will
initiate multiplayer games.

00:19:26.550 --> 00:19:30.400
There's Game Kit, the framework,
which is a set of APIs that you'll use

00:19:30.540 --> 00:19:34.490
to incorporate Game Center functionality
into your application.

00:19:34.820 --> 00:19:37.530
And then there's the
service segment of it,

00:19:37.590 --> 00:19:41.120
the network service segment of it,
where players will go and where high

00:19:41.140 --> 00:19:43.400
scores are stored and leaderboards.

00:19:43.450 --> 00:19:47.510
It's also where the service
that provides auto-matching

00:19:47.510 --> 00:19:49.930
capabilities for Game Center.

00:19:50.520 --> 00:19:54.500
So let's talk a little bit more
about the features available that you

00:19:54.500 --> 00:19:56.290
can start leveraging in your game.

00:19:56.470 --> 00:19:57.600
So first is friends.

00:19:57.780 --> 00:20:01.720
Friends is at the heart of
the social gaming experience.

00:20:01.860 --> 00:20:07.930
Friends like to play against each other,
look at achievements and leaderboards.

00:20:09.670 --> 00:20:12.130
Leaderboards are where
players post high scores,

00:20:12.270 --> 00:20:15.850
get bragging rights,
increases their engagement and

00:20:15.890 --> 00:20:18.040
excitement around your game.

00:20:21.050 --> 00:20:22.380
There's achievements.

00:20:22.530 --> 00:20:26.070
Achievements are something
significant or difficult a

00:20:26.070 --> 00:20:28.820
player will earn in your game.

00:20:28.910 --> 00:20:34.270
They enjoy finding them,
they enjoy earning new achievements,

00:20:34.490 --> 00:20:39.680
and it just raises the excitement level
that you can generate with your game.

00:20:40.980 --> 00:20:42.260
Then there's multiplayer.

00:20:42.320 --> 00:20:45.280
Multiplayer, of course,
is the ultimate challenge where two

00:20:45.280 --> 00:20:47.870
players can play against each other.

00:20:50.450 --> 00:20:51.400
and VoiceChat.

00:20:51.480 --> 00:20:55.020
VoiceChat enables two players,
while they're playing a multiplayer game,

00:20:55.100 --> 00:20:59.760
to talk to each other,
further enhancing the multiplayer

00:20:59.760 --> 00:21:06.520
excitement and enjoyment that a user
will have while playing multiplayer.

00:21:07.210 --> 00:21:10.990
And we enable customization,
so when you use Game Center,

00:21:10.990 --> 00:21:14.730
you can customize leaderboards
and achievements to match

00:21:14.730 --> 00:21:16.890
the style of your game.

00:21:18.710 --> 00:21:22.620
So new for iOS 5 is
turn-based multiplayer.

00:21:22.680 --> 00:21:25.140
We're all familiar
with this kind of game,

00:21:25.150 --> 00:21:27.960
which is like a card
game or a board game,

00:21:27.960 --> 00:21:31.060
where a player takes a turn,
and then the next player,

00:21:31.060 --> 00:21:32.110
and then the next, and so on.

00:21:32.120 --> 00:21:37.280
And the turns go around
sequentially between the players.

00:21:38.290 --> 00:21:43.520
So let's look a little bit
closer at how iOS 5 works,

00:21:43.520 --> 00:21:44.870
multiplayer works.

00:21:45.010 --> 00:21:48.760
So what happens is a
player takes their turn,

00:21:48.760 --> 00:21:52.840
and the game data goes
up to the game center.

00:21:52.920 --> 00:21:56.750
And the next player is notified,
and they run the application,

00:21:56.760 --> 00:21:59.480
and the data comes down to their game.

00:21:59.950 --> 00:22:01.410
They take their turn.

00:22:01.490 --> 00:22:03.210
The next player is notified.

00:22:03.440 --> 00:22:06.160
The data goes to them, and so on.

00:22:09.540 --> 00:22:15.420
Now, a really neat part about multi-turn
gameplay is that Game Center will

00:22:15.450 --> 00:22:17.820
auto-match players into empty seats.

00:22:17.950 --> 00:22:21.740
So a game could actually be started,
and as it proceeds along,

00:22:21.740 --> 00:22:24.260
it'll auto-match a new
player into the game.

00:22:24.280 --> 00:22:27.880
It'll be their turn immediately,
and they can take their turn,

00:22:27.880 --> 00:22:29.840
and then the game will proceed.

00:22:29.960 --> 00:22:33.280
So multi-auto-matching is
a fantastic feature for

00:22:33.280 --> 00:22:35.860
Game Center turn-by-turn playing.

00:22:37.310 --> 00:22:42.330
and you have control over the order
in which the turns will occur.

00:22:42.410 --> 00:22:45.990
You know, it can go forwards, backwards,
you can skip players.

00:22:46.180 --> 00:22:50.120
It can proceed in any
order that you wish.

00:22:50.260 --> 00:22:54.850
So you have complete control
over the order which players

00:22:54.850 --> 00:22:56.650
will take their turns.

00:22:57.750 --> 00:23:02.190
And a player can have up to 15 sessions
of your game running at a time.

00:23:02.310 --> 00:23:04.280
So in one session,
it might be their turn.

00:23:04.280 --> 00:23:06.140
Another, it'll be someone else's turn.

00:23:06.160 --> 00:23:08.300
But they can have up to 15
sessions of your game running.

00:23:12.670 --> 00:23:16.200
So to preview this a little bit,
I'm going to bring up Meriko,

00:23:16.200 --> 00:23:17.710
and she's going to run an application.

00:23:17.780 --> 00:23:20.200
See this in real.

00:23:21.640 --> 00:23:23.860
So I'm a big fan of turn-based--

00:23:26.030 --> 00:23:29.980
I'm a big fan of turn-based gameplay,
and I'm a big fan of word games.

00:23:30.080 --> 00:23:33.000
So the guys wrote an application
called Word for Word,

00:23:33.000 --> 00:23:35.080
and I'd like to show it to you.

00:23:35.480 --> 00:23:39.980
The first thing I'd like to do is give
you a look at the user interface for

00:23:40.000 --> 00:23:42.840
the new turn-based multiplayer gaming.

00:23:42.920 --> 00:23:49.380
So this is what you're going to get
when you call a GK turn-based multi--

00:23:49.720 --> 00:23:53.670
really long word-- a GK turn-based
matchmaking view controller.

00:23:53.760 --> 00:23:56.190
This is what your users will see.

00:23:56.440 --> 00:23:57.160
Right.

00:23:57.350 --> 00:24:00.850
So most importantly,
your turns that you need to play are

00:24:00.900 --> 00:24:02.420
right here at the front of your game.

00:24:02.620 --> 00:24:04.760
I've got a couple of turns to play.

00:24:04.830 --> 00:24:05.800
I have some friends.

00:24:05.840 --> 00:24:07.940
They're lagging on their turns.

00:24:07.960 --> 00:24:10.280
New to iOS 5,
you can actually rate your game

00:24:10.280 --> 00:24:12.040
from directly inside the game.

00:24:12.040 --> 00:24:15.340
So we're going to go ahead
and give our game five stars.

00:24:15.340 --> 00:24:15.340
I think it's great.

00:24:16.440 --> 00:24:18.530
I played it just a little bit.

00:24:18.610 --> 00:24:21.310
So in order to start a new match,
I'd like to show you that.

00:24:21.390 --> 00:24:24.160
You can tap the plus button
up in the upper hand corner.

00:24:24.160 --> 00:24:27.400
So you can see me right up at the top.

00:24:27.520 --> 00:24:30.800
You can see how many
players can play this game.

00:24:30.800 --> 00:24:34.310
Games support up to 16 players,
and this is going to come up when you

00:24:34.310 --> 00:24:36.250
add how many games are in your code.

00:24:36.260 --> 00:24:40.060
You can use this button here to
add players or remove players.

00:24:40.060 --> 00:24:42.410
If you'd like to invite one
of your Game Center friends,

00:24:42.410 --> 00:24:45.010
you can tap on Invite Friend,
and you're presented with a list

00:24:45.010 --> 00:24:46.380
of your Game Center friends.

00:24:46.400 --> 00:24:51.020
New in iOS 5 is the ability to
have a photo attached to your user.

00:24:51.020 --> 00:24:55.690
So this is a really good way for me to
see if this is actually Corey or not.

00:24:55.900 --> 00:24:58.340
This Play Now button in
the upper right-hand corner

00:24:58.340 --> 00:24:59.800
is also pretty powerful.

00:24:59.800 --> 00:25:01.510
What this lets you do is,
if you don't want to

00:25:01.510 --> 00:25:03.530
invite specific friends,
you can say Auto Match,

00:25:03.530 --> 00:25:07.220
and Game Center will find your friends
and automatically match you with game

00:25:07.220 --> 00:25:08.710
players who are good to play with.

00:25:08.800 --> 00:25:13.200
So what I'd like to do is
go ahead and play a turn.

00:25:14.900 --> 00:25:16.810
Now, let's see,
we're playing a little bit of

00:25:16.810 --> 00:25:18.400
a self-referential game here.

00:25:18.400 --> 00:25:24.400
What I'd like to point out is this game
is entirely implemented inside of UIKit,

00:25:24.560 --> 00:25:26.560
and it's running at 60 frames per second.

00:25:26.580 --> 00:25:30.230
What that lets me do is have
a very interactive game where

00:25:30.230 --> 00:25:32.640
I feel like I'm actually touching
the environment that I'm in.

00:25:32.640 --> 00:25:37.190
I'm picking up those tiles,
laying them down, and I'll play my turn.

00:25:38.010 --> 00:25:41.440
So, given that this is in UIKit,
in iOS 5,

00:25:41.650 --> 00:25:44.800
you can customize even more of UIKit,
which is really powerful.

00:25:44.900 --> 00:25:48.460
This allows you to get the look you
want in your game and still have the

00:25:48.460 --> 00:25:51.800
feeling of our buttons and our behavior,
so your users are going to

00:25:51.840 --> 00:25:53.490
understand how to play your game.

00:25:53.500 --> 00:25:56.050
I asked our guys to go ahead
and make a menu that fit in with

00:25:56.320 --> 00:25:59.000
the look and feel of this game,
and you can see that this fits

00:25:59.000 --> 00:26:00.800
into my gameplay pretty nicely.

00:26:00.800 --> 00:26:02.800
You can start an online
match up at the top.

00:26:02.800 --> 00:26:04.210
You can also do pass and play.

00:26:04.210 --> 00:26:07.000
You might only have one iPad
on an airplane or something.

00:26:07.570 --> 00:26:10.480
You can still see the games where it's
your turn and go and take a turn there.

00:26:10.480 --> 00:26:13.850
We're also using the
Game Center services to pull down

00:26:13.890 --> 00:26:16.440
your achievements from the server.

00:26:16.440 --> 00:26:18.740
We're sorting those in
an order that we prefer.

00:26:18.740 --> 00:26:20.520
We're going ahead and
putting the completed,

00:26:20.520 --> 00:26:23.580
the earned achievements at the top,
and we're putting the in-progress

00:26:23.580 --> 00:26:25.320
achievements down in the bottom.

00:26:25.320 --> 00:26:28.500
You're looking at a whole
lot of UI table views here,

00:26:28.500 --> 00:26:31.360
and in iOS 5 with the
new interface builder,

00:26:31.360 --> 00:26:34.130
you can now do table cell
view prototyping directly

00:26:34.130 --> 00:26:37.400
inside of interface builder,
which is going to let you have a rapid

00:26:37.400 --> 00:26:39.140
iteration of your user interface.

00:26:39.310 --> 00:26:40.840
We think this is pretty powerful too.

00:26:47.100 --> 00:26:50.100
I'd also like to show you
what we did with leaderboards.

00:26:50.100 --> 00:26:52.030
In addition to making
it look like your game,

00:26:52.110 --> 00:26:55.100
you can also go ahead
and add functionality.

00:26:55.100 --> 00:26:56.800
Right here we have our
friend's leaderboard.

00:26:56.800 --> 00:26:58.100
You can see our friend's pictures.

00:26:58.100 --> 00:27:01.880
Again, when I'm looking at Lyricist,
it's good to know that that's really her.

00:27:01.880 --> 00:27:05.180
But our designer really felt like
you should be able to start a game

00:27:05.180 --> 00:27:06.960
from inside of the leaderboard.

00:27:06.960 --> 00:27:08.510
Maybe I want to knock
Lyricist down a peg,

00:27:08.600 --> 00:27:11.120
maybe I want an easy game,
so I'll play with Hans Sutter.

00:27:11.120 --> 00:27:14.100
But you can launch that game here
without going back and starting a new

00:27:14.120 --> 00:27:16.020
game and looking for your friend again.

00:27:17.100 --> 00:27:19.340
The last thing I'd like to
point out are these buttons.

00:27:19.340 --> 00:27:22.900
So if you look at the challenge button,
the back button, the refresh button,

00:27:22.940 --> 00:27:25.440
these little lozenges,
we're using a feature in iOS 5

00:27:25.480 --> 00:27:27.200
in UIKit called UI Appearance.

00:27:27.200 --> 00:27:31.180
UI Appearance is very powerful because
what it lets you do is configure the

00:27:31.250 --> 00:27:35.100
look and feel for an entire class
of buttons or class of controllers.

00:27:35.100 --> 00:27:37.960
You can either tint our controller
or you can replace it with artwork

00:27:37.960 --> 00:27:40.800
of your own in order to have a
completely customized look and feel.

00:27:40.830 --> 00:27:43.290
To do all of these buttons
throughout the whole game was one

00:27:43.290 --> 00:27:44.940
line of code for our developers.

00:27:44.960 --> 00:27:46.600
Which is pretty cool.

00:27:47.100 --> 00:27:52.270
So that's word for word.

00:27:52.410 --> 00:27:54.100
Thanks, John.

00:27:57.900 --> 00:28:00.840
Thank you, Meriko.

00:28:01.000 --> 00:28:05.400
So let's look at some of the other
new features in iOS 5 and Game Center.

00:28:05.420 --> 00:28:06.540
There's achievement banners.

00:28:06.560 --> 00:28:09.900
Achievement banners are when
a player earns an achievement.

00:28:09.930 --> 00:28:12.740
They'll get notified with a banner.

00:28:15.430 --> 00:28:18.130
Custom invite sounds,
where you can build and

00:28:18.130 --> 00:28:21.230
incorporate custom sounds
associated with your application

00:28:21.260 --> 00:28:23.780
when a player receives an invite.

00:28:25.100 --> 00:28:30.370
in-game ratings so your players can rate
your game right inside of the game title,

00:28:30.560 --> 00:28:36.360
so making it easier for players
to get your ratings out there.

00:28:37.700 --> 00:28:41.770
Achievement Leader Boards,
Raising the Visibility of Achievements.

00:28:41.850 --> 00:28:43.580
So now we have Achievement Leader Boards.

00:28:45.310 --> 00:28:46.340
Game recommendations.

00:28:46.480 --> 00:28:50.950
Players will receive recommendations
on games based on what they play.

00:28:52.670 --> 00:28:58.290
and friend recommendations helping
players build their friends network.

00:28:59.990 --> 00:29:04.020
And now players can associate
a photo that they want to

00:29:04.020 --> 00:29:05.720
share with other players.

00:29:07.440 --> 00:29:12.200
So that's Game Center,
Apple's social gaming network.

00:29:12.200 --> 00:29:17.780
It increases player engagement,
raises visibility of your games.

00:29:17.780 --> 00:29:21.020
We highly encourage you to start
taking advantage of all the features

00:29:21.020 --> 00:29:23.460
of Game Center in your game.

00:29:24.610 --> 00:29:27.620
So next,
we're going to talk about AV Foundation.

00:29:27.630 --> 00:29:33.710
AV Foundation is the framework you should
be using for all of your time-based

00:29:33.710 --> 00:29:36.590
media needs in your application.

00:29:37.730 --> 00:29:41.680
We've had AV Foundation on
iOS for some time,

00:29:41.760 --> 00:29:44.630
and we now have brought
AV Foundation to Lion.

00:29:44.630 --> 00:29:49.870
So you can use the same powerful
API in iOS and Mac OS for all

00:29:50.320 --> 00:29:53.590
of your time-based media needs.

00:29:54.680 --> 00:29:58.660
AV Foundation has four
fundamental operations:

00:29:58.730 --> 00:30:02.790
playback, edit, capture, and export.

00:30:04.590 --> 00:30:08.100
And the beauty of the way
we've designed AV Foundation,

00:30:08.100 --> 00:30:13.260
it's designed around some intuitive,
easy-to-use, abstract objects.

00:30:13.340 --> 00:30:15.700
One example of that is AV Asset.

00:30:15.780 --> 00:30:19.140
And AV Asset abstracts your media types.

00:30:19.280 --> 00:30:22.410
So whether it be media on
local storage on device,

00:30:22.480 --> 00:30:27.650
or whether it's coming over the network,
or whether it's a live HTTP stream,

00:30:27.780 --> 00:30:29.280
it's all an AV Asset.

00:30:30.340 --> 00:30:32.870
This is just one example of
how we've tried to design the

00:30:33.020 --> 00:30:36.530
API such that it's easy to use,
so that you'll be able to incorporate all

00:30:36.530 --> 00:30:40.420
of the unique functionality and powerful
functionality into your application.

00:30:43.600 --> 00:30:46.540
So let's talk a little
bit about playback.

00:30:46.600 --> 00:30:48.180
Playback starts with an AV asset.

00:30:48.420 --> 00:30:52.560
You attach an AV player object to
it to control the playback sequence,

00:30:52.650 --> 00:30:54.600
start, stop, fast forward.

00:30:54.660 --> 00:30:58.100
And then to present it,
you use an AV presentation object

00:30:58.820 --> 00:31:02.530
to present it on screen and out
the microphone or the speaker.

00:31:02.760 --> 00:31:04.200
It's that simple.

00:31:04.250 --> 00:31:09.770
But AV Foundation is a very powerful API,
giving you flexibility and

00:31:09.770 --> 00:31:14.140
capabilities to use it in
unique ways in your application.

00:31:14.230 --> 00:31:16.940
For example,
you can use AV Foundation to build

00:31:16.940 --> 00:31:20.600
your own custom user interface
for the playback experience.

00:31:20.620 --> 00:31:24.070
AV Foundation does not have
a built-in user interface.

00:31:24.120 --> 00:31:27.480
To get the default user interface,
you would have to go up to UI kit.

00:31:27.520 --> 00:31:29.180
But when you're at the
AV Foundation layer,

00:31:29.210 --> 00:31:32.360
you would provide your
own user interface.

00:31:32.390 --> 00:31:34.870
We give you all the data you
need to build a complete and

00:31:34.990 --> 00:31:37.260
full-featured playback experience.

00:31:37.300 --> 00:31:40.610
The user elements you would provide
will be composited by core animation,

00:31:40.620 --> 00:31:43.840
giving you a high-performance
user interface.

00:31:43.850 --> 00:31:47.280
And of course,
AV Foundation is an asynchronous API,

00:31:47.280 --> 00:31:54.970
ensuring that the user interface will
remain responsive even under the most

00:31:54.970 --> 00:31:59.010
demanding playback decoding sequences.

00:32:00.440 --> 00:32:05.190
Now new on line in iOS
5 are media options.

00:32:05.260 --> 00:32:10.490
Media options allow you to have
alternate audio tracks and video tracks,

00:32:10.490 --> 00:32:14.550
so you can have support for
things like alternate languages,

00:32:14.580 --> 00:32:17.290
subtitles, closed captions.

00:32:18.570 --> 00:32:22.380
We also give you the ability
to introspect chapter

00:32:22.450 --> 00:32:26.390
information for titles,
play duration, and artwork.

00:32:26.440 --> 00:32:30.080
The combination of these
gives you the ability to build

00:32:30.080 --> 00:32:35.070
complete professional-grade user
interfaces into your application.

00:32:38.330 --> 00:32:40.700
Let's move on to editing.

00:32:40.770 --> 00:32:43.810
Editing starts with a series of assets.

00:32:44.040 --> 00:32:46.900
You're able to take clips
out of those assets,

00:32:47.020 --> 00:32:50.590
sequence them together,
and combine them in an

00:32:50.590 --> 00:32:52.400
AV composition object.

00:32:53.360 --> 00:32:57.470
You can provide transitions
between those sequences,

00:32:57.530 --> 00:32:59.890
such as wipes and blurs,

00:33:00.830 --> 00:33:03.100
You can overlay audio tracks.

00:33:03.140 --> 00:33:06.690
And again, we've provided an intuitive,
easy-to-use model that you

00:33:06.700 --> 00:33:10.400
can use to build this editing
capability into your application.

00:33:10.400 --> 00:33:14.190
But it's also a complete and
professional-grade interface

00:33:14.530 --> 00:33:19.030
that allows you to support the
most demanding editing problems.

00:33:23.680 --> 00:33:24.660
Let's talk about capture.

00:33:24.880 --> 00:33:27.960
So most devices today come with a camera.

00:33:28.030 --> 00:33:31.780
And AV Foundation is how you
will get access to those cameras.

00:33:31.820 --> 00:33:34.030
AV Foundation gives you
control over the camera,

00:33:34.030 --> 00:33:40.170
such as focus, exposure,

00:33:40.310 --> 00:33:43.460
and Control to the Flash,
so you can access the flash,

00:33:43.460 --> 00:33:47.850
allowing you to set the settings of
the camera to get the right video

00:33:47.870 --> 00:33:50.850
and photos that you're desiring.

00:33:52.700 --> 00:33:56.710
In line, we've introduced a new
framework called Core Media I/O.

00:33:56.920 --> 00:34:03.790
Core Media I/O allows you to write device
drivers for your own capture devices.

00:34:03.990 --> 00:34:07.750
integrating them right into
the AV Foundation pipeline,

00:34:07.750 --> 00:34:11.700
making them accessible to
anybody who uses AV Foundation.

00:34:13.870 --> 00:34:15.640
So that's capture.

00:34:15.640 --> 00:34:17.960
And then lastly is export.

00:34:18.180 --> 00:34:24.040
Now how we've made export easy is
we've defined a series of presets.

00:34:24.100 --> 00:34:28.800
These presets are optimized
for classes of devices.

00:34:28.800 --> 00:34:33.430
So you can simply use a preset
when you are exporting or

00:34:33.430 --> 00:34:35.890
transcoding out to a file.

00:34:35.890 --> 00:34:41.450
And you can use those presets to
ensure that the resulting file,

00:34:41.450 --> 00:34:43.780
the resulting video, is being captured.

00:34:43.800 --> 00:34:48.280
And then the final preset, the audio,
is going to give the optimal

00:34:48.280 --> 00:34:52.160
experience during playback
for that family of devices.

00:34:52.230 --> 00:34:55.590
So we have tried to make it
easy for you to get the right

00:34:55.590 --> 00:34:58.280
export properties into the file.

00:35:00.350 --> 00:35:04.700
AV Foundation is based on some
of the best industry codecs,

00:35:04.830 --> 00:35:10.800
such as H.264 for video and AAC,
ensuring the best quality,

00:35:10.810 --> 00:35:16.420
no matter if you're using it for
HD resolution or for something smaller,

00:35:16.420 --> 00:35:21.870
or an AAC for scaling the bit
rate and quality of your audio.

00:35:21.870 --> 00:35:26.150
Two of the best codecs in the world.

00:35:28.780 --> 00:35:33.300
And on Mac OS X,
we provide ProRes encoding for

00:35:33.300 --> 00:35:37.400
integration into professional workflows.

00:35:41.790 --> 00:35:44.770
Now,
we talked about the pipelines of how you

00:35:44.840 --> 00:35:48.700
can have playback and edit and capture,
but what we also allow you to

00:35:48.700 --> 00:35:54.620
do is to get access to those
frames as they're being captured

00:35:54.620 --> 00:35:59.020
and do additional processing on
them before they get displayed.

00:35:59.020 --> 00:36:02.430
So you can use OpenGL or the
CPU to do additional processing,

00:36:02.430 --> 00:36:04.670
and we've had that on AV Foundation.

00:36:04.940 --> 00:36:09.250
Well, new for Line and iOS 5,
we now allow you to get

00:36:09.500 --> 00:36:14.050
frame-level access to the
video and the stills on export,

00:36:14.050 --> 00:36:19.870
allowing you to use Core Image, OpenGL,
and the CPU to modify, edit,

00:36:20.010 --> 00:36:23.950
to enhance the photos
and video on export.

00:36:28.450 --> 00:36:29.790
So that's AV Foundation.

00:36:29.810 --> 00:36:32.680
AV Foundation has a wealth of classes.

00:36:32.720 --> 00:36:38.120
We'll have four sessions this week
going into the details of AV Foundation.

00:36:38.130 --> 00:36:40.330
And we encourage you to learn
all the details of how you

00:36:40.360 --> 00:36:42.540
can take advantage of it.

00:36:43.360 --> 00:36:46.420
So AV Foundation,
it's the framework that you should

00:36:46.420 --> 00:36:51.490
be using for your time-based
media needs in your application.

00:36:53.370 --> 00:36:55.290
Next is Core Image.

00:36:55.360 --> 00:36:59.310
Core Image is our powerful
image processing framework.

00:37:01.030 --> 00:37:06.610
We've had Core Image on Lion,
on Mac OS X for some time,

00:37:06.660 --> 00:37:09.670
and now we've brought it to iOS.

00:37:09.740 --> 00:37:12.590
So we now are giving you
the same powerful image

00:37:12.680 --> 00:37:16.870
processing framework on iOS.

00:37:18.840 --> 00:37:23.000
Let's look a little bit closer
at how Core Image works.

00:37:23.040 --> 00:37:27.200
Core Image,
you can take a still image or a frame

00:37:27.200 --> 00:37:31.360
out of a video and apply an effect to it.

00:37:31.390 --> 00:37:35.340
In this case, I'm showing applying
a sepia filter effect,

00:37:35.340 --> 00:37:41.660
and that filter operates on each
individual pixel in that image.

00:37:41.680 --> 00:37:45.350
Now, Core Image allows you to
chain filters together.

00:37:45.950 --> 00:37:50.910
and you can build simple or
very complex filter chains.

00:37:50.920 --> 00:37:53.850
And what Core Image will do is,
when possible,

00:37:53.850 --> 00:37:58.450
it'll take those filters and coalesce
them together and in real time

00:37:58.450 --> 00:38:02.210
recompile them into an optimal filter.

00:38:02.810 --> 00:38:07.170
that you can target against a CPU or GPU,
ensuring the maximum performance,

00:38:07.170 --> 00:38:11.400
no matter how complex of a
filter chain you're building.

00:38:15.190 --> 00:38:22.730
So on iOS 5, we've brought a number of
powerful filters for you to use

00:38:22.880 --> 00:38:24.940
built right into Core Image.

00:38:24.950 --> 00:38:28.800
These filters are targeted
towards photographic effects,

00:38:28.800 --> 00:38:34.550
like color controls, crop, straighten,
affine transform, shadow adjust.

00:38:34.760 --> 00:38:40.970
These are available for you to build your
filter chains and to process your photos.

00:38:41.870 --> 00:38:44.860
We've also introduced a series of APIs.

00:38:44.910 --> 00:38:50.320
What these APIs do is they build filter
chains for you to give you a more complex

00:38:50.820 --> 00:38:53.660
filtering operation automatically.

00:38:53.780 --> 00:38:56.360
The first one is Auto-enhance.

00:38:56.390 --> 00:39:02.250
Auto-enhance gives you that same
one-touch enhancement that we

00:39:02.270 --> 00:39:05.910
built right into iOS 5 photo app.

00:39:06.010 --> 00:39:10.270
You now have access to that same
capability right through Core Image.

00:39:11.960 --> 00:39:14.560
We also have face detection.

00:39:14.600 --> 00:39:17.780
With an API call,
face detection will identify

00:39:17.780 --> 00:39:21.440
the rectangles in the
image that contain faces,

00:39:21.440 --> 00:39:23.610
allowing you to focus--

00:39:26.500 --> 00:39:30.320
Allowing you to focus your image
processing based on the information

00:39:30.360 --> 00:39:31.640
returned by those rectangles.

00:39:34.600 --> 00:39:36.840
Also, red-eye reduction.

00:39:36.840 --> 00:39:41.560
One function call to achieve the
same red-eye reduction that we

00:39:41.560 --> 00:39:49.190
offer you in our photo application,
iOS 5, through an API call.

00:39:51.770 --> 00:39:55.590
So that's Core Image,
the same powerful image

00:39:55.590 --> 00:39:57.500
processing framework.

00:39:57.510 --> 00:40:03.930
We've brought it to iOS 5 with a
set of powerful filters that you can

00:40:03.930 --> 00:40:07.180
use for your photo editing needs.

00:40:09.280 --> 00:40:10.980
Next, I want to talk about AirPlay.

00:40:11.040 --> 00:40:19.630
AirPlay allows you to stream audio,

00:40:20.900 --> 00:40:28.540
to an Apple TV,
as well as two third-party devices

00:40:28.540 --> 00:40:28.540
that support the AirPlay protocol.

00:40:29.730 --> 00:40:34.330
AirPlay also allows you to
stream video to an Apple TV,

00:40:34.470 --> 00:40:37.180
HD resolution video.

00:40:39.340 --> 00:40:42.840
And with iPad 2,
we introduced an audio/video cable

00:40:43.260 --> 00:40:45.950
that allowed you to mirror the display.

00:40:47.690 --> 00:40:53.030
With AirPlay,
we now can mirror the display wirelessly.

00:40:59.990 --> 00:41:06.930
This gives you an HD resolution
wireless mirroring through AirPlay.

00:41:07.830 --> 00:41:11.410
And the interesting
opportunity for you developers,

00:41:11.410 --> 00:41:17.010
I want to point out, is that-- yeah.

00:41:21.240 --> 00:41:27.020
So we've integrated AirPlay in such
a way that that wireless display

00:41:27.660 --> 00:41:31.200
behaves the same as though
somebody plugged that cable in.

00:41:31.300 --> 00:41:33.280
So it looks like a second display to you.

00:41:33.330 --> 00:41:37.580
And if you have already started using

00:41:38.290 --> 00:41:42.200
The second display as a feature in
your application where you can have it

00:41:42.270 --> 00:41:46.630
being out the window like this shows,
and then the handheld being some other

00:41:46.660 --> 00:41:50.860
information like course information and
being able to use it as a steering wheel.

00:41:50.860 --> 00:41:55.460
It will just work that same
way with AirPlay Video.

00:41:55.460 --> 00:41:59.190
And I think that poses some unique
opportunities for you to leverage

00:41:59.330 --> 00:42:03.010
this capability in your application,
integrating you into the

00:42:03.010 --> 00:42:04.740
family room environment.

00:42:05.520 --> 00:42:09.020
So to demonstrate this,
I'm going to bring Geoff on stage

00:42:09.020 --> 00:42:11.410
and we're going to do a demo of this.

00:42:16.920 --> 00:42:17.700
Thanks, John.

00:42:17.700 --> 00:42:21.360
So first thing we'll do is let's
go through AirPlay and show

00:42:21.360 --> 00:42:23.080
you how you can enable that.

00:42:23.280 --> 00:42:25.600
We bring up the multitasking bar.

00:42:25.600 --> 00:42:27.400
We'll quit that app.

00:42:27.430 --> 00:42:29.460
We'll slide over to the
Now Playing controls,

00:42:29.460 --> 00:42:32.000
and you notice there's that
AirPlay icon right there.

00:42:32.000 --> 00:42:34.720
We tap on the AirPlay icon,
and you see we have the iPad

00:42:35.000 --> 00:42:36.560
and the Great Room Apple TV.

00:42:36.560 --> 00:42:39.850
If I select the Great Room Apple TV,
we now have that new controls

00:42:39.920 --> 00:42:41.720
as a mirroring of the iPad 2.

00:42:42.180 --> 00:42:44.980
What you have here is
you have your AV assets.

00:42:44.980 --> 00:42:48.580
So if you're playing audio
or you're playing a video,

00:42:48.580 --> 00:42:51.460
that's going to your Great Room Apple TV.

00:42:51.460 --> 00:42:53.940
If I turn mirroring on, we mirror.

00:42:53.940 --> 00:42:58.050
And I think we need to bring
up the Apple TV at this point.

00:43:01.610 --> 00:43:03.030
There we go.

00:43:03.090 --> 00:43:06.710
So now let's go demonstrate that again
so you actually can see that we do

00:43:06.710 --> 00:43:08.740
have the Apple TV hooked up there.

00:43:08.880 --> 00:43:12.920
So if I do a back to select back to iPad,
we have our Apple TV.

00:43:13.010 --> 00:43:16.500
Of course, like Apple TV,
remembers your settings

00:43:16.500 --> 00:43:18.010
as you would expect.

00:43:19.350 --> 00:43:24.720
So now let's look at the
Real Racing example and show you what

00:43:24.720 --> 00:43:28.780
they did to integrate the controls in
front of the player while putting the

00:43:28.790 --> 00:43:30.880
play experience up on the Apple TV.

00:43:31.390 --> 00:43:39.610
Launched Real Racing.

00:43:39.610 --> 00:43:39.610
If you notice the menu
bar on top was blue,

00:43:39.610 --> 00:43:39.610
status bar was blue,
and that indicates you're

00:43:39.610 --> 00:43:39.610
actually in airplane mode.

00:43:51.900 --> 00:43:53.910
Okay,
so I have my controls up on this side.

00:43:54.090 --> 00:43:55.440
You have the car.

00:43:55.440 --> 00:43:59.000
And what we can do is we can
hop right into a quick race.

00:43:59.650 --> 00:44:00.600
That's my track.

00:44:00.600 --> 00:44:01.500
I want to do a single lap there.

00:44:01.500 --> 00:44:02.600
That looks good.

00:44:02.600 --> 00:44:05.600
Tap on the track into racing.

00:44:05.600 --> 00:44:08.600
So now I'm going to have the status,
what the track looks like,

00:44:08.600 --> 00:44:12.100
what the upcoming corners are,
where I am in the race in front of me,

00:44:12.100 --> 00:44:16.600
and everyone in the living room and the
great room can enjoy the race itself.

00:44:16.600 --> 00:44:20.710
And of course,
controlling directly with your iPad.

00:44:22.900 --> 00:44:25.240
There we go.

00:44:25.240 --> 00:44:26.140
Not starting off very good.

00:44:26.140 --> 00:44:26.980
I'm in last place.

00:44:26.980 --> 00:44:29.540
We're seeing if we can
pass a few cars here.

00:44:29.540 --> 00:44:31.980
Sliding by on the right.

00:44:34.900 --> 00:44:37.900
Right in front of me,
I can see exactly what's going on.

00:44:37.900 --> 00:44:41.550
The airplay.

00:44:46.200 --> 00:44:48.100
I guess the move's an awesome experience.

00:44:48.100 --> 00:44:50.500
Great control here.

00:44:50.500 --> 00:44:53.200
Great work with the visuals and airplay.

00:44:53.200 --> 00:44:55.200
You've been hanging on the track.

00:44:55.200 --> 00:44:56.200
And I'll hand it back to John.

00:44:56.200 --> 00:44:58.550
Thank you very much.

00:45:04.400 --> 00:45:06.490
Thank you, Geoff.

00:45:06.610 --> 00:45:09.840
So AirPlay, we think, is incredible.

00:45:09.840 --> 00:45:12.920
And we think it gives you some
interesting opportunities for

00:45:12.930 --> 00:45:14.580
how to stream audio and video.

00:45:14.580 --> 00:45:16.800
Now, AirPlay is not a framework.

00:45:16.800 --> 00:45:20.060
What AirPlay is,
is it's a system service.

00:45:20.060 --> 00:45:23.720
And how you control it is
distributed through other frameworks.

00:45:23.720 --> 00:45:29.880
For instance, the media player is where
the user interface is for

00:45:29.890 --> 00:45:32.730
routing of video and audio.

00:45:33.980 --> 00:45:36.940
UI screen is how you,
the class you'll use to get

00:45:36.940 --> 00:45:41.020
access to be able to drive the
second display independently.

00:45:41.020 --> 00:45:45.250
Or AV Foundation that gives you control
over the streaming characteristics

00:45:45.250 --> 00:45:47.300
you want for your video and audio.

00:45:47.300 --> 00:45:50.220
So I encourage you to go
to the AirPlay sessions.

00:45:50.220 --> 00:45:54.280
Learn how to take advantage of this
and learn what control and APIs you

00:45:54.280 --> 00:45:58.660
should be using to get the right
behaviors for you and your application.

00:46:01.870 --> 00:46:07.380
So that's AirPlay,
wireless streaming of video and audio,

00:46:07.380 --> 00:46:14.470
a great opportunity for you to integrate
with wireless displays and audio devices.

00:46:16.790 --> 00:46:19.910
So when we build these
technologies at Apple,

00:46:20.180 --> 00:46:23.300
we put a lot of thought into
how they can play together,

00:46:23.380 --> 00:46:27.940
how people, you developers,
may want to use them together

00:46:27.940 --> 00:46:32.040
to build unique solutions,
use them in innovative ways

00:46:32.040 --> 00:46:33.250
we haven't thought about.

00:46:33.260 --> 00:46:36.730
So we put a lot of time into
high-performance integration

00:46:36.730 --> 00:46:40.600
of these technologies,
allowing you to mix and match them.

00:46:41.700 --> 00:46:45.500
And to show you a little demo we put
together to try to show that off because

00:46:45.600 --> 00:46:48.520
we thought it would be worthwhile to
give one last punch in this session,

00:46:48.520 --> 00:46:52.210
I'm going to bring Meriko up on
stage and show off a demonstration.

00:46:52.220 --> 00:46:54.080
Meriko Borogrove, Geoff Stauffer Thanks,
John.

00:46:58.900 --> 00:47:01.650
If you guys bring up the Apple TV for me,
that would be great.

00:47:01.660 --> 00:47:04.680
In the 1920s,
the surrealists invented a parlor game,

00:47:05.120 --> 00:47:07.500
called the Exquisite Corpse.

00:47:07.500 --> 00:47:10.240
And the way they would play Exquisite
Corpse is they'd sit around,

00:47:10.240 --> 00:47:13.180
somebody would write a sentence or so,
and fold over the paper,

00:47:13.180 --> 00:47:15.140
so that you could just see the last word.

00:47:15.140 --> 00:47:17.800
They'd pass it to their friend,
and that person would take

00:47:17.800 --> 00:47:20.630
that word and key off of it and
write another sentence or two.

00:47:20.760 --> 00:47:22.980
Fold over the paper,
leaving just the last word,

00:47:23.000 --> 00:47:24.930
and then they'd continue on from there.

00:47:24.940 --> 00:47:27.400
They created crazy stories
that had a really interesting

00:47:27.400 --> 00:47:28.760
thread running through them.

00:47:28.760 --> 00:47:31.340
So over the last five or six days,
we challenged our engineers to do

00:47:31.340 --> 00:47:34.760
that with the technologies that
you've seen in this kickoff today.

00:47:34.760 --> 00:47:37.490
And I'd love to show you our story.

00:47:38.510 --> 00:47:42.500
So the first thing I'm going
to do is bring up AirPlay,

00:47:42.500 --> 00:47:46.880
because I think 720p
streaming is awesome.

00:47:51.890 --> 00:47:56.280
Okay, so the first thing that they wrote
was a fluid dynamic simulation.

00:47:56.320 --> 00:48:00.400
It's written in GLSL with
a huge series of shaders.

00:48:00.500 --> 00:48:06.840
It has density and acceleration being
injected into the simulation by my touch.

00:48:06.870 --> 00:48:11.720
The color is keying off of the mass
of the particles in the plasma.

00:48:11.720 --> 00:48:13.640
It's quite computationally intensive.

00:48:13.720 --> 00:48:16.110
I also think it's quite beautiful.

00:48:16.360 --> 00:48:19.570
The first thing that they decided
to key off was that density.

00:48:19.640 --> 00:48:23.040
And what we've done is we've
brought up an audio track,

00:48:23.040 --> 00:48:26.600
and we're controlling the
complexity of the audio track on

00:48:26.610 --> 00:48:28.980
the density of the simulation.

00:48:28.980 --> 00:48:33.300
So you can just hear a percussion
line with a little plasma.

00:48:33.330 --> 00:48:35.680
You can hear the bass come in.

00:48:35.900 --> 00:48:38.740
I really start kind of playing.

00:48:38.750 --> 00:48:40.440
Bring up a guitar.

00:48:40.440 --> 00:48:42.810
And if I really get crazy,

00:48:44.300 --> 00:48:45.300
and John Steele.

00:48:45.300 --> 00:48:46.300
You can get a second guitar line in.

00:48:46.300 --> 00:48:51.460
So what we're doing here is I have a
movie file with four synced audio tracks,

00:48:51.460 --> 00:48:53.360
one for each instrument.

00:48:53.360 --> 00:48:57.870
I'm using AV Foundation to play them
back and to mix based on the density

00:48:57.870 --> 00:49:01.110
of the plasma in the simulation.

00:49:01.130 --> 00:49:04.460
I'm using the pan and the
volume controls to do that.

00:49:04.460 --> 00:49:07.170
And that movie is my AV asset that
John was talking to you about.

00:49:09.100 --> 00:49:13.780
So the next thing that we thought
about injecting in was some extra mass.

00:49:13.780 --> 00:49:17.490
And to do that,
we started taking some input

00:49:17.490 --> 00:49:19.780
off the front-facing camera.

00:49:23.200 --> 00:49:28.300
See, I can continue running along here.

00:49:28.300 --> 00:49:31.750
One of the great things about a shader
is that you can change the look and

00:49:31.750 --> 00:49:35.200
feel of it very simply with parameters
once you've got your shader written.

00:49:35.200 --> 00:49:37.720
I kind of like this ghost look.

00:49:49.400 --> 00:49:52.660
The CineDation API have a bunch
of new performance enhancements

00:49:52.660 --> 00:49:54.380
in iOS 5 that are fantastic.

00:49:54.430 --> 00:49:56.970
You can take your CV pixel
buffers and you can send them

00:49:56.970 --> 00:49:58.400
straight to a GL texture.

00:49:58.400 --> 00:50:01.670
The way we're doing this is we're taking
that frame and we're processing it

00:50:01.690 --> 00:50:03.830
with an edge map that's a GLSL shader.

00:50:03.840 --> 00:50:07.460
And then we're taking that
edge map and using it to inject

00:50:07.470 --> 00:50:09.490
mass into the simulation.

00:50:09.600 --> 00:50:12.480
Next thing we kind of thought
about is that maybe we could

00:50:12.570 --> 00:50:14.230
add some acceleration in.

00:50:14.260 --> 00:50:16.400
And we've got these
great Core Motion API.

00:50:16.400 --> 00:50:19.810
So we keyed off of acceleration,
and we're measuring the

00:50:19.810 --> 00:50:21.430
acceleration of the iPad.

00:50:22.400 --> 00:50:25.500
Adding acceleration to the particles.

00:50:25.500 --> 00:50:26.470
And that's just really surreal.

00:50:29.000 --> 00:50:30.400
You can still see me.

00:50:30.400 --> 00:50:33.700
So the last thing that we keyed
off of is the entire scene.

00:50:33.700 --> 00:50:36.220
We wrapped it up and
we put it on a texture.

00:50:36.220 --> 00:50:38.720
And if you've been in a media
and graphics State of the

00:50:38.720 --> 00:50:42.200
Union or a Kickoff before,
you know what we do with textures,

00:50:42.200 --> 00:50:44.260
which is we map them on 3D objects.

00:50:44.260 --> 00:50:49.350
You can see.

00:50:58.400 --> 00:51:01.730
We used GLKit to bring up this scene,
and we used all three of the

00:51:01.730 --> 00:51:03.590
performance debugging tools earlier.

00:51:03.590 --> 00:51:06.830
They were successful there,
and optimized the performance to

00:51:06.830 --> 00:51:08.460
keep the frame rate full here.

00:51:08.460 --> 00:51:12.980
So I guess what I'd really like to do
is recap the storyline for you here.

00:51:12.980 --> 00:51:17.400
So what we've got is we have a full fluid
dynamics simulation running on the GPU.

00:51:17.400 --> 00:51:21.820
It has density and acceleration
being injected by my fingers.

00:51:22.800 --> 00:51:28.820
It has mass being injected by
camera frames that are being

00:51:28.820 --> 00:51:33.210
processed again on the GPU,
mapped to the surfaces of this cube,

00:51:33.250 --> 00:51:36.500
along with a real-time video preview
being processed to black and white,

00:51:36.500 --> 00:51:41.510
all on a spinning cube in 3D space,
streaming at 720p to my Apple TV,

00:51:41.520 --> 00:51:43.180
all from my iPad 2.

00:51:59.900 --> 00:52:11.610
and the team at Microsoft are here
to share their exquisite story.

00:52:11.610 --> 00:52:11.610
Back to you, John.

00:52:11.610 --> 00:52:11.610
JOHN STAFFER: I'm glad to hear you clap.

00:52:12.300 --> 00:52:16.570
It's amazing what you can do on
iPads nowadays and with iOS and

00:52:16.680 --> 00:52:20.180
Mac OS because that is an incredible
amount of computing that's going

00:52:20.180 --> 00:52:22.470
on there to drive those simulations.

00:52:22.470 --> 00:52:23.680
It's absolutely incredible.

00:52:25.800 --> 00:52:32.220
So this week, we have 22 sessions
covering the Graphics,

00:52:32.220 --> 00:52:33.560
Media, and Games technologies.

00:52:33.560 --> 00:52:36.690
And hopefully,
we gave you a little bit of an

00:52:36.690 --> 00:52:41.450
insight about what you may want
to learn and go dive deep into and

00:52:41.450 --> 00:52:44.360
integrate into your application.

00:52:44.360 --> 00:52:47.550
We also have 25 labs.

00:52:47.940 --> 00:52:51.210
These labs are great opportunities for
you to go and talk to the engineers

00:52:51.370 --> 00:52:54.520
that build these technologies,
getting help from them,

00:52:54.520 --> 00:52:58.110
asking them the most detailed
and difficult questions about how

00:52:58.330 --> 00:53:02.350
you should be using and taking
advantage of these technologies.

00:53:02.360 --> 00:53:06.320
So hopefully, we kicked off your week
in a useful manner.

00:53:06.320 --> 00:53:09.320
And thank you for coming,
and welcome to WWDC.