WEBVTT

00:00:10.390 --> 00:00:13.490
Good afternoon.

00:00:13.620 --> 00:00:16.630
Happy World IPv6 Day.

00:00:21.110 --> 00:00:22.440
My name is Sam Bushell.

00:00:22.440 --> 00:00:27.500
I work on writing code and fixing
bugs on our media frameworks.

00:00:27.560 --> 00:00:32.490
And today I'm talking to you about
working with Media in AV Foundation.

00:00:33.750 --> 00:00:37.040
The APIs and tools I'm going to
talk about today were introduced

00:00:37.240 --> 00:00:42.440
in iOS 4 and some of them were
added in iOS 4.1 and now they're

00:00:42.440 --> 00:00:45.830
all brought to Lion in Mac OS X.

00:00:46.330 --> 00:00:52.340
They're the same APIs and tools
that we use to build iMovie for iOS

00:00:52.730 --> 00:00:56.830
and QuickTime Player 10 for Lion.

00:00:59.320 --> 00:01:02.260
And I'm going to do some demos.

00:01:02.280 --> 00:01:04.990
The sample code for those
demos is live on the web.

00:01:04.990 --> 00:01:08.990
And if you go to the schedule
page for this session,

00:01:09.200 --> 00:01:11.500
there's a link to the sample code there.

00:01:11.540 --> 00:01:13.960
And I recommend that if you
want to follow along with some

00:01:14.030 --> 00:01:17.330
of the code samples I'm going
to go through on the slides,

00:01:17.330 --> 00:01:20.590
you can look at the file
called simpleeditor.m for

00:01:20.960 --> 00:01:22.970
more details and more context.

00:01:25.780 --> 00:01:28.120
So let's look at where
AV Foundation fits in.

00:01:28.120 --> 00:01:32.040
AV Foundation is an
Objective-C framework that sits upon

00:01:32.040 --> 00:01:36.280
the foundations of the C frameworks,
Core Audio, Core Media, Core Animation,

00:01:36.310 --> 00:01:38.880
Core Video, and so forth.

00:01:38.900 --> 00:01:42.080
And it's below the level of UIKit.

00:01:42.560 --> 00:01:45.840
Which means that we can deliver
the same framework and more

00:01:45.840 --> 00:01:49.600
or less the same APIs on iOS.

00:01:50.120 --> 00:01:51.840
and Alan Lyon.

00:01:51.910 --> 00:01:57.230
So the things I'm telling you about
today are uniform across those.

00:02:00.110 --> 00:02:04.110
So I'm going to go through a number of
scenarios today and talk about how you

00:02:04.160 --> 00:02:08.170
can use AV Foundation's APIs and tools
to deliver those kinds of features

00:02:08.540 --> 00:02:10.910
to your users in your applications.

00:02:11.020 --> 00:02:16.470
I'm going to talk about how to
generate a still image from a movie,

00:02:16.680 --> 00:02:19.640
how to export a movie to a new file,

00:02:20.430 --> 00:02:25.590
How to assemble a movie from
clips from other source movies.

00:02:25.740 --> 00:02:28.130
How to add an additional audio.

00:02:28.300 --> 00:02:31.740
How to add video
transitions like crossfades.

00:02:31.920 --> 00:02:34.180
How to add core animation.

00:02:34.970 --> 00:02:39.980
and my colleague Adam Sonnanstine
is going to tell you about how to

00:02:40.430 --> 00:02:45.200
extract audio and video data from
movies and how to build a new movie

00:02:45.730 --> 00:02:48.270
from your own video and audio data.

00:02:50.520 --> 00:02:52.560
But first,
let's talk about some fundamentals

00:02:52.560 --> 00:02:54.230
that AV Foundation is based on.

00:02:54.300 --> 00:02:56.730
I want to introduce the
framework CoreMedia.

00:02:56.860 --> 00:03:00.440
CoreMedia is a C framework
that provides some basic data

00:03:00.440 --> 00:03:03.190
types that AV Foundation uses.

00:03:03.550 --> 00:03:07.140
The most important one for
our session is called CM Time.

00:03:07.250 --> 00:03:11.440
CM Time is a C struct
like CG Size or CG Rect,

00:03:11.480 --> 00:03:14.940
and it's a struct type
that defines rational time.

00:03:14.970 --> 00:03:18.190
It's counting a number of seconds
as a rational with a 64-bit

00:03:18.250 --> 00:03:22.500
numerator and a 32-bit denominator
that we call a time scale.

00:03:23.710 --> 00:03:26.080
We have constants for zero,
positive infinity,

00:03:26.080 --> 00:03:28.650
negative infinity and so forth.

00:03:28.790 --> 00:03:30.890
We have utilities for adding
and subtracting and various

00:03:30.940 --> 00:03:33.400
other arithmetical utilities.

00:03:33.530 --> 00:03:37.700
We have utilities for
comparing CM time values.

00:03:37.820 --> 00:03:41.100
And if you have a start
time and a duration,

00:03:41.410 --> 00:03:43.630
you can construct a time range.

00:03:43.730 --> 00:03:47.000
And if you have two time ranges,
that's called a mapping.

00:03:48.810 --> 00:03:53.740
So, enough of core media,
let's move out and look at AV Foundation.

00:03:53.840 --> 00:03:59.320
In yesterday's session,
Simon introduced AV Asset.

00:04:00.680 --> 00:04:03.800
AV Asset is what you use in
AV Foundation to represent

00:04:03.800 --> 00:04:06.100
a movie that's in a file.

00:04:06.420 --> 00:04:11.280
And inside AV Asset,
you can browse and find AV Asset tracks,

00:04:11.280 --> 00:04:15.510
each representing the video
and audio tracks in the movie.

00:04:16.810 --> 00:04:19.370
To play an AV asset,
you construct an AV player

00:04:19.370 --> 00:04:23.990
item from the AV asset and then
you attach it to an AV player.

00:04:26.260 --> 00:04:28.700
So let's get into these scenarios.

00:04:28.760 --> 00:04:32.470
First one is creating a
still image from a movie.

00:04:33.170 --> 00:04:37.340
AV Asset Image Generator is
the class used for doing this.

00:04:37.420 --> 00:04:40.970
You build your AV Asset
Image Generator from an asset,

00:04:41.320 --> 00:04:45.200
And then you can ask it to generate
images for you by giving an array

00:04:45.200 --> 00:04:48.110
of the times you want images at.

00:04:48.420 --> 00:04:51.660
Now you need to retain your
image generator until you're

00:04:51.660 --> 00:04:53.600
done getting those images.

00:04:53.720 --> 00:04:55.420
And you'll notice that
I passed in a handle block.

00:04:55.540 --> 00:04:57.540
The handle block is important.

00:04:57.690 --> 00:04:59.540
That's how you get the output.

00:04:59.650 --> 00:05:02.930
And it's important that you check the
result because it may not succeed.

00:05:03.050 --> 00:05:07.130
If it did succeed, then you can go ahead
and use the CG image,

00:05:07.130 --> 00:05:09.410
retain it if you need it later.

00:05:10.500 --> 00:05:13.130
If for some reason it fails,
you can examine the error

00:05:13.130 --> 00:05:14.540
object to find out why.

00:05:14.650 --> 00:05:18.240
And it's also possible for you to cancel
outstanding image generation requests,

00:05:18.240 --> 00:05:21.480
in which case your handle block
will still be called to say

00:05:21.480 --> 00:05:23.640
that this request was cancelled.

00:05:25.960 --> 00:05:28.640
Exporting and trimming movies.

00:05:28.700 --> 00:05:35.040
You export an AV asset to a new file
using the class AV asset export session.

00:05:36.240 --> 00:05:37.960
Whenever you make an
AV asset export session,

00:05:37.960 --> 00:05:40.100
you have to specify a preset.

00:05:40.150 --> 00:05:43.940
We have presets for different
sizes and bit rates and so forth.

00:05:45.720 --> 00:05:49.260
You have to specify the
output URL and the file type.

00:05:49.560 --> 00:05:52.510
In this case,
we're generating a QuickTime movie.

00:05:52.920 --> 00:05:54.900
Optionally, you can set a time range.

00:05:54.920 --> 00:05:58.970
If you don't set a time range,
then we'll export the entire asset.

00:06:00.730 --> 00:06:06.190
You can also optionally
modify or add metadata.

00:06:06.200 --> 00:06:09.340
And then you kick off the export
asynchronously and provide

00:06:09.340 --> 00:06:12.750
another handler block that's
called when it's all done.

00:06:13.300 --> 00:06:16.280
Again, the handle block looks a lot
like the one for image generator

00:06:16.890 --> 00:06:19.100
and you should examine the
status to see if it completed,

00:06:19.220 --> 00:06:21.960
failed or if you cancelled it.

00:06:22.480 --> 00:06:24.460
So I'm not going to give a
demo of either of those cases.

00:06:24.460 --> 00:06:29.240
They're fairly basic and you can use
the sample code to do that yourself.

00:06:29.320 --> 00:06:32.670
I do want to talk about
error handling for a moment.

00:06:32.890 --> 00:06:36.220
It's important that you
handle failures gracefully.

00:06:38.290 --> 00:06:40.360
AV asset export session
will not overwrite files.

00:06:40.360 --> 00:06:41.660
If you try, it will fail.

00:06:41.810 --> 00:06:44.780
If you want to overwrite a file,
it's your responsibility

00:06:44.780 --> 00:06:46.130
to delete it first.

00:06:46.660 --> 00:06:49.270
On iOS,
your application is restricted to a

00:06:49.270 --> 00:06:53.130
certain sandbox and AV asset export
session cannot be used to write files

00:06:53.160 --> 00:06:55.870
outside your application sandbox.

00:06:59.340 --> 00:07:05.710
Also on iOS, the multitasking features of
iOS let the user go off and do

00:07:05.710 --> 00:07:09.200
something else while your export
can continue in the background.

00:07:09.200 --> 00:07:13.440
And this is a great feature,
but it introduces more situations

00:07:13.440 --> 00:07:16.200
where export could fail after a while.

00:07:16.450 --> 00:07:18.200
For example,

00:07:18.410 --> 00:07:21.290
If the user goes and
starts playback of video,

00:07:21.290 --> 00:07:24.530
that might use resources that
you'd been using for your export,

00:07:24.530 --> 00:07:29.100
and so that playback could interrupt that
background export and cause it to fail.

00:07:29.230 --> 00:07:31.980
But even if your application
is still in the foreground,

00:07:31.980 --> 00:07:33.000
export can fail.

00:07:33.130 --> 00:07:37.690
For example, an incoming phone call or
FaceTime call can interrupt export.

00:07:39.460 --> 00:07:43.740
So let's move along to the next things.

00:07:43.750 --> 00:07:48.580
Let's talk about AV composition, which,
along with AV Asset,

00:07:48.590 --> 00:07:52.260
are the cornerstones of
editing in AV Foundation.

00:07:53.180 --> 00:07:55.900
We've seen how you can use
AV Asset as a source object

00:07:56.000 --> 00:07:59.110
representing a single movie,
and then you can use that

00:07:59.110 --> 00:08:03.780
AV Asset for playback with
AV Player and AV Player Item,

00:08:03.940 --> 00:08:08.200
for image generation with
AV Asset Image Generator,

00:08:08.880 --> 00:08:11.430
for export with AV Asset Export Session.

00:08:11.430 --> 00:08:14.280
And a little later on,
you'll see how you can use it with

00:08:14.280 --> 00:08:19.000
AV Asset Reader to extract audio
and video data out of the asset.

00:08:19.860 --> 00:08:22.240
What about the case where you
have several source movies and

00:08:22.240 --> 00:08:23.940
you want to put them together?

00:08:23.950 --> 00:08:27.940
AV Foundation's tool for doing
this is called AV Composition.

00:08:28.150 --> 00:08:32.630
And because AV Composition
is a subclass of AV Asset,

00:08:32.770 --> 00:08:35.940
you can use it in the same great
ways that you can use AV Asset.

00:08:36.150 --> 00:08:42.230
You can use it for playback,
for image generation, for export,

00:08:42.230 --> 00:08:45.290
and for asset reading.

00:08:47.610 --> 00:08:53.610
So let's take a demo of cutting
together a bunch of different

00:08:53.880 --> 00:08:56.070
clips and playing them together.

00:08:59.600 --> 00:09:03.800
Okay, I'm launching AV Edit Demo,
the iPad version.

00:09:03.800 --> 00:09:07.470
The first thing you're going to look
at this is to say this is no iMovie.

00:09:07.720 --> 00:09:10.090
This is not designed
for users to play with.

00:09:10.350 --> 00:09:14.580
This is designed as a programmer's
playground so that people like you

00:09:14.580 --> 00:09:19.450
can understand how the APIs work and
explore and experiment with them.

00:09:19.500 --> 00:09:24.480
The UI is very close to
the way the API works.

00:09:24.480 --> 00:09:27.010
So the first thing I'm going to
do is select the clips that I'm

00:09:27.010 --> 00:09:28.470
going to use to edit together.

00:09:28.490 --> 00:09:33.790
I have a clip here of a cat
and a clip here of a beach and

00:09:33.810 --> 00:09:36.500
the third clip of some flowers.

00:09:36.500 --> 00:09:39.240
And you can see that there
are start and end times.

00:09:39.240 --> 00:09:40.320
I can set my edits.

00:09:40.340 --> 00:09:43.190
I can set the portion of these
clips that I want to use.

00:09:43.190 --> 00:09:48.500
I'm going to take in a section
from about 20 seconds of the cat.

00:09:48.500 --> 00:09:49.500
Oh, I'm going to take in a section
from about 20 seconds of the cat.

00:09:49.500 --> 00:09:54.050
Oh, the first eight seconds or so
of the beach and then some eight

00:09:54.050 --> 00:09:56.440
second portion of the flowers.

00:09:56.510 --> 00:09:57.500
That's about that.

00:09:57.500 --> 00:10:00.500
And now let's view the player
and see what that looks like.

00:10:01.220 --> 00:10:01.840
Okay.

00:10:01.840 --> 00:10:06.360
I'll play through this so you
can hear what it looks like.

00:10:38.880 --> 00:10:40.990
So what did we just see?

00:10:41.410 --> 00:10:46.480
We started with three clips, the cat,
the beach, and the flowers.

00:10:46.530 --> 00:10:51.660
And we took segments of each of these
and composed them on the same timeline.

00:10:57.300 --> 00:11:00.500
The tool we use for doing
this again is AV Composition.

00:11:00.520 --> 00:11:04.510
So what AV Composition does
is it takes segments of assets

00:11:04.510 --> 00:11:06.890
and places them on a timeline.

00:11:07.390 --> 00:11:13.130
So your AV Composition object contains
a number of AV Composition tracks,

00:11:13.140 --> 00:11:16.290
just like AV Asset
contains AV Asset tracks.

00:11:16.410 --> 00:11:20.620
And each AV Composition
track contains segments.

00:11:20.630 --> 00:11:27.900
And each segment contains information
that defines the source movie,

00:11:27.980 --> 00:11:32.570
the video track, and the time range.

00:11:35.340 --> 00:11:38.420
Here's the mutable
version of AV Composition,

00:11:38.420 --> 00:11:42.480
which is called AV Mutable Composition,
can be edited in a number of different

00:11:42.480 --> 00:11:44.300
ways depending on your needs.

00:11:44.340 --> 00:11:51.560
There's a family of APIs which edit
across all of the tracks at once,

00:11:51.560 --> 00:11:55.450
and there are some other that only
modify a single track at a time.

00:11:55.930 --> 00:11:59.080
And you can also modify the
whole segment array directly if

00:11:59.110 --> 00:12:03.280
you have your own representation
of how the editing should work.

00:12:04.250 --> 00:12:12.770
New in iOS 5 is an optimized batch
version of the single track editing API.

00:12:15.770 --> 00:12:19.370
So here's how it looks in the code
that you'd see in simpleeditor.m.

00:12:19.370 --> 00:12:22.780
First,
we make a mutable composition object and

00:12:22.780 --> 00:12:24.820
then we add composition tracks to it.

00:12:25.110 --> 00:12:29.370
Here I'm adding one for video and
I'm taking that video composition

00:12:29.370 --> 00:12:34.570
track and adding a segment
of a source asset into it.

00:12:38.350 --> 00:12:44.920
Now, it's generally not a safe idea to
modify a composition object while you're

00:12:44.920 --> 00:12:49.440
using that same object for playback,
for image generation, for export,

00:12:49.500 --> 00:12:51.940
or for media data extraction.

00:12:52.210 --> 00:12:56.200
Instead, you want to make a copy and then
you can modify the original.

00:12:56.390 --> 00:13:00.390
Here I'm making an immutable copy
of the immutable composition and

00:13:00.510 --> 00:13:02.440
creating the player item from that.

00:13:02.610 --> 00:13:06.110
Now, if you have a live view of what
your video preview should look

00:13:06.110 --> 00:13:09.640
like and you want to change it
sharply and snappily and safely,

00:13:09.810 --> 00:13:16.600
you can use the replace current item
with player item API to do that.

00:13:16.720 --> 00:13:19.270
All right,
let's move on to the next scenario

00:13:19.270 --> 00:13:21.200
of adding additional audio.

00:13:28.710 --> 00:13:30.560
Now that I've shown you
what AV Composition is,

00:13:30.560 --> 00:13:33.940
you can get a better idea about what
you're seeing in the lower right part.

00:13:33.960 --> 00:13:38.280
We have enough space on the iPad version
of AV Edit Demo to draw an illustration,

00:13:38.280 --> 00:13:43.140
a visualization of the same objects that
are actually being used for playback.

00:13:43.150 --> 00:13:44.780
This is not generated separately.

00:13:44.780 --> 00:13:47.660
This is actually generated-- this
artwork is generated from the

00:13:47.710 --> 00:13:49.960
objects that are used for playback.

00:13:50.240 --> 00:13:55.830
So you can see that
there are three segments.

00:13:56.050 --> 00:13:58.740
for the video track and three
segments for the audio track.

00:13:58.870 --> 00:14:01.530
And now I'm going to go down
to these extra options here

00:14:01.950 --> 00:14:03.930
and add a commentary track.

00:14:04.040 --> 00:14:06.840
I'm going to select my audio clip.

00:14:07.540 --> 00:14:11.510
And I get to choose when in the
overall composition that audio clip

00:14:11.590 --> 00:14:13.500
should start with this slider here.

00:14:13.500 --> 00:14:16.450
So I'm going to drag
that to about 11 seconds.

00:14:17.950 --> 00:14:20.900
You can see how the
AV composition has been set up.

00:14:20.960 --> 00:14:26.020
And now let's play through this and
listen carefully for what you hear.

00:14:37.300 --> 00:14:43.410
It's true, when something exceeds your
ability to understand how it works,

00:14:43.420 --> 00:14:45.930
it sort of becomes magical.

00:14:50.770 --> 00:14:53.700
Scrub back just one more time
and play just a bit just before

00:14:53.700 --> 00:14:57.800
he starts to talk and listen
carefully for how it becomes quiet.

00:15:00.000 --> 00:15:06.240
It's true, when something exceeds your
ability to understand how it works,

00:15:06.290 --> 00:15:08.890
it sort of becomes magical.

00:15:12.420 --> 00:15:14.640
So what's happened this time?

00:15:14.710 --> 00:15:19.600
So once again, we have our compositions,
audio and video tracks.

00:15:19.600 --> 00:15:21.320
And this time,
we're adding an additional audio

00:15:21.400 --> 00:15:23.980
track in parallel with the other ones.

00:15:24.550 --> 00:15:27.430
Notice that this audio doesn't begin
at the beginning of the movie and

00:15:27.560 --> 00:15:29.040
doesn't go all the way to the end.

00:15:29.240 --> 00:15:30.230
There are gaps.

00:15:30.650 --> 00:15:35.340
These gaps are called empty
edits or empty segments.

00:15:36.600 --> 00:15:39.860
The other thing we noticed was
that the audio became quiet just

00:15:39.860 --> 00:15:43.200
before Johnny Ives started talking
so that we could hear him clearly.

00:15:43.320 --> 00:15:47.460
This technique is called ducking and it's
accomplished in AV Foundation through

00:15:47.460 --> 00:15:50.190
the use of audio volume ramps.

00:15:51.730 --> 00:15:56.390
Looking at the objects we use,
once again we have our composition

00:15:56.490 --> 00:16:00.680
with the old tracks and now the
new track that we're adding.

00:16:01.410 --> 00:16:05.470
And AV Audio Mix is the object that we're
using for representing the audio ramps.

00:16:05.490 --> 00:16:10.760
It contains a list of audio volume ramps.

00:16:16.120 --> 00:16:20.260
An audio volume mix has an array
of input parameters objects.

00:16:20.280 --> 00:16:25.820
Each input parameters object adjusts
the volume level of one track.

00:16:26.040 --> 00:16:28.970
If a track does not have
an input parameters object,

00:16:28.970 --> 00:16:33.480
then it will maintain the default
volume level of full volume.

00:16:37.900 --> 00:16:40.300
Here's how you generate them in code.

00:16:40.340 --> 00:16:43.300
You create an input parameters object.

00:16:43.340 --> 00:16:48.420
And then you set the volume at
times and across time ranges.

00:16:49.490 --> 00:16:54.100
Note that in between the volume
times and ranges that you specify,

00:16:54.100 --> 00:16:57.800
the volume level continues
at the last value.

00:16:57.940 --> 00:17:00.640
So in this case,
I'm setting the volume at time

00:17:00.640 --> 00:17:05.940
zero and from time X to time Y,
and that's sufficient to draw

00:17:05.940 --> 00:17:08.150
the yellow line on the right.

00:17:09.490 --> 00:17:11.790
Once you have your input
parameters for each track,

00:17:11.790 --> 00:17:14.770
you collect them up into
an audio mix object.

00:17:15.780 --> 00:17:19.300
And then to use that audio mix object,
you set it as a property

00:17:19.640 --> 00:17:23.190
on your player item,
your export session,

00:17:23.190 --> 00:17:27.490
and there's a special subclass of
AV Asset Reader output that knows how

00:17:27.490 --> 00:17:32.780
to deal with multi-track audio mixing,
and you'd set it on that one as well.

00:17:35.570 --> 00:17:38.340
Let's move on to some video transitions.

00:17:38.500 --> 00:17:42.090
Those cuts are a little bit abrupt,
so let's add some crossfades

00:17:42.530 --> 00:17:44.580
to smooth that over.

00:17:48.770 --> 00:17:52.340
Now you know what the AV Audio Mix that
you're seeing there is all about.

00:17:52.430 --> 00:17:55.270
So now I'm going to go
down to the second option,

00:17:55.300 --> 00:17:57.870
Transitions, and turn that on.

00:17:58.030 --> 00:18:00.470
See a lot more stuff happening there.

00:18:03.270 --> 00:18:04.560
I'll play it again.

00:18:04.630 --> 00:18:08.630
Watch the cat as it goes
through the transition period.

00:18:19.200 --> 00:18:25.360
It's true, when something exceeds your
ability to understand how it works,

00:18:25.500 --> 00:18:28.030
it sort of becomes magical.

00:18:29.610 --> 00:18:31.720
So that's what a crossfade looks like.

00:18:31.820 --> 00:18:35.340
I can also set it to a push transition
and I can change the length.

00:18:35.340 --> 00:18:37.600
It's kind of fun the way
everything moves around.

00:18:37.620 --> 00:18:41.040
And I'll just adjust the start time
of this guy to bring it back in.

00:18:41.090 --> 00:18:42.030
And let's play this again.

00:18:42.040 --> 00:18:47.030
This time we're showing about
a two second push transition.

00:18:55.600 --> 00:19:01.750
It's true, when something exceeds your
ability to understand how it works,

00:19:01.870 --> 00:19:04.490
it sort of becomes magical.

00:19:06.200 --> 00:19:09.760
That's some transitions.

00:19:09.920 --> 00:19:13.080
So,
recapping again what we're seeing here.

00:19:13.110 --> 00:19:18.480
Once again, we're using AV Composition,
but there's something different.

00:19:19.960 --> 00:19:24.810
This time, instead of just cutting from
one segment to the next,

00:19:24.810 --> 00:19:25.990
we have transitions.

00:19:26.000 --> 00:19:30.960
So we're taking the middle segment of
video and moving it into its own track.

00:19:31.000 --> 00:19:33.780
Now you can see that each of
those transition periods is a

00:19:33.780 --> 00:19:37.900
period when two video tracks are
being decoded at the same time.

00:19:37.950 --> 00:19:41.660
Now, we're also decoding two audio
tracks at the same time,

00:19:41.930 --> 00:19:43.700
but that's pretty natural.

00:19:43.880 --> 00:19:46.110
When you hear two sounds,
what you hear is the

00:19:46.140 --> 00:19:47.390
sum of their waveforms.

00:19:47.400 --> 00:19:49.820
So we don't have to do anything
particularly special there.

00:19:49.820 --> 00:19:53.980
But for video,
it's important to explicitly

00:19:53.980 --> 00:19:57.800
define what the output should look
like in terms of the input videos.

00:19:57.800 --> 00:20:01.790
AV Foundation's tool for doing this
is called AV Video Composition.

00:20:01.790 --> 00:20:04.800
Not to be confused with AV Composition.

00:20:04.850 --> 00:20:08.910
AV Video Composition has
instructions that tell

00:20:09.000 --> 00:20:14.790
AV Foundation when to play track A,
when to play track B,

00:20:14.980 --> 00:20:16.680
when to play some combination of the two.

00:20:16.800 --> 00:20:20.440
So if we take this video
composition and apply it to the

00:20:20.460 --> 00:20:25.140
multitrack composition above,
we get something that looks like this.

00:20:32.260 --> 00:20:38.030
So AV Video Composition contains an
array of video composition instructions,

00:20:38.040 --> 00:20:40.440
each for one period of time.

00:20:40.450 --> 00:20:46.280
Each instruction describes the output
video in terms of instruction layers,

00:20:46.500 --> 00:20:48.120
layer instructions.

00:20:48.120 --> 00:20:52.200
And each layer,
which is associated with the track,

00:20:52.220 --> 00:20:55.550
has an opacity and an affine transform.

00:20:55.700 --> 00:20:59.150
Now you can apply a ramp to these values,
what we call a tween.

00:20:59.260 --> 00:21:04.820
You can tween the opacity to get a
crossfade or you can tween the affine

00:21:04.820 --> 00:21:07.310
transform to get a push transition.

00:21:08.790 --> 00:21:11.460
Here's how we put them together in code.

00:21:11.650 --> 00:21:17.460
First, you make your video
composition instruction object.

00:21:17.770 --> 00:21:20.620
You must set a time range
that says what time range that

00:21:20.620 --> 00:21:23.260
instruction is going to apply for.

00:21:23.840 --> 00:21:27.920
And then you construct layer
instruction objects that represent

00:21:28.230 --> 00:21:32.700
the tracks that are being inserted
into that composition instruction.

00:21:32.700 --> 00:21:35.870
So here we're making one for track A.

00:21:36.040 --> 00:21:40.080
And now we're going to fade out
track A by setting a tween on

00:21:40.080 --> 00:21:43.730
the opacity from 1 down to 0.

00:21:44.890 --> 00:21:49.600
We then make a second layer instruction
representing track B and we'll leave

00:21:49.600 --> 00:21:53.400
that at the default full opacity of 1.0.

00:21:53.510 --> 00:21:58.730
And then we set our layer instructions
array to be an array of these layer

00:21:58.730 --> 00:22:01.310
instructions from top to bottom.

00:22:04.470 --> 00:22:08.390
Once you have all of your instructions,
you assemble them and set them

00:22:08.460 --> 00:22:11.440
on a video composition object.

00:22:11.540 --> 00:22:15.300
It's critical that the time
ranges do not overlap and the

00:22:15.300 --> 00:22:17.040
time ranges may not contain gaps.

00:22:17.130 --> 00:22:20.140
There may not be gaps
between the time ranges.

00:22:20.610 --> 00:22:23.890
You have to tell the video
composition what frame duration,

00:22:23.890 --> 00:22:25.540
which effectively means the frame rate.

00:22:25.680 --> 00:22:28.740
Here I'm saying what the frame
duration is 1/30th of a second,

00:22:28.900 --> 00:22:32.340
which means we'll
generate a 30/5 animation.

00:22:32.500 --> 00:22:37.710
You also have to set the render size,
here we're using 720p.

00:22:37.710 --> 00:22:40.480
And for playback,
you can optimize the frame rate

00:22:40.480 --> 00:22:42.510
by lowering the rendering scale.

00:22:43.800 --> 00:22:47.000
To use AV Video Composition, once again,
just like Audio Mix,

00:22:47.030 --> 00:22:48.840
you set it on the player
item for playback,

00:22:48.990 --> 00:22:52.290
on the image generator,
the export session, and again,

00:22:52.300 --> 00:22:57.690
there's a special subclass of
AV Asset Reader output that knows

00:22:57.700 --> 00:22:59.810
how to do video compositions.

00:23:00.670 --> 00:23:03.000
A couple of things to watch out for.

00:23:03.040 --> 00:23:06.840
Like I said, the time ranges must not
overlap or contain gaps.

00:23:06.900 --> 00:23:10.510
Every time range must begin
where the previous one ended.

00:23:10.510 --> 00:23:13.450
And they must not be short
of the Navy composition.

00:23:13.790 --> 00:23:17.040
They have to fill out the full
duration of the composition.

00:23:17.730 --> 00:23:19.700
Now if you know something
about video compression,

00:23:19.700 --> 00:23:25.050
you might be thinking, okay,
can I edit anywhere or can

00:23:25.050 --> 00:23:28.300
I only edit at keyframes,
at iframes?

00:23:28.340 --> 00:23:30.970
Rest assured,
AV Foundation lets you edit at

00:23:30.970 --> 00:23:33.250
any frame boundary you want.

00:23:33.420 --> 00:23:37.320
How that works is that to
play a video segment that

00:23:37.350 --> 00:23:42.690
doesn't begin with a keyframe,
AV Foundation has to go back and decode

00:23:42.690 --> 00:23:44.690
frames from the previous keyframe.

00:23:44.920 --> 00:23:46.400
This is called catch-up.

00:23:46.460 --> 00:23:48.780
As an optimization,

00:23:48.980 --> 00:23:54.200
It's possible to use AV Composition
to put alternating segments in

00:23:54.200 --> 00:23:58.300
alternating tracks and then use
AV Video Composition to select

00:23:58.400 --> 00:24:00.530
which track to play at a given time.

00:24:00.660 --> 00:24:05.170
Doing this gives AV Foundation more
time to do the catch-up

00:24:05.170 --> 00:24:07.500
decoding in those empty gaps.

00:24:07.890 --> 00:24:10.480
Let's go on to the
Core Animation Scenario and

00:24:10.480 --> 00:24:12.130
have a look at one more demo.

00:24:16.930 --> 00:24:20.070
I'm going to scroll down on
the left to the last option,

00:24:20.180 --> 00:24:22.200
which is for a title.

00:24:22.200 --> 00:24:24.500
And I'm going to go and type in my title.

00:24:24.500 --> 00:24:25.900
Ooh, I can use this thing.

00:24:26.040 --> 00:24:26.790
Use my thumbs.

00:24:26.920 --> 00:24:29.890
M-A-G-I-C.

00:24:29.920 --> 00:24:32.040
Oh, thank you, autocorrect.

00:24:32.090 --> 00:24:32.340
All right.

00:24:32.420 --> 00:24:37.020
Okay, so let's play this one.

00:24:37.020 --> 00:24:40.190
I've added some animation.

00:24:48.400 --> 00:24:54.600
It's true, when something exceeds your
ability to understand how it works,

00:24:54.650 --> 00:24:57.290
it sort of becomes magical.

00:24:58.230 --> 00:25:01.100
didn't say it wouldn't
be cheesy animation.

00:25:01.200 --> 00:25:05.100
So let's scroll back here,
and you see that as I go back,

00:25:05.200 --> 00:25:09.810
the stars spin anticlockwise,
and you go forward, they go clockwise.

00:25:14.240 --> 00:25:15.200
Core animation.

00:25:15.230 --> 00:25:18.780
We've taken our AV composition and we've
also added some core animation stuff.

00:25:18.860 --> 00:25:24.700
We've added layers that contain the
text and the stars and some animations.

00:25:24.770 --> 00:25:27.180
Here's what our layer tree looks like.

00:25:39.810 --> 00:25:45.880
We have one parent layer which contains
a layer that contains the text and a

00:25:45.880 --> 00:25:48.530
layer that contains the ring of stars.

00:25:48.740 --> 00:25:51.960
And we have an animation controlling
Spinning the Ring of Stars and

00:25:51.960 --> 00:25:55.360
another animation that fades
everything out after 10 seconds.

00:25:56.430 --> 00:25:59.920
If you need a recap on core animation,
there's a session tomorrow.

00:26:02.430 --> 00:26:04.560
Let me take a moment to
talk about animation.

00:26:04.610 --> 00:26:09.820
Animation is the result of modifying
a property like position over time.

00:26:09.960 --> 00:26:13.560
If you've used that Core Animation,
you know what it's like to use

00:26:13.560 --> 00:26:16.400
it for real-time animations
of your user interface.

00:26:16.550 --> 00:26:19.310
AV Foundation lets you use
the same tools in movies.

00:26:19.640 --> 00:26:22.760
The only difference is that
instead of applying in real-time,

00:26:22.840 --> 00:26:26.600
the timeline for these animations
is now your movie's timeline.

00:26:26.700 --> 00:26:28.680
Let me illustrate how that works.

00:26:28.820 --> 00:26:33.140
Your UI view or NS view is going
to contain a layer hierarchy.

00:26:33.340 --> 00:26:37.610
Somewhere inside that layer
hierarchy is an AV player layer.

00:26:38.240 --> 00:26:43.190
The AV Player layer has a private
layer which contains the video.

00:26:43.320 --> 00:26:46.600
Now, that video's timing is special.

00:26:47.100 --> 00:26:50.970
Every other layer in this
diagram operates in host time.

00:26:51.080 --> 00:26:53.840
Time is counted as the number
of seconds since boot and it's

00:26:53.960 --> 00:26:56.400
always monotonically increasing.

00:26:59.360 --> 00:27:03.000
The video layer, on the other hand,
runs in movie time.

00:27:03.070 --> 00:27:06.290
Its timeline is the number of
seconds since the start of the movie.

00:27:06.370 --> 00:27:11.080
And that starts when I start
playback and it stops if I pause.

00:27:11.080 --> 00:27:13.590
But I can even rewind it
and make it go backwards,

00:27:13.790 --> 00:27:17.590
which real time can't do.

00:27:17.950 --> 00:27:22.300
When I add my animation,
the animation needs to

00:27:22.300 --> 00:27:25.500
run along movie time,
not real time.

00:27:25.580 --> 00:27:27.930
AV Foundation provides

00:27:28.910 --> 00:27:33.070
The AV synchronized layer
object to make that happen.

00:27:33.250 --> 00:27:36.940
So for playback,
you use AV synchronized layer to

00:27:36.940 --> 00:27:39.070
make animation use movie timing.

00:27:39.800 --> 00:27:43.640
For export,
it's similar but a little different.

00:27:43.710 --> 00:27:46.220
AV Foundation's object is
called AV Video Composition

00:27:46.370 --> 00:27:49.310
Core Animation Tool and that
integrates Core Animation as

00:27:49.460 --> 00:27:51.980
a processing video stage.

00:27:53.200 --> 00:27:56.700
So in this case,
you set up a single parent layer

00:27:56.930 --> 00:28:05.130
that contains both your video layer
and the animations you want to do.

00:28:05.720 --> 00:28:11.100
For optimized rendering,
it helps to indicate when there's

00:28:11.100 --> 00:28:14.700
no core animation artwork to render
for a particular time period.

00:28:14.720 --> 00:28:17.520
By setting the enable
post-processing property to no,

00:28:17.520 --> 00:28:20.570
you can tell us to skip
unnecessary rendering.

00:28:21.860 --> 00:28:26.070
On iOS, core animation use is prohibited
while you're in the background.

00:28:26.180 --> 00:28:29.090
If you try,
it'll cause your export to fail.

00:28:29.780 --> 00:28:34.890
I need to give you a few hints
about coordination features

00:28:35.340 --> 00:28:37.810
that are convenient when you're
working in real-time animation,

00:28:37.880 --> 00:28:39.700
but they don't work so well for movies.

00:28:39.960 --> 00:28:43.400
First is that if you have an
animation with begin time set to zero,

00:28:43.400 --> 00:28:46.700
which is the default,
as soon as you commit it,

00:28:46.700 --> 00:28:49.620
its begin time is changed
to the current host time.

00:28:49.700 --> 00:28:51.920
That's very convenient
for real-time animations,

00:28:51.920 --> 00:28:53.700
but it's not at all useful for movies.

00:28:53.700 --> 00:28:59.780
So, you want to use a very small
non-zero number for the begin time,

00:28:59.780 --> 00:29:01.630
and if you can't think of
a very small non-zero time,

00:29:01.760 --> 00:29:04.250
we have one for you.

00:29:05.050 --> 00:29:07.910
Another thing is that
Core Animation automatically collects

00:29:07.910 --> 00:29:12.140
and removes animations after it thinks
that they have gone into the past.

00:29:12.250 --> 00:29:14.810
That's obviously a useful
idea for real-time animations,

00:29:14.810 --> 00:29:16.000
you can never go back.

00:29:16.070 --> 00:29:17.800
But with movies you can go back.

00:29:17.930 --> 00:29:24.500
So you need to set the
removed on completion property

00:29:24.510 --> 00:29:24.510
of the animation to no,
to tell Core Animation to

00:29:24.510 --> 00:29:24.510
keep its hands off.

00:29:25.530 --> 00:29:30.290
The third thing from Core Automation
is that if you set a property or

00:29:30.290 --> 00:29:34.870
change anything about a layer tree,
by default Core Automation will

00:29:34.870 --> 00:29:38.400
construct an implicit animation
from the old state to the new state.

00:29:38.400 --> 00:29:41.120
And that's set up to
operate in real time.

00:29:41.250 --> 00:29:42.640
Generally that's an unwanted thing.

00:29:42.640 --> 00:29:44.720
You don't want that to
happen inside your movie.

00:29:44.900 --> 00:29:49.740
So you need to surround all of
your changes to the layer tree in

00:29:49.740 --> 00:29:54.190
explicit transactions and you need
to set disable actions to yes.

00:29:55.990 --> 00:30:00.320
Finally, sometimes you want your
animation to extend past the

00:30:00.320 --> 00:30:02.840
end of your AV composition.

00:30:02.890 --> 00:30:04.780
And that's okay.

00:30:05.290 --> 00:30:08.880
But we need to know how long
playback should end or how

00:30:08.950 --> 00:30:11.080
long export should happen.

00:30:12.140 --> 00:30:16.860
So you set the playback,
for playback you set the player item,

00:30:16.860 --> 00:30:20.580
the forward playback end time,
and for export you need to

00:30:20.580 --> 00:30:22.460
set the time range explicitly.

00:30:23.400 --> 00:30:27.040
Okay,
so I've gone through these six scenarios.

00:30:27.040 --> 00:30:31.300
I'm now going to hand over to Adam,
who's going to tell you about reading

00:30:31.300 --> 00:30:35.160
audio data and constructing movies
from your own audio and video data.

00:30:35.170 --> 00:30:36.700
Thanks a lot.

00:30:37.100 --> 00:30:38.210
All right.

00:30:38.210 --> 00:30:39.760
Thank you, Sam.

00:30:39.880 --> 00:30:43.420
So up until this point,
we've generally been talking

00:30:43.420 --> 00:30:48.840
about pretty high-level use
cases for audiovisual assets,

00:30:49.420 --> 00:30:53.230
whether we're taking an entire
asset and exporting it to a new file

00:30:53.230 --> 00:30:56.300
with AV Composition -- or sorry,
AV Export Session,

00:30:56.440 --> 00:30:59.920
or if we're taking multiple
segments of assets and stitching

00:30:59.920 --> 00:31:02.570
them together with AV Composition.

00:31:02.730 --> 00:31:06.450
So for the next 25 minutes or so,
we're going to dive down a little

00:31:06.450 --> 00:31:10.400
deeper and get our hands dirty and
learn how to read and manipulate

00:31:10.400 --> 00:31:15.630
the individual pieces of audio and
video data that make up media assets.

00:31:15.820 --> 00:31:17.600
So what are we going to cover?

00:31:17.710 --> 00:31:18.860
First, the why and the how.

00:31:18.950 --> 00:31:22.110
We're going to go through a few
simple scenarios that show what

00:31:22.110 --> 00:31:24.110
you can do with these capabilities.

00:31:24.240 --> 00:31:28.550
Then we're going to go into detail
about reading data from existing

00:31:28.550 --> 00:31:30.780
assets and doing stuff with it.

00:31:30.960 --> 00:31:33.210
And then we're going to talk
about taking media data that

00:31:33.210 --> 00:31:37.030
you have -- audio and video data
-- and writing it to new files.

00:31:37.200 --> 00:31:40.100
Finally, we're going to talk about some
considerations to keep in mind

00:31:40.100 --> 00:31:44.040
whenever you're writing files
that contain audiovisual media.

00:31:44.190 --> 00:31:49.140
So say that you have an app
that does simple video editing,

00:31:49.140 --> 00:31:54.240
like we have iMovie here,
and you want your users to be able

00:31:54.240 --> 00:31:58.600
to have a simple graphical interface
but to be able to do precise edits.

00:31:58.630 --> 00:32:02.490
Maybe they want to trim out the
silence at the beginning of the clip.

00:32:02.520 --> 00:32:04.140
So it's helpful to them,
if you draw an audio waveform

00:32:04.140 --> 00:32:05.620
like iMovie does here.

00:32:05.640 --> 00:32:07.420
In order to do that,
you're going to need to be able to

00:32:07.420 --> 00:32:12.980
examine the audio stream in detail
so you can draw it on the screen.

00:32:13.050 --> 00:32:18.080
So to do that in AV Foundation,
you use a class called AV Asset Reader,

00:32:18.080 --> 00:32:21.920
which was available starting
in iOS 4.1 and is now available

00:32:21.920 --> 00:32:23.780
on the desktop in Lion.

00:32:23.780 --> 00:32:26.720
And the way that it works is
you hook it up to an AV asset,

00:32:26.720 --> 00:32:31.320
which could be a movie file on disk,
and then it will decode the data in

00:32:31.320 --> 00:32:35.410
that and give it to you piece by piece,
so that you can work with it.

00:32:35.570 --> 00:32:42.020
And AV Asset Reader is an offline tool
to be used for doing offline processing.

00:32:42.570 --> 00:32:46.230
The next thing you might want to
do if you have a graphical game,

00:32:46.240 --> 00:32:48.000
then you want to take
a segment of the game,

00:32:48.000 --> 00:32:52.350
a sequence of gameplay and record it
to a movie file so you can play it back

00:32:52.350 --> 00:32:56.310
later and relive that great game moment.

00:32:56.410 --> 00:32:58.930
What you'll want to use is
another class from AV Foundation,

00:32:58.980 --> 00:33:03.090
AV Asset Reader's counterpart
called AV Asset Writer.

00:33:03.290 --> 00:33:07.240
And the way this works is you'll take
your rendered frames from your game

00:33:07.540 --> 00:33:11.990
and you'll push it into an AV Asset
Writer which will compress them and

00:33:11.990 --> 00:33:14.940
write them out to your movie file.

00:33:15.380 --> 00:33:20.300
Final scenario is if you want to let your
users manipulate the color in a video,

00:33:20.300 --> 00:33:24.310
you're going to need access to the
individual pixels so that you can

00:33:24.310 --> 00:33:26.250
change the color properties of them.

00:33:26.550 --> 00:33:29.280
And then you want to write
the results out to a new file,

00:33:29.310 --> 00:33:33.140
you're going to want to combine
AV Asset Reader and AV Asset Writer.

00:33:33.330 --> 00:33:37.300
First you hook up the AV Asset Reader
to your movie so that you can read

00:33:37.420 --> 00:33:40.280
out your uncompressed video frames.

00:33:40.310 --> 00:33:43.100
Then you'll do your color
manipulation and write the new

00:33:43.100 --> 00:33:46.850
frames out to an AV Asset Writer,
which will compress them to your file.

00:33:46.990 --> 00:33:51.280
So that's the basics of what we
can do in a general overview.

00:33:51.340 --> 00:33:58.930
So now let's dive deeper into the actual
reading from assets with AV Asset Reader.

00:33:59.090 --> 00:34:02.060
So recall these simple use cases,
drawing an audio waveform

00:34:02.150 --> 00:34:08.330
or decoding video frames so
you can mess with the color.

00:34:08.440 --> 00:34:10.500
So to zoom in on the waveform
scenario a little bit,

00:34:10.610 --> 00:34:12.420
the way the classes are laid out.

00:34:12.420 --> 00:34:13.080
You have an AV Asset Reader.

00:34:13.080 --> 00:34:15.500
You have an AV Asset,
which will represent your movie file.

00:34:15.540 --> 00:34:20.300
And the AV Asset has a single
audio AV Asset track within it.

00:34:20.330 --> 00:34:23.290
And you want to be able to
decode the data in that track and

00:34:23.300 --> 00:34:25.400
get PCM out on the other side.

00:34:25.450 --> 00:34:27.670
If you're not familiar with PCM,
it's basically just an

00:34:27.680 --> 00:34:29.340
uncompressed audio format.

00:34:29.490 --> 00:34:32.620
If you imagine the wave of the
actual audio that's happening,

00:34:32.620 --> 00:34:37.470
it's just the raw values that we
sample when we record that audio.

00:34:38.620 --> 00:34:42.660
and to actually do that decoding,
you use a class called

00:34:42.660 --> 00:34:45.810
AV Asset Reader Track Output,
which you can hook up

00:34:45.900 --> 00:34:47.490
to your AV Asset Reader.

00:34:47.900 --> 00:34:49.720
If you go to the pixel
filtering scenario,

00:34:49.760 --> 00:34:52.410
you'll have a video track,
an AV asset track with

00:34:52.510 --> 00:34:55.000
compressed video in it,
and you want to decode that

00:34:55.110 --> 00:34:56.360
to get your decoded frames.

00:34:56.430 --> 00:35:00.640
And the decoding is done by AV asset
reader track output once again.

00:35:00.740 --> 00:35:03.000
But then say you also
have an audio track,

00:35:03.110 --> 00:35:06.520
and although you're filtering
the color in the video frames,

00:35:06.560 --> 00:35:09.000
you just want to keep
the audio track as it is.

00:35:09.100 --> 00:35:12.480
You can also read those samples out
with AV asset reader track output,

00:35:12.540 --> 00:35:16.780
but configure it so that it just passes
through the samples as they're stored

00:35:16.780 --> 00:35:18.760
in the asset without decoding them.

00:35:18.830 --> 00:35:21.560
And in this case,
you'll get AAC audio if that's how

00:35:21.560 --> 00:35:23.550
the audio is stored in the asset.

00:35:23.680 --> 00:35:26.830
So when you have multiple tracks,
are there any rules on how

00:35:26.880 --> 00:35:28.720
you can choose those tracks?

00:35:28.720 --> 00:35:29.400
Well, there are.

00:35:29.430 --> 00:35:32.170
All the tracks for a single
AV asset reader operation

00:35:32.170 --> 00:35:33.850
must come from the same asset.

00:35:34.020 --> 00:35:36.810
If you want to combine
tracks from multiple assets,

00:35:36.810 --> 00:35:38.770
you should use an AV composition.

00:35:38.860 --> 00:35:41.470
And since AV composition
is a subclass of AV asset,

00:35:41.570 --> 00:35:45.070
as Sam mentioned earlier,
you can feed that into an AV asset

00:35:45.390 --> 00:35:48.280
reader and read out your decoded samples.

00:35:48.360 --> 00:35:52.640
So let's talk more about how
you actually set them up.

00:35:52.760 --> 00:35:53.710
There's a few simple steps.

00:35:53.960 --> 00:35:57.520
First, you want to instantiate your
asset reader using a reference

00:35:57.720 --> 00:35:59.840
to the asset that you're reading.

00:35:59.870 --> 00:36:02.380
Then you want to create your track
output within a reference to the

00:36:02.490 --> 00:36:04.750
track that you're going to read from,
in this case,

00:36:04.750 --> 00:36:08.090
this audio track for the waveform,
and also an NSDictionary of

00:36:08.120 --> 00:36:10.770
output settings,
which we'll talk about

00:36:10.850 --> 00:36:12.380
more in a little bit.

00:36:12.420 --> 00:36:15.210
And then you can connect them
with the add output method.

00:36:15.290 --> 00:36:18.290
And then you want to
do some configuration.

00:36:18.500 --> 00:36:20.360
In this case,
we're telling the asset reader

00:36:20.360 --> 00:36:23.300
that we only want to read out the
first five seconds of the asset.

00:36:23.300 --> 00:36:25.420
And then you start reading.

00:36:25.440 --> 00:36:26.560
And this is your commit point.

00:36:26.560 --> 00:36:29.070
And after this,
no more configuration is allowed.

00:36:29.080 --> 00:36:31.910
And you really just need to
focus on your reading of the

00:36:31.910 --> 00:36:35.330
actual audio and video data,
which you usually do in a loop.

00:36:35.420 --> 00:36:39.470
And inside that loop,
you'll read each piece of audio

00:36:39.470 --> 00:36:43.880
or video data using the copy
next sample buffer method.

00:36:44.450 --> 00:36:47.860
And that will give you an
instance of CM sample buffer,

00:36:47.940 --> 00:36:51.500
which is the data type we
use for representing media,

00:36:51.500 --> 00:36:54.040
whether it's audio, video,
or another media type.

00:36:54.150 --> 00:36:57.190
Then if you got a valid
non-null sample buffer,

00:36:57.190 --> 00:36:59.060
you do something with it.

00:36:59.140 --> 00:37:02.000
In the waveform case,
you'll extract your PCM values and

00:37:02.000 --> 00:37:04.020
draw your waveform up to that point.

00:37:04.020 --> 00:37:06.870
And then don't forget to release your
sample buffer when you're done with it.

00:37:06.940 --> 00:37:10.180
Now, copy next sample buffer
can also return null.

00:37:10.180 --> 00:37:11.680
And this could mean one of two things.

00:37:11.700 --> 00:37:15.300
Either you've finished reading
all of the... ...the buffers for

00:37:15.300 --> 00:37:16.660
the time range that you selected.

00:37:16.660 --> 00:37:20.660
Or an error occurred that prevented
you from reading any more buffers.

00:37:20.700 --> 00:37:24.010
And to distinguish between these cases,
you can query the status

00:37:24.170 --> 00:37:25.870
property on AVAssetReader.

00:37:25.880 --> 00:37:29.300
So now let's talk more about
those output settings that we had.

00:37:29.300 --> 00:37:32.400
Output settings, as I said,
are represented as an

00:37:32.400 --> 00:37:34.670
NSDictionary of key value pairs.

00:37:34.680 --> 00:37:38.330
And what you're doing with the
output settings is telling the

00:37:38.330 --> 00:37:42.350
asset reader the format that you
want to receive the buffers in,

00:37:42.350 --> 00:37:44.320
the audio and video buffers,
...when you're reading the data.

00:37:44.320 --> 00:37:45.780
And it decodes them
and gives them to you.

00:37:45.840 --> 00:37:48.990
So for this example, for audio,
we have linear PCM,

00:37:48.990 --> 00:37:53.060
32-bit floating point,
using the keys you see on the screen.

00:37:53.610 --> 00:37:58.360
These keys and more are
declared in AVAudioSettings.h.

00:37:58.650 --> 00:38:02.290
On the video side, remember,
Asset Reader is always

00:38:02.750 --> 00:38:04.340
doing decompression.

00:38:04.340 --> 00:38:08.540
To specify the format that we want
of the decompressed video frames,

00:38:08.680 --> 00:38:11.600
we use pixel buffer
attributes from Core Video.

00:38:11.600 --> 00:38:14.430
And although these keys
are from Core Video,

00:38:14.430 --> 00:38:19.100
AVVideoSettings.h is where we want to
go to get more information on how to

00:38:19.110 --> 00:38:21.600
construct them for AV Asset Reader.

00:38:21.720 --> 00:38:25.940
In addition, your choice of pixel format,
here we use 32-bit ARGB,

00:38:25.940 --> 00:38:28.600
which is convenient
for manipulating color.

00:38:28.600 --> 00:38:33.300
Your choice of pixel format might be
influenced by the platform you're on,

00:38:33.300 --> 00:38:36.600
iOS versus desktop,
or it might be influenced

00:38:36.600 --> 00:38:39.540
by the format of the encoded
media that you are decoding.

00:38:39.600 --> 00:38:44.190
So for more information about how
to choose a good pixel format,

00:38:44.190 --> 00:38:46.470
see avassetreaderoutput.h.

00:38:48.100 --> 00:41:52.200
[Transcript missing]

00:41:52.250 --> 00:41:53.960
Then you're going to append your samples.

00:41:53.970 --> 00:41:57.980
The append sample buffer method
of AV Asset Writer input is

00:41:57.990 --> 00:42:00.310
the method you use to do this.

00:42:00.490 --> 00:42:03.910
And finally, as a last step,
you're going to tell the Asset

00:42:03.910 --> 00:42:07.070
Writer to finish up writing the file,
make sure it flushes out

00:42:07.190 --> 00:42:10.440
any queued samples it has,
and tell you whether

00:42:10.440 --> 00:42:12.760
it succeeded or failed.

00:42:12.820 --> 00:42:15.270
So now we'll talk more about those two
things that I sort of glossed over.

00:42:15.500 --> 00:42:16.890
First, the sessions.

00:42:17.050 --> 00:42:22.140
So imagine that you have a group of audio
samples and a group of video samples,

00:42:22.180 --> 00:42:26.680
but the start and end times don't quite
line up like we have in this example.

00:42:26.690 --> 00:42:29.430
It's important to keep in mind
that anything that you append

00:42:29.430 --> 00:42:32.780
to the Asset Writer will get
written to your output file.

00:42:32.820 --> 00:42:35.560
And by default,
if you play that file back,

00:42:35.650 --> 00:42:37.450
it'll all get played back.

00:42:37.580 --> 00:42:39.980
You'll see all the video
and hear all the audio.

00:42:40.010 --> 00:42:44.800
But if you've ever seen a movie that
has a few frames of video with silence

00:42:45.240 --> 00:42:48.880
until the audio starts in abruptly,
you know how distracting that could be.

00:42:48.910 --> 00:42:51.860
So usually we want to have a
clean start and end where the

00:42:51.860 --> 00:42:53.380
audio and video are matched up.

00:42:53.380 --> 00:42:58.370
So you can do that with AV Asset Writer
by calling startSessionAtSourceTime,

00:42:58.630 --> 00:43:02.850
and that will give the Asset Writer
a place to start the presentation.

00:43:02.880 --> 00:43:06.650
It's a good idea to give it a
time that is the beginning of a

00:43:06.650 --> 00:43:10.700
video frame that also lines up
with a segment of audio data.

00:43:10.880 --> 00:43:14.730
And the grayed out part of the
audio sample here will still be

00:43:14.730 --> 00:43:17.740
in the file that gets written,
but, you know, you just won't hear it

00:43:17.740 --> 00:43:18.820
when you play it back.

00:43:18.820 --> 00:43:20.650
You'll get a clean start
where both the audio and the

00:43:20.660 --> 00:43:22.460
video start at the same time.

00:43:22.570 --> 00:43:26.460
And you can do the same thing at the
end using endSessionAtSourceTime.

00:43:26.530 --> 00:43:29.460
So then we'll talk about the
output settings for compression,

00:43:29.460 --> 00:43:31.660
which is a little bit different
than the output settings that

00:43:31.660 --> 00:43:33.460
we use for the Asset Reader.

00:43:33.540 --> 00:43:36.400
So here we have an example dictionary.

00:43:36.560 --> 00:43:39.460
These keys also come
from AVAudioSettings.h.

00:43:39.480 --> 00:43:43.730
And here we have AAC,
128 kilobits per second,

00:43:43.730 --> 00:43:46.370
and 44.1 kilohertz.

00:43:46.600 --> 00:43:50.740
On the video side, we're going to look to
AVVideoSettings.h once again,

00:43:50.870 --> 00:43:53.500
but we'll use keys that
are actually in that file.

00:43:53.610 --> 00:43:58.500
In this example,
we have H.264 at 640 by 480.

00:43:58.760 --> 00:44:02.280
Now, H.264, as most of you know,
is a great choice for most

00:44:02.400 --> 00:44:03.300
consumer applications.

00:44:03.300 --> 00:44:07.340
If you want to integrate with
a professional video workflow,

00:44:07.520 --> 00:44:13.200
AVAsset Writer also supports compressing
to two different flavors of Apple ProRes.

00:44:13.250 --> 00:44:16.480
Apple ProRes 422 and Apple ProRes 420.

00:44:16.500 --> 00:44:21.170
Both of which give you
excellent video fidelity.

00:44:21.320 --> 00:44:24.180
For more information about ProRes,
as well as a link to a white paper,

00:44:24.180 --> 00:44:27.740
you can go visit the link on this slide.

00:44:28.440 --> 00:44:32.380
So that's the basics of AV Asset Writer,
how you configure it, how you use it.

00:44:32.670 --> 00:44:36.230
And at this point,
we need to think a little bit about where

00:44:36.230 --> 00:44:38.700
our audio and video data is coming from.

00:44:38.700 --> 00:44:43.310
Because that's going to have an
impact on how we use the Asset Writer

00:44:43.310 --> 00:44:45.910
and how the Asset Writer behaves.

00:44:45.940 --> 00:44:50.590
So you might be getting your audio
and video data from an offline source

00:44:50.710 --> 00:44:55.000
like AV Asset Reader or maybe from
a real-time source like AV Capture.

00:44:55.600 --> 00:44:58.280
Similarly, you might have a pull
model or a push model.

00:44:58.280 --> 00:45:01.640
And all these things influence
how you use AV Asset Writer.

00:45:01.640 --> 00:45:04.920
But before we get into the differences,
we need to talk a little bit

00:45:04.970 --> 00:45:08.070
and understand how AV Asset
Writer wants to lay out the data

00:45:08.080 --> 00:45:09.830
that it writes to the files.

00:45:11.560 --> 00:45:16.180
So you have a choice when you have
an audio track and a video track.

00:45:16.210 --> 00:45:19.040
You need to make a choice on how
you're going to lay those out in the

00:45:19.040 --> 00:45:20.960
resulting file relative to each other.

00:45:20.960 --> 00:45:23.460
One way you can do it is very simple.

00:45:23.460 --> 00:45:27.520
You can just take the entire video track
and then write the entire audio track.

00:45:27.600 --> 00:45:29.390
And this would work.

00:45:29.440 --> 00:45:32.290
And you see in the diagram
we have subscripts to

00:45:32.340 --> 00:45:34.350
indicate times that match up.

00:45:34.480 --> 00:45:36.990
So we want to display V1
and A1 at the same time,

00:45:36.990 --> 00:45:39.330
V1 and A2 at the same time, and so on.

00:45:39.730 --> 00:45:43.290
But the problem here is that the
corresponding video and audio samples

00:45:43.340 --> 00:45:44.700
are really far apart from each other.

00:45:44.700 --> 00:45:47.840
So if we want to read the file
while we're playing it back,

00:45:47.840 --> 00:45:49.700
in order to keep the audio
and the video synced up,

00:45:49.700 --> 00:45:52.540
we're going to have to
jump back and forth between

00:45:52.660 --> 00:45:54.700
these two tracks constantly.

00:45:54.700 --> 00:45:57.680
This is very inefficient,
and it's even worse if you're trying to

00:45:57.720 --> 00:45:59.510
download and play back from a network.

00:45:59.700 --> 00:46:02.600
A better way would be
to mix them together.

00:46:02.670 --> 00:46:07.300
We call this audio-video interleaving,
and you just basically do one segment

00:46:07.370 --> 00:46:10.730
of video with one segment of audio,
one segment of video, and so on.

00:46:10.970 --> 00:46:14.900
And this is much more efficient
because the video and the audio

00:46:14.900 --> 00:46:17.900
that's supposed to be played at the
same time are much closer together,

00:46:17.900 --> 00:46:20.900
so we don't have to jump
around when we're playing back,

00:46:20.900 --> 00:46:22.980
when we're reading through the file.

00:46:23.450 --> 00:46:27.490
And so the thing to remember about
AV Asset Writer is it's always

00:46:27.490 --> 00:46:31.200
going to try to do this audio/video
interleaving thing to make sure

00:46:31.200 --> 00:46:35.150
that when you play this file back,
you get the most efficient

00:46:35.150 --> 00:46:37.160
I/O pattern that you can.

00:46:37.270 --> 00:46:40.100
So this works well,
but how does it achieve this?

00:46:40.270 --> 00:46:45.080
After all, you're the one who is writing
your video data and writing your

00:46:45.080 --> 00:46:47.640
audio data at your own leisure,
if you want.

00:46:47.820 --> 00:46:51.980
Well, it uses this property called
Ready For More Media Data on the

00:46:51.980 --> 00:46:55.780
Asset Writer input to try and
balance out how frequently you're

00:46:55.780 --> 00:46:58.040
appending data to each input.

00:46:58.090 --> 00:46:59.680
And we'll illustrate
it with this diagram.

00:46:59.700 --> 00:47:01.370
In the middle,
we have an Asset Writer with an

00:47:01.370 --> 00:47:03.040
audio input and a video input.

00:47:03.210 --> 00:47:05.210
And at the bottom,
we have an empty file that

00:47:05.210 --> 00:47:07.620
we'll be writing data to.

00:47:08.990 --> 00:47:12.520
And imagine for this example
that the ideal interleaving

00:47:12.520 --> 00:47:16.270
pattern is just one audio sample,
then one video sample,

00:47:16.270 --> 00:47:17.810
then one audio sample, and so on.

00:47:18.090 --> 00:47:20.840
It's not quite how it works in real life,
but it's close enough

00:47:20.910 --> 00:47:22.280
to illustrate the point.

00:47:22.540 --> 00:47:24.720
So as we're going through,
we're going to be

00:47:24.720 --> 00:47:26.260
receiving audio data in.

00:47:26.260 --> 00:47:28.100
We're going to ask the
input if it's ready.

00:47:28.140 --> 00:47:30.640
It'll say yes,
so we can go ahead and append.

00:47:30.790 --> 00:47:34.710
And we'll have a video frame come in,
and that input's ready,

00:47:34.750 --> 00:47:36.590
so we're able to append that.

00:47:36.990 --> 00:47:40.740
But then imagine that your audio starts
coming in faster than your video.

00:47:40.790 --> 00:47:46.770
Now, AVAsset Writer wants to maintain
this ideal interleaving pattern,

00:47:46.850 --> 00:47:51.510
and so it's going to tell you to hold off
a little bit until more video comes in.

00:47:51.710 --> 00:47:55.150
And so your video comes in,
and it'll let you append that.

00:47:55.330 --> 00:47:57.990
And then that'll unblock your
audio input and you can add

00:47:58.000 --> 00:48:01.150
more data to that and move on.

00:48:01.400 --> 00:48:02.960
So this works quite well.

00:48:03.140 --> 00:48:05.770
But then you might be wondering,
what's the best way to keep track

00:48:05.860 --> 00:48:09.440
of when your inputs are ready
for data and when they're not?

00:48:09.510 --> 00:48:13.110
Well, the answer depends on whether
you're using a pull model

00:48:13.240 --> 00:48:15.050
source or a push model source.

00:48:15.180 --> 00:48:18.170
So if you're using a pull model source,
like AVAsset Reader,

00:48:18.510 --> 00:48:22.620
generally what you're doing is
you request each piece of data

00:48:22.620 --> 00:48:25.050
individually when you're ready for it.

00:48:25.180 --> 00:48:28.300
So what we let you do,
we provide an API called Request

00:48:28.300 --> 00:48:33.050
Media Data When Ready that will let the
asset writer tell you exactly when it's

00:48:33.150 --> 00:48:38.320
ready for more media data so that you
can go and pull another chunk to append.

00:48:38.490 --> 00:48:42.100
And the way this API works is you give
it a block that it's going to call back

00:48:42.130 --> 00:48:47.320
any time that the value of ready for more
media data transitions from no to yes.

00:48:47.330 --> 00:48:50.050
And inside the block,
you'll generally want to loop and

00:48:50.060 --> 00:48:54.430
append samples until your input is
no longer ready for more media data.

00:48:54.670 --> 00:48:57.060
So inside that loop,
we'll grab our sample buffer,

00:48:57.090 --> 00:48:58.300
possibly from our asset reader.

00:48:58.300 --> 00:49:02.670
We'll go ahead and append
it using AppendSampleBuffer.

00:49:02.860 --> 00:49:07.140
But the last thing to keep in mind
is what happens when you run out of,

00:49:07.280 --> 00:49:10.420
say, when you run out of audio to append?

00:49:10.420 --> 00:49:14.190
Now it's important that you tell the
asset writer that you have no more

00:49:14.190 --> 00:49:18.720
data to append to a certain input,
because in its efforts to balance out how

00:49:18.720 --> 00:49:22.590
you're appending audio and video data,
it might be holding off letting

00:49:22.590 --> 00:49:25.380
you append more video data
until you get more audio.

00:49:25.380 --> 00:49:28.430
And if you have no more audio and you
don't tell the asset writer anything,

00:49:28.530 --> 00:49:30.100
the whole process might stall out.

00:49:30.140 --> 00:49:32.310
So you want to call the
method markIsFinished,

00:49:32.400 --> 00:49:37.550
and that'll tell the asset writer not
to expect any more data in that input.

00:49:37.890 --> 00:49:41.740
So things are a little
different for a push model.

00:49:41.770 --> 00:49:44.390
In a push model,
generally what's going to

00:49:44.400 --> 00:49:46.920
happen is you're periodically
going to get a callback.

00:49:47.120 --> 00:49:50.720
In this case,
we have an example of the AV Captures

00:49:51.040 --> 00:49:54.100
Data Output Sample Buffer method,
which is the delegate method

00:49:54.100 --> 00:49:57.990
that you use with AV capture
audio or video data output.

00:49:58.090 --> 00:49:59.840
And this is typical of
a push model source,

00:49:59.840 --> 00:50:03.040
where it's just going to give you
a callback and hand you a buffer,

00:50:03.150 --> 00:50:07.040
and you have to do something with it
quickly before the next one comes in.

00:50:07.160 --> 00:50:09.530
So in this case,
we recommend that you just append

00:50:09.530 --> 00:50:13.070
your sample right then and there,
do any processing you need to do,

00:50:13.140 --> 00:50:15.920
and then append it without any delay.

00:50:16.040 --> 00:50:19.380
Now you notice that we still check the
value of ready for more media data,

00:50:19.380 --> 00:50:23.330
because it's possible that we are
in a push model source that we're

00:50:23.410 --> 00:50:27.180
being pushed data faster than the
asset writer can actually process,

00:50:27.300 --> 00:50:30.150
compress, and write to the file.

00:50:30.750 --> 00:50:31.690
and Adam Sarkozy.

00:50:32.700 --> 00:50:35.450
So if this is happening,
it's tempting that you would want to

00:50:35.590 --> 00:50:39.210
do your own queuing where you save
off the buffers and you wait and

00:50:39.440 --> 00:50:43.800
you hold on to them until your input
is once again ready for more data.

00:50:43.800 --> 00:50:45.700
We recommend that you don't do this.

00:50:45.710 --> 00:50:48.380
First of all,
I'll let you in on a little secret.

00:50:48.520 --> 00:50:51.160
AV Asset Writer is doing
queuing on your behalf.

00:50:51.280 --> 00:50:54.380
So queuing on top of queuing isn't
going to buy you a whole lot.

00:50:54.460 --> 00:50:57.120
It's usually not necessary
for most use cases.

00:50:57.180 --> 00:51:01.430
It's error prone and it typically
will just hide the real problem that

00:51:01.430 --> 00:51:05.610
you're just producing data too fast
and the Asset Writer can't keep up.

00:51:05.730 --> 00:51:09.930
So instead, we recommend that you drop
some video frames in the short

00:51:09.930 --> 00:51:11.560
term in order to catch up.

00:51:11.610 --> 00:51:15.340
You don't want to drop audio
because then you might lose AV sync.

00:51:15.340 --> 00:51:18.710
And if possible,
try to go and throttle down the

00:51:18.710 --> 00:51:22.280
rate at which you are producing
those video frames to avoid

00:51:22.340 --> 00:51:24.820
overwhelming the Asset Writer further.

00:51:25.820 --> 00:51:26.960
An example of how you can do that
is if you do that with AV Capture,

00:51:27.090 --> 00:51:29.890
there's a property that lets
you set a maximum frame rate

00:51:30.360 --> 00:51:34.460
for your audio -- sorry,
your video data output.

00:51:34.460 --> 00:51:37.360
So that's a good story
for push model sources,

00:51:37.390 --> 00:51:41.870
but a lot of push model sources
are also operate in real time.

00:51:41.870 --> 00:51:44.960
And AV Capture is an example of that.

00:51:45.050 --> 00:51:49.290
And with a real time source,
the time constraints for how much time

00:51:49.290 --> 00:51:53.940
you have to deal with each piece of
audio or video data is even stricter.

00:51:54.070 --> 00:51:57.410
And with these additional constraints.

00:51:58.150 --> 00:52:02.560
Although interleaving in the output
file is always important to make sure

00:52:02.560 --> 00:52:07.100
you get good playback I/O efficiency,
even more important is making sure

00:52:07.100 --> 00:52:11.440
that we can capture as much of the data
coming at us and get it written out

00:52:11.440 --> 00:52:13.970
to the file so we don't lose any data.

00:52:14.160 --> 00:52:20.530
In addition, in a real-time scenario,
the interleaving will generally be OK,

00:52:20.810 --> 00:52:23.300
even if we don't do much
to try and manage it,

00:52:23.540 --> 00:52:27.320
because the audio and the video are
coming in at about the same time.

00:52:27.380 --> 00:52:33.100
And so if the asset writer knows that the
data is coming from a real-time source,

00:52:33.220 --> 00:52:37.090
it can focus less on micromanaging
the interleaving and give you

00:52:37.090 --> 00:52:42.250
an opportunity to keep the
gates open for appending data.

00:52:42.520 --> 00:52:45.780
And what that means concretely
is that ready for more media

00:52:45.820 --> 00:52:50.340
data will be yes a lot more often
for your real-time scenario.

00:52:50.350 --> 00:52:52.840
And the way that you tell asset
writer this is you use this

00:52:52.840 --> 00:52:56.820
property on the asset writer input,
expects media data in real-time.

00:52:57.000 --> 00:53:00.540
And you want to set this to yes
for all of your inputs that are

00:53:00.540 --> 00:53:03.500
getting data from a real-time source.

00:53:03.760 --> 00:53:07.920
So that's the basics of Asset
Writer and Asset Reader.

00:53:08.260 --> 00:53:12.530
We've talked a lot about what
they're good for and how to use them,

00:53:12.530 --> 00:53:16.380
but we should really also talk
about when you shouldn't use them,

00:53:16.420 --> 00:53:19.290
because sometimes there's
a better tool for the job.

00:53:19.360 --> 00:53:22.520
As I mentioned before,
AV Asset Reader's not for playback or

00:53:22.520 --> 00:53:25.260
any sort of other real-time scenario.

00:53:25.270 --> 00:53:30.490
It's just for offline grabbing
samples from an asset and

00:53:30.490 --> 00:53:32.750
doing your offline processing.

00:53:33.210 --> 00:53:35.600
Also,
if you're just doing a simple transcode

00:53:35.600 --> 00:53:40.440
or an export where you just want to
write your file in a different format,

00:53:40.560 --> 00:53:43.790
AV Asset Export Session will
typically be better suited to that

00:53:44.230 --> 00:53:46.260
task as well as being easier to use.

00:53:46.470 --> 00:53:49.320
Similarly,
if you just want to do a capture

00:53:49.320 --> 00:53:53.450
and write all of that capture from
a camera or a microphone and get

00:53:53.520 --> 00:53:57.260
that written out to a movie file,
then AV Capture Movie File Output

00:53:57.340 --> 00:54:00.810
is going to be the better
tool to use for that.

00:54:01.220 --> 00:54:03.720
So, let's sum up.

00:54:03.870 --> 00:54:06.970
Sam and I have talked about a lot
of different APIs today that fill

00:54:06.980 --> 00:54:09.180
a lot of different editing tasks.

00:54:09.330 --> 00:54:12.300
So, let's just go through
them to review one by one.

00:54:12.380 --> 00:54:15.660
First, if you want to create
an image for a time,

00:54:15.660 --> 00:54:17.820
use AV Asset Image Generator.

00:54:18.030 --> 00:54:20.900
If you want to output a movie,
maybe in a different format,

00:54:20.950 --> 00:54:24.080
you use AV Asset Export Session.

00:54:24.180 --> 00:54:28.790
If you want to combine multiple clips,
you use AV Composition.

00:54:28.890 --> 00:54:33.500
For audio volume adjustments,
you use AV Audio Mix.

00:54:33.630 --> 00:54:37.570
For video transitions,
you use AV Video Composition.

00:54:38.050 --> 00:54:41.300
If you want to incorporate core
animation into your presentations,

00:54:41.410 --> 00:54:45.990
you use either AV Synchronized Layer for
playback or AV Video Composition

00:54:45.990 --> 00:54:51.500
Core Animation Tool for
export and offline operations.

00:54:51.670 --> 00:54:54.960
If you want to read audio and
video data from your assets,

00:54:54.960 --> 00:54:56.400
you use AV Asset Reader.

00:54:56.680 --> 00:55:01.470
And finally, if you want to create a new
movie file with your data,

00:55:01.620 --> 00:55:03.700
then you use AV Asset Writer.

00:55:03.840 --> 00:55:07.730
And there's an additional piece of sample
code available that's not quite up yet,

00:55:07.730 --> 00:55:10.000
but it should be up tomorrow morning.

00:55:10.000 --> 00:55:13.780
And it's called -- it covers
AV Asset Reader and AV Asset Writer,

00:55:13.780 --> 00:55:16.930
and it's called, quite simply,
AV Reader Writer.

00:55:17.050 --> 00:55:19.050
So look for that in the morning.

00:55:19.400 --> 00:55:21.640
For more information,
there's documentation.

00:55:21.640 --> 00:55:24.780
We have a programming guide,
and you can get to it at this URL.

00:55:24.880 --> 00:55:27.180
As usual,
you can use the Apple Developer Forums

00:55:27.290 --> 00:55:29.300
to ask questions and get them answered.

00:55:29.360 --> 00:55:32.780
And you can also contact our
Media Technologies Evangelist,

00:55:32.830 --> 00:55:34.650
Eric Version.

00:55:35.040 --> 00:55:37.550
There were a few sessions
that happened yesterday.

00:55:37.690 --> 00:55:40.420
If you didn't catch them,
then you can catch them on the

00:55:40.690 --> 00:55:43.240
videos when those become available.

00:55:43.320 --> 00:55:46.230
There's also two more capture
sessions right in this room

00:55:46.320 --> 00:55:47.540
for the rest of the afternoon.

00:55:47.680 --> 00:55:51.650
So if you want to learn about
capture on both Lion and iOS 5,

00:55:51.920 --> 00:55:53.750
stick around right here.

00:55:53.890 --> 00:55:55.850
So thank you very much for coming.

00:55:56.010 --> 00:55:58.750
Have a great rest of your afternoon
and go write some great editing

00:55:58.820 --> 00:56:01.710
applications with AV Foundation.