WEBVTT

00:00:10.380 --> 00:00:11.690
Hello.

00:00:11.900 --> 00:00:12.760
Welcome.

00:00:12.810 --> 00:00:15.950
This is Best Practices for OpenGL on iOS.

00:00:16.160 --> 00:00:17.400
My name is Richard Schryehr.

00:00:17.440 --> 00:00:20.880
I work in Apple's GPU Software Group,
and I'd like to talk to you

00:00:20.880 --> 00:00:22.390
about some best practices.

00:00:22.430 --> 00:00:26.180
And what I really mean by that are some
of the ways to take code written for

00:00:26.210 --> 00:00:30.930
the cross-platform OpenGL standard and
code written for the iOS platform and

00:00:30.930 --> 00:00:34.810
integrating those together to build
a really high-quality application.

00:00:35.060 --> 00:00:37.440
I'm going to cover
four main topics today.

00:00:37.600 --> 00:00:42.250
First up are going to be view controllers
and what using a view controller to

00:00:42.360 --> 00:00:45.020
manage your OpenGL view gets you.

00:00:45.170 --> 00:00:47.540
Second subject is going
to be multithreading.

00:00:47.640 --> 00:00:49.940
OpenGL has a lot of somewhat
hairy thread safety rules,

00:00:50.030 --> 00:00:52.760
and I want to talk to you about what you
might stand to gain from multithreading,

00:00:52.760 --> 00:00:55.350
and if so, how to do it successfully.

00:00:55.540 --> 00:00:57.830
Third,
I want to talk about how to handle the

00:00:57.830 --> 00:01:01.620
range of screen sizes we have on our
various iOS products today and how to

00:01:01.780 --> 00:01:03.830
handle those as easily as possible.

00:01:03.960 --> 00:01:06.010
And then finally,
we'll end things off by talking

00:01:06.440 --> 00:01:10.040
about how to take advantage
of the performance of iPad 2.

00:01:10.170 --> 00:01:13.160
So, to start things off
with view controllers.

00:01:14.390 --> 00:01:17.670
If you haven't done any significant
amount of UIKit programming before,

00:01:17.850 --> 00:01:22.260
you know, view controllers are an object
in a UIKit application that

00:01:22.260 --> 00:01:24.920
plays the controller in the model
view controller design pattern.

00:01:25.330 --> 00:01:28.230
It's responsible for
creating and managing a,

00:01:28.230 --> 00:01:31.490
you know, either one view or an entire
view hierarchy that builds an

00:01:31.490 --> 00:01:33.580
entire scene of an application.

00:01:34.840 --> 00:01:37.870
This is a screenshot of Interface
Builder's new storyboard

00:01:37.870 --> 00:01:43.880
feature and with a sample game,
in this case our Touch Fighter game.

00:01:44.220 --> 00:01:46.800
Storyboarding lets you sort of
lay out the overall high-level

00:01:46.920 --> 00:01:49.900
flow of your application,
which scenes the user sees,

00:01:49.930 --> 00:01:52.590
and how the user progresses
through those scenes.

00:01:52.640 --> 00:01:55.660
And in this case,
each one of these scenes are managed

00:01:55.720 --> 00:01:57.790
by a separate view controller.

00:01:58.270 --> 00:01:59.780
So if you want to start
taking use of these features,

00:01:59.780 --> 00:02:04.720
you'll need to start from having a
view controller for all of your views,

00:02:04.720 --> 00:02:04.720
both your 2D views and OpenGL.

00:02:05.740 --> 00:02:07.810
So also consider the case
if you want to integrate

00:02:08.210 --> 00:02:09.740
Game Center into your application.

00:02:10.010 --> 00:02:12.190
Again,
Game Center generates a very complex

00:02:12.190 --> 00:02:15.610
hierarchy of views on your behalf,
achievements, leaderboards, and the like.

00:02:15.660 --> 00:02:18.390
And it packages all of that
up for you in the form,

00:02:18.390 --> 00:02:20.340
again, of a view controller.

00:02:20.340 --> 00:02:23.980
And so if you want to transition from
to a Game Center view controller,

00:02:23.980 --> 00:02:26.960
you need a view controller
to transition from.

00:02:27.120 --> 00:02:29.920
And that's what a lot of
OpenGL applications are missing today.

00:02:29.930 --> 00:02:32.660
And so I'd like to talk about how
to integrate a view controller

00:02:32.660 --> 00:02:35.660
into your OpenGL application
and then use that successfully.

00:02:37.700 --> 00:02:40.040
So what is a view
controller responsible for?

00:02:40.070 --> 00:02:42.520
As I said, it creates and manages
a collection of views.

00:02:42.910 --> 00:02:46.710
It also controls transitioning from
one view controller to the next,

00:02:46.890 --> 00:02:49.800
which is really one of the big
things that we want to enable.

00:02:49.860 --> 00:02:54.460
And then finally, I'll add a couple of
OpenGL-specific considerations here,

00:02:54.500 --> 00:02:58.170
one of which is deciding when you're
going to animate as your scene leaves

00:02:58.180 --> 00:03:00.400
the user's view and comes back in.

00:03:00.410 --> 00:03:02.950
And the second,
I'll talk a little bit in specific about

00:03:02.950 --> 00:03:04.800
how to handle rotating your device.

00:03:04.830 --> 00:03:06.830
Visibility is actually
pretty straightforward.

00:03:07.010 --> 00:03:09.760
A view controller,
your subclass of view controller,

00:03:09.760 --> 00:03:12.800
is the place where you
receive -- provides a set of

00:03:12.800 --> 00:03:15.190
methods that you can override,
which lets you know when your view

00:03:15.270 --> 00:03:17.200
hierarchy becomes visible or invisible.

00:03:17.230 --> 00:03:21.040
And as the user transitions away from
your OpenGL view into another view,

00:03:21.110 --> 00:03:24.400
you know, it makes no sense to animate
something that the user cannot see.

00:03:24.410 --> 00:03:28.240
And so we want to start and stop that
animation at the appropriate times.

00:03:28.240 --> 00:03:32.200
A view controller provides these really
handy call-outs -- view will appear,

00:03:32.370 --> 00:03:34.560
view did disappear -- which
gives you a -- which gives

00:03:34.560 --> 00:03:34.560
you a view that's not visible.

00:03:34.560 --> 00:03:34.560
And then finally,
it allows you to animate the

00:03:34.560 --> 00:03:34.560
view that you want to see.

00:03:34.560 --> 00:03:36.730
Which gives you a place where
you can choose to start and stop

00:03:36.730 --> 00:03:38.060
that animation as appropriate.

00:03:38.100 --> 00:03:40.210
In GL kit,
we've added a new sort of default

00:03:40.290 --> 00:03:43.280
OpenGL view controller that
you can use to do exactly this.

00:03:43.540 --> 00:03:46.960
GLK view controller abstracts a way,
setting up a -- in this case,

00:03:46.960 --> 00:03:50.080
a display link for you,
which produces regular animation events

00:03:50.510 --> 00:03:53.500
that are tied to the display's refresh.

00:03:53.860 --> 00:03:56.760
GLK View Controller determines
an appropriate frame rate,

00:03:56.960 --> 00:03:59.480
taking into account both your
desired frame rate and the

00:03:59.480 --> 00:04:02.760
capabilities of the display,
and it delivers these animation

00:04:02.760 --> 00:04:04.800
events regularly on the main thread.

00:04:04.840 --> 00:04:08.100
It also overrides these methods that
I just named to automatically start

00:04:08.100 --> 00:04:10.560
and stop the animation as appropriate.

00:04:10.780 --> 00:04:15.840
So, if you're one of the actually very,
very many OpenGL games who really

00:04:15.840 --> 00:04:19.530
just looks like one big 3D view
that the entire user experience

00:04:19.640 --> 00:04:23.310
lives in and you want to start,
you know, having your view be a

00:04:23.310 --> 00:04:26.210
little bit less lonely,
this is actually a really great

00:04:26.210 --> 00:04:29.120
place to start by dropping one
of these into your application.

00:04:29.120 --> 00:04:31.330
The other aspect of
ViewControllers is rotation,

00:04:31.490 --> 00:04:33.890
and this is particularly
interesting because in the past

00:04:33.890 --> 00:04:36.240
we've suggested to not use this,
and I'm going to change

00:04:36.240 --> 00:04:37.200
that advice today.

00:04:37.200 --> 00:04:39.460
How many of you have ever seen
some game that's sort of done

00:04:39.460 --> 00:04:40.670
something like this to you?

00:04:40.880 --> 00:04:45.380
where various aspects of the UI just
don't agree on which way is up.

00:04:45.770 --> 00:04:47.930
I've seen it in a number of places.

00:04:47.990 --> 00:04:52.120
And if this application properly
used view controller rotation,

00:04:52.120 --> 00:04:54.080
this wouldn't have happened.

00:04:55.510 --> 00:04:59.270
So the UIViewController class also
provides iOS support for handling

00:04:59.270 --> 00:05:02.640
device orientation and making
sure every part of the UI agrees

00:05:02.640 --> 00:05:04.420
on what that orientation is.

00:05:04.940 --> 00:05:06.580
In the past,
I've suggested not using this

00:05:06.580 --> 00:05:10.000
feature because it actually had a
fairly large performance impact.

00:05:10.050 --> 00:05:13.000
But I'm actually very,
very happy to say that as of iOS 4.3,

00:05:13.000 --> 00:05:15.610
that performance impact
is completely gone.

00:05:15.810 --> 00:05:19.120
View controller rotation
is free on iOS 4.3,

00:05:19.120 --> 00:05:22.580
and so it is now, you know, it is now,
without qualification,

00:05:22.760 --> 00:05:28.250
the best way to rotate your OpenGL views
along with every other view on iOS.

00:05:29.290 --> 00:05:31.060
In the past,
we've suggested as an alternative,

00:05:31.060 --> 00:05:32.510
you know,
do the rotation yourself within your

00:05:32.520 --> 00:05:33.870
view rather than rotating your view.

00:05:34.100 --> 00:05:36.100
And generally,
that's a little bit difficult to set up.

00:05:36.200 --> 00:05:38.340
It's kind of annoying,
and it's actually kind of error-prone,

00:05:38.400 --> 00:05:39.140
as we just saw.

00:05:39.310 --> 00:05:41.610
And so you get to remove all of this.

00:05:42.170 --> 00:05:44.580
So I want to show a little bit
about how to actually rotate your

00:05:44.580 --> 00:05:47.600
OpenGL view with view controllers.

00:05:48.570 --> 00:05:51.640
Step one is not
OpenGL specific in any way.

00:05:51.740 --> 00:05:54.320
This is your standard
view controller subclass,

00:05:54.320 --> 00:05:58.370
and you're going to override should
auto-rotate to interface orientation.

00:05:58.580 --> 00:06:01.180
In my example,
I'm going to support every orientation.

00:06:01.270 --> 00:06:05.290
Many games may just say landscape
left and landscape right.

00:06:06.930 --> 00:06:10.400
The second step is specific to OpenGL.

00:06:10.530 --> 00:06:15.540
And this is, once you have your view,
you have to create a frame buffer that

00:06:15.730 --> 00:06:17.210
lets OpenGL render into that view.

00:06:17.430 --> 00:06:20.300
And that frame buffer's dimensions
are set when you create it.

00:06:20.390 --> 00:06:22.260
So if your view is -- the
bounds of a view change,

00:06:22.370 --> 00:06:25.600
your frame buffer is not going to
change automatically behind your back.

00:06:25.710 --> 00:06:29.020
And so you need to delete your old
frame buffer and create new ones,

00:06:29.040 --> 00:06:31.500
which will then pick
up the new dimensions.

00:06:32.360 --> 00:06:35.760
Usually the easiest place to do
this is in your OpenGL view subclass

00:06:36.100 --> 00:06:39.800
where UIView provides a layout
subviews method that you can override.

00:06:39.850 --> 00:06:43.840
This is called whenever the
bounds of the view change.

00:06:43.890 --> 00:06:48.210
If you use GLKit's new GLK view,
it would do this automatically

00:06:48.230 --> 00:06:49.700
for you on your behalf.

00:06:50.550 --> 00:06:52.220
Step 3 is the best part.

00:06:52.260 --> 00:06:54.080
This is when we can
remove a whole bunch of,

00:06:54.100 --> 00:06:56.480
basically, hacks.

00:06:56.480 --> 00:06:59.090
You don't have to swap the
width and height arguments

00:06:59.150 --> 00:07:00.740
to all of your OpenGL APIs.

00:07:00.740 --> 00:07:03.560
You don't have to mangle
your transform matrices.

00:07:03.590 --> 00:07:07.410
You don't have to manually correct all
of your incoming touch coordinates.

00:07:07.560 --> 00:07:12.890
The view controller transform
mechanism handles all of

00:07:12.890 --> 00:07:12.890
this for you automatically.

00:07:14.240 --> 00:07:17.570
And then finally, this fourth step isn't
actually writing any code.

00:07:17.710 --> 00:07:19.920
This is a verification step.

00:07:21.610 --> 00:07:25.090
Core animation has some very
carefully written optimizations

00:07:25.090 --> 00:07:28.700
for getting OpenGL content onto
the display as fast as possible.

00:07:28.700 --> 00:07:31.320
But unfortunately,
there are some things you can do

00:07:31.380 --> 00:07:33.480
that will defeat those optimizations.

00:07:33.500 --> 00:07:36.660
So what you can do is you
can launch instruments,

00:07:36.800 --> 00:07:41.000
go to the core animation tool,
and then in the lower left corner here,

00:07:41.000 --> 00:07:45.000
you'll see a checkbox called
Color OpenGL Fast Path Blue.

00:07:45.000 --> 00:07:47.500
And it does exactly what it sounds like.

00:07:47.500 --> 00:07:50.740
For all OpenGL views in the system,
if they are being composited

00:07:50.740 --> 00:07:53.440
via Core animation's most
efficient path possible,

00:07:53.440 --> 00:07:57.500
it'll put a big blue tint over that view,
in which case you know you're done.

00:07:57.500 --> 00:07:59.640
If you don't see your view
turn blue in this case,

00:07:59.640 --> 00:08:02.410
then you've done something to
defeat these optimizations.

00:08:02.490 --> 00:08:07.490
For example,
your OpenGL view may be transparent.

00:08:07.500 --> 00:08:10.060
We actually have in our
written documentation,

00:08:10.060 --> 00:08:12.690
which I'll link to later,
quite a bit more detail on what kind

00:08:12.790 --> 00:08:16.450
of things you can do that either enable
the really efficient compositing paths

00:08:16.500 --> 00:08:17.450
or may force a little bit of a delay.

00:08:17.560 --> 00:08:20.470
fallbacks to slower compositing paths,
slower but more complete

00:08:20.500 --> 00:08:22.100
compositing paths.

00:08:23.770 --> 00:08:26.100
So that's view controllers.

00:08:26.150 --> 00:08:30.000
All views in an iOS application
should be managed by view controllers,

00:08:30.000 --> 00:08:33.170
and OpenGL views are
no exception to that.

00:08:33.710 --> 00:08:36.030
If you need to add one to
your existing application,

00:08:36.220 --> 00:08:40.790
GL Kit provides a really good one to
use to start with in GLKViewController.

00:08:40.830 --> 00:08:45.620
And this provides you your automatic
animation timing on the main thread.

00:08:45.770 --> 00:08:48.590
View controller rotation is
now completely free on iOS 4,

00:08:48.680 --> 00:08:53.180
3, and later, which erases all previous
advice to the contrary.

00:08:53.710 --> 00:08:55.950
And then finally,
Instruments provides a really handy

00:08:55.950 --> 00:09:00.760
tool to verify that your compositing is
being done as efficiently as possible.

00:09:00.890 --> 00:09:02.560
So that's view controllers.

00:09:02.610 --> 00:09:06.040
And that brings us to the second
and largest subject of the day,

00:09:06.050 --> 00:09:09.210
and that is multithreading.

00:09:11.020 --> 00:09:14.070
So I'm going to start by proposing a
couple different design patterns for

00:09:14.070 --> 00:09:16.910
multithreading an OpenGL application.

00:09:17.270 --> 00:09:20.230
The first of these is
asynchronous resource loading.

00:09:20.330 --> 00:09:21.620
You know,
if you have an application where

00:09:21.620 --> 00:09:23.200
you've decided that being able to,
say,

00:09:23.200 --> 00:09:26.960
stream textures in dynamically without
interrupting rendering is desirable,

00:09:27.070 --> 00:09:29.780
then this is the kind of design
pattern you should be looking into.

00:09:29.920 --> 00:09:33.100
And the second design pattern I'll talk
about is to actually pick up your entire

00:09:33.100 --> 00:09:34.890
game and move it off the main thread.

00:09:34.970 --> 00:09:38.100
And I'll get into how to
identify if that may benefit you,

00:09:38.100 --> 00:09:40.900
and if so,
a little bit about how to do it.

00:09:41.020 --> 00:09:43.890
But to start with,
I'm actually going to go through

00:09:44.010 --> 00:09:47.870
a few preliminary concepts and in
the end put them all together to

00:09:47.890 --> 00:09:51.460
show you a functioning asynchronous
texture loader just like the one that

00:09:51.530 --> 00:09:54.050
GLK Texture Loader provides for you.

00:09:55.870 --> 00:10:00.800
So the first preliminary
concept is the current context.

00:10:00.890 --> 00:10:03.840
In this case, if you have multiple
contexts in your application,

00:10:03.940 --> 00:10:07.740
the system needs to know which one is
going to receive your OpenGL commands,

00:10:07.800 --> 00:10:11.320
since GL calls don't take an
explicit context argument.

00:10:11.430 --> 00:10:13.760
And this is a per-thread variable
that you can set with the

00:10:13.760 --> 00:10:16.690
setCurrentContext class method.

00:10:17.850 --> 00:10:22.010
It's very important to note for the
content that follows is that the

00:10:22.050 --> 00:10:24.340
current context is per thread state.

00:10:24.400 --> 00:10:26.870
This means that you can set a
different current context on two

00:10:26.900 --> 00:10:30.590
different threads and call into two
different contexts concurrently.

00:10:30.910 --> 00:10:33.590
Similarly,
it is possible to set the same context

00:10:33.610 --> 00:10:36.790
current on two different threads,
but to do so is actually

00:10:36.790 --> 00:10:41.600
quite dangerous because
OpenGL contexts are not thread-safe.

00:10:41.650 --> 00:10:43.440
In this case,
our first naive attempt at the

00:10:43.510 --> 00:10:47.310
texture loader is we set the same
context current on two threads,

00:10:47.310 --> 00:10:51.320
and we call tech image
concurrently with ongoing

00:10:51.320 --> 00:10:53.540
rendering on the rendering thread.

00:10:53.580 --> 00:10:56.300
If you're lucky, this will crash.

00:10:56.310 --> 00:10:57.980
If you're unlucky,
it'll be a lot harder to

00:10:57.980 --> 00:10:59.400
figure out what's happening.

00:11:00.530 --> 00:11:03.150
So if we want to be able
to have that tech image run

00:11:03.160 --> 00:11:06.150
without blocking rendering,
without a whole bunch of synchronization,

00:11:06.150 --> 00:11:08.600
then we need to move our text
loader to a different thread.

00:11:08.720 --> 00:11:11.020
So let's move the rendering
thread over to context B.

00:11:13.110 --> 00:11:17.000
The second concept is shared contexts.

00:11:17.270 --> 00:11:19.550
By default,
OpenGL contexts all have their own

00:11:19.560 --> 00:11:21.510
completely separate pools of objects.

00:11:21.760 --> 00:11:24.410
One context has its own
collection of textures,

00:11:24.470 --> 00:11:28.280
which are completely different from
another context pool of textures.

00:11:28.710 --> 00:11:31.620
That doesn't work for us here because
we want to create a texture on one

00:11:31.620 --> 00:11:33.640
context and then use it on another.

00:11:33.730 --> 00:11:36.910
And the solution to that
are shared contexts.

00:11:37.510 --> 00:11:40.200
In this case,
you can create two or more contexts

00:11:40.320 --> 00:11:44.500
that all use the same pool of
objects in the same namespace.

00:11:45.080 --> 00:11:49.790
In this case,
we have two textures that are shared,

00:11:50.100 --> 00:11:53.030
or two contexts that are shared by
referencing the same share group,

00:11:53.130 --> 00:11:55.630
and we still have a third
context on the side that's sort

00:11:55.630 --> 00:11:58.070
of in its own separate silo.

00:11:58.220 --> 00:11:59.940
Setting this up is really, really easy.

00:12:00.180 --> 00:12:01.900
In this case,
we'll allocate our first context

00:12:01.940 --> 00:12:05.480
as usual with Eagle context,
Alec, and it.

00:12:05.780 --> 00:12:09.130
This also implicitly creates a new share
group for that context behind the scenes,

00:12:09.210 --> 00:12:11.680
which normally you don't
have to worry about.

00:12:12.160 --> 00:12:15.330
When creating our second context,
we'll use an alternative version

00:12:15.450 --> 00:12:18.010
of the initializer method,
which takes an additional

00:12:18.010 --> 00:12:20.310
share group argument,
and we'll pull that value

00:12:20.310 --> 00:12:21.780
out of the first context.

00:12:21.840 --> 00:12:24.600
With this,
we've now created two contexts that

00:12:24.730 --> 00:12:27.070
both share the same pool of objects.

00:12:27.820 --> 00:12:30.280
Now, this actually has some
implications on thread safety.

00:12:30.330 --> 00:12:32.080
Because word before,
when I said you could call

00:12:32.100 --> 00:12:34.610
into two separate contexts,
that was sort of on the assumption that,

00:12:34.610 --> 00:12:36.670
again, these two contexts were
completely separate entities.

00:12:36.680 --> 00:12:39.420
But now that we've shared them,
they're sort of intertwined again,

00:12:39.420 --> 00:12:42.290
and so, again, there are thread safety
implications with that.

00:12:42.330 --> 00:12:46.120
So those implications are that, well,
first thing, two contexts or more can

00:12:46.120 --> 00:12:49.180
concurrently read from the
same objects at the same time.

00:12:49.220 --> 00:12:50.890
So there's no problem with that.

00:12:50.960 --> 00:12:54.040
But you cannot modify an
OpenGL object in parallel with

00:12:54.100 --> 00:12:56.200
any other context reading from it.

00:12:56.690 --> 00:12:59.060
So if you actually want
to safely modify objects,

00:12:59.390 --> 00:13:03.980
first you have to quiesce all usage of
those objects on any other contexts.

00:13:04.260 --> 00:13:07.690
Call your modification command,
in this case, techimage2d,

00:13:07.690 --> 00:13:09.700
buffer_subdata, and so on.

00:13:10.230 --> 00:13:13.730
And then after modifying that object,
you have to take a couple

00:13:13.730 --> 00:13:16.240
more steps because,
you know, first,

00:13:16.240 --> 00:13:19.990
that modification command may still be
sitting in some command queue somewhere.

00:13:20.000 --> 00:13:23.000
It hasn't actually been pushed
all the way to the GPU yet,

00:13:23.170 --> 00:13:26.400
which means it's not really
available for anybody else to see.

00:13:26.470 --> 00:13:30.440
Well, the first thing to do is your
modifying context has to call gl flush,

00:13:30.550 --> 00:13:33.210
which will guarantee that all of
those commands have at least been

00:13:33.210 --> 00:13:36.780
minimally processed to be able
to do this dependency tracking.

00:13:38.090 --> 00:13:40.960
After the flush returns,
all of the rest of the contexts

00:13:41.020 --> 00:13:44.840
that want to successfully observe
this change must bind that object.

00:13:45.130 --> 00:13:47.900
Even if it was already bound,
they have to bind it again.

00:13:47.970 --> 00:13:51.260
Otherwise,
they may just not see the changes because

00:13:51.260 --> 00:13:55.590
the context may be caching information
about its currently bound objects.

00:13:57.960 --> 00:14:01.550
A little bit more about which
OpenGL commands modify objects,

00:14:01.550 --> 00:14:04.060
since the cases I have
here are fairly obvious,

00:14:04.060 --> 00:14:06.880
but there are some other
cases that are not obvious and

00:14:06.880 --> 00:14:08.650
might catch you by surprise.

00:14:10.560 --> 00:14:15.670
For example, a uniform is a property
of a GLSL program.

00:14:15.880 --> 00:14:20.140
And so if you set a uniform,
that effectively counts as modifying

00:14:20.160 --> 00:14:25.340
the entire program and subjecting the
entire program to this flush bind rule.

00:14:27.020 --> 00:14:29.600
Similarly,
rendering to a frame buffer counts

00:14:29.600 --> 00:14:33.150
as modifying the frame buffer,
and it counts as modifying all of

00:14:33.150 --> 00:14:35.820
that frame buffer's attachments,
its color buffer, its depth buffer,

00:14:35.820 --> 00:14:37.770
and its stencil buffer.

00:14:38.340 --> 00:14:42.250
The implication here is that you cannot
have two contexts concurrently issuing

00:14:42.250 --> 00:14:47.600
commands to draw into the same texture,
however tempting that may be to try.

00:14:48.630 --> 00:14:51.160
And then finally,
I'll call out our Eagle Context

00:14:51.200 --> 00:14:54.480
render buffer management methods,
since these are a little

00:14:54.480 --> 00:14:57.710
bit weird in that they're
really quite specific to iOS.

00:14:58.870 --> 00:15:01.550
As far as thread safety goes,
these methods are exactly the

00:15:01.550 --> 00:15:05.600
same as if you called a normal
GL function on the named context,

00:15:05.680 --> 00:15:08.750
but they are both considered to
modify the named render buffer.

00:15:08.910 --> 00:15:11.550
In this case, the first one actually
creates our render buffer,

00:15:11.550 --> 00:15:15.690
and the second one swaps its
current context to the display.

00:15:17.880 --> 00:15:21.430
So with all of these put together,
we can now create our correct example

00:15:21.680 --> 00:15:24.000
of an asynchronous texture loader.

00:15:24.880 --> 00:15:26.290
In this case, we have our two contexts.

00:15:26.450 --> 00:15:27.900
On our loading thread,
we'll set the loader

00:15:27.900 --> 00:15:29.680
context to be current.

00:15:29.760 --> 00:15:33.780
We'll create our texture
as usual and call flush.

00:15:33.860 --> 00:15:35.600
That completes its job.

00:15:35.650 --> 00:15:40.660
After the flush returns,
the rendering thread on its own

00:15:40.660 --> 00:15:45.210
context can rebind that texture
and then draw from it as usual.

00:15:45.510 --> 00:15:47.980
And this is completely correct.

00:15:48.060 --> 00:15:51.120
However, it can actually be made a
little bit better still.

00:15:51.120 --> 00:15:53.610
Because I've really left out all the
code around here that you didn't really

00:15:53.610 --> 00:15:55.290
want to write in the first place.

00:15:55.400 --> 00:15:57.400
And that is having to
go create the thread,

00:15:57.410 --> 00:16:01.150
having to go come up with some mechanism
for doing cross-thread messaging,

00:16:01.300 --> 00:16:05.190
marshalling of arguments,
using semaphores or condition

00:16:05.190 --> 00:16:08.800
variables to tell the scheduler
that the thread is now runnable.

00:16:08.830 --> 00:16:12.320
And this is a fairly standard
multi-thread producer-consumer problem,

00:16:12.490 --> 00:16:14.510
but it's still just a lot
of busy work to write,

00:16:14.530 --> 00:16:15.990
and there is a better way.

00:16:16.470 --> 00:16:22.860
And so I want to take this same example
and restate it in the form of some

00:16:22.860 --> 00:16:25.480
code using Grand Central Dispatch.

00:16:26.370 --> 00:16:28.000
which makes all of this
quite a bit simpler,

00:16:28.000 --> 00:16:31.990
even if, you know,
although some of you may have

00:16:31.990 --> 00:16:31.990
not seen the syntax before.

00:16:32.350 --> 00:16:35.130
So I want to step through this in pieces.

00:16:35.270 --> 00:16:37.140
Right in the middle,
we have our plain old

00:16:37.140 --> 00:16:41.090
OpenGL texture creation code,
followed by the flush for the

00:16:41.150 --> 00:16:43.590
first half of our flush bind rule.

00:16:45.150 --> 00:16:50.280
This code is executing within a block
that is called by dispatch async.

00:16:50.570 --> 00:16:53.000
If you haven't seen
Grand Central Dispatch before,

00:16:53.120 --> 00:16:57.670
Dispatch Async will schedule a
task to run on my loader queue,

00:16:57.730 --> 00:17:01.460
which will run the code
inside of that block.

00:17:01.600 --> 00:17:04.050
And it will do that on whatever
thread of Grand Central Dispatch

00:17:04.050 --> 00:17:07.650
is choosing based on its knowledge
of the current load of the system.

00:17:08.940 --> 00:17:11.260
Similarly,
when the texture load is complete,

00:17:11.330 --> 00:17:14.400
we're going to call dispatch
async a second time and message

00:17:14.400 --> 00:17:16.670
back to some other queue,
in this case the queue that

00:17:16.750 --> 00:17:21.220
protects our rendering context,
and let it know that, hey,

00:17:21.260 --> 00:17:23.640
this texture load's done and the
texture is now available for use.

00:17:24.390 --> 00:17:26.150
And one of the coolest
things here is that,

00:17:26.150 --> 00:17:28.120
you know,
my printf here is actually using

00:17:28.120 --> 00:17:32.260
the variable -- is actually
using the texture name variable.

00:17:32.260 --> 00:17:35.160
Despite the fact that my render queue
code is actually going to happen on some

00:17:35.160 --> 00:17:39.330
other thread at some later point in time,
this is because Grand Central Dispatch

00:17:39.380 --> 00:17:44.250
and blocks have captured the various
named variables on the stack and

00:17:44.720 --> 00:17:47.540
pretty much automatically marshaled
them along for me just so I don't have

00:17:47.540 --> 00:17:49.540
to actually do all of that myself.

00:17:49.540 --> 00:17:53.730
It cleans up a whole lot of -- you know,
it cleans up a whole lot of,

00:17:53.730 --> 00:17:56.360
quite frankly, quite boring code.

00:17:58.150 --> 00:18:01.210
And so I'll end this by highlighting
I have some explicit calls

00:18:01.210 --> 00:18:03.000
to set current context here.

00:18:03.060 --> 00:18:05.770
And this is actually here
for a very good reason.

00:18:06.360 --> 00:18:09.960
Because Grand Central Dispatch
itself selects which thread

00:18:09.960 --> 00:18:13.180
it's going to run the task on,
and it's going to be

00:18:13.180 --> 00:18:16.250
a thread that it owns,
and the current context

00:18:16.360 --> 00:18:21.990
is per thread state,
it means that you can never know which

00:18:21.990 --> 00:18:26.200
thread you're actually going to run on,
and you can never rely on the current

00:18:26.200 --> 00:18:26.200
context when you enter a dispatch block.

00:18:26.380 --> 00:18:35.000
And so, when using OpenGL and
Grand Central Dispatch together,

00:18:35.000 --> 00:18:35.000
you should always explicitly
set the current context at

00:18:35.000 --> 00:18:35.000
the beginning of your block.

00:18:35.390 --> 00:18:37.560
Similarly,
we don't want to leave a dangling

00:18:37.560 --> 00:18:40.460
reference to our context on
a thread that we don't own.

00:18:40.660 --> 00:18:43.900
And so we're going to clear our
current context before leaving.

00:18:43.980 --> 00:18:48.100
So with that,
we now have an asynchronous texture

00:18:48.100 --> 00:18:52.160
loader that can let your main thread
run unimpeded and does so with

00:18:52.170 --> 00:18:54.460
actually a very small amount of code.

00:18:54.520 --> 00:18:58.760
And if you had the ability to look
inside GLKit's new texture loader,

00:18:58.830 --> 00:19:02.100
this is pretty much exactly
what it does internally.

00:19:02.200 --> 00:19:04.260
So if you need asynchronous
texture loading,

00:19:04.320 --> 00:19:06.660
you can either do it in just a
couple lines of code with GLKit if

00:19:06.730 --> 00:19:09.370
you have more common needs,
or if you need to do

00:19:09.370 --> 00:19:12.820
something really exotic,
you know, reimplementing it yourself

00:19:13.000 --> 00:19:14.810
is actually quite possible.

00:19:17.200 --> 00:19:19.280
So with that,
I'm going to switch subjects a little

00:19:19.280 --> 00:19:22.820
bit and talk about the other usage case,
where you actually want to pick up

00:19:22.820 --> 00:19:26.750
your entire game or your rendering
loop and move it all off of the main

00:19:27.120 --> 00:19:29.380
thread and onto a background thread.

00:19:29.830 --> 00:19:30.820
Why would you do that?

00:19:31.030 --> 00:19:34.060
So one big thing that matters
to quite a few game developers,

00:19:34.210 --> 00:19:36.400
especially game developers porting
code from another platform,

00:19:36.460 --> 00:19:38.880
is control over the event loop.

00:19:39.480 --> 00:19:43.490
On an iOS application's main thread,
you have to return control to the NS run

00:19:43.690 --> 00:19:47.310
loop really quite frequently because
that's the run loop that's going to

00:19:47.310 --> 00:19:52.150
deliver pretty much all of the events
that come from iOS into your application.

00:19:52.270 --> 00:19:55.280
So if you've got a game that really
wants to have the model of sitting

00:19:55.280 --> 00:20:01.200
in a while loop and spinning forever,
that's not going to work very well.

00:20:01.340 --> 00:20:04.430
So you can either try to --
some developers have tried to

00:20:04.470 --> 00:20:07.720
restructure their code to fit
within the model of getting,

00:20:07.740 --> 00:20:10.440
you know,
regular event callouts from that run loop

00:20:10.670 --> 00:20:13.570
via timers or display links and the like.

00:20:14.150 --> 00:20:16.230
and a number of others have
also had quite a bit of success

00:20:16.500 --> 00:20:19.240
just picking their code up and
moving it off to another thread,

00:20:19.330 --> 00:20:20.500
which they control.

00:20:20.540 --> 00:20:23.540
And what you get out of
that is that's your thread,

00:20:23.540 --> 00:20:26.840
and you can build whatever
event loop you want on it.

00:20:26.850 --> 00:20:30.130
Another really interesting
reason to do this is to avoid

00:20:30.130 --> 00:20:31.980
blocking on the main thread.

00:20:32.310 --> 00:20:34.900
Normally we consider blocking
something that happens when you

00:20:35.010 --> 00:20:37.530
do file system or network I/O,
and you block your main thread

00:20:37.540 --> 00:20:41.600
for tens of seconds at a
time if something goes wrong.

00:20:41.680 --> 00:20:44.200
OpenGL doesn't really block
anything for tens of seconds,

00:20:44.270 --> 00:20:48.070
but it certainly can block your main
thread for tens of milliseconds.

00:20:48.250 --> 00:20:50.430
For most applications,
that really doesn't matter,

00:20:50.660 --> 00:20:52.700
but there are a few
we've seen that really,

00:20:52.700 --> 00:20:56.500
really demand very low latency
response to things like touch events,

00:20:56.520 --> 00:20:59.460
where this actually did
become a bit of a problem.

00:20:59.850 --> 00:21:02.500
And so by getting that work off
of the main thread and leaving

00:21:02.630 --> 00:21:05.280
the event loop pretty much,
the main thread's event loop

00:21:05.470 --> 00:21:08.200
pretty much uncontended,
you know, they had some success in

00:21:08.260 --> 00:21:09.600
addressing that problem.

00:21:09.610 --> 00:21:11.740
It's not something that
many game developers,

00:21:11.740 --> 00:21:13.440
not a problem that many
game developers face,

00:21:13.470 --> 00:21:15.860
but it was an important issue for some.

00:21:16.540 --> 00:21:21.880
And then finally, especially on iPad 2,
utilizing multiple CPU cores.

00:21:22.730 --> 00:21:25.770
Picking up your whole game and moving it
to one background thread doesn't actually

00:21:25.870 --> 00:21:29.900
use multiple CPU cores quite yet,
but it is one really big step

00:21:29.900 --> 00:21:33.180
in that direction in setting
your application up to do that.

00:21:33.320 --> 00:21:37.480
So I'm going to include it here because
it's sort of a preliminary to that.

00:21:38.150 --> 00:21:42.700
So if you've decided this is
something that might benefit you,

00:21:42.710 --> 00:21:45.290
then how do you go about doing it?

00:21:45.860 --> 00:21:48.680
Well, the first thing is,
way back on your main thread,

00:21:48.680 --> 00:21:52.210
you still should have your view
managed by a view controller subclass,

00:21:52.470 --> 00:21:56.030
but you should use your own
subclass and not GLKViewController.

00:21:56.180 --> 00:21:59.290
Because as I said before,
GLKViewController is all about

00:21:59.290 --> 00:22:02.860
a really easy way to get regular
animation events on that main thread.

00:22:03.000 --> 00:22:06.340
And once you're not there anymore,
it's not doing much for you.

00:22:06.770 --> 00:22:08.470
So that means that you are
going to have to create your

00:22:08.470 --> 00:22:12.580
own UIViewController subclass,
override the visibility methods,

00:22:12.630 --> 00:22:16.060
and signal your background thread as
appropriate when it's time to start

00:22:16.060 --> 00:22:18.410
and stop animation as appropriate.

00:22:19.850 --> 00:22:22.000
Another thing is,
you do want to pick one thread

00:22:22.000 --> 00:22:25.100
to do all of your OpenGL work on,
and be very careful to make sure

00:22:25.100 --> 00:22:28.600
that you haven't accidentally
left anything behind.

00:22:28.750 --> 00:22:31.490
Consider this very
easy trap to fall into,

00:22:31.530 --> 00:22:35.440
where we have our very same layout
subviews that we talked about earlier.

00:22:35.570 --> 00:22:45.410
Well, UIKit, when you're -- when you're
-- say the device rotates,

00:22:45.410 --> 00:22:45.410
UIKit is going to handily call
that on the main thread for you.

00:22:45.410 --> 00:22:45.410
This could be very
difficult to track down.

00:22:47.000 --> 00:22:49.340
So in this case, you know,
whenever you see this or

00:22:49.400 --> 00:22:52.190
any other cases like it,
usually the thing to do is either--

00:22:52.190 --> 00:22:55.400
you'll either have to signal the
background thread to do the work or

00:22:55.400 --> 00:23:00.080
even just leave a flag set on the
main thread and let your background

00:23:00.090 --> 00:23:07.150
rendering loop pick it up on its
next trip through the animation loop.

00:23:07.150 --> 00:23:07.440
In this case, we'll see the flag,
we'll reallocate the frame buffers,

00:23:07.440 --> 00:23:07.440
and we'll clear them.

00:23:07.780 --> 00:23:10.220
In turn,
our create framebuffers will end up

00:23:10.220 --> 00:23:14.520
calling the Eagle context render buffer
storage from drawable in that API,

00:23:14.520 --> 00:23:18.400
and that API is perfectly safe
to call from a background thread.

00:23:18.490 --> 00:23:21.250
Today I've mentioned both using
threads at some point and using

00:23:21.250 --> 00:23:23.200
Grand Central Dispatch at other points.

00:23:23.210 --> 00:23:25.610
Which one of these should you use?

00:23:26.220 --> 00:23:29.780
Well, if you're really just looking to
control your own event loop and

00:23:29.780 --> 00:23:32.770
you're not going to do any more
aggressive multithreading beyond that,

00:23:32.860 --> 00:23:35.840
then creating one thread that you
own and sticking your while loop in

00:23:35.910 --> 00:23:37.780
it is probably perfectly adequate.

00:23:37.780 --> 00:23:40.300
There's not much that
Grand Center Dispatch adds

00:23:40.380 --> 00:23:42.020
for you in such a usage case.

00:23:42.020 --> 00:23:44.980
So in this case, create your one thread,
move your code there,

00:23:44.980 --> 00:23:46.480
and you're pretty much done.

00:23:46.500 --> 00:23:50.920
However, if you're going to be a little
bit more ambitious and you

00:23:51.330 --> 00:23:54.520
really want to take advantage of
iPad 2's dual-core processors,

00:23:55.250 --> 00:23:57.990
then you're going to say, "Oh,
I'm going to divide my physics

00:23:58.030 --> 00:23:59.160
work up into multiple threads.

00:23:59.160 --> 00:24:02.770
I'm going to do skinning,
my game logic AI, and so on."

00:24:03.110 --> 00:24:06.260
Now, that's the kind -- when you
start having these more complex

00:24:06.410 --> 00:24:09.460
graphs of work between tasks,
that's when Granted Dispatch

00:24:09.460 --> 00:24:11.970
starts to be a really,
really big convenience,

00:24:11.970 --> 00:24:15.920
and you should seriously consider
leveraging it as much as possible.

00:24:16.830 --> 00:24:19.410
That being said,
as widely as you take your own

00:24:19.600 --> 00:24:23.680
code in terms of tasks execute,
I still very strongly suggest that

00:24:23.680 --> 00:24:27.330
you keep all of your OpenGL API usage,
again,

00:24:27.330 --> 00:24:30.520
into just one thread or just one task.

00:24:30.780 --> 00:24:33.920
As we've seen,
OpenGL's thread safety rules

00:24:33.920 --> 00:24:36.780
are kind of tricky to get right.

00:24:36.940 --> 00:24:41.090
And usually the best answer is to
just not tempt that and multi-thread

00:24:41.090 --> 00:24:45.410
everything else around it and have
it all feed into one final task.

00:24:45.510 --> 00:24:47.540
For example,
you could have your game update for

00:24:47.540 --> 00:24:50.860
the next frame happening in parallel
with OpenGL for the previous frame,

00:24:50.920 --> 00:24:54.760
but you should avoid doing
OpenGL in parallel with OpenGL.

00:24:54.830 --> 00:24:58.030
There are two other sessions on
Grand Central Dispatch if you

00:24:58.030 --> 00:25:00.200
haven't heard all about it already.

00:25:00.270 --> 00:25:02.910
The first one of which happened
this morning and I believe

00:25:03.090 --> 00:25:05.550
was completely sold out,
called Blocks in

00:25:05.550 --> 00:25:07.390
Grand Central Dispatch in Practice.

00:25:07.440 --> 00:25:10.310
So I highly suggest you
catch that on video.

00:25:10.510 --> 00:25:13.060
And there'll be another session
happening tomorrow morning called

00:25:13.060 --> 00:25:15.190
Mastering Grand Central Dispatch,
which is going to be a bit

00:25:15.200 --> 00:25:16.360
more of an advanced course.

00:25:16.360 --> 00:25:18.940
So both of these are fantastic
sessions to attend if

00:25:18.940 --> 00:25:21.020
multithreading interests you at all.

00:25:24.100 --> 00:25:28.080
So in summary, OpenGL is not limited to
the main thread in any form.

00:25:28.080 --> 00:25:30.990
You can use OpenGL from
any thread you want,

00:25:31.180 --> 00:25:34.360
but I do suggest that you
keep it to one thread.

00:25:36.070 --> 00:25:38.770
will draw an exception for this
asynchronous texture loading case

00:25:38.890 --> 00:25:41.810
because that design pattern is well
enough contained that it's pretty easy

00:25:41.840 --> 00:25:43.250
to get right and make it efficient.

00:25:43.360 --> 00:25:46.250
So, but other than that,
keep your actual active

00:25:46.760 --> 00:25:48.600
animation loop all in one place.

00:25:49.190 --> 00:25:51.040
And that's multithreading.

00:25:51.130 --> 00:25:54.540
That brings us to our
third subject of the day,

00:25:54.590 --> 00:25:57.730
and that are screen sizes.

00:25:59.050 --> 00:26:03.240
Across the range of iOS devices today,
you will see three screen sizes that

00:26:03.270 --> 00:26:06.300
you want to support in your application.

00:26:06.360 --> 00:26:08.590
On iPhone 3GS,

00:26:09.070 --> 00:26:11.200
You'll see 320 by 480.

00:26:11.280 --> 00:26:15.910
On iPhone 4, you'll see the Retina
display at 960 by 640.

00:26:16.010 --> 00:26:17.540
And finally, on iPad,
you'll see something a little

00:26:17.540 --> 00:26:20.770
bit larger at 1024 by 768.

00:26:21.660 --> 00:26:25.090
To an OpenGL developer,
the biggest implication this

00:26:25.090 --> 00:26:26.980
has on you is performance.

00:26:26.980 --> 00:26:29.400
The larger your frame buffer is,
the more times your

00:26:29.400 --> 00:26:33.110
fragment shader has to run,
the longer it takes to fill.

00:26:33.690 --> 00:26:37.400
In this case,
note that iPhone 4 has to fill four

00:26:37.480 --> 00:26:40.700
times as many pixels as the iPhone 3GS.

00:26:40.820 --> 00:26:43.790
And while its GPU is faster
than the iPhone 3GS's,

00:26:43.790 --> 00:26:46.910
I can't tell you that it
is four times as fast.

00:26:47.350 --> 00:26:51.310
So in this case, if your application is
fragment shader bound,

00:26:51.350 --> 00:26:56.410
it won't be too surprising to see that
your application might actually perform

00:26:56.410 --> 00:26:59.040
slower on an iPhone 4 than a 3GS.

00:26:59.100 --> 00:27:03.070
And in turn, iPad is, again,
about 30% larger still.

00:27:03.780 --> 00:27:05.200
So what to do about this?

00:27:05.220 --> 00:27:08.450
Well, the first thing to do is, you know,
go through the standard

00:27:08.450 --> 00:27:09.770
set of optimizations.

00:27:10.030 --> 00:27:13.100
You know, I'll go, you know,
make your fragment shaders

00:27:13.140 --> 00:27:14.490
as simple as possible.

00:27:14.620 --> 00:27:16.550
Try to, you know,
use smaller texture formats,

00:27:16.610 --> 00:27:18.120
especially in iPad 1.

00:27:18.200 --> 00:27:21.200
Texture lookup tables may be a
better preference for doing math,

00:27:21.200 --> 00:27:21.550
so on.

00:27:21.700 --> 00:27:25.460
This is all advice that you'll find in
written documentation and that we've

00:27:25.460 --> 00:27:28.270
discussed in more detail in years past.

00:27:29.080 --> 00:27:31.640
You know, you want to strongly consider
your fragment shader coverage.

00:27:31.640 --> 00:27:34.480
Every layer of blending you do,
you're now filling that

00:27:34.480 --> 00:27:35.840
pixel multiple times.

00:27:35.840 --> 00:27:39.160
And if you've got four times
the screen coverage and

00:27:39.160 --> 00:27:42.570
you're filling every pixel 4,
10, 25 times,

00:27:42.570 --> 00:27:45.700
it starts to multiply up very quickly.

00:27:46.440 --> 00:27:48.940
The architecture is a
unified shader architecture,

00:27:49.000 --> 00:27:51.280
so if you're drawing a
huge number of vertexes,

00:27:51.290 --> 00:27:54.470
that very well can sap performance
away from fragment shading.

00:27:54.760 --> 00:27:57.120
In this case,
the OpenGL driver monitor and

00:27:57.120 --> 00:28:00.290
instruments can give you a feel
for what the utilization of the

00:28:00.290 --> 00:28:04.650
vertex processor is and let you
know if this might be a factor.

00:28:04.800 --> 00:28:07.640
But, you know,
these are your standard optimizations,

00:28:07.640 --> 00:28:10.040
and they're good on
all devices everywhere.

00:28:11.410 --> 00:28:15.080
If you find that this just is not enough
to get you to your performance targets,

00:28:15.080 --> 00:28:18.120
there's one really big tool you
still have available to you,

00:28:18.130 --> 00:28:20.970
and that is to directly attack
what changed to slow your

00:28:20.970 --> 00:28:23.020
application down in the first place.

00:28:23.230 --> 00:28:27.540
And that is to back off a little bit
on the frame buffer width and height.

00:28:27.620 --> 00:28:31.330
Now, take the example of
iPhone 4's Retina display.

00:28:32.010 --> 00:28:35.900
If we were to fill 720
by 480 pixels instead,

00:28:35.940 --> 00:28:40.210
you're only covering 56%
as many pixels as before.

00:28:40.410 --> 00:28:43.340
If your application was
fragment shader bound,

00:28:43.460 --> 00:28:47.730
it is not unreasonable to expect that
your application will actually be nearly

00:28:47.760 --> 00:28:50.060
twice as fast by making this change.

00:28:50.120 --> 00:28:54.010
That's a really,
really big tool available to

00:28:54.060 --> 00:28:56.810
you to improve performance.

00:28:56.940 --> 00:29:00.070
Now, we don't want to leave big
black bars on an iPhone screen.

00:29:00.200 --> 00:29:03.280
So, fortunately,
Core Animation has some really

00:29:03.280 --> 00:29:07.460
easy support for taking your lower
resolution content and scaling it

00:29:07.460 --> 00:29:10.430
back up to fill the entire view.

00:29:10.620 --> 00:29:13.280
And that takes just one line of code.

00:29:14.730 --> 00:29:17.370
That is UIView's content
scale factor property,

00:29:17.520 --> 00:29:20.550
which effectively determines
how much detail every view

00:29:20.550 --> 00:29:22.340
in the system is drawn with.

00:29:22.460 --> 00:29:26.820
And this applies to OpenGL views as
much as it applies to every other view.

00:29:28.370 --> 00:29:31.200
If your content scale factor is,
in most cases,

00:29:31.220 --> 00:29:34.140
less than the scale of the screen,
then you're going to be

00:29:34.140 --> 00:29:38.030
rendering to a lower resolution,
and Core Animation will transparently

00:29:38.030 --> 00:29:41.610
scale your content back up to fill
the bounds of the original view.

00:29:43.490 --> 00:29:46.330
As we saw with rotation,
your frame buffer size is fixed,

00:29:46.420 --> 00:29:49.900
and so if you want to -- when you
change your content scale factor,

00:29:49.960 --> 00:29:53.750
you have to reallocate your frame
buffers to pick up the new dimensions,

00:29:53.750 --> 00:29:54.720
as before.

00:29:56.320 --> 00:29:58.960
This support is very,
very efficient on all of

00:29:58.960 --> 00:30:02.130
the larger screen devices,
iPhone 4 and iPad.

00:30:02.140 --> 00:30:06.560
The API works as described on
the smaller screen devices,

00:30:06.560 --> 00:30:09.340
but it's neither efficient
there nor is there really any

00:30:09.340 --> 00:30:11.180
reason to need to use it there.

00:30:11.250 --> 00:30:16.200
So, but on the large screen devices,
this can be a lifesaver.

00:30:16.300 --> 00:30:21.220
Then comes external displays
where there is more variety.

00:30:21.400 --> 00:30:25.380
In this case, on iPhone 4 and iPad 1,
you'll often see 480p

00:30:25.440 --> 00:30:27.460
displays or 720p displays.

00:30:27.860 --> 00:30:30.700
iPad 2 cannot put to 1080p.

00:30:30.920 --> 00:30:33.900
Now, 720p is, again,
about a 30% larger still

00:30:34.190 --> 00:30:40.230
than the iPad's display,
and 1080p is twice as large again.

00:30:40.400 --> 00:30:42.950
It adds up very, very quickly.

00:30:43.050 --> 00:30:45.070
So what to do about this?

00:30:46.500 --> 00:30:50.700
Well, the first thing is,
if your application is using mirroring,

00:30:50.760 --> 00:30:52.640
or, more accurately,
if you've done nothing,

00:30:52.740 --> 00:30:54.640
then you still get to do nothing.

00:30:54.640 --> 00:30:57.390
Your application is rendering at
its internal display resolution,

00:30:57.500 --> 00:30:58.530
and you're done.

00:30:58.690 --> 00:31:01.430
The user will see the mirrored content.

00:31:01.640 --> 00:31:04.710
However, if you're going to drive the
external display into second

00:31:04.710 --> 00:31:08.260
display mode because you want to put
different content on the internal

00:31:08.260 --> 00:31:12.310
display and on the external display,
then the performance implications

00:31:12.330 --> 00:31:14.040
here start to matter to you.

00:31:14.730 --> 00:31:18.110
So my suggestion here is when
developing your application,

00:31:18.140 --> 00:31:21.810
based on your performance targets
and your performance measurements,

00:31:21.830 --> 00:31:24.840
you want to pick sort of your upper
bound on how big of an external

00:31:25.040 --> 00:31:27.010
display you are going to support.

00:31:27.620 --> 00:31:29.910
You know,
usually that'll be 720p because that's

00:31:29.950 --> 00:31:31.670
closest to the iPad's display size.

00:31:32.040 --> 00:31:34.360
However, if you have a really
aggressive application,

00:31:34.410 --> 00:31:36.810
maybe something smaller
is more appropriate.

00:31:37.990 --> 00:31:44.490
At runtime, you can query the available
modes on the display with the

00:31:44.490 --> 00:31:44.490
UIScreenAvailableModes property.

00:31:44.920 --> 00:31:48.390
You'll want to iterate --
enumerate through this array,

00:31:48.440 --> 00:31:51.890
find the best match for your
development time target,

00:31:52.060 --> 00:31:54.880
and assign that match
to the mode property.

00:31:55.030 --> 00:31:57.100
This will cause a mode
switch on the display and,

00:31:57.190 --> 00:32:00.470
for example,
get it down from 1080p to 720p.

00:32:02.290 --> 00:32:04.960
On an external display,
you also have the option of using

00:32:04.960 --> 00:32:08.520
the content scale factor solution,
although it tends to be a little

00:32:08.520 --> 00:32:12.690
bit less efficient than just
setting the display mode directly.

00:32:13.250 --> 00:32:16.340
So, when given the option,
set the display mode first

00:32:16.750 --> 00:32:20.580
and then rely on content scale
factor from there if necessary.

00:32:22.870 --> 00:32:26.550
There is actually an entire session on
handling AirPlay and external displays,

00:32:26.550 --> 00:32:29.200
which happened yesterday,
so you'll have to catch that on video.

00:32:29.200 --> 00:32:32.120
But it goes into all of these
topics in quite a bit more detail.

00:32:36.690 --> 00:32:41.590
The other side of supporting
different display sizes is actually

00:32:41.840 --> 00:32:41.840
the size of your input textures.

00:32:41.880 --> 00:32:44.740
So I'm going to take all of your
input textures and subdivide

00:32:44.750 --> 00:32:47.040
them into two course buckets.

00:32:47.100 --> 00:32:50.180
The first of those are going to
be your user interface textures.

00:32:50.210 --> 00:32:53.300
These are your buttons, your HUDs,
anything you're drawing

00:32:53.350 --> 00:32:55.490
to a screen-aligned quad.

00:32:56.230 --> 00:32:58.280
These are the kind of
things that tend to be,

00:32:58.370 --> 00:33:00.690
you know,
quite specific to a particular DPI,

00:33:00.690 --> 00:33:03.500
to a particular aspect ratio.

00:33:03.530 --> 00:33:06.700
You know,
it matters if it's iPad versus iPhone.

00:33:06.750 --> 00:33:11.400
For these, much like UI images in
normal UIKit applications,

00:33:11.400 --> 00:33:13.700
you probably actually need to draw,
you know,

00:33:13.720 --> 00:33:18.470
draw a different version of that texture
for each one of the screen size targets.

00:33:18.800 --> 00:33:21.380
At runtime,
when it comes time to load them,

00:33:21.470 --> 00:33:24.310
you can do something like UIImage,
which provides this built-in

00:33:24.310 --> 00:33:27.210
naming convention where you
can just say load image,

00:33:27.240 --> 00:33:30.760
and based on the file names,
it will automatically pick up the

00:33:30.760 --> 00:33:35.420
right version of that image depending
on what device you're running on.

00:33:35.560 --> 00:33:38.080
Or, even easier,
you can use UIImage to actually

00:33:38.140 --> 00:33:41.220
load your images and not have
to worry about it at all.

00:33:42.350 --> 00:33:45.170
So then comes the other
bucket of textures.

00:33:45.330 --> 00:33:48.640
And those are the textures that don't
have a DPI in any way because they're

00:33:48.730 --> 00:33:53.710
the -- they're the mipmap textures that
you're wrapping across a 3D object.

00:33:54.700 --> 00:33:57.360
For these,
the best approach is to actually

00:33:57.360 --> 00:34:00.190
-- you really don't want to
generate three different versions

00:34:00.220 --> 00:34:01.430
of your textures offline.

00:34:01.660 --> 00:34:04.590
Because there's no DPI,
there's really no reason to do that.

00:34:04.690 --> 00:34:13.240
And so what you'll do here is you should
generate the full set of bitmaps offline,

00:34:13.240 --> 00:34:15.200
you know,
one bitmap stack for all devices,

00:34:15.200 --> 00:34:15.200
and ship all of those images
in your application bundle.

00:34:15.740 --> 00:34:18.290
At runtime,
depending on either you're on a

00:34:18.290 --> 00:34:22.360
smaller screen device or you're on a
device that has somewhat less memory,

00:34:22.370 --> 00:34:26.700
you can simply choose to, for example,
skip loading the most detailed level.

00:34:27.230 --> 00:34:29.460
You may want to only do this for
some textures and not others,

00:34:29.460 --> 00:34:35.410
you know,
maybe an artistic decision depending

00:34:35.410 --> 00:34:35.410
on what's actually important to
the look of your application.

00:34:36.520 --> 00:34:38.200
Oftentimes,
you can get away with this without

00:34:38.200 --> 00:34:41.670
actually having any impact on
the visual quality of the app.

00:34:42.080 --> 00:34:47.090
So I've sort of put together this
example where we have a texture,

00:34:47.090 --> 00:34:52.590
the same scene drawn on a 3GS resolution
and an iPad screen resolution.

00:34:53.230 --> 00:34:56.280
Each MIP level has been
given a different color tint,

00:34:56.400 --> 00:35:00.430
with the reds being the more detailed
levels and the greens and yellows

00:35:00.530 --> 00:35:02.690
being the less detailed levels.

00:35:03.390 --> 00:35:06.070
You know, as you can see,
for exactly the same scene,

00:35:06.150 --> 00:35:09.390
the 3GS screen really tops
out at the 512 by 512,

00:35:09.390 --> 00:35:11.820
this sort of purplish level,
whereas on iPad,

00:35:11.890 --> 00:35:13.720
you can see quite a bit more detail.

00:35:14.090 --> 00:35:19.930
On the 3GS, you can barely see the small
sliver on the column where the

00:35:19.930 --> 00:35:19.930
largest texture level was used.

00:35:20.170 --> 00:35:23.110
If that texture level just
did not exist on the 3GS,

00:35:23.130 --> 00:35:25.850
it would have had very,
very little impact on the

00:35:25.850 --> 00:35:27.480
user-perceived quality.

00:35:27.680 --> 00:35:32.250
And so this could be a really easy way
to both significantly reduce memory

00:35:32.250 --> 00:35:36.180
usage and also to reduce loading time
on the devices that were probably

00:35:36.190 --> 00:35:38.590
taking longer to load to begin with.

00:35:40.530 --> 00:35:42.220
So that's their screen sizes.

00:35:42.340 --> 00:35:46.320
There are three internal
screen sizes to support.

00:35:46.500 --> 00:35:50.110
The larger ones are more
expensive for the GPU to fill.

00:35:50.810 --> 00:35:54.450
If necessary, you can use content scale
factor to reduce the resolution.

00:35:54.540 --> 00:35:56.600
If that's an appropriate
solution for your application,

00:35:56.600 --> 00:35:59.240
you know, actually really depends on the
exact content you're drawing.

00:35:59.400 --> 00:36:02.600
Some applications have been more
successful than others with that.

00:36:02.700 --> 00:36:12.110
If you're supporting an external display,
then prefer setting the display mode

00:36:12.290 --> 00:36:15.320
before turning down content scale factor.

00:36:15.320 --> 00:36:16.750
That will generally be a
little bit more efficient.

00:36:16.760 --> 00:36:19.650
And then finally,
bake all your levels offline,

00:36:19.650 --> 00:36:22.370
and at runtime,
then it's easy to just skip one

00:36:22.370 --> 00:36:23.890
to save memory and loading time.

00:36:23.900 --> 00:36:26.600
So that is screen sizes.

00:36:26.600 --> 00:36:31.280
So that brings us to our last
topic of the day and the most fun.

00:36:31.300 --> 00:36:35.650
And that is what to do with an iPad 2.

00:36:37.880 --> 00:36:41.300
So as you heard
Gil Khan describe earlier today,

00:36:41.300 --> 00:36:47.010
iPad 2, we've exposed a number of new
features on iPad 2 in iOS 5.

00:36:47.130 --> 00:36:51.000
We've improved support for Float
16 rendering and texturing.

00:36:51.080 --> 00:36:54.100
We've added support for
binary occlusion query.

00:36:54.180 --> 00:36:56.830
We've added support for an
extension in GLSL that does

00:36:56.950 --> 00:36:59.300
for sample shadow filtering.

00:36:59.420 --> 00:37:02.370
And we've also increased
the maximum texture size.

00:37:03.650 --> 00:37:05.040
At runtime,
if you want to know these features

00:37:05.050 --> 00:37:07.400
are -- you want to check if
these features are available,

00:37:07.430 --> 00:37:10.400
then, as always,
the one true way to do that is

00:37:10.460 --> 00:37:12.830
with OpenGL's extension string.

00:37:12.930 --> 00:37:15.880
All of these, except for the 4K textures,
have a specific extension

00:37:15.880 --> 00:37:18.500
name to check for,
and the 4K textures has the

00:37:18.590 --> 00:37:22.350
sort of classic get integer max
texture size that you can query.

00:37:22.470 --> 00:37:25.980
Separate from features,
and probably much more interestingly,

00:37:25.980 --> 00:37:27.060
is performance.

00:37:27.130 --> 00:37:30.500
iPad 2 is really fast.

00:37:30.560 --> 00:37:35.900
It is hugely faster than any
previous product of ours.

00:37:36.000 --> 00:37:39.290
In this case, and it's not just one area
of the device that's faster,

00:37:39.290 --> 00:37:41.900
it's all faster all around.

00:37:42.030 --> 00:37:45.180
The number of shader instructions
per second you can execute,

00:37:45.310 --> 00:37:47.750
the number of texture samples,
the memory bandwidth,

00:37:47.850 --> 00:37:50.820
the vertexes per second,
triangle setup rate,

00:37:50.890 --> 00:37:54.220
every part of it is hugely faster.

00:37:54.830 --> 00:37:56.700
Within your shaders,
the performance degradation

00:37:56.700 --> 00:37:59.060
you go from low precision to
medium and high precision in

00:37:59.060 --> 00:38:01.460
your shader is actually much,
much reduced.

00:38:01.570 --> 00:38:04.200
There's not much you pay
there at all anymore.

00:38:04.270 --> 00:38:07.460
This opens up a whole range of new
shader algorithms that previously

00:38:07.510 --> 00:38:11.650
may have been difficult because they
really demanded the higher precisions.

00:38:12.430 --> 00:38:15.310
The ratio of shader instructions
to texture samples has sort

00:38:15.460 --> 00:38:19.300
of swung dramatically in
favor of shader instructions.

00:38:19.430 --> 00:38:22.650
So, you know, but where before, you know,
you may have -- some

00:38:22.650 --> 00:38:23.800
people found success,
you know,

00:38:23.800 --> 00:38:28.300
replacing math in their shaders with
lookup tables baked into textures.

00:38:28.430 --> 00:38:30.920
On iPad 2,
it may actually be more efficient to

00:38:30.960 --> 00:38:33.160
go back to just doing the math again.

00:38:34.910 --> 00:38:37.550
So how do you tell if this
performance is available to you?

00:38:37.610 --> 00:38:39.450
Well, unfortunately,
there is no direct query

00:38:39.780 --> 00:38:43.300
for OpenGL performance,
but we've got a pretty good proxy

00:38:43.370 --> 00:38:46.130
in the OpenGL renderer string.

00:38:46.210 --> 00:38:49.480
In this case, this returns a string that
names the model of GPU that

00:38:49.480 --> 00:38:51.030
you are currently using.

00:38:51.150 --> 00:38:53.180
On all of the devices
that iOS 5 supports,

00:38:53.290 --> 00:38:59.660
you'll see one of two values from that:
PowerVR SGX535, which is the GPU used

00:38:59.660 --> 00:39:01.810
on iPad 1 and previous.

00:39:01.960 --> 00:39:06.990
And on iPad 2,
you will see PowerVR SGX543.

00:39:07.130 --> 00:39:09.660
So if you see this value,
that's your best indication that

00:39:09.890 --> 00:39:14.090
you have this huge performance
potential available to you.

00:39:15.120 --> 00:39:18.850
I do want to make one caution in
that this is returning a string,

00:39:18.850 --> 00:39:21.860
and without saying anything,
someday there will be a third

00:39:21.910 --> 00:39:23.440
or fourth or fifth entry there.

00:39:23.440 --> 00:39:27.260
So please do code defensively
here and do something reasonable

00:39:27.260 --> 00:39:29.300
when you see an unexpected value.

00:39:29.850 --> 00:39:31.760
In this case,
something reasonable is probably

00:39:31.760 --> 00:39:35.000
going to be to default to your
highest quality rendering path.

00:39:35.150 --> 00:39:38.050
So, once you've detected this,
what can you do with it?

00:39:38.680 --> 00:39:41.280
So remember what I said about content
scale factor and turning that down?

00:39:41.300 --> 00:39:42.240
Forget it.

00:39:42.330 --> 00:39:44.800
Turn it all the way back up,
all the way as high as it goes.

00:39:44.830 --> 00:39:46.900
It can handle it.

00:39:47.160 --> 00:39:48.660
Throw in full-scene
multi-sampling while you're at it.

00:39:48.800 --> 00:39:50.520
You can do that, too.

00:39:50.540 --> 00:39:53.310
It's got more than enough
performance for that.

00:39:54.430 --> 00:39:57.520
If you had problems with level
of blending and overdraw,

00:39:57.520 --> 00:40:01.380
you have much, much,
much more budget for that specifically.

00:40:01.380 --> 00:40:03.930
You can either have a
larger number of particles,

00:40:04.050 --> 00:40:08.280
you can have larger size particles,
generally a much higher density

00:40:08.370 --> 00:40:09.370
in your particle systems.

00:40:09.590 --> 00:40:11.940
Similarly,
if you're using blending for drawing

00:40:11.990 --> 00:40:13.750
trees or other kinds of foliage.

00:40:14.990 --> 00:40:19.360
It's not just the GPU that's faster,
the CPU is quite a bit faster as well.

00:40:19.420 --> 00:40:22.130
And even on a single thread,
the CPU is going to get through an

00:40:22.130 --> 00:40:25.230
OpenGL draw call in much less time,
which means that you can afford to

00:40:25.330 --> 00:40:28.840
do a much larger number of draw calls
every second in your application.

00:40:28.840 --> 00:40:34.490
If your application is multi-threaded
and moving other work off to other cores,

00:40:34.890 --> 00:40:37.230
then that just goes up from there.

00:40:37.270 --> 00:40:39.980
On the shading side,
the first thing you should be

00:40:40.060 --> 00:40:43.670
looking at is to actually move
to proper per-pixel lighting.

00:40:44.860 --> 00:40:46.710
As I said,
you can actually get away with using

00:40:46.710 --> 00:40:48.420
much greater precision in your shaders.

00:40:48.520 --> 00:40:50.660
In this case,
actually writing shaders that do a

00:40:50.680 --> 00:40:54.510
reasonable amount of high-precision math
is well within the performance budget.

00:40:54.520 --> 00:40:58.810
You can use high-precision normal
maps and gloss maps to provide really

00:40:58.810 --> 00:41:00.550
high-quality per-pixel lighting.

00:41:00.720 --> 00:41:05.330
This is something that you saw
Real Racing 2 use to great effect.

00:41:05.560 --> 00:41:09.120
We've had a really interesting
recent example in light probes.

00:41:09.120 --> 00:41:13.650
The Shadowgun demo that you saw used
precomputed light probes to apply

00:41:13.970 --> 00:41:19.380
baked indirect lighting onto dynamic
objects that moved around the scene.

00:41:20.000 --> 00:41:24.950
Parallax mapping is a very interesting
technique that has actually been used

00:41:24.950 --> 00:41:30.260
to great effect in Epic Citadel to
improve the perceived detail on surfaces.

00:41:31.380 --> 00:41:33.980
You also have performance
budget now for shadow mapping.

00:41:33.980 --> 00:41:36.550
In this case, we have a new GLSL function
to actually do,

00:41:36.550 --> 00:41:39.860
you know, read sample from the shadow
map and filter it for you.

00:41:39.930 --> 00:41:42.210
We've actually seen examples
of all of these techniques,

00:41:42.400 --> 00:41:44.470
and sometimes all of
them at the same time,

00:41:44.710 --> 00:41:47.990
used in real shipping applications.

00:41:48.340 --> 00:41:51.100
Now, these are all techniques
that are well within the

00:41:51.370 --> 00:41:53.180
performance budget of an iPad 2.

00:41:53.710 --> 00:41:58.500
We wanted to go a little bit farther and
see what iPad 2 was really capable of.

00:41:58.660 --> 00:42:02.300
And so I want to show
you what we came up with.

00:42:05.020 --> 00:42:08.660
So you've seen a few shots of this
in various instances earlier today,

00:42:08.760 --> 00:42:11.170
but I want to talk about this
demo and what it's doing in

00:42:11.170 --> 00:42:12.740
a little bit more detail.

00:42:12.880 --> 00:42:16.470
This is a demo of a technique
called light pre-pass rendering,

00:42:16.470 --> 00:42:20.380
which is in turn one of a class of
techniques called deferred shading.

00:42:21.260 --> 00:42:24.620
One of the big advantages of this
kind of technique is that it provides,

00:42:24.700 --> 00:42:27.250
you know,
it lets you dramatically increase the

00:42:27.250 --> 00:42:29.710
number of dynamic lights in your scene.

00:42:30.170 --> 00:42:36.990
In this case,
all of these little lights you see,

00:42:36.990 --> 00:42:42.790
our little fairies here,
are all each a... There's 64 of them,

00:42:42.790 --> 00:42:42.790
and they're all each a light
casting per-pixel lighting

00:42:42.790 --> 00:42:42.790
on the surrounding geometry.

00:42:43.860 --> 00:42:46.360
One of the things that this class
of deferred shading techniques lets

00:42:46.360 --> 00:42:50.520
you do is draw all of your geometry,
completely ignoring what

00:42:50.690 --> 00:42:57.220
lights apply to them,
and then later draw all of your lights,

00:42:57.220 --> 00:43:00.500
completely ignoring what
geometry they apply to,

00:43:00.500 --> 00:43:00.500
which is what lets it scale so well
with a much larger number of lights.

00:43:01.270 --> 00:43:04.400
So how is this actually put together?

00:43:04.590 --> 00:43:07.180
Well, the first thing is,
we have rendering of the shadows

00:43:07.470 --> 00:43:09.060
that are casted by the sun.

00:43:09.230 --> 00:43:11.720
So Gokhan talked about this
a little bit earlier today.

00:43:11.720 --> 00:43:13.480
But this is our shadow map.

00:43:13.600 --> 00:43:17.940
The second step in the Light Prepass
technique is to render our G buffer.

00:43:18.040 --> 00:43:20.000
In this case, we're rendering two images.

00:43:20.120 --> 00:43:22.930
We're rendering our color buffer,
which we're actually

00:43:22.930 --> 00:43:25.380
not writing colors to,
but we're actually writing

00:43:25.380 --> 00:43:27.240
viewspace normals of that pixel.

00:43:27.330 --> 00:43:29.580
On the left, we're actually running
to a depth texture,

00:43:29.580 --> 00:43:33.030
recording the depth from
the camera of that pixel.

00:43:33.760 --> 00:43:35.860
So what that lets you do is
that if you read the depth from

00:43:35.860 --> 00:43:38.780
this texture and you know its x,
y coordinates in the texture,

00:43:38.900 --> 00:43:42.670
you can reconstruct where
that point was in 3D space.

00:43:42.950 --> 00:43:46.230
In turn, that lets you find out how
far that was from the light,

00:43:46.390 --> 00:43:49.300
and given that you also can find
the normal from the other texture,

00:43:49.410 --> 00:43:52.890
that gives you what you need to
calculate the lighting equation.

00:43:53.050 --> 00:43:58.760
And that leads to the next pass,
which is to actually render the lights.

00:43:58.830 --> 00:44:02.210
So this image is actually a little
bit misleading in what it's doing.

00:44:03.460 --> 00:44:05.170
This is actually, you know,
it looks like we're drawing lights

00:44:05.250 --> 00:44:08.330
on top of our little temple with,
you know, trees around it,

00:44:08.360 --> 00:44:10.430
but we're actually not applying
lights to the geometry at all.

00:44:10.460 --> 00:44:14.350
We're applying lights to the images,
the G buffer that we just saw.

00:44:14.360 --> 00:44:17.720
What we're actually drawing are spheres,
or some very coarse

00:44:17.720 --> 00:44:20.730
approximation thereof,
and for every pixel on the

00:44:20.730 --> 00:44:24.380
surface of that sphere,
we're looking up into the normal texture,

00:44:24.380 --> 00:44:27.800
we're looking up into the depth texture,
and using that to calculate what the

00:44:27.800 --> 00:44:29.830
contribution from this dynamic light is.

00:44:29.840 --> 00:44:31.730
One sphere per dynamic light.

00:44:32.940 --> 00:44:35.780
And then we just add that in to
the light buffer as we move along.

00:44:35.840 --> 00:44:40.070
And that leaves us with our light image.

00:44:41.490 --> 00:44:44.550
And our final step is to
composite all of that together,

00:44:44.550 --> 00:44:50.200
where we effectively blend that
light image in with the geometry

00:44:50.200 --> 00:44:52.640
again with its diffused texture.

00:44:52.710 --> 00:44:56.040
We also sample from that shadow
map that we saw in the beginning

00:44:56.040 --> 00:44:58.030
to determine the sun shadowing.

00:44:59.330 --> 00:45:02.140
So just to show you what this
kind of thing lets you do,

00:45:02.140 --> 00:45:04.920
if we remove all of the
actual fairies in the scene,

00:45:05.040 --> 00:45:08.660
then you can see how much character
that takes out of the scene.

00:45:08.860 --> 00:45:12.740
And it gives you a really easy idea of
what the ability to just throw a lot

00:45:12.950 --> 00:45:15.270
of lights at the problem gives you.

00:45:15.280 --> 00:45:20.020
So this is a light prepress
renderer rendering four passes,

00:45:20.020 --> 00:45:23.280
our shadow pass, G buffer, light,
and final composition.

00:45:23.280 --> 00:45:28.650
It is applying 64 dynamic lights to this
object and also applying one light from

00:45:28.660 --> 00:45:30.440
the sun that fills the entire scene.

00:45:30.770 --> 00:45:36.000
The sun is casting soft shadows
via a 1024 by 1024 shadow map,

00:45:36.250 --> 00:45:39.680
all running at 30 frames
per second on an iPad 2.

00:45:39.680 --> 00:45:43.550
So that brings us to the
end of today's presentation.

00:45:43.790 --> 00:45:46.110
So a quick summary of what we went over.

00:45:46.320 --> 00:45:49.300
We talked about view controllers.

00:45:49.370 --> 00:45:51.660
Unless you want your
OpenGL view to be very,

00:45:51.660 --> 00:45:55.470
very lonely, it needs to have a view
controller paired with it.

00:45:55.980 --> 00:45:59.290
We talked about some
OpenGL multi-thread design patterns,

00:45:59.400 --> 00:46:04.020
in which case OpenGL's thread concurrency
rules and some suggested design patterns

00:46:04.020 --> 00:46:06.130
on how to use those effectively.

00:46:06.300 --> 00:46:09.700
We talked about handling the range of
three internal display sizes and more

00:46:10.020 --> 00:46:14.040
external display sizes if you choose
to support the second display feature.

00:46:14.170 --> 00:46:16.040
And then finally,
we went over a little bit about what

00:46:16.040 --> 00:46:21.230
you can do with the extra features and
the performance that iPad 2 provides.

00:46:22.480 --> 00:46:25.240
If you'd like more information,
you can contact Alan Schaefer,

00:46:25.240 --> 00:46:28.000
our graphics and game
technologies evangelist.

00:46:28.070 --> 00:46:31.160
We have a very large document
called the OpenGL ES Programming

00:46:31.160 --> 00:46:34.580
Guide for iOS that is available
on Apple's developer website.

00:46:34.640 --> 00:46:38.520
This has a lot of information in
it that we did not cover today.

00:46:38.880 --> 00:46:42.070
We also have a section in the
Apple Developer Forums specifically

00:46:42.140 --> 00:46:44.810
for OpenGL that actually
gets quite a bit of traffic,

00:46:44.960 --> 00:46:47.540
both beginner, expert,
and a number of people from

00:46:47.540 --> 00:46:51.960
Apple's OpenGL team contributing
to answer questions there.

00:46:52.030 --> 00:46:53.450
Thank you.