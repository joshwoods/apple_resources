# Wwdc2025 112

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Platforms State of the Union (ASL)Discover the newest advancements on Apple platforms.ResourcesHD VideoSD Video

Discover the newest advancements on Apple platforms.

HD VideoSD Video

HD Video

SD Video

Search this video…Welcome to the 2025 Platform State of the Union.This is a huge year for our platforms.And today, we'll dive into some of the exciting new features,APIs, and technologies for your apps and games.All of our work this year builds on top of Apple's powerful platforms.Platforms that bring your imaginative, creative, and ambitious ideas to life.And what makes that possible is the unique fusionof Apple's hardware, software, and services with your apps.At the core is Apple silicon,which provides unprecedented power and efficiency across all our platforms.With unified memory that maximizes performance,specialized accelerators for video and machine learning,and a secure enclave that guarantees the system's integrity.And all of this provides a strong foundationfor our software technologies to build upon,like Metal, with low-level APIsthat unlock the hardware's full potential.Apple Intelligence, with powerful generative modelsand privacy built in from the ground up.Swift, delivering performance and safetyacross the system, SDK, and apps.And SwiftUI, enabling rich interactivity,animations, and adaptive design.And because our platforms are deeply infusedwith technologies like privacy, accessibility,and internationalization,your apps can benefit from them too.So the broadest range of users can access your appsin the ways that work best for them.The potential for this builds even furtherwith higher level APIs that help your apps expandacross devices.Using iCloud and CloudKit,your app's data automatically syncs from device to device,all while leveraging advanced privacy and security guarantees.With widgets, your app's notification and contentare intelligently surfaced at the right placeand the right time.This also works for Live Activities,so your users have immediate accessto your app's actions and data.And you can add support for new platforms like visionOSwith the same frameworks and concepts.When your apps take advantage of Apple platforms,the experience becomes more than the sum of its parts.All of this is an amazing opportunity,and it's getting even bigger and better this yearas we dive into how you can bring vitality to your appswith the new design and Liquid Glass materials,deliver new possibilities for your userswith Apple Intelligence and machine learning,transform the way you write appswith generative intelligence in Xcode and updates to Swift,and further elevate your app's performance and capabilitieswith enhancements to frameworks like SwiftUI and Metal.Let's start with our UI design built with Liquid Glass.Here's Billy to tell you more.This year introduces our broadest design update everand begins the next era of our software design.Transformations of this magnitude are rare.When they do occur, they mark inflection points,moments that redefine what's possible.And that's certainly been true for us.The new design beautifully scalesacross Apple's apps and platforms,all while maintaining the iconic experienceusers rely on every day.Importantly, it gives you the perfect opportunity to refreshand modernize elements of your app's design,making them more delightful than ever before.So today we're gonna walk you through our design thinkingand high-level design concepts that you should consider,updates to our developer API for building your apps,and updates to how you express your app’s look through beautiful new icons.Software is the heart and soul of our products.We didn't approach such an ambitious design lightly.We had several goals behind the new design.First, we want to elevate the content users care about most.UI is in service of the experience.It should be easily accessible when neededand elegantly recede to the background when not,making users’ experiences of reading, creating, and watching contentas immersive and impactful as possible.Secondly, we want to establish greater consistency,harmony, and usability by creating a universal design language,one that offers a seamless experience as your app's users move across platformswhile maintaining the distinct qualities that make each unique.And finally, with the incredibletechnological advances of our hardware,we can craft interaction designin ways that simply weren't possible before today.The new design is built around dynamism, expressiveness, and a focuson user experiences that are joyful and delightful.So let's start with the foundational elementof the new design, Liquid Glass.Liquid Glass enables an entirely new levelof depth and vitality by combining the optical qualitiesof glass with responsive fluidity.It's designed to refract content from below it,reflect light from around it,and have responsive lensing along its edges.As you interact with the glass, it feels fluid and alive,as if the physical glass of your device is the UI itself.This is much more than visual craft.Interactivity is at the core of the new design.Specular highlights, refraction,and the translucent properties of Liquid Glass visually lift controls,all when maintaining a close relationshipto the content beneath.Now that we’ve covered the high-level design thinking,let's focus on three guiding principlesfor implementing the new design in your apps.First, establishing hierarchy.Second, creating harmony.And third, maintaining consistency.Let's start with hierarchy.Liquid Glass controls and navigation actas a distinct functional layer that floats above your app.And this allows a new dimension of depth,bringing greater focus to your content.To enable this, elements once consideredfor rectangular displays have been redesignedto respect the rounded corners of the hardware,freeing up valuable space for your app's contentAnd by thoughtfully grouping controls in this new floating layer,it removes visual density,allowing your content to extend to the edges of the display or window.The color of Liquid Glass is informed by your app's content,intelligently adapting between light and dark app environments.Of course, you can apply your own custom colors to Liquid Glass as well.Keep this in mind as you indicate key actions,selection state, or status within your app.And Liquid Glass is dynamic by design.Controls can fluidly morph to recede in prominencewhen a user wants to focus on your app content.The moment a user needs them again, they'll expand.This works across different types of apps,whether they are designed as a single viewor with multiple tabs.The new design ensures a content-rich experience.By elevating controls and fluidly morphing between states,the new design elegantly reinforces hierarchythroughout the user experience.It feels both familiar and entirely new all at once.And this brings me to our second design principle.These new dynamic controls create harmonybetween hardware, content, and controls.The shape of our modern devices inform the curvature,size, and shape of our UI elements,delivering concentricity and visual harmony.Going further, the new rounded formsare influenced by the geometry of your fingers,adding to more natural touch interactions across apps.Concentricity is key to the new design's abilityto scale from smaller to larger screens,where sidebars and toolbars nest perfectly within windows.Along refreshed shapes, sizes, and color,our typography is updated as well.In an effort to make content more approachable,the new design includes larger, bolder, left-aligned typography.When applying the new design language to your app,you'll find nearly every component and control has been updated,with increased heights and softer shapes.This harmonizes the experience across Apple platforms,ensuring your app design feels considered.And it also helps with our third principle,maintaining consistency.The new design is universal across platforms,so now it's easier than everfor you to establish consistency for your apps.On macOS, your app becomes more visually alignedwith iOS and iPadOS,while retaining the density Mac users love.And iPadOS now shares many of the same layout considerations as macOS,including consistent placement of common elements,as well as dynamically scalable windows and floating controls.And on watchOS, Liquid Glass controls allow content to shine through.As a developer, the easiest way to design for consistencythroughout your user experienceis by adopting the new inset Liquid Glass controls.This ensures your most essential UI elementsare available across screen sizes,window sizes, and platforms.So that's a quick overview of the new design.We couldn't be more excited to see it come to life in your apps,making them feel more seamless and delightful,all while giving your users deeper connection to their content,harmony throughout their experience,and consistency across platforms.Now, over to Taylor to share the APIsthat enable you to implement the new design in your app.Each of Apple's native UI frameworks, SwiftUI,UIKit and AppKit provide your app everything it needsto adopt the new design.You'll start by just recompiling your app on the new releasesand seeing how it looks with no code changes.Next is refining that result using new APIs to tailor the design to your app.And finally, updating your custom views with the new design principlesand Liquid Glass effects.Let's start by taking a look at what you can expect to seewhen you recompile your app for the new releases.The framework views your app is already usingwill automatically update with the new design.Here are some of the most common ones.Multi-tab apps using TabView or equivalent APIwill automatically get a new design with Liquid Glass tab bars.Or if your app uses NavigationSplitView,it will now have a Liquid Glass sidebar on both MacOS and iPadOS.Your iPad app will automatically now have the ability to resize columns too.And inspector columns have been updatedwith a unique edge-to-edge application of Liquid Glassto reflect the relationship with the content they edit.The new design for toolbars and navigation bars build upon the existing patternsfor how your app uses them.Your app’s toolbar items are now placed within glassand sit on top of a new scroll-edge effect,which provides separation between the glass and main app content.Navigation stacks have been updated to enablefluid morphing of the toolbar as users navigateand scroll through your app's content.Menus or popovers in your app's toolbarwill automatically morph directly into those presentations.And a new API gives you additional controlfor other uses like sheet presentations.Those are just a few quick examples.Most of the views your app is already usingwill automatically get a fresh new look and new metricsto enhance utility and legibility.And these updates apply across all of the platformsyour app runs on.Let's see the new design in action.I'm gonna try this out with a sample projectwe worked on last year, Destination Video.Now, I've just downloaded the existing projectand I've opened it in Xcode 26,but I've made no other changes.The preview shows me how the app now lookswith the new Liquid Glass tab bar.I'm gonna preview this on deviceto browse through more of the app.Look how the Liquid Glass plays beautifullyagainst the content underneath as I scroll around.The tabs have a new control interaction effectas I switch between them.And when I drill into one of the videos, the back button is now within glass.Finally, the video player has a new designwith Liquid Glass controls.Destination Video is a great exampleof making the most of framework-provided views.I didn't have to make any code changes to adopt the new design,and that'll be the case for many of your apps too.This is also the perfect time to considerwhere you could simplify custom componentsand take more advantage of framework views.With Liquid Glass enabled in your app,now we move on to refining that initial resultand adopting new APIs to tailor the design to your app.Now it's unlikely your app will use all of these new APIs,so you can pick and choose the ones that best fitthe design and intent of your app.Toolbars have several new APIs thatallow you to section and style items to reflect their role.Some views automatically create separationin the toolbar to reinforce the grouping of their content,and the new toolbar spacer API enables you to create additional groupings.Content in glass is monochrome by default,but you can apply color with purpose using tint modifiersand the prominent style for key actions.TabView has a new API for adding a custom bottom accessorythat sits alongside the tab bar,which is perfect for showing playback controlsor global status in your app.And this integrates with a new APIthat causes the tab bar to collapse when scrolling,offering even more space for your app's content.The design of search has been updatedto be more consistent within and across platforms.On iPhone, the search field floatsat the bottom of the screen,right where your thumb can reach it.We've also brought the toolbar search patternfrom macOS to iPadOS,with the searchable API providing a consistent resultbetween both platforms.Let's take a look at an example.We've been working on a sample app called Landmarks.I have the project open right here in Xcode.I've started with the detail page.Here's the code and a preview of Landmarks running on macOS.It shows the new design of the sidebar and toolbar.Now I want this prominent image to make the mostof the Liquid Glass sidebar instead of ending at the edge.This is the perfect use case for background extension effect.This new modifier extends a copy of the imageout of the safe area so that the real image isn't covered up.It's always so cool to see how much betterthat immediately looks in the preview.Next, I'll add some fixed spacers between itemsin the toolbar to create sections of the related elements.And now let's switch over to the iPad previewwhere you can see that the same two improvementshave come through here as well.Now, in addition to the high-level framework views,there are APIs that allow you to createcustom experiences with Liquid Glass material,complete with features like tinting and interactivity.Let's jump straight into adopting these in a custom controlI've been building in the Landmarks app.Here I am back in the Landmarks project,this time editing the badges view, which displaysbadges for achievements I've received on the right side of the screen.It floats above the content already,which makes it a great candidate to adopt the Liquid Glass material.I’ll replace the custom background of each badge with the new glassEffect modifier,and I’ll replace the custom button style with the new glass button style.I’ll also add a glassEffect container,so all these effects are grouped as a set that can morph together.And there it is, the preview updates to show their new appearance,which is already looking great.But as you've seen, Liquid Glass almost feels like a physical material.The best way to experience it is with the device and input you're designing for.On touch, the button springs up and glowsto highlight my interaction with a subtle stretch effect.And on release, the Liquid Glass morphs to reveal the badges.Of course, every app will have its own paththrough its adoption of the new design, depending on how it was builtand its design and complexity.But using Apple's native frameworks puts your app in a great positionto make this adoption easy.Now, over to Bobby, who's going to tell you moreabout updating your app icons.Liquid Glass will make your app icons shine like never before.The new design creates opportunities for personalizationand, for the first time, gives every app a cohesive identityacross Apple platforms.Your app icon is a big deal.It represents your brand, tells your story, and builds engagement.Liquid Glass brings it to life with layering, depth, and vitality.Users can now choose from a variety of expressive appearances,each offering a light and dark variant.Most familiar is the classic full color appearance.Tint mode has an even more colorful light variantand a more translucent dark variant.New this year, we're introducing a clear mode,that beautifully shows off the Liquid Glass material.On Mac, icons now support clear and tint modesand adopt the rounded rectangular shape that matches iPhone.And because you'll want to pay attentionto how you're crafting the layers, highlights,and transparency of your icon,we're introducing Icon Composer,a new tool for building stunning icons for Apple platforms.As we've redesigned our own icons,we found that crafting them with two to four layers is the sweet spot.And Icon Composer is designed to help you do just that.Let's take a look.You can start by importing vector content.You can organize and annotate layers for multiple rendering modes,add blurring, adjust translucency, test specular highlighting,and preview icons in various tinting modesto ensure that your icon looks just right.When you're ready to publish,Icon Composer generates a single source artifactthat you can import into Xcode.It can also export high resolution versions of the iconin fully rendered form for marketing and communication needs.Your icons will look radiant with Liquid Glass.And Icon Composer will help make your app's visual identitymore consistent than ever.Icon Composer is included as part of Xcode,and you can get the latest downloadat the Apple Developer website.Back to you, Matthew.So that's the iconic new design for appsand system experiences across Apple platforms.With Liquid Glass, your apps blend seamlessly into the displaywith new visual depth and a focus on your content.All of our UI frameworks fully support Liquid Glass.So whether you're using SwiftUI, UIKit, or AppKit,your app can take advantage of its beauty and expressiveness.When run on iOS 26 and macOS Tahoe,apps built with Xcode 16 will have an unchanged user interface,keeping their current design.When you rebuild your app with Xcode 26,standard controls will automaticallybe rendered with the new design and materials.So you can then identify other opportunitieswhere Liquid Glass can make your app shine,particularly for your custom controls and views.As you evaluate your app's UIand the time you need to adopt the new design,we're providing an option to continueto use your app's current design with Xcode 26.We intend this option to be removedin the next major release.We are so excited to see the transformative effectsof Liquid Glass in your apps.Now let's talk about intelligence.At Apple, we use artificial intelligenceand machine learning to add innovative featuresto all our platforms.And there are many opportunities for youto bring intelligence into your apps too.Josh will tell you how.Apple Intelligence is the personal intelligence systembuilt into the core of our operating systemsthat helps your users get things donethrough many features like Writing Tools, GenMoji,and Image Playground in apps across the system,including many of yours.For most of you using standard UI frameworksto render text fields,your apps support Writing Tools automatically.And those of you with custom text enginescan adopt APIs to provide your users accessto these capabilities in your apps.Similarly, GenMoji is automatically supportedas stickers in your app when you use system text controls.And there are APIs for you to render themwith custom text engines.And Image Playground APIs can supporton-device image generation right in your apps.These are just the tip of the icebergwhen it comes to the many ways your appscan take advantage of intelligence on Apple devices.This year, any app can tap into intelligence that's powerful,fast, built with privacy, and available even when the user is offlinethrough direct access to the on-device foundation modelthat powers many of our featureswith the Foundation Models framework.This API allows you to tap into our highlyoptimized on-device foundation model which is specialized for everyday tasks.You can use the framework to power intelligent features in your appusing model capabilitiessuch as text extraction, summarization, and more.Prompting the model starts with just three lines of code:import the framework, create a session, and send your prompt to the model.The model is optimized with state-of-the-art quantization techniquesand speculative decodingto provide performance, efficiency, and quality.And with Swift concurrency, the API enables you to chooseto display the answer as one response or incrementally using streaming output.The framework also includes guardrails for our core features,and you can add your own safety rules for your specific use cases.It's great for things like content generation, in-app user guides,customized learning, and much more.We fine-tune the model for broad use cases,and when you invoke the model,you'll have the choice to add additional adapters like content taggingto improve performance even further for specific tasks.Often when you prompt a model, you'll need the LLM togenerate structured responses to be used directly by your app.We've made this really easywith guided generation.With it, you can make your own data structures generable.Whenever you send a request to the model,your struct gets filled in with matching information,enabling you to prompt the model to produce full instances of your data typeand allowing you to focus on your app's unique featuresinstead of the details of directing and parsing model output.By supporting structured data output in addition to natural language,you can easily integrate intelligent featuresin whatever way best fits your app's user experience.This is a first-class experience written in Swift for Swift.The Foundation Models API also includes support for tool calling.It allows the model to identify a task that may require additional informationor actions and call the appropriate functionwhile it's processing the user's request.To utilize this capability, you define in Swift the tools the model can use,such as fetching up-to-date content from Wikipedia,referencing information from your app, or taking actions likecreating a journal entry in your app.Then, the model can autonomously make decisionsabout what tool to use and when, so you don't have to decide it programmatically.Here's Richard to show you a demo of all of this in action.Let's use the Foundation Models framework to addgenerative content to a travel app I'm building.But first, let me show you how to prompt the model in Xcode.I'll start by importing Foundation Models.Then I'm going to use the new playground macro in Xcode to preview my non-UI code.To interact with the model,I first create a Language Model Session.As I type, it immediately sees the canvas on the rightthat we got a session.Then I just call session.respond to send my first prompt.I'll ask for a good name for a trip to Japan.And right away, we'll see the model's responseappear in the canvas.For large language models,prompt engineering is all about trying outdifferent prompts and finding the best ones.I want to see how my prompt works forvarious travel destinations.So I can add a for loop to iterate overall of the destinations featured in my Landmarks app.Now in the canvas, I can see the entire history of the model's responsesto different prompts.Quickly iterating with Playgrounds is so great for prompt engineering.Now that we've seen it work,let's add a feature to my app to generate travel plans.I built my travel plan UI on top of these Swift data structures.With guided generation, I can annotate them as @Generableso that the model can create them automatically based on my prompt.And I can also provide additional guides on the propertiesso that the model will only produce the values I expect.Then in my app logic, I go ahead and create a sessionand pass my custom instructions to the model.I ask it to generate an itineraryto help the user visit a landmark.I can also include an example itinerarythat I created before to give the model an ideawhat kind of a response I'm looking for.In my session, I can leveragethe model's tool calling capability.This is a great way to let the model fetchexternal information autonomously.Here’s my custom tool that uses Mapkitto find points of interest whenever the model needs them.Now, I'm going to call session.streamResponseand ask the model to generate an itinerary struct.Pass in my prompt.Then streamResponse returns an async sequencethat lets me update the itinerary in my UI as the model is generating it.And now, let's try it out.On my phone, I start by selecting the Grand Canyon,tap Generate Itinerary.Then I see the model generates a descriptionand activities for each day.And the model also decided to fetch points of interest,like hotels, using our custom tool.With prompting, guided generation, and tool calling,our on-device model created this Grand Canyon adventurefor me right in the palm of my hand.Pretty amazing.Back to Josh.Since the model is on-device, your users’ data stays privateand doesn't need to go to a server-side model or to anyone else.The on-device foundation model is readily available,so features you build will work offline, and you don't have to worryabout account setup or API keys.And all of this at no cost to you or your users for any requests.The Foundation Models framework joins the suiteof machine learning APIs and toolsthat you can use to tap into on-device intelligence for features within your app,including updates coming to the Speech API.Beyond the models we’ve provided on-device,you can also use Core ML to run models you bring onto device.Core ML optimizes performance by leveraging the CPU, GPU, and neural engine.With additional frameworks, you can further optimize your ML workloadsfor real-time signal processing on the CPU,or you can enable low-level access to GPU compute,all powered by Apple silicon.Based on your needs and level of expertise with models,you can pick the machine learning and AI frameworksand tools that best support you across our platforms.Then, for those of you experimenting with, training,and fine-tuning large language and other models,you can use MLX, an open-source librarythat takes full advantage of Apple silicon's unified memory.Another way you can enhance your app's features and capabilitiesis by giving them more visibilityacross our platforms through the App Intents framework.It can help your users easily find and use core functions of your app,even when they're not in your app.With this framework, you can define App Intents,the actions your app can perform,as well as app entities, the content your app can handle and produce.These come together to describe the important functions of your app.App Intents can be used with context-aware action button experiences,interactivity in widgets,automation via shortcuts, quick controls in Control Center,and customized results in Spotlight.And with the all-new Spotlight experience in macOS Tahoe,users can access all the App Intentsthat you've created right from Spotlight.If your App Intent has parameters, users can easily fill them in,creating more natural and seamless ways to find and get into your appfrom anywhere on the system.We're also introducing a new App Intents schema for Visual Intelligence.You can apply your app-specific Visual Search logicto content in Visual Intelligence.This brings your resultsright into the search experience so users can deep link into your appright from the results.Altogether, App Intents are the key to delivering rich experiences to your usersall across the system.Now back to Matthew.Intelligence is also transforming how we write code.New developer tools and powerful coding modelsare already making us more productive and creative.And with the power and ease of Swift and SwiftUI,there is so much potential for everyone to explore new ideas.So let's take a look at some of the new featuresin our tools and languagesdesigned to empower developers like never before.Ken and Holly will start with what's new in Xcode.Millions of developers around the world use Xcodeto build the most innovative and creative apps for Apple platforms.Xcode 26 is packed with incredible features and experiencesthat can help make your ideas a reality.Let's start by talking about intelligence.Last year, we introduced Predictive Code Completion,which uses a local model running on Apple siliconto provide intelligent suggestions based on your project and coding style.Millions of lines of code are createdusing Predictive Code Completion every week.We continue to make the model better,improving accuracy and optimizing context gatheringto help the model use more of your code, all running locally.Beyond code completion, generative intelligence really shineswhen you interact with code using natural language.We tested Swift Assist with developers, and the main feedback we heardwas about models.Many of you are already using models from multiple providers.And since Xcode plays such an important role in your development workflow,you want to have those models right at your fingertips as you craft code.This space is moving fast,with new capabilities like reasoning, multimodality, and more.So we expanded our vision, creating an even better experiencethat we think you'll love.First, we're excited to bring ChatGPT to Xcode.We're working with OpenAIto seamlessly integrate their optimized coding models right in Xcode.And you can try this in the first beta of Xcode 26 today.Let's see it in action.Take it away, Holly.I have an idea for a feature in the Landmarks app.Let's take a look at how easy it is to bring it to life.I'll open the new coding assistant from the toolbar right at the top of Xcode.I've already configured Xcode, so I'm ready to go.First, I'm going to add a new view to the Landmarks app.My idea is to show statistics about my landmark locations.Xcode created a statistics view and modified my existing navigation list.I can click on each code snippet and see the changes.I can also open the overview.It shows me all of the modified files in a single view with colorful annotationshighlighting all of the code changes.The best part?Xcode automatically updates the code for me.And with previews, I can visualize my app's UI almost instantly.Now that I've got the statistics view in place,I'll ask what landmark data is in the projectthat might make a more interesting dashboard.When interacting with the model,Xcode automatically sends the context, like the file I'm in,what code I have selected, errors, and related files.And the model can ask for more information from my project as it works on a response.Here it looked at various files in my projectto understand my code and summarize datastructures as feature ideas.And Xcode linked me to the reference files so I can understand the code too.This looks like a good plan.I'll ask to implement these ideas.I haven't really given any direction on how to present this data.Let's see what it comes up with.Okay, now that I've got the data, let's design the dashboard.Here's a quick sketch of what I'm thinking.I'll drop it in with my request.Sometimes the easiest way to express an idea is visually,with a drawing or mockup or annotated screenshot.Wow, that's a pretty great start.It even used system colors and SF Symbols to bringmy sketch to life.What was just an idea a few minutes ago is now a feature I can try in my app.And to help you stay in the flow and be more productivein the tasks you're doing every day, like writing tests and documentation,fixing issues, or simply understanding code,we're putting those capabilities right where you need them.Let me start by showing you a new feature called Coding Tools.It's just like Writing Tools, but for code.I can bring it up anywhere in my code and get suggested actionslike generating a preview or playground or fixing an issue.And if I'm looking for something more specific, I can just ask for it.A great way to understand non-UI code is to try it out.Like you saw earlier, there's a new playground macro for exploring code.It's just like a preview, but it works for any code.I’ll choose Generate Playground.The code appears right in my file.It gives me a real example calling into the code.I can preview anything.Now that I know how this code works, let's add documentation.I'll make a selection and choose Document.It created DocC comments and I can also preview the rendered documentation.Everyone always writes perfect bug-free code, right?But if something does slip through the cracks,don't worry, I can just click on the issueand choose Generate Fix and get back to building.And my favorite feature, the conversation history.When I'm working with the model,I love having the freedom to safely explore ideas.I'm often many prompts in before I realize I want to go back in timeand go a different way.With the history slider, I can scrub through timeand see every change, making it easyto roll back and keep on vibing.With quick actions, intelligent error fixing,conversation history, and more, Xcode is now supercharged.In just a few clicks, you can start using ChatGPT and Xcodewithout even creating an account.You'll get a limited number of requests each and every day.ChatGPT subscribers can connect their accounts for even more requests.And you're in control of the data you share with OpenAI.If you're using models from different providers,it's easy to bring those to Xcode too.For example, you can add your anthropic API key.And use their latest models like Claude 4 Opusand Sonnet directly in Xcode.And you can run models locally on your Mac or private network,powered by the tool of your choice.This gives you flexibility and controlto use the model that works best for you.And when a new model is released,you can just use it with Xcode.With built-in intelligence powered by the best coding models,Xcode 26 will transform the way you create apps.There are many more exciting features to discover,like the redesigned and simplified tab experience.So just like in Safari, you can quickly open a new tabwith Command T and all navigation happensright in the same tab.And if you want to stay focused on a file in a tab,just pin it.Xcode is also more accessible.If you have limited use of the keyboard,Xcode 26 improves support for Voice Control,letting you dictate Swift codeand navigate through the interface entirely by voice.And to make localizing your app easier,you can automatically generate usage description commentsin the string catalog,providing the right context for accurate translation.The first beta of Xcode 26 is available now,and you can start coding with ChatGPT and other models today.Next, to talk about all the exciting changes in Swift,here's Ben.We created Swift with a clear goalof building a language that meets the challengesof modern development without trading off performancefor safety.One that's powerful, but also easy to use.And today, we're taking that furtherwith Swift 6.2.This release adds some great features focused on performance.One of the most anticipated is inline arrays.These allow you to declare arrays with a fixed sizethat can be stored on the stack or directly inside other typeswithout using heap memory.Knowing the size of an array at compile timeunlocks optimizations by the Swift compiler,enabling significant performance wins.We're also introducing a new span type.It provides a safe alternative to pointersfor fast direct access to contiguous memory.This type is key to another new featurethat improves communication with unsafe languages like C.When C pointers are annotated with length and lifetime information,they can be bridged into Swift as a span,providing a memory-safe interface that’s also easier to use.This combination of safety and performancemakes Swift a great option where these attributes are critical.And that's why WebKit is introducing Swift into its code base,making use of a new opt-in strict memory safety featureto make sure interaction with C APIs happens securely.We've also made improvements to C++ interoperability,with code written using more advanced C++ language featuresnow callable from Swift.And beyond C, Swift's cross-language support has expandedwith packages for interfacing with Java and JavaScript code.And you can now run Swift in the browser.Working with the open source community,we’ve brought official toolchain support for WebAssemblyto Swift 6.2.Next, let's talk about concurrency.For your app to be secure and stable,it's really important that your code is free from data races.The Swift 6 language mode is designedto make your concurrent code safer.In many cases, though, like your app's user interfaceor command line tools, you're actuallywriting code that’s only ever meant to be single threaded.Swift 6.2 makes it easier to write that single-threaded code.You can configure modules or individual filesas running on the main actor by defaultwithout any additional annotations.It's also easier to make async calls from the MainActor,with better language defaults thatgenerate fewer compiler warnings for codethat is not intended to be run in parallel.And when performing CPU-intensive tasks, you can offload tasks to the backgroundto keep apps responsive with the new concurrent attribute.At Apple, we're using Swift everywhere.We run it embedded on the silicon that secures memory management on the GPU.And in large-scale server workloads like the Apple Password service,which handles billions of requests a day from devices all over the world,and where a recent rewrite in Swiftresulted in a huge reduction in server footprint.Many of you also develop cloud services for your apps.Reusing your app's Swift code in your server implementationis an exciting opportunity for you as an app developer.Like the team at Cultured Code,who use Swift to power the server-based synchronizationof their award-winning task manager, Things.To streamline the development of these server-side components,we've created Containerization, a new framework and toolfor containers.Its command line tool lets you create, download,and run Linux container images right on your Mac.And it's built on an open source frameworkthat is optimized for Apple siliconand provides secure isolation between container images.Containerization is written in Swift,and it's available as open source today.You can download the binaries or check out the repo on GitHub.On the new Swift.org website,you'll find guides for getting up and running writing cloud servicesin Swift, along with a new Toolchain installerthat makes using Swift on Linux easier than ever.We're excited about the future of Swift wherever you use it.Now, back to Matthew.When you use Apple's native frameworks,you can write better apps with less code.Some other frameworks promise the abilityto write code once for Android and iOS.And that may sound good, but by the timeyou've written custom code to adapteach platform's conventions, connected to hardwarewith platform-specific APIs, implemented accessibility,and then filled in functionality gapsby adding additional logic and relying on a host of plugins,you've likely written a lot more code than you'd planned on.And you are still left with an app that could be slower,look out of place, and can't directlytake advantage of features like Live Activities and widgets.Apple's native frameworks are uncompromisingly focusedon helping you build the best apps.So let's dig into some of the new experiencesand capabilities in our SDKs,starting with improvements coming to SwiftUI.Here's Sommer.Whether you’re creating a new appor expanding an existing one,SwiftUI is the best way to build it.And today brings a set of exciting updates inspired directly by your questions,your ideas, and your feedback, including new web APIs,new rich text editing capabilities, and support for 3D charts,as well as big improvements to performance.Let's start with our powerful new web APIs.Today, your apps can embed web content with WebKit's WKWebView API.In SwiftUI this year, a new version of OpenURLallows you to show a simple in-app browser.For more power, WebKit adds a new declarative WebView componentthat's designed for SwiftUI,as well as a new web page API for programmatically controlling web content.These three new APIs are built with modern Swift technologieslike observation and strict concurrency,meaning it's never been simplerto bring web content to your apps.Next, we have one of your most-requested features.The SwiftUI text editor has gotten rich.To enable rich text editing,simply change the binding of your text editor's textfrom a string to an attributed string.Now you have a rich text editor with styling you can fully customize.And by tracking attributed text selection,you can develop your own editing experiences,complete with controls and inspectors for formatting selected text.Finally, SwiftCharts now supports 3D thanks to RealityKit.This update includes support for directly interacting with the camerato rotate and zoom in on your charts from every angle.And on visionOS, SwiftCharts works in spatial environments too.Now, let's talk about performance.Nothing makes an app feel fast like smooth scrolling.iOS, SwiftUI, and UIKit use a technique calledidle prefetch, taking advantage of the idle timeafter rendering the current frame in order to geta head start on rendering the next frame.That extra time helps reduce the chance of dropping a frame while scrolling.This year, SwiftUI brings idle prefetch to the Mac for the first timefor a huge boost in performancewith optimizations across all other platforms as well.Of course, the most common scrollable views are lists and tables,and SwiftUI is getting even faster at displaying lists and tableswith very large amounts of data.On macOS, a list of 100,000 items will now load over six times faster.Incremental changes, like inserting new items, are up to 16 times faster,and larger lists will see even bigger gains.Altogether, these improvements represent a big step forwardin SwiftUI scrolling performance.And this year, we're bringing you a powerful new performance instrumentto help you optimize your own code,allowing you to drill down to the exact moments thatimpact your app's performance and analyze precisely where and whyyour own views are updating.Powerful web APIs, rich text editing,beautiful 3D charts, and faster performancejoin a whole host of other improvements to SwiftUI this year,including a more flexible SwiftDatawith model subclassing, entity inheritance,and support for additional common data typeslike attributed string.There's so much to get excited about: push notifications for widgets,better control over drag and drop, and scene interoperability.And if you're building a spatial app with SwiftUI,there are even more cool features in this year's release.Here's En to tell you more.visionOS 26 will enable groundbreaking new spatial experiencesin your apps and games.This year brings an extensive update with new volumetric APIs,advanced sharing capabilities,exciting immersive media tools, and powerful enterprise features.Now, enhancements across new and existing SwiftUI APIs make it even easier to buildcompelling volumetric experiences.You can create even richer 3D layouts in the same familiar way as 2D UI.Layouts are now aware of visual effects like rotation.Existing APIs allow you to easily align your views within volumes.You can align overlapping content in the same 3D space with spatial container,or anchor content to specific locations with 3D anchor preferences,all in SwiftUI.Dynamic bounds restrictions allows you to drawoutside your app's bounds in both volumesand windows with a simple view modifier.And environment occlusion makes it so virtual objectscan be occluded by static real world objects.You can bring this behavior to your appsby adding an environment blending component to any entity.Now, a new suite of APIs deep in the integrationbetween SwiftUI, RealityKit, and ARKit.It is easier to position and translate contentacross these three fundamental frameworks,regardless of the coordinate space you're working in.RealityKit's entity and its animations are observable,allowing them to be used directly in SwiftUI views.You can directly apply gestures to entitiesor present and animate 3D content in your app with Model3D.Because many of the best spatial experiences are shared,visionOS 26 introduces a new capability.With nearby window sharing, you can build shared spatial experiences for userslocated in the same room,like Rock Paper Reality's Defender-Ella,as well as bring in remote participantsusing FaceTime and spatial personas.New SharePlay APIs make adoption even easier,and your existing SharePlay apps will automatically work.ARKit also adds support for shared world anchors,so you can precisely anchor shared content to the room.In visionOS 26, apps and QuickLook contentpersist or reappear in the same place, even after restart.This behavior is also coming to widgets.The familiar widgetKit framework, along with new APIsto specify its texture or react to users' proximity,are now available, allowing you to build dynamic widgetsthat persist throughout user spaces.Around the world, users love experiencing contenton Vision Pro, and now they have an incredible new wayto experience photos.RealityKit's image presentation componentcan be used in your app to transform 2D imagesinto 3D spatial scenes,leveraging on-device, generative AI algorithmsto create a 3D representation of your image,optimized for real-time renderingfrom multiple points of view.If you are building media applications,you can play and distribute even more typesof immersive content with built-in supportfor 180 degree, 360 degree, and wide-field-of-view videothrough Apple Projected Media Profile, or APMP.You can play and stream these new immersive media formatsinside your app using familiar AVKit, RealityKit, WebKit, and QuickLook APIs.And if you produce Apple immersive video contentusing the new Blackmagic Camera and DaVinci Resolve app,you can play it back in your apps or directly from web pages in Safariusing the HTML video element.In enterprise environments,visionOS 26 makes it even easier for developersto incorporate Vision Pro into their organizations.With enterprise entitlements,you can disable content captures of your app's view,enable apps to automatically follow the user's positionas they navigate a space, access the left and rightcamera feed simultaneously,or grab a specified region of the camera feed for stabilizationand enhancement.These are just a few of the incredible features coming to visionOS.Now I'll hand over to Eric to talk about gaming.Apple silicon enables exceptional performance and visualsthat unlock the most advanced games.This year, we're making it even easier to bring your gameto Apple's unified gaming platform.We've focused on three key areas:advanced graphics technologies, improved game developer tools,and system features to deliver a great gaming experience for your players.The key graphics technology powering these experiences is Metal.Ten years ago, we brought Metal to the Mac,and since then we've been adding capabilitiesto power the most advanced graphics workloads.Now we're introducing Metal 4 with tons of new features tosupport the most advanced graphics and ML technologieslike neural rendering which combines traditional graphicswith machine learning inference.With Metal 4 you can now run inference networksdirectly in your shaders to compute lighting,materials, and geometry,enabling highly realistic visual effects for your games.And you can use MetalFX upscaling, frame interpolation,and denoising APIs to take your game’s graphics performance to the next level.MetalFX frame interpolation generates an intermediate framefor every two input framesto achieve higher and more stable frame rates.Here we're showing the upcoming Mac versionof Cyberpunk 2077 on the M4 MacBook Air.On the right, CD Projekt Red is using MetalFX frame interpolationto increase performance to a solid 60 frames per second.They also use MetalFX denoising to enable ray tracingon the game's ultra settings on the M4 Max MacBook Pro.Metal 4 is designed exclusively for Apple siliconand it sets the stage for the next generation of games on Mac.This year, we further streamlined the game development experiencewith improved developer tools.The updated Game Porting Toolkit provides everything you need to get startedbringing your Windows game to Apple's platforms.Like tools to evaluate and profile your game,convert your shaders and assets,and human interface guidelines and code samplesto build native games that feel at home on Apple devices.For example, CD Projekt Red used Game Porting Toolkitto dramatically speed up the process of bringing Cyberpunk 2077 to Mac.And the latest version of Game Porting Toolkitprovides new tools to make it even easier tooptimize your game, with support for Windows upscaling technologies.For example, a developer like Remedycould use it early in the porting process to evaluatehow much MetalFX could improve the performance of their game, Control,when running on Apple silicon.Game Porting Toolkit provides on-screen insights and guidancefor optimizing your graphics code for the best possible performance.And you can now customize the Metal Performance HUDas you profile and debug your code.And finally, there are new tools to build, run, and debug games remotelyfrom a Windows environment.This is great for targeting Mac from an existing game development toolchain.And once you've got your game up and running,you can adopt powerful system frameworks to deliver immersive graphics and audio,incredibly responsive input,and a seamless gaming experience for your players.This year, the frameworks that power input across iPhone,iPad, Mac, and Vision Pro are getting major upgrades,with easier pairing for PlayStation DualSense controllersacross all of your devices.A new touch controller API provides an easy wayto add on-screen controls for iPhone and iPad,and you can enable powerful new ways to play gameson your Vision Pro,with support for PlayStation VR2 Sense controllersand up to three times faster hand tracking.To enable seamless play across devices,you can bring cloud save to your gameswith the new GameSave framework.For playing on the go,macOS Tahoe has optimized Low Power Mode for gaming.As a developer, you can further extend battery lifeby enabling more efficient game settingswhen the system is in Low Power Mode.With the new Game Center Challenges API,you can turn single player game activitiesinto social experiences with friends.These challenges will appear in the new Games appand players can also access them in the Game Overlay,interact with friends and change settingsall without leaving the game.With all of these new features,it's never been a better timeto bring your next generation gamesto Apple's unified gaming platform.Now back to Matthew.Metal 4 is a great example of the tight integrationof our software with Apple silicon,creating a whole new class of experiences.In fact, since we began the transition to Apple siliconover five years ago,we've been able to add incredible featureslike Apple Intelligence, Game Mode,Presenter Overlay, and more.We completed the transition to Apple siliconacross our entire product lineup two years ago.So your apps can now depend on and build upon these features too.Apple silicon enables us all to achieve thingsthat were previously unimaginable.And it's time to put all of our focus and innovation there.And so, macOS Tahoe will be the final release for Intel Macs.So if you've not done so already, now is a great time to help your users migrateto the Apple silicon versions of your apps.There's a lot to love in this year's release.The new design with Liquid Glass brings new depth, fluidity,and dynamism to your apps.Apple Intelligence lets you take advantage of on-device modelswith guided generation.Xcode transforms the way you create apps using any coding model.And updates to Swift and SwiftUIfurther expand your app's performance and capabilities,making it easy to bring your apps to the full range of Apple platforms.So, is that all we have? Not even close.There are so many other new features and APIs to explore.And we have over 100 sessions that go deeper into what you've heard about todayand what you haven't yet.Here's a few examples.Let's do this as a lightning round.You can now create menus and commandsthat are included in the new iPad menu bar.With an updated Background Tasks API on iOS and iPadOS,you can start long-running tasks that will complete in the background,like a video export.CarPlay now supports Live Activitiesso your app can show timely, relevant updates,even when users are on the road.In macOS, Terminal has a fresh look with 24-bit color,new themes inspired by Liquid Glass, and support for Powerline fonts.The HTML model element embeds 3D models into your webpages.And on visionOS, it can be viewed stereoscopically in lineand dragged out into the real world.When you adopt Look to Scroll on visionOS,users can browse hands-freejust by looking at the edges of content.The declared age range API helps you adjustyour app's experience to be age appropriatewhile preserving user privacy.The new PermissionKit framework gives your apps new toolsto help children communicate safelywith parental supervision.You can now highlight your app's accessibility featuresin a dedicated section of your App Store product page.And for assistive access,you can now customize the experience in your appwith more focused features and a simplified user interface.There's just so much to explore.The sessions are available starting today,so you can just go dive in.And we look forward to connecting with you in the Labsand the Apple Developer Forums.What you do as developers is amazing.You turn ideas into incredible experiences for your usersand bring our platforms to life.Apps have become essential to how we all connectand communicate, deliver our best work, get creative, or explore new things.So whether you are just starting out or have been building apps for years,thank you for being part of such a vibrant developer community.We can't wait to see what you create next.

Welcome to the 2025 Platform State of the Union.This is a huge year for our platforms.And today, we'll dive into some of the exciting new features,APIs, and technologies for your apps and games.

All of our work this year builds on top of Apple's powerful platforms.Platforms that bring your imaginative, creative, and ambitious ideas to life.And what makes that possible is the unique fusionof Apple's hardware, software, and services with your apps.

At the core is Apple silicon,which provides unprecedented power and efficiency across all our platforms.

With unified memory that maximizes performance,specialized accelerators for video and machine learning,and a secure enclave that guarantees the system's integrity.

And all of this provides a strong foundationfor our software technologies to build upon,like Metal, with low-level APIsthat unlock the hardware's full potential.

Apple Intelligence, with powerful generative modelsand privacy built in from the ground up.

Swift, delivering performance and safetyacross the system, SDK, and apps.And SwiftUI, enabling rich interactivity,animations, and adaptive design.

And because our platforms are deeply infusedwith technologies like privacy, accessibility,and internationalization,your apps can benefit from them too.So the broadest range of users can access your appsin the ways that work best for them.

The potential for this builds even furtherwith higher level APIs that help your apps expandacross devices.

Using iCloud and CloudKit,your app's data automatically syncs from device to device,all while leveraging advanced privacy and security guarantees.

With widgets, your app's notification and contentare intelligently surfaced at the right placeand the right time.This also works for Live Activities,so your users have immediate accessto your app's actions and data.

And you can add support for new platforms like visionOSwith the same frameworks and concepts.

When your apps take advantage of Apple platforms,the experience becomes more than the sum of its parts.

All of this is an amazing opportunity,and it's getting even bigger and better this yearas we dive into how you can bring vitality to your appswith the new design and Liquid Glass materials,deliver new possibilities for your userswith Apple Intelligence and machine learning,transform the way you write appswith generative intelligence in Xcode and updates to Swift,and further elevate your app's performance and capabilitieswith enhancements to frameworks like SwiftUI and Metal.Let's start with our UI design built with Liquid Glass.Here's Billy to tell you more.

This year introduces our broadest design update everand begins the next era of our software design.Transformations of this magnitude are rare.When they do occur, they mark inflection points,moments that redefine what's possible.And that's certainly been true for us.The new design beautifully scalesacross Apple's apps and platforms,all while maintaining the iconic experienceusers rely on every day.

Importantly, it gives you the perfect opportunity to refreshand modernize elements of your app's design,making them more delightful than ever before.So today we're gonna walk you through our design thinkingand high-level design concepts that you should consider,updates to our developer API for building your apps,and updates to how you express your app’s look through beautiful new icons.

Software is the heart and soul of our products.We didn't approach such an ambitious design lightly.We had several goals behind the new design.First, we want to elevate the content users care about most.UI is in service of the experience.It should be easily accessible when neededand elegantly recede to the background when not,making users’ experiences of reading, creating, and watching contentas immersive and impactful as possible.Secondly, we want to establish greater consistency,harmony, and usability by creating a universal design language,one that offers a seamless experience as your app's users move across platformswhile maintaining the distinct qualities that make each unique.And finally, with the incredibletechnological advances of our hardware,we can craft interaction designin ways that simply weren't possible before today.

The new design is built around dynamism, expressiveness, and a focuson user experiences that are joyful and delightful.So let's start with the foundational elementof the new design, Liquid Glass.

Liquid Glass enables an entirely new levelof depth and vitality by combining the optical qualitiesof glass with responsive fluidity.It's designed to refract content from below it,reflect light from around it,and have responsive lensing along its edges.As you interact with the glass, it feels fluid and alive,as if the physical glass of your device is the UI itself.This is much more than visual craft.Interactivity is at the core of the new design.

Specular highlights, refraction,and the translucent properties of Liquid Glass visually lift controls,all when maintaining a close relationshipto the content beneath.Now that we’ve covered the high-level design thinking,let's focus on three guiding principlesfor implementing the new design in your apps.

First, establishing hierarchy.Second, creating harmony.And third, maintaining consistency.

Let's start with hierarchy.Liquid Glass controls and navigation actas a distinct functional layer that floats above your app.And this allows a new dimension of depth,bringing greater focus to your content.To enable this, elements once consideredfor rectangular displays have been redesignedto respect the rounded corners of the hardware,freeing up valuable space for your app's contentAnd by thoughtfully grouping controls in this new floating layer,it removes visual density,allowing your content to extend to the edges of the display or window.

The color of Liquid Glass is informed by your app's content,intelligently adapting between light and dark app environments.

Of course, you can apply your own custom colors to Liquid Glass as well.

Keep this in mind as you indicate key actions,selection state, or status within your app.

And Liquid Glass is dynamic by design.Controls can fluidly morph to recede in prominencewhen a user wants to focus on your app content.The moment a user needs them again, they'll expand.This works across different types of apps,whether they are designed as a single viewor with multiple tabs.The new design ensures a content-rich experience.

By elevating controls and fluidly morphing between states,the new design elegantly reinforces hierarchythroughout the user experience.

It feels both familiar and entirely new all at once.And this brings me to our second design principle.These new dynamic controls create harmonybetween hardware, content, and controls.The shape of our modern devices inform the curvature,size, and shape of our UI elements,delivering concentricity and visual harmony.Going further, the new rounded formsare influenced by the geometry of your fingers,adding to more natural touch interactions across apps.

Concentricity is key to the new design's abilityto scale from smaller to larger screens,where sidebars and toolbars nest perfectly within windows.Along refreshed shapes, sizes, and color,our typography is updated as well.In an effort to make content more approachable,the new design includes larger, bolder, left-aligned typography.When applying the new design language to your app,you'll find nearly every component and control has been updated,with increased heights and softer shapes.This harmonizes the experience across Apple platforms,ensuring your app design feels considered.And it also helps with our third principle,maintaining consistency.The new design is universal across platforms,so now it's easier than everfor you to establish consistency for your apps.On macOS, your app becomes more visually alignedwith iOS and iPadOS,while retaining the density Mac users love.

And iPadOS now shares many of the same layout considerations as macOS,including consistent placement of common elements,as well as dynamically scalable windows and floating controls.And on watchOS, Liquid Glass controls allow content to shine through.

As a developer, the easiest way to design for consistencythroughout your user experienceis by adopting the new inset Liquid Glass controls.

This ensures your most essential UI elementsare available across screen sizes,window sizes, and platforms.So that's a quick overview of the new design.We couldn't be more excited to see it come to life in your apps,making them feel more seamless and delightful,all while giving your users deeper connection to their content,harmony throughout their experience,and consistency across platforms.

Now, over to Taylor to share the APIsthat enable you to implement the new design in your app.

Each of Apple's native UI frameworks, SwiftUI,UIKit and AppKit provide your app everything it needsto adopt the new design.You'll start by just recompiling your app on the new releasesand seeing how it looks with no code changes.Next is refining that result using new APIs to tailor the design to your app.And finally, updating your custom views with the new design principlesand Liquid Glass effects.Let's start by taking a look at what you can expect to seewhen you recompile your app for the new releases.The framework views your app is already usingwill automatically update with the new design.Here are some of the most common ones.

Multi-tab apps using TabView or equivalent APIwill automatically get a new design with Liquid Glass tab bars.Or if your app uses NavigationSplitView,it will now have a Liquid Glass sidebar on both MacOS and iPadOS.

Your iPad app will automatically now have the ability to resize columns too.

And inspector columns have been updatedwith a unique edge-to-edge application of Liquid Glassto reflect the relationship with the content they edit.

The new design for toolbars and navigation bars build upon the existing patternsfor how your app uses them.

Your app’s toolbar items are now placed within glassand sit on top of a new scroll-edge effect,which provides separation between the glass and main app content.Navigation stacks have been updated to enablefluid morphing of the toolbar as users navigateand scroll through your app's content.Menus or popovers in your app's toolbarwill automatically morph directly into those presentations.And a new API gives you additional controlfor other uses like sheet presentations.

Those are just a few quick examples.Most of the views your app is already usingwill automatically get a fresh new look and new metricsto enhance utility and legibility.

And these updates apply across all of the platformsyour app runs on.

Let's see the new design in action.I'm gonna try this out with a sample projectwe worked on last year, Destination Video.Now, I've just downloaded the existing projectand I've opened it in Xcode 26,but I've made no other changes.The preview shows me how the app now lookswith the new Liquid Glass tab bar.I'm gonna preview this on deviceto browse through more of the app.

Look how the Liquid Glass plays beautifullyagainst the content underneath as I scroll around.The tabs have a new control interaction effectas I switch between them.And when I drill into one of the videos, the back button is now within glass.Finally, the video player has a new designwith Liquid Glass controls.

Destination Video is a great exampleof making the most of framework-provided views.I didn't have to make any code changes to adopt the new design,and that'll be the case for many of your apps too.

This is also the perfect time to considerwhere you could simplify custom componentsand take more advantage of framework views.

With Liquid Glass enabled in your app,now we move on to refining that initial resultand adopting new APIs to tailor the design to your app.

Now it's unlikely your app will use all of these new APIs,so you can pick and choose the ones that best fitthe design and intent of your app.

Toolbars have several new APIs thatallow you to section and style items to reflect their role.Some views automatically create separationin the toolbar to reinforce the grouping of their content,and the new toolbar spacer API enables you to create additional groupings.Content in glass is monochrome by default,but you can apply color with purpose using tint modifiersand the prominent style for key actions.

TabView has a new API for adding a custom bottom accessorythat sits alongside the tab bar,which is perfect for showing playback controlsor global status in your app.

And this integrates with a new APIthat causes the tab bar to collapse when scrolling,offering even more space for your app's content.

The design of search has been updatedto be more consistent within and across platforms.

On iPhone, the search field floatsat the bottom of the screen,right where your thumb can reach it.We've also brought the toolbar search patternfrom macOS to iPadOS,with the searchable API providing a consistent resultbetween both platforms.Let's take a look at an example.We've been working on a sample app called Landmarks.I have the project open right here in Xcode.

I've started with the detail page.Here's the code and a preview of Landmarks running on macOS.It shows the new design of the sidebar and toolbar.Now I want this prominent image to make the mostof the Liquid Glass sidebar instead of ending at the edge.This is the perfect use case for background extension effect.This new modifier extends a copy of the imageout of the safe area so that the real image isn't covered up.It's always so cool to see how much betterthat immediately looks in the preview.

Next, I'll add some fixed spacers between itemsin the toolbar to create sections of the related elements.

And now let's switch over to the iPad previewwhere you can see that the same two improvementshave come through here as well.Now, in addition to the high-level framework views,there are APIs that allow you to createcustom experiences with Liquid Glass material,complete with features like tinting and interactivity.

Let's jump straight into adopting these in a custom controlI've been building in the Landmarks app.

Here I am back in the Landmarks project,this time editing the badges view, which displaysbadges for achievements I've received on the right side of the screen.It floats above the content already,which makes it a great candidate to adopt the Liquid Glass material.I’ll replace the custom background of each badge with the new glassEffect modifier,and I’ll replace the custom button style with the new glass button style.I’ll also add a glassEffect container,so all these effects are grouped as a set that can morph together.

And there it is, the preview updates to show their new appearance,which is already looking great.But as you've seen, Liquid Glass almost feels like a physical material.The best way to experience it is with the device and input you're designing for.

On touch, the button springs up and glowsto highlight my interaction with a subtle stretch effect.And on release, the Liquid Glass morphs to reveal the badges.

Of course, every app will have its own paththrough its adoption of the new design, depending on how it was builtand its design and complexity.But using Apple's native frameworks puts your app in a great positionto make this adoption easy.Now, over to Bobby, who's going to tell you moreabout updating your app icons.

Liquid Glass will make your app icons shine like never before.The new design creates opportunities for personalizationand, for the first time, gives every app a cohesive identityacross Apple platforms.Your app icon is a big deal.It represents your brand, tells your story, and builds engagement.Liquid Glass brings it to life with layering, depth, and vitality.Users can now choose from a variety of expressive appearances,each offering a light and dark variant.

Most familiar is the classic full color appearance.

Tint mode has an even more colorful light variantand a more translucent dark variant.New this year, we're introducing a clear mode,that beautifully shows off the Liquid Glass material.On Mac, icons now support clear and tint modesand adopt the rounded rectangular shape that matches iPhone.And because you'll want to pay attentionto how you're crafting the layers, highlights,and transparency of your icon,we're introducing Icon Composer,a new tool for building stunning icons for Apple platforms.As we've redesigned our own icons,we found that crafting them with two to four layers is the sweet spot.And Icon Composer is designed to help you do just that.Let's take a look.You can start by importing vector content.You can organize and annotate layers for multiple rendering modes,add blurring, adjust translucency, test specular highlighting,and preview icons in various tinting modesto ensure that your icon looks just right.When you're ready to publish,Icon Composer generates a single source artifactthat you can import into Xcode.It can also export high resolution versions of the iconin fully rendered form for marketing and communication needs.Your icons will look radiant with Liquid Glass.And Icon Composer will help make your app's visual identitymore consistent than ever.Icon Composer is included as part of Xcode,and you can get the latest downloadat the Apple Developer website.Back to you, Matthew.

So that's the iconic new design for appsand system experiences across Apple platforms.With Liquid Glass, your apps blend seamlessly into the displaywith new visual depth and a focus on your content.

All of our UI frameworks fully support Liquid Glass.So whether you're using SwiftUI, UIKit, or AppKit,your app can take advantage of its beauty and expressiveness.

When run on iOS 26 and macOS Tahoe,apps built with Xcode 16 will have an unchanged user interface,keeping their current design.When you rebuild your app with Xcode 26,standard controls will automaticallybe rendered with the new design and materials.So you can then identify other opportunitieswhere Liquid Glass can make your app shine,particularly for your custom controls and views.As you evaluate your app's UIand the time you need to adopt the new design,we're providing an option to continueto use your app's current design with Xcode 26.

We intend this option to be removedin the next major release.

We are so excited to see the transformative effectsof Liquid Glass in your apps.

Now let's talk about intelligence.At Apple, we use artificial intelligenceand machine learning to add innovative featuresto all our platforms.

And there are many opportunities for youto bring intelligence into your apps too.Josh will tell you how.

Apple Intelligence is the personal intelligence systembuilt into the core of our operating systemsthat helps your users get things donethrough many features like Writing Tools, GenMoji,and Image Playground in apps across the system,including many of yours.For most of you using standard UI frameworksto render text fields,your apps support Writing Tools automatically.And those of you with custom text enginescan adopt APIs to provide your users accessto these capabilities in your apps.Similarly, GenMoji is automatically supportedas stickers in your app when you use system text controls.And there are APIs for you to render themwith custom text engines.And Image Playground APIs can supporton-device image generation right in your apps.These are just the tip of the icebergwhen it comes to the many ways your appscan take advantage of intelligence on Apple devices.This year, any app can tap into intelligence that's powerful,fast, built with privacy, and available even when the user is offlinethrough direct access to the on-device foundation modelthat powers many of our featureswith the Foundation Models framework.This API allows you to tap into our highlyoptimized on-device foundation model which is specialized for everyday tasks.You can use the framework to power intelligent features in your appusing model capabilitiessuch as text extraction, summarization, and more.Prompting the model starts with just three lines of code:import the framework, create a session, and send your prompt to the model.The model is optimized with state-of-the-art quantization techniquesand speculative decodingto provide performance, efficiency, and quality.And with Swift concurrency, the API enables you to chooseto display the answer as one response or incrementally using streaming output.The framework also includes guardrails for our core features,and you can add your own safety rules for your specific use cases.It's great for things like content generation, in-app user guides,customized learning, and much more.We fine-tune the model for broad use cases,and when you invoke the model,you'll have the choice to add additional adapters like content taggingto improve performance even further for specific tasks.Often when you prompt a model, you'll need the LLM togenerate structured responses to be used directly by your app.We've made this really easywith guided generation.With it, you can make your own data structures generable.Whenever you send a request to the model,your struct gets filled in with matching information,enabling you to prompt the model to produce full instances of your data typeand allowing you to focus on your app's unique featuresinstead of the details of directing and parsing model output.By supporting structured data output in addition to natural language,you can easily integrate intelligent featuresin whatever way best fits your app's user experience.This is a first-class experience written in Swift for Swift.The Foundation Models API also includes support for tool calling.It allows the model to identify a task that may require additional informationor actions and call the appropriate functionwhile it's processing the user's request.To utilize this capability, you define in Swift the tools the model can use,such as fetching up-to-date content from Wikipedia,referencing information from your app, or taking actions likecreating a journal entry in your app.Then, the model can autonomously make decisionsabout what tool to use and when, so you don't have to decide it programmatically.Here's Richard to show you a demo of all of this in action.

Let's use the Foundation Models framework to addgenerative content to a travel app I'm building.But first, let me show you how to prompt the model in Xcode.

I'll start by importing Foundation Models.

Then I'm going to use the new playground macro in Xcode to preview my non-UI code.To interact with the model,I first create a Language Model Session.As I type, it immediately sees the canvas on the rightthat we got a session.Then I just call session.respond to send my first prompt.

I'll ask for a good name for a trip to Japan.And right away, we'll see the model's responseappear in the canvas.

For large language models,prompt engineering is all about trying outdifferent prompts and finding the best ones.I want to see how my prompt works forvarious travel destinations.

So I can add a for loop to iterate overall of the destinations featured in my Landmarks app.Now in the canvas, I can see the entire history of the model's responsesto different prompts.

Quickly iterating with Playgrounds is so great for prompt engineering.

Now that we've seen it work,let's add a feature to my app to generate travel plans.

I built my travel plan UI on top of these Swift data structures.

With guided generation, I can annotate them as @Generableso that the model can create them automatically based on my prompt.And I can also provide additional guides on the propertiesso that the model will only produce the values I expect.Then in my app logic, I go ahead and create a sessionand pass my custom instructions to the model.I ask it to generate an itineraryto help the user visit a landmark.

I can also include an example itinerarythat I created before to give the model an ideawhat kind of a response I'm looking for.In my session, I can leveragethe model's tool calling capability.

This is a great way to let the model fetchexternal information autonomously.

Here’s my custom tool that uses Mapkitto find points of interest whenever the model needs them.

Now, I'm going to call session.streamResponseand ask the model to generate an itinerary struct.Pass in my prompt.Then streamResponse returns an async sequencethat lets me update the itinerary in my UI as the model is generating it.And now, let's try it out.On my phone, I start by selecting the Grand Canyon,tap Generate Itinerary.

Then I see the model generates a descriptionand activities for each day.

And the model also decided to fetch points of interest,like hotels, using our custom tool.

With prompting, guided generation, and tool calling,our on-device model created this Grand Canyon adventurefor me right in the palm of my hand.Pretty amazing.Back to Josh.

Since the model is on-device, your users’ data stays privateand doesn't need to go to a server-side model or to anyone else.The on-device foundation model is readily available,so features you build will work offline, and you don't have to worryabout account setup or API keys.And all of this at no cost to you or your users for any requests.The Foundation Models framework joins the suiteof machine learning APIs and toolsthat you can use to tap into on-device intelligence for features within your app,including updates coming to the Speech API.

Beyond the models we’ve provided on-device,you can also use Core ML to run models you bring onto device.Core ML optimizes performance by leveraging the CPU, GPU, and neural engine.With additional frameworks, you can further optimize your ML workloadsfor real-time signal processing on the CPU,or you can enable low-level access to GPU compute,all powered by Apple silicon.Based on your needs and level of expertise with models,you can pick the machine learning and AI frameworksand tools that best support you across our platforms.Then, for those of you experimenting with, training,and fine-tuning large language and other models,you can use MLX, an open-source librarythat takes full advantage of Apple silicon's unified memory.Another way you can enhance your app's features and capabilitiesis by giving them more visibilityacross our platforms through the App Intents framework.It can help your users easily find and use core functions of your app,even when they're not in your app.With this framework, you can define App Intents,the actions your app can perform,as well as app entities, the content your app can handle and produce.These come together to describe the important functions of your app.App Intents can be used with context-aware action button experiences,interactivity in widgets,automation via shortcuts, quick controls in Control Center,and customized results in Spotlight.And with the all-new Spotlight experience in macOS Tahoe,users can access all the App Intentsthat you've created right from Spotlight.If your App Intent has parameters, users can easily fill them in,creating more natural and seamless ways to find and get into your appfrom anywhere on the system.We're also introducing a new App Intents schema for Visual Intelligence.You can apply your app-specific Visual Search logicto content in Visual Intelligence.This brings your resultsright into the search experience so users can deep link into your appright from the results.Altogether, App Intents are the key to delivering rich experiences to your usersall across the system.Now back to Matthew.

Intelligence is also transforming how we write code.New developer tools and powerful coding modelsare already making us more productive and creative.

And with the power and ease of Swift and SwiftUI,there is so much potential for everyone to explore new ideas.So let's take a look at some of the new featuresin our tools and languagesdesigned to empower developers like never before.

Ken and Holly will start with what's new in Xcode.

Millions of developers around the world use Xcodeto build the most innovative and creative apps for Apple platforms.Xcode 26 is packed with incredible features and experiencesthat can help make your ideas a reality.Let's start by talking about intelligence.Last year, we introduced Predictive Code Completion,which uses a local model running on Apple siliconto provide intelligent suggestions based on your project and coding style.

Millions of lines of code are createdusing Predictive Code Completion every week.

We continue to make the model better,improving accuracy and optimizing context gatheringto help the model use more of your code, all running locally.

Beyond code completion, generative intelligence really shineswhen you interact with code using natural language.

We tested Swift Assist with developers, and the main feedback we heardwas about models.Many of you are already using models from multiple providers.And since Xcode plays such an important role in your development workflow,you want to have those models right at your fingertips as you craft code.This space is moving fast,with new capabilities like reasoning, multimodality, and more.So we expanded our vision, creating an even better experiencethat we think you'll love.First, we're excited to bring ChatGPT to Xcode.We're working with OpenAIto seamlessly integrate their optimized coding models right in Xcode.And you can try this in the first beta of Xcode 26 today.Let's see it in action.Take it away, Holly.

I have an idea for a feature in the Landmarks app.Let's take a look at how easy it is to bring it to life.

I'll open the new coding assistant from the toolbar right at the top of Xcode.I've already configured Xcode, so I'm ready to go.First, I'm going to add a new view to the Landmarks app.

My idea is to show statistics about my landmark locations.

Xcode created a statistics view and modified my existing navigation list.I can click on each code snippet and see the changes.I can also open the overview.It shows me all of the modified files in a single view with colorful annotationshighlighting all of the code changes.

The best part?Xcode automatically updates the code for me.And with previews, I can visualize my app's UI almost instantly.Now that I've got the statistics view in place,I'll ask what landmark data is in the projectthat might make a more interesting dashboard.

When interacting with the model,Xcode automatically sends the context, like the file I'm in,what code I have selected, errors, and related files.And the model can ask for more information from my project as it works on a response.

Here it looked at various files in my projectto understand my code and summarize datastructures as feature ideas.And Xcode linked me to the reference files so I can understand the code too.

This looks like a good plan.I'll ask to implement these ideas.

I haven't really given any direction on how to present this data.Let's see what it comes up with.Okay, now that I've got the data, let's design the dashboard.

Here's a quick sketch of what I'm thinking.I'll drop it in with my request.

Sometimes the easiest way to express an idea is visually,with a drawing or mockup or annotated screenshot.

Wow, that's a pretty great start.It even used system colors and SF Symbols to bringmy sketch to life.

What was just an idea a few minutes ago is now a feature I can try in my app.

And to help you stay in the flow and be more productivein the tasks you're doing every day, like writing tests and documentation,fixing issues, or simply understanding code,we're putting those capabilities right where you need them.

Let me start by showing you a new feature called Coding Tools.It's just like Writing Tools, but for code.

I can bring it up anywhere in my code and get suggested actionslike generating a preview or playground or fixing an issue.And if I'm looking for something more specific, I can just ask for it.

A great way to understand non-UI code is to try it out.Like you saw earlier, there's a new playground macro for exploring code.It's just like a preview, but it works for any code.I’ll choose Generate Playground.

The code appears right in my file.It gives me a real example calling into the code.I can preview anything.

Now that I know how this code works, let's add documentation.I'll make a selection and choose Document.

It created DocC comments and I can also preview the rendered documentation.

Everyone always writes perfect bug-free code, right?But if something does slip through the cracks,don't worry, I can just click on the issueand choose Generate Fix and get back to building.

And my favorite feature, the conversation history.When I'm working with the model,I love having the freedom to safely explore ideas.I'm often many prompts in before I realize I want to go back in timeand go a different way.With the history slider, I can scrub through timeand see every change, making it easyto roll back and keep on vibing.With quick actions, intelligent error fixing,conversation history, and more, Xcode is now supercharged.In just a few clicks, you can start using ChatGPT and Xcodewithout even creating an account.You'll get a limited number of requests each and every day.ChatGPT subscribers can connect their accounts for even more requests.And you're in control of the data you share with OpenAI.If you're using models from different providers,it's easy to bring those to Xcode too.For example, you can add your anthropic API key.And use their latest models like Claude 4 Opusand Sonnet directly in Xcode.And you can run models locally on your Mac or private network,powered by the tool of your choice.This gives you flexibility and controlto use the model that works best for you.

And when a new model is released,you can just use it with Xcode.

With built-in intelligence powered by the best coding models,Xcode 26 will transform the way you create apps.

There are many more exciting features to discover,like the redesigned and simplified tab experience.So just like in Safari, you can quickly open a new tabwith Command T and all navigation happensright in the same tab.And if you want to stay focused on a file in a tab,just pin it.

Xcode is also more accessible.If you have limited use of the keyboard,Xcode 26 improves support for Voice Control,letting you dictate Swift codeand navigate through the interface entirely by voice.And to make localizing your app easier,you can automatically generate usage description commentsin the string catalog,providing the right context for accurate translation.The first beta of Xcode 26 is available now,and you can start coding with ChatGPT and other models today.Next, to talk about all the exciting changes in Swift,here's Ben.We created Swift with a clear goalof building a language that meets the challengesof modern development without trading off performancefor safety.

One that's powerful, but also easy to use.And today, we're taking that furtherwith Swift 6.2.

This release adds some great features focused on performance.One of the most anticipated is inline arrays.These allow you to declare arrays with a fixed sizethat can be stored on the stack or directly inside other typeswithout using heap memory.

Knowing the size of an array at compile timeunlocks optimizations by the Swift compiler,enabling significant performance wins.

We're also introducing a new span type.

It provides a safe alternative to pointersfor fast direct access to contiguous memory.

This type is key to another new featurethat improves communication with unsafe languages like C.

When C pointers are annotated with length and lifetime information,they can be bridged into Swift as a span,providing a memory-safe interface that’s also easier to use.

This combination of safety and performancemakes Swift a great option where these attributes are critical.And that's why WebKit is introducing Swift into its code base,making use of a new opt-in strict memory safety featureto make sure interaction with C APIs happens securely.We've also made improvements to C++ interoperability,with code written using more advanced C++ language featuresnow callable from Swift.And beyond C, Swift's cross-language support has expandedwith packages for interfacing with Java and JavaScript code.And you can now run Swift in the browser.Working with the open source community,we’ve brought official toolchain support for WebAssemblyto Swift 6.2.

Next, let's talk about concurrency.

For your app to be secure and stable,it's really important that your code is free from data races.The Swift 6 language mode is designedto make your concurrent code safer.

In many cases, though, like your app's user interfaceor command line tools, you're actuallywriting code that’s only ever meant to be single threaded.

Swift 6.2 makes it easier to write that single-threaded code.You can configure modules or individual filesas running on the main actor by defaultwithout any additional annotations.

It's also easier to make async calls from the MainActor,with better language defaults thatgenerate fewer compiler warnings for codethat is not intended to be run in parallel.

And when performing CPU-intensive tasks, you can offload tasks to the backgroundto keep apps responsive with the new concurrent attribute.

At Apple, we're using Swift everywhere.

We run it embedded on the silicon that secures memory management on the GPU.And in large-scale server workloads like the Apple Password service,which handles billions of requests a day from devices all over the world,and where a recent rewrite in Swiftresulted in a huge reduction in server footprint.

Many of you also develop cloud services for your apps.

Reusing your app's Swift code in your server implementationis an exciting opportunity for you as an app developer.

Like the team at Cultured Code,who use Swift to power the server-based synchronizationof their award-winning task manager, Things.

To streamline the development of these server-side components,we've created Containerization, a new framework and toolfor containers.Its command line tool lets you create, download,and run Linux container images right on your Mac.

And it's built on an open source frameworkthat is optimized for Apple siliconand provides secure isolation between container images.

Containerization is written in Swift,and it's available as open source today.

You can download the binaries or check out the repo on GitHub.

On the new Swift.org website,you'll find guides for getting up and running writing cloud servicesin Swift, along with a new Toolchain installerthat makes using Swift on Linux easier than ever.

We're excited about the future of Swift wherever you use it.Now, back to Matthew.

When you use Apple's native frameworks,you can write better apps with less code.Some other frameworks promise the abilityto write code once for Android and iOS.

And that may sound good, but by the timeyou've written custom code to adapteach platform's conventions, connected to hardwarewith platform-specific APIs, implemented accessibility,and then filled in functionality gapsby adding additional logic and relying on a host of plugins,you've likely written a lot more code than you'd planned on.And you are still left with an app that could be slower,look out of place, and can't directlytake advantage of features like Live Activities and widgets.Apple's native frameworks are uncompromisingly focusedon helping you build the best apps.So let's dig into some of the new experiencesand capabilities in our SDKs,starting with improvements coming to SwiftUI.Here's Sommer.

Whether you’re creating a new appor expanding an existing one,SwiftUI is the best way to build it.And today brings a set of exciting updates inspired directly by your questions,your ideas, and your feedback, including new web APIs,new rich text editing capabilities, and support for 3D charts,as well as big improvements to performance.Let's start with our powerful new web APIs.Today, your apps can embed web content with WebKit's WKWebView API.

In SwiftUI this year, a new version of OpenURLallows you to show a simple in-app browser.For more power, WebKit adds a new declarative WebView componentthat's designed for SwiftUI,as well as a new web page API for programmatically controlling web content.

These three new APIs are built with modern Swift technologieslike observation and strict concurrency,meaning it's never been simplerto bring web content to your apps.

Next, we have one of your most-requested features.The SwiftUI text editor has gotten rich.To enable rich text editing,simply change the binding of your text editor's textfrom a string to an attributed string.Now you have a rich text editor with styling you can fully customize.And by tracking attributed text selection,you can develop your own editing experiences,complete with controls and inspectors for formatting selected text.

Finally, SwiftCharts now supports 3D thanks to RealityKit.

This update includes support for directly interacting with the camerato rotate and zoom in on your charts from every angle.And on visionOS, SwiftCharts works in spatial environments too.

Now, let's talk about performance.Nothing makes an app feel fast like smooth scrolling.iOS, SwiftUI, and UIKit use a technique calledidle prefetch, taking advantage of the idle timeafter rendering the current frame in order to geta head start on rendering the next frame.That extra time helps reduce the chance of dropping a frame while scrolling.

This year, SwiftUI brings idle prefetch to the Mac for the first timefor a huge boost in performancewith optimizations across all other platforms as well.Of course, the most common scrollable views are lists and tables,and SwiftUI is getting even faster at displaying lists and tableswith very large amounts of data.On macOS, a list of 100,000 items will now load over six times faster.Incremental changes, like inserting new items, are up to 16 times faster,and larger lists will see even bigger gains.

Altogether, these improvements represent a big step forwardin SwiftUI scrolling performance.And this year, we're bringing you a powerful new performance instrumentto help you optimize your own code,allowing you to drill down to the exact moments thatimpact your app's performance and analyze precisely where and whyyour own views are updating.

Powerful web APIs, rich text editing,beautiful 3D charts, and faster performancejoin a whole host of other improvements to SwiftUI this year,including a more flexible SwiftDatawith model subclassing, entity inheritance,and support for additional common data typeslike attributed string.There's so much to get excited about: push notifications for widgets,better control over drag and drop, and scene interoperability.And if you're building a spatial app with SwiftUI,there are even more cool features in this year's release.Here's En to tell you more.

visionOS 26 will enable groundbreaking new spatial experiencesin your apps and games.This year brings an extensive update with new volumetric APIs,advanced sharing capabilities,exciting immersive media tools, and powerful enterprise features.Now, enhancements across new and existing SwiftUI APIs make it even easier to buildcompelling volumetric experiences.You can create even richer 3D layouts in the same familiar way as 2D UI.Layouts are now aware of visual effects like rotation.Existing APIs allow you to easily align your views within volumes.You can align overlapping content in the same 3D space with spatial container,or anchor content to specific locations with 3D anchor preferences,all in SwiftUI.

Dynamic bounds restrictions allows you to drawoutside your app's bounds in both volumesand windows with a simple view modifier.And environment occlusion makes it so virtual objectscan be occluded by static real world objects.

You can bring this behavior to your appsby adding an environment blending component to any entity.

Now, a new suite of APIs deep in the integrationbetween SwiftUI, RealityKit, and ARKit.It is easier to position and translate contentacross these three fundamental frameworks,regardless of the coordinate space you're working in.

RealityKit's entity and its animations are observable,allowing them to be used directly in SwiftUI views.You can directly apply gestures to entitiesor present and animate 3D content in your app with Model3D.

Because many of the best spatial experiences are shared,visionOS 26 introduces a new capability.With nearby window sharing, you can build shared spatial experiences for userslocated in the same room,like Rock Paper Reality's Defender-Ella,as well as bring in remote participantsusing FaceTime and spatial personas.

New SharePlay APIs make adoption even easier,and your existing SharePlay apps will automatically work.

ARKit also adds support for shared world anchors,so you can precisely anchor shared content to the room.In visionOS 26, apps and QuickLook contentpersist or reappear in the same place, even after restart.This behavior is also coming to widgets.The familiar widgetKit framework, along with new APIsto specify its texture or react to users' proximity,are now available, allowing you to build dynamic widgetsthat persist throughout user spaces.

Around the world, users love experiencing contenton Vision Pro, and now they have an incredible new wayto experience photos.RealityKit's image presentation componentcan be used in your app to transform 2D imagesinto 3D spatial scenes,leveraging on-device, generative AI algorithmsto create a 3D representation of your image,optimized for real-time renderingfrom multiple points of view.

If you are building media applications,you can play and distribute even more typesof immersive content with built-in supportfor 180 degree, 360 degree, and wide-field-of-view videothrough Apple Projected Media Profile, or APMP.You can play and stream these new immersive media formatsinside your app using familiar AVKit, RealityKit, WebKit, and QuickLook APIs.And if you produce Apple immersive video contentusing the new Blackmagic Camera and DaVinci Resolve app,you can play it back in your apps or directly from web pages in Safariusing the HTML video element.

In enterprise environments,visionOS 26 makes it even easier for developersto incorporate Vision Pro into their organizations.With enterprise entitlements,you can disable content captures of your app's view,enable apps to automatically follow the user's positionas they navigate a space, access the left and rightcamera feed simultaneously,or grab a specified region of the camera feed for stabilizationand enhancement.These are just a few of the incredible features coming to visionOS.Now I'll hand over to Eric to talk about gaming.

Apple silicon enables exceptional performance and visualsthat unlock the most advanced games.This year, we're making it even easier to bring your gameto Apple's unified gaming platform.We've focused on three key areas:advanced graphics technologies, improved game developer tools,and system features to deliver a great gaming experience for your players.The key graphics technology powering these experiences is Metal.Ten years ago, we brought Metal to the Mac,and since then we've been adding capabilitiesto power the most advanced graphics workloads.Now we're introducing Metal 4 with tons of new features tosupport the most advanced graphics and ML technologieslike neural rendering which combines traditional graphicswith machine learning inference.With Metal 4 you can now run inference networksdirectly in your shaders to compute lighting,materials, and geometry,enabling highly realistic visual effects for your games.And you can use MetalFX upscaling, frame interpolation,and denoising APIs to take your game’s graphics performance to the next level.MetalFX frame interpolation generates an intermediate framefor every two input framesto achieve higher and more stable frame rates.Here we're showing the upcoming Mac versionof Cyberpunk 2077 on the M4 MacBook Air.On the right, CD Projekt Red is using MetalFX frame interpolationto increase performance to a solid 60 frames per second.They also use MetalFX denoising to enable ray tracingon the game's ultra settings on the M4 Max MacBook Pro.Metal 4 is designed exclusively for Apple siliconand it sets the stage for the next generation of games on Mac.This year, we further streamlined the game development experiencewith improved developer tools.The updated Game Porting Toolkit provides everything you need to get startedbringing your Windows game to Apple's platforms.Like tools to evaluate and profile your game,convert your shaders and assets,and human interface guidelines and code samplesto build native games that feel at home on Apple devices.For example, CD Projekt Red used Game Porting Toolkitto dramatically speed up the process of bringing Cyberpunk 2077 to Mac.And the latest version of Game Porting Toolkitprovides new tools to make it even easier tooptimize your game, with support for Windows upscaling technologies.For example, a developer like Remedycould use it early in the porting process to evaluatehow much MetalFX could improve the performance of their game, Control,when running on Apple silicon.Game Porting Toolkit provides on-screen insights and guidancefor optimizing your graphics code for the best possible performance.And you can now customize the Metal Performance HUDas you profile and debug your code.

And finally, there are new tools to build, run, and debug games remotelyfrom a Windows environment.This is great for targeting Mac from an existing game development toolchain.And once you've got your game up and running,you can adopt powerful system frameworks to deliver immersive graphics and audio,incredibly responsive input,and a seamless gaming experience for your players.This year, the frameworks that power input across iPhone,iPad, Mac, and Vision Pro are getting major upgrades,with easier pairing for PlayStation DualSense controllersacross all of your devices.A new touch controller API provides an easy wayto add on-screen controls for iPhone and iPad,and you can enable powerful new ways to play gameson your Vision Pro,with support for PlayStation VR2 Sense controllersand up to three times faster hand tracking.To enable seamless play across devices,you can bring cloud save to your gameswith the new GameSave framework.For playing on the go,macOS Tahoe has optimized Low Power Mode for gaming.As a developer, you can further extend battery lifeby enabling more efficient game settingswhen the system is in Low Power Mode.With the new Game Center Challenges API,you can turn single player game activitiesinto social experiences with friends.These challenges will appear in the new Games appand players can also access them in the Game Overlay,interact with friends and change settingsall without leaving the game.

With all of these new features,it's never been a better timeto bring your next generation gamesto Apple's unified gaming platform.Now back to Matthew.

Metal 4 is a great example of the tight integrationof our software with Apple silicon,creating a whole new class of experiences.In fact, since we began the transition to Apple siliconover five years ago,we've been able to add incredible featureslike Apple Intelligence, Game Mode,Presenter Overlay, and more.

We completed the transition to Apple siliconacross our entire product lineup two years ago.So your apps can now depend on and build upon these features too.

Apple silicon enables us all to achieve thingsthat were previously unimaginable.And it's time to put all of our focus and innovation there.

And so, macOS Tahoe will be the final release for Intel Macs.

So if you've not done so already, now is a great time to help your users migrateto the Apple silicon versions of your apps.

There's a lot to love in this year's release.

The new design with Liquid Glass brings new depth, fluidity,and dynamism to your apps.Apple Intelligence lets you take advantage of on-device modelswith guided generation.

Xcode transforms the way you create apps using any coding model.And updates to Swift and SwiftUIfurther expand your app's performance and capabilities,making it easy to bring your apps to the full range of Apple platforms.

So, is that all we have? Not even close.There are so many other new features and APIs to explore.And we have over 100 sessions that go deeper into what you've heard about todayand what you haven't yet.Here's a few examples.Let's do this as a lightning round.You can now create menus and commandsthat are included in the new iPad menu bar.With an updated Background Tasks API on iOS and iPadOS,you can start long-running tasks that will complete in the background,like a video export.CarPlay now supports Live Activitiesso your app can show timely, relevant updates,even when users are on the road.In macOS, Terminal has a fresh look with 24-bit color,new themes inspired by Liquid Glass, and support for Powerline fonts.The HTML model element embeds 3D models into your webpages.And on visionOS, it can be viewed stereoscopically in lineand dragged out into the real world.When you adopt Look to Scroll on visionOS,users can browse hands-freejust by looking at the edges of content.The declared age range API helps you adjustyour app's experience to be age appropriatewhile preserving user privacy.The new PermissionKit framework gives your apps new toolsto help children communicate safelywith parental supervision.You can now highlight your app's accessibility featuresin a dedicated section of your App Store product page.And for assistive access,you can now customize the experience in your appwith more focused features and a simplified user interface.

There's just so much to explore.The sessions are available starting today,so you can just go dive in.And we look forward to connecting with you in the Labsand the Apple Developer Forums.

What you do as developers is amazing.You turn ideas into incredible experiences for your usersand bring our platforms to life.

Apps have become essential to how we all connectand communicate, deliver our best work, get creative, or explore new things.So whether you are just starting out or have been building apps for years,thank you for being part of such a vibrant developer community.

We can't wait to see what you create next.

## Code Samples

