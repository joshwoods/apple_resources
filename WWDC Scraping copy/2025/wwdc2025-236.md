# Wwdc2025 236

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Summary

Transcript

Unlock GPU computing with WebGPULearn how the WebGPU API provides safe access to GPU devices for graphics and general-purpose computation. We'll also explore the WGSL shading language to write GPU programs. And we'll dive into best practices to achieve optimal performance while using minimal power across desktop and mobile devices.Chapters0:00 -Introduction2:14 -Explore the WebGPU API9:54 -Develop shaders13:57 -Optimize performanceResourcesbabylon.js – webGL and WebXR libraryMetal Performance Shadersthree.js – webGL and WebXR libraryTransformers.js - HuggingfaceWebGPU - W3CWebGPU Samples - github.ioHD VideoSD VideoRelated VideosWWDC25Meet WebKit for SwiftUIWhat’s new in Safari and WebKitWWDC20Harness Apple GPUs with MetalOptimize Metal Performance for Apple silicon Macs

Learn how the WebGPU API provides safe access to GPU devices for graphics and general-purpose computation. We'll also explore the WGSL shading language to write GPU programs. And we'll dive into best practices to achieve optimal performance while using minimal power across desktop and mobile devices.

0:00 -Introduction

2:14 -Explore the WebGPU API

9:54 -Develop shaders

13:57 -Optimize performance

babylon.js – webGL and WebXR library

Metal Performance Shaders

three.js – webGL and WebXR library

Transformers.js - Huggingface

WebGPU - W3C

WebGPU Samples - github.io

HD VideoSD Video

HD Video

SD Video

Meet WebKit for SwiftUI

What’s new in Safari and WebKit

Harness Apple GPUs with Metal

Optimize Metal Performance for Apple silicon Macs

Search this video…Hi, I’m Mike, an engineer on the Safari team.Today I’m going to show you how WebGPUallows you to unlock parallel computing on GPUs from the web.WebGPU can do everything WebGL can when it comes to 3D graphics,but with far greater performance and flexibility.It’s the best choice for graphics on the web.And on top of that,it’s the only way to run general-purpose computations on the GPUright in the browser.And if you’re familiar with Metal, you’ll feel right at home.Most calls are one-to-one mapping with Metal framework calls.In fact, it’s supported on all platforms where Metal is supported,specifically: Mac, iPhone, iPad, and Vision Pro.Being a web API, websites and web apps using WebGPUwill run everywhere it is supported.On non-Apple systems, WebGPU is implemented with APIs similar to Metal.And if you’re not familiar with low-level graphics programming,there are many web graphics libraries you can use that support WebGPU,giving you access to all of the performanceand capabilities it offers.In fact, you can use threeJS running WebGPU under-the-hoodto animate these gorgeous 3D jellyfish in real time.I think it’s a stunning example, and it runs so smoothly in Safari,thanks to WebGPU being built from the ground upto take full advantage of today’s modern hardware.I’ll start by exploring the API and how WebGPU maps to Metal.This will walk you through much of the code necessary for any WebGPU application.Then, I’ll go over how to create WebGPU shader programs—code that runs directly on the GPU.I’ll cover the shading language and why a new one is necessary for the web.After I've covered the fundamentals,I’ll talk about how to get the best performance with the API.If you’re already familiar with WebGPU, this will be especially interestingas I cover specific optimizations for Apple’s platforms.So let’s get started by taking a quick look at the graphics pipeline.The pipeline can be thought of as flowing from left to right.It starts with your website or web app, which loads content—things like images, videos, or binary data.That content then gets passed to WebKit,which is responsible for making it ready for the GPU.WebKit calls into Metal framework to create the resources and programswhich will later be run directly on the graphics hardware.Now let's break that down a bit.In WebGPU, Metal generates three types of resources:buffers, textures, and samplers.These get organized by WebKit into something called a GPU bind group.Basically, a structured way of grouping resources togetherso they can be efficiently used by the GPU.Under the hood, these are all packed into an argument bufferwhich is just a Metal buffer that holds references to the actual GPU resources.The programs themselves come from strings of codeand get compiled into three main types:compute, vertex, and fragment programs.These are the actual instructions that run on the GPU,doing everything from calculations to rendering pixels on the screen.So, with a solid understanding of how resources and programsfit into the pipeline,I’ll give a brief overview of how WebGPU defines the different interfaces in its API.WebGPU is a flat API, but it has a lot of interfaces.At the very top of the hierarchy is the GPU objectand GPU adapter interfaces.A canvas is often used with WebGPU.Canvas can now return a GPUCanvasContext by querying the WebGPU context.A device is the main entry point for most API calls.It’s what you use to create most other interfaces.While there are a lot of different interfaces in the API,they simplify into a few categories.Namely, resources like textures, buffers, and samplers.Encoders, which issue commands on resources.Pipelines, which tell how various resourcesshould be interpreted by the encoders.Bind groups, which group related resources together.And shader modules, which contain instructionsfor running calculations on the GPU.So now, with an understanding of the overall structureof WebGPU, let me introduce you to working with the APIby showing you how to create the device and resources.A device is the entry point into most API calls.If you’re familiar with Metal, it’s very similar to MTLDevice.Assuming you have a page with a canvas, start by getting the canvas element.Then, use navigator.gpu.requestAdapter()to create an adapter and call requestDeviceto create your GPU device.WebGPU supports several extensions,one being the shader-f16 extension, which lets you use half-precision floats.They help with performance by cutting down memory bandwidth.While supported on all Apple devices, it’s an optional feature,so please make sure to check for support before using it on other platforms.Next, set up the canvas context with the device by calling configure.That links the canvas to memory the GPU can actually write to.Now that the device is ready, I can start creating some resources.In WebGPU, you’ll be working with things like buffers and textures a lot.In Metal, they’re represented by MTLBuffer and MTLTexture.Buffers are super flexible.You can use them to store all sorts of data,from simple stuff like a vector of floatsto more complex, custom data types you define yourself.For example, you might have a buffer holding multiple instancesof a particle type.Imagine, three particles stored right there in the buffer.A buffer is created by calling createBuffer on the device.Passing the buffer size and a usage mode.The usage mode allows WebGPU to avoid data raceswithout additional API complexities.Device has a property called queue,which is used for performing operations on buffers and textures.Once the buffer is created, populate its contents by calling the writeBuffer,passing the buffer, an offset, and a JavaScript arrayBuffer.Like buffers, textures are basically blobs of memory,but they get associated with special texture registersand instructions on the GPU.They’re often a representation of some image dataand can be one-dimensional, two-dimensional,an array of two-dimensional textures,a cube map, which is just an array of six two-dimensional textures,or alternatively, a three-dimensional texture.You create a texture by calling device.createTexture,passing in the width and height of the texture,the 2D texture format, and the usage modes.After creating the GPUTexture,we can load image data with device.queue.copyExternalImageToTexturepassing the image bitmap, the 2D texture we just created,and the image size.A texture is often created from image data and represents an image on the GPU.After creating a device and resources, let’s look at how to create a pipeline.A pipeline specifies how textures and buffers will be used on the GPU.There are two types of pipelines.Render pipelines, which are used with vertex and fragment programs,and compute pipelines, which are used with compute programs.These map to MTLRenderPipelineStateand MTLComputePipelineState objects in Metal.To create a compute pipeline, simply call device.createComputePipelinepassing either a bind group layout,or the constant auto identifier, which generates a layout from the shader.A layout is a structured way buffers, textures,and samplers are passed from the API to the GPU program.A shader module is required to create a pipeline.It’s created from a string.Render pipelines are created in a similar fashion,with an auto layout, a vertex shader module,and a fragment shader module.With the device, resources, and pipelines created,the basic setup for any WebGPU application is complete.Now that we’ve explored the architecture of the WebGPU API,let's look at how to develop your shaders.The WebGPU shading language, known as WGSL,allows websites to easily write programs which run directly on the GPU.Apple is heavily involved in the designand implementation of the WGSL shading language.WGSL is built from the ground up to be safe for the web.WGSL supports three types of programs:vertex programs, fragment programs, and compute programs.I’m going to walk through how to create this simple WebGPU example,which is composed of: a vertex program, which takes buffer data from JavaScriptand creates triangles on the screen.A fragment program, which computes individual colorand depth values of textures.And a compute program, which can do any general computations,but in this case, we will perform a physics simulation.The vertex program computes where triangles appear on the screen.Here, we can see the outlines of the 100,000 triangleswhich are used in this example.To write the output position of the triangles,use the @builtin position attribute.Here is the definition of the main functionalong with the vertex shader inputs.It just writes the position and a color.Now, let’s take a look at a fragment shader.So take the color we generated in the vertex stageand store that color in the texture.Like this is a simple example, but you can insert any logic hereto compute color and depth values.You can also write to storage textures, buffers,perform atomic operations, and a lot more.WGSL is really flexible.So now let’s look at something even more flexible: compute shaders.Like other program types, compute shaders can contain many bindings,which are inputs from JavaScript into a shader.Compute shaders are really coolbecause you can perform any computations you want,store the results in buffers,and read the buffers back out into your JavaScript code.There doesn’t have to be any visualization on the screen.Compute shaders weren’t possible with WebGL,which is another reason to use WebGPU for any new applications.The compute program requires a workgroup size,which defines the size of the grid the compute shaderwill execute over.We’ll also use the global_invocation_id, which is the position in the entire grid.This is a builtin variable,which can be used without needing to pass anything from JavaScript.The body of the compute shader updates the particle simulation,applying gravity, velocity, and elapsed time.You can perform any computations you’d like in a compute shaderand it executes in parallel with incredible performance on the GPU.Once the particle fades out completely,a new point is chosen to respawn to the particleby calling textureLoad on a probability mapand selecting a new position for the particle.Finally, the rest of the particle attributesare reset to their starting values, and the particle is stored in the buffer.Put it all together and we get this nice animation with the WebGPU logo.By leveraging the parallel processing capabilities of the GPU,you can perform arbitrary computationsof sizes not previously possible from the webwhile still achieving real-time performance.It's great, isn't it?That was a quick overview of how to develop shaders for WebGPU applications.So now, let me show you how to get the best performance out of WebGPU.There are just a few guidelines to keep in mindthat will help you deliver the best experience on Apple’s platforms.A key to great performance is to be mindful of memory use, and that means:use memory efficient data types,record your render commands once, then reuse them,and keep the number of resources low.OK, so let's dive into more detail.There are a couple of ways to minimize memory use.First, you can use half precision floats.They're an IEEE standard.In WGSL, the data type is called f16.They really help cut down on memory use and boost performance.That said, they're not always practical.You need to make sure your algorithms are stablewith reduced precision,and keep in mind, their values max out at just over 65,000,unlike 32-bit floats that can handle much larger values.On iOS and visionOS specifically, storing data in f16 or compressed formatscan really help you avoid getting your program terminateddue to memory pressure.To use half-precision floats, you’ll need to enable them during device creationand in your WGSL code.Let me show you how to do that with a quick code example.First, enable the shader-f16 extension in the call to requestDevice,and in the shader, add the ‘enable f16’ statement.Then you can use f16 scalar and vector types,along with all the 32-bit types like before.And, even if you just store the data in half precisionand immediately unpack to f32,you’ll still get a lot of memory benefitto avoid getting your app terminated due to memory pressure.Another way to minimize memory usageis by avoiding unnecessary buffer and texture update calls.These require data copies from JavaScriptinto the memory which backs the Metal resource.Updating buffers with index and indirect usage modescan be especially expensivesince validation needs to be performed prior to using the buffer again.Those buffers index either directly or indirectly into vertex buffers,and WebGPU must ensure all the offsets into these buffersare within bounds before any draw commands execute.Only update these type of buffers when needed.This also applies to using a buffer in a bind groupwith write or read/write access.As illustrated in the code example, prefer read-only accessunless you are writing through the resource in the shader,especially if the resource is an index or indirect buffer.Following those memory tips can have a big impact on performance,not just on Apple’s platforms, but across all mobile and desktop devices.Next, I want to tell you more about reusing your render commands.Render bundles are a great way to do that,allowing you to encode commands once and replay them as many times as you need.WebGPU has to make sure all reads and writesare well-defined and within bounds,which normally means a lot of validation every frame.But with render bundles,that validation happens once, when the bundle is created,instead of every time it runs.That saves time and brings your app closer to native performance,leaving more room for your actual logic.And creating a render bundle is pretty simple.Start by creating a render bundle encoder and then encode your draw calls,just like you would with a render pass encoder.Calling finish() creates the bundle for reuse.Now that you have a bundle, you can run all those draw commandswith a call to executeBundles(),and you can do that over and over as needed.Under the hood, render bundles map to Metal’s indirect command buffersand give similar performance benefits.So now that we’ve tackled memory usage and cut down validation overhead,let’s look at reducing the number of resources.Specifically, command buffers, render and compute passes,bind group layouts, and bind groups.Command buffer boundaries require synchronizationbetween high-speed on-chip memory and unified on-device memory.If possible, use a single command buffer per update loop,or if that is not possible,a general good rule of thumb is that as few command buffersas possible should be used.Remember, it is only necessary to split command bufferswhen you require the data written back to unified memory.Usually, that's a rare occurrence.Unlike command buffers,passes don’t require synchronization with unified memory.They still consume substantial memory bandwidth,depending on the render target and compute dispatch sizes.So it’s best to use as few as possible to save memory bandwidth.Like many mobile phones, the GPU in Apple’s devicesis based on a tile-based deferred renderer.Following best practices for combining passesand saving memory bandwidthwill help your site or web app excel on Apple’s hardware.For more information on tile-based renderers,check out “Optimize Metal Performance for Apple silicon Macs”and “Harness Apple GPUs with Metal” from WWDC 2020.With that, let me focus on bind groups.They are implemented with Metal argument buffers,so creating a bind group also creates a new MTLBufferBy using dynamic offsets, a single bind group,which shares the same layout, but uses different resources at runtime,can be created.To use dynamic offsets, a custom bind group layout must be createdinstead of using an auto layout from the shader module.The layout is created by calling createBindGroupLayout with hasDynamicOffset,and then pass the newly created layout to create the bind group.The dynamic offsets are involved in calls to setBindGroup.One offset per dynamic buffer in the bind group is required.In this case, the bind group has one buffer using dynamic offsets,so one offset is passed to setBindGroup.For instance, instead of creating 10 bind groups, each with a 64-byte buffer inside,a much better approach is to make one 640-byte bufferto represent 10 64-byte objects.I’ve just avoided creating 9 Metal buffers by doing that.By storing similar data in less memory, avoiding repeated validation,and minimizing the total number of Metal objects created,you can create stunning, highly efficient websites and web apps with WebGPU.I hope you take these performance considerations into accountwhen using WebGPU.WebGPU allows for running custom algorithms directly on the GPU,something not previously possible from the web.I encourage you to start using WebGPU today on Mac,iPhone, iPad, and Vision Pro,and please consider the optimal usage guidelines.I’m so excited for the future of GPU programming on the web.

Hi, I’m Mike, an engineer on the Safari team.Today I’m going to show you how WebGPUallows you to unlock parallel computing on GPUs from the web.WebGPU can do everything WebGL can when it comes to 3D graphics,but with far greater performance and flexibility.It’s the best choice for graphics on the web.And on top of that,it’s the only way to run general-purpose computations on the GPUright in the browser.And if you’re familiar with Metal, you’ll feel right at home.Most calls are one-to-one mapping with Metal framework calls.In fact, it’s supported on all platforms where Metal is supported,specifically: Mac, iPhone, iPad, and Vision Pro.Being a web API, websites and web apps using WebGPUwill run everywhere it is supported.On non-Apple systems, WebGPU is implemented with APIs similar to Metal.And if you’re not familiar with low-level graphics programming,there are many web graphics libraries you can use that support WebGPU,giving you access to all of the performanceand capabilities it offers.In fact, you can use threeJS running WebGPU under-the-hoodto animate these gorgeous 3D jellyfish in real time.I think it’s a stunning example, and it runs so smoothly in Safari,thanks to WebGPU being built from the ground upto take full advantage of today’s modern hardware.I’ll start by exploring the API and how WebGPU maps to Metal.This will walk you through much of the code necessary for any WebGPU application.Then, I’ll go over how to create WebGPU shader programs—code that runs directly on the GPU.I’ll cover the shading language and why a new one is necessary for the web.

After I've covered the fundamentals,I’ll talk about how to get the best performance with the API.If you’re already familiar with WebGPU, this will be especially interestingas I cover specific optimizations for Apple’s platforms.So let’s get started by taking a quick look at the graphics pipeline.

The pipeline can be thought of as flowing from left to right.It starts with your website or web app, which loads content—things like images, videos, or binary data.

That content then gets passed to WebKit,which is responsible for making it ready for the GPU.

WebKit calls into Metal framework to create the resources and programswhich will later be run directly on the graphics hardware.

Now let's break that down a bit.In WebGPU, Metal generates three types of resources:buffers, textures, and samplers.These get organized by WebKit into something called a GPU bind group.Basically, a structured way of grouping resources togetherso they can be efficiently used by the GPU.Under the hood, these are all packed into an argument bufferwhich is just a Metal buffer that holds references to the actual GPU resources.

The programs themselves come from strings of codeand get compiled into three main types:compute, vertex, and fragment programs.These are the actual instructions that run on the GPU,doing everything from calculations to rendering pixels on the screen.So, with a solid understanding of how resources and programsfit into the pipeline,I’ll give a brief overview of how WebGPU defines the different interfaces in its API.

WebGPU is a flat API, but it has a lot of interfaces.At the very top of the hierarchy is the GPU objectand GPU adapter interfaces.

A canvas is often used with WebGPU.Canvas can now return a GPUCanvasContext by querying the WebGPU context.

A device is the main entry point for most API calls.It’s what you use to create most other interfaces.

While there are a lot of different interfaces in the API,they simplify into a few categories.Namely, resources like textures, buffers, and samplers.

Encoders, which issue commands on resources.Pipelines, which tell how various resourcesshould be interpreted by the encoders.Bind groups, which group related resources together.And shader modules, which contain instructionsfor running calculations on the GPU.So now, with an understanding of the overall structureof WebGPU, let me introduce you to working with the APIby showing you how to create the device and resources.

A device is the entry point into most API calls.If you’re familiar with Metal, it’s very similar to MTLDevice.

Assuming you have a page with a canvas, start by getting the canvas element.Then, use navigator.gpu.requestAdapter()to create an adapter and call requestDeviceto create your GPU device.

WebGPU supports several extensions,one being the shader-f16 extension, which lets you use half-precision floats.

They help with performance by cutting down memory bandwidth.

While supported on all Apple devices, it’s an optional feature,so please make sure to check for support before using it on other platforms.

Next, set up the canvas context with the device by calling configure.That links the canvas to memory the GPU can actually write to.

Now that the device is ready, I can start creating some resources.In WebGPU, you’ll be working with things like buffers and textures a lot.In Metal, they’re represented by MTLBuffer and MTLTexture.

Buffers are super flexible.You can use them to store all sorts of data,from simple stuff like a vector of floatsto more complex, custom data types you define yourself.For example, you might have a buffer holding multiple instancesof a particle type.Imagine, three particles stored right there in the buffer.

A buffer is created by calling createBuffer on the device.Passing the buffer size and a usage mode.

The usage mode allows WebGPU to avoid data raceswithout additional API complexities.

Device has a property called queue,which is used for performing operations on buffers and textures.

Once the buffer is created, populate its contents by calling the writeBuffer,passing the buffer, an offset, and a JavaScript arrayBuffer.

Like buffers, textures are basically blobs of memory,but they get associated with special texture registersand instructions on the GPU.They’re often a representation of some image dataand can be one-dimensional, two-dimensional,an array of two-dimensional textures,a cube map, which is just an array of six two-dimensional textures,or alternatively, a three-dimensional texture.

You create a texture by calling device.createTexture,passing in the width and height of the texture,the 2D texture format, and the usage modes.

After creating the GPUTexture,we can load image data with device.queue.copyExternalImageToTexturepassing the image bitmap, the 2D texture we just created,and the image size.

A texture is often created from image data and represents an image on the GPU.After creating a device and resources, let’s look at how to create a pipeline.

A pipeline specifies how textures and buffers will be used on the GPU.There are two types of pipelines.Render pipelines, which are used with vertex and fragment programs,and compute pipelines, which are used with compute programs.These map to MTLRenderPipelineStateand MTLComputePipelineState objects in Metal.

To create a compute pipeline, simply call device.createComputePipelinepassing either a bind group layout,or the constant auto identifier, which generates a layout from the shader.

A layout is a structured way buffers, textures,and samplers are passed from the API to the GPU program.

A shader module is required to create a pipeline.It’s created from a string.

Render pipelines are created in a similar fashion,with an auto layout, a vertex shader module,and a fragment shader module.

With the device, resources, and pipelines created,the basic setup for any WebGPU application is complete.

Now that we’ve explored the architecture of the WebGPU API,let's look at how to develop your shaders.

The WebGPU shading language, known as WGSL,allows websites to easily write programs which run directly on the GPU.Apple is heavily involved in the designand implementation of the WGSL shading language.WGSL is built from the ground up to be safe for the web.WGSL supports three types of programs:vertex programs, fragment programs, and compute programs.

I’m going to walk through how to create this simple WebGPU example,which is composed of: a vertex program, which takes buffer data from JavaScriptand creates triangles on the screen.A fragment program, which computes individual colorand depth values of textures.And a compute program, which can do any general computations,but in this case, we will perform a physics simulation.

The vertex program computes where triangles appear on the screen.

Here, we can see the outlines of the 100,000 triangleswhich are used in this example.

To write the output position of the triangles,use the @builtin position attribute.

Here is the definition of the main functionalong with the vertex shader inputs.It just writes the position and a color.Now, let’s take a look at a fragment shader.

So take the color we generated in the vertex stageand store that color in the texture.Like this is a simple example, but you can insert any logic hereto compute color and depth values.You can also write to storage textures, buffers,perform atomic operations, and a lot more.WGSL is really flexible.So now let’s look at something even more flexible: compute shaders.

Like other program types, compute shaders can contain many bindings,which are inputs from JavaScript into a shader.

Compute shaders are really coolbecause you can perform any computations you want,store the results in buffers,and read the buffers back out into your JavaScript code.There doesn’t have to be any visualization on the screen.Compute shaders weren’t possible with WebGL,which is another reason to use WebGPU for any new applications.

The compute program requires a workgroup size,which defines the size of the grid the compute shaderwill execute over.

We’ll also use the global_invocation_id, which is the position in the entire grid.This is a builtin variable,which can be used without needing to pass anything from JavaScript.

The body of the compute shader updates the particle simulation,applying gravity, velocity, and elapsed time.

You can perform any computations you’d like in a compute shaderand it executes in parallel with incredible performance on the GPU.

Once the particle fades out completely,a new point is chosen to respawn to the particleby calling textureLoad on a probability mapand selecting a new position for the particle.

Finally, the rest of the particle attributesare reset to their starting values, and the particle is stored in the buffer.

Put it all together and we get this nice animation with the WebGPU logo.By leveraging the parallel processing capabilities of the GPU,you can perform arbitrary computationsof sizes not previously possible from the webwhile still achieving real-time performance.

It's great, isn't it?That was a quick overview of how to develop shaders for WebGPU applications.So now, let me show you how to get the best performance out of WebGPU.

There are just a few guidelines to keep in mindthat will help you deliver the best experience on Apple’s platforms.A key to great performance is to be mindful of memory use, and that means:use memory efficient data types,record your render commands once, then reuse them,and keep the number of resources low.OK, so let's dive into more detail.

There are a couple of ways to minimize memory use.

First, you can use half precision floats.They're an IEEE standard.In WGSL, the data type is called f16.

They really help cut down on memory use and boost performance.That said, they're not always practical.You need to make sure your algorithms are stablewith reduced precision,and keep in mind, their values max out at just over 65,000,unlike 32-bit floats that can handle much larger values.On iOS and visionOS specifically, storing data in f16 or compressed formatscan really help you avoid getting your program terminateddue to memory pressure.To use half-precision floats, you’ll need to enable them during device creationand in your WGSL code.Let me show you how to do that with a quick code example.

First, enable the shader-f16 extension in the call to requestDevice,and in the shader, add the ‘enable f16’ statement.

Then you can use f16 scalar and vector types,along with all the 32-bit types like before.And, even if you just store the data in half precisionand immediately unpack to f32,you’ll still get a lot of memory benefitto avoid getting your app terminated due to memory pressure.

Another way to minimize memory usageis by avoiding unnecessary buffer and texture update calls.These require data copies from JavaScriptinto the memory which backs the Metal resource.Updating buffers with index and indirect usage modescan be especially expensivesince validation needs to be performed prior to using the buffer again.Those buffers index either directly or indirectly into vertex buffers,and WebGPU must ensure all the offsets into these buffersare within bounds before any draw commands execute.

Only update these type of buffers when needed.This also applies to using a buffer in a bind groupwith write or read/write access.As illustrated in the code example, prefer read-only accessunless you are writing through the resource in the shader,especially if the resource is an index or indirect buffer.

Following those memory tips can have a big impact on performance,not just on Apple’s platforms, but across all mobile and desktop devices.Next, I want to tell you more about reusing your render commands.

Render bundles are a great way to do that,allowing you to encode commands once and replay them as many times as you need.WebGPU has to make sure all reads and writesare well-defined and within bounds,which normally means a lot of validation every frame.But with render bundles,that validation happens once, when the bundle is created,instead of every time it runs.That saves time and brings your app closer to native performance,leaving more room for your actual logic.And creating a render bundle is pretty simple.Start by creating a render bundle encoder and then encode your draw calls,just like you would with a render pass encoder.Calling finish() creates the bundle for reuse.

Now that you have a bundle, you can run all those draw commandswith a call to executeBundles(),and you can do that over and over as needed.

Under the hood, render bundles map to Metal’s indirect command buffersand give similar performance benefits.So now that we’ve tackled memory usage and cut down validation overhead,let’s look at reducing the number of resources.

Specifically, command buffers, render and compute passes,bind group layouts, and bind groups.

Command buffer boundaries require synchronizationbetween high-speed on-chip memory and unified on-device memory.If possible, use a single command buffer per update loop,or if that is not possible,a general good rule of thumb is that as few command buffersas possible should be used.Remember, it is only necessary to split command bufferswhen you require the data written back to unified memory.Usually, that's a rare occurrence.

Unlike command buffers,passes don’t require synchronization with unified memory.They still consume substantial memory bandwidth,depending on the render target and compute dispatch sizes.So it’s best to use as few as possible to save memory bandwidth.

Like many mobile phones, the GPU in Apple’s devicesis based on a tile-based deferred renderer.Following best practices for combining passesand saving memory bandwidthwill help your site or web app excel on Apple’s hardware.For more information on tile-based renderers,check out “Optimize Metal Performance for Apple silicon Macs”and “Harness Apple GPUs with Metal” from WWDC 2020.

With that, let me focus on bind groups.They are implemented with Metal argument buffers,so creating a bind group also creates a new MTLBufferBy using dynamic offsets, a single bind group,which shares the same layout, but uses different resources at runtime,can be created.

To use dynamic offsets, a custom bind group layout must be createdinstead of using an auto layout from the shader module.

The layout is created by calling createBindGroupLayout with hasDynamicOffset,and then pass the newly created layout to create the bind group.The dynamic offsets are involved in calls to setBindGroup.One offset per dynamic buffer in the bind group is required.

In this case, the bind group has one buffer using dynamic offsets,so one offset is passed to setBindGroup.

For instance, instead of creating 10 bind groups, each with a 64-byte buffer inside,a much better approach is to make one 640-byte bufferto represent 10 64-byte objects.I’ve just avoided creating 9 Metal buffers by doing that.

By storing similar data in less memory, avoiding repeated validation,and minimizing the total number of Metal objects created,you can create stunning, highly efficient websites and web apps with WebGPU.I hope you take these performance considerations into accountwhen using WebGPU.WebGPU allows for running custom algorithms directly on the GPU,something not previously possible from the web.I encourage you to start using WebGPU today on Mac,iPhone, iPad, and Vision Pro,and please consider the optimal usage guidelines.

I’m so excited for the future of GPU programming on the web.

0:00 -IntroductionWebGPU enables high-performance 3D graphics and general-purpose parallel computing on GPUs. It builds on WebGL, offering greater flexibility and speed. WebGPU is designed to be platform-agnostic, with a Metal-like API, and is supported on Mac, iPhone, iPad, Vision Pro, and other non-Apple systems.2:14 -Explore the WebGPU APIThe WebGPU pipeline processes content from websites or web apps through WebKit and the Metal framework. Metal generates GPU resources — buffers, textures, and samplers — organized into GPU bind groups for efficient use. These resources, along with compiled shader programs (compute, vertex, and fragment), are then utilized by the GPU.

WebGPU's API, which is a flat API, provides interfaces for managing devices, resources, encoders, pipelines, bind groups, and shader modules. You can often use a canvas with WebGPU, and you can query a 'GPUCanvasContext' to create a GPU device.9:54 -Develop shadersWebGPU uses WGSL, a language for web-based GPU programming. It supports three main program types: vertex, fragment, and compute. 

Vertex programs define triangle positions on the screen. Fragment programs compute colors and depths for textures. Compute shaders, new to WebGPU, perform general computations in parallel, enabling physics simulations and other complex tasks.13:57 -Optimize performanceTo optimize WebGPU performance, focus on memory efficiency. You can also minimize unnecessary buffer and texture update calls, as they require data copies and can be expensive. Reusing render commands through render bundles is highly recommended because it eliminates redundant validation, saving time and bringing performance closer to native levels. Further, reducing the number of resources — such as command buffers, render passes, and bind groups — is crucial.

By following these guidelines, you can create stunning and highly efficient websites and web apps that excel on Apple hardware and across all mobile and desktop devices.

0:00 -Introduction

WebGPU enables high-performance 3D graphics and general-purpose parallel computing on GPUs. It builds on WebGL, offering greater flexibility and speed. WebGPU is designed to be platform-agnostic, with a Metal-like API, and is supported on Mac, iPhone, iPad, Vision Pro, and other non-Apple systems.

WebGPU enables high-performance 3D graphics and general-purpose parallel computing on GPUs. It builds on WebGL, offering greater flexibility and speed. WebGPU is designed to be platform-agnostic, with a Metal-like API, and is supported on Mac, iPhone, iPad, Vision Pro, and other non-Apple systems.

2:14 -Explore the WebGPU API

The WebGPU pipeline processes content from websites or web apps through WebKit and the Metal framework. Metal generates GPU resources — buffers, textures, and samplers — organized into GPU bind groups for efficient use. These resources, along with compiled shader programs (compute, vertex, and fragment), are then utilized by the GPU.

WebGPU's API, which is a flat API, provides interfaces for managing devices, resources, encoders, pipelines, bind groups, and shader modules. You can often use a canvas with WebGPU, and you can query a 'GPUCanvasContext' to create a GPU device.

The WebGPU pipeline processes content from websites or web apps through WebKit and the Metal framework. Metal generates GPU resources — buffers, textures, and samplers — organized into GPU bind groups for efficient use. These resources, along with compiled shader programs (compute, vertex, and fragment), are then utilized by the GPU.

WebGPU's API, which is a flat API, provides interfaces for managing devices, resources, encoders, pipelines, bind groups, and shader modules. You can often use a canvas with WebGPU, and you can query a 'GPUCanvasContext' to create a GPU device.

9:54 -Develop shaders

WebGPU uses WGSL, a language for web-based GPU programming. It supports three main program types: vertex, fragment, and compute. 

Vertex programs define triangle positions on the screen. Fragment programs compute colors and depths for textures. Compute shaders, new to WebGPU, perform general computations in parallel, enabling physics simulations and other complex tasks.

WebGPU uses WGSL, a language for web-based GPU programming. It supports three main program types: vertex, fragment, and compute. 

Vertex programs define triangle positions on the screen. Fragment programs compute colors and depths for textures. Compute shaders, new to WebGPU, perform general computations in parallel, enabling physics simulations and other complex tasks.

13:57 -Optimize performance

To optimize WebGPU performance, focus on memory efficiency. You can also minimize unnecessary buffer and texture update calls, as they require data copies and can be expensive. Reusing render commands through render bundles is highly recommended because it eliminates redundant validation, saving time and bringing performance closer to native levels. Further, reducing the number of resources — such as command buffers, render passes, and bind groups — is crucial.

By following these guidelines, you can create stunning and highly efficient websites and web apps that excel on Apple hardware and across all mobile and desktop devices.

To optimize WebGPU performance, focus on memory efficiency. You can also minimize unnecessary buffer and texture update calls, as they require data copies and can be expensive. Reusing render commands through render bundles is highly recommended because it eliminates redundant validation, saving time and bringing performance closer to native levels. Further, reducing the number of resources — such as command buffers, render passes, and bind groups — is crucial.

By following these guidelines, you can create stunning and highly efficient websites and web apps that excel on Apple hardware and across all mobile and desktop devices.

## Code Samples

