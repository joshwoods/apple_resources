# Wwdc2025 304

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Summary

Transcript

Explore video experiences for visionOSLearn about the different ways you can create and present immersive video experiences within your app. We'll explore the diverse media types available in visionOS 26, including profiles for 180°, 360°, and wide FOV video; options for creating and playing Apple Immersive Video; and expanded capabilities for 2D, 3D, and spatial video. Discover which profiles are best for your app and its content.Chapters0:00 -Introduction1:36 -2D and 3D video4:16 -Spatial video8:10 -180°, 360°, and Wide FOV video19:25 -Apple Immersive Video23:05 -Choosing a profileResourcesApple Movie Profiles for Spatial and Immersive MediaAuthoring Apple Immersive VideoConverting projected video to Apple Projected Media ProfileConverting side-by-side 3D video to multiview HEVC and spatial videoCreating spatial photos and videos with spatial metadataHTTP Live Streaming ExamplesISO Base Media File Format and Apple HEVC Stereo VideoPlaying immersive media with AVKitPlaying immersive media with RealityKitPresenting images in RealityKitQuickTime and ISO Base Media File Formats and Spatial and Immersive MediaRectangular Mask Payload Metadata within the QuickTime Movie File FormatWriting spatial photosHD VideoSD VideoRelated VideosWWDC25Learn about Apple Immersive Video technologiesLearn about the Apple Projected Media ProfileSupport immersive video playback in visionOS appsWhat’s new for the spatial webWhat’s new in RealityKitWWDC24Build compelling spatial photo and video experiencesWWDC23Deliver video content for spatial experiences

Learn about the different ways you can create and present immersive video experiences within your app. We'll explore the diverse media types available in visionOS 26, including profiles for 180°, 360°, and wide FOV video; options for creating and playing Apple Immersive Video; and expanded capabilities for 2D, 3D, and spatial video. Discover which profiles are best for your app and its content.

0:00 -Introduction

1:36 -2D and 3D video

4:16 -Spatial video

8:10 -180°, 360°, and Wide FOV video

19:25 -Apple Immersive Video

23:05 -Choosing a profile

Apple Movie Profiles for Spatial and Immersive Media

Authoring Apple Immersive Video

Converting projected video to Apple Projected Media Profile

Converting side-by-side 3D video to multiview HEVC and spatial video

Creating spatial photos and videos with spatial metadata

HTTP Live Streaming Examples

ISO Base Media File Format and Apple HEVC Stereo Video

Playing immersive media with AVKit

Playing immersive media with RealityKit

Presenting images in RealityKit

QuickTime and ISO Base Media File Formats and Spatial and Immersive Media

Rectangular Mask Payload Metadata within the QuickTime Movie File Format

Writing spatial photos

HD VideoSD Video

HD Video

SD Video

Learn about Apple Immersive Video technologies

Learn about the Apple Projected Media Profile

Support immersive video playback in visionOS apps

What’s new for the spatial web

What’s new in RealityKit

Build compelling spatial photo and video experiences

Deliver video content for spatial experiences

Search this video…Hi, I’m Dave, an engineer on the visionOS Spatial Media team.Today, we’re going to explore all of the different typesof video media available on visionOS, including some new ones in visionOS 26.Vision Pro is a spatial computer that shows high quality pass-through videoof the surrounding world.Because Vision Pro is with you wherever you look,content creators have an entire 360° around the viewerin which they can present engaging content.They’re not just limited to a flat screen in front of the viewer.This enables a wide range of media playback options,some of which are only possible on a spatial computer.Let's take a look.We’ll start by exploring how 2D and 3D videocan be presented on visionOS,including some cool new features coming in visionOS 26.We'll see how spatial video enables people to capture their own stereo videos,and some new ways you can play those videos in your app.We’ll learn about new immersive video formatsfor 180°, 360°, and wide FOV video.And for the ultimate immersive experience, there's Apple Immersive Video.We’ll see how you can now create your own Apple Immersive content and tooling.Finally, we’ll explore how all these different video profiles compareto help you choose the right one for your app.Let's get started with 2D and 3D video.Vision Pro is a great device for enjoying 2D movies and TV shows,and as a stereo device, it’s perfect for watching stereoscopic 3D movies too.2D videos can be played inline anywhere in your app’s UIusing an embedded playback experience,where the video appears alongside other UI elements.Here’s an example of playing video inline in freeformas part of a board full of content.Note that if you embed a 3D video inline, it gracefully falls back to playing in 2D.And both 2D and 3D video can be played in an expanded experienceon a floating screen in the shared space.Note that an expanded experience is requiredto play a 3D movie stereoscopically.2D and 3D video can also transition to a docked state in a virtual environment.Here’s an example from the Destination Video sample code project,available from developer.apple.com,where the video fades out from its expanded view and fades back in,docked within the app’s own custom studio environment,created with Reality Composer Pro.The video automatically shows dynamic light spillto make it feel like an integral part of that environment.Docking in an environment is a great exampleof how spatial computing enables video playbackto move beyond the bounds of a fixed single screen.And there are even more ways that 2D and 3D video playbackcan take advantage of Vision Pro’s infinite canvas.visionOS 2 introduced multi-view video,where viewers can enjoy multiple camera angles of a single eventor multiple sources of video simultaneously in Vision Pro.A new in visionOS 26, 2D and 3D videos can specify a per-frame dynamic maskto change or animate their frame size and aspect ratio,to accentuate a story point,or to combine archival and modern-day footage in a single scene,without needing to show black bars for letterboxing or pillarboxing.These kinds of seamless transitions, with a framing that best suits each shot,are only possible on a spatial computer.For more information, see the “Rectangular Mask Payload Metadata”document on developer.apple.com.3D video is the medium of choice for professional stereo productionsdesigned to be viewed on a big screen.But stereo video doesn’t have to require a movie studio.Vision Pro supports a new kind of stereo mediathat people can capture themselves, known as Spatial Video.People can shoot comfortable, compelling stereo contenton devices like iPhonewithout needing to be an expert in the rules of 3D filmmaking.Spatial video is stereo video with additional metadata,that enables windowed and immersive treatments on Vision Proto mitigate common causes of stereo discomfort.By default, spatial video renders through a window,with a faint glow around the edges.It can also expand into an immersive presentation,where the content is scaled to match the real size of objects.The edge of the frame disappears,and the content blends seamlessly into the real world.Spatial videos automatically fall back to 2D presentation on other platforms,enabling them to be played on all Apple devices.This enables people to capture spatial content to enjoy on Vision Pro,and still share their memories in 2Dwith friends and family who don’t yet have a Vision Pro.We saw earlier how 2D and 3D video is presented on a flat screen.For spatial videos, we inset that flat screenbehind a window and blur the edges of the window to soften them.This helps avoid issues when an object is clipped by the windowmore in one eye than the other, which can be uncomfortable to view.Spatial videos can be captured today oniPhone 15 Pro, iPhone 16, and iPhone 16 Pro,in the Camera app and in your own app via AVCaptureDevice APIs.Spatial videos can also be captured on Apple Vision Proand, with Canon’s R7 and R50 cameras with a Canon DUAL lens.In visionOS 2, spatial videos can be playedwith spatial styling  in your own appwith the QuickLook PreviewApplication API.In visionOS 26, we’re bringing that same spatial stylingto all of Apple’s media playback frameworks.We’re adding QLPreviewController support in QuickLook,plus support in AVKit, RealityKit, Safari, and WebKit,enabling you to incorporate spatial videos however you choose in your app,with support for HTTP Live Streaming, or HLS.And if you’re looking to edit and combine spatial videos in your appto create a longer narrative,the format is now supported in industry standard editing tools,such as Compressor, DaVinci Resolve Studio, and Final Cut Pro.To see more examples of what’s possible with spatial videosand spatial photos as well,check out the Spatial Gallery app on Vision Pro.To learn more about the spatial photo and video formats,check out “Build compelling spatial photo and video experiences” from WWDC24.And for more about the new ways you can play spatial videos in your app,check out “Support immersive video playback in visionOS apps”.And talking of spatial photos, there’s new RealityKit API in visionOS 26for displaying spatial photos in your appand for converting 2D photos to a 3D spatial scene.To learn how to present spatial photos and generate spatial scenesusing the new ImagePresentationComponent and Spatial3DImage APIs,check out “What’s new in RealityKit”.We saw earlier how 2D, 3D, and spatial videosare all played on a flat surface in Vision Pro.This is because these videos typically use what's known as a rectilinear projection,as seen in this photo of the Apple Park Visitor center.Rectilinear just means that straight lines are straight.There’s no lens curvature or warping in the video.And because of this, these kinds of videos feel correctwhen viewed on a flat surfacethat also doesn’t have any curvature or warping.We saw how the playback experience for these rectilinear videos on Vision Proexpands that flat surface to fill more of the viewer’s field of view,via docking for 2D and 3D video,and immersive presentation for spatial video.But on a spatial computing device,we’re not just restricted to a flat surface in front of the viewer.There’s even more space around them we can fill with pixels.And there are other non-rectilinear video typesthat are great for filling even more of the viewer’s field of view,by presenting video on a curved surface, not a flat one.visionOS 26 adds native support for three of these non-rectilinear media types:180° video, 360° video, and wide FOV video.Let's take a look.180° video is presented on a half sphere directly in front of the viewer.Video is projected onto that half sphereto completely fill the viewer’s forward field of view.In this example, it’s a 180° video of the pond at Apple Park.From the viewer’s point of view, it’s like being there.This is a great way for content creatorsto transport their viewers to amazing locations.180° video is typically captured in stereo.And because it’s stereo, and completely fills your forward field of view,it feels like you’re looking at the real thing.360° video takes things a step further, filling the entire world with content.With 360° video, the content literally surrounds the viewer,giving them the freedom to look wherever they like.Here’s an example of a 360° video captured underneath the rainbow at Apple Park.The viewer can look around at any angleand feel like they are right there beneath the rainbow.Everything looks just as it would if they were there in person.To achieve this, the 360° video is wrapped onto a spherecompletely surrounding the viewer,centred on their eyes and filling their field of view whichever way they look.A rectangular video frame, twice as wide as it is high,is used to achieve this, covering 360° of the scene across its widthand 180° across its height.This video is mapped onto a sphere around the viewerwith an equirectangular projection.This is like how a map of the world is drawn,where the north and south poles are stretched horizontally,to show a flat representation of a sphere.180° video’s projection is similar to 360° video, but for half a sphere.This is known as a half-equirectangular projection.Half-equirectangular videos are square and map their square video frameonto the half sphere in the same way 360° videos do for a full sphere.For stereo 180° video we simply have two squares of video, one for each eye.Many existing stereo 180° videos encode these two squares side-by-sidein a single pixel buffer that’s twice as wide as the resolution per eye.This is known as side-by-side or frame-packed encoding.However, there’s a lot of redundancy here.Because they’re two views of the same scene,the left and right eye images are very similar.Vision Pro takes advantage of this similarityto use a different approach for encoding stereo video,known as multiview encoding.Apple platforms already have hardware support for HEVC,or High Efficiency Video Coding, a fast modern codec for video compression.And so for stereo videos, we use MV-HEVC, or MultiView HEVC.For stereo video, MV-HEVC encodes each eye into its own pixel bufferand writes those two buffers together in a single video track.It takes advantage of the image similarityto compress one eye’s pixels relative to the other,encoding only the differences for the second eye.This gives a smaller encoded size for each frame,making stereo MV-HEVC videos smaller and more efficient.This is particularly important when streaming stereo video.To learn more about multiview encoding and MV-HEVC,check out “Deliver video content for spatial experiences” from WWDC23.Now, there’s a third kind of non-rectilinear videothat’s new in visionOS 26.Wide FOV video from action camerassuch as the GoPro HERO13 and Insta360 Ace Pro 2.These action cameras capture highly stabilized footageof whatever adventures you take them on.They capture a wide horizontal field of view,typically between 120° and 180°, and often use fisheye-like lensesthat show visible curvature of straight lines in the real world.This enables them to capture as much of the view as possible.Traditionally, these kinds of videos have been enjoyed on flat-screen deviceslike iPhone and iPad,and this is a fun way to relive the adventure.But in visionOS 26, we’re introducing a new formof immersive playback for these kinds of action cameras,recreating the unique wide-angle lens profile of each cameraas a curved surface in 3D space,and placing the viewer at the center of the action.Because that curved surface matches the camera’s lens profile,it effectively undoes the fisheye effect,and the viewer sees straight lines as straight,even at the edge of the image.This recreates the feeling of the real worldas captured by the wide-angle lens,while still displaying a maximum field of view.Wide FOV action cameras have lots of different modes,and the right mode to use depends on what you're shooting.Some modes prioritize the middle of the lens,for cases where that’s where the action is.Other modes prioritize the edges of the frameto capture as wide a field of view as possible.And there are many more permutations.To represent all of these different modes and lens configurations,we need a more expressive way to describe how the real world gets mapped topixels in an image.For this, we use math.Different lenses have different shapes and profiles.To model these different lens profiles,we define a bunch of parameters for things like the focal length, skew,and distortion of the lens.Camera and lens manufacturers can tailor these parametersto describe a wide variety of lenses,and how those lenses map the real world onto pixels in an image.Because it's defined by parameters,we call this projection a parametric immersive projection.In visionOS 26, these immersive video types,180°, 360°, and wide FOV video, are supported natively on visionOSvia a new QuickTime movie profile called Apple Projected Media Profile, or APMP.If you’ve already worked with QuickTime moviesand the spatial video format, this profile will feel very familiar,with new fields added to describe each of the new projection types.We’ve updated the Spatial and Immersive Media Format Edition specon developer.apple.com, to cover all of the details of this new profile.We’ve also added automatic conversion to APMP for many existing videos,both in files on Vision Pro and in your own app.Stereo 180° videos captured with Canon’s EOS VR systemand converted with the EOS VR Utility,are automatically converted to 180° APMP when opened on Vision Pro.360° videos from devices like the GoPro MAX and Insta360 X5are automatically converted to 360° APMP.180° and 360° videos that conform to the equirectangular versionof Google Spherical Video v1 or v2 are also detected and converted.And straight-off-the-camera videos from recent action camslike the GoPro HERO13 and Insta360 Ace Pro 2,are automatically converted to wide FOV APMP.The same is true for single-lens captures from the 360° cameras mentioned earlier.We’ve also updated the avconvert command-line tool on macOSto convert existing 180° and 360° content to APMP on Mac.Just like spatial videos, APMP can be played on visionOS 26by all of Apple’s media playback frameworks,with support for HTTP Live Streaming.Note that APMP content is supported for expanded and immersive playback,but not for embedded inline playback.Playing video immersively puts the viewer’s headright where the camera was during capture,even if that camera was strapped to the end of a surfboard.This means that immersive playback is especially sensitive to camera motion.To help mitigate this, we’ve added automatic high motion detectionin QuickLook, AVKit, and RealityKit.Playback will automatically reduce immersion when high motion is detected,which can be more comfortable for the viewer during high motion scenes.There are options in the Settings app to customize high motion detectionto match the viewer’s personal level of motion sensitivity.To dive even deeper into the new Apple Projected Media Profile,including how to read and write it for your own content,check out “Learn about the Apple Projected Media Profile”.Now, for the ultimate immersive experience, there’s Apple Immersive Video,which we’re making available to developers and content creatorsfor the first time this year.Here’s an example from the Apple TV+ series, “Wild Life”,which transports viewers to meet the elephantsat Kenya’s Sheldrick Wildlife Trust.This scene would be almost impossible to experience in reality,but with Apple Immersive Video, it feels like you're truly there.If you’re working with the Blackmagic URSA Cine Immersive camera,you can create, edit and distribute Apple Immersive Video yourself.The specs for the URSA Cine Immersive camera are astounding.Every lens in every camera is individually calibrated at the factory,using the parametric approach we saw earlier,but tuned to that individual lens.The Cine Immersive captures stereo video with 8160 x 7200 pixels per eye.That’s 59 megapixels per eye, at 90 frames per second.That’s over 10 billion pixels per second.The URSA Cine Immersive captures up to 210° FOV horizontally,and 180° vertically,with a sharpness approaching that of the human eye.In visionOS 26, your app can play Apple Immersive Videowith all the same media frameworks as APMP,with support for HTTP Live Streaming.Like APMP,Apple Immersive Content is supported for expanded and immersive playback,but not for embedded inline playback.So how do creators bring their Apple Immersive content to Vision Pro?There are four main steps in the content creation pipeline.First, capture video on the URSA Cine immersive camera.Next, edit that video in DaVinci Resolve Studio.Then preview and validate content using the newApple Immersive Video Utility apps for macOS and visionOS.And finally, segment content in Compressor for distribution via HTTP Live Streaming.For pro app developers who want to create their own toolsto work with Apple Immersive Video,such as a non-linear editor, or a custom pipeline tool,we’re introducing the ImmersiveMediaSupport frameworkfor macOS and visionOS 26.This framework enables you to read and writeApple Immersive content programmatically.And there are many more capabilities of Apple Immersive Videothat are unique to the format,including per-shot edge blends, custom backdrop environments,the new Apple Spatial Audio Format, and live preview on Apple Vision Pro.Let’s dig a little deeper into just one of these, per-shot edge blends.Every shot in an Apple Immersive Videocan define a custom edge blend curve that best suits its content and framing.This isn’t a baked-in mask.It’s a dynamic alpha blend curve that feathers the edges of the shotto transition it into a custom backdrop environment.And that’s just a flavor of what’s possible with Apple Immersive Video.Check out “Learn about Apple Immersive Video technologies” for more information.Let’s finish by taking a look at all of these media profiles together,to help decide which ones are right for your app’s experience.To recap, we have 2D and 3D video presented on a flat screen,spatial video, where stereo video is inset behind a flat screenfor windowed presentationand shown at true scale when immersive,180° and 360° video projected onto a half sphere, and a full sphere,wide FOV video with a curved meshthat matches the projection of a wide angle lens from an action cam,and Apple Immersive Video, with high resolution stereo video,perfectly calibrated to each lens in the camera that captured it.Here are all the fundamentals for these different video profiles,including how they can be captured, their visual characteristics,their horizontal field of view, and their projection type.Note that 180°, 360°, and wide FOV videos can be mono or stereo.Typically 180° is stereo, and 360° and wide FOV are mono.And here’s a reminder of how all of the different profilescan be presented during playback.Note that high motion detection is automatically enabledfor all three APMP profiles.And 2D, 3D, and spatial videosall offer 2D playback when embedded in line,because of their rectilinear projection.Vision Pro enables so many exciting video playback experiences,from new ways to experience 2D and 3D video,to new types of media that only make sense on a spatial computing platform.To get started with all these video profiles,check out our new immersive playback sample code projectsfor AVKit and RealityKit,and new sample code projects for writing and working with APMPand Apple Immersive Video.We’ve also provided example video downloads  and HLS streamsfor spatial, 180°, 360°, wide FOV and Apple Immersive Video,available from developer.apple.com.For more information, check out related video sessionson immersive video playback, Apple Projected Media Profile,and Apple Immersive Video.And how to play all these media types on the spatial web in Safari and WebKit.And now: Go... immerse!

Hi, I’m Dave, an engineer on the visionOS Spatial Media team.Today, we’re going to explore all of the different typesof video media available on visionOS, including some new ones in visionOS 26.Vision Pro is a spatial computer that shows high quality pass-through videoof the surrounding world.Because Vision Pro is with you wherever you look,content creators have an entire 360° around the viewerin which they can present engaging content.They’re not just limited to a flat screen in front of the viewer.This enables a wide range of media playback options,some of which are only possible on a spatial computer.Let's take a look.We’ll start by exploring how 2D and 3D videocan be presented on visionOS,including some cool new features coming in visionOS 26.We'll see how spatial video enables people to capture their own stereo videos,and some new ways you can play those videos in your app.

We’ll learn about new immersive video formatsfor 180°, 360°, and wide FOV video.

And for the ultimate immersive experience, there's Apple Immersive Video.We’ll see how you can now create your own Apple Immersive content and tooling.Finally, we’ll explore how all these different video profiles compareto help you choose the right one for your app.Let's get started with 2D and 3D video.Vision Pro is a great device for enjoying 2D movies and TV shows,and as a stereo device, it’s perfect for watching stereoscopic 3D movies too.2D videos can be played inline anywhere in your app’s UIusing an embedded playback experience,where the video appears alongside other UI elements.

Here’s an example of playing video inline in freeformas part of a board full of content.

Note that if you embed a 3D video inline, it gracefully falls back to playing in 2D.

And both 2D and 3D video can be played in an expanded experienceon a floating screen in the shared space.Note that an expanded experience is requiredto play a 3D movie stereoscopically.

2D and 3D video can also transition to a docked state in a virtual environment.

Here’s an example from the Destination Video sample code project,available from developer.apple.com,where the video fades out from its expanded view and fades back in,docked within the app’s own custom studio environment,created with Reality Composer Pro.The video automatically shows dynamic light spillto make it feel like an integral part of that environment.

Docking in an environment is a great exampleof how spatial computing enables video playbackto move beyond the bounds of a fixed single screen.And there are even more ways that 2D and 3D video playbackcan take advantage of Vision Pro’s infinite canvas.

visionOS 2 introduced multi-view video,where viewers can enjoy multiple camera angles of a single eventor multiple sources of video simultaneously in Vision Pro.

A new in visionOS 26, 2D and 3D videos can specify a per-frame dynamic maskto change or animate their frame size and aspect ratio,to accentuate a story point,or to combine archival and modern-day footage in a single scene,without needing to show black bars for letterboxing or pillarboxing.

These kinds of seamless transitions, with a framing that best suits each shot,are only possible on a spatial computer.

For more information, see the “Rectangular Mask Payload Metadata”document on developer.apple.com.

3D video is the medium of choice for professional stereo productionsdesigned to be viewed on a big screen.But stereo video doesn’t have to require a movie studio.Vision Pro supports a new kind of stereo mediathat people can capture themselves, known as Spatial Video.People can shoot comfortable, compelling stereo contenton devices like iPhonewithout needing to be an expert in the rules of 3D filmmaking.

Spatial video is stereo video with additional metadata,that enables windowed and immersive treatments on Vision Proto mitigate common causes of stereo discomfort.

By default, spatial video renders through a window,with a faint glow around the edges.It can also expand into an immersive presentation,where the content is scaled to match the real size of objects.The edge of the frame disappears,and the content blends seamlessly into the real world.

Spatial videos automatically fall back to 2D presentation on other platforms,enabling them to be played on all Apple devices.This enables people to capture spatial content to enjoy on Vision Pro,and still share their memories in 2Dwith friends and family who don’t yet have a Vision Pro.

We saw earlier how 2D and 3D video is presented on a flat screen.For spatial videos, we inset that flat screenbehind a window and blur the edges of the window to soften them.This helps avoid issues when an object is clipped by the windowmore in one eye than the other, which can be uncomfortable to view.

Spatial videos can be captured today oniPhone 15 Pro, iPhone 16, and iPhone 16 Pro,in the Camera app and in your own app via AVCaptureDevice APIs.Spatial videos can also be captured on Apple Vision Proand, with Canon’s R7 and R50 cameras with a Canon DUAL lens.

In visionOS 2, spatial videos can be playedwith spatial styling  in your own appwith the QuickLook PreviewApplication API.In visionOS 26, we’re bringing that same spatial stylingto all of Apple’s media playback frameworks.We’re adding QLPreviewController support in QuickLook,plus support in AVKit, RealityKit, Safari, and WebKit,enabling you to incorporate spatial videos however you choose in your app,with support for HTTP Live Streaming, or HLS.

And if you’re looking to edit and combine spatial videos in your appto create a longer narrative,the format is now supported in industry standard editing tools,such as Compressor, DaVinci Resolve Studio, and Final Cut Pro.To see more examples of what’s possible with spatial videosand spatial photos as well,check out the Spatial Gallery app on Vision Pro.To learn more about the spatial photo and video formats,check out “Build compelling spatial photo and video experiences” from WWDC24.And for more about the new ways you can play spatial videos in your app,check out “Support immersive video playback in visionOS apps”.And talking of spatial photos, there’s new RealityKit API in visionOS 26for displaying spatial photos in your appand for converting 2D photos to a 3D spatial scene.

To learn how to present spatial photos and generate spatial scenesusing the new ImagePresentationComponent and Spatial3DImage APIs,check out “What’s new in RealityKit”.

We saw earlier how 2D, 3D, and spatial videosare all played on a flat surface in Vision Pro.This is because these videos typically use what's known as a rectilinear projection,as seen in this photo of the Apple Park Visitor center.Rectilinear just means that straight lines are straight.There’s no lens curvature or warping in the video.And because of this, these kinds of videos feel correctwhen viewed on a flat surfacethat also doesn’t have any curvature or warping.

We saw how the playback experience for these rectilinear videos on Vision Proexpands that flat surface to fill more of the viewer’s field of view,via docking for 2D and 3D video,and immersive presentation for spatial video.

But on a spatial computing device,we’re not just restricted to a flat surface in front of the viewer.There’s even more space around them we can fill with pixels.And there are other non-rectilinear video typesthat are great for filling even more of the viewer’s field of view,by presenting video on a curved surface, not a flat one.visionOS 26 adds native support for three of these non-rectilinear media types:180° video, 360° video, and wide FOV video.Let's take a look.180° video is presented on a half sphere directly in front of the viewer.Video is projected onto that half sphereto completely fill the viewer’s forward field of view.In this example, it’s a 180° video of the pond at Apple Park.

From the viewer’s point of view, it’s like being there.This is a great way for content creatorsto transport their viewers to amazing locations.180° video is typically captured in stereo.And because it’s stereo, and completely fills your forward field of view,it feels like you’re looking at the real thing.

360° video takes things a step further, filling the entire world with content.With 360° video, the content literally surrounds the viewer,giving them the freedom to look wherever they like.Here’s an example of a 360° video captured underneath the rainbow at Apple Park.The viewer can look around at any angleand feel like they are right there beneath the rainbow.Everything looks just as it would if they were there in person.

To achieve this, the 360° video is wrapped onto a spherecompletely surrounding the viewer,centred on their eyes and filling their field of view whichever way they look.

A rectangular video frame, twice as wide as it is high,is used to achieve this, covering 360° of the scene across its widthand 180° across its height.This video is mapped onto a sphere around the viewerwith an equirectangular projection.This is like how a map of the world is drawn,where the north and south poles are stretched horizontally,to show a flat representation of a sphere.

180° video’s projection is similar to 360° video, but for half a sphere.This is known as a half-equirectangular projection.Half-equirectangular videos are square and map their square video frameonto the half sphere in the same way 360° videos do for a full sphere.

For stereo 180° video we simply have two squares of video, one for each eye.

Many existing stereo 180° videos encode these two squares side-by-sidein a single pixel buffer that’s twice as wide as the resolution per eye.This is known as side-by-side or frame-packed encoding.However, there’s a lot of redundancy here.Because they’re two views of the same scene,the left and right eye images are very similar.Vision Pro takes advantage of this similarityto use a different approach for encoding stereo video,known as multiview encoding.

Apple platforms already have hardware support for HEVC,or High Efficiency Video Coding, a fast modern codec for video compression.

And so for stereo videos, we use MV-HEVC, or MultiView HEVC.

For stereo video, MV-HEVC encodes each eye into its own pixel bufferand writes those two buffers together in a single video track.It takes advantage of the image similarityto compress one eye’s pixels relative to the other,encoding only the differences for the second eye.This gives a smaller encoded size for each frame,making stereo MV-HEVC videos smaller and more efficient.This is particularly important when streaming stereo video.

To learn more about multiview encoding and MV-HEVC,check out “Deliver video content for spatial experiences” from WWDC23.

Now, there’s a third kind of non-rectilinear videothat’s new in visionOS 26.Wide FOV video from action camerassuch as the GoPro HERO13 and Insta360 Ace Pro 2.

These action cameras capture highly stabilized footageof whatever adventures you take them on.They capture a wide horizontal field of view,typically between 120° and 180°, and often use fisheye-like lensesthat show visible curvature of straight lines in the real world.This enables them to capture as much of the view as possible.

Traditionally, these kinds of videos have been enjoyed on flat-screen deviceslike iPhone and iPad,and this is a fun way to relive the adventure.But in visionOS 26, we’re introducing a new formof immersive playback for these kinds of action cameras,recreating the unique wide-angle lens profile of each cameraas a curved surface in 3D space,and placing the viewer at the center of the action.

Because that curved surface matches the camera’s lens profile,it effectively undoes the fisheye effect,and the viewer sees straight lines as straight,even at the edge of the image.This recreates the feeling of the real worldas captured by the wide-angle lens,while still displaying a maximum field of view.

Wide FOV action cameras have lots of different modes,and the right mode to use depends on what you're shooting.

Some modes prioritize the middle of the lens,for cases where that’s where the action is.

Other modes prioritize the edges of the frameto capture as wide a field of view as possible.And there are many more permutations.To represent all of these different modes and lens configurations,we need a more expressive way to describe how the real world gets mapped topixels in an image.For this, we use math.

Different lenses have different shapes and profiles.

To model these different lens profiles,we define a bunch of parameters for things like the focal length, skew,and distortion of the lens.Camera and lens manufacturers can tailor these parametersto describe a wide variety of lenses,and how those lenses map the real world onto pixels in an image.

Because it's defined by parameters,we call this projection a parametric immersive projection.

In visionOS 26, these immersive video types,180°, 360°, and wide FOV video, are supported natively on visionOSvia a new QuickTime movie profile called Apple Projected Media Profile, or APMP.If you’ve already worked with QuickTime moviesand the spatial video format, this profile will feel very familiar,with new fields added to describe each of the new projection types.

We’ve updated the Spatial and Immersive Media Format Edition specon developer.apple.com, to cover all of the details of this new profile.We’ve also added automatic conversion to APMP for many existing videos,both in files on Vision Pro and in your own app.

Stereo 180° videos captured with Canon’s EOS VR systemand converted with the EOS VR Utility,are automatically converted to 180° APMP when opened on Vision Pro.

360° videos from devices like the GoPro MAX and Insta360 X5are automatically converted to 360° APMP.

180° and 360° videos that conform to the equirectangular versionof Google Spherical Video v1 or v2 are also detected and converted.

And straight-off-the-camera videos from recent action camslike the GoPro HERO13 and Insta360 Ace Pro 2,are automatically converted to wide FOV APMP.

The same is true for single-lens captures from the 360° cameras mentioned earlier.We’ve also updated the avconvert command-line tool on macOSto convert existing 180° and 360° content to APMP on Mac.

Just like spatial videos, APMP can be played on visionOS 26by all of Apple’s media playback frameworks,with support for HTTP Live Streaming.

Note that APMP content is supported for expanded and immersive playback,but not for embedded inline playback.

Playing video immersively puts the viewer’s headright where the camera was during capture,even if that camera was strapped to the end of a surfboard.This means that immersive playback is especially sensitive to camera motion.To help mitigate this, we’ve added automatic high motion detectionin QuickLook, AVKit, and RealityKit.Playback will automatically reduce immersion when high motion is detected,which can be more comfortable for the viewer during high motion scenes.There are options in the Settings app to customize high motion detectionto match the viewer’s personal level of motion sensitivity.

To dive even deeper into the new Apple Projected Media Profile,including how to read and write it for your own content,check out “Learn about the Apple Projected Media Profile”.

Now, for the ultimate immersive experience, there’s Apple Immersive Video,which we’re making available to developers and content creatorsfor the first time this year.Here’s an example from the Apple TV+ series, “Wild Life”,which transports viewers to meet the elephantsat Kenya’s Sheldrick Wildlife Trust.This scene would be almost impossible to experience in reality,but with Apple Immersive Video, it feels like you're truly there.

If you’re working with the Blackmagic URSA Cine Immersive camera,you can create, edit and distribute Apple Immersive Video yourself.

The specs for the URSA Cine Immersive camera are astounding.Every lens in every camera is individually calibrated at the factory,using the parametric approach we saw earlier,but tuned to that individual lens.

The Cine Immersive captures stereo video with 8160 x 7200 pixels per eye.That’s 59 megapixels per eye, at 90 frames per second.

That’s over 10 billion pixels per second.

The URSA Cine Immersive captures up to 210° FOV horizontally,and 180° vertically,with a sharpness approaching that of the human eye.

In visionOS 26, your app can play Apple Immersive Videowith all the same media frameworks as APMP,with support for HTTP Live Streaming.Like APMP,Apple Immersive Content is supported for expanded and immersive playback,but not for embedded inline playback.So how do creators bring their Apple Immersive content to Vision Pro?There are four main steps in the content creation pipeline.

First, capture video on the URSA Cine immersive camera.Next, edit that video in DaVinci Resolve Studio.

Then preview and validate content using the newApple Immersive Video Utility apps for macOS and visionOS.And finally, segment content in Compressor for distribution via HTTP Live Streaming.

For pro app developers who want to create their own toolsto work with Apple Immersive Video,such as a non-linear editor, or a custom pipeline tool,we’re introducing the ImmersiveMediaSupport frameworkfor macOS and visionOS 26.This framework enables you to read and writeApple Immersive content programmatically.

And there are many more capabilities of Apple Immersive Videothat are unique to the format,including per-shot edge blends, custom backdrop environments,the new Apple Spatial Audio Format, and live preview on Apple Vision Pro.

Let’s dig a little deeper into just one of these, per-shot edge blends.

Every shot in an Apple Immersive Videocan define a custom edge blend curve that best suits its content and framing.

This isn’t a baked-in mask.It’s a dynamic alpha blend curve that feathers the edges of the shotto transition it into a custom backdrop environment.

And that’s just a flavor of what’s possible with Apple Immersive Video.Check out “Learn about Apple Immersive Video technologies” for more information.Let’s finish by taking a look at all of these media profiles together,to help decide which ones are right for your app’s experience.To recap, we have 2D and 3D video presented on a flat screen,spatial video, where stereo video is inset behind a flat screenfor windowed presentationand shown at true scale when immersive,180° and 360° video projected onto a half sphere, and a full sphere,wide FOV video with a curved meshthat matches the projection of a wide angle lens from an action cam,and Apple Immersive Video, with high resolution stereo video,perfectly calibrated to each lens in the camera that captured it.

Here are all the fundamentals for these different video profiles,including how they can be captured, their visual characteristics,their horizontal field of view, and their projection type.Note that 180°, 360°, and wide FOV videos can be mono or stereo.Typically 180° is stereo, and 360° and wide FOV are mono.

And here’s a reminder of how all of the different profilescan be presented during playback.Note that high motion detection is automatically enabledfor all three APMP profiles.And 2D, 3D, and spatial videosall offer 2D playback when embedded in line,because of their rectilinear projection.

Vision Pro enables so many exciting video playback experiences,from new ways to experience 2D and 3D video,to new types of media that only make sense on a spatial computing platform.To get started with all these video profiles,check out our new immersive playback sample code projectsfor AVKit and RealityKit,and new sample code projects for writing and working with APMPand Apple Immersive Video.We’ve also provided example video downloads  and HLS streamsfor spatial, 180°, 360°, wide FOV and Apple Immersive Video,available from developer.apple.com.For more information, check out related video sessionson immersive video playback, Apple Projected Media Profile,and Apple Immersive Video.And how to play all these media types on the spatial web in Safari and WebKit.And now: Go... immerse!

0:00 -IntroductionLearn about the different ways you can create and present immersive video experiences within your app. We’ll explore the diverse media types available in visionOS 26, including profiles for 180°, 360°, and wide FOV video; options for creating and playing Apple Immersive Video; and expanded capabilities for 2D, 3D, and spatial video.1:36 -2D and 3D videovisionOS offers versatile video playback capabilities for both 2D and 3D content. You can display videos inline within your app's interface, expanded in its own window, or docked within a custom environment. 

New in visionOS 26, per-frame dynamic masks enable videos to change size and aspect ratio seamlessly, enhancing storytelling and eliminating the need for letterboxing or pillarboxing.4:16 -Spatial videoSpatial Video is a stereo media format that you can capture using devices like iPhone 15 Pro, iPhone 16, iPhone 16 Pro, Apple Vision Pro, and specific third-party cameras. It's a great point-and-shoot format, and includes specific metadata to support more immersive presentations. In visionOS 26, you can integrate Spatial Video directly into your apps using new frameworks.8:10 -180°, 360°, and Wide FOV videovisionOS 26 introduces the new Apple Projected Media Profile (APMP) to support formats like 180°, 360°, and wide-field-of-view video. 

To enhance comfort during high-motion scenes, automatic high-motion detection is added, reducing immersion when necessary. Developers can find detailed information on how to work with APMP for their own content on Apple's developer website.19:25 -Apple Immersive VideoApple Immersive Video is a new format, available to developers and creators, that you can play back in your own apps and experiences. 

The content-creation pipeline involves capturing video on the URSA Cine camera, editing it in DaVinci Resolve Studio, previewing and validating it using new Apple Immersive Video Utility apps, and then segmenting it for distribution. You can also create custom tools to work with Apple Immersive Video using the ImmersiveMediaSupport framework.23:05 -Choosing a profileLearn the differences between the media profiles available on visionOS 26, including traditional 2D and 3D video, spatial video, APMP, and Apple Immersive Video. Each profile is detailed in terms of capture, visual characteristics, field of view, and projection type.

0:00 -Introduction

Learn about the different ways you can create and present immersive video experiences within your app. We’ll explore the diverse media types available in visionOS 26, including profiles for 180°, 360°, and wide FOV video; options for creating and playing Apple Immersive Video; and expanded capabilities for 2D, 3D, and spatial video.

Learn about the different ways you can create and present immersive video experiences within your app. We’ll explore the diverse media types available in visionOS 26, including profiles for 180°, 360°, and wide FOV video; options for creating and playing Apple Immersive Video; and expanded capabilities for 2D, 3D, and spatial video.

1:36 -2D and 3D video

visionOS offers versatile video playback capabilities for both 2D and 3D content. You can display videos inline within your app's interface, expanded in its own window, or docked within a custom environment. 

New in visionOS 26, per-frame dynamic masks enable videos to change size and aspect ratio seamlessly, enhancing storytelling and eliminating the need for letterboxing or pillarboxing.

visionOS offers versatile video playback capabilities for both 2D and 3D content. You can display videos inline within your app's interface, expanded in its own window, or docked within a custom environment. 

New in visionOS 26, per-frame dynamic masks enable videos to change size and aspect ratio seamlessly, enhancing storytelling and eliminating the need for letterboxing or pillarboxing.

4:16 -Spatial video

Spatial Video is a stereo media format that you can capture using devices like iPhone 15 Pro, iPhone 16, iPhone 16 Pro, Apple Vision Pro, and specific third-party cameras. It's a great point-and-shoot format, and includes specific metadata to support more immersive presentations. In visionOS 26, you can integrate Spatial Video directly into your apps using new frameworks.

Spatial Video is a stereo media format that you can capture using devices like iPhone 15 Pro, iPhone 16, iPhone 16 Pro, Apple Vision Pro, and specific third-party cameras. It's a great point-and-shoot format, and includes specific metadata to support more immersive presentations. In visionOS 26, you can integrate Spatial Video directly into your apps using new frameworks.

8:10 -180°, 360°, and Wide FOV video

visionOS 26 introduces the new Apple Projected Media Profile (APMP) to support formats like 180°, 360°, and wide-field-of-view video. 

To enhance comfort during high-motion scenes, automatic high-motion detection is added, reducing immersion when necessary. Developers can find detailed information on how to work with APMP for their own content on Apple's developer website.

visionOS 26 introduces the new Apple Projected Media Profile (APMP) to support formats like 180°, 360°, and wide-field-of-view video. 

To enhance comfort during high-motion scenes, automatic high-motion detection is added, reducing immersion when necessary. Developers can find detailed information on how to work with APMP for their own content on Apple's developer website.

19:25 -Apple Immersive Video

Apple Immersive Video is a new format, available to developers and creators, that you can play back in your own apps and experiences. 

The content-creation pipeline involves capturing video on the URSA Cine camera, editing it in DaVinci Resolve Studio, previewing and validating it using new Apple Immersive Video Utility apps, and then segmenting it for distribution. You can also create custom tools to work with Apple Immersive Video using the ImmersiveMediaSupport framework.

Apple Immersive Video is a new format, available to developers and creators, that you can play back in your own apps and experiences. 

The content-creation pipeline involves capturing video on the URSA Cine camera, editing it in DaVinci Resolve Studio, previewing and validating it using new Apple Immersive Video Utility apps, and then segmenting it for distribution. You can also create custom tools to work with Apple Immersive Video using the ImmersiveMediaSupport framework.

23:05 -Choosing a profile

Learn the differences between the media profiles available on visionOS 26, including traditional 2D and 3D video, spatial video, APMP, and Apple Immersive Video. Each profile is detailed in terms of capture, visual characteristics, field of view, and projection type.

Learn the differences between the media profiles available on visionOS 26, including traditional 2D and 3D video, spatial video, APMP, and Apple Immersive Video. Each profile is detailed in terms of capture, visual characteristics, field of view, and projection type.

## Code Samples

