WEBVTT

00:00:08.300 --> 00:00:09.360
My name is Brad Ford.

00:00:09.610 --> 00:00:13.380
I'm a media engineer on the
iPhone engineering team.

00:00:13.870 --> 00:00:15.300
Let's dive right in.

00:00:15.370 --> 00:00:17.060
Here's what you'll learn today.

00:00:17.220 --> 00:00:20.860
Why and when you should use
AV Foundation capture APIs,

00:00:20.860 --> 00:00:24.160
as opposed to some of the other
options we have on the platform.

00:00:24.230 --> 00:00:27.800
The AV Foundation capture
programming model.

00:00:27.870 --> 00:00:31.360
And throughout this presentation,
I'll be peppering the demos and

00:00:31.400 --> 00:00:35.970
the talk with performance hints,
gotchas, things that you should be

00:00:35.970 --> 00:00:38.310
aware of when using the camera.

00:00:39.370 --> 00:00:42.000
We have four demos that we're
going to show you today.

00:00:42.080 --> 00:00:45.900
All of these apps are
available right now.

00:00:45.940 --> 00:00:49.680
If you were a crazy person,
you could log into the website,

00:00:49.820 --> 00:00:53.030
you could download the apps,
you could compile them,

00:00:53.240 --> 00:00:56.150
and put them on your phone,
and you could follow along with me,

00:00:56.300 --> 00:00:58.490
but only if you're crazy.

00:01:00.770 --> 00:01:03.900
Again, for those who've been here
with us this afternoon,

00:01:03.900 --> 00:01:06.160
you've seen this,
this is the third time now.

00:01:06.230 --> 00:01:08.700
But here's where we sit in
the technology hierarchy.

00:01:08.700 --> 00:01:11.760
Our framework that we're talking
about today is AV Foundation.

00:01:11.760 --> 00:01:14.400
It sits below the thin blue line.

00:01:14.400 --> 00:01:19.260
That is, it does not link against or
have dependencies on UIKit.

00:01:19.270 --> 00:01:24.320
It purposely sits lower in the
framework so that it is lean and mean.

00:01:25.220 --> 00:01:29.220
Most of the heavy lifting done by
AV Foundation is actually accomplished

00:01:29.230 --> 00:01:32.830
by lower-level core frameworks,
core audio, core animation,

00:01:32.830 --> 00:01:33.940
and core media.

00:01:33.940 --> 00:01:36.120
Chief among these is core media.

00:01:36.120 --> 00:01:42.140
Core media is a new public
C interface framework in iOS 4.

00:01:42.140 --> 00:01:45.720
It's core foundation-based,
which means the objects have the

00:01:45.720 --> 00:01:49.150
same semantics you're used to,
CF retain and CF release.

00:01:49.260 --> 00:01:54.370
Core media is where the power
of AV Foundation derives from.

00:01:56.280 --> 00:01:58.840
Let's step back and talk
about shipping software,

00:01:58.890 --> 00:02:00.850
iPhone OS 3.

00:02:00.960 --> 00:02:03.820
There we have a simple
programmatic access,

00:02:03.820 --> 00:02:07.020
and let's see by show of hands
who has an app in the app

00:02:07.020 --> 00:02:09.350
store that uses the camera.

00:02:09.450 --> 00:02:10.640
Wow, quite a few of you.

00:02:10.710 --> 00:02:13.270
All of you are using UI Image Picker
Controller in some way.

00:02:13.270 --> 00:02:16.120
That's because there
were no other options.

00:02:16.580 --> 00:02:21.470
UI Image Picker Controller is how
we do simple things for recording,

00:02:21.470 --> 00:02:25.460
like choose high, medium,
or low quality for recording.

00:02:25.460 --> 00:02:28.440
We give you that little
hideable camera controls UI,

00:02:28.510 --> 00:02:30.820
the same that you see in the camera app.

00:02:30.900 --> 00:02:36.800
That lets you do things like toggle the
photo movie button showing or hidden,

00:02:36.800 --> 00:02:39.060
and it lets you take photos.

00:02:39.060 --> 00:02:41.890
There's actually an API for that.

00:02:42.100 --> 00:02:44.760
But you do have to use the control
overlay for doing things like

00:02:44.760 --> 00:02:46.220
starting or stopping recording.

00:02:46.340 --> 00:02:47.590
We can't do that programmatically.

00:02:47.710 --> 00:02:51.670
And if you want to do touch to focus,
that's just up to the

00:02:51.670 --> 00:02:53.160
users using that UI view.

00:02:55.060 --> 00:03:00.150
The good news is, in iOS 4,
UI Image Picker Controller has

00:03:00.160 --> 00:03:01.870
gotten a substantial upgrade.

00:03:02.090 --> 00:03:03.720
We offer more control there.

00:03:03.960 --> 00:03:07.740
There's now API for starting
and stopping movie recording,

00:03:07.810 --> 00:03:10.720
so you don't have to use our stock UI.

00:03:10.760 --> 00:03:15.720
You also get the same high resolution
still image capture as you would expect.

00:03:15.790 --> 00:03:19.820
But new in iPhone 4 are
additional camera capabilities,

00:03:19.850 --> 00:03:22.620
like access to the flash.

00:03:22.670 --> 00:03:25.330
You also get switching between
front and back cameras.

00:03:25.490 --> 00:03:28.720
All of this is available
at the high level UI kit,

00:03:28.760 --> 00:03:32.370
UI Image Picker Controller API level.

00:03:33.400 --> 00:03:35.810
But for those of you
power junkies out there,

00:03:35.810 --> 00:03:41.420
you might want to use AV Foundation for
capture because it lets you go deeper.

00:03:41.770 --> 00:03:43.690
Full access to the camera.

00:03:43.770 --> 00:03:46.880
Steve promised it,
and we think we've delivered it.

00:03:47.430 --> 00:03:49.800
What do we mean when we say
full access to the camera?

00:03:49.800 --> 00:03:54.260
We mean independent focus, exposure,
and white balance controls.

00:03:54.280 --> 00:03:56.380
Independent locking.

00:03:57.020 --> 00:04:00.500
Independent points of interest
for focus and exposure.

00:04:00.610 --> 00:04:03.200
Let's say you're developing
an HDR application.

00:04:03.330 --> 00:04:09.490
You can set focus to a
given point on your video,

00:04:09.510 --> 00:04:13.680
and then keep that composed and locked
while you set different exposure

00:04:13.680 --> 00:04:17.370
values and take multiple pictures
and then stitch them together.

00:04:17.870 --> 00:04:22.020
We also give you probably the number
one most requested feature in iPhone

00:04:22.020 --> 00:04:25.820
OS 3 with regards to the camera,
which was access to video frame

00:04:25.820 --> 00:04:29.440
data in your process per frame data.

00:04:29.670 --> 00:04:31.710
But we don't just give you the data,
we actually also give

00:04:31.710 --> 00:04:34.750
you accurate timestamps,
so you know exactly when those

00:04:34.880 --> 00:04:37.200
frames came in and hit the sensor.

00:04:37.260 --> 00:04:39.660
We give you per frame metadata,
so you know interesting

00:04:39.660 --> 00:04:46.490
things about those frames,
like the f-stop and the exposure level.

00:04:47.520 --> 00:04:51.220
We give you configurable output formats,
for instance, 4:2:0V,

00:04:51.220 --> 00:04:55.110
a bi-planar YUV format, or BGRA,
if you're going to be doing some

00:04:55.110 --> 00:04:59.240
rendering using Core Graphics or OpenGL.

00:04:59.270 --> 00:05:01.720
We also let you configure
the max frame rate.

00:05:01.730 --> 00:05:05.880
Maybe 30 frames per second is too much,
or more than your application needs,

00:05:05.890 --> 00:05:08.680
and 15 frames per second is just fine,
thank you.

00:05:08.690 --> 00:05:11.900
We let you throttle the
frame rate if you need to.

00:05:11.910 --> 00:05:15.330
We also let you configure the resolution,
so you can get a full

00:05:15.460 --> 00:05:19.040
720p if you need that,
but if your processing

00:05:19.040 --> 00:05:22.240
algorithm needs less,
you can get more CPU back for

00:05:22.240 --> 00:05:25.890
your interesting processing that
you're going to do by asking

00:05:25.890 --> 00:05:30.250
for it at a lower resolution,
for instance, 480 by 360.

00:05:30.740 --> 00:05:32.540
We also give you flexible output.

00:05:32.560 --> 00:05:36.780
These are new features that you won't
find at the higher level in our UI stack.

00:05:36.850 --> 00:05:40.720
For still image output,
we give you not just JPEG,

00:05:41.010 --> 00:05:44.000
but in addition to that,
you get YUV and RGB output.

00:05:44.060 --> 00:05:46.620
Think of that:
access to the full 5 megapixel

00:05:46.620 --> 00:05:49.340
images from the camera,
but uncompressed.

00:05:49.450 --> 00:05:53.890
So you can do a lot of processing with
those and do great things with them.

00:05:53.950 --> 00:05:56.200
We're interested to see
what you'll come up with.

00:05:56.260 --> 00:06:01.800
You also get EXIF metadata insertion,
so you can insert your own custom tags.

00:06:01.990 --> 00:06:03.440
As you would expect, we do recording.

00:06:03.590 --> 00:06:05.360
We record QuickTime movies.

00:06:05.580 --> 00:06:08.900
We allow you to insert your
own movie-level metadata.

00:06:09.050 --> 00:06:12.820
And we also let you control
the presentation of the movie.

00:06:12.960 --> 00:06:16.120
For instance, doing an orientation lock.

00:06:16.640 --> 00:06:19.900
What if you had an app, for instance,
that's only a landscape app?

00:06:20.090 --> 00:06:22.670
You don't want to allow them
to turn it portrait because

00:06:22.740 --> 00:06:23.960
you don't want portrait movies.

00:06:24.060 --> 00:06:26.690
We allow you to lock the
orientation of the recorded

00:06:26.690 --> 00:06:29.410
movie so they are all landscape,
for instance.

00:06:29.660 --> 00:06:33.520
We also give you access to video preview,
not in a UI view,

00:06:33.590 --> 00:06:35.740
but in a core animation layer.

00:06:35.790 --> 00:06:38.010
That means it's performant
like core animation.

00:06:38.110 --> 00:06:40.530
It lets you insert this layer
into a rendering tree like any

00:06:40.530 --> 00:06:41.940
other core animation layer.

00:06:41.940 --> 00:06:44.110
And we give you some
interesting features there,

00:06:44.110 --> 00:06:47.300
one of which is video gravity,
and we'll talk more about that later.

00:06:47.300 --> 00:06:50.450
But that lets you control how
the video stretches or fits or

00:06:50.450 --> 00:06:52.380
fills that video preview layer.

00:06:53.560 --> 00:06:58.000
We also give you audio level metering
and access to audio sample data as well.

00:06:58.000 --> 00:07:04.120
This is the only Objective-C API in
our stack that gives you access

00:07:04.120 --> 00:07:07.610
to audio samples in your process.

00:07:08.750 --> 00:07:11.460
All right,
let's start with capture basics.

00:07:11.480 --> 00:07:13.550
What might you want to
do if you have an iPhone?

00:07:13.670 --> 00:07:17.700
I'm going to go out on a limb and venture
that most of you have an iPhone here.

00:07:17.700 --> 00:07:19.500
So let's say you have an iPhone.

00:07:19.510 --> 00:07:21.460
It has a camera on the back.

00:07:21.480 --> 00:07:23.460
What kinds of things might
you want to do with it?

00:07:23.470 --> 00:07:27.280
Well, you might want to preview what
you're seeing from the camera

00:07:27.370 --> 00:07:29.120
to a core animation layer.

00:07:29.130 --> 00:07:32.880
You might want to take
high quality still images.

00:07:32.910 --> 00:07:35.990
You might want to get
individual video frames into

00:07:35.990 --> 00:07:38.460
your process and process them.

00:07:38.480 --> 00:07:41.270
you might want to record
to a QuickTime movie.

00:07:41.590 --> 00:07:44.760
Now that camera is not
the only input you have.

00:07:45.020 --> 00:07:48.290
There's of course one high
quality back facing camera,

00:07:48.320 --> 00:07:51.360
and in a couple weeks I'm sure you'll
all have newer phones that have

00:07:51.360 --> 00:07:53.780
two high quality cameras on them.

00:07:54.130 --> 00:07:58.040
There's also a built-in microphone,
and the microphone is another input

00:07:58.110 --> 00:08:00.540
that we can use for doing capture.

00:08:00.610 --> 00:08:03.090
You can get those audio samples
directly into your process

00:08:03.430 --> 00:08:06.320
for additional processing,
or you can write those audio

00:08:06.320 --> 00:08:08.440
samples to a QuickTime movie.

00:08:08.520 --> 00:08:12.490
All of these capture scenarios
are provided for in our

00:08:12.490 --> 00:08:15.190
API using a hierarchy of classes.

00:08:15.300 --> 00:08:18.370
Let's look at what this
looks like to AV Capture.

00:08:18.540 --> 00:08:24.280
The center of the AV Capture universe
is the AV Capture Session object.

00:08:24.340 --> 00:08:27.140
The session is your central hub.

00:08:27.190 --> 00:08:29.770
It's where you,
it controls the flow of data.

00:08:30.070 --> 00:08:33.330
It's where you add inputs and outputs.

00:08:33.560 --> 00:08:37.400
Each of those sources that
I talked about is represented in

00:08:37.400 --> 00:08:40.630
the API as an AV capture input.

00:08:41.610 --> 00:08:45.640
Each of those outputs I talked
about are AV capture outputs.

00:08:45.740 --> 00:08:48.200
The preview layer is a little
bit different because it is a

00:08:48.200 --> 00:08:51.300
subclass of core animation layer,
CA layer.

00:08:51.740 --> 00:08:53.730
It behaves a little bit
differently and plugs into the

00:08:53.790 --> 00:08:56.170
session a little bit differently,
so it's a special case.

00:08:56.330 --> 00:08:58.380
We'll take care of it separately.

00:08:58.580 --> 00:09:02.810
But this is what, from the high level,
AV capture looks like.

00:09:03.230 --> 00:09:06.780
The rest of the talk is going to be
devoted to four common usage cases.

00:09:06.880 --> 00:09:10.440
The first one, processing YUV video
frames from the camera,

00:09:10.590 --> 00:09:14.220
controlling the camera, taking photos,
recording movies,

00:09:14.370 --> 00:09:18.020
previewing video from the camera
to a core animation layer,

00:09:18.110 --> 00:09:20.980
and finally,
processing PCM audio data from

00:09:20.980 --> 00:09:23.620
the microphone to draw waveform.

00:09:23.730 --> 00:09:27.960
Let's tackle that first one first,
since that was the most requested feature

00:09:27.960 --> 00:09:31.120
in iPhone OS 3 with regards to camera.

00:09:31.210 --> 00:09:31.940
Let's do a demo.

00:09:32.070 --> 00:09:33.810
This one's called Find My Icone.

00:09:34.060 --> 00:09:37.510
I'd like to invite up Matthew Calhoun,
who's going to help me with this demo.

00:09:37.740 --> 00:09:41.240
You see before me a cone, a traffic cone.

00:09:41.350 --> 00:09:46.670
You're probably asking yourself the
same question I've been asking myself.

00:09:46.770 --> 00:09:52.500
You know, how many times have I found my
cone missing and wished that I had

00:09:52.510 --> 00:09:55.000
an application to find my Icone?

00:09:55.430 --> 00:09:59.140
Well, now we've provided it in this talk.

00:09:59.210 --> 00:10:05.280
As you can see, he's running a preview,
and he found the cone.

00:10:05.630 --> 00:10:09.970
He sampled the cone's colors,
and he's looking for a range of pixels

00:10:10.030 --> 00:10:12.260
that are close to that color orange.

00:10:12.280 --> 00:10:15.260
And when he finds it,
when he finds a threshold of 10,

00:10:15.290 --> 00:10:16.620
he draws a rectangle around it.

00:10:16.750 --> 00:10:18.620
So he's finding the cone.

00:10:18.650 --> 00:10:20.240
He's drawing that little
rectangle around it.

00:10:20.240 --> 00:10:21.960
You see it move with the cone.

00:10:22.000 --> 00:10:25.620
And when I hide the cone-- oops,
it went away.

00:10:25.630 --> 00:10:26.740
Bring the cone back.

00:10:26.740 --> 00:10:28.440
Oh, there it is again.

00:10:28.460 --> 00:10:31.340
This isn't just a cutesy little demo app.

00:10:31.350 --> 00:10:33.010
This has a real world application.

00:10:33.020 --> 00:10:38.150
I mean, think if you were in a bar,
and your cone happened to

00:10:38.150 --> 00:10:40.160
fall out of your pocket.

00:10:40.370 --> 00:10:44.530
You would really want an
app to find your icon.

00:10:47.810 --> 00:10:48.800
So find my icon.

00:10:48.800 --> 00:10:50.360
How do we do that?

00:10:50.470 --> 00:10:53.420
We started with the camera.

00:10:53.600 --> 00:10:59.320
And it's outputting video frames to
the client process to the application.

00:10:59.620 --> 00:11:01.680
It's also using a video preview layer.

00:11:01.680 --> 00:11:03.970
And we saw that running
at full resolution,

00:11:04.020 --> 00:11:05.620
1280 by 720.

00:11:05.740 --> 00:11:07.220
And it was very smooth.

00:11:07.400 --> 00:11:08.940
Wasn't dropping any frames at all.

00:11:09.090 --> 00:11:11.310
But he's doing processing
on the background.

00:11:11.400 --> 00:11:13.870
When he finds that
pattern and matches to it,

00:11:13.990 --> 00:11:18.140
he superimposes the rectangle on
top of his core animation layer.

00:11:18.230 --> 00:11:21.190
And we see where the icon is.

00:11:21.310 --> 00:11:24.250
What does this look like to
AV Foundation's capture objects?

00:11:24.500 --> 00:11:26.860
Well, again,
you have a session in the middle.

00:11:27.080 --> 00:11:32.480
You have a concrete subclass of
AV capture input on the source side.

00:11:32.780 --> 00:11:36.000
And that is an AV capture device input.

00:11:36.060 --> 00:11:40.530
Each device on the system is
represented as an AV capture device.

00:11:40.880 --> 00:11:45.240
On an iPhone 3GS, there are two devices,
one for the camera,

00:11:45.310 --> 00:11:46.270
one for the built-in microphone.

00:11:46.350 --> 00:11:49.650
On an iPhone 4,
there will be three devices,

00:11:49.750 --> 00:11:52.780
one for the back-facing camera,
one for the front-facing camera,

00:11:52.790 --> 00:11:54.800
one for the built-in mic.

00:11:55.790 --> 00:11:59.390
He also used a concrete subclass
of AV Capture output called

00:11:59.390 --> 00:12:01.360
AV Capture Video Data Output.

00:12:01.490 --> 00:12:04.460
This will be your friend if you
want to do video processing.

00:12:04.630 --> 00:12:07.900
From this video data output,
he gets delegate callbacks,

00:12:07.990 --> 00:12:11.730
each providing a sample
buffer with a video frame.

00:12:11.860 --> 00:12:17.320
He also used an AV Capture video preview
layer to draw the video to the screen and

00:12:17.320 --> 00:12:20.530
superimpose his rectangle on top of it.

00:12:20.760 --> 00:12:22.270
Let's look at the code for this.

00:12:22.320 --> 00:12:23.430
It's actually very simple.

00:12:23.500 --> 00:12:26.970
The setup for this is about 30 lines.

00:12:27.110 --> 00:12:31.580
Find My Icon is available as sample code,
and also this snippet that I'm about

00:12:31.580 --> 00:12:36.340
to show you is available and attached
to this session as code snippet SP16.

00:12:36.340 --> 00:12:37.090
You can follow along.

00:12:37.600 --> 00:12:38.600
So what do we do first?

00:12:38.600 --> 00:12:40.100
We make a capture session.

00:12:40.100 --> 00:12:44.160
We set the preset on the
session to whatever desired

00:12:44.160 --> 00:12:46.450
quality of service we want.

00:12:46.780 --> 00:12:48.110
For this one, I set it to high.

00:12:48.110 --> 00:12:50.570
High because we wanted
the full resolution,

00:12:50.600 --> 00:12:54.850
we wanted a nice-looking preview,
and the processing was quick enough

00:12:54.850 --> 00:12:57.560
that we could tolerate a high level.

00:12:58.030 --> 00:13:01.300
Next, you need to find a
suitable AV capture device.

00:13:01.440 --> 00:13:05.440
In this case, we just chose the default,
which is the back-facing camera.

00:13:05.700 --> 00:13:11.940
So we used default device with media type
and asked for the video AV media type.

00:13:12.110 --> 00:13:16.250
Once we've got that,
we create and add an AV capture device

00:13:16.250 --> 00:13:18.860
input and add it to our session.

00:13:19.040 --> 00:13:22.020
You've just configured
half of your graph.

00:13:22.510 --> 00:13:25.400
So now, how do we do the output side?

00:13:25.400 --> 00:13:28.760
Well, first we make an AV Capture
Video Data Output instance,

00:13:29.020 --> 00:13:30.500
add it to the session.

00:13:30.520 --> 00:13:34.170
We configure our output,
and then start the session.

00:13:34.600 --> 00:13:37.710
So how you do this is if you
don't have a delegate callback,

00:13:37.780 --> 00:13:40.160
you're not going to get any video frames.

00:13:40.250 --> 00:13:44.620
You have to tell your video data output
the callback to deliver the frames to.

00:13:44.620 --> 00:13:47.980
Now, this is not a traditional
delegate callback like most

00:13:47.980 --> 00:13:49.550
Objective-C objects have.

00:13:49.710 --> 00:13:51.020
It's a fancy delegate.

00:13:51.060 --> 00:13:54.550
So when you associate a delegate
with your video data output,

00:13:54.550 --> 00:13:57.120
you call set sample
buffer delegate queue.

00:13:57.120 --> 00:14:00.160
Now, this queue,
you may or may not be familiar with.

00:14:00.300 --> 00:14:04.470
This is a recent development
and certainly a new development.

00:14:04.500 --> 00:14:08.420
On iOS 4, which is the use of
Grand Central Dispatch,

00:14:08.420 --> 00:14:08.920
or GCD.

00:14:09.020 --> 00:14:12.970
You can associate a
GCD queue with your delegate.

00:14:13.000 --> 00:14:17.010
That means that you have
control over the priority,

00:14:17.030 --> 00:14:20.590
the thread of when
these callbacks happen.

00:14:20.610 --> 00:14:24.640
We give this control to you because
we want you to be able to manage

00:14:24.650 --> 00:14:26.960
the performance of video frames.

00:14:26.960 --> 00:14:30.720
Video is hard,
and it really taxes the system.

00:14:30.720 --> 00:14:34.060
And this is about the hardest
thing you can do on the phone.

00:14:34.060 --> 00:14:36.120
It lights up the just about
every block we've got.

00:14:36.300 --> 00:14:39.380
So we want to give you all
the tools we can to help you

00:14:39.380 --> 00:14:41.080
mitigate performance problems.

00:14:41.200 --> 00:14:42.480
And this is one of them.

00:14:42.480 --> 00:14:46.530
Being able to specify a queue,
you have some control over

00:14:46.530 --> 00:14:48.480
the relative priority.

00:14:48.850 --> 00:14:50.830
Next,
you implement your delegate callback,

00:14:50.910 --> 00:14:51.740
which is simple.

00:14:51.870 --> 00:14:54.440
It calls you with did
output sample buffer,

00:14:54.490 --> 00:14:57.140
and then you can start
and do your processing.

00:14:57.200 --> 00:14:59.000
Now, that might bring up a question.

00:14:59.000 --> 00:15:01.220
What is a CM sample buffer?

00:15:01.240 --> 00:15:03.000
I saw that object there,
but I've never heard

00:15:03.000 --> 00:15:04.160
of one of those before.

00:15:04.230 --> 00:15:07.440
Well, it's defined in the new
core media framework.

00:15:07.490 --> 00:15:12.280
It is a CF object,
so it has retain and release semantics.

00:15:12.810 --> 00:15:15.910
First and foremost,
it contains the sample data.

00:15:15.910 --> 00:15:20.340
And it does that by wrapping
it in a CV image buffer,

00:15:20.340 --> 00:15:23.490
or in our case,
it's a concrete type of CV image

00:15:23.490 --> 00:15:25.310
buffer called a CV pixel buffer ref.

00:15:25.380 --> 00:15:27.520
If you've ever worked with
Core Video on the Mac,

00:15:27.520 --> 00:15:29.110
you know what I'm talking about.

00:15:29.110 --> 00:15:33.350
When you have a CV pixel buffer ref,
you can get at the base address,

00:15:33.430 --> 00:15:36.640
the row bytes, you can start iterating
through the pixels and do

00:15:36.670 --> 00:15:38.110
whatever it is you need to do.

00:15:38.760 --> 00:15:44.100
It also contains timing information,
accurate timestamps from exactly when

00:15:44.100 --> 00:15:46.740
that frame showed up on the sensor.

00:15:46.740 --> 00:15:49.540
You can get the presentation
time as a CM time.

00:15:49.640 --> 00:15:53.530
Eric told you all about
that in the last session.

00:15:54.730 --> 00:15:56.440
You can get format information.

00:15:56.620 --> 00:16:01.210
Format information is housed in the
CM sample buffer as another CF object

00:16:01.240 --> 00:16:03.240
called a CM format description.

00:16:03.500 --> 00:16:05.730
Once you have that,
you can find out things about

00:16:05.800 --> 00:16:11.540
the format like its pixel type,
its clean aperture, its dimensions,

00:16:11.540 --> 00:16:15.170
things that you might
want to know about it.

00:16:15.970 --> 00:16:19.160
And lastly, metadata about the samples.

00:16:19.210 --> 00:16:21.560
You get these as attachments.

00:16:21.560 --> 00:16:25.800
They're carried along with the sample
buffer as a dictionary of attachments.

00:16:25.920 --> 00:16:29.000
In this case right here,
I'm asking for the metadata

00:16:29.000 --> 00:16:30.530
dictionary attachment.

00:16:31.080 --> 00:16:33.570
If it has it,
we can look through that dictionary and

00:16:33.570 --> 00:16:35.730
find all kinds of interesting metadata.

00:16:35.930 --> 00:16:40.650
Focus scores and exposure levels
and whether the flash was firing.

00:16:41.320 --> 00:16:42.800
Interesting stuff.

00:16:42.800 --> 00:16:46.900
All of this is in code snippet SP20,
and please refer to the CoreMedia

00:16:46.900 --> 00:16:49.490
framework documentation for
more information on how to

00:16:49.500 --> 00:16:51.800
work with CM sample buffers.

00:16:52.700 --> 00:16:54.440
Performance considerations.

00:16:54.660 --> 00:16:57.880
Can we just pause for a second
to reflect on how cool this is?

00:16:58.090 --> 00:17:01.750
You're getting 1280, okay, go ahead.

00:17:04.700 --> 00:17:10.140
We're getting 1280 by 720,
30 frames per second video delivered

00:17:10.140 --> 00:17:12.710
to your process on a phone.

00:17:12.760 --> 00:17:14.650
You know,
this is things that we were doing on

00:17:14.650 --> 00:17:18.610
the desktop not too many years ago.

00:17:18.750 --> 00:17:20.510
I liken to it to the following analogy.

00:17:20.670 --> 00:17:23.860
Let's say all of you
are high school seniors,

00:17:23.860 --> 00:17:25.470
and it's prom night.

00:17:25.540 --> 00:17:26.760
This is your senior prom.

00:17:26.950 --> 00:17:29.460
And let's pretend that Apple is your dad.

00:17:30.360 --> 00:17:33.670
And so you're all dolled
up and ready to go,

00:17:33.690 --> 00:17:38.150
and you think you're going
to take the family car,

00:17:38.150 --> 00:17:42.800
and then your dad pulls out
the keys to the Porsche and

00:17:42.970 --> 00:17:46.910
gives them to you and says,
have fun with it.

00:17:47.020 --> 00:17:48.330
I trust you.

00:17:48.330 --> 00:17:48.330
But

00:17:48.820 --> 00:17:53.990
Please bring the car back on time,
and please don't have a scratch on it,

00:17:53.990 --> 00:17:57.220
or else you're grounded and you
never get to use it ever again.

00:17:57.280 --> 00:17:59.700
That's the kind of performance
considerations we're talking about

00:17:59.700 --> 00:18:01.780
with AV Capture Video Data Output.

00:18:01.830 --> 00:18:05.050
You must be timely with
your use of these buffers,

00:18:05.230 --> 00:18:07.280
or you might not get any more.

00:18:07.440 --> 00:18:10.140
So, as I said before,
you set the sample buffer

00:18:10.140 --> 00:18:11.580
delegate and queue.

00:18:11.630 --> 00:18:14.900
The queue that you set on
us must be a serial queue.

00:18:14.950 --> 00:18:17.780
That ensures properly
ordered buffer callbacks.

00:18:18.000 --> 00:18:20.540
If you use one of the
global concurrent queues,

00:18:20.570 --> 00:18:22.640
order is not guaranteed.

00:18:22.720 --> 00:18:25.230
So how hilarious would it
be if you started getting

00:18:25.270 --> 00:18:26.970
video frames out of order?

00:18:29.230 --> 00:18:31.780
So don't pass dispatch
get current queue either.

00:18:32.010 --> 00:18:35.620
You can't guarantee what thread it's on.

00:18:36.630 --> 00:18:38.920
By default,
the buffers you get from the video

00:18:38.930 --> 00:18:42.360
data output are emitted in the
camera's most efficient format.

00:18:42.680 --> 00:18:45.500
That is, the format that's easiest
for it to produce,

00:18:45.730 --> 00:18:48.130
which may or may not be the best
format for your application.

00:18:48.140 --> 00:18:51.540
If you find that by default
it's not giving you the best

00:18:51.540 --> 00:18:55.880
format for your application,
you can specify a custom output format

00:18:55.970 --> 00:18:58.480
using the video settings property.

00:18:58.480 --> 00:19:01.960
Set the video settings, for instance,
if you want to output BGRA.

00:19:01.960 --> 00:19:05.680
And as I hinted before,
both Core Graphics and

00:19:05.680 --> 00:19:08.110
OpenGL work well with BGRA.

00:19:08.160 --> 00:19:12.490
It's not the default emitted format,
but if you plan to process

00:19:12.590 --> 00:19:17.260
pixels and then render them,
this might be a good choice.

00:19:18.200 --> 00:19:19.830
Additional performance considerations.

00:19:19.930 --> 00:19:24.580
You can set the min frame duration
property on the AV capture video data

00:19:24.580 --> 00:19:26.420
output to cap the max frame rate.

00:19:26.740 --> 00:19:28.100
That might sound a little backwards.

00:19:28.280 --> 00:19:31.400
Min frame duration is the
reciprocal of the max frame rate.

00:19:31.700 --> 00:19:35.940
So if you set it to 1 over 15,
that's going to give you a max

00:19:35.940 --> 00:19:38.960
frame rate of 15 frames per second.

00:19:39.170 --> 00:19:42.760
You can also configure the session to
output the lowest practical resolution

00:19:42.760 --> 00:19:44.640
for your processing algorithm.

00:19:44.690 --> 00:19:48.240
You'll want to do that to save
CPU cycles if you're doing

00:19:48.240 --> 00:19:50.810
some complicated processing.

00:19:51.200 --> 00:19:56.640
There's also this long property name
called Always Discards Late Video Frames,

00:19:56.680 --> 00:19:58.640
and the default is yes.

00:19:58.720 --> 00:20:02.190
By default,
we want to drop video frames early

00:20:02.280 --> 00:20:04.780
and efficiently if you fall behind.

00:20:04.860 --> 00:20:08.120
So if you accept the default,
you're giving us leeway to drop

00:20:08.420 --> 00:20:13.740
frames early before messaging them
over to your process and perhaps

00:20:13.870 --> 00:20:15.640
causing you to get even later.

00:20:15.910 --> 00:20:17.620
Now, you can set it to no.

00:20:17.680 --> 00:20:20.620
That doesn't guarantee that we're
not going to drop video frames.

00:20:20.660 --> 00:20:24.020
It just means we're not going to
drop them as early and efficiently

00:20:24.090 --> 00:20:26.150
as we might have if you said yes.

00:20:26.280 --> 00:20:29.760
Now, why might you want to set it to no?

00:20:29.820 --> 00:20:32.440
You might set it to no
if you're recording,

00:20:32.470 --> 00:20:34.910
and it doesn't matter if the video
frames are a little bit late.

00:20:34.960 --> 00:20:37.490
You want all of them that you can get.

00:20:38.320 --> 00:20:40.850
So, again,
let me impress upon you that your sample

00:20:40.850 --> 00:20:42.750
buffer delegate callbacks must be fast.

00:20:42.980 --> 00:20:45.610
Do as little processing
as you can get away with,

00:20:45.750 --> 00:20:47.430
and return that buffer.

00:20:47.590 --> 00:20:50.720
Because if you hold onto
the buffers too long,

00:20:50.790 --> 00:20:53.800
the camera is going to
stop producing buffers,

00:20:53.800 --> 00:20:57.420
your preview will stop,
your processing algorithm will

00:20:57.420 --> 00:21:01.110
probably get really confused,
hilarity will ensue.

00:21:01.430 --> 00:21:04.040
Also, this was the first time
we saw AV Capture Session,

00:21:04.100 --> 00:21:08.640
which again is the central hub of the
AV Foundation Capture API universe.

00:21:08.780 --> 00:21:12.030
It's the place for adding
inputs and outputs,

00:21:12.040 --> 00:21:16.940
and the flow of data does not start
until you call Start Running on it.

00:21:17.050 --> 00:21:20.740
Lastly, we talked about that
session preset property.

00:21:20.860 --> 00:21:25.060
We have six supported
session presets in iOS 4:

00:21:25.190 --> 00:21:27.660
high, medium, low, some named ones,
and photo.

00:21:27.700 --> 00:21:28.900
Let's talk about these.

00:21:29.050 --> 00:21:35.300
High means the highest quality
video and audio recording resolution

00:21:35.300 --> 00:21:37.200
and quality that we can give you.

00:21:37.280 --> 00:21:40.440
It changes from product to product.

00:21:40.630 --> 00:21:45.150
High on a 3GS is not the
same as high on an iPhone 4.

00:21:45.330 --> 00:21:48.530
But it means that if you use high,
you'll always scale to the very

00:21:48.550 --> 00:21:51.300
best that the given product can do.

00:21:51.430 --> 00:21:55.000
Medium we define as
suitable for Wi-Fi sharing.

00:21:55.090 --> 00:21:57.560
Low we define as suitable for 3GS.

00:21:57.560 --> 00:22:00.060
And low we define as
suitable for 4G sharing.

00:22:00.060 --> 00:22:04.060
But we don't make guarantees about what
those resolutions are and bit rates are,

00:22:04.060 --> 00:22:07.060
just that they'll fall
within those parameters.

00:22:07.060 --> 00:22:10.470
If you need to have something
that is VGA and stays VGA for

00:22:10.470 --> 00:22:14.060
all time and eternity,
you can use one of these named presets,

00:22:14.060 --> 00:22:15.050
like the 640x480 preset.

00:22:15.140 --> 00:22:18.560
We guarantee that that will not
change from product to product.

00:22:18.560 --> 00:22:20.930
And lastly,
there's that photo preset at the bottom,

00:22:21.180 --> 00:22:27.320
which is a special case for getting
absolutely the highest resolution,

00:22:27.430 --> 00:22:27.540
the full 5 megapixel on an iPhone 4,
or the full 5 megapixel on an iPhone 5.

00:22:27.650 --> 00:22:30.700
a three megapixel on an iPhone 3GS.

00:22:30.930 --> 00:22:32.960
Here's a list,
a grid of all the supported

00:22:33.050 --> 00:22:34.700
resolutions and formats.

00:22:34.740 --> 00:22:36.890
I don't expect you to
memorize this right now,

00:22:37.010 --> 00:22:39.920
but you can see in
AV Capture Video Data Output,

00:22:39.940 --> 00:22:44.180
you can get the full 1280 by 720 if,
for instance, you're on the iPhone

00:22:44.180 --> 00:22:45.960
4's back-facing camera.

00:22:45.960 --> 00:22:51.000
I did want to call out at the bottom
that photo resolution is not supported

00:22:51.000 --> 00:22:53.930
for video data output on any platform.

00:22:53.930 --> 00:22:55.450
The buffers are just too big.

00:22:57.440 --> 00:22:58.680
All right,
we've covered the first capture scenario.

00:22:58.680 --> 00:23:01.400
Let's move on to the second,
which is controlling the camera,

00:23:01.520 --> 00:23:03.560
taking photos, recording movies.

00:23:03.670 --> 00:23:07.140
And let's start that with a
demo and bring up Sean Ojakian.

00:23:07.230 --> 00:23:10.600
All right, he's running an application
called AVCam Demo,

00:23:10.600 --> 00:23:14.640
which is also available and
associated with this session.

00:23:14.700 --> 00:23:18.460
Notice that it has the same or very
similar features to our camera app,

00:23:18.460 --> 00:23:20.260
but a completely different UI.

00:23:20.440 --> 00:23:22.130
There are buttons on the bottom.

00:23:22.130 --> 00:23:24.920
There's a HUD button
that we'll come back to.

00:23:25.030 --> 00:23:26.400
The second one says swap.

00:23:26.460 --> 00:23:31.160
And when Eric pushes swap,
it switches to the front-facing camera,

00:23:31.160 --> 00:23:34.400
and now he can smile at you and
you can see his beautiful face.

00:23:34.630 --> 00:23:38.150
Now, if he pushes the record button,
he's recording to a movie.

00:23:38.250 --> 00:23:42.320
We'll do a quick recording
and there you go.

00:23:42.560 --> 00:23:47.000
Once he stops the recording,
it records the movie to his

00:23:47.000 --> 00:23:52.690
sandboxed process space,
and he writes it over to the camera roll

00:23:52.690 --> 00:23:56.350
using the new AL asset library class.

00:23:56.360 --> 00:23:58.590
The third one says high
quality still images.

00:23:58.610 --> 00:24:00.910
Let's go ahead and take a
still image right there.

00:24:01.110 --> 00:24:04.510
He flashed the screen for us so that
we could see it taking the picture.

00:24:04.730 --> 00:24:07.950
And now let's go back to the
back-facing camera and display

00:24:07.950 --> 00:24:09.690
what's in the HUD controls.

00:24:09.750 --> 00:24:12.620
Here's where things get
interesting and new.

00:24:12.620 --> 00:24:18.540
Okay, notice he's got in there flash off,
torch, auto focus, auto exposure,

00:24:18.540 --> 00:24:20.150
auto white balance.

00:24:20.260 --> 00:24:24.420
So let's go ahead and turn the
flash on and then take another

00:24:24.500 --> 00:24:28.270
picture and... Point it at the
audience so they can be blinded.

00:24:28.360 --> 00:24:29.280
Great.

00:24:29.510 --> 00:24:32.650
And then let's turn on the torch.

00:24:33.710 --> 00:24:35.840
Torch is kind of like flash,
except that it's at a

00:24:35.840 --> 00:24:39.150
lower intensity beam,
and while you take a recording,

00:24:39.150 --> 00:24:44.310
you can see it humming along there,
illuminating your recording and making

00:24:44.320 --> 00:24:46.400
it brighter in low-light conditions.

00:24:46.400 --> 00:24:51.340
Okay, and then next, we've got autofocus,
which is currently locked.

00:24:51.440 --> 00:24:54.250
He has it wired up so that
when he does a single tap,

00:24:54.250 --> 00:24:58.420
it does an autofocus and then locks
at that current focus position.

00:24:58.420 --> 00:25:01.990
Okay,
let's back up now and have something

00:25:01.990 --> 00:25:05.390
bright on one side and dark in the back.

00:25:05.460 --> 00:25:08.070
If he double taps,
it will expose on the point

00:25:08.070 --> 00:25:09.200
at which he double taps.

00:25:09.550 --> 00:25:13.210
So let's double tap on the screen.

00:25:18.840 --> 00:25:19.330
Okay, it just got, you know,
it adjusted for the

00:25:19.330 --> 00:25:19.890
brightness of the screen,
and now let's double tap

00:25:19.890 --> 00:25:20.120
over on the dark side.

00:25:20.380 --> 00:25:23.200
And you see the auto exposure
just kind of blew out.

00:25:23.250 --> 00:25:25.670
Now, while he was doing that,
he didn't change the focus.

00:25:25.800 --> 00:25:27.030
The focus remained locked.

00:25:27.180 --> 00:25:30.570
So we're setting separate exposure
windows and focus windows.

00:25:30.640 --> 00:25:32.790
This is a first on our platform.

00:25:33.060 --> 00:25:35.370
And also notice that while he's
doing something like a focus,

00:25:35.500 --> 00:25:37.490
look at those cool little
traffic lights there.

00:25:37.650 --> 00:25:39.450
They light up when things happen.

00:25:39.580 --> 00:25:42.200
So even if he's in a
continuous auto focus mode,

00:25:42.260 --> 00:25:46.160
it will light up when
the focus event happens.

00:25:46.440 --> 00:25:47.130
Thanks, Sean.

00:25:47.300 --> 00:25:49.250
Let's go back to slides.

00:25:56.070 --> 00:25:56.840
What did we just see there?

00:25:56.840 --> 00:26:03.340
We saw two inputs,
a preview to a core animation layer,

00:26:03.380 --> 00:26:06.090
output to a still image,
and movie recording.

00:26:06.340 --> 00:26:08.830
And again, to AV Capture,
it looks like this.

00:26:08.990 --> 00:26:09.940
You have a session in the middle.

00:26:09.940 --> 00:26:15.670
You have two AV Capture device inputs,
a new subclass of AV Capture output

00:26:15.670 --> 00:26:20.550
called AV Capture Still Image Output,
and another new one called

00:26:20.550 --> 00:26:22.700
AV Capture Movie File Output.

00:26:22.720 --> 00:26:25.740
Video preview layer is our old friend.

00:26:28.560 --> 00:26:31.040
Moving on,
let's talk about focus support.

00:26:31.110 --> 00:26:33.360
There are three supported focus modes.

00:26:33.510 --> 00:26:34.180
Locked.

00:26:34.490 --> 00:26:36.200
Locked means what you would expect.

00:26:36.400 --> 00:26:38.640
It parks the sensor at
its current position,

00:26:38.710 --> 00:26:41.030
and it doesn't do any focus.

00:26:41.160 --> 00:26:44.580
So you can compose a scene,
frame it how you like,

00:26:44.690 --> 00:26:49.360
do a focus operation, lock,
so that it will stay there.

00:26:50.220 --> 00:26:55.940
Focus mode autofocus does a single
scan focus and then reverts to locked.

00:26:56.070 --> 00:26:58.570
So this is something that might
be suitable for a touch-to-focus

00:26:58.660 --> 00:27:02.100
interface where you want to do
one focus and then keep it there.

00:27:02.380 --> 00:27:05.600
Lastly,
there's continuous autofocus mode.

00:27:05.680 --> 00:27:09.540
That continuously autofocuses
as needed in the background.

00:27:09.600 --> 00:27:13.100
It's constantly monitoring
the scene for fuzziness.

00:27:13.100 --> 00:27:16.330
When it gets blurry enough that
it thinks it needs to focus again,

00:27:16.330 --> 00:27:17.230
it'll do that.

00:27:17.900 --> 00:27:22.150
You can use the isFocusModeSupported
property to determine if your given

00:27:22.170 --> 00:27:24.320
AV capture device supports it.

00:27:24.470 --> 00:27:25.920
Not all devices support focus.

00:27:26.000 --> 00:27:31.620
For instance,
an iPhone 3G is a fixed focus camera.

00:27:31.820 --> 00:27:36.270
Also, you can observe the adjusting focus
property using key value coding,

00:27:36.540 --> 00:27:39.250
key value observation,
to know when it changes.

00:27:39.390 --> 00:27:43.920
That's what he was driving
his red blinky lights using.

00:27:44.100 --> 00:28:49.000
[Transcript missing]

00:28:50.820 --> 00:28:54.880
Setting the focus mode or focus point
of interest requires calling lock for

00:28:54.880 --> 00:28:57.460
configuration on the AV capture device.

00:28:57.520 --> 00:28:59.610
Think of AV capture device
as a shareable object.

00:29:00.300 --> 00:29:04.330
These are things that you would set on
the AV capture device that might mess

00:29:04.330 --> 00:29:08.580
up another application that's using the
same shared resource at the same time.

00:29:08.580 --> 00:29:13.210
So before messing with their state,
we want to make sure that you have

00:29:13.210 --> 00:29:15.250
mutually exclusive access to that device.

00:29:15.250 --> 00:29:17.980
So here's some code that you might use.

00:29:18.040 --> 00:29:20.680
You would see if that focus mode is
supported if you wanted to lock it.

00:29:20.700 --> 00:29:24.400
If you see that it is supported,
you would call lock for configuration,

00:29:24.440 --> 00:29:29.620
then go ahead and lock it,
lock the focus mode, and then unlock the

00:29:29.620 --> 00:29:31.130
device for configuration.

00:29:31.130 --> 00:29:35.440
And please do avoid holding the
lock for configuration for too long.

00:29:35.440 --> 00:29:38.880
Again, think of it as a shared resource.

00:29:38.900 --> 00:29:41.980
You might degrade other
applications' user experience

00:29:42.070 --> 00:29:45.060
if you hold it indefinitely.

00:29:45.060 --> 00:29:50.240
Exposure modes follow the
same basic rules that focus.

00:29:50.770 --> 00:29:51.670
modes do.

00:29:51.940 --> 00:29:54.500
There's locked and continuous.

00:29:54.960 --> 00:29:58.600
We have the same isSupported
and adjustingExposure key

00:29:58.600 --> 00:30:00.670
value observable property.

00:30:00.670 --> 00:30:03.510
And again,
you must call lock for configuration

00:30:03.870 --> 00:30:07.800
before you set the exposure
mode or point of interest.

00:30:07.930 --> 00:30:11.370
Also with white balance,
the same two supported modes,

00:30:11.460 --> 00:30:12.800
continuous and locked.

00:30:13.010 --> 00:30:14.800
You can ask if it's supported.

00:30:14.850 --> 00:30:16.690
You can observe when it changes.

00:30:16.780 --> 00:30:21.800
And you must call lock for
configuration before setting it.

00:30:21.800 --> 00:30:25.710
Now let's talk about
Flash support on the camera.

00:30:26.740 --> 00:30:29.500
Flash modes, we have three of them.

00:30:29.530 --> 00:30:31.540
We have flash mode off.

00:30:31.570 --> 00:30:33.930
When flash mode is off,
the flash will not fire,

00:30:34.060 --> 00:30:37.700
even if it's the middle of the night
and you're out in the middle of nowhere.

00:30:37.700 --> 00:30:41.650
AV capture flash mode on always fires
the flash when you take a picture,

00:30:41.730 --> 00:30:44.700
even if it's the middle of the
day and it's bright outside.

00:30:44.700 --> 00:30:50.590
AV capture flash mode auto will
only fire the flash if ambient light

00:30:50.590 --> 00:30:54.660
conditions determine that it's low
enough that we should fire the flash.

00:30:55.200 --> 00:30:59.410
Again, you have those has flash type
properties to know whether

00:30:59.820 --> 00:31:03.480
you can use that facility,
and you can call lock for

00:31:03.550 --> 00:31:05.530
configuration to set it.

00:31:05.850 --> 00:31:06.790
Torch support.

00:31:06.850 --> 00:31:13.640
Torch is actually the same LED used for
illumination that the flash or strobe is,

00:31:13.670 --> 00:31:17.310
but it fires at a much lower
intensity that's sustainable

00:31:17.410 --> 00:31:19.560
for a longer period of time.

00:31:19.590 --> 00:31:22.980
When you use the torch,
that's what you would

00:31:22.980 --> 00:31:25.000
use for video recording.

00:31:25.110 --> 00:31:27.150
Off, on,
and auto follow the same semantics

00:31:27.290 --> 00:31:28.940
that I just talked about for flash.

00:31:28.960 --> 00:31:34.640
Off means always off, on means always on,
and auto will only turn on if ambient

00:31:35.240 --> 00:31:38.750
light requires it during a recording.

00:31:39.680 --> 00:31:44.030
You can ask if it has a torch,
and you must lock for configuration.

00:31:44.150 --> 00:31:47.150
Please also note that the torch
only turns on if the device

00:31:47.240 --> 00:31:51.040
is associated with a session,
and that session is running.

00:31:51.110 --> 00:31:53.550
It's meant for video recording.

00:31:55.320 --> 00:32:02.510
Here is a grid of all of our AV capture
device properties and the various

00:32:02.690 --> 00:32:04.030
products and what's supported.

00:32:04.200 --> 00:32:07.180
So if you want the Uber list,
you've got to go get an iPhone

00:32:07.180 --> 00:32:09.530
4 and use the back camera.

00:32:12.140 --> 00:32:13.440
Let's talk about camera switching.

00:32:13.460 --> 00:32:16.000
There are some performance
considerations here.

00:32:16.040 --> 00:32:19.170
When you use AVCaptureSession,
you can tell it,

00:32:19.310 --> 00:32:23.000
since it's the control object,
you can tell it to start or stop running.

00:32:23.130 --> 00:32:27.350
But these are synchronous calls,
meaning when you call "start running,"

00:32:27.470 --> 00:32:31.620
it's not going to return until
everything is actually running and going.

00:32:31.840 --> 00:32:35.060
This can take a little bit of time,
same with "stop running." So it

00:32:35.060 --> 00:32:37.800
would be wasteful and it would
be a bad user experience if,

00:32:37.920 --> 00:32:39.930
for instance,
you wanted to switch from front

00:32:39.930 --> 00:32:42.900
to back camera and you had
to stop the session running,

00:32:42.960 --> 00:32:45.940
wait for it to stop running,
then set to a new camera,

00:32:45.990 --> 00:32:47.780
then start it running again.

00:32:47.820 --> 00:32:50.060
It would glitch and stutter.

00:32:50.180 --> 00:32:55.290
So instead, AVCaptureSession is meant to
be reconfigured while running.

00:32:55.660 --> 00:32:58.650
You can use begin configuration
and commit configuration,

00:32:58.730 --> 00:33:02.160
which are very similar to
CoreAnimation's CA transaction,

00:33:02.160 --> 00:33:03.590
begin and commit.

00:33:04.680 --> 00:33:09.110
This is all in code snippet SP21,
but the abbreviated version is you call

00:33:09.440 --> 00:33:13.800
begin configuration on the session,
and then you do stuff to the session.

00:33:13.940 --> 00:33:18.100
Add inputs, remove outputs,
swap front and back camera.

00:33:18.100 --> 00:33:21.080
In this case, we're removing the
front-facing camera input,

00:33:21.080 --> 00:33:23.360
adding the back-facing camera input.

00:33:23.360 --> 00:33:27.500
But no work is done until we
call commit configuration when

00:33:27.500 --> 00:33:31.040
it's committed all in one call,
and it's very smooth

00:33:31.040 --> 00:33:32.720
and as fast as can be.

00:33:32.720 --> 00:33:35.970
So please do use begin and
commit configuration when you're

00:33:35.970 --> 00:33:37.830
reconfiguring your session.

00:33:39.850 --> 00:33:43.940
Now let's move on to movie recording
and the AV capture movie file output,

00:33:44.050 --> 00:33:46.730
and some performance considerations.

00:33:47.120 --> 00:33:49.300
When you initiate a
QuickTime movie recording,

00:33:49.330 --> 00:33:51.810
you supply a file URL and a delegate.

00:33:51.900 --> 00:33:52.500
It's very simple.

00:33:52.500 --> 00:33:53.920
It looks like that.

00:33:54.000 --> 00:33:55.170
You have a URL.

00:33:55.370 --> 00:33:57.320
You supply a delegate.

00:33:57.740 --> 00:34:01.340
There are a couple optional
delegate callbacks,

00:34:01.630 --> 00:34:06.590
but one is mandatory, and that is,
did finish recording

00:34:06.730 --> 00:34:08.500
to output file at URL.

00:34:08.640 --> 00:34:14.110
We require that you be informed when
your recording finishes so that you're

00:34:14.110 --> 00:34:15.350
not just recording into the ether.

00:34:15.470 --> 00:34:20.440
In your did finish recording
to output file at URL callback,

00:34:20.440 --> 00:34:23.740
you might do things like
write it to the camera roll,

00:34:23.750 --> 00:34:25.510
as AVCam demo does.

00:34:25.620 --> 00:34:30.110
And if you look at code snippet SP24,
you'll see how to do that.

00:34:31.350 --> 00:34:35.080
Here is AV Capture
Movie File Output's writing policy.

00:34:35.100 --> 00:34:38.270
You must pass a file-based NSURL.

00:34:39.090 --> 00:34:44.100
You can't pass an HTTP URL or
anything other than a file-based one.

00:34:44.270 --> 00:34:47.580
You may not pass a
URL to an existing file.

00:34:47.760 --> 00:34:52.720
The Movie File Output does not
overwrite existing resources.

00:34:52.720 --> 00:34:56.320
Also, you must have permission to
write to the URL specified.

00:34:56.320 --> 00:35:01.170
We won't write to privileged
locations on your behalf.

00:35:01.330 --> 00:35:01.960
Setting limits.

00:35:01.970 --> 00:35:06.360
You might want to do things like set
a max recorded duration or file size,

00:35:06.470 --> 00:35:10.140
or ensure that your recordings
don't fill up the disk so that users

00:35:10.140 --> 00:35:11.830
can no longer boot their phone.

00:35:11.840 --> 00:35:16.080
You can use these properties
to set these recording limits.

00:35:16.110 --> 00:35:20.880
And when you do that,
be prepared that you might spontaneously

00:35:20.880 --> 00:35:26.000
get a did finish recording callback
when you didn't ask for it.

00:35:26.040 --> 00:35:29.100
So for instance,
if you set a max recorded

00:35:29.650 --> 00:35:33.370
duration property to say,
I want it to record for just 10 seconds,

00:35:33.370 --> 00:35:37.840
then after 10 seconds,
your callback will fire telling

00:35:37.840 --> 00:35:39.360
you that the recording did finish.

00:35:39.360 --> 00:35:42.000
And it will have an
NSError associated with it.

00:35:42.030 --> 00:35:44.890
That error will tell you
the reason that it finished.

00:35:44.890 --> 00:35:48.160
But that does not mean that
your file is not usable.

00:35:48.160 --> 00:35:51.800
So please get in the habit of
checking both the error and its

00:35:51.800 --> 00:35:56.020
user info dictionary to find out
if the recording was successful.

00:35:56.020 --> 00:36:00.540
And you can also find out
from that why it stopped.

00:36:00.650 --> 00:36:04.100
Here are some early recording
termination conditions.

00:36:04.380 --> 00:36:05.740
I wanted to call these out.

00:36:05.760 --> 00:36:07.520
AV error disk full.

00:36:07.670 --> 00:36:08.360
Pretty understandable.

00:36:08.360 --> 00:36:10.540
If you filled up your disk,
it had to stop.

00:36:10.750 --> 00:36:14.290
If a device gets disconnected,
when might that happen?

00:36:14.450 --> 00:36:17.160
Well, if you're on an iPod touch,
and it doesn't have a

00:36:17.180 --> 00:36:19.750
built-in microphone,
but it has headphones,

00:36:19.880 --> 00:36:23.380
and someone pulls out the headphones so
the headphone mic suddenly disappears,

00:36:23.410 --> 00:36:25.480
your recording will stop.

00:36:26.730 --> 00:36:30.780
Maximum duration reached,
maximum file size reached,

00:36:30.790 --> 00:36:33.020
and session was interrupted.

00:36:33.040 --> 00:36:34.080
And what's a session interruption?

00:36:34.080 --> 00:36:37.080
That's when, for instance,
a phone call comes in.

00:36:37.490 --> 00:36:40.310
Phone calls need to rip
hardware away from you that's

00:36:40.310 --> 00:36:44.190
being used for your recording,
so the phone call wins.

00:36:44.270 --> 00:36:46.110
It's more important than your recording.

00:36:46.280 --> 00:36:49.670
So your recording will stop right now,
and you'll be told that

00:36:49.670 --> 00:36:51.140
you were interrupted.

00:36:51.450 --> 00:36:57.280
Again, look at SP24,
code snippet 24 for the full list.

00:36:57.320 --> 00:36:59.800
Metadata, let's move on to metadata,
which is also a very interesting

00:36:59.800 --> 00:37:02.090
feature of our movie file output.

00:37:02.370 --> 00:37:07.360
You can set movie-level metadata
at any time while recording.

00:37:07.550 --> 00:37:11.020
That's different from other properties,
and there's a good reason for it.

00:37:11.070 --> 00:37:12.560
It allows for slow metadata.

00:37:12.760 --> 00:37:16.500
Not all metadata is available at
the time you start your recording.

00:37:16.550 --> 00:37:19.170
Let's take GPS location, for instance.

00:37:19.260 --> 00:37:23.180
If someone starts up your app
and pushes record immediately,

00:37:23.180 --> 00:37:26.350
you may not have had time
to get a GPS location fix.

00:37:26.480 --> 00:37:28.590
But you really wanted to
put that in your movie.

00:37:28.740 --> 00:37:33.490
So at any time while it's recording,
you can update the metadata

00:37:33.490 --> 00:37:37.140
array with metadata up until
the point where you stop.

00:37:37.300 --> 00:37:40.980
And we will update the movie file with
whatever metadata you come up with.

00:37:41.060 --> 00:37:44.420
So you can wait to know what
the right metadata is until

00:37:44.420 --> 00:37:46.300
your recording has started.

00:37:46.380 --> 00:37:49.100
Here's a code snippet that shows
how you might set the location.

00:37:49.100 --> 00:37:52.080
So this is the location metadata.

00:37:52.090 --> 00:37:56.710
These are expressed as AV mutable
metadata items in an array.

00:37:56.730 --> 00:37:58.490
This one has a key space of common.

00:37:58.640 --> 00:38:00.510
The key is location.

00:38:00.540 --> 00:38:06.920
And it uses an ISO 6709 compliant string
to express latitude and longitude.

00:38:06.920 --> 00:38:11.260
This is all in the code,
and you can see it in the code snippet.

00:38:11.310 --> 00:38:13.380
Code snippet 25.

00:38:14.010 --> 00:38:18.130
Here are supported resolutions
and bit rates on various products.

00:38:18.140 --> 00:38:22.400
You can get video in any
format as long as it's H.264,

00:38:22.430 --> 00:38:25.640
and audio in any format you
want as long as it's AAC,

00:38:25.690 --> 00:38:29.560
except on iPhone 3G,
where there is no video

00:38:29.560 --> 00:38:36.560
supported for movie file output
because of hardware constraints.

00:38:36.610 --> 00:38:40.170
As you can see,
the iPhone 4 back camera at its highest

00:38:40.750 --> 00:38:44.740
Supports 1280 by 720 at 10.5 megabits.

00:38:45.210 --> 00:38:49.630
And I also wanted to call out that
the photo preset is not supported

00:38:49.890 --> 00:38:51.500
for writing to movie files.

00:38:51.540 --> 00:38:54.120
That's just too big of buffers.

00:38:55.210 --> 00:38:57.030
And then let's talk about
photos for a minute.

00:38:57.110 --> 00:39:02.600
The still image output is a block style
completion handler that delivers image

00:39:02.700 --> 00:39:04.410
data to you as a CM sample buffer.

00:39:04.640 --> 00:39:06.440
Well, you guys know about
CM sample buffers now.

00:39:06.440 --> 00:39:09.160
We just talked about them when we
talked about video data output.

00:39:09.340 --> 00:39:12.460
That sample buffer
contains useful metadata.

00:39:12.460 --> 00:39:16.180
In addition to the ones you would
normally find in your video data output,

00:39:16.180 --> 00:39:18.340
you'll find EXIF, an EXIF dictionary.

00:39:18.340 --> 00:39:22.300
So for instance, when you want to take a
high quality still image,

00:39:22.400 --> 00:39:26.360
you would call capture still image
asynchronously from connection

00:39:26.400 --> 00:39:29.730
and provide a completion handler,
which is a block.

00:39:29.800 --> 00:39:33.360
That block will be invoked when
the picture is ready and the data

00:39:33.360 --> 00:39:35.490
has been messaged to your process.

00:39:35.540 --> 00:39:38.760
Here I show what I might do
to get at the EXIF dictionary.

00:39:39.390 --> 00:39:43.460
So I call CM get attachment,
and then I can inspect the

00:39:43.610 --> 00:39:47.490
EXIF dictionary associated
with that sample buffer

00:39:47.570 --> 00:39:50.130
containing still image data.

00:39:51.350 --> 00:39:54.420
We support a number of output formats,
as I said earlier.

00:39:54.680 --> 00:39:59.710
You can call available image data
CV pixel format types and available

00:39:59.710 --> 00:40:05.110
image data codec types to find out
which are supported on your device.

00:40:05.240 --> 00:40:11.200
And you can also set your preferred
pixel format or data codec format

00:40:11.250 --> 00:40:14.800
using the output settings property.

00:40:14.850 --> 00:40:17.770
If your final destination
still image format is JPEG,

00:40:17.770 --> 00:40:21.990
we highly recommend letting
AV Capture Still Image Output

00:40:22.050 --> 00:40:24.550
do the compression for you.

00:40:24.600 --> 00:40:25.390
You say, "Well, why?

00:40:25.400 --> 00:40:31.780
Maybe I want to insert my own metadata,
so I want to let Image I/O do the

00:40:31.780 --> 00:40:36.410
compression afterwards." Well,
if you use AV Capture Still Image Output,

00:40:36.530 --> 00:40:38.800
we will use hardware
to do the JPEG encode,

00:40:38.800 --> 00:40:41.420
and it will be as fast as it can be.

00:40:41.480 --> 00:40:46.580
If you do want to have that very fast,
you can use the JPEG still

00:40:46.580 --> 00:40:55.240
image NSData representation,
which will fetch that sample

00:40:55.330 --> 00:40:58.720
buffer in JPEG format,
write it to an NSData,

00:40:58.860 --> 00:41:03.980
merging in whatever additional custom
metadata you have without recompressing.

00:41:04.140 --> 00:41:07.160
So again,
that's a performance hint if you want

00:41:07.160 --> 00:41:13.790
to get really fast JPEG encoded still
images and insert your own metadata.

00:41:14.310 --> 00:41:16.430
Here are our supported
resolutions and formats.

00:41:16.490 --> 00:41:22.520
As you can see, most--well,
all platforms support BGRA and JPEG.

00:41:22.540 --> 00:41:23.240
That's kind of small.

00:41:23.240 --> 00:41:25.110
I don't know if you can see that.

00:41:25.260 --> 00:41:28.840
And all have their various resolutions.

00:41:29.010 --> 00:41:34.200
You can see that photo was a
full 5-megapixel photo preset.

00:41:34.200 --> 00:41:37.200
Let's move on to our
third capture use case,

00:41:37.200 --> 00:41:41.100
which is previewing video from a
camera to a core animation layer.

00:41:41.240 --> 00:41:44.910
And I'm going to do a demo for
that called Pinchy Preview.

00:41:45.530 --> 00:41:48.440
Okay, Pinchy Preview is a
very simple application.

00:41:48.440 --> 00:41:52.640
It's about 200 lines long,
and it's mostly UI gesture recognizers,

00:41:52.640 --> 00:41:56.900
and it's about 30 lines
of AV capture code.

00:41:56.900 --> 00:42:01.350
This garish red rectangle you see is
an AV capture video preview layer,

00:42:01.350 --> 00:42:04.160
but it's not showing any video, you say.

00:42:04.160 --> 00:42:06.350
That's because I haven't
pushed the start button yet.

00:42:06.990 --> 00:42:09.750
When I push the start button,
I start seeing video.

00:42:09.750 --> 00:42:12.110
It is a core animation layer.

00:42:12.210 --> 00:42:15.720
It inherits from CA layer,
so it behaves as you might expect

00:42:16.030 --> 00:42:18.350
any other CA layer to behave.

00:42:18.450 --> 00:42:21.990
I have it hooked up to a number
of UI gesture recognizer,

00:42:22.000 --> 00:42:23.100
UI gestures.

00:42:23.100 --> 00:42:27.240
So, for instance, when I touch,
I can move the layer around.

00:42:27.240 --> 00:42:31.060
If I pinch,
I can make myself really small.

00:42:31.060 --> 00:42:34.310
This is a fun app to
play with late at night.

00:42:36.310 --> 00:42:42.020
And you can also twist with your
fingers to rotate yourself around.

00:42:42.260 --> 00:42:44.620
And if you get tired of everything
you've been doing with this,

00:42:44.730 --> 00:42:48.310
you can shake,
and it goes back to its default location.

00:42:48.580 --> 00:42:51.310
Again, this is about 200 lines of code.

00:42:56.210 --> 00:43:00.830
Now, what's that equally garish orange
pointer you see at the top?

00:43:00.960 --> 00:43:08.330
The pointer is showing you where the
UI orientation is oriented towards.

00:43:08.500 --> 00:43:14.210
So this shows that we're a portrait app,
and when called to auto-rotate,

00:43:14.460 --> 00:43:16.820
we're saying no,
except for portrait mode.

00:43:16.820 --> 00:43:20.640
So if I turn my phone sideways,
I'm turning the phone sideways,

00:43:20.640 --> 00:43:23.960
you're not seeing it turn,
but I'm turning it upside down,

00:43:24.030 --> 00:43:27.260
you can see that my UI is still,
you know, pointed down.

00:43:27.260 --> 00:43:32.020
So no matter what happens,
I'm turned right side up

00:43:32.020 --> 00:43:34.340
with respect to my UI.

00:43:34.340 --> 00:43:37.890
Now, most applications will just set
this once and forget about it,

00:43:38.020 --> 00:43:38.960
like Camera app.

00:43:39.180 --> 00:43:41.480
They'll set their orientation,
and then they'll keep that one

00:43:41.550 --> 00:43:43.180
orientation for the life of the app.

00:43:43.240 --> 00:43:46.440
But if you have a very
complicated application where

00:43:46.440 --> 00:43:46.800
you need to set up a camera app,
you can set it up in the camera app.

00:43:46.800 --> 00:43:48.750
But if you have a very complicated
application where you need to

00:43:48.750 --> 00:43:51.920
auto-rotate to different orientations,
I'm going to push this button

00:43:52.100 --> 00:43:53.430
to stop locking UI view.

00:43:53.680 --> 00:43:57.320
If you forget to tell the preview
layer the orientation of your UI,

00:43:57.320 --> 00:43:58.700
this is what will happen.

00:43:58.920 --> 00:44:04.420
So when I rotate, okay, my UI rotated,
but my video didn't, so now I'm sideways.

00:44:04.660 --> 00:44:08.290
And if I go this way, oh no,
my video's upside down.

00:44:08.490 --> 00:44:12.230
But you can correct for that
by using the video preview

00:44:12.230 --> 00:44:15.530
layer's orientation property,
and when I push this button

00:44:15.530 --> 00:44:18.780
to turn the lock off,
it's now going to follow my

00:44:18.780 --> 00:44:21.230
UI orientation as it turns.

00:44:21.380 --> 00:44:25.110
So as I turn,
my video preview turns with it.

00:44:25.230 --> 00:44:30.150
And up is always up,
and down is always down.

00:44:31.020 --> 00:44:35.570
All it's got is one
input and zero outputs.

00:44:35.670 --> 00:44:38.550
There are no outputs at all,
just one preview layer.

00:44:38.660 --> 00:44:41.000
You have a session in the middle.

00:44:41.000 --> 00:44:44.280
You have a device input for the camera.

00:44:44.510 --> 00:44:48.620
You have a preview layer
for what we saw on screen.

00:44:49.510 --> 00:44:50.820
Considerations when using these.

00:44:51.000 --> 00:44:57.240
Unlike the AV Capture output,
it retains and owns its session.

00:44:57.360 --> 00:44:58.750
That might seem a little bit backwards.

00:44:58.760 --> 00:45:01.280
As I said, the session was the
center of our universe.

00:45:01.380 --> 00:45:05.400
But still,
it's idiomatic for core animation

00:45:05.400 --> 00:45:08.630
programming to sometimes make
your core animation layer,

00:45:08.630 --> 00:45:11.720
do your configuration on it,
and then throw it into your

00:45:11.720 --> 00:45:12.980
render tree and forget about it.

00:45:13.030 --> 00:45:16.410
So that when it comes time
to dispose of that layer,

00:45:16.410 --> 00:45:18.700
it takes care of all the cleanup.

00:45:18.700 --> 00:45:21.770
And that's why we carry
that idiom over here.

00:45:21.900 --> 00:45:26.200
So the video preview layer retains
and owns its capture session.

00:45:26.200 --> 00:45:28.770
It behaves like any other CA layer,
as you saw.

00:45:28.990 --> 00:45:31.000
We could perform transforms on it.

00:45:31.000 --> 00:45:33.750
We could rotate it, scale it.

00:45:33.840 --> 00:45:38.060
You can set the orientation
property to ensure that it rotates

00:45:38.320 --> 00:45:43.920
the preview layer correctly with
respect to your UI's orientation.

00:45:44.030 --> 00:45:46.860
And on iPhone 4,
the preview layer supports mirroring.

00:45:47.070 --> 00:45:48.040
We were actually seeing that.

00:45:48.040 --> 00:45:48.730
I didn't call it out.

00:45:48.830 --> 00:45:52.550
But when you saw pictures of me,
it was showing me as a

00:45:52.550 --> 00:45:54.040
mirror image of myself.

00:45:54.040 --> 00:45:56.800
This is the default for
the front-facing camera,

00:45:56.840 --> 00:45:59.850
because it's easier for people to
orient themselves when they see a mirror

00:45:59.850 --> 00:46:01.550
image of themselves in the preview.

00:46:01.690 --> 00:46:05.490
But you can turn that off if you
want to see exactly what the image

00:46:05.490 --> 00:46:07.970
looks like without mirroring.

00:46:08.900 --> 00:46:15.770
We support three video gravity modes:
Aspect, Aspect Fill, and Resize.

00:46:16.220 --> 00:46:20.720
Okay, so let's take a look at this
picture of a person playing guitar.

00:46:20.830 --> 00:46:22.320
This is resize aspect.

00:46:22.460 --> 00:46:24.870
Now, as you notice, on the top and bottom
there are black bars.

00:46:25.120 --> 00:46:29.430
That's because this
movie was taken 16 by 9.

00:46:29.430 --> 00:46:33.640
It's a 720 movie shown
on a 4 by 3 display.

00:46:33.640 --> 00:46:35.990
So, of course, there are black bars
because it doesn't fit,

00:46:35.990 --> 00:46:37.670
and we're preserving the aspect ratio.

00:46:37.680 --> 00:46:41.730
If you use aspect fill,
we're going to fill

00:46:41.730 --> 00:46:46.320
the given viewing size,
but keep the aspect ratio.

00:46:46.320 --> 00:46:48.620
So now we've cut out
something on the sides.

00:46:48.620 --> 00:46:51.070
Let's go back to the previous
one so you can see what happened.

00:46:51.080 --> 00:46:53.450
Look at where the guitarist's hands are.

00:46:53.450 --> 00:46:55.960
And when we go back to the other one,
you see they're kind of

00:46:55.960 --> 00:46:57.270
chopped off on the sides.

00:46:57.280 --> 00:47:02.080
And then finally,
comparison between aspect and resize.

00:47:02.080 --> 00:47:04.120
Resize is like Funhaus effects.

00:47:04.120 --> 00:47:07.660
It just stretches it or squishes
it to fit your previews.

00:47:07.680 --> 00:47:09.510
So you can see that the aspect ratio
is the same as the size of the video.

00:47:09.510 --> 00:47:11.340
So you can see that the aspect ratio
is the same as the size of the video.

00:47:11.340 --> 00:47:13.500
So you can see that the aspect ratio
is the same as the size of the video.

00:47:14.910 --> 00:47:17.380
Now, there's an extra consideration
you should be aware of,

00:47:17.420 --> 00:47:21.730
and that is when you're trying to
drive a tap to focus or tap to expose

00:47:21.730 --> 00:47:24.590
UI using this video preview layer,
there's some translation

00:47:24.590 --> 00:47:25.590
that you have to do.

00:47:25.600 --> 00:47:26.800
Why?

00:47:26.980 --> 00:47:32.040
Because the focus touch
from a video preview may be,

00:47:32.040 --> 00:47:37.350
your video preview may be rotated
differently than the buffer

00:47:37.350 --> 00:47:39.980
as it comes in on the sensor.

00:47:41.040 --> 00:47:43.590
It also might have a
different video gravity,

00:47:43.590 --> 00:47:45.890
you know,
so you may not be seeing the entire

00:47:46.080 --> 00:47:47.970
buffer on screen because it's blown up.

00:47:48.080 --> 00:47:52.320
Or mirroring may be enabled,
in which case a touch on your video

00:47:52.320 --> 00:47:57.510
preview needs to be translated,
you know, flip it over the vertical axis.

00:47:57.850 --> 00:48:00.580
The good news is,
if you look at AVCam Demo,

00:48:00.630 --> 00:48:03.590
it's got all of that translation code.

00:48:03.600 --> 00:48:07.850
So it shouldn't be a mystery how
to perform this translation between

00:48:08.160 --> 00:48:10.740
preview and driving your touch to focus.

00:48:11.040 --> 00:48:13.420
or touch to expose.

00:48:13.730 --> 00:48:18.480
Let's move on to the very last,
and that's processing PCM audio data

00:48:18.800 --> 00:48:21.190
from the microphone to draw waveform.

00:48:21.290 --> 00:48:24.620
We'll have Matthew come back
up and help me with this demo.

00:48:24.620 --> 00:48:27.620
Okay, this is probably the
simplest app of the day.

00:48:27.620 --> 00:48:31.580
It has a neat-looking

00:48:44.500 --> 00:48:44.720
You can see the little gradient there,
sort of Darth Vader-ish,

00:48:44.720 --> 00:48:44.720
and nothing happening until
you push the Start button.

00:48:44.720 --> 00:48:44.720
But when you do,
it starts drawing an audio waveform.

00:48:44.720 --> 00:48:44.720
So if, Matthew, you blow in or whistle
into the microphone,

00:48:45.230 --> 00:48:47.560
You see it get really big.

00:48:47.700 --> 00:48:49.100
That's kind of a neat feature.

00:48:49.360 --> 00:48:52.900
But what's even neater
is if you menu out,

00:48:54.430 --> 00:48:58.390
You see that it's drawing that
double height pulsing red bar,

00:48:58.510 --> 00:49:02.060
indicating that Wavy is still running
the audio device in the background.

00:49:02.140 --> 00:49:03.900
It's still getting processing time.

00:49:03.900 --> 00:49:06.290
It's still processing
those audio samples.

00:49:06.440 --> 00:49:09.890
So if you're, I don't know,
doing some strange reverb effect,

00:49:10.050 --> 00:49:11.900
you'd still be getting your callbacks.

00:49:12.040 --> 00:49:14.900
And now if you touch that and go back,

00:49:17.510 --> 00:49:19.750
You see that he was indeed
still getting called back,

00:49:19.750 --> 00:49:22.670
and when he did his whistle
while it was in the background,

00:49:22.670 --> 00:49:24.560
it was doing the drawing as well.

00:49:24.670 --> 00:49:26.320
Now, how did we do that?

00:49:26.530 --> 00:49:28.940
We had a single input,
this time no camera involved,

00:49:29.010 --> 00:49:33.780
just the built-in microphone,
and going to a single output.

00:49:35.070 --> 00:49:38.300
This looks like a capture
session in the middle,

00:49:38.320 --> 00:49:42.870
a device input on top,
and an audio data output on the bottom,

00:49:43.030 --> 00:49:46.400
which is another concrete
subclass of AV capture output,

00:49:46.460 --> 00:49:51.190
which delivers CM sample
buffers of audio samples.

00:49:52.000 --> 00:49:54.330
Performance considerations.

00:49:54.460 --> 00:49:57.080
Just like when you use
the video data output,

00:49:57.150 --> 00:50:00.770
you provide a delegate callback
along with a GCD queue,

00:50:00.780 --> 00:50:05.660
so you have some control over when and
how these samples are delivered to you.

00:50:05.800 --> 00:50:10.690
And again, do use a serial dispatch queue
to ensure proper ordering.

00:50:10.690 --> 00:50:16.430
I mean, if you think video frames coming
in out of order are funny,

00:50:16.460 --> 00:50:18.010
audio samples coming in out
of order are even funnier.

00:50:19.450 --> 00:50:23.120
The emitted sample buffers for
an audio data output are always,

00:50:23.170 --> 00:50:28.440
always, always interleaved 16-bit
signed integer PCM.

00:50:28.830 --> 00:50:33.360
They might be mono or stereo,
depending on the kind of 30-pin

00:50:33.360 --> 00:50:34.580
adapter you have on there.

00:50:34.680 --> 00:50:40.200
For instance, some 30-pin accessories
support stereo recording.

00:50:40.280 --> 00:50:42.740
If you have one of these,
you will get stereo

00:50:42.880 --> 00:50:44.400
audio in your callbacks.

00:50:44.440 --> 00:50:47.990
By default,
you get 44.1 kilohertz sample rate.

00:50:48.020 --> 00:50:50.960
But again, depending on the kind of
accessory that you use,

00:50:50.970 --> 00:50:53.190
you might have a different
source sample rate,

00:50:53.190 --> 00:50:56.500
and we will deliver you the
sample rate of the source device.

00:50:59.310 --> 00:50:59.920
Very important.

00:51:00.000 --> 00:51:04.640
Unlike video capture, video data output,
there is no affordance

00:51:04.860 --> 00:51:06.290
for dropping samples.

00:51:06.400 --> 00:51:10.000
You can't set it to a
lower max frame rate.

00:51:10.140 --> 00:51:11.280
You can't do that with audio.

00:51:11.390 --> 00:51:13.700
It's just the samples or a glitch.

00:51:13.850 --> 00:51:18.510
So it's even more important here that
you be fast in your delegate callback.

00:51:18.720 --> 00:51:23.160
Otherwise, you might drop audio samples,
and your user experience

00:51:23.160 --> 00:51:24.600
will be degraded.

00:51:25.520 --> 00:51:29.100
The CM Sample Buffer usage is almost
the same for audio as it was for video,

00:51:29.380 --> 00:51:30.640
with one exception.

00:51:30.750 --> 00:51:32.390
It contains no image buffer.

00:51:32.400 --> 00:51:37.190
There's no CV pixel buffer
backing this CM Sample Buffer.

00:51:37.300 --> 00:51:41.690
Instead, it contains an object
called a CM Block Buffer.

00:51:42.090 --> 00:51:46.330
You can think of a CM Block Buffer
as a very fancy CFData.

00:51:46.430 --> 00:51:52.740
It supports things like non-contiguous
ranges of data within the buffer.

00:51:52.820 --> 00:51:57.390
But for audio,
it will be just like a fancy CFData.

00:51:57.680 --> 00:52:04.820
You can use CM Block Buffer APIs to
address into the--to get a base

00:52:04.820 --> 00:52:07.500
pointer for the audio samples.

00:52:07.550 --> 00:52:09.690
And when you do that,
you call CM Block Buffer,

00:52:09.770 --> 00:52:10.580
get data pointer.

00:52:10.800 --> 00:52:18.390
You now have your data pointer
to the base address of the

00:52:18.390 --> 00:52:18.390
samples in the PCM buffer.

00:52:19.450 --> 00:52:20.950
Multitasking considerations.

00:52:21.050 --> 00:52:23.800
I saved this for last because
the rules are important.

00:52:23.800 --> 00:52:27.220
I wanted it to be near
the going away message.

00:52:27.330 --> 00:52:31.750
You may record or process
audio in the background.

00:52:32.490 --> 00:52:37.600
If you set the appropriate
UI background modes in your plist.

00:52:37.600 --> 00:52:39.450
If you've used Xcode,
you'll know what this

00:52:39.540 --> 00:52:41.770
little plist looks like.

00:52:42.210 --> 00:52:46.380
You can add a key to your plist
called required background modes.

00:52:46.450 --> 00:52:48.400
If you add the one that
says app plays audio,

00:52:48.400 --> 00:52:52.600
then you will continue to get
callbacks while you're backgrounded.

00:52:52.600 --> 00:52:56.130
Just like the app Wavy that
Matthew showed you while

00:52:56.130 --> 00:53:00.800
he was in the background,
because his app was a app plays

00:53:00.930 --> 00:53:05.290
audio in the background app,
he continued to get callbacks.

00:53:06.250 --> 00:53:09.250
Users are alerted to the fact that
there's still stuff going on in

00:53:09.250 --> 00:53:13.940
the background by that pulsing,
double-height, red status bar.

00:53:14.110 --> 00:53:14.940
That's good.

00:53:14.940 --> 00:53:18.790
That tells them that the battery
may be drained while you're

00:53:18.790 --> 00:53:21.010
doing stuff in the background.

00:53:22.480 --> 00:53:28.600
Background apps may not record or
process video from the cameras.

00:53:28.870 --> 00:53:32.620
So we do not allow background
usage of the camera.

00:53:32.650 --> 00:53:35.080
When you're backgrounded,
here's what happens.

00:53:35.240 --> 00:53:38.740
If you're running the camera,
your session gets told

00:53:38.970 --> 00:53:41.790
that it was interrupted,
and then it stops,

00:53:41.990 --> 00:53:44.600
and you're told that it stopped.

00:53:44.630 --> 00:53:47.690
If you have any movie
recordings in progress,

00:53:47.690 --> 00:53:49.080
they are stopped.

00:53:49.960 --> 00:53:55.130
When reentering the foreground,
a user has come back to your app or, say,

00:53:55.130 --> 00:53:57.190
a phone call ends,

00:53:57.880 --> 00:54:01.140
Your session is told that
the interruption ended,

00:54:01.180 --> 00:54:02.130
and then it starts back up.

00:54:02.350 --> 00:54:04.930
So it's as if it never left,
and there's very little work

00:54:05.030 --> 00:54:08.430
that you have to do on your
part to take care of this.

00:54:08.620 --> 00:54:13.990
You can key value observe the running
and interrupted properties if you

00:54:13.990 --> 00:54:18.980
want to know when you got interrupted
and take some additional action.

00:54:19.890 --> 00:54:22.050
The last thing we're going to talk
about today is an advanced topic

00:54:22.130 --> 00:54:24.230
called AV Capture Connections.

00:54:24.330 --> 00:54:27.170
These have been there all along,
but I kept them obscured from

00:54:27.170 --> 00:54:31.340
view because I didn't want
to obstruct the main message,

00:54:31.340 --> 00:54:35.050
which is inputs, outputs,
session in the middle.

00:54:35.220 --> 00:54:40.790
These are the glue that holds those
sessions and inputs and outputs together.

00:54:41.610 --> 00:54:42.500
Here's how you use them.

00:54:42.740 --> 00:54:47.920
Let's take the AVCam demo
use case that we saw earlier,

00:54:47.920 --> 00:54:51.930
where it was capturing from a
mic and from the built-in camera,

00:54:51.930 --> 00:54:56.100
and going to still image output,
movie file output,

00:54:56.270 --> 00:54:59.290
and video preview layer.

00:54:59.870 --> 00:55:02.950
Now,
you see those little red and blue lines,

00:55:03.040 --> 00:55:05.430
red for video and blue for audio.

00:55:05.520 --> 00:55:07.930
Those are represented in the API.

00:55:08.150 --> 00:55:11.330
They're represented in the
API as AV capture connections.

00:55:11.540 --> 00:55:15.020
So each one of those streams
of data going to an output

00:55:15.020 --> 00:55:16.750
is an AV capture connection.

00:55:16.880 --> 00:55:22.940
Now, notice there's a big X going
to the video preview layer.

00:55:22.940 --> 00:55:24.560
That's because it's not an output,
so it doesn't get a connection.

00:55:25.960 --> 00:55:28.950
The purpose of the AV Capture
Connection is to identify a

00:55:28.950 --> 00:55:31.160
specific stream of captured media.

00:55:31.690 --> 00:55:36.240
It allows you to enable or disable a
stream of media going to an output.

00:55:36.360 --> 00:55:40.560
And more importantly,
it allows you to control the data

00:55:40.560 --> 00:55:43.750
that's presented to the output,
or monitor the data that's

00:55:43.810 --> 00:55:45.380
presented to an output.

00:55:45.600 --> 00:55:48.020
For an audio connection,
this is where you can do

00:55:48.020 --> 00:55:49.560
your audio level metering.

00:55:49.640 --> 00:55:52.590
For a video connection,
this is where you can do things

00:55:52.670 --> 00:55:55.040
like locking the video orientation.

00:55:55.120 --> 00:55:58.640
If you want to make sure that all of your
still image pictures are always portrait,

00:55:58.680 --> 00:56:01.100
not landscape,
you can lock it to portrait.

00:56:01.250 --> 00:56:02.700
Or same goes for movie recording.

00:56:04.550 --> 00:56:07.440
Now, one thing that's important to
note is that the AV capture video

00:56:07.440 --> 00:56:08.770
data output is an exception.

00:56:08.810 --> 00:56:13.380
It does not support setting video
orientation or mirrored on its

00:56:13.380 --> 00:56:17.000
connection for performance reasons.

00:56:18.760 --> 00:56:21.990
AV Capture Connection exposes the
current state of the media stream

00:56:22.250 --> 00:56:23.420
while the session is running.

00:56:23.540 --> 00:56:26.710
If you refer to code snippet 27,
this shows how you do

00:56:26.720 --> 00:56:28.300
audio level metering.

00:56:28.380 --> 00:56:30.910
If you have an output,
you can ask the output

00:56:30.920 --> 00:56:32.450
for its connections.

00:56:32.540 --> 00:56:35.460
Once you've got the connection,
so here I omitted the code where

00:56:35.460 --> 00:56:40.060
you found your audio connection,
it has an array of audio channel objects.

00:56:40.140 --> 00:56:42.480
One for each source audio channel.

00:56:42.670 --> 00:56:44.640
Usually you'll have mono,
so there'll just be one channel.

00:56:44.870 --> 00:56:47.780
But if you have a cool
accessory plugged in,

00:56:47.780 --> 00:56:49.050
you might have two.

00:56:49.300 --> 00:56:52.560
And then for each of those channels,
you can iterate over them and get the

00:56:52.620 --> 00:56:55.520
channel's average or peak hold level,
update your levels,

00:56:55.530 --> 00:56:59.960
and do a bouncy lights
audio level kind of UI.

00:57:00.240 --> 00:57:03.560
Now, this is not, these are not key value
observable properties.

00:57:03.620 --> 00:57:06.160
You have to poll for audio levels.

00:57:06.210 --> 00:57:09.460
We don't want to assume
that you want audio levels.

00:57:09.510 --> 00:57:12.520
And so we don't automatically
update them on your behalf.

00:57:12.650 --> 00:57:17.000
As often as you want audio levels,
poll for the new value and you'll get it.

00:57:18.380 --> 00:57:23.060
AV capture connections refer to the
specific stream in an output delegate.

00:57:23.200 --> 00:57:25.460
We talked about that
throughout the session as we

00:57:25.470 --> 00:57:27.110
looked at these connections.

00:57:27.260 --> 00:57:32.690
It's always the second to last or
last parameter from connections.

00:57:33.000 --> 00:57:36.110
It identifies a single stream
going to that connection.

00:57:36.290 --> 00:57:38.540
AV capture session is greedy.

00:57:38.640 --> 00:57:41.520
You can't make an AV capture
connection directly.

00:57:41.640 --> 00:57:44.510
When you make a session
and you add an input to it,

00:57:44.670 --> 00:57:48.040
it's going to greedily try to form
connections to all outputs that

00:57:48.410 --> 00:57:50.420
are compatible with that input.

00:57:50.510 --> 00:57:52.560
And the same goes for
when you add an output.

00:57:52.720 --> 00:57:57.670
So if you add a video input and you've
already got an output that accepts video,

00:57:57.790 --> 00:58:01.110
it will greedily go and form
connections on your behalf.

00:58:01.220 --> 00:58:02.200
But maybe you don't want that.

00:58:02.200 --> 00:58:06.080
Maybe you want a video input,
but just to do preview.

00:58:06.080 --> 00:58:09.580
You don't really want to record
video to your QuickTime movie.

00:58:09.690 --> 00:58:12.910
So knowing where the connection is,
you can set the property on

00:58:12.910 --> 00:58:14.640
the connection to disable it.

00:58:14.660 --> 00:58:16.880
And then you'll get no
video into your movie,

00:58:16.900 --> 00:58:19.280
just where you wanted it in your preview.

00:58:19.340 --> 00:58:22.720
So here we're showing how you can
get at the connections property.

00:58:22.740 --> 00:58:25.060
And here's how you might
disable the connection.

00:58:25.090 --> 00:58:28.210
Finding the connection with the
media type that you're interested

00:58:28.210 --> 00:58:30.020
in-- look at the orange part.

00:58:30.040 --> 00:58:32.190
If it is equal to the media type you
want-- it's going to be the same.

00:58:32.200 --> 00:58:36.770
you can disable the connection by
setting its enabled property to "no."

00:58:37.760 --> 00:58:41.200
In summary, we processed YU video frames.

00:58:41.240 --> 00:58:41.950
And how did we do that?

00:58:42.020 --> 00:58:45.030
We used the Video Data Output class.

00:58:45.130 --> 00:58:48.220
To control the camera,
we used AV Capture device.

00:58:48.290 --> 00:58:50.580
Take photos, we used still image output.

00:58:50.630 --> 00:58:53.300
Movie file output to record movies.

00:58:53.350 --> 00:58:57.640
We used the AV Capture video preview
layer to preview video from the

00:58:57.740 --> 00:58:59.540
camera to a core animation layer.

00:58:59.580 --> 00:59:04.190
And we processed PCM audio data
using the audio data output.

00:59:04.260 --> 00:59:08.980
Please contact Eric Verschen if you have
any more questions about the technology.

00:59:09.000 --> 00:59:13.020
And come and see us throughout
the week in our other sessions.

00:59:13.060 --> 00:59:14.640
Thank you all for
sticking it out with us,

00:59:14.770 --> 00:59:17.190
and have a great rest of your show.