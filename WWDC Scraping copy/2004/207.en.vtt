WEBVTT

00:00:12.300 --> 00:02:34.900
[Transcript missing]

00:02:37.100 --> 00:02:39.490
Thank you, Travis, for the introduction,
and thank you all for coming to

00:02:39.560 --> 00:02:44.200
today's session on high dynamic
range imaging with Image IO.

00:02:44.960 --> 00:02:48.240
What I want to talk about today and
what you'll learn is about the new,

00:02:48.240 --> 00:02:51.140
exciting,
emerging field of high dynamic range

00:02:51.140 --> 00:02:58.400
imaging and how you can take advantage
of it today in Tiger using a new

00:02:58.400 --> 00:02:58.400
facet of Quartz called Image IO.

00:02:58.710 --> 00:03:02.540
But before I talk about those two
fields and the people who'll be coming

00:03:02.540 --> 00:03:05.410
up and talking about it in more detail,
I want to give a brief update on

00:03:05.410 --> 00:03:07.620
what's new in ColorSync for Tiger.

00:03:07.620 --> 00:03:11.110
Because ColorSync is one of the key
pieces of technology that allows

00:03:11.110 --> 00:03:14.680
for the proper rendering of both
standard and high dynamic range images.

00:03:14.680 --> 00:03:17.400
So let me give an update
on ColorSync for Tiger.

00:03:17.400 --> 00:03:22.240
We'll be talking briefly about adding
floating point support in ColorSync,

00:03:22.240 --> 00:03:26.760
use of core foundation types,
some API changes we'll be making,

00:03:27.840 --> 00:03:31.790
some notes for developers of custom CMMs,
and some changes to ColorSync

00:03:31.790 --> 00:03:33.520
Utility's user interface.

00:03:33.520 --> 00:03:36.640
So first and foremost is
floating point support.

00:03:36.640 --> 00:03:39.870
As Travis mentioned earlier,
one of the things we're trying to do

00:03:39.960 --> 00:03:44.380
for Tiger is provide a new high fidelity
cinematic graphic environment for Tiger.

00:03:44.380 --> 00:03:47.000
And in order to achieve that,
we need full floating point support

00:03:47.000 --> 00:03:48.490
throughout the entire system.

00:03:48.500 --> 00:03:50.940
And one key piece of that is ColorSync.

00:03:50.980 --> 00:03:54.020
So in order to achieve this,
the first thing we needed to do was

00:03:54.110 --> 00:03:57.630
to have a new bitmap structure in
ColorSync for supporting arbitrary

00:03:57.630 --> 00:04:01.280
bitmaps of floating point data that
your application can pass to us.

00:04:01.280 --> 00:04:04.320
We wanted to make the structure
as flexible as possible so that

00:04:04.320 --> 00:04:07.000
you wouldn't have to repack the
data before you send it to us.

00:04:07.000 --> 00:04:10.990
So this new structure supports
both chunky and planar arrangement

00:04:11.030 --> 00:04:14.860
of data and also allows for the
channels to be in any arbitrary order.

00:04:14.860 --> 00:04:17.830
The way we achieve this in this structure
is it's a little different from other

00:04:17.910 --> 00:04:21.310
bitmap structures you may have seen,
is that instead of having a single

00:04:21.310 --> 00:04:24.670
base address for all the pixel data,
we actually have a different

00:04:24.670 --> 00:04:26.160
base address for each channel.

00:04:26.320 --> 00:04:28.020
This allows for the
channels to be in any order.

00:04:28.080 --> 00:04:33.350
And then we also allow for both row
bytes and column bytes to be specified,

00:04:33.400 --> 00:04:37.450
which allows for you to have your data
be scanned in reverse order if needed,

00:04:37.500 --> 00:04:40.690
or also if you've got unusual
packing between channels that you

00:04:40.870 --> 00:04:42.560
want to make sure to skip over.

00:04:44.100 --> 00:04:47.320
So it's a fairly basic structure,
but in most cases,

00:04:47.360 --> 00:04:51.730
most people will be passing in a
buffer of chunky or interleaved data.

00:04:51.730 --> 00:04:56.360
And so we provided a simple utility
function called cmFloatBitmapMakeChunky,

00:04:56.360 --> 00:04:58.330
which you supply at a
single base address,

00:04:58.330 --> 00:05:01.220
and then it'll fill in the
structure appropriately for you.

00:05:01.280 --> 00:05:03.980
In either case,
whether you fill in the structure by

00:05:03.980 --> 00:05:07.360
hand or whether you call this helper API,
once you have a source and

00:05:07.410 --> 00:05:10.430
destination float bitmap,
you can then call color sync to

00:05:10.550 --> 00:05:12.660
match data from one space to another.

00:05:12.660 --> 00:05:14.750
We have three functions to do this.

00:05:14.750 --> 00:05:20.370
The first one is cmConvertXYZFloatMap,
which allows you to convert between

00:05:20.370 --> 00:05:25.360
all the CIE-related color spaces,
so XYZ, YXY, LAB, and LUV.

00:05:25.360 --> 00:05:29.010
And also another function,
which is convertRGBFloatMap,

00:05:29.050 --> 00:05:32.790
which allows you to convert
between the RGB-derived spaces,

00:05:32.790 --> 00:05:34.320
RGB, HSV, and HLS.

00:05:34.320 --> 00:05:37.310
Both of these functions are
based on textbook formulas,

00:05:37.390 --> 00:05:40.140
and so as a result,
there's no need to pass in a profile

00:05:40.140 --> 00:05:42.260
or color world to do the transform.

00:05:42.400 --> 00:05:44.800
It just does the math for you
with floating point precision.

00:05:46.540 --> 00:05:48.260
The last is probably
the most interesting.

00:05:48.260 --> 00:05:52.250
This is the new API, CMMatchFloatMap,
which allows you to pass in a

00:05:52.250 --> 00:05:56.020
color world reference to perform
the actual transformation.

00:05:56.160 --> 00:05:59.490
You can create the color world by
concatenating one or more profiles.

00:05:59.660 --> 00:06:06.270
And then at that point,
the data will be sent through to the CMM,

00:06:06.380 --> 00:06:07.930
which,
if it supports floating point data,

00:06:07.930 --> 00:06:07.930
will be done in full
floating point precision.

00:06:09.100 --> 00:06:12.900
One of the other changes we've made
to ColorSync is integrated in more

00:06:13.050 --> 00:06:15.040
closely with the core foundation types.

00:06:15.040 --> 00:06:18.840
And the key way we've done
this is that the two common

00:06:19.290 --> 00:06:23.270
ColorSync opaque data types,
which are the CM Profile

00:06:23.580 --> 00:06:27.340
Ref and the CM ColorWorld Ref,
are now CF types.

00:06:27.340 --> 00:06:29.790
And this is quite convenient
because it means that you can

00:06:29.790 --> 00:06:33.320
now call the CF-based functions,
such as CF Retain and CF Release.

00:06:33.320 --> 00:06:36.060
And it also means you can
add profiles and color worlds

00:06:36.060 --> 00:06:37.660
to dictionaries or arrays.

00:06:37.990 --> 00:06:40.840
This is kind of handy if you're
passing profiles and dictionaries

00:06:40.840 --> 00:06:42.200
around to other parts of your code.

00:06:42.220 --> 00:06:46.740
The other way that we supported a
core foundation type is to actually

00:06:47.230 --> 00:06:49.120
get the data out of a profile.

00:06:49.120 --> 00:06:52.720
One of the questions I often hear
from new users to ColorSync is,

00:06:52.720 --> 00:06:55.220
I've got this profile reference,
how do I get the data out of it?

00:06:55.370 --> 00:06:58.400
In the past,
that was done by calling either

00:06:58.450 --> 00:07:01.450
CM Copy Profile or CM Flatten Profile.

00:07:01.460 --> 00:07:02.700
Now it's much easier.

00:07:02.700 --> 00:07:05.300
You can just call
CM Profile Copy ICC Data,

00:07:05.300 --> 00:07:08.910
and it will return you all
the data within the profile

00:07:08.910 --> 00:07:11.850
as one giant CFData type.

00:07:16.140 --> 00:07:20.930
Next thing I want to talk about are some
API changes that we're making for Tiger.

00:07:21.180 --> 00:07:23.880
Way back several years ago,
one of the features

00:07:23.880 --> 00:07:26.400
we added to ColorSync,
both at the API and the

00:07:26.400 --> 00:07:30.160
user interface level,
were a set of preferences,

00:07:30.160 --> 00:07:35.530
so that applications could have one
place to go to for specifying default

00:07:35.530 --> 00:07:38.230
profiles based on usage or color space.

00:07:38.460 --> 00:07:41.060
And at the time,
we hoped that this would be a way

00:07:41.140 --> 00:07:45.090
of simplifying the user interface
across a wide variety of applications.

00:07:45.090 --> 00:07:49.760
And so we presented both API and
user interface to help with this.

00:07:49.850 --> 00:07:52.180
In practice, however,
it's turned out that very few

00:07:52.210 --> 00:07:54.000
applications have used this API.

00:07:54.000 --> 00:07:56.110
And what we're left with is
user interface in ColorSync

00:07:56.210 --> 00:07:59.340
utility where people say,
"I can't figure out what this does

00:07:59.340 --> 00:08:04.050
because nothing I change here seems to
make a difference." So we're listening

00:08:04.050 --> 00:08:08.330
to the usage and we're actually
beginning the process of deprecating

00:08:08.330 --> 00:08:11.060
the API and also the user interface.

00:08:11.060 --> 00:08:13.000
So we still want the--any application
that's used in the ColorSync utility

00:08:13.000 --> 00:08:13.420
to be able to make a difference.

00:08:13.420 --> 00:08:13.420
So we're still looking at the application
that's used in the ColorSync utility.

00:08:13.420 --> 00:08:13.420
And so we're looking at the application
that's used in the ColorSync utility.

00:08:13.420 --> 00:08:13.420
And so we're looking at the application
that's used in the ColorSync utility.

00:08:13.420 --> 00:08:14.820
And so we're looking at the
applications that were using

00:08:14.820 --> 00:08:16.500
this API to function correctly.

00:08:16.590 --> 00:08:18.340
So what we're doing is
changing the behavior of

00:08:18.340 --> 00:08:23.100
CMGET default profile by space,
CMGET default profile by use,

00:08:23.290 --> 00:08:25.140
and CMGET preferred CMM.

00:08:25.270 --> 00:08:30.080
Instead of storing their preferences as a
setting that's global across the machine,

00:08:30.080 --> 00:08:32.670
it will now be stored in
the current application,

00:08:32.670 --> 00:08:34.340
current host, current user domain.

00:08:34.570 --> 00:08:38.470
So the APIs will still function,
but we're deprecating them.

00:08:38.600 --> 00:08:40.330
This has some ramifications
also in the UI,

00:08:40.330 --> 00:08:42.690
which I'll talk about later.

00:08:43.670 --> 00:08:47.240
I also want to take this time to
talk a little bit about custom CMMs.

00:08:47.260 --> 00:08:50.910
One of the things that we've been doing
over the last few years is making even

00:08:50.910 --> 00:08:54.660
tighter and more powerful integration
between the graphics system as a whole,

00:08:54.660 --> 00:08:57.880
notably courts and printing
and color management.

00:08:57.880 --> 00:09:01.820
And in order to achieve this with
high performance and high reliability,

00:09:01.820 --> 00:09:07.870
we have made it so that courts and
printing will only use the Apple CMM.

00:09:07.880 --> 00:09:10.390
That said,
we have a long tradition of allowing

00:09:10.390 --> 00:09:14.640
applications and other developers
to develop their own CMMs and for

00:09:14.770 --> 00:09:16.680
applications to call those if they wish.

00:09:16.680 --> 00:09:19.580
It's still possible for applications,
if they wish,

00:09:19.580 --> 00:09:22.680
to have a custom CMM and for
them to explicitly create a

00:09:22.830 --> 00:09:25.400
color world using that CMM,
and that can be done using the

00:09:25.780 --> 00:09:29.330
recommended API for this now,
is NCW Concat Color World.

00:09:29.340 --> 00:09:32.750
And this API has an easy,
convenient way for you to

00:09:32.810 --> 00:09:34.360
specify which CMM to use.

00:09:34.360 --> 00:09:38.420
The other thing to mention for
CMM developers is that there's

00:09:38.420 --> 00:09:41.670
a new entry point for CMMs,
which is CMM Match Float Map.

00:09:41.720 --> 00:09:45.450
If your CMM supports this,
then you can have a full floating

00:09:45.550 --> 00:09:47.740
point support throughout the
rest of the court system.

00:09:47.740 --> 00:09:50.870
And if you don't support this,
then the data will be truncated

00:09:50.870 --> 00:09:53.430
to 16-bit integers and everything
will work sufficiently.

00:09:56.130 --> 00:09:59.500
Lastly, I want to mention some changes
we're making to ColorSync Utility.

00:09:59.500 --> 00:10:03.200
As I mentioned earlier,
we're deprecating the Preferences

00:10:03.200 --> 00:10:05.020
APIs for default profiles.

00:10:05.180 --> 00:10:09.310
And one visual manifestation of this
is that we were removing the user

00:10:09.310 --> 00:10:11.380
interface from ColorSync Utility.

00:10:11.440 --> 00:10:15.160
However,
we're adding something in its place.

00:10:15.160 --> 00:10:19.390
We'll be adding a new utility
to the ColorSync Utility,

00:10:19.410 --> 00:10:21.640
which we call a calculator.

00:10:21.640 --> 00:10:22.850
So let me give a brief
demonstration of this on Demo 2.

00:10:24.800 --> 00:10:26.690
over here.

00:10:26.740 --> 00:10:29.890
So as we see in the ColorSync utility,
everything looks similar except

00:10:30.000 --> 00:10:32.820
that there's no longer the
preferences pane as the first item.

00:10:32.990 --> 00:10:35.350
But we have a new item
which is a calculator,

00:10:35.350 --> 00:10:39.440
which provides a very simple way
to convert color spaces between all

00:10:39.580 --> 00:10:43.680
the various different color spaces
using floating point precision.

00:10:43.910 --> 00:10:46.640
This is a convenience that also
provides a good way to demonstrate

00:10:46.750 --> 00:10:48.340
our floating point data path.

00:10:48.400 --> 00:10:50.560
So obviously,
we can specify our source color space

00:10:50.560 --> 00:10:52.020
and our destination color space.

00:10:52.020 --> 00:10:55.780
If we're just converting RGB to HSV,
we can see the slider values.

00:10:55.780 --> 00:10:59.480
We can update the sliders on the left,
and they update on the right.

00:11:00.060 --> 00:11:05.400
One thing you'll notice is because the
RGB and HSV are related color spaces,

00:11:05.430 --> 00:11:08.500
they're basic formulas for each other.

00:11:08.500 --> 00:11:10.810
So as a result,
the color on the left will be the

00:11:10.860 --> 00:11:12.480
same as the color on the right.

00:11:12.550 --> 00:11:17.990
If we switch to CMYK,
you'll see something slightly different,

00:11:18.360 --> 00:11:21.810
which is now it's going
through a profile.

00:11:21.810 --> 00:11:23.640
And if I go to a saturated color,
you'll notice that the color

00:11:23.640 --> 00:11:23.640
on the right is desaturated.

00:11:23.830 --> 00:11:27.470
One of the other things we added is the
ability for it to be fully symmetrical.

00:11:27.540 --> 00:11:30.010
So now instead of just
updating on the left,

00:11:30.010 --> 00:11:32.930
I can also update on the right,
and it'll show you the

00:11:33.180 --> 00:11:34.400
values in that order.

00:11:34.400 --> 00:11:38.100
We can also, this is an interesting way
to test out a CMYK profile.

00:11:38.100 --> 00:11:42.060
We can specify that we want to
input LAB values and output to CMYK.

00:11:42.060 --> 00:11:45.770
And as we scroll through
all the possible LAB values,

00:11:45.770 --> 00:11:49.410
we can see what the resulting
CMYK values will be.

00:11:51.720 --> 00:11:55.360
So that's the brief demo
of the color calculator.

00:11:55.360 --> 00:11:58.840
We hope that's a useful function.

00:11:58.910 --> 00:12:01.000
So back to slides.

00:12:03.950 --> 00:12:07.260
So the next thing I want to talk about
is something that's all new for Tiger,

00:12:07.280 --> 00:12:10.320
which is this new facet
of Quartz called Image IO.

00:12:10.510 --> 00:12:14.860
And again, as Travis alluded to earlier,
we wanted to provide a new API for

00:12:14.960 --> 00:12:19.860
doing image processing or image reading
and writing from a variety of formats.

00:12:19.910 --> 00:12:20.860
And this is Image IO.

00:12:20.860 --> 00:12:23.410
We'll be talking today
about its features,

00:12:23.470 --> 00:12:27.070
its goals, what formats it supports,
the clients of this API,

00:12:27.200 --> 00:12:31.350
some of the core concepts that you
need to understand for using this API,

00:12:31.620 --> 00:12:33.900
and some advanced techniques as well.

00:12:35.430 --> 00:12:36.890
So what are the features of Image IO?

00:12:37.050 --> 00:12:38.580
Well,
first is we want to be able to read a

00:12:38.660 --> 00:12:42.480
wide variety of file formats and write
to a wide variety of file formats.

00:12:42.480 --> 00:12:45.360
We also want to support
reading and writing metadata.

00:12:45.420 --> 00:12:48.200
And also,
we want to support incremental loading

00:12:48.240 --> 00:12:51.770
for clients such as web browsers
that get data in an incremental

00:12:51.770 --> 00:12:54.160
fashion over a slow data connection.

00:12:54.160 --> 00:12:58.720
We also want to support
floating point support,

00:12:58.720 --> 00:12:59.840
because that's one of the key
initiatives for graphics in Tiger.

00:13:00.090 --> 00:13:03.920
We also want to have broad color
space support and something

00:13:03.920 --> 00:13:05.600
called cacheable decompression.

00:13:05.600 --> 00:13:09.120
I mentioned a little bit on this now,
which is, typically,

00:13:09.150 --> 00:13:12.630
different APIs for reading and writing
image file formats have one of two

00:13:12.690 --> 00:13:15.180
behaviors in terms of decompression.

00:13:15.250 --> 00:13:17.670
In the case of the existing
core graphics APIs,

00:13:18.040 --> 00:13:21.100
every time you draw the image,
it's fully decompressed each time.

00:13:21.180 --> 00:13:24.350
This obviously has the advantage that
you have very little memory overhead,

00:13:24.450 --> 00:13:28.200
but it's a performance hit if you
draw the image more than once.

00:13:28.260 --> 00:13:31.960
Other APIs have the behavior that
the first time you draw the image,

00:13:31.960 --> 00:13:35.630
it fully decompresses it,
which obviously requires more memory,

00:13:35.760 --> 00:13:40.540
but has the advantage that subsequent
draws will perform quickly.

00:13:40.600 --> 00:13:42.130
There are merits to both approaches.

00:13:42.340 --> 00:13:45.800
And so one of the approaches
we've used with ImageIO is to

00:13:45.920 --> 00:13:47.960
try to allow for both features.

00:13:48.030 --> 00:13:49.980
Not all file formats
support both approaches,

00:13:49.990 --> 00:13:54.520
but wherever possible,
we support both philosophies.

00:13:55.210 --> 00:13:57.640
Here are some of the
overarching goals for image.io.

00:13:57.760 --> 00:14:01.080
First and foremost was to
reduce code duplications.

00:14:01.090 --> 00:14:04.670
Turns out there was an embarrassing
number of different variants of

00:14:04.740 --> 00:14:08.100
JPEG readers and writers and TIFF readers
and writers within our system.

00:14:08.100 --> 00:14:10.320
And they all had different
strengths and weaknesses.

00:14:10.320 --> 00:14:12.200
And if you were actually
trying to write an application

00:14:12.200 --> 00:14:14.730
that read and wrote images,
you had to make a choice

00:14:14.730 --> 00:14:17.700
between which strengths and
weaknesses you wanted to use.

00:14:17.790 --> 00:14:21.000
We wanted to have a single reference
implementation within the system

00:14:21.050 --> 00:14:24.510
and use that in as many places as
possible so that we have a single

00:14:24.620 --> 00:14:27.090
place to make changes in the future.

00:14:27.320 --> 00:14:29.860
One of the other goals is we wanted
to leverage open source so that our

00:14:30.000 --> 00:14:33.200
behavior of our APIs was consistent
with other implementations.

00:14:33.340 --> 00:14:34.630
And improve performance.

00:14:34.780 --> 00:14:35.840
This is one of the other key things.

00:14:35.840 --> 00:14:42.620
We've been spending a lot of time
with the vectorization team at

00:14:42.680 --> 00:14:45.430
Apple to make sure that our key file
formats decompress with optimum speed.

00:14:46.120 --> 00:14:49.180
Another feature was lazy decompression
in the sense that if all you

00:14:49.180 --> 00:14:52.350
need to do is get the height
and width or metadata out of an image,

00:14:52.370 --> 00:14:54.100
you shouldn't have to
fully decompress the data.

00:14:54.100 --> 00:14:55.500
So we want to support that as well.

00:14:55.500 --> 00:14:58.850
And lastly, we wanted to make sure
we had a very modern,

00:14:58.850 --> 00:15:02.700
core graphics-friendly,
and easy-to-use API that you could all

00:15:02.700 --> 00:15:04.860
easily adopt this in your applications.

00:15:06.680 --> 00:15:09.500
So one of the first questions I always
get when I'm talking about image I/O is,

00:15:09.500 --> 00:15:11.500
well, what formats do you support?

00:15:11.520 --> 00:15:13.820
And we support all the
standards for the internet,

00:15:13.830 --> 00:15:17.480
TIFF, JPEG, PNG, JIF, and JPEG 2000.

00:15:17.480 --> 00:15:21.480
These are already supported on the
Developer CD that you got this week.

00:15:21.610 --> 00:15:23.550
We're also supporting
some exciting new formats,

00:15:23.550 --> 00:15:27.710
such as some high dynamic range formats,
such as OpenAXR, Radiance,

00:15:27.710 --> 00:15:34.140
and some important variants on TIFF,
such as Log LUV, and some Pixar variants.

00:15:34.180 --> 00:15:38.160
There's also countless other formats
we're going to be supporting,

00:15:38.160 --> 00:15:43.100
BMP, PSD, QTIF, SGI, ICNS files.

00:15:43.140 --> 00:15:47.110
And we're considering more,
both for Tiger and beyond.

00:15:48.670 --> 00:15:50.000
So the clients for Image IO.

00:15:50.090 --> 00:15:52.620
Obviously, we hope that anyone who wishes
to use this API are free to

00:15:52.760 --> 00:15:54.000
use them in their application.

00:15:54.000 --> 00:16:02.260
But there's also lots of places
within the system that are

00:16:02.260 --> 00:16:02.740
going to be calling Image IO.

00:16:02.740 --> 00:16:02.740
So you may get the benefits
of Image IO without having

00:16:02.740 --> 00:16:02.740
to change your code at all.

00:16:03.130 --> 00:16:06.330
Probably the first and most
important client for Image IO is

00:16:06.330 --> 00:16:07.900
the preview application.

00:16:07.900 --> 00:16:12.350
This has been a great example of how
the power of the new Image IO and some

00:16:12.350 --> 00:16:14.910
of the advantages you can get from it.

00:16:14.970 --> 00:16:17.100
It's making strong use of this new API.

00:16:17.100 --> 00:16:19.460
Also, AppKit will be switching over.

00:16:19.460 --> 00:16:22.540
It's not yet switched over in
the current developer release,

00:16:22.540 --> 00:16:27.350
but AppKit will be switching over to
using the new Image IO API as well.

00:16:28.440 --> 00:16:33.390
WebKit and its clients, such as Safari,
Mail, and any of your applications

00:16:33.430 --> 00:16:35.580
that are using WebKit,
will be using Image IO.

00:16:35.680 --> 00:16:39.210
Core Image is using Image IO to
load data in floating point format.

00:16:39.280 --> 00:16:44.200
Spotlight is using it for generation
of thumbnails and getting metadata.

00:16:44.420 --> 00:16:47.880
And some of our scripting technologies,
such as SIPs and image events,

00:16:47.900 --> 00:16:49.230
are also using Image IO.

00:16:49.240 --> 00:16:53.230
So we're trying to use this
everywhere in the system.

00:16:54.520 --> 00:16:59.410
Eventually, I want to give an outline
on the API in Image IO,

00:16:59.410 --> 00:17:05.530
but before I do that,
I want to talk a little bit about

00:17:05.530 --> 00:17:05.530
how images are organized so that
you can get an understanding for why

00:17:05.530 --> 00:17:05.530
we designed the API the way we did.

00:17:06.390 --> 00:17:09.870
In previous systems,
the standard way of representing an image

00:17:09.900 --> 00:17:12.440
in core graphics was with a CgImageRef.

00:17:12.440 --> 00:17:15.660
And this was a great basic
format for representing images.

00:17:15.660 --> 00:17:19.310
It allows you to specify three things:
the geometry of the image,

00:17:19.320 --> 00:17:22.390
such as its height, width,
rowbytes and pixel size,

00:17:22.390 --> 00:17:24.940
the color space of the image,
which can be a profile or

00:17:24.940 --> 00:17:27.240
other equivalent description
of the color space,

00:17:27.240 --> 00:17:28.610
and the actual pixel data.

00:17:28.610 --> 00:17:32.200
This is the minimum information
you need to describe an image.

00:17:32.360 --> 00:17:34.790
However, it turns out that there's a
lot of file formats out there,

00:17:34.790 --> 00:17:38.260
and they are actually quite
elaborate in many cases.

00:17:38.260 --> 00:17:41.210
And so one of the things we
wanted to support in Image.io

00:17:41.210 --> 00:17:43.580
was a richer model for images.

00:17:43.580 --> 00:17:46.060
For one thing,
we wanted to be able to support

00:17:46.130 --> 00:17:49.560
thumbnails and metadata for images.

00:17:49.590 --> 00:17:51.590
And also,
a lot of file formats support multiple

00:17:51.600 --> 00:17:54.940
images within the same file format,
such as TIFF.

00:17:54.940 --> 00:17:57.460
So we want to make sure
we support that as well.

00:17:57.470 --> 00:18:00.140
And also,
there's a set of attributes that apply

00:18:00.140 --> 00:18:03.330
to the image file as a whole rather
than to the individual file images

00:18:03.330 --> 00:18:05.420
contained within the image file.

00:18:05.670 --> 00:18:09.980
This is the file format of the image,
such as whether it's TIFF or JPEG,

00:18:09.980 --> 00:18:12.560
and also some properties that
apply to the file as a whole.

00:18:12.730 --> 00:18:15.540
For example,
TIFF files can be big Indian.

00:18:16.300 --> 00:18:18.240
Here's an example of how
this works in practice.

00:18:18.250 --> 00:18:20.500
We're using an example of a TIFF file.

00:18:20.650 --> 00:18:23.660
The file type is public.TIFF,
which is a universal type

00:18:23.730 --> 00:18:27.500
identifier that describes this
image as being of the type TIFF.

00:18:27.560 --> 00:18:29.840
We have some properties that
apply to the file as a whole,

00:18:29.910 --> 00:18:33.120
the file size and bytes, for example,
and the endianness of the TIFF.

00:18:33.120 --> 00:18:36.780
And then we have the standard
information for each image,

00:18:36.970 --> 00:18:40.650
such as its height and width,
its color space, its pixel data,

00:18:40.710 --> 00:18:43.750
its thumbnail, if possible,
and its metadata,

00:18:43.810 --> 00:18:46.150
such as copyright and artistry.

00:18:46.200 --> 00:18:48.260
information, you name it.

00:18:49.310 --> 00:18:53.200
So here's how this model is reflected
in our API through data types.

00:18:53.370 --> 00:18:57.390
What we have is we use the existing
CG image ref to represent the geometry,

00:18:57.440 --> 00:18:59.090
color space, and pixel data.

00:18:59.230 --> 00:19:02.630
The thumbnail is also
represented by a CG image ref.

00:19:02.800 --> 00:19:05.380
The metadata and the file
properties are represented as

00:19:05.410 --> 00:19:07.020
key values in a CFDictionaryRef.

00:19:07.230 --> 00:19:09.420
So it's all very simple.

00:19:10.480 --> 00:19:12.930
So now I can talk a
little bit about the API.

00:19:13.050 --> 00:19:16.400
What we've added is a new data
type called CGImageSource,

00:19:16.420 --> 00:19:19.230
and this is the opaque type
used for reading images

00:19:19.630 --> 00:19:21.910
from either memory or disk.

00:19:22.030 --> 00:19:26.400
You can create a CGImageSource
from either a CFURLRef,

00:19:26.430 --> 00:19:29.590
CFData, or with a CG data provider.

00:19:29.840 --> 00:19:32.870
Once you have a CG image source,
you can query the image

00:19:33.100 --> 00:19:35.190
source for several attributes.

00:19:35.200 --> 00:19:38.190
You can ask for the properties
of the file as a whole using

00:19:38.280 --> 00:19:40.160
CGImageSourceGetProperties.

00:19:40.290 --> 00:19:44.200
You can ask for its file type
by calling CGImageSourceGetType.

00:19:44.540 --> 00:19:48.480
You can get the count of images
using CGImageSourceGetCount.

00:19:48.520 --> 00:19:51.270
Once you know the count of images,
you can then, for each image,

00:19:51.270 --> 00:19:53.000
ask for its image.

00:19:53.050 --> 00:19:56.480
You can ask for its thumbnail,
and you can ask for its metadata.

00:19:56.940 --> 00:19:58.840
So it's pretty simple.

00:19:58.900 --> 00:20:01.140
Just to show you how this works,
here's a little code

00:20:01.140 --> 00:20:03.590
sample that shows you how,
given a URL,

00:20:03.590 --> 00:20:06.120
to get the first image out of the file.

00:20:06.150 --> 00:20:08.060
It also returns some simple metadata.

00:20:08.060 --> 00:20:10.790
In this case,
it's just returning the DPI of the image

00:20:10.860 --> 00:20:13.150
in the horizontal and vertical direction.

00:20:13.470 --> 00:20:20.190
First thing this code does is
call CGImageSourceCreateWithURL,

00:20:20.190 --> 00:20:21.730
which creates our data type for
subsequent access to the file.

00:20:21.950 --> 00:20:23.750
Then what we want to do is
we want to get the set of

00:20:23.750 --> 00:20:25.020
properties for the first image.

00:20:25.250 --> 00:20:27.960
So we call
CGImageSource.getPropertiesAtIndex,

00:20:28.100 --> 00:20:29.580
and that returns a dictionary.

00:20:29.720 --> 00:20:36.550
We can then query that
dictionary to see if it has the

00:20:36.550 --> 00:20:36.550
DPI height and width properties
and return those to the client.

00:20:36.780 --> 00:20:38.550
Lastly,
we need to actually return the image,

00:20:38.710 --> 00:20:41.240
so we call CGImageSource
createImageAtIndex,

00:20:41.240 --> 00:20:43.830
and that will return
the image to the caller.

00:20:44.650 --> 00:20:47.360
Here's another example for getting
a thumbnail out of an image.

00:20:47.490 --> 00:20:50.390
Image IO is very flexible
for creating thumbnails.

00:20:50.550 --> 00:20:53.030
As it turns out,
some file formats support thumbnails,

00:20:53.040 --> 00:20:54.090
some don't.

00:20:54.190 --> 00:20:56.890
Also, with some file formats,
the thumbnails can be quite large.

00:20:57.100 --> 00:21:05.870
Your application may need to have
control over how thumbnails are returned,

00:21:05.870 --> 00:21:05.870
and we provided that with the
Image IO API via an options dictionary.

00:21:06.730 --> 00:21:08.860
In this case,
what we're doing is we're again creating

00:21:08.860 --> 00:21:11.950
a CG image source by specifying a URL.

00:21:12.210 --> 00:21:14.300
And then we're going to be
creating an options dictionary

00:21:14.300 --> 00:21:16.180
with two key value pairs in it.

00:21:16.220 --> 00:21:20.200
The first key is CG image source
create thumbnail from image if present.

00:21:20.200 --> 00:21:24.200
What this does is tell Image IO that even
if the image doesn't create a thumbnail,

00:21:24.200 --> 00:21:26.180
return the actual image instead.

00:21:26.180 --> 00:21:28.120
So we'll always get an
image for the thumbnail.

00:21:28.850 --> 00:21:34.280
The second key value pair we specify is
CG image source thumbnail max pixel size.

00:21:34.390 --> 00:21:37.540
And this allows us to make sure that
the thumbnail is of a reasonable size,

00:21:37.540 --> 00:21:40.740
which is especially important if
you've specified the previous option.

00:21:40.740 --> 00:21:42.770
So in this case,
we're saying that we always

00:21:42.770 --> 00:21:45.070
want an image to be returned,
and we want it to be no

00:21:45.070 --> 00:21:47.340
bigger than 160 by 160 pixels.

00:21:47.340 --> 00:21:50.480
Once we've created that dictionary,
all we do is call CG image

00:21:50.590 --> 00:21:54.820
source create thumbnail at index,
specifying the image source, 0 at index,

00:21:54.820 --> 00:21:57.740
and the options dictionary,
and it's returned.

00:21:58.580 --> 00:22:01.000
This is, for example,
the way that the spotlight

00:22:01.000 --> 00:22:04.850
technology creates thumbnails for
images in the search results field.

00:22:07.570 --> 00:22:10.560
So that's the basics of
reading from an image I/O.

00:22:10.670 --> 00:22:11.650
Here's what we do for writing.

00:22:11.810 --> 00:22:14.680
We have another data type,
which is CGImageDestination,

00:22:14.880 --> 00:22:19.440
which can be created with the CFURL,
CF mutable data,

00:22:19.570 --> 00:22:21.400
or with a CG data consumer.

00:22:21.410 --> 00:22:24.220
At the time of creation,
you also specify the type of the file,

00:22:24.370 --> 00:22:28.750
whether it's a JPEG or TIFF for example,
and the capacity, or the number of images

00:22:28.830 --> 00:22:30.480
that that image will hold.

00:22:30.520 --> 00:22:33.810
Once you have a CGImageDestination,
you can specify the properties

00:22:33.810 --> 00:22:37.360
for the file as a whole using
CGImageDestinationSetProperties.

00:22:37.390 --> 00:22:40.700
And then you can repeatedly add
each image with various options

00:22:40.700 --> 00:22:45.020
and metadata at the same time
using CGImageDestinationAddImage.

00:22:45.050 --> 00:22:50.070
Lastly, you can flush the file out to
either the URL or to the data by

00:22:50.300 --> 00:22:52.330
calling CGImageDestinationFinalize.

00:22:52.470 --> 00:22:56.650
And that returns true if the
image was successfully flushed.

00:22:59.370 --> 00:23:02.580
Again, let me give a short example
just to show how easy this is

00:23:02.580 --> 00:23:04.570
to add to your application.

00:23:04.700 --> 00:23:10.080
We have a function called WriteJPEGData,
which takes a URL and an image to write

00:23:10.080 --> 00:23:13.540
and a DPI to specify in the metadata.

00:23:13.540 --> 00:23:17.190
First thing we do is we create
an image destination with a URL,

00:23:17.190 --> 00:23:22.130
specifying that it's going to be of type
JPEG and that it's got one image in it.

00:23:22.220 --> 00:23:26.160
Next thing we do is we specify
a dictionary with three keys and

00:23:26.160 --> 00:23:28.620
values for options and metadata.

00:23:29.200 --> 00:23:32.150
One option that we're specifying
is the quality of the JPEG,

00:23:32.230 --> 00:23:36.740
and that's specified with the
key KCG image property quality.

00:23:36.760 --> 00:23:39.590
In this example,
we're specifying a quality

00:23:39.590 --> 00:23:42.180
of 0.8 or 80% compression.

00:23:42.180 --> 00:23:45.890
The other two key
values are for metadata,

00:23:45.890 --> 00:23:51.310
and they are the KCG image
property DPI width and DPI height.

00:23:51.320 --> 00:23:54.000
In this case,
we're just creating CFNumbers based

00:23:54.000 --> 00:23:55.900
on the value that was passed in.

00:23:55.920 --> 00:23:59.180
Once we have this dictionary,
then we call CGImageDict.

00:23:59.260 --> 00:24:02.670
We call CGImageDestinationAddImage
to add the image and its options and

00:24:02.670 --> 00:24:04.820
metadata to the CGImageDestination.

00:24:04.820 --> 00:24:07.850
And lastly,
we call CGImageDestinationFinalize

00:24:07.850 --> 00:24:09.540
to write the file to disk.

00:24:09.600 --> 00:24:10.790
So it's pretty easy.

00:24:13.180 --> 00:24:14.440
So those are the basics of Image IO.

00:24:14.440 --> 00:24:17.810
I hope I've given the impression
that this is a very simple and easy

00:24:17.820 --> 00:24:19.740
API to add to your application.

00:24:19.960 --> 00:24:21.820
And again,
some of these benefits you'll be

00:24:22.020 --> 00:24:25.000
getting for free if you're using
AppKit and other technologies.

00:24:25.030 --> 00:24:27.440
Let me talk for a minute about some
of the more advanced techniques

00:24:27.570 --> 00:24:29.820
that come up when we talk about
image reading and writing,

00:24:29.940 --> 00:24:33.980
such as extracting ARGB data,
requesting the depth of an image,

00:24:33.980 --> 00:24:36.200
and loading an image incrementally.

00:24:38.560 --> 00:24:41.480
So one of the common
questions we have is,

00:24:41.510 --> 00:24:44.570
well,
an image has been returned from ImageIO,

00:24:44.670 --> 00:24:46.920
but I don't know what color space it is.

00:24:46.920 --> 00:24:47.820
I don't know what depth it is.

00:24:47.820 --> 00:24:49.820
I don't know what pixel format it is.

00:24:49.850 --> 00:24:52.120
And I have an application
that only works in RGB.

00:24:52.120 --> 00:24:53.130
That's a common scenario.

00:24:53.140 --> 00:24:55.490
And this is an interesting
piece of code that makes it

00:24:55.500 --> 00:24:58.560
very easy to convert the data,
no matter what format it came in,

00:24:58.790 --> 00:24:59.620
into ARGB.

00:25:00.030 --> 00:25:05.350
Basically, the technique is to use a
CG bitmap context to render the

00:25:05.350 --> 00:25:07.920
original image into an offscreen.

00:25:07.950 --> 00:25:10.280
And one advantage of this is
that it takes care of all the

00:25:10.400 --> 00:25:11.360
color management correctly.

00:25:11.370 --> 00:25:14.800
If the image happened to be an
LAB or CMYK image and had a profile,

00:25:14.930 --> 00:25:18.270
then it'll be correctly color
managed to the RGB color

00:25:18.270 --> 00:25:20.290
space that you're working in.

00:25:21.820 --> 00:25:25.640
Another interesting question
is the depths of image.

00:25:25.670 --> 00:25:27.700
Some formats only
support one pixel depth.

00:25:27.790 --> 00:25:31.070
For example,
JPGs are always 8 bits per sample.

00:25:31.180 --> 00:25:33.400
Other formats can support
arbitrary pixel depths.

00:25:33.460 --> 00:25:38.100
For example, TIFFs can be 1, 2, 4, 8,
or 16 bits per sample.

00:25:38.230 --> 00:25:42.730
As a rule, the image returned by
Image IO will be the same depth

00:25:42.950 --> 00:25:44.380
as that indicated by the file.

00:25:44.590 --> 00:25:50.170
So if you open a 16-bit TIFF file,
you'll get a 16-bit CG image ref.

00:25:50.670 --> 00:25:53.420
However, in the case of high
dynamic range file formats,

00:25:53.420 --> 00:25:55.290
it gets a little bit more complicated.

00:25:55.460 --> 00:25:58.010
The data in these file formats
are typically encoded in

00:25:58.010 --> 00:26:00.800
special encoding formats,
which can then be decoded

00:26:00.800 --> 00:26:01.940
in a variety of ways.

00:26:01.940 --> 00:26:05.290
They can either be unpacked
to floating point values,

00:26:05.290 --> 00:26:08.850
either 32- or 16-bit formats,
or to integers with

00:26:09.160 --> 00:26:11.150
16- or 8-bit precision.

00:26:11.180 --> 00:26:14.470
Also, in the decoding process,
they can either be left

00:26:14.470 --> 00:26:17.900
as extended range values,
or they can be compressed to the

00:26:17.900 --> 00:26:20.160
logical 0-to-1 clipped range.

00:26:21.650 --> 00:26:24.740
Both of these are reasonable
types of values to be returned,

00:26:24.740 --> 00:26:27.460
and your application may
want one versus the other.

00:26:27.680 --> 00:26:32.150
By default,
CG Image IO will return an image ref

00:26:32.350 --> 00:26:34.610
that's compressed to 16-bit integers.

00:26:34.740 --> 00:26:38.320
This gives the best results
with reasonable memory for

00:26:38.320 --> 00:26:40.300
the typical application.

00:26:40.470 --> 00:26:45.780
However, if by request,
an application can specify that

00:26:45.790 --> 00:26:47.800
they want the floating point
unprocessed data returned.

00:26:48.490 --> 00:26:50.710
Here's a brief example
that shows how to do this.

00:26:50.710 --> 00:26:54.550
This is a code snippet that, given a URL,
will request that the data

00:26:54.550 --> 00:26:55.930
be returned in floats.

00:26:56.240 --> 00:26:58.900
And if the data is actually
returned as a float,

00:26:58.900 --> 00:27:02.960
a boolean will be returned to
specify that it was actually floats.

00:27:03.000 --> 00:27:05.950
The way we've done this is,
as you've seen from

00:27:05.950 --> 00:27:09.370
the previous examples,
we create an image source,

00:27:09.370 --> 00:27:14.440
and we specify an options dictionary,
which has as one of its key value pairs,

00:27:14.570 --> 00:27:16.750
CGImageSourceMaximumDepth
with the value 32.

00:27:16.910 --> 00:27:18.900
At this point,
we can then ask Image IO to get

00:27:18.900 --> 00:27:21.770
the properties of the first image,
given those options.

00:27:21.770 --> 00:27:23.760
And this will return a dictionary.

00:27:23.760 --> 00:27:28.930
We can then query that dictionary to see
if it has floating point data or not.

00:27:29.130 --> 00:27:32.730
Then lastly, we can get the image and
return that to the client.

00:27:34.150 --> 00:27:36.910
Another advanced technique I wanted to
make sure people knew that we supported

00:27:37.000 --> 00:27:38.600
was incremental loading of images.

00:27:38.600 --> 00:27:43.220
I won't go into too much detail on this,
but the basic idea is that you create an

00:27:43.220 --> 00:27:47.940
image source in an incremental fashion
using CG image source create incremental,

00:27:47.970 --> 00:27:51.000
and then you repeatedly add
updated data to the image source.

00:27:51.200 --> 00:27:56.280
Each time you add data,
you can request a new image,

00:27:56.280 --> 00:27:58.830
and it'll give you a partial image or
complete if the image is fully loaded.

00:27:59.530 --> 00:28:01.940
The, um, and then at the-- once
you're done with the image,

00:28:01.980 --> 00:28:04.390
you can release it,
and then once you've added more data,

00:28:04.390 --> 00:28:05.760
you can get a new updated image.

00:28:06.030 --> 00:28:13.920
It's important that you release
it before you ask for a new image.

00:28:13.920 --> 00:28:13.920
So let me give a brief
demonstration of Image IO in action.

00:28:17.100 --> 00:28:21.870
So one of the things I want to
show first is the new preview.

00:28:21.870 --> 00:28:26.950
And I've got a bunch of images here.

00:28:26.950 --> 00:28:26.950
Open.

00:28:33.120 --> 00:28:35.690
And one nice thing in preview
is you can open all the images

00:28:35.690 --> 00:28:38.100
just by selecting a folder.

00:28:38.120 --> 00:28:40.400
And I've got a variety of images in here.

00:28:40.490 --> 00:28:45.170
One of them is an LAB image,
and we can do that by-- we

00:28:45.170 --> 00:28:49.140
can verify that it is an
LAB image by going to Tools,

00:28:49.140 --> 00:28:50.070
Get Info.

00:28:50.070 --> 00:28:55.290
And this shows the metadata that's
been obtained using Image IO.

00:28:55.290 --> 00:28:58.250
And we can tell in here from the
metadata that's currently returned

00:28:58.250 --> 00:28:58.250
that the color model is LAB.

00:29:00.000 --> 00:29:01.500
We have a variety of other images.

00:29:01.500 --> 00:29:02.440
We can zoom in and zoom out.

00:29:02.440 --> 00:29:05.550
The thumbnails over here were
obtained using Image IO as well.

00:29:05.560 --> 00:29:09.720
We have high dynamic range images here.

00:29:09.720 --> 00:29:12.030
We can zoom in and zoom out on that.

00:29:12.100 --> 00:29:16.140
Luke later will show how we can
manipulate these images in real time.

00:29:16.140 --> 00:29:19.860
Here's another interesting example
which I like to show people.

00:29:19.860 --> 00:29:21.900
This is one of our things
that we use for testing.

00:29:21.900 --> 00:29:24.570
Oftentimes, people want to know, well,
how do I know if the

00:29:24.570 --> 00:29:25.780
profile is being used?

00:29:25.800 --> 00:29:27.470
What I have here is a document.

00:29:27.470 --> 00:29:29.590
It's a black and white CMYK document.

00:29:29.930 --> 00:29:34.650
that has a profile in it that makes
values that are gray disappear.

00:29:34.650 --> 00:29:37.800
So if this image were rendered
and the profile were ignored,

00:29:37.800 --> 00:29:41.430
what you'd see is the text,
the embedded test profile is not used.

00:29:41.560 --> 00:29:45.520
And that's because you can't see it here,
because the profile is being used,

00:29:45.520 --> 00:29:48.120
but there's actually a
gray word not right here.

00:29:48.290 --> 00:29:51.510
So it provides an interesting
test so that you can tell if your

00:29:51.510 --> 00:29:53.500
profile is being respected or not.

00:29:53.500 --> 00:29:56.340
Here in this gray version,
you can kind of see a little

00:29:56.340 --> 00:29:59.250
bit of the hint of what was
once there and the word not.

00:29:59.250 --> 00:30:01.540
But this is a great
way of testing images.

00:30:01.540 --> 00:30:03.590
We really should distribute
these at some point.

00:30:04.340 --> 00:30:08.600
One other example of using Image IO,
I have a test application which

00:30:08.710 --> 00:30:10.020
shows some of the options.

00:30:10.150 --> 00:30:13.880
So let me go to open one
of the images we just saw,

00:30:13.880 --> 00:30:19.660
look at desktop images,
and open up this image here.

00:30:19.890 --> 00:30:23.590
We can see some information,
the height and width,

00:30:23.660 --> 00:30:25.840
and how long it took to draw.

00:30:25.840 --> 00:30:30.940
One thing we can do is we can specify
that we'd like to see what this would

00:30:30.940 --> 00:30:31.050
look like if it was progressively loaded.

00:30:31.360 --> 00:30:38.990
If I open up another image,
if I open the high dynamic range image,

00:30:38.990 --> 00:30:41.850
this is a big image, unfortunately,
so it takes a couple seconds to open.

00:30:43.110 --> 00:30:48.840
If we bring up the metadata on this,
we go to Window, Metadata.

00:30:48.840 --> 00:30:53.030
We can see that it has height and width,
and its depth is 16.

00:30:53.030 --> 00:30:55.560
This is because by default
we return 16-bit integers.

00:30:55.560 --> 00:31:02.710
However, if we want to return it as 32,
and again, it'll take a second or so.

00:31:04.830 --> 00:31:07.290
This code still needs to
be alt of x someday soon.

00:31:07.290 --> 00:31:09.540
We need to bring up the metadata.

00:31:09.850 --> 00:31:13.370
And now we can see that
there's a new property in here,

00:31:13.410 --> 00:31:16.980
which is saying that data
is returned as floats.

00:31:19.560 --> 00:31:21.000
So that's the introduction to Image IO.

00:31:21.000 --> 00:31:27.620
I'm going to pass the microphone
and the demonstration and all the

00:31:27.620 --> 00:31:30.060
new stuff over to Luke Wallis,
who will be talking about

00:31:30.090 --> 00:31:31.140
high dynamic range imaging.

00:31:31.140 --> 00:31:35.880
Thank you.

00:31:39.310 --> 00:31:41.360
Thank you, David.

00:31:41.530 --> 00:31:45.900
So today,
I will be talking about Mac OS X support

00:31:46.090 --> 00:31:50.960
for high dynamic range imaging,
which is a new and exciting feature that

00:31:51.130 --> 00:31:54.810
we are adding into the Tiger release.

00:31:54.910 --> 00:32:00.480
As many of you know,
high dynamic range imaging is generating

00:32:00.480 --> 00:32:04.940
a lot of interest and is still a
subject of very active research.

00:32:04.940 --> 00:32:08.680
So, we could talk about high
dynamic range imaging from

00:32:09.080 --> 00:32:13.240
many different points of view,
but what I would like to do

00:32:13.440 --> 00:32:18.350
today is concentrate on answering
very simple three questions.

00:32:18.360 --> 00:32:19.400
What is it?

00:32:19.440 --> 00:32:20.880
Why use it?

00:32:20.930 --> 00:32:23.530
And how to process it?

00:32:25.560 --> 00:32:32.120
Before we try to answer these questions,
let's take a quick look at the current

00:32:32.120 --> 00:32:36.340
status quo in digital image processing.

00:32:36.490 --> 00:32:42.990
We can conclude that in the majority,
digital image processing is dominated by

00:32:43.000 --> 00:32:46.460
what is called output-referred approach.

00:32:46.540 --> 00:32:49.010
What it means is that

00:32:49.190 --> 00:32:54.680
The requirement of image reproduction
are imposing certain requirements on

00:32:54.680 --> 00:32:59.910
the way we acquire and create images.

00:32:59.910 --> 00:33:02.370
And because most of the
devices we are dealing with,

00:33:02.650 --> 00:33:09.770
like displays and printers,
can only handle 8-bit

00:33:09.770 --> 00:33:09.770
data per color channel,

00:33:10.560 --> 00:33:15.900
We impose the same requirement
on digital cameras that,

00:33:16.120 --> 00:33:19.830
in fact,
could produce much more about an order

00:33:19.830 --> 00:33:25.480
of magnitude more data if they were
not restricted to that requirement.

00:33:27.310 --> 00:33:28.840
Obviously, there are some advantages.

00:33:28.910 --> 00:33:31.560
This is not done for no reason.

00:33:31.680 --> 00:33:36.710
The main is that there is a very minimal
image manipulation required before

00:33:36.710 --> 00:33:39.300
displaying or printing such an image.

00:33:39.300 --> 00:33:42.300
But obviously,
there is a disadvantage that we

00:33:42.300 --> 00:33:47.010
are losing a lot of color and image
information that could be used in further

00:33:47.230 --> 00:33:53.660
image processing that could result in
much higher quality of display or print.

00:33:55.880 --> 00:33:57.240
Oops, sorry, wrong direction.

00:33:57.240 --> 00:34:02.880
Another requirement,
which is sort of hidden in

00:34:02.880 --> 00:34:07.560
the output-referred approach,
is that the data is exchanged

00:34:07.560 --> 00:34:10.100
in one predefined color space.

00:34:10.100 --> 00:34:13.310
And in the most difficult case,
this is sRGB.

00:34:13.740 --> 00:34:21.080
So when you look at this slide,
you see I drew the shape of the

00:34:21.080 --> 00:34:26.900
typical exchange color space,
made it be sRGB.

00:34:27.470 --> 00:34:30.900
That color space covers
only a part of visual gamut.

00:34:30.970 --> 00:34:35.230
So everything is fine as long
as the camera is acquiring the

00:34:35.490 --> 00:34:37.600
color data within that triangle.

00:34:37.600 --> 00:34:41.700
But if we are outside,
then we are out of luck.

00:34:41.740 --> 00:34:45.050
We have to do something with this color,
and typically we have to

00:34:45.050 --> 00:34:46.720
push it into the color space.

00:34:46.720 --> 00:34:51.450
It can be done through different methods,
but because the cameras are

00:34:51.480 --> 00:34:55.300
not very sophisticated in
terms of processing power,

00:34:55.300 --> 00:34:57.380
we are using very often color space.

00:34:57.420 --> 00:35:01.600
And as we know from practice,
gamut clipping can produce

00:35:01.730 --> 00:35:05.340
really bad results,
like, for example, hue shift.

00:35:05.590 --> 00:35:09.730
And here is one of the maybe a
little bit strong and exaggerated

00:35:09.730 --> 00:35:13.940
examples what could happen,
but this is a real clipping

00:35:13.940 --> 00:35:19.590
in which the white color,
because of clipping, became a mixture of

00:35:19.660 --> 00:35:21.860
completely unrelated colors.

00:35:24.630 --> 00:35:30.320
So, when that is what we can conclude
when we look at the image processing

00:35:30.470 --> 00:35:35.500
from the point of view of device
capabilities to reproduce the image.

00:35:35.500 --> 00:35:38.860
And what I would like to do now is
to look at the image processing from

00:35:38.860 --> 00:35:42.590
a little bit different perspective,
from the perspective of human vision.

00:35:43.130 --> 00:35:47.820
And as we know from the very
rich research in this area,

00:35:48.140 --> 00:35:52.360
color and visual acuity are
two of the most important

00:35:52.370 --> 00:35:54.920
characteristics of the scene.

00:35:55.100 --> 00:35:59.260
And not only this,
these two depend on luminance

00:35:59.260 --> 00:36:02.600
and observer's visual adaptation.

00:36:02.750 --> 00:36:06.140
We know that we can measure
the world luminance,

00:36:06.140 --> 00:36:11.190
and it will cover the range of the
values between 10 to power of minus 6,

00:36:11.190 --> 00:36:16.970
all the way to the power of 10 to 8 when
measured in candelas per square meter.

00:36:17.300 --> 00:36:23.770
But what is important for us is
that different ranges of luminance

00:36:24.100 --> 00:36:27.690
create different illuminations.

00:36:28.820 --> 00:36:32.700
Now, and that illumination also can
stretch all the way from very

00:36:32.800 --> 00:36:37.080
dark environment through starlight
all the way beyond the sunlight.

00:36:37.660 --> 00:36:40.520
And now,
I could spend a lot of time talking

00:36:40.520 --> 00:36:50.700
about physiological and physiological
mechanism controlling our vision,

00:36:50.870 --> 00:36:54.140
but what I would like to do without
going through those details,

00:36:54.140 --> 00:36:57.950
to say that humans have
three types of vision,

00:36:58.270 --> 00:37:00.960
which are dependent of
the type of luminance.

00:37:00.960 --> 00:37:04.110
We have scotopic vision,
which works when we are

00:37:04.120 --> 00:37:05.780
in the dark environment.

00:37:06.100 --> 00:37:09.810
We have mesopic vision,
which works in light-dark environment.

00:37:10.230 --> 00:37:15.300
And finally, when we are in high
illumination environment,

00:37:15.470 --> 00:37:18.100
we switching to photopic vision.

00:37:18.590 --> 00:37:20.500
Why is this division important?

00:37:20.540 --> 00:37:25.760
Because our quality of vision is
related to this type of vision.

00:37:25.890 --> 00:37:30.640
As we know, if we look at something in
a very dark environment,

00:37:30.710 --> 00:37:35.260
we have no color vision
and very poor acuity.

00:37:35.310 --> 00:37:39.810
Everything in the darkness seems
to be just a shade of gray.

00:37:40.080 --> 00:37:45.510
On the other hand,
our best vision is in the photopic range,

00:37:45.510 --> 00:37:52.280
where we can see many colors and
have a good color and visual acuity.

00:37:53.550 --> 00:37:55.390
This is not everything.

00:37:55.390 --> 00:38:02.590
What is very important is that humans
have a limited simultaneous range,

00:38:02.800 --> 00:38:06.400
which also depends on
the type of illumination.

00:38:06.620 --> 00:38:11.390
And here I'm showing the
widest simultaneous range,

00:38:11.390 --> 00:38:14.690
which again exists in
the photopic vision,

00:38:14.840 --> 00:38:21.400
that can cover the range of
order of magnitude 3 to 4.

00:38:21.600 --> 00:38:23.790
But if we...

00:38:24.700 --> 00:38:34.470
Try to estimate this simultaneous
range in poor vision.

00:38:34.470 --> 00:38:37.460
The values can drop by the order of two.

00:38:38.190 --> 00:38:42.400
So, we may ask ourselves why
this is all important.

00:38:42.400 --> 00:38:45.730
Well, I think there is an answer.

00:38:45.880 --> 00:38:50.640
Because if we want to represent
faithfully the scene that we want

00:38:50.740 --> 00:38:57.010
to process through image processing,
we should have a mechanism to

00:38:57.030 --> 00:39:04.170
encode the data the same way,
or at least as close as possible

00:39:04.170 --> 00:39:06.000
to the human vision fidelity.

00:39:07.330 --> 00:39:11.060
So now,
let's take a look where in this picture

00:39:11.060 --> 00:39:14.200
we can fit the typical 8-bit display.

00:39:14.230 --> 00:39:17.720
And as we know,
the typical 8-bit display can

00:39:17.720 --> 00:39:23.080
cover the range of luminance
on the order of magnitude of 2.

00:39:23.080 --> 00:39:28.550
That is a big discrepancy between
human simultaneous range and

00:39:28.550 --> 00:39:31.220
dynamic range of a display.

00:39:31.720 --> 00:39:35.410
So,
this is the biggest challenge that we are

00:39:36.090 --> 00:39:43.090
facing when we have to map the relatively
wide human simultaneous range into low

00:39:43.390 --> 00:39:46.270
dynamic range of our display device.

00:39:47.030 --> 00:39:49.510
There is one solution which
we already know about.

00:39:49.730 --> 00:39:52.430
This is the output-referred
digital photography.

00:39:52.540 --> 00:39:56.170
We are imposing

00:39:56.200 --> 00:40:02.200
[Transcript missing]

00:40:02.310 --> 00:40:06.540
This is a small color space,
and the only thing we can do is to

00:40:06.540 --> 00:40:09.340
choose between different options.

00:40:09.340 --> 00:40:12.240
This is a simplistic
view in which we may say,

00:40:12.240 --> 00:40:14.960
well, if I want to expose the
details in highlight,

00:40:14.960 --> 00:40:16.840
I can use the short exposure.

00:40:16.840 --> 00:40:19.750
But if I want to see the
details in the shades,

00:40:19.750 --> 00:40:23.450
I can sacrifice the details
in highlights and use the long

00:40:23.450 --> 00:40:26.030
exposure to capture what I wanted.

00:40:26.040 --> 00:40:30.750
The most important point is that
this applied exposure is permanent.

00:40:30.870 --> 00:40:35.150
Once we burn this into the image,
there is no way back.

00:40:35.890 --> 00:40:39.220
So I think that at this moment
I will try to answer the question,

00:40:39.220 --> 00:40:40.980
what is high dynamic range?

00:40:41.250 --> 00:40:44.880
And I think that we can define
high dynamic range as a special

00:40:44.900 --> 00:40:48.680
encoding of the image data,
which allows us to preserve the

00:40:48.680 --> 00:40:50.780
full fidelity of human vision.

00:40:50.960 --> 00:40:54.800
From the implementation point of view,

00:40:55.020 --> 00:40:58.540
The high dynamic range imaging
is based on color values that,

00:40:58.540 --> 00:41:02.140
first of all, extend over at least
four orders of magnitude,

00:41:02.260 --> 00:41:05.660
that can encompass the
entire visible color gamut,

00:41:05.660 --> 00:41:12.690
and allow the values outside of a
typical 0 to 1 range values of color.

00:41:15.020 --> 00:41:19.150
In a summary, what it means that in high
dynamic range imaging,

00:41:19.150 --> 00:41:22.360
we are no longer limited
to a specific color space.

00:41:22.360 --> 00:41:28.650
We are trying to encompass, as I said,
all visible colors.

00:41:29.420 --> 00:41:32.100
But on the other hand,
we need to remember that we

00:41:32.100 --> 00:41:36.400
no longer have a convenient,
ready-to-display or ready-to-print image.

00:41:36.400 --> 00:41:40.570
High dynamic range data requires
some kind of manipulation

00:41:40.690 --> 00:41:42.860
before it can be displayed.

00:41:42.880 --> 00:41:46.260
But the big advantage is that
we can make this decision at the

00:41:46.520 --> 00:41:50.820
moment when we need to reproduce the
image with our preference instead

00:41:50.830 --> 00:41:52.220
of burning that to the image.

00:41:52.600 --> 00:41:59.910
This is a kind of simple
explanation how we can do that.

00:41:59.920 --> 00:42:02.410
We can go back and select
the short exposure,

00:42:02.510 --> 00:42:03.560
long exposure.

00:42:03.560 --> 00:42:07.880
But most importantly,
we can implement something

00:42:08.030 --> 00:42:12.030
which was not needed before,
is the tone map rendering,

00:42:12.030 --> 00:42:15.280
which will allow us to achieve
completely different results.

00:42:15.370 --> 00:42:19.730
For example, here,
I can try to combine in one image

00:42:19.730 --> 00:42:24.210
the details from the highlights
with the details from the shades.

00:42:25.760 --> 00:42:30.660
So now, I'll try to answer the question,
why use high dynamic range images?

00:42:30.660 --> 00:42:34.840
And the most important reason is
to preserve the scene-referred

00:42:34.960 --> 00:42:38.650
information that can be useful
in further image processing.

00:42:38.660 --> 00:42:41.620
And this way,
we want to avoid intermediate

00:42:41.620 --> 00:42:46.900
encoding with restrictive color gamut,
which was happening in this previous

00:42:46.900 --> 00:42:49.510
approach called output-preferred.

00:42:51.070 --> 00:42:57.540
And also, we can avoid irreversible
modifications that happened

00:42:57.540 --> 00:43:00.320
during the image acquisition.

00:43:02.430 --> 00:43:05.560
How to process high dynamic range images?

00:43:05.590 --> 00:43:13.290
The simplest answer is that we should
not add any rounding or clipping errors.

00:43:13.520 --> 00:43:16.490
And for that,
we want to render and capture

00:43:16.830 --> 00:43:18.860
the data in floating point.

00:43:18.880 --> 00:43:21.200
We want to store the entire image.

00:43:21.200 --> 00:43:24.960
And if needed, to process the color data
in extended color space,

00:43:24.960 --> 00:43:28.200
which again will not impose any clipping.

00:43:28.200 --> 00:43:31.260
And at the end,
we want to apply a tone mapping

00:43:31.330 --> 00:43:33.990
for a specific image reproduction.

00:43:34.060 --> 00:43:36.850
For example,
that specific reproduction could be

00:43:36.850 --> 00:43:40.280
an example I just showed you that
I want to see all the details in the

00:43:40.310 --> 00:43:43.740
image from the highlights and shadows.

00:43:44.850 --> 00:43:48.150
Now,
let's take a look at the file formats

00:43:48.240 --> 00:43:51.070
that we are supporting in Tiger.

00:43:51.590 --> 00:43:58.840
I think that the most important citizen
here is OpenEXR that comes from ILM.

00:43:58.840 --> 00:44:02.670
First of all,
it has the smallest quantization error.

00:44:02.670 --> 00:44:06.360
And most importantly,
as you will see later,

00:44:06.360 --> 00:44:10.680
it comes with the recommended
way of tone rendering,

00:44:10.680 --> 00:44:16.110
which solves a lot of problems in
terms of presenting the image content.

00:44:16.120 --> 00:44:22.510
The other formats basically just define
the way of encoding and decoding data

00:44:22.510 --> 00:44:27.140
with preserving the image fidelity.

00:44:28.120 --> 00:44:32.130
So now,
I would like to show you-- if I can

00:44:32.130 --> 00:44:39.730
get my-- this is demo machine-- my
little application in which I can

00:44:39.860 --> 00:44:43.320
open high dynamic range images.

00:44:43.340 --> 00:44:46.360
And what I would like to show
you is that we have to do

00:44:46.360 --> 00:44:50.230
something with those values,
which are so large and much

00:44:50.320 --> 00:44:56.640
bigger than what we can represent
by typical range of 0 to 1.

00:44:56.660 --> 00:45:02.850
And one would think that very
simple approach would be to simply--

00:45:04.590 --> 00:45:09.840
map the brightest point in the image
to the brightest point of the display.

00:45:09.840 --> 00:45:14.580
But if I do that with my
little demo application,

00:45:14.710 --> 00:45:19.640
you see that we don't see
too much in this image.

00:45:19.640 --> 00:45:23.440
There is way too much information
beyond 1 and scaling didn't

00:45:23.440 --> 00:45:25.340
produce any visible image.

00:45:25.340 --> 00:45:29.290
Another very simple approach could be,
okay, let's say I would like to see

00:45:29.290 --> 00:45:34.910
whatever you have in this image,
clip the values to 0, 1, typical range,

00:45:34.910 --> 00:45:36.540
and show me that.

00:45:36.540 --> 00:45:40.160
Well, as you see,
the image quality somehow improved,

00:45:40.220 --> 00:45:42.060
but it's still very poor.

00:45:42.060 --> 00:45:45.110
And now, if I use the OpenEXR,
and this is their

00:45:45.110 --> 00:45:49.630
default 0 exposure value,
I'm getting some reasonable result,

00:45:49.630 --> 00:45:51.800
and I can see many more details.

00:45:51.800 --> 00:45:55.560
And not only this,
I can do what I was talking about,

00:45:55.560 --> 00:46:00.050
that I can impose my preference at
the moment of reproducing the image.

00:46:00.060 --> 00:46:02.880
For example,
someone may like this kind of image,

00:46:02.880 --> 00:46:07.950
or someone else may still want to
focus on this beautiful stained glass.

00:46:08.250 --> 00:46:10.710
I want to show you a
couple of classic examples,

00:46:10.740 --> 00:46:14.260
like for example,
the famous Memorial Church picture,

00:46:14.260 --> 00:46:18.160
which comes from the Debeweg website.

00:46:18.160 --> 00:46:19.630
And the same thing happens here.

00:46:19.640 --> 00:46:25.200
If we just scale the image,
the image is basically unreadable.

00:46:25.200 --> 00:46:30.020
Clipping will show something,
that quality is really poor.

00:46:30.310 --> 00:46:34.290
OpenEXR is doing a very good job here.

00:46:35.430 --> 00:46:38.880
Another example is the picture
I was using in the previous

00:46:38.880 --> 00:46:42.400
slides of our garage at Apple.

00:46:43.630 --> 00:46:45.880
And this is how it looks when scaled.

00:46:45.930 --> 00:46:48.520
This is how it looks when clipped.

00:46:48.540 --> 00:46:52.840
Once again,
typical hue shift when clipping the data.

00:46:52.850 --> 00:46:58.250
And OpenEXR producing
quite reasonable result.

00:46:58.450 --> 00:47:05.200
What this leads us to the conclusion
that tone rendering is a very

00:47:05.200 --> 00:47:11.080
important issue when processing
the high dynamic range images.

00:47:11.100 --> 00:47:14.480
And maybe there may be many
different methods of doing that.

00:47:14.480 --> 00:47:19.530
And I think this gives me a very good
segue to introduce Gabriel Marcu,

00:47:19.560 --> 00:47:25.210
who will be talking about high dynamic
range tone mapping developed at Apple.

00:47:32.500 --> 00:51:29.700
[Transcript missing]

00:51:29.800 --> 00:55:45.500
[Transcript missing]

00:55:46.520 --> 00:55:51.000
How do we create high dynamic
range images is the next topic.

00:55:51.000 --> 00:55:55.220
And this is quite interesting.

00:55:55.220 --> 00:55:58.660
We can start with a file
format of these images.

00:55:58.660 --> 00:56:04.490
And we have to code in RGB floats
the radiance of the scene.

00:56:04.490 --> 00:56:06.160
So how do we capture this?

00:56:06.160 --> 00:56:12.760
We turn to a method that was
published by Debevec and Malik,

00:56:12.760 --> 00:56:17.160
recovering high dynamic range
radiance maps from photographs.

00:56:17.430 --> 00:56:22.310
And essentially this method is
requiring to take multiple shots of

00:56:22.320 --> 00:56:27.440
different exposures of the same scene,
and then combine these exposures

00:56:27.570 --> 00:56:31.490
into a high dynamic range file.

00:56:32.720 --> 00:56:38.290
We start with the block
diagram of the digital camera.

00:56:38.290 --> 00:56:43.580
And if you look closely,
you can see that the scene radiance,

00:56:43.580 --> 00:56:50.490
it is transformed to the digital
output in the digital file,

00:56:50.490 --> 00:56:56.140
which is maybe JPG or other file,
by a set of transformation.

00:56:56.140 --> 00:56:59.130
First,
the image is passing through the lenses,

00:56:59.130 --> 00:57:02.890
then the shutter,
then the image is captured by the

00:57:02.890 --> 00:57:08.390
CCD and converted by ADC converter,
and then some mapping is

00:57:08.390 --> 00:57:11.520
happening in the camera,
for example,

00:57:11.710 --> 00:57:17.790
gamma correction or raw image
to JPG image transformation,

00:57:18.030 --> 00:57:22.230
and you finally get the
digital values in the file.

00:57:22.600 --> 00:59:55.500
[Transcript missing]

00:59:55.900 --> 01:00:24.100
[Transcript missing]

01:00:24.930 --> 01:00:30.490
I choose a number of
already exposed shots,

01:00:30.490 --> 01:00:33.930
and we get a thumbnail
view on the left side.

01:00:34.170 --> 01:00:38.010
And in here,
we can select any of these images

01:00:38.330 --> 01:00:41.500
and see what is their content.

01:00:41.520 --> 01:00:47.520
You note immediately that no
matter how we take these images,

01:00:47.860 --> 01:00:53.650
you can see either details in
the shadow or either details

01:00:53.780 --> 01:00:56.460
in the highlight of this.

01:00:56.460 --> 01:01:00.610
And the high dynamic range file
will be able to capture all

01:01:00.670 --> 01:01:06.100
information of the radiance of the
scene and will encapsulate this

01:01:06.100 --> 01:01:09.200
in a high dynamic range format.

01:01:09.200 --> 01:01:13.190
The first thing is to calculate
the high dynamic range,

01:01:13.230 --> 01:01:15.980
to calculate the transfer
function of the camera.

01:01:15.980 --> 01:01:17.820
And we did this in a single step.

01:01:17.870 --> 01:01:20.400
You have seen several
curves put together,

01:01:20.440 --> 01:01:23.550
and you recover the transfer
function of the camera.

01:01:23.560 --> 01:01:28.130
Then the next step is to use this
transfer function and to compute

01:01:28.130 --> 01:01:30.460
the high dynamic range image.

01:01:30.460 --> 01:01:37.030
Now you can see that even in the paper,
it said that you need to do

01:01:37.030 --> 01:01:39.140
this processing of the image.

01:01:39.140 --> 01:01:42.540
And you can see that the transfer
function of the camera over many

01:01:42.550 --> 01:01:46.130
and many images until you get an
average behavior of the camera

01:01:46.520 --> 01:01:49.510
and use that transfer function
to create the high dynamic range.

01:01:49.590 --> 01:01:55.420
We actually add more robustness to the
algorithm that is computing the transfer

01:01:55.430 --> 01:02:00.870
function of the camera such that we are
able to recover the transfer function

01:02:00.970 --> 01:02:05.950
only from the same set of images that we
used to create the high dynamic range.

01:02:05.960 --> 01:02:09.080
So we recover the function
from this set of images.

01:02:09.080 --> 01:02:11.790
And we apply this
function to these images.

01:02:11.880 --> 01:02:14.320
And we create the high dynamic range.

01:02:14.450 --> 01:02:21.130
This brings us to an algorithm that
will be able to do this kind of things

01:02:21.310 --> 01:02:25.600
by just specifying the set of images.

01:02:25.840 --> 01:02:28.090
So we choose a set of images.

01:02:28.250 --> 01:02:31.630
Then the algorithm is computing
the transfer function of the

01:02:31.630 --> 01:02:36.210
camera and is computing the high
dynamic range in a single shot.

01:02:36.340 --> 01:02:39.020
And this gives independence
of this application.

01:02:39.330 --> 01:02:45.870
from any camera settings or any
setup that you may have been

01:02:45.940 --> 01:02:51.180
required to do for the method that
is published in the literature.

01:02:51.180 --> 01:02:59.560
So this, let's say, you are switching to
another set of images,

01:02:59.570 --> 01:03:01.210
for example.

01:03:01.390 --> 01:03:04.740
From a different camera,
you don't have to specify the camera,

01:03:04.740 --> 01:03:10.320
and you immediately get the high
dynamic range file direct from

01:03:10.320 --> 01:03:13.520
specifying only the set of images.

01:03:13.520 --> 01:03:19.270
The interesting thing about this is we
want the Apple user to be able to have

01:03:19.270 --> 01:03:23.550
less intervention in this algorithm,
less guesswork,

01:03:23.970 --> 01:03:27.860
and finally end up with an application
that will be able to provide

01:03:27.930 --> 01:03:33.080
directly high dynamic range images
without taking care of anything.

01:03:33.080 --> 01:03:35.140
And this is an advantage for the user.

01:03:35.140 --> 01:03:40.520
Finally, I would like to mention that,
as you have seen here,

01:03:40.520 --> 01:03:44.900
we select the images from a folder,
but we have worked

01:03:44.900 --> 01:03:48.510
with the image capture,
so I invite you on

01:03:48.510 --> 01:03:52.500
Friday afternoon from 5 p.m.

01:03:52.500 --> 01:03:58.700
to see an integration of this algorithm
with the image capture modules,

01:03:58.760 --> 01:04:02.850
and you will see an interactive
demonstration of how these images

01:04:02.860 --> 01:04:06.520
are captured live with the camera,
and then a high dynamic

01:04:06.520 --> 01:04:08.300
range file is created.

01:04:08.320 --> 01:04:13.130
And with this, I thank you very much,
and I will turn back to Luke.

01:04:23.020 --> 01:04:25.000
Thank you, Gabriel.

01:04:25.040 --> 01:04:30.420
So, at the end of the presentation
on high dynamic range images,

01:04:30.420 --> 01:04:33.710
I'd like to touch on the subject
which is very close to our

01:04:33.710 --> 01:04:36.000
hearts of color-seeing engineers.

01:04:36.000 --> 01:04:41.000
We are really interested in color
managing high dynamic range images.

01:04:41.000 --> 01:04:44.680
And you must know that this
is the area which is under

01:04:44.680 --> 01:04:50.980
very intensive investigation,
both in academic society

01:04:51.000 --> 01:04:53.000
and in the industry.

01:04:53.000 --> 01:04:57.300
At Apple,
we also are developing our own method of

01:04:57.300 --> 01:05:03.200
color managing high dynamic range images,
and we are trying to take a new approach,

01:05:03.200 --> 01:05:09.000
which is based on human adaptation
to image viewing environment.

01:05:09.000 --> 01:05:14.210
We think that image contains enough white
point and adopting luminance information

01:05:14.210 --> 01:05:19.490
that could be used by color appearance
model to predict human perception of

01:05:19.490 --> 01:05:24.910
color in different viewing environments,
which basically means we can color

01:05:24.910 --> 01:05:28.400
manage our high dynamic range images.

01:05:28.700 --> 01:05:35.720
Just to clarify what kind of color
appearance modeling we are dealing with,

01:05:35.720 --> 01:05:41.320
let me say that we are looking
at this kind of modeling

01:05:41.320 --> 01:05:45.810
which consists of two major,
is based on two major concepts.

01:05:45.900 --> 01:05:48.910
On chromatic adaptation,
which allows us to predict

01:05:48.940 --> 01:05:52.400
the influence of adopted white
point on the color perception.

01:05:53.140 --> 01:05:56.360
And on the second concept
is the degree of adaptation,

01:05:56.360 --> 01:06:00.930
which allows us to predict simultaneous
color contrast related to the

01:06:00.930 --> 01:06:03.130
luminance of adopted white point.

01:06:03.160 --> 01:06:09.020
So, in summary,
what we are trying to do is to transform

01:06:09.450 --> 01:06:17.870
the colorimetry of the source using high
dynamic range data to our destination.

01:06:17.880 --> 01:06:24.870
And then,
after doing... after color managing

01:06:24.870 --> 01:06:28.440
and bringing to new environment,
then applying tone mapping,

01:06:28.440 --> 01:06:32.490
which will compress color to
the range of destination device.

01:06:32.620 --> 01:06:38.180
And this is what concludes our
talk on high dynamic range images.

01:06:38.180 --> 01:06:40.030
And I'll turn back microphone to David.

01:06:40.290 --> 01:06:41.080
Thank you.

01:06:47.020 --> 01:06:49.410
Thank you, Luke and Gabriel,
for your discussion.

01:06:49.410 --> 01:06:52.110
I just wanted to bring it back
just to do a quick summary slide,

01:06:52.110 --> 01:06:54.440
and then we'll have a few
minutes of Q&A at least.

01:06:54.480 --> 01:06:57.070
Just wanted to summarize once
again what's new in Tiger.

01:06:57.070 --> 01:06:58.460
We've got a lot of great stuff here.

01:06:58.460 --> 01:07:00.990
First of all, in ColorSync,
we have floating point support.

01:07:01.000 --> 01:07:03.530
Image IO,
we have a brand new modern API for

01:07:03.650 --> 01:07:07.800
reading and writing that has optimized
performance and support for metadata.

01:07:07.800 --> 01:07:10.800
And then we're doing a lot
with high dynamic range,

01:07:10.880 --> 01:07:16.000
supporting OpenEXR file formats,
access to compressed or unprocessed data.

01:07:16.000 --> 01:07:19.500
And also, this is an area of all sorts
of ongoing and future research.

01:07:19.500 --> 01:07:20.600
We'll have lots to show for you.

01:07:20.600 --> 01:07:24.400
So, again, we have a few other places
you might want to go.

01:07:24.400 --> 01:07:27.330
There's a Graphics and
Media Lab session on Thursday where

01:07:27.330 --> 01:07:29.990
you can talk to us if you have more
questions than we can get to today.

01:07:30.000 --> 01:07:32.340
And then also,
there's going to be some great

01:07:32.340 --> 01:07:35.500
demonstrations on the last show,
last session on Friday,

01:07:35.500 --> 01:07:37.600
talking about image
capability and how to use it.

01:07:37.600 --> 01:07:39.190
image capture in high dynamic range.