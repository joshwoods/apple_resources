WEBVTT

00:00:12.250 --> 00:00:13.190
Good afternoon everyone.

00:00:13.190 --> 00:00:18.120
Welcome to session 205,
Audio Hardware and MIDI.

00:00:18.170 --> 00:00:22.630
Please welcome Core Audio MIDI Plumber,
Doug Wyatt.

00:00:27.640 --> 00:00:28.500
Thank you.

00:00:28.600 --> 00:00:29.370
Good afternoon.

00:00:29.550 --> 00:00:32.000
This session is in three parts.

00:00:32.000 --> 00:00:34.890
In the first part,
I'll be going over a few things

00:00:34.890 --> 00:00:37.500
about the core MIDI framework.

00:00:37.500 --> 00:00:40.810
In the second part,
Jeff Moore will cover what's new in

00:00:40.840 --> 00:00:43.490
Tiger for the core audio framework.

00:00:43.620 --> 00:00:51.490
And the last portion of the session,
Nick Thompson will be covering some

00:00:51.490 --> 00:00:51.490
audio hardware and driver issues.

00:00:56.230 --> 00:00:59.940
So for the core
MIDI portion of this talk,

00:00:59.950 --> 00:01:04.450
I'll be covering very briefly
some basics of core MIDI.

00:01:04.970 --> 00:01:08.670
There's some best practices
issues I'd like to cover.

00:01:08.670 --> 00:01:13.090
And there's a new API for
Tiger called the Core Audio Clock.

00:01:15.710 --> 00:01:21.200
So most of you who are working with
MIDI already know what it's about,

00:01:21.200 --> 00:01:26.040
but for those of you who don't,
a good resource is the MIDI Manufacturers

00:01:26.040 --> 00:01:28.760
Association at mma.org on the net.

00:01:28.780 --> 00:01:31.760
And there's some good
books out there about MIDI.

00:01:31.760 --> 00:01:39.440
Our APIs are documented in the headers,
and there's some documentation and

00:01:39.440 --> 00:01:41.660
examples in the developer directory.

00:01:42.380 --> 00:01:47.590
We've got a very active mailing list,
and there's, this is probably about the

00:01:47.590 --> 00:01:50.690
fifth WWDC that I've been
talking about core MIDI at,

00:01:50.720 --> 00:01:53.550
and there's DVDs of the
previous year's sessions.

00:01:57.430 --> 00:02:01.310
So in the area of best practices
with the existing core MIDI APIs,

00:02:01.400 --> 00:02:04.270
there's just two things
I want to talk about.

00:02:04.290 --> 00:02:08.550
One falls in the area of user experience,
and the other is performance

00:02:08.550 --> 00:02:10.510
issue with timing accuracy.

00:02:12.130 --> 00:02:17.100
So the first thing that I've seen
in some applications is difficulty

00:02:17.100 --> 00:02:22.520
in giving the user a good experience
with seeing the names of his devices.

00:02:22.610 --> 00:02:28.030
And here we've got a moderate-sized
studio with a bunch of devices,

00:02:28.030 --> 00:02:31.490
as seen in the
AudioMIDI setup application.

00:02:31.540 --> 00:02:36.160
And there's devices connected to
about five of the eight ports there.

00:02:36.700 --> 00:02:41.660
And what I've seen is
that in some applications,

00:02:41.660 --> 00:02:45.970
they'll just show me the name
of the MIDI port where the user

00:02:45.970 --> 00:02:48.860
would really like to see the
name of the external device.

00:02:49.060 --> 00:02:51.360
I realized after I made this slide,
this is sort of a confusing

00:02:51.360 --> 00:02:55.270
example because there's actually
two different devices on port 3.

00:02:55.350 --> 00:02:58.400
So for output, I'd want to see repeater.

00:02:58.560 --> 00:03:03.920
For input, I would want to see radium,
the names of the external devices.

00:03:05.690 --> 00:03:09.630
So I just want to quickly show
you a little application that

00:03:09.640 --> 00:03:15.160
illustrates a couple of approaches

00:03:15.650 --> 00:03:38.700
displaying MIDI endpoints
in your application.

00:03:38.700 --> 00:03:38.700
So here you might want to,
in the case of multiple

00:03:38.700 --> 00:03:38.700
devices on one port,
and actually this setup that I have

00:03:38.700 --> 00:03:38.700
here doesn't have any examples of it,
but here we see the names of the ports

00:03:38.700 --> 00:03:38.700
where there aren't external devices,
and then we see the names of the

00:03:38.700 --> 00:03:38.700
external devices where there are some.

00:03:40.380 --> 00:03:44.010
These menus don't have the names
of the external ports in them.

00:03:44.320 --> 00:03:45.700
This may be a little draconian.

00:03:45.700 --> 00:03:49.290
It forces your users to go
through audio MIDI setup.

00:03:49.410 --> 00:03:53.160
Some applications do that.

00:03:53.160 --> 00:03:53.160
It's okay.

00:03:53.550 --> 00:04:01.000
And this also illustrates that you can
go through and obtain pairs of ports.

00:04:01.140 --> 00:04:05.660
So here we're only seeing the devices
which I have a two-way connection to.

00:04:05.710 --> 00:04:08.720
Notice here that I have
the radium as a source,

00:04:08.740 --> 00:04:11.960
the repeater as a destination,
but it doesn't appear here.

00:04:11.960 --> 00:04:13.460
Wow, that's probably a bug.

00:04:13.670 --> 00:04:17.780
So the idea is to only show
here the devices to which

00:04:17.780 --> 00:04:20.780
there is a two-way connection.

00:04:20.780 --> 00:04:24.920
So, back to the slides, please.

00:04:29.100 --> 00:04:32.930
So what this quick and
dirty program does,

00:04:33.180 --> 00:04:39.080
it's using some sample code from our SDK,
but just to go over the process,

00:04:39.080 --> 00:04:42.800
you can iterate through the sources
and destinations in the system with

00:04:42.900 --> 00:04:44.560
MIDI get source and get destination.

00:04:44.560 --> 00:04:48.380
Once you've found a source
or destination endpoint,

00:04:48.380 --> 00:04:54.900
you can find out what's connected to it
with the property connection unique ID.

00:04:55.100 --> 00:04:58.430
Then you can go find that
object that is connected with

00:04:58.670 --> 00:05:05.890
MIDI object find by unique ID,
and then you can ask that for its name.

00:05:06.050 --> 00:05:09.860
But it's probably best if you
use the C++ class in our SDK,

00:05:09.860 --> 00:05:11.430
CA MIDI endpoints.

00:05:11.450 --> 00:05:13.780
And if there's bugs in it,
like in my demo,

00:05:13.780 --> 00:05:16.420
I don't know if that's in
my demo or in the SDK code,

00:05:16.440 --> 00:05:19.000
but in any case,
that's a really good place to start.

00:05:19.000 --> 00:05:20.350
It'll show you the sequence of calls.

00:05:20.350 --> 00:05:23.040
There's a few strange cases to deal with.

00:05:23.080 --> 00:05:28.070
And it'll give your users the
names that they expect to see.

00:05:29.680 --> 00:05:35.710
So the other best practices issue
I'd like to cover is MIDI timestamps.

00:05:35.730 --> 00:05:39.370
I've noticed that there are some
applications that send all their

00:05:39.370 --> 00:05:45.100
outgoing MIDI with a timestamp of now,
which means that by definition,

00:05:45.100 --> 00:05:48.610
it's going to be late by the
time it gets to the hardware.

00:05:48.790 --> 00:05:52.810
Not very late, necessarily.

00:05:52.810 --> 00:05:56.790
But there's some good
reasons not to do that,

00:05:56.790 --> 00:05:56.790
because

00:05:57.040 --> 00:06:00.600
Well, one I've got mentioned here on
the slide is that there is an

00:06:00.600 --> 00:06:06.180
Internet Engineering Task Force proposal
in the works for doing MIDI over IP.

00:06:06.390 --> 00:06:10.890
And with networking MIDI,
the timestamps are going to become really

00:06:10.890 --> 00:06:15.870
important because we're going to see
more jitter and latency than we would

00:06:15.870 --> 00:06:18.780
just on a normal local MIDI network.

00:06:19.190 --> 00:06:23.370
The other is that we're starting
to see applications or contacts

00:06:23.370 --> 00:06:27.260
where people want to use multiple
applications on the same computer

00:06:27.260 --> 00:06:28.500
and synchronize them together.

00:06:28.500 --> 00:06:33.370
And you can send a MIDI timecode or
MIDI beat clock very efficiently between

00:06:33.370 --> 00:06:38.240
applications using the IAC driver,
which was introduced in Panther.

00:06:38.240 --> 00:06:43.340
And if those events are timestamped,
then the applications can achieve really

00:06:43.420 --> 00:06:46.010
good synchronization between them.

00:06:46.020 --> 00:06:47.910
If they're not,
then application A may not

00:06:47.910 --> 00:06:49.160
be able to synchronize.

00:06:49.180 --> 00:06:54.140
It may be sending its timestamp,
you know, sending with no timestamp now.

00:06:54.140 --> 00:06:57.150
And there's going to be a little
bit of propagation until the

00:06:57.150 --> 00:07:00.120
time it gets to application B,
maybe only a couple hundred

00:07:00.120 --> 00:07:01.630
microseconds or something.

00:07:01.640 --> 00:07:04.720
But that's not going to
provide totally accurate sync.

00:07:04.760 --> 00:07:09.110
So there's no reason not to be using
timestamps when you schedule and paying

00:07:09.110 --> 00:07:11.760
attention to timestamps when you record.

00:07:13.750 --> 00:07:16.810
There are a few applications that
might want to do MIDI throughing

00:07:16.810 --> 00:07:19.580
in real time and say,
"Well, I just need to send everything

00:07:19.580 --> 00:07:23.310
as soon as I get it,
and that's okay." I would just suggest

00:07:23.390 --> 00:07:27.840
that you measure your performance,
and if you see that you're

00:07:27.840 --> 00:07:33.110
getting more jitter than you like,
you can add a little bit of latency.

00:07:33.110 --> 00:07:36.510
Say, "Okay,
play this two milliseconds from

00:07:36.510 --> 00:07:40.890
when it came in," for example,
and that should smooth out most

00:07:40.890 --> 00:07:40.890
of the jitter that you'll see.

00:07:43.700 --> 00:07:48.930
One major area of new features
in Tiger for us is this API set

00:07:49.060 --> 00:07:51.040
called Core Audio Clock.

00:07:51.080 --> 00:07:54.260
It's actually in the
audio toolbox framework,

00:07:54.260 --> 00:07:58.090
but it touches on core
MIDI in a lot of ways.

00:07:58.150 --> 00:08:01.710
So it's being discussed in this session.

00:08:03.300 --> 00:08:08.360
So if your app has any kinds
of synchronization needs,

00:08:08.360 --> 00:08:12.300
especially involving
MIDI timecode and MIDI beat clock,

00:08:12.300 --> 00:08:15.920
whether it's coming from an
external source or you want to

00:08:15.920 --> 00:08:22.260
sync to another application,
this API will provide a lot

00:08:22.260 --> 00:08:27.100
of the grungy code for dealing
with those MIDI timing formats.

00:08:27.100 --> 00:08:32.780
It also does some other time conversions,
interpolations between various formats,

00:08:32.830 --> 00:08:34.400
as we'll see in a minute.

00:08:34.400 --> 00:08:37.090
And if your application is
already used in the music player

00:08:37.120 --> 00:08:41.780
APIs in the audio toolbox,
this hasn't happened yet,

00:08:41.800 --> 00:08:47.360
but those will be put on top of -- well,
there will be a clock object

00:08:47.490 --> 00:08:49.000
embedded in the music player.

00:08:49.000 --> 00:08:52.850
So if you're using the music player,
then you'll get the ability to send

00:08:52.850 --> 00:08:54.990
and receive MIDI timecode for free.

00:08:55.100 --> 00:08:56.970
Modulo,
whatever user interface you're using.

00:08:57.080 --> 00:08:59.450
face you need to put on top of it.

00:09:01.700 --> 00:09:06.580
And so, yeah, what the clock does,
it manages synchronizing your

00:09:06.580 --> 00:09:12.690
application between audio and
MIDI timecode or MIDI clock.

00:09:12.730 --> 00:09:17.560
It's an extensible internal architecture,
and at some point we may add

00:09:17.580 --> 00:09:18.860
other synchronization sources.

00:09:18.900 --> 00:09:23.670
And it's got math for, you know,
but it does all the grungy math of

00:09:23.670 --> 00:09:28.430
dealing between SMPTE time formats,
synchronizing as an audio device's

00:09:28.430 --> 00:09:31.360
time base and samples via the HAL.

00:09:31.600 --> 00:09:35.950
It deals with seconds along your
application's media timeline,

00:09:36.010 --> 00:09:40.470
and if your application has a
concept of musical beat time,

00:09:40.470 --> 00:09:45.820
it'll convert between seconds and
beats and those other formats.

00:09:47.610 --> 00:09:54.300
So this just illustrates kind of what's
going on under the hood in the clock.

00:09:54.300 --> 00:09:58.650
In the top blue line,
we have your application's

00:09:58.650 --> 00:10:02.710
media timeline,
so zero being the beginning of time,

00:10:02.780 --> 00:10:03.240
for example.

00:10:03.240 --> 00:10:10.560
And in the green boxes,
we have the hardware reference timeline.

00:10:10.560 --> 00:10:15.980
And so what the clock is doing is
maintaining a series of correlation

00:10:15.980 --> 00:10:19.300
points between those two timelines.

00:10:19.990 --> 00:10:22.220
There's this idea of a start time.

00:10:22.360 --> 00:10:25.820
If your application is
starting itself internally,

00:10:25.820 --> 00:10:30.460
then the user might have said
start 40 seconds into the piece.

00:10:30.460 --> 00:10:35.160
And so you set the start time,
and that's where playback begins.

00:10:35.160 --> 00:10:39.670
If you are in external sync mode,
the start time is the timestamp,

00:10:39.700 --> 00:10:44.710
for example, of the first MIDI time code
message that was received.

00:10:44.710 --> 00:10:49.080
So it's the point at which sync was
achieved and time begins moving.

00:10:50.180 --> 00:10:55.590
And then as time continues to move,
the clock object continues to

00:10:55.760 --> 00:11:01.040
take new anchor points referencing
media and hardware times,

00:11:01.040 --> 00:11:06.260
and then performs all subsequent
time correlations and conversions

00:11:06.260 --> 00:11:08.530
using those anchor points.

00:11:10.950 --> 00:11:16.050
So here we see diagrammatically
how the different time

00:11:16.160 --> 00:11:18.290
formats relate to each other.

00:11:18.360 --> 00:11:22.660
On the left in green,
we have the hardware time references,

00:11:22.660 --> 00:11:30.290
the host time base as used by the-- well,
that everything's based on in the

00:11:30.290 --> 00:11:30.290
Core Audio APIs and Core MIDI.

00:11:30.540 --> 00:11:34.140
There's the audio devices sample time.

00:11:34.160 --> 00:11:38.950
The HAL does the correlation
between the host and audio times.

00:11:39.010 --> 00:11:43.160
On the right, we have different ways of
expressing time along the timeline,

00:11:43.230 --> 00:11:44.730
the blue boxes.

00:11:44.820 --> 00:11:49.890
So seconds is the main way
of describing these times.

00:11:49.920 --> 00:11:52.060
It's a floating point number.

00:11:52.650 --> 00:11:57.390
And from seconds we can convert
to beats if you supply a tempo map

00:11:57.620 --> 00:12:03.820
and we can apply a SMPTE offset
to get to a SMPTE time in seconds.

00:12:03.820 --> 00:12:03.820
Excuse me.

00:12:04.500 --> 00:12:08.560
In the gray boxes on the right,
this just illustrates that there are

00:12:08.560 --> 00:12:14.310
some auxiliary APIs in the clock for
converting between beats and a display

00:12:14.390 --> 00:12:17.160
textual representation of beats.

00:12:17.190 --> 00:12:20.040
And similarly with SMPTE seconds away.

00:12:20.100 --> 00:12:22.100
Since SMPTE seconds
can be floating point,

00:12:22.130 --> 00:12:27.440
we're actually seeing an example here of
a SMPTE time that's going out to 80 bits

00:12:27.550 --> 00:12:30.820
per frame or however many bits you want,
actually.

00:12:32.710 --> 00:12:38.280
And the circle in the middle indicates
how the clock is correlating between

00:12:38.930 --> 00:12:43.940
the hardware and timeline times using
variable play rate that you can set.

00:12:44.040 --> 00:12:47.310
You can say, for example,
play twice as fast.

00:12:49.130 --> 00:12:51.740
Okay, so with those concepts,
I'd like to just give you a

00:12:51.750 --> 00:12:56.650
quick look at an application
that uses the Core Audio Clock.

00:12:59.800 --> 00:13:04.950
OK, so this document shows pretty much
everything that's in a clock object,

00:13:04.950 --> 00:13:08.430
except what's below this line
here is an audio file player,

00:13:08.550 --> 00:13:10.800
and I'll show you that in a minute.

00:13:11.610 --> 00:13:16.220
And so if I click go,
then time starts moving.

00:13:16.220 --> 00:13:21.260
I've got a SMPTE time over here on the
left and a bar beat time on the right.

00:13:21.300 --> 00:13:24.100
If I change the tempo,
you can see suddenly we're at

00:13:24.200 --> 00:13:29.100
a different bar beat time and
it's moving twice as quickly.

00:13:29.100 --> 00:13:33.060
And I can create a second clock object.

00:13:37.000 --> 00:13:41.530
And I'll have this one send
MIDI timecode to the IAC bus.

00:13:41.540 --> 00:13:46.600
I'll have this one receive
MIDI timecode from the IAC bus.

00:13:46.600 --> 00:13:49.600
And I'll play them, and they're in sync.

00:13:52.600 --> 00:14:00.980
Let's have a little more fun here and
we'll have this one play an audio file.

00:14:08.210 --> 00:14:13.700
So I can very speed this clock,
and this one's following along.

00:14:19.100 --> 00:14:22.310
And so I got all that running
and I thought that's pretty cool.

00:14:22.420 --> 00:14:27.880
So what happens if I have two of these
guys playing audio files together?

00:14:27.950 --> 00:14:29.830
So now these are both
playing the same file.

00:14:29.830 --> 00:14:33.020
They're synced together
with MIDI timecode getting

00:14:33.020 --> 00:14:34.550
sent over the IEC bus.

00:14:34.710 --> 00:14:38.710
And how close together do
these clocks really stay?

00:14:40.580 --> 00:14:43.540
Let's turn down the volume here.

00:14:43.540 --> 00:14:47.530
And I'll go to my favorite
portion of this song.

00:14:54.800 --> 00:14:58.300
That's a little confusing because
there is a very phased sound there.

00:14:58.300 --> 00:15:00.290
I don't know if you can hear the hi-hat.

00:15:00.300 --> 00:15:01.700
It's over to the left.

00:15:01.850 --> 00:15:08.170
In any case, according to my math here,
these two players

00:15:08.900 --> 00:15:12.500
Despite being yanked
around with various speeds,

00:15:12.500 --> 00:15:15.900
are within one or two
frames of each other.

00:15:15.900 --> 00:15:19.400
So that's the Core Audio Clock.

00:15:25.900 --> 00:15:28.540
Okay,
so next Jeff Moore is going to talk about

00:15:28.540 --> 00:15:30.410
new features in the Core Audio Hell.

00:15:39.110 --> 00:15:43.180
So today I'm going to talk, as Doug said,
about a couple of new features

00:15:43.180 --> 00:15:45.140
in the Core Audio HAL.

00:15:45.290 --> 00:15:49.250
The first new feature that you'll
see is there are new I/O data

00:15:49.250 --> 00:15:53.320
formats supported by the HAL,
including variable bitrate I/O,

00:15:53.890 --> 00:15:57.800
and also non-audio data like
sideband data such as timecode

00:15:58.010 --> 00:16:02.060
and control data and other things
that aren't actual audio samples.

00:16:02.200 --> 00:16:06.220
And the other new feature I'm going
to talk a little bit about today

00:16:06.220 --> 00:16:08.490
is the aggregate device support.

00:16:10.290 --> 00:16:13.640
So currently,
when you're doing I/O with the HAL,

00:16:13.640 --> 00:16:15.280
in your I/O proc,
you're always going to be

00:16:15.280 --> 00:16:16.800
moving the same number of bytes.

00:16:16.800 --> 00:16:20.020
Either you're going to be getting
x number of bytes of input,

00:16:20.080 --> 00:16:23.580
or you're going to be providing
y number of bytes of output.

00:16:23.660 --> 00:16:27.220
And further,
the mixability of the streams is

00:16:27.220 --> 00:16:30.430
always controlled at the device level,
meaning that if you want to

00:16:30.430 --> 00:16:33.290
switch to a non-mixable format,
you have to tell the device,

00:16:33.510 --> 00:16:36.470
switch to a non-mixable format,
and all the streams are

00:16:36.470 --> 00:16:38.160
switched to that way.

00:16:40.190 --> 00:16:46.840
And currently we support linear
PCM data and IEC 6958 compliant streams,

00:16:46.840 --> 00:16:51.540
and that's SPDIF for
the alphabet impaired.

00:16:51.540 --> 00:16:55.220
That includes data formats like AC3,
MPEG-1, MPEG-2,

00:16:55.250 --> 00:16:58.780
and other things that can be
smashed into a format that can be

00:16:58.790 --> 00:17:01.020
sent over that digital interface.

00:17:02.290 --> 00:17:05.190
So now in Tiger,
we're adding the ability to move

00:17:05.200 --> 00:17:09.210
a varying number of bytes through
your IOPROC when it's called.

00:17:09.260 --> 00:17:16.840
This is important for formats such
as RAW AC3 where the number of bytes

00:17:16.840 --> 00:17:18.800
per packet varies for each packet.

00:17:18.800 --> 00:17:22.750
And you're going to be told that
through the audio buffer list,

00:17:22.750 --> 00:17:24.630
the mdata byte size field.

00:17:24.640 --> 00:17:27.210
And you'll need to make sure
you're always paying attention

00:17:27.210 --> 00:17:31.000
to that field and aren't just
assuming that it's constant anymore.

00:17:32.200 --> 00:17:35.480
And on output,
you have to make sure that you tell

00:17:35.480 --> 00:17:38.300
the HAL how much data you're supplying.

00:17:38.300 --> 00:17:41.340
And you can see in this
code example a very simple

00:17:41.340 --> 00:17:43.770
IOPROC that is doing exactly that.

00:17:43.800 --> 00:17:47.050
It is iterating through all
the output audio buffers in

00:17:47.100 --> 00:17:49.190
the provided audio buffer list.

00:17:49.240 --> 00:17:54.720
And it is stuffing some VBR data
into it and then telling the HAL how

00:17:54.720 --> 00:17:59.260
much data it's stuffing in there
by assigning back to the mdata byte

00:17:59.270 --> 00:18:01.080
size field of the audio buffer.

00:18:03.800 --> 00:18:09.880
So now with the new IO data formats,
this basically is around

00:18:09.880 --> 00:18:11.540
other non-mixable formats.

00:18:11.540 --> 00:18:15.980
And with these,
you have to be able to have

00:18:15.980 --> 00:18:20.180
a mixable data stream side by
side with a non-mixable stream.

00:18:20.180 --> 00:18:22.410
Consequently,
you're going to have to be dealing

00:18:22.410 --> 00:18:25.790
with mixability now at the stream
level as opposed to the device level.

00:18:25.800 --> 00:18:29.130
And you can find out about
the mixability in two ways,

00:18:29.130 --> 00:18:34.310
either by the mixability property,
or you can use the format information

00:18:34.310 --> 00:18:36.360
that's provided by the HAL.

00:18:36.360 --> 00:18:40.060
In particular,
the audio format flag is non-mixable

00:18:40.060 --> 00:18:44.870
will be set in the M format flags
field for non-mixable formats now.

00:18:44.900 --> 00:18:49.680
Variable bitrate and coded formats
are also now going to be supported

00:18:49.680 --> 00:18:51.820
for input as well as output.

00:18:51.820 --> 00:18:54.400
Previously,
they were just supported for output only.

00:18:54.400 --> 00:18:57.870
And this is going to be including,
as I said,

00:18:57.870 --> 00:19:01.800
raw AC3 data as well as raw MPEG 1 and
2 and any other data that you have.

00:19:01.800 --> 00:19:09.540
And this can also be used to
transport non-audio sideband data.

00:19:09.540 --> 00:19:12.970
For example, time code,
such as SMPTE coming into the

00:19:12.970 --> 00:19:17.060
hardware or word clock time or
other forms of synchronization.

00:19:17.060 --> 00:19:21.140
And it's also good for real-time
controller information for

00:19:21.310 --> 00:19:23.160
devices that support that.

00:19:25.910 --> 00:19:31.180
So before I talk a little bit
more about aggregate devices,

00:19:31.180 --> 00:19:33.340
I want to talk a little bit
about the problem that aggregate

00:19:33.420 --> 00:19:34.520
devices are there to solve.

00:19:34.560 --> 00:19:37.850
Basically,
when you're syncing multiple devices,

00:19:37.850 --> 00:19:40.180
you have two problems to deal with.

00:19:40.230 --> 00:19:43.780
You have the different
interpretation each device has for

00:19:43.780 --> 00:19:45.840
what the sample rate really is.

00:19:45.860 --> 00:19:47.910
That's also known as
the clock drift problem.

00:19:47.920 --> 00:19:53.470
And then you have each device has its
own amount of presentation latency in it.

00:19:53.920 --> 00:19:57.830
And you have to solve both of these
problems if you want to do I.O.

00:19:57.840 --> 00:20:00.920
synchronized on multiple devices.

00:20:02.590 --> 00:20:05.670
So to solve these problems,
you can use hardware

00:20:05.670 --> 00:20:08.250
clock synchronization,
and that's where you are running

00:20:08.260 --> 00:20:11.550
an actual physical cable between
all the devices and sharing a

00:20:11.550 --> 00:20:13.720
clock signal among all the devices.

00:20:13.720 --> 00:20:18.200
And this can be done using
digital audio interfaces like

00:20:18.200 --> 00:20:21.040
AES or SPDIF or ADAT interfaces.

00:20:21.040 --> 00:20:24.000
And you can also use
things like House Sync,

00:20:24.000 --> 00:20:29.530
Blackburst, and other more high-end
video-oriented Studio Sync situations.

00:20:30.600 --> 00:20:34.950
Hardware Sync provides the best solution
for the clock drift problem since it's

00:20:34.950 --> 00:20:39.190
actually synchronizing the hardware
at the DAC level so that you know the

00:20:39.190 --> 00:20:43.590
samples are going to be within some
very small amount of time of each other.

00:20:43.600 --> 00:20:48.270
But hardware clock synchronization
doesn't solve the latency problem at all.

00:20:49.800 --> 00:20:52.410
So in addition to hardware,
you can also do the

00:20:52.410 --> 00:20:54.700
resynchronization in software.

00:20:54.750 --> 00:20:58.130
Now, doing it in software is an order of
magnitude more complicated than it

00:20:58.130 --> 00:21:02.760
is in hardware because your software
needs to be able to judge how fast each

00:21:02.760 --> 00:21:08.800
device is running with respect to each
other and then compensate accordingly.

00:21:08.800 --> 00:21:13.790
And you use various kinds of
resampling techniques to do that.

00:21:14.030 --> 00:21:17.490
But you still need to compensate
for the latency differences even

00:21:17.570 --> 00:21:19.770
when you're doing software sync.

00:21:21.260 --> 00:21:25.980
So aggregate devices are the
HAL's attempt to solve all these

00:21:25.980 --> 00:21:30.410
problems in a way that makes
it useful for your application.

00:21:30.420 --> 00:21:34.520
It gathers together any number
of disparate audio devices

00:21:34.520 --> 00:21:39.310
on the system into a single
cohesive unit for audio I.O.

00:21:39.320 --> 00:21:41.890
And it will perform synchronized I.O.

00:21:41.890 --> 00:21:46.300
to all those sub-devices regardless
of what their sync situation is.

00:21:46.300 --> 00:21:49.340
They can be hardware synchronized,
they can be software synchronized,

00:21:49.430 --> 00:21:51.700
and the HAL will still be
able to deal with that.

00:21:51.750 --> 00:21:54.860
And to do this, of course,
it solves the problems I was just

00:21:54.860 --> 00:21:58.520
talking about of the different
amounts of presentation latency,

00:21:58.520 --> 00:22:01.920
and it does the clock drift compensation.

00:22:04.300 --> 00:22:08.390
So the user can create aggregate
devices that are global to the

00:22:08.390 --> 00:22:10.680
entire system in audio MIDI setup.

00:22:10.680 --> 00:22:13.620
And I'll show you in a few
minutes about how that works.

00:22:13.620 --> 00:22:20.190
Applications can also create aggregate
devices that are either global to the

00:22:20.190 --> 00:22:23.620
system or local just to that process.

00:22:23.620 --> 00:22:27.450
And that's done programmatically
through API calls in the HAL.

00:22:28.340 --> 00:22:33.300
And then the HAL will also, on its own,
create a global aggregate device

00:22:33.620 --> 00:22:38.330
for each I/O audio device that has
multiple I/O audio engines in it.

00:22:38.560 --> 00:22:44.380
For example, USB audio devices that have
both input and output will now

00:22:44.380 --> 00:22:47.490
appear as a single unified whole.

00:22:51.530 --> 00:22:58.540
So you can only aggregate devices that
are implemented by I/O audio drivers.

00:22:58.730 --> 00:23:02.750
So some of you may have heard me talk
about the need to write an I/O audio

00:23:03.200 --> 00:23:05.900
driver rather than a user land driver.

00:23:05.910 --> 00:23:09.230
This is one of the benefits
you get by doing that.

00:23:09.240 --> 00:23:14.820
You get to play for free in
the aggregate device world.

00:23:14.870 --> 00:23:17.960
So further,
all sub-devices in an aggregate device

00:23:18.030 --> 00:23:20.420
have to be of the same sample rate.

00:23:20.450 --> 00:23:24.140
And of course, the sub-devices can't be
hogged by another process.

00:23:24.180 --> 00:23:27.200
And all their streams have to be mixable.

00:23:30.510 --> 00:23:34.740
So when you're looking at an
aggregate device and its sub-devices,

00:23:34.740 --> 00:23:39.050
the ordering of the sub-devices that
you set up either programmatically

00:23:39.170 --> 00:23:42.070
or through the AMS UI is important.

00:23:42.140 --> 00:23:45.390
And it determines the ordering
of the streams in the aggregate

00:23:45.390 --> 00:23:47.330
device that you see in your IOPROC.

00:23:47.400 --> 00:23:53.470
So for instance, if you have two devices,
device A and device B, and in that order,

00:23:53.470 --> 00:23:57.220
devices A streams will come
before devices B when you

00:23:57.220 --> 00:23:59.450
look at them in your IOPROC.

00:24:00.720 --> 00:24:04.670
and further, aggregate devices will
retain knowledge about the

00:24:04.670 --> 00:24:09.570
sub-devices that they aggregate,
even if the devices aren't

00:24:09.570 --> 00:24:15.200
present or have been deactivated
because of some format conflict.

00:24:15.350 --> 00:24:18.760
And further,
missing devices or devices that are in

00:24:18.770 --> 00:24:24.430
the wrong format will automatically just
come back into being in the aggregate

00:24:24.430 --> 00:24:27.860
device when their situation is updated.

00:24:30.320 --> 00:24:33.960
Each aggregate device
has a master sub-device.

00:24:34.090 --> 00:24:39.060
The master sub-device defines the overall
timeline for the entire aggregate device.

00:24:39.370 --> 00:24:43.030
This means that all the timestamps
you see from the HAL when you call

00:24:43.030 --> 00:24:46.770
audio device translate time or in
your IOPROC are going to be defined

00:24:46.780 --> 00:24:48.960
in the timeline of the master device.

00:24:48.960 --> 00:24:51.430
Further,
all the timing numbers that go with

00:24:51.430 --> 00:24:55.110
the aggregate device are the ones
reported for the master device.

00:24:55.110 --> 00:24:58.030
For instance,
the latency and safety offset figures

00:24:58.030 --> 00:24:59.980
are that of the master device.

00:25:00.200 --> 00:25:05.430
The final job the master device serves
is to provide the frame of reference

00:25:05.430 --> 00:25:11.130
that the HAL uses to judge clock drift
in the other sub-devices in the device.

00:25:11.140 --> 00:25:14.230
Now, when you're picking
the master sub-device,

00:25:14.340 --> 00:25:17.330
obviously if you have a
hardware sync situation,

00:25:17.330 --> 00:25:20.890
you already have in hardware
a notion of a master clock,

00:25:20.930 --> 00:25:24.360
and the device that corresponds
to that clock should also be the

00:25:24.360 --> 00:25:26.280
master device in the aggregate.

00:25:26.280 --> 00:25:29.230
Now, barring that,
you should always just look

00:25:29.320 --> 00:25:30.130
and set the device's clock.

00:25:30.140 --> 00:25:33.700
You can also look at the device
that has the most stable clock.

00:25:33.710 --> 00:25:37.900
Now, you can kind of guess at that by
what transport type the device uses.

00:25:37.960 --> 00:25:41.980
PCI and FireWire devices, for instance,
tend to have much more stable

00:25:41.980 --> 00:25:43.940
clocks than USB devices.

00:25:46.860 --> 00:25:52.800
So now to deal with the differing amounts
of latency in the various sub devices,

00:25:52.870 --> 00:25:57.720
the HAL has to go through and look at
all the sub devices and figure out what

00:25:57.840 --> 00:26:02.900
the maximum amount of latency there
is going to be for each sub device.

00:26:02.960 --> 00:26:08.130
And once it finds out which sub
device has the most latency,

00:26:08.300 --> 00:26:11.700
it then will pad out the
latency of the other devices by

00:26:12.010 --> 00:26:15.300
padding the safety offset of the
devices so that they all match.

00:26:15.910 --> 00:26:18.790
And here you can see a little
diagram showing three audio devices.

00:26:18.820 --> 00:26:25.400
Now, device C has the most combination
of latency and safety offset.

00:26:25.400 --> 00:26:29.300
And you can see how device A and
device B are getting padded out

00:26:29.300 --> 00:26:31.540
so that they all come out equal.

00:26:31.540 --> 00:26:35.600
Now, this is really important to do
this padding because that's what

00:26:35.600 --> 00:26:40.010
ensures that all the devices start
in synchronization with each other.

00:26:40.020 --> 00:26:42.370
Without that,
you'll be all skewed all over the place

00:26:42.370 --> 00:26:44.330
and you'll never be able to achieve sync.

00:26:46.300 --> 00:26:48.920
So once you've dealt with the latency,
you also have to deal

00:26:48.920 --> 00:26:49.870
with the clock drift.

00:26:49.880 --> 00:26:54.410
Now, aggregate devices in the HAL will
work regardless of what the clock

00:26:54.410 --> 00:26:56.500
domain situation is for each device.

00:26:56.500 --> 00:26:59.490
So whether it's hardware
synchronized or whether it needs

00:26:59.490 --> 00:27:02.540
to be synchronized in software,
the HAL's game for doing it.

00:27:02.640 --> 00:27:07.480
Now, for each sub-device you
have in an aggregate,

00:27:07.480 --> 00:27:13.680
you can set independently what kind
of clock drift compensation to use.

00:27:14.100 --> 00:27:17.740
Now, there are going to be three
basic versions of it in Tiger.

00:27:17.740 --> 00:27:21.230
First, there's no compensation,
and that's the method you're going to

00:27:21.230 --> 00:27:24.650
use for hardware sync situations because,
well, you don't have to do anything.

00:27:24.660 --> 00:27:25.800
It's already in sync.

00:27:25.800 --> 00:27:30.610
And then there's going to be a very
low CPU overhead sample dropping

00:27:30.700 --> 00:27:35.060
doubling algorithm who's going to
be there to account for that one

00:27:35.180 --> 00:27:39.460
sample of drift over five hours
of time that you're going to see.

00:27:39.500 --> 00:27:42.900
And that's going to be little CPU,
very little CPU.

00:27:42.900 --> 00:27:48.820
But with a potential... If it has to
run often to make the synchronization

00:27:48.820 --> 00:27:52.940
happen of getting some audio artifacts.

00:27:53.060 --> 00:27:56.530
And then the HAL will also use
the same high-quality resampling

00:27:56.530 --> 00:28:00.370
algorithms that are in the audio
converter to do the full bandwidth,

00:28:00.370 --> 00:28:04.250
you know, quality really matters
style of resynchronization.

00:28:04.260 --> 00:28:08.220
And just so you guys know,
the software synchronization is

00:28:08.220 --> 00:28:10.420
not in the seed you have today.

00:28:10.420 --> 00:28:13.320
That will be coming, we hope,
sometime in the future.

00:28:16.200 --> 00:28:18.750
So now you know what agro-devices do do.

00:28:18.750 --> 00:28:20.980
Now there are a few
things that they don't do.

00:28:20.980 --> 00:28:23.700
They don't provide controls.

00:28:23.700 --> 00:28:27.140
They don't do volume, mute,
data source selection,

00:28:27.140 --> 00:28:32.240
and all the other sort of little doodads
that you get on a regular audio device.

00:28:33.590 --> 00:28:36.830
And the reason for this is simple,
is that aggregate devices

00:28:36.830 --> 00:28:38.230
are there to be an I.O.

00:28:38.230 --> 00:28:39.260
abstraction.

00:28:39.260 --> 00:28:41.840
They're not meant to be
kind of the system console,

00:28:41.840 --> 00:28:42.620
if you will.

00:28:42.630 --> 00:28:48.660
You should always go back to the original
device to do the manipulations of volume,

00:28:48.670 --> 00:28:52.090
stream format,
and other things like that.

00:28:52.360 --> 00:28:55.310
Now,
aggregate devices also can't be hogged.

00:28:55.590 --> 00:29:00.340
That kind of plays into the fact that
they can't be non-mixable either.

00:29:00.340 --> 00:29:03.500
And finally,
an aggregate device cannot be hogged.

00:29:03.500 --> 00:29:06.420
So if you're going to
use aggregate devices,

00:29:06.420 --> 00:29:11.430
you have to provide the means for your
users to select them for your engine.

00:29:11.460 --> 00:29:13.850
They cannot be set as the default.

00:29:13.850 --> 00:29:18.730
Mostly that's to shield applications
that don't want to have the impact,

00:29:19.020 --> 00:29:22.930
the performance impact of running
on an aggregate device from

00:29:23.070 --> 00:29:25.370
just inadvertently seeing that.

00:29:25.420 --> 00:29:30.120
So now I'm going to show you a little
bit about how aggregate devices work.

00:29:35.800 --> 00:29:42.530
So in Tiger, in AMS,
there's a brand new dialog

00:29:42.530 --> 00:29:46.460
that allows you to configure
the various aggregate devices.

00:29:46.460 --> 00:29:51.170
Now, I'm here on a 15-inch PowerBook,
and I've also brought with me a

00:29:51.220 --> 00:29:55.680
bunch of other kinds of devices just
to show you kind of how it works.

00:29:55.680 --> 00:30:00.650
The first device I have here is a,
let's show you this one first.

00:30:00.670 --> 00:30:03.540
It's a Edderall UA3 USB interface.

00:30:03.540 --> 00:30:05.720
It has input and output.

00:30:05.720 --> 00:30:06.450
It's stereo.

00:30:06.460 --> 00:30:10.140
Now, the reason this one's interesting
is this will show you what

00:30:10.140 --> 00:30:13.620
happens when the HAL creates
an automatic aggregate device,

00:30:13.620 --> 00:30:18.470
since this device has one IO audio
device that has two IO audio engines.

00:30:23.200 --> 00:30:24.200
and the rest of the team.

00:30:25.200 --> 00:30:32.360
So, you can see an AMS by looking at
the icon what kind of device it is.

00:30:32.360 --> 00:30:36.280
You can see the UA3,
the normal UA3 is here and you can

00:30:36.450 --> 00:30:38.840
see all its controls and stuff.

00:30:38.840 --> 00:30:40.560
And now we go to the aggregate UA3.

00:30:40.660 --> 00:30:45.630
Now, an AMS kind of shields you from some
of the implementation details but,

00:30:45.670 --> 00:30:48.200
you know,
those of you that have been fighting with

00:30:48.490 --> 00:30:52.050
this for a while know that this is really
when you look at the UA3 in AMS you're

00:30:52.050 --> 00:30:55.740
looking at two independent audio devices.

00:30:55.740 --> 00:31:00.180
And so you have to run two separate
I/O procs in order to do I/O with that,

00:31:00.390 --> 00:31:02.300
to just do pass-through I/O,
for instance.

00:31:02.510 --> 00:31:07.710
Now, with the aggregate UA3 USB device,
you can now run one I/O proc and do

00:31:07.710 --> 00:31:11.970
pass-through and in-place processing
and all the things you would have had

00:31:11.970 --> 00:31:14.620
to do more complex management before.

00:31:14.620 --> 00:31:18.290
Now,
I've also brought an Echo Indigo PC card.

00:31:19.400 --> 00:31:19.400
Just kind of showing you the interface.

00:31:19.400 --> 00:31:19.400
Okay.

00:31:19.400 --> 00:31:19.400
So, I've got a few things here.

00:31:19.400 --> 00:31:19.400
I've got a few things here.

00:31:19.400 --> 00:31:20.900
I've got a few kind of show you
something a little more exotic.

00:31:20.900 --> 00:31:27.690
It's a little stereo two-channel device,
and it pops up, and it's all good.

00:31:27.700 --> 00:31:31.610
So now I'm going to make an
aggregate device out of it.

00:31:31.720 --> 00:31:36.070
So you open the aggregate device editor,
and you start out with no aggregate

00:31:36.070 --> 00:31:37.730
devices that are user-made.

00:31:38.110 --> 00:31:41.660
The automatically generated aggregate
devices don't appear in this

00:31:41.660 --> 00:31:45.060
dialogue because there's nothing
you can really configure about them.

00:31:45.170 --> 00:31:47.350
So you click on the plus
button to make a new one.

00:31:47.500 --> 00:31:49.560
You can give it an interesting name.

00:31:49.560 --> 00:31:51.560
Whoops.

00:31:57.930 --> 00:32:01.820
And then you go in and you can see
down below all the devices that you

00:32:01.820 --> 00:32:04.570
have that you can add to the aggregate.

00:32:04.760 --> 00:32:07.060
Now I'm just going to
click on all of them.

00:32:07.080 --> 00:32:11.140
And then once you have them clicked,
you can move them around.

00:32:11.990 --> 00:32:15.200
Because the order is important,
so you can drag them around.

00:32:15.380 --> 00:32:19.310
And then you can use the clock
radio button to select which is

00:32:19.310 --> 00:32:21.620
going to be the master device.

00:32:22.020 --> 00:32:23.240
And that's pretty much it.

00:32:23.240 --> 00:32:26.580
And you can see now that we've
created this aggregate device,

00:32:26.580 --> 00:32:32.870
it now shows up in the pop-up for-- well,
it did show-- this is it.

00:32:32.880 --> 00:32:33.880
The name isn't updated.

00:32:33.880 --> 00:32:36.680
That's a bug, too.

00:32:37.960 --> 00:32:39.720
So, but there you can see it.

00:32:39.720 --> 00:32:41.740
You can see now this
aggregate device has,

00:32:41.740 --> 00:32:44.770
you know, four input channels and
four output channels and,

00:32:44.900 --> 00:32:46.610
you know, and it's, when you do I.O.

00:32:46.610 --> 00:32:48.760
with that, you're going to see,
you're going to be

00:32:48.760 --> 00:32:50.010
doing synchronized I.O.

00:32:50.010 --> 00:32:52.280
across all the devices
that were in the aggregate.

00:32:52.280 --> 00:32:54.630
And that's pretty much
all there is to it.

00:32:57.460 --> 00:33:02.960
Next up, I'm going to be bringing
up Nick Thompson,

00:33:02.960 --> 00:33:06.040
and he's going to talk about
driver development in OS X.

00:33:13.420 --> 00:33:15.450
and other devices.

00:33:15.450 --> 00:33:22.400
So I want to talk about developing
audio hardware devices for Mac OS X.

00:33:22.400 --> 00:33:26.160
I wanted to look at the kinds of
devices you might do for built-in

00:33:26.160 --> 00:33:30.510
hardware with a standard Macintosh,
and I want to look at how you can expand

00:33:30.610 --> 00:33:34.990
on the built-in capabilities that you
find in every Macintosh computer by

00:33:34.990 --> 00:33:37.670
using high-speed serial interfaces.

00:33:37.700 --> 00:33:43.380
You'll have noticed that music and audio
have become very important to Apple.

00:33:43.400 --> 00:33:49.000
And what we're talking about in this
part of the session is how to get

00:33:49.000 --> 00:33:51.790
audio in and out of your computer.

00:33:52.820 --> 00:33:58.150
So the key thing here when we're thinking
about this is when you develop a product,

00:33:58.190 --> 00:34:01.200
you want to hit as
many people as you can.

00:34:01.540 --> 00:34:06.500
So USB and FireWire, if you're developing
an expansion product,

00:34:06.500 --> 00:34:09.420
are in every Macintosh
computer that we ship today.

00:34:09.460 --> 00:34:13.210
There's also good opportunities for
using the built-in analog connections,

00:34:13.210 --> 00:34:17.110
both for input and output
for audio peripherals.

00:34:18.250 --> 00:34:20.610
When you look in Darwin at
the driver stack,

00:34:20.610 --> 00:34:22.060
you'll see a bunch of things.

00:34:22.060 --> 00:34:24.560
The two things you really want
to look at are Apple Onboard

00:34:24.560 --> 00:34:26.650
Audio and Apple USB Audio.

00:34:26.660 --> 00:34:32.840
Apple USB Audio gives you kind of a basic
template for how to write a USB driver.

00:34:32.840 --> 00:34:36.450
The Onboard Audio is a little more
complex because there's a whole

00:34:36.500 --> 00:34:38.020
bunch of stuff that we have to do.

00:34:38.020 --> 00:34:39.560
So when you're looking
at the source code,

00:34:39.670 --> 00:34:41.380
you'll actually see a
whole bunch of plug-ins.

00:34:41.480 --> 00:34:44.580
So I recommend if you want
a template audio driver,

00:34:44.580 --> 00:34:47.930
USB,
or the examples in the Core Audio SDK for

00:34:47.930 --> 00:34:50.040
the Phantom Audio driver
are the place to start.

00:34:53.010 --> 00:34:55.140
So the technologies
available are basically,

00:34:55.140 --> 00:34:57.620
you can use the stuff that's built in,
and that's usually analog,

00:34:57.620 --> 00:35:02.390
but we also supply digital output
on Power Mac and Touch G5s,

00:35:02.460 --> 00:35:04.580
but basically you're
limited to two channels.

00:35:04.600 --> 00:35:06.890
If you want to go multi-channel,
you're going to need some

00:35:06.890 --> 00:35:08.180
kind of audio peripheral.

00:35:08.180 --> 00:35:11.580
And if you look at the list of
things that you can do here,

00:35:11.580 --> 00:35:14.820
PC cards, PCI, I mean,
they're good solutions,

00:35:14.820 --> 00:35:17.380
but you're only going to
hit a subset of the market.

00:35:17.400 --> 00:35:19.580
And if you're going to
develop for the platform,

00:35:19.700 --> 00:35:22.120
it's a good idea to hit the
most people that you can.

00:35:22.120 --> 00:35:27.100
So we really recommend USB and FireWire
for the development of audio peripherals.

00:35:29.370 --> 00:35:32.880
So we kind of think about audio
devices in this kind of continuum,

00:35:32.880 --> 00:35:35.300
for want of a better word,
of audio devices.

00:35:35.410 --> 00:35:38.660
And at the consumer level,
we kind of see built-in audio.

00:35:38.660 --> 00:35:40.930
It's cheap to do an analog peripheral.

00:35:41.010 --> 00:35:43.020
You can do some really
attractive things with that.

00:35:43.020 --> 00:35:45.140
USB is a good approach for hobbyists.

00:35:45.140 --> 00:35:48.450
You're a little limited in the
number of channels that you get,

00:35:48.580 --> 00:35:50.600
but it's a good connect solution.

00:35:50.620 --> 00:35:53.430
And we look at FireWire as
being a kind of prosumer,

00:35:53.470 --> 00:35:54.460
pro solution.

00:35:54.460 --> 00:35:58.490
So let's kind of dive in and take a
look at what's available for built-in.

00:35:59.790 --> 00:36:04.200
Basically, you've got two kinds of things
that you'd be looking at here,

00:36:04.260 --> 00:36:07.660
input devices, output devices,
or little mixers.

00:36:07.780 --> 00:36:09.020
They'd be analog connect.

00:36:09.040 --> 00:36:13.560
The codecs that we ship in Macintosh
computers have great noise specs,

00:36:13.560 --> 00:36:17.140
and they actually measure better
than a lot of USB devices out there.

00:36:17.140 --> 00:36:21.070
So this is a good way of
actually connecting peripherals

00:36:21.070 --> 00:36:22.990
if you only need stereo.

00:36:23.230 --> 00:36:26.200
The other thing that's important
to think about is optical SPDIF,

00:36:26.250 --> 00:36:28.480
which is available on
the Power Macintosh G5.

00:36:28.480 --> 00:36:34.010
You can develop peripherals
that can do things like AC3 if

00:36:34.010 --> 00:36:36.590
you want to do multi-channel
data by encoding the stream.

00:36:36.600 --> 00:36:42.220
You can also use this for getting
audio in and out of your computer

00:36:42.220 --> 00:36:45.000
digitally at a very low cost.

00:36:45.000 --> 00:36:50.110
So consider SPDIF if you're looking at
development of this type of peripheral.

00:36:53.640 --> 00:36:57.410
So kind of summing up for built-in,
it's basically stereo,

00:36:57.410 --> 00:36:59.350
and there's also optical support.

00:36:59.490 --> 00:37:02.770
So there's some good opportunities
there for peripheral development.

00:37:02.980 --> 00:37:05.690
Moving on kind of to USB.

00:37:08.130 --> 00:37:11.710
The important thing to emphasize
here is if you develop a device that

00:37:11.710 --> 00:37:18.280
conforms to the USB Implementers
Forum specifications for audio devices,

00:37:18.280 --> 00:37:20.640
it's just going to work
with Apple's driver.

00:37:20.670 --> 00:37:23.410
This is really important because you want
to minimize your development costs when

00:37:23.430 --> 00:37:25.560
you're bringing a new device to market.

00:37:25.590 --> 00:37:28.460
So always consider trying to
make a class-compliant device

00:37:28.480 --> 00:37:30.710
if that's possible for you.

00:37:30.830 --> 00:37:33.420
We put the audio class driver in Darwin.

00:37:33.420 --> 00:37:34.310
It's open source.

00:37:34.430 --> 00:37:37.280
But what we've seen in the past
is that developers will take a

00:37:37.280 --> 00:37:40.300
drop of the Darwin source code,
start working with it.

00:37:40.450 --> 00:37:43.600
We go fix a bunch of bugs,
improve the parser, add new features,

00:37:43.670 --> 00:37:47.040
and they're kind of stuck on
this two-year-old source base.

00:37:47.070 --> 00:37:50.680
So if you can develop a
class-compliant device,

00:37:50.730 --> 00:37:52.480
it's going to work with our driver.

00:37:52.510 --> 00:37:55.060
If it doesn't work with our driver,
please let us know,

00:37:55.060 --> 00:37:57.380
and we'll fix our driver.

00:37:57.860 --> 00:38:02.280
The other thing I wanted to call out
here is the Audio Device 2.0 spec.

00:38:02.440 --> 00:38:06.540
The current spec is, I believe,
the Audio Device 1.0 spec,

00:38:06.540 --> 00:38:08.930
and that's several years old now.

00:38:09.060 --> 00:38:12.260
There's a device working
group working on a 2.0 spec,

00:38:12.300 --> 00:38:14.820
and we're tracking this work.

00:38:15.000 --> 00:38:16.250
We're studying it.

00:38:16.530 --> 00:38:20.940
If you're developing a USB 2.0 device,
please talk to us because we

00:38:20.940 --> 00:38:24.290
really want to make sure it
works with our driver set.

00:38:26.300 --> 00:38:28.090
The Class Drive is full-featured.

00:38:28.200 --> 00:38:31.540
One of the things that we want to
call out is there's actually a small

00:38:31.540 --> 00:38:34.920
API in there for doing DSP plugins,
and that may seem kind of weird

00:38:34.920 --> 00:38:38.540
because you've probably heard
a lot about core audio plugins.

00:38:38.580 --> 00:38:40.410
This is kind of a different thing.

00:38:40.410 --> 00:38:43.800
This is if you're, for example,
making some speakers and you have

00:38:43.800 --> 00:38:47.220
a proprietary base enhancement
algorithm for your loudspeakers,

00:38:47.270 --> 00:38:50.460
and you don't want everybody
to get access to that code.

00:38:50.960 --> 00:38:54.060
You can use the plugin API to
basically match to your device and

00:38:54.060 --> 00:38:57.500
only your device so that your code
will only run with your device,

00:38:57.500 --> 00:38:59.470
and that's an important thing.

00:39:01.910 --> 00:39:05.510
So summing up on USB,
basically we see USB as a very good

00:39:05.510 --> 00:39:09.280
solution for consumer applications
and low-cost applications.

00:39:09.380 --> 00:39:13.710
But the thing that's problematic about
USB is that customization of your device

00:39:13.760 --> 00:39:16.010
may actually require a custom driver.

00:39:16.050 --> 00:39:18.150
It's a lot of work.

00:39:20.600 --> 00:39:25.200
The other thing is that the bandwidth for
USB 1.1 devices is relatively limited.

00:39:25.200 --> 00:39:27.860
You're looking at basically eight
channels of input or output.

00:39:27.860 --> 00:39:32.580
But it's a good solution
for a limited channel count,

00:39:32.620 --> 00:39:35.730
and you can also do MIDI support.

00:39:37.130 --> 00:39:40.440
The thing I really wanted to
dive into today is FireWire.

00:39:40.480 --> 00:39:43.020
We're really excited about FireWire.

00:39:43.120 --> 00:39:45.700
If you're developing a
FireWire audio device,

00:39:45.720 --> 00:39:47.320
you essentially have multiple options.

00:39:47.330 --> 00:39:50.540
You can develop a custom device,
and a lot of developers have been

00:39:50.540 --> 00:39:52.560
very successful with a custom device.

00:39:52.780 --> 00:39:56.040
The problem with developing custom
devices is you've got to figure out the

00:39:56.040 --> 00:39:57.990
protocol for getting data to the device.

00:39:58.290 --> 00:40:00.020
You've got to write
firmware for the device,

00:40:00.050 --> 00:40:02.660
and you've got to write a
device driver for the device.

00:40:02.680 --> 00:40:05.460
Now, the people who've done this
have come first to market,

00:40:05.460 --> 00:40:07.070
and they've got great products.

00:40:07.200 --> 00:40:10.630
But it is something to think
about when you're considering

00:40:10.630 --> 00:40:12.460
how to implement your device.

00:40:12.500 --> 00:40:15.940
A better way to go is to develop
your device according to some

00:40:15.940 --> 00:40:17.660
of the TA specs out there.

00:40:17.800 --> 00:40:20.820
And there's really two specs that
you want to look at-- the audio

00:40:20.820 --> 00:40:22.690
subunit and the music subunit.

00:40:22.930 --> 00:40:26.500
They kind of overlap,
and it may actually be necessary

00:40:26.500 --> 00:40:29.930
in a music subunit device to
have an audio subunit so that you

00:40:29.990 --> 00:40:33.220
can get at some of the controls,
such as volume controls.

00:40:33.270 --> 00:40:36.160
The other thing we stress is if
you're developing a FireWire device,

00:40:36.390 --> 00:40:38.630
join the 1394 Trade Association.

00:40:38.650 --> 00:40:42.140
They're the umbrella organization for
people developing FireWire devices.

00:40:42.190 --> 00:40:44.160
They look after some of the specs.

00:40:44.260 --> 00:40:46.880
And there's a lot of
good information there,

00:40:46.930 --> 00:40:51.400
particularly in terms of getting
access to draft specifications.

00:40:53.410 --> 00:40:56.590
However, we recognize that there are
some challenges in developing

00:40:56.590 --> 00:40:59.770
a FireWire audio device,
and we kind of looked at why it was

00:40:59.770 --> 00:41:03.210
difficult to do this and why there
weren't more FireWire devices out there.

00:41:03.300 --> 00:41:06.760
Really, it falls into three main areas
in terms of the problems.

00:41:06.760 --> 00:41:08.350
There's a lot of standards.

00:41:08.350 --> 00:41:14.130
If you go to the 1394 TA standards page,
you can spend 10 or 15 minutes trying to

00:41:14.130 --> 00:41:17.840
figure out how everything fits together,
and then you can spend several

00:41:17.840 --> 00:41:20.770
weeks actually downloading and
reading all of those specs.

00:41:21.640 --> 00:41:24.680
Also, compared to USB,
the cost of silicon has been

00:41:24.680 --> 00:41:26.360
perceived as really high.

00:41:26.480 --> 00:41:29.490
We're going to talk about that,
and I'm actually going to bring up

00:41:29.490 --> 00:41:32.840
a couple of vendors that we've been
working with who've been looking

00:41:32.840 --> 00:41:34.530
at much lower-cost solutions.

00:41:34.580 --> 00:41:37.890
And then the other difficulty
is the software development.

00:41:37.890 --> 00:41:41.800
You've got two kind of areas here,
the problems in terms of developing the

00:41:41.800 --> 00:41:46.270
firmware for the device and also the
problems for developing device drivers.

00:41:46.280 --> 00:41:48.400
So let's try and clear some of this up.

00:41:51.460 --> 00:41:57.460
In terms of a roadmap for standards
relating to audio devices,

00:41:57.550 --> 00:42:00.170
this slide shows the kind of things
that you're going to be interested in.

00:42:00.180 --> 00:42:05.600
Really, 1394 defines the base electrical
spec and packet format on the bus,

00:42:05.600 --> 00:42:09.200
and the 61883 specs
kind of cover streaming.

00:42:09.200 --> 00:42:12.640
In a sense,
when you're dealing with your device,

00:42:12.640 --> 00:42:16.640
the stuff that you're going to
be sending and receiving from

00:42:16.640 --> 00:42:20.180
the device falls into two areas,
isochronous transfers and

00:42:20.180 --> 00:42:21.440
asynchronous transfers.

00:42:21.520 --> 00:42:25.080
Isochronous transfers
for guaranteed bandwidth,

00:42:25.250 --> 00:42:30.070
and for every 1394 packet,
a certain amount of that packet on the

00:42:30.160 --> 00:42:32.460
bus is reserved for isochronous data.

00:42:32.530 --> 00:42:36.060
Asynchronous is data that you kind
of want to get to the device and

00:42:36.060 --> 00:42:38.280
you want to have it acknowledged,
but it doesn't necessarily

00:42:38.280 --> 00:42:39.180
have to go right now.

00:42:39.250 --> 00:42:42.670
It turns out you use ISOC for
streaming MIDI and audio,

00:42:42.670 --> 00:42:45.400
and it turns out that generally
you use async for querying the

00:42:45.400 --> 00:42:47.910
capabilities of the device.

00:42:48.820 --> 00:42:52.440
So this slide-- can
you actually read this?

00:42:52.440 --> 00:42:56.810
This slide kind of covers the
specs that you really care about.

00:42:56.930 --> 00:43:01.730
At the top, audio and music subunit,
you kind of need to decide which

00:43:01.730 --> 00:43:04.180
is most appropriate to your device.

00:43:04.240 --> 00:43:07.180
Generally, audio subunit devices
are simpler devices.

00:43:07.200 --> 00:43:09.760
They're appropriate for speakers.

00:43:09.900 --> 00:43:12.200
They're appropriate
for simple I/O devices.

00:43:12.360 --> 00:43:15.960
Music subunits are usually devices
where you have a number of audio streams

00:43:15.960 --> 00:43:19.900
and you also want to embed MIDI data.

00:43:22.300 --> 00:43:24.960
So when you're considering
developing a FireWire audio solution,

00:43:24.960 --> 00:43:27.180
there's essentially
three main components.

00:43:27.180 --> 00:43:31.080
We've talked about the hardware,
the software, the hardware, the firmware,

00:43:31.080 --> 00:43:32.440
and the device driver.

00:43:32.500 --> 00:43:35.180
Firmware is basically what's going
to run on your embedded system.

00:43:35.180 --> 00:43:37.520
The device driver is what's
going to run on the Mac to

00:43:37.520 --> 00:43:40.410
communicate with your device.

00:43:41.230 --> 00:43:46.580
The key point here is if you develop
firmware that's spec compliant,

00:43:46.710 --> 00:43:48.550
you don't have to do device driver work.

00:43:48.600 --> 00:43:53.380
And that's a really big issue in terms of
the cost of development of your product.

00:43:54.750 --> 00:43:57.400
So let's look at some of the
resources available for developing

00:43:57.630 --> 00:44:00.260
audio devices based on FireWire.

00:44:00.540 --> 00:44:03.500
There's a number of silicon vendors
out there who have products.

00:44:03.570 --> 00:44:07.400
They range from relatively
expensive to relatively inexpensive.

00:44:07.400 --> 00:44:11.110
We recommend that you do some research
and have a look at a couple of vendors

00:44:11.200 --> 00:44:13.100
when you're choosing a solution.

00:44:16.170 --> 00:44:18.680
BridgeCo were pretty much the
first out of the gate shipping

00:44:18.780 --> 00:44:21.460
standards-compliant silicon.

00:44:21.590 --> 00:44:24.200
And they have a solution
called the DM1000,

00:44:24.200 --> 00:44:28.540
which is in a number of the devices that
were announced earlier this year at NAMM.

00:44:28.750 --> 00:44:32.900
The interesting thing about BridgeCo is
they have licensable firmware which

00:44:32.900 --> 00:44:34.780
can be customized for your application.

00:44:37.070 --> 00:44:38.790
and we've been working with
a number of vendors who are

00:44:38.840 --> 00:44:41.500
bringing their products to market
based on the Bridgecut solution.

00:44:41.600 --> 00:44:45.500
The first one out of the
gate was the Roland FA-101.

00:44:45.500 --> 00:44:47.640
It's a cool illustration of it up here.

00:44:47.640 --> 00:44:51.220
A 10 in, 10 out device with MIDI support.

00:44:51.480 --> 00:44:57.250
A number of other vendors have
announced support of this platform.

00:44:57.320 --> 00:45:01.570
And this platform is basically
music subunit compliant.

00:45:02.630 --> 00:45:04.880
To talk about an audio
subunit compliant device,

00:45:04.890 --> 00:45:07.970
I'd like to bring up
James Lewis from Otsu Semiconductor

00:45:07.970 --> 00:45:16.350
to talk about their product.

00:45:23.600 --> 00:45:24.790
Thanks Nick.

00:45:24.790 --> 00:45:28.500
We're here today to introduce some
technology for bringing a very

00:45:28.500 --> 00:45:34.100
low-cost solution to FireWire audio
for multi-channel applications.

00:45:34.100 --> 00:45:36.670
You can also see this on
our booth downstairs and at

00:45:36.670 --> 00:45:38.950
Plugfest later on in the week.

00:45:41.630 --> 00:45:46.060
Now Oxford Semiconductor has a very
strong background in FireWire technology

00:45:46.060 --> 00:45:49.780
through our mass storage chips,
so most of you have probably heard of us.

00:45:49.780 --> 00:45:54.080
And we're a very strong
adherer to the 1394 standard,

00:45:54.080 --> 00:45:59.100
and also through our position
on the 1394 Trade Association,

00:45:59.100 --> 00:46:03.820
we're actively involved in developing
new aspects of 1394 standards.

00:46:03.820 --> 00:46:08.470
So we're going to give you a bit
of a technology introduction into

00:46:08.610 --> 00:46:10.950
the chip and a demo to finish up.

00:46:11.080 --> 00:46:14.520
And I'm going to hand over
to Andy Parker to do that.

00:46:16.200 --> 00:46:18.660
Thanks, James.

00:46:18.660 --> 00:46:20.640
OK, so we're all developers.

00:46:20.760 --> 00:46:26.880
Oh, could we go back to the slides,
please?

00:46:31.750 --> 00:46:32.050
Maybe not.

00:46:32.070 --> 00:46:33.200
Could we have the slides, please?

00:46:33.200 --> 00:46:33.540
Thank you.

00:46:33.600 --> 00:46:35.590
So we're all developers.

00:46:35.600 --> 00:46:38.900
What we're really interested
in is what's in the box.

00:46:38.900 --> 00:46:41.960
And the first thing we turn to
in the spec is the block diagram.

00:46:41.960 --> 00:46:47.800
The real thing to take home from
this picture is that most of what

00:46:47.800 --> 00:46:52.600
you get on the 970 is actually
contained within the device.

00:46:52.600 --> 00:46:55.990
And if you want to implement
an audio subunit which you can

00:46:55.990 --> 00:47:00.040
connect onto the FireWire or 1394,
as we call it, bus,

00:47:00.740 --> 00:47:03.250
you only need really a
handful of components.

00:47:03.260 --> 00:47:05.600
And in this case,
we're talking about an external

00:47:05.600 --> 00:47:09.580
physical interface for the
1394 and also at the back end,

00:47:09.580 --> 00:47:11.860
an I2S audio interface.

00:47:13.360 --> 00:47:18.360
In terms of the data flow
from the bus to the output,

00:47:18.410 --> 00:47:23.000
we basically have a very short
path from the link layer going

00:47:23.050 --> 00:47:26.380
through a queue selector,
which basically filters out

00:47:26.380 --> 00:47:29.830
isochronous and asynchronous data
that Nick talked about earlier,

00:47:29.830 --> 00:47:32.820
through a FIFO,
which is just a small buffer,

00:47:32.820 --> 00:47:35.320
and then out onto the audio core.

00:47:39.380 --> 00:47:43.800
We have an interesting application
example which is basically looking

00:47:43.800 --> 00:47:46.830
at multi-channel audio decode.

00:47:46.860 --> 00:47:52.080
And in this particular case we have
a compressed stream arriving over

00:47:52.080 --> 00:47:58.200
FireWire and is being transferred
by the 970 and through a hardware

00:47:58.200 --> 00:48:04.120
decoder and then passed out to a
multi-channel audio D2A converter stage.

00:48:05.560 --> 00:48:09.900
And this would be sort of
typically applied for replaying

00:48:09.900 --> 00:48:13.280
surround sound on your system.

00:48:13.700 --> 00:48:18.880
It's an interesting application
because it exploits one of the more

00:48:18.880 --> 00:48:22.360
interesting features of the 970,
which is that it's quite flexible in

00:48:22.360 --> 00:48:23.800
terms of the content that you pass it.

00:48:24.020 --> 00:48:28.880
The firmware actually transfers the data
from the iSoconer side to the I2S port.

00:48:28.900 --> 00:48:33.420
So whatever that data is,
provided it's compliant with standards,

00:48:33.420 --> 00:48:37.460
you can then transfer the data
over and match the two formats.

00:48:40.250 --> 00:48:44.680
We provide a developer kit which,
as Nick has talked about before,

00:48:44.680 --> 00:48:46.860
implements an AVC audio subunit.

00:48:46.860 --> 00:48:50.900
And it uses the standard
AVC command set to control and

00:48:50.900 --> 00:48:54.550
monitor the audio properties,
so things like mute settings,

00:48:54.620 --> 00:48:55.420
volume control.

00:48:55.420 --> 00:48:58.480
And it also decodes the
incoming isochronous data,

00:48:58.510 --> 00:49:02.380
which is, again,
compliant to AM824 specifications.

00:49:03.520 --> 00:49:07.100
It implements clock recovery,
which is basically just matching

00:49:07.110 --> 00:49:10.450
the rate of data that comes in
to the rate of data going out.

00:49:10.480 --> 00:49:13.800
Because if you don't do that,
you'll get strange distortions.

00:49:13.800 --> 00:49:19.400
And it works with the existing
Mac OS X FireWire audio driver.

00:49:19.400 --> 00:49:23.720
For the firmware development,
we use standard

00:49:23.720 --> 00:49:26.620
open-source GCC toolchain.

00:49:26.620 --> 00:49:30.730
And you can even develop
that on the Mac itself.

00:49:30.800 --> 00:49:36.190
We support most... popular
host development systems.

00:49:37.230 --> 00:49:43.740
We can also provide with the
framework to basically customize

00:49:43.970 --> 00:49:47.600
the firmware to match your specific
codec which is set on the back end.

00:49:47.620 --> 00:49:50.670
There's a full reference
design schematics and

00:49:50.670 --> 00:49:52.800
evaluation board available.

00:49:55.230 --> 00:50:00.200
In terms of the firmware itself,
the whole thing,

00:50:00.200 --> 00:50:03.980
the important thing to note is
the whole thing only comes to less

00:50:03.980 --> 00:50:07.370
than 64 kilobytes in terms of the
operating size of the program.

00:50:07.370 --> 00:50:09.390
And we've crammed quite a lot in there.

00:50:09.630 --> 00:50:13.310
So we have...

00:50:13.670 --> 00:50:16.140
Mac OS X, ooh, in 64K.

00:50:16.140 --> 00:50:17.580
I think that may be a mistake.

00:50:17.580 --> 00:50:21.360
We have an operating system layer,
which is not Mac OS X.

00:50:21.360 --> 00:50:27.130
And that just basically provides
a sort of low-level startup

00:50:27.230 --> 00:50:30.780
code for the processor that
we have embedded within the 970.

00:50:32.380 --> 00:50:37.360
And then we have a standard 1394,
or FireWire for the rest of its API,

00:50:37.360 --> 00:50:39.360
and some queue selector configuration.

00:50:39.360 --> 00:50:42.980
And again, all the queue selector does is
it's just filtering out isochronous

00:50:42.980 --> 00:50:43.880
and asynchronous traffic.

00:50:43.880 --> 00:50:46.870
And then we have some
higher-level handlers,

00:50:46.870 --> 00:50:51.100
which are handling the
standards-compliant data and generating

00:50:51.100 --> 00:50:56.500
the right responses to keep the Mac side
happy and compliant with the AVC specs.

00:51:00.230 --> 00:51:03.180
and I think we now have
time for a quick demo.

00:51:03.240 --> 00:51:05.310
Could we roll the demo, please?

00:51:13.900 --> 00:51:17.450
So this is generating the
surround sound over FireWire,

00:51:17.450 --> 00:51:21.320
being decoded on the 970
and played through the PA.

00:52:31.500 --> 00:52:33.660
Yes, all these FireWire guys do
is stand around and play

00:52:33.660 --> 00:52:36.810
Unreal Tournament all day.

00:52:37.230 --> 00:52:40.770
That's the Oxford board, the EVM board.

00:52:43.410 --> 00:52:47.700
We'll talk about this in a second,
but we'll have both of the solutions that

00:52:47.730 --> 00:52:51.320
we're going to talk about today available
for you to take a look at in the lab.

00:52:51.360 --> 00:52:54.330
We'll talk about that at
the end of the session.

00:52:56.200 --> 00:52:59.030
So one of the difficulties we
talked about with USB devices

00:52:59.030 --> 00:53:01.270
is customizing your device.

00:53:01.280 --> 00:53:04.690
One of the really cool things about
FireWire is it makes customizing

00:53:04.690 --> 00:53:06.880
device behavior way simpler.

00:53:06.880 --> 00:53:10.680
And the way that you can do that is
to send AVC commands to the device.

00:53:10.680 --> 00:53:13.570
So I'm going to talk you
through a quick example.

00:53:13.680 --> 00:53:16.570
It's not particularly realistic because,
hey, we're sending a volume command,

00:53:16.570 --> 00:53:19.830
and usually you'd rely on Core Audio to
send the volume command via the

00:53:19.830 --> 00:53:21.800
Apple FireWire Audio device driver.

00:53:21.910 --> 00:53:26.790
But it's a good example of how you
can customize behavior of your device.

00:53:27.230 --> 00:53:31.350
So there's actually a user client
in the FireWire audio driver that

00:53:31.350 --> 00:53:35.250
allows you access to various services.

00:53:35.310 --> 00:53:41.440
And you'll see in this example that these
services are preceded by the FWA prefix.

00:53:41.440 --> 00:53:44.110
So you can go count
the devices on the bus,

00:53:44.110 --> 00:53:48.420
open one of them, check its vendor ID,
and get its device name.

00:53:48.780 --> 00:53:52.810
Now, this obviously isn't a particularly
realistic example of how you

00:53:52.810 --> 00:53:56.030
would match to your device,
so I would suggest that you go

00:53:56.030 --> 00:53:58.980
look at the FireWire SDK for
much more comprehensive

00:53:58.980 --> 00:54:01.040
examples of device matching.

00:54:01.040 --> 00:54:03.220
But it kind of illustrates the point.

00:54:03.220 --> 00:54:07.340
The really cool thing about doing device
customization in this way is you don't

00:54:07.390 --> 00:54:09.590
have to write a kernel device driver.

00:54:09.590 --> 00:54:12.550
And your customization
code resides in user space,

00:54:12.550 --> 00:54:15.970
so you don't have to deal with
kernel panics if you screw up.

00:54:16.080 --> 00:54:18.760
And it's going to help you to do that.

00:54:18.780 --> 00:54:20.730
debug your code.

00:54:22.760 --> 00:54:25.360
To send the command to the device,
you set up a command block,

00:54:25.390 --> 00:54:29.100
and this example shows how to set
it up for an AVC volume command.

00:54:29.100 --> 00:54:33.930
And then to send your command,
you simply call the execute AVC command,

00:54:33.930 --> 00:54:39.590
making sure that you check that your
device actually accepted the command.

00:54:41.090 --> 00:54:43.800
An example of using the FireWire
audio client is actually

00:54:43.800 --> 00:54:47.440
the MLan implementation and
MLan support in Mac OS X.

00:54:47.440 --> 00:54:53.340
The Apple driver creates and
manipulates 61883-6 streams,

00:54:53.400 --> 00:54:56.830
but Yamaha supply an application
which does device discovery

00:54:56.870 --> 00:54:58.910
and configures the network.

00:54:59.570 --> 00:55:02.340
While we're on the subject of MLan,
some of the enhancements

00:55:02.360 --> 00:55:06.000
coming to future system update,
multiple device support,

00:55:06.060 --> 00:55:10.770
so you're going to be able to use
things like an ONX with Motif EX,

00:55:10.890 --> 00:55:16.770
and also external sync so the devices
can sync to an external clock.

00:55:19.110 --> 00:55:21.150
One of the things that I really
want to talk about today is

00:55:21.150 --> 00:55:24.970
the reference implementation
of AVC music and audio devices.

00:55:25.030 --> 00:55:28.000
Apple have been working on this,
and we're going to release it

00:55:28.000 --> 00:55:31.550
later in the year as part of
the FireWire reference platform.

00:55:31.680 --> 00:55:35.960
We're going to provide an audio subunit
reference and a music subunit reference.

00:55:37.960 --> 00:55:40.100
The way that this is all going
to fit together is you have all

00:55:40.100 --> 00:55:42.260
this stuff that runs on the Mac.

00:55:42.290 --> 00:55:45.690
On the device,
you're going to run some firmware.

00:55:45.830 --> 00:55:48.650
This is based on a
real-time operating system,

00:55:48.730 --> 00:55:49.710
RTOS.

00:55:49.830 --> 00:55:52.660
And on top of that,
we're layering the Apple FireWire

00:55:52.660 --> 00:55:54.640
Reference Platform.

00:55:54.700 --> 00:55:59.080
And the Apple Reference Music subunit
will sit on top of that.

00:56:04.200 --> 00:56:07.470
The other thing that's necessary when
you're developing a device is the

00:56:07.470 --> 00:56:09.470
ability to update the device's firmware.

00:56:09.610 --> 00:56:11.430
There's really two sides to this.

00:56:11.560 --> 00:56:15.940
The firmware on the device needs to be
able to accept an incoming ROM image,

00:56:16.010 --> 00:56:18.780
and you also need an application
that can send the firmware

00:56:18.780 --> 00:56:20.410
image down to the device.

00:56:20.680 --> 00:56:23.930
Most people who have FireWire
devices expect the device to

00:56:23.930 --> 00:56:25.790
be updatable over FireWire.

00:56:28.350 --> 00:56:30.950
The other resource when you're
developing your device are tools

00:56:30.950 --> 00:56:33.220
from the Apple FireWire SDK.

00:56:33.460 --> 00:56:37.620
Matt, our FireWire developer, said,
don't develop a device without it.

00:56:37.700 --> 00:56:40.300
There's some really cool
tools on the FireWire SDK.

00:56:40.420 --> 00:56:41.860
Firebug is a packet sniffer.

00:56:41.860 --> 00:56:44.100
An AVC browser will allow
you to look at the device

00:56:44.140 --> 00:56:47.300
descriptor for your AVC device.

00:56:48.620 --> 00:56:51.700
So I'd like to bring up Yoaram Solomon,
who's the general manager of the

00:56:51.830 --> 00:56:55.740
consumer electronics connectivity
business unit at Texas Instruments,

00:56:55.760 --> 00:56:58.700
to talk about some exciting things
that we've been working with TI on.

00:56:58.740 --> 00:57:00.800
Thanks, Yoaram.

00:57:03.700 --> 00:57:06.700
That's only half of my title.

00:57:06.700 --> 00:57:09.930
If we used the entire title,
I would run out of five minutes I have.

00:57:09.980 --> 00:57:13.980
Nick, thank you for having
me here in California.

00:57:13.980 --> 00:57:15.960
Anybody else flew from Texas here today?

00:57:17.320 --> 00:57:22.000
Yeah, we just left a whole month
minus five days worth of rain

00:57:22.000 --> 00:57:23.840
and tornadoes and everything.

00:57:23.840 --> 00:57:25.540
Believe me, you're not missing anything.

00:57:25.540 --> 00:57:29.040
Anyway,
I'm going to spend the next 20 minutes,

00:57:29.040 --> 00:57:32.150
got you, three minutes,
talking about what is

00:57:32.150 --> 00:57:34.080
it that we're offering.

00:57:34.460 --> 00:57:37.230
We've been working with
Apple for the past,

00:57:37.230 --> 00:57:41.080
I guess, several months,
more than just several months,

00:57:41.080 --> 00:57:45.840
developing this platform that
you can take off the shelf

00:57:45.980 --> 00:57:49.290
and we make it available right
now and work with the SDK.

00:57:49.340 --> 00:57:51.940
It has been quite an experience.

00:57:51.940 --> 00:57:56.850
It's kind of fun taking the devices
that we typically put in just those

00:57:57.170 --> 00:58:03.100
standard boring type end products and
finally put them on a kind of fun device.

00:58:04.260 --> 00:58:08.260
Some of the... Am I going
backwards or... Yeah,

00:58:08.310 --> 00:58:09.440
I'm going backwards.

00:58:13.000 --> 00:58:14.860
I'll stay on my title again.

00:58:15.060 --> 00:58:19.150
Okay, I already told you about
the cooperation with Apple.

00:58:19.470 --> 00:58:23.700
Texas Instruments has been focused,
the 1394 development to some extent,

00:58:23.700 --> 00:58:27.620
in audio products where they have
a lot of sensitivity to timing

00:58:27.950 --> 00:58:30.400
and all kinds of specifications.

00:58:30.400 --> 00:58:32.020
You know, one thing,
three things I can promise

00:58:32.020 --> 00:58:33.120
you in this presentation.

00:58:33.120 --> 00:58:35.000
I'm not going to get too technical,
that's one.

00:58:35.140 --> 00:58:37.860
Two is I don't have a demo,
and the third thing is we don't

00:58:37.860 --> 00:58:40.960
have Mac OS in 64K either.

00:58:42.090 --> 00:58:45.100
Our USB devices,
we have USB devices especially

00:58:45.200 --> 00:58:46.880
for audio applications.

00:58:46.890 --> 00:58:51.580
You can see them whether it's audio DACs,
ADCs, controllers, codecs.

00:58:51.580 --> 00:58:56.440
Therefore, as Nick said,
kind of the mid-range, lower-end,

00:58:56.440 --> 00:58:59.180
cost-sensitive type solutions.

00:58:59.180 --> 00:59:01.780
FireWire is really where we shine.

00:59:02.160 --> 00:59:05.060
Nick focused on that, we focused on that.

00:59:05.100 --> 00:59:09.240
We have a device that you're going to
see in the next slide called IC-Links,

00:59:09.240 --> 00:59:14.060
or as we like calling it, TSB43CB43A.

00:59:14.060 --> 00:59:16.200
And that's not including the package.

00:59:16.210 --> 00:59:20.800
That's really a relatively high-quality
device that you should see.

00:59:20.800 --> 00:59:23.790
It's reasonably priced.

00:59:23.800 --> 00:59:27.510
The board that Nick talked about
is a board that's going to be

00:59:27.560 --> 00:59:29.960
demonstrated in the lab tomorrow.

00:59:29.960 --> 00:59:32.770
The device that I'm
going to emphasize now,

00:59:32.780 --> 00:59:34.380
this is the IC-Links.

00:59:34.600 --> 00:59:38.440
Right top corner is where it's really at.

00:59:38.500 --> 00:59:44.300
This device is one-stop shop for
everything $13.94 to a relatively

00:59:44.300 --> 00:59:47.630
high-quality audio platform.

00:59:47.640 --> 00:59:49.440
That's all I have.

00:59:49.490 --> 00:59:50.310
Thank you.

00:59:59.100 --> 01:00:01.900
So we're absolutely delighted
to be working with TI on this.

01:00:01.900 --> 01:00:08.590
And it basically gives you a
low-cost development platform

01:00:08.680 --> 01:00:13.120
for adding high-speed serial
into an existing device.

01:00:13.130 --> 01:00:16.640
We see this applicable to
things like synthesizers,

01:00:16.790 --> 01:00:19.710
digital musical instruments,
digital effects units,

01:00:19.770 --> 01:00:22.340
kind of MI products.

01:00:23.910 --> 01:00:26.940
The key thing here is by basing
your audio device on Apple's

01:00:26.940 --> 01:00:31.010
Music Subunit Reference firmware,
you're going to really reduce

01:00:31.010 --> 01:00:34.100
your cost because there's quite
a lot of effort in actually just

01:00:34.230 --> 01:00:36.580
doing the FireWire firmware.

01:00:36.600 --> 01:00:43.700
So by adopting this solution,
you're going to be able to very easily

01:00:44.070 --> 01:00:48.190
work on the parts of your product
that differentiates in the marketplace

01:00:48.600 --> 01:00:50.180
rather than doing infrastructure work.

01:00:50.280 --> 01:00:52.760
And we think this is very important.

01:00:53.300 --> 01:00:55.850
The other thing is you'll be able
to work with our device driver,

01:00:55.860 --> 01:00:59.470
and this is going to save you
development time on the driver side.

01:01:00.500 --> 01:01:03.320
So summarizing, FireWire Audio,
it's a big pipe.

01:01:03.470 --> 01:01:04.740
There's more bandwidth than USB.

01:01:04.740 --> 01:01:09.140
There's a number of other advantages.

01:01:09.140 --> 01:01:11.310
We'll list some of them here.

01:01:16.570 --> 01:01:18.970
So FireWire is a good solution
where you need a lot of

01:01:19.050 --> 01:01:20.340
bandwidth and a lot of channels.

01:01:20.340 --> 01:01:23.960
You've got MIDI support in there,
and it's extensible by using

01:01:23.960 --> 01:01:25.500
AVC vendor-specific commands.

01:01:25.520 --> 01:01:30.070
So if you're considering producing
a new device or adding high-speed

01:01:30.070 --> 01:01:33.420
serial to an existing device,
we really encourage you to look

01:01:33.540 --> 01:01:35.390
at developing with FireWire.

01:01:35.400 --> 01:01:39.700
We've got resources available
from multiple vendors that are

01:01:39.700 --> 01:01:42.900
far lower cost than the products
that are currently shipping,

01:01:43.600 --> 01:01:46.960
and we're going to save you
money in terms of development

01:01:46.960 --> 01:01:48.640
time on your driver set.

01:01:52.850 --> 01:01:56.620
That kind of covers our
continuum of audio devices.

01:01:56.660 --> 01:01:59.640
So just to summarize,
there's a ton of opportunities out there.

01:01:59.750 --> 01:02:02.200
You can look at low-cost
garage band peripherals.

01:02:02.240 --> 01:02:06.780
You can look at very high-end
FireWire solutions for the music

01:02:06.780 --> 01:02:11.140
and audio production environment
and everything in between.

01:02:11.380 --> 01:02:15.180
Analog solutions are great for built-in
audio on Mac and such computers.

01:02:15.220 --> 01:02:18.740
And for hobbyist and prosumer solutions,
we recommend that you

01:02:18.920 --> 01:02:20.820
look at high-speed serial.

01:02:20.940 --> 01:02:24.540
The key thing here is I really urge you,
when you're considering

01:02:24.540 --> 01:02:27.980
developing a new device,
look at standards-based devices.

01:02:28.090 --> 01:02:31.220
You know,
you'll be saving yourself driver work,

01:02:31.250 --> 01:02:34.070
and your customers will be way happier.

01:02:36.100 --> 01:02:38.240
So in terms of who to
contact about stuff,

01:02:38.240 --> 01:02:41.090
I definitely recommend if you're a
hardware developer that you build

01:02:41.090 --> 01:02:42.590
a relationship with Craig Keithley.

01:02:42.640 --> 01:02:45.870
He's an IO Technologies evangelist.

01:02:45.880 --> 01:02:47.740
His email address is here.

01:02:47.760 --> 01:02:51.490
There's also a great mailing
list with a lot of traffic on it

01:02:51.560 --> 01:02:54.860
and a lot of very cool people,
both inside Apple and outside of Apple,

01:02:54.860 --> 01:02:57.780
answering questions on
the Corotia mailing list.

01:02:57.790 --> 01:03:02.270
And there's mailing lists available
for FireWire and USB developers.

01:03:07.660 --> 01:03:09.880
We also have a fairly
considerable reference library.

01:03:09.880 --> 01:03:14.210
There's a good bulk of information
about Core Audio and developing

01:03:14.310 --> 01:03:16.220
device drivers on Apple's website.

01:03:16.220 --> 01:03:21.220
Generally, a good jumping-off point is
developer.apple.com slash audio,

01:03:21.220 --> 01:03:25.000
and there's a reference to
most of these resources there.

01:03:25.000 --> 01:03:28.100
There's a Core Audio SDK,
which you should definitely be

01:03:28.230 --> 01:03:31.810
looking at from developing at
an application point of view,

01:03:31.810 --> 01:03:34.480
and there's sample drivers
in the Core Audio SDK.

01:03:34.480 --> 01:03:37.780
And the audio web page is there.

01:03:37.780 --> 01:03:41.330
If you're developing a FireWire device,
you should also look at Apple's

01:03:41.390 --> 01:03:44.480
FireWire reference platform,
because that can save you a lot of time

01:03:44.480 --> 01:03:46.100
and effort in firmware development.

01:03:54.200 --> 01:03:56.560
The other thing is,
the thing at the bottom is the

01:03:56.560 --> 01:03:57.860
important thing on this slide.

01:03:57.860 --> 01:04:02.000
There's a couple of trade groups,
USB Implementers Forum, 3940A.

01:04:02.000 --> 01:04:05.360
Check those out if you're developing
either a USB or a FireWire device.

01:04:05.360 --> 01:04:11.980
And then finally, tomorrow at noon,
the audio driver team will be available

01:04:11.980 --> 01:04:14.770
in the Graphics and Media Lab.

01:04:14.840 --> 01:04:16.840
We'll be showing the TI board.

01:04:16.840 --> 01:04:20.040
We'll, I think,
have Oxford represented there,

01:04:20.040 --> 01:04:22.150
so you can look at their board.

01:04:23.590 --> 01:04:25.310
Hopefully,
we'll be able to answer any questions

01:04:25.310 --> 01:04:28.910
that you have about developing firmware
or device drivers for audio devices.

01:04:28.910 --> 01:04:30.310
So thanks a lot.