WEBVTT

00:00:12.560 --> 00:00:17.780
Session 211, OpenGL Optimization: Live.

00:00:17.780 --> 00:00:18.900
I'm Dave Springer.

00:00:18.930 --> 00:00:25.290
This is Chris Niederauer.

00:00:26.230 --> 00:00:28.540
So it's 3:30 on Thursday.

00:00:28.540 --> 00:00:32.230
This is like nearly the
last day of the conference,

00:00:32.270 --> 00:00:33.250
right?

00:00:33.330 --> 00:00:35.690
You guys have been here a long time.

00:00:36.050 --> 00:00:40.600
You feeling a little conference burn?

00:00:40.680 --> 00:00:43.000
Here's a thought that keeps me going.

00:00:43.070 --> 00:00:49.000
In the whole of human history,
there's been appointed one Dave Springer.

00:00:49.090 --> 00:00:53.400
And for my life, my entire life,
I get to be him.

00:01:05.060 --> 00:01:07.820
We're going to talk about a couple
tools that we developed at Apple:

00:01:07.820 --> 00:01:11.910
OpenGL Profiler and
OpenGL Driver Monitor.

00:01:12.850 --> 00:01:17.940
And we're going to have live demos,
because we like to live on the edge.

00:01:18.350 --> 00:01:21.890
And this software you
see is pretty fresh,

00:01:21.900 --> 00:01:22.120
right?

00:01:22.240 --> 00:01:25.180
Pretty fresh.

00:01:25.260 --> 00:01:29.880
So anything could happen at any time.

00:01:30.460 --> 00:01:33.680
But what we're going to
do during these demos,

00:01:33.720 --> 00:01:39.350
and we're going to do it,
is show some of the performance

00:01:39.360 --> 00:01:44.780
bottlenecks that we've seen that
are common among OpenGL apps.

00:01:44.860 --> 00:01:51.770
So we get a lot of applications
come through the shop,

00:01:51.770 --> 00:01:51.770
and we see a lot of

00:01:51.960 --> 00:01:54.490
things like immediate mode,
when display list might

00:01:54.530 --> 00:01:55.770
be more appropriate.

00:01:55.830 --> 00:02:00.600
We see things like texture upload
usage that could be a little better.

00:02:00.650 --> 00:02:04.550
We see state changes that
aren't always necessary.

00:02:04.690 --> 00:02:10.450
So also, we'll show you about how to
debug your OpenGL applications

00:02:10.460 --> 00:02:12.170
using these tools as well.

00:02:14.000 --> 00:02:16.000
Okay.

00:02:16.000 --> 00:02:17.440
Now, why did we build this tool?

00:02:17.440 --> 00:02:21.830
Well, really,
it's -- those were the issues that

00:02:21.830 --> 00:02:23.600
we were running into all the time.

00:02:23.600 --> 00:02:30.860
We see a lot of performance problems
and we notice common themes.

00:02:30.860 --> 00:02:35.990
So we built this tool to quickly
identify those areas where you're maybe

00:02:35.990 --> 00:02:39.160
losing performance in your OpenGL apps.

00:02:39.260 --> 00:02:43.110
Also,
there was a lot of common misconceptions

00:02:44.180 --> 00:02:47.340
about why performance is being lost.

00:02:47.550 --> 00:02:50.460
A lot of people would,
you get a lot of finger pointing.

00:02:50.460 --> 00:02:53.450
Well,
now we have a tool that will exactly

00:02:53.450 --> 00:02:57.800
measure and precisely identify
where the performance is going.

00:02:58.410 --> 00:03:00.000
So what does it do?

00:03:00.120 --> 00:03:07.020
Profiler will show your usage
of the OpenGL engine library.

00:03:07.080 --> 00:03:09.170
Collect a lot of data
and a lot of statistics.

00:03:09.280 --> 00:03:13.720
You can also control your application
kind of like a debugger level.

00:03:14.480 --> 00:03:21.110
And we'll also show the graphic state
that your application has in it.

00:03:24.020 --> 00:03:26.480
And we'll get into what all
that really means in the demos.

00:03:26.530 --> 00:03:28.430
Okay, now here's how Profiler works.

00:03:28.480 --> 00:03:30.780
Now I've got to refer
to my cheat sheet here,

00:03:30.790 --> 00:03:34.600
because my memory is like a sieve,
and besides, this makes it look like

00:03:34.620 --> 00:03:37.720
I prepared beforehand.

00:03:37.820 --> 00:03:41.850
Profiler is a runtime system.

00:03:41.860 --> 00:03:50.160
What happens is it gets in between
your app and the OpenGL engine.

00:03:50.160 --> 00:03:53.630
You don't have to
recompile your application,

00:03:53.630 --> 00:03:57.740
run it in a special mode,
or anything like that.

00:03:57.740 --> 00:04:00.170
Profiler really does work
like a debugger in that sense,

00:04:00.170 --> 00:04:05.020
in that you can just run your app
under the Profiler environment.

00:04:05.470 --> 00:04:11.190
And now how it does it is
that Profiler gets into the

00:04:11.190 --> 00:04:16.300
OpenGL library at the library level
and wraps all those functions.

00:04:16.300 --> 00:04:18.530
So imagine like in the old
days you just have jump tables,

00:04:18.580 --> 00:04:20.300
dynamically loaded libraries.

00:04:20.300 --> 00:04:26.540
Get in there and masquerade each
one of those function calls to go

00:04:26.540 --> 00:04:30.300
into Profiler and then from there
into the engine or to the CGL shim.

00:04:30.300 --> 00:04:37.180
And it does wrap both CGL,
which is our OS dependent layer

00:04:37.180 --> 00:04:40.300
of OpenGL and also OpenGL.

00:04:40.440 --> 00:04:42.390
And there's a quick note
under the X window system.

00:04:42.390 --> 00:04:49.290
If you're using that platform,
you actually end up profiling the server,

00:04:49.340 --> 00:04:52.530
not your client app.

00:04:52.830 --> 00:04:58.520
Because it's a runtime system like this,
it means that you can launch an

00:04:58.520 --> 00:05:03.100
app under Profiler and then using
GDB or another favorite debugger,

00:05:03.100 --> 00:05:06.010
you can attach to that same app.

00:05:06.110 --> 00:05:13.220
So you can have a full debugger at the
same time that you're running Profiler.

00:05:13.300 --> 00:05:16.350
There's some little tricks in how
to keep it synchronized there and

00:05:16.390 --> 00:05:19.740
you'd have to experiment with that.

00:05:19.850 --> 00:05:21.910
That's an exercise to the reader.

00:05:24.400 --> 00:05:26.290
Okay, here's a screenshot.

00:05:26.410 --> 00:05:31.270
This is all new for Tiger, Profiler 3.0.

00:05:31.430 --> 00:05:36.080
First thing we did was take
the two-panel approach,

00:05:36.140 --> 00:05:40.120
startup approach that we used to have,
and compress it into one panel.

00:05:40.300 --> 00:05:45.520
So now there's no start and then
start and then really start.

00:05:45.800 --> 00:05:48.920
This is, you select your app at the top.

00:05:48.920 --> 00:05:51.200
Now let me get these fancy builds.

00:05:51.340 --> 00:05:52.100
There we go.

00:05:52.100 --> 00:05:56.170
You, first of all,
set up the app that you want to

00:05:56.820 --> 00:05:59.340
profile in this top table here.

00:05:59.550 --> 00:06:03.940
If you click "Attach," that table's
automatically populated with all the

00:06:04.070 --> 00:06:10.560
running applications on your system.

00:06:11.780 --> 00:06:18.240
You can, in the new 3.0 profiler,
set environment variables.

00:06:18.240 --> 00:06:21.380
This window, by the way, is open large.

00:06:21.380 --> 00:06:23.660
This doesn't default to this size.

00:06:23.960 --> 00:06:27.590
Normally, this part of it is hidden
when you run profiler.

00:06:27.700 --> 00:06:30.700
You can set a custom pixel format,
which I'll talk about more later.

00:06:30.700 --> 00:06:34.660
You can emulate sort of graphics drivers.

00:06:34.700 --> 00:06:36.700
Again, I'll talk about that
in more detail later.

00:06:36.950 --> 00:06:41.700
New for Tiger,
you can set environment variables.

00:06:41.700 --> 00:06:45.700
Like you can if you're
launching from a shell in Unix,

00:06:45.700 --> 00:06:49.700
you can set environment variables
that you then get inside your app.

00:06:49.700 --> 00:06:51.700
Now you can do it right from profiler.

00:06:51.700 --> 00:06:55.300
I do this all the time to
tell my target app to launch

00:06:55.300 --> 00:06:59.080
different dynamic libraries,
like debug versions of a framework,

00:06:59.110 --> 00:06:59.700
for example.

00:06:59.700 --> 00:07:03.090
You can do that through
environment variables.

00:07:04.470 --> 00:07:10.740
Okay, and the third part of
this panel is down here.

00:07:10.740 --> 00:07:15.000
The most important part, really,
of this panel is the frame rate.

00:07:15.050 --> 00:07:20.600
Now, this is an out-of-the-gate
estimation of your app's performance.

00:07:20.670 --> 00:07:24.880
It's not a real precise, nailed-down,
"This is what my performance

00:07:24.880 --> 00:07:28.000
really is," but this is going
to give you a general idea.

00:07:28.060 --> 00:07:31.270
Oh yeah,
I'm getting about 200 frames per second,

00:07:31.460 --> 00:07:33.600
and I'm expecting 500.

00:07:33.600 --> 00:07:37.350
Okay, so that's what that gives you.

00:07:38.050 --> 00:07:43.130
Now, let me get into some of
the things that we collect.

00:07:43.280 --> 00:07:49.580
This is the data that Profiler
gathers out of your app.

00:07:51.570 --> 00:07:57.770
It takes the amount of time that
you actually spend in OpenGL Engine.

00:07:58.070 --> 00:08:01.780
So when you make a call,
we start a timer, go into the engine,

00:08:01.830 --> 00:08:05.000
come out of the engine, stop the timer,
add all those up.

00:08:05.000 --> 00:08:11.690
So this is a pretty precise measurement
of your actual usage of the engine.

00:08:12.420 --> 00:08:17.820
"Per call." Now these
are cumulative values,

00:08:17.820 --> 00:08:20.570
and they are also,
but they are per context or global.

00:08:20.610 --> 00:08:23.970
So you can see globally if you have a
lot of threads and a lot of context,

00:08:23.970 --> 00:08:27.830
you can see globally how much
time you're spending in functions,

00:08:27.830 --> 00:08:30.340
or you can look at it
per context as well.

00:08:31.200 --> 00:08:35.150
Now, one of the really important numbers
on this panel here is the estimated

00:08:35.150 --> 00:08:37.600
percent time spent in OpenGL Engine.

00:08:37.620 --> 00:08:39.600
And here we're spending
about a quarter of the time.

00:08:39.740 --> 00:08:43.600
If the app is 100%, we're spending
about a quarter of the time

00:08:43.600 --> 00:08:47.600
actually in GL-- in other words,
on the GPU.

00:08:47.910 --> 00:08:51.510
Now, what this number is
going to tell you is--

00:08:51.880 --> 00:08:56.410
"Profiler, the tool you want to keep
using to measure performance,

00:08:56.440 --> 00:09:01.050
or do you want to move on to something
like Shark and the Chud tools in order to

00:09:01.420 --> 00:09:04.620
work on your performance on the CPU side?

00:09:04.680 --> 00:09:08.800
And we'll go into more detail later
about how to balance those two off.

00:09:08.800 --> 00:09:11.260
Okay, with that,
I'm going to turn it over to Chris,

00:09:11.330 --> 00:09:15.750
who's going to show us a demo." "Okay,
so we're on computer number three.

00:09:15.900 --> 00:09:17.160
Okay, that's good.

00:09:17.400 --> 00:09:20.300
So here's the new Profiler window,
and as we see,

00:09:20.300 --> 00:09:23.740
it's actually a little bit smaller
than what we saw in Dave's screenshot.

00:09:23.740 --> 00:09:25.800
This is how it starts up by default.

00:09:25.800 --> 00:09:31.200
So we've constructed an application that
shows some of the common pitfalls that

00:09:31.200 --> 00:09:36.240
we see with a lot of the applications
today that use OpenGL on Mac OS X.

00:09:36.280 --> 00:09:42.350
And so this application, we call it,
what did we call it?

00:09:43.010 --> 00:09:44.000
Trytip Bandit.

00:09:44.000 --> 00:09:44.930
Trytip Bandit.

00:09:45.010 --> 00:09:47.640
That is its name.

00:09:47.640 --> 00:09:51.380
We wrote that it will use
this in OpenGL Profiler,

00:09:51.380 --> 00:09:53.590
use these tools and
improve its performance.

00:09:53.780 --> 00:09:57.170
So one of the first things that
you generally want to do is you

00:09:57.170 --> 00:10:01.510
want to figure out what percentage
of the time your application

00:10:01.510 --> 00:10:06.400
is spending in OpenGL and what
it's doing with that time.

00:10:06.400 --> 00:10:10.630
So we've got the applications
right here ready to launch.

00:10:10.630 --> 00:10:14.990
And so launch that.

00:10:20.690 --> 00:10:22.090
So we've got it showing up here.

00:10:22.220 --> 00:10:26.300
It's just running as it would normally
if I were to start it from the finder.

00:10:26.390 --> 00:10:30.500
And one thing you may notice is we
already have the frame rate is already

00:10:30.500 --> 00:10:36.190
showing in the bottom of the profiler
panel because it's non-invasively able

00:10:36.310 --> 00:10:40.660
to capture the calls of OpenGL and
it's displaying this information.

00:10:40.770 --> 00:10:44.720
So we're saying we're getting around
33 frames per second right now.

00:10:44.880 --> 00:10:48.380
So let's go and find out where
that time is going to make

00:10:48.380 --> 00:10:50.700
that 33 frames per second.

00:10:50.860 --> 00:10:55.090
So I'm going to check the statistics,
collect statistics right here.

00:10:55.900 --> 00:12:21.100
[Transcript missing]

00:12:21.470 --> 00:12:25.790
So what I'm going to do is I'm
going to disable that function.

00:12:25.890 --> 00:12:28.180
So let's go--

00:12:29.700 --> 00:12:32.420
So I'm going to open up
the breakpoints window.

00:12:32.420 --> 00:12:36.400
And this window gives a list
of all the functions of OpenGL.

00:12:36.400 --> 00:12:38.360
And you can control them
through different ways.

00:12:38.530 --> 00:12:41.970
We're going to show you how-- if
you don't understand all of it yet,

00:12:41.970 --> 00:12:42.590
don't worry.

00:12:42.740 --> 00:12:50.020
We're going to go over how
to use this window in depth a

00:12:50.020 --> 00:12:51.290
little bit further later on.

00:12:51.290 --> 00:12:51.290
So I'm going to look for glFinish.

00:12:52.940 --> 00:12:55.340
We see the command here.

00:12:55.380 --> 00:12:58.580
And I can simply-- we
see this column execute,

00:12:58.620 --> 00:13:01.220
and I'm going to simply
turn off that column.

00:13:01.250 --> 00:13:06.580
And we see already in our
statistics that it's turned red,

00:13:06.650 --> 00:13:09.930
which means that we're no
longer calling that function.

00:13:10.020 --> 00:13:15.830
So I'm going to clear this, recheck,
and we can confirm that glFinish

00:13:15.830 --> 00:13:18.850
is no longer in the statistics.

00:13:18.890 --> 00:13:22.010
So we're already--

00:13:22.330 --> 00:13:27.860
It's about 5% faster from what I've
measured just by taking out the function.

00:13:27.860 --> 00:13:29.800
It allows you to do this all on the fly.

00:13:30.080 --> 00:13:34.160
So, let's see.

00:13:34.600 --> 00:13:36.380
So with that, back to you, Dave.

00:13:36.440 --> 00:13:37.880
Thanks, Chris.

00:13:37.960 --> 00:13:45.680
OK, I want to mention here that Chris and
I work about 200 miles apart or so.

00:13:45.750 --> 00:13:49.530
And I have never seen
this demo until now.

00:13:49.600 --> 00:13:50.960
And it was awesome.

00:13:51.060 --> 00:13:52.660
So thanks.

00:13:52.670 --> 00:13:54.780
It was awesome.

00:13:58.350 --> 00:14:01.190
Okay,
let's go on to another section of usage

00:14:01.190 --> 00:14:05.200
data that we harvest with Profiler.

00:14:05.380 --> 00:14:07.200
This is a call trace.

00:14:07.200 --> 00:14:14.200
In the last demo, you saw that we capture
every function and time it.

00:14:14.200 --> 00:14:19.620
And in this usage data capture,
we grab every function as

00:14:19.620 --> 00:14:22.090
you call it and store it.

00:14:22.090 --> 00:14:25.110
So you've got a whole trace
of all the GL function calls

00:14:25.210 --> 00:14:27.200
you make as you make them.

00:14:27.430 --> 00:14:32.080
And you can see here that the
output is kind of C-style.

00:14:32.190 --> 00:14:35.200
You couldn't actually just take,
grab this and compile it and get errors.

00:14:35.200 --> 00:14:41.200
But it does print out the
symbolic names of the parameters.

00:14:41.210 --> 00:14:43.050
So that makes it a little easier to read.

00:14:43.200 --> 00:14:46.200
And I want to point out a
couple new features for Tiger.

00:14:46.200 --> 00:14:50.200
One is that you can apply
a filter to this trace.

00:14:50.200 --> 00:14:55.400
A couple of you guys,
developers out there, had this excellent,

00:14:55.400 --> 00:14:59.790
excellent idea of taking this text
and running it through various

00:14:59.790 --> 00:15:03.200
Python and Perl scripts to come
up with statistical analysis.

00:15:03.200 --> 00:15:05.200
And that was built right in.

00:15:05.200 --> 00:15:09.260
So you just say,
"Enable filter." You pick the filter

00:15:09.590 --> 00:15:12.200
and it'll push it right through
there and show you your output.

00:15:12.200 --> 00:15:17.580
The other thing that we have
on here that's new for Tiger is

00:15:17.580 --> 00:15:21.200
timing information per function.

00:15:21.200 --> 00:15:26.220
So before you saw in the statistics
window that the timing information is

00:15:26.220 --> 00:15:29.200
cumulative for all the function calls.

00:15:29.200 --> 00:15:33.900
So when it read GL vertex 3F,
for example,

00:15:33.900 --> 00:15:41.150
that timing information is the sum
of all your GL vertex 3F calls.

00:15:41.300 --> 00:15:43.740
In this case,
you get the time for just the

00:15:43.740 --> 00:15:46.050
individual one that's on this list.

00:15:46.200 --> 00:15:50.200
Now what that's really useful
for is finding hotspots.

00:15:50.200 --> 00:15:56.200
Because you might have instances,
for example, of CGL flush drawable.

00:15:56.200 --> 00:15:58.200
I'm just pulling this out of the air.

00:15:58.200 --> 00:16:02.290
That might take a short amount
of time and one or two that

00:16:02.290 --> 00:16:06.200
are super long because of state
changes and things like that.

00:16:06.410 --> 00:16:10.200
Well, on the stats window,
it's going to show up

00:16:10.200 --> 00:16:10.200
as taking a long time.

00:16:10.200 --> 00:16:13.200
Cumulatively.

00:16:13.200 --> 00:16:15.200
But what you really want to do
is narrow down those one or two

00:16:15.200 --> 00:16:19.200
that are really soaking up all the
time and figure out why that is.

00:16:19.200 --> 00:16:23.730
Well, this timing information that
is coming in Tiger will enable

00:16:23.730 --> 00:16:25.100
you to find those really fast.

00:16:25.200 --> 00:16:31.010
Plus, attached to each one of these lines
will be a reveal for a full backtrace.

00:16:31.200 --> 00:16:36.430
So you can click on the function
and find out where in your code

00:16:36.430 --> 00:16:39.200
that specific call was made.

00:16:39.280 --> 00:16:41.910
narrow it down.

00:16:42.510 --> 00:16:46.190
And again,
this is all per context or global.

00:16:46.420 --> 00:16:50.400
So if you have a bunch of contexts,
you can narrow it down to looking at

00:16:50.760 --> 00:16:53.270
function calls just in one context.

00:16:56.460 --> 00:16:59.840
Okay, and I think with that we're going
to turn it back over to Chris.

00:16:59.950 --> 00:17:02.470
So back to computer three?

00:17:02.600 --> 00:17:03.900
Thanks.

00:17:04.080 --> 00:17:08.190
So I've got here,
I have a second application here which

00:17:08.280 --> 00:17:14.350
I've already taken the finish out of
and I'm going to demonstrate how to

00:17:14.360 --> 00:17:20.200
more effectively pass down vertices
through your application to OpenGL.

00:17:20.220 --> 00:17:23.270
So let's launch this
application up again.

00:17:25.880 --> 00:17:30.800
And so, as Dave was showing,
OpenGL Profiler allows you

00:17:30.800 --> 00:17:35.800
to get the trace of all the
OpenGL functions that are being called.

00:17:35.850 --> 00:17:37.510
And I'm going to go ahead and do that.

00:17:37.630 --> 00:17:41.630
So, let's click this button,
"Create Trace." And I'm going

00:17:41.630 --> 00:17:45.700
to stop that because otherwise
I might fill up hard drive.

00:17:46.000 --> 00:17:49.360
So, looking through this trace,
we see that there's a

00:17:49.430 --> 00:17:52.690
lot of vertex begin-end,
basically, calls.

00:17:52.710 --> 00:17:54.730
That type of call.

00:17:54.950 --> 00:17:58.900
So, GL begin, GL vertex, GL vertex,
GL vertex, GL end.

00:17:58.930 --> 00:18:06.900
And this is actually, for static data,
this is a, actually, it's more,

00:18:06.900 --> 00:18:09.900
it would be more efficient to use
display lists for this particular case.

00:18:10.120 --> 00:18:13.600
For instance,
the land here is all static,

00:18:13.600 --> 00:18:17.850
yet I'm passing it down
through immediate mode.

00:18:17.930 --> 00:18:21.500
And so,
what I'm going to change about it is

00:18:21.800 --> 00:18:26.900
you can either add vertex array range,
vertex buffer object, display lists.

00:18:26.900 --> 00:18:30.890
All of these allow you
to effectively pick,

00:18:30.920 --> 00:18:34.620
you can pick the type that you feel
is most appropriate for the type of

00:18:34.620 --> 00:18:35.900
data that you're trying to draw with.

00:18:35.900 --> 00:18:39.900
And use that to more efficiently
take advantage of the video.

00:18:39.900 --> 00:18:43.890
More efficiently take advantage
of the bandwidth of the system.

00:18:43.900 --> 00:18:49.720
So, one thing to note is when
you do have all these calls,

00:18:50.030 --> 00:18:54.900
like, immediate mode requires a lot of
calls with all the begin-ends.

00:18:54.900 --> 00:18:58.020
Versus if you were to
say use a display list,

00:18:58.020 --> 00:19:00.850
which is a single call, GL call list.

00:19:00.900 --> 00:19:06.530
So, again, also as John Stauffer went
over in his talk earlier today

00:19:06.530 --> 00:19:08.900
on optimization in general.

00:19:08.900 --> 00:19:09.900
And so, that's a little bit of
a different approach.

00:19:09.900 --> 00:19:14.130
But, in the case of a display list,
you can use CGL macros to,

00:19:14.240 --> 00:19:18.820
in order to cut down on the
overhead that each function call,

00:19:18.910 --> 00:19:23.900
basically the overhead of
making the function call itself.

00:19:23.980 --> 00:19:27.900
So, in the case where,
in this particular application,

00:19:28.010 --> 00:19:32.900
simply switching to CGL macros
will definitely get us a gain,

00:19:32.900 --> 00:19:34.470
a good gain.

00:19:34.900 --> 00:19:38.740
But, I've already written this
to use display lists.

00:19:38.900 --> 00:19:43.730
And, well, first let's check out
the statistics again.

00:19:43.900 --> 00:19:51.890
And we can see, sorting by the GL time,
that we've got vertex 3f, tech cord 2f,

00:19:51.890 --> 00:19:54.840
vertex 3d, color 4f, begin-end.

00:19:54.900 --> 00:19:57.900
All these calls are immediate calls.

00:19:57.900 --> 00:20:00.930
And so, let's launch, well.

00:20:01.980 --> 00:20:05.240
And so we get about 35 frames per second.

00:20:05.350 --> 00:20:08.780
So I'm going to stop this application.

00:20:08.820 --> 00:20:12.520
Start up one using display
lists vertex array range.

00:20:14.990 --> 00:20:19.520
And that alone, we're already up to 160,
170 frames per second.

00:20:19.660 --> 00:20:21.020
165.

00:20:21.110 --> 00:20:26.520
Simply by passing the data using
display list vertex array range.

00:20:26.610 --> 00:20:29.230
Let's go back to statistics.

00:20:29.530 --> 00:20:34.890
And now we see that we're
actually... So most of our time

00:20:34.890 --> 00:20:38.090
is being spent in GL Call List,
and then the rest of the time,

00:20:38.100 --> 00:20:41.200
most of the rest of the time is
being spent in CGL Flush Drawable,

00:20:41.200 --> 00:20:43.890
which basically means it's
waiting for the video card to

00:20:43.890 --> 00:20:45.110
stick more data back on it.

00:20:45.220 --> 00:20:49.800
So we've pretty effectively used
OpenGL on the CPU side right now.

00:20:49.920 --> 00:20:53.160
So back to you.

00:20:53.290 --> 00:20:55.310
All right, thanks, Chris.

00:20:58.260 --> 00:21:03.920
All right, let's move on to application
control and some of these features

00:21:03.920 --> 00:21:06.540
that are in Profiler for this.

00:21:06.610 --> 00:21:12.540
One of the ways you can control your
app is by setting a custom pixel format.

00:21:12.770 --> 00:21:16.500
And what we do here is--.

00:21:16.770 --> 00:21:20.810
"How to inject a different
pixel format than what you asked

00:21:20.810 --> 00:21:24.830
for in your code." So again,
this is without recompiling

00:21:25.210 --> 00:21:28.100
your application or
changing any code like that.

00:21:28.100 --> 00:21:35.570
We can do things, for example,
change the depth buffer size.

00:21:35.970 --> 00:21:39.440
So you want to see if your
app will run with a 16-bit

00:21:39.500 --> 00:21:41.740
Z-buffer instead of a 32-bit.

00:21:41.740 --> 00:21:46.800
You can do that through Profiler
without having to rerun your app.

00:21:46.800 --> 00:21:48.300
Or recompile your app, I mean.

00:21:48.300 --> 00:21:50.130
You have to rerun it.

00:21:50.860 --> 00:21:56.300
The other thing you can do is
what we call driver emulation.

00:21:56.300 --> 00:22:01.750
We don't actually fully emulate the
graphics drivers because we can't.

00:22:01.750 --> 00:22:07.350
It's hardware, there's all kinds of
stuff involved in there.

00:22:07.540 --> 00:22:14.650
But what we can do in Profiler as a
runtime system is get in the way of

00:22:14.650 --> 00:22:19.400
the GL get calls and make it seem
like you're running on another card.

00:22:19.480 --> 00:22:22.010
So this is useful if you
want to make sure your app is

00:22:22.010 --> 00:22:23.770
following correct code paths.

00:22:23.890 --> 00:22:26.030
For example,
you've got different code paths

00:22:26.360 --> 00:22:29.840
depending on the return from
a GL get string because you're

00:22:29.840 --> 00:22:33.180
looking at different card features.

00:22:33.220 --> 00:22:36.580
And you're going to enable or
disable certain functions in menus.

00:22:36.580 --> 00:22:39.440
I see this in games all the time.

00:22:39.450 --> 00:22:45.580
You're going to change a menu that
allows you to turn on certain features.

00:22:45.800 --> 00:22:51.940
and David DeRose, the team of developers,
are here to discuss

00:22:51.940 --> 00:22:54.780
the OpenGL application.

00:22:54.900 --> 00:23:05.600
[Transcript missing]

00:23:05.770 --> 00:23:10.850
"Your app thinks it's something else,
an NVIDIA card, and really it's an ATI.

00:23:10.920 --> 00:23:16.400
So you use it with care,
but it does have use.

00:23:16.450 --> 00:23:19.700
Now another way we can
control the application

00:23:19.700 --> 00:23:24.340
Chris already showed in his demo,
GL Finish, is that you can enable

00:23:24.340 --> 00:23:26.500
and disable GL calls.

00:23:26.580 --> 00:23:31.120
So you want to see what your app looks
like without ever calling GL Finish,

00:23:31.120 --> 00:23:32.380
just turn it off.

00:23:32.630 --> 00:23:35.620
And you saw that the app
not only looked the same,

00:23:35.620 --> 00:23:38.890
but ran way faster.

00:23:39.730 --> 00:23:42.010
We can do that.

00:23:42.080 --> 00:23:46.200
You can also attach
scripts at breakpoints.

00:23:46.230 --> 00:23:48.700
Now,
what that means is you can write little

00:23:48.730 --> 00:23:55.540
pieces of GL code and Profiler will take
and inject those into your application

00:23:55.540 --> 00:23:56.940
at breakpoints while you run it.

00:23:56.940 --> 00:24:00.940
And then we're going to see
an example of that later on.

00:24:02.980 --> 00:24:08.970
Okay, this is the breakpoint window,
and Chris showed this earlier.

00:24:09.420 --> 00:24:12.380
These, like a debugger,
you can set breakpoints.

00:24:12.380 --> 00:24:14.240
But unlike a debugger,
you can only set them

00:24:14.240 --> 00:24:17.460
on certain functions,
which is all the GL calls.

00:24:17.630 --> 00:24:20.130
So this is not a general
debugger feature.

00:24:20.290 --> 00:24:24.080
This is just a way to stop
your app on certain GL calls.

00:24:24.150 --> 00:24:29.050
and the interesting thing
is that you can stop it just

00:24:29.110 --> 00:24:33.700
before it goes into the engine,
or you can stop it right after

00:24:33.700 --> 00:24:35.120
it comes back from the engine.

00:24:35.170 --> 00:24:41.120
Why this is useful is because
along with a backtrace,

00:24:41.100 --> 00:24:57.300
[Transcript missing]

00:24:57.810 --> 00:25:01.860
And again,
this handles the multiple context case.

00:25:01.920 --> 00:25:04.490
Now, what we do here, though, is,
you know, like a debugger,

00:25:04.600 --> 00:25:09.300
if you have a bunch of threads
running and you put a breakpoint on,

00:25:09.370 --> 00:25:12.870
you know, function foo,
then it's going to stop in every thread.

00:25:12.880 --> 00:25:14.300
Well, it's the same here.

00:25:14.340 --> 00:25:19.410
If you put a breakpoint on GL flush,
then it's going to stop at every

00:25:19.410 --> 00:25:22.780
context and every thread that calls it.

00:25:24.680 --> 00:25:27.810
Okay, and with that,
I'm going to go back to

00:25:27.810 --> 00:25:30.420
Chris for catching OpenGL errors.

00:25:31.300 --> 00:25:36.900
So, GL Profiler is good for breakpoints,
and one of those types of

00:25:36.900 --> 00:25:41.940
breakpoints that you can set is
a breakpoint on any GL error.

00:25:42.200 --> 00:25:47.100
So, what I'm going to do is run my
application this time with a breakpoint

00:25:47.100 --> 00:25:49.200
set any time that GL error might occur.

00:25:49.200 --> 00:25:52.540
So, I'm going to go up and
go back to the views,

00:25:52.540 --> 00:25:55.580
set the breakpoints,
and we can see here we've

00:25:55.580 --> 00:25:59.040
got a list of different types
of errors we can break on.

00:25:59.200 --> 00:26:03.200
I'm going to break on error,
which refers to the normal GL error,

00:26:03.320 --> 00:26:09.400
and let's start this program up.

00:26:11.920 --> 00:26:14.400
So already, it's caught a geo error.

00:26:14.460 --> 00:26:18.500
And it says that I'm calling geo
blend with geo blend equation,

00:26:18.550 --> 00:26:22.200
when in fact,
blend equation is not something that's

00:26:22.260 --> 00:26:23.750
supposed to be enabled and disabled.

00:26:23.870 --> 00:26:28.740
Geo blend is more common-- is
actually what's supposed to be there.

00:26:28.860 --> 00:26:31.280
So we get the error, geo invalid enum.

00:26:31.420 --> 00:26:38.990
And we also see-- we can see the
backtrace and the actual line of code.

00:26:40.610 --> 00:26:43.710
Somewhere here.

00:26:43.710 --> 00:26:47.360
You can see the line of code
where this error is occurring.

00:26:47.770 --> 00:26:52.400
And so using this, I was able to quickly
realize where this was,

00:26:52.630 --> 00:26:58.900
fix it, correct it to GL Blend instead
of GL Blend equation.

00:27:00.560 --> 00:27:03.400
And I'll show you the result.

00:27:03.500 --> 00:27:06.220
We got one taker.

00:27:07.150 --> 00:27:09.000
Let's see.

00:27:09.100 --> 00:27:13.270
So the blending, that's actually,
if you notice the function backtrace,

00:27:13.380 --> 00:27:15.400
that was in drawSky.

00:27:15.430 --> 00:27:18.000
And so I had blending basically
was not enabled for that.

00:27:18.050 --> 00:27:20.760
So let's start up the
version without errors.

00:27:20.760 --> 00:27:22.630
I'll set that breakpoint again.

00:27:22.710 --> 00:27:24.020
Let's see.

00:27:24.690 --> 00:27:27.320
Break on error.

00:27:27.530 --> 00:27:29.140
Start it up.

00:27:31.450 --> 00:27:34.460
And as we can see,
it's not breaking on any errors,

00:27:34.470 --> 00:27:40.290
and now we've got the
clouds blending pretty well.

00:27:41.440 --> 00:27:43.970
Let's go back to you, Dave,
and you can explain some of the other

00:27:44.170 --> 00:27:46.000
types of errors that you can break on.

00:27:46.200 --> 00:27:47.990
Thanks, Chris.

00:27:50.930 --> 00:27:55.640
Okay, we saw breaking OpenGL errors.

00:27:55.720 --> 00:27:58.020
Very useful.

00:27:58.020 --> 00:28:04.240
Another way that you can trap these
errors in your app is on thread conflict.

00:28:04.240 --> 00:28:07.440
John talked earlier
about multiple contexts,

00:28:07.440 --> 00:28:15.950
multiple threads, and what's legal and
what's okay and what's not.

00:28:15.950 --> 00:28:15.950
Well,

00:28:16.780 --> 00:28:23.120
You can have more than one thread
talking to one single GL context,

00:28:23.170 --> 00:28:28.490
but it's up to you to make sure that
the thread is locking correctly and

00:28:28.490 --> 00:28:35.640
not in the context--not more than one
thread in the context at the same time.

00:28:36.070 --> 00:28:40.690
If you end up with more than one
thread talking to the same context,

00:28:40.690 --> 00:28:44.820
you can get all kinds of funky
data corruption problems and bad

00:28:44.820 --> 00:28:48.490
things can happen to your computer.

00:28:48.660 --> 00:28:52.530
So you don't want that.

00:28:52.530 --> 00:28:52.530
Well,

00:28:53.160 --> 00:28:56.760
Profiler,
what really is happening here in this

00:28:56.760 --> 00:29:02.300
thread conflict is that you are supposed
to have the mutex locks on the threads

00:29:02.300 --> 00:29:05.380
if you're going to talk to one context.

00:29:06.100 --> 00:29:12.200
Profiler has this mode where it applies
the locks that you're supposed to have.

00:29:12.400 --> 00:29:17.480
So if you get into the case where
threads are going to conflict,

00:29:17.530 --> 00:29:20.440
it'll trip over one of those
locks and stop and say,

00:29:20.440 --> 00:29:23.620
"Hey, you know, there's an error here."

00:29:23.900 --> 00:29:27.640
Then you can go back into your app,
again by using the back trace.

00:29:27.760 --> 00:29:30.580
And you can apply the
locks and clean it up.

00:29:31.580 --> 00:29:35.320
Personally, I recommend that you have
one context per thread,

00:29:35.320 --> 00:29:37.380
but that's just my personal opinion.

00:29:37.380 --> 00:29:40.760
Do what you want.

00:29:40.980 --> 00:29:45.920
Now, this threading collision stuff is
only detected in the OpenGL APIs.

00:29:45.990 --> 00:29:48.620
We don't detect it in the CGL layer.

00:29:48.700 --> 00:29:50.370
So you're on your own there.

00:29:52.220 --> 00:30:01.180
Another way we can detect errors is the
panel up there is a break on var error.

00:30:01.360 --> 00:30:07.060
It stops on vertex array range
and vertex array object errors.

00:30:07.070 --> 00:30:16.720
Essentially, these four points, in sum,
say, any time an index that you're using

00:30:16.720 --> 00:30:22.080
to draw with veers outside of an
array range that you've specified,

00:30:22.100 --> 00:30:27.000
or if you're going to hand in a pointer
that is outside of one of those ranges

00:30:27.000 --> 00:30:32.040
that you haven't properly set up,
then we'll stop and we'll break.

00:30:32.060 --> 00:30:35.380
And again, show you the back trace,
the full GL state,

00:30:35.380 --> 00:30:37.250
everything you need to see.

00:30:37.720 --> 00:30:41.720
And we validate your vertex
array range on any of these

00:30:41.800 --> 00:30:44.760
functions that you see up there.

00:30:50.660 --> 00:30:56.600
Okay, we talked about the full
snapshot of OpenGL state.

00:30:56.660 --> 00:30:58.670
It is a full snapshot.

00:30:58.700 --> 00:31:03.090
So every GL get call that you
can make is done right here.

00:31:03.090 --> 00:31:07.160
And we put it in this list,
this reveal list.

00:31:07.160 --> 00:31:12.350
Now what happens is that
the state is gathered,

00:31:12.500 --> 00:31:17.600
it's harvested every time
you stop at a breakpoint.

00:31:17.730 --> 00:31:21.100
And the changes in the
state are shown in red,

00:31:21.190 --> 00:31:24.400
and the changes being
since the last breakpoint.

00:31:24.620 --> 00:31:27.110
And to show that,
what I did here in this screenshot

00:31:27.750 --> 00:31:32.700
is I've got a stop on glEnable
before it goes into the engine,

00:31:32.900 --> 00:31:35.700
and then another stop
as soon as it comes out.

00:31:35.820 --> 00:31:39.100
So what I would expect
is that it's glEnable,

00:31:39.100 --> 00:31:42.340
so I would expect the
state to be turned on,

00:31:42.380 --> 00:31:44.200
right, that I'm changing.

00:31:44.340 --> 00:31:46.580
And that's in fact what happens.

00:31:46.680 --> 00:31:50.890
You can see down here at the bottom
it says it broke after glEnable.

00:31:51.270 --> 00:31:52.870
In other words,
it's gone into the engine,

00:31:52.870 --> 00:31:54.700
it's come back out,
and it's stopped again.

00:31:54.800 --> 00:32:00.410
And then you can see there that
the call face is now enabled.

00:32:00.740 --> 00:32:07.580
So this is really useful for
detecting errors where you think you

00:32:07.580 --> 00:32:11.700
have states set up that may not be,
or a state that's set

00:32:11.700 --> 00:32:13.420
with incorrect values.

00:32:13.420 --> 00:32:15.170
You can watch the change.

00:32:15.170 --> 00:32:18.960
We've got another take for that.

00:32:18.960 --> 00:32:18.960
Awesome.

00:32:21.210 --> 00:32:26.300
Okay, just another quick,
couple quick points on this window.

00:32:26.300 --> 00:32:29.380
There's,
under that Actions pull-down there,

00:32:29.380 --> 00:32:35.100
these are just shortcut menu
options to stop everywhere before,

00:32:35.100 --> 00:32:38.830
stop everywhere after, stop nowhere,
you know, it turns on all those buttons

00:32:38.830 --> 00:32:40.220
or turns them all off.

00:32:40.340 --> 00:32:45.190
You can also execute no GL functions.

00:32:45.190 --> 00:32:48.900
So if you want to see,
and we've had examples

00:32:48.900 --> 00:32:51.260
of this in the lab,
where people, you know,

00:32:51.490 --> 00:32:54.820
your graphic is slow and my
app runs slow because your

00:32:54.820 --> 00:32:57.040
graphic's just not up to par.

00:32:57.440 --> 00:33:00.640
Well, so we said, "Okay,
we'll take your app,

00:33:00.640 --> 00:33:05.890
we'll turn off all the graphics,
and notice it goes the same speed."

00:33:06.910 --> 00:33:10.160
Guess what?

00:33:10.320 --> 00:33:14.990
So you can run your app
open loop and decide,

00:33:14.990 --> 00:33:20.270
oh, well, maybe I better get Shark and
Chud tools out and make that

00:33:20.440 --> 00:33:24.160
go a little faster first before
I start blaming people randomly.

00:33:24.160 --> 00:33:29.390
Not that I've ever done that.

00:33:30.830 --> 00:33:33.300
And of course,
you can ignore all the breakpoints, too,

00:33:33.300 --> 00:33:40.100
if you just want to run your
app without stopping anywhere.

00:33:41.610 --> 00:33:44.490
Okay, now with that,
we'll turn it back over to

00:33:44.490 --> 00:33:47.500
Chris and we'll talk about
unnecessary state changes.

00:33:47.600 --> 00:33:51.200
So, already I talked about
the immediate mode.

00:33:51.200 --> 00:33:54.280
I talked about how making a
lot of calls actually will

00:33:54.420 --> 00:33:56.500
result in function overhead.

00:33:56.500 --> 00:34:00.470
And the same holds
true for setting state.

00:34:00.610 --> 00:34:05.510
Except there's also the fact that
setting state can also itself,

00:34:05.550 --> 00:34:08.500
the actual setting of the state,
can take up time.

00:34:08.630 --> 00:34:12.500
And even if the setting of the
state doesn't take up time,

00:34:12.500 --> 00:34:15.710
you may not know,
but some of the state changes will

00:34:15.710 --> 00:34:17.500
be deferred until your draw command.

00:34:17.500 --> 00:34:21.320
And that will cause your draw
commands to go a little bit slower.

00:34:21.500 --> 00:34:28.930
So, like in the statistics, for instance,
you'll see draw rays taking a longer

00:34:28.930 --> 00:34:33.500
time than usual because you've
accidentally turned something on

00:34:33.500 --> 00:34:35.500
or turned it on multiple times.

00:34:35.500 --> 00:34:38.480
Or just switch some sort of state.

00:34:38.560 --> 00:34:40.490
So, that's a state that you
didn't need to switch.

00:34:40.510 --> 00:34:46.300
So, one thing that developers should
try and do is they should try and

00:34:46.600 --> 00:34:49.500
avoid state changes when they can.

00:34:49.500 --> 00:34:54.500
But they should also keep in mind
that OpenGL does keep track of,

00:34:54.600 --> 00:34:57.410
as a state machine,
it is keeping track of what you're doing.

00:34:57.500 --> 00:35:01.500
And depending on the type of
state that you're setting,

00:35:01.500 --> 00:35:05.930
it may be more efficient for
you as a developer with the

00:35:05.930 --> 00:35:07.500
semantics of the application.

00:35:07.500 --> 00:35:09.500
So, that's a good thing.

00:35:09.500 --> 00:35:11.540
And then, of course,
you can also use the state

00:35:11.540 --> 00:35:14.490
change to decide whether or not
to do the state change yourself.

00:35:14.500 --> 00:35:16.150
So, I'm going to launch up.

00:35:17.700 --> 00:35:20.420
The application here.

00:35:20.420 --> 00:35:23.160
And I'm going to go look at statistics.

00:35:24.050 --> 00:35:28.960
And one thing I wanted to reiterate
that Dave said earlier was the

00:35:29.540 --> 00:35:35.440
estimated percent time in GL is
a really useful feature to look at.

00:35:35.810 --> 00:35:39.340
Like here we see the
applications taking 91% of the

00:35:39.340 --> 00:35:43.500
application is going to OpenGL.

00:35:43.630 --> 00:35:48.220
And sometimes,
so depending on your application,

00:35:48.420 --> 00:35:49.340
that percentage will be different.

00:35:49.340 --> 00:35:52.320
But for this particular application,
since I'm just pounding

00:35:52.320 --> 00:35:55.700
on the graphics hardware,
I'm not doing anything that has to,

00:35:55.800 --> 00:36:02.460
I'm not doing any CPU calculations such
as physics or anything similar to that.

00:36:02.550 --> 00:36:06.700
So because of that, I have a pretty high
percentage of time in OpenGL.

00:36:06.840 --> 00:36:09.740
Sometimes it's better to have a
higher percentage of OpenGL time

00:36:09.740 --> 00:36:14.540
because that means that you're giving
more data to OpenGL in general.

00:36:14.730 --> 00:36:17.940
So let's look at,
I wanted to look in particular

00:36:18.570 --> 00:36:21.110
at the number of function calls.

00:36:21.500 --> 00:36:24.540
With GL Enable and GL Disable.

00:36:24.580 --> 00:36:27.500
And if you look at the number
of calls between those two,

00:36:27.500 --> 00:36:30.310
you'll notice there's actually,
they're very different.

00:36:30.390 --> 00:36:37.390
So there's 190,000 disabled calls
while there's only 125 enabled calls.

00:36:37.710 --> 00:36:41.680
So obviously this is not necessary,
that means that there's some

00:36:41.680 --> 00:36:43.480
sort of imbalance there.

00:36:43.610 --> 00:36:48.400
And that's just one example of a
state change which is unnecessary.

00:36:48.600 --> 00:36:56.100
So by taking that state change out,
you don't just gain the time

00:36:56.500 --> 00:36:59.630
in the actual function itself,
like here, percent,

00:36:59.670 --> 00:37:04.640
so the average time here is very
small here for the enable and disable.

00:37:04.760 --> 00:37:08.490
However,
this time might be actually showing up

00:37:08.550 --> 00:37:15.410
in your other calls such as gl_begin and
other similar function drawing commands.

00:37:16.200 --> 00:37:18.750
So, back to you.

00:37:19.600 --> 00:37:25.760
There's a 9600,
ATR 9600 card on a dual two.

00:37:31.310 --> 00:37:36.440
Let's talk about some of the graphics
state that your application keeps.

00:37:36.890 --> 00:37:42.120
There's a differentiation
between state in OpenGL,

00:37:42.120 --> 00:37:45.500
which is a state machine,
and graphic state that

00:37:45.560 --> 00:37:47.340
your application owns.

00:37:47.340 --> 00:37:52.330
The difference being that your app
is going to own things like textures,

00:37:52.740 --> 00:37:58.140
vertex programs, and as this slide shows,
a depth buffer, back buffer,

00:37:58.290 --> 00:37:59.760
things like that.

00:37:59.760 --> 00:38:03.420
It's not strictly
speaking GL engine state.

00:38:03.420 --> 00:38:07.810
But because it's important,
especially when you're debugging

00:38:07.840 --> 00:38:11.910
and in performance analysis,
to know what's going on with that state,

00:38:12.030 --> 00:38:14.780
Profiler captures it all, too.

00:38:14.780 --> 00:38:18.200
So this view is the depth buffer.

00:38:18.440 --> 00:38:25.530
And what Profiler does
here is grab the Z-buffer,

00:38:25.580 --> 00:38:28.920
the depth buffer, and then grayscales it.

00:38:29.060 --> 00:38:38.660
Okay, so that on your gray scale here,
the black pixels are minimum z and

00:38:38.660 --> 00:38:41.350
the white pixels are maximum z.

00:38:42.940 --> 00:38:49.320
That slider at the top is
showing you your Z range.

00:38:50.080 --> 00:38:53.820
When you get the depth buffer up
and you click that magnifying glass,

00:38:53.820 --> 00:38:59.180
the profiler will automatically
analyze the image and say,

00:38:59.210 --> 00:39:03.320
"All right,
your minimum Z value in the depth

00:39:03.430 --> 00:39:12.780
buffer is such in this case 0.3 and 0.4,
and your maximum is 1." Now, in OpenGL,

00:39:12.780 --> 00:39:12.780
the default

00:39:13.010 --> 00:39:17.370
The first thing I want to say is
that the z values in the depth

00:39:17.370 --> 00:39:20.460
buffer are always between 0 and 1.

00:39:20.500 --> 00:39:24.770
There is a way to change that,
but generally speaking,

00:39:24.770 --> 00:39:30.940
the values of the floating point range
of z in the depth buffer is 0 to 1.

00:39:32.530 --> 00:39:38.770
The idea here is to show how
much Z precision you're using.

00:39:40.270 --> 00:39:42.630
So there's one of the
common problems we run into,

00:39:42.630 --> 00:39:46.790
which Chris is going to demo later on,
is something we call Z-fighting.

00:39:47.050 --> 00:39:49.260
That's our colloquial term for it.

00:39:49.300 --> 00:39:54.060
And how that manifests itself is you
get these little flashing polygons,

00:39:54.100 --> 00:39:59.940
because there's not enough Z precision
to tell which part is in front and

00:39:59.940 --> 00:40:02.780
which part is behind consistently.

00:40:02.830 --> 00:40:06.500
And so you don't have enough
precision in your depth buffer.

00:40:06.650 --> 00:40:08.890
The first step in how you can
see if you have enough precision

00:40:08.890 --> 00:40:12.120
or not is by using this view.

00:40:12.120 --> 00:40:15.600
And if that orange bar at
the top is really tiny,

00:40:15.660 --> 00:40:18.620
then you've got almost no z-precision.

00:40:18.620 --> 00:40:21.820
The wider that bar is,
the more z-precision you have.

00:40:21.820 --> 00:40:24.190
So that's what you're striving for.

00:40:24.610 --> 00:40:30.080
And the way that you affect z-precision
is by changing the near and far

00:40:30.380 --> 00:40:32.630
planes in your GL frustum call.

00:40:32.740 --> 00:40:35.380
You know, I want to,
this sometimes has been

00:40:35.380 --> 00:40:38.650
a point of confusion,
especially on the OpenGL list I've seen,

00:40:38.650 --> 00:40:44.530
where the values of z in the z-buffer,
the range of those values, I should say,

00:40:44.640 --> 00:40:46.890
is not affected by GL frustum.

00:40:46.900 --> 00:40:49.330
They always go from zero to one.

00:40:49.590 --> 00:40:52.720
What changes,
what GL frustum changes is how many

00:40:52.720 --> 00:40:56.930
of those bits you're going to use
for the zCompare and the zBuffer.

00:40:57.030 --> 00:40:58.440
Make sense?

00:40:58.510 --> 00:41:01.950
So in other words, you want to,
you don't want to have just the top two

00:41:02.030 --> 00:41:04.740
bits being used for all your zComparers.

00:41:04.740 --> 00:41:08.890
You want to try and get all 32 or
all 16 or whatever your depth is.

00:41:09.700 --> 00:41:13.550
and your near and far plane are
going to be the determining factors

00:41:13.910 --> 00:41:15.400
for how much precision you use.

00:41:15.400 --> 00:41:18.090
The actual values are always 0 to 1.

00:41:18.220 --> 00:41:20.470
The range is always 0 to 1.

00:41:24.510 --> 00:41:26.780
Okay,
then another kind of buffer you can look

00:41:26.780 --> 00:41:30.410
at with Profile is a stencil buffer.

00:41:31.120 --> 00:41:35.000
What Profiler does is
pseudo-color the stencil planes.

00:41:35.080 --> 00:41:39.830
The way you use a stencil buffer is
that you set individual bit planes.

00:41:40.010 --> 00:41:43.240
So, Profiler, you can pseudo-color those.

00:41:43.240 --> 00:41:45.800
On this example here,
we've got three bitplanes being

00:41:45.800 --> 00:41:47.040
used in the stencil buffer.

00:41:47.040 --> 00:41:50.050
And Profiler pseudo-colored
them with blue,

00:41:50.060 --> 00:41:51.300
green, and red.

00:41:51.340 --> 00:41:53.890
So,
you can see here there's an area of black

00:41:53.890 --> 00:41:56.380
where there's no stencil bit set at all.

00:41:56.380 --> 00:42:00.220
Then,
which planes have stencil bits set in

00:42:00.220 --> 00:42:02.860
the red and the green and the blue?

00:42:03.240 --> 00:42:06.560
And then where it's purple,
Profiler composites bitplanes together

00:42:06.570 --> 00:42:08.780
and comes up with another pseudo-color.

00:42:08.780 --> 00:42:12.300
So, the purple areas are where
you have red and blue set.

00:42:12.300 --> 00:42:16.500
So, both of those bitplanes have
been set in your rendering there.

00:42:21.660 --> 00:42:26.430
Now, other buffer views that you
can get are the back buffer.

00:42:26.430 --> 00:42:27.280
And that's pretty straightforward.

00:42:27.280 --> 00:42:31.190
It just looks like the front
buffer before it got swapped.

00:42:32.160 --> 00:42:37.100
You can look at the alpha buffer,
which is also gray scale colored.

00:42:37.100 --> 00:42:38.970
And you can look at all
your auxiliary buffers.

00:42:39.050 --> 00:42:42.800
So depending on how many you asked
for in your pixel format or how

00:42:42.890 --> 00:42:47.040
many the engine or card supports,
that's how many you can look at.

00:42:47.040 --> 00:42:49.410
Buffer views are all static.

00:42:49.480 --> 00:42:51.660
So they're just what
your app put in there.

00:42:51.660 --> 00:42:54.640
You can't edit them and then
shove them back in and say,

00:42:54.680 --> 00:42:58.420
oh, well, what happens if I really had
a Z precision range of much

00:42:58.950 --> 00:43:00.160
bigger than I really do?

00:43:00.440 --> 00:43:01.500
You can't do that.

00:43:01.500 --> 00:43:03.540
It's just reporting what you did.

00:43:03.620 --> 00:43:06.970
So it's just static images.

00:43:11.060 --> 00:43:14.230
Okay, now with that,
turn it over to Chris.

00:43:14.230 --> 00:43:19.510
So I'm going to show an example of
being able to look at those buffers.

00:43:23.120 --> 00:43:27.660
So looking closely at this application,
we can see in the background where

00:43:27.660 --> 00:43:32.530
the waters and the land is meeting.

00:43:32.740 --> 00:43:34.640
The land doesn't quite look right.

00:43:34.640 --> 00:43:37.380
It's not a smooth land.

00:43:37.420 --> 00:43:39.680
There's not a smooth line there.

00:43:39.800 --> 00:43:42.150
And what I think this is,
is I think it's Z-fighting.

00:43:42.290 --> 00:43:47.240
So the way that I would check on this,
the first thing I would do is I'm going

00:43:47.240 --> 00:43:49.400
to take a look at the depth buffer.

00:43:49.530 --> 00:43:51.960
So to do this,
I have to set a breakpoint in

00:43:51.960 --> 00:43:56.080
order to specify exactly where
I want to look at the buffer.

00:43:56.260 --> 00:43:59.790
So I go up to views and...

00:44:00.220 --> 00:44:13.690
"I'm going to set a breakpoint
right before GeoClear is called.

00:44:13.810 --> 00:44:17.200
So that means everything's done,
it's going on to the next frame.

00:44:17.200 --> 00:44:22.660
But since I set it before,
it won't actually execute it until…"

00:44:23.800 --> 00:44:28.080
So I set my breakpoint
and I go up to the views.

00:44:28.080 --> 00:44:30.780
Let's look at the depth buffer.

00:44:31.570 --> 00:44:35.310
So, well, you can set slider here,
but I'm just going to use

00:44:35.310 --> 00:44:41.300
the auto find min max,
which will, we can see that the min and

00:44:41.300 --> 00:44:46.200
the max Z value that we're
using is actually very small.

00:44:46.200 --> 00:44:49.280
So the precision that we're using,
this is a 32-bit depth

00:44:49.280 --> 00:44:51.810
buffer in this case,
but we're only using a very small

00:44:51.810 --> 00:44:53.780
amount of it from 0.9 to 0.9.

00:44:53.800 --> 00:44:56.560
So we're going to set the
value from 0.996 to 1.0.

00:44:56.560 --> 00:45:00.790
And what we'd like is for
this value to be a lot bigger.

00:45:00.790 --> 00:45:04.800
We'd like to use a lot
more of that 0 to 1.

00:45:04.800 --> 00:45:11.250
So let's go ahead and
figure out why this is,

00:45:11.730 --> 00:45:13.320
why we're using so
little of the Z buffer.

00:45:13.320 --> 00:45:18.320
And I'm going to set a
breakpoint on GL frustum.

00:45:22.480 --> 00:45:30.970
I think that I don't actually call
frustum unless I resize a window.

00:45:31.290 --> 00:45:32.820
Here we go, frustum.

00:45:32.900 --> 00:45:36.890
And we see the frustum
is being set with the x,

00:45:36.890 --> 00:45:39.200
y, or I can't remember what
these arguments are.

00:45:39.260 --> 00:45:43.520
It's basically-- and then these two
values are the z min and the z max.

00:45:43.570 --> 00:45:48.350
So we're going from 1 to 100,000 or
a million or something like that,

00:45:48.350 --> 00:45:55.260
which is pretty large considering that
I'm only really drawing from 0 to 40.

00:45:55.330 --> 00:45:57.630
So because of that,
that's making our depth

00:45:57.630 --> 00:45:57.630
buffer look incorrect.

00:45:58.490 --> 00:45:59.520
So let's see.

00:45:59.880 --> 00:46:04.940
So I'm going to show another application,
this same application,

00:46:04.940 --> 00:46:08.950
with the frustum modified so
it will clip between 0 and 40.

00:46:17.170 --> 00:46:20.250
And again,
I'm going to look at the depth buffer.

00:46:20.410 --> 00:46:24.600
Well, we can see already that the
water is looking much nicer.

00:46:24.710 --> 00:46:31.260
We've got clear lines where we used
to be having some z-fighting issues.

00:46:31.350 --> 00:46:34.190
So let's set a breakpoint to clear.

00:46:34.450 --> 00:46:37.930
And we can see the depth
buffer automatically updated.

00:46:37.930 --> 00:46:42.690
And we're actually using
a lot more of that range.

00:46:42.790 --> 00:46:45.860
So in effect,
we've gotten rid of those issues.

00:46:45.910 --> 00:46:50.220
And back to you.

00:46:50.260 --> 00:46:52.290
All right.

00:46:52.290 --> 00:46:52.290
Thanks, Chris.

00:46:58.730 --> 00:47:02.400
That Z fighting is, that's,
that in the past has been

00:47:02.400 --> 00:47:04.230
a real hard one to find.

00:47:04.450 --> 00:47:06.940
You know,
we've got a lot of chatter on the

00:47:06.940 --> 00:47:14.190
OpenGL list about my polygons keep
flashing in and out and to try and...

00:47:14.430 --> 00:47:20.900
It's not obvious that your z-precision
is related to the GL frustum call.

00:47:20.900 --> 00:47:23.660
The GL frustum has nothing
to do with the death buffer,

00:47:23.660 --> 00:47:24.200
right?

00:47:24.340 --> 00:47:29.560
So there's not that instant correlation.

00:47:32.260 --> 00:47:35.520
Okay,
more of the application graphics state.

00:47:35.800 --> 00:47:41.440
Profiler will capture all your
textures that you're uploading,

00:47:41.460 --> 00:47:44.780
vertex programs and fragment programs.

00:47:44.820 --> 00:47:47.170
And you can look at those.

00:47:47.720 --> 00:47:52.390
and make sure and verify for yourself
with Profiler that you really did

00:47:52.390 --> 00:47:55.150
upload what you think you uploaded.

00:47:55.480 --> 00:47:58.940
And one place where this is really
useful and Chris is going to show

00:47:59.030 --> 00:48:04.990
later is in your mipmaps because
you can get a lot of weird texturing

00:48:04.990 --> 00:48:11.400
errors when you think you've got a
mipmap up there that you really don't.

00:48:11.400 --> 00:48:15.550
This screenshot up here
is showing a cube map.

00:48:16.230 --> 00:48:21.510
and what Profiler does there,
capture each of the individual

00:48:21.520 --> 00:48:25.860
six faces that go on the cube
map and we stick them on a cube.

00:48:26.580 --> 00:48:30.600
You can rotate that around and it
will show you which map is being

00:48:30.600 --> 00:48:32.980
applied to which face of the cube.

00:48:33.040 --> 00:48:38.140
So again, verify that you've uploaded the
right texture to the right face.

00:48:38.520 --> 00:48:40.830
Plus there's a bunch of
information up there that talks

00:48:40.830 --> 00:48:45.400
about the internal format,
the source format.

00:48:45.530 --> 00:48:51.130
So when you're looking at
performance issues in terms of...

00:48:51.880 --> 00:48:56.460
What kind of texture formats the
card's going to perform best with?

00:48:56.460 --> 00:48:58.860
You can see, oh, well,
if I change the internal format and

00:48:59.010 --> 00:49:02.270
ask for a different internal format,
you can maybe get better performance.

00:49:02.350 --> 00:49:06.680
It shows the texture dimensions.

00:49:06.680 --> 00:49:09.580
There's a mipmap slider down there,
which Chris is going to

00:49:09.580 --> 00:49:10.990
get into more detail on.

00:49:11.520 --> 00:49:16.240
and other little buttons and
things like that to show you can

00:49:16.240 --> 00:49:18.630
flip the texture up and down.

00:49:19.150 --> 00:49:19.700
Upside down.

00:49:19.830 --> 00:49:24.030
And so with that, I'm going to turn it
over to Chris with ML.

00:49:24.130 --> 00:49:25.040
Okay.

00:49:25.190 --> 00:49:27.100
So we've got the profiler running here.

00:49:27.130 --> 00:49:29.310
This time when we
launched the application,

00:49:29.390 --> 00:49:32.790
just like normal,
we -- this time I set collect resources,

00:49:32.790 --> 00:49:33.280
however.

00:49:33.570 --> 00:49:37.770
And so this brings up the
resources window right here.

00:49:37.770 --> 00:49:41.300
And so right now I'm
viewing the textures.

00:49:41.630 --> 00:49:45.680
So looking at this application,
we see it's a nice sunny day.

00:49:45.700 --> 00:49:47.000
You know, it's a sunset.

00:49:47.030 --> 00:49:50.970
It looks pretty warm here,
but looking down at the ground,

00:49:50.970 --> 00:49:53.050
it looks kind of cold, like snow.

00:49:53.090 --> 00:49:57.400
But that's actually because one of my
textures isn't uploading correctly.

00:49:57.400 --> 00:50:01.040
And so by default,
when a texture image is

00:50:01.120 --> 00:50:07.090
not specified correctly,
it defaults to a white texture.

00:50:07.280 --> 00:50:11.250
So let's go and see why
this texture is being white.

00:50:11.290 --> 00:50:13.920
So we see, well here's a grass texture.

00:50:13.920 --> 00:50:16.380
We don't see that grass texture in here.

00:50:16.380 --> 00:50:19.520
We've got sand,
shows you all these resources,

00:50:19.520 --> 00:50:22.880
I'll show you these, and like clouds.

00:50:22.880 --> 00:50:27.950
And so the mipmap slider down here
actually serves a dual purpose in

00:50:27.950 --> 00:50:33.700
that when you have mipmapping enabled,
it will let you slide between all

00:50:33.700 --> 00:50:35.950
of the mipmaps and see each one.

00:50:35.970 --> 00:50:39.980
And when it's disabled,
this actual slider here will be disabled.

00:50:40.050 --> 00:50:44.800
So let's go look at one of the
textures we know is uploaded correctly

00:50:44.800 --> 00:50:47.670
and go look through these mipmaps.

00:50:47.680 --> 00:50:51.100
It looks like they're
all specified correctly.

00:50:52.960 --> 00:50:55.840
So let's go back to the grass texture.

00:50:55.870 --> 00:51:02.830
And we notice that these mipmap
levels have not been updated.

00:51:02.830 --> 00:51:06.130
So to fix this,
either we could turn off mipmapping

00:51:06.460 --> 00:51:09.240
for this particular texture,
or what I'm going to do is

00:51:09.250 --> 00:51:13.790
just I'm going to specify the
mipmap levels for all of those.

00:51:13.850 --> 00:51:19.680
And so I'm going to actually--
this is a great way to show off

00:51:19.680 --> 00:51:22.340
the scripting ability in Profiler.

00:51:22.460 --> 00:51:30.460
So I'm going to, on the fly,
disable mipmapping for the texture

00:51:30.590 --> 00:51:34.250
so that hopefully we can make sure,
we can verify that this is why

00:51:34.260 --> 00:51:36.240
this texture is not showing up.

00:51:36.350 --> 00:51:39.450
So I'm going to go to
the breakpoints window.

00:51:39.550 --> 00:51:41.460
This is where you can
set up your scripts.

00:51:41.460 --> 00:51:44.620
And I'm going to have a script
that turns off MIT mapping.

00:51:44.790 --> 00:51:50.690
So a logical place for me to do this
is after every bind texture call.

00:51:53.000 --> 00:51:55.020
So by doing this after
each bind texture call,

00:51:55.020 --> 00:51:59.120
I'm going to call
GL_TECH_PARAMETER_I with the target

00:51:59.170 --> 00:52:05.440
texture 2D and set the min filter
to linear as opposed to linear,

00:52:05.440 --> 00:52:07.140
mipmap linear.

00:52:07.190 --> 00:52:09.210
So let's go ahead and do that.

00:52:09.280 --> 00:52:15.930
So I'm going to attach a script
through the actions here.

00:52:17.850 --> 00:52:19.560
Let's open up my script.

00:52:19.590 --> 00:52:20.830
You know what, Chris,
while you're doing that,

00:52:20.840 --> 00:52:21.720
I want to jump in here.

00:52:21.720 --> 00:52:23.380
Sure.

00:52:23.410 --> 00:52:26.700
You'll notice that whenever Chris is
up there looking for functions,

00:52:26.730 --> 00:52:29.460
that he's not moving the mouse around.

00:52:29.460 --> 00:52:31.250
He's typing on here.

00:52:31.290 --> 00:52:33.800
Because it finds-- yeah.

00:52:33.850 --> 00:52:36.320
Chris is a real keyboard-oriented guy.

00:52:36.380 --> 00:52:38.500
And so we put in these--
Keyboard is good.

00:52:38.670 --> 00:52:42.880
Yeah, put in these ways to find
functions passed by just typing.

00:52:44.750 --> 00:52:47.640
Okay, so let's attach that script.

00:52:47.640 --> 00:52:51.030
And for this particular script,
I'm going to attach the no-mitmap

00:52:51.090 --> 00:52:52.940
script that I just specified.

00:52:53.230 --> 00:52:57.770
I'm going to have it execute
after the bind texture call.

00:52:57.830 --> 00:53:02.610
You can either execute before or after,
so I'm going to have it execute after.

00:53:03.690 --> 00:53:07.280
And after it does execute that script,
I'm going to have it continue.

00:53:07.280 --> 00:53:09.980
You can have it otherwise
pause and show you the state

00:53:10.150 --> 00:53:11.290
after that script's been done.

00:53:11.320 --> 00:53:14.340
So let's watch this.

00:53:14.350 --> 00:53:18.480
Attach, and as we can see,
on the fly we've corrected

00:53:18.480 --> 00:53:23.180
that and everything looks much
better than it did before.

00:53:24.320 --> 00:53:26.180
This is a live demo,
ladies and gentlemen.

00:53:26.230 --> 00:53:27.200
That just really worked.

00:53:27.570 --> 00:53:32.180
Awesome.

00:53:35.200 --> 00:53:36.260
So back to you.

00:53:36.380 --> 00:53:40.340
All right, thanks, Chris.

00:53:40.580 --> 00:53:44.380
OK, so let's move on to the
OpenGL driver monitor,

00:53:44.380 --> 00:53:47.640
the second tool in our suite.

00:53:47.680 --> 00:53:49.550
We can call it a suite because
it has more than one tool.

00:53:49.650 --> 00:53:51.230
It has two.

00:53:51.300 --> 00:53:52.950
OK.

00:53:53.670 --> 00:54:00.520
The driver monitor is where Profiler
attaches to your software and shows how

00:54:00.550 --> 00:54:04.630
your software is interacting with OpenGL.

00:54:04.680 --> 00:54:09.680
Driver monitor attaches to
the hardware and it shows you

00:54:09.680 --> 00:54:12.600
what's going on in the GPU.

00:54:13.440 --> 00:54:17.290
Earlier versions of Driver Monitor had
these really bizarre,

00:54:17.400 --> 00:54:22.310
obscure parameter names like Gart
Wait Time and stuff like that.

00:54:22.340 --> 00:54:24.060
It's one of my favorites.

00:54:24.190 --> 00:54:32.620
And we got a lot of questions like,
"What does that mean?"

00:54:33.040 --> 00:54:38.850
We developed the decoder ring to say,
well, when you look at these arcane

00:54:38.870 --> 00:54:41.950
cryptic parameter names,
this is what's really going on.

00:54:42.230 --> 00:54:45.920
And you had to go to
this URL to get that.

00:54:45.970 --> 00:54:50.760
Well, for Tiger,
we built all that into driver monitor.

00:54:50.810 --> 00:54:57.650
So not only are the parameter names
text that's even sort of human readable,

00:54:57.650 --> 00:55:02.140
you can roll over it and
it'll pop up the decoder ring.

00:55:03.060 --> 00:55:06.560
For that particular parameter,
I'll tell you what.

00:55:06.560 --> 00:55:08.770
You're welcome.

00:55:09.830 --> 00:55:18.180
Uh,
Driver Monitor does remote monitoring,

00:55:18.180 --> 00:55:18.180
too, which means if you
have a full-screen app,

00:55:18.250 --> 00:55:23.780
It's pretty hard to run another
app on top of it and see it.

00:55:23.780 --> 00:55:25.140
Actually, you can't.

00:55:25.140 --> 00:55:29.070
So what you can do is run your
full-screen app on one computer,

00:55:29.070 --> 00:55:33.030
and then as long as you're connected
on a LAN with a second computer,

00:55:33.030 --> 00:55:37.020
you can run driver monitor on
that second one and monitor

00:55:37.060 --> 00:55:40.590
the other GPU over the network.

00:55:44.110 --> 00:55:46.980
Okay,
let's have a demo of Driver Monitor.

00:55:47.220 --> 00:55:51.720
So I'm going to show the
Driver Monitor in use.

00:55:51.830 --> 00:55:54.180
So I'm going to start up my
application just using Profiler,

00:55:54.220 --> 00:55:55.540
just because it's handy.

00:55:55.620 --> 00:55:59.560
I've got my list of applications,
and I've launched it up.

00:55:59.720 --> 00:56:03.360
And everything looks good.

00:56:03.480 --> 00:56:05.820
Let's bring up Driver Monitor.

00:56:07.690 --> 00:56:10.360
And so we've got the list
of everything we've got,

00:56:10.360 --> 00:56:14.700
of all the parameters, and by default,
whoops,

00:56:14.860 --> 00:56:16.880
We can set use descriptive names.

00:56:17.050 --> 00:56:19.980
By default, it will be like this,
and we've got...

00:56:20.400 --> 00:56:30.400
[Transcript missing]

00:56:30.540 --> 00:56:33.900
And you also have mouseovers which
explain everything that you'd

00:56:33.900 --> 00:56:35.500
want to know about these things.

00:56:35.550 --> 00:56:39.700
So here I've added,
right now I'm viewing on the graph,

00:56:39.780 --> 00:56:44.900
the current free video memory,
the texture page off and page on data.

00:56:44.900 --> 00:56:49.570
And so we see that right now we've got,
let's switch this to linear.

00:56:51.620 --> 00:56:57.300
We've got about 7 megabytes of VRAMs,
8 megabytes of VRAM free.

00:56:57.300 --> 00:57:02.280
And we can see that there's only
about 1 or 2 megabytes being paged

00:57:02.360 --> 00:57:05.500
on of texture data each frame.

00:57:05.500 --> 00:57:08.950
If you don't understand what
any of these things are,

00:57:09.020 --> 00:57:12.500
you can always just go over
these in your free time,

00:57:12.500 --> 00:57:16.360
set it up, figure it out,
pick the ones that you think are going

00:57:16.360 --> 00:57:18.500
to work for what you want to figure out.

00:57:18.500 --> 00:57:23.430
And so let's actually make
this window pretty large.

00:57:23.530 --> 00:57:27.210
And we notice-- uh-oh.

00:57:28.210 --> 00:57:33.760
This video card must have
more VRAM than I expected.

00:57:35.290 --> 00:57:37.200
They really beef up these demo machines.

00:57:37.200 --> 00:57:39.200
Ah, that's well... That's
just to make us look good,

00:57:39.200 --> 00:57:41.200
I don't know.

00:57:41.300 --> 00:57:44.500
Let's see.

00:57:44.510 --> 00:57:47.530
So we see that actually we can see
that the current free video memory

00:57:47.640 --> 00:57:53.060
is bobbing up and down and whoa,
let's go up to one gigabyte.

00:57:53.060 --> 00:57:57.130
We see that we're actually uploading
texture page on data is reached,

00:57:57.130 --> 00:58:02.890
it's about 400 megabytes per second
simply because I've made the window

00:58:02.950 --> 00:58:07.210
so large and I've got multi-sampling,
all those nifty features on.

00:58:07.210 --> 00:58:07.210
So it's taking up a lot of VRAM.

00:58:07.400 --> 00:58:13.810
So, because I used the drive
monitor to figure this out,

00:58:13.860 --> 00:58:17.010
I can see that it's a VRAM issue
that's causing it to slow down

00:58:17.100 --> 00:58:19.140
so much when I'm at full screen.

00:58:19.190 --> 00:58:26.690
And what I'm going to do is I decided to
fix this by using compressed textures.

00:58:26.830 --> 00:58:29.190
which allowed me to stay
at the same resolution,

00:58:29.190 --> 00:58:33.110
but I'm actually using only a quarter
of the memory in VRAM for these

00:58:33.190 --> 00:58:38.280
textures using some OpenGL extensions
which allow you to do this.

00:58:38.600 --> 00:58:40.840
So let's do that again.

00:58:40.900 --> 00:58:44.100
And let's look at driver monitor.

00:58:44.170 --> 00:58:47.490
We can see that the
VRAM has flattened out.

00:58:47.760 --> 00:58:54.410
If I were using... Well,
it's a little bit faster,

00:58:54.410 --> 00:58:58.930
but in more extreme cases,
you would see a huge benefit from doing

00:58:59.370 --> 00:59:02.040
things such as compressing textures,
saving your VRAM.

00:59:02.060 --> 00:59:04.180
And there's so many other
things that you can check.

00:59:04.340 --> 00:59:08.060
You can see where your time is being
spent using the driver monitor.

00:59:08.060 --> 00:59:10.060
So... All right.

00:59:10.060 --> 00:59:11.060
That's it.

00:59:11.060 --> 00:59:12.060
Thanks, Chris.

00:59:12.060 --> 00:59:13.130
Thank you.

00:59:17.870 --> 00:59:23.110
Quick words on what's new for
Tiger in Profiler and Driver Monitor.

00:59:23.110 --> 00:59:26.690
You saw the single control panel,
you saw the decoder ring built in,

00:59:26.710 --> 00:59:29.890
the new trace info stuff
for the call trace.

00:59:30.230 --> 00:59:34.140
We're also going to--we've
worked on better integration

00:59:34.570 --> 00:59:36.960
between OpenGL apps and Shark.

00:59:37.180 --> 00:59:43.240
Okay, a lot of you have said,
"All my time in the Shark trace is being

00:59:43.260 --> 00:59:46.490
spent in GLD get string." What is that?

00:59:46.600 --> 00:59:50.860
Well, it's not really there.

00:59:50.860 --> 00:59:54.080
We fixed it.

00:59:55.320 --> 00:59:58.500
Also coming in Tiger, remote profiling.

00:59:58.500 --> 01:00:01.960
So as with driver monitor,
you can hook up across a network and

01:00:02.760 --> 01:00:05.990
monitor the GPU of a full-screen app.

01:00:06.090 --> 01:00:08.280
You can do the same thing
with OpenGL Profiler.

01:00:08.410 --> 01:00:12.560
So you can run your full-screen
app really in full-screen and get

01:00:12.800 --> 01:00:15.600
the full OpenGL Profiler benefit.

01:00:15.720 --> 01:00:18.940
You're welcome.

01:00:21.220 --> 01:00:26.390
Quick note,
you need to have the same OS and

01:00:26.400 --> 01:00:31.180
profiler versions running on
both computers to make that work.

01:00:31.720 --> 01:00:36.920
Okay, now to wrap up,
let's talk about really your

01:00:36.920 --> 01:00:41.600
performance issues is a balancing act.

01:00:41.600 --> 01:00:45.990
We've seen here a lot of talk about
how you can improve the performance,

01:00:46.000 --> 01:00:52.710
your GPU usage, and you use Profiler to
do that in driver monitor.

01:00:53.050 --> 01:00:56.880
You also have a CPU in the computer.

01:00:56.900 --> 01:00:59.790
So you need to be sure that you're
on top of its performance too.

01:00:59.890 --> 01:01:06.600
So your performance improvement
cycle is going to work like this.

01:01:06.730 --> 01:01:09.340
First of all,
your GPU usage might be very,

01:01:09.340 --> 01:01:12.180
very high and your CPU usage low.

01:01:12.240 --> 01:01:16.520
As a ratio,
whole app is 100%. GPU to start

01:01:16.910 --> 01:01:21.920
with might be way up in the
high 90s and CPU down in 10.

01:01:21.920 --> 01:01:25.920
As you use Profiler and improve your
performance on the graphics card,

01:01:25.940 --> 01:01:29.460
well, now what's going to happen
is your GPU usage as a

01:01:29.460 --> 01:01:35.040
percentage is going to drop,
maybe driving your CPU usage higher.

01:01:35.800 --> 01:01:39.000
Switch over to Chud Tools in Shark.

01:01:39.060 --> 01:01:42.000
Start driving that CPU usage back down.

01:01:42.020 --> 01:01:43.800
Well, that's going to,
because it's a ratio,

01:01:43.800 --> 01:01:47.700
that's going to start
pulling your GPU usage up.

01:01:48.080 --> 01:01:49.560
And then this is a cycle.

01:01:49.610 --> 01:01:53.500
And what you want to ultimately
get towards is where they're

01:01:53.500 --> 01:01:54.700
just about 50/50 balance.

01:01:54.760 --> 01:01:57.490
You're never going to, you know,
that's a perfect ideal you may not reach,

01:01:57.570 --> 01:02:02.780
but that's how you would use these
tools in conjunction with each other.