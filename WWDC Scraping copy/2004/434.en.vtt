WEBVTT

00:00:12.250 --> 00:00:13.340
Hello.

00:00:13.450 --> 00:00:16.430
Welcome to session 434,
Cocoa Performance Techniques.

00:00:16.450 --> 00:00:18.840
My name is Troy Stephens.

00:00:18.880 --> 00:00:21.700
I'm a software engineer in the
Cocoa Frameworks group at Apple.

00:00:21.760 --> 00:00:25.500
And I'm here today to talk to you
about performance and optimization,

00:00:25.710 --> 00:00:30.080
specifically as they apply to developing
Cocoa applications on Mac OS X.

00:00:30.250 --> 00:00:34.250
Now, as we all probably know,
performance is work and diligence.

00:00:34.280 --> 00:00:36.310
But it can also be
exciting and rewarding.

00:00:36.380 --> 00:00:39.920
It can pay off in applications
that your users want to use.

00:00:40.230 --> 00:00:43.860
If there's one thing that users love,
it's a well-optimized,

00:00:43.880 --> 00:00:47.370
responsive application,
one that not only empowers them

00:00:47.370 --> 00:00:50.740
to do something of interest,
but is ready to respond to their

00:00:50.740 --> 00:00:54.850
requests and provide feedback with
quick turnaround to interact with

00:00:55.370 --> 00:00:58.000
them in a way that is responsive.

00:00:58.300 --> 00:01:02.500
So optimization.

00:01:07.500 --> 00:01:13.800
[Transcript missing]

00:01:16.020 --> 00:01:17.790
So turnaround is part of it.

00:01:18.050 --> 00:01:24.940
And one thing that you want to do is
figure out where the opportunities for

00:01:24.940 --> 00:01:29.030
optimization in your application lie.

00:01:29.120 --> 00:01:30.930
And how do you do that?

00:01:31.670 --> 00:01:33.970
How do we figure out where to do things?

00:01:34.030 --> 00:01:38.330
Well, it's partly a matter of metrics,
of using measurement techniques

00:01:38.330 --> 00:01:39.500
and measurement tools.

00:01:39.770 --> 00:01:42.850
It's partly a matter of having
some general ideas about

00:01:42.850 --> 00:01:44.140
optimization that may apply.

00:01:44.140 --> 00:01:48.000
You may have brought these from other
platforms that you've worked on.

00:01:48.150 --> 00:01:51.680
And it's partly a matter of knowing the
frameworks that you're working with and

00:01:51.680 --> 00:01:54.080
the platform that you're working with,
knowing the various

00:01:54.090 --> 00:01:57.740
capabilities that it provides,
their performance characteristics,

00:01:57.800 --> 00:01:59.950
and so forth.

00:02:00.580 --> 00:02:02.330
So that's what I want to
talk to you about today.

00:02:02.380 --> 00:02:04.370
The other issues,
the platform-independent

00:02:04.370 --> 00:02:06.880
issues about performance,
are easily covered elsewhere.

00:02:06.880 --> 00:02:08.590
They're comprehensively
covered elsewhere.

00:02:08.690 --> 00:02:11.280
Today I want to talk
specifically about Cocoa.

00:02:11.340 --> 00:02:14.730
And in particular,
I'll try to point out to you some

00:02:14.780 --> 00:02:17.700
common performance techniques,
some issues that you may

00:02:17.700 --> 00:02:20.100
encounter commonly as you're
developing Cocoa applications,

00:02:20.100 --> 00:02:21.940
things lots of people run into.

00:02:22.070 --> 00:02:25.520
I'll try to point out some
API usage techniques and recommended

00:02:25.520 --> 00:02:28.970
usage patterns that you can
use to help improve performance.

00:02:29.140 --> 00:02:33.110
And we'll also look at alternative ways,
different ways that Cocoa provides a

00:02:33.110 --> 00:02:39.700
variety of ways to perform a particular
task that give you the opportunity to

00:02:39.750 --> 00:02:45.930
choose the way that is most conducive
to getting the best performance.

00:02:46.050 --> 00:02:48.560
So as prerequisites for this talk,
I assume only that you have some

00:02:48.830 --> 00:02:53.920
general experience developing in Cocoa,
some familiarity, more or less,

00:02:53.970 --> 00:02:57.760
with the various APIs and classes
and capabilities that it provides.

00:02:57.800 --> 00:03:00.220
And if you have some general knowledge
of performance techniques that

00:03:00.220 --> 00:03:03.220
you've brought from another platform,
that could be helpful too,

00:03:03.220 --> 00:03:05.740
but it's not strictly required.

00:03:05.900 --> 00:03:08.000
So first,
before we dive into the Cocoa specifics,

00:03:08.000 --> 00:03:11.740
I want to cover some general concepts,
just to get us into the right mindset

00:03:11.860 --> 00:03:14.110
for thinking about optimization.

00:03:14.130 --> 00:03:17.360
There's a lot of wisdom that's
been accumulated from various other

00:03:17.360 --> 00:03:19.440
platforms that we all have worked on.

00:03:19.480 --> 00:03:21.990
Some things about
performance are constants,

00:03:22.060 --> 00:03:23.700
and we can learn from that.

00:03:23.760 --> 00:03:26.100
So one of the most important
things about performance tuning

00:03:26.100 --> 00:03:28.500
is it involves trade-offs,
some give and take.

00:03:28.500 --> 00:03:31.500
On the one hand,
you have this ideal of achieving high

00:03:31.500 --> 00:03:34.860
performance in your applications,
creating a responsive application.

00:03:34.990 --> 00:03:38.350
But there are a number of various
areas in which you may need to

00:03:38.350 --> 00:03:40.720
give a little and compromise.

00:03:40.760 --> 00:03:43.210
There are trade-offs involved.

00:03:43.910 --> 00:03:46.430
One of those trade-offs
is resource usage.

00:03:46.690 --> 00:03:50.600
A common technique for producing
higher performance is rather

00:03:50.600 --> 00:03:52.800
than recalculating results,
say caching it.

00:03:52.800 --> 00:03:57.370
You use a little more resource,
keep some block of memory around,

00:03:57.370 --> 00:03:58.650
and reuse that.

00:03:58.860 --> 00:04:01.200
You're trading memory for
performance in that case.

00:04:01.200 --> 00:04:03.980
There are lots of other examples of
that with other types of resources.

00:04:05.400 --> 00:04:07.460
Engineering time is always at a premium.

00:04:07.460 --> 00:04:08.760
There's never enough of it.

00:04:08.900 --> 00:04:11.610
And there are any number of
aspects of your application

00:04:11.610 --> 00:04:13.400
that you can spend time tuning.

00:04:13.500 --> 00:04:16.540
You don't want to spend time optimizing
every little bit of your application,

00:04:16.540 --> 00:04:18.900
because in many cases
that can be premature,

00:04:18.900 --> 00:04:20.730
and it can lead to more
complex code that's just

00:04:20.950 --> 00:04:22.820
completely unwieldy to maintain.

00:04:22.930 --> 00:04:25.650
So since engineering time
is a limited resource,

00:04:25.650 --> 00:04:29.540
you need to really focus in on where
you'll get the most benefit from the

00:04:29.630 --> 00:04:32.300
performance optimizations you're doing.

00:04:33.010 --> 00:04:35.230
Convenience and simplicity.

00:04:35.310 --> 00:04:38.320
A lot of times, though not always,
the most convenient way to do

00:04:38.320 --> 00:04:43.390
something is not always the way that is
conducive to the highest performance.

00:04:43.500 --> 00:04:48.240
So sometimes you have to make your code
a little more complicated to optimize

00:04:48.350 --> 00:04:51.420
it for the special case that it's really
going to have to handle so that you

00:04:51.480 --> 00:04:54.080
can get maximum performance out of it.

00:04:55.360 --> 00:04:57.540
Loose coupling, flexibility to change.

00:04:57.540 --> 00:05:00.480
These are the hallmarks of
object-oriented programming.

00:05:00.480 --> 00:05:02.490
And to some extent,
you can achieve performance while

00:05:02.570 --> 00:05:04.330
still retaining some loose coupling.

00:05:04.530 --> 00:05:08.020
But the essence of programming
and developing an application is,

00:05:08.020 --> 00:05:11.940
in some sense, making assumptions,
defining the assumptions

00:05:11.940 --> 00:05:13.740
of your problem domain.

00:05:13.810 --> 00:05:18.040
So often, the more assumptions you deny
yourself the ability to make,

00:05:18.040 --> 00:05:20.890
the more general your code is,
and the fewer the optimization

00:05:20.890 --> 00:05:23.050
opportunities you're
really taking advantage of.

00:05:23.070 --> 00:05:26.260
So sometimes you have to give up
a little flexibility in order to

00:05:26.260 --> 00:05:30.320
hardwire your code for the fastest
path for the best performance.

00:05:30.350 --> 00:05:32.450
Lastly, strict correctness and safety.

00:05:32.680 --> 00:05:35.560
Almost all the time,
you want to make sure no matter what your

00:05:35.560 --> 00:05:37.760
code is correct and does the right thing.

00:05:37.760 --> 00:05:40.450
Only a few cases can you actually
get away with approximating.

00:05:40.530 --> 00:05:43.170
But there are some cases,
such as when you're drawing.

00:05:43.300 --> 00:05:45.660
If you're drawing something
that doesn't need to be exact,

00:05:45.680 --> 00:05:50.980
that maybe speed is more important,
you can approximate in cases like that.

00:05:51.260 --> 00:05:55.840
And also, in terms of safety,
if you're developing generic code,

00:05:55.840 --> 00:05:57.880
let's say,
that you're going to put in a framework,

00:05:57.890 --> 00:05:59.180
and you don't know who's
going to use it yet.

00:05:59.180 --> 00:06:03.700
It might be used by some unknown
application or applications.

00:06:03.720 --> 00:06:08.010
You might not know whether those
applications will need those objects

00:06:08.050 --> 00:06:10.700
that you're providing to be thread safe,
let's say.

00:06:10.820 --> 00:06:13.410
So if you have to provide
locking and thread safety,

00:06:13.430 --> 00:06:15.830
that's a whole other burden
that can affect performance.

00:06:15.860 --> 00:06:19.070
You have to be able to balance
the desire for performance against

00:06:19.070 --> 00:06:20.720
these other competing demands.

00:06:22.430 --> 00:06:26.060
So there are some general recommendations
we can make about performance.

00:06:26.090 --> 00:06:28.540
One of the most important things
that you can do is to choose a

00:06:28.540 --> 00:06:30.920
scalable application architecture.

00:06:31.050 --> 00:06:34.010
Think about the ways that your
application is going to be used.

00:06:34.120 --> 00:06:37.680
Try to anticipate the numbers
of objects that your application

00:06:37.680 --> 00:06:39.200
is going to have to deal with.

00:06:39.240 --> 00:06:42.370
And choose appropriate
algorithms and data structures.

00:06:42.420 --> 00:06:44.590
On any platform,
this can make a huge difference

00:06:44.600 --> 00:06:46.820
in how your application performs.

00:06:46.830 --> 00:06:49.420
Also, when you're working
with the framework APIs,

00:06:49.510 --> 00:06:51.230
don't fight the framework.

00:06:51.390 --> 00:06:53.970
Try to leverage as much as possible
what the framework provides.

00:06:54.000 --> 00:06:57.360
And in terms of Cocoa in particular,
where Cocoa provides a

00:06:57.360 --> 00:07:00.590
facility to do something,
it's in many ways to your advantage

00:07:00.700 --> 00:07:04.180
to leverage that facility to its
maximum capability and use it,

00:07:04.180 --> 00:07:07.500
because then you have the benefit of
a whole team of frameworks engineers

00:07:07.500 --> 00:07:10.670
at Apple who are constantly making
not only performance improvements,

00:07:10.670 --> 00:07:12.540
but also enhancements and functionality.

00:07:12.580 --> 00:07:15.300
And you get to inherit
all of that for free.

00:07:15.330 --> 00:07:18.020
Also, wherever possible,
when you're defining your own internal

00:07:18.020 --> 00:07:21.320
data structures and your own objects,
try to use API-compatible

00:07:21.320 --> 00:07:23.200
types where possible.

00:07:23.330 --> 00:07:26.780
You notice, for example, in APKID APIs,
we largely use NSArray.

00:07:26.780 --> 00:07:32.260
I don't think we have any APIs,
maybe a few, that use NSSets.

00:07:32.410 --> 00:07:35.620
So if you use a lot of sets, let's say,
for example, in your code,

00:07:35.620 --> 00:07:38.120
in your model code,
you may find you have to do a

00:07:38.120 --> 00:07:41.000
lot of conversions between your
internal representation and what

00:07:41.120 --> 00:07:44.960
the framework expects every time
you make a message send that uses

00:07:45.370 --> 00:07:47.390
some particular type of data.

00:07:47.400 --> 00:07:49.800
So try to avoid that sort of
type impedance mismatch by

00:07:49.880 --> 00:07:50.880
using API-compatible types.

00:07:51.440 --> 00:07:53.700
And you can do that with a lot
of other types where you can.

00:07:53.700 --> 00:07:56.050
Also, try to keep in mind
easily overlooked costs,

00:07:56.130 --> 00:07:58.710
things like heap allocations,
including allocating and

00:07:58.760 --> 00:07:59.880
deallocating objects.

00:07:59.970 --> 00:08:01.560
Heap operations do take some time.

00:08:01.560 --> 00:08:03.440
There's some overhead involved in that.

00:08:03.440 --> 00:08:04.940
We don't normally think about that.

00:08:04.940 --> 00:08:06.700
We kind of think that
it's just kind of magic.

00:08:06.700 --> 00:08:09.860
We ask for some memory
and get it for free.

00:08:09.860 --> 00:08:13.480
Also, keep in mind indeterminate
time operations,

00:08:13.480 --> 00:08:16.080
particularly synchronous operations,
such as synchronous file

00:08:16.080 --> 00:08:19.750
system and network operations,
things where your application is going

00:08:19.750 --> 00:08:21.180
to block for a fair amount of time.

00:08:21.320 --> 00:08:24.580
You don't want to freeze
up your user interface,

00:08:24.580 --> 00:08:28.390
obviously,
while the user is waiting for some file

00:08:28.400 --> 00:08:29.930
system or network access to happen.

00:08:29.970 --> 00:08:32.200
So if you have things like
that that may block for an

00:08:32.360 --> 00:08:35.120
unpredictable amount of time,
try to make those asynchronous.

00:08:35.120 --> 00:08:37.960
And we'll look at techniques
for doing things like that.

00:08:38.300 --> 00:08:41.630
Consider caching expensive results,
where that may help.

00:08:41.680 --> 00:08:45.020
If you have something that you do,
that you compute, that you draw,

00:08:45.140 --> 00:08:48.360
that may take a lot of time and
that you may reuse many times

00:08:48.450 --> 00:08:51.060
before you have to change it again,
it may pay off to cache it.

00:08:51.560 --> 00:08:55.020
Keep in mind at the same time that
it may not pay off to cache it.

00:08:55.040 --> 00:08:59.400
If the framework, say AppKit,
is already doing some caching for you and

00:08:59.400 --> 00:09:03.580
you add your own caching on top of that,
you may find that there's not a net win,

00:09:03.590 --> 00:09:09.110
that you've actually added just
another layer of extra code that

00:09:09.120 --> 00:09:10.690
doesn't necessarily have any effect.

00:09:10.700 --> 00:09:14.040
So you want to measure to see
whether the caching actually helps.

00:09:14.070 --> 00:09:16.580
But in general,
caching can be a useful technique.

00:09:16.600 --> 00:09:20.440
Also, lastly, consider deferring
operations when you can.

00:09:20.440 --> 00:09:21.320
And this is a good one.

00:09:21.320 --> 00:09:23.080
This is an interesting
and powerful technique,

00:09:23.080 --> 00:09:25.840
and so I'll go into a little more detail.

00:09:25.900 --> 00:09:28.830
Think about deferring operations.

00:09:29.440 --> 00:09:32.220
The benefits of deferring
operations include not having,

00:09:32.220 --> 00:09:34.570
obviously, not having to perform an
operation immediately.

00:09:34.630 --> 00:09:37.150
If you don't need the result right away,
well, maybe you don't have to perform

00:09:37.240 --> 00:09:38.170
the operation right away.

00:09:38.210 --> 00:09:40.270
Maybe you just need to
make a note somewhere that,

00:09:40.470 --> 00:09:41.970
hey, I need to compute this later.

00:09:41.980 --> 00:09:45.450
You obviously then don't incur the
cost of the operation right now.

00:09:45.460 --> 00:09:49.820
And if you have a number of requests,
a series of requests,

00:09:49.820 --> 00:09:52.080
that come in maybe from
different parts of the system

00:09:52.080 --> 00:09:55.350
to perform that given operation,
but they don't need the, again,

00:09:55.350 --> 00:09:58.660
don't need the result immediately,
you may be able to save doing

00:09:58.670 --> 00:10:02.040
that operation several times
by coalescing those requests,

00:10:02.040 --> 00:10:03.480
just setting that flag.

00:10:03.480 --> 00:10:06.240
And every time you set that flag, well,
it's a constant time operation,

00:10:06.240 --> 00:10:07.160
and it's really cheap.

00:10:07.310 --> 00:10:09.200
And then later,
when you actually need the result,

00:10:09.200 --> 00:10:11.000
you can go back and say, oh,
I need to compute this.

00:10:11.000 --> 00:10:13.880
And there you've got it,
and you only compute it once

00:10:13.880 --> 00:10:14.910
instead of several times.

00:10:14.940 --> 00:10:18.550
Lastly, if you're really lucky,
you may never have to incur

00:10:18.550 --> 00:10:21.640
the cost of the operation at
all if the result isn't needed.

00:10:21.640 --> 00:10:24.390
So try to think as you're
coding about whether what you're

00:10:24.390 --> 00:10:25.960
computing really needs to be done.

00:10:25.960 --> 00:10:26.880
Is this really necessary?

00:10:27.100 --> 00:10:27.640
Right now.

00:10:27.660 --> 00:10:30.660
Now, on the flip side,
one of the costs of this

00:10:30.660 --> 00:10:33.880
is that when you do ask,
when some part of the application

00:10:33.900 --> 00:10:37.020
does ask for the result later,
it's not going to be there ready to go.

00:10:37.020 --> 00:10:39.180
The computation has to be done then.

00:10:39.310 --> 00:10:41.020
So obviously,
you want to use some discretion

00:10:41.020 --> 00:10:43.980
in applying this technique,
but it is very useful and powerful.

00:10:43.980 --> 00:10:47.240
We use it, for example,
in the app kit when we're drawing views.

00:10:47.300 --> 00:10:49.940
You're familiar probably
with the set needs display

00:10:49.940 --> 00:10:52.180
mechanism that we recommend.

00:10:52.180 --> 00:10:54.920
Rather than asking views to
display themselves immediately,

00:10:54.980 --> 00:10:58.320
you tell them, hey,
you're dirty in this area.

00:10:58.320 --> 00:10:59.440
You're going to need to draw here.

00:10:59.440 --> 00:11:02.670
And you can have potentially many
requests to mark different parts

00:11:02.670 --> 00:11:05.340
of the view dirty as needing
display at some later point.

00:11:05.430 --> 00:11:08.070
And all that drawing doesn't
happen normally until you

00:11:08.070 --> 00:11:10.570
get back to the run loop,
to the top of the run loop.

00:11:10.610 --> 00:11:13.020
And then we look and say, oh,
it's part of the window dirty.

00:11:13.040 --> 00:11:15.040
Yeah, OK, we've got to redraw the parts
of the window that are dirty.

00:11:15.060 --> 00:11:16.290
But we can do it all at once.

00:11:16.380 --> 00:11:20.660
And so we can have thousands of requests
to dirty different parts of the window

00:11:20.690 --> 00:11:22.540
satisfied by a single drawing pass.

00:11:22.570 --> 00:11:25.320
Similarly, in your own applications,
if you break your

00:11:25.320 --> 00:11:29.160
application into components,
if you do initialization in stages,

00:11:29.170 --> 00:11:34.540
that can be a useful way to improve
performance by deferring results,

00:11:34.540 --> 00:11:36.720
operations, till later.

00:11:36.730 --> 00:11:38.500
Lastly,
some other things to keep in mind.

00:11:38.540 --> 00:11:41.220
Some of the techniques
that I recommend here,

00:11:41.230 --> 00:11:43.740
or point out to you rather,
may not be appropriate

00:11:43.760 --> 00:11:46.440
in certain situations,
may actually degrade performance.

00:11:46.460 --> 00:11:49.210
And the only way you can really know,
although our intuition as

00:11:49.210 --> 00:11:52.660
engineers is very useful,
the only way you can really know

00:11:52.770 --> 00:11:56.620
whether an attempted optimization has
had a positive effect is to measure.

00:11:56.620 --> 00:12:00.380
And remember to not just measure after,
but measure before,

00:12:00.390 --> 00:12:03.920
so you have something to compare with.

00:12:03.950 --> 00:12:05.860
That's the only way to
really know whether you've

00:12:05.860 --> 00:12:07.000
made things better or worse.

00:12:07.000 --> 00:12:09.370
And often the result is surprising.

00:12:09.460 --> 00:12:11.840
So along these lines,
we provide some very powerful

00:12:11.840 --> 00:12:14.230
tools for you to use,
including Shark,

00:12:14.330 --> 00:12:16.920
which is covered in another session.

00:12:16.960 --> 00:12:19.780
Any of you who are here right
now and not in the Shark session,

00:12:19.780 --> 00:12:22.040
I recommend looking into
Shark on your own later.

00:12:22.040 --> 00:12:24.390
It's a very powerful tool,
enables you to sample not

00:12:24.410 --> 00:12:27.010
just your application,
but performance of the entire

00:12:27.010 --> 00:12:28.520
system while your app is running.

00:12:28.540 --> 00:12:32.190
Also, if you happen to be using OpenGL,
OpenGL Profiler is a tremendously

00:12:32.270 --> 00:12:33.800
powerful tool in getting better.

00:12:33.950 --> 00:12:38.180
So be aware of these tools and use
them to measure to find out what's

00:12:38.180 --> 00:12:40.230
really going on in your apps.

00:12:41.110 --> 00:12:43.660
So OK, now we're ready to get-- we're
in the right frame of mind.

00:12:43.660 --> 00:12:46.650
We're ready to get into
Cocoa in particular.

00:12:46.970 --> 00:12:49.500
I'm going to divide the rest of
the talk into two general parts.

00:12:49.580 --> 00:12:51.710
First,
we'll look at optimization techniques

00:12:51.720 --> 00:12:56.530
and API usage techniques that apply
to the APIs that AppKit provides.

00:12:56.720 --> 00:13:01.410
And then we're going to dive deeper and
look at some foundation-related issues.

00:13:01.780 --> 00:13:04.920
So first, the AppKit-related stuff,
things that I refer to

00:13:04.920 --> 00:13:07.450
as user interface issues.

00:13:07.730 --> 00:13:09.910
and a number of techniques
I want to cover with you today,

00:13:09.930 --> 00:13:13.360
including reducing launch time,
taking long operations,

00:13:13.360 --> 00:13:15.760
as I was saying earlier,
making them asynchronous,

00:13:15.790 --> 00:13:19.660
optimizing drawing and
scrolling in various ways,

00:13:19.660 --> 00:13:21.550
and so forth.

00:13:23.080 --> 00:13:24.580
So what about reducing launch time?

00:13:24.580 --> 00:13:27.690
This isn't exactly, maybe strictly,
an optimization technique.

00:13:27.770 --> 00:13:32.600
This is a matter more of
deferring operations until later.

00:13:32.600 --> 00:13:35.360
You can actually use
both techniques here.

00:13:35.420 --> 00:13:37.680
Remember that the user's
experience of using your app

00:13:37.750 --> 00:13:39.860
begins with launching the app.

00:13:39.920 --> 00:13:42.180
The sooner your application
can be ready to go,

00:13:42.180 --> 00:13:44.180
the happier your user is going to be.

00:13:44.400 --> 00:13:46.640
So there are a number of ways
you can reduce launch time.

00:13:46.640 --> 00:13:48.860
Obviously,
brute force-- if there are things

00:13:48.860 --> 00:13:52.160
that you do at launch time and you
can optimize them to run faster,

00:13:52.160 --> 00:13:55.040
well, obviously, that's one way to do it.

00:13:55.090 --> 00:13:58.680
If you can defer loading of data,
initializing different subsystems--

00:13:58.680 --> 00:14:02.060
if your app has a lot of different
subsystems and maybe your user isn't

00:14:02.060 --> 00:14:06.920
going to touch them immediately,
certain features they may not use even in

00:14:07.090 --> 00:14:10.870
the session of launching the application,
using it,

00:14:11.110 --> 00:14:14.780
and quitting it-- you can actually
defer initialization of those

00:14:14.780 --> 00:14:17.100
subsystems if it's costly until later.

00:14:17.100 --> 00:14:18.920
And one technique you
can use for doing this,

00:14:18.920 --> 00:14:21.310
you can use nib files
and plug-in bundles.

00:14:21.320 --> 00:14:23.990
These are two very powerful
capabilities and facilities that

00:14:24.460 --> 00:14:28.490
Cocoa provides for factoring your
user interface and your code.

00:14:28.500 --> 00:14:32.610
You can actually dynamically
load code in bundles at runtime.

00:14:32.740 --> 00:14:36.700
You can factor your application into
components that are loaded in as needed.

00:14:36.740 --> 00:14:40.840
And that also, incidentally,
provides a way for other developers to

00:14:40.920 --> 00:14:42.960
be able to extend your applications,
potentially.

00:14:43.070 --> 00:14:45.230
So plug-ins are great.

00:14:46.320 --> 00:14:49.160
Where you perform your
initialization may be important.

00:14:49.240 --> 00:14:51.950
You all know Awake from Nib--
this is our friend-- when we

00:14:52.100 --> 00:14:58.090
instantiate objects in Nib files,
and we load those Nib files at runtime,

00:14:58.320 --> 00:15:02.250
Awake from Nib is sent to every
object at a stage after all of

00:15:02.250 --> 00:15:04.750
the objects' interconnections,
as were made in the Nib,

00:15:04.800 --> 00:15:05.740
have been established.

00:15:05.770 --> 00:15:08.400
And the network of objects is intact.

00:15:08.590 --> 00:15:09.860
They're ready to go and wired up.

00:15:09.980 --> 00:15:14.260
That's usually a very good and convenient
time to perform initialization.

00:15:14.330 --> 00:15:17.920
One thing about that is that
Awake from Nib is usually sent,

00:15:18.000 --> 00:15:21.140
say, for your main menu Nib,
or for your document Nib,

00:15:21.140 --> 00:15:23.280
if you're writing a document-based app.

00:15:23.350 --> 00:15:25.980
That's sent before the
UI is brought on screen.

00:15:26.100 --> 00:15:29.440
So any initialization that you do
there is going to make the user wait,

00:15:29.600 --> 00:15:31.480
potentially, if it takes a long time.

00:15:31.520 --> 00:15:34.300
A lesser-known place to perform
initialization that's very useful

00:15:34.300 --> 00:15:36.820
is ApplicationDidFinishLaunching.

00:15:36.880 --> 00:15:39.930
This is a message that is sent
either to the application's delegate,

00:15:39.930 --> 00:15:45.010
if it has one, or to any observer,
any object that registers as an observer

00:15:45.010 --> 00:15:48.840
of the NSApplicationDidFinishLaunching
notification.

00:15:48.960 --> 00:15:52.830
It is sent significantly after
the UI is already on screen,

00:15:53.040 --> 00:15:56.180
after any files that were
requested to be open when the app

00:15:56.260 --> 00:15:59.540
was launched have been opened,
and the run loop is ready

00:15:59.540 --> 00:16:00.760
to begin handling events.

00:16:00.760 --> 00:16:01.910
Your app is ready to go.

00:16:01.920 --> 00:16:06.440
So if there's initialization
operations you can perform later

00:16:06.440 --> 00:16:10.420
at ApplicationDidFinishLaunching,
that's a useful place to hook in.

00:16:11.000 --> 00:16:14.440
What about long blocking operations
that may block your user interface?

00:16:14.500 --> 00:16:18.780
Remember, in a Cocoa application,
by default, unless you do otherwise,

00:16:18.850 --> 00:16:23.320
you basically have one thread on which
everything happens-- your event handling,

00:16:23.480 --> 00:16:26.570
your drawing,
any processing that your application

00:16:26.570 --> 00:16:30.490
does when I click this button over here,
and so forth.

00:16:30.680 --> 00:16:35.260
And so any long synchronous operation
that you perform is performed

00:16:35.260 --> 00:16:38.990
on the main thread and blocks
your user interface normally.

00:16:39.600 --> 00:16:41.700
So there are a couple of
ways to deal with this.

00:16:41.760 --> 00:16:45.030
We can make the operation take less time,
again, obviously.

00:16:45.150 --> 00:16:48.180
Or you can use any of various
techniques to move the

00:16:48.180 --> 00:16:50.300
operation into the background.

00:16:50.350 --> 00:16:53.270
And a few of the facilities
that we provide for doing this

00:16:53.360 --> 00:16:56.120
are asynchronous notifications,
which are also sometimes

00:16:56.120 --> 00:16:59.320
called idle timers,
run loop observers, and threads.

00:16:59.430 --> 00:17:01.770
Let's look at those in some detail.

00:17:03.350 --> 00:17:06.600
Asynchronous notifications are
simply notifications that are

00:17:06.640 --> 00:17:08.000
added to a notification queue.

00:17:08.000 --> 00:17:12.660
They are enqueued with the
posting style of post when idle.

00:17:12.720 --> 00:17:15.850
These notifications are handled
when the run loop figures out that

00:17:15.850 --> 00:17:19.100
the application is sitting idle
and there's time to do something.

00:17:19.100 --> 00:17:21.420
It's just sitting there spinning,
waiting for something

00:17:21.420 --> 00:17:22.820
interesting to happen.

00:17:22.850 --> 00:17:25.730
Optionally, you can ask for such
notifications to be coalesced.

00:17:25.790 --> 00:17:29.310
So if there are a number of different
places you want to post them from to

00:17:29.310 --> 00:17:34.310
stimulate this idle activity to happen,
whatever activity you've designated to

00:17:34.310 --> 00:17:39.950
happen in response to the notification,
you can have them coalesced

00:17:39.970 --> 00:17:44.380
either on name or on the
notification sender on the poster.

00:17:45.530 --> 00:17:48.980
Another powerful technique that exists
actually in core foundation-- remember,

00:17:48.980 --> 00:17:55.120
you can use core foundation from your
Cocoa apps-- is the CFRunLoop observer.

00:17:55.170 --> 00:17:58.500
And what this lets you do is
hook into not just your run loop,

00:17:58.710 --> 00:18:01.990
but at the idle time point,
but at any point you want, really.

00:18:02.000 --> 00:18:05.110
And we have a number of different
options here on entry to the run loop,

00:18:05.210 --> 00:18:08.560
before timers are handled, and so forth.

00:18:08.830 --> 00:18:10.590
So you can hook in-- actually,
this is a mask.

00:18:10.650 --> 00:18:14.060
So you can specify several different
places that you want to hook in.

00:18:14.130 --> 00:18:17.720
And it's basically a mechanism for you
to provide a callback function that

00:18:17.720 --> 00:18:21.210
will be called when the run loop reaches
these various stages of processing.

00:18:21.390 --> 00:18:23.520
And then you can do
whatever you want there.

00:18:23.590 --> 00:18:25.280
Well,
these are two very powerful techniques.

00:18:25.280 --> 00:18:28.420
But obviously, they're still doing their
processing on the main thread.

00:18:28.450 --> 00:18:31.740
They're maybe a little more friendly
to responsiveness of the application,

00:18:31.740 --> 00:18:34.330
because they're letting you do
things sort of when the application

00:18:34.450 --> 00:18:35.580
figures out that it's idle.

00:18:35.670 --> 00:18:38.840
And if you don't do your
operations in two big chunks,

00:18:38.840 --> 00:18:40.910
then you're OK.

00:18:40.990 --> 00:18:44.480
But what if you have a long operation,
and there's no two ways about it?

00:18:44.580 --> 00:18:48.900
You've got to find another way to do it,
and keep it from disturbing your UI.

00:18:48.960 --> 00:18:52.310
Another possibility is to
use a background thread.

00:18:52.510 --> 00:18:53.780
spin off another thread.

00:18:53.790 --> 00:18:56.940
This is supported through
the NSThread class,

00:18:56.940 --> 00:19:00.260
and in particular,
is very easy to do in Cocoa.

00:19:00.260 --> 00:19:04.980
The hard part, as with multi-threaded
programming on any platform,

00:19:05.020 --> 00:19:08.120
is getting synchronization right
and synchronizing object accesses

00:19:08.120 --> 00:19:09.300
and getting thread safety.

00:19:09.300 --> 00:19:11.340
But spinning off the thread is very easy.

00:19:11.340 --> 00:19:14.740
NSThread provides the detached
new thread selector method.

00:19:14.740 --> 00:19:17.510
You specify a message
that you want to send,

00:19:17.510 --> 00:19:18.940
the target object.

00:19:18.940 --> 00:19:22.480
You can optionally specify a
parameter object to be passed in.

00:19:22.500 --> 00:19:27.580
And then here we have a method
that basically is the thread.

00:19:27.580 --> 00:19:28.400
It becomes the thread.

00:19:28.400 --> 00:19:32.500
When the thread is spun off,
that method begins execution,

00:19:32.500 --> 00:19:36.490
and that method can run
forever if it expects to exist,

00:19:36.490 --> 00:19:38.630
if it wants to exist for
the lifetime of the app,

00:19:38.750 --> 00:19:41.230
or it can quit out if
it's done processing,

00:19:41.230 --> 00:19:43.620
and then that terminates the thread.

00:19:45.140 --> 00:19:49.830
And one thing that you want to do here
is put an auto-release pool in there so

00:19:49.840 --> 00:19:54.070
that any objects that you auto-release
during the course of processing in your

00:19:54.080 --> 00:19:56.210
background thread do get cleaned up.

00:19:56.290 --> 00:19:58.840
Otherwise, you're going to get
messages in the console.

00:19:58.840 --> 00:20:00.460
When you're just doing
main thread programming,

00:20:00.460 --> 00:20:03.740
you get an auto-release pool for free
that's automatically provided for you.

00:20:03.840 --> 00:20:06.090
So we'll see that again.

00:20:07.270 --> 00:20:10.110
So as I said,
the main thing to do when you are

00:20:10.290 --> 00:20:13.300
doing multi-threaded programming,
you have to make sure that no

00:20:13.580 --> 00:20:17.160
two threads are simultaneously
accessing and especially trying

00:20:17.160 --> 00:20:19.190
to mutate a given object.

00:20:19.540 --> 00:20:22.920
We provide locking semantics for that.

00:20:22.950 --> 00:20:25.550
And another thing that you need
to do when you're doing the

00:20:25.700 --> 00:20:27.880
processing in a background thread,
obviously your main thread at

00:20:27.880 --> 00:20:29.350
some point wants to know about,
well,

00:20:29.360 --> 00:20:31.090
what were the results of that processing?

00:20:31.100 --> 00:20:33.300
They usually affect
something on the main thread,

00:20:33.300 --> 00:20:33.930
maybe some UI.

00:20:34.120 --> 00:20:37.800
And you need a way to communicate
back to your main thread what the

00:20:37.800 --> 00:20:43.330
results of that processing was and
maybe even some intermediate results.

00:20:43.480 --> 00:20:45.140
So there are various ways to do that.

00:20:45.170 --> 00:20:49.320
The easiest way to do it is to use
performSelector on main thread.

00:20:49.590 --> 00:20:52.770
This is a method that's defined
in a category on NSObject.

00:20:52.880 --> 00:20:55.940
You'll find it's hidden
away in nsthread.h.

00:20:55.940 --> 00:20:58.610
If you don't know about it,
this is a great, powerful method.

00:20:58.620 --> 00:21:01.900
And what it enables you to do is not
just send a message to the main thread,

00:21:02.070 --> 00:21:04.940
but it schedules your message
so that it's performed.

00:21:04.940 --> 00:21:06.580
It doesn't interrupt the
main thread while it's in the

00:21:06.580 --> 00:21:07.800
middle of doing something else.

00:21:07.800 --> 00:21:12.320
And so you can pass objects across
thread boundaries fairly safely.

00:21:12.350 --> 00:21:14.960
So this is interesting stuff.

00:21:14.960 --> 00:21:17.270
And to go into this further,
let's see what we have

00:21:17.400 --> 00:21:19.580
cooking on demo one.

00:21:29.390 --> 00:21:35.760
So here I have a document-based
application that I call Scrapbook.

00:21:36.230 --> 00:21:37.380
And it's fairly simple.

00:21:37.610 --> 00:21:39.980
Got my model view
controller divisions here.

00:21:40.030 --> 00:21:44.010
Basically what it does is it gives
you a page on which you're able

00:21:44.040 --> 00:21:46.640
to arrange a number of photos.

00:21:46.670 --> 00:21:51.480
And you have a page view that you
can use to see that and visualize it.

00:21:51.580 --> 00:21:52.680
So let's see.

00:21:52.690 --> 00:21:55.070
I've launched the application.

00:22:01.740 --> 00:22:02.940
is a clean new document.

00:22:02.940 --> 00:22:05.700
Let's drag some pictures in.

00:22:05.700 --> 00:22:09.960
And it loads them up,
and we can drag them

00:22:10.190 --> 00:22:12.280
around and move them.

00:22:12.640 --> 00:22:15.390
Simple document-based application.

00:22:16.710 --> 00:22:20.880
And this is a custom NS view that
I simply wrote that displays the

00:22:20.880 --> 00:22:23.510
photos when it's asked to draw.

00:22:34.290 --> 00:22:34.290
Hi, everyone.

00:22:34.290 --> 00:22:34.290
I'm Troy Stephens.

00:22:34.290 --> 00:22:34.290
I'm the founder of
Cocoa Performance Techniques.

00:22:35.280 --> 00:22:35.800
It's loading it.

00:22:35.900 --> 00:22:36.900
Oh, there it goes.

00:22:36.920 --> 00:22:38.940
Well, that took a little while.

00:22:38.970 --> 00:22:40.870
Let's try that again.

00:22:41.120 --> 00:22:43.450
Drag the document down.

00:22:45.510 --> 00:22:46.920
It took a few seconds to do it.

00:22:46.940 --> 00:22:50.300
Now we're running, fortunately,
on a dual-proc 2 gigahertz G5 here,

00:22:50.300 --> 00:22:52.920
but you can imagine easily on
a machine that's more memory

00:22:52.920 --> 00:22:56.120
constrained or that's slower that
this could take a lot more time.

00:22:56.230 --> 00:22:58.680
And especially if we only
have two dozen photos here,

00:22:58.740 --> 00:22:59.970
that's not a whole lot.

00:23:00.060 --> 00:23:07.800
So how could we make this a more
satisfying experience for the user?

00:23:07.800 --> 00:23:09.810
How can we make it so that the
document comes up more immediately?

00:23:13.490 --> 00:23:14.900
Sure we can.

00:23:14.930 --> 00:23:17.240
And in fact,
here we have a multi-threaded

00:23:17.240 --> 00:23:19.860
version of Scrapbook that's
not much more complicated.

00:23:19.950 --> 00:23:24.720
And when I run it--

00:23:29.200 --> 00:23:59.300
[Transcript missing]

00:23:59.600 --> 00:24:00.100
Here we go.

00:24:00.100 --> 00:24:04.150
And we just display a placeholder
image in place of each image until

00:24:04.150 --> 00:24:06.640
the image arrives on the main thread.

00:24:06.670 --> 00:24:09.480
And if I do this fast enough,
I can even grab the window,

00:24:09.480 --> 00:24:13.610
start resizing and interacting with
it while the images are still loading.

00:24:17.490 --> 00:24:18.770
So let's look at the code for that.

00:24:18.850 --> 00:24:21.680
It's fairly simple.

00:24:21.700 --> 00:24:25.320
Any venture into multi-threaded
programming comes with certain warnings

00:24:25.320 --> 00:24:28.420
about how complicated it can be to get
it right and to not have your app crash.

00:24:28.480 --> 00:24:30.180
But this is, in fact,
not very complicated.

00:24:30.180 --> 00:24:33.810
I've got a background bitmap loader
class that's simply a subclass

00:24:33.810 --> 00:24:36.300
of NSObject that I created here.

00:24:36.320 --> 00:24:41.540
It's got as its attributes a
path queue that keeps track of--

00:24:41.540 --> 00:24:42.720
this is basically its to-do list.

00:24:42.760 --> 00:24:45.980
These are the paths of the image
files that I'm supposed to load.

00:24:46.010 --> 00:24:50.590
We've got a lock that we use to
ensure safe access to the path queue.

00:24:50.620 --> 00:24:53.500
So any time some code
accesses the path queue,

00:24:53.520 --> 00:24:56.300
it takes this lock and then
releases the lock when it's done.

00:24:56.340 --> 00:25:00.320
I've got a simple flag here to keep
track of whether the thread is running,

00:25:00.480 --> 00:25:03.740
because I don't start it immediately
when I create the object.

00:25:03.770 --> 00:25:06.750
And now we've got a delegate here,
which is our connection back to

00:25:06.750 --> 00:25:08.080
the object on the main thread.

00:25:08.080 --> 00:25:10.040
In this case,
I've chosen the document object

00:25:10.440 --> 00:25:14.290
as the object that receives
the images as they're loaded.

00:25:15.350 --> 00:25:18.640
So you create this
object with a delegate.

00:25:18.640 --> 00:25:20.260
You can set its delegate.

00:25:20.310 --> 00:25:23.260
And when you want to load an image,
we create one instance of

00:25:23.260 --> 00:25:24.940
the background bitmap loader.

00:25:24.990 --> 00:25:27.250
When we want to load an image,
we send this request

00:25:27.350 --> 00:25:30.870
bitmap at path message,
send it the path, and that returns

00:25:30.920 --> 00:25:35.280
immediately to the caller,
has stuck the path in the queue already,

00:25:35.330 --> 00:25:38.100
and it's on its to-do
list for images to load.

00:25:38.160 --> 00:25:41.750
We also wanted to have a cancel all
requests message that I can send

00:25:41.750 --> 00:25:44.590
so that if we close the document,
let's say,

00:25:44.720 --> 00:25:47.860
before all the images are done loading,
we want to be able to safely abort out

00:25:47.860 --> 00:25:52.200
of this so that we're not messaging
back to a non-existent document object.

00:25:52.260 --> 00:25:54.550
And in the implementation--

00:25:56.970 --> 00:26:00.830
The interesting methods here,
request bitmap at path.

00:26:00.980 --> 00:26:04.690
As I said, we take the lock on the path
queue before we manipulate it.

00:26:04.770 --> 00:26:07.400
We add the object,
add the path to the path queue.

00:26:07.690 --> 00:26:11.320
I actually make a copy
here to be completely safe.

00:26:12.060 --> 00:26:16.140
The interesting methods here,
request bitmap at path.

00:26:16.140 --> 00:26:19.940
As I said, we take the lock on the path
queue before we manipulate it.

00:26:19.940 --> 00:26:22.830
We add the object,
add the path to the path queue.

00:26:22.840 --> 00:26:26.440
I actually make a copy
here to be completely safe.

00:26:34.970 --> 00:26:37.790
Similarly, for later,
when we want to cancel all requests,

00:26:37.790 --> 00:26:40.620
all we do is take the lock,
drain the queue of all the

00:26:40.870 --> 00:26:44.120
paths that have been queued up,
and release the lock.

00:26:44.320 --> 00:26:46.500
So this is the workhorse
method of the thread,

00:26:46.500 --> 00:26:48.500
load queued images.

00:26:48.560 --> 00:26:50.720
We create an auto-release pool
here to make sure auto-released

00:26:50.800 --> 00:26:55.420
objects are automatically taken
care of once the method exits.

00:26:55.420 --> 00:26:59.380
And then I've got a loop here where
I basically go until I run out of paths.

00:26:59.440 --> 00:27:02.610
Each time through the loop,
I look and see if I have

00:27:02.610 --> 00:27:03.960
another path to process.

00:27:03.960 --> 00:27:07.310
I've got to take the lock on the
path queue before I touch it.

00:27:07.580 --> 00:27:12.010
I grab the next path in the queue,
remove it, and unlock the queue,

00:27:12.060 --> 00:27:13.040
because I'm done with the queue.

00:27:13.040 --> 00:27:17.260
So the main thread is now
free to add requests to it.

00:27:17.460 --> 00:27:21.220
And now, if I've got a path,
if the queue isn't empty now,

00:27:21.220 --> 00:27:26.300
I go ahead and basically load my
bitmap image rep using NSDatas in

00:27:26.300 --> 00:27:29.900
it with contents of file,
and then NSBitmapImageReps

00:27:30.100 --> 00:27:31.640
in it with data.

00:27:31.790 --> 00:27:34.630
I check whether I still have a delegate,
and whether the delegate knows

00:27:34.630 --> 00:27:35.660
how to handle this message.

00:27:35.660 --> 00:27:38.320
And I message it back by
sending it-- because I don't

00:27:38.320 --> 00:27:39.360
want to just send it the image.

00:27:39.360 --> 00:27:43.170
It's going to get the image and say,
well, yeah, OK, which image is that?

00:27:43.250 --> 00:27:45.120
I want to send it also
the path to the image.

00:27:45.140 --> 00:27:47.500
So I just wrap those up in a dictionary.

00:27:47.660 --> 00:27:48.950
Let's see.

00:27:48.990 --> 00:27:51.330
I need some code wrap here.

00:27:58.710 --> 00:27:58.740
All right.

00:27:58.750 --> 00:27:58.820
Yes, I mean now.

00:27:58.820 --> 00:28:01.300
Okay, that's much better.

00:28:01.300 --> 00:28:02.200
So I create a dictionary.

00:28:02.200 --> 00:28:06.000
And the only sort of unusual thing to
notice here that I'm doing is in terms

00:28:06.000 --> 00:28:10.240
of the normal object ownership rules,
usually you hand something off to another

00:28:10.240 --> 00:28:13.440
method and you want to auto-release
it so that you've discharged yourself

00:28:13.450 --> 00:28:15.200
of responsibility for releasing it.

00:28:15.210 --> 00:28:18.260
But when you're passing an
object across thread boundaries,

00:28:18.260 --> 00:28:21.800
you kind of want to make sure that
that object's still going to be around

00:28:21.800 --> 00:28:26.850
by the time the other thread grabs
hold of it and retains it and so forth.

00:28:26.860 --> 00:28:30.200
So I'm sidestepping the usual rules
and I'm alloc-initing this dictionary

00:28:30.200 --> 00:28:34.020
and I'm passing it across using
perform selector on main thread.

00:28:34.220 --> 00:28:36.730
I tell the object on the main thread,
the delegate,

00:28:36.850 --> 00:28:39.800
the bitmap has been loaded and
here's the dictionary that has

00:28:39.800 --> 00:28:42.520
the path and the bitmap itself.

00:28:42.520 --> 00:28:49.110
Wait until done basically says return
immediately as soon as you register this

00:28:49.210 --> 00:28:51.740
message to be sent on the main thread.

00:28:51.740 --> 00:28:53.810
Just come back immediately.

00:28:53.870 --> 00:28:56.010
It's safe to do because I've
already made the bitmap info.

00:28:56.020 --> 00:28:56.020
It's safe to do.

00:28:56.020 --> 00:28:57.780
It's got a retain count of one.

00:28:57.780 --> 00:29:02.120
It's going to stick around until the
main thread takes responsibility for it.

00:29:02.170 --> 00:29:02.950
And then that's it.

00:29:02.960 --> 00:29:06.190
Once I've handed off,
I can let go of the bitmap, the data,

00:29:06.190 --> 00:29:07.120
and the path.

00:29:09.080 --> 00:29:11.470
And I'm also using an inner
auto-release pool here,

00:29:11.470 --> 00:29:13.660
because I may be loading
hundreds of images.

00:29:13.660 --> 00:29:16.890
This is an important point when you're
writing a secondary thread method,

00:29:16.890 --> 00:29:19.290
is that I'm loading
potentially many images.

00:29:19.300 --> 00:29:20.080
I don't know how many.

00:29:20.080 --> 00:29:20.600
It could be hundreds.

00:29:20.670 --> 00:29:21.230
It could be thousands.

00:29:21.240 --> 00:29:25.640
And if I'm auto-releasing things,
I could end up filling up memory

00:29:25.640 --> 00:29:29.090
with all these images that have been
handed off and are still sitting

00:29:29.100 --> 00:29:30.720
there waiting to be auto-released.

00:29:30.850 --> 00:29:34.140
So what I want to do is clean up
each time through the iteration.

00:29:34.140 --> 00:29:37.000
You don't necessarily have to do
this every time through an iteration.

00:29:37.170 --> 00:29:39.000
You might,
if you're doing 10,000 iterations,

00:29:39.030 --> 00:29:42.020
do 100 iterations of 100 and
have an inner auto-release

00:29:42.140 --> 00:29:43.980
pool only in the inner loop.

00:29:43.980 --> 00:29:47.450
But basically, every time we hit this
inner pool release,

00:29:47.500 --> 00:29:49.680
we're going to clean up any
auto-released objects that were

00:29:50.690 --> 00:29:53.350
created during the course of that loop.

00:29:55.520 --> 00:29:58.640
So that's the most
interesting part of it.

00:29:58.690 --> 00:30:02.990
In the photo object itself,
where we used to load

00:30:03.000 --> 00:30:05.420
the image immediately,
we simply load a placeholder image

00:30:05.480 --> 00:30:08.000
that's small and quick to load,
and it's only loaded once because

00:30:08.080 --> 00:30:09.000
it's part of our resources.

00:30:09.000 --> 00:30:14.850
And in the page view itself--

00:30:20.600 --> 00:30:26.160
Oops, I'm sorry,
in the document class itself,

00:30:26.200 --> 00:30:30.460
we have the bitmap loaded method
that receives this dictionary.

00:30:30.460 --> 00:30:33.340
This is the other side of the gate,
and this receives the dictionary

00:30:33.340 --> 00:30:35.040
passed off by the secondary thread.

00:30:35.340 --> 00:30:36.250
It's handed off to us.

00:30:36.260 --> 00:30:39.160
We get the path and the photo
that are in the dictionary.

00:30:39.380 --> 00:30:45.210
And basically all we have to do here
is identify the photo model object that

00:30:45.490 --> 00:30:48.050
that image belongs to and assign it.

00:30:48.160 --> 00:30:51.390
And then we tell the page view, hey,
you've got to redisplay this photo

00:30:51.390 --> 00:30:52.910
because something's changed about it.

00:30:53.090 --> 00:30:53.820
And that's that.

00:30:53.840 --> 00:30:58.330
We've got a multi-threaded
version of our scrapbook app

00:30:58.420 --> 00:30:59.650
without a whole lot of effort.

00:30:59.790 --> 00:31:01.220
Let's go back to the slides if we could.

00:31:01.340 --> 00:31:05.700
Is this going to be a wait-and-fill?

00:31:05.760 --> 00:31:07.660
It will be eventually.

00:31:11.290 --> 00:31:13.900
So what are some other techniques
you can use that relate to

00:31:13.900 --> 00:31:17.270
AppKit components and facilities?

00:31:18.000 --> 00:35:20.300
[Transcript missing]

00:35:21.340 --> 00:35:23.650
Here's a real simple, cheap optimization.

00:35:23.660 --> 00:35:27.300
This is an easy one-liner you
can add to your custom views.

00:35:27.350 --> 00:35:29.860
And the reason for the existence
of the isOpaque method,

00:35:29.860 --> 00:35:33.660
I should point out, is that by default,
AppKit cannot assume that a view

00:35:33.660 --> 00:35:38.070
will draw with complete opaque
coverage of its background.

00:35:38.410 --> 00:35:42.210
Our Aqua widgets are often
non-rectangular in shape.

00:35:42.290 --> 00:35:44.560
They have nice rounded
corners and so forth.

00:35:44.560 --> 00:35:47.710
So this is less an issue of
transparency as of coverage.

00:35:47.800 --> 00:35:50.720
Basically, this is saying,
if I'm not opaque,

00:35:50.830 --> 00:35:55.110
if I'm a custom view and I'm not opaque,
I'm saying that I may need some of the

00:35:55.110 --> 00:35:59.750
background provided by the views higher
up than me and the window background

00:35:59.820 --> 00:36:02.010
to show through to complete my drawing.

00:36:02.110 --> 00:36:05.160
I only draw some stuff on top of that.

00:36:05.210 --> 00:36:07.260
If you don't need the
background to show through,

00:36:07.260 --> 00:36:08.570
declare yourself to be opaque.

00:36:08.690 --> 00:36:11.240
This saves AppKit from drawing
all the stuff behind your view.

00:36:11.240 --> 00:36:15.490
If you've got this huge document view in
particular that's covering your window,

00:36:15.610 --> 00:36:17.420
if you don't make it opaque,
we're going to think, OK,

00:36:17.430 --> 00:36:19.200
we've got to draw the
window background behind it.

00:36:19.200 --> 00:36:20.440
OK, now we've got to draw your view.

00:36:20.440 --> 00:36:21.500
We don't know that you're covering it.

00:36:21.500 --> 00:36:23.500
We don't know what you're
doing in your draw rect.

00:36:23.670 --> 00:36:25.460
So be opaque when you can.

00:36:25.460 --> 00:36:27.380
Also,
when your draw rect method is called,

00:36:27.380 --> 00:36:28.220
draw minimally.

00:36:28.310 --> 00:36:31.910
Try to draw only what
we're asking you to draw.

00:36:32.740 --> 00:36:36.800
The simplest first-level optimization
you can do is simply use and observe

00:36:36.800 --> 00:36:41.990
the single rectangle parameter
that is passed to draw rect that

00:36:42.070 --> 00:36:47.040
tells you basically a bounding
box on the area that needs display.

00:36:47.040 --> 00:36:49.310
And you can use NS intersect rect,
for example,

00:36:49.450 --> 00:36:51.440
to test against that bounding box.

00:36:51.440 --> 00:36:53.520
If you have a number of objects,
for example, here,

00:36:53.520 --> 00:36:55.600
drawable things that we
need to draw in our view,

00:36:55.600 --> 00:36:56.790
this is a common case.

00:36:56.940 --> 00:36:59.430
For each object,
before I go to the trouble of drawing it,

00:36:59.430 --> 00:37:03.040
which may be costly,
see if its bounding box intersects

00:37:03.040 --> 00:37:04.240
the bounding box that I've been given.

00:37:04.240 --> 00:37:06.580
If not, don't bother drawing.

00:37:07.700 --> 00:37:09.900
On Panther and Tiger,
you can further constrain

00:37:09.900 --> 00:37:10.840
drawing beyond that.

00:37:10.990 --> 00:37:13.920
Beginning in Panther,
we've been keeping a more detailed

00:37:13.920 --> 00:37:18.770
accounting than we used to of specific
regions within a view that need drawing.

00:37:18.820 --> 00:37:24.620
We can give you, if you ask for it,
a list of rectangles that are

00:37:24.620 --> 00:37:28.970
non-overlapping that specify
the area that needs to be drawn.

00:37:29.290 --> 00:37:32.370
So you can get this directly
using the getRectsBeingDrawnCount

00:37:32.540 --> 00:37:35.330
method if you want direct
access to that rectangle list.

00:37:35.460 --> 00:37:39.220
And if you use those Rects,
you can use the parameter to draw Rect.

00:37:39.340 --> 00:37:43.360
You can still use that as a bounding
box to do trivial rejection testing.

00:37:43.480 --> 00:37:45.940
You can first check your objects
against that bounding box.

00:37:45.940 --> 00:37:48.030
If they lie within it, OK, well,
maybe they're in this

00:37:48.030 --> 00:37:49.200
list of Rects somewhere.

00:37:49.380 --> 00:37:51.830
Maybe they intersect that list
of Rects and need drawing.

00:37:51.970 --> 00:37:55.330
Alternatively, in the common case,
like we had before on the previous slide,

00:37:55.330 --> 00:37:58.380
where you're just iterating over
a list of things to be drawn,

00:37:58.600 --> 00:38:00.780
you just want to test each
of those things in sequence

00:38:00.780 --> 00:38:02.880
and not do anything fancy.

00:38:02.950 --> 00:38:05.090
You can use needsToDrawRect,
which was a new method

00:38:05.090 --> 00:38:07.520
provided in Panther,
that will do all the testing

00:38:07.520 --> 00:38:09.220
against this list of Rects for you.

00:38:09.220 --> 00:38:13.870
It will do the trivial rejection
test against the bounding box.

00:38:13.990 --> 00:38:16.800
So use that.

00:38:16.860 --> 00:38:20.390
That's sort of the more modern
alternative to NSIntersectsRect

00:38:20.400 --> 00:38:21.930
that we have in this code sample.

00:38:22.110 --> 00:38:24.940
If you're doing Panther and later,
you can use that.

00:38:26.540 --> 00:38:29.230
What about speeding up window resizing?

00:38:29.250 --> 00:38:32.960
Window resizing, obviously,
is partly dependent on view drawing.

00:38:33.130 --> 00:38:36.350
Window resizing is something that
heavily exercises view drawing.

00:38:36.520 --> 00:38:40.640
When the user grabs a corner of your
resizable window and starts dragging it,

00:38:40.820 --> 00:38:43.350
basically, at the worst case,
we have to redraw the entire

00:38:43.350 --> 00:38:47.270
window for every iteration,
every step of that drag.

00:38:47.420 --> 00:38:49.500
So if it takes your
window longer to draw,

00:38:49.500 --> 00:38:55.600
you have slower updates,
then your resize is going to chunk along.

00:38:55.600 --> 00:38:57.260
On the other hand,
if you make the updates

00:38:57.260 --> 00:38:59.730
shorter and faster,
we get a higher frame rate,

00:38:59.730 --> 00:39:02.670
a much more fluid motion,
and a much more satisfying

00:39:02.670 --> 00:39:03.700
user experience.

00:39:03.860 --> 00:39:06.790
So obviously,
anything you can do to optimize

00:39:06.860 --> 00:39:10.510
view drawing will also give
you a payoff in window resize.

00:39:10.830 --> 00:39:14.080
There are also some further things
you can do specifically for the case

00:39:14.140 --> 00:39:16.610
where a window is being resized.

00:39:16.970 --> 00:39:20.270
Not just drawing your views more quickly,
but preserving view

00:39:20.270 --> 00:39:22.520
content wherever possible.

00:39:23.880 --> 00:39:26.940
One thing you can do that's
been around for a long time

00:39:27.050 --> 00:39:32.200
is the concept of live resize,
I think since the beginning of Cocoa.

00:39:32.240 --> 00:39:36.240
A view, when it's drawing itself,
can check whether it's being drawn in the

00:39:36.240 --> 00:39:41.730
middle of a window resize using the in
live resize message that's highlighted

00:39:41.800 --> 00:39:43.890
in orange up at the top there.

00:39:44.200 --> 00:39:46.700
If you are in live resize,
you may want to take advantage of the

00:39:46.700 --> 00:39:51.100
opportunity to do some less expensive
drawing than you might otherwise do.

00:39:51.100 --> 00:39:54.790
Because you're deciding, hey,
if I'm just going to be drawing a

00:39:54.910 --> 00:39:59.000
whole bunch repeatedly real fast,
maybe I don't need to be pixel exact.

00:39:59.230 --> 00:40:03.520
Maybe I can take a cheaper,
faster route and trade some

00:40:03.520 --> 00:40:06.520
accuracy for performance,
let's say.

00:40:06.680 --> 00:40:11.870
We also have view will start live resize
and view did end live resize are two

00:40:11.910 --> 00:40:16.720
methods that you can override to prepare
to enter live resize mode and prepare to

00:40:16.830 --> 00:40:18.900
do any cleanup you need to do after exit.

00:40:18.900 --> 00:40:22.080
So those are a couple of additional
hooks that you get before you're that

00:40:22.210 --> 00:40:25.560
all views get this message sent to them
before the window starts going into

00:40:25.560 --> 00:40:27.550
live resize and then after it ends.

00:40:27.580 --> 00:40:32.220
So if you need to do setup or cleanup,
that's where you would do it.

00:40:32.590 --> 00:40:36.100
In addition, on Tiger,
we've been doing some further

00:40:36.100 --> 00:40:40.550
optimizations to allow Windows to
preserve content when they're resizing.

00:40:40.600 --> 00:40:42.920
One thing you'll notice
when you resize a window,

00:40:42.970 --> 00:40:45.930
oftentimes a lot of the
pixels aren't really changing.

00:40:46.050 --> 00:40:49.160
They don't need to be redrawn,
rerendered.

00:40:49.160 --> 00:40:52.120
And to help support that,
we've added new API in

00:40:52.120 --> 00:40:54.480
Tiger on NSWindow and NSView.

00:40:54.790 --> 00:40:57.930
A window has the capability to be
put in a mode where it preserves

00:40:57.930 --> 00:41:03.100
its content during live resize,
and a view that is savvy about this

00:41:03.160 --> 00:41:08.100
mechanism can implement certain
functionality to help support it,

00:41:08.170 --> 00:41:09.010
to make it possible.

00:41:09.020 --> 00:41:11.660
This is something that propagates
down the view hierarchy.

00:41:11.820 --> 00:41:14.000
So in order for a view to
take advantage of this,

00:41:14.060 --> 00:41:18.090
all of its super views have to be clued
in and know how to use this mechanism.

00:41:18.100 --> 00:41:21.320
And we're working now actively
to optimize the various views,

00:41:21.510 --> 00:41:26.510
especially the container views in
AppKit that will help support this.

00:41:26.990 --> 00:41:33.610
And an example of how you would use this,
if you have a custom view class, My View,

00:41:34.360 --> 00:41:38.680
You override the preserves
content during live resize method.

00:41:38.680 --> 00:41:40.330
This is a simple thing like isOpake.

00:41:40.400 --> 00:41:43.140
You're just returning a bool to say, hey,
I support this feature.

00:41:43.140 --> 00:41:43.980
I'm clued in.

00:41:44.250 --> 00:41:45.160
I'm in the know.

00:41:45.240 --> 00:41:49.120
And I know what to do to help
support this live resize mode.

00:41:49.180 --> 00:41:52.440
Then you override, usually, setFrameSize.

00:41:52.440 --> 00:41:56.000
Or if you have some other tile method,
sometimes you'll override a

00:41:56.000 --> 00:41:57.920
different method to do this.

00:41:57.940 --> 00:42:01.360
But usually,
setFrameSize is a good point to do this.

00:42:01.410 --> 00:42:01.960
You hook in.

00:42:01.960 --> 00:42:04.850
You pass on the message to
super first to do whatever

00:42:04.850 --> 00:42:06.520
normally would need to be done.

00:42:06.520 --> 00:42:09.050
And then in addition,
you can check whether

00:42:09.050 --> 00:42:10.440
you're in live resize mode.

00:42:10.640 --> 00:42:13.840
This is, again,
that in live resize message.

00:42:13.860 --> 00:42:17.280
If we are in live resize,
then what we become

00:42:17.360 --> 00:42:20.160
responsible for doing,
if we have declared that

00:42:20.160 --> 00:42:24.600
we support this feature,
is dirtying the parts of myself,

00:42:24.600 --> 00:42:31.560
of the view, that will need to be redrawn
to accommodate the new size.

00:42:31.560 --> 00:42:33.660
Usually,
when you're redrawing in a window,

00:42:33.660 --> 00:42:37.360
if your view's content is pinned to
the upper left corner of the window,

00:42:37.420 --> 00:42:39.940
which is the case that
we support right now,

00:42:39.940 --> 00:42:43.210
then usually you have sort of
an L-shaped update region on the

00:42:43.210 --> 00:42:47.900
right-hand side and the bottom side as
the user is resizing the view larger.

00:42:48.190 --> 00:42:50.580
So you have these two strips
that need to be drawn.

00:42:50.820 --> 00:42:53.820
And in fact, AppKit computes these and
figures them out for you.

00:42:53.820 --> 00:42:57.740
So all you really need to do at this
point is get the rectangles from

00:42:57.740 --> 00:43:01.160
AppKit-- and we have this method--
getRectsExposedDuringLiveResize,

00:43:01.160 --> 00:43:02.450
count.

00:43:02.460 --> 00:43:04.460
And you get back the count
of the number of rects,

00:43:04.490 --> 00:43:06.040
and you get back the rectangles.

00:43:06.220 --> 00:43:10.960
It's guaranteed to be never
more than four rectangles.

00:43:11.140 --> 00:43:14.450
And then you can iterate over
that list of rectangles and mark

00:43:14.450 --> 00:43:15.620
yourself dirty in those areas.

00:43:15.670 --> 00:43:17.920
So this is something that you
do only during live resize.

00:43:17.920 --> 00:43:22.150
When we're not in live resize,
we simply do a full set needs display to

00:43:22.240 --> 00:43:25.540
require the entire view to be redrawn.

00:43:25.630 --> 00:43:27.600
So that's kind of not
so interesting in code.

00:43:27.600 --> 00:43:30.900
Let's look at a demo
and see how this works.

00:43:37.990 --> 00:43:41.350
So I've got my old scrapbook app here.

00:43:41.430 --> 00:43:46.110
And one of the things you may have
noticed as I started resizing my view is,

00:43:46.110 --> 00:43:49.460
boy, it's really chunking along there.

00:43:49.460 --> 00:43:52.490
I mean, that's just too slow.

00:43:53.960 --> 00:43:57.580
Now, to be completely honest in
disclosing what I'm doing here,

00:43:57.630 --> 00:44:01.180
I'm not exactly trying hard to be very
smart about the drawing I'm doing.

00:44:01.180 --> 00:44:03.140
We've only got two dozen photos up here.

00:44:03.140 --> 00:44:07.100
But what I'm doing is,
these are full-size images in memory.

00:44:07.270 --> 00:44:09.560
And I'm scaling them down
every time I draw them.

00:44:09.680 --> 00:44:12.110
So I'm doing sort of an expensive,
unnecessary operation.

00:44:12.120 --> 00:44:15.020
If I really wanted to make this fast,
one of the things I might do is

00:44:15.020 --> 00:44:18.520
resample the images as they're
loaded down to thumbnail size,

00:44:18.520 --> 00:44:19.960
since that's all I'm drawing them as.

00:44:19.960 --> 00:44:21.160
I don't need the full detail.

00:44:21.160 --> 00:44:24.950
But you could suppose that you
have some other objects that are

00:44:25.020 --> 00:44:26.650
complex and expensive to draw.

00:44:26.760 --> 00:44:28.810
So this is just kind of embarrassing.

00:44:28.820 --> 00:44:31.820
On a dual-proc G5,
we shouldn't be chunking along this slow.

00:44:31.820 --> 00:44:35.430
And in fact, if we run Quartz debug,

00:44:38.360 --> 00:44:42.910
This is a useful feature for
gross display speed measurement.

00:44:42.970 --> 00:44:46.140
If you're not familiar with it,
there is a frame meter in Quartz Debug

00:44:46.140 --> 00:44:49.350
that's available from the Tools menu.

00:44:49.450 --> 00:44:51.040
Show frame meter.

00:44:51.440 --> 00:44:54.760
And you can use it as you-- tells you
basically your number of frames per

00:44:54.820 --> 00:44:59.100
second on the red gauge there as you
move windows around and as you resize.

00:44:59.180 --> 00:45:03.240
And if we start measuring this,
just sort of informally

00:45:03.240 --> 00:45:04.080
dragging it around.

00:45:04.080 --> 00:45:06.000
I'm not even breaking 10
frames a second there.

00:45:06.000 --> 00:45:07.760
This is really embarrassing.

00:45:07.880 --> 00:45:10.680
So what can we do about this?

00:45:15.000 --> 00:45:18.780
Start by dragging
OK Scrapbook to the trash.

00:45:18.800 --> 00:45:24.210
And luckily, I made a copy of it first,
and we've got this better scrapbook.

00:45:30.540 --> 00:45:36.250
And what I've done in my page view

00:45:40.470 --> 00:45:43.840
This is my custom document view class.

00:45:43.860 --> 00:45:48.190
I have overridden, just as I said,
preserves content during live resize.

00:45:48.230 --> 00:45:52.200
I've got an IVAR for this setting
so that I can show it in the demo,

00:45:52.200 --> 00:45:54.730
but basically we'd always
return yes if we know that we

00:45:54.770 --> 00:45:56.390
want to support this feature.

00:45:56.610 --> 00:45:58.860
And then in set frame size,
just as I showed you,

00:45:58.860 --> 00:46:02.810
this is almost an identical snapshot
of the code that was on the slide.

00:46:03.020 --> 00:46:06.110
We figure out if this option
is turned on for the demo.

00:46:06.370 --> 00:46:08.390
OK, yeah, we want to preserve content.

00:46:08.460 --> 00:46:11.570
If we do want to do that,
we check whether we're in live resize.

00:46:11.840 --> 00:46:14.760
And just as a paranoia check,
I checked whether we actually

00:46:14.780 --> 00:46:21.440
support this message in NSVUE in
case I was running this on Panther.

00:46:21.440 --> 00:46:23.020
Remember,
you can do these kinds of checks

00:46:23.020 --> 00:46:25.720
so that you can take advantage of
a feature only if you're running

00:46:25.720 --> 00:46:27.600
on the newer version of the system.

00:46:27.650 --> 00:46:29.740
We get the rectangles being exposed.

00:46:29.780 --> 00:46:31.760
We mark them as needing display.

00:46:32.000 --> 00:46:39.890
And let's see if that was even worth
all that trouble of two methods.

00:46:42.530 --> 00:46:46.990
"So we've got the application here,
drag the album in,

00:46:46.990 --> 00:46:51.260
we've got our background
image loading happening,

00:46:51.260 --> 00:46:51.260
and

00:46:54.020 --> 00:46:57.480
So again, slow before.

00:46:57.840 --> 00:47:02.190
If I go here and turn on preserving
content during live resize--

00:47:04.510 --> 00:47:04.950
Look at that.

00:47:05.050 --> 00:47:06.660
That's just silky smooth now.

00:47:06.660 --> 00:47:08.260
We go up to 60 frames a second.

00:47:08.270 --> 00:47:11.210
So that was significant in this case.

00:47:22.060 --> 00:47:24.550
And in fact, while we're at it,
before we leave the demo machine,

00:47:24.550 --> 00:47:28.460
let's look at another
optimization that I put in there.

00:47:29.340 --> 00:47:34.280
So we've got preserving content,
but supposing also that you just want

00:47:34.280 --> 00:47:37.260
to take advantage of in-library size,
as I was saying,

00:47:37.330 --> 00:47:39.720
to just do simpler drawing.

00:47:40.030 --> 00:47:42.510
I've gone to an extreme here.

00:47:42.910 --> 00:47:45.760
And I've got a mode where
I can have my view just draw

00:47:45.760 --> 00:47:50.030
the photos as simple outlines,
just real simple stroked

00:47:50.030 --> 00:47:52.280
boxes during live resize mode.

00:47:52.330 --> 00:47:55.380
I enable that optimization,
and as soon as I-- things are

00:47:55.380 --> 00:47:57.850
normal when I'm just dragging things
around-- but as soon as I grab the

00:47:57.870 --> 00:48:02.320
window corner and start to resize,
everything changes to boxes.

00:48:02.420 --> 00:48:04.220
And I can resize all I want.

00:48:04.220 --> 00:48:06.360
Obviously,
this is extremely cheap drawing,

00:48:06.360 --> 00:48:09.460
so I could be on any old machine.

00:48:09.460 --> 00:48:12.370
Even if I'm on a limited memory
iBook or something like that,

00:48:12.450 --> 00:48:14.060
this would be very fast.

00:48:14.060 --> 00:48:18.280
And this technique is usable way
back on earlier versions of OS X.

00:48:18.310 --> 00:48:21.370
So you probably wouldn't
want to go to this extreme.

00:48:21.380 --> 00:48:25.520
I'm sort of doing it to make a point
that you can do very different drawing,

00:48:25.550 --> 00:48:27.990
entirely different drawing if you want,
or you can do somewhat similar

00:48:27.990 --> 00:48:31.800
drawing is the more likely case,
that is somehow less expensive

00:48:32.080 --> 00:48:35.380
and approximate in some way
while you're in live resize mode.

00:48:35.440 --> 00:48:38.840
So basically, you can do anything
you want in this mode.

00:48:38.920 --> 00:48:41.030
And what I've done-- to
implement this is fairly simple.

00:48:41.080 --> 00:48:48.920
There we go.

00:48:57.410 --> 00:49:01.180
Here we have the draw rec method.

00:49:01.210 --> 00:49:02.890
And I guess we didn't
look at this before.

00:49:02.950 --> 00:49:06.430
I'm doing some of the other
optimizations I recommended.

00:49:06.450 --> 00:49:09.090
We're getting a list of recs
that we're drawing so that when

00:49:09.090 --> 00:49:11.680
we go to do our background fill,
we can only fill that list of recs

00:49:11.680 --> 00:49:13.180
instead of trying to fill the whole view.

00:49:13.180 --> 00:49:16.820
We do clip for you when we're drawing
just specific areas of the view.

00:49:16.930 --> 00:49:18.930
So even if you don't
obey that list of recs,

00:49:18.930 --> 00:49:23.410
even if you just look at the bounding box
or just try to draw all over the view,

00:49:23.410 --> 00:49:28.650
we will clip your drawing just to the
area that drawing is being requested in.

00:49:28.660 --> 00:49:31.190
But you still save something by
not even issuing those drawing

00:49:31.210 --> 00:49:34.290
commands in the first place
when you have a choice about it.

00:49:35.370 --> 00:49:38.900
So we're drawing the background
fill using that list of recs.

00:49:38.920 --> 00:49:41.440
And the interesting part here--

00:49:42.220 --> 00:49:54.060
is if I have this Draw as Outlines
in Live Resize mode enabled,

00:49:54.060 --> 00:49:54.060
and we're in Live Resize mode,
then instead of drawing the whole photo,

00:49:54.060 --> 00:49:54.060
I'll just get the frame of the photo,

00:49:55.170 --> 00:49:59.720
And I'll just use BezierPath to stroke
erect and white where it would be.

00:49:59.750 --> 00:50:01.380
And that's pretty much all we have to do.

00:50:01.380 --> 00:50:04.470
The only other thing that I need
to add is in view will start live

00:50:04.480 --> 00:50:09.820
resize and view did end live resize,
I need to tell the view

00:50:09.820 --> 00:50:11.100
to redisplay itself.

00:50:11.190 --> 00:50:14.670
Because when I grab that corner of
the window and I start dragging,

00:50:14.780 --> 00:50:17.700
if I don't do this,
then I will get the complete

00:50:17.700 --> 00:50:20.160
photo drawing on the one hand.

00:50:20.220 --> 00:50:22.310
And then as I start dragging,
new stuff that appears

00:50:22.370 --> 00:50:23.280
will be drawn and outlined.

00:50:23.280 --> 00:50:24.880
And that looks kind of
inconsistent and weird.

00:50:24.880 --> 00:50:26.740
And same thing when you're
exiting live resize mode.

00:50:26.740 --> 00:50:29.620
You want to redisplay the whole view
at that point to go back into the

00:50:29.620 --> 00:50:31.840
old mode and reflect the change.

00:50:31.910 --> 00:50:34.970
So OK, if we could go back to slides,
please.

00:50:39.470 --> 00:50:41.390
Thank you.

00:50:41.670 --> 00:50:43.990
Scrolling-- not a whole
lot to say about scrolling,

00:50:44.050 --> 00:50:49.080
except that obviously it hinges
somewhat on view drawing performance.

00:50:49.150 --> 00:50:52.170
And in some sense,
it's related a bit to window drawing,

00:50:52.170 --> 00:50:54.190
window resize performance,
because it exercises

00:50:54.270 --> 00:50:55.650
view drawing intensively.

00:50:55.780 --> 00:50:59.030
So if you have a document view that
you're going to put in a scroll view,

00:50:59.030 --> 00:51:01.480
and you want your scrolling
to be smooth and fluid,

00:51:01.480 --> 00:51:04.470
one thing you can do is make sure
that your document view uses these

00:51:04.570 --> 00:51:08.270
facilities that I pointed out earlier,
and can efficiently draw

00:51:08.270 --> 00:51:10.500
small bands of its content.

00:51:10.500 --> 00:51:13.170
Because those are the kinds of
requests that you're likely to get

00:51:13.170 --> 00:51:16.620
during a scrolling operation-- lots
of small little incremental scrolls,

00:51:16.670 --> 00:51:18.250
where you just have to
draw a little strip.

00:51:18.410 --> 00:51:20.440
And the more efficiently
you can determine,

00:51:20.540 --> 00:51:22.590
oh, I don't need to draw this,
I don't need to draw that,

00:51:22.600 --> 00:51:25.150
all this other stuff
that's not in that strip,

00:51:25.260 --> 00:51:29.510
the more quickly you can draw and
the smoother your scrolling will be.

00:51:30.030 --> 00:51:33.460
Another little feature of
Scroll View and Clip View to be aware of,

00:51:33.550 --> 00:51:35.390
by default they are opaque.

00:51:35.400 --> 00:51:38.900
They are set to draw an opaque
background behind the document view.

00:51:38.900 --> 00:51:42.720
So if the Clip View area is sized
bigger than the document view,

00:51:42.720 --> 00:51:45.480
you will get opaque
fill all around there.

00:51:45.840 --> 00:51:49.460
For best performance, leave it that way,
unless you really,

00:51:49.460 --> 00:51:53.940
really want that outside margin
area to show through to the

00:51:53.960 --> 00:51:56.060
views and the window behind.

00:51:56.060 --> 00:51:58.970
Because it does significantly impact
drawing performance and scrolling

00:51:58.970 --> 00:52:01.360
performance within the Scroll View.

00:52:01.500 --> 00:52:03.080
So that feature is there to use it.

00:52:03.230 --> 00:52:06.350
Be aware that that has
a performance cost.

00:52:07.700 --> 00:52:09.630
String drawing,
we provide very convenient

00:52:09.690 --> 00:52:12.620
methods as categories on NSString.

00:52:12.620 --> 00:52:16.840
You can draw a string at any point
or within a bounding rectangle and

00:52:17.170 --> 00:52:22.200
supply a dictionary of text attributes,
and we'll just do that for you.

00:52:22.200 --> 00:52:24.120
I mean that's very little
work to draw a string.

00:52:24.170 --> 00:52:25.420
That's a one-liner, right?

00:52:25.680 --> 00:52:27.560
It's very convenient.

00:52:27.560 --> 00:52:30.770
But note that when you invoke
these methods to do this

00:52:30.770 --> 00:52:34.180
convenient string drawing,
what we have to do under the

00:52:34.180 --> 00:52:37.820
hood to implement that is
potentially set up the text system,

00:52:37.820 --> 00:52:39.210
wire together the various objects.

00:52:39.270 --> 00:52:40.660
If you've worked with
the Cocoa text system,

00:52:40.670 --> 00:52:42.720
you know there's a lot of
different things involved,

00:52:42.720 --> 00:52:47.020
text containers, layout manager,
and the text view itself and so forth.

00:52:47.020 --> 00:52:49.340
So we've got to figure out how
to lay out the glyphs for the

00:52:49.430 --> 00:52:52.520
string that you've given us,
and then we've got to do the actual

00:52:52.520 --> 00:52:54.940
rasterization or drawing of the glyphs.

00:52:54.940 --> 00:52:57.400
This is a lot of stuff
going on under the hood.

00:52:57.400 --> 00:53:00.920
Now this is an area that's
being actively optimized.

00:53:00.920 --> 00:53:02.970
We do provide some degree of caching.

00:53:02.980 --> 00:53:04.780
Obviously,
it's sort of a general caching.

00:53:04.780 --> 00:53:08.080
We can't know what the behaviors of
your applications will be because

00:53:08.090 --> 00:53:10.160
every application is different.

00:53:10.160 --> 00:53:12.750
But we do attempt to avoid these costs.

00:53:12.770 --> 00:53:16.490
So you should see this
improving on Panther and Tiger.

00:53:16.500 --> 00:53:18.790
This is continuing to evolve.

00:53:18.800 --> 00:53:22.340
But it may still be advantageous
to use an old technique that was

00:53:22.340 --> 00:53:26.160
discussed years ago and is illustrated,
still best illustrated by the

00:53:26.160 --> 00:53:30.420
worm demo that's available in
developer examples app kit.

00:53:30.420 --> 00:53:34.840
If you're repeatedly drawing the same
string-- with the same layout-- you

00:53:34.840 --> 00:53:37.500
need only compute the glyph layout once.

00:53:37.550 --> 00:53:40.160
The glyph layout isn't going to change.

00:53:40.160 --> 00:53:44.510
And so for that reason and others,
you can get some performance

00:53:44.590 --> 00:53:47.940
benefit by assembling your text
objects and hanging onto them.

00:53:47.940 --> 00:53:50.900
If you just do a little manual
mucking with the text system,

00:53:50.950 --> 00:53:54.960
allocate your text storage object--
text storage is an object that contains

00:53:55.280 --> 00:53:59.480
both the characters and the attributes
applied to runs of those characters.

00:53:59.530 --> 00:54:00.860
Allocate your own layout manager.

00:54:00.860 --> 00:54:02.940
Allocate a text container.

00:54:03.020 --> 00:54:04.740
Wire them together and hang onto them.

00:54:04.740 --> 00:54:06.470
Keep them around.

00:54:06.560 --> 00:54:07.200
And use them.

00:54:07.200 --> 00:54:09.990
Every time you need to draw the glyphs,
then all you have to do is message

00:54:10.290 --> 00:54:11.880
the layout manager directly.

00:54:11.880 --> 00:54:13.480
Say, draw glyphs for glyph range.

00:54:13.480 --> 00:54:17.150
And if you play with the worm example,
you'll see that this makes a tremendous

00:54:17.160 --> 00:54:19.930
difference when you're rendering,
especially on older

00:54:19.930 --> 00:54:23.600
versions of the system,
when you're rendering text repeatedly.

00:54:23.910 --> 00:54:26.400
Bezier paths-- not a whole
lot to say about Bezier paths.

00:54:26.540 --> 00:54:30.610
But if you're drawing really complicated
Bezier paths-- I'm talking about paths

00:54:30.770 --> 00:54:35.310
with hundreds or thousands of elements--
be aware that there are crossing

00:54:35.420 --> 00:54:37.440
calculations that have to be done.

00:54:37.740 --> 00:54:41.410
And the scaling of the algorithms that
necessarily need to be used to get

00:54:41.410 --> 00:54:44.940
the closures right and get everything
right with the Bezier path rendering,

00:54:44.940 --> 00:54:48.300
it doesn't scale too well when
you get to very complex paths.

00:54:48.550 --> 00:54:51.180
So one thing you can do,
if you don't need to get-- if

00:54:51.230 --> 00:54:53.860
you're drawing paths like this
that are very complicated,

00:54:53.870 --> 00:54:56.480
if you don't need to get exact,
exact results,

00:54:56.490 --> 00:55:01.340
you can split those paths into
segments and render them in sequence.

00:55:01.340 --> 00:55:04.740
And it looks like pretty much the same--
it looks like pretty much the same thing,

00:55:04.820 --> 00:55:08.360
except you get a big
performance win from doing that.

00:55:08.360 --> 00:55:12.330
Also, if you have paths that you're
creating over and over again,

00:55:12.330 --> 00:55:14.480
the same path,
drawing it over and over again,

00:55:14.480 --> 00:55:17.300
stroking or filling it, keep them around.

00:55:17.300 --> 00:55:21.140
And this applies in general to a lot
of different types of graphics objects.

00:55:21.140 --> 00:55:25.220
If you create them and hang on to them,
there's a lot more caching that we

00:55:25.220 --> 00:55:28.830
can do and that other layers below us,
like Core Graphics, can do to recognize,

00:55:28.830 --> 00:55:30.800
oh, yeah,
that's the same thing I saw before.

00:55:30.990 --> 00:55:32.840
I just draw that again.

00:55:32.990 --> 00:55:36.970
Object allocation, initialization,
deallocation.

00:55:38.080 --> 00:55:42.770
There are a couple of interesting things
to be aware of with relation to NSImage.

00:55:43.070 --> 00:55:47.170
SetDataRetained,
we have this notion of where an image is

00:55:47.170 --> 00:55:54.150
able to reference its data source rather
than actually containing the image data.

00:55:54.160 --> 00:55:58.100
If you initialize an NSImage
using either a NIT by referencing

00:55:58.250 --> 00:56:02.600
file or a NIT by referencing URL,
you will get an image that, for example,

00:56:02.660 --> 00:56:05.290
when it's archived,
instead of archiving itself with all the

00:56:05.350 --> 00:56:08.130
image data that it loaded from that file,
it just archives the

00:56:08.240 --> 00:56:09.840
reference to the file or URL.

00:56:09.840 --> 00:56:13.440
So that creates a very
compact representation.

00:56:13.440 --> 00:56:17.020
Some people use it for that purpose so
that they can maintain the reference

00:56:17.020 --> 00:56:18.990
rather than just copy the image in.

00:56:19.000 --> 00:56:20.690
But be aware that if you're
drawing that image repeatedly

00:56:20.690 --> 00:56:22.410
and you are in particular using
it for a specific purpose,

00:56:22.410 --> 00:56:24.140
you're going to have to be
very careful about that.

00:56:24.140 --> 00:56:29.000
If you're drawing a particular image and
you're in particular changing its size,

00:56:29.020 --> 00:56:32.420
this may cause NSImage to go back
to disk or go back to retrieve

00:56:32.590 --> 00:56:36.100
the image from the URL every
time that it needs to resize it,

00:56:36.100 --> 00:56:38.360
recache it at a new size to draw.

00:56:38.360 --> 00:56:40.690
Remember,
NSImage does do some caching in the

00:56:40.850 --> 00:56:42.850
background that's transparent to you.

00:56:42.930 --> 00:56:46.220
So if you're using a referenced
image and you're resizing a window

00:56:46.220 --> 00:56:49.520
and things are chunking along,
this is a thing to look into.

00:56:49.520 --> 00:56:53.920
Check whether this setting
is on and be aware of it.

00:56:54.120 --> 00:56:57.830
And if you need to resize an image,
try and resize it once and get the

00:56:58.000 --> 00:57:00.070
size you want and leave it that way.

00:57:00.120 --> 00:57:04.260
There's also this notion
of caching separately.

00:57:07.700 --> 00:57:11.020
When you've used NSImages,
if you've ever dumped the debug

00:57:11.020 --> 00:57:14.480
description for an NSImage,
you may have seen cached image reps.

00:57:14.480 --> 00:57:15.460
And you may have seen these.

00:57:15.460 --> 00:57:16.920
And they're part of the public API.

00:57:16.920 --> 00:57:20.740
A cached image rep is a representation
of an image that usually is

00:57:20.740 --> 00:57:24.420
generated from something else,
some drawing you've captured from a view,

00:57:24.420 --> 00:57:27.380
or from resizing an image that
you originally loaded as a bitmap.

00:57:27.520 --> 00:57:31.760
A cached image rep is an image that
lives in an offscreen window somewhere,

00:57:31.760 --> 00:57:34.920
and that's where the
Windows server is keeping it in

00:57:34.920 --> 00:57:39.490
a screen-compatible pixel format,
usually ready to go.

00:57:39.500 --> 00:57:42.470
This is sort of an optimization,
keeping these cached images.

00:57:42.640 --> 00:57:48.830
Now by default, an image is not cached
separately in its own window.

00:57:49.160 --> 00:57:53.450
We have the possibility for NSImages
allowed to cache images together and

00:57:53.450 --> 00:57:57.760
to just sort of grow this shared window
or shared windows as it sees fit when

00:57:57.890 --> 00:58:00.740
it needs to load additional images.

00:58:00.800 --> 00:58:05.000
If you have large transient images
that you're loading using NSImage,

00:58:05.000 --> 00:58:08.540
and you load them, and then they go away,
and you're not going to replace

00:58:08.540 --> 00:58:11.560
them with another large image,
and you want to avoid the potential

00:58:11.610 --> 00:58:15.950
resource usage cost of this cache
window growing and growing and growing,

00:58:15.950 --> 00:58:19.910
you may want to set
cached separately to yes,

00:58:19.970 --> 00:58:23.660
to force the use of a separate offscreen
window for that particular image.

00:58:23.700 --> 00:58:26.470
That image will stand alone in
the offscreen cache that the

00:58:26.480 --> 00:58:28.440
Windows server that NSImage uses.

00:58:28.540 --> 00:58:32.070
So this is a good strategy
to use for transient images.

00:58:33.280 --> 00:58:37.300
So that's issues that generally
pertain to AppKit APIs.

00:58:37.360 --> 00:58:40.280
Let's dive in deeper now and
look at things that are more

00:58:40.280 --> 00:58:42.220
at the foundation level.

00:58:44.200 --> 00:58:46.300
In particular,
we'll look at notifications.

00:58:46.300 --> 00:58:50.750
These are venerable and widely used,
and still very powerful and

00:58:50.860 --> 00:58:53.320
important mechanism in AppKit.

00:58:53.340 --> 00:58:56.540
Ways of accessing collections
and strings are sort of a kind

00:58:56.540 --> 00:58:58.600
of collection more efficiently.

00:58:58.660 --> 00:59:03.130
Using auto-release and the
memory management mechanisms

00:59:03.210 --> 00:59:05.640
that ObjC and Cocoa provide.

00:59:05.640 --> 00:59:10.800
The immutability concept
and also techniques for

00:59:10.800 --> 00:59:11.070
working with property lists.

00:59:12.330 --> 00:59:13.760
So notifications, first of all.

00:59:13.760 --> 00:59:17.540
Notifications are a very powerful
and flexible mechanism for

00:59:17.540 --> 00:59:22.480
a given object to broadcast,
volunteer information about some

00:59:22.480 --> 00:59:25.810
interesting event or potentially
interesting event that's occurred in

00:59:26.000 --> 00:59:29.850
it to any number of other observers
that the object isn't aware of.

00:59:29.850 --> 00:59:33.260
The observers don't need
to be aware of one another.

00:59:33.260 --> 00:59:36.000
They can all register with the
central notification center.

00:59:36.030 --> 00:59:39.030
And the notification center mechanism
provides sort of the loose coupling

00:59:39.040 --> 00:59:42.260
that allows all these objects to
communicate about a particular topic.

00:59:42.320 --> 00:59:44.770
without necessarily
knowing about one another.

00:59:44.770 --> 00:59:48.430
As an observer,
you can subscribe for a specific

00:59:48.510 --> 00:59:52.980
notification posted by a specific object,
or you can cast wider nets and ask

00:59:52.980 --> 00:59:56.770
for all notifications posted by
a given object or all instances

00:59:56.770 --> 00:59:59.760
of a particular notification,
regardless of the

00:59:59.770 --> 01:00:01.500
object that posted them.

01:00:01.600 --> 01:00:05.390
You can also use the distributed
notification mechanism to pass

01:00:05.400 --> 01:00:07.540
notifications across process bounds.

01:00:07.540 --> 01:00:09.300
This is a very powerful general facility.

01:00:09.300 --> 01:00:11.690
It's been in the app
kit since the beginning.

01:00:13.300 --> 01:00:15.820
But there are certain performance
issues associated with its use,

01:00:15.920 --> 01:00:17.170
particularly abuse.

01:00:17.230 --> 01:00:21.410
One thing to be aware of is that
when you post a notification,

01:00:21.650 --> 01:00:25.240
there's a cost there,
even if nobody is listening.

01:00:25.630 --> 01:00:27.600
Obviously,
we've tried to optimize this to make

01:00:27.600 --> 01:00:31.180
it a fast path within the notification
center's dispatch mechanism.

01:00:31.180 --> 01:00:33.770
But even if nobody's listening,
there's a certain cost

01:00:33.770 --> 01:00:36.610
involved in checking to see
whether anyone is listening.

01:00:36.610 --> 01:00:39.500
And this gets to be a problem
in particular if you are

01:00:39.840 --> 01:00:42.280
sort of speculatively writing
classes if you're not listening.

01:00:43.300 --> 01:00:44.610
But you're writing code maybe
that's going to go in a framework,

01:00:44.610 --> 01:00:47.520
once again,
that's sort of intended for general

01:00:47.520 --> 01:00:51.340
reuse by potentially unknown clients,
clients you may not know about right now.

01:00:51.340 --> 01:00:54.050
You may not know, well,
what sorts of notifications

01:00:54.050 --> 01:00:55.690
might they be interested in?

01:00:55.700 --> 01:00:58.360
What kinds of changes in me
might they want to know about?

01:00:58.360 --> 01:01:01.700
So you get into this problem
of sort of speculative posting.

01:01:01.700 --> 01:01:04.840
You tend to err on the side of
caution and post notifications

01:01:04.840 --> 01:01:06.970
for all kinds of things,
potentially,

01:01:06.980 --> 01:01:10.690
just in case somebody might be
interested in listening for that.

01:01:11.600 --> 01:02:46.200
[Transcript missing]

01:02:46.980 --> 01:02:51.050
So what can you do if you are going to
use notifications to get around this?

01:02:51.190 --> 01:02:53.180
In general, help us help you.

01:02:53.360 --> 01:02:57.620
Be selective as much as you can
about what kinds of events you really

01:02:57.620 --> 01:02:59.850
need to broadcast to the world.

01:02:59.920 --> 01:03:02.980
Be as specific as you can
as an observer when you're

01:03:02.980 --> 01:03:05.240
registering for notifications.

01:03:05.300 --> 01:03:08.760
If you know the name of the notification
you want and you know the object,

01:03:09.080 --> 01:03:11.300
register using a non-nil name and object.

01:03:11.300 --> 01:03:14.430
These types of entries in
the dispatch table are,

01:03:14.430 --> 01:03:16.780
in general, easier for us to optimize.

01:03:16.900 --> 01:03:29.900
You can add yourself as an observer with
nil as the name and just the object.

01:03:29.900 --> 01:03:32.380
You can also, remember,
as an alternative to that,

01:03:32.460 --> 01:03:36.050
you can add yourself several times as
an observer once for each notification,

01:03:36.050 --> 01:03:39.280
depending what version of the system
you're running on that may or may

01:03:39.440 --> 01:03:41.240
not be a performance advantage.

01:03:41.240 --> 01:03:43.340
So measure to see if that's an issue.

01:03:43.900 --> 01:03:46.880
Also, obviously, the notification handler
methods that I mentioned,

01:03:46.880 --> 01:03:46.880
the notification handler
methods that I mentioned,

01:03:46.880 --> 01:03:46.880
they're not necessarily the
same as the notification handler

01:03:46.880 --> 01:03:46.880
methods that I mentioned.

01:03:46.880 --> 01:03:50.490
that block while they're processing
and don't return control to

01:03:50.490 --> 01:03:52.800
the poster until they're done,
obviously make these as

01:03:52.800 --> 01:03:53.840
efficient as possible.

01:03:53.840 --> 01:03:56.680
And if they don't have to do work
right away and you can defer it,

01:03:56.680 --> 01:03:58.510
defer that work.

01:03:59.560 --> 01:04:02.850
And as I said,
avoid repeated removal and addition

01:04:02.850 --> 01:04:04.830
of observers if you possibly can.

01:04:04.840 --> 01:04:08.880
One way around this is to consider
using a longer-lived intermediary

01:04:08.950 --> 01:04:13.550
object that keeps track of all of these
transient objects and directly messages

01:04:13.590 --> 01:04:15.880
them when it receives the notification.

01:04:15.930 --> 01:04:18.590
As an example of this,
let's say we have an originator object

01:04:18.700 --> 01:04:22.220
that volunteers some information about
itself by posting a notification.

01:04:22.270 --> 01:04:24.380
It posts the notification
to the Notification Center.

01:04:24.380 --> 01:04:26.800
And if we do this in a
really simplistic way,

01:04:26.800 --> 01:04:29.500
we'll have all these
transient objects here.

01:04:29.500 --> 01:04:30.840
They're coming and going.

01:04:30.870 --> 01:04:33.640
They're adding themselves as
observers to the Notification Center.

01:04:33.640 --> 01:04:37.320
They receive the notifications
directly from the Notification

01:04:37.320 --> 01:04:40.060
Center when they are posted.

01:04:40.070 --> 01:04:45.860
An alternative to this is to drop a
longer-lived object in the middle there

01:04:46.180 --> 01:04:50.220
and have it be the only observer that
is added to the Notification Center.

01:04:50.230 --> 01:04:53.260
It's maybe some object that knows
about all of these other transient

01:04:53.260 --> 01:04:57.130
objects and can more efficiently
dispatch this information to them by,

01:04:57.130 --> 01:05:00.500
say, sending a simple objc
message to each object.

01:05:00.500 --> 01:05:02.660
You've got less overhead there
because you've got fewer entries

01:05:02.660 --> 01:05:05.730
in the Notification Center dispatch
table at any one time.

01:05:05.740 --> 01:05:08.150
And also,
you're not adding and removing them and

01:05:08.150 --> 01:05:11.440
churning that table over and over again.

01:05:11.440 --> 01:05:13.740
So this is one technique you can
use if you're seeing a lot of

01:05:13.740 --> 01:05:16.440
load in the Notification Center.

01:05:16.440 --> 01:05:17.760
Consider using intermediate objects.

01:05:20.820 --> 01:05:25.300
As an alternative to using notifications,
you may not have considered key value

01:05:25.300 --> 01:05:26.800
observing and key value binding.

01:05:26.800 --> 01:05:32.020
These are powerful technologies that
were introduced in Panther that basically

01:05:32.020 --> 01:05:36.600
enable one object to observe value
changes in an attribute of another

01:05:36.600 --> 01:05:40.700
object or bind one of its attributes
to the attributes of another object.

01:05:40.830 --> 01:05:43.070
You may not have thought
of these as alternatives,

01:05:43.070 --> 01:05:45.760
but really they're just sort
of another way of propagating

01:05:45.760 --> 01:05:47.670
changes through your application.

01:05:47.800 --> 01:05:51.640
One advantage to this approach is
you don't have to anticipate what

01:05:51.650 --> 01:05:53.700
others might be interested in.

01:05:53.700 --> 01:05:57.610
You just have to make your accessor
methods key value coding compliant.

01:05:58.010 --> 01:06:00.700
There's no performance
penalty for unobserved changes

01:06:00.700 --> 01:06:04.900
because you're not posting,
trying to anticipate what

01:06:04.900 --> 01:06:06.200
others may be interested in.

01:06:06.200 --> 01:06:10.070
There's no overhead involved for
an object whose attributes aren't

01:06:10.070 --> 01:06:14.200
observed or for a particular attribute
that isn't observed to change.

01:06:15.010 --> 01:06:17.720
So obviously that lifts
the burden from you,

01:06:17.720 --> 01:06:20.340
too, of having to figure out what
others might be interested in.

01:06:20.400 --> 01:06:24.590
And it facilitates a similarly loose
coupling to what notifications provide.

01:06:24.640 --> 01:06:26.990
I'm not saying that notifications
are going away by any means.

01:06:27.020 --> 01:06:29.360
They're hardwired into a lot
of what we do in the kit.

01:06:29.360 --> 01:06:31.480
We have notifications
that objects advertise.

01:06:31.480 --> 01:06:32.890
They'll continue to provide those.

01:06:32.900 --> 01:06:35.640
Like NSView provides
view bounds did change,

01:06:35.650 --> 01:06:38.580
view frame did change notifications
when its geometry changes.

01:06:38.800 --> 01:06:41.030
There are lots of things
that are built on that.

01:06:41.320 --> 01:06:45.050
But if you're writing new modern code,
you might want to consider KVO and

01:06:45.150 --> 01:06:51.080
KVB as another way to go if notifications
aren't appropriate performance-wise.

01:06:51.160 --> 01:06:53.080
Also, obviously,
if your problem is simpler and

01:06:53.080 --> 01:06:56.840
you don't have a whole lot of
objects you have to notify,

01:06:56.970 --> 01:06:59.020
consider the delegation
pattern that we use throughout

01:06:59.020 --> 01:07:01.130
the app kit and foundation.

01:07:01.230 --> 01:07:04.440
Just have an object have a delegate
that it passes off a message to.

01:07:04.770 --> 01:07:09.740
It's a simple Objective-C message send
to a single receiver with the same cost.

01:07:10.600 --> 01:09:28.000
[Transcript missing]

01:09:28.600 --> 01:09:32.030
If you have an ordered collection,
and specifically an NSArray,

01:09:32.030 --> 01:09:36.530
you can use the objected index method
and get objects range to directly access

01:09:36.530 --> 01:09:40.720
the elements much more efficiently than
you might be able to with an enumerator.

01:09:40.720 --> 01:09:44.240
And in particular,
if you're doing random access,

01:09:44.240 --> 01:09:46.730
this is the only way to really do it.

01:09:48.000 --> 01:09:53.300
So if we're iterating through
an array using these methods

01:09:53.300 --> 01:09:56.880
instead of using an enumerator,
one thing you want to remember

01:09:57.130 --> 01:09:58.490
to do is cache your count.

01:09:58.740 --> 01:10:01.650
And in fact, this goes for anything that
any properties of an object

01:10:01.800 --> 01:10:05.250
that are invariant over
the course of an iteration.

01:10:05.430 --> 01:10:09.430
Move the getting of those
values outside of the iteration,

01:10:09.430 --> 01:10:10.900
and you save time.

01:10:10.900 --> 01:10:12.390
In other languages
that you may have used,

01:10:12.400 --> 01:10:13.770
this may not be as important.

01:10:13.930 --> 01:10:18.010
But the Objective-C compiler
is not able to know that,

01:10:18.100 --> 01:10:21.620
for example,
if I had written i less than bracket

01:10:21.760 --> 01:10:26.080
an array count bracket there,
the compiler would not be able to know.

01:10:26.080 --> 01:10:28.630
It would have no way of knowing
that the count is not changing.

01:10:28.640 --> 01:10:32.740
It's got to send that message every
time it checks the termination

01:10:32.740 --> 01:10:34.440
condition for the for loop.

01:10:34.630 --> 01:10:36.340
So keep that in mind.

01:10:36.340 --> 01:10:39.640
If there are messages that you
send to get invariant quantities,

01:10:39.640 --> 01:10:43.040
cache those instead of using
them each time through the array,

01:10:43.100 --> 01:10:43.840
instead of asking for them.

01:10:43.850 --> 01:10:45.620
for them each time.

01:10:46.080 --> 01:10:48.090
Calling a method through an imp.

01:10:48.090 --> 01:10:50.310
I don't know how many of you are
familiar with this technique.

01:10:50.380 --> 01:10:52.770
It's been around for a long time.

01:10:52.910 --> 01:10:56.640
It should be used with care,
as for one thing, it breaks polymorphism.

01:10:56.640 --> 01:11:00.410
It only works when all of the objects
that you are sending the message

01:11:00.760 --> 01:11:02.510
to are in general of the same type.

01:11:02.570 --> 01:11:06.220
Actually, they really just need to have
the same method implementation.

01:11:06.490 --> 01:11:09.210
So usually,
maybe a common base class would

01:11:09.210 --> 01:11:13.120
be sufficient for a given message
that you want to send them.

01:11:13.300 --> 01:11:16.180
What an imp is,
is an instance method pointer,

01:11:16.180 --> 01:11:20.600
a pointer to an implementation
method for a particular message.

01:11:20.660 --> 01:11:26.280
You can get that and then use that
as basically a function pointer

01:11:26.590 --> 01:11:28.620
to call that method directly.

01:11:28.790 --> 01:11:31.190
And this is particularly useful
where you have a whole bunch

01:11:31.200 --> 01:11:35.090
of objects of the same type,
and you want to really minimize the

01:11:35.090 --> 01:11:37.200
overhead of communicating with them.

01:11:37.240 --> 01:11:41.420
Here in this code sample,
we say have a do something useful

01:11:41.420 --> 01:11:45.120
with message that we want to send
to all the objects in an array.

01:11:45.120 --> 01:11:48.900
First thing we need to do is
get the imp for that message.

01:11:48.900 --> 01:11:53.680
And I take the object at index zero
as an arbitrary object in the array.

01:11:53.680 --> 01:11:56.170
I'm assuming that this is
a heterogeneous collection,

01:11:56.260 --> 01:11:58.430
I mean a homogeneous collection rather,
excuse me.

01:11:58.520 --> 01:12:01.840
And these objects are all going
to have the same implementation.

01:12:01.840 --> 01:12:03.060
This code will break otherwise.

01:12:04.080 --> 01:12:05.740
So I get the imp pointer.

01:12:05.740 --> 01:12:08.260
So basically now I've
got the function pointer.

01:12:08.260 --> 01:12:11.500
I don't have to go through the
obc dispatch tables for methods.

01:12:11.500 --> 01:12:15.050
I just call that function method
directly as if it were a function.

01:12:15.060 --> 01:12:17.720
So I get my count of the
objects in the array.

01:12:17.720 --> 01:12:20.590
And I'm also here using,
it's not highlighted,

01:12:20.590 --> 01:12:24.670
but I'm using the get objects method,
which enables you to retrieve at

01:12:24.740 --> 01:12:26.640
once a whole bunch of objects.

01:12:26.640 --> 01:12:29.250
In fact, in this case,
all of the objects out of an array.

01:12:29.260 --> 01:12:33.740
There's also a get objects variant
that has a range parameter.

01:12:33.740 --> 01:12:37.690
That lets you specify a sub range of the
array whose elements you want to get.

01:12:37.740 --> 01:12:41.740
So here what we're doing is we're
getting all of the objects out and we're

01:12:41.740 --> 01:12:47.340
mallocing a memory block to hold the ids,
the instance pointers for all of

01:12:47.340 --> 01:12:50.430
these objects so that we have them
in a standard C array and then we

01:12:50.430 --> 01:12:52.210
can access them any way we want.

01:12:52.270 --> 01:12:55.370
It's not essential in this case,
but it's something that might be

01:12:55.370 --> 01:12:58.580
useful if we wanted to do other
really fast random accesses.

01:12:58.580 --> 01:13:02.300
So we get the objects out
and then for each iteration,

01:13:02.300 --> 01:13:05.150
all we have to do is call
through the function pointer.

01:13:05.440 --> 01:13:08.640
And the important thing here to
note is the first two parameters.

01:13:08.650 --> 01:13:13.520
When you send a message to an
object using the usual obc syntax,

01:13:13.520 --> 01:13:18.710
the target is specified as the
first thing in the brackets.

01:13:18.710 --> 01:13:20.760
And then the selector is
sort of collected together

01:13:20.760 --> 01:13:23.760
as the message to send,
the different selector elements if

01:13:23.780 --> 01:13:24.920
you have more than one parameter.

01:13:24.920 --> 01:13:29.490
These are sort of implicit parameters
to the method implementation

01:13:29.490 --> 01:13:31.150
that obc usually hides from you.

01:13:31.150 --> 01:13:34.540
So when you do call through an imp,
you have to provide those yourself.

01:13:34.540 --> 01:13:38.180
So as the first parameter to
this imp that we're calling,

01:13:38.180 --> 01:13:41.280
we provide the object that's
the target of the message.

01:13:41.730 --> 01:13:45.040
We provide the selector just in case
the imp wants to check these because

01:13:45.040 --> 01:13:51.420
it can ask for it obviously is going to
need self and it might actually check

01:13:51.560 --> 01:13:53.750
the command that is being sent to it,
the selector.

01:13:53.760 --> 01:13:54.480
So we send those.

01:13:54.480 --> 01:13:57.490
And then we provide an argument
here because in this case our

01:13:57.490 --> 01:14:01.290
do something useful with needs a
something to do something useful with.

01:14:04.470 --> 01:14:06.520
So that was collections in general.

01:14:06.520 --> 01:14:09.550
String operations are, in some sense,
sort of a special case.

01:14:09.560 --> 01:14:12.400
I mean, a string is really just a
collection of characters,

01:14:12.400 --> 01:14:12.900
right?

01:14:12.920 --> 01:14:15.690
So a lot of the same
conceptual ideas apply.

01:14:15.830 --> 01:14:18.780
In particular,
you want to avoid intensive character by

01:14:18.880 --> 01:14:22.280
character access to a string if you can.

01:14:22.410 --> 01:14:25.810
Character at index is there if you
just need to grab a character or

01:14:25.810 --> 01:14:27.600
two out of a string once in a while.

01:14:27.600 --> 01:14:31.560
But it's not really
intended for heavy use.

01:14:31.560 --> 01:14:33.470
And again,
this is the kind of thing that the

01:14:33.470 --> 01:14:36.640
Objective-C compiler can't really
inline these types of things.

01:14:36.640 --> 01:14:40.400
It needs to send the message each time
in order to actually get the character.

01:14:40.450 --> 01:14:44.440
So as alternatives,
look at all of the methods

01:14:44.490 --> 01:14:45.480
that NSString provides.

01:14:45.480 --> 01:14:47.680
It's a big header,
one of the bigger headers we have.

01:14:47.680 --> 01:14:51.500
And there are all kinds of useful
methods that can directly access

01:14:51.500 --> 01:14:56.600
the internals of the string and
can do more efficient operations

01:14:56.600 --> 01:15:00.980
if you're looking for substrings,
doing searches through a string,

01:15:00.980 --> 01:15:04.230
and so forth,
or doing mutations to mutable strings.

01:15:04.440 --> 01:15:07.720
Try to use the NSString methods
when there's one available.

01:15:07.720 --> 01:15:11.800
When you're doing sequential
scanning or parsing through a string,

01:15:11.800 --> 01:15:14.390
searching for substrings,
and wanting to keep track of

01:15:14.390 --> 01:15:16.840
your position in a scanner,
remember NSScanner provides a whole

01:15:16.930 --> 01:15:18.640
bunch of methods for doing that.

01:15:19.010 --> 01:15:22.420
And if neither of those
facilities provides what you need,

01:15:22.420 --> 01:15:25.040
you might just want to fetch
the characters in blocks.

01:15:25.040 --> 01:15:29.170
And you can use the
getCharactersRange method to do that.

01:15:29.180 --> 01:15:31.180
Similar thing to what I was
doing with getObjects.

01:15:31.180 --> 01:15:35.940
For NSArray,
you can get all of the characters

01:15:35.940 --> 01:15:39.100
out as Unicode characters
into a standard C array.

01:15:39.100 --> 01:15:41.760
And then you can do
whatever you want with them,

01:15:41.760 --> 01:15:44.810
including using C functions and so forth.

01:15:47.710 --> 01:15:51.750
Object management and managing
responsibility for objects is a big

01:15:51.880 --> 01:15:57.190
part of any object-oriented application,
and Cocoa applications are no different.

01:15:57.310 --> 01:15:59.960
We provide a number of
convenience methods,

01:16:00.060 --> 01:16:03.640
factory methods,
class methods on various objects

01:16:04.070 --> 01:16:06.400
for very quickly and easily,
with very little code,

01:16:06.400 --> 01:16:08.640
getting back an auto-released object.

01:16:08.750 --> 01:16:11.280
It's important to remember that
these are auto-released by convention

01:16:11.280 --> 01:16:12.590
when you use a factory method.

01:16:12.600 --> 01:16:15.910
So if I call NSMutableArray array,
I'm getting back an array

01:16:15.910 --> 01:16:19.010
that has been auto-released,
so it's been added to the auto-release

01:16:19.160 --> 01:16:22.060
pool for the current thread,
and it's going to have to be processed

01:16:22.060 --> 01:16:23.480
by that auto-release pool later.

01:16:23.600 --> 01:16:26.850
This is a lot more
convenient than writing,

01:16:26.850 --> 01:16:31.260
say, NSMutableArray alloc init,
and then remembering to

01:16:31.260 --> 01:16:33.160
release the array later.

01:16:33.310 --> 01:16:36.110
It's less code, and so it's convenient,
and it's okay to use in

01:16:36.110 --> 01:16:38.780
the majority of cases,
unless performance is

01:16:38.910 --> 01:16:40.600
really being impacted.

01:16:40.600 --> 01:16:42.600
If you have large numbers of
objects or large numbers of objects,

01:16:42.600 --> 01:16:42.600
you're going to have to
use a lot of performance.

01:16:42.630 --> 01:16:46.280
numbers of iterations
that you're dealing with.

01:16:46.830 --> 01:16:51.840
Also remember that there's no need to
auto-release a temporary object that

01:16:51.840 --> 01:16:54.440
you're using just within a method body.

01:16:54.440 --> 01:16:56.350
It's something you're not
returning back from the method.

01:16:56.360 --> 01:16:59.130
You're just creating it,
and you're going to use it temporarily

01:16:59.130 --> 01:17:00.840
to do some operation and get rid of it.

01:17:00.880 --> 01:17:04.840
That would be a case where you can
alloc init and release instead.

01:17:04.860 --> 01:17:08.340
Again, not in every case is
this really necessary.

01:17:08.340 --> 01:17:11.080
But if it becomes a significant
fraction of what you're doing,

01:17:11.080 --> 01:17:12.630
you might want to consider that.

01:17:12.780 --> 01:17:13.490
Keep that in mind.

01:17:14.090 --> 01:17:17.910
This is obviously most worthwhile
for objects that are created and

01:17:17.910 --> 01:17:21.300
auto-released in large numbers,
and it avoids potential spikes

01:17:21.300 --> 01:17:23.260
in memory or resource usage.

01:17:23.260 --> 01:17:24.750
Remember,
when an object is auto-released,

01:17:24.760 --> 01:17:28.940
all these auto-released objects start to
sort of pile up and stick around because

01:17:28.940 --> 01:17:33.450
they're waiting around to be disposed of
when the auto-release pool is cleaned up.

01:17:33.580 --> 01:17:35.790
By default, unless you're creating your
own auto-release pools,

01:17:35.790 --> 01:17:38.500
that's when your code kind of finishes up
and returns control back to the run loop,

01:17:38.500 --> 01:17:41.000
usually after processing a user
input event or something like that.

01:17:41.000 --> 01:17:46.570
When you get back to the run loop,
all that stuff gets cleaned up.

01:17:46.660 --> 01:17:48.430
But in the interim,
if you're doing a whole lot of

01:17:48.460 --> 01:17:51.140
operations and creating a lot of
auto-released objects and maybe a

01:17:51.140 --> 01:17:53.870
lot of big auto-released objects,
if you're doing, say,

01:17:53.870 --> 01:17:56.050
image processing or image loading,
as I was doing,

01:17:56.050 --> 01:18:00.990
you can get spikes in memory usage,
where instantaneously you get

01:18:00.990 --> 01:18:03.160
peaks in your usage of memory.

01:18:03.160 --> 01:18:05.190
So, for example,
that's the kind of thing that

01:18:05.220 --> 01:18:07.930
you would see using ObjectAlloc,
one of the performance tools

01:18:07.930 --> 01:18:10.960
that we provide for you,
and it's also a useful debugging tool.

01:18:11.100 --> 01:18:14.100
So we have an application here,
and I'll magnify,

01:18:14.100 --> 01:18:17.310
where we've gone through a loop
and we've basically allocated

01:18:17.310 --> 01:18:21.740
10,000 auto-released strings,
a real simple, trivial example.

01:18:21.740 --> 01:18:25.150
We have a current count
of only 1,097 strings,

01:18:25.150 --> 01:18:29.140
but at the peak,
we had about 11,000 strings that were

01:18:29.210 --> 01:18:32.520
running around in this application,
hanging around,

01:18:32.520 --> 01:18:35.920
waiting to be auto-released at
the end of the loop and as we

01:18:35.920 --> 01:18:37.960
got back to the main run loop.

01:18:38.060 --> 01:18:40.580
So this is what an
auto-release spike looks like.

01:18:40.680 --> 01:18:43.310
When you see these long
bars in ObjectAlloc,

01:18:43.310 --> 01:18:47.750
you may want to look at what your
auto-release patterns are and

01:18:47.750 --> 01:18:51.360
whether there are cases where you
could use additional auto-release

01:18:51.560 --> 01:18:56.220
pools to provide cleanup before
memory usage gets out of control.

01:18:56.220 --> 01:18:59.050
It's not a big deal if you're
not using a whole lot of memory,

01:18:59.070 --> 01:19:01.620
but if you're really using
big chunks of memory,

01:19:01.620 --> 01:19:05.470
remember you're sharing the system
with a whole bunch of other processes,

01:19:05.470 --> 01:19:07.860
other applications,
and if memory is tight,

01:19:07.860 --> 01:19:10.080
you may start swapping and thrashing.

01:19:10.320 --> 01:19:12.970
and it becomes a performance issue.

01:19:13.590 --> 01:19:16.210
So again,
an application's main thread has

01:19:16.210 --> 01:19:19.550
a default auto-release pool that's
provided for you when you auto-release.

01:19:19.550 --> 01:19:20.260
You don't have to worry about it.

01:19:20.260 --> 01:19:23.100
It just goes to that.

01:19:23.300 --> 01:19:26.490
You can bracket operations with
your own auto-release pools,

01:19:26.510 --> 01:19:27.890
as we've already seen.

01:19:29.400 --> 01:23:41.800
[Transcript missing]

01:23:42.880 --> 01:23:43.840
So we're almost done here.

01:23:43.840 --> 01:23:46.140
One last thing I want
to point out to you.

01:23:46.230 --> 01:23:48.780
We have a binary format
for property lists.

01:23:48.930 --> 01:23:50.470
You've all seen the XML format.

01:23:50.590 --> 01:23:55.160
Property lists provide a convenient way,
if you have data structures,

01:23:55.160 --> 01:23:59.290
data storage that uses dictionaries,
arrays, strings, and all the sort of

01:23:59.310 --> 01:24:02.510
standard foundation types,
they provide a convenient

01:24:02.510 --> 01:24:08.040
way to serialize those out,
save them out to disk, and so forth.

01:24:08.090 --> 01:24:09.250
The XML format is great.

01:24:09.260 --> 01:24:10.000
It's human readable.

01:24:10.000 --> 01:24:11.460
You can go in and hand edit it.

01:24:11.510 --> 01:24:13.500
If your user has
corruption in a document,

01:24:13.550 --> 01:24:15.960
they can send it to you,
and you can read it and say, oh,

01:24:15.960 --> 01:24:18.060
this is where this went wrong.

01:24:18.280 --> 01:24:21.020
But we also have a binary
format that is smaller.

01:24:21.020 --> 01:24:22.840
It is faster to read and parse.

01:24:22.890 --> 01:24:26.960
It is very easy to specify it when
you're serializing out your data.

01:24:27.010 --> 01:24:28.300
It's just another parameter.

01:24:28.300 --> 01:24:32.180
And we have a PLUtil command line
tool that you can use to convert back

01:24:32.180 --> 01:24:35.790
and forth between binary and XML.

01:24:36.150 --> 01:24:40.930
All you have to do is specify the
format to be binary when you're

01:24:41.030 --> 01:24:45.940
serializing your property list using
NSPropertyList serialization APIs.

01:24:46.000 --> 01:24:46.500
That's it.

01:24:46.740 --> 01:24:50.310
And then you get a binary representation
handed back to you instead of

01:24:50.310 --> 01:24:52.940
the textual XML representation.

01:24:53.090 --> 01:24:57.220
When you're reading back that data,
you don't even have to worry about it.

01:24:57.280 --> 01:24:58.620
It doesn't matter.

01:24:58.620 --> 01:25:02.970
NSPropertyList serialization
APIs will figure out for you whether

01:25:03.060 --> 01:25:08.070
it's being handed some binary
or textual XML property list data.

01:25:08.260 --> 01:25:11.800
So if you want,
that information is available to you.

01:25:11.800 --> 01:25:14.440
It will tell you, oh,
I opened this document.

01:25:14.770 --> 01:25:17.120
It was XML, or this was binary.

01:25:17.270 --> 01:25:19.560
But you don't even have to
be concerned with it when

01:25:19.560 --> 01:25:21.660
you're reading the files back.

01:25:22.110 --> 01:25:23.960
So that's it for Foundation Techniques.

01:25:24.050 --> 01:25:28.120
Just some quick conclusions
to help you optimize better.

01:25:28.190 --> 01:25:28.940
Know the framework.

01:25:29.080 --> 01:25:31.780
That's, I hope,
the take-home lesson today.

01:25:31.780 --> 01:25:35.980
And I hope I've provided something
new for everyone with respect to that.

01:25:36.030 --> 01:25:37.500
Know the functionality it provides.

01:25:37.500 --> 01:25:42.660
Know where there are different ways
to perform a given task that may have

01:25:42.660 --> 01:25:44.400
different performance characteristics.

01:25:44.460 --> 01:25:46.440
Work with the framework wherever you can.

01:25:46.730 --> 01:25:48.470
Where appropriate,
look beyond the framework.

01:25:48.560 --> 01:25:51.460
Remember, we have a lot of facilities
available to Cocoa apps,

01:25:51.550 --> 01:25:54.900
things like Core Data and QuartzCore
you've heard about at the talk here.

01:25:54.950 --> 01:26:01.470
OpenGL is the fast path to the
hardware for rendering not just 3D,

01:26:01.500 --> 01:26:02.880
but also 2D.

01:26:03.020 --> 01:26:05.920
We have the Accelerate framework
that encapsulates AlteVec-based image

01:26:06.030 --> 01:26:08.100
processing and general computation.

01:26:08.100 --> 01:26:10.190
And remember,
use the provided performance

01:26:10.190 --> 01:26:11.780
tools to measure.

01:26:11.830 --> 01:26:14.980
Because if you don't measure,
you don't really know what's going on.

01:26:14.980 --> 01:26:17.920
And you may actually waste time
optimizing in areas that you think

01:26:18.020 --> 01:26:19.770
a lot of time is being spent in.

01:26:20.010 --> 01:26:23.140
But you may be surprised to find that
time is really being spent elsewhere.

01:26:23.140 --> 01:26:25.780
And you could spend your
time more productively.

01:26:25.980 --> 01:26:29.280
For more info,
we have documentation about performance

01:26:29.360 --> 01:26:32.360
in general and drawing performance
in particular that you might want

01:26:32.460 --> 01:26:34.350
to look at on the ADC home page.

01:26:34.750 --> 01:26:39.250
Matthew Formica is the contact for
any questions that you may have

01:26:39.250 --> 01:26:41.460
subsequent to this conference.