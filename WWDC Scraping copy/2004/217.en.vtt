WEBVTT

00:00:13.890 --> 00:00:14.440
Good afternoon.

00:00:14.440 --> 00:00:19.650
Welcome to the penultimate session for
WWDC and the ultimate QuickTime session.

00:00:19.660 --> 00:00:22.360
Today we're going to be
talking about next generation

00:00:22.360 --> 00:00:23.960
video formats in QuickTime.

00:00:23.960 --> 00:00:25.660
My name is Tim Chernia.

00:00:25.660 --> 00:00:28.340
I'm the manager of the
QuickTime Video Foundation team.

00:00:28.340 --> 00:00:32.940
And the QuickTime team is going
to be talking to you about H.264,

00:00:32.940 --> 00:00:37.120
AVC, the new video codec that
we're shipping in QuickTime,

00:00:37.120 --> 00:00:41.810
the next version of QuickTime in Tiger,
and the technologies that are required

00:00:41.810 --> 00:00:47.280
in QuickTime to support H.264,
and as well as changes that were required

00:00:47.280 --> 00:00:50.120
to support IPB video frame coding.

00:00:50.120 --> 00:00:51.880
We're going to talk a lot
about what that actually is.

00:00:51.880 --> 00:00:54.260
So you're going to see a bunch
of abbreviations in my slides,

00:00:54.320 --> 00:00:55.790
and it'll be a little bit strange.

00:00:55.820 --> 00:01:00.200
So let me talk about the QuickTime video
technologies before Tiger.

00:01:00.200 --> 00:01:04.250
Basically, we have this software stack,
and at the top of the software

00:01:04.250 --> 00:01:06.010
stack is the movie toolbox.

00:01:06.120 --> 00:01:11.040
The movie toolbox is used for creation
and editing and navigating movies.

00:01:11.040 --> 00:01:14.900
It's also used for playing back movies,
stepping through movies,

00:01:14.940 --> 00:01:17.850
and so it's typically what the
highest level applications use.

00:01:17.860 --> 00:01:22.880
Now, the movie toolbox is using the video
media handler to sequence video frames

00:01:22.880 --> 00:01:28.930
from files or from a network device
to the image compression manager.

00:01:28.940 --> 00:01:33.160
An image compression manager is a
service within QuickTime that deals

00:01:33.160 --> 00:01:35.680
with compression and decompression.

00:01:36.120 --> 00:01:40.030
And so we create these compressor
components and decompressor

00:01:40.110 --> 00:01:42.720
components underneath the ICM,
which are created by

00:01:42.870 --> 00:01:46.710
Apple and third parties,
and that serves as the codec model.

00:01:46.720 --> 00:01:49.340
And there's a base codec,
a base decompressor,

00:01:49.400 --> 00:01:51.490
which helps implement decoders.

00:01:51.550 --> 00:01:54.350
And we recommend you actually use that,
and you'll see today that

00:01:54.350 --> 00:01:59.000
it's actually essential for
the new decompressor formats.

00:02:00.620 --> 00:02:03.100
So, before Tiger,
there were some limitations

00:02:03.100 --> 00:02:06.340
in the movie toolbox and the
video media handler in ICM.

00:02:06.520 --> 00:02:10.770
This wasn't really a big issue
because most of the codecs were

00:02:10.780 --> 00:02:15.500
either iframe or keyframe codecs,
such as DV or motion JPEG,

00:02:15.550 --> 00:02:21.540
or difference frame or IP coded videos,
such as MPEG-4 simple profile, CinePack,

00:02:21.710 --> 00:02:24.110
the Sorenson codecs, etc.

00:02:24.370 --> 00:02:27.580
What we didn't support is the
more complex frame ordering,

00:02:27.580 --> 00:02:32.990
IPB frame ordering that's
used within H.264 and MPEG-2,

00:02:33.060 --> 00:02:34.210
MPEG-1.

00:02:34.280 --> 00:02:37.660
Now, we do support MPEG-1 and 2,
but that's via the MPEG media handler,

00:02:37.660 --> 00:02:38.700
not the video media handler.

00:02:38.700 --> 00:02:41.000
It's a different code path,
and we're not changing

00:02:41.000 --> 00:02:43.470
that code path in Tiger.

00:02:43.860 --> 00:02:46.470
So today we're going to
cover some fundamentals about

00:02:46.470 --> 00:02:51.630
the new H.264 video codec,
details about what IPB is and

00:02:51.680 --> 00:02:53.240
how it differs from I and IP.

00:02:53.240 --> 00:02:55.500
By the end, you'll really know that.

00:02:55.550 --> 00:02:59.750
The user level impact of the changes
that we're doing in QuickTime 6.6,

00:02:59.750 --> 00:03:04.040
changes to the movie toolbox
for navigation editing,

00:03:04.040 --> 00:03:08.540
and of course the changes to the ICM to
support these new kinds of video codecs.

00:03:08.540 --> 00:03:12.560
With that, I'd like to bring up
Thomas Pun to talk about H.264.

00:03:18.310 --> 00:03:21.870
Hi, I'm Thomas and I work in the
Video Codec team in QuickTime.

00:03:21.960 --> 00:03:25.750
Oh, actually, back to the side first.

00:03:26.130 --> 00:03:31.120
So today I'm going to
briefly talk about H.264.

00:03:31.120 --> 00:03:34.160
I'm sure you guys have all heard
about it throughout the whole week.

00:03:34.160 --> 00:03:35.830
I'm just going to recap.

00:03:36.040 --> 00:03:38.440
So H.264, what is it?

00:03:38.440 --> 00:03:44.700
It's a joint effort from the two biggest
organizations regarding standards.

00:03:44.780 --> 00:03:47.260
One is the ISO and the
other one is the ITU.

00:03:47.260 --> 00:03:50.030
They brought us video
standards such as MPAT-1,

00:03:50.030 --> 00:03:53.200
MPAT-2, and also H.261, H.263.

00:03:54.330 --> 00:03:57.160
Now because it's a joint
effort at different stage,

00:03:57.160 --> 00:03:59.500
they seem to give this
codec a different name.

00:03:59.500 --> 00:04:07.500
So you may also heard MPAT-4 Part 10,
JVT, H.264, and also AVC.

00:04:07.670 --> 00:04:12.650
Now it's standardized in last year,
so it's a very recent addition

00:04:12.650 --> 00:04:14.610
to the video standard.

00:04:14.770 --> 00:04:22.110
and it has all the new technologies and
it works very well at various bitrate all

00:04:22.110 --> 00:04:25.980
the way down to 3G all the way up to HD.

00:04:25.980 --> 00:04:29.510
And because of that,
it has recently been chosen for one

00:04:29.520 --> 00:04:34.580
of the video codecs for HD DVD and
also 3GPP standards as well.

00:04:34.580 --> 00:04:38.540
And because QuickTime always stands
behind standards and it will for sure

00:04:38.540 --> 00:04:41.380
become a new video codec in QuickTime.

00:04:41.530 --> 00:04:45.600
and with that I'm just
going to show some demos.

00:04:45.620 --> 00:04:48.090
Can you go to your demo machine please?

00:04:48.880 --> 00:04:53.820
Now, as I said,
it has been recently chosen for HD-DVD,

00:04:53.820 --> 00:04:57.690
and let's see how it
looks at HD resolution.

00:05:00.950 --> 00:05:03.910
I have a clip here, a sender.

00:05:04.000 --> 00:05:07.810
It's encoded at HD resolution
1280 by about 550.

00:05:07.950 --> 00:05:12.670
And this is actually only at 6 megabit.

00:05:12.710 --> 00:05:17.660
We couldn't really do that with
MPAT 2 at this kind of quality before.

00:05:17.740 --> 00:05:18.560
So let's see.

00:05:18.560 --> 00:05:21.370
I'm going to play the whole clip.

00:05:45.700 --> 00:05:53.700
[Transcript missing]

00:07:10.280 --> 00:07:12.540
So that's how it looks at 6 megabit.

00:07:12.570 --> 00:07:16.080
And if you actually play
with our encoding video,

00:07:16.080 --> 00:07:19.280
you notice at the beginning,
the sandstorm is actually

00:07:19.280 --> 00:07:20.730
really hard to code.

00:07:20.820 --> 00:07:25.100
And the codec does it really well.

00:07:25.700 --> 00:07:29.380
Another demo that I'm going to show
is to give you an idea of how it

00:07:29.380 --> 00:07:31.600
compares with existing standards.

00:07:31.970 --> 00:07:34.600
One that I chose is MP4.

00:07:34.600 --> 00:07:39.160
So I'm going to open this file first.

00:07:44.860 --> 00:07:50.100
Now when we try to compare
with different standards,

00:07:50.100 --> 00:07:52.300
we usually use three guidelines.

00:07:52.500 --> 00:07:56.630
You fix the bit rate, you have quality,
how does the quality look,

00:07:56.630 --> 00:07:59.340
how does the bit rate,
so one could be a lot bigger,

00:07:59.340 --> 00:08:00.300
twice as big.

00:08:00.350 --> 00:08:03.560
The other one is how much information
you actually pack in the stream.

00:08:03.610 --> 00:08:07.700
So that goes with frame rate,
with resolution or frame size.

00:08:07.720 --> 00:08:12.410
So here I have two clips,
both of them encoded at megabit.

00:08:12.830 --> 00:08:20.800
The H.264 one is about four
times as big as the MPAT-4

00:08:20.800 --> 00:08:23.700
one that we shipped earlier.

00:08:23.700 --> 00:08:25.670
So I'm going to play this.

00:08:25.670 --> 00:08:29.700
I'm just going to play a short,
about 30 seconds.

00:08:29.700 --> 00:08:32.410
I'm going to play a movie.

00:08:35.170 --> 00:08:38.540
So the quality is about the same,
except that the rest of

00:08:38.540 --> 00:08:44.500
the... ♪ ♪ Thomas Sykes,
Spooner.

00:08:50.400 --> 00:09:05.100
[Transcript missing]

00:09:05.400 --> 00:09:21.400
[Transcript missing]

00:09:21.840 --> 00:09:27.100
We can play the whole clip later
if anyone wants to continue.

00:09:27.110 --> 00:09:29.860
So can we get back to the slide, please?

00:09:33.460 --> 00:09:36.460
So what makes this
codec a lot better than,

00:09:36.570 --> 00:09:41.040
say, MPAT 4, MPAT 2 that we already have?

00:09:41.220 --> 00:09:44.890
So here's a big table that
I'm sure some of you may have

00:09:44.890 --> 00:09:46.020
seen it from another section.

00:09:46.020 --> 00:09:50.440
What I really want to point
out here is three things.

00:09:50.440 --> 00:09:53.110
The first one is there's really
not one single technology

00:09:53.180 --> 00:09:54.600
that gives you all the gains.

00:09:54.610 --> 00:09:58.260
It's a combination of
advances in different fields,

00:09:58.260 --> 00:10:00.280
different technologies.

00:10:00.280 --> 00:10:04.520
Most of the technologies that
we use in H.264 are based on

00:10:04.520 --> 00:10:07.710
technologies that we already have,
like 10 years ago.

00:10:07.970 --> 00:10:11.730
So we have a lot more improvement
and we know how to use the

00:10:11.730 --> 00:10:14.370
technologies a lot better.

00:10:14.590 --> 00:10:20.220
Second thing is I want to bring out is,
as we mentioned earlier, that,

00:10:20.310 --> 00:10:23.060
for example, MPAT 2,
it took us a couple of years to try

00:10:23.060 --> 00:10:24.980
to get the best out of the MPAT 2.

00:10:24.980 --> 00:10:28.440
And H.264 is a very new standard.

00:10:28.440 --> 00:10:29.960
It's just standardized last year.

00:10:29.960 --> 00:10:34.500
So you should expect the quality
of H.264 stream getting better

00:10:34.500 --> 00:10:38.910
and better once we know how to use
the tools even more efficiently.

00:10:40.380 --> 00:10:44.320
And the last thing is,
a lot of the technologies here,

00:10:44.320 --> 00:10:47.060
I'm not going to go over all
of them because it's boring.

00:10:47.060 --> 00:10:50.780
But most of the technologies,
what it really means is it's

00:10:50.780 --> 00:10:53.090
self-contained within a codec.

00:10:53.100 --> 00:10:56.740
So your codec just have to implement it,
for example, a different transform,

00:10:56.740 --> 00:11:00.040
different way of packing
the bits in the streams.

00:11:00.040 --> 00:11:03.630
But there's one particular technology,
which is...

00:11:05.120 --> 00:11:09.930
and the IPB frames,
which is the third column down.

00:11:10.520 --> 00:11:13.090
With H.264, you have a lot more options.

00:11:13.120 --> 00:11:15.400
It's very flexible.

00:11:15.400 --> 00:11:17.980
You can do almost anything you want.

00:11:18.000 --> 00:11:21.940
The simplest form is about
the same as the previous MPAC,

00:11:21.940 --> 00:11:25.000
IBP, which we're going to explain more.

00:11:25.090 --> 00:11:27.400
But if you really need
to take advantage of it,

00:11:27.400 --> 00:11:30.210
then the higher layer
will require some changes,

00:11:30.220 --> 00:11:34.000
and thus QuickTime will have to
make some structural change as well.

00:11:34.250 --> 00:11:38.990
And that's going to bring it to an end,
which is going to talk about what changes

00:11:38.990 --> 00:11:45.000
in QuickTime are needed to support H.264.

00:11:54.050 --> 00:11:57.900
So how are we going to
deliver H.264 in QuickTime?

00:11:57.980 --> 00:12:01.680
We've added four new
H.264 specific components,

00:12:01.680 --> 00:12:04.740
a compressor/decompressor and
a packetizer and reassembler,

00:12:04.840 --> 00:12:07.780
and made a whole lot of changes
inside the infrastructure

00:12:07.780 --> 00:12:10.090
to support these components.

00:12:11.510 --> 00:12:15.900
with Tiger, applications will be able
to play back H.264 content.

00:12:15.900 --> 00:12:18.760
They can also play back H.264 streams.

00:12:18.760 --> 00:12:21.640
And if they use the
high-level movie toolbox APIs,

00:12:21.640 --> 00:12:23.980
they'll be able to do this
without any changes in their apps.

00:12:25.380 --> 00:12:31.820
In addition, to QuickTime movie files,
we'll be able to store these H.264

00:12:32.070 --> 00:12:36.170
streams in MP4 files and 3GPP files.

00:12:38.570 --> 00:12:42.150
and the streaming realm will
fully support H.264 in that you

00:12:42.370 --> 00:12:46.900
can play back H.264 streams,
you can take H.264 content, hint them,

00:12:46.900 --> 00:12:50.200
put them on the QuickTime streaming
server and stream them to clients,

00:12:50.200 --> 00:12:53.500
and you can broadcast using
QuickTime Broadcaster.

00:12:53.690 --> 00:13:00.700
These H.264 streams are in the
standard format as defined by the IETF.

00:13:03.530 --> 00:13:06.500
On the authoring front,
applications will be able

00:13:06.590 --> 00:13:09.520
to edit H.264 movies,
and if they call the

00:13:09.520 --> 00:13:12.430
high-level movie toolbox APIs,
they'll be able to cut, copy,

00:13:12.440 --> 00:13:13.680
paste with no changes.

00:13:13.680 --> 00:13:19.230
They'll be able to produce H.264 content
and store them in QuickTime files,

00:13:19.230 --> 00:13:21.700
also MP4 files, 3GPP files.

00:13:25.890 --> 00:13:30.700
So if you want to compress H.264 content,
you can do it using the

00:13:30.840 --> 00:13:32.170
movie exporter components.

00:13:32.220 --> 00:13:35.830
And if you call these components,
we've modified them so that they

00:13:35.920 --> 00:13:38.660
can generate H.264 B-frame content.

00:13:38.660 --> 00:13:42.620
Now, if you call std compression and
the ICM APIs yourself instead

00:13:42.620 --> 00:13:46.840
of the movie exporter APIs,
then H.264 will show up as a

00:13:46.840 --> 00:13:48.790
new item in the codec list.

00:13:49.160 --> 00:13:52.040
However,
B-frames won't be enabled by default.

00:13:52.440 --> 00:13:55.500
And in order to get B-frame content,
you'll have to opt in to B-frames

00:13:55.500 --> 00:13:58.260
by calling new APIs that we'll
describe in this session.

00:14:00.600 --> 00:14:06.000
If you call the sequence grabber
APIs and you want H.264 B-frame content,

00:14:06.030 --> 00:14:10.220
you'll have to call std compression
and compress the frames yourself.

00:14:13.220 --> 00:14:15.440
So what's in the seed?

00:14:15.440 --> 00:14:16.990
With the seed,
you'll be able to play back

00:14:17.090 --> 00:14:20.240
H.264 streams and edit them.

00:14:20.240 --> 00:14:23.740
We've been working really hard on H.264,
but we haven't fully integrated

00:14:23.740 --> 00:14:26.620
it into all our exporters yet.

00:14:26.700 --> 00:14:30.120
But we really wanted to get
you something in your hands,

00:14:30.120 --> 00:14:33.280
so we've included a
preview H.264 exporter.

00:14:33.300 --> 00:14:36.700
It appears as a new menu
item in the exporter list,

00:14:36.720 --> 00:14:39.530
and it does support multi-passing code.

00:14:39.640 --> 00:14:44.160
One thing to note is that it
produces an interim format right now.

00:14:44.160 --> 00:14:45.920
The format is guaranteed
to change before GM,

00:14:45.920 --> 00:14:49.010
so don't produce any content that
you want to stick around for a long

00:14:49.010 --> 00:14:53.610
time and be able to play it back,
with the seed anyway.

00:14:54.000 --> 00:14:56.370
The APIs we talk about
today are in the seed,

00:14:56.410 --> 00:14:57.590
so please try them out.

00:14:57.750 --> 00:15:01.780
And a couple things, H.264,
there's a lot going on there,

00:15:01.790 --> 00:15:04.020
so it requires a G4 or G5.

00:15:04.020 --> 00:15:06.940
And also the seed doesn't
contain a compressor,

00:15:06.970 --> 00:15:09.770
packetizer, or reassembler yet.

00:15:12.350 --> 00:15:15.880
So, say you want to take advantage
of H.264 in your application.

00:15:15.880 --> 00:15:18.060
What do you have to do and
what do you have to change?

00:15:18.080 --> 00:15:22.550
Well, what you have to change depends on
what level of APIs you're calling.

00:15:22.560 --> 00:15:25.860
If you're calling into the
high-level QuickTime APIs,

00:15:25.860 --> 00:15:28.560
then chances are you don't have
to do anything in order to gain

00:15:28.560 --> 00:15:30.550
support for H.264 in your app.

00:15:30.660 --> 00:15:33.830
However,
if you call some of the lower-level APIs,

00:15:33.830 --> 00:15:36.610
such as the media level,
you might or might not have to

00:15:36.690 --> 00:15:40.500
change your application depending on
what specific APIs you're calling.

00:15:40.500 --> 00:15:43.210
And if you access the
sample-level APIs yourself,

00:15:43.210 --> 00:15:46.990
if you access the samples yourself,
you'll have to change your app.

00:15:50.930 --> 00:15:54.020
So as I said,
if you call the high-level APIs,

00:15:54.030 --> 00:15:58.880
you'll be able to gain access to
H.264 with no changes to your app.

00:15:58.980 --> 00:16:02.150
And some examples of the
high-level APIs are the various

00:16:02.150 --> 00:16:06.600
views that QuickTime provides,
such as the new Qt Movie View,

00:16:06.600 --> 00:16:09.400
part of the Qt Kit,
the new HI Movie View,

00:16:09.400 --> 00:16:11.340
and the older Carbon Movie Control.

00:16:13.000 --> 00:16:14.640
If you use those views, you're all set.

00:16:14.640 --> 00:16:18.620
You don't have to do anything
in order to use H.264.

00:16:18.620 --> 00:16:21.200
If you call the movie
and track level APIs,

00:16:21.200 --> 00:16:24.390
you'll still be able to play back,
step through the movies, edit them,

00:16:24.390 --> 00:16:27.400
navigate through the movies
without any changes in your app.

00:16:27.400 --> 00:16:30.060
So let's have a look at that.

00:16:39.560 --> 00:16:40.340
Okay.

00:16:40.340 --> 00:16:50.380
Here I have a H.264 movie
that I've compressed,

00:16:50.410 --> 00:16:55.690
and if I drop it on the currently
shipping version of Adobe Go Live,

00:16:56.600 --> 00:17:02.610
I can go and it opens as expected
and it plays the video as expected.

00:17:08.540 --> 00:17:11.500
Turn to page 394.

00:17:11.540 --> 00:17:17.500
Okay, and just for fun,
I can bring up this

00:17:17.500 --> 00:17:22.560
timeline editor in Go Live,
and if I click around in there,

00:17:22.590 --> 00:17:25.230
I can click around in the movie
and step around in the movie,

00:17:25.230 --> 00:17:26.120
and that works.

00:17:34.000 --> 00:17:38.160
I can also take this movie
into QuickTime Player,

00:17:38.160 --> 00:17:42.700
select a portion of the movie,

00:17:46.010 --> 00:17:50.070
go over here,
copy that small portion of the movie.

00:17:50.070 --> 00:17:55.080
And this is the currently
shipping version of Word.

00:17:55.100 --> 00:18:00.200
I can create a new document
and if I go and paste,

00:18:00.200 --> 00:18:05.140
then that small section of the
movie is pasted into the document

00:18:05.140 --> 00:18:07.660
and Word will play it back.

00:18:07.670 --> 00:18:13.260
There's something moving out there.

00:18:13.260 --> 00:18:14.200
It was a Dementor.

00:18:18.740 --> 00:18:24.860
So use the high-level APIs if at all
possible because when you do that,

00:18:24.860 --> 00:18:27.670
with each new release of QuickTime,
you'll gain a lot of new functionality

00:18:27.670 --> 00:18:29.720
and usually you won't have to
make any changes to your app

00:18:29.810 --> 00:18:31.200
and they'll just magically work.

00:18:31.290 --> 00:18:36.100
Can we go back to slides?

00:18:41.140 --> 00:18:45.610
Okay, so if you can't just call the
high-level APIs and you have to

00:18:45.610 --> 00:18:47.430
call some of the lower-level APIs,
well,

00:18:47.460 --> 00:18:51.020
in order to use this B-Frame content,
you might have to

00:18:51.020 --> 00:18:52.450
change your application.

00:18:52.460 --> 00:18:55.630
So if you're calling the
media-level APIs and you call

00:18:55.630 --> 00:18:59.040
APIs that don't reference time,
durations, or sample flags,

00:18:59.050 --> 00:19:01.260
then those APIs haven't changed.

00:19:01.340 --> 00:19:02.620
You don't have to do anything.

00:19:05.380 --> 00:19:08.640
However,
if you do make calls at that level that

00:19:08.640 --> 00:19:12.480
reference time duration or sample flags,
it won't work with the new

00:19:12.480 --> 00:19:15.190
B-frame content and you'll have
to change your application.

00:19:15.200 --> 00:19:19.000
You obviously can still use those APIs.

00:19:19.000 --> 00:19:23.400
It will still work with content
that doesn't contain B-frames,

00:19:23.400 --> 00:19:26.120
but once you start trying
to use it with B-frames,

00:19:26.120 --> 00:19:28.020
those APIs will return errors.

00:19:28.060 --> 00:19:30.620
And we've added some new
errors so you know that that's

00:19:30.620 --> 00:19:32.020
the cause of the problem.

00:19:33.680 --> 00:19:38.370
Instead of using those older APIs,
we've added some new APIs for you to use.

00:19:38.380 --> 00:19:43.880
If you use sample references,
then we've added a whole new

00:19:43.880 --> 00:19:46.900
set of Qt sample table APIs,
which I'll describe later.

00:19:46.900 --> 00:19:51.370
And for everything else,
we've added similar-looking APIs,

00:19:51.370 --> 00:19:53.910
which I'll also describe later.

00:19:57.820 --> 00:20:00.890
Okay,
and one last thing before Sam comes up.

00:20:01.060 --> 00:20:06.800
I want to stress that these new APIs work
for content that contains Bframes,

00:20:06.800 --> 00:20:09.040
but they also work for
all the other content too.

00:20:09.040 --> 00:20:13.090
So please switch to
them whenever you can.

00:20:13.280 --> 00:20:16.900
and here's Sam to talk about B-Frames.

00:20:16.900 --> 00:20:17.740
- Thanks Anne.

00:20:17.740 --> 00:20:19.400
- Thank you.

00:20:22.520 --> 00:20:23.540
Hi, I'm Sam.

00:20:23.590 --> 00:20:28.600
Let's talk for a moment about
video compression technology.

00:20:30.300 --> 00:20:37.740
Lossy Video Codecs provide you with a
tradeoff between quality and bit rate.

00:20:37.740 --> 00:20:40.610
If you want more quality,
you need to use more bits.

00:20:40.680 --> 00:20:44.440
If you can't use so many bits,
you might have to accept a lower quality.

00:20:44.520 --> 00:20:50.800
And we're constantly trying to improve
this quality curve and move it towards

00:20:51.060 --> 00:20:53.200
A higher quality at a lower bit rate.

00:20:53.250 --> 00:20:55.440
And we do this by adding more tricks.

00:20:55.530 --> 00:20:59.960
As Thomas said, many of these tricks are
self-contained within the codec,

00:20:59.960 --> 00:21:03.310
but some of them require
awareness outside the codec

00:21:03.330 --> 00:21:06.440
in other parts of the system,
other modules.

00:21:06.440 --> 00:21:08.590
And that's what we're
going to talk about.

00:21:10.670 --> 00:21:14.720
So, suppose you had some video
that you wanted to compress.

00:21:14.820 --> 00:21:19.030
Here's a clip of some
guy parking his car.

00:21:19.060 --> 00:21:22.950
It's prosaic, but this is educational.

00:21:23.800 --> 00:21:27.460
So we could encode each of
these frames independently.

00:21:27.490 --> 00:21:32.880
If we did this, this is called spatial
compression because we're only

00:21:33.320 --> 00:21:35.920
compressing in the spatial domain.

00:21:37.690 --> 00:21:40.750
If every frame is self-contained,
we call it key frames,

00:21:40.820 --> 00:21:43.230
we call it sync samples,
we call them iframes.

00:21:43.530 --> 00:21:45.100
I stands for intra.

00:21:45.210 --> 00:21:51.420
Random access is fast, which is good,
but the data rate isn't so good.

00:21:51.810 --> 00:21:55.940
Because if we're compressing
everything independently,

00:21:55.990 --> 00:21:58.550
we're not taking advantage of
the similarities between frames.

00:21:58.640 --> 00:22:04.600
I've got frames 4 and 5 of the
previous 6 on the screen here,

00:22:04.770 --> 00:22:08.300
and you can see that the tree and the
building are practically the same.

00:22:08.300 --> 00:22:12.690
And the car has moved a little,
but it's mostly the same.

00:22:13.620 --> 00:22:21.440
So we can improve compression performance
substantially by using one frame as

00:22:21.460 --> 00:22:23.460
the basis for describing another frame.

00:22:23.480 --> 00:22:27.980
And the jargon for this in codec
terminology is temporal prediction.

00:22:30.020 --> 00:22:33.710
The way it works is you start
off by saying these are the

00:22:33.710 --> 00:22:39.170
areas of the new frame that are
similar to areas of the old frame.

00:22:39.930 --> 00:22:42.160
For example,
in the example that I've got here,

00:22:42.360 --> 00:22:45.560
we're describing frame
5 in terms of frame 4.

00:22:45.740 --> 00:22:49.520
So first,
in the yellow parts of the screen,

00:22:49.520 --> 00:22:53.040
we're saying these pixels are more
or less the same as the pixels

00:22:53.040 --> 00:22:55.800
in the same location in frame 4.

00:22:55.910 --> 00:22:59.580
And then the green part,
that's where we're saying these pixels

00:22:59.580 --> 00:23:05.390
are like the frames if you just move
over so many pixels to the right.

00:23:06.520 --> 00:23:10.060
But these are only first approximations.

00:23:10.060 --> 00:23:14.620
There's still a fix-up that has to be
added because the wheel is turning and

00:23:14.620 --> 00:23:16.180
the reflection doesn't move with the car.

00:23:16.180 --> 00:23:17.580
It sort of seems to stay in place.

00:23:17.720 --> 00:23:20.230
And so you can see that
there's an additional image

00:23:20.260 --> 00:23:21.780
that must be added as well.

00:23:21.780 --> 00:23:23.650
This is called the residue.

00:23:23.690 --> 00:23:26.470
The first part is called
motion compensation and the

00:23:26.490 --> 00:23:28.170
fix-up is called the residue.

00:23:28.220 --> 00:23:33.280
And you'll notice that there's a
strip of that car that is in frame

00:23:33.370 --> 00:23:36.720
five that wasn't there in frame four.

00:23:36.840 --> 00:23:39.420
And this part might need
to be coded from scratch,

00:23:39.430 --> 00:23:40.860
encoded from scratch.

00:23:43.960 --> 00:23:47.420
So this is what we get if we
encode the last five frames out of

00:23:47.420 --> 00:23:52.770
those six as a motion compensation
piece and then a residue.

00:23:53.040 --> 00:23:56.000
We call these difference
frames or P frames.

00:23:56.150 --> 00:23:58.610
P stands for predicted.

00:23:59.770 --> 00:24:04.240
Well, we get better compression because
motion compensation can be described

00:24:04.270 --> 00:24:10.460
extremely compactly relative to
describing something from scratch.

00:24:10.460 --> 00:24:13.030
And as a result, the bit rate that we get
is a whole lot better.

00:24:15.310 --> 00:24:18.270
There's something else that's
worth paying attention to here,

00:24:18.270 --> 00:24:21.790
which is that each of these frames

00:24:21.840 --> 00:24:27.930
The encoded frame can only be interpreted
with reference to the previous one,

00:24:27.930 --> 00:24:33.310
which means each frame in a way
depends on the previous one.

00:24:33.310 --> 00:24:33.310
If you want to

00:24:33.870 --> 00:24:37.750
Decode and display the last frame
in this sequence and you haven't

00:24:37.790 --> 00:24:40.420
decoded the previous frames,
well you better go and

00:24:40.420 --> 00:24:41.450
do that right away.

00:24:41.650 --> 00:24:46.470
So random access into a sequence like
this could be somewhat expensive.

00:24:47.120 --> 00:24:52.110
So when we have iframes and pframes,
or keyframes and difference frames,

00:24:52.330 --> 00:24:53.800
This is what it's like.

00:24:53.920 --> 00:24:56.820
We call it IP for I frames and P frames.

00:24:56.870 --> 00:25:00.510
And it gives you much better
compression than I frames only,

00:25:00.610 --> 00:25:03.110
but random access can be somewhat slower.

00:25:03.210 --> 00:25:06.020
For example,
if the key frame rate is 20 frames,

00:25:06.030 --> 00:25:09.260
you might have to decode 20
frames before you can display

00:25:09.260 --> 00:25:11.010
the one that you want to see.

00:25:12.180 --> 00:25:15.650
Another thing to pay attention to
is that gradually appearing images

00:25:15.990 --> 00:25:19.620
are constructed incrementally,
like the car in this clip.

00:25:19.700 --> 00:25:23.760
The image of the car that you see
in frame six was constructed out

00:25:23.770 --> 00:25:27.660
of strips in five different frames.

00:25:27.740 --> 00:25:31.170
This might not be the most
efficient way of doing things.

00:25:33.040 --> 00:25:35.710
So let's introduce an alternative.

00:25:36.050 --> 00:25:39.820
What if we encode the first frame
in that sequence as an iframe,

00:25:40.020 --> 00:25:43.200
self-contained,
and then go all the way to the

00:25:43.500 --> 00:25:49.700
end and encode frame 6 as a
pframe based on that iframe?

00:25:51.060 --> 00:25:54.970
Well, if we'd done that first,
then we can encode all the frames in

00:25:54.970 --> 00:25:59.910
between using motion compensation,
part from the previous frame,

00:26:00.030 --> 00:26:04.830
that's the yellow piece,
and part from the later frame,

00:26:04.840 --> 00:26:05.680
which is the blue piece.

00:26:05.680 --> 00:26:10.280
And you can see that these frames are
almost entirely motion compensation.

00:26:10.280 --> 00:26:13.610
Very little residue to encode.

00:26:14.290 --> 00:26:17.330
Here's what it looks like
if we encode our six frames,

00:26:17.370 --> 00:26:21.420
which with all of the four frames
in the middle encoded as B frames,

00:26:21.500 --> 00:26:23.700
which stands for
bidirectional prediction,

00:26:23.790 --> 00:26:26.800
based on the frames at the end.

00:26:27.850 --> 00:26:30.420
Again,
these four frames in the middle are

00:26:30.420 --> 00:26:33.130
almost entirely motion compensation.

00:26:34.180 --> 00:26:38.020
and another thing to notice about them is
that random access can be a bit faster.

00:26:38.040 --> 00:26:41.060
For any of the frames in the middle,
starting from scratch,

00:26:41.060 --> 00:26:44.480
if you needed to display those,
you only need to decode three frames,

00:26:44.480 --> 00:26:46.760
the one at the beginning,
the one at the end and

00:26:46.760 --> 00:26:47.340
the one in the middle.

00:26:54.620 --> 00:26:55.920
So these are B-frames.

00:26:55.960 --> 00:27:00.190
They refer to information in a
future frame as well as perhaps

00:27:00.470 --> 00:27:02.040
information from a previous frame.

00:27:02.040 --> 00:27:05.250
And the good news about B-frames
is that they let us enhance

00:27:05.250 --> 00:27:10.410
the compression quality,
lower the bitrate even further.

00:27:13.100 --> 00:27:16.940
There's two benefits.

00:27:16.940 --> 00:27:19.400
You get better compression,
especially when objects appear gradually,

00:27:19.810 --> 00:27:21.860
for the reasons that we've described.

00:27:21.880 --> 00:27:23.600
And also, random access is faster.

00:27:23.690 --> 00:27:27.240
As I illustrated,
accessing any of those frames,

00:27:27.420 --> 00:27:31.780
the worst case for random access
is having to decode three frames.

00:27:33.700 --> 00:27:37.300
Another example to think about is
if you're playing in fast forward.

00:27:37.300 --> 00:27:41.950
You could skip the frames you didn't
need to display if they were B frames.

00:27:42.860 --> 00:27:44.640
You wouldn't have to decode them at all.

00:27:44.670 --> 00:27:47.980
The jargon for this is
temporal scalability.

00:27:50.190 --> 00:27:54.030
But there's something
tricky about B-frames.

00:27:54.400 --> 00:27:57.710
The decoder that's displaying these

00:27:57.800 --> 00:28:03.400
can only use motion compensation
from frames that's already decoded.

00:28:03.400 --> 00:28:06.040
If one of those frames is
going to be displayed later,

00:28:06.160 --> 00:28:09.160
then that means the order in which
frames are decoded and the order in

00:28:09.190 --> 00:28:12.020
which frames are displayed is different.

00:28:12.130 --> 00:28:14.590
So the frames have to
be reordered somewhere.

00:28:14.640 --> 00:28:18.550
And this reordering is why
your application might need

00:28:18.630 --> 00:28:20.770
to understand B-frames.

00:28:21.730 --> 00:28:24.550
So some of you have been working
with IPB codecs for some time

00:28:24.660 --> 00:28:26.640
and this is no news to you.

00:28:26.640 --> 00:28:30.110
But I wanted to speak to you guys for
a moment because there's an important

00:28:30.110 --> 00:28:32.250
point that I want to drive home.

00:28:32.920 --> 00:28:38.710
With some other IPB codecs,
you can implement playback using

00:28:38.710 --> 00:28:43.450
a small finite state machine,
which is driven with different

00:28:43.450 --> 00:28:48.060
transitions for iframes,
pframes, and bframes.

00:28:49.500 --> 00:28:55.160
And this works for MPEG-2 because
only one frame can be held at a time.

00:28:55.270 --> 00:28:58.360
There's only one future frame
that would ever need to have

00:28:58.360 --> 00:29:00.530
been decoded but not displayed.

00:29:00.920 --> 00:29:04.040
And this is not true for H.264.

00:29:04.050 --> 00:29:09.630
The standard for H.264 allows up
to 16 future frames to be held.

00:29:11.570 --> 00:29:14.850
In fact,
H.264 allows the encoder an enormous new

00:29:14.850 --> 00:29:22.740
amount of flexibility in how it chooses
to find material for motion compensation.

00:29:22.810 --> 00:29:27.300
P and B frames can depend
on up to 16 frames.

00:29:27.840 --> 00:29:30.140
Not all iframes reset
the decoder completely.

00:29:30.140 --> 00:29:31.960
We have a new tag for those.

00:29:32.290 --> 00:29:35.120
The name in H.264 is IDR frames,
which stands for

00:29:35.180 --> 00:29:37.140
Instantaneous Decoder Reset,
if you care.

00:29:38.540 --> 00:29:43.740
Some B-frames can be used to provide
material for motion compensation,

00:29:43.830 --> 00:29:46.100
so not all B-frames can be skipped.

00:29:46.270 --> 00:29:49.900
And some I-frames and P-frames
can be skipped because they don't

00:29:49.950 --> 00:29:52.500
count for motion compensation.

00:29:52.700 --> 00:29:56.940
So, as on the left,
you can see that the pattern for

00:29:57.160 --> 00:30:03.130
MPEG-2 is fairly regular and,
in fact, you can entirely derive

00:30:03.440 --> 00:30:09.600
The dependency graph of the frames,
just knowing the frame letters,

00:30:09.630 --> 00:30:11.640
and that's how the finite
state machine works.

00:30:11.660 --> 00:30:14.590
Everything can be worked
out from the frame letters.

00:30:14.650 --> 00:30:19.870
But with H.264, the encoder is free to do
things in a much wilder way

00:30:20.100 --> 00:30:22.300
and just knowing those letters,
those frame letters,

00:30:22.370 --> 00:30:23.590
doesn't let you derive the graph.

00:30:23.660 --> 00:30:27.820
In fact, as you can see,
I didn't know that you'd really

00:30:27.820 --> 00:30:32.070
want to try and store that graph
unless you were the decoder itself.

00:30:32.160 --> 00:30:34.660
So.

00:30:37.070 --> 00:30:42.600
The new rules,
if you want to work in H.264,

00:30:42.610 --> 00:30:46.660
it's no longer sufficient to use
the frame type letters to derive

00:30:46.820 --> 00:30:49.990
frame dependency information
and the dependency graph.

00:30:50.110 --> 00:30:54.150
Instead,
you should pay attention to four things.

00:30:56.250 --> 00:30:59.940
First is a frame of
synchronization sample.

00:30:59.950 --> 00:31:02.980
Not all iframes are sync samples.

00:31:03.680 --> 00:31:08.310
This is because an iframe may not,
if you decode an iframe,

00:31:08.320 --> 00:31:11.210
that may not prime the decoder

00:31:11.580 --> 00:31:16.500
with all of the motion compensation
material that it'll need in

00:31:16.500 --> 00:31:19.300
P and B frames that follow it.

00:31:19.940 --> 00:31:23.880
So instead,
you only want to pay attention to

00:31:23.880 --> 00:31:26.270
whether a frame is a sync sample,
which is equivalent in the

00:31:26.270 --> 00:31:27.500
new world to an IDR frame.

00:31:29.570 --> 00:31:32.480
Number two is a frame droppable.

00:31:32.480 --> 00:31:37.300
Now some B frames are not
droppable and some INP frames are.

00:31:37.300 --> 00:31:40.040
And that's the information that
if you're outside of the codec

00:31:40.040 --> 00:31:41.390
that you really want to know.

00:31:41.390 --> 00:31:44.280
You want to know whether you
need to decode that frame in

00:31:44.290 --> 00:31:48.690
order to get random access.

00:31:48.690 --> 00:31:49.780
Number three.

00:31:50.790 --> 00:31:53.380
What order must the frames be decoded in?

00:31:53.380 --> 00:31:58.080
And sometimes it's also sensible to
include information about what time

00:31:58.080 --> 00:32:01.570
the frames should be encoded at,
decoded at.

00:32:02.060 --> 00:32:05.330
Number four, what time should each
frame be displayed at?

00:32:05.570 --> 00:32:08.490
And this is how we know how
the frames are reordered.

00:32:12.120 --> 00:32:13.100
to summarize.

00:32:13.100 --> 00:32:16.370
Dependencies between
frames are getting weirder,

00:32:16.370 --> 00:32:22.700
but it's all in the cause of improving
the quality versus bit rate trade-off.

00:32:22.770 --> 00:32:27.410
Number two, IPB means someone needs to
know about frame reordering,

00:32:27.410 --> 00:32:29.090
and if you work with
the compressed media,

00:32:29.190 --> 00:32:31.040
it could be you.

00:32:31.200 --> 00:32:35.250
and three, some of the convenient rules,
things like the one frame delay

00:32:35.540 --> 00:32:38.540
and the ability to build this
little finite state machine,

00:32:38.660 --> 00:32:44.320
although they're okay for MPEG-2,
they don't hold for H.264.

00:32:44.320 --> 00:32:45.940
Back to Anne.

00:32:53.780 --> 00:32:56.740
So what changes did we have
to make in the movie toolbox

00:32:56.910 --> 00:32:58.700
in order to support B-frames?

00:32:58.750 --> 00:33:01.540
Well,
first we had to change the file format.

00:33:01.610 --> 00:33:04.480
For those of you who care
and parse the files yourself,

00:33:04.480 --> 00:33:08.800
we've added four new tables in the
QuickTime files when there's B-frames.

00:33:08.800 --> 00:33:15.140
One other thing to note is that samples
are stored in the files in decode order.

00:33:15.170 --> 00:33:18.200
Now, they've actually always been stored
in the files in decode order,

00:33:18.200 --> 00:33:20.760
but decode order and display
order were always the same before,

00:33:20.760 --> 00:33:23.070
so you couldn't tell the difference.

00:33:24.790 --> 00:33:28.450
We've added a bunch of new
APIs to distinguish between decode

00:33:28.450 --> 00:33:32.000
time and display time because,
as Sam explained, with B-frame content,

00:33:32.000 --> 00:33:35.700
they're not necessarily the same anymore.

00:33:38.040 --> 00:33:42.480
and some of those APIs take
something called a display offset.

00:33:42.510 --> 00:33:45.500
And a display offset is simply
just the difference between the

00:33:45.570 --> 00:33:46.980
decode time and the display time.

00:33:47.140 --> 00:33:52.460
And just note that sometimes
display offset is a negative number.

00:33:56.040 --> 00:33:59.190
Okay, so for example,
where you used to call

00:33:59.370 --> 00:34:03.840
sampleNumToMediaTime,
if you're processing B-frame content,

00:34:03.840 --> 00:34:06.290
that call is going to return an error.

00:34:06.300 --> 00:34:09.370
So instead of calling that,
you should call either

00:34:09.370 --> 00:34:13.630
sampleNumToMediaDisplayTime
or sampleNumToMediaDecodeTime,

00:34:13.660 --> 00:34:16.110
and which one you call depends on
which time it is that you want.

00:34:20.600 --> 00:34:24.490
We've added a whole bunch of new
sample flags and increased the

00:34:24.490 --> 00:34:26.660
size from 16 bits to 32 bits.

00:34:27.030 --> 00:34:29.190
Most of them are optional,
but the main one that you need to

00:34:29.190 --> 00:34:32.970
know about is media sample droppable,
which usually but not

00:34:32.970 --> 00:34:35.150
always indicates a B-frame.

00:34:37.400 --> 00:34:41.300
If you need to know whether a movie
or track contains B-frame content,

00:34:41.300 --> 00:34:47.020
don't hard code in if track is encoded
with H.264 because not all H.264

00:34:47.020 --> 00:34:48.860
movies necessarily contain B-frames.

00:34:48.860 --> 00:34:53.320
And we might add new codecs in
the future that use B-frames.

00:34:53.320 --> 00:34:57.520
So instead,
call MediaContainsDisplayOffsets.

00:35:00.080 --> 00:35:02.980
Okay,
so if you're using sample references,

00:35:03.090 --> 00:35:07.100
we've added a whole new set of APIs,
the Qt Sample Table APIs,

00:35:07.100 --> 00:35:08.920
for you to work with these.

00:35:08.920 --> 00:35:13.920
Qt Sample Tables represent media
sample references in a movie.

00:35:13.920 --> 00:35:16.460
They're reference-counted,
so use retain and release,

00:35:16.460 --> 00:35:18.740
similar to other Apple APIs.

00:35:18.740 --> 00:35:21.600
And you can use these
APIs for all media types,

00:35:21.600 --> 00:35:25.440
so audio, video, text, et cetera,
not just video and B-frames.

00:35:30.000 --> 00:35:35.000
are working on a new model in order
to get sample references out of

00:35:35.000 --> 00:35:36.750
a movie called Copy Media Mutable
Sample Table to get the sample table.

00:35:36.900 --> 00:35:40.030
From that, you can get the number
of samples in there,

00:35:40.170 --> 00:35:42.170
and then you can index
through the samples and get

00:35:42.290 --> 00:35:45.900
information about each sample,
such as data offset, sample flags,

00:35:45.900 --> 00:35:46.900
a whole bunch of things.

00:35:46.900 --> 00:35:54.020
And these samples are in decode order,
same as stored in the files.

00:35:55.440 --> 00:35:58.120
In order to add sample
references to a movie,

00:35:58.190 --> 00:36:03.580
call QTSampleTableCreateMutable
to create an empty sample table,

00:36:03.580 --> 00:36:07.220
and then add your sample references
to the sample table similar to the

00:36:07.220 --> 00:36:09.440
old addMediaSampleReference call.

00:36:09.440 --> 00:36:13.450
And when you're done,
call addSampleTableToMedia to actually

00:36:13.450 --> 00:36:16.190
add the sample references to the movie.

00:36:17.790 --> 00:36:24.790
We've also included a whole bunch
of more advanced sample table APIs,

00:36:24.790 --> 00:36:27.400
so if these aren't quite what you need,
you could have a look in the

00:36:27.400 --> 00:36:32.480
headers in the documentation to
see if what we've provided helps.

00:36:32.700 --> 00:36:38.370
And here's Sam to talk
about changes in the ICM.

00:36:44.490 --> 00:36:47.200
I'm still Sam.

00:36:47.210 --> 00:36:50.960
So Anne's explained that if
you call high-level APIs,

00:36:50.960 --> 00:36:54.040
you might not need to worry
about B-frames because they might

00:36:54.040 --> 00:36:55.760
not make a difference for you.

00:36:55.760 --> 00:36:58.040
But if you write the kind of
application that deals with

00:36:58.040 --> 00:37:00.680
compressed frame data yourself,
or if you write a codec,

00:37:00.680 --> 00:37:02.790
then there's no hiding this
information from you and you

00:37:02.790 --> 00:37:04.440
wouldn't even want to anyway.

00:37:04.590 --> 00:37:10.290
So let's talk about how the APIs at
this layer might need to make -- well,

00:37:10.310 --> 00:37:13.190
how they've been changed
to support B-frame codecs.

00:37:17.230 --> 00:37:20.770
There are three things that are
missing from the current APIs in

00:37:20.770 --> 00:37:22.980
order to support B-Frames.

00:37:23.290 --> 00:37:28.100
Frame reordering, new frame information
like the droppable flag,

00:37:28.110 --> 00:37:29.590
and multiple buffers in flight at once.

00:37:38.600 --> 00:37:41.810
The Image Compression
Manager provides APIs both for

00:37:41.810 --> 00:37:44.170
compression and decompression.

00:37:44.170 --> 00:37:47.840
It provides high-level client
APIs and also defines the

00:37:47.850 --> 00:37:52.280
interface to decompressor and
compressor components underneath.

00:37:52.380 --> 00:37:54.530
Let's go through each of these in turn.

00:37:54.630 --> 00:38:00.610
In Tiger, we're introducing a new
multi-buffer API for compression.

00:38:01.120 --> 00:38:05.450
We're also extending the existing
GWorld-based decompression

00:38:05.460 --> 00:38:07.840
API to support B-Frames.

00:38:07.950 --> 00:38:13.720
And we're introducing a new
multi-buffer decompression session API.

00:38:13.720 --> 00:38:18.400
These new multi-buffer APIs are
based on core video pixel buffers.

00:38:19.640 --> 00:38:25.130
Underneath,
we're introducing a new multi-buffer

00:38:25.180 --> 00:38:30.900
API for compressor components,
and we have extended the decompressor

00:38:30.900 --> 00:38:32.950
component API to support B-frames.

00:38:32.960 --> 00:38:35.640
So if you write code that
works at any of these levels,

00:38:35.730 --> 00:38:37.930
then you'll want to look at this stuff.

00:38:46.400 --> 00:38:53.300
[Transcript missing]

00:38:56.390 --> 00:38:59.670
The existing GWorld-based
API is one frame in,

00:38:59.670 --> 00:39:00.900
one frame out.

00:39:01.020 --> 00:39:05.750
What this means is that the compressor
has to give you back the compressed

00:39:05.750 --> 00:39:11.600
data for frame one before it'll
get the image data for frame two.

00:39:11.710 --> 00:39:17.090
This makes it really
difficult to reorder frames.

00:39:17.090 --> 00:39:17.090
Also,

00:39:18.590 --> 00:39:24.000
The current compression API is
almost completely unaware of time.

00:39:29.370 --> 00:39:32.820
The new compression session
API is based on core video pixel

00:39:32.820 --> 00:39:34.700
buffers instead of GWorlds.

00:39:34.700 --> 00:39:38.240
If you're using a new
style compressor component,

00:39:38.270 --> 00:39:41.280
a B-frame aware compressor,
then multiple buffers

00:39:41.280 --> 00:39:42.640
may be in flight at once.

00:39:42.640 --> 00:39:47.510
This allows the compressor to reorder
the frames in order to encode B-frames.

00:39:47.510 --> 00:39:50.040
It also allows the compressor
to have a look ahead window

00:39:50.050 --> 00:39:51.230
for better rate control.

00:39:52.760 --> 00:39:57.810
Timestamps can flow all the way
through the compression chain.

00:39:57.810 --> 00:40:01.210
And the new API supports
multi-pass encoding.

00:40:05.450 --> 00:40:09.300
So whereas in the previous API,
with the GWEL-based compression API,

00:40:09.630 --> 00:40:14.100
you draw each frame into the same buffer,
and then each time you'd pass

00:40:14.140 --> 00:40:15.960
that buffer off to the ICM.

00:40:16.090 --> 00:40:21.860
With the new API, you take a fresh
Core Video Pixel buffer each time,

00:40:22.030 --> 00:40:24.750
put your source frame in it,
and then pass that over to

00:40:24.750 --> 00:40:25.960
the compression session.

00:40:26.130 --> 00:40:28.320
And it'll retain those
until it's done with them,

00:40:28.460 --> 00:40:29.960
and then it'll release them.

00:40:30.080 --> 00:40:33.210
So you can release the buffer
as soon as you've passed it

00:40:33.210 --> 00:40:34.960
to the compression session.

00:40:40.560 --> 00:40:43.510
So this uses standard retain
and release semantics.

00:40:43.720 --> 00:40:47.220
And you could just allocate
these each time if you wanted.

00:40:47.290 --> 00:40:50.440
But mapping and unmapping these
large pieces of virtual memory

00:40:50.440 --> 00:40:55.600
that you use for pixel buffers--

00:40:55.720 --> 00:40:57.510
can involve some memory
management overhead,

00:40:57.510 --> 00:40:59.080
and that can be somewhat expensive.

00:40:59.270 --> 00:41:04.590
So we have a pixel buffer pool as part of
Core Video that does efficient recycling.

00:41:09.920 --> 00:41:12.070
So this is how reordering happens.

00:41:12.150 --> 00:41:18.630
You push source core video
pixel buffers in display order.

00:41:19.050 --> 00:41:23.350
and the session will call a callback
function that you provide with the frames

00:41:23.490 --> 00:41:26.800
that have been encoded in decode order.

00:41:28.420 --> 00:41:32.200
The session will also call you when
it's releasing those pixel buffers,

00:41:32.200 --> 00:41:36.600
so you can perform your own frame
buffer recycling if you want.

00:41:45.580 --> 00:41:49.370
In some cases,
you might not want the compressor to

00:41:49.370 --> 00:41:52.220
hang onto too many frames at a time.

00:41:52.280 --> 00:41:56.450
Perhaps you're a networked application,
like a video conferencing application,

00:41:56.450 --> 00:42:00.510
and there's a maximum latency
before you have to send those

00:42:00.980 --> 00:42:03.100
frames out over the network.

00:42:03.100 --> 00:42:05.960
Well, in those cases,
you can set a maximum number of

00:42:05.960 --> 00:42:09.450
frames that the compressor is
allowed to hang onto at once,

00:42:09.550 --> 00:42:13.720
and you can also make an explicit
request that forces the compressor

00:42:13.720 --> 00:42:17.810
to finish encoding the frames
that it's currently hanging onto.

00:42:19.700 --> 00:42:23.000
Their new compression session
API has a bunch of other features

00:42:23.320 --> 00:42:25.130
that make it a big jump forward.

00:42:25.130 --> 00:42:29.390
It's easier than before to
add encoded frames to a movie.

00:42:29.570 --> 00:42:32.280
You can use the fixed or
flexible GOT pattern if you

00:42:32.530 --> 00:42:34.130
know what a GOT pattern is.

00:42:34.190 --> 00:42:36.500
It's not politics, don't worry.

00:42:36.580 --> 00:42:38.900
You can set a CPU time budget.

00:42:39.010 --> 00:42:41.140
You can set data rate limits.

00:42:41.140 --> 00:42:44.490
And as I said before,
it supports multi-pass encoding.

00:42:44.590 --> 00:42:49.170
In fact, the movie exporter that's
in the Tiger seed supports

00:42:49.200 --> 00:42:51.640
multi-pass encoding as well.

00:42:53.090 --> 00:42:56.400
In the final version of Tiger,
the compression session API will be

00:42:56.400 --> 00:43:01.060
compatible with existing compressors,
but no B-frames will be generated.

00:43:03.210 --> 00:43:06.660
However,
in the Tiger seed that you've got,

00:43:06.700 --> 00:43:09.600
it's not yet compatible
with existing compressors.

00:43:09.670 --> 00:43:13.510
And also,
we don't have an H264 compressor.

00:43:13.680 --> 00:43:17.140
So it would be a good idea to try
and get on our seed program if you

00:43:17.140 --> 00:43:18.720
want to try and exercise this API.

00:43:21.900 --> 00:43:23.040
What's next?

00:43:23.140 --> 00:43:27.080
Let's talk about what's underneath
the compression session API,

00:43:27.330 --> 00:43:30.750
which is the new compressor
component interface.

00:43:31.090 --> 00:43:35.760
New style compressor components still
use the four character code IMCO,

00:43:35.850 --> 00:43:39.240
but they support three new
component calls for B-frames.

00:43:39.340 --> 00:43:41.990
And if you want to opt in
for multi-pass support,

00:43:42.080 --> 00:43:47.200
there's three more
APIs to implement as well.

00:43:47.310 --> 00:43:50.320
Let's also talk for a
moment about decompression.

00:44:02.500 --> 00:44:07.520
There's two flavors of decompression
API that we have in the GWELD-based mode.

00:44:07.600 --> 00:44:11.360
We have synchronous APIs,
and these are all one frame in,

00:44:11.360 --> 00:44:13.270
one frame out.

00:44:14.600 --> 00:44:18.490
We also have a second
mode for decompression,

00:44:18.490 --> 00:44:21.280
which is called Scheduled Decompression.

00:44:21.460 --> 00:44:24.700
And with scheduled decompression,
you can queue multiple frames,

00:44:24.750 --> 00:44:26.360
each of which with a frame time.

00:44:26.360 --> 00:44:30.690
And when that time arrives,
the frame is triggered and

00:44:30.690 --> 00:44:33.170
we decode it and display it.

00:44:37.460 --> 00:44:40.950
With B-Frames, as we've gone through,
the decode order and the

00:44:40.950 --> 00:44:43.270
display order can be different.

00:44:43.330 --> 00:44:46.660
In fact, you may need to decode several
frames before you come to

00:44:46.810 --> 00:44:48.400
the first frame to display.

00:44:48.400 --> 00:44:54.350
So immediate one-frame-in,
one-frame-out APIs aren't a good match.

00:44:55.260 --> 00:45:01.590
Let's look at the example of the
little clip of that car parking.

00:45:02.580 --> 00:45:08.140
In the decode case,
the first frame happens to be the first

00:45:08.900 --> 00:45:11.900
frame both to display and to decode.

00:45:11.960 --> 00:45:13.920
So we decode it and then we display it.

00:45:14.000 --> 00:45:17.380
But the second frame in
decode order doesn't need to

00:45:17.380 --> 00:45:19.770
be displayed until time 60.

00:45:20.230 --> 00:45:26.110
But it does need to be decoded before
the next frame in decode order,

00:45:26.110 --> 00:45:28.900
which is the frame at time 20.

00:45:29.960 --> 00:45:32.890
and it needs to be decoded
before the frame after that,

00:45:32.890 --> 00:45:35.110
which is at time 30,
and the one at time 40,

00:45:35.210 --> 00:45:36.560
and the one at time 50.

00:45:36.600 --> 00:45:43.400
After that, it's okay for that frame
to be displayed at time 60.

00:45:44.120 --> 00:45:49.890
The new model for doing
decompression is that you always

00:45:49.890 --> 00:45:52.290
queue frames in decode order.

00:45:53.990 --> 00:45:57.460
And then you provide the display
timestamps so that we know how

00:45:57.460 --> 00:45:59.780
the frames should be reordered.

00:46:00.180 --> 00:46:04.020
As before, frames can be scheduled
against a time base,

00:46:04.040 --> 00:46:07.320
in which case the frames will
automatically be output according to that

00:46:07.330 --> 00:46:09.700
time base when that trigger time happens.

00:46:09.820 --> 00:46:14.880
But we have a new mode called
non-scheduled display times.

00:46:15.270 --> 00:46:18.820
In which case,
there's no time base and you have to

00:46:18.860 --> 00:46:23.320
make an explicit call to the ICM to say,
"I would like this frame back."

00:46:24.000 --> 00:46:27.170
You can also optionally
supply decode timestamps,

00:46:27.260 --> 00:46:29.240
which are a hint saying this
is when it would be a good

00:46:29.240 --> 00:46:31.510
time to decode that frame.

00:46:32.710 --> 00:46:39.060
So many of you will have
loops in your code where you

00:46:39.800 --> 00:47:00.000
[Transcript missing]

00:47:00.100 --> 00:47:03.710
Like I've been saying, immediate mode,
one frame in, one frame out,

00:47:03.710 --> 00:47:06.620
is very awkward for B frames,
at least if you want to get the

00:47:06.640 --> 00:47:09.990
frames out in display order,
which is the order that

00:47:09.990 --> 00:47:12.420
makes sense to the user.

00:47:12.420 --> 00:47:15.450
So we need to enhance this a bit.

00:47:16.440 --> 00:47:19.860
So here we have an outer
loop and an inner loop.

00:47:19.980 --> 00:47:24.090
The outer loop queues
frames in decode order,

00:47:24.090 --> 00:47:28.650
and the inner loop retrieves
frames in display order.

00:47:28.910 --> 00:47:33.030
So frames go in in decode order and
you pull them out in display order.

00:47:33.100 --> 00:47:35.200
And there may not be a
one-to-one correspondence,

00:47:35.300 --> 00:47:37.660
so that's why we have the
outer loop and the inner loop.

00:47:37.840 --> 00:47:39.770
The inner loop isn't going
to be run many times.

00:47:39.930 --> 00:47:41.480
I'll show you in a second.

00:47:41.590 --> 00:47:44.530
One other thing,
because you're queuing multiple frames,

00:47:44.530 --> 00:47:46.910
you need to load them
into multiple buffers.

00:47:47.190 --> 00:47:50.260
These aren't called video pixel buffers,
these are just data buffers.

00:47:50.350 --> 00:47:53.510
And the ICM will call you back to
say when it's time to release those

00:47:53.570 --> 00:47:55.800
because the codec no longer needs them.

00:47:57.500 --> 00:48:01.990
You can do this both with
the existing GWeld API,

00:48:01.990 --> 00:48:06.160
and we've also introduced this new
multi-buffer core video pixel buffer

00:48:06.160 --> 00:48:10.280
based API called Decompression Sessions.

00:48:10.390 --> 00:48:14.810
Now the Decompression Session API does
not support any drawing operations.

00:48:14.910 --> 00:48:16.730
It doesn't do clipping.

00:48:16.830 --> 00:48:19.120
It doesn't do matrix transformations.

00:48:19.230 --> 00:48:21.980
It doesn't do transfer modes
or any of that other guff.

00:48:22.100 --> 00:48:26.510
Instead, it just gives you the buffers
in the format you want.

00:48:26.780 --> 00:48:30.460
There's a flavor of this API that
supports sending the buffers

00:48:30.460 --> 00:48:32.460
directly to a visual context.

00:48:32.460 --> 00:48:36.300
And there's one that just
gives you the buffers back.

00:48:36.480 --> 00:48:38.000
So, let's do a demo.

00:48:38.220 --> 00:48:39.750
Wake up!

00:48:41.500 --> 00:48:48.500
[Transcript missing]

00:48:51.340 --> 00:48:52.840
So I have a little clip here.

00:48:53.080 --> 00:48:56.020
I like the Harry Potter trailer,
and I clipped out a little

00:48:56.020 --> 00:48:58.890
bit of it in the middle.

00:48:59.380 --> 00:49:01.050
It's not very long.

00:49:03.480 --> 00:49:06.600
It plays in display order.

00:49:06.890 --> 00:49:07.790
See, everything's moving forward.

00:49:07.850 --> 00:49:10.370
The bus is moving down the road.

00:49:11.500 --> 00:49:17.040
QuickTime Player has not been
revised to understand B-frames.

00:49:17.210 --> 00:49:19.070
So like Anne said,

00:49:20.100 --> 00:49:24.580
If you're using the high-level APIs,
you don't need to change.

00:49:24.700 --> 00:49:26.090
What's more,
I'm going to step through this

00:49:26.100 --> 00:49:29.320
by pressing the arrow key,
and you notice that the

00:49:29.320 --> 00:49:30.580
frame is moving forward.

00:49:30.610 --> 00:49:36.760
So what's happening here is we are
telling the movie to move forward

00:49:36.760 --> 00:49:40.940
to new movie times and rendering
the frame for each of those times.

00:49:40.940 --> 00:49:43.990
If you do that in your application,
if you step through with something

00:49:43.990 --> 00:49:47.880
like setMovieTime and moviesTask,
if appropriate,

00:49:47.930 --> 00:49:50.120
then you don't need to worry.

00:49:50.120 --> 00:49:51.690
You'll get the frames
out in display order.

00:49:51.700 --> 00:49:53.500
Everyone will be happy.

00:49:55.900 --> 00:49:57.980
and David Schreiber.

00:49:57.980 --> 00:49:59.160
That's a great sound.

00:49:59.160 --> 00:50:01.380
But this movie does have B-frames.

00:50:01.390 --> 00:50:02.660
The frames are being reordered.

00:50:02.800 --> 00:50:04.520
I have a copy of Dumpster here.

00:50:04.550 --> 00:50:07.960
It's great when we get to demo Dumpster.

00:50:07.960 --> 00:50:09.420
Many of you will know what Dumpster is.

00:50:09.420 --> 00:50:11.120
Some of you won't.

00:50:11.150 --> 00:50:14.460
Dumpster is a tool that shows you the
internal structure of movie files.

00:50:14.460 --> 00:50:16.040
Actually of the movie header.

00:50:16.040 --> 00:50:19.120
Not the place where the
media compressed data is,

00:50:19.120 --> 00:50:21.490
but the movie header itself.

00:50:22.190 --> 00:50:24.170
And we've modified Dumpster,
this version of Dumpster,

00:50:24.200 --> 00:50:27.580
to show you the new B-frame
tables that Anne was mentioning.

00:50:27.680 --> 00:50:32.590
You probably can't see the details,
so I'll just pop them open so you can...

00:50:32.840 --> 00:50:34.300
take my word that they're there.

00:50:34.300 --> 00:50:39.330
There's a piece of information here that
tells you the size of individual frames.

00:50:39.470 --> 00:50:43.220
These are numbers varying
between 40 and 80 kilobytes.

00:50:43.340 --> 00:50:45.640
It also stores the timing information.

00:50:45.640 --> 00:50:49.790
Each of these frames
has a duration of 1,000.

00:50:49.800 --> 00:50:52.820
And this is from film,
so the speed is more or

00:50:52.820 --> 00:50:54.940
less 24 frames per second.

00:50:54.940 --> 00:50:58.290
And so the time brace here
is something around 24,000.

00:50:59.450 --> 00:51:02.780
and each frame has the same duration,
1000.

00:51:02.940 --> 00:51:05.750
We also now store,
this is a new table for Tiger,

00:51:06.010 --> 00:51:09.500
you also store the display
offsets and you probably can't

00:51:09.500 --> 00:51:12.720
see but the first one is zero,
the next one is a thousand,

00:51:12.720 --> 00:51:16.440
then minus a thousand, then a thousand,
then minus a thousand.

00:51:16.640 --> 00:51:17.910
What does this mean?

00:51:17.910 --> 00:51:21.070
Well,
if you think about the durations which

00:51:21.130 --> 00:51:28.910
are now interpreted as decode durations,
the frames are at times zero, 1000, 2000,

00:51:28.990 --> 00:51:33.680
3000 and we add the display times,
we add the display offsets

00:51:33.740 --> 00:51:38.690
to those to find the display
times and we'll see zero,

00:51:38.690 --> 00:51:38.690
2000, 3000, 2000, 3000.

00:51:39.260 --> 00:51:42.240
2000, 1000.

00:51:42.260 --> 00:51:45.840
These first,
the second two frames are reordered,

00:51:45.840 --> 00:51:47.330
they're exchanged in pairs.

00:51:47.410 --> 00:51:49.750
And the same for the next one.

00:51:49.750 --> 00:51:49.750
So,

00:51:49.710 --> 00:51:54.140
Here's the difference between the
decode order and the display order.

00:51:54.150 --> 00:51:55.970
I'm an adopter.

00:51:56.950 --> 00:52:01.240
Here's the difference between the
decode order and the display order.

00:52:01.240 --> 00:52:03.080
I'm an adopter.

00:52:11.130 --> 00:52:15.440
Here's the difference between the
decode order and the display order.

00:52:15.440 --> 00:52:17.280
I'm an adopter.

00:52:22.800 --> 00:52:40.400
[Transcript missing]

00:52:43.290 --> 00:52:46.270
This is a little command line
tool which was included in the

00:52:46.340 --> 00:52:48.040
disk image for this session.

00:52:48.060 --> 00:52:52.230
It's a command line tool that steps
through a movie and does that new

00:52:52.230 --> 00:52:54.820
kind of loop that I was describing.

00:52:54.830 --> 00:52:58.800
It calls the new decompression
session API to decode each frame

00:52:58.800 --> 00:53:00.760
into a core video pixel buffer.

00:53:00.760 --> 00:53:03.160
And it takes command line arguments.

00:53:03.280 --> 00:53:05.200
I've made it scale the frame down.

00:53:05.200 --> 00:53:07.580
It's so big there's not a lot
of space for the debugger.

00:53:07.680 --> 00:53:14.300
And it also takes a command
online path to the movie file.

00:53:15.870 --> 00:53:20.480
So let's try it out.

00:53:20.480 --> 00:53:25.940
I'm pausing in between the frames so that
you can see them so they don't race past.

00:53:25.940 --> 00:53:27.020
Wasn't there something odd there?

00:53:27.020 --> 00:53:27.900
Did you see that?

00:53:27.900 --> 00:53:29.520
I'll play it again.

00:53:33.950 --> 00:53:35.900
and Harry Potter.

00:53:35.900 --> 00:53:36.900
Where did he come from?

00:53:36.950 --> 00:53:39.870
He wasn't there when we opened
this movie in QuickTime Player.

00:53:39.930 --> 00:53:42.850
What's going on?

00:53:42.850 --> 00:53:42.850
Well,

00:53:43.070 --> 00:53:48.180
This little tool is going down to
the media layer of the movie and it's

00:53:48.180 --> 00:53:50.000
accessing the sample table directly.

00:53:50.000 --> 00:53:53.500
But when you do that,
you're circumventing the higher

00:53:53.720 --> 00:53:57.000
layers and at the track layer
there's a thing called the edit list.

00:53:57.000 --> 00:54:00.610
And when I cropped that little piece out,
copied and pasted it

00:54:00.780 --> 00:54:03.940
out of the longer movie,
I had edited out the

00:54:04.260 --> 00:54:06.100
frame of Harry Potter.

00:54:06.350 --> 00:54:10.860
But it's still inside that sequence
of frames at the media layer.

00:54:10.940 --> 00:54:12.700
So we're going around the edit list.

00:54:12.730 --> 00:54:16.140
If we wanted to make the movie,
set through the movie in

00:54:16.150 --> 00:54:19.840
the same way that it appears
to someone who's using it,

00:54:19.850 --> 00:54:22.620
then it would look-- we'd have
to put a bit more code that would

00:54:22.720 --> 00:54:23.940
have to walk through the edit list.

00:54:23.940 --> 00:54:27.140
Or an easy way would be to do that,
what I did with the arrow keys,

00:54:27.140 --> 00:54:28.900
stepping through the movie.

00:54:29.060 --> 00:54:34.010
So briefly, let's have a look at
this in the debugger.

00:54:38.200 --> 00:54:40.310
will talk a little bit about
this code and see how it works.

00:54:40.330 --> 00:54:43.600
So we're doing some things that aren't
very special about B-frame movies,

00:54:43.600 --> 00:54:45.040
and I'll skip over those.

00:54:45.040 --> 00:54:47.350
We are opening the movie.

00:54:47.580 --> 00:54:51.310
We are getting the video track,
we're getting the image description,

00:54:51.340 --> 00:54:54.890
and then we're making a window that's
the scale size of that image description.

00:54:54.900 --> 00:54:57.500
There's the window in
the background there.

00:54:57.600 --> 00:54:59.190
Nothing big yet.

00:54:59.280 --> 00:55:00.980
Then we're making a
decompression session.

00:55:01.070 --> 00:55:03.050
I want to show you this.

00:55:04.010 --> 00:55:05.890
Local variables, love them.

00:55:05.910 --> 00:55:08.960
So we're creating a pixel
buffer attributes dictionary.

00:55:08.960 --> 00:55:12.630
This is how we're describing the kinds
of pixel buffers we'd like to get

00:55:12.630 --> 00:55:14.880
back from the decompression session.

00:55:14.980 --> 00:55:20.140
And we give it the width and height
that we'd like it to give us buffers in,

00:55:20.320 --> 00:55:24.370
because we would like them to be a
specific width and a specific height.

00:55:24.730 --> 00:55:26.530
Local variables, love them.

00:55:26.530 --> 00:55:29.660
So we're creating a pixel
buffer attributes dictionary.

00:55:29.760 --> 00:55:33.320
This is how we're describing the kinds
of pixel buffers we'd like to get

00:55:33.320 --> 00:55:34.830
back from the decompression session.

00:55:37.430 --> 00:55:42.600
We also pass a callback when we're
creating the decompression session.

00:55:42.720 --> 00:55:46.400
This callback is called with
the encoded pixel buffers.

00:55:46.620 --> 00:55:48.060
There's no GWorld here.

00:55:48.160 --> 00:55:50.730
The callback is called with
a fresh buffer for each time,

00:55:50.730 --> 00:55:54.560
and when you release them,
they can be -- go back into

00:55:54.630 --> 00:55:58.860
the pool that the ICM is using
to recycle pixel buffers.

00:55:59.570 --> 00:56:02.500
That tracking callback is also
called when we want to recycle,

00:56:02.500 --> 00:56:06.470
when the data buffers can be recycled.

00:56:07.680 --> 00:56:09.670
Okay,
so now we've got a decompression session,

00:56:09.740 --> 00:56:11.030
but nothing's been decoded into it.

00:56:11.060 --> 00:56:14.510
Now we've got to have a look at the
media and pull out those frames.

00:56:16.430 --> 00:56:19.270
We get the number of samples
in the media and we allocate

00:56:19.270 --> 00:56:21.500
some storage for each of them.

00:56:21.500 --> 00:56:23.390
Now here's the first
interesting question.

00:56:23.410 --> 00:56:25.380
What's the first frame
that we want to display?

00:56:25.570 --> 00:56:29.000
Well, we're starting at time
zero in display time,

00:56:29.140 --> 00:56:31.830
but that might not be the
same as the first frame,

00:56:31.910 --> 00:56:37.560
so we need to go and do a mapping,
and this is calling a new API in Tiger.

00:56:37.810 --> 00:56:41.140
Previously we'd call media time to
sample them to get this information,

00:56:41.140 --> 00:56:44.990
but now we need to specify which
kind of time we want to talk about,

00:56:44.990 --> 00:56:48.610
so it's media display
time to sample them.

00:56:49.190 --> 00:56:53.610
and I think I have debug tools.

00:56:53.690 --> 00:56:55.980
Expressions, aha,
my little expressions window.

00:56:55.980 --> 00:56:57.980
Some of these variables
are uninitialized.

00:56:57.980 --> 00:57:02.350
So you can't see this,
but I'm telling you that

00:57:02.350 --> 00:57:04.390
number in red is one.

00:57:06.540 --> 00:57:08.800
So that's the next sample
number we want to display.

00:57:08.810 --> 00:57:12.190
That's also the first sample
that we're going to decode.

00:57:12.530 --> 00:57:14.240
That's just like the...

00:57:15.690 --> 00:57:17.440
as we saw it in dumpster.

00:57:17.560 --> 00:57:17.800
OK.

00:57:17.990 --> 00:57:19.840
So we're approaching the outer loop here.

00:57:19.860 --> 00:57:22.920
The outer loop queues
frames in decode order.

00:57:22.920 --> 00:57:25.160
That's just ascending
numbers in sample time.

00:57:25.200 --> 00:57:28.130
So we use plus plus to
get to the next one.

00:57:28.210 --> 00:57:34.200
So we translate that sample number
to a decode time so that we can

00:57:34.420 --> 00:57:36.450
get the size of that sample.

00:57:36.460 --> 00:57:37.820
We allocate some storage.

00:57:37.840 --> 00:57:39.480
We load it into that storage.

00:57:39.480 --> 00:57:43.270
Along the way,
we have found out what the decode

00:57:43.370 --> 00:57:45.060
time and display offset are.

00:57:45.070 --> 00:57:48.640
And we add those to find out
the display time for that frame.

00:57:48.640 --> 00:57:50.940
And now we have enough
information to queue that frame

00:57:50.940 --> 00:57:52.300
with the decompression session.

00:57:52.300 --> 00:57:55.660
And we hand it to the ICM,
and nothing happens yet.

00:57:55.810 --> 00:58:02.410
Nothing happens because we're using this
new mode where you pass display times

00:58:03.080 --> 00:58:05.160
and they're non-scheduled.

00:58:05.240 --> 00:58:06.320
There's no time base.

00:58:06.390 --> 00:58:09.910
They're not going to come out
until we ask for them back.

00:58:10.070 --> 00:58:13.460
So the next question is, well,
have we enqueued the frame

00:58:13.460 --> 00:58:15.380
that we need to get out?

00:58:15.390 --> 00:58:17.420
And so we just compare these two numbers.

00:58:17.440 --> 00:58:20.270
We've queued sample one,
and we want to get back sample one.

00:58:20.370 --> 00:58:23.140
So yep, let's go into the inner loop,
where we retrieve

00:58:23.300 --> 00:58:25.550
samples in display order.

00:58:25.800 --> 00:58:28.300
And we do that by saying,
here's the non-scheduled

00:58:28.300 --> 00:58:31.450
display time that I would like
to get the frame back for.

00:58:31.530 --> 00:58:32.460
And there's the frame.

00:58:32.480 --> 00:58:34.080
Hooray!

00:58:34.480 --> 00:58:36.970
And we do that by saying,
here's the non-scheduled

00:58:37.000 --> 00:58:39.840
display time that I would like
to get the frame back for.

00:58:40.170 --> 00:58:41.080
And there's the frame.

00:58:41.160 --> 00:58:42.780
Hooray!

00:58:54.380 --> 00:58:56.480
But that's frame three.

00:58:56.550 --> 00:58:57.640
So let's go around this loop again.

00:58:57.640 --> 00:58:58.480
I've got a break point here.

00:58:58.480 --> 00:59:04.280
So the next thing that we decode is--that
we schedule for decode is frame two.

00:59:06.480 --> 00:59:09.300
And now we've queued frame two,
but we want frame three,

00:59:09.300 --> 00:59:10.400
so we have to go around again.

00:59:10.400 --> 00:59:13.230
We'll skip over the inner loop
and come back to the outer loop.

00:59:13.290 --> 00:59:18.720
We'll enqueue frame three,
and then we'll ask back for frame three,

00:59:18.720 --> 00:59:19.640
which is in the queue now.

00:59:19.640 --> 00:59:20.500
And here we go.

00:59:20.500 --> 00:59:22.140
The bus will move a bit.

00:59:22.240 --> 00:59:23.380
Or the road will move.

00:59:23.380 --> 00:59:24.650
I guess we're in the bus.

00:59:24.660 --> 00:59:29.140
And the next time is 2000,
and that's frame two.

00:59:29.140 --> 00:59:31.060
So remember this order?

00:59:31.060 --> 00:59:32.960
We're going through the
frames in display order,

00:59:32.980 --> 00:59:37.710
thanks to the Get Media Next interesting
display time and so forth.

00:59:37.770 --> 00:59:39.810
We're going through these
frames in order one,

00:59:39.810 --> 00:59:41.800
three, two, five, four, seven, six.

00:59:44.180 --> 00:59:50.440
So as we go through,
we're going to get back frame two now.

00:59:50.600 --> 00:59:52.820
So OK, big deal.

00:59:52.820 --> 00:59:54.440
We carry on in this pattern.

00:59:54.440 --> 00:59:57.310
Because the frames are
exchanged in pairs,

00:59:57.340 --> 01:00:00.820
we'll queue two frames and
then retrieve two frames,

01:00:00.920 --> 01:00:04.700
and then we'll queue two
frames and retrieve two frames.

01:00:04.700 --> 01:00:07.220
And it's going to carry on like this.

01:00:07.220 --> 01:00:10.310
I'll clear that breakpoint
and just continue.

01:00:10.310 --> 01:00:11.100
And in fact,

01:00:12.960 --> 01:00:14.980
Here's us going through
the rest of the frames.

01:00:14.980 --> 01:00:17.980
And here's Harry Potter.

01:00:18.050 --> 01:00:18.790
Great note to end on.

01:00:27.180 --> 01:00:31.200
Okay, so one more thing.

01:00:31.200 --> 01:00:34.580
It's not like a Steve one more thing,
I'm sorry.

01:00:38.290 --> 01:00:44.020
We've enhanced the decompression
component interface to support B-frames.

01:00:44.560 --> 01:00:46.100
This is all based on
the Base Decompressor.

01:00:46.100 --> 01:00:48.810
We introduced the Base Decompressor
six years ago in QuickTime 3.

01:00:48.990 --> 01:00:52.140
It's been helping you write video codecs.

01:00:52.190 --> 01:00:55.590
The Base Codec helps by...

01:00:56.370 --> 01:01:01.410
Implementing the queue that
holds the scheduled frames.

01:01:01.680 --> 01:01:07.660
and now it'll also help you with
frame reordering for B-frames.

01:01:07.660 --> 01:01:09.480
The new rules for
B-frame-aware decompressors,

01:01:09.480 --> 01:01:13.780
if you want to write one yourself,
you opt in in your initialized

01:01:13.890 --> 01:01:15.770
function by setting a flag.

01:01:15.830 --> 01:01:18.630
You classify frames in
your begin band function,

01:01:18.630 --> 01:01:21.550
which means that you say whether
the frame is a key frame,

01:01:21.660 --> 01:01:23.940
a difference frame or a
droppable difference frame.

01:01:23.940 --> 01:01:27.900
It's always been a good idea to do this,
but for B-frames it's mandatory.

01:01:28.320 --> 01:01:31.360
Third, we've split the work in
the drawband function.

01:01:31.360 --> 01:01:34.170
This used to be where both
decode and display happened,

01:01:34.240 --> 01:01:37.100
and now we've separated those,
and decode happens in the

01:01:37.100 --> 01:01:41.630
decode band function and display
happens in the drawband function.

01:01:41.790 --> 01:01:48.990
And only one of those will get called
if we just need to decode the frame in

01:01:48.990 --> 01:01:48.990
order to prime it inside your decoder.

01:01:51.770 --> 01:01:54.200
Final note,
and this is not just for B-frame codecs,

01:01:54.200 --> 01:01:57.540
but in fact any codec that wants
to work in QuickTime Player now,

01:01:57.540 --> 01:02:00.400
don't cache the Pixmap
base address in Begin Band.

01:02:00.400 --> 01:02:02.790
It might change between
Begin Band and Draw Band.

01:02:05.100 --> 01:02:07.020
and then you draw in the wrong place.

01:02:07.200 --> 01:02:11.500
So these are the new APIs that we've
provided in the Image Compression

01:02:11.500 --> 01:02:16.420
Manager for multi-buffer
support and for B-frame support.

01:02:19.860 --> 01:02:24.980
There's a video track
movie exporter in the seed.

01:02:25.190 --> 01:02:26.480
I encourage you to try it.

01:02:26.550 --> 01:02:29.690
I encourage you to try out the new
APIs that exercise that because the

01:02:29.690 --> 01:02:33.220
new APIs will work with the B-frame
stuff and you'll see how that works.

01:02:33.660 --> 01:02:39.150
Also,
exercise your application and examine

01:02:39.150 --> 01:02:41.900
whether your application needs revising
in order to cope with B-frame content.

01:02:42.480 --> 01:02:45.780
I want to give you one
small warning about one bug,

01:02:45.800 --> 01:02:49.400
because it's likely to bite
you and I'm a kind guy.

01:02:49.410 --> 01:02:51.870
The bug is this.

01:02:52.280 --> 01:02:55.190
The Video Track Movie Exporter
only creates video tracks.

01:02:55.280 --> 01:02:56.440
It doesn't copy the soundtrack.

01:02:56.440 --> 01:02:58.750
So it's likely that you're going
to want to go and extract the

01:02:58.780 --> 01:03:01.330
soundtrack and paste it into the
new movie with the add command so

01:03:01.330 --> 01:03:02.880
that they're next to each other.

01:03:02.990 --> 01:03:11.710
If you do that, save the movie but don't
save it self-contained.

01:03:11.710 --> 01:03:11.710
And save as self-contained is now the
default in the new QuickTime player.

01:03:12.460 --> 01:03:15.860
Carefully switch it back to
save a reference or what used

01:03:15.860 --> 01:03:17.900
to be called save normally.

01:03:17.900 --> 01:03:20.340
The reason for this is that when
you save a movie self-contained,

01:03:20.340 --> 01:03:22.690
we do a thing called
interleaved flattening.

01:03:22.690 --> 01:03:26.720
We interleave half-second
chunks of audio and video.

01:03:26.720 --> 01:03:29.650
And the code that does this,
it's got a bug that doesn't do the

01:03:29.700 --> 01:03:34.030
right thing for H.264 and you end up
with movies that won't play properly.

01:03:34.030 --> 01:03:36.660
They're not going to cause any harm,
they just won't play right.

01:03:36.690 --> 01:03:39.580
So avoid saving those
movies self-contained.

01:03:40.580 --> 01:03:43.400
So, more information.

01:03:43.900 --> 01:03:51.300
Both on the CD, the DVD,
and on the net at connect.apple.com

01:03:51.300 --> 01:03:54.340
you can download a bunch
of documentation for this.

01:03:54.340 --> 01:04:01.220
There's a "What's New in QuickTime 6.6"
document in -- it's the big 60

01:04:01.220 --> 01:04:03.870
megabyte tiger documentation.

01:04:03.870 --> 01:04:08.240
Download it here while Apple's
paying for the bandwidth.

01:04:08.720 --> 01:04:09.600
and others.

01:04:09.810 --> 01:04:12.600
Also download the disk
image for this session.

01:04:12.600 --> 01:04:16.360
You can go to connect.apple.com,
log in and click download software

01:04:16.360 --> 01:04:20.530
and see what's new and it'll be there
under the developer's conference stuff.

01:04:20.780 --> 01:04:24.570
The API reference won't be
updated until Tiger goes final.

01:04:28.150 --> 01:04:29.680
And one more thing.

01:04:29.690 --> 01:04:31.900
It's another dull one more thing.

01:04:31.900 --> 01:04:37.250
Just around the back here in the
hands-on lab for the QuickTime

01:04:38.130 --> 01:04:40.300
for the Graphics and
Media and QuickTime Lab.

01:04:40.310 --> 01:04:45.050
We have a special extended
hands-on lab time so that you can

01:04:45.150 --> 01:04:48.630
talk to me and other folks about
IPB and about visual contexts.

01:04:48.680 --> 01:04:51.230
And that's starting more or
less right after this session.

01:04:51.230 --> 01:04:55.620
And that'll go until 6.30 and they'll
be tearing down everything else.

01:04:55.620 --> 01:04:58.560
But they're going to let us stay in
the room so that we can help you.

01:04:58.620 --> 01:04:59.420
So come along.

01:05:01.130 --> 01:05:01.780
Also seeding.

01:05:01.780 --> 01:05:03.520
You've got the Tiger seed.

01:05:03.520 --> 01:05:07.530
It's possible that we'll do
a further QuickTime seeds.

01:05:07.530 --> 01:05:10.140
If you would like to be
involved in such seeds,

01:05:10.180 --> 01:05:14.050
please send an email with your name,
company, product, technology interest to

01:05:14.050 --> 01:05:15.790
QuickTimeSeed at Apple.com.

01:05:15.870 --> 01:05:17.720
I have some reminder cards.

01:05:20.740 --> 01:05:22.810
I have some reminder cards
that I can give you if you

01:05:22.820 --> 01:05:24.380
come and see me after this.

01:05:24.380 --> 01:05:28.030
Or you can contact your
friendly evangelist.