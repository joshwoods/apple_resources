WEBVTT

00:00:12.390 --> 00:00:13.870
Hi, everybody.

00:00:13.920 --> 00:00:16.720
Welcome to session 435.

00:00:16.750 --> 00:00:19.970
My name is Xavier Legro,
and I work in developer relations.

00:00:20.230 --> 00:00:24.370
Most of my job is actually to go
around the world and kind of tell

00:00:24.370 --> 00:00:28.290
you about the latest technologies
and encourage you about opting for

00:00:28.290 --> 00:00:31.960
adopting modern Mac OS X technologies.

00:00:31.990 --> 00:00:35.670
What has been coming quite often is
that very often people are afraid

00:00:35.670 --> 00:00:37.820
of threading their applications.

00:00:37.820 --> 00:00:40.630
So we've been doing a lot
of what we call workshops,

00:00:40.630 --> 00:00:43.900
where we take groups of 20, 25,
30 people,

00:00:44.050 --> 00:00:45.980
and we kind of teach them one topic.

00:00:45.980 --> 00:00:47.070
We have Cocoa workshops.

00:00:47.120 --> 00:00:51.620
We have HI Toolbox, Carbon workshops.

00:00:51.800 --> 00:00:54.400
When we do this presentation,
we get very, very good feedback,

00:00:54.400 --> 00:00:56.920
and very interestingly,
I think it really helps adopt actually

00:00:56.930 --> 00:00:58.300
in threading your application.

00:00:58.350 --> 00:01:01.000
So that's going to be the topic today.

00:01:02.810 --> 00:01:04.220
So what are we going to talk about?

00:01:04.430 --> 00:01:07.940
So today we're going to talk
quickly about why you as a developer

00:01:07.940 --> 00:01:10.470
should care about threading.

00:01:10.570 --> 00:01:12.810
We'll go through some
threading terminology,

00:01:12.810 --> 00:01:17.440
some buzzwords to make sure that we all
speak the same language here-- French,

00:01:17.830 --> 00:01:19.320
obviously.

00:01:19.520 --> 00:01:22.280
And we'll go through a couple of
examples of threading architecture.

00:01:22.280 --> 00:01:24.950
I'll go through three of the
main architectures that I think

00:01:24.980 --> 00:01:27.340
are used around threading.

00:01:27.680 --> 00:01:31.330
And I think the best part is going to
be I'm going to try to take you step by

00:01:31.330 --> 00:01:36.880
step and try to teach you how to thread
your application using the MP APIs.

00:01:36.910 --> 00:01:39.320
And then we'll have some
dos and don'ts and something

00:01:39.320 --> 00:01:41.880
that I think is a cool demo.

00:01:41.910 --> 00:01:43.390
OK.

00:01:43.540 --> 00:01:46.730
So why should you use threads?

00:01:47.400 --> 00:01:49.960
Well, because if you use threads and
you thread your application,

00:01:49.960 --> 00:01:53.480
we're going to get you 50%
of one of these brand new

00:01:53.580 --> 00:01:55.870
G5s and a brand new display.

00:01:56.910 --> 00:02:00.340
Usually everybody's
like-- that's a nice box.

00:02:00.430 --> 00:02:02.860
And you're probably thinking, really?

00:02:02.890 --> 00:02:05.040
No, not really, of course.

00:02:05.130 --> 00:02:07.090
But why should you
thread your application?

00:02:07.100 --> 00:02:10.200
Well, the first thing that comes to mind,
of course, is scalability.

00:02:10.290 --> 00:02:15.060
We are shipping now a lot of
these boxes with two CPUs inside,

00:02:15.430 --> 00:02:18.520
specifically you as a developer
with your nice application.

00:02:18.610 --> 00:02:22.680
If you use only one CPU,
it's like having our users

00:02:22.680 --> 00:02:26.680
use half of like $3,000,
so like using half of a machine.

00:02:26.730 --> 00:02:30.770
I think a lot of applications could
actually use threading in their app.

00:02:31.070 --> 00:02:33.920
And we're going to go here through some
of the main concepts and explain why

00:02:33.920 --> 00:02:38.880
it's not so much of a big deal sometimes
to thread part of an application.

00:02:38.940 --> 00:02:42.190
Here what I'm showing you is
actually a couple of results with

00:02:42.190 --> 00:02:44.620
some graphic transformations.

00:02:44.620 --> 00:02:46.720
Here in this case,
we have like a Gaussian blur,

00:02:46.720 --> 00:02:48.670
and we go to a motion blur.

00:02:48.680 --> 00:02:52.240
And you can expect when you
thread part of your application

00:02:52.240 --> 00:02:59.990
for like high intensive tasks,
between 1.3 to 2.3 times faster.

00:03:00.190 --> 00:03:03.120
And here you're probably wondering,
why 2.3 times faster, right?

00:03:03.120 --> 00:03:05.900
If I have two CPUs,
how can I get like more

00:03:05.900 --> 00:03:09.000
than twice as fast,
right?

00:03:09.000 --> 00:03:10.850
And here in this case,
if I'm not mistaken,

00:03:10.850 --> 00:03:13.240
we're getting super-scalar results.

00:03:13.240 --> 00:03:16.340
The main important thing to
understand is that in our boxes,

00:03:16.340 --> 00:03:19.340
we have a little bit
more than just two CPUs.

00:03:19.690 --> 00:03:21.770
We have a very,
very strong architecture that

00:03:21.770 --> 00:03:25.360
enables us to actually take advantage
of both of these G5s in the box.

00:03:25.380 --> 00:03:30.200
Specifically here-- why do we get
things such as 2.3 times faster?

00:03:30.250 --> 00:03:34.010
Well, for the simple reason that actually
each CPU is going to have its own

00:03:34.010 --> 00:03:36.240
bus to go to the memory controller.

00:03:36.240 --> 00:03:38.530
That makes a big, big, big difference.

00:03:38.590 --> 00:03:41.880
In certain cases, maybe your algorithm is
going to be CPU-bounded.

00:03:42.060 --> 00:03:44.510
In this case,
when threading your application,

00:03:44.540 --> 00:03:48.600
just imagine that you're giving twice
as much bandwidth to the main memory.

00:03:51.100 --> 00:03:52.570
So why use thread?

00:03:52.810 --> 00:03:56.680
So obviously, customer's expectation,
as I talked about, and scalability.

00:03:56.990 --> 00:03:59.020
Once again, look,
the three of the G5 shipping

00:03:59.020 --> 00:04:00.980
right now all have dual CPUs.

00:04:01.020 --> 00:04:01.760
This is a big deal.

00:04:01.760 --> 00:04:04.270
And I think you've seen
the industry-- I mean,

00:04:04.270 --> 00:04:06.940
Intel has been doing some
announcements about dual core.

00:04:06.980 --> 00:04:09.510
This is something that really
the industry is moving towards.

00:04:09.590 --> 00:04:13.370
So please keep that in mind
in your future development.

00:04:13.690 --> 00:04:14.340
OK, threads.

00:04:14.420 --> 00:04:15.500
Qu'est-ce que c'est?

00:04:15.560 --> 00:04:19.010
So we're going to throw
a couple of buzzwords.

00:04:19.270 --> 00:04:21.850
And trust me,
by the end of this presentation,

00:04:21.850 --> 00:04:24.080
you'll probably be speaking French.

00:04:25.120 --> 00:04:26.320
Okay, so what's a thread?

00:04:26.480 --> 00:04:30.700
So a thread, think of a thread as an
independent execution code path.

00:04:30.820 --> 00:04:32.430
And this is very, very important.

00:04:32.520 --> 00:04:34.840
If you're new to threading,
and if you have no clue

00:04:34.840 --> 00:04:37.720
about how you should be able
to thread your application,

00:04:37.720 --> 00:04:41.000
think about your function that
you're going to want to thread.

00:04:41.000 --> 00:04:44.560
Is it considered as, you know,
something that can be executed

00:04:44.570 --> 00:04:47.000
independently of the rest of the code?

00:04:47.190 --> 00:04:51.550
And specifically,
think of it as something that's going

00:04:51.590 --> 00:04:52.580
to have its own stack and register set.

00:04:54.680 --> 00:04:55.680
So what's a process?

00:04:55.840 --> 00:04:58.160
A process is going to be actually
a collection of threads with

00:04:58.160 --> 00:05:00.790
the resources necessary to run.

00:05:00.950 --> 00:05:03.400
Specifically, a process,
think of it like when you

00:05:03.400 --> 00:05:05.490
launch your application,
boom, that's a process.

00:05:05.510 --> 00:05:07.740
And inside that process,
you could have different, actually,

00:05:07.740 --> 00:05:09.720
threads going on.

00:05:09.760 --> 00:05:13.560
The cool thing here is that a
process has its own address space.

00:05:13.590 --> 00:05:16.830
That means that actually the threads
inside that address space can access,

00:05:16.830 --> 00:05:20.350
actually, global variables if you had to.

00:05:20.370 --> 00:05:23.400
And memory that you pass on the main
thread to view the thread is the

00:05:23.400 --> 00:05:26.660
memory from the same address space,
obviously.

00:05:28.460 --> 00:05:32.270
Okay, now before we go and we explain
why and how you should use threads,

00:05:32.270 --> 00:05:35.400
let's think a little bit about
when you should not use threads.

00:05:35.400 --> 00:05:38.070
Okay,
obviously in the case where it's going

00:05:38.070 --> 00:05:42.320
to add complexity to your application,
you don't want to get in that business.

00:05:42.470 --> 00:05:45.400
There is no need for you to spend
six months threading your application

00:05:45.400 --> 00:05:48.400
if it's going to be like every
time you want to add a feature,

00:05:48.400 --> 00:05:52.330
another six months of trying to
find out and managing the thread,

00:05:52.330 --> 00:05:54.310
doing the thread management.

00:05:54.420 --> 00:05:58.400
Obviously, things that are going to
require locks are a bad idea.

00:05:58.510 --> 00:06:01.400
And here in this case,
think of it as like in a database

00:06:01.400 --> 00:06:05.400
and a lot of people trying
to write to the same record.

00:06:05.400 --> 00:06:08.350
Depending on the granularity of the lock,
obviously you're going

00:06:08.350 --> 00:06:09.990
to have to be very,
very careful.

00:06:10.300 --> 00:06:23.500
[Transcript missing]

00:06:25.070 --> 00:06:26.920
Some other options,
you could use cooperative threading,

00:06:26.920 --> 00:06:31.820
which is probably what most of
you have been using on Mac OS 9.

00:06:31.820 --> 00:06:35.560
I put timers here, and I'm talking here
about Carbon event timers.

00:06:35.580 --> 00:06:37.960
And this is very often
people don't understand,

00:06:37.960 --> 00:06:40.760
but they're like, well,
I'm doing a bunch of processing on the

00:06:40.760 --> 00:06:44.740
hard drive and I want to show the user
the progress and give them a chance maybe

00:06:44.790 --> 00:06:46.440
to cancel the operation or something.

00:06:46.440 --> 00:06:48.640
You could use a
Carbon event timer for that.

00:06:48.640 --> 00:06:50.590
OK,
use a Carbon event timer that's going to

00:06:50.590 --> 00:06:53.090
fire every second or twice per second.

00:06:53.100 --> 00:06:54.000
It's up to you.

00:06:54.000 --> 00:06:57.730
And then the toolbox will call you
inside your Carbon event handler,

00:06:57.890 --> 00:07:00.940
your timer event handler,
and actually that will enable you to

00:07:00.940 --> 00:07:03.140
update whatever you want on the screen.

00:07:03.200 --> 00:07:05.510
So that's why I want you to put timers.

00:07:06.130 --> 00:07:10.740
Okay, now, so hopefully you get the idea,
and if you're here in this room,

00:07:10.740 --> 00:07:12.370
obviously you want to learn,
and you're interested in

00:07:12.370 --> 00:07:13.340
threading your application.

00:07:13.340 --> 00:07:17.120
Now, I'm going to go through what I think
are three of the main threading

00:07:17.120 --> 00:07:18.660
architectures that we see out there.

00:07:18.660 --> 00:07:21.920
Parallel task,
we've shared parallel buffer.

00:07:22.050 --> 00:07:24.010
You can read the slides better than me.

00:07:24.020 --> 00:07:25.980
I think it's better if
I show you a picture.

00:07:25.980 --> 00:07:30.270
So in this first case,
one example to think about this

00:07:30.520 --> 00:07:34.600
parallel task with parallel buffer
architecture would be to think of maybe,

00:07:34.600 --> 00:07:37.500
let's see a simulator,
a flight simulator.

00:07:37.500 --> 00:07:40.930
You get data in one buffer,
and that data is going to be computed,

00:07:40.990 --> 00:07:43.230
and the result is going to be,
maybe you're going to

00:07:43.240 --> 00:07:45.240
compute atmospheric settings,
okay?

00:07:45.240 --> 00:07:47.320
So this is totally an independent path.

00:07:47.400 --> 00:07:50.420
You have, like, you know, one IO buffer,
one output buffer.

00:07:50.420 --> 00:07:52.260
They don't depend on
the rest of the data.

00:07:52.260 --> 00:07:55.620
Then on thread number two,
what you could do is compute, let's say,

00:07:55.620 --> 00:07:58.170
the ground, and you get, you know,
the data, let's say,

00:07:58.230 --> 00:08:01.220
from the Internet or from, like,
you know, some geostationary satellites.

00:08:01.260 --> 00:08:02.720
So you get the data,
and I don't know if you can see it,

00:08:02.720 --> 00:08:03.220
but that's one of the thread.

00:08:03.220 --> 00:08:04.460
That's your IO buffer.

00:08:04.460 --> 00:08:07.910
Then you do the processing to
compute maybe some fractal terrains,

00:08:07.920 --> 00:08:10.670
okay, like some 3D world,
and then at the end, you get, like,

00:08:10.670 --> 00:08:14.180
you know, a G world, an offscreen, or,
you know, CG context, or, like,

00:08:14.180 --> 00:08:17.180
an open GL surface, whatever you want,
et cetera, et cetera.

00:08:17.180 --> 00:08:20.070
You could have, you know, thread,
you know, number three, for instance, do,

00:08:20.070 --> 00:08:22.470
like, the computation of...

00:08:22.820 --> 00:08:29.110
VeloCity, or whatever you want it,
collision, you know.

00:08:29.170 --> 00:08:35.820
And here the main idea in this
architecture is that think of it as,

00:08:36.050 --> 00:08:38.280
you know, you have N different input
buffers and N output buffers.

00:08:38.280 --> 00:08:38.280
And they just do like, you know,
like your different processing

00:08:38.280 --> 00:08:38.280
on each of these threads.

00:08:39.890 --> 00:08:40.130
All right.

00:08:40.140 --> 00:08:44.100
This architecture is actually
the one that works better,

00:08:44.100 --> 00:08:45.180
I think, in my mind.

00:08:45.180 --> 00:08:47.080
And I think, like,
a lot of applications could use that.

00:08:47.140 --> 00:08:50.540
And here in this case,
we have a buffer of data.

00:08:50.540 --> 00:08:53.280
Okay, it could be, like, an image,
and you want to apply a transform.

00:08:53.280 --> 00:08:56.470
Or it could be pretty much anything.

00:08:56.560 --> 00:08:58.920
It could be, like, a huge array of, like,
floating points.

00:08:58.920 --> 00:09:01.650
And you want to, like, you know,
compute the cosinus, the sinus,

00:09:01.650 --> 00:09:04.100
the tangent, and, you know,
generate at the end, like, you know,

00:09:04.100 --> 00:09:05.540
this huge output buffer.

00:09:05.540 --> 00:09:09.200
Here in this case,
this is what I'm going to use in my demo.

00:09:09.200 --> 00:09:12.370
So, and not to ruin it,
what's going to happen is that I have

00:09:12.370 --> 00:09:14.320
this application that computes a fractal.

00:09:14.320 --> 00:09:15.760
So why do I have an input?

00:09:15.820 --> 00:09:19.010
An input, what I do have is, you know,
this buffer, which is actually a

00:09:19.140 --> 00:09:20.110
pointer on my offscreen.

00:09:20.120 --> 00:09:23.280
Okay, I have a graph board, an offscreen,
and it points to the

00:09:23.310 --> 00:09:24.660
beginning of my image.

00:09:24.660 --> 00:09:26.840
And, you know,
to compute the model broad space,

00:09:26.840 --> 00:09:28.700
which is the fractal I'm
going to be computing,

00:09:28.700 --> 00:09:33.020
I just need to compute, like, you know,
if, like, each pixel is in or out

00:09:33.020 --> 00:09:34.280
of a model broad space.

00:09:34.280 --> 00:09:37.610
Well, what I can do very quickly,
and in an easy way that

00:09:37.610 --> 00:09:40.740
hopefully I will show you,
is that I could take that

00:09:40.750 --> 00:09:43.980
initial buffer and pass it,
actually, to n threads.

00:09:44.000 --> 00:09:47.870
I'm going to divide, actually,
my picture in n different parts,

00:09:47.880 --> 00:09:50.240
and n different threads
are going to be computing,

00:09:50.240 --> 00:09:51.440
actually, the data for me.

00:09:51.440 --> 00:09:53.720
And then at the end,
because of some magic,

00:09:53.720 --> 00:09:56.700
what I could do is pass different
pointers inside my image,

00:09:56.700 --> 00:09:58.750
you know, think of it as, like, you know,
just, like,

00:09:58.830 --> 00:10:02.020
slicing the initial image and passing
one slice to each of the threads.

00:10:02.020 --> 00:10:04.520
I don't need to, like, you know,
recombine, actually,

00:10:04.520 --> 00:10:06.320
all the results because I just have,
like, you know,

00:10:06.320 --> 00:10:07.760
the initial pointer to the offscreen.

00:10:07.760 --> 00:10:10.680
But that's something,
you could apply pretty much to anything.

00:10:10.680 --> 00:10:13.460
Think of it, like, you know,
let's say you have this hard

00:10:13.460 --> 00:10:15.980
drive and you need to compress
all the files one by one.

00:10:16.000 --> 00:10:18.580
Well, you could spend, you know,
10 threads, and, you know,

00:10:18.580 --> 00:10:20.940
each of the threads will take one
of the files from the directory.

00:10:20.960 --> 00:10:25.030
Think of it, for instance,
if you're doing HPC or if you're doing,

00:10:25.030 --> 00:10:27.260
in this case, like, you know,
some sci-tech computation,

00:10:27.260 --> 00:10:29.730
and you have this huge array
of data that you need to,

00:10:29.780 --> 00:10:32.170
like, you know,
crunch through it and apply, you know,

00:10:32.240 --> 00:10:34.640
like, some FFTs or, you know,
2D transformation or

00:10:34.640 --> 00:10:36.100
rotation of the data set.

00:10:36.100 --> 00:10:39.080
Well, you could actually use the same,
actually, architecture here,

00:10:39.200 --> 00:10:40.360
to go through your data set.

00:10:40.420 --> 00:10:42.040
You know, you spawn, and you're, like,
you know,

00:10:42.040 --> 00:10:44.940
you're going to slice your input
data and pass it to n threads,

00:10:44.940 --> 00:10:46.880
and then recombine the data at the end.

00:10:49.760 --> 00:10:54.800
The last one sounds more difficult,
but actually works pretty well.

00:10:54.870 --> 00:10:57.140
Here in this case,
we're going to have sequential

00:10:57.140 --> 00:10:58.790
tasks with multiple hour buffer.

00:10:58.880 --> 00:11:01.740
The type of usage,
the type of application

00:11:01.800 --> 00:11:05.950
that could use that,
are applications that need to execute,

00:11:05.950 --> 00:11:09.740
let's say, any different task on
an initial data set.

00:11:09.800 --> 00:11:12.560
One example that I like
to give people is,

00:11:12.560 --> 00:11:15.310
for instance, take a word processor.

00:11:15.310 --> 00:11:17.820
Let's say you have this word processor,
and you have this

00:11:18.230 --> 00:11:20.920
You have to run different tasks onto,
like, you know, the data set.

00:11:20.920 --> 00:11:21.630
So you open a file.

00:11:21.770 --> 00:11:22.430
It's a huge file.

00:11:22.470 --> 00:11:24.900
It's, like, you know,
it makes a megabyte, two megabytes,

00:11:24.900 --> 00:11:25.400
whatever.

00:11:25.410 --> 00:11:26.700
It could be 100K.

00:11:26.700 --> 00:11:28.890
And what you're going to
do is that you have to run,

00:11:28.890 --> 00:11:31.280
like, spell checking,
then grammatical analysis,

00:11:31.280 --> 00:11:34.960
and then maybe after that you're going to
want to translate the result into French,

00:11:34.960 --> 00:11:36.240
German, you name it.

00:11:36.240 --> 00:11:39.330
Here, in this case, what will happen is
that the input buffer,

00:11:39.330 --> 00:11:42.150
the initial buffer,
will be the first paragraph, okay,

00:11:42.150 --> 00:11:43.200
of a document.

00:11:43.930 --> 00:11:45.520
We're going to pass that
to thread number one.

00:11:45.520 --> 00:11:47.350
Thread number one is going
to do the spell checking.

00:11:47.360 --> 00:11:50.890
When the spell checking is done,
you take the output buffer and

00:11:51.150 --> 00:11:53.700
you pass it to thread number two,
who's going to be doing

00:11:53.700 --> 00:11:56.040
the grammatical analysis,
for instance.

00:11:56.040 --> 00:11:56.760
Okay?

00:11:56.890 --> 00:11:57.720
So what do we have?

00:11:57.760 --> 00:11:59.920
At this point in time,
we have thread number two

00:11:59.930 --> 00:12:02.720
doing grammatical analysis
on paragraph number one.

00:12:02.720 --> 00:12:04.800
And then thread number
one will be grabbing,

00:12:04.800 --> 00:12:07.440
actually, let's say,
paragraph number two of a document

00:12:07.490 --> 00:12:10.320
and do the spell checking on it,
et cetera, et cetera.

00:12:10.320 --> 00:12:12.300
So think of it as, like,
cascading the result

00:12:12.300 --> 00:12:13.500
of a previous thread.

00:12:13.880 --> 00:12:17.080
And here, in this case,
the end threads are actually dependent on

00:12:17.080 --> 00:12:20.640
the result of the end minus one threads,
but after end operations,

00:12:20.640 --> 00:12:22.660
all the threads will be
actually full doing work.

00:12:25.200 --> 00:12:32.390
and then the output buffer will
be obviously the French text

00:12:32.390 --> 00:12:32.390
or the corrected English text,
whatever you want.

00:12:34.440 --> 00:12:37.680
Okay, so now let's talk about the
different implementation and what

00:12:37.680 --> 00:12:41.360
APIs that you can use as a developer.

00:12:41.460 --> 00:12:43.630
What's important to understand
is that your Mac OS X,

00:12:43.630 --> 00:12:46.300
the three different implementations
I'm going to be talking about,

00:12:46.430 --> 00:12:50.640
actually are implemented over Pthreads,
which is really good news.

00:12:50.640 --> 00:12:52.760
I mean,
if you've been coming from Mac OS 9,

00:12:52.760 --> 00:12:54.880
this is like, you know,
Mac OS X is like a truly

00:12:54.880 --> 00:12:57.290
multi-tasking system,
preemptive multi-tasking system,

00:12:57.290 --> 00:12:59.280
and it's great to have, actually,
that implementation.

00:12:59.450 --> 00:13:02.090
And obviously,
if you're coming from a Unix background,

00:13:02.130 --> 00:13:04.300
you're probably very pleased with that.

00:13:04.300 --> 00:13:06.030
On top of that,
what we have is a different

00:13:06.080 --> 00:13:07.300
type of implementation.

00:13:07.300 --> 00:13:10.710
So Java has like the Java threads
implemented on top of Pthreads

00:13:10.790 --> 00:13:13.300
and they have their own APIs,
obviously.

00:13:13.380 --> 00:13:16.600
Carbon has what we call the MP APIs,
and I'll talk a little bit more

00:13:16.600 --> 00:13:18.300
detail about that in a second.

00:13:18.300 --> 00:13:21.460
And Cocoa with NS threads
actually is the same thing,

00:13:21.460 --> 00:13:24.300
a set of APIs implemented
on top of Pthreads.

00:13:24.520 --> 00:13:26.900
Usually, like, what I get at, like,
the first question I get

00:13:27.030 --> 00:13:29.300
after my presentation is like,
"So we have all these threads.

00:13:29.300 --> 00:13:30.220
"So what should I do?

00:13:30.360 --> 00:13:33.550
"Like, why should I use MP instead
of Pthreads?" Well,

00:13:33.550 --> 00:13:37.540
it's not--there is no answer for that
question because the idea here is that

00:13:37.540 --> 00:13:40.140
we give you as many choices as we can,
and it's up to you

00:13:40.140 --> 00:13:43.290
guys as a developer to,
like, find what fits best for you.

00:13:43.300 --> 00:13:46.280
I'm going to show you--I'm going to be
using the MP APIs because when I started,

00:13:46.310 --> 00:13:49.380
I had no clue and, you know,
I needed to actually

00:13:49.450 --> 00:13:50.300
thread my application.

00:13:50.300 --> 00:13:52.300
And I wondered, like, you know,
what I wanted to use.

00:13:52.300 --> 00:13:54.490
You know,
Pthreads were a little bit too level for

00:13:54.490 --> 00:13:58.300
me and documentation was kind of hard,
you know, just, you know,

00:13:58.300 --> 00:13:58.300
coming from the Mac database.

00:13:58.300 --> 00:14:02.300
You know,
I'm not really a Unix developer yet.

00:14:02.300 --> 00:14:04.300
And the MP APIs really
offered a nice abstraction,

00:14:04.300 --> 00:14:06.190
and so that's why I decided.

00:14:06.370 --> 00:14:08.640
But if you're more comfortable
with Pthreads and you've been

00:14:08.640 --> 00:14:10.300
developing with Pthreads,
please do so.

00:14:10.300 --> 00:14:11.290
Use Pthreads, okay?

00:14:11.330 --> 00:14:14.290
There is no big deal.

00:14:14.360 --> 00:14:17.560
And then Cocoa or Java, depending on,
like, you know, what type of application

00:14:17.560 --> 00:14:19.300
you're developing,
it's up to you.

00:14:21.260 --> 00:14:24.360
OK, for Carbon development,
and I should rephrase that,

00:14:24.360 --> 00:14:26.890
because we've had some folks
actually doing Cocoa that use the

00:14:26.890 --> 00:14:28.520
MP APIs in one of our workshops.

00:14:28.540 --> 00:14:32.590
Since it's a C API, you know,
Cocoa applications can use it as well.

00:14:32.600 --> 00:14:34.760
You can pretty much do
everything you want from Cocoa.

00:14:34.760 --> 00:14:39.010
But if you have a Carbon application,
the MP APIs are available

00:14:39.010 --> 00:14:41.900
in multiprocessing.h,
and I hope it is clear

00:14:41.900 --> 00:14:43.130
for you guys in the back.

00:14:43.140 --> 00:14:46.460
And, you know, we offer, like, you know,
services and objects such as

00:14:46.460 --> 00:14:49.780
MP Sema for MPQs and MP Tasks,
and I'm going to be talking

00:14:49.810 --> 00:14:50.970
about that in more details.

00:14:51.200 --> 00:14:53.660
And once again,
important to understand that, you know,

00:14:53.660 --> 00:14:57.650
below that, what we did, in fact,
is offer you an abstraction

00:14:57.690 --> 00:14:59.920
level on top of P threads,
OK?

00:14:59.920 --> 00:15:03.580
So you're going to get, like, you know,
the result and the quality of P threads.

00:15:06.320 --> 00:15:07.830
Okay, so threading implementation.

00:15:07.840 --> 00:15:09.660
This is where things get interesting.

00:15:09.710 --> 00:15:11.520
You have two approaches.

00:15:11.630 --> 00:15:14.940
The first, and I remember from talking
to some folks out there,

00:15:14.980 --> 00:15:17.100
you know, think, "Oh,
you want me to thread my application,

00:15:17.100 --> 00:15:18.380
but this is going to be
a nightmare." I mean,

00:15:18.380 --> 00:15:21.220
you don't realize, you know, we have,
like, you know, the menu management.

00:15:21.270 --> 00:15:22.800
I need to keep track of what's going on.

00:15:22.800 --> 00:15:25.750
I mean, this is going to take me, like,
a year to thread my application.

00:15:25.830 --> 00:15:29.200
So the first approach, of course,
is the difficult one, I think, which is,

00:15:29.250 --> 00:15:31.460
you have an application that
is not threaded right now,

00:15:31.520 --> 00:15:33.090
and you're going to re-thread everything.

00:15:33.100 --> 00:15:35.260
And here, the main idea, of course,
is to, like, you know,

00:15:35.260 --> 00:15:40.110
give your users as much
responsiveness as you can.

00:15:40.910 --> 00:15:43.930
But I think there's a better way actually
to start threading your application,

00:15:43.930 --> 00:15:46.080
depending of what type
of applications you have.

00:15:46.160 --> 00:15:51.860
But another task would be to actually
just thread CPU intensive operations.

00:15:51.860 --> 00:15:55.620
And here the main advantage of that
approach is that you don't have to

00:15:55.620 --> 00:15:58.360
re-architecture your whole application,
OK?

00:15:58.370 --> 00:16:00.910
So let's say you have an application
and you do some computing,

00:16:00.930 --> 00:16:05.290
and you need to compute, you know,
I don't know, like a 3D-generated model,

00:16:05.290 --> 00:16:07.820
or you have to do some compression.

00:16:07.820 --> 00:16:11.660
Well, what you could do is when you get--
and the user executes that task,

00:16:11.660 --> 00:16:15.060
you could start just threading
that part of the processing.

00:16:15.060 --> 00:16:17.920
And I'm going to show you
techniques actually to enable

00:16:17.920 --> 00:16:20.700
you to do that without having to
re-architecture the rest of the app,

00:16:20.700 --> 00:16:23.110
because we're going to work
on that part of the code,

00:16:23.240 --> 00:16:26.230
and we won't touch the
rest of the application.

00:16:31.040 --> 00:16:34.450
So if you wanted to thread
your whole application,

00:16:34.450 --> 00:16:36.470
you have a couple of
concepts to implement.

00:16:36.560 --> 00:16:40.450
Thread management, obviously,
what thread is going on.

00:16:40.460 --> 00:16:43.050
If a user wants to redo the
operation and the thread is not done,

00:16:43.050 --> 00:16:45.280
you'll have to actually kill
the thread and restart it,

00:16:45.340 --> 00:16:46.540
and this kind of things.

00:16:46.600 --> 00:16:48.230
And then you have to do
some synchronization,

00:16:48.230 --> 00:16:48.790
of course.

00:16:48.800 --> 00:16:51.620
When a thread is done,
maybe it's going to spawn five threads,

00:16:51.650 --> 00:16:53.800
and they're going to do
each part of something.

00:16:53.910 --> 00:16:56.670
You're going to have to
notify back to the main event

00:16:56.840 --> 00:17:00.600
loop that a thread is done,
or there is an error, or it crashed,

00:17:00.600 --> 00:17:02.130
you name it.

00:17:03.910 --> 00:17:05.720
And of course,
you'd have to make sure that you

00:17:05.720 --> 00:17:08.520
implement thread-safe services
in your application as well.

00:17:08.520 --> 00:17:12.160
That will force you to think, well,
that global data is being

00:17:12.160 --> 00:17:14.840
accessed not only as read,
but as write as well,

00:17:14.840 --> 00:17:17.940
and I'm going to have to put a lock
on that so my threads can access it.

00:17:17.960 --> 00:17:21.430
Now, let's go with what I think
is the simplest approach,

00:17:21.490 --> 00:17:24.510
which is thread just
one part of application.

00:17:24.520 --> 00:17:28.490
Thread an operation in your application
that takes relatively a long time,

00:17:28.490 --> 00:17:30.300
that is really CPU-intensive.

00:17:31.170 --> 00:17:36.160
So the way to go about that is identify
a tight loop that uses a lot of CPU,

00:17:36.160 --> 00:17:41.370
or just takes a very long time and
always at 20%. The main idea here

00:17:41.420 --> 00:17:45.740
is that if you fit in that category,
I think it's very,

00:17:45.740 --> 00:17:49.170
very straightforward to
actually just divide that loop.

00:17:49.180 --> 00:17:52.180
But you'd have to ensure that
that loop can be divided.

00:17:52.180 --> 00:17:56.020
In my example, for instance,
I don't have any data dependencies

00:17:56.100 --> 00:17:57.880
from one pixel to the other.

00:17:57.880 --> 00:18:01.080
If you wanted to do something
a little bit more elaborated,

00:18:01.160 --> 00:18:05.800
where a value of a pixel depends on
the one that is maybe 10 rows below,

00:18:05.800 --> 00:18:08.860
or five pixels before,
it may be a little bit

00:18:08.860 --> 00:18:11.190
more difficult to achieve,
because you'd have to make

00:18:11.190 --> 00:18:13.180
sure that actually that pixel
value has been computed.

00:18:17.850 --> 00:18:19.580
So typically, what are you looking for?

00:18:19.580 --> 00:18:22.760
So here, in this case, in my code,
I had a compute model broad that

00:18:22.810 --> 00:18:24.560
was taking a bunch of parameters.

00:18:24.570 --> 00:18:28.960
And here, I had a loop that was
actually doing the work.

00:18:28.960 --> 00:18:30.420
OK, and I was going line by line.

00:18:30.420 --> 00:18:32.500
Typically,
the best way to look at it is that

00:18:32.800 --> 00:18:34.600
try to find-- and you know your code.

00:18:34.600 --> 00:18:36.760
Obviously,
you don't have to do searching for loops.

00:18:36.760 --> 00:18:40.640
But the main idea here is identify
something in the aspect of you have

00:18:40.640 --> 00:18:45.040
this big loop to a large number
and that does some processing.

00:18:45.060 --> 00:18:47.040
Here, in this case,
remember what I said at the beginning.

00:18:47.040 --> 00:18:51.040
You need to make sure that the
code can be executed independently.

00:18:51.040 --> 00:18:54.140
Here, in this case,
I had to ensure that compute my fractal,

00:18:54.220 --> 00:18:57.180
the API,
the function that does all the work,

00:18:57.180 --> 00:19:00.550
could actually be executed
as a separate entity.

00:19:01.400 --> 00:19:04.640
Which, no big deal,
because it's pretty straightforward.

00:19:04.670 --> 00:19:07.970
So let's try to see a nice
graphic here on what's going on.

00:19:08.080 --> 00:19:09.950
So what's going on when
you're not threaded?

00:19:09.980 --> 00:19:13.000
Remember, I have one thread, one process.

00:19:13.180 --> 00:19:15.210
One thread in the process
that has been launched,

00:19:15.210 --> 00:19:17.410
the process being the application.

00:19:17.610 --> 00:19:21.960
In that case, I get a command from my
Carbon event handler that says,

00:19:21.960 --> 00:19:25.240
hey, do some benchmarking,
or compute the factor.

00:19:25.270 --> 00:19:27.000
Then I get into the main thread.

00:19:27.040 --> 00:19:28.720
I compute Mandelbrot.

00:19:28.750 --> 00:19:30.580
Then after that, I compute.

00:19:30.580 --> 00:19:33.720
I have the API that does the real work,
that's going to do that loop

00:19:33.760 --> 00:19:35.840
that goes through each line.

00:19:35.840 --> 00:19:37.540
And then we go back
to compute Mandelbrot.

00:19:37.540 --> 00:19:38.480
The buffer has been filled.

00:19:38.510 --> 00:19:39.610
It's been computed.

00:19:39.640 --> 00:19:42.250
And then I go back to
the main event loop,

00:19:42.250 --> 00:19:45.710
and I display the buffer results.

00:19:46.860 --> 00:19:50.780
So now, how are we going to have to
recapture that part of the code,

00:19:50.830 --> 00:19:53.300
that routine, in order to be threaded?

00:19:53.420 --> 00:19:53.600
OK.

00:19:53.600 --> 00:19:55.850
So what's going to happen,
same as before,

00:19:55.850 --> 00:19:59.980
somebody's going to do the benchmark,
like compute the model broad space.

00:20:01.010 --> 00:20:03.940
What I'm going to do then is that
I'm going to spawn two threads.

00:20:03.970 --> 00:20:08.290
I'm going to divide my buffer
into two different parts.

00:20:08.380 --> 00:20:11.220
The first one,
I'm going to spawn thread number one,

00:20:11.320 --> 00:20:17.980
and that's going to be in this routine
that is pretty much an exact copy

00:20:17.980 --> 00:20:21.950
of actually the one I had before,
but just with an adjustment of

00:20:21.950 --> 00:20:21.950
parameters for like the beginning
and the end of the computation.

00:20:22.190 --> 00:20:24.600
And here what I do is
that I pass the offset,

00:20:24.610 --> 00:20:26.630
you know,
a pointer to the beginning of a picture.

00:20:26.820 --> 00:20:29.720
And then the last, you know,
another parameter is actually

00:20:29.720 --> 00:20:31.250
the end when I want to stop.

00:20:31.290 --> 00:20:36.300
And here in this case,
it's like the size of a

00:20:36.300 --> 00:20:36.300
picture divided by two,
you know, for the number of loops.

00:20:36.510 --> 00:20:38.680
Thread number two is going
to be spawned as well.

00:20:38.920 --> 00:20:41.150
And here, as you can see,
the red value has been changed.

00:20:41.260 --> 00:20:46.170
And what's going to happen is that
I pass the second half of the picture.

00:20:46.510 --> 00:20:49.800
And here, you're probably wondering,
well, why just two?

00:20:49.800 --> 00:20:53.010
And this is actually something that
happened during one of our workshops,

00:20:53.010 --> 00:20:56.350
where some folks were wondering, well,
the problem here is that you

00:20:56.350 --> 00:20:59.020
think that there's only two CPUs,
but what happens if one

00:20:59.020 --> 00:21:00.420
day you have more CPUs?

00:21:00.420 --> 00:21:00.920
And that's true.

00:21:00.920 --> 00:21:02.520
You should not make
that type of assumption.

00:21:02.520 --> 00:21:06.880
Your code should be able to actually
divide and slice a trend time.

00:21:06.980 --> 00:21:07.940
And it's not very difficult.

00:21:07.940 --> 00:21:10.320
Just count the number of CPUs,
and you can actually divide

00:21:10.660 --> 00:21:16.200
your picture like that,
which actually I did as well.

00:21:17.040 --> 00:21:20.320
The cool thing here is that remember,
I'm gonna spawn these threads,

00:21:20.340 --> 00:21:23.930
but I don't want to get in the business
of doing management of threads,

00:21:23.930 --> 00:21:24.380
okay?

00:21:24.410 --> 00:21:26.730
I don't want to re-architecture
my whole application.

00:21:26.830 --> 00:21:29.490
So I still want the
application to be blocked.

00:21:29.580 --> 00:21:33.000
So, when I get inside that routine,
CalculMondelbrot,

00:21:33.010 --> 00:21:36.200
I want to spawn my two threads,
but I want to wait there.

00:21:36.200 --> 00:21:40.130
I don't want to go back to the main event
loop because I don't want to be able to,

00:21:40.140 --> 00:21:42.760
I don't want the user to
click again and recompute,

00:21:42.790 --> 00:21:44.660
because then I'll have to
do all that management,

00:21:44.760 --> 00:21:46.880
find out if the threads
are done computing,

00:21:46.900 --> 00:21:50.300
restart them, I mean, kill them,
restart them with the new parameters.

00:21:50.400 --> 00:21:54.940
So here, my idea was, very simply,
I wanted to take advantage to the fact

00:21:54.940 --> 00:21:57.890
that the 2.5 of two processors inside.

00:21:58.000 --> 00:22:02.000
So what I wanted to do is that made
that computation as fast as possible.

00:22:02.000 --> 00:22:04.280
I didn't want to
re-architecture everything.

00:22:04.340 --> 00:22:06.540
So here, what I'm gonna do is that
in ComputeMondelbrot,

00:22:06.540 --> 00:22:09.280
CalculMondelbrot, I'm gonna wait.

00:22:09.300 --> 00:22:10.700
I'm gonna sit tight and I'm gonna wait.

00:22:10.720 --> 00:22:13.380
And we're gonna see how
we're gonna do that.

00:22:14.580 --> 00:22:17.110
And then, obviously,
remember what I said,

00:22:17.110 --> 00:22:20.800
when the threads are done,
we need to find a way to signal or notify

00:22:20.800 --> 00:22:23.600
the main thread that actually we're done.

00:22:23.640 --> 00:22:26.240
Because remember,
we're inside the routine,

00:22:26.240 --> 00:22:27.460
CalculMondelBrot.

00:22:27.490 --> 00:22:28.790
I spawn two threads.

00:22:29.060 --> 00:22:31.530
These two threads are going
to be just doing some work.

00:22:31.540 --> 00:22:35.320
But it's like 10 milliseconds
to spawn the thread,

00:22:35.320 --> 00:22:37.730
and then we go to the next code.

00:22:37.810 --> 00:22:40.390
And then there is no way for
me to get back to my routine,

00:22:40.450 --> 00:22:43.050
because that's an independent
execution code path.

00:22:43.060 --> 00:22:44.430
Remember that.

00:22:44.550 --> 00:22:45.700
So we need to signal.

00:22:45.700 --> 00:22:47.640
We need to get back to
a main thread and say,

00:22:47.720 --> 00:22:49.500
hey, I'm done.

00:22:50.820 --> 00:22:51.090
OK.

00:22:51.200 --> 00:22:52.600
So how are we going to achieve that?

00:22:52.600 --> 00:22:55.640
Step number one,
and hopefully it's big enough

00:22:55.740 --> 00:22:58.350
for you guys in the back,
step number one is that you're going

00:22:58.350 --> 00:23:00.440
to have to initialize the MP libraries.

00:23:00.610 --> 00:23:03.160
And here, the example I'm taking,
I'm going to be using

00:23:03.160 --> 00:23:05.810
actually the MP libraries,
multiprocessing.h.

00:23:05.910 --> 00:23:10.160
I think it's in Core Services,
in the framework Core Services.

00:23:10.220 --> 00:23:13.960
So first thing I'm going to do is
count the number of processors.

00:23:13.960 --> 00:23:15.560
Then I'm going to create a queue.

00:23:15.570 --> 00:23:18.680
And I'm going to explain in
more detail what that is about.

00:23:18.680 --> 00:23:21.610
And then after that,
I have this loop that goes from zero

00:23:21.610 --> 00:23:23.440
to actually the number of processors.

00:23:23.440 --> 00:23:25.010
And I create a task.

00:23:25.150 --> 00:23:27.280
Think of a task as a thread.

00:23:27.280 --> 00:23:29.260
Well, kind of.

00:23:29.270 --> 00:23:31.620
Let me go in more detail about that.

00:23:31.620 --> 00:23:34.180
The MP APIs have a
cool abstraction level.

00:23:34.180 --> 00:23:37.140
I mean, I really liked it personally,
because I think it made my life very

00:23:37.180 --> 00:23:39.720
easy for implementing that feature.

00:23:39.810 --> 00:23:40.810
Think of it as this way.

00:23:40.850 --> 00:23:44.500
What happens is that we're going to have
a queue where we're going to submit jobs.

00:23:44.640 --> 00:23:47.490
And the MP library is going to
be the one actually dispatching

00:23:47.490 --> 00:23:48.680
that to the different libraries.

00:23:48.680 --> 00:23:51.590
And then the MP APIs are going to
be the one distributing that load

00:23:51.670 --> 00:23:53.180
actually to the different tasks.

00:23:53.180 --> 00:23:56.130
So this is where I'm going to
schedule my jobs to be executed.

00:23:56.220 --> 00:23:59.180
And then after that,
the MP APIs are going to be actually

00:23:59.180 --> 00:24:02.180
the one distributing that load
actually to the different tasks.

00:24:02.200 --> 00:24:05.180
So this is where I'm going to
schedule my jobs to be executed.

00:24:05.180 --> 00:24:08.180
And then after that,
the MP APIs are going to be actually

00:24:08.180 --> 00:24:14.150
the one distributing that load
actually to the different tasks.

00:24:14.380 --> 00:24:18.310
Even if you have a dual tool,
for instance, you can create four tasks,

00:24:18.310 --> 00:24:21.380
or eight tasks if you want it,
or six for that matter.

00:24:21.380 --> 00:24:22.440
It's up to you.

00:24:22.470 --> 00:24:26.570
And I'll show you that in the
demo some actually interesting

00:24:26.990 --> 00:24:31.510
things about the overhead for
creating more tasks than processors.

00:24:32.880 --> 00:24:36.420
So the reason I think that this is kind
of cool is that we had George Warner,

00:24:36.460 --> 00:24:40.500
who works in DTS and all
psychophrenic optimizer guy.

00:24:40.770 --> 00:24:42.710
He wrote some sample code because
I went to see him and I said,

00:24:42.710 --> 00:24:43.710
OK, I'd like to thread that.

00:24:43.740 --> 00:24:45.040
Like, what do you think I should do?

00:24:45.040 --> 00:24:46.300
Like, what should I read?

00:24:46.320 --> 00:24:51.430
And he wrote actually yet another
abstraction layer on top of the MP API.

00:24:51.440 --> 00:24:52.120
So it's pretty cool.

00:24:52.120 --> 00:24:55.520
So to do the job that I showed you here,
you can just do that

00:24:55.520 --> 00:24:57.140
or call it MPJobsInit.

00:24:57.160 --> 00:24:59.570
And I'm going to be posting, actually,
the sample code,

00:24:59.650 --> 00:25:01.620
that code specifically for you guys.

00:25:01.690 --> 00:25:02.390
So you can use that.

00:25:02.400 --> 00:25:05.930
It's like a very easy set of
APIs to actually submit jobs

00:25:05.940 --> 00:25:07.650
and initialize the stuff.

00:25:07.660 --> 00:25:09.280
I think it's three or four routines.

00:25:09.290 --> 00:25:11.510
It's very cool.

00:25:12.020 --> 00:25:15.120
And then he has an MPJobsInit,
as I showed you, and an MPJobsSubmit.

00:25:15.120 --> 00:25:17.700
And actually, that in the sample code is
going to be submit my thread,

00:25:17.700 --> 00:25:21.500
spawn my thread,
submit a job to actually the queue.

00:25:21.750 --> 00:25:23.860
So we'll see that in a second.

00:25:23.860 --> 00:25:25.950
Then step number two,
we're going to have to move our

00:25:26.060 --> 00:25:27.920
tight loop inside a new routine.

00:25:27.920 --> 00:25:30.460
So remember what I said,
where the CalculMondedBoard,

00:25:30.460 --> 00:25:31.600
that does the work.

00:25:31.620 --> 00:25:34.630
Now we're going to have to
create something that can

00:25:34.630 --> 00:25:37.180
be executed independently.

00:25:37.520 --> 00:25:40.820
And here what happens is that I'm
going to create a new routine.

00:25:40.820 --> 00:25:42.940
I could have overridden the other one.

00:25:42.950 --> 00:25:44.540
And in this case,
because I want to be able

00:25:44.590 --> 00:25:50.000
to reuse my sample code,
I'm going to pass two void pointers.

00:25:50.050 --> 00:25:51.500
Because then I can do
dynamic typecasting,

00:25:51.500 --> 00:25:55.520
and I can use that code later on
in another project if I wanted.

00:25:55.790 --> 00:25:59.060
That's going to be the routine,
the function that is going to be called,

00:25:59.100 --> 00:26:01.610
actually, by the threads.

00:26:01.800 --> 00:26:05.410
This is my execution code path that's
going to be executed independently

00:26:05.420 --> 00:26:06.780
of the rest of my application.

00:26:06.780 --> 00:26:09.400
So that routine is going to be
the one doing the crunching.

00:26:09.460 --> 00:26:10.360
So what should you do in there?

00:26:10.460 --> 00:26:11.570
You should prepare the data.

00:26:11.720 --> 00:26:13.560
What I mean by that is
that I'm going to reticast,

00:26:13.630 --> 00:26:16.490
actually,
the void pointer to some internal data so

00:26:16.570 --> 00:26:20.020
I can get back the beginning of the loop,
the end of the loop,

00:26:20.020 --> 00:26:22.960
a pointer on the picture.

00:26:23.030 --> 00:26:27.710
Because it's a Mandelbrot space,
the imaginary number to compute the

00:26:27.710 --> 00:26:31.570
deltas and find out if the number
is in or out of a Mandelbrot space.

00:26:31.610 --> 00:26:34.500
So the real part, the imaginary part,
and et cetera.

00:26:34.510 --> 00:26:36.350
Then I do my crunching.

00:26:36.360 --> 00:26:39.040
So it's yet a loop that's
going to be executing here.

00:26:39.040 --> 00:26:42.950
And I'm going to compute if the
pixel is in or out of the space.

00:26:42.980 --> 00:26:44.640
And then once I'm done, I signal.

00:26:44.730 --> 00:26:47.100
So I need to find a way
to-- because that routine,

00:26:47.100 --> 00:26:48.160
once we get out, we're lost.

00:26:48.160 --> 00:26:49.520
We're in the blue.

00:26:49.540 --> 00:26:51.240
So I need to find a way to say, hey,
you know what?

00:26:51.240 --> 00:26:51.730
I did my job.

00:26:51.820 --> 00:26:52.300
You know, I'm done.

00:26:52.300 --> 00:26:55.200
I computed like half of
a picture is finished.

00:27:00.500 --> 00:27:03.240
Okay, so step number three,
what I'm going to do is that, you know,

00:27:03.240 --> 00:27:05.280
to simplify once again,
I don't want to go back

00:27:05.350 --> 00:27:06.400
to the main event loop.

00:27:06.400 --> 00:27:09.080
I'm going to create a new routine,
which is a completion routine.

00:27:09.080 --> 00:27:11.490
And what that's going to do is
that it's going to sit tight.

00:27:11.500 --> 00:27:13.740
It's going to like, you know, you know,
just wait in there.

00:27:13.740 --> 00:27:16.290
It's going to be a routine that's
going to be called for my main thread.

00:27:16.290 --> 00:27:16.540
Okay.

00:27:16.630 --> 00:27:18.750
I don't spawn that, you know,
I'm going to be waiting there.

00:27:18.840 --> 00:27:21.570
And that's going to be my routine that's
going to be waiting to be signaled.

00:27:21.570 --> 00:27:22.380
Okay.

00:27:24.100 --> 00:27:27.170
And once again here,
that enables me to keep my existing

00:27:27.170 --> 00:27:31.450
architecture and not to have to
re-architecture the whole application.

00:27:33.670 --> 00:27:35.610
OK,
so here you have actually the way that

00:27:35.610 --> 00:27:37.310
I'm going to do to schedule the work.

00:27:37.460 --> 00:27:39.050
First, I'm going to create a semaphore.

00:27:39.240 --> 00:27:42.490
And the semaphore is going to be that
object that I'm going to keep between,

00:27:42.590 --> 00:27:44.130
actually, my threads.

00:27:44.250 --> 00:27:47.120
And I'm going into more details about
the semaphore in a couple of slides.

00:27:47.170 --> 00:27:50.820
The API I'm going to use, mpjobsubmit,
is actually the one that is in the sample

00:27:50.840 --> 00:27:53.970
code that I'm going to give you guys,
that enables me to just

00:27:53.970 --> 00:27:55.660
actually submit a job.

00:27:55.660 --> 00:27:57.490
And here in this case,
what it takes is actually a

00:27:57.510 --> 00:28:01.270
proc pointer on my routine,
which is a CalculMondel.thread proc.

00:28:01.320 --> 00:28:04.080
And the two parameters you see after,
remember,

00:28:04.100 --> 00:28:06.520
are actually a pointer on the data.

00:28:06.520 --> 00:28:08.200
Don't make the same
mistake that what I did,

00:28:08.200 --> 00:28:10.750
which is I created a pointer.

00:28:10.790 --> 00:28:15.070
So first, remember,
each of the threaded routines

00:28:15.390 --> 00:28:17.400
has its own register and stack.

00:28:17.450 --> 00:28:20.840
So that means that you want
to pass a pointer on memory.

00:28:20.850 --> 00:28:23.390
Because once you've got in there,
you want to make sure that

00:28:23.390 --> 00:28:25.540
that memory is unique.

00:28:25.620 --> 00:28:28.700
So the error I did the
first time was that,

00:28:28.700 --> 00:28:28.700
you know,

00:28:28.940 --> 00:28:30.520
I get, like, you know,
create a new pointer.

00:28:30.780 --> 00:28:33.900
I set my data inside, so I say, like,
start of the loop at zero and end at,

00:28:33.900 --> 00:28:35.710
like, you know, half of a picture.

00:28:35.830 --> 00:28:36.790
Then I spawn my thread.

00:28:37.090 --> 00:28:40.070
Then I use the same pointer, and I,
you know, just modified, like, you know,

00:28:40.070 --> 00:28:41.240
the parameters inside.

00:28:41.240 --> 00:28:42.960
I said, you know,
start from half of a picture.

00:28:42.960 --> 00:28:45.480
But the fact of the matter,
when I was doing that,

00:28:45.480 --> 00:28:49.620
I was modifying memory that was actually
being executed in another thread because

00:28:49.620 --> 00:28:51.360
I passed that to my first thread.

00:28:51.480 --> 00:28:52.860
So don't make that mistake.

00:28:52.860 --> 00:28:55.740
Here, in this case,
I create two pointers, P and P2,

00:28:55.740 --> 00:28:57.900
that have been typecasted
to a void point,

00:28:57.900 --> 00:28:58.590
to a void star.

00:28:58.660 --> 00:29:00.590
And then after that,
you have to understand

00:29:00.600 --> 00:29:03.560
that the MPJobsSubmit,
you submit the job, it doesn't wait until

00:29:03.560 --> 00:29:04.640
the job is finished,
OK?

00:29:04.750 --> 00:29:07.420
That's the main idea of threading,
actually, that part of the routine.

00:29:07.420 --> 00:29:08.570
So it comes back.

00:29:08.640 --> 00:29:11.130
And then I spawn in the second thread,
it comes back,

00:29:11.140 --> 00:29:12.530
it doesn't wait for it to be finished.

00:29:12.560 --> 00:29:14.000
And then we wait for completion.

00:29:14.080 --> 00:29:16.760
And this is actually the
routine that's going to block.

00:29:16.780 --> 00:29:19.300
That routine is going to stay
and wait for me to be finished.

00:29:19.300 --> 00:29:20.670
OK?

00:29:22.120 --> 00:29:27.760
So the semaphore is this opaque object
that's going to enable us to actually

00:29:27.760 --> 00:29:31.780
be notified when the thread is finished.

00:29:31.810 --> 00:29:34.690
I had this first version of a
slide that used a semaphore.

00:29:34.700 --> 00:29:37.880
Semaphore in French is like
the lights with a state.

00:29:37.930 --> 00:29:38.340
Bad idea.

00:29:38.340 --> 00:29:41.430
Think of it as like a little
box with state changes.

00:29:41.430 --> 00:29:42.600
So like maybe a state table.

00:29:42.620 --> 00:29:43.880
Think of it as a state table.

00:29:43.880 --> 00:29:45.870
And this is what we're going to use.

00:29:45.870 --> 00:29:48.580
We're going to use that
object to actually find out

00:29:48.580 --> 00:29:50.190
when the threads are done.

00:29:50.380 --> 00:29:53.370
So here in this case,
we're going to call MPCreateSemaphore,

00:29:53.370 --> 00:29:55.380
which is in multiprocessing.h.

00:29:55.380 --> 00:29:59.640
The first two parameters are the
maximum state and the initial value.

00:29:59.640 --> 00:30:01.500
And here in this case,
the max state is going to be two.

00:30:01.500 --> 00:30:02.710
It's going to correspond to two threads.

00:30:02.740 --> 00:30:04.290
And the initial state
is going to be zero.

00:30:04.290 --> 00:30:05.260
I want to start at zero.

00:30:05.260 --> 00:30:10.480
And it sends me back actually
a pointer on my data.

00:30:10.480 --> 00:30:13.240
And here what happens is
that that data is global.

00:30:13.240 --> 00:30:16.100
Because what happens,
I want it as a global because

00:30:16.100 --> 00:30:19.500
I want it to be able to access
from the different threads.

00:30:19.500 --> 00:30:19.800
Okay.

00:30:19.800 --> 00:30:20.360
So the main thread is going
to be the main thread.

00:30:20.380 --> 00:30:21.510
And the spawn thread.

00:30:21.520 --> 00:30:22.520
Okay.

00:30:22.520 --> 00:30:24.670
Remember, because all these threads,
they're actually in

00:30:24.670 --> 00:30:26.020
the same memory space.

00:30:26.020 --> 00:30:26.440
Okay.

00:30:26.440 --> 00:30:27.450
So I can do that.

00:30:29.670 --> 00:30:32.100
So now, remember,
we have actually the threaded proc.

00:30:32.100 --> 00:30:33.140
How do we notify?

00:30:33.140 --> 00:30:35.560
How do we signal that actually, like,
you know, you're done?

00:30:35.580 --> 00:30:37.420
How do you change the
state in the semaphore?

00:30:37.420 --> 00:30:38.200
Well, very easy.

00:30:38.200 --> 00:30:41.310
MP signal semaphore,
which is available as well in, like,

00:30:41.310 --> 00:30:42.780
multiprocessing.h.

00:30:42.780 --> 00:30:45.090
And you just pass, actually,
your global semaphore.

00:30:50.100 --> 00:30:51.960
So, waiting on the semaphore.

00:30:51.990 --> 00:30:54.040
That's what I call the waiting game.

00:30:54.050 --> 00:30:57.160
You have two ways to
wait on the semaphore.

00:30:57.340 --> 00:30:59.540
mpwait on semaphore is the
API you're going to be using if

00:30:59.540 --> 00:31:02.060
you want to sit tight and wait
until you're being notified.

00:31:02.060 --> 00:31:06.190
If you pass k duration forever,
what happens is that

00:31:06.190 --> 00:31:09.180
you're going to wait,
that code is going to block

00:31:09.260 --> 00:31:13.030
until somebody changes the
state in the semaphore.

00:31:13.040 --> 00:31:15.230
So here is what happens.

00:31:15.320 --> 00:31:17.640
You remember,
we spawned the thread number one,

00:31:17.760 --> 00:31:20.360
we spawned the thread number two,
and we call this API,

00:31:20.360 --> 00:31:21.650
mpwait on semaphore.

00:31:21.660 --> 00:31:24.510
So we're waiting there because
we passed k duration forever.

00:31:25.650 --> 00:31:29.120
When the signal is done in the thread,
what happens is that the

00:31:29.120 --> 00:31:30.860
semaphore state changes.

00:31:30.880 --> 00:31:31.690
It goes to one.

00:31:31.740 --> 00:31:35.060
Then that API comes back because
the state has been changed

00:31:35.060 --> 00:31:36.680
and puts it back to zero.

00:31:36.680 --> 00:31:38.170
And I'm going to show you
that in the next lecture,

00:31:38.170 --> 00:31:38.820
which is better.

00:31:38.820 --> 00:31:41.830
The k duration immediate changes
the state in the semaphore

00:31:41.950 --> 00:31:43.360
as soon as you call the API.

00:31:43.360 --> 00:31:44.050
It doesn't block.

00:31:44.060 --> 00:31:47.770
So for instance, if the state was at two,
and you would call mpwait on

00:31:47.770 --> 00:31:51.820
semaphore with k duration immediate,
it would actually subtract the state,

00:31:51.820 --> 00:31:53.720
so it would go back to
one and then to zero,

00:31:53.720 --> 00:31:55.220
if you were to call it twice.

00:31:57.170 --> 00:31:59.710
So now, let's look at our next graphic
again and let's see what's

00:31:59.720 --> 00:32:01.260
going on in the threaded case.

00:32:01.260 --> 00:32:02.610
We're in the main thread.

00:32:02.700 --> 00:32:11.490
We've been past the buffer
when CalculMondell brought.

00:32:11.490 --> 00:32:11.490
We create the semaphore, two states,
initial state zero.

00:32:11.690 --> 00:32:15.820
OK, what's going to happen after that is
that I'm going to spawn thread number 1.

00:32:15.820 --> 00:32:18.810
And here, the MP weight on semaphore
should be after my mistake,

00:32:18.810 --> 00:32:22.440
but I'm going to spawn thread
number 1 and thread number 2,

00:32:22.440 --> 00:32:23.660
as we did before.

00:32:23.710 --> 00:32:26.400
So now, what's going on in that point?

00:32:26.410 --> 00:32:29.670
At that point, we have thread number 1
doing some computation.

00:32:29.700 --> 00:32:33.400
Thread number 2 doing some computation
on the other half of a picture.

00:32:33.440 --> 00:32:37.560
And the main thread is blocked
on MP weight on semaphore.

00:32:37.580 --> 00:32:37.980
Which is good.

00:32:38.100 --> 00:32:38.840
That's what we want.

00:32:38.840 --> 00:32:40.720
We don't want to re-architecture,
so that's good.

00:32:41.030 --> 00:32:42.880
Now, what happens?

00:32:42.900 --> 00:32:44.370
Boom, MP signal semaphore.

00:32:44.540 --> 00:32:45.500
We're done.

00:32:45.500 --> 00:32:47.230
We computed half of a picture.

00:32:47.440 --> 00:32:48.000
We're finished.

00:32:48.060 --> 00:32:49.490
We say, hey, you know what?

00:32:49.640 --> 00:32:50.440
We're done computing.

00:32:50.440 --> 00:32:51.880
Do whatever you want now.

00:32:51.930 --> 00:32:53.100
My part is done.

00:32:53.100 --> 00:32:54.620
The thread is finished.

00:32:54.650 --> 00:32:58.180
What happens is that that's
going to actually increment the

00:32:58.180 --> 00:33:01.760
state in MP weight on semaphore.

00:33:01.760 --> 00:33:03.880
I'm sorry, that's going to increment
the state in the semaphore.

00:33:03.880 --> 00:33:05.830
So from 0, we come to 1.

00:33:05.940 --> 00:33:07.740
MP signal semaphore is done.

00:33:07.740 --> 00:33:09.020
Our whole thread is finished.

00:33:09.120 --> 00:33:09.540
It's done.

00:33:09.710 --> 00:33:10.400
That routine.

00:33:10.460 --> 00:33:12.270
We're not there anymore.

00:33:12.530 --> 00:33:15.750
But then what happens, the state changes,
so in our main thread,

00:33:15.860 --> 00:33:19.350
mp-weight on semaphor changes
and comes back and doesn't block.

00:33:19.350 --> 00:33:25.390
And in doing so,
we put the state of the semaphor to zero.

00:33:25.660 --> 00:33:28.500
then after that and you know in this
case I said you know thread number one

00:33:28.500 --> 00:33:33.480
finishes but it doesn't really matter
okay semaphores are reentrant so if both

00:33:33.480 --> 00:33:36.660
finish at the same time the MP library
knows what to do so don't worry about

00:33:36.660 --> 00:33:40.310
that so now let's say and you know it
doesn't matter to effect thread number

00:33:40.350 --> 00:33:44.260
two finishes before one we don't really
care so now let's say that MP semaphore

00:33:44.260 --> 00:33:48.410
thread number two is done you know we're
done with our loop then we call MP signal

00:33:48.410 --> 00:33:52.820
semaphore in that in that routine what
happens here is that that increments

00:33:52.820 --> 00:33:57.140
actually the count on the semaphore
we're back to one oh the semaphore

00:33:57.220 --> 00:34:01.080
state has changed then what happens
well MP when on semaphore the second one

00:34:01.080 --> 00:34:05.780
we hide comes back the state goes back
to zero that means that actually like

00:34:05.850 --> 00:34:09.830
the CalculModelBroad is done so we know
we don't block when we're blocking that

00:34:10.140 --> 00:34:13.980
routine we go back to the main event loop
and we display the result so remember

00:34:13.980 --> 00:34:17.840
that everything below or like you know
at the same level CalculModelBroad

00:34:17.840 --> 00:34:21.640
has not been changed our main event loop
the rest of our application we didn't

00:34:21.640 --> 00:34:25.330
have to do anything That make sense?

00:34:25.810 --> 00:34:26.960
Good.

00:34:26.960 --> 00:34:29.840
OK, now let me show you a demo of that.

00:34:29.840 --> 00:34:32.760
If we could switch to
the demo number one,

00:34:32.760 --> 00:34:33.640
please.

00:34:33.640 --> 00:34:35.280
OK, great.

00:34:35.770 --> 00:34:37.380
First thing first,
I wanted to mention that

00:34:37.380 --> 00:34:39.920
actually Richard Kurtz,
who is one of our longtime

00:34:39.920 --> 00:34:42.340
developers on our computer,
sent me that code.

00:34:42.340 --> 00:34:45.780
And thank you, Richard, for that.

00:34:45.820 --> 00:34:48.180
We were working on some things,
and he sent me that code.

00:34:48.180 --> 00:34:50.340
And then I decided, hmm,
wouldn't it be good to use that

00:34:50.340 --> 00:34:51.510
as an example for threading?

00:34:51.530 --> 00:34:53.620
And so then what I did is
that I thread the application.

00:34:53.660 --> 00:34:55.540
So thank you, Richard.

00:34:55.550 --> 00:34:57.180
There we go.

00:34:57.250 --> 00:35:01.890
So here what we have is just
a basic manager board space.

00:35:02.830 --> 00:35:20.420
If you do some research,
what happens is that you should

00:35:20.420 --> 00:35:20.420
know that before doing anything,
you should put some kind of

00:35:20.420 --> 00:35:20.420
benchmarking if you want to
do some work on performance.

00:35:20.420 --> 00:35:20.420
Here in this case,
what I do is that I have a benchmark.

00:35:20.420 --> 00:35:20.420
Let me move that a little bit.

00:35:20.420 --> 00:35:20.420
Everybody can see?

00:35:21.260 --> 00:35:24.860
Here I put a benchmark and so
here it's a pretty easy space.

00:35:24.870 --> 00:35:27.320
You know, you have to understand that
the difficult part to compute

00:35:27.340 --> 00:35:29.730
is actually the part in black,
okay?

00:35:29.820 --> 00:35:31.420
So here what happens
that I have a flight,

00:35:31.420 --> 00:35:33.760
so I compute, I think that picture,
I compute the picture

00:35:33.790 --> 00:35:35.760
like something like,
you know, 10 or 20 times,

00:35:35.760 --> 00:35:38.920
I don't remember exactly, but whoa,
what happened here?

00:35:40.050 --> 00:35:41.400
- We crashed or we disappeared?

00:35:41.400 --> 00:35:43.830
- Oh, that's a good demo.

00:35:43.840 --> 00:35:45.620
No, it's here, I'm sorry.

00:35:45.790 --> 00:35:46.580
I don't know.

00:35:46.630 --> 00:35:47.500
Maybe I clicked too fast.

00:35:47.500 --> 00:35:50.810
Let me remove the dock.

00:35:52.180 --> 00:35:54.370
OK, so what happens here is that
I estimated a benchmark,

00:35:54.440 --> 00:35:58.130
actually Richard wrote that code,
and it just tells us how

00:35:58.130 --> 00:35:59.000
long it is to compute.

00:35:59.000 --> 00:36:02.280
And here,
you can see that it took like 0.95

00:36:02.280 --> 00:36:04.140
seconds to compute that space.

00:36:04.140 --> 00:36:07.060
Once again,
important to understand that the black

00:36:07.060 --> 00:36:08.380
part is the difficult part to compute.

00:36:08.380 --> 00:36:11.300
So obviously here, there's nothing very
difficult to compute.

00:36:11.330 --> 00:36:13.620
What I wanted to show you, too,
is one of the tools that

00:36:13.620 --> 00:36:17.620
ships with our system,
which is called ThreadViewer.

00:36:17.860 --> 00:36:18.860
You guys know about ThreadViewer?

00:36:18.860 --> 00:36:20.640
Raise your hand if you know.

00:36:20.640 --> 00:36:21.770
OK, good, pretty good.

00:36:21.840 --> 00:36:24.480
Seems like all of you know
about threading already.

00:36:24.980 --> 00:36:28.390
And here you can see that what I did is
that I initialized at the beginning the

00:36:28.390 --> 00:36:30.900
MP libraries with like three processors.

00:36:31.030 --> 00:36:32.890
But for Kicks,
I actually have this routine

00:36:32.890 --> 00:36:35.430
that enables you to create like
more threads if you wanted,

00:36:35.430 --> 00:36:36.610
but I'll show you that.

00:36:36.690 --> 00:36:43.760
So what happens here is that we can
see actually the work that is going on.

00:36:43.880 --> 00:36:46.650
I'm going to go to
like maybe a difficult,

00:36:46.650 --> 00:36:46.650
more difficult part,
and I have a cheat sheet

00:36:46.650 --> 00:36:46.650
to make things faster.

00:36:47.700 --> 00:36:50.200
So here we're gonna try to find, like,
we're gonna try to fill

00:36:50.200 --> 00:36:52.250
the screen with more black,
so like, you know,

00:36:52.250 --> 00:36:53.550
we really use the CPU power.

00:36:53.600 --> 00:36:56.600
Computing the white part is like
pretty straightforward and easy.

00:36:56.600 --> 00:37:05.900
It would just take a second.

00:37:15.340 --> 00:37:17.340
Okay, I think it's good enough.

00:37:17.340 --> 00:37:19.050
Let's not worry too much about it.

00:37:19.060 --> 00:37:21.970
Okay, good.

00:37:22.460 --> 00:37:25.580
So we're here,
let me remove like Veltevec.

00:37:25.730 --> 00:37:28.840
And so here I'm gonna benchmark it
and I want to show you that here,

00:37:28.840 --> 00:37:31.020
we're using only one
thread in the bottom,

00:37:31.020 --> 00:37:31.500
okay?

00:37:31.510 --> 00:37:33.240
You can see here,
actually the green is like, you know,

00:37:33.240 --> 00:37:35.700
when user space and so
we're computing here,

00:37:35.740 --> 00:37:39.130
which is kind of sad because that's a
typical example where actually you want

00:37:39.130 --> 00:37:41.890
to use threads for that type of like,
you know, computing.

00:37:41.900 --> 00:37:43.400
Obviously it makes a lot of sense.

00:37:43.450 --> 00:37:46.740
So here you can see that, you know,
to doing my benchmarking takes quite

00:37:46.780 --> 00:37:49.020
some time and that's a dual G5.

00:37:49.070 --> 00:37:51.080
And I have something like, you know,
something like two gigs of RAM.

00:37:51.080 --> 00:37:55.570
So obviously you guys don't sell
software that compute model broad space,

00:37:55.570 --> 00:37:59.710
or maybe not that close,
but I think you can like, you know,

00:37:59.830 --> 00:38:02.870
probably relate to like some part of
your code that you could use that in.

00:38:02.960 --> 00:38:03.750
So here we're done.

00:38:03.760 --> 00:38:05.540
You can see I run with the
thread and it took like,

00:38:05.600 --> 00:38:07.460
you know, 6.31 seconds.

00:38:07.460 --> 00:38:11.680
And, you know, I have a min and max,
like, you know, computed.

00:38:11.800 --> 00:38:15.450
What we're going to do is that, you know,
I'm just going to use the threading,

00:38:15.450 --> 00:38:17.710
and I'm going to do the benchmark again.

00:38:17.840 --> 00:38:18.960
I'll show you the code after that.

00:38:19.020 --> 00:38:23.010
But what you can see here is that
now both CPUs are being utilized.

00:38:23.320 --> 00:38:25.620
The white space you can see
between the threads is because

00:38:25.620 --> 00:38:27.820
the fact of the matter,
what happens is that--

00:38:27.820 --> 00:38:30.520
I'm doing a flight,
so what happens is that the picture

00:38:30.610 --> 00:38:33.020
takes a certain number of seconds,
but I do that processing

00:38:33.020 --> 00:38:35.080
something like 20 or 50 times.

00:38:35.130 --> 00:38:38.560
So that's why we go back to the main
event loop because the threads are gone,

00:38:38.560 --> 00:38:40.360
so you see one thread at one point.

00:38:40.380 --> 00:38:42.250
And here you see four seconds.

00:38:42.310 --> 00:38:45.420
So we went from what is it,
like 8 point something to four.

00:38:45.620 --> 00:38:48.830
So we get almost twice speed improvement.

00:38:49.080 --> 00:38:52.990
I did some testing before which
was actually rather interesting.

00:38:55.010 --> 00:38:59.360
but between the FP results,
I got an average,

00:38:59.430 --> 00:39:02.170
depending on how difficult
things like 1.7 times faster

00:39:02.170 --> 00:39:04.150
between the different results.

00:39:04.230 --> 00:39:07.750
The cool thing too is that if you
then on top of that put Altivec,

00:39:07.760 --> 00:39:11.670
you get some dramatic performance
because then you use both Altivec units,

00:39:11.860 --> 00:39:15.740
128 bit computing per cycle,
and you get to something that gets very,

00:39:15.740 --> 00:39:16.360
very cool.

00:39:16.360 --> 00:39:19.260
So here in this case, you know,
depending with like what you're

00:39:19.260 --> 00:39:22.410
doing with Altivec on the threaded,
I get to like something like like 1.8,

00:39:22.470 --> 00:39:26.000
1.9 times faster depending on the space.

00:39:28.370 --> 00:39:31.680
So I can show you that, you know,
now if I do the benchmarking, you know,

00:39:31.680 --> 00:39:33.640
we're at eight or nine seconds.

00:39:33.640 --> 00:39:36.150
And now if I do altivec
plus the threading,

00:39:36.160 --> 00:39:38.600
we get a huge speed improvement here.

00:39:39.420 --> 00:39:44.400
: So we got like six times faster
between the threading and the altivec.

00:39:44.450 --> 00:39:45.840
Okay, so that's a cool demo.

00:39:45.880 --> 00:39:48.400
What I want to show you
is that it's always hard,

00:39:48.400 --> 00:39:51.400
and I got the question which is like,
"Well, so how many slides?

00:39:51.400 --> 00:39:53.550
How do you slice your picture?" I mean,
you have two CPUs,

00:39:53.550 --> 00:39:55.910
but what happens if you,
let's say I'm going to have four

00:39:55.910 --> 00:39:59.400
slides and I want four threads,
and I have only two CPUs.

00:39:59.400 --> 00:40:01.950
And I was thinking, "Well, that's true,
so what's the overhead?" And this is

00:40:01.950 --> 00:40:07.300
where you see that actually Mac OS X is
truly great at multitasking because I'm

00:40:07.410 --> 00:40:11.400
going to put four threads and four jobs,
and I'm going to move altivec

00:40:11.400 --> 00:40:14.400
because it goes way too fast,
well actually it doesn't matter.

00:40:14.650 --> 00:40:17.860
But if I benchmark here,
and here you can see that

00:40:17.860 --> 00:40:20.100
I have four threads going on,
okay.

00:40:20.610 --> 00:40:22.500
you're going to see that
there is not so much overhead.

00:40:22.560 --> 00:40:25.610
And in certain cases,
actually depending on the memory usage,

00:40:25.760 --> 00:40:27.740
you get actually some
pretty good results.

00:40:27.860 --> 00:40:31.310
So it's very interesting because
what I'm getting to is that you

00:40:31.310 --> 00:40:35.430
could ship code that is threaded,
OK, and let's say you're going

00:40:35.430 --> 00:40:37.860
to decide on two threads,
and you divide your picture

00:40:37.860 --> 00:40:40.100
or whatever you're doing,
you're processing in two threads,

00:40:40.100 --> 00:40:42.760
and then you go back and if you
run it actually on your powerbook,

00:40:42.760 --> 00:40:45.230
you'll see that there is not
so much of a big overhead.

00:40:45.260 --> 00:40:47.210
In certain cases,
it's probably going to be the same speed,

00:40:47.210 --> 00:40:49.970
depending on what are the processes
that are running on the system,

00:40:49.980 --> 00:40:50.680
of course.

00:40:50.760 --> 00:40:52.310
So this is very important to understand.

00:40:52.390 --> 00:40:55.050
Truly great multitasking system.

00:40:56.680 --> 00:40:57.860
OK, I showed you that.

00:40:57.980 --> 00:41:00.220
Let me show you the code quickly.

00:41:00.490 --> 00:41:02.850
This is the library I told you about.

00:41:02.920 --> 00:41:05.640
And these are the two files I'm
going to be actually posting for you

00:41:05.710 --> 00:41:07.980
and I'll tell you during the Q&A.

00:41:08.070 --> 00:41:09.650
I don't want to take
too much time right now.

00:41:09.740 --> 00:41:11.440
But here we have a couple of wrappers.

00:41:11.440 --> 00:41:13.390
And here you have the MP jobs in it.

00:41:13.440 --> 00:41:16.070
So what we do, just as I showed you,
what you're going to create is the

00:41:16.140 --> 00:41:17.700
number of processors that are scheduled.

00:41:17.820 --> 00:41:19.470
OK, it's going to be one or two.

00:41:19.560 --> 00:41:21.780
And then after that, we create the queue.

00:41:21.790 --> 00:41:23.160
This is actually a global variable.

00:41:23.160 --> 00:41:24.840
And this is where, actually,
you're going to submit

00:41:24.840 --> 00:41:28.480
your code for execution.

00:41:28.550 --> 00:41:36.270
And then I just like this basic loop that
actually creates a task per processor.

00:41:38.670 --> 00:41:41.690
Okay,
now let me go back to the compute code.

00:41:41.790 --> 00:41:44.930
This is the fractal, so we get in here.

00:41:46.190 --> 00:41:46.970
Is that large enough?

00:41:47.050 --> 00:41:47.950
Everybody can see in the back?

00:41:48.110 --> 00:41:48.940
We're good?

00:41:49.020 --> 00:41:50.100
Is that clear?

00:41:50.100 --> 00:41:51.060
Hello?

00:41:51.350 --> 00:41:51.800
Yeah?

00:41:51.800 --> 00:41:52.260
Everybody can see?

00:41:52.260 --> 00:41:53.300
Okay, good.

00:41:53.300 --> 00:41:54.290
Thank you.

00:41:54.690 --> 00:41:56.190
So here I just have a
global that I checked,

00:41:56.290 --> 00:41:58.570
you know, it's because for the demo
purposes I check if we're

00:41:58.570 --> 00:41:59.850
in the threaded case or not.

00:41:59.900 --> 00:42:02.700
And here I have actually something
that computes the number of jobs,

00:42:02.770 --> 00:42:06.220
and that's another global that I use
that is set actually through the menus.

00:42:06.220 --> 00:42:10.830
As I told you,
I create a pointer for each of

00:42:10.890 --> 00:42:14.150
the data structures I want to
pass to each of the threads.

00:42:14.160 --> 00:42:16.570
Then I have a loop that submits the jobs.

00:42:16.640 --> 00:42:21.180
And this is very cool because seriously,
with the MP wrapper APIs that I had,

00:42:21.210 --> 00:42:23.660
it took me a couple of
hours to implement that.

00:42:24.600 --> 00:42:29.160
We had a Cocoa guy actually that was
here that has a software that does

00:42:29.220 --> 00:42:31.680
compression for extending to a phone.

00:42:31.680 --> 00:42:32.770
I mean, it's pretty cool, good stuff.

00:42:32.970 --> 00:42:35.250
He has a wavelet compression algorithm.

00:42:35.280 --> 00:42:39.990
In less than four hours,
we actually changed his code

00:42:39.990 --> 00:42:42.870
to use that type of threading.

00:42:42.880 --> 00:42:46.690
And it took us actually like three hours,
but that's because I was coding.

00:42:49.760 --> 00:42:52.600
I mean, somebody else will do
it probably way faster.

00:42:52.630 --> 00:42:59.170
But here, the cool thing is that you can
see I'm using MPJobsSummit,

00:42:59.300 --> 00:43:05.650
which is an API that is part of the
code I'm going to give you guys.

00:43:05.650 --> 00:43:07.170
And I just passed, actually,
my routine and some pointers.

00:43:07.170 --> 00:43:07.170
And here, you see the job data,
which is the stuff I have.

00:43:07.170 --> 00:43:07.170
Let me show you.

00:43:10.010 --> 00:43:12.850
I don't know why certain comments
seem to be hiding things.

00:43:12.940 --> 00:43:14.420
Oh, I'm sorry.

00:43:14.430 --> 00:43:18.510
Okay, let me open the project again.

00:43:18.510 --> 00:43:18.510
Great.

00:43:18.510 --> 00:43:18.510
Awesome.

00:43:20.650 --> 00:43:25.000
I'm going to go back here,
and I want to show you the submit code.

00:43:25.000 --> 00:43:26.160
I want to show you here.

00:43:29.700 --> 00:43:30.530
It doesn't see it.

00:43:30.540 --> 00:43:33.440
It seems like... Okay, so we're here.

00:43:33.540 --> 00:43:36.610
So what happens, this is actually,
remember the routine that's

00:43:36.610 --> 00:43:38.430
gonna be called by each thread.

00:43:38.440 --> 00:43:43.060
Okay, remember, ExecutionCodePath,
that's gonna be done independently.

00:43:43.070 --> 00:43:44.600
So this is actually
what's gonna be called.

00:43:44.600 --> 00:43:46.720
I just passed actually the
address of that routine.

00:43:46.750 --> 00:43:47.560
Very cool.

00:43:47.600 --> 00:43:50.820
First thing I do is that
I repurpose actually the data.

00:43:50.820 --> 00:43:53.160
Obviously,
you could pass the fractal data,

00:43:53.160 --> 00:43:58.300
which is a structure I created,
but because I wanted to use the MP.C,

00:43:58.300 --> 00:44:04.140
MPJobs.C code in other programs,
I decided to use void star as a way

00:44:04.140 --> 00:44:06.540
of not depending of a data type.

00:44:06.540 --> 00:44:07.370
This is actually cool.

00:44:07.380 --> 00:44:09.540
I mean, once you see the code,
it's pretty cool.

00:44:09.610 --> 00:44:10.940
So I repurpose all the data.

00:44:11.100 --> 00:44:12.160
Okay, we're good.

00:44:12.160 --> 00:44:14.440
I recompute actually
the delta for the start,

00:44:14.560 --> 00:44:15.200
remember?

00:44:15.200 --> 00:44:18.690
I have to adjust that routine
of the algorithms from the start

00:44:18.690 --> 00:44:21.020
to the end of a computation.

00:44:22.110 --> 00:44:24.640
And here, don't worry about that,
I should have removed that,

00:44:24.740 --> 00:44:26.950
but the main thing is that we're here,
I do the loop.

00:44:27.000 --> 00:44:28.200
Why is it fast?

00:44:28.250 --> 00:44:30.750
Well, because, you know,
what happens is that think of it

00:44:30.760 --> 00:44:32.270
as like two different code paths.

00:44:32.270 --> 00:44:35.280
One is going to start and do
like the first part of a picture,

00:44:35.280 --> 00:44:38.320
and the second one, the second part,
and I change that in the

00:44:38.340 --> 00:44:39.780
beginning and end of sets.

00:44:39.780 --> 00:44:42.300
And we do the computation
in floating point here,

00:44:42.300 --> 00:44:45.130
and with a velocity engine here,
and then when I'm done,

00:44:45.240 --> 00:44:47.480
I signal the semaphor,
remember what I showed

00:44:47.530 --> 00:44:48.830
you like in the program.

00:44:49.000 --> 00:44:49.200
Okay?

00:44:49.320 --> 00:44:51.960
If you could switch back to the slides,
please.

00:44:57.850 --> 00:44:59.030
OK, some recommendations.

00:44:59.100 --> 00:45:06.360
So the MP init, the stuff I showed you,
when you initialize the MP library and

00:45:06.360 --> 00:45:09.220
count the number of jobs and submit,
create the task,

00:45:09.290 --> 00:45:12.670
don't do that for each time that
somebody requests to do an action

00:45:12.670 --> 00:45:14.520
that's going to code your threaded code.

00:45:14.550 --> 00:45:17.720
Do that in your main when
you start the program.

00:45:17.970 --> 00:45:21.560
And then when your program quits,
just clean after yourself.

00:45:21.560 --> 00:45:23.370
Don't recreate and reuse.

00:45:23.400 --> 00:45:25.990
In this case,
I do that because I wanted to have

00:45:25.990 --> 00:45:29.970
an example where I use eight threads,
for instance, and show you the results

00:45:29.970 --> 00:45:31.240
with only two CPUs.

00:45:31.300 --> 00:45:36.190
But in a typical case,
you would not want to have this overhead.

00:45:37.160 --> 00:45:39.550
So do be data driven,
and what I mean by that

00:45:39.620 --> 00:45:42.470
is that think of it as

00:45:42.940 --> 00:45:46.400
Do your setup, your memory management,
create your arrays,

00:45:46.470 --> 00:45:51.360
and then your threads should be actually
the routines that do the real work.

00:45:51.420 --> 00:45:55.080
You don't want to start to be in a thread
and wait for a Carbon event somewhere

00:45:55.080 --> 00:45:56.890
or be notified by another thread.

00:45:57.000 --> 00:46:00.620
You want to use really the threads
for doing the data crunching.

00:46:00.880 --> 00:46:03.230
You don't want to sit in there because
then what's the point of having a

00:46:03.230 --> 00:46:06.600
thread if you're waiting for something
to happen from another thread?

00:46:06.600 --> 00:46:10.160
And that could be a case,
but the main idea is you want

00:46:10.160 --> 00:46:12.550
to use the bandwidth of the G5s.

00:46:12.680 --> 00:46:15.270
You want to have the threads
do the data crunching.

00:46:15.300 --> 00:46:18.470
So before you spawn the threads,
set up all your arrays,

00:46:18.470 --> 00:46:21.050
set up the memory,
and all the things you need to do to

00:46:21.050 --> 00:46:22.820
make the data crunching effective.

00:46:22.820 --> 00:46:25.340
And then when you come back,
we'll do the closing,

00:46:25.340 --> 00:46:27.880
or before the thread dies,
do the cleaning.

00:46:27.880 --> 00:46:30.180
you know,
clean the memory that you have allocated

00:46:30.180 --> 00:46:32.470
from a thread and that kind of thing.

00:46:34.290 --> 00:46:35.360
Okay, so let's go back.

00:46:35.490 --> 00:46:38.200
What happens in the threaded case?

00:46:38.200 --> 00:46:42.390
You're going to love that slide.

00:46:42.750 --> 00:46:46.700
Remember, we create the semaphor.

00:46:46.700 --> 00:46:48.140
OK, initial state 0.

00:46:48.140 --> 00:46:48.900
That's good.

00:46:48.910 --> 00:46:50.400
We spawn the two threads.

00:46:50.400 --> 00:46:53.140
OK, thread number 1, thread number 2,
and then what?

00:46:53.160 --> 00:46:55.580
Well, we wait on the semaphor,
but what happens here?

00:46:55.620 --> 00:46:57.200
We're blocked.

00:46:57.210 --> 00:46:59.040
OK, as I told you before, that's fine.

00:46:59.130 --> 00:47:03.290
Our initial goal was to
really get the data crunching.

00:47:03.300 --> 00:47:05.950
We wanted to do that
operation as fast as we could.

00:47:05.990 --> 00:47:08.580
And we didn't want to re-architecture
the whole application.

00:47:08.610 --> 00:47:11.220
So let's say now, step number 2,
you ship your application

00:47:11.470 --> 00:47:12.400
with a step number 1.

00:47:12.400 --> 00:47:13.480
That's the first step.

00:47:13.480 --> 00:47:14.860
OK, that's cool.

00:47:14.860 --> 00:47:17.000
Your customers are very
happy because some operations

00:47:17.000 --> 00:47:19.700
are up to two times faster.

00:47:19.730 --> 00:47:20.120
That's cool.

00:47:20.120 --> 00:47:21.040
Everybody's happy.

00:47:21.180 --> 00:47:23.220
But now,
let's make the whole experience better.

00:47:23.220 --> 00:47:25.340
Let's try to actually thread
the whole application.

00:47:25.400 --> 00:47:27.940
What should we do in this typical case?

00:47:27.970 --> 00:47:29.220
Well, that's going to be the easy one.

00:47:29.240 --> 00:47:33.400
But what we're going to do is that
we're going to create a semaphor.

00:47:33.410 --> 00:47:34.880
We're in CalculMonded mode.

00:47:34.940 --> 00:47:35.770
That's good.

00:47:36.060 --> 00:47:39.460
We're going to spawn the
thread that does the waiting.

00:47:40.020 --> 00:47:42.200
Remember like, you know,
before that routine,

00:47:42.200 --> 00:47:44.880
I had something that was
doing the wait with the two

00:47:44.880 --> 00:47:46.120
calls to wait for completion.

00:47:46.120 --> 00:47:47.860
What I'm going to do
now is that that code,

00:47:47.920 --> 00:47:49.840
I'm going to put it in a
routine and I'm going to spawn

00:47:50.060 --> 00:47:52.360
that routine as being like,
you know, one thread.

00:47:52.410 --> 00:47:55.830
So what that thread does is that,
you know, it sits down right now.

00:47:55.840 --> 00:47:56.760
It's like just waiting.

00:47:56.760 --> 00:47:59.360
Then what we're going to do is that we're
going to spawn the other two threads,

00:47:59.360 --> 00:48:01.020
thread number two and
thread number three.

00:48:01.020 --> 00:48:03.400
And then when we do that, what happens?

00:48:03.500 --> 00:48:05.250
Well, we go back to the main event loop.

00:48:05.620 --> 00:48:09.370
So now careful because that means the
user could actually go back and say,

00:48:09.400 --> 00:48:12.880
hey, benchmark again,
and the threads could still be running.

00:48:12.880 --> 00:48:14.560
So remember,
we go back to the first part of

00:48:14.560 --> 00:48:17.500
the presentation where I said,
hey, guys, you have to be careful.

00:48:17.500 --> 00:48:18.880
If you want to thread
the whole application,

00:48:18.880 --> 00:48:20.560
you're going to have to
do some thread management.

00:48:20.560 --> 00:48:22.080
It's possible, okay?

00:48:22.080 --> 00:48:24.470
It's just I want you guys to
understand that there are different

00:48:24.470 --> 00:48:27.440
steps and different ways where you
can plug and thread your application.

00:48:27.440 --> 00:48:29.690
So let's say we did that work.

00:48:29.780 --> 00:48:30.830
Well, very cool.

00:48:30.840 --> 00:48:32.480
And what happens when it works?

00:48:32.480 --> 00:48:33.960
Well, we're going to signal.

00:48:35.420 --> 00:48:39.820
Remember, the signal is going to
bump actually to one,

00:48:39.820 --> 00:48:42.080
in this case, like the semaphore.

00:48:42.090 --> 00:48:45.920
Then what happens is that the
NP-way-on semaphore in our routine,

00:48:45.950 --> 00:48:49.040
because you know, once again,
the semaphore is global,

00:48:49.040 --> 00:48:50.280
is going to actually come back.

00:48:50.310 --> 00:48:51.960
So like, you know,
that code doesn't block.

00:48:52.010 --> 00:48:54.060
Now we're blocked on the number two.

00:48:54.070 --> 00:48:57.740
NP-signal semaphore is actually
called inside thread number two.

00:48:57.770 --> 00:49:00.260
The state changes to one,
and then what happens,

00:49:00.260 --> 00:49:02.860
the NP-way-on semaphore is
going to turn it back to zero.

00:49:02.870 --> 00:49:07.240
At that point in time,
we have a thread that tells us,

00:49:07.270 --> 00:49:11.140
that thread here, thread number one,
says, "Hey, my other two threads are done

00:49:11.140 --> 00:49:13.030
doing the work." Now what do we do?

00:49:13.280 --> 00:49:15.850
We have that, but we need to notify
the main event loop.

00:49:15.860 --> 00:49:20.540
Remember, we have to tell the event loop,
"Hey, I'm done." So how are

00:49:20.550 --> 00:49:21.170
we going to do that?

00:49:21.260 --> 00:49:22.140
Well, very cool.

00:49:22.150 --> 00:49:26.560
There is a very nice Carbon event code,
which is called postEventToQueue.

00:49:26.620 --> 00:49:29.010
And what that's going to do is that
we're going to create a Carbon event,

00:49:29.170 --> 00:49:30.660
pass it to this API.

00:49:30.690 --> 00:49:32.640
That's going to send it
to the event manager,

00:49:32.650 --> 00:49:37.540
and then that manager is going to
dispatch it to our main thread.

00:49:37.550 --> 00:49:40.460
This is what you're going to
do when you want to update UI,

00:49:40.460 --> 00:49:41.580
for instance.

00:49:41.600 --> 00:49:42.980
PostEventToQueue, very cool.

00:49:42.980 --> 00:49:45.190
You pass a Carbon event,
you just need to install

00:49:45.190 --> 00:49:46.250
a Carbon event handler.

00:49:46.270 --> 00:49:48.240
The Carbon event handler could
be installed on a window,

00:49:48.240 --> 00:49:52.380
on a control, a widget, an HIView,
on the application, it's up to you.

00:49:52.380 --> 00:49:53.900
A lot of flexibility.

00:49:53.980 --> 00:49:57.500
And then inside my application,
the main event loop gets notified,

00:49:57.520 --> 00:50:01.150
and then I can display my
picture when we're done.

00:50:01.760 --> 00:50:05.570
So, some do's and don'ts in that
case when you start threading

00:50:05.690 --> 00:50:06.740
the whole application.

00:50:06.740 --> 00:50:09.400
Be careful with the UI, okay?

00:50:09.480 --> 00:50:11.200
It's okay to draw with quarts.

00:50:11.200 --> 00:50:13.400
You may have some issues
depending on what you're doing,

00:50:13.410 --> 00:50:15.790
but it's okay to draw with
quarts from different threads.

00:50:15.860 --> 00:50:20.130
And we have some,
actually some sample code on DTS.

00:50:20.330 --> 00:50:31.750
on DTS on our developer.apple.com
website enables you to check that out.

00:50:31.750 --> 00:50:31.750
And George is gonna be here and
can give you the complete URL.

00:50:31.750 --> 00:50:31.750
OpenGL is okay as well.

00:50:32.150 --> 00:50:34.430
And once again,
if you want to notify the main

00:50:34.450 --> 00:50:38.130
event queue for drawing a button,
for updating a scroller,

00:50:38.130 --> 00:50:40.360
please use postEventToQueue.

00:50:40.470 --> 00:50:43.700
PostEventToQueue is very cool because
you can call that from wherever you want.

00:50:43.720 --> 00:50:45.750
You create your own
Carbon event with your type,

00:50:45.800 --> 00:50:47.000
you know, like it's up to you.

00:50:47.000 --> 00:50:48.890
And then, you know,
you have your Carbon event

00:50:48.890 --> 00:50:50.820
handler in your window,
and your application is

00:50:50.860 --> 00:50:52.000
just going to be called.

00:50:52.000 --> 00:50:55.990
This is the way to do, like, you know,
user interface from different threads.

00:50:57.000 --> 00:51:00.500
All right, quick summary,
it's not that best.

00:51:00.570 --> 00:51:03.500
So once again, thread your application
when it's appropriate.

00:51:03.500 --> 00:51:06.070
Obviously,
some of the examples I gave you

00:51:06.070 --> 00:51:08.280
here maybe don't apply to you.

00:51:08.300 --> 00:51:11.200
Don't start going in a
frenzy and start threading,

00:51:11.200 --> 00:51:13.400
even if it's easy.

00:51:13.400 --> 00:51:15.630
And the main idea is that
I would encourage you guys

00:51:15.700 --> 00:51:18.290
to go back and think maybe,
for a couple of minutes, think,

00:51:18.430 --> 00:51:20.940
what part of my application is
taking a long time right now?

00:51:21.020 --> 00:51:23.050
What part can I do better for the user?

00:51:23.180 --> 00:51:25.710
And once again,
you can have two motivations

00:51:25.760 --> 00:51:27.260
for threading your applications.

00:51:27.260 --> 00:51:31.060
It could be responsiveness,
because you're doing a lot of things,

00:51:31.060 --> 00:51:34.200
and sometimes the user can't do anything,
the menus don't go down,

00:51:34.200 --> 00:51:34.940
and you're blocked.

00:51:34.960 --> 00:51:37.340
And you want to improve
that user experience.

00:51:37.340 --> 00:51:40.500
But then the other one is for,
in this case, for instance,

00:51:40.500 --> 00:51:44.560
that I showed you, you're doing a lot of
CPU-intensive tasks.

00:51:44.560 --> 00:51:47.010
Maybe you're doing the computing,
or this huge array,

00:51:47.010 --> 00:51:51.230
like matrix manipulation,
or your job is to compute.

00:51:51.240 --> 00:51:53.310
You get an MRI,
and you have to find out if that

00:51:53.310 --> 00:51:54.740
MRI has cancer or something.

00:51:54.740 --> 00:51:55.740
You get the idea.

00:51:55.740 --> 00:51:57.660
And it can take a long time.

00:51:57.660 --> 00:52:01.050
That's the typical case where I want
you to think and think in terms of,

00:52:01.050 --> 00:52:02.500
can that be divided?

00:52:02.660 --> 00:52:04.140
Could I use different threads?

00:52:04.150 --> 00:52:07.800
Is my code path can be
executed independently?

00:52:07.820 --> 00:52:08.550
So think about that.

00:52:08.610 --> 00:52:11.550
I think a lot of developers actually
sometimes just don't think about it,

00:52:11.550 --> 00:52:13.910
because we're going all these features.

00:52:13.960 --> 00:52:16.370
But I think it's very,
very important with what our users

00:52:16.410 --> 00:52:19.320
are buying now in these new G5s,
that actually we all think

00:52:19.360 --> 00:52:23.740
about responsiveness and high
performance by threading.

00:52:24.090 --> 00:52:26.680
And once again,
I'll be posting the sample

00:52:26.970 --> 00:52:28.500
code probably tonight.

00:52:28.520 --> 00:52:29.910
Actually, I think I can do it now at 5.

00:52:29.920 --> 00:52:31.510
I don't think I have
a session after that.

00:52:31.910 --> 00:52:35.510
And I'll go into more details
about that in a second.

00:52:37.810 --> 00:52:42.500
All right, if you want more information,
we have some stuff on Carbon threads

00:52:42.500 --> 00:52:44.740
and the multiprocessing services.

00:52:44.740 --> 00:52:48.200
And ADC home, you know,
is developer.apple.com.

00:52:48.200 --> 00:52:50.000
I'll let you read the slides.

00:52:50.000 --> 00:52:53.990
If you're interested in Cocoa,
obviously Cocoa has

00:52:53.990 --> 00:52:53.990
some threading as well.

00:52:55.120 --> 00:52:58.560
If you're interested
in the POSIX P threads,

00:52:58.640 --> 00:53:00.560
you can just do a main.

00:53:00.590 --> 00:53:02.660
The main page is actually pretty good.

00:53:02.660 --> 00:53:04.960
I mean,
I know if you're coming from Mac OS X,

00:53:05.010 --> 00:53:07.250
you're probably thinking, "Main pages?

00:53:07.250 --> 00:53:10.070
I don't want to go to the
terminal." But personally,

00:53:10.070 --> 00:53:12.280
I encourage you to actually check it out.

00:53:12.280 --> 00:53:15.480
It's a very, very good start when you
look for information.

00:53:15.670 --> 00:53:19.110
The Darwin CVS repository,
if you really want it, but technically,

00:53:19.110 --> 00:53:22.060
I think the opengroup.org
has some pretty good news and

00:53:22.060 --> 00:53:22.190
updated information on P threads.

00:53:22.190 --> 00:53:22.190
Okay.

00:53:22.790 --> 00:53:30.890
We have some technical notes,
the 2028 for the technical architectures,

00:53:30.890 --> 00:53:30.890
and we have actually a tech
note with the MPCF routines.