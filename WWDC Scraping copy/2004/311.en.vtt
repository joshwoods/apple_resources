WEBVTT

00:00:12.800 --> 00:00:13.970
Good morning everyone.

00:00:14.230 --> 00:00:17.980
Welcome to
Using Performance Analysis Tools for

00:00:17.980 --> 00:00:18.580
Mac OS X.

00:00:18.680 --> 00:00:19.580
Let's dive in.

00:00:19.580 --> 00:00:23.570
I'm Dave Payne,
working on the performance tools.

00:00:24.380 --> 00:00:28.770
So this morning we're going to cover some
of the concepts of performance analysis,

00:00:28.770 --> 00:00:33.680
just general concepts for any system,
and then look at the performance tools

00:00:33.760 --> 00:00:38.750
that we have available for Mac OS X,
and then dive into looking at a case

00:00:38.750 --> 00:00:43.140
study of real-world use of the tools,
and then showing some of the cool

00:00:43.140 --> 00:00:46.980
new work that we've been doing to
integrate some of the features of the

00:00:47.030 --> 00:00:52.540
sampler profiling tool into Shark,
which is another profiling tool,

00:00:52.540 --> 00:00:53.910
to combine them.

00:00:53.920 --> 00:00:58.900
And then add a bunch of powerful new
features to help you find performance

00:00:58.900 --> 00:01:02.180
problems faster in your applications.

00:01:03.120 --> 00:01:05.340
So why are we interested in this?

00:01:05.370 --> 00:01:07.880
After all, those machines are
getting faster and faster,

00:01:07.880 --> 00:01:08.130
right?

00:01:08.130 --> 00:01:09.670
Just buy beefier hardware.

00:01:09.670 --> 00:01:10.330
That's really cool.

00:01:10.340 --> 00:01:14.830
Well, there's a lot of jobs no matter
how fast the hardware is.

00:01:15.350 --> 00:01:17.040
People always need more power.

00:01:17.040 --> 00:01:22.000
You need it in your development tools,
for example, faster compilations, etc.

00:01:22.110 --> 00:01:24.460
In general,
I don't want to have to go out

00:01:24.460 --> 00:01:27.520
and buy another gigabyte of
RAM to run this application

00:01:27.680 --> 00:01:29.660
or these three in combination.

00:01:30.440 --> 00:01:33.940
I'd like my laptop to have
the battery last all the way

00:01:33.940 --> 00:01:35.910
back to Dallas on my flight.

00:01:35.940 --> 00:01:38.900
A lot of that is how much am
I beating on the hardware,

00:01:38.900 --> 00:01:40.390
the CPU, the memory.

00:01:40.400 --> 00:01:44.940
When the fan kicks in,
what's going on there?

00:01:44.940 --> 00:01:47.200
That takes power as well on the laptops.

00:01:47.260 --> 00:01:50.030
In general,
we want applications that play

00:01:50.040 --> 00:01:51.810
well together with others.

00:01:51.960 --> 00:01:56.350
That really is important to reduce
the amount of overall memory

00:01:56.350 --> 00:01:58.560
that your application is using.

00:01:58.560 --> 00:02:01.820
Because I'm running... I'm
running more and more applications

00:02:01.820 --> 00:02:02.740
on my system every day.

00:02:02.740 --> 00:02:04.250
You guys are creating cool apps.

00:02:04.560 --> 00:02:05.270
Thanks.

00:02:05.380 --> 00:02:09.560
But I don't want to have to page
tremendously when I'm switching

00:02:09.560 --> 00:02:10.800
between those applications.

00:02:12.610 --> 00:02:16.660
So rather than just diving in and saying,
well,

00:02:16.660 --> 00:02:18.340
I think this routine is going to be slow.

00:02:18.340 --> 00:02:21.790
I want to go rewrite it
because it'll be fun and cool.

00:02:21.890 --> 00:02:26.500
Humans are notoriously bad at guessing
where the performance problems might be.

00:02:26.500 --> 00:02:29.480
So we need a systematic way
to go about looking at this.

00:02:30.000 --> 00:02:32.620
You're the expert in
using your application,

00:02:32.620 --> 00:02:33.620
what it's for.

00:02:33.620 --> 00:02:38.000
So an approach to performance analysis,
first, define what the major

00:02:38.000 --> 00:02:42.120
operations you're interested in
having fast for the user are.

00:02:42.120 --> 00:02:45.440
Then,
what are your goals to make sure that

00:02:45.440 --> 00:02:48.320
that's nice and fast for the user?

00:02:48.320 --> 00:02:50.780
For example, responsiveness.

00:02:50.780 --> 00:02:53.880
If you have slow operations,
then you can either speed

00:02:53.880 --> 00:02:56.500
those operations up,
which is the best case,

00:02:56.500 --> 00:02:59.960
this just happened like that,
or if it's unavailable,

00:02:59.970 --> 00:02:59.980
you can speed those operations up.

00:03:00.070 --> 00:03:02.650
If it's unavoidable that
it's going to be slow,

00:03:02.660 --> 00:03:05.590
then you want the user to be
able to be in control of the

00:03:05.590 --> 00:03:07.350
application again quickly.

00:03:07.350 --> 00:03:10.700
So maybe move the slow operation
to a separate thread so that

00:03:10.700 --> 00:03:12.820
the UI can be responsive again.

00:03:12.840 --> 00:03:13.750
Throughput.

00:03:13.800 --> 00:03:17.290
If you're doing a game,
you want lots of frames per second.

00:03:17.290 --> 00:03:21.610
If you're doing a network application,
you want a lot of data throughput.

00:03:21.820 --> 00:03:24.870
Servers,
you want lots of transactions per second.

00:03:25.290 --> 00:03:27.040
What's the goal for your arena?

00:03:27.040 --> 00:03:29.960
Then, establish precise benchmarks.

00:03:30.000 --> 00:03:32.380
For that,
define what your target hardware

00:03:32.500 --> 00:03:35.280
for your customer segment is,
what operating system

00:03:35.280 --> 00:03:39.360
version you're testing with,
and the specific data that you're

00:03:39.360 --> 00:03:44.270
going to be passing in and specifically
what operations you want to test.

00:03:44.420 --> 00:03:48.520
Then, add in time measurement code
instrumentation so you can time

00:03:48.660 --> 00:03:53.040
and time again measure that same
operation and see how you're doing.

00:03:55.340 --> 00:03:57.410
Track that throughout your development.

00:03:57.450 --> 00:04:00.680
This is what the Safari team was
doing to make sure that they had

00:04:00.730 --> 00:04:03.200
the fastest web browser on Mac OS X.

00:04:03.200 --> 00:04:08.310
Define a precise set of benchmarks
and then ran it time and time again.

00:04:08.310 --> 00:04:11.360
And when somebody was going to check
in a major piece of new functionality,

00:04:11.360 --> 00:04:16.200
it couldn't go in if it caused the
system to slow down noticeably.

00:04:16.200 --> 00:04:18.190
So don't allow regressions.

00:04:18.350 --> 00:04:22.200
And finally, if you do identify some
performance problems,

00:04:22.530 --> 00:04:26.200
then focus your tuning
efforts on those hotspots.

00:04:26.500 --> 00:04:30.120
Well, that's easily said,
but how do you actually do that?

00:04:30.260 --> 00:04:32.200
How do you find what the hotspots are?

00:04:32.200 --> 00:04:35.200
Got tools to help with that?

00:04:35.410 --> 00:04:36.590
Yes, absolutely.

00:04:36.590 --> 00:04:37.820
We've got tools.

00:04:37.820 --> 00:04:39.200
You've got tools.

00:04:39.200 --> 00:04:42.920
These have been included with
your Mac OS X performance tools

00:04:43.020 --> 00:04:45.140
for several years at this point.

00:04:45.260 --> 00:04:48.080
Take a look in Developer Applications
Performance Tools.

00:04:48.080 --> 00:04:52.200
As with all of our developer tools,
these tools are free.

00:04:52.200 --> 00:04:56.200
We really want you to use these
things to create great applications.

00:04:56.480 --> 00:05:00.650
They provide full support for
everything you need to do with Mac OS X,

00:05:00.650 --> 00:05:05.200
including now a lot of support has
been added in for Java profiling.

00:05:05.220 --> 00:05:07.970
And in addition,
our GUI-based tools are integrated

00:05:07.970 --> 00:05:11.200
with Xcode for a full round
trip of the development cycle.

00:05:11.200 --> 00:05:14.200
You can launch your binary
under a performance tool.

00:05:14.200 --> 00:05:19.700
And then you can get back to the
source code directly from the

00:05:19.700 --> 00:05:23.200
performance tool back into Xcode.

00:05:23.200 --> 00:05:28.200
So we have a variety of performance tools
for monitoring performance problems,

00:05:28.200 --> 00:05:33.330
for analyzing what once you've found
that you do have a performance problem,

00:05:33.330 --> 00:05:38.200
then analyzing what is the problem,
where is it, why is it happening

00:05:38.200 --> 00:05:41.630
in a variety of areas,
memory use, execution time,

00:05:41.750 --> 00:05:43.200
other types of resources.

00:05:43.200 --> 00:05:48.020
And I'm going to dive into a bunch
of these tools as we go through.

00:05:48.200 --> 00:05:52.370
So in the area of high-level monitoring,
there's a number of things you

00:05:52.440 --> 00:05:56.150
can look at to help answer just
what in general is happening.

00:05:56.200 --> 00:05:59.500
One of the primary ones
is the command line tool,

00:05:59.500 --> 00:06:01.870
Top, which is always there for you.

00:06:02.320 --> 00:06:08.590
You can use that for just my system
right now or to look at a headless

00:06:09.050 --> 00:06:12.200
server or remotely log into a system.

00:06:12.200 --> 00:06:16.190
You can also use that to look
at a full-screen game going.

00:06:16.200 --> 00:06:19.690
But we've got a bunch of other tools
as well that are a little bit more

00:06:19.690 --> 00:06:22.200
friendly with graphical user interfaces.

00:06:22.200 --> 00:06:25.830
So for example,
a nicer user interface to Top is the

00:06:26.020 --> 00:06:31.200
activity monitor application that can
help you analyze why is my system slow.

00:06:31.200 --> 00:06:34.200
Is there some particular
process that's taking time?

00:06:34.200 --> 00:06:36.190
Is its memory growing?

00:06:36.220 --> 00:06:38.200
So this one ships on the user CD.

00:06:38.200 --> 00:06:40.090
If the user calls up your
support line and says,

00:06:40.230 --> 00:06:43.300
"My system's slow." You can
call fire up activity monitor

00:06:43.300 --> 00:06:45.190
and tell me what it looks like.

00:06:45.200 --> 00:06:48.200
Another one you might
not be familiar with,

00:06:48.200 --> 00:06:49.200
this was one of the Chud tools.

00:06:49.240 --> 00:06:54.050
We've now elevated it up into the
mainstream set of performance tools.

00:06:54.220 --> 00:06:56.950
It's called Big Top.

00:06:57.210 --> 00:07:01.200
So this actually takes the
Top information and graphs it over time.

00:07:01.200 --> 00:07:04.120
So you can really see how
it's changing over time.

00:07:04.220 --> 00:07:09.210
I find this very useful to watch and
actually see graphically is the private

00:07:09.390 --> 00:07:10.200
memory use of my application growing.

00:07:10.200 --> 00:07:12.200
Or the virtual memory use.

00:07:12.200 --> 00:07:14.190
Those are two of the best metrics.

00:07:14.250 --> 00:07:17.740
And you may end up,
you don't want to look at shared resident

00:07:17.990 --> 00:07:23.200
size because that's like your frameworks
that are shared with other apps.

00:07:23.200 --> 00:07:25.190
But the private space could be growing.

00:07:25.200 --> 00:07:28.200
And that's important to know.

00:07:28.980 --> 00:07:32.140
Oftentimes, I'm sure you've seen it,
the spinning cursor comes up.

00:07:32.260 --> 00:07:35.200
And you wonder, dang,
I wish I could capture that.

00:07:35.200 --> 00:07:37.070
Maybe it's a two second spin.

00:07:37.260 --> 00:07:39.200
And by the time you're off typing
sample on the command line,

00:07:39.200 --> 00:07:41.200
the spin's over.

00:07:41.200 --> 00:07:44.160
But it makes your app
not feel responsive.

00:07:44.220 --> 00:07:47.140
So spin control is a great
way to just capture that.

00:07:47.230 --> 00:07:50.200
Just have it running in the
background all the time.

00:07:50.200 --> 00:07:53.160
It automatically detects when
applications aren't responding

00:07:53.230 --> 00:07:56.200
to the user interface events.

00:07:56.460 --> 00:07:59.200
And lets you see what's going on there.

00:08:01.120 --> 00:08:04.980
Now, sometimes I mention that
the fan will kick in.

00:08:04.980 --> 00:08:08.500
I've noticed this a number of times
that my machine is sitting there idle

00:08:08.500 --> 00:08:10.330
and yet suddenly the fan fires up.

00:08:10.970 --> 00:08:12.100
Whoa, what's going on there?

00:08:12.100 --> 00:08:16.000
So I fire up top or activity
monitor and take a look and some

00:08:16.300 --> 00:08:18.890
process is using 50% of the CPU.

00:08:19.390 --> 00:08:21.310
Maybe it's drawing too much.

00:08:21.310 --> 00:08:24.600
Quartz Debug is a great way to look
at this and I've actually seen this a

00:08:24.600 --> 00:08:26.720
number of times in real applications.

00:08:26.720 --> 00:08:32.000
It's periodically drawing and Quartz
Debug flashes the graphics yellow

00:08:32.250 --> 00:08:34.360
on the screen every time it draws.

00:08:34.380 --> 00:08:37.460
Or you can also set it up to
just see duplicate drawing

00:08:37.460 --> 00:08:40.080
in just normal operations.

00:08:40.150 --> 00:08:40.950
Very useful.

00:08:40.950 --> 00:08:45.870
So once you've used the high-level
performance analysis tools to

00:08:45.870 --> 00:08:50.750
see what's going on overall,
then now we want to go and dive

00:08:50.750 --> 00:08:57.200
into why is this happening.

00:08:57.300 --> 00:09:01.060
So we have a variety of profiling tools.

00:09:01.060 --> 00:09:01.060
We're going to talk a lot about
Shark today because we've put a lot

00:09:01.060 --> 00:09:01.060
of effort into the Shark application.

00:09:01.070 --> 00:09:02.950
Spin control, I mentioned.

00:09:03.050 --> 00:09:08.240
Thread viewer lets you see the
thread activity of your application.

00:09:08.240 --> 00:09:11.060
What are all the different threads
and what are the back traces of them.

00:09:11.280 --> 00:09:15.050
And then for those of you doing
OpenGL graphics programming,

00:09:15.340 --> 00:09:18.910
OpenGL Profiler is a fantastic
application to help figure out

00:09:18.910 --> 00:09:20.470
where the time is going there.

00:09:20.470 --> 00:09:24.870
Command line tools,
sample is excellent for just a quick

00:09:24.920 --> 00:09:29.720
basic sample process name or process ID,
number of seconds.

00:09:29.770 --> 00:09:31.040
Very useful.

00:09:31.040 --> 00:09:34.130
And then we have the
Venerable Unix Gprof tool.

00:09:34.200 --> 00:09:37.980
But that's the only one that really
requires recompiling for profiling.

00:09:38.050 --> 00:09:42.660
The others don't need to do any
recompilation of your application.

00:09:44.140 --> 00:09:45.440
So I mentioned Shark.

00:09:45.440 --> 00:09:47.910
We have a new version that
was shown yesterday in the

00:09:47.910 --> 00:09:50.290
Development Tools Keynote,
Shark 4.0.

00:09:50.300 --> 00:09:54.690
This tool helps you figure out why is my
time being spent in some certain place,

00:09:54.780 --> 00:09:55.920
where is it going.

00:09:55.920 --> 00:10:01.030
You can look at specific threads,
specific processes, the overall system,

00:10:01.030 --> 00:10:04.700
and now you can actually do
sampling over the network as well.

00:10:04.700 --> 00:10:09.560
For, again,
like dual full-screen games or something.

00:10:10.320 --> 00:10:13.420
This captures all the
information about the system,

00:10:13.420 --> 00:10:15.170
both user space and kernel space.

00:10:15.220 --> 00:10:18.820
There's a full session on
Shark this Friday afternoon.

00:10:18.820 --> 00:10:20.450
I'd encourage you to go to that.

00:10:20.560 --> 00:10:23.180
We'll see more of this today,
but we aren't going to dive into

00:10:23.220 --> 00:10:24.960
all the full-blown features of it.

00:10:25.020 --> 00:10:28.950
One of the things I really love
about Shark is I don't even have

00:10:28.950 --> 00:10:31.250
to attach to a process with this.

00:10:31.360 --> 00:10:35.870
It's always sitting in the background
with an option escape hotkey that

00:10:35.870 --> 00:10:38.090
will sample the entire system.

00:10:38.820 --> 00:10:40.890
So if I notice something
seeming sluggish,

00:10:41.050 --> 00:10:43.270
I can just hit option escape right away.

00:10:43.690 --> 00:10:48.120
Shark fires up and says, "Okay,
let's sample," and then I can option

00:10:48.260 --> 00:10:51.260
escape to stop it and see what's
going on in the system and then

00:10:51.260 --> 00:10:53.060
dive into that specific process.

00:10:53.100 --> 00:10:57.320
But there's a lot of ways to get
more specific information here.

00:10:58.030 --> 00:11:01.850
Different sampling methods,
memory tracing, function tracing,

00:11:01.850 --> 00:11:03.440
we'll look at a lot of these.

00:11:03.520 --> 00:11:06.150
There's three primary views in Shark.

00:11:06.260 --> 00:11:08.560
A profile view that lets
you see a top-down view.

00:11:08.560 --> 00:11:08.760
A profile view that lets
you see a top-down view.

00:11:08.760 --> 00:11:10.380
A profile view that lets
you see a top-down call

00:11:10.400 --> 00:11:11.450
tree of your function calls.

00:11:11.920 --> 00:11:15.830
Bottom up for real profiling information
and who's calling the leaf functions.

00:11:15.960 --> 00:11:20.070
We've done a lot of work in this
to really let you hone in and

00:11:20.070 --> 00:11:24.780
do filtering and data mining to
simplify the complex picture.

00:11:24.860 --> 00:11:28.280
There's a chart view that helps
you really see the patterns

00:11:28.290 --> 00:11:29.830
of execution of your code.

00:11:30.250 --> 00:11:34.330
This is excellent for both performance
analysis and just understanding

00:11:34.330 --> 00:11:36.630
what's going on in your application.

00:11:36.640 --> 00:11:37.850
It's really cool.

00:11:38.310 --> 00:11:42.250
And finally, within Shark itself,
there's a code browser that you

00:11:42.250 --> 00:11:45.700
can see source code or assembly,
get hints about what

00:11:45.820 --> 00:11:49.240
the assembly code is,
and get directly back to the

00:11:49.310 --> 00:11:51.800
offending lines of code in Xcode.

00:11:51.800 --> 00:11:56.210
These are all instrumented
here with specific lines of

00:11:56.210 --> 00:11:58.670
code the time is going into.

00:12:00.230 --> 00:12:03.400
So I haven't talked a lot about Sampler.

00:12:03.420 --> 00:12:05.780
So many of you may be
familiar with using Sampler.

00:12:05.780 --> 00:12:06.980
What's going on with that?

00:12:07.190 --> 00:12:11.420
We've integrated all of the features
of Sampler into Shark and we plan

00:12:11.520 --> 00:12:14.170
to remove Sampler from the system.

00:12:14.520 --> 00:12:18.200
So you can see here that Shark has
a number of additional features

00:12:18.200 --> 00:12:21.290
and we'll touch on some of
these and then more on Friday.

00:12:21.470 --> 00:12:26.780
But please try Shark and
the team's been very busy.

00:12:26.780 --> 00:12:31.200
So Shark is there on your Tiger CDs,
but there's actually a newer public

00:12:31.200 --> 00:12:35.110
beta that's got a number of additional
features that the team banged

00:12:35.110 --> 00:12:37.980
in in the last couple of weeks.

00:12:37.980 --> 00:12:40.860
So please download the
new version of Shark.

00:12:40.860 --> 00:12:45.460
It runs on both Panther and
Tiger and send us your feedback.

00:12:45.530 --> 00:12:47.820
I'll give an address later.

00:12:47.840 --> 00:12:48.770
So what about memory use?

00:12:48.920 --> 00:12:51.780
I mentioned that it's really important
to try to minimize the overall

00:12:51.900 --> 00:12:53.540
footprint of your application.

00:12:53.650 --> 00:12:58.750
We have a number of tools to help
analyze what's going on with memory use.

00:12:59.170 --> 00:13:02.430
So, a very nice one is ObjectAlloc.

00:13:02.530 --> 00:13:05.560
This is great for looking
at dynamic memory use,

00:13:05.620 --> 00:13:09.570
both how much memory am I using right
now and how much was the peak that

00:13:09.660 --> 00:13:11.610
I used in some particular operation.

00:13:11.720 --> 00:13:17.280
You can use this with Cocoa applications
and this is great for seeing your

00:13:17.610 --> 00:13:20.240
allocations by allocation type.

00:13:20.340 --> 00:13:25.010
What type of objects, so Cocoa objects,
core foundation objects like you would

00:13:25.010 --> 00:13:30.280
also have with Carbon applications,
and just general malloc allocations and

00:13:30.280 --> 00:13:33.800
it says what size they are because a
lot of times you'll allocate specific

00:13:33.800 --> 00:13:36.500
sizes at specific points in your code.

00:13:36.500 --> 00:13:38.390
So you can see all that.

00:13:38.550 --> 00:13:42.440
And you can look at information
about specific instances of that.

00:13:42.580 --> 00:13:47.620
It's not quite as good for
pinning down precise memory leaks.

00:13:47.850 --> 00:13:50.800
MallocDebug is still the
best application for that.

00:13:51.350 --> 00:13:55.630
This shows a full call tree
of all the allocated memory,

00:13:55.630 --> 00:13:56.800
not by type, and it's not so good
for dynamic allocation.

00:13:56.800 --> 00:14:00.280
But it is still the best tool for leaks.

00:14:00.380 --> 00:14:04.800
There's a command line tool equivalent
of this called leaks that can also show

00:14:04.800 --> 00:14:09.810
you the backtraces of where allocations
were occurring if you set this malloc

00:14:09.810 --> 00:14:12.530
stack logging environment variable.

00:14:12.820 --> 00:14:16.190
So another major function of
MallocDebug was to help find

00:14:16.190 --> 00:14:18.110
corrupt memory operations.

00:14:18.110 --> 00:14:21.980
But we actually have a better
solution for that at this point.

00:14:21.980 --> 00:14:25.360
The purpose was to help crash
your application if you did

00:14:25.500 --> 00:14:27.270
something bad with memory.

00:14:27.270 --> 00:14:30.040
But really,
you want to be operating within a

00:14:30.040 --> 00:14:32.700
debugging environment if this happens.

00:14:32.700 --> 00:14:36.630
So we have a new Malloc debugging
library called GuardMalloc.

00:14:36.730 --> 00:14:40.370
So this operates within the
context of the Xcode debugger.

00:14:40.370 --> 00:14:45.750
There's a nice switch on the
debugger menu item now to say "Enable

00:14:45.750 --> 00:14:50.640
GuardMalloc." And what this does when you
turn it on is every allocation you make

00:14:50.640 --> 00:14:53.450
goes onto a separate virtual memory page.

00:14:54.640 --> 00:14:59.700
Then the end of the buffer is lined
up with the end of that memory page,

00:14:59.780 --> 00:15:02.740
and the next page is non-allocating.

00:15:02.740 --> 00:15:05.820
So if you overrun the buffer,
you'll crash immediately,

00:15:05.840 --> 00:15:10.510
and you're in the Xcode debugger,
you can see immediately where

00:15:10.670 --> 00:15:12.660
buffer overruns are in your code.

00:15:12.660 --> 00:15:16.500
If you free the block,
then we free the virtual memory page.

00:15:16.550 --> 00:15:20.960
And so if you go and read or write
from that page again after freeing it,

00:15:21.020 --> 00:15:23.170
then again, you crash immediately.

00:15:23.240 --> 00:15:27.640
So this is a great way to find
really nasty memory problems.

00:15:27.700 --> 00:15:30.880
So you can learn more about
this in the Xcode debugging

00:15:30.880 --> 00:15:34.960
session on Thursday morning
and the libgmallocman page.

00:15:35.210 --> 00:15:37.720
So not so much a performance tool,
but a great solution.

00:15:37.720 --> 00:15:42.280
So again, I've said we're putting a
lot of effort into Shark.

00:15:42.710 --> 00:15:45.960
We're trying to add a number
of these memory analysis

00:15:45.960 --> 00:15:48.080
features into Shark as well.

00:15:48.100 --> 00:15:52.890
Shark can now do malloc allocation
sampling and show you the size of

00:15:52.980 --> 00:15:55.600
your allocations and call trees there.

00:15:55.770 --> 00:16:00.300
There are still different strengths and
weaknesses of our memory analysis tools.

00:16:00.570 --> 00:16:03.330
Again,
objectalloc is great for dynamic analysis

00:16:03.350 --> 00:16:05.720
and looking at specific object types.

00:16:05.950 --> 00:16:09.190
Malloc debug is good for leaks,
and we want to add leaks

00:16:09.190 --> 00:16:12.620
detection into Shark,
but Shark has new capabilities too.

00:16:13.660 --> 00:16:18.920
So that's it for a broad brush
overview of the performance tools.

00:16:18.920 --> 00:16:21.200
Now let's dive into a
specific case study.

00:16:21.240 --> 00:16:25.900
Now I'm not actually going to do
the requisite planetary motion

00:16:25.900 --> 00:16:28.600
simulator that seems to be so popular.

00:16:28.600 --> 00:16:33.320
I'm going to be looking at an
application called Disk Inventory X.

00:16:33.610 --> 00:16:35.590
This is an open source application.

00:16:35.590 --> 00:16:37.600
It's kind of cool and
actually kind of useful.

00:16:37.600 --> 00:16:42.630
It uses a concept from Ben Schneiderman
at the University of Maryland for

00:16:42.630 --> 00:16:48.480
representing hierarchical information
in a compact two-dimensional space.

00:16:48.600 --> 00:16:51.000
So it's an open source application,
GPL'd.

00:16:51.060 --> 00:16:53.600
I'll be sending changes
back to the author.

00:16:53.600 --> 00:16:54.600
He's pretty excited about that.

00:16:54.600 --> 00:16:57.610
And as we go through,
we'll be looking at a number of

00:16:57.610 --> 00:17:03.500
areas of what might be slow here:
time, memory, other resource use.

00:17:03.600 --> 00:17:06.600
So in your application,
as you look at something like this,

00:17:06.600 --> 00:17:07.600
what might you want to look at?

00:17:07.600 --> 00:17:09.580
Of course, major operations.

00:17:09.680 --> 00:17:12.520
How long does it take to
open a large document?

00:17:12.600 --> 00:17:17.600
If the application is idle, again,
you should be taking 0% of the CPU.

00:17:17.600 --> 00:17:23.590
And again,
watch for UI spins and deal with those.

00:17:23.600 --> 00:17:26.410
Memory size,
I've talked about the importance

00:17:26.410 --> 00:17:28.590
of looking at dynamic memory use.

00:17:28.590 --> 00:17:28.600
We'll see that.

00:17:28.720 --> 00:17:30.600
Leaks.

00:17:30.600 --> 00:17:34.050
One thing that may not be
obvious is auto-released

00:17:34.200 --> 00:17:36.480
objects with Cocoa applications.

00:17:36.600 --> 00:17:37.600
If you create a separate memory,
you'll have to look at the memory size.

00:17:37.600 --> 00:17:41.740
If you create a separate thread,
or if you have a foundation-based tool,

00:17:41.740 --> 00:17:44.600
it's real easy with a lot
of the Cocoa APIs to end up

00:17:44.600 --> 00:17:48.930
creating an auto-released object,
but maybe not getting back and freeing

00:17:48.930 --> 00:17:51.600
the auto-release pool very frequently.

00:17:51.600 --> 00:17:54.800
Maybe it's a long-running thread,
and those objects just

00:17:55.120 --> 00:17:59.450
build up and get paged out,
and that can take-- I've actually seen

00:17:59.540 --> 00:18:01.580
applications crash due to this problem.

00:18:01.580 --> 00:18:03.600
The system gets slow, you crash.

00:18:03.810 --> 00:18:07.600
So also look at disk
and network activity.

00:18:07.600 --> 00:18:10.060
I'm going to be specifically
looking at some of this with

00:18:10.060 --> 00:18:11.600
our sample application here.

00:18:11.880 --> 00:18:18.600
So what I want to do is switch
to--oops--we'll switch to demo one here.

00:18:20.950 --> 00:18:24.620
So this is the disk
inventory application.

00:18:24.650 --> 00:18:32.700
What we've done here is-- actually,
we can't see the menu bar up there.

00:18:33.120 --> 00:18:35.690
If we can get the menu bar,
that'd be great.

00:18:35.960 --> 00:18:40.440
So what we've done is taken a look
at our applications directory that's

00:18:40.440 --> 00:18:42.760
got 1.9 gigabytes of space in it.

00:18:42.760 --> 00:18:45.670
And I'm interested in
where is that space going?

00:18:45.920 --> 00:18:48.120
So what this application
does is graphically show

00:18:48.120 --> 00:18:49.720
me the size of the files.

00:18:49.760 --> 00:18:52.680
The larger the rectangle,
the bigger the file.

00:18:52.690 --> 00:18:55.040
And the color represents
what kind of file it is.

00:18:55.040 --> 00:18:56.620
So we can see the blue is a disk image.

00:18:56.880 --> 00:19:00.620
So wow,
I have at least one big file here.

00:19:00.620 --> 00:19:04.740
OK, that looks like the
Adobe Photoshop 7 disk image.

00:19:04.740 --> 00:19:06.970
I probably don't need that.

00:19:07.030 --> 00:19:12.130
Down here, a couple other disk images,
application packages.

00:19:12.190 --> 00:19:13.380
So this is kind of cool.

00:19:13.380 --> 00:19:18.220
I can click on a directory and see how
much space that directory is taking.

00:19:18.220 --> 00:19:21.560
I can move around with the
mouse and see things there.

00:19:21.700 --> 00:19:25.250
So it's actually kind of useful.

00:19:25.880 --> 00:19:30.300
So let's go ahead and quit
out of this and bring up the

00:19:30.400 --> 00:19:31.900
Performance Tools folder.

00:19:31.900 --> 00:19:35.140
I'm going to launch the
Big Top tool that I referred to,

00:19:35.150 --> 00:19:38.020
and I'm also going to
launch Spin Control.

00:19:38.020 --> 00:19:41.280
I'll just put Spin Control down
here in the background.

00:19:41.400 --> 00:19:46.760
Now, with Big Top,
I can look at things like the CPU usage.

00:19:46.760 --> 00:19:51.680
As I move a window around,
we can see that CPU use goes up and down,

00:19:51.720 --> 00:19:54.040
as expected.

00:19:54.470 --> 00:20:02.030
Let's go ahead and launch the
Disk Inventory application again.

00:20:02.510 --> 00:20:07.220
I'm going to look at the,
specifically the disk inventory

00:20:07.220 --> 00:20:13.580
process and watch the memory
size of that as I go through and,

00:20:13.580 --> 00:20:18.740
so what I'm doing is going to open
recent and actually reopening the

00:20:18.740 --> 00:20:23.340
applications window there and scrolling,
analyzing that.

00:20:23.840 --> 00:20:26.680
So you can see that memory
use is climbing here.

00:20:26.680 --> 00:20:31.300
I've added a little instrumentation
window here and it took a little bit

00:20:31.300 --> 00:20:34.880
of time to analyze that 1.9 gigabytes.

00:20:34.880 --> 00:20:38.570
So that took about 9 seconds
to scan that folder and a

00:20:38.580 --> 00:20:43.790
little less than a second here,
so about 10 seconds to look at this.

00:20:44.090 --> 00:20:47.810
Actually I haven't tried this
operation on this machine.

00:20:48.080 --> 00:20:52.890
We can also show package contents and

00:20:53.610 --> 00:20:57.130
Note that we actually caught a
little spin here as well with

00:20:57.270 --> 00:20:58.370
Spin Control at this point.

00:20:58.430 --> 00:21:02.650
So it took about four seconds
to show the package contents.

00:21:02.650 --> 00:21:06.350
And with the spin,
I can come down here and select

00:21:06.350 --> 00:21:10.100
that and show a text report and just
see what was happening in there.

00:21:10.100 --> 00:21:14.380
So we were making a bunch of recursive
calls to determine the file kinds inside

00:21:14.810 --> 00:21:17.120
of this package that I'm looking at.

00:21:17.120 --> 00:21:19.130
So that's interesting.

00:21:20.300 --> 00:21:21.990
So we saw the memory use climb.

00:21:21.990 --> 00:21:24.990
That's not totally surprising
because we were building up data

00:21:24.990 --> 00:21:26.560
structures to represent this.

00:21:26.740 --> 00:21:29.540
But we should look at that and see
if we're as efficient as we could be.

00:21:29.540 --> 00:21:30.980
Let's look at one other thing.

00:21:30.980 --> 00:21:35.640
If I resize this window here,
notice a slight pause before redrawing.

00:21:35.670 --> 00:21:37.750
And that was interesting
with the memory use.

00:21:37.830 --> 00:21:40.040
A little spike there, actually.

00:21:40.040 --> 00:21:43.480
That looks like it was probably
over about a megabyte of

00:21:43.610 --> 00:21:47.760
dynamic memory creation while
I was resizing that window.

00:21:47.760 --> 00:21:50.180
So maybe that dynamic memory creation
was a little bit more efficient.

00:21:50.200 --> 00:21:53.080
But I think that the duration and
deletion has something to do with

00:21:53.180 --> 00:21:55.190
why it's not as fast as it could be.

00:21:55.200 --> 00:22:00.820
So let's go back to slides.

00:22:05.620 --> 00:22:11.110
So when we tested this,
we don't have such beefy

00:22:11.180 --> 00:22:12.040
hardware in the labs.

00:22:12.270 --> 00:22:14.960
We have mere mortal dual G5s.

00:22:15.100 --> 00:22:19.540
So my results on testing this
same directory in the lab was

00:22:19.540 --> 00:22:21.800
a little slower than that.

00:22:21.840 --> 00:22:24.900
It was actually almost 20
seconds for scanning the folder

00:22:25.040 --> 00:22:29.700
and getting the file sizes,
and about 10 seconds actually

00:22:29.700 --> 00:22:31.850
to classify the file kinds.

00:22:32.480 --> 00:22:35.930
And showing the package contents was
again pretty consistent there at about 4

00:22:35.930 --> 00:22:41.180
seconds for a total of almost 33 seconds
to scan not quite 2 gigabytes of space.

00:22:41.280 --> 00:22:45.300
There's a lot of 80 gigabyte disks out
there on your personal computer systems.

00:22:45.300 --> 00:22:48.500
So what, 20 minutes to scan my disk?

00:22:48.630 --> 00:22:52.140
What if I have a terabyte disk farm
and I want to use this technique?

00:22:52.390 --> 00:22:53.200
That could be nasty.

00:22:53.200 --> 00:22:54.850
Maybe we can speed this up.

00:22:54.920 --> 00:22:58.510
Now, I've often heard the question of
what are the best timing APIs for

00:22:58.620 --> 00:23:00.540
instrumentation on the system?

00:23:01.340 --> 00:23:05.640
So, Mach Absolute Time is a
Mach API that's the fundamental call.

00:23:05.950 --> 00:23:10.280
This goes down in and reads the
time-based register out of the CPU.

00:23:10.280 --> 00:23:14.040
There's a number of other different
APIs that you can use for different,

00:23:14.210 --> 00:23:16.080
you know,
depending on what's convenient for you.

00:23:16.350 --> 00:23:20.220
Like Get Time of Day is a nice
portable API in the Unix environment.

00:23:20.620 --> 00:23:24.730
These all end up calling
down into Mach Absolute Time.

00:23:25.230 --> 00:23:29.290
This is the way, the actual code that
I used in this application.

00:23:29.430 --> 00:23:31.990
So I simply call Mac Absolute Time,
say get time,

00:23:32.300 --> 00:23:34.610
gives me a 64-bit value back.

00:23:34.730 --> 00:23:37.740
I guess I could just recall it,
call it directly.

00:23:37.890 --> 00:23:41.420
Then I, in subtract time,
once I have two of these,

00:23:41.600 --> 00:23:45.300
I just subtract them and
apply a conversion to get me

00:23:45.300 --> 00:23:49.730
a double value that's seconds,
makes it easy to print.

00:23:49.980 --> 00:23:52.930
So with that,
I've identified that we have some issues.

00:23:53.180 --> 00:23:58.480
I'd like to bring on one of our experts
in analyzing these issues and also then

00:23:58.780 --> 00:24:01.900
creating tools to help do this process.

00:24:01.900 --> 00:24:04.220
So it's my pleasure to
introduce Christy Warren.

00:24:11.200 --> 00:26:45.200
[Transcript missing]

00:26:45.620 --> 00:26:49.500
So going back to this picture,
we're going to zoom in on this graph.

00:26:49.500 --> 00:26:52.060
And it's not just complexity
at the high level.

00:26:52.060 --> 00:26:54.380
Look at it as you zoom
in to the finest detail.

00:26:54.380 --> 00:26:56.140
You see repetition on
many different levels.

00:26:56.330 --> 00:26:59.780
It's like a fractal,
like in a Mandelbrot set.

00:26:59.780 --> 00:27:03.610
You see coarse,
grand detail and then finer

00:27:03.610 --> 00:27:05.540
structure as you zoom in.

00:27:05.540 --> 00:27:09.000
It's amazing what we run into with
software and processors today.

00:27:09.000 --> 00:27:12.310
It's just incredible.

00:27:12.640 --> 00:27:15.210
So to analyze performance,
I've come up with a

00:27:15.220 --> 00:27:16.740
sort of simple formula.

00:27:16.800 --> 00:27:20.770
The impact of any operation you
do is equal to the cost of that

00:27:20.770 --> 00:27:24.310
operation times the number of
places it's used in your code.

00:27:24.660 --> 00:27:27.620
So like in the Dave and
me quicksort example,

00:27:27.920 --> 00:27:30.580
there's two uses of
it that are redundant,

00:27:30.580 --> 00:27:34.380
so that makes it twice as
expensive as it needs to be.

00:27:34.500 --> 00:27:38.500
Now traditional profilers make it
really easy to understand cost.

00:27:38.500 --> 00:27:43.190
You know, you sample a program,
you see all the leaf functions

00:27:43.190 --> 00:27:44.500
that you spend time in.

00:27:44.500 --> 00:27:47.180
But it's hard to see use,
because these are complex

00:27:47.180 --> 00:27:50.500
patterns of usage that often
go through not just my library,

00:27:50.500 --> 00:27:55.310
but ten of your libraries
scattered throughout the system.

00:27:56.520 --> 00:28:01.010
So to help us analyze use,
we have two techniques available to us.

00:28:01.120 --> 00:28:03.100
One is called Call Stack Data Mining.

00:28:03.100 --> 00:28:05.520
And this is a new functionality
that we're introducing.

00:28:05.550 --> 00:28:09.150
We're not aware of this being
available elsewhere in other programs.

00:28:09.160 --> 00:28:14.130
And the idea here is you can strip away
the stuff that you don't want to see

00:28:14.380 --> 00:28:17.000
and focus on what you really care about.

00:28:17.000 --> 00:28:19.520
I'll describe that more in a second.

00:28:20.320 --> 00:28:22.960
The other approach is
this graphical analysis.

00:28:23.100 --> 00:28:26.150
The idea here is you visualize
your execution trace,

00:28:26.150 --> 00:28:27.180
as I've shown.

00:28:27.180 --> 00:28:30.180
And it turns out there's a technique
called software fingerprinting.

00:28:30.180 --> 00:28:32.940
Where, when you see similar
patterns on the picture,

00:28:32.940 --> 00:28:35.980
they would mean that you're
going through the same code path.

00:28:36.170 --> 00:28:39.210
And if there's repeated
patterns that are the same,

00:28:39.210 --> 00:28:42.060
like heartbeats on an EKG,
that means you're going

00:28:42.060 --> 00:28:44.830
through the same code path ten,
a hundred, or a thousand,

00:28:44.830 --> 00:28:45.940
or a million times.

00:28:46.230 --> 00:28:48.860
And it's at least worth looking
to make sure that you aren't

00:28:48.860 --> 00:28:49.920
just doing it on the same data.

00:28:49.970 --> 00:28:51.940
You're going to be looking at the
same data over and over again.

00:28:51.940 --> 00:28:53.940
Or even if you are doing
it on different data,

00:28:54.010 --> 00:28:54.940
can you hoist things out?

00:28:54.940 --> 00:28:57.810
Like in a quick draw,
I mean a quick sort, sorry,

00:28:57.810 --> 00:29:01.200
each time you do a compare,
the compare may go through a

00:29:01.220 --> 00:29:02.850
whole bunch of layers of objects.

00:29:02.940 --> 00:29:05.300
You know, a whole bunch of overhead
that has nothing to do with,

00:29:05.350 --> 00:29:06.940
you know, just comparing two values.

00:29:07.070 --> 00:29:08.230
So remove that stuff.

00:29:08.230 --> 00:29:10.680
Pull it outside of the
iterative structure,

00:29:10.680 --> 00:29:12.820
and your program will run a lot faster.

00:29:13.040 --> 00:29:15.940
But with this tool,
you'll be able to see these things.

00:29:15.940 --> 00:29:17.780
You know,
they'll shout out at you things that

00:29:17.780 --> 00:29:19.700
you'd either have to go digging through
code and spend countless hours on.

00:29:19.770 --> 00:29:23.880
countless hours trying to find the
problem if you didn't have these tools.

00:29:25.480 --> 00:29:27.480
This is working?

00:29:27.500 --> 00:29:29.540
So data mining concepts.

00:29:29.570 --> 00:29:31.880
So I talked about stripping
away what you don't want.

00:29:31.880 --> 00:29:33.620
Now, I have a question for you.

00:29:33.660 --> 00:29:38.200
How many of you have profiled your
program and seen not your code,

00:29:38.200 --> 00:29:42.020
but like countless system files,
system frameworks?

00:29:42.020 --> 00:29:43.150
Isn't that stuff annoying?

00:29:43.360 --> 00:29:44.520
Some of you?

00:29:44.520 --> 00:29:45.020
A lot of you?

00:29:45.020 --> 00:29:45.800
Yeah.

00:29:45.800 --> 00:29:48.750
I mean, when I first used a profile,
that was the first problem I ran

00:29:48.880 --> 00:29:49.940
into when I was new at this.

00:29:49.940 --> 00:29:52.720
And it was like, well, what good is this?

00:29:52.720 --> 00:29:55.260
I can't do anything about C-Live.

00:29:55.260 --> 00:29:56.960
I can't do anything about AppKit.

00:29:56.960 --> 00:29:58.740
I can only do things on my own program.

00:29:58.780 --> 00:30:02.460
So wouldn't it be great to have a
button that goes-- you push this button,

00:30:02.500 --> 00:30:07.040
and all that stuff goes away,
and you see your functions as the leaves,

00:30:07.040 --> 00:30:10.540
and the charge-- the cost of the
system libraries all ascribed to

00:30:10.610 --> 00:30:12.680
various functions in your code.

00:30:12.680 --> 00:30:14.580
Wouldn't that be a lot better?

00:30:14.580 --> 00:30:16.650
I mean, I find that really useful.

00:30:16.670 --> 00:30:19.860
And that's a very coarse operation.

00:30:19.940 --> 00:30:23.920
If you want to do finer-grained stuff,
you could strip away one library.

00:30:23.920 --> 00:30:25.550
Now,
let's say you have any work that you're

00:30:25.560 --> 00:30:29.750
working with the AppKit team or the
Foundation team and say-- so you want

00:30:29.750 --> 00:30:32.060
to see details in those libraries,
but you want to get

00:30:32.060 --> 00:30:33.060
rid of the low levels.

00:30:33.060 --> 00:30:34.600
So you want to get rid
of core foundation.

00:30:34.600 --> 00:30:36.440
You want to get rid of standard lib.

00:30:36.440 --> 00:30:41.360
Exclude by library lets you strip out
a particular library in the trace.

00:30:41.380 --> 00:30:42.780
And this is all non-destructive.

00:30:42.920 --> 00:30:45.180
It gives you a different view on it.

00:30:45.190 --> 00:30:48.930
And you get rid of those libraries,
and it charges the cost up.

00:30:49.220 --> 00:30:52.330
So by transforming the data,
you can focus in on the

00:30:52.330 --> 00:30:54.610
hotspots that you care about.

00:30:54.650 --> 00:30:56.950
This idea of flattened library.

00:30:57.050 --> 00:30:59.560
Instead of just completely
limiting a library,

00:30:59.560 --> 00:31:01.810
you can flatten it to its entry points.

00:31:01.830 --> 00:31:05.100
So you can see where your code is
only calling into these libraries.

00:31:05.160 --> 00:31:08.530
We don't see all the details of how, say,
CFDictionary is implemented,

00:31:08.560 --> 00:31:10.000
because you don't care about that.

00:31:10.000 --> 00:31:13.990
You just care that I'm calling
CFDictionary get value.

00:31:14.560 --> 00:31:19.640
So, to help you see what you want,
use the thing Focus Symbol.

00:31:19.660 --> 00:31:22.140
In Focus Symbol,
you choose a particular call

00:31:22.700 --> 00:31:23.990
tree that you want to look at.

00:31:23.990 --> 00:31:26.230
And when you do that,
you strip away everything that's

00:31:26.270 --> 00:31:27.620
above it or to the sides of it.

00:31:27.660 --> 00:31:30.360
So, I just told you a lot,
and it's kind of thick,

00:31:30.360 --> 00:31:33.970
so I'm going to give you some
pictures to help illustrate this.

00:31:33.980 --> 00:31:37.930
So, here we have a main,
and it calls an init function, you know,

00:31:38.080 --> 00:31:41.540
do example, which does your work,
and some cleanup.

00:31:42.290 --> 00:31:44.520
And then you have this bar function
that's called four times by,

00:31:44.640 --> 00:31:45.680
you know, our function.

00:31:45.680 --> 00:31:47.550
In real programming,
it's probably more like a

00:31:47.550 --> 00:31:49.880
hundred or a thousand times,
but I made it simple here.

00:31:49.880 --> 00:31:54.870
And this, in turn, calls core foundation,
and it's using a CFDictionary get value.

00:31:54.880 --> 00:31:58.930
Now, if I just profile this,
I'll see functions mostly

00:31:59.010 --> 00:32:01.220
from these ones in yellow.

00:32:01.220 --> 00:32:03.670
These are leaf functions,
and they'll be far removed

00:32:03.750 --> 00:32:05.040
from what you care about.

00:32:05.080 --> 00:32:08.310
So, if we do the exclude library,
those go away,

00:32:08.400 --> 00:32:11.080
and now bar becomes our leaf function.

00:32:12.060 --> 00:32:14.760
So, by doing that operation now,
instead of seeing these things are

00:32:14.760 --> 00:32:17.320
removed from what we care about,
we're in what we care about.

00:32:19.000 --> 00:32:21.360
So now, Flatten Library is similar.

00:32:21.490 --> 00:32:22.700
Let's go through this quickly.

00:32:22.730 --> 00:32:25.720
But it replaces the library
with the entry point.

00:32:25.770 --> 00:32:27.410
Focus.

00:32:27.580 --> 00:32:29.140
Do example.

00:32:29.180 --> 00:32:30.860
Strip those away.

00:32:30.890 --> 00:32:32.000
And boom.

00:32:32.080 --> 00:32:34.740
So by doing these transformations,
you can manipulate your qualities.

00:32:34.740 --> 00:32:37.800
And this is also really cool
because you can make really

00:32:37.800 --> 00:32:38.920
good performance arguments.

00:32:38.920 --> 00:32:41.470
When you strip these things away,
you're no longer trying to

00:32:41.470 --> 00:32:44.250
point out something here,
something there, something there,

00:32:44.250 --> 00:32:45.460
and maybe it makes sense.

00:32:45.460 --> 00:32:48.390
You actually see the counts
and the places that matter.

00:32:48.440 --> 00:32:51.320
And you can make really good
arguments to other people that

00:32:51.400 --> 00:32:52.870
we need to work on this stuff.

00:32:52.900 --> 00:32:53.860
We need to fix it.

00:32:53.930 --> 00:32:57.470
So with that, let's go do a little demo.

00:32:57.500 --> 00:32:58.790
Bye now.

00:33:04.900 --> 00:33:09.360
We're going to launch our application,
and we're going to launch Shark.

00:33:09.360 --> 00:33:12.980
Now, how many of you have used
some version of Shark before?

00:33:13.010 --> 00:33:15.160
So about most of you?

00:33:15.190 --> 00:33:16.720
So this is Shark 4.

00:33:16.720 --> 00:33:19.400
And you're going to see a lot
more of it in the Shark session

00:33:19.400 --> 00:33:22.180
later this week on Friday at 3:30.

00:33:22.180 --> 00:33:24.420
But you're going to get
a little preview today.

00:33:24.420 --> 00:33:25.920
The UI is a little bit different.

00:33:25.920 --> 00:33:28.410
The original Shark was a
time-based sampler that lets

00:33:28.460 --> 00:33:29.670
you sample the entire system.

00:33:29.680 --> 00:33:30.760
That's really cool.

00:33:30.760 --> 00:33:33.500
It's good to have it around
in the background and whatnot.

00:33:33.500 --> 00:33:37.120
But in this case,
we want to focus on particular processes.

00:33:37.120 --> 00:33:39.540
And there's a number of
different things we can do.

00:33:39.540 --> 00:33:42.540
We can trace memory allocations,
function traces.

00:33:42.540 --> 00:33:46.210
We can trace various
Java things if you do Java.

00:33:46.220 --> 00:33:48.710
And for this application,
we're going to use what's

00:33:48.710 --> 00:33:51.200
called a sampler time profile.

00:33:51.200 --> 00:33:55.020
We choose this because the program
uses file system operations.

00:33:55.020 --> 00:33:57.300
And this involves a lot
of waiting on the kernel.

00:33:57.300 --> 00:33:59.560
And this trace does the best
job of attributing those

00:33:59.720 --> 00:34:02.100
costs to the user calls.

00:34:02.100 --> 00:34:03.480
So let's go over to our application.

00:34:03.500 --> 00:34:04.750
.

00:34:06.780 --> 00:34:08.260
And do Open Recent.

00:34:08.260 --> 00:34:11.450
And Shark gives you this
Option Escape hotkey,

00:34:11.620 --> 00:34:12.340
which is really handy.

00:34:12.420 --> 00:34:14.200
So I'm in the middle
of the UI manipulating,

00:34:14.200 --> 00:34:16.580
and I can hit Option Escape and do Start.

00:34:16.610 --> 00:34:18.730
So we're going to start our scan.

00:34:18.980 --> 00:34:21.720
And this stops every thread
and records a sample,

00:34:21.720 --> 00:34:27.230
whether it's doing something or
it's waiting on a kernel call.

00:34:27.370 --> 00:34:29.450
Now that it's done, we stop.

00:34:31.220 --> 00:34:33.140
And we have a heavy view.

00:34:33.140 --> 00:34:36.200
This is a view of all the leaf functions,
as I've been talking about,

00:34:36.200 --> 00:34:38.640
and the relative percentage
of the counts that we're in.

00:34:38.660 --> 00:34:42.170
So we click on this
syscall thread switch,

00:34:42.170 --> 00:34:44.840
and on the right here,
this is one of the nice new features,

00:34:44.840 --> 00:34:47.700
is you can see a backtrace
of that particular similar.

00:34:47.700 --> 00:34:50.610
So we see that we're
in a heartbeat thread.

00:34:50.640 --> 00:34:52.210
Well, that's not very interesting.

00:34:52.210 --> 00:34:53.900
It's sleeping, sleeping until date.

00:34:55.340 --> 00:34:57.850
So in this case,
let's get rid of that thread.

00:34:57.860 --> 00:35:00.230
So we're going to go down to
the thread pop-up here and

00:35:00.420 --> 00:35:02.300
choose one of the threads.

00:35:02.340 --> 00:35:04.680
And it's going to give us the
one that we're interested in.

00:35:04.780 --> 00:35:07.240
So the topmost function
here is get adder list.

00:35:07.320 --> 00:35:11.250
And this gives you a very
large call stack to look at.

00:35:11.280 --> 00:35:13.610
Now,
to help us navigate things a little bit,

00:35:13.620 --> 00:35:16.860
there's a nice little thing over
here called color by library.

00:35:16.880 --> 00:35:19.310
And when you click that,
some of you may remember

00:35:19.390 --> 00:35:20.410
this from Sampler.

00:35:20.480 --> 00:35:21.980
That feature was in there.

00:35:22.820 --> 00:35:26.710
And now we see that we've colored
things by different colors.

00:35:26.740 --> 00:35:30.610
So lib system is lavender,
comp page is red,

00:35:30.610 --> 00:35:33.040
disk inventory is brown.

00:35:33.040 --> 00:35:35.820
And this just helps us make a
little more sense of it visually

00:35:35.820 --> 00:35:37.500
without spending a lot of time.

00:35:37.500 --> 00:35:38.640
Let me make this a little bigger.

00:35:41.240 --> 00:35:42.970
So we click on Get Adder List.

00:35:42.970 --> 00:35:44.930
We see that, yes, we're in user code.

00:35:44.940 --> 00:35:47.750
This fsitem load childs is our own thing.

00:35:47.890 --> 00:35:50.920
But let's use the exclude
library operation.

00:35:51.040 --> 00:35:53.070
We're going to exclude libsystembdlib.

00:35:53.070 --> 00:35:57.230
And when that happens,
that goes away and we see that a fair

00:35:57.230 --> 00:36:00.230
amount of time is spent in CarbonCore.

00:36:00.380 --> 00:36:01.420
So we're going to do this again.

00:36:01.420 --> 00:36:04.300
We're going to exclude
library CarbonCore.

00:36:04.300 --> 00:36:06.690
And we'll do this a few more times.

00:36:08.650 --> 00:36:11.340
So there,
one piece of user code comes up.

00:36:11.340 --> 00:36:17.710
Let's do core foundation
and launch services.

00:36:20.150 --> 00:36:25.660
And you see that this FS item load
properties and this load child

00:36:25.930 --> 00:36:30.860
are all floating up as pretty
major players in this profile.

00:36:30.860 --> 00:36:33.360
Before we go in and look at
those in a little more detail,

00:36:33.370 --> 00:36:35.120
let's go over to the heavy and tree view.

00:36:35.120 --> 00:36:36.590
This is another new feature in Shark.

00:36:36.600 --> 00:36:39.220
It lets you see both the
heavy and the tree view,

00:36:39.220 --> 00:36:41.840
the top-down view, simultaneously.

00:36:41.920 --> 00:36:44.640
So in the top-down view,
we start at the start of our program,

00:36:44.800 --> 00:36:46.580
kind of like that diagram I showed you.

00:36:46.610 --> 00:36:50.180
And you walk down through your
program until you get to our code.

00:36:50.200 --> 00:36:52.140
But there's still a problem.

00:36:52.150 --> 00:36:56.020
You've probably seen this before, too,
that there are all these app kit calls.

00:36:56.020 --> 00:36:58.900
There's all these system calls that
makes it kind of hard to look around.

00:36:58.910 --> 00:37:01.520
If you expand one of these trees,
the outline will be awfully

00:37:01.880 --> 00:37:03.920
big and hard to keep track of.

00:37:04.020 --> 00:37:06.000
So we're in luck.

00:37:06.030 --> 00:37:10.040
There's a button over here
called Flatten System Libraries,

00:37:10.040 --> 00:37:13.800
which does that flatten operation
in all the system libraries.

00:37:13.820 --> 00:37:16.350
And when we do that now,

00:37:16.640 --> 00:37:19.260
This guy simplifies,
and it's a lot more manageable.

00:37:19.260 --> 00:37:21.940
There's only a few layers of these calls,
so it gives us context.

00:37:21.940 --> 00:37:23.700
You could also exclude
them if you wanted to.

00:37:23.700 --> 00:37:26.100
But in this case,
I just thought it was useful to

00:37:26.170 --> 00:37:27.910
help me keep track of where I was.

00:37:27.920 --> 00:37:33.520
But then we'll notice another problem,
which is we just expanded

00:37:33.520 --> 00:37:35.740
this recursive call to load.

00:37:35.780 --> 00:37:39.130
This is a file system application,
so it's very natural to write

00:37:39.130 --> 00:37:40.620
it in a recursive style.

00:37:40.620 --> 00:37:44.700
But if any of you have tried to analyze
performance on a recursive function,

00:37:44.700 --> 00:37:46.200
it's rather difficult.

00:37:46.600 --> 00:37:51.100
Because at each layer of the recursion,
you may call out to a branch function.

00:37:51.100 --> 00:37:55.640
And each of them individually will show
up as relatively small contributors.

00:37:55.640 --> 00:37:59.690
But there's no way to kind of
gather them together and focus them.

00:37:59.720 --> 00:38:06.540
So for example,
this FS item path shows up as 0.1% here,

00:38:06.740 --> 00:38:09.720
0.1% here at different levels.

00:38:09.720 --> 00:38:12.780
But it's kind of hard to determine
if that means anything or not.

00:38:12.800 --> 00:38:16.360
But luckily, there's another option here
called flatten recursion.

00:38:17.730 --> 00:38:21.340
We click on that and look what happens.

00:38:21.380 --> 00:38:25.840
LoadChild becomes a single
thing and look at that.

00:38:25.840 --> 00:38:30.600
A knit with name parent suddenly
pops up to 43% of the overall time.

00:38:30.600 --> 00:38:33.910
So by using this data mining,
we're getting past the

00:38:34.060 --> 00:38:36.840
obstacles and getting to the
parts that are interesting.

00:38:37.010 --> 00:38:40.840
And by the way, with the Shark 4 download
that Dave mentioned,

00:38:41.010 --> 00:38:43.490
there's actually a nice tutorial
that you can go through that will

00:38:43.500 --> 00:38:44.600
walk you through these things.

00:38:44.630 --> 00:38:48.600
You don't have to remember
everything I'm going through today.

00:38:48.600 --> 00:38:51.640
So let's double click on
a knit name with parent.

00:38:57.840 --> 00:38:59.300
and Pray to the Demo Gods.

00:38:59.300 --> 00:38:59.750
There we go.

00:38:59.800 --> 00:39:09.300
So this shows you source now,
annotated with percentages of time.

00:39:09.300 --> 00:39:11.600
Those of you who've seen
Shark have seen this before.

00:39:11.620 --> 00:39:14.130
But there's a couple new
things that are really cool.

00:39:14.140 --> 00:39:17.300
You notice that various
symbols are underlined.

00:39:17.350 --> 00:39:21.860
So that means you can follow that link,
just like in a web browser.

00:39:21.900 --> 00:39:23.980
So if we double-click
on self-load properties,

00:39:23.980 --> 00:39:27.520
which is our heaviest line,
we go to another source file.

00:39:28.150 --> 00:39:30.870
And you can navigate forward and back.

00:39:30.880 --> 00:39:35.000
And this way you can move around
and explore your performance problem

00:39:35.000 --> 00:39:37.500
in a way that's much more concrete,
at least it is to me.

00:39:37.510 --> 00:39:39.690
I mean,
isn't it better to deal with source than

00:39:39.690 --> 00:39:41.500
to deal with these trees of symbols?

00:39:41.650 --> 00:39:44.000
So I found this really a nice feature.

00:39:44.000 --> 00:39:45.410
So now we can look at our problem.

00:39:45.860 --> 00:39:48.000
This class is an FS item.

00:39:48.000 --> 00:39:51.490
Even its name suggests that it's
something you do on every file

00:39:51.490 --> 00:39:55.000
system item that you encounter as you
iterate through these directories.

00:39:55.160 --> 00:40:00.000
And if you look at the details here,
it does an fs_path_make_ref.

00:40:00.130 --> 00:40:01.770
It does file attributes at path.

00:40:01.770 --> 00:40:05.000
It does fs_get_catalog_info.

00:40:05.000 --> 00:40:06.320
So there's a bunch of these.

00:40:06.370 --> 00:40:08.000
It's only about five operations.

00:40:08.000 --> 00:40:09.900
And if I look elsewhere,
there'd be even a sixth

00:40:10.510 --> 00:40:14.000
operation that we're doing for
every file in the directory.

00:40:14.150 --> 00:40:17.990
Now, Dave, there are bulk file system
operations that we support.

00:40:18.150 --> 00:40:20.000
They're really cool.

00:40:20.000 --> 00:40:22.230
And you can reduce this from
doing this for every file to just

00:40:22.630 --> 00:40:24.000
doing it for every directory.

00:40:24.000 --> 00:40:27.000
And this should give you
a really nice speedup.

00:40:27.100 --> 00:40:31.930
So please consider using that, you know,
in optimizing your program.

00:40:32.520 --> 00:40:35.560
So while Dave's off working on that,
I'm going to show you

00:40:35.630 --> 00:40:40.460
some function tracing.

00:40:42.440 --> 00:40:44.910
You know,
I just showed you data mining and how to

00:40:44.910 --> 00:40:46.900
analyze your program using data mining.

00:40:46.950 --> 00:40:49.300
Now I'm going to show
you graphical analysis.

00:40:49.300 --> 00:40:52.420
You know, using this feature
called function tracing,

00:40:52.420 --> 00:40:56.290
you can specify a list of functions
that will let you do an exact trace

00:40:56.290 --> 00:40:57.300
of the functions that are called.

00:40:57.300 --> 00:41:01.300
So I can choose function trace,
and there's some presets down here.

00:41:01.300 --> 00:41:04.300
And you can also enter your own if you
have a set that you particularly like.

00:41:04.300 --> 00:41:06.140
So I'm going to do file I/O.

00:41:06.140 --> 00:41:08.300
And this gives you a list
of file I/O functions.

00:41:08.300 --> 00:41:10.300
It's a little bit hard to read,
but these are just the

00:41:10.300 --> 00:41:12.260
standard Unix file calls.

00:41:12.300 --> 00:41:16.130
And I already made a preset
here called file I/O.

00:41:16.260 --> 00:41:17.290
So we're going to choose that.

00:41:17.300 --> 00:41:20.300
And go back to our program.

00:41:20.300 --> 00:41:22.120
Open recent.

00:41:22.230 --> 00:41:24.110
Start recording.

00:41:24.110 --> 00:41:29.720
And this time... Oh.

00:41:33.840 --> 00:41:35.800
Okay, we'll just have to do this again.

00:41:35.800 --> 00:41:42.370
That's the nice thing about
Shark is it's pretty forgiving.

00:41:44.880 --> 00:41:47.520
So we've-- and when
you do an exact trace,

00:41:47.550 --> 00:41:50.270
you want to do it for a
relatively short time,

00:41:50.270 --> 00:41:54.560
or you might wind up with hundreds of
thousands or even millions of samples.

00:41:54.560 --> 00:41:58.160
Even in that short time,
we got 60,000 samples.

00:41:58.170 --> 00:42:00.160
And this is kind of a cool view.

00:42:00.180 --> 00:42:03.810
You get a distribution of different
file system calls and the percentage

00:42:03.870 --> 00:42:05.160
of time that you've used them.

00:42:05.210 --> 00:42:08.260
So it gives you a hint of
what your program is doing.

00:42:08.280 --> 00:42:10.150
But there's an even better
thing we can look at here.

00:42:10.330 --> 00:42:12.310
Let's go to the chart.

00:42:13.190 --> 00:42:16.920
And in the chart here--
let me do one thing.

00:42:16.950 --> 00:42:18.880
So I get selections out of the way.

00:42:18.880 --> 00:42:20.910
Here in the chart,
you see that there's this

00:42:20.910 --> 00:42:22.400
kind of wavy pattern.

00:42:22.400 --> 00:42:26.020
And let's just zoom into it a little bit,
like here.

00:42:26.230 --> 00:42:27.640
And this is a new feature.

00:42:27.640 --> 00:42:29.740
This is a really nice zoom control.

00:42:29.740 --> 00:42:32.200
As you drag along,
you can zoom in and out,

00:42:32.200 --> 00:42:33.460
just like we did in that movie.

00:42:33.460 --> 00:42:34.540
That movie wasn't fake.

00:42:34.540 --> 00:42:39.100
It was just filmed from
the actual live program.

00:42:39.150 --> 00:42:41.460
So we go in here,
and we see this thing that looks

00:42:41.650 --> 00:42:43.060
like we're iterating over files.

00:42:43.060 --> 00:42:44.240
It's kind of different levels.

00:42:44.310 --> 00:42:47.690
If you look in a finder outline view,
you'll see that it's a

00:42:47.690 --> 00:42:49.020
similar kind of pattern.

00:42:49.030 --> 00:42:52.030
And you'll see that load child
shows up in the stack here.

00:42:52.140 --> 00:42:55.020
So let's just do flatten recursion.

00:42:55.250 --> 00:43:00.920
And look what it does,
is it completely flattens out our trace.

00:43:01.050 --> 00:43:04.240
And we come down here and
we find a fingerprint.

00:43:04.270 --> 00:43:07.290
This little shape here is very redundant.

00:43:07.580 --> 00:43:10.380
It occurs over and over again,
even in this little thing.

00:43:10.440 --> 00:43:14.150
And that happens to be in load child,
a knit name with parent,

00:43:14.150 --> 00:43:15.870
and then load properties.

00:43:16.170 --> 00:43:19.840
So we found our culprit with
graphical analysis very quickly.

00:43:19.940 --> 00:43:22.240
So use both techniques.

00:43:22.290 --> 00:43:25.700
If you have an idea of what
functions are expensive already,

00:43:25.750 --> 00:43:27.960
you can do a function trace.

00:43:28.010 --> 00:43:31.380
You know, if you need to figure out
what areas are expensive,

00:43:31.460 --> 00:43:34.300
do time tracing and use
call stack data mining.

00:43:34.360 --> 00:43:36.960
Okay, back to you, Dave.

00:43:46.800 --> 00:43:48.800
Okay, praying to the audio gods.

00:43:48.800 --> 00:43:50.030
Excellent, excellent.

00:43:50.150 --> 00:43:52.040
Good job, thanks.

00:43:52.050 --> 00:43:53.790
Okay, moving on.

00:43:53.800 --> 00:43:57.980
So I did my homework while
Christy was speaking.

00:43:58.030 --> 00:44:00.070
And what I've learned here,
I studied the app.

00:44:00.100 --> 00:44:04.520
In each directory,
we're making a directory

00:44:04.600 --> 00:44:08.700
contents at path call to say,
enumerate all the files and

00:44:08.700 --> 00:44:11.060
folders in this directory.

00:44:11.060 --> 00:44:14.680
Then for each one of those items,
let's go through and do a number

00:44:14.680 --> 00:44:18.360
of things to gather the information
that the program wants to display.

00:44:18.570 --> 00:44:22.340
So again, I'm getting an FS ref for
each item so that I can make

00:44:22.340 --> 00:44:24.620
additional calls with that.

00:44:24.630 --> 00:44:28.420
I want to know whether it's a folder
or a file or a symlink because

00:44:28.420 --> 00:44:32.660
I don't want to navigate the symlink
to duplicate the representation

00:44:32.660 --> 00:44:34.800
of the space taken by the file.

00:44:34.960 --> 00:44:37.950
So I make an attributes
at path call on that.

00:44:37.950 --> 00:44:43.650
I want to get the file sizes,
so the data fork and the resource fork,

00:44:43.650 --> 00:44:46.560
and also the parent ID to see
if I'm on the same volume.

00:44:46.600 --> 00:44:50.840
I don't want to walk off
to multiple volumes here.

00:44:50.840 --> 00:44:56.040
So I'm making a FS get
catalog info call on that.

00:44:56.170 --> 00:44:59.340
And finally,
when it's doing that classifying files,

00:44:59.450 --> 00:45:03.800
it's saying I want to get the kind
string as represented in the finder.

00:45:03.800 --> 00:45:06.760
So if it's a .nib file,
we want to show that as

00:45:07.130 --> 00:45:09.200
interface builder document.

00:45:09.200 --> 00:45:13.440
So for each FS ref,
we end up calling down to launch services

00:45:13.440 --> 00:45:16.440
saying get me the kind string for this.

00:45:16.580 --> 00:45:19.820
And then we're going to
call the FS ref this file.

00:45:19.820 --> 00:45:23.960
So having done my homework,
I did learn about the FS get

00:45:23.960 --> 00:45:26.620
catalog info bulk call.

00:45:26.620 --> 00:45:29.160
So what this does is it's optimized.

00:45:29.160 --> 00:45:33.330
I can say for X number of files,
I can specify how many

00:45:33.330 --> 00:45:35.540
I want in a given directory.

00:45:35.550 --> 00:45:38.610
I'm looking for a set
of information here.

00:45:38.640 --> 00:45:43.520
I want to get the bit that says
is it a directory or is it a file.

00:45:43.520 --> 00:45:46.300
I want to get the parent directory ID.

00:45:46.320 --> 00:45:46.320
I want to get the directory ID.

00:45:46.320 --> 00:45:49.040
I want to get the resource
and data fork sizes.

00:45:49.060 --> 00:45:52.280
I want to get the type
and creator information.

00:45:52.280 --> 00:45:55.560
And we'll see what I'll do
with that in the next slide.

00:45:55.560 --> 00:45:59.920
And then I want to get just the full
array of FS refs for all the individual

00:46:00.500 --> 00:46:03.760
items and the full array of entry names.

00:46:03.760 --> 00:46:09.130
So I get arrays of all this
from one call that before I was

00:46:09.840 --> 00:46:12.780
making lots of file system calls.

00:46:13.400 --> 00:46:18.430
So in the classifying files, so again,
what we were doing was hitting the

00:46:18.430 --> 00:46:23.460
file system once for each file to say,
give me the kind name for this.

00:46:23.490 --> 00:46:28.660
And then the way the code was written,
it's actually storing that kind string

00:46:28.660 --> 00:46:31.340
for each individual different file.

00:46:32.120 --> 00:46:35.300
But if we step back and think about it,
I just don't have that many

00:46:35.300 --> 00:46:37.790
different kinds of files.

00:46:37.790 --> 00:46:39.980
And I really don't
need to query the file,

00:46:40.060 --> 00:46:41.900
you know, about the specific file.

00:46:41.900 --> 00:46:43.360
What I care about is the kind.

00:46:43.360 --> 00:46:46.590
And the information that
specifies the kind is the type,

00:46:46.590 --> 00:46:48.510
the creator and the extension.

00:46:49.220 --> 00:46:53.000
So I can build a dictionary
to map this triplet of type,

00:46:53.000 --> 00:46:56.760
creator,
extension to the file name kind string.

00:46:56.760 --> 00:47:00.670
So I actually put all of those into
a string and just make it unique,

00:47:00.730 --> 00:47:03.860
use that as a key into an
NSDictionary to do a lookup.

00:47:03.940 --> 00:47:06.570
Now,
if I don't find it in the cache there,

00:47:06.570 --> 00:47:09.720
I can make a different
launch services call to say,

00:47:09.720 --> 00:47:14.310
given this triplet of information,
look up the kind string for that.

00:47:14.310 --> 00:47:16.630
Now,
that's not even hitting the file system,

00:47:16.630 --> 00:47:17.160
right?

00:47:17.160 --> 00:47:19.040
So I'm going down from an order.

00:47:19.220 --> 00:47:23.590
I'm going down from an operation
here for once for each file down

00:47:23.590 --> 00:47:25.920
to zero file system accesses.

00:47:26.160 --> 00:47:30.410
And I'm also only storing the kind
string for each different kind,

00:47:30.410 --> 00:47:31.830
not once per file.

00:47:31.950 --> 00:47:34.900
So I'm also significantly
reducing my memory use.

00:47:34.900 --> 00:47:37.770
So before I show the results,
let's see if there's anything

00:47:37.770 --> 00:47:40.580
else that we can determine
from the application here.

00:47:40.930 --> 00:47:45.340
So let's do a memory analysis demo.

00:47:46.240 --> 00:47:52.060
So let's go ahead and quit out of the app
and bring up our performance tools again.

00:47:52.060 --> 00:47:55.200
So let me also point out Shark is
now up here in the performance tools.

00:47:55.200 --> 00:47:56.840
It used to be down in the chud folder.

00:47:56.880 --> 00:48:00.020
Now it's really going mainstream here.

00:48:00.260 --> 00:48:01.850
So let's look at ObjectAlloc, though.

00:48:02.110 --> 00:48:04.000
So we double click on that.

00:48:04.020 --> 00:48:08.350
What we do here is we launch our target
application from within ObjectAlloc,

00:48:08.350 --> 00:48:11.960
because it needs to set up
some of the environment for it.

00:48:12.030 --> 00:48:15.600
So with this, I simply hit Go.

00:48:15.610 --> 00:48:18.140
And what I want is to
keep the backtraces.

00:48:18.140 --> 00:48:22.780
I could keep reference counts on objects,
but I don't need that in this situation.

00:48:22.780 --> 00:48:25.000
So it goes ahead and launches the app.

00:48:25.000 --> 00:48:26.980
Hasn't done too much yet.

00:48:26.980 --> 00:48:31.730
I'm going to change the scale here,
because I might have a lot of objects.

00:48:31.980 --> 00:48:35.960
And we'll see that this
application is doing live updates.

00:48:35.960 --> 00:48:41.440
Let's go ahead and walk
that folder hierarchy again.

00:48:41.440 --> 00:48:48.110
As we go through,
we see-- let's do an auto sort.

00:48:51.030 --> 00:48:54.640
We see that we're building
up a lot of CFStrings.

00:48:54.640 --> 00:48:56.910
These are currently allocated items.

00:48:57.120 --> 00:48:58.800
We're building up a lot of FS items.

00:48:59.110 --> 00:49:00.900
Now those make sense, kind of.

00:49:00.900 --> 00:49:03.810
FS item, I'm getting one for
each file system item.

00:49:03.810 --> 00:49:08.100
The CFString is actually the name
for that particular file system item,

00:49:08.210 --> 00:49:09.740
so that's being stored.

00:49:09.740 --> 00:49:11.280
So that's kind of useful.

00:49:11.280 --> 00:49:14.730
I can see the peak amount,
how many has been the peak of

00:49:14.730 --> 00:49:18.970
any particular type that I had,
and I can see the total amount.

00:49:19.670 --> 00:49:23.980
And you saw again,
live update and auto sorting.

00:49:24.130 --> 00:49:27.900
So if I go to total,
this is really interesting.

00:49:27.900 --> 00:49:30.580
We see the different
colors of the bars here.

00:49:30.680 --> 00:49:33.530
What the red bars indicate,
as opposed to blue,

00:49:33.610 --> 00:49:37.600
is the percentage of objects
that you have left remaining.

00:49:37.600 --> 00:49:41.990
What's the current number of objects
versus the total you've allocated?

00:49:42.470 --> 00:49:46.210
Red means that you have less
than 10% of them remaining,

00:49:46.280 --> 00:49:50.280
so maybe you've got a dynamic
memory issue there of creating more

00:49:50.290 --> 00:49:51.590
of them than you actually need.

00:49:51.600 --> 00:49:55.600
Yellow means, I believe,
it's 25% or a third.

00:49:55.600 --> 00:50:00.520
So the bright color indicates the
number that's currently allocated,

00:50:00.600 --> 00:50:03.570
so we can see that we have
a lot of CFStrings still.

00:50:03.600 --> 00:50:09.370
We had a little bit more peak,
and we had more total that we got rid of.

00:50:09.820 --> 00:50:11.600
But what's this NSPath store?

00:50:11.600 --> 00:50:14.600
We can see that we've
got 24 of them left,

00:50:14.600 --> 00:50:20.080
but we allocated 180,000 of
them in going through this.

00:50:20.100 --> 00:50:21.100
What's up with that?

00:50:21.100 --> 00:50:25.400
I can actually double-click
on this and get an allocation

00:50:25.540 --> 00:50:31.090
chart and see what the dynamic
allocation pattern looked like here.

00:50:31.100 --> 00:50:35.900
So it kind of looks almost like this
might have been walking the file system

00:50:36.050 --> 00:50:39.100
hierarchy and we're doing something here.

00:50:39.140 --> 00:50:43.100
It looks similar to some of the
patterns that Christy showed in Sampler.

00:50:43.140 --> 00:50:47.680
I can go in and look at specific
instances of these objects.

00:50:47.790 --> 00:50:50.980
And where they're allocated
and what the contents are,

00:50:50.980 --> 00:50:55.200
we can see this is Twitter library fonts,
another path there.

00:50:55.200 --> 00:50:59.130
I can look at call stacks,
go down through,

00:50:59.210 --> 00:51:00.350
descend the maximum path.

00:51:02.730 --> 00:51:10.460
Another thing I can do is I can
set a mark and say I'm only

00:51:11.080 --> 00:51:20.970
interested in seeing the number
of objects since the mark.

00:51:20.970 --> 00:51:20.970
If I do the show package contents,
we see that I can just watch

00:51:20.970 --> 00:51:20.970
how many objects are created
during that operation there.

00:51:21.310 --> 00:51:28.590
So you can get a lot of information
about your application here through this.

00:51:28.600 --> 00:51:32.090
What I want to do here is go
back in and look at-- now,

00:51:32.090 --> 00:51:36.050
you'll notice that it actually took a lot
longer to run under Object Alloc because

00:51:36.050 --> 00:51:37.440
of the amount of time it was taking.

00:51:37.440 --> 00:51:41.760
So don't do time analysis
while you're doing this.

00:51:41.760 --> 00:51:46.220
But let's go back in and do
some memory analysis with Shark.

00:51:48.200 --> 00:51:53.870
So I'm going to switch to the
MallocTrace operation and start

00:51:54.000 --> 00:51:59.740
up Disk Inventory again and
select the Disk Inventory process.

00:52:00.370 --> 00:52:05.730
So going back to disk inventory,
let's now--

00:52:05.780 --> 00:52:08.200
Look at apps once again.

00:52:08.240 --> 00:52:13.250
And like Christy did,
I'll start the sampling and stop it.

00:52:22.050 --> 00:52:25.830
And I'm actually going
to jump directly-- well,

00:52:25.830 --> 00:52:26.280
that's right.

00:52:26.320 --> 00:52:28.580
First off, I wanted to show that
with the value here,

00:52:28.660 --> 00:52:31.130
if I switch to value,
you can actually see in the call

00:52:31.130 --> 00:52:36.420
tree the amount of memory that was
allocated by the various calls here.

00:52:36.740 --> 00:52:41.670
And I could exclude everything that
I don't have source code for and get

00:52:41.790 --> 00:52:49.390
down to just seeing the stuff that I do
and where that allocation is going.

00:52:49.840 --> 00:52:51.700
So that's fairly interesting.

00:52:51.700 --> 00:52:54.260
Let's go directly over to the chart view.

00:52:54.260 --> 00:52:57.180
Remove the exclude no source.

00:52:57.350 --> 00:53:00.000
And we can see from the chart
here that again this looks like

00:53:00.000 --> 00:53:01.890
we have some interesting patterns.

00:53:01.890 --> 00:53:05.860
So let's just click on one
of these and that might be

00:53:05.860 --> 00:53:07.270
potentially interesting there.

00:53:07.520 --> 00:53:11.600
Let's zoom in a little bit,
see what we might see.

00:53:11.650 --> 00:53:14.310
Zoom, zoom, zoom.

00:53:14.310 --> 00:53:18.160
Interesting little
sawtooth patterns here.

00:53:18.560 --> 00:53:21.940
So if I click on this,
we see a number of different

00:53:22.040 --> 00:53:25.250
allocations of paths,
and I can just use the

00:53:25.250 --> 00:53:28.790
cursor keys to move through.

00:53:29.220 --> 00:53:32.730
So it looks like, in fact, from the code,

00:53:32.830 --> 00:53:36.800
As I'm walking down through
the file system hierarchy,

00:53:36.940 --> 00:53:40.420
the way the code was written was
that when I got to each FS item,

00:53:40.420 --> 00:53:44.230
it was making several calls to say,
"Well, I need to know the path right

00:53:44.230 --> 00:53:47.970
here." I'm being a good citizen
for memory and I'm not storing

00:53:47.970 --> 00:53:49.960
the full path with each object.

00:53:50.160 --> 00:53:51.580
That would be overkill.

00:53:51.580 --> 00:53:53.260
That's too much memory use.

00:53:53.400 --> 00:53:55.210
So I'll dynamically ask for it.

00:53:55.380 --> 00:53:58.760
So I'll get my path by asking
what my parent folder is and

00:53:59.050 --> 00:54:01.260
then appending my name to it.

00:54:01.430 --> 00:54:04.960
But my parent says, "Well,
what's my name?" Let me ask my parent

00:54:04.960 --> 00:54:06.830
and then append my name to that.

00:54:07.020 --> 00:54:08.450
And up we go.

00:54:08.670 --> 00:54:14.430
So that's dynamically creating
lots of auto-released NSPath store

00:54:14.430 --> 00:54:16.940
to string objects with Cocoa.

00:54:17.110 --> 00:54:22.520
And then the next thing that we see
happening is then we spend a bunch

00:54:22.520 --> 00:54:26.710
of time actually auto-releasing that.

00:54:26.920 --> 00:54:28.920
We can see the auto-release time there.

00:54:28.990 --> 00:54:32.330
So you can see the impact
of too much memory use.

00:54:32.460 --> 00:54:36.200
So since I'm recursively descending
down through the file system,

00:54:36.200 --> 00:54:38.280
I should be able to, at each level, say,
well,

00:54:38.280 --> 00:54:39.890
this is the path that I'm currently at.

00:54:39.950 --> 00:54:43.100
And when I go down into the
next directory level deeper,

00:54:43.110 --> 00:54:46.700
just append the path part to
that and pass that down through.

00:54:46.700 --> 00:54:50.130
I don't have to recursively go
back up every file system item.

00:54:50.130 --> 00:54:53.800
So that significantly reduced
the amount of memory we're using.

00:54:54.660 --> 00:54:58.890
So now let's go back through and say, OK,
that's all good.

00:54:58.890 --> 00:55:00.290
Did we have any results?

00:55:00.660 --> 00:55:05.070
Well, I was busy coding away and
slapped a new binary up here.

00:55:05.130 --> 00:55:09.030
So let me dynamically
enable some optimizations.

00:55:09.030 --> 00:55:11.020
And let's try it again.

00:55:12.210 --> 00:55:13.390
So off we go.

00:55:13.640 --> 00:55:15.580
Boom.

00:55:15.580 --> 00:55:19.200
OK, so what are my test results here?

00:55:19.660 --> 00:55:23.600
The folder scanning that before
took over 10 seconds in this case,

00:55:23.600 --> 00:55:28.850
about 9 seconds before,
is now a little less than 2 seconds.

00:55:28.930 --> 00:55:32.590
Remember this is from vastly reducing
the number of file system operations.

00:55:32.640 --> 00:55:37.180
The classifying files that
again was asking for the file

00:55:37.260 --> 00:55:41.600
kind string for each file,
that's down to virtually instantaneous

00:55:41.600 --> 00:55:45.600
because you'll remember I'm doing
no file system calls there now.

00:55:45.670 --> 00:55:49.650
And if I do this show
package contents operation,

00:55:49.750 --> 00:55:55.600
boom again, 0.16 whereas before it
was about 4 seconds.

00:55:55.660 --> 00:55:59.370
So we can see that we've
significantly reduced the amount

00:55:59.400 --> 00:56:01.600
of time the program is taking.

00:56:01.600 --> 00:56:04.520
Let's switch back to slides please.

00:56:05.920 --> 00:56:09.300
So to summarize,
what the tools helped me do is figure out

00:56:09.390 --> 00:56:13.000
that I should use bulk file system calls,
and there's documentation about this.

00:56:13.000 --> 00:56:17.320
I actually copied much of the code
from the performance documentation.

00:56:17.370 --> 00:56:22.110
I used caching of the file kind
strings so I could just do rapid

00:56:22.160 --> 00:56:25.460
lookups and not query the file system.

00:56:25.830 --> 00:56:31.720
That helps me reduce my storage
for the file kind strings.

00:56:32.110 --> 00:56:35.630
I talked about reducing the
dynamic creation of the path

00:56:35.630 --> 00:56:37.440
strings as we go through.

00:56:37.490 --> 00:56:42.170
And then as you go through, you know,
optimization is an iterative process,

00:56:42.380 --> 00:56:42.550
right?

00:56:42.800 --> 00:56:46.410
You've got a hotspot, so you go in,
you tune that, you make that faster,

00:56:46.490 --> 00:56:48.780
and now you've got a different hotspot.

00:56:48.880 --> 00:56:51.450
So it was actually interesting
to discover that once we made the

00:56:51.590 --> 00:56:56.130
file system accesses a lot faster,
that the way it was updating the UI for

00:56:56.240 --> 00:56:59.600
feedback about what it was doing,
display this path, display this path,

00:56:59.740 --> 00:57:02.060
display this path,
was actually starting to take place.

00:57:02.090 --> 00:57:03.760
And it took a fair amount of time.

00:57:03.780 --> 00:57:08.690
And so I just display fewer paths because
all you want to know is where you are.

00:57:08.940 --> 00:57:12.410
And so that made things faster
also because that's not an

00:57:12.520 --> 00:57:14.690
important part of my process here.

00:57:14.830 --> 00:57:17.340
So we made significant improvement here.

00:57:17.340 --> 00:57:19.380
This is the measurements
I got in the lab,

00:57:19.380 --> 00:57:21.540
again, on somewhat slower hardware.

00:57:21.570 --> 00:57:25.990
We ended up making the file system
traversal seven times faster.

00:57:26.370 --> 00:57:31.970
Classifying file kinds, you know,
depends on the size of your file system.

00:57:32.110 --> 00:57:34.600
But that's like infinitely faster.

00:57:34.600 --> 00:57:37.610
Much faster showing file
contents for a total of,

00:57:37.920 --> 00:57:39.540
call it, ten times faster.

00:57:39.700 --> 00:57:44.220
So now this starts to get to be
a more useful application for me.

00:57:44.640 --> 00:57:47.210
So we've covered a lot
of things here today,

00:57:47.250 --> 00:57:49.290
a lot of tools, a lot of techniques.

00:57:49.310 --> 00:57:54.090
We have a lot of documentation about
this on the system for both of these.

00:57:54.220 --> 00:57:58.420
Plus the tools have documentation
in them and with them.

00:57:58.490 --> 00:58:02.090
There's man pages for
the command line tools.

00:58:02.470 --> 00:58:07.600
And so in conclusion,
we've seen we have some powerful tools

00:58:07.640 --> 00:58:11.690
that help you both monitor to see if
you've got performance problems and

00:58:11.690 --> 00:58:13.770
then analyze what the problems are.

00:58:13.780 --> 00:58:18.500
We've put a lot of work into Shark,
working with Nathan and Sanjay,

00:58:18.500 --> 00:58:23.570
doing a very collaborative effort
here to try to improve both the power,

00:58:23.570 --> 00:58:27.110
add more new features,
but make it easier to approach

00:58:27.110 --> 00:58:29.120
and understand at the same time.

00:58:29.120 --> 00:58:31.080
So we need to know how we're doing.

00:58:31.720 --> 00:58:33.220
You know, does this work for you?

00:58:33.220 --> 00:58:37.880
If I remove sampler from the systems,
is that going to cause you a problem?

00:58:37.900 --> 00:58:39.420
So download the beta.

00:58:39.420 --> 00:58:40.960
Please send us your feedback.

00:58:40.960 --> 00:58:44.010
So I'm going to bring
Xavier Legros on stage,

00:58:44.010 --> 00:58:47.670
who's our Mac OS X technology
evangelist for this.

00:58:47.680 --> 00:58:51.110
This is a feedback list that
you can send information,

00:58:51.110 --> 00:58:52.880
feedback about this too.