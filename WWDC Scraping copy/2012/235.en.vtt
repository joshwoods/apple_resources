WEBVTT

00:00:11.350 --> 00:00:12.280
I'm Ben Nham.

00:00:12.500 --> 00:00:14.760
I'm an engineer on the
iOS performance team.

00:00:14.990 --> 00:00:17.220
I'll be joined in a bit by my colleague,
Tim Lee,

00:00:17.300 --> 00:00:19.730
who is also an engineer on our team.

00:00:19.810 --> 00:00:23.470
And we've been working on performance
for the last three or four years.

00:00:23.470 --> 00:00:27.610
And we're going to talk about improving
your app's responsiveness today.

00:00:28.960 --> 00:00:30.090
So we're going to talk about two topics.

00:00:30.160 --> 00:00:32.460
One is responsiveness,
and that's how quickly your

00:00:32.460 --> 00:00:34.600
app responds to user events.

00:00:34.660 --> 00:00:38.260
So you really want your application to
respond to things like touch events,

00:00:38.340 --> 00:00:41.530
accelerometer events,
and so forth quickly so

00:00:41.560 --> 00:00:44.900
that they feel like they're
interacting with a real object.

00:00:45.010 --> 00:00:46.670
And we're also going to be
talking about performance.

00:00:46.760 --> 00:00:50.080
That's how to make your
app do work efficiently.

00:00:51.460 --> 00:00:53.450
We're going to look at that
in a few different contexts.

00:00:53.680 --> 00:00:56.760
One,
the real key to this talk is to measure

00:00:56.760 --> 00:00:59.030
and profile your app for performance.

00:00:59.110 --> 00:01:02.200
So we'll be going over a couple of
profiling tools and showing you how

00:01:02.200 --> 00:01:04.660
to use them to make your app faster.

00:01:04.710 --> 00:01:06.330
We'll also look at a
couple of key scenarios.

00:01:06.520 --> 00:01:07.770
One is fast app launch.

00:01:08.060 --> 00:01:11.300
That's the first user event in your app.

00:01:11.300 --> 00:01:14.440
We'll also be looking at how to
make your app respond to events

00:01:14.750 --> 00:01:16.690
faster once it's already launched.

00:01:16.910 --> 00:01:19.560
And we'll also give you a few
key performance strategies that

00:01:19.560 --> 00:01:22.730
that you can apply to your app,
whatever performance

00:01:22.730 --> 00:01:24.100
problem you might have.

00:01:26.810 --> 00:01:31.300
So let's talk about a workflow
for fixing performance problems.

00:01:31.330 --> 00:01:33.370
It's really like fixing
any other problem.

00:01:33.420 --> 00:01:36.390
The first step is to
reproduce the problem,

00:01:36.390 --> 00:01:38.290
just like you have with any other bug.

00:01:38.350 --> 00:01:41.050
And once you've reproduced the problem,
hopefully you can time it,

00:01:41.190 --> 00:01:43.880
get some sort of number,
like a wall clock time,

00:01:43.880 --> 00:01:47.510
frames per second, network throughput,
whatever it may be.

00:01:47.670 --> 00:01:51.660
Hopefully you get some sort of one number
that you can keep going back to to make

00:01:51.660 --> 00:01:54.280
sure you're making forward progress.

00:01:55.500 --> 00:01:59.120
The next step is to profile
your app with some of our tools,

00:01:59.320 --> 00:02:00.860
say instruments.

00:02:01.230 --> 00:02:03.730
And once you take a look at the
time profile or the system trace

00:02:03.740 --> 00:02:07.930
or whatever profiling tool you use,
hopefully you come up with some

00:02:07.930 --> 00:02:09.630
hypothesis of what's wrong.

00:02:09.720 --> 00:02:12.960
And sometimes you'll only get
some sort of general hypothesis,

00:02:12.960 --> 00:02:15.440
like, "Well,
this doesn't seem like a CPU problem.

00:02:15.720 --> 00:02:18.100
Maybe it's really a GPU problem.

00:02:18.140 --> 00:02:19.070
It's a graphics problem.

00:02:19.180 --> 00:02:22.100
I should use a different instrument,
like the core animation instrument."

00:02:22.180 --> 00:02:25.300
So you might go around in a cycle
with sort of a general hypothesis

00:02:25.300 --> 00:02:27.460
and then more narrow hypothesis.

00:02:27.530 --> 00:02:29.690
And hopefully, eventually,
you'll figure out something

00:02:29.700 --> 00:02:31.890
to do to fix your application.

00:02:31.950 --> 00:02:36.200
And once you make the fix,
you come back to reproducing the problem.

00:02:36.300 --> 00:02:39.740
If it doesn't reproduce and you
measure it and it's gotten better,

00:02:39.870 --> 00:02:40.560
you're done.

00:02:40.610 --> 00:02:43.210
Otherwise,
you go around in this loop again until

00:02:43.210 --> 00:02:46.100
your performance problem is fixed.

00:02:46.180 --> 00:02:50.050
So we'll be going over this workflow
in all our performance talks today.

00:02:50.910 --> 00:02:53.890
Let's take a look at how that
applies to a key performance

00:02:53.900 --> 00:02:56.300
scenario like application launch.

00:02:56.420 --> 00:02:58.550
So why is application
launch so important?

00:02:58.800 --> 00:03:02.960
Well, the first reason is it's the
first thing that the user does.

00:03:02.960 --> 00:03:05.450
They'll tap your icon,
and they'll expect a responsive

00:03:05.450 --> 00:03:08.040
user interface really quickly.

00:03:08.130 --> 00:03:11.500
And really what you're shooting
for is a really fast app launch,

00:03:11.500 --> 00:03:15.470
like, say, 400 or 500 milliseconds,
because that's how long the

00:03:15.470 --> 00:03:17.630
application zoom animation takes.

00:03:17.730 --> 00:03:22.140
And we launch your app concurrently
with the zoom animation.

00:03:22.240 --> 00:03:25.290
So if you can actually
launch that quickly,

00:03:25.410 --> 00:03:29.130
to the user, it seems like your app
has launched instantly.

00:03:29.230 --> 00:03:31.880
Of course,
your app might do nontrivial work,

00:03:31.880 --> 00:03:34.070
so it might be hard to get to 400,
500 milliseconds,

00:03:34.110 --> 00:03:38.220
but that's really the goal
at the end of the day.

00:03:39.080 --> 00:03:40.160
So that's sort of the carrot.

00:03:40.210 --> 00:03:43.120
Users love fast app launch times.

00:03:43.160 --> 00:03:43.720
What's the stick?

00:03:43.850 --> 00:03:47.610
Well, the system really dislikes
slow app launch times.

00:03:47.670 --> 00:03:52.640
And so if you launch in 20 seconds,
we'll actually terminate your app.

00:03:52.760 --> 00:03:54.730
That's the system watchdog at work.

00:03:54.890 --> 00:03:57.420
And you really want to avoid that
because that's a really bad user

00:03:57.420 --> 00:04:00.550
experience where the user taps your
app and it just shows a loading

00:04:00.550 --> 00:04:02.280
screen and then just terminates.

00:04:02.280 --> 00:04:06.590
And of course,
users often give up before 20 seconds.

00:04:06.860 --> 00:04:10.400
So you really want to be on
the low end of this scale.

00:04:10.400 --> 00:04:14.390
Just one thing to note is that if you're
running in the debugger from Xcode,

00:04:14.390 --> 00:04:17.910
the watchdog will be disabled so
we can attach with the debugger.

00:04:17.910 --> 00:04:24.240
So you have to launch the app like a real
user would to get this timeout behavior.

00:04:26.000 --> 00:05:43.600
[Transcript missing]

00:05:46.110 --> 00:05:48.560
So one way of measuring the
launch time using logging,

00:05:48.780 --> 00:05:54.560
as I said, is to set a global, say,
start time in main and save to

00:05:54.560 --> 00:05:57.510
that global in your first line.

00:05:57.780 --> 00:06:02.280
And then after you get the application
did finish launching callback,

00:06:02.300 --> 00:06:05.430
when you get that callback,
it doesn't mean your application

00:06:05.460 --> 00:06:07.090
has actually finished launching.

00:06:07.090 --> 00:06:10.170
It means that we're giving control
to your app to do all the work that

00:06:10.170 --> 00:06:11.960
it needs to do to finish launching.

00:06:11.960 --> 00:06:14.990
So you might think that, well,
it'd be valid to just stop

00:06:15.000 --> 00:06:18.860
the timer at the end of
application did finish launching.

00:06:18.910 --> 00:06:21.280
But actually,
because of the way the system works,

00:06:21.450 --> 00:06:24.180
all the initial layout and
drawing doesn't happen until

00:06:24.290 --> 00:06:27.600
after you've returned from
application did finish launching.

00:06:27.720 --> 00:06:30.500
So that's why in the first
line of this callback,

00:06:30.500 --> 00:06:35.390
I've actually used dispatch async to
sort of end the time of the end of

00:06:35.600 --> 00:06:42.320
the timer after that work that happens
after application did finish launching.

00:06:42.320 --> 00:06:42.320
So.

00:06:43.010 --> 00:06:46.280
That's a little tricky,
so I wanted to point it out here.

00:06:47.980 --> 00:06:51.530
Another way to measure launch
time is to use Time Profiler.

00:06:51.560 --> 00:06:53.930
A lot of people don't know
about the CPU Strategy View,

00:06:53.930 --> 00:06:55.690
so I'll be demonstrating that today.

00:06:55.760 --> 00:06:58.770
And what that will show you is
every single call stack that

00:06:58.770 --> 00:07:01.030
Time Profiler has taken over time.

00:07:01.110 --> 00:07:03.720
And you can actually search
through those call stacks.

00:07:03.790 --> 00:07:07.250
So the idea here would be to search
for this ReportAppLaunchFinished

00:07:07.510 --> 00:07:13.890
method and look for the very last
sample with that call stack in it.

00:07:13.950 --> 00:07:18.810
And that's where you can sort of endpoint
the launch time of your application,

00:07:18.820 --> 00:07:21.280
at least if you care about that now.

00:07:21.320 --> 00:07:23.940
If you care about something else,
like when the shutter button is able,

00:07:23.960 --> 00:07:25.500
you'll have to search for that instead.

00:07:28.590 --> 00:07:30.330
So this is a little
easier to demonstrate,

00:07:30.330 --> 00:07:34.850
so I'm going to head over here to
show you how to take a time profile.

00:07:34.920 --> 00:07:36.640
So just to make this a
little more interesting and

00:07:36.640 --> 00:07:39.930
show you a real application,
we're going to actually be

00:07:39.930 --> 00:07:41.460
looking at the WWDC app.

00:07:41.660 --> 00:07:44.990
And the first thing I want
to show you is how to report

00:07:45.310 --> 00:07:47.880
the launch time via logging.

00:07:47.960 --> 00:07:53.180
So as you can see, I've declared a global
up here for start time,

00:07:53.180 --> 00:07:59.020
and in the first line in main,
I've I've stored the current time to it.

00:08:03.620 --> 00:08:08.960
In my app delegates,
application did finish launching.

00:08:08.960 --> 00:08:09.980
This probably belongs in a header.

00:08:09.980 --> 00:08:12.510
I've just put it here just
so it's all in one place.

00:08:12.670 --> 00:08:16.970
But I've declared that the
start time global exists.

00:08:16.970 --> 00:08:20.970
And then, as I said,
I dispatch async back to the main queue.

00:08:21.130 --> 00:08:24.400
And that's so that I'm
measuring the launch time.

00:08:24.400 --> 00:08:28.550
I'm taking into account the layout and
drawing that happens after you return

00:08:28.550 --> 00:08:30.800
from application did finish launching.

00:08:30.840 --> 00:08:39.620
And all this is going to do is report
the launch time to the console.

00:08:39.620 --> 00:08:42.250
So let's build and run this.

00:08:47.330 --> 00:08:51.420
And you can see that the
current application launch

00:08:51.490 --> 00:08:53.000
time is reported down here.

00:08:53.000 --> 00:08:57.100
It says it launched in 1.15 seconds,
so that's actually pretty good because,

00:08:57.100 --> 00:09:03.070
as I said, the animation is 500
milliseconds on a iPad.

00:09:04.190 --> 00:09:06.060
And this should be actually
pretty reproducible.

00:09:06.060 --> 00:09:12.270
Now, note that the output down here
is from running with a debugger.

00:09:12.550 --> 00:09:16.380
You probably want to run this, you know,
not in the debugger,

00:09:16.430 --> 00:09:21.310
and then you'll see the output
in the Xcode Organizer console.

00:09:22.370 --> 00:09:27.800
And just to convince you,
I'm actually looking at the Xcode app.

00:09:28.360 --> 00:09:33.840
So all I did was launch the
Xcode app and a launch time

00:09:33.840 --> 00:09:36.980
appeared in my system console.

00:09:37.050 --> 00:09:38.700
So that should be relatively repeatable.

00:09:38.700 --> 00:09:43.090
That's one number you can keep going
back to as you work on launch time.

00:09:43.090 --> 00:09:46.700
As you keep making improvements,
hopefully that launch time

00:09:46.700 --> 00:09:49.410
keeps going down and down.

00:09:50.110 --> 00:09:52.050
Now let's talk about how
to take a time profile.

00:09:52.060 --> 00:09:56.530
So I've already built the application
and uploaded it to my iPad,

00:09:56.540 --> 00:10:03.740
so I'm just going to start
Instruments as a separate program.

00:10:03.830 --> 00:10:07.340
And I've selected time profile.

00:10:09.800 --> 00:10:12.250
There are a few options I like to use.

00:10:12.430 --> 00:10:17.860
So one of them is in File,
Record Options.

00:10:17.860 --> 00:10:21.280
So there's this option
called Deferred Mode.

00:10:21.860 --> 00:10:26.720
That basically minimizes the overhead
of the trace because by default you

00:10:26.720 --> 00:10:30.050
might have noticed that Instruments
sort of interactively displays

00:10:30.160 --> 00:10:31.860
the profile as you're taking it.

00:10:31.910 --> 00:10:35.510
This will just put up a block out
screen that you'll see while taking the

00:10:35.510 --> 00:10:38.690
trace so that overhead is minimized.

00:10:39.240 --> 00:10:43.800
Also by default,
a lot of people attach to one process.

00:10:44.200 --> 00:10:48.200
I'm just going to profile all processes
because it's also relatively efficient.

00:10:48.380 --> 00:10:52.910
And sometimes your application
has some interesting interactions

00:10:52.910 --> 00:10:55.200
with other system processes.

00:10:55.200 --> 00:10:58.280
So for instance,
if you wrote an app that gets events

00:10:58.280 --> 00:11:01.980
from the user's events database,
that'll talk to a calendar

00:11:02.360 --> 00:11:04.200
access daemon and so forth.

00:11:04.200 --> 00:11:09.980
So sometimes it's just good to see
all the processes that are running.

00:11:12.180 --> 00:11:15.550
So I'm just going to hit record now.

00:11:15.660 --> 00:11:18.010
Launch wwc.app.

00:11:21.360 --> 00:11:23.650
Okay,
something is going a little awry here,

00:11:24.060 --> 00:11:28.080
so I'll bring up one of my backup traces.

00:11:35.630 --> 00:11:38.740
So this is what you would see
after taking the time profile.

00:11:38.740 --> 00:11:40.730
You would see a screen that
looks something like this.

00:11:40.810 --> 00:11:47.990
So what this purple at the
top shows CPU usage over time.

00:11:48.060 --> 00:11:54.430
And what this is saying is,
might be hard to see, but in the WWC app,

00:11:54.430 --> 00:11:59.880
we spent two seconds of CPU time.

00:11:59.880 --> 00:11:59.880
Now,

00:12:00.430 --> 00:12:04.600
As I was saying,
one of the features of Time Profile

00:12:04.600 --> 00:12:08.240
that a lot of people don't know about
is this CPU strategy view up here.

00:12:08.240 --> 00:12:10.590
That's this button at the left.

00:12:10.640 --> 00:12:15.030
And that'll show you every single
call stack sampled over time.

00:12:15.040 --> 00:12:18.890
So by default, we'll sample the call
stack every millisecond.

00:12:19.570 --> 00:12:23.940
And if you switch over
to the sample list here,

00:12:23.940 --> 00:12:26.940
you can actually see every
single call stack over time.

00:12:27.170 --> 00:12:29.600
Now,
another feature that's kind of handy,

00:12:29.600 --> 00:12:34.240
let's say we want to figure out the
launch time from the time profile.

00:12:34.280 --> 00:12:40.070
We can restrict the trace
to just WWC's main thread by

00:12:40.170 --> 00:12:43.040
clicking on this thread picker.

00:12:43.100 --> 00:12:47.010
And I'm going to click
on WWC's main thread.

00:12:48.800 --> 00:12:54.410
And as you can see,
we've highlighted only the stacks that

00:12:54.420 --> 00:12:57.760
have to do with the WABC main thread.

00:12:57.760 --> 00:13:00.070
So there's a lot of other stuff
going on in this system other

00:13:00.070 --> 00:13:02.400
than the main thread of WABC.

00:13:02.400 --> 00:13:07.580
So the beginning of app launch,
let's say it happens around here.

00:13:07.580 --> 00:13:11.320
You can see the first highlighted
call stack is about -- it's about

00:13:11.970 --> 00:13:15.860
It's at about 2.265 milliseconds.

00:13:15.940 --> 00:13:19.970
And let's say we want to find
what's happening-- Let's say we

00:13:19.970 --> 00:13:24.840
want to find the end of app launch,
the end of the first layout and draw.

00:13:25.210 --> 00:13:27.000
So as I said,

00:13:27.170 --> 00:13:30.220
We can search all the call stacks here.

00:13:30.220 --> 00:13:33.620
We can search for report
app launch finished.

00:13:36.900 --> 00:13:40.300
And that'll actually
show that there were,

00:13:40.300 --> 00:13:44.470
in this case, 59 samples with report
app launch finished in it.

00:13:44.540 --> 00:13:48.130
And the last one,
you can actually see that

00:13:48.170 --> 00:13:52.400
Xcode has moved the inspection
head to about 2.995 seconds.

00:13:52.400 --> 00:13:59.560
So 2.265 to 2.995, that's about, say,
750 milliseconds spent launching the app.

00:13:59.740 --> 00:14:04.060
So you can, at this point,
you can restrict your trace, let's say,

00:14:04.060 --> 00:14:06.800
to just this time period.

00:14:06.800 --> 00:14:10.390
If you only care about what happens
until the first layout and draw.

00:14:10.550 --> 00:14:15.340
So that's how to use the CPU strategy
view to sort of restrict your

00:14:15.340 --> 00:14:17.390
trace to what you're interested in.

00:14:17.450 --> 00:14:21.690
And we'll go back to this
trace in just a moment.

00:14:21.860 --> 00:14:24.050
As you saw,
there's a lot of information that

00:14:24.100 --> 00:14:25.560
comes out of that time profile.

00:14:25.560 --> 00:14:26.990
It can be really overwhelming.

00:14:27.110 --> 00:14:30.260
So I'm just going to go over some
of the key phases of application

00:14:30.260 --> 00:14:34.750
launch so you know when you take
a look at that time profile,

00:14:34.760 --> 00:14:39.010
you'll have an idea what
all those functions mean.

00:14:40.020 --> 00:14:43.420
So the first thing that happens
in application launch is we have

00:14:43.500 --> 00:14:44.750
to do some linking and loading.

00:14:44.840 --> 00:14:47.870
So if your application links
against a bunch of frameworks,

00:14:47.870 --> 00:14:51.000
and maybe you refer to some
constants in that framework,

00:14:51.000 --> 00:14:53.990
we might have to bind to those symbols.

00:14:54.000 --> 00:14:59.090
And this all happens before we
even hit main in your application.

00:14:59.550 --> 00:15:01.880
So some of the things that you
can do to minimize the time

00:15:01.880 --> 00:15:03.260
spent linking and loading.

00:15:03.310 --> 00:15:08.040
One is to take a look at which
frameworks you've linked against.

00:15:08.040 --> 00:15:11.620
This is in the build phases
section of your Xcode project.

00:15:11.920 --> 00:15:15.780
And take a look here because
there's a tendency for frameworks

00:15:15.820 --> 00:15:17.420
to sort of accumulate in this list.

00:15:17.440 --> 00:15:20.690
Now, in this case, there's only UIKit,
Foundation, and Core Graphics.

00:15:20.690 --> 00:15:22.520
That's sort of the bare
minimum that you need.

00:15:22.600 --> 00:15:25.990
But there's a tendency for
people to experiment with new

00:15:26.080 --> 00:15:30.520
features and add a bunch of
frameworks and never remove them.

00:15:30.630 --> 00:15:34.400
And you really want to minimize the
amount of frameworks here because

00:15:34.780 --> 00:15:38.210
every single Objective-C framework
you bring in does a little bit of

00:15:38.240 --> 00:15:40.240
extra work at link and load time.

00:15:40.250 --> 00:15:44.000
So, for instance,
there is a hash table that,

00:15:44.010 --> 00:15:46.940
of all classes,
and that has to be populated

00:15:46.940 --> 00:15:50.380
at load time based on each
framework that you link against.

00:15:50.450 --> 00:15:52.780
And that's how things like
NSClass from String work.

00:15:53.000 --> 00:15:53.700
That's how we can do that.

00:15:53.720 --> 00:15:57.000
You can actually look up a class
based on a string and give it--give

00:15:57.000 --> 00:15:58.580
that class instance to you.

00:15:58.580 --> 00:16:00.980
So take a look at your linked frameworks.

00:16:01.140 --> 00:16:04.580
Make sure there's nothing
that you don't need there.

00:16:05.880 --> 00:16:09.970
Another thing that sometimes
developers get confused with is how

00:16:09.980 --> 00:16:12.040
to use the optional frameworks flag.

00:16:12.150 --> 00:16:14.860
So we'll say, well,
minimize your linked frameworks,

00:16:14.920 --> 00:16:19.560
and then we'll see that someone
has marked UIKit as optional.

00:16:19.650 --> 00:16:21.520
And you can't really trick the linker.

00:16:21.840 --> 00:16:22.900
You really need UIKit.

00:16:22.900 --> 00:16:24.830
So we're going to detect that.

00:16:25.110 --> 00:16:29.240
And you really shouldn't use optional
for frameworks that you actually need,

00:16:29.240 --> 00:16:34.480
because it has the potential to just
add work to linking and load time.

00:16:34.500 --> 00:16:37.600
So that's not the
correct use of optional.

00:16:37.710 --> 00:16:39.960
Where you would use optional is,
for instance,

00:16:39.980 --> 00:16:43.740
if you're deploying against 5.0,
and you want to link

00:16:43.740 --> 00:16:46.730
against a framework like,
say, passkit.framework that

00:16:46.820 --> 00:16:49.640
was introduced in iOS 6.

00:16:49.810 --> 00:16:52.480
So that's where you would use
the optional flag so that users

00:16:52.530 --> 00:16:58.860
on iOS 5 would not error out
looking for a passkit framework.

00:16:59.020 --> 00:17:02.310
So that's the proper use
of optional frameworks.

00:17:03.010 --> 00:17:06.460
The last thing I want to bring
up is static initializers.

00:17:06.590 --> 00:17:08.740
So this is easy to do
with C++ especially.

00:17:08.740 --> 00:17:13.120
So a lot of games are written in C++ and
you'll tend to accumulate a lot of global

00:17:13.120 --> 00:17:16.890
objects with nontrivial initializers.

00:17:16.980 --> 00:17:20.740
And so for instance, in this case,
I have a C++11 statement

00:17:20.740 --> 00:17:24.240
that initializes a map,
a standard map.

00:17:24.320 --> 00:17:27.930
And what that's going to do is
run the code for the constructor

00:17:27.930 --> 00:17:30.940
of standard map at load time,
before you even hit main.

00:17:31.010 --> 00:17:35.580
And it's going to go through every single
one of these in all of your object files.

00:17:35.660 --> 00:17:37.300
So that's probably not what you want.

00:17:37.300 --> 00:17:41.180
That's bringing in a lot of code
before you even do any user work.

00:17:41.220 --> 00:17:45.500
So you're forcing the user to pay for
work that they might not even need.

00:17:45.570 --> 00:17:48.100
There's ways to do this
in Objective-C and C too,

00:17:48.100 --> 00:17:50.780
using the load method, for instance.

00:17:50.830 --> 00:17:53.220
So try to avoid those methods.

00:17:53.220 --> 00:17:55.630
Avoid static initializers.

00:17:55.680 --> 00:17:58.980
You should instead make
objects when you need them.

00:17:58.980 --> 00:18:00.940
So Objective-C has a lot
of static initializers.

00:18:00.940 --> 00:18:03.940
And there's a class method called
plus_initialize that's great for this,

00:18:03.940 --> 00:18:08.940
because plus_initialize is only called
the first time you use the class.

00:18:08.940 --> 00:18:11.630
There's a couple gotchas with using it.

00:18:11.640 --> 00:18:14.570
So refer to the Objective-C programming
guide to learn how to

00:18:14.570 --> 00:18:15.930
use initialize correctly.

00:18:15.940 --> 00:18:18.670
But that's--if you need to
set up global and you have a

00:18:18.670 --> 00:18:22.440
class that uses that global,
use plus_initialize to initialize

00:18:22.440 --> 00:18:25.930
those globals so that it only
happens when you first use the class,

00:18:25.940 --> 00:18:28.330
not at load time.

00:18:29.440 --> 00:18:32.150
Okay, so after linking and loading,
we have to do some UI kit

00:18:32.260 --> 00:18:34.640
initialization for every single app.

00:18:34.870 --> 00:18:40.720
That includes things like creating fonts,
creating the first status bar,

00:18:40.980 --> 00:18:43.440
reading your user defaults,

00:18:43.550 --> 00:18:45.300
Deserializing your main nib.

00:18:45.350 --> 00:18:49.250
And that will show up in functions
like UI application initialize,

00:18:49.260 --> 00:18:53.760
instantiate singleton, create status bar,
and load main nib file.

00:18:54.090 --> 00:18:56.850
So that's where it will
show up in time profiler.

00:18:56.920 --> 00:18:59.160
So what can you do to reduce
the amount of time spent in

00:18:59.170 --> 00:19:00.850
this part of application launch?

00:19:00.850 --> 00:19:03.710
Well, the first is to minimize
the size of your main nib.

00:19:03.710 --> 00:19:06.870
And so in this case,
I've got nine top level views,

00:19:06.880 --> 00:19:08.760
each with sub views in my nib.

00:19:08.760 --> 00:19:11.480
So that's definitely not
the right way to use nibs.

00:19:11.800 --> 00:19:15.720
And iOS makes it really easy to
use nibs in the right way because

00:19:15.720 --> 00:19:18.930
it really enforces the idea of
one nib per view controller.

00:19:19.010 --> 00:19:21.180
So have one nib per view controller.

00:19:21.250 --> 00:19:26.380
You can have your view hierarchy for
that view in the view controller.

00:19:26.380 --> 00:19:29.410
But definitely don't have something like
this where you have nine top level views,

00:19:29.460 --> 00:19:31.900
each with a very complex view hierarchy.

00:19:31.900 --> 00:19:34.760
Because we're going to have to
deserialize that entire nib before

00:19:34.840 --> 00:19:37.020
we even respond to any user events.

00:19:37.050 --> 00:19:37.380
So that's the first thing.

00:19:37.380 --> 00:19:38.040
And then the second thing is
to minimize the amount of time

00:19:38.040 --> 00:19:38.040
spent in the application launch.

00:19:38.040 --> 00:19:38.040
So that's the first thing.

00:19:38.040 --> 00:19:38.040
And then the third thing is
to minimize the amount of time

00:19:38.040 --> 00:19:38.040
spent in the application launch.

00:19:38.040 --> 00:19:38.040
So that's the first thing.

00:19:38.040 --> 00:19:38.040
And then the fourth thing is
to minimize the amount of time

00:19:38.040 --> 00:19:38.040
spent in the application launch.

00:19:38.040 --> 00:19:38.040
So that's the first thing.

00:19:38.040 --> 00:19:41.220
And then the fourth thing So minimize
the size of your main Nib.

00:19:41.720 --> 00:19:44.850
Also,
one of the things we'll do is we'll look

00:19:44.850 --> 00:19:47.000
in your app for certain key preferences.

00:19:47.070 --> 00:19:50.060
And underneath the hood,
preferences are implemented

00:19:50.130 --> 00:19:51.460
as property lists.

00:19:51.550 --> 00:19:53.800
And property lists are great,
but they're not designed

00:19:53.800 --> 00:19:55.250
for large amounts of data.

00:19:55.320 --> 00:19:58.200
And the reason for that is that,
say you ask preferences

00:19:58.640 --> 00:20:02.760
for an object for a key,
because of the way property lists work,

00:20:02.870 --> 00:20:06.490
we have to deserialize everything in
your user preferences before we can

00:20:06.490 --> 00:20:08.540
hand you back that object for that key.

00:20:08.630 --> 00:20:12.880
So if you store large pieces of data,
like in this case a ping image,

00:20:12.950 --> 00:20:16.540
inside your user preferences,
we have to go deserialize and

00:20:16.700 --> 00:20:20.230
create all those objects in memory,
even before we do any

00:20:20.480 --> 00:20:21.570
real work in your app.

00:20:21.730 --> 00:20:25.350
So again, use preferences for what
they're meant to be,

00:20:25.470 --> 00:20:29.100
for, you know, booleans, integers,
and so forth.

00:20:29.150 --> 00:20:33.370
Don't store giant pieces of
objects inside your preferences.

00:20:34.010 --> 00:20:35.990
Next,
we'll call back to your application.

00:20:36.120 --> 00:20:42.410
So this is really where
your application will--

00:20:42.700 --> 00:20:44.660
where we're giving control to
your application to do work.

00:20:44.660 --> 00:20:47.140
So first,
we'll call application will finish

00:20:47.140 --> 00:20:49.740
launching with options in iOS 6.

00:20:49.740 --> 00:20:53.220
Then we'll restore your application
state if you're using that API.

00:20:53.300 --> 00:20:56.700
And then we'll call application
did finish launching with options.

00:20:56.760 --> 00:21:01.070
So in time profiler, when you see this,
that's where you really have

00:21:01.070 --> 00:21:04.250
to concentrate your efforts for
figuring out where hotspots are.

00:21:04.340 --> 00:21:07.360
Because this is really where
your app is in control.

00:21:07.360 --> 00:21:12.400
And finally, we're gonna do the first
core-animation transaction.

00:21:12.410 --> 00:21:15.640
So if you don't know what that means,
that's okay.

00:21:15.640 --> 00:21:18.510
This is where we batch up all
the work related to laying

00:21:18.510 --> 00:21:20.000
out and drawing your views.

00:21:20.000 --> 00:21:23.340
This happens after you return from
application did finish launching.

00:21:23.340 --> 00:21:27.200
And as I said, we force this to happen
at least at launch time in

00:21:27.200 --> 00:21:29.500
report app launch finished.

00:21:29.500 --> 00:21:34.630
It also usually happens implicitly
at the end of the event loop.

00:21:34.650 --> 00:21:38.590
So for instance, if you call set needs
display 10 times on a view,

00:21:38.660 --> 00:21:42.620
we're not going to actually call
drawRect on that view 10 times.

00:21:42.700 --> 00:21:46.390
Instead, we coalesce all those set needs
display until the end of the event

00:21:46.390 --> 00:21:50.200
loop when we commit the transaction
and we just draw the view once.

00:21:50.300 --> 00:21:54.210
So a lot of people are sort of
mystified by what is this --

00:21:54.210 --> 00:21:56.700
what is occurring during commit.

00:21:56.730 --> 00:21:59.600
And there's sort of three main
things that you'll see taking time.

00:21:59.630 --> 00:22:01.060
One is preparation.

00:22:01.180 --> 00:22:05.590
So you'll see as a sub call
inside a CA transaction commit

00:22:05.590 --> 00:22:08.230
sort of prepare transaction.

00:22:08.330 --> 00:22:13.040
And that's where you'll see things
like decompressing pings and JPEGs if

00:22:13.090 --> 00:22:15.770
you set an image on an image view.

00:22:15.920 --> 00:22:17.590
The next is layout.

00:22:17.710 --> 00:22:19.540
So this is where we
call layout sub views.

00:22:19.650 --> 00:22:22.320
And a lot of views have
nontrivial layout sub views.

00:22:22.380 --> 00:22:26.740
So for instance,
UI table view in its layout sub views,

00:22:26.750 --> 00:22:28.500
that's where it loads new cells.

00:22:28.600 --> 00:22:30.090
So that's where you'll see work
related to creating new cells.

00:22:30.090 --> 00:22:31.230
And then the last thing we're
going to do is we're going to call

00:22:31.230 --> 00:22:32.020
the view sub view and then we're
going to call the view sub view.

00:22:32.020 --> 00:22:32.960
And then we're going to
call the view sub view.

00:22:33.020 --> 00:22:33.210
And then we're going to
call the view sub view.

00:22:33.210 --> 00:22:34.010
And then we're going to
call the view sub view.

00:22:34.020 --> 00:22:35.020
So there's a lot of time that we're going
to spend in creating table view cells.

00:22:35.020 --> 00:22:36.060
So there is going to -- generally
a good amount of time is spent in

00:22:36.140 --> 00:22:37.350
this layout portion of the commit.

00:22:37.350 --> 00:22:40.270
And then finally,
after we've laid out your views,

00:22:40.270 --> 00:22:42.420
we know where they are,
we know what the size of them are,

00:22:42.550 --> 00:22:46.370
we can finally call drawRect if
you've called -- if your -- if your

00:22:46.370 --> 00:22:51.070
view implements drawRect because
we know the size of the view.

00:22:52.790 --> 00:22:56.080
So again, let's take a look at how
this manifests itself in the

00:22:56.080 --> 00:22:58.770
time profile for the WWC app.

00:22:59.650 --> 00:23:03.590
So this is the time profile
we just took of the WABC app.

00:23:03.590 --> 00:23:10.470
And I'm going to switch back from the
sample list view to the call tree view.

00:23:10.540 --> 00:23:15.100
And the sample list view, as I said,
shows what happened over time.

00:23:15.140 --> 00:23:19.070
The call tree view shows in
aggregate where time was spent.

00:23:19.080 --> 00:23:25.070
I have to clear this filter
at the top right here.

00:23:25.230 --> 00:23:28.520
So as you can see,
we spent 700 milliseconds in

00:23:28.520 --> 00:23:33.150
the main thread of WWDC during
the application launch.

00:23:33.280 --> 00:23:36.130
And I'm just going to walk you through
some of those things I just mentioned.

00:23:36.210 --> 00:23:42.000
So in this particular trace,
we spent 26 milliseconds in DYLD.

00:23:42.350 --> 00:23:43.990
That's the linking and loading phase.

00:23:44.230 --> 00:23:45.450
That's not a lot of time.

00:23:45.680 --> 00:23:47.860
As I said,
if you see a lot of time there,

00:23:47.860 --> 00:23:51.150
check for static initializers,
check for linking against

00:23:51.150 --> 00:23:53.730
a lot of frameworks,
and so forth.

00:23:53.790 --> 00:23:57.410
After we've linked and load,
we actually hit Main.

00:23:58.530 --> 00:24:00.340
And we do some UI kit initialization.

00:24:00.340 --> 00:24:04.400
So UI application initialize,
that's where we'll do things

00:24:04.400 --> 00:24:06.900
like reading your user defaults.

00:24:07.020 --> 00:24:10.720
UI application instantiate singleton,
that's where we'll make the

00:24:10.930 --> 00:24:15.740
UI application singleton
object and your app delegate.

00:24:16.890 --> 00:24:20.720
And to continue with
UIKit initialization,

00:24:20.780 --> 00:24:24.410
you'll have to expand
this call tree a bit.

00:24:25.980 --> 00:24:33.150
And you'll see that we spend some
time creating the status bar and

00:24:33.150 --> 00:24:35.680
also loading the main NIM file.

00:24:35.830 --> 00:24:42.100
So those are call stacks that are
associated with sort of UI kit

00:24:42.100 --> 00:24:44.520
initialization for every app.

00:24:45.170 --> 00:24:48.600
Now where we start calling
you back is in this call

00:24:48.600 --> 00:24:51.180
initialization delegates for URL.

00:24:51.290 --> 00:24:57.570
So as you can see, we called,
did finish launching with options here.

00:25:01.330 --> 00:25:03.700
This is where we give hand
control to your application.

00:25:03.700 --> 00:25:07.120
So you can see that we spent
400 milliseconds here in

00:25:07.120 --> 00:25:09.180
this particular app launch.

00:25:09.230 --> 00:25:12.560
And this is where you really need
to focus your investigations.

00:25:12.670 --> 00:25:15.260
The other call stack
I want to point out is in,

00:25:15.270 --> 00:25:17.860
as I said, Report App Launch Finished.

00:25:17.960 --> 00:25:20.940
If you expand this out,
this is where you'll see

00:25:20.940 --> 00:25:22.950
the CA transaction commit.

00:25:23.590 --> 00:25:28.670
And as I said, there are a few key phases
to see a transaction commit.

00:25:28.740 --> 00:25:30.340
One is preparing the commit.

00:25:30.340 --> 00:25:32.830
That's where you'll see
deserialization of images.

00:25:32.920 --> 00:25:34.010
Laying out and displaying.

00:25:34.190 --> 00:25:37.340
In layout, you'll see things like
calling layout subviews,

00:25:37.370 --> 00:25:39.700
loading table view cells, and so forth.

00:25:39.730 --> 00:25:44.600
And display, that's where you'll see the
callbacks to your app for draw rect.

00:25:44.600 --> 00:25:47.710
So I'm not going to go over looking
at this app launch right now because

00:25:47.710 --> 00:25:52.690
Tim is going to go over how to look
at this time profile and optimize

00:25:52.700 --> 00:25:55.590
some key aspects of WBC in just a bit.

00:25:55.710 --> 00:26:00.510
But hopefully that gives you an
idea of where certain key operations

00:26:00.650 --> 00:26:02.600
and application launch occur.

00:26:04.120 --> 00:26:07.000
Okay, so to summarize,
you want to make sure your

00:26:07.000 --> 00:26:10.300
application launches fast because
that's the first user interaction,

00:26:10.350 --> 00:26:13.160
and try to get it to be as
instantaneous as possible.

00:26:13.340 --> 00:26:16.230
And the way to do that is by
measuring and profiling your

00:26:16.230 --> 00:26:19.420
application launch with Time Profiler.

00:26:21.460 --> 00:26:26.140
So next we want to give you a few sort
of key performance principles that you

00:26:26.140 --> 00:26:29.710
can apply to any performance problem.

00:26:30.510 --> 00:26:33.440
And the first one is you
have to profile your app.

00:26:33.670 --> 00:26:35.560
Don't guess as to what's slow.

00:26:35.590 --> 00:26:37.310
I mean, really,
if there's nothing else you

00:26:37.390 --> 00:26:41.240
take back from this talk,
remember to profile your application.

00:26:41.320 --> 00:26:44.350
So after you profile your application
and you figure out what's slow,

00:26:44.380 --> 00:26:45.650
how do you make it faster?

00:26:45.760 --> 00:26:49.230
Well, there's just a bunch of general
performance dos and don'ts.

00:26:49.350 --> 00:26:53.890
Don't do it, don't do it again,
do it faster, do it beforehand,

00:26:53.990 --> 00:26:57.340
do it afterwards, and do it at scale.

00:26:58.580 --> 00:27:02.500
So really the most common performance
optimization is just not doing

00:27:02.620 --> 00:27:04.540
whatever takes a long time.

00:27:04.560 --> 00:27:08.210
And year in and year out in the labs,
we always ask people

00:27:08.280 --> 00:27:12.550
to take time profiles,
system traces, and other profiles,

00:27:12.550 --> 00:27:16.150
and we always see some
sort of useless work.

00:27:16.480 --> 00:27:20.790
And that can be something graphical
like an unnecessary mask layer,

00:27:20.790 --> 00:27:24.340
an unnecessary shadow,
or it could be something database

00:27:24.340 --> 00:27:27.790
related like multiple queries for the
exact same data over and over again,

00:27:27.790 --> 00:27:31.680
or maybe hundreds of milliseconds
logging or sorting at launch time.

00:27:31.770 --> 00:27:34.160
So really take a look
at your time profile,

00:27:34.170 --> 00:27:36.530
and more often than not,
if it's the first profile

00:27:36.530 --> 00:27:40.550
you've ever taken,
you'll probably see something that you

00:27:40.550 --> 00:27:45.010
can really quickly remove and improve
your launch time or your responsiveness.

00:27:46.950 --> 00:27:48.800
The next is to not do it again.

00:27:48.940 --> 00:27:53.300
So there are certain classes that take
a good amount of time to initialize.

00:27:53.320 --> 00:27:56.230
And the most common example
is TableView cells that's

00:27:56.330 --> 00:27:58.290
baked right into the API.

00:27:58.300 --> 00:28:02.320
We really encourage you to reuse
TableView cells because there's a

00:28:02.400 --> 00:28:06.800
method in TableView that actually
lets you get a reused TableView cell.

00:28:07.010 --> 00:28:10.300
But there are other classes
that fall into this category.

00:28:10.300 --> 00:28:14.800
Things like date and number formatters,
regular expressions, SQLite statements.

00:28:15.020 --> 00:28:18.860
And in this case,
once you've made that expensive object,

00:28:18.930 --> 00:28:22.800
you should reuse that object instead
of recreating it over and over again.

00:28:22.800 --> 00:28:28.800
So for instance, with date formatters,
a common operation is to format a date.

00:28:28.800 --> 00:28:32.300
In this case, we want to format
February in a TableView cell.

00:28:32.310 --> 00:28:36.910
And if you create that date formatter
in cell4row at index path and

00:28:36.970 --> 00:28:39.890
then just immediately release it,
you're going to be paying the

00:28:39.890 --> 00:28:43.800
overhead of initializing the date
formatter over and over again.

00:28:43.800 --> 00:28:47.560
So really what you want to do is
you want to sort of cache one date

00:28:47.560 --> 00:28:49.800
formatter for each date format.

00:28:49.800 --> 00:28:52.920
If you do that,
you'll have to invalidate that cached

00:28:53.080 --> 00:28:55.800
date formatter when the locale changes.

00:28:55.800 --> 00:28:59.800
And note that you can't
really trick the system.

00:28:59.800 --> 00:29:02.280
So if you create one date
formatter and just call set date

00:29:02.280 --> 00:29:05.880
format on it over and over again,
that's just as slow as creating

00:29:05.930 --> 00:29:08.740
date formatters over and over again.

00:29:08.800 --> 00:29:11.110
So you really should,
if you're going to use a

00:29:11.110 --> 00:29:13.860
date formatter over and over,
keep it around and keep

00:29:13.860 --> 00:29:17.800
one date formatter for each
date format in your program.

00:29:18.010 --> 00:29:20.750
Another example is with calendars,
NSCalendar.

00:29:20.800 --> 00:29:22.800
So this can happen behind your back.

00:29:22.800 --> 00:29:26.770
So for instance,
NSLog calls-- creates an NSCalendar

00:29:26.900 --> 00:29:30.800
to format that date in the log
line every single time you call it.

00:29:30.800 --> 00:29:33.900
So it's not something you want to call
thousands of times on app launch or

00:29:33.900 --> 00:29:35.800
when you're responding to a user event.

00:29:35.960 --> 00:29:40.790
So don't log every single method
you hit in your application.

00:29:40.820 --> 00:29:43.420
I mean, it's fine if you log a few times,
hopefully you don't log at

00:29:43.420 --> 00:29:47.690
all on a release build because
your users can't see it anyway.

00:29:48.030 --> 00:29:52.630
But for this reason,
avoid calling NSLog excessively.

00:29:52.840 --> 00:29:56.800
One real gotcha is that NSCalendar,
current calendar,

00:29:56.800 --> 00:30:00.230
actually creates a different
calendar instance every single

00:30:00.250 --> 00:30:02.800
time because NSCalendar is mutable.

00:30:02.800 --> 00:30:09.080
So this can really get you if you're,
say, in a loop, getting dates from a

00:30:09.140 --> 00:30:10.770
calendar for each event,
let's say.

00:30:10.870 --> 00:30:14.790
Because it looks like a singleton,
but it's not.

00:30:14.800 --> 00:30:17.800
So this is just a
gotcha in the framework.

00:30:17.860 --> 00:30:21.600
If you're using current calendar,
save it instead of calling

00:30:21.660 --> 00:30:22.800
it over and over again.

00:30:24.150 --> 00:30:25.470
And finally, SQLite statements.

00:30:25.610 --> 00:30:28.670
They're really actually
little compiled programs.

00:30:28.780 --> 00:30:32.190
So you should make sure
to call SQLite3 prepare.

00:30:32.300 --> 00:30:35.100
You shouldn't call that over
and over with a format string.

00:30:35.100 --> 00:30:38.820
Instead,
use bind parameters and reuse that

00:30:39.130 --> 00:30:42.780
prepared statement over and over again.

00:30:45.040 --> 00:30:48.510
So what if you just have
to do whatever is slow?

00:30:48.770 --> 00:30:51.200
Well, hopefully you can do it faster.

00:30:51.240 --> 00:30:54.340
And this really is the domain of...

00:30:54.670 --> 00:30:57.080
Correct data structures
and faster algorithms.

00:30:57.160 --> 00:31:00.120
This is where your creativity
sort of has to come into play.

00:31:00.120 --> 00:31:05.000
So I can't really give you too
many general examples of this,

00:31:05.340 --> 00:31:07.160
but one thing you can do,
as I said before,

00:31:07.210 --> 00:31:08.690
choose the right data format.

00:31:08.700 --> 00:31:11.670
If you're using property lists,
make sure you're using the

00:31:11.760 --> 00:31:14.460
binary property list format
and you're not storing a ton

00:31:14.520 --> 00:31:16.240
of data in the property list.

00:31:16.290 --> 00:31:18.920
Because as I said before,
it's not a lazy format.

00:31:19.120 --> 00:31:21.030
If you want one key
from the property list,

00:31:21.120 --> 00:31:24.380
you have to create all the objects
in the property list in memory.

00:31:24.390 --> 00:31:27.030
If you have really -- if you have
tens of thousands of objects,

00:31:27.030 --> 00:31:29.640
you should really be looking
at Core Data or SQLite,

00:31:29.710 --> 00:31:31.980
because those are incremental formats.

00:31:32.000 --> 00:31:35.150
You can -- if you need one
object from the database,

00:31:35.150 --> 00:31:38.820
the database will try to just read
in the set of pages that contain

00:31:38.820 --> 00:31:42.590
that data instead of reading in
the entire database into memory.

00:31:44.130 --> 00:31:46.830
If you are using SQLite correctly,
I just want to point out there

00:31:46.830 --> 00:31:50.100
are a couple callback functions
you can use that are public.

00:31:50.150 --> 00:31:53.700
SQLite 3 Trace and SQLite 3
Profile will call you back with

00:31:53.700 --> 00:31:59.710
every single query you make,
as well as an estimate of how long

00:31:59.710 --> 00:32:01.710
it took to perform that query.

00:32:01.710 --> 00:32:04.010
And once you figure out
which query took a long time,

00:32:04.010 --> 00:32:08.180
you can use Explain Query
Plan to figure out what SQLite

00:32:08.180 --> 00:32:10.970
is doing to satisfy the query.

00:32:13.500 --> 00:32:15.650
Another performance strategy:
do it beforehand.

00:32:15.900 --> 00:32:16.380
Precompute.

00:32:16.400 --> 00:32:18.930
So if you have some sort
of expensive calculation,

00:32:18.930 --> 00:32:22.150
you might be able to precompute
it and save it off to disk or

00:32:22.250 --> 00:32:26.020
save it in memory somewhere and
reuse it over and over again.

00:32:26.120 --> 00:32:30.220
So for instance,
Calendar supports recurring events.

00:32:30.390 --> 00:32:32.890
And those recurrences can be
pretty much arbitrarily complex.

00:32:32.960 --> 00:32:37.180
You can schedule a meeting every Monday,
Wednesday, and Friday of every

00:32:37.180 --> 00:32:40.580
month except in February,
or on the last week of every Monday,

00:32:40.580 --> 00:32:42.240
Wednesday, Friday of every month.

00:32:42.330 --> 00:32:46.570
And that can take quite a long time
when you take into account leap years,

00:32:46.570 --> 00:32:48.440
time zones, and so forth.

00:32:48.570 --> 00:32:52.310
So the solution we have here is
to pre-expand the recurrences

00:32:52.310 --> 00:32:54.640
into objects we call occurrences.

00:32:54.740 --> 00:32:58.330
And we'll store those occurrences in
the database so that at launch time,

00:32:58.440 --> 00:33:01.440
we're not pre--we're not
expanding any recurrences.

00:33:01.440 --> 00:33:04.910
We're just fetching those
pre-expanded recurrences.

00:33:05.630 --> 00:33:08.260
Now when you do do this,
beware of memory growth.

00:33:08.450 --> 00:33:14.590
Because where this really can hurt you
is if you cache a really large image,

00:33:14.590 --> 00:33:15.750
like a screen-sized image.

00:33:15.960 --> 00:33:19.420
That's like a 640 by 960
image at 4 bytes per pixel.

00:33:19.560 --> 00:33:23.230
If you store that in a static
UI image and it's been decompressed,

00:33:23.230 --> 00:33:25.760
you've just blown away
2.4 megabytes of memory.

00:33:25.760 --> 00:33:28.500
So that's a really bad pattern.

00:33:28.500 --> 00:33:30.850
Really, really,
really think hard if you're

00:33:31.170 --> 00:33:32.750
saving large images in global.

00:33:32.760 --> 00:33:34.760
You probably should not be doing it.

00:33:34.780 --> 00:33:39.410
And we'll have a session later this
afternoon about memory to show you

00:33:39.410 --> 00:33:41.760
how to track down these issues.

00:33:43.960 --> 00:33:46.400
Another performance strategy,
instead of doing it beforehand,

00:33:46.400 --> 00:33:47.420
do it afterwards.

00:33:47.480 --> 00:33:51.910
So if you have a lot of data to load,
ideally you can load it synchronously,

00:33:51.990 --> 00:33:56.010
but if you have thousands of events that
you just have to load at launch time,

00:33:56.070 --> 00:34:01.320
maybe you can use Grand Central Dispatch
to push that work later.

00:34:01.320 --> 00:34:05.000
So for instance, in Calendar,
we load all the events asynchronously.

00:34:05.060 --> 00:34:08.340
So if you look closely,
we'll put up a responsive user interface.

00:34:08.340 --> 00:34:12.130
You can scroll immediately,
and then we'll load that user

00:34:12.130 --> 00:34:15.890
interface with events sometime
later in the background.

00:34:16.920 --> 00:34:18.480
And finally, do it at scale.

00:34:18.730 --> 00:34:21.610
So test your application
with lots of data.

00:34:21.640 --> 00:34:25.870
So for instance, the contacts app that
ships with the system,

00:34:25.870 --> 00:34:29.550
it scales pretty well with
the amount of contacts.

00:34:29.640 --> 00:34:31.990
So for instance,
if you have 3,000 contacts

00:34:32.000 --> 00:34:34.760
versus 300 contacts,
it launches in pretty much the

00:34:34.820 --> 00:34:37.790
same amount of time instead
of ten times as much time.

00:34:37.860 --> 00:34:42.550
So make sure to test your
app with large data sets.

00:34:42.630 --> 00:34:46.260
And the way to do that is to think about
the critical methods in your application.

00:34:46.260 --> 00:34:48.730
So in terms of contacts,
it's a table view app.

00:34:48.820 --> 00:34:51.340
So you have to make sure sections
are loaded quickly and the

00:34:51.340 --> 00:34:54.260
index bar is loaded quickly,
and then whatever visible

00:34:54.260 --> 00:34:56.470
cells are loaded quickly.

00:34:57.440 --> 00:35:02.550
And one way to do that is to make
sure you store the section counts and

00:35:02.550 --> 00:35:07.070
titles into some side table in your
database or somewhere else so that

00:35:07.130 --> 00:35:11.630
you don't have to load the entire
data set just to group by sections.

00:35:11.680 --> 00:35:15.800
And Core Data users actually get this
for free in the fetch results controller.

00:35:15.860 --> 00:35:19.800
So make sure to check that out and
make sure you're doing the most

00:35:19.800 --> 00:35:22.460
efficient thing with large data sets.

00:35:22.460 --> 00:35:26.960
So in conclusion,
to make your app faster,

00:35:27.000 --> 00:35:28.450
you have to profile your app.

00:35:28.470 --> 00:35:30.680
And once you figure out
what the hot spots are,

00:35:30.790 --> 00:35:32.900
do it faster, do it later, don't do it.

00:35:32.980 --> 00:35:36.640
Follow those general performance
strategies to figure out a way

00:35:36.640 --> 00:35:38.490
to make your application faster.

00:35:38.490 --> 00:35:41.400
And remember to test your
application not just as a bare

00:35:41.400 --> 00:35:45.300
application but with large data sets.

00:35:45.300 --> 00:35:48.720
And I'll hand it over to Tim to
talk about event handling.

00:35:52.500 --> 00:35:54.500
Thanks, Ben.

00:35:54.570 --> 00:35:55.920
All right.

00:35:56.320 --> 00:35:58.690
So besides app launch,
the rest of the time your

00:35:58.690 --> 00:36:01.050
users are using your app,
the thing that matters

00:36:01.050 --> 00:36:02.280
most is event handling.

00:36:02.360 --> 00:36:06.100
When somebody touches a button
or does a swipe or gestures,

00:36:06.100 --> 00:36:12.120
handling those events quickly is the
key to maintaining responsiveness.

00:36:12.120 --> 00:36:14.880
And the thing that you want to
remember is that handling pretty

00:36:14.880 --> 00:36:18.500
much all of these events is all
about keeping the main run loop free.

00:36:18.500 --> 00:36:21.690
All these events end up
happening on the main run loop,

00:36:21.690 --> 00:36:25.210
except for a few cases where
the API explicitly lets you

00:36:25.210 --> 00:36:27.240
handle them on another queue.

00:36:27.300 --> 00:36:31.090
So keep in mind that the main
run loop is the one that matters.

00:36:31.690 --> 00:36:33.420
So here's an illustration
of what that means.

00:36:33.550 --> 00:36:37.200
So when an event comes in,
it gets processed by your run loop.

00:36:37.270 --> 00:36:40.140
You'll do some layout,
you'll do some drawing or whatever.

00:36:40.420 --> 00:36:44.080
And one at a time, you'll get processed,
and things will happen normally.

00:36:44.170 --> 00:36:48.260
The problem happens when
events are handled slowly.

00:36:48.310 --> 00:36:50.330
What can happen then is
you'll get your event in,

00:36:50.330 --> 00:36:52.500
and this is moving around
a little bit slower.

00:36:52.500 --> 00:36:55.840
And in the meantime,
another event's come in, and another one.

00:36:55.910 --> 00:36:58.520
And by then,
the user has done some action,

00:36:58.520 --> 00:37:03.090
and your main run loop has not gone
around quickly enough to process it.

00:37:03.220 --> 00:37:05.240
So now the user's waiting.

00:37:05.350 --> 00:37:10.800
So we want to avoid this,
and there's a few ways to handle this,

00:37:10.800 --> 00:37:12.680
a few strategies.

00:37:12.680 --> 00:37:12.680
So the simplest is just...

00:37:12.900 --> 00:38:16.100
[Transcript missing]

00:38:16.230 --> 00:38:19.490
So in this case, I happen to know my app
just like you'll know yours.

00:38:19.610 --> 00:38:23.650
And I know that "Did control did
change?" is really the call that

00:38:23.890 --> 00:38:25.560
gets called when I switch tabs.

00:38:25.780 --> 00:38:29.310
So just like in the beginning of main,
instead of main will be "Did control

00:38:29.310 --> 00:38:31.520
did change?" We keep some time.

00:38:31.640 --> 00:38:33.350
And down here...

00:38:34.270 --> 00:38:35.200
We print again.

00:38:35.200 --> 00:38:37.500
The difference between the
end time and the start time.

00:38:37.620 --> 00:38:39.760
And you may notice here that

00:38:40.080 --> 00:38:42.400
There's this dispatch async,
which Bennett explained earlier,

00:38:42.400 --> 00:38:44.790
but there's actually the second one,
and this one can come up

00:38:44.950 --> 00:38:46.340
and is a little bit tricky.

00:38:46.450 --> 00:38:49.000
So what's going on here is
that the first time through,

00:38:49.130 --> 00:38:52.630
it could be the case that this block,
which is dispatched asynchronously,

00:38:52.630 --> 00:38:56.540
may happen before Core Animation gets
to doing its layout and drawing for

00:38:56.540 --> 00:38:58.840
this particular turn of the run loop.

00:38:58.950 --> 00:39:00.590
Now,
the thing that'll tip you off here is

00:39:00.900 --> 00:39:04.200
that if you log on the outside and then
log within the first dispatch block,

00:39:04.200 --> 00:39:05.840
you'll have pretty much the same time.

00:39:05.990 --> 00:39:08.080
And it'll be unusually fast.

00:39:08.250 --> 00:39:11.050
So in that case,
you can try this trick of dispatching it

00:39:11.050 --> 00:39:15.440
again to make sure that you've captured
the time that Core Animation is using.

00:39:15.440 --> 00:39:19.350
So I'm going to build and run it here.

00:39:27.080 --> 00:39:28.720
Killing off the app.

00:39:28.860 --> 00:39:35.360
And here we go.

00:39:35.360 --> 00:39:39.170
So now we see the
launch time from before.

00:39:39.270 --> 00:39:46.000
And we see that it took about 400
milliseconds to load one of the tabs.

00:39:46.000 --> 00:39:46.000
And if we're switching here,

00:39:46.460 --> 00:39:51.400
It's taken about 450-ish
milliseconds between switching tabs.

00:39:51.450 --> 00:39:52.990
That's--again, it's okay.

00:39:53.100 --> 00:39:53.660
It's not great.

00:39:53.660 --> 00:39:57.860
We'd like to keep our interactions down
within a couple hundred milliseconds.

00:39:57.890 --> 00:40:02.170
I mean, ideally, it's instantaneous, but,
you know, you do the best that you can.

00:40:02.420 --> 00:40:06.550
So the next step, as usual,
is to take a time profile.

00:40:06.750 --> 00:40:10.590
So I'm gonna fire up Instruments again.

00:40:12.040 --> 00:40:17.070
Do the same trick that
Ben did with deferred mode.

00:40:17.180 --> 00:40:20.180
Hit record and switch tabs.

00:40:20.230 --> 00:40:24.280
So I'm switching,
and I'm switching again.

00:40:24.280 --> 00:40:24.280
All right.

00:40:25.690 --> 00:40:29.730
Now we can see very clearly here what
the times are when we're switching tabs.

00:40:29.890 --> 00:40:32.310
So just like before,
we can use the inspection

00:40:32.330 --> 00:40:33.590
range to zoom in.

00:40:33.610 --> 00:40:36.230
What I'm going to do here is
actually use a keyboard shortcut.

00:40:36.300 --> 00:40:42.390
I'm going to hold Option and drag,
and that will also create

00:40:42.450 --> 00:40:43.100
the inspection range.

00:40:43.170 --> 00:40:46.160
So you can see here there's
500-ish milliseconds.

00:40:46.210 --> 00:40:48.830
And I'm going to use Shift to zoom in.

00:40:53.730 --> 00:40:54.690
How do we take a look at this trace?

00:40:54.740 --> 00:40:58.440
So the easiest thing to do is
start with this extended detail,

00:40:58.440 --> 00:41:02.700
which will give you a backtrace of
the hottest backtrace that you've got.

00:41:02.820 --> 00:41:06.980
You know, you could go down here and you
can expand this tree and manually

00:41:06.980 --> 00:41:09.690
look at the times on the side.

00:41:09.720 --> 00:41:13.290
and look for things that
take an unusually long time.

00:41:13.380 --> 00:41:16.740
But this thing on the side actually
gives you a shortcut into doing that.

00:41:16.740 --> 00:41:20.800
So for example,
one of the hot traces here

00:41:20.810 --> 00:41:23.780
we see is UILabelDrawRect.

00:41:23.780 --> 00:41:27.820
And looking at the app,
we can see that there are actually

00:41:27.820 --> 00:41:30.100
a lot of labels going on here.

00:41:30.100 --> 00:41:33.930
For every session,
there's the session title and the name,

00:41:33.930 --> 00:41:36.220
and there's quite a few of these.

00:41:36.220 --> 00:41:40.180
So this makes sense,
which is always a good thing.

00:41:40.180 --> 00:41:42.980
The question is,
what can we do about this?

00:41:42.980 --> 00:41:47.260
Well, first,
before you even try to fix label drawing,

00:41:47.260 --> 00:41:50.400
you want to confirm that your
hypothesis is actually a problem.

00:41:50.400 --> 00:41:54.170
So I'm going to go back to the app.

00:41:55.130 --> 00:41:56.590
And I'm going to confirm this.

00:41:56.670 --> 00:41:58.560
You know, it's label drawing,
and it's actually largely

00:41:58.560 --> 00:42:03.450
here in NSString Drawing Rect.

00:42:03.810 --> 00:42:07.090
So it's actually doing
the string drawing.

00:42:07.540 --> 00:42:11.340
An easy way to confirm that this is a
problem is to just not draw the strings.

00:42:11.340 --> 00:42:19.970
We'll keep the views to make sure that
it's not view processing and whatnot.

00:42:19.970 --> 00:42:19.970
So I can go to -- let me see.

00:42:28.530 --> 00:42:31.010
And what I'm going to do
is just remove this text.

00:42:31.250 --> 00:42:32.210
So we'll keep the views around.

00:42:32.280 --> 00:42:38.800
And see what that does.

00:42:42.720 --> 00:42:45.440
This is the process of confirming
the hypothesis from the workflow

00:42:45.440 --> 00:42:48.140
that we saw in the beginning.

00:42:48.260 --> 00:42:50.250
So we'll run the app again.

00:42:50.500 --> 00:42:53.130
So the idea here is that if you
don't see enough improvement,

00:42:53.130 --> 00:42:56.490
it's really not worth spending a
lot of time optimizing this case.

00:42:56.590 --> 00:43:01.340
I mean, you can see here that this
is not a shippable app.

00:43:01.400 --> 00:43:04.640
But in the meantime,
it's gotten really fast.

00:43:04.740 --> 00:43:09.140
At least 100-- almost
150 milliseconds faster.

00:43:09.190 --> 00:43:13.300
Okay, so now we have an avenue of
optimization that we can pursue.

00:43:13.300 --> 00:43:16.570
What can we do to maintain
a shippable app while--

00:43:16.890 --> 00:43:18.100
while maintaining the speed.

00:43:18.250 --> 00:43:22.080
So going back to the principles and
strategies that Ben talked about before,

00:43:22.080 --> 00:43:24.720
one thing that we can do is
precompute or don't do it again.

00:43:24.740 --> 00:43:29.820
So the labels are actually something
that you're doing all the time.

00:43:29.820 --> 00:43:32.300
A lot of the room titles are the same.

00:43:32.480 --> 00:43:35.190
So even the lab sessions
have common names.

00:43:35.360 --> 00:43:37.600
So there's actually a lot
of redundant work there.

00:43:37.640 --> 00:43:40.900
So one thing about redundant work
is you can save doing it multiple

00:43:40.920 --> 00:43:42.150
times if you just cache it.

00:43:42.150 --> 00:43:48.030
So what I'm going to do is I'm
going to cache the labels as

00:43:54.600 --> 00:43:58.880
I've already done this,
because it's not exactly

00:43:58.880 --> 00:44:01.830
a trivial thing to do.

00:44:07.550 --> 00:44:11.270
So I'm caching the labels,
and basically what this does is it

00:44:11.270 --> 00:44:16.770
replaces the UI labels in the app with

00:44:17.100 --> 00:44:29.300
[Transcript missing]

00:44:30.280 --> 00:44:32.200
We're down to the 300
millisecond range again.

00:44:32.260 --> 00:44:34.010
You'll notice that it's quicker later.

00:44:34.250 --> 00:44:38.200
You know, we're down in the 200s,
because, again, this is a cache,

00:44:38.200 --> 00:44:40.110
and ideally what I would
do is save it on disk.

00:44:40.380 --> 00:44:45.300
But, you know, this is incremental,
so... Again, you can see in the app.

00:44:45.900 --> 00:44:48.650
We have text, and it's quicker.

00:44:48.770 --> 00:44:50.560
So this is kind of the
cycle that you go through.

00:44:50.560 --> 00:44:53.230
From here, I would go on to time profile,
look for something else,

00:44:53.310 --> 00:44:54.400
and optimize again.

00:44:54.570 --> 00:44:59.080
But this is the general workflow
through the circle that we saw earlier.

00:45:01.650 --> 00:45:05.030
So besides doing this process
and minimizing the time,

00:45:05.260 --> 00:45:09.280
making your algorithm faster and doing
trade-offs and things of that sort,

00:45:09.510 --> 00:45:11.480
you can just get work
off of the main thread.

00:45:11.590 --> 00:45:17.050
That will leave your main thread time
to process events and be responsive.

00:45:17.170 --> 00:45:19.620
And there's two main
ways that this happens.

00:45:19.780 --> 00:45:21.530
Implicit and explicit.

00:45:21.540 --> 00:45:23.310
So implicitly,
there are lots of frameworks

00:45:23.460 --> 00:45:25.740
that will take care of things
for you behind your back.

00:45:25.800 --> 00:45:28.500
Because we know that
things take a long time.

00:45:28.500 --> 00:45:29.780
The view and layer animations.

00:45:29.900 --> 00:45:32.480
Not the drawing, but the animations when
things move across the screen.

00:45:32.480 --> 00:45:36.650
That happens in a separate process
and your app is not responsible

00:45:36.650 --> 00:45:38.500
for it after it's set it up.

00:45:38.610 --> 00:45:40.330
The next is layer compositing.

00:45:40.330 --> 00:45:43.720
After you've drawn your layers
and created your view hierarchy,

00:45:43.800 --> 00:45:46.510
the actual processing of
that hierarchy happens,

00:45:46.510 --> 00:45:48.490
again, off in another process.

00:45:48.560 --> 00:45:52.510
And another very,
very interesting one is ping decoding.

00:45:52.890 --> 00:45:55.410
Oftentimes,
you might look at a trace and wonder,

00:45:55.410 --> 00:45:56.760
how is this so fast?

00:45:56.760 --> 00:45:58.940
And notice a lot of ping
decoding in the background.

00:45:59.100 --> 00:46:03.200
So what generally happens is ping
decoding will dispatch off into the

00:46:03.210 --> 00:46:08.080
background and use multiple cores even
and then come back to the main thread.

00:46:08.560 --> 00:46:13.220
Now, one very important thing to remember
is that scrolling is not an animation.

00:46:13.350 --> 00:46:17.020
It sets up a timer that happens
on the main run loop and processes

00:46:17.020 --> 00:46:18.790
events on the main run loop.

00:46:18.970 --> 00:46:22.370
So keep that part of Snappy.

00:46:22.560 --> 00:46:25.960
Explicit concurrency is
where you guys get control.

00:46:25.960 --> 00:46:31.960
And there's a few ways that you can
exploit having multiple threads.

00:46:31.960 --> 00:46:34.830
The easiest, the quickest,
is Grand Central Dispatch.

00:46:34.890 --> 00:46:36.570
There's lots of information about it.

00:46:36.600 --> 00:46:39.060
I hope you all love it like I do.

00:46:39.110 --> 00:46:42.260
If you need a little bit more control,
there's NSOperationQueue.

00:46:42.260 --> 00:46:45.160
It lets you have some
control over the widths,

00:46:45.190 --> 00:46:48.490
a little bit more control
over priority and tasks,

00:46:48.510 --> 00:46:51.600
a little bit more setup,
but sometimes it's useful.

00:46:51.790 --> 00:46:53.770
And finally,
NSThread gives you full control

00:46:54.100 --> 00:46:55.890
over what thread everything runs on.

00:46:55.900 --> 00:47:00.450
Now, here's an example of where you might
want to use Grand Central Dispatch.

00:47:00.520 --> 00:47:04.300
And this is a case of doing it later,
I suppose.

00:47:04.300 --> 00:47:07.880
So let's say you're in the middle of an
animation and you get an event that says,

00:47:07.980 --> 00:47:11.350
you know, you should update something by
reading something off a string.

00:47:11.540 --> 00:47:13.690
Reading something off a disk, sorry.

00:47:14.100 --> 00:47:16.780
And by doing so,
you've now dropped a frame

00:47:17.270 --> 00:47:20.760
because the time to read
something off a disk is not quick.

00:47:20.980 --> 00:47:22.580
So it's pretty simple.

00:47:22.580 --> 00:47:24.980
You dispatch it off
onto a background queue,

00:47:25.050 --> 00:47:29.120
and then things proceed
normally as if you did no work.

00:47:29.680 --> 00:47:34.200
and doing the code is almost
as simple as visualizing it.

00:47:34.200 --> 00:47:36.350
You have your original code
that's synchronously grabbing

00:47:36.420 --> 00:47:39.060
something off of disk,
setting a text field.

00:47:39.130 --> 00:47:41.500
You wrap the whole thing
in a dispatch async,

00:47:41.570 --> 00:47:44.860
do it in the background,
and then this is key,

00:47:44.860 --> 00:47:48.280
you have to dispatch back
to the main thread if you're

00:47:48.280 --> 00:47:50.000
doing something with UIKit.

00:47:50.040 --> 00:47:52.950
Thread safety we'll
talk about in a second.

00:47:54.390 --> 00:47:56.980
So a few gotchas with GCD.

00:47:57.340 --> 00:48:02.140
It is possible to have
GCD spawn too many threads.

00:48:02.140 --> 00:48:03.530
And this is actually a problem.

00:48:03.650 --> 00:48:07.250
There's significant overhead, well,
depending on how many threads you have.

00:48:07.350 --> 00:48:09.700
There is overhead with
having too many threads.

00:48:09.720 --> 00:48:11.100
So this can happen.

00:48:11.380 --> 00:48:13.670
And there's also a physical
hard limit on the number of

00:48:13.790 --> 00:48:15.290
threads that can get spawned.

00:48:15.300 --> 00:48:19.640
And you don't want that to happen.

00:48:19.640 --> 00:48:19.640
Bad things happen.

00:48:19.980 --> 00:48:21.430
So how can this happen
and how can you avoid it?

00:48:21.640 --> 00:48:23.520
So it's pretty simple.

00:48:23.520 --> 00:48:26.460
You start with one of the
global concurrent queues.

00:48:26.510 --> 00:48:28.490
You dispatch some blocks onto it.

00:48:28.590 --> 00:48:29.890
And they're running and
they're doing their thing.

00:48:29.890 --> 00:48:30.890
This is fine.

00:48:31.170 --> 00:48:35.200
And the problem comes in when these
blocks do something that takes a long

00:48:35.200 --> 00:48:37.100
time and is waiting on something.

00:48:37.440 --> 00:48:39.730
If you're waiting for the network,
you're waiting for disk, lock,

00:48:39.730 --> 00:48:41.470
something like that,
then these guys are blocked.

00:48:41.760 --> 00:48:44.750
The system detects that and figures, oh,
we can do some more work.

00:48:45.100 --> 00:48:46.140
So let's find some more threads.

00:48:46.200 --> 00:48:51.710
And this is okay as long as
this doesn't go on in a loop.

00:48:52.310 --> 00:48:55.900
Because then you'll just
get an explosion of threads.

00:48:55.900 --> 00:48:57.100
And it's actually pretty innocuous.

00:48:57.100 --> 00:48:59.420
The code that can spawn
this looks pretty innocuous.

00:48:59.560 --> 00:49:04.930
So be careful for things that --
where you're synchronously blocking

00:49:05.020 --> 00:49:07.540
in a loop in a dispatch block.

00:49:07.540 --> 00:49:09.620
Some solutions to this.

00:49:10.380 --> 00:49:11.300
Serial queue.

00:49:11.300 --> 00:49:13.230
You know,
just don't do things concurrently.

00:49:13.350 --> 00:49:14.540
Sometimes that's okay.

00:49:14.570 --> 00:49:19.240
If things are going on quick,
or you don't need things immediately,

00:49:19.240 --> 00:49:20.300
this works.

00:49:20.450 --> 00:49:23.780
Dispatch sources is one option,
which will control the dispatching

00:49:23.780 --> 00:49:28.290
of blocks onto those queues,
so it's not happening behind your back.

00:49:28.300 --> 00:49:33.260
This is a case where NSOperationQueue,
which has a concurrency width option,

00:49:33.370 --> 00:49:35.300
and that will limit the number
of threads that get spawned.

00:49:35.300 --> 00:49:38.460
And finally,
if you're just doing NSURL connections,

00:49:38.460 --> 00:49:40.300
just use the async methods.

00:49:40.300 --> 00:49:40.300
It'll take care of it.

00:49:40.390 --> 00:49:42.970
So, pretty easy solutions.

00:49:43.520 --> 00:49:45.140
Thread safety.

00:49:45.140 --> 00:49:49.000
Like I mentioned before,
there are some cases where you need to be

00:49:49.080 --> 00:49:51.700
careful about what threads things run on.

00:49:51.970 --> 00:49:54.600
So the big gotcha is UIKit.

00:49:54.630 --> 00:49:57.540
In many cases, in most cases,
UIKit can only be called

00:49:57.580 --> 00:49:58.200
on the main thread.

00:49:58.200 --> 00:50:00.140
If you call it on the main thread,
bad things happen.

00:50:00.300 --> 00:50:02.900
Or they could,
and that gets harder to debug.

00:50:03.130 --> 00:50:04.410
There are some exceptions.

00:50:04.410 --> 00:50:06.900
There's actually talk
about this yesterday.

00:50:06.900 --> 00:50:08.900
You can refer back to
the videos and notes.

00:50:08.900 --> 00:50:11.760
UI image, UI graphics,
those are actually okay to

00:50:11.760 --> 00:50:14.900
use in the background and
can be used very effectively.

00:50:14.900 --> 00:50:21.880
A couple other frameworks.

00:50:21.900 --> 00:50:23.110
Most of the rest of Cocoa, Cocoa Touch,
is thread safe insofar as you can

00:50:23.140 --> 00:50:26.820
use multiple objects from any thread,
but you can only use them once at a time.

00:50:26.930 --> 00:50:31.370
So you need to either dispatch
onto the same thread to use them,

00:50:31.380 --> 00:50:35.090
or the same queue,
or lock around access to them.

00:50:35.410 --> 00:50:39.020
And finally, there are libraries that
are completely thread safe.

00:50:39.120 --> 00:50:40.270
You don't have to worry about it at all.

00:50:40.290 --> 00:50:41.300
They'll do their own locking.

00:50:41.470 --> 00:50:44.960
The one that you might be familiar
with is Objective-C introspection.

00:50:44.960 --> 00:50:47.240
So you're calling in to
getting information about

00:50:47.240 --> 00:50:48.540
your Objective-C objects.

00:50:48.710 --> 00:50:49.800
You don't need a lock.

00:50:49.960 --> 00:50:51.300
You can do this from multiple threads.

00:50:51.420 --> 00:50:53.300
And Objective-C will handle it for you.

00:50:53.300 --> 00:50:56.820
Don't do it too much,
because you might get into a

00:50:56.900 --> 00:50:59.550
contention with that one massive lock.

00:50:59.800 --> 00:51:02.870
And then in that case,
you will have to use system trace

00:51:03.030 --> 00:51:04.720
to figure out what's going on.

00:51:04.980 --> 00:51:06.790
And we'll have a demo of that in a bit.

00:51:06.800 --> 00:51:10.800
There are also possibly third party
frameworks that could lead you there.

00:51:13.000 --> 00:51:15.900
Finally, background queues.

00:51:15.900 --> 00:51:19.180
We introduced this a few releases ago,
but it bears repeating.

00:51:19.180 --> 00:51:23.040
These background queues,
dispatch queue priority background

00:51:23.040 --> 00:51:24.850
is extremely low priority.

00:51:24.980 --> 00:51:27.700
I/O is throttled, your CPU is throttled.

00:51:28.190 --> 00:51:31.900
Basically, you're telling the system,
"I really don't care when this finishes.

00:51:31.900 --> 00:51:35.650
Just do it whenever you've got
time." This can take seconds,

00:51:35.780 --> 00:51:37.900
tens of seconds, minutes.

00:51:37.900 --> 00:51:42.270
Only dispatch things onto this queue,
into this priority, when you really don't

00:51:42.270 --> 00:51:43.900
care when it finishes.

00:51:43.900 --> 00:51:48.540
If you actually care,
then use dispatch priority low.

00:51:49.630 --> 00:51:55.920
And finally,
getting work off the main thread is good.

00:51:55.930 --> 00:51:58.200
There are cases when

00:51:58.490 --> 00:52:00.640
You'll notice that you're not
spending a whole lot of time

00:52:00.640 --> 00:52:03.710
CPU-wise on the main thread,
but your thread's blocked.

00:52:03.900 --> 00:52:07.730
And this is also a problem,
because you're not processing events.

00:52:07.790 --> 00:52:09.860
So you'll look into time
profiler and it's like,

00:52:09.890 --> 00:52:11.630
there's nothing going on here.

00:52:11.730 --> 00:52:12.310
What's the deal?

00:52:12.430 --> 00:52:14.660
And there are various causes for this.

00:52:14.700 --> 00:52:16.670
Disk network, locking, etc.

00:52:16.840 --> 00:52:18.700
So how can you figure this out?

00:52:18.700 --> 00:52:21.220
Like I said, time profiler,
it's kind of hard to find.

00:52:21.230 --> 00:52:23.880
You pretty much have to go
to the CPU strategy view,

00:52:23.880 --> 00:52:27.420
look at individual call traces at the
beginning and end of this long blank

00:52:27.730 --> 00:52:29.970
space and try to deduce what's going on.

00:52:30.380 --> 00:52:32.170
You can use record waiting threads.

00:52:32.170 --> 00:52:35.280
That will actually give you the
back traces of the threads while

00:52:35.470 --> 00:52:37.280
they're not running on the CPU.

00:52:37.280 --> 00:52:38.860
And that can be effective.

00:52:38.860 --> 00:52:41.930
But really system trace
is the way to go here.

00:52:54.290 --> 00:53:12.130
So what I've got here
is a pretty simple app.

00:53:12.310 --> 00:53:14.380
It just has a button,
and it's a button that you can press.

00:53:14.380 --> 00:53:16.730
And in response to the button press,
it sends a synchronous URL request.

00:53:16.730 --> 00:53:20.380
I know it's kind of a tired example,
but it's one that works every single

00:53:20.440 --> 00:53:24.910
time to lock up your main thread
to show you how System Trace works.

00:53:25.040 --> 00:53:28.050
So let me show you the app.

00:53:28.050 --> 00:53:33.660
So the idea is you click "Load
URL," and this might take a while.

00:53:33.660 --> 00:53:39.820
It took two seconds because the Wi-Fi in
this room is pretty bad right now.

00:53:39.900 --> 00:53:41.620
So how do we detect this?

00:53:41.620 --> 00:53:43.360
Now,
if you looked at this in time profile,

00:53:43.360 --> 00:53:46.140
you would see almost no
time on the main thread,

00:53:46.170 --> 00:53:48.500
almost no CPU time on the main thread.

00:53:48.500 --> 00:53:54.500
But if you take a look at System Trace,
which I'll switch to --

00:53:55.810 --> 00:53:59.780
If you take a look at System Trace,
you can use it to find blocking

00:53:59.780 --> 00:54:01.000
system calls on the main thread.

00:54:01.000 --> 00:54:05.740
So I'm just going to click record.

00:54:10.550 --> 00:54:14.000
And then I'm going to click Load URL.

00:54:14.000 --> 00:54:17.660
And it says it took 1.5
seconds to load that URL.

00:54:18.700 --> 00:54:20.890
And as I said,
if you looked at this in System Trace,

00:54:20.970 --> 00:54:24.340
you would see almost no
work on the main thread.

00:54:24.550 --> 00:54:27.470
Now, if you're an advanced user,
you'll love System Trace because it

00:54:27.530 --> 00:54:32.960
logs all sorts of system operations,
such as scheduling events, VM events,

00:54:32.960 --> 00:54:33.940
and system calls.

00:54:34.230 --> 00:54:36.080
In this case,
we are just going to look at system

00:54:36.080 --> 00:54:39.330
calls for this demonstration.

00:54:39.420 --> 00:54:45.160
And my application was called
Synchronous URL Tester,

00:54:45.180 --> 00:54:47.860
and I'm going to focus
on that application,

00:54:47.890 --> 00:54:50.490
and I'm going to click on the
arrow here to focus on all the

00:54:50.520 --> 00:54:53.100
system calls on its main thread.

00:54:53.130 --> 00:54:55.010
And as I said,

00:54:55.250 --> 00:55:01.060
The basic idea is to look at the wait
time of system calls on the main thread.

00:55:01.130 --> 00:55:04.010
So I'm going to sort by
wait time descending,

00:55:04.150 --> 00:55:08.130
and you can actually click on
each of these system calls and

00:55:08.300 --> 00:55:13.120
get a back trace for how long it
took that system call to complete.

00:55:13.300 --> 00:55:15.660
So some of these are
actually pretty innocent.

00:55:15.660 --> 00:55:18.880
So for instance,
here's a 73 millisecond wait time,

00:55:18.880 --> 00:55:23.440
and it's in a call stack
that's actually pretty bare.

00:55:23.460 --> 00:55:25.220
It's just your event
loop waiting for events.

00:55:25.220 --> 00:55:25.970
So that's good.

00:55:25.970 --> 00:55:28.080
That means your event loop
is waiting for events,

00:55:28.080 --> 00:55:30.030
and it's actually responsive.

00:55:30.120 --> 00:55:34.870
Now, the problem is if you--in this case,
there's a 1.5 second block.

00:55:35.180 --> 00:55:41.660
And you have a call stack
that is in this case.

00:55:41.660 --> 00:55:46.010
View controller did press button and it
calls to send synchronous URL request.

00:55:46.190 --> 00:55:48.530
So that's what you're
looking for in system trace.

00:55:48.530 --> 00:55:52.250
You'll focus on the main thread,
sort by wait time descending,

00:55:52.250 --> 00:55:55.950
and see if there are any back
traces in event processing.

00:55:56.030 --> 00:55:59.470
And so that's sort of a quick
way to find blocking system

00:55:59.470 --> 00:56:01.460
calls on your main thread.

00:56:01.510 --> 00:56:01.710
Okay.

00:56:01.720 --> 00:56:05.440
So just to wrap up,
if you take notes on this,

00:56:05.530 --> 00:56:07.600
if you're doing nothing
else away from this talk,

00:56:07.600 --> 00:56:09.080
remember to profile your application.

00:56:09.080 --> 00:56:13.460
That's the key to improving
your application's launch time.

00:56:13.460 --> 00:56:17.790
Understand app launch to figure out
what's going on in those time profiles.

00:56:17.790 --> 00:56:23.700
And avoid blocking the main thread
using dispatch and other techniques.

00:56:23.700 --> 00:56:25.830
For more information,
contact our developer evangelist,

00:56:25.830 --> 00:56:26.670
Michael Jurowicz.

00:56:26.670 --> 00:56:29.740
The iOS app programming guide has
a nice flow chart of different

00:56:29.740 --> 00:56:31.730
phases of application launch.

00:56:31.730 --> 00:56:35.100
And you can ask us
questions on the dev forums.

00:56:35.100 --> 00:56:35.530
That's all.