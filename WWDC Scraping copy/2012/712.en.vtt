WEBVTT

00:00:10.210 --> 00:00:15.540
Good morning and welcome.

00:00:15.570 --> 00:00:16.630
Thanks.

00:00:16.830 --> 00:00:19.700
Welcome to Asynchronous
Design Patterns with Blocks,

00:00:19.700 --> 00:00:21.130
GCD, and XPC.

00:00:21.380 --> 00:00:26.540
My name is Kevin Van Vechten and I'm
the manager of the GCD and XPC team.

00:00:27.270 --> 00:00:31.350
And today we're going to start off
with a bit of an overview of blocks,

00:00:31.490 --> 00:00:36.240
GCD, and XPC for those of you who might
not be familiar with the technology.

00:00:36.330 --> 00:00:40.360
And then we're going to dive into
some detail about what's new with

00:00:40.360 --> 00:00:43.600
Objective-C and ARC in GCD and XPC.

00:00:43.680 --> 00:00:47.420
And then finish up the talk with a lot
of discussion about how to use these

00:00:47.500 --> 00:00:52.350
technologies to implement asynchronous
design patterns in your code.

00:00:53.550 --> 00:00:58.720
So first, let's get started with an
introduction to blocks.

00:00:58.720 --> 00:01:01.870
The best way to think about
blocks is by first thinking

00:01:01.870 --> 00:01:03.640
about function pointers in C.

00:01:03.890 --> 00:01:07.610
Blocks are really
anonymous functions in C.

00:01:07.670 --> 00:01:11.360
So here we have a type declaration
of a callback function.

00:01:11.420 --> 00:01:13.000
It takes a string as an argument.

00:01:13.000 --> 00:01:15.000
It doesn't return any value.

00:01:15.020 --> 00:01:20.100
And we can turn this into a block type
simply by changing the star to a caret.

00:01:20.100 --> 00:01:23.630
And the caret is a special
character the compiler recognizes to

00:01:23.630 --> 00:01:25.600
indicate that this is a block type.

00:01:25.860 --> 00:01:30.190
But otherwise,
it looks the same as a function pointer.

00:01:31.640 --> 00:01:34.800
So we can use these blocks in
a much different way than we

00:01:34.800 --> 00:01:38.400
typically use function pointers,
and we can actually

00:01:38.410 --> 00:01:39.600
declare a block variable.

00:01:39.600 --> 00:01:41.110
So we have our type, callback block.

00:01:41.290 --> 00:01:43.100
The variable name is b.

00:01:43.120 --> 00:01:46.600
And then instead of just giving it
the address of a function to call,

00:01:46.600 --> 00:01:51.100
we can actually give it the body of the
function right there in line in our code.

00:01:51.100 --> 00:01:54.600
We declare the arguments,
which in this case is a string,

00:01:54.770 --> 00:01:58.670
and then the body of code
prints that string out.

00:02:00.450 --> 00:02:03.980
Calling the block is really the same
as invoking a function pointer in C.

00:02:04.120 --> 00:02:07.100
All you need to do is reference
the block variable by name

00:02:07.130 --> 00:02:08.830
and pass it the arguments.

00:02:08.930 --> 00:02:12.230
So in this example,
if we were to compile and run this code,

00:02:12.320 --> 00:02:14.990
it would just print "Hello, world."

00:02:17.100 --> 00:02:20.970
So declaring the body of code in
place right where you need it is

00:02:20.970 --> 00:02:23.170
really the key benefit of blocks.

00:02:23.310 --> 00:02:26.230
With function pointers,
you need to define a function that's

00:02:26.310 --> 00:02:28.420
a helper somewhere else in your code.

00:02:28.460 --> 00:02:32.120
You need to make changes
there and wherever you use it,

00:02:32.120 --> 00:02:38.040
you know, if you need to renegotiate how
you pass data to that code.

00:02:38.040 --> 00:02:41.500
But with blocks,
since you declare them directly in line,

00:02:41.660 --> 00:02:45.700
they actually can make reference to
variables in the enclosing scope.

00:02:45.840 --> 00:02:48.310
So if you have a big function and
then you declare a block in it,

00:02:48.440 --> 00:02:51.610
any variables outside of the
block in the function are

00:02:51.610 --> 00:02:53.040
actually visible to the block.

00:02:53.040 --> 00:02:57.120
And we'll go into detail in a
moment to see how that works.

00:02:57.170 --> 00:02:59.820
And even further than just
referring to these variables,

00:02:59.960 --> 00:03:02.830
you can actually modify
variables in the enclosing scope,

00:03:02.910 --> 00:03:05.290
which is also very powerful.

00:03:05.850 --> 00:03:10.180
So let's take a look at these three
benefits of blocks in the context of

00:03:10.180 --> 00:03:17.730
three very common types of blocks:
completion, comparison, and enumeration.

00:03:18.610 --> 00:03:22.180
So completion is something you probably
are all familiar with to some extent.

00:03:22.180 --> 00:03:27.040
There's typically a pattern where
you tell the system to perform

00:03:27.040 --> 00:03:31.070
some activity on your behalf,
and then it calls a function that

00:03:31.070 --> 00:03:35.100
you provide when it's done and
passes the result of that operation.

00:03:35.280 --> 00:03:42.170
So we might have a
completion callback function,

00:03:42.170 --> 00:03:42.170
and we can turn that into a block.

00:03:42.370 --> 00:03:47.990
And then let's say we've defined a
routine ourselves or maybe we're making

00:03:47.990 --> 00:03:51.400
use of an API call that looks like
this where it downloads some resource

00:03:51.400 --> 00:03:53.400
asynchronously from the network.

00:03:53.520 --> 00:03:57.210
All we have to do is provide it a
URL and then we provide it a completion

00:03:57.210 --> 00:04:02.050
block that gets called when the resource
has been downloaded and that passes

00:04:02.050 --> 00:04:04.760
us back the data that was downloaded.

00:04:05.060 --> 00:04:09.910
Well, we can combine these two together
and write a very simple routine that,

00:04:10.110 --> 00:04:14.420
say, updates an image in one of
our views based on the data

00:04:14.420 --> 00:04:16.700
downloaded from that URL.

00:04:16.810 --> 00:04:19.760
So you can see we're just
downloading data from the URL.

00:04:19.970 --> 00:04:23.600
When that operation is complete,
we've provided a completion block.

00:04:23.630 --> 00:04:25.140
We get past the data.

00:04:25.190 --> 00:04:27.060
We can turn that data into an NSImage.

00:04:27.130 --> 00:04:30.590
We can update our view,
and then we're done.

00:04:31.690 --> 00:04:34.570
So the key here is we're
declaring it in place.

00:04:34.600 --> 00:04:39.340
We don't have to define an external
function and refer to that.

00:04:40.810 --> 00:04:42.400
Our next example is comparison.

00:04:42.450 --> 00:04:45.600
You've probably all written a
comparison function at some point.

00:04:45.650 --> 00:04:48.240
To look at two values,
decide which one is greater

00:04:48.240 --> 00:04:51.640
or less than the other value,
and maybe you would use this

00:04:51.640 --> 00:04:53.900
in some sort of sort operation.

00:04:54.170 --> 00:04:57.800
So we're taking two arguments,
returning a comparison result.

00:04:57.800 --> 00:05:00.300
We'll turn that into a block.

00:05:00.490 --> 00:05:04.160
And we'll assume that there's some
sort API on the system or some

00:05:04.160 --> 00:05:09.200
function that we've defined that
sorts the contents of a mutable array.

00:05:09.200 --> 00:05:11.480
In this example,
we're going to have a mutable

00:05:11.550 --> 00:05:14.870
array of string objects,
and then we're going to

00:05:14.870 --> 00:05:16.960
sort them in some way.

00:05:17.120 --> 00:05:21.450
Well, we can very easily define a helper
routine that sorts all the strings

00:05:21.450 --> 00:05:23.260
in this array alphabetically.

00:05:23.340 --> 00:05:27.980
And all it needs to do is call
the compare method on one of the

00:05:27.980 --> 00:05:30.930
strings to compare it against the
other string and return the results.

00:05:30.940 --> 00:05:34.380
And then at the end of the call,
all the elements in the

00:05:34.380 --> 00:05:35.940
array will be sorted.

00:05:37.000 --> 00:05:41.500
But we can expand this a little bit and
really make use of blocks by referring

00:05:41.500 --> 00:05:43.210
to a variable in the enclosing scope.

00:05:43.360 --> 00:05:47.050
Let's say we want a more
generic sort operation.

00:05:47.210 --> 00:05:50.750
We want to be able to sometimes
sort case-sensitively and other

00:05:50.750 --> 00:05:53.240
times sort case-insensitively.

00:05:53.290 --> 00:05:56.250
Well, we can take an argument to our
helper routine and turn that

00:05:56.250 --> 00:06:01.040
into the right option flags for
the compare method of NSString.

00:06:01.100 --> 00:06:05.140
And we can do that in
the calling function.

00:06:05.170 --> 00:06:11.070
And at the time the comparison block
is passed into the sort routine,

00:06:11.390 --> 00:06:14.900
It has reference to whatever
option flags we specified.

00:06:14.950 --> 00:06:19.080
So we've really taken our completion
callback and made it very generic,

00:06:19.250 --> 00:06:20.070
very simply.

00:06:20.120 --> 00:06:24.670
If we were to try to do
this with function pointers,

00:06:24.700 --> 00:06:28.100
we would probably have to define
some sort of context structure

00:06:28.110 --> 00:06:31.700
and get the data into the context
structure and pass it along,

00:06:31.720 --> 00:06:33.800
and then, you know,
do a bunch of casting and make

00:06:33.800 --> 00:06:35.300
sure everything's all in sync.

00:06:35.370 --> 00:06:38.090
But with blocks,
we can just refer to the variable

00:06:38.100 --> 00:06:39.710
exactly where we need it.

00:06:41.850 --> 00:06:45.160
And finally,
let's look at the example of iteration.

00:06:45.260 --> 00:06:46.250
Pretty common pattern.

00:06:46.410 --> 00:06:49.000
You know, perhaps you have a lot of data.

00:06:49.000 --> 00:06:52.000
In this case,
we'll talk about numbers in a set.

00:06:52.050 --> 00:06:58.400
And we just want to enumerate every item
in the set and apply some function to it.

00:06:58.420 --> 00:07:01.700
We can turn our Applier
function into a block.

00:07:02.680 --> 00:07:05.560
And we can assume that there's an API on
the system or something that we've

00:07:05.570 --> 00:07:10.540
written that does the iteration of
all the values in the set and applies

00:07:10.620 --> 00:07:13.000
our function to each of those values.

00:07:13.100 --> 00:07:16.600
And so we'll use these two
concepts to implement something

00:07:16.690 --> 00:07:18.270
that's pretty powerful.

00:07:20.260 --> 00:07:24.260
We will have a helper routine
that returns the maximum

00:07:24.280 --> 00:07:25.840
value that we see in the set.

00:07:25.850 --> 00:07:30.530
And we can do this very easily by making
use of the fact that blocks can modify

00:07:30.550 --> 00:07:33.360
the variables in the enclosing scope.

00:07:33.420 --> 00:07:38.520
Now, you'll notice in this example our
result variable has this "under

00:07:38.540 --> 00:07:41.460
under block" keyword attached to it.

00:07:41.530 --> 00:07:45.780
By default, all the variables that are
referenced by blocks are constant

00:07:45.930 --> 00:07:48.150
read-only copies of the variable.

00:07:48.290 --> 00:07:50.240
And that's done for performance reasons.

00:07:50.330 --> 00:07:53.070
The compiler has to do a little
bit extra work if you want to

00:07:53.070 --> 00:07:54.490
make the variable modifiable.

00:07:54.560 --> 00:07:56.160
So we don't do it by default.

00:07:56.200 --> 00:07:58.000
But when you apply this
keyword to the variable,

00:07:58.000 --> 00:08:00.720
you're telling the compiler
that you do wish this variable

00:08:00.720 --> 00:08:02.480
to be modifiable by the block.

00:08:02.560 --> 00:08:06.000
The compiler does the extra work
that's needed to make that possible.

00:08:06.110 --> 00:08:09.270
And so here we have a result
variable that can be modified by our

00:08:09.270 --> 00:08:11.460
callback block or our applier block.

00:08:11.460 --> 00:08:13.960
And we'll start off with
the best guess value.

00:08:13.960 --> 00:08:17.400
You know, let's say it's the smallest
number we can possibly represent.

00:08:17.550 --> 00:08:20.960
So whatever maximum we find is
probably going to be bigger than that.

00:08:20.960 --> 00:08:25.700
And we apply our block to all
of the numbers in the set.

00:08:25.960 --> 00:08:30.960
The supplier function calls
our block once for each number.

00:08:31.110 --> 00:08:33.400
Within the block,
we can look and we can see is

00:08:33.620 --> 00:08:37.050
this new number we're looking at
greater than the previous best

00:08:37.150 --> 00:08:38.930
guess that we have for the maximum.

00:08:39.020 --> 00:08:41.230
If it is,
we can just update that variable.

00:08:41.490 --> 00:08:43.860
It modifies it in the enclosing scope.

00:08:43.860 --> 00:08:47.820
And then when the apply function is done,
we're left with the most recently

00:08:47.820 --> 00:08:52.320
updated version of the result variable,
which now contains our maximum value,

00:08:52.450 --> 00:08:54.860
and we can simply return that.

00:08:57.790 --> 00:09:01.740
So now I'd like to
move to talk about GCD.

00:09:01.760 --> 00:09:07.490
GCD takes blocks and it treats them
like data objects and lets you do

00:09:07.500 --> 00:09:09.790
very powerful things with them.

00:09:10.370 --> 00:09:14.090
So,
GCD is short for Grand Central Dispatch.

00:09:14.090 --> 00:09:18.890
And what it fundamentally lets you
do is take blocks and enqueue them

00:09:18.890 --> 00:09:23.200
on queues for later asynchronous
invocation by the system.

00:09:23.310 --> 00:09:25.900
And we provide a thread-safe
enqueue operation,

00:09:25.900 --> 00:09:28.440
so you can have any number of
threads in your application and

00:09:28.440 --> 00:09:31.360
they can all be operating on
the same queue simultaneously.

00:09:31.420 --> 00:09:34.800
You don't need to do
any additional locking.

00:09:35.270 --> 00:09:38.970
And once the blocks have been enqueued,
the system is then responsible

00:09:39.170 --> 00:09:42.310
for asynchronously dequeuing
the blocks from those queues and

00:09:42.350 --> 00:09:44.690
invoking them on your behalf.

00:09:45.970 --> 00:09:50.290
So before we get started talking
about the invocation aspect,

00:09:50.290 --> 00:09:54.640
I want to clarify the particular
type of block that GCD uses.

00:09:54.820 --> 00:09:59.440
We refer to them as dispatch blocks,
and they're a special case in that all

00:09:59.440 --> 00:10:05.610
of the blocks that GCD uses take no
arguments and have no return value.

00:10:05.900 --> 00:10:10.040
And the reason we do this is because we
can treat every block of code completely

00:10:10.040 --> 00:10:14.820
identically if we know that the signature
has no arguments and no return value.

00:10:14.990 --> 00:10:19.800
And we can rely exclusively on capturing
variables in the enclosing scope as

00:10:19.800 --> 00:10:22.060
the way to get data into your block.

00:10:22.060 --> 00:10:24.970
And it turns out that this
is a very elegant approach.

00:10:25.070 --> 00:10:27.990
And in fact,
these specialized blocks that don't

00:10:27.990 --> 00:10:31.440
have any return value and don't take
any arguments can actually be written

00:10:31.440 --> 00:10:33.250
with the syntax that you see on screen.

00:10:33.260 --> 00:10:36.020
You can just use the caret
and then an open brace,

00:10:36.130 --> 00:10:39.910
and that begins your block declaration.

00:10:42.440 --> 00:10:44.580
So we have dispatch blocks.

00:10:44.620 --> 00:10:48.500
Now let's talk a little bit
about the dispatch queues.

00:10:49.360 --> 00:10:52.240
Creating a dispatch queue is a
very straightforward operation.

00:10:52.240 --> 00:10:54.080
We have a create routine.

00:10:54.190 --> 00:10:55.370
It only takes two arguments.

00:10:55.450 --> 00:10:57.990
The first argument is a
label that you provide.

00:10:58.160 --> 00:10:59.350
It can be anything you want.

00:10:59.590 --> 00:11:03.630
We recommend the reverse
DNS style naming scheme.

00:11:03.750 --> 00:11:07.420
And we actually take these labels
that are applied to queues and

00:11:07.430 --> 00:11:11.060
we print them out in things
like sample or crash reports.

00:11:11.060 --> 00:11:14.430
So when you're analyzing your code,
you can match up what

00:11:14.430 --> 00:11:18.220
activity is corresponding to
which queues you've defined.

00:11:18.330 --> 00:11:22.000
And the second argument is
really the type of the queue.

00:11:22.140 --> 00:11:24.450
And there are two main types of queues.

00:11:24.530 --> 00:11:27.580
There's a serial queue,
which executes blocks that are

00:11:27.580 --> 00:11:30.080
enqueued on it one at a time serially.

00:11:30.200 --> 00:11:34.680
And there's a concurrent queue,
which can potentially execute

00:11:34.710 --> 00:11:37.480
blocks in parallel at the same time.

00:11:37.630 --> 00:11:41.610
So in this example, we're creating a very
simple serial queue,

00:11:41.610 --> 00:11:43.910
the basic building block of GCD.

00:11:44.260 --> 00:11:46.680
And once we've created the queue,
we're going to print out a

00:11:46.750 --> 00:11:51.490
message that says we're before
this dispatch async call.

00:11:51.920 --> 00:11:57.180
Now, Dispatch Async is a really
fundamental piece of GCD,

00:11:57.190 --> 00:12:02.810
and what it's doing is it's enqueuing
a block for asynchronous execution.

00:12:03.090 --> 00:12:07.320
So it takes two arguments,
the queue that we want to target and

00:12:07.320 --> 00:12:10.150
the block that we want to enqueue.

00:12:10.260 --> 00:12:15.460
And all this does is it puts the block
onto the queue and returns immediately.

00:12:15.590 --> 00:12:17.760
It doesn't wait for the block to execute.

00:12:17.880 --> 00:12:20.910
That'll be done later by the system.

00:12:22.590 --> 00:12:26.520
And after we've called dispatch async,
we print out a little message

00:12:26.520 --> 00:12:29.340
that says that we're after
this dispatch async call.

00:12:29.410 --> 00:12:32.460
Now, what's really important to
note is when we run this,

00:12:32.530 --> 00:12:36.740
the order is going to be a little bit
different than what you might expect.

00:12:36.890 --> 00:12:41.590
We'll actually see before async,
after async, and then later the hello

00:12:41.590 --> 00:12:43.390
world that was in the block.

00:12:43.520 --> 00:12:47.130
And again, the reason for this is that
dispatch async simply enqueues

00:12:47.130 --> 00:12:48.760
the block and returns immediately.

00:12:48.760 --> 00:12:50.190
It doesn't run it yet.

00:12:50.300 --> 00:12:52.720
So in our code,
we've printed out before async,

00:12:52.720 --> 00:12:55.460
we've enqueued it,
we've printed out after async,

00:12:55.460 --> 00:12:57.700
and then at some later point,
the system pairs up that

00:12:57.890 --> 00:13:01.470
queue with a worker thread,
dequeues the block from the queue,

00:13:01.480 --> 00:13:05.500
invokes it, and that's when we see
hello world printed out.

00:13:08.710 --> 00:13:11.580
So these dispatch queues,
I talked a little bit

00:13:11.580 --> 00:13:15.770
about the serial queue,
have some interesting properties,

00:13:16.040 --> 00:13:20.080
the first of which is that a
serial queue always processes

00:13:20.080 --> 00:13:22.600
blocks in strictly FIFO order.

00:13:22.630 --> 00:13:24.970
So if you submit multiple
blocks to the queue,

00:13:24.970 --> 00:13:28.600
the first one that's enqueued is
going to be the first one that's run,

00:13:28.600 --> 00:13:32.590
and that's a strong guarantee
that the system makes.

00:13:33.040 --> 00:13:35.970
And that turns out to be very
useful in that if you have multiple

00:13:35.980 --> 00:13:42.180
threads enqueuing onto a queue,
the FIFO serialization that's done helps

00:13:42.180 --> 00:13:47.500
you synchronize your code and kind of
provide strong ordering guarantees.

00:13:47.670 --> 00:13:51.220
The second interesting property
of these queues is that we have

00:13:51.220 --> 00:13:53.050
an atomic enqueue algorithm.

00:13:53.280 --> 00:13:57.590
So you're not going to have
threads that are waiting on a

00:13:57.590 --> 00:14:01.830
lock to get their opportunity to
enqueue a block onto the queue.

00:14:01.890 --> 00:14:04.180
And it's, you know,
some sort of highly contended resource.

00:14:04.200 --> 00:14:07.380
It's actually a very efficient algorithm,
and you can have many,

00:14:07.380 --> 00:14:10.470
many threads enqueuing onto a queue,
and they're all going to

00:14:10.580 --> 00:14:13.850
atomically get their block
enqueued and return immediately.

00:14:13.990 --> 00:14:17.540
It's a weight-free algorithm.

00:14:17.810 --> 00:14:19.700
And then, of course,
as I've already mentioned,

00:14:19.730 --> 00:14:23.420
the automatic dequeue is the third very
interesting property of these queues.

00:14:23.560 --> 00:14:28.810
The system is responsible for creating
worker threads to process the queues,

00:14:28.850 --> 00:14:31.770
and it then takes...

00:14:32.170 --> 00:14:36.500
takes these threads and dequeues the
blocks and invokes them on your behalf.

00:14:36.520 --> 00:14:40.000
We'll talk a little bit more about
why that's so important in a moment.

00:14:40.000 --> 00:14:43.900
So here's a little animation of
the automatic dequeue process.

00:14:43.900 --> 00:14:46.400
In this example, we have two queues.

00:14:46.400 --> 00:14:47.600
They're both serial queues.

00:14:47.600 --> 00:14:48.700
One of them has two blocks.

00:14:48.700 --> 00:14:51.000
The other has three blocks.

00:14:51.000 --> 00:14:54.400
And we're going to start
running the simulation,

00:14:54.400 --> 00:14:58.080
and you'll see that the system is going
to take the first block enqueued to

00:14:58.080 --> 00:14:59.500
one of the queues and start running it.

00:14:59.500 --> 00:15:02.120
And when that's finished,
it'll move on to the next

00:15:02.130 --> 00:15:03.500
and move on to the next.

00:15:03.520 --> 00:15:07.570
Now, what's interesting is if
another thread becomes available

00:15:07.580 --> 00:15:11.420
to process additional work,
we'll then pick up the next queue and

00:15:11.430 --> 00:15:12.800
start running blocks on that queue.

00:15:12.800 --> 00:15:16.500
And so even though we've satisfied
that strong FIFO ordering guarantee

00:15:16.500 --> 00:15:19.480
for each individual queue,
you can see there's also the

00:15:19.480 --> 00:15:23.800
opportunity for two queues to be
processed concurrently in parallel.

00:15:23.830 --> 00:15:26.900
So why are asynchronous
blocks so important?

00:15:27.010 --> 00:15:32.300
Well, the key to asynchronous blocks is
that they allow you to easily wrap

00:15:32.650 --> 00:15:37.890
certain pieces of code for execution
asynchronous to your main thread.

00:15:37.900 --> 00:15:41.040
And this is really important
because the main thread in your

00:15:41.040 --> 00:15:44.900
application is what's responsible
for running the main event loop.

00:15:44.900 --> 00:15:48.650
And the main event loop is what's
receiving and responding to touch events

00:15:48.650 --> 00:15:50.900
or keyboard events or things like that.

00:15:50.900 --> 00:15:54.900
It's what keeps your application
responsive to user input.

00:15:54.900 --> 00:15:54.900
And so if you do some really
long-term work on this,

00:15:54.900 --> 00:15:54.900
you'll see that the main
thread is responsible for

00:15:54.900 --> 00:15:54.900
running the main event loop.

00:15:54.900 --> 00:15:54.900
And the main event loop is what's
receiving and responding to touch events

00:15:54.900 --> 00:15:54.900
or keyboard events or things like that.

00:15:54.900 --> 00:15:54.900
It's what keeps your application
responsive to user input.

00:15:54.900 --> 00:15:54.900
And so if you do some really
long-term work on this,

00:15:54.900 --> 00:15:54.900
you'll see that the main
thread is responsible for

00:15:54.900 --> 00:15:54.900
running the main event loop.

00:15:54.900 --> 00:15:58.200
And so if you do some really long
running operation on the main thread,

00:15:58.200 --> 00:16:01.520
let's say you're just waiting for
some file to download from the

00:16:01.520 --> 00:16:05.380
network or something like that,
all the time that's spent in

00:16:05.380 --> 00:16:11.160
that operation if it's being done
synchronously is time that is not being

00:16:11.160 --> 00:16:13.320
spent receiving events from the user.

00:16:13.410 --> 00:16:16.040
And so ultimately it makes
the app appear unresponsive.

00:16:16.070 --> 00:16:21.280
On OS X you see the spinning cursor to
indicate that an app is unresponsive.

00:16:21.290 --> 00:16:23.950
On iOS it just doesn't
respond to touch events.

00:16:24.190 --> 00:16:28.520
And of course if you do this
long enough on iOS at some point

00:16:28.520 --> 00:16:32.520
the app is terminated and you
return back to the home screen.

00:16:32.520 --> 00:16:37.120
So it's really important to keep the main
thread responsive to all these UI events.

00:16:37.120 --> 00:16:39.970
And asynchronous blocks
are a great way to do this.

00:16:42.220 --> 00:16:45.390
Now, if you're going to take a bunch
of work and get it off of the main

00:16:45.390 --> 00:16:48.780
thread to run in the background,
you also at some point need to take the

00:16:48.870 --> 00:16:52.690
results of that work and get it back
to the main thread to be able to update

00:16:52.690 --> 00:16:55.130
your UI and communicate with the user.

00:16:55.320 --> 00:16:58.650
And we can do this very easily
with something that we call

00:16:58.650 --> 00:17:00.530
the call callback pattern.

00:17:01.780 --> 00:17:05.120
So let's go back to our previous
example of updating an image view

00:17:05.290 --> 00:17:10.140
with some resource that we've
downloaded from the network.

00:17:10.360 --> 00:17:13.420
And depending on what our view is doing,
you know,

00:17:13.420 --> 00:17:17.060
you may have read in documentation
or experienced in your own

00:17:17.060 --> 00:17:22.920
debugging that really UI elements
in interaction with the UI should

00:17:22.940 --> 00:17:24.650
all happen from the main thread.

00:17:24.720 --> 00:17:29.060
And this is both for, you know,
real low-level thread safety type issues

00:17:29.140 --> 00:17:32.820
and also you want things happening on
the main thread just so it's easy to

00:17:32.880 --> 00:17:40.180
keep all of your view state in sync
with incoming events from the user.

00:17:40.600 --> 00:17:44.430
So in our example before,
we had an asynchronous download

00:17:44.430 --> 00:17:47.200
routine that as soon as it
downloaded something from the URL,

00:17:47.200 --> 00:17:50.700
it called our completion block.

00:17:50.950 --> 00:17:55.200
Perhaps we don't want to just set the
image of that view right here in the

00:17:55.290 --> 00:17:58.550
completion block because we're not really
sure if the completion block is going to

00:17:58.620 --> 00:18:04.490
be called on that background operations
thread that was doing the download.

00:18:05.110 --> 00:18:07.920
So we can add a little bit of
code and implement the call

00:18:07.930 --> 00:18:13.400
callback pattern to get that image
update back to the main thread.

00:18:13.410 --> 00:18:16.520
And we're using our dispatch
async routine that enqueues a

00:18:16.530 --> 00:18:19.160
block for asynchronous execution.

00:18:19.240 --> 00:18:22.600
And we're using a second routine
called dispatch get main queue.

00:18:22.600 --> 00:18:27.150
And this is a special routine that
always returns a reference to the

00:18:27.150 --> 00:18:29.030
main queue of your application.

00:18:29.070 --> 00:18:35.180
And the main queue is defined to
correspond to the main event loop and

00:18:35.180 --> 00:18:36.680
the main thread of the application.

00:18:36.680 --> 00:18:41.100
So it's a very convenient way to get
blocks to execute in that context.

00:18:41.210 --> 00:18:44.310
And so the reason it's a call
callback pattern is the outer block

00:18:44.390 --> 00:18:47.040
is the initial call that's happening.

00:18:47.110 --> 00:18:50.020
And then inside of it,
we can repeat the same approach of a

00:18:50.020 --> 00:18:52.920
dispatch async with a nested block.

00:18:52.970 --> 00:18:55.480
And that's our callback.

00:18:55.600 --> 00:18:58.210
It's also important to note
that this code is correct.

00:18:58.320 --> 00:19:03.720
It's okay that the view object isn't
retained or released in this inner block.

00:19:04.030 --> 00:19:08.940
Blocks actually automatically retain
and release all Objective-C objects

00:19:09.020 --> 00:19:12.900
that they reference,
even when not compiled in arc mode.

00:19:15.790 --> 00:19:18.800
So I'd like to extend on
this call-callback pattern

00:19:18.800 --> 00:19:21.840
a bit and talk about XPC.

00:19:23.390 --> 00:19:26.830
XPC is a technology
that's available on OS X,

00:19:26.830 --> 00:19:32.540
and it gives you a very simple
interface to look up a service by name.

00:19:32.660 --> 00:19:35.120
And once you've looked up a service,
you can send and receive

00:19:35.120 --> 00:19:36.840
messages to it asynchronously.

00:19:36.920 --> 00:19:40.420
And the important part about
these services is they're actually

00:19:40.420 --> 00:19:43.540
separate processes outside of
your application's process.

00:19:43.540 --> 00:19:45.620
So it's a completely
different address space,

00:19:45.730 --> 00:19:49.340
a completely different
process managed by the kernel.

00:19:49.480 --> 00:19:55.790
And we leverage all the blocks
and queues in GCD to deliver these

00:19:55.880 --> 00:20:00.470
asynchronous messages simply as blocks
submitted to queues that you provide.

00:20:00.640 --> 00:20:04.110
So it makes the asynchronous nature
of this communication very easy

00:20:04.190 --> 00:20:06.170
to work with in your application.

00:20:07.600 --> 00:21:05.800
[Transcript missing]

00:21:06.000 --> 00:21:09.840
But you might have a little helper
that needs to do some network activity

00:21:09.840 --> 00:21:12.040
or interface with certain hardware.

00:21:12.170 --> 00:21:16.370
And so you can compartmentalize all
of that higher privilege code in its

00:21:16.380 --> 00:21:20.780
own service and apply the principle
of least privilege to your design.

00:21:21.570 --> 00:21:25.820
So let's look through the sample code
of working with an XPC service and how

00:21:25.820 --> 00:21:28.790
it implements the call-callback pattern.

00:21:29.250 --> 00:21:34.080
First, we create a dispatch queue and an
XPC connection to talk to our service,

00:21:34.100 --> 00:21:36.780
and these two work as a pair.

00:21:36.920 --> 00:21:39.060
We can look up our service by name.

00:21:39.060 --> 00:21:42.360
In this example, it's com.example.render.

00:21:42.430 --> 00:21:44.920
And we're going to build on our
previous example of decoding some

00:21:44.920 --> 00:21:48.900
image data and assume that the data
we download from the URL might not be

00:21:48.940 --> 00:21:51.340
in a format that NSImage can parse.

00:21:51.410 --> 00:21:56.010
And so we're going to do some
transformation on that data

00:21:56.010 --> 00:22:00.770
first in an XPC service and then
try to make an image from it.

00:22:01.720 --> 00:22:04.440
Once we've created the connection,
we set an event handler on it.

00:22:04.440 --> 00:22:09.840
The event handler gets called when
there's a reply from the service.

00:22:09.950 --> 00:22:13.680
We'll do a superficial check to make
sure the reply isn't some type of error,

00:22:13.680 --> 00:22:16.840
but it's real data that we're
getting back from our service.

00:22:16.960 --> 00:22:20.340
Then we can extract data from the reply.

00:22:20.340 --> 00:22:23.650
It's really just a dictionary,
property list style dictionary.

00:22:23.750 --> 00:22:27.000
We'll get the data out,
and then we can call our

00:22:27.010 --> 00:22:29.030
completion callback with the data.

00:22:29.040 --> 00:22:33.050
And the completion callback we had
before is the one that actually

00:22:33.050 --> 00:22:36.730
takes this new style of data
and turns it into an NS image.

00:22:38.380 --> 00:22:41.780
Once we've fully configured our
connection by setting the event handler,

00:22:41.840 --> 00:22:44.790
we need to call xpc_resume,
and that lets the system know

00:22:44.790 --> 00:22:47.900
that we're ready to start
activity on this connection,

00:22:47.900 --> 00:22:51.800
we're prepared to receive events from it.

00:22:53.320 --> 00:22:55.920
And then interacting with the
service is really as simple as

00:22:55.920 --> 00:23:00.510
creating an XPC message dictionary,
adding some data to a

00:23:00.550 --> 00:23:02.660
key in the dictionary,

00:23:03.440 --> 00:23:05.990
Sending the message to the service,
and it's at this point when we

00:23:05.990 --> 00:23:09.010
actually send the first message
that the system launches the

00:23:09.030 --> 00:23:14.750
service if it's not already running,
but it's done completely transparently.

00:23:14.760 --> 00:23:18.180
And then when we're done,
we can release the message.

00:23:19.230 --> 00:23:22.030
So to go into more detail
about Objective-C and blocks,

00:23:22.190 --> 00:23:24.510
I'd like to invite
Daniel Steffen onto the stage.

00:23:24.640 --> 00:23:26.340
Good morning.

00:23:26.440 --> 00:23:29.810
So let's dive right into
blocks and Objective-C.

00:23:29.950 --> 00:23:34.550
We've already seen how you can declare
a block indirectly in your code in line.

00:23:34.860 --> 00:23:37.590
When you actually do that,
what happens is that there

00:23:37.590 --> 00:23:40.940
is an Objective-C block
object created on the stack.

00:23:41.010 --> 00:23:43.590
Blocks start out on the
stack for performance,

00:23:43.590 --> 00:23:47.180
for speed, but they are copied to
the heap in many cases.

00:23:47.250 --> 00:23:49.870
For instance,
when you are scheduling them for

00:23:49.870 --> 00:23:52.740
asynchronous execution with GCD,
because in that case,

00:23:52.740 --> 00:23:55.860
they need to survive the
lifetime of the current scope.

00:23:55.930 --> 00:24:00.060
So what happens to the variables that
are captured by a block when you do that?

00:24:00.090 --> 00:24:04.010
As we've already mentioned,
scalers are const copied to the heap.

00:24:04.080 --> 00:24:08.200
Objective-C objects are retained,
but any plain C pointer

00:24:08.210 --> 00:24:11.630
is just copied as a value,
and its underlying storage

00:24:11.630 --> 00:24:12.920
is not managed for you.

00:24:13.230 --> 00:24:16.140
So let's see an example of
where this can trip this up.

00:24:16.200 --> 00:24:17.140
Here we are implementing a block.

00:24:17.140 --> 00:24:20.910
We have a method that will do some
asynchronous work on behalf of the

00:24:20.910 --> 00:24:25.100
caller and call them back on a queue
that they provide by invoking a method

00:24:25.100 --> 00:24:27.900
on the object that they give us.

00:24:27.900 --> 00:24:31.920
And we implement that by doing a
dispatch async in our method to a

00:24:31.920 --> 00:24:37.360
queue internal to our object and do
some asynchronous work and perform the

00:24:37.360 --> 00:24:40.900
callback to the caller-supplied queue.

00:24:40.940 --> 00:24:43.900
Now, this code looks just fine,
no obvious errors,

00:24:43.990 --> 00:24:45.900
but it turns out that it crashes.

00:24:45.900 --> 00:24:47.090
So let's see why that is.

00:24:47.100 --> 00:24:51.450
So here we've represented the two areas
of memory important in this problem,

00:24:51.500 --> 00:24:53.060
the stack and the heap.

00:24:53.060 --> 00:24:57.620
And when we enter our method,
we start out with the two pointers to

00:24:57.620 --> 00:25:02.060
the objects that the caller passes us
and their underlying storage on the heap.

00:25:02.060 --> 00:25:05.010
Imagine that they start out
with reference count one.

00:25:05.060 --> 00:25:08.140
Now we create this callback
block on the stack,

00:25:08.430 --> 00:25:12.140
which captures the Objective-C object
and the block that will

00:25:12.140 --> 00:25:15.540
execute asynchronously,
which in turn captures

00:25:15.540 --> 00:25:16.990
the dispatch queue.

00:25:17.070 --> 00:25:19.410
and the callback block.

00:25:20.150 --> 00:25:23.020
When we do dispatch async of this block,
as part of that,

00:25:23.130 --> 00:25:26.400
the block gets copied to the heap,
and because it captures

00:25:26.400 --> 00:25:29.980
the callback block,
that block also gets copied to the heap.

00:25:30.030 --> 00:25:33.220
Because that block in turn
captured the Objective-C object,

00:25:33.240 --> 00:25:36.400
this now has its reference count
incremented because it's being

00:25:36.400 --> 00:25:38.220
retained by the block's runtime.

00:25:38.290 --> 00:25:42.280
But note that the dispatch queue
still has a reference count of one.

00:25:42.330 --> 00:25:48.180
That is because the dispatch queue T-type
there is just a plain C pointer type.

00:25:48.410 --> 00:25:50.220
And of course this is
where the problem occurs.

00:25:50.260 --> 00:25:55.610
When our method returns and the caller
releases the references to these objects,

00:25:55.610 --> 00:25:57.720
the storage for our dispatch
queue will get deallocated,

00:25:57.790 --> 00:26:00.490
and now we have this dangling
reference and the block will

00:26:00.490 --> 00:26:01.860
crash when it gets executed.

00:26:02.200 --> 00:26:02.950
How do we solve this?

00:26:03.200 --> 00:26:06.350
We have to manually manage the
lifetime of the queue object

00:26:06.430 --> 00:26:08.360
that's passed into this method.

00:26:08.480 --> 00:26:11.590
We need to add dispatch retain
and dispatch release calls.

00:26:11.770 --> 00:26:16.630
We retain before we async the block
and release once we are done with

00:26:16.700 --> 00:26:18.300
the queue object inside that block.

00:26:18.300 --> 00:26:22.990
So now I'm very happy to announce that
we've improved on this situation in

00:26:22.990 --> 00:26:29.500
iOS 6 and Mountain Lion because GCD and
XPC objects are now Objective-C objects.

00:26:30.360 --> 00:26:34.060
Thanks.

00:26:36.560 --> 00:26:41.060
So back in the same situation,
the incoming object,

00:26:41.090 --> 00:26:43.580
QObject that's passed to us
is now an Objective-C object,

00:26:43.610 --> 00:26:47.180
so the blocks runtime takes care
of managing the lifetime for

00:26:47.180 --> 00:26:50.550
us and we can get rid of these
retain release calls again.

00:26:50.810 --> 00:26:53.200
And everything works correctly.

00:26:53.710 --> 00:26:57.840
So automatically being retained released
by blocks is one big benefit of these

00:26:57.840 --> 00:27:00.560
objects now being Object-DC objects.

00:27:00.600 --> 00:27:01.390
There's many others.

00:27:01.500 --> 00:27:04.920
You can also use them directly
as add property retains now.

00:27:04.960 --> 00:27:07.650
Previously you had to use add
property assign and manually

00:27:07.650 --> 00:27:08.920
manage the property storage.

00:27:08.930 --> 00:27:12.090
Now the Object-DC runtime
will do it for you.

00:27:12.430 --> 00:27:15.910
You can also use these objects in
foundation collections directly,

00:27:15.910 --> 00:27:18.330
so you can make an
NSRA of dispatch queues,

00:27:18.330 --> 00:27:19.770
for instance.

00:27:19.840 --> 00:27:23.120
The static analyzer understands
more about these objects,

00:27:23.120 --> 00:27:26.490
and instruments in the debugger
support them better via their generic

00:27:26.570 --> 00:27:29.800
support for Objective-C objects.

00:27:30.900 --> 00:27:33.030
Of course,
another area where we've improved

00:27:33.030 --> 00:27:37.030
the Object-DC language last year
with the introduction of ARC in iOS

00:27:37.030 --> 00:27:40.640
5 and Line is reference counting.

00:27:40.760 --> 00:27:43.380
And so here's a typical example of
a method where we have to create a

00:27:43.410 --> 00:27:46.790
bunch of temporary objects to send
a message to an XPC connection,

00:27:46.790 --> 00:27:50.840
and we have to be careful to release
all these objects manually at the end of

00:27:50.940 --> 00:27:53.080
the method so as not to leak any code.

00:27:53.080 --> 00:27:56.860
When you compile this code with ARC now,
there's no more need for these release

00:27:56.860 --> 00:27:58.580
calls at the end of the method.

00:27:58.580 --> 00:28:01.680
The compiler manages the storage
of these objects for you.

00:28:01.680 --> 00:28:06.190
So when you migrate
GCD and XPC code to ARC,

00:28:06.190 --> 00:28:06.190
you can see that the
compiler is able to store

00:28:07.020 --> 00:28:10.320
You can just use the Convert
to Objective-C ARC menu item

00:28:10.330 --> 00:28:13.930
in the Xcode refactor menu.

00:28:15.200 --> 00:28:19.480
which will run the ARC Migrator and
remove these retained release calls

00:28:19.600 --> 00:28:23.100
for you and do all the other work
of converting your code to ARC.

00:28:23.130 --> 00:28:26.400
Note that it's even possible to do
this again when you've already migrated

00:28:26.400 --> 00:28:29.740
your code to ARC in the past and
it will do the extra work required.

00:28:29.820 --> 00:28:32.040
Or you can just remove
these calls yourselves,

00:28:32.040 --> 00:28:33.880
of course,
and in fact you have to because

00:28:33.960 --> 00:28:37.660
like calls to the retained
release Objective-C methods,

00:28:37.720 --> 00:28:41.400
these now cause compiler
errors when you build with ARC.

00:28:42.950 --> 00:28:44.880
What are the requirements
for this support?

00:28:44.970 --> 00:28:49.110
Of course, you have to build with the
Objective-C or Objective-C++ compiler,

00:28:49.110 --> 00:28:53.070
and you have to have a minimum
deployment target of iOS 6 or Mac OS X.8.

00:28:53.200 --> 00:28:57.230
If you still need to support older
releases and supply an older,

00:28:57.230 --> 00:29:00.490
lower deployment target,
you will be automatically

00:29:00.490 --> 00:29:02.070
opted out of this support.

00:29:02.240 --> 00:29:05.350
Or you can opt out manually if you
need to for some reason by passing

00:29:05.470 --> 00:29:08.650
OS object use option C equals
zero in your preprocessor flags.

00:29:09.620 --> 00:29:13.580
There's a couple of special
considerations when...

00:29:14.070 --> 00:29:18.500
doing this conversion to Objective-C and
ARC of your GCD and XPC code.

00:29:18.550 --> 00:29:27.050
These are many things that the automatic
migration doesn't handle for you,

00:29:27.050 --> 00:29:27.050
but look at blocks and return cycles
and APIs that expose interior pointers.

00:29:27.240 --> 00:29:30.660
Let's look at a general example
of how you can set up a retain

00:29:30.750 --> 00:29:32.600
cycle in an object with a block.

00:29:32.800 --> 00:29:35.100
Here we have declared a class
that has two properties,

00:29:35.100 --> 00:29:40.900
an integer value property and one
of these dispatch block type block

00:29:40.900 --> 00:29:43.930
properties that we've seen earlier.

00:29:44.090 --> 00:29:47.140
And we've represented the storage
of that object on the heap with

00:29:47.210 --> 00:29:50.650
an initial reference count,
retain count of one.

00:29:51.540 --> 00:29:56.760
Now we declare a setup method that
assigns a block to our block property.

00:29:56.760 --> 00:30:00.580
And as part of this assignment,
we'll have to copy this block

00:30:00.600 --> 00:30:05.060
to the heap because obviously it
has to survive the lifetime of

00:30:05.180 --> 00:30:07.370
the scope of the setup method.

00:30:07.820 --> 00:30:11.420
And as shown here,
the block captures the value

00:30:11.420 --> 00:30:13.200
instance variable of our object.

00:30:13.250 --> 00:30:15.910
And because this is an integer,
we expect this to do a const

00:30:16.540 --> 00:30:18.540
copy of that integer value.

00:30:18.650 --> 00:30:21.140
But of course,
that's not actually what happens.

00:30:21.240 --> 00:30:25.060
If you access an instance
variable in an Objective-C method,

00:30:25.370 --> 00:30:29.000
the compiler transparently
indirects that by itself for you.

00:30:29.120 --> 00:30:32.000
And what actually happens is
that the block now captures self.

00:30:32.070 --> 00:30:34.200
And because self is
an Objective-C object,

00:30:34.300 --> 00:30:36.860
the block increments the
reference count of self.

00:30:36.970 --> 00:30:38.900
And now you have a retain cycle.

00:30:38.940 --> 00:30:42.260
When you get rid of this object,
it will not disappear because it

00:30:42.310 --> 00:30:45.580
retains itself via that property.

00:30:45.720 --> 00:30:47.850
So how do we break such retained cycles?

00:30:48.000 --> 00:30:51.130
We'll look at three ways via scoping,
programmatically,

00:30:51.130 --> 00:30:53.720
and with compiler attributes.

00:30:54.130 --> 00:30:55.740
So, same situation as before.

00:30:55.900 --> 00:30:58.480
We've made the capture
a bit more explicit,

00:30:58.680 --> 00:31:00.880
but we still have this retain cycle.

00:31:00.880 --> 00:31:03.390
How can we break this with scoping?

00:31:03.490 --> 00:31:07.850
We simply set up a local variable
where we put the value that we want

00:31:07.850 --> 00:31:11.500
to use from the object into before
we set up the block and capture

00:31:11.620 --> 00:31:16.250
that value instead rather than the
instance variable or the property,

00:31:16.250 --> 00:31:19.400
and so we avoid the
capture of self completely.

00:31:20.190 --> 00:31:23.090
Of course,
this behaves slightly differently

00:31:23.170 --> 00:31:26.740
from before because the value,
the property is actually read out

00:31:26.820 --> 00:31:29.740
much earlier when we set up the
block rather than when it runs.

00:31:29.790 --> 00:31:33.050
Because this is a read-only integer here,
this presumably doesn't make

00:31:33.050 --> 00:31:36.230
any difference in this code,
but this is not a solution that

00:31:36.230 --> 00:31:41.100
may be generally applicable if
you have this type of issue.

00:31:41.190 --> 00:31:44.840
So an alternative is to break
these cycles programmatically.

00:31:44.890 --> 00:31:48.990
Here we are, same situation we have,
but we've changed the example slightly

00:31:49.140 --> 00:31:52.980
to use a captured Objective-C object
property where we presumably

00:31:52.980 --> 00:31:55.210
can't apply the previous idea.

00:31:55.580 --> 00:31:59.060
So here we'll set up a manual
cancel method that simply

00:31:59.140 --> 00:32:01.280
nils out the block property.

00:32:01.320 --> 00:32:03.810
By doing that,
we release the previous value

00:32:03.810 --> 00:32:07.320
that was stored in that property,
and so it releases its reference

00:32:07.320 --> 00:32:11.200
that it had on itself and
thus breaks the retain cycle.

00:32:11.380 --> 00:32:14.840
And this is in fact exactly
what we recommend that you do.

00:32:14.960 --> 00:32:18.540
When you encounter retain cycles
in your use of GCD or XPC API,

00:32:18.540 --> 00:32:20.480
that has block properties.

00:32:20.610 --> 00:32:23.460
Here we have two such objects,
the dispatch source

00:32:23.540 --> 00:32:25.030
and the XPC connection.

00:32:25.250 --> 00:32:29.880
Most of these have event handlers that
are block properties of these objects,

00:32:29.880 --> 00:32:34.100
and it's very common to use the
objects themselves in those blocks.

00:32:34.230 --> 00:32:37.340
So in both of these cases,
we've set up retain cycles on these

00:32:37.430 --> 00:32:39.330
objects and need to break them.

00:32:39.440 --> 00:32:42.880
And you do that by calling the
dispatch source cancel or the

00:32:42.880 --> 00:32:44.810
XPC connection cancel APIs.

00:32:44.840 --> 00:32:50.670
These are previously existing APIs that
were optional because the final release

00:32:50.680 --> 00:32:52.320
would do this cancellation for you.

00:32:52.340 --> 00:32:55.460
If you have in fact one
of these retain cycles,

00:32:55.460 --> 00:32:58.340
then you now have to call these methods.

00:32:58.340 --> 00:33:02.620
And of course, if you convert to Arc,
the release calls at the

00:33:02.620 --> 00:33:04.670
end here will get removed.

00:33:06.130 --> 00:33:10.040
The third way is to use
compiler attributes.

00:33:10.040 --> 00:33:13.850
If you build with ARC,
you can use the under_weak compiler

00:33:13.890 --> 00:33:16.390
attribute to set up weak references.

00:33:16.500 --> 00:33:21.680
And here we use this in our setup
method to have the block in our object,

00:33:21.680 --> 00:33:23.990
rather than capturing self,
it captures a local

00:33:24.350 --> 00:33:26.100
weak reference to self.

00:33:26.240 --> 00:33:29.840
And because it's a weak reference,
the block capture doesn't cause an extra

00:33:29.840 --> 00:33:34.100
retain count to be taken on the object,
and so we don't have this retain cycle.

00:33:34.240 --> 00:33:38.100
But because weak references
are zeroing weak references,

00:33:38.100 --> 00:33:43.050
inside the block once we run,
we now have to check, or maybe we...

00:33:43.140 --> 00:33:48.820
We may want to check that the weak self
is actually still pointing to the object,

00:33:48.900 --> 00:33:51.740
that the object is
still alive when we run.

00:33:51.760 --> 00:33:54.730
And we do that by setting up a
strong reference inside the block

00:33:55.090 --> 00:33:58.340
and checking that that succeeded
by checking for nil and then doing

00:33:58.340 --> 00:34:02.420
our asynchronous work and maybe,
if not, doing something else.

00:34:03.100 --> 00:34:06.720
for many more details on under
under weak and ARC in general,

00:34:06.720 --> 00:34:10.560
please go to the adopting automatic
reference counting session later that

00:34:10.660 --> 00:34:12.360
is being repeated later this morning.

00:34:12.440 --> 00:34:16.710
Our next topic is interior
pointers and APIs that expose

00:34:16.790 --> 00:34:21.110
interior pointers to objects,
to container objects.

00:34:22.800 --> 00:35:49.500
[Transcript missing]

00:35:50.000 --> 00:35:51.120
How do we solve this?

00:35:51.250 --> 00:35:54.340
One option is to add the
Objective-C precise lifetime

00:35:54.340 --> 00:35:58.500
attribute to the container
object that needs to stay alive.

00:35:58.580 --> 00:36:02.100
And that tells the compiler that this
object should stick around for the

00:36:02.100 --> 00:36:06.300
whole duration of the surrounding scope,
exactly the duration of that scope.

00:36:06.410 --> 00:36:11.330
So what the compiler will do is insert
its release call at the end of the scope

00:36:11.610 --> 00:36:14.340
right before the close curly brace.

00:36:15.270 --> 00:36:17.630
And this makes it safe for
us to access the interior

00:36:17.730 --> 00:36:19.870
pointer inside this method now.

00:36:20.000 --> 00:36:23.130
So in our next section,
we'd like to go over some asynchronous

00:36:23.210 --> 00:36:28.440
design patterns with you that are very
concrete steps that you can apply to

00:36:28.450 --> 00:36:32.330
your code to make it more asynchronous
and some best practices to avoid some

00:36:32.330 --> 00:36:36.670
common trouble spots along the way and
show you some ideas of patterns that

00:36:36.670 --> 00:36:42.590
you can apply to your own APIs when you
design your apps or to Apple's APIs.

00:36:42.830 --> 00:36:44.970
And as a guiding example
throughout this section,

00:36:44.970 --> 00:36:48.660
we'll use an imaginary image of your
application that can display images

00:36:48.820 --> 00:36:52.440
stored locally on your device or
retrieve them from other instances of

00:36:52.560 --> 00:36:55.370
the app on the network and display them.

00:36:56.510 --> 00:37:02.710
And step one in this set of design
patterns is the most important

00:37:02.710 --> 00:37:06.320
thing to always remember when
you're writing code on iOS or

00:37:06.320 --> 00:37:09.710
OS X is don't block the main thread.

00:37:09.990 --> 00:37:11.700
We've discussed this already.

00:37:11.740 --> 00:37:15.460
The main thread is what handles
the user interaction and the UI,

00:37:15.460 --> 00:37:18.530
and because we want responsive
UI in our apps at all times,

00:37:18.560 --> 00:37:20.980
that's really the only thing that
the main thread should be doing.

00:37:21.000 --> 00:37:24.240
Anything that is CPU-intensive
or blocking should be running

00:37:24.250 --> 00:37:25.530
elsewhere in your app.

00:37:25.640 --> 00:37:29.610
And running elsewhere,
you implement that by running in

00:37:29.610 --> 00:37:32.190
the background with GCD and blocks.

00:37:32.940 --> 00:37:36.380
So here, in our image viewer application,
we are on the main thread.

00:37:36.380 --> 00:37:40.530
We need to do a CPU-intensive
render operation for some males,

00:37:40.730 --> 00:37:44.530
and we want to move that to the
background because this could affect

00:37:44.530 --> 00:37:49.240
the interactivity of our application
if we ran this on the main thread.

00:37:49.290 --> 00:37:52.470
So we pick a dispatch queue that
we want to run this code on.

00:37:52.500 --> 00:37:56.220
Here, we just use the global default
priority dispatch queue.

00:37:56.220 --> 00:38:01.520
We enclose this work in a block
and dispatch async it to our queue.

00:38:02.170 --> 00:38:04.610
And in the call callback
pattern that we've seen earlier,

00:38:04.610 --> 00:38:07.070
once we're done inside
this block with the work,

00:38:07.200 --> 00:38:10.360
we need to update the UI,
so we enclose the updating of

00:38:10.360 --> 00:38:14.850
the UI in a block and dispatch
async that back to the main queue.

00:38:15.750 --> 00:38:17.800
So when you apply this
pattern into your code,

00:38:17.850 --> 00:38:21.250
it's important to not block
too many background threads.

00:38:22.550 --> 00:38:25.050
Here we have almost exactly
the same example as before,

00:38:25.180 --> 00:38:29.280
except that we're now doing some
IO on the background thread with the

00:38:29.280 --> 00:38:31.960
NSData DataWeek contents of URL API.

00:38:32.270 --> 00:38:36.570
We're reading some file
in from the file system.

00:38:37.300 --> 00:38:39.790
Now, one of these dispatch
asyncs is just fine.

00:38:39.790 --> 00:38:40.940
This doesn't cause any problems.

00:38:41.050 --> 00:38:42.850
That's in fact exactly
the right thing to do.

00:38:43.050 --> 00:38:45.840
But imagine that we now enclose this
whole thing in a big for loop that

00:38:45.840 --> 00:38:49.960
iterates over all the images that
we have stored in our application,

00:38:49.960 --> 00:38:51.340
which could be many hundreds.

00:38:51.420 --> 00:38:53.360
Now your app could run into a problem.

00:38:53.400 --> 00:38:55.310
Let's see why.

00:38:56.120 --> 00:38:59.530
So this is an illustration of the
single case where we async one of

00:38:59.640 --> 00:39:03.240
these blocks and run it on our queue
and an automatic worker thread comes up

00:39:03.360 --> 00:39:09.280
and now it's blocked in IO for a while
to bring the data in from storage.

00:39:09.530 --> 00:39:12.990
Now the thing to realize is
when you block these automatic

00:39:12.990 --> 00:39:16.060
worker threads in your apps,
after a certain amount of time,

00:39:16.150 --> 00:39:18.930
the system will create additional threads
if there is still pending work to be

00:39:18.930 --> 00:39:21.250
done so that the app can make progress.

00:39:21.380 --> 00:39:25.330
But now if you block these additional
threads that come up with more IO,

00:39:25.540 --> 00:39:28.890
this pattern will continue and you
will end up with more and more and

00:39:29.160 --> 00:39:30.910
more threads that are all blocked.

00:39:31.110 --> 00:39:33.920
And of course,
this can now lead you into trouble.

00:39:34.080 --> 00:39:38.310
You could deadlock your whole application
by having too many worker threads blocked

00:39:38.310 --> 00:39:43.200
like this and hit the limit of threads
that the system allows you to create.

00:39:43.290 --> 00:39:47.870
Or all these threads could end up using
so much memory that your app gets killed,

00:39:47.870 --> 00:39:48.880
on iOS anyway.

00:39:48.960 --> 00:39:51.200
So what's the solution?

00:39:51.200 --> 00:39:56.250
One option is to use dispatch IO,
an asynchronous IO API that we've

00:39:56.250 --> 00:40:04.490
introduced last year in line and iOS 5
to do this asynchronous IO differently.

00:40:04.950 --> 00:40:08.750
So here we have the same for loop
but instead of doing a dispatch

00:40:08.750 --> 00:40:13.040
async of a blocking IO API,
we use the dispatch IO subsystem

00:40:13.050 --> 00:40:15.310
to perform asynchronous IO.

00:40:15.860 --> 00:40:21.220
Here we create an IO object from
one of these zero paths and we

00:40:21.280 --> 00:40:25.680
can submit an asynchronous IO read
operation and ask it to call us back

00:40:25.680 --> 00:40:27.760
on the main queue with the results.

00:40:27.960 --> 00:40:30.680
And this will now take care to,
even if you submit

00:40:30.680 --> 00:40:32.860
hundreds of these requests,
to all do them,

00:40:32.870 --> 00:40:36.410
perform them in a way that
doesn't overwhelm the system.

00:40:37.520 --> 00:40:40.680
And for many more details on Dispatch.io,
please see the Mastering

00:40:40.680 --> 00:40:45.770
Grand Central Dispatch session from
last year's conference on iTunes.

00:40:48.600 --> 00:40:51.780
Our next step is how to
integrate with the main run loop

00:40:51.780 --> 00:40:53.580
when you're writing GCD code.

00:40:53.710 --> 00:40:57.500
You've already seen the Dispatch
Get Main Queue API quite a bit.

00:40:57.560 --> 00:41:00.210
This, in fact,
returns a serial queue to you that

00:41:00.210 --> 00:41:02.290
cooperates with the main run loop.

00:41:02.480 --> 00:41:05.540
Every time the main thread
goes through its event loop,

00:41:05.540 --> 00:41:09.000
it will look at the serial queue
and perform any blocks that

00:41:09.000 --> 00:41:10.980
are present on it at that time.

00:41:11.090 --> 00:41:15.260
So you can be sure that any block that
you async to this queue will run in the

00:41:15.270 --> 00:41:17.410
context of the main thread's event loop.

00:41:17.700 --> 00:41:21.800
But of course, we also have many run-loop
based APIs on our system.

00:41:21.850 --> 00:41:23.840
And APIs that have
run-loop based callbacks.

00:41:24.060 --> 00:41:28.520
Here I'm thinking of things like NSTimer,
any of the perform-mit-selector APIs,

00:41:28.520 --> 00:41:32.000
anything that has an
asynchronous delegate call.

00:41:32.090 --> 00:41:37.850
All of these APIs schedule a callback on
either a specifically selected run-loop

00:41:37.850 --> 00:41:40.400
or the current thread's run-loop.

00:41:40.470 --> 00:41:45.180
And it is important to be aware
of which thread that run-loop

00:41:45.390 --> 00:41:48.340
belongs to when you use these APIs.

00:41:48.450 --> 00:41:50.510
In particular,
typically you shouldn't call these

00:41:50.510 --> 00:41:53.990
on the automatic worker threads
that GCD provides if they're going

00:41:54.090 --> 00:41:58.440
to schedule a run-loop callback
on the current thread's run-loop.

00:41:58.660 --> 00:42:01.600
This is because you don't have control
over the lifetime of these automatic

00:42:01.600 --> 00:42:07.000
worker threads and their run-loops
are typically not running anyway.

00:42:07.150 --> 00:42:11.070
So the usual solution is to call
such APIs on the main thread,

00:42:11.070 --> 00:42:13.100
but then when you get
a callback from them,

00:42:13.100 --> 00:42:16.000
be aware that you are now
still on the main thread.

00:42:16.000 --> 00:42:21.470
So don't block there if you have to
do any blocking or CPU intensive work,

00:42:21.770 --> 00:42:23.990
apply step number two there.

00:42:24.910 --> 00:42:28.140
So let's look at an example of this
in our image viewer application.

00:42:28.150 --> 00:42:31.510
We'd like to download some pictures
from a remote instance of our app.

00:42:31.660 --> 00:42:36.640
We have saved the name,
the Bonjour name of that previously.

00:42:36.640 --> 00:42:39.840
And here we use the NSNetService
API to resolve that name to an

00:42:39.840 --> 00:42:41.640
address that we can connect to.

00:42:41.660 --> 00:42:46.500
And this API schedules a run loop
callback on the current thread's run loop

00:42:46.510 --> 00:42:53.210
and calls the NetServiceDidResolveAddress
delegate method when it's done.

00:42:53.300 --> 00:42:56.780
So if you do this on the main thread,
this works perfectly fine.

00:42:56.800 --> 00:43:00.510
But because this is a network
operation that could potentially block,

00:43:00.600 --> 00:43:03.800
we want to do the right thing and
dispatch async this into the background.

00:43:03.800 --> 00:43:05.240
And now we have a problem.

00:43:05.240 --> 00:43:07.370
The run loop method,
the run loop callback

00:43:07.630 --> 00:43:09.230
doesn't get called anymore.

00:43:09.240 --> 00:43:11.300
And let's see why this is.

00:43:11.370 --> 00:43:14.530
Here we start out on the main thread
with its main run loop running.

00:43:14.540 --> 00:43:17.650
We async this block to
a background thread,

00:43:17.650 --> 00:43:21.520
to a queue,
and we run on an automatic worker thread,

00:43:21.520 --> 00:43:25.170
and it now schedules its run
loop callback on that automatic

00:43:25.170 --> 00:43:26.170
worker thread's run loop.

00:43:26.220 --> 00:43:29.200
This run loop isn't running, and worse,
when the block finishes,

00:43:29.200 --> 00:43:31.770
that thread will probably
get recycled by the system,

00:43:31.770 --> 00:43:34.760
and your callback along with
the run loop disappears,

00:43:34.810 --> 00:43:37.290
and then it gets called.

00:43:38.020 --> 00:43:41.340
So the solution here is to continue
calling such API on the main thread.

00:43:41.340 --> 00:43:42.820
It's already asynchronous.

00:43:42.970 --> 00:43:46.500
It doesn't block your thread,
your main thread, so this is safe.

00:43:46.580 --> 00:43:50.590
But then inside its run loop callback,
that's where you should be careful

00:43:50.590 --> 00:43:55.810
to not block and dispatch async
into the background if necessary.

00:43:58.600 --> 00:44:02.530
The next pattern we'd like to look
at is using one queue per subsystem.

00:44:02.660 --> 00:44:08.050
This is an idea to subdivide your
app into independently operating

00:44:08.050 --> 00:44:12.580
subsystems that are controlled with
serial dispatch queues and interchange

00:44:12.640 --> 00:44:14.880
messages with dispatch async.

00:44:15.270 --> 00:44:19.410
And in this architecture,
you can think of the main queue as simply

00:44:19.410 --> 00:44:22.360
the access queue for the UI subsystem.

00:44:22.460 --> 00:44:27.890
So here we've represented our app,
architected in this fashion

00:44:28.040 --> 00:44:31.500
graphically with the UI subsystem
in the top left corner,

00:44:31.560 --> 00:44:35.160
a networking subsystem,
an image processing subsystem,

00:44:35.160 --> 00:44:38.200
and the storage subsystem,
all of which can operate independently.

00:44:38.340 --> 00:44:43.110
And now they can exchange messages
by dispatch asyncing blocks between

00:44:43.500 --> 00:44:47.200
themselves and queuing them on
their controlling serial queues.

00:44:47.350 --> 00:44:50.700
And typically,
using this architecture gives

00:44:50.700 --> 00:44:55.500
you a very good granularity of
asynchrony in your application.

00:44:55.600 --> 00:44:58.350
So let's look at a very simple example
of how we would do this in code.

00:44:58.510 --> 00:45:00.760
We're back in our net service,
the resolve address,

00:45:00.800 --> 00:45:02.420
run loop callback on the main thread.

00:45:02.660 --> 00:45:04.400
Now we want to do some
network operations,

00:45:04.510 --> 00:45:08.260
so we go to our networking subsystem
with a dispatch async to its computer.

00:45:08.360 --> 00:45:11.810
And we go to our storage subsystem
to store that data by dispatch

00:45:11.810 --> 00:45:19.320
asyncing to its controlling queue,
the store queue.

00:45:19.500 --> 00:45:22.130
Once you have that,
we go to the rendering subsystem by

00:45:22.130 --> 00:45:24.240
dispatch asyncing to the render queue.

00:45:24.280 --> 00:45:26.900
And once we have finished
our rendering operation,

00:45:26.900 --> 00:45:30.010
we go back to the UI subsystem
by dispatch asyncing to

00:45:30.020 --> 00:45:32.080
its controlling queue,
the main queue.

00:45:32.230 --> 00:45:35.590
Of course, this is a very simplified
example in your code.

00:45:35.760 --> 00:45:38.390
These asyncs probably wouldn't
all be inside the same method,

00:45:38.490 --> 00:45:41.090
but the same idea applies.

00:45:43.640 --> 00:45:46.520
And when you're implementing
this kind of architecture,

00:45:46.520 --> 00:45:50.920
you may have subsystems that
have reader/writer access,

00:45:51.020 --> 00:45:53.040
that support reader/writer access.

00:45:53.110 --> 00:45:57.500
And you can improve performance of these
by using a concurrent subsystem queue.

00:45:57.540 --> 00:46:01.010
This is a type of queue that
we've introduced last year in

00:46:01.170 --> 00:46:04.840
iOS 5 and Line that support
multiple concurrent operations.

00:46:04.860 --> 00:46:07.610
And you create these with the
same dispatch queue create

00:46:07.750 --> 00:46:12.520
call but pass in dispatch queue
concurrent as the second parameter.

00:46:13.050 --> 00:46:16.180
And once you have one of these queues,
you can implement multiple

00:46:16.180 --> 00:46:20.600
synchronous read operations by doing
a dispatch sync onto that queue.

00:46:20.640 --> 00:46:23.210
Multiple of these dispatch syncs
can occur at the same time without

00:46:23.210 --> 00:46:26.650
interfering with each other,
so you can have multiple

00:46:26.730 --> 00:46:28.450
concurrent readers.

00:46:28.630 --> 00:46:31.910
If you have to do a write operation,
you will use the dispatch

00:46:31.910 --> 00:46:33.260
barrier async call.

00:46:33.310 --> 00:46:35.770
This will ensure that
because it's a barrier,

00:46:35.980 --> 00:46:39.910
it is the only call,
the only block that's accessing the

00:46:40.010 --> 00:46:43.270
subsystem during a write operation.

00:46:44.910 --> 00:46:47.040
Let's look at a very
simple example of-- oh,

00:46:47.040 --> 00:46:49.360
before that,
we went into much more detail

00:46:49.360 --> 00:46:53.470
on this in the Mastering
Grand Central Dispatch session last year.

00:46:53.780 --> 00:46:56.180
Let's look at the quick
example of this in code.

00:46:56.470 --> 00:47:00.430
Here in our storage subsystem,
we create its controlling queue

00:47:00.760 --> 00:47:04.480
with a DispatchQueueCreate call by
passing in the DispatchQueueConcant

00:47:04.510 --> 00:47:08.860
flag that I just mentioned,
and now implement a read operation to

00:47:08.860 --> 00:47:12.120
the subsystem with DispatchBarrierAsync.

00:47:12.370 --> 00:47:15.920
Once we are inside this block,
we are sure that we are the only

00:47:16.540 --> 00:47:19.450
ones on that queue at that time,
so we can safely mutate

00:47:19.590 --> 00:47:21.300
our storage at that point.

00:47:21.380 --> 00:47:25.060
But now in our rendering subsystem,
we need some image data

00:47:25.060 --> 00:47:26.130
to render the thumbnail.

00:47:26.370 --> 00:47:28.900
This is where we would do a read
operation from the storage subsystem,

00:47:28.900 --> 00:47:31.300
so we use a dispatch sync
call to our store queue.

00:47:31.300 --> 00:47:35.010
And multiple of these could now occur
in the application at the same time

00:47:35.320 --> 00:47:40.460
and operate very cheaply by just
doing a direct check for any presence

00:47:40.640 --> 00:47:43.430
of barrier operations on the queue,
and if not,

00:47:43.430 --> 00:47:45.300
doing this block inline directly.

00:47:45.300 --> 00:47:49.270
And we extract some data from that
block with the under_under block

00:47:49.320 --> 00:47:51.300
syntax that we've seen earlier.

00:47:56.110 --> 00:47:58.670
Our next topic is the importance
of separating control and

00:47:58.670 --> 00:48:01.560
data flow in your application.

00:48:02.080 --> 00:48:06.350
Dispatch queues are great to
organize control flow in your app,

00:48:06.350 --> 00:48:09.990
but they weren't really designed as a
general purpose data storage mechanism.

00:48:10.300 --> 00:50:07.900
[Transcript missing]

00:50:12.310 --> 00:50:15.350
The next topic is how to update
state asynchronously very

00:50:15.430 --> 00:50:17.780
efficiently by using dispatch queues.

00:50:17.920 --> 00:50:23.320
Imagine in our app we have a progress
bar that keeps track of how many

00:50:23.810 --> 00:50:25.760
thumbnails have already been rendered.

00:50:25.830 --> 00:50:28.760
And we want to very,
very cheaply update the state of this

00:50:28.760 --> 00:50:31.930
progress bar from anywhere in our app.

00:50:32.040 --> 00:50:35.750
We will use a dispatch source for this.

00:50:35.870 --> 00:50:39.800
Here we're creating it with the
dispatch source type data add.

00:50:39.870 --> 00:50:44.710
and we ask for the callbacks from this
queue to be called on the main queue.

00:50:45.740 --> 00:50:52.430
Now we're setting up an event handler
for this source that simply gets the

00:50:52.670 --> 00:50:56.680
pending data from the source object
and updates our progress view with

00:50:56.750 --> 00:51:00.640
the progress that has been made since
the last time our block was called.

00:51:00.640 --> 00:51:04.400
And once we've resumed this source,
we can, from anywhere in our app now,

00:51:04.480 --> 00:51:09.240
update the progress by calling the
dispatch source Merge Data API.

00:51:09.260 --> 00:51:13.800
This will very cheaply just do
an atomic add operation to merge

00:51:13.980 --> 00:51:17.900
in the state and trigger the
execution of the event handler.

00:51:17.900 --> 00:51:21.210
Importantly, though,
the dispatch source infrastructure

00:51:21.310 --> 00:51:26.110
takes care to coalesce potentially
many of these update events into one

00:51:26.110 --> 00:51:28.300
single invocation of the handler.

00:51:28.360 --> 00:51:32.240
So this is something you can use
this to make sure that you're not

00:51:32.240 --> 00:51:36.930
overwhelming the main queue with many
requests to update the progress bar.

00:51:37.160 --> 00:51:44.220
It will only execute as many times as the
main queue can actually handle and maybe

00:51:44.250 --> 00:51:48.800
update the progress bar for a larger
amount of progress for every invocation.

00:51:48.840 --> 00:51:52.360
Another advantage is that you
can cancel dispatch sources.

00:51:52.410 --> 00:51:55.320
So if the user has completely switched
to a different part of your app where

00:51:55.420 --> 00:51:58.300
that progress bar isn't even visible,
you can just cancel this source

00:51:58.300 --> 00:52:02.840
and prevent any invocations of this
event handler to occur in the future,

00:52:02.890 --> 00:52:06.520
even if there have been some
updates in the meantime with the

00:52:06.630 --> 00:52:08.560
dispatch source Merge Data call.

00:52:12.150 --> 00:52:17.340
Our last topic is moving
code out of process with XPC.

00:52:17.830 --> 00:52:22.580
We've already seen how you can use XPC to
apply the principles of fault isolation

00:52:22.710 --> 00:52:24.630
and privilege separation to your code.

00:52:24.730 --> 00:52:29.220
And one way to think of this is to
improve the user experience of your app

00:52:29.350 --> 00:52:34.710
by not just not block the main thread,
but don't crash the main thread.

00:52:34.910 --> 00:52:41.050
So moving code that may have to operate
on untrusted data or that is known

00:52:41.300 --> 00:52:46.360
to be prone to crashes or security
issues out of process is a good way to

00:52:46.360 --> 00:52:48.580
improve the user experience of your app.

00:52:48.620 --> 00:52:52.280
And in this infrastructure that we've
described of one queue per subsystem,

00:52:52.280 --> 00:52:55.530
you can simply think of
XPC connections as a remote queue.

00:52:55.820 --> 00:53:02.110
And for many more details on the XPC,
we've introduced an awesome new

00:53:02.410 --> 00:53:07.200
API in Mountain Lion in Cocoa for
XPC that was covered yesterday.

00:53:07.200 --> 00:53:08.400
You should definitely go and see it.

00:53:08.400 --> 00:53:10.350
If you've missed it,
go and see that session on

00:53:10.350 --> 00:53:14.020
iTunes once it becomes available,
along with last year's

00:53:14.060 --> 00:53:16.140
Introducing XPC session.

00:53:16.990 --> 00:53:23.040
So here we've represented the same
architecture of our app as before,

00:53:23.070 --> 00:53:27.810
except we've decided we should really
put the image rendering subsystem

00:53:27.860 --> 00:53:29.210
of our app into a different process.

00:53:29.310 --> 00:53:32.000
It's operating on network data,
image data that comes

00:53:32.010 --> 00:53:34.230
in from the network,
and we can't be sure that

00:53:34.230 --> 00:53:37.870
that won't cause us to crash
or to have a security issue.

00:53:38.070 --> 00:53:40.590
And except for doing that,
for moving that code

00:53:40.590 --> 00:53:44.430
into a separate process,
our app architecture is exactly the same.

00:53:44.620 --> 00:53:48.720
We still send messages back and
forth between the subsystems,

00:53:48.720 --> 00:53:51.590
except that some of these
messages now travel over XPC.

00:53:51.750 --> 00:53:55.780
But if you've already applied the
one-cube-a-subsystem idea and subdivided

00:53:55.780 --> 00:53:58.800
your app into different areas,
it is actually very,

00:53:58.800 --> 00:54:03.990
very easy to apply XPC to this and
extract some of these subsystems

00:54:03.990 --> 00:54:07.890
into their own processes that may
have different privileges or may need

00:54:08.330 --> 00:54:12.320
to not cause the main app to crash.

00:54:14.370 --> 00:54:18.810
So in summary, let's review the design
patterns that we've seen.

00:54:18.900 --> 00:54:23.370
Number one, most important to remember,
don't block the main thread.

00:54:23.630 --> 00:54:28.120
You do that by running code in the
background with GCD and blocks.

00:54:28.390 --> 00:54:30.370
And while doing that,
make sure that you don't block

00:54:30.500 --> 00:54:33.000
too many background threads
with blocking IO operations

00:54:33.000 --> 00:54:35.990
or other blocking operations.

00:54:36.160 --> 00:54:40.650
We've seen how to integrate with the
main run loop when you write GCD code.

00:54:41.420 --> 00:54:46.450
How to apply the one queue per subsystem
pattern and read a writer access

00:54:46.460 --> 00:54:52.180
pattern when you have subsystems
in your app that support reader access.

00:54:52.270 --> 00:54:56.820
How to separate control and data flow
and the importance of doing that.

00:54:56.910 --> 00:55:01.420
And how to update data synchronously
with dispatch sources very efficiently.

00:55:01.490 --> 00:55:05.460
And finally, how to move operations
out of process with XPC.

00:55:07.230 --> 00:55:08.930
For more information,
we have some excellent

00:55:09.000 --> 00:55:10.940
documentation on the developer site.

00:55:11.030 --> 00:55:15.200
The Concurrency Programming Guide covers
GCD and related technologies.

00:55:15.290 --> 00:55:18.860
The Daemons and Services Programming
Guide covers XPC.

00:55:18.940 --> 00:55:22.700
And the Transitioning to
ARC Release Note goes into much

00:55:22.760 --> 00:55:28.260
more detail about the blocks and
ARC topics that I've covered earlier.

00:55:28.370 --> 00:55:31.120
If you have any questions,
please contact our evangelist,

00:55:31.190 --> 00:55:33.460
Michael Turowicz,
or ask on the developer forums.

00:55:33.580 --> 00:55:38.970
There is dedicated sections
for both GCD and XPC on those.

00:55:39.550 --> 00:55:41.660
We've already gone over
the related sessions.

00:55:41.700 --> 00:55:44.070
Don't forget to go to the
Adopting Automatic Reference

00:55:44.120 --> 00:55:45.420
Counting repeat later.

00:55:45.420 --> 00:55:46.150
And that is it.

00:55:46.180 --> 00:55:46.900
Thanks a lot.