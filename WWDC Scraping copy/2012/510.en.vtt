WEBVTT

00:00:10.070 --> 00:00:10.640
Good morning, everyone.

00:00:10.640 --> 00:00:14.120
My name is David Hayward,
and I work on the imaging team at Apple.

00:00:14.120 --> 00:00:17.400
And I want to talk today about
Core Image and how you can

00:00:17.470 --> 00:00:20.890
use it in your application,
give you a good introduction to this

00:00:20.900 --> 00:00:24.180
technology we're talking about today,
which is available for

00:00:24.180 --> 00:00:25.280
both MacÂ OS and iOS.

00:00:25.280 --> 00:00:29.210
So today we'll be talking about giving
you an introduction to Core Image,

00:00:29.220 --> 00:00:32.210
what are the key concepts of Core Image,
and what are the built-in

00:00:32.210 --> 00:00:33.230
filters it provides.

00:00:33.300 --> 00:00:36.740
Then we'll go into a bit more
detail about how to use the

00:00:37.160 --> 00:00:40.890
key classes in Core Image,
some details on the specifics

00:00:40.940 --> 00:00:44.660
of the two different platforms
that we provide support for.

00:00:44.660 --> 00:00:50.160
And then also we'll be talking about
images and filters and contexts.

00:00:50.160 --> 00:00:53.180
After that,
in the second half of our presentation,

00:00:53.220 --> 00:00:56.580
Alex will be talking about how to combine
some filters in some really exciting

00:00:56.580 --> 00:00:58.360
ways to produce some unusual effects.

00:00:58.360 --> 00:00:59.590
Thank you.

00:01:00.510 --> 00:01:02.830
So, first off,
introduction to Core Image.

00:01:03.040 --> 00:01:05.940
So Core Image is an image
processing framework.

00:01:05.940 --> 00:01:07.360
But it's not just useful for images.

00:01:07.360 --> 00:01:09.640
It can also be used for
video and for games.

00:01:09.710 --> 00:01:13.460
The idea behind it is that you
can use filters to apply per-pixel

00:01:13.460 --> 00:01:17.040
operations to an image of data.

00:01:17.160 --> 00:01:19.700
So, for example,
in a simple test case here,

00:01:19.700 --> 00:01:22.760
we have an original image that we have,
and we want to apply a

00:01:22.760 --> 00:01:24.090
sepia tone filter to it.

00:01:24.240 --> 00:01:27.400
And it produces a new image as a result.

00:01:29.680 --> 00:01:32.260
One of the key flexibilities of
Core Image is that it's very easy

00:01:32.260 --> 00:01:34.290
to chain together multiple filters.

00:01:34.410 --> 00:01:37.200
So, for example, in addition to applying
sepia tone to an image,

00:01:37.200 --> 00:01:40.830
we can apply a hue rotation filter,
which will turn it into

00:01:40.830 --> 00:01:42.400
kind of a blue tone effect.

00:01:42.500 --> 00:01:44.400
And then we can apply
another effect after that,

00:01:44.400 --> 00:01:48.420
which is a contrast enhancing filter, to,
you know, give a new,

00:01:48.420 --> 00:01:50.050
more complicated effect.

00:01:50.170 --> 00:01:53.780
And it's important to keep this in mind,
that these unique combinations

00:01:53.780 --> 00:01:57.500
of filters can produce a
myriad of different options.

00:01:57.720 --> 00:02:00.180
While conceptually you can think of
there being an intermediate image

00:02:00.200 --> 00:02:02.540
between each of these filters,
one of the key things that

00:02:02.590 --> 00:02:06.100
Core Image does to improve performance
is concatenate filter chains

00:02:06.100 --> 00:02:09.060
so as to reduce intermediate buffers.

00:02:09.100 --> 00:02:12.230
And this is a key thing that
Core Image does to improve performance.

00:02:12.240 --> 00:02:16.310
Another key thing that we do to
improve performance is that we

00:02:16.370 --> 00:02:21.130
optimize our render graphs at the
time that the actual render occurs.

00:02:21.220 --> 00:02:24.940
This allows us to know at the time of
rendering what exact optimizations we

00:02:24.940 --> 00:02:27.010
can make and do several enhancements.

00:02:27.670 --> 00:02:33.010
For example, the color rotation and the
contrast filters are internally

00:02:33.010 --> 00:02:34.820
represented as color matrices.

00:02:34.820 --> 00:02:37.650
And these color matrices,
because they're matrices,

00:02:37.680 --> 00:02:38.980
can be concatenated.

00:02:38.980 --> 00:02:41.980
And this actually further
improves performance and actually

00:02:41.980 --> 00:02:44.720
improves precision as well because
we can be doing this matrix

00:02:44.720 --> 00:02:46.210
concatenation at high precision.

00:02:46.220 --> 00:02:47.550
Thank you.

00:02:49.180 --> 00:02:52.480
Another key power of Core Image is
that it's a very easy-to-use

00:02:52.530 --> 00:02:56.060
Objective-C API that has a lot
of different flexible inputs.

00:02:56.060 --> 00:02:59.680
For example, those images can come
from a variety of sources.

00:02:59.680 --> 00:03:01.400
They can come from your iPhoto library.

00:03:01.400 --> 00:03:03.830
They can come from a live
video capture session.

00:03:03.840 --> 00:03:07.400
They can come from images that you've
created in memory using other techniques.

00:03:07.440 --> 00:03:12.030
They can come from JPEGs and
PNG files that you may have on disk.

00:03:12.060 --> 00:03:15.160
They can also even come
in from OpenGL textures.

00:03:15.400 --> 00:03:19.580
And we'll be talking more about how to
leverage OpenGL and Core Image together

00:03:19.580 --> 00:03:21.080
in our second session this afternoon.

00:03:23.710 --> 00:03:26.480
We also have very flexible outputs,
and this is also really important.

00:03:26.490 --> 00:03:30.300
One type of output you can get out
of Core Image is a CG image ref.

00:03:30.380 --> 00:03:32.250
And from a CG image ref,
you can go to a lot of other

00:03:32.250 --> 00:03:33.700
different places in the system.

00:03:33.700 --> 00:03:36.060
Like,
you can create a UI image from that,

00:03:36.060 --> 00:03:39.340
or you can go out to Image.io
to save these images to disk,

00:03:39.340 --> 00:03:42.880
or you can use the assets library
to save it into PhotoRoll.

00:03:43.800 --> 00:03:47.480
We can also render into an
Eagle layer for OpenGL rendering.

00:03:47.480 --> 00:03:51.680
We can render into a CV pixel buffer,
which is useful if you're going

00:03:51.680 --> 00:03:55.610
to be using Core Image as part of
an AV Foundation API application.

00:03:55.620 --> 00:04:00.080
You can also render to raw
bits or to OpenGL textures.

00:04:02.040 --> 00:04:06.100
So again, it's a very easy-to-use
Objective-C library that has very

00:04:06.160 --> 00:04:11.690
flexible ways of combining filters and
flexible inputs and flexible outputs.

00:04:12.150 --> 00:04:14.800
Part of the magic of Core Image is
that it comes with a large

00:04:14.800 --> 00:04:16.590
library of built-in filters.

00:04:16.770 --> 00:04:20.480
And a year ago at WWC, before iOS 5,
we only had a few filters

00:04:20.480 --> 00:04:22.260
that were available on iOS.

00:04:22.390 --> 00:04:25.900
We've greatly increased
that when iOS 5 shipped,

00:04:25.930 --> 00:04:30.640
and we've further increased
that significantly with iOS 6.

00:04:30.700 --> 00:04:34.000
We now have 93 built-in filters.

00:04:34.020 --> 00:04:36.160
Thank you.

00:04:36.900 --> 00:04:39.780
I'll talk about them in
a little bit more detail.

00:04:39.780 --> 00:04:42.730
Obviously, there's too many just to read
easily on this screen here,

00:04:42.730 --> 00:04:45.180
so let me kind of break them
down into different groups.

00:04:45.180 --> 00:04:47.760
Core Image has different
categories of filters,

00:04:47.760 --> 00:04:50.180
and I'm going to give some highlights
of the different categories.

00:04:50.180 --> 00:04:52.920
So first of all,
we have a category of filters which are

00:04:53.010 --> 00:04:55.340
for color effects or color adjustments.

00:04:55.340 --> 00:04:59.550
And these are ones like the sepia
tone image that I showed earlier,

00:04:59.550 --> 00:05:02.700
which allows you to take an
image and apply an operation that

00:05:02.700 --> 00:05:04.280
will change the color on that.

00:05:05.270 --> 00:05:09.590
Now, conceptually,
a filter like this takes an input

00:05:09.780 --> 00:05:11.600
image and produces an output image.

00:05:11.600 --> 00:05:13.200
All filters produce an output image.

00:05:13.200 --> 00:05:16.430
And it also may have additional
numerical parameters on it,

00:05:16.750 --> 00:05:19.480
such as the intensity of the
sepia tone effect in this example.

00:05:19.500 --> 00:05:23.430
So a lot of the color adjustment
filters will look like this,

00:05:23.480 --> 00:05:25.990
an input image, an output image,
and one or more additional parameters.

00:05:28.140 --> 00:05:32.200
Another category of filters that
we have are compositing operations.

00:05:32.370 --> 00:05:34.940
And these are operations that
allow you to combine two images,

00:05:35.060 --> 00:05:38.420
either using Porter-Duff compositing
or some of the other compositing

00:05:38.420 --> 00:05:42.390
modes that are very common in
image editing applications.

00:05:42.550 --> 00:05:44.000
I can give an example of that here.

00:05:44.000 --> 00:05:48.650
We have a blend mode operation where we
take in our picture of these boats and

00:05:48.650 --> 00:05:53.690
a checkerboard image and combine them
into an image where you can see both the

00:05:53.830 --> 00:05:56.570
boats and the checkerboards together.

00:05:56.960 --> 00:05:58.640
Conceptually,
these filters are interesting

00:05:58.640 --> 00:06:02.820
because they actually have two
input images and one output image.

00:06:02.820 --> 00:06:06.380
So you can see that now that we've got
an example of a filter with two inputs,

00:06:06.380 --> 00:06:11.450
you can see that we can create
complex graphs of filter operations.

00:06:12.360 --> 00:06:16.410
Another class of filters are for
adjusting the geometry on an image.

00:06:16.730 --> 00:06:19.880
A canonical example of that is
something that allows you to do

00:06:19.980 --> 00:06:22.340
an affine transform on an image.

00:06:24.020 --> 00:06:25.840
Another example are tiling effects.

00:06:25.840 --> 00:06:29.130
These are effects that will
allow you to take an image and

00:06:29.130 --> 00:06:31.140
repeat it in interesting ways.

00:06:31.140 --> 00:06:33.660
For example,
we have a perspective tile effect,

00:06:33.830 --> 00:06:37.450
which will take the original image
and tile it and apply a perspective

00:06:37.450 --> 00:06:39.630
transform to it in a shader program.

00:06:39.660 --> 00:06:43.290
One thing that's interesting about
this class of filters is it actually

00:06:43.310 --> 00:06:47.050
produces an infinite image because
the tiles repeat off to infinity.

00:06:47.060 --> 00:06:50.120
So this is one thing that's
unique about the Core Image APIs,

00:06:50.120 --> 00:06:53.740
actually is perfectly suited to
handling images of infinite extent.

00:06:53.900 --> 00:06:54.740
Bye.

00:06:57.320 --> 00:07:00.000
Another class of filters
are distortion effects.

00:07:00.040 --> 00:07:03.800
These also affect the location of pixels,
for example, a twirled distortion.

00:07:03.830 --> 00:07:08.720
You might be familiar with these if you
use the Photo Booth application on iOS,

00:07:08.720 --> 00:07:12.910
which uses Core Image and filters
like these quite frequently.

00:07:14.280 --> 00:07:17.300
Another class are blur
and sharpen effects.

00:07:17.300 --> 00:07:21.480
And this has been one of our most
requested filters to be added to iOS 6.

00:07:21.600 --> 00:07:24.860
Blur is a really critical filter,
and it's also the basis of

00:07:24.920 --> 00:07:28.760
many other important filters,
like sharpening filters.

00:07:29.070 --> 00:07:30.320
So this isn't focused.

00:07:30.360 --> 00:07:32.880
It's just a blurry image.

00:07:35.240 --> 00:07:38.120
Another set of effects we have are
what we call some stylizing filters.

00:07:38.210 --> 00:07:39.960
And these are just interesting effects.

00:07:40.050 --> 00:07:42.680
We have, for example,
highlights and shadows adjustments.

00:07:42.870 --> 00:07:45.780
And I've kind of overdriven
it for sake of demo here,

00:07:45.780 --> 00:07:49.950
so it kind of produces a fake HDR look
where you brought up the shadows of an

00:07:49.950 --> 00:07:54.400
image and brought down the highlights
to create a very stylized image.

00:07:54.400 --> 00:07:55.400
Halftone effects.

00:07:55.400 --> 00:07:56.360
These are another set of fun effects.

00:07:56.430 --> 00:07:59.590
We'll take an image and
produce a two-color image

00:07:59.590 --> 00:08:01.390
based on a halftone pattern.

00:08:01.500 --> 00:08:04.500
Here's a kind of
traditional halftone screen.

00:08:06.590 --> 00:08:07.470
And transition effects.

00:08:07.600 --> 00:08:08.530
These are also fun.

00:08:08.760 --> 00:08:12.200
These are effects that are very useful
if you're using Core Image in a video

00:08:12.200 --> 00:08:17.580
or gaming environment where you want to
transition between two sets of content.

00:08:17.580 --> 00:08:21.170
If you have a first scene and a second
scene and you want to do a transition

00:08:21.210 --> 00:08:23.110
or blend between those two scenes.

00:08:23.700 --> 00:08:25.800
We have here a copy machine effect.

00:08:25.870 --> 00:08:29.170
We have two images and we got a
screenshot of it halfway between

00:08:29.170 --> 00:08:32.680
in the middle of the transition
where we have a checkerboard and the

00:08:32.680 --> 00:08:37.130
boats image and this sort of copy
machine blue highlight that's in the

00:08:37.130 --> 00:08:39.770
process of moving across the screen.

00:08:40.930 --> 00:08:43.790
Transition effects are sort of
interesting because they take two images,

00:08:43.930 --> 00:08:46.330
the input image,
which is the image you start with

00:08:46.330 --> 00:08:48.600
at the beginning of the transition,
the target image,

00:08:48.600 --> 00:08:51.780
which is the effect that you
want to end up with at the end,

00:08:51.790 --> 00:08:55.120
and then a time value,
which ranges from zero to one.

00:08:55.120 --> 00:08:57.900
Generators is another
interesting class of filters.

00:08:57.900 --> 00:09:00.340
These are filters that
don't take any input images.

00:09:00.340 --> 00:09:02.680
They just produce an
algorithmically generated image.

00:09:02.800 --> 00:09:05.240
And here's a very dramatic one,
a starburst pattern,

00:09:05.240 --> 00:09:06.680
but there's other generators as well.

00:09:06.680 --> 00:09:11.350
One important one that we'll show
later today is one that produces a

00:09:11.480 --> 00:09:15.650
tiled image of random texture data,
and that's very useful for

00:09:15.780 --> 00:09:17.690
interesting effects as well.

00:09:17.700 --> 00:09:21.370
Generators, like the Starshine generator,
are interesting because

00:09:21.370 --> 00:09:24.290
they have an output image,
just like all other filters,

00:09:24.290 --> 00:09:26.000
but there's no input image.

00:09:26.000 --> 00:09:28.460
All the inputs are numerical parameters.

00:09:28.480 --> 00:09:32.500
And in fact, some of the generators
have no input parameters.

00:09:32.640 --> 00:09:36.210
like random,
it just produces a output image.

00:09:38.730 --> 00:09:42.270
So these are the 93 filters
that we've added in iOS 6,

00:09:42.270 --> 00:09:44.560
and we've taken quite a bit of
care to choose these filters.

00:09:44.560 --> 00:09:49.130
The key things we've decided is to make
sure we support both some fun effects,

00:09:49.140 --> 00:09:53.920
some effects that are all
performant on a variety of devices,

00:09:53.920 --> 00:09:57.730
and also the kind of effects that can
be combined in important ways to produce

00:09:57.730 --> 00:09:59.960
additional effects in your application.

00:09:59.960 --> 00:10:02.140
All right,
so I'm going to come over to my

00:10:02.250 --> 00:10:05.320
device here and show you a new
application we have to demonstrate

00:10:05.320 --> 00:10:09.150
all these filters that I was
talking about a few slides ago.

00:10:09.160 --> 00:10:12.700
So as I mentioned before,
we have 93 filters,

00:10:12.700 --> 00:10:15.960
and we have this great application that
now allows you to explore these filters.

00:10:17.730 --> 00:10:20.700
What we can do when we launch the app
here is we just get an empty screen.

00:10:20.700 --> 00:10:22.700
So the first thing we're
going to do is go to Filters,

00:10:22.700 --> 00:10:25.700
and we're going to add a video source.

00:10:25.700 --> 00:10:27.700
So I'm going to go and
add an import video.

00:10:28.010 --> 00:10:31.700
And now we can see a picture of myself.

00:10:31.820 --> 00:10:33.680
But we want to start seeing
what the filters look like.

00:10:33.700 --> 00:10:36.700
So the first thing I'm going
to do is add a filter on here,

00:10:36.800 --> 00:10:39.640
and I'm going to add a very
simple one called Color Controls.

00:10:39.700 --> 00:10:42.700
And after clicking on that,
I can then go and adjust

00:10:42.700 --> 00:10:44.690
all of its input parameters.

00:10:44.700 --> 00:10:48.200
So, for example,
we can adjust the saturation way

00:10:48.300 --> 00:10:52.700
up to be saturated or all the way
down and make the image grayscale.

00:10:52.700 --> 00:10:57.700
Or we can adjust the brightness up
or down or the contrast up or down.

00:10:57.700 --> 00:10:59.700
And this kind of gives you an
idea of the frame rates we can

00:10:59.700 --> 00:11:01.700
get for a very simple filter.

00:11:01.800 --> 00:11:02.700
I go back.

00:11:02.700 --> 00:11:04.610
I can now start doing some other filters.

00:11:04.810 --> 00:11:08.700
The next one I want to add is a
filter that we'll see a lot today,

00:11:08.720 --> 00:11:11.140
which is called Pixlite.

00:11:11.330 --> 00:11:14.540
So I can scroll down through
here through all these filters.

00:11:14.540 --> 00:11:15.500
Gone too far.

00:11:15.500 --> 00:11:16.530
Pixelate.

00:11:16.680 --> 00:11:18.530
And as you can already see,
it's pixelated.

00:11:18.640 --> 00:11:20.520
We can go in here and
adjust the parameters.

00:11:20.550 --> 00:11:24.540
We can make the pixels
really big or really small.

00:11:24.540 --> 00:11:27.740
And again, you can see the kind of
frame rate we can get.

00:11:28.880 --> 00:11:31.090
All right,
next thing I can show you is sort

00:11:31.100 --> 00:11:32.800
of another more interesting effect.

00:11:32.990 --> 00:11:36.490
We have here, again,
looking at the image,

00:11:36.680 --> 00:11:40.800
we want to apply a filter
called Circular Screen.

00:11:40.800 --> 00:11:44.790
Let me find that in the list under C.

00:11:45.920 --> 00:11:47.010
Circular screen.

00:11:47.230 --> 00:11:50.030
Circular screen is a
halftone type filter.

00:11:50.030 --> 00:11:52.780
And in this case,
it produces a circular halftone.

00:11:52.980 --> 00:11:56.960
And we can adjust where the
center of it is on the screen,

00:11:56.960 --> 00:11:58.370
left and right.

00:11:58.800 --> 00:12:04.010
We can also adjust the scale
of it so you can get an idea.

00:12:04.540 --> 00:12:06.520
And the sharpness of it, how crisp.

00:12:06.670 --> 00:12:09.830
This might be harder to see,
but you get the idea.

00:12:11.300 --> 00:12:13.390
But what we have right now is
sort of an interesting image,

00:12:13.460 --> 00:12:16.560
but we'd like to be able to combine
maybe another effect on top of this.

00:12:16.690 --> 00:12:18.960
And it would be kind of nice
if this had the screen effect,

00:12:19.100 --> 00:12:23.140
but also you could still see some of
the color from the video coming through.

00:12:23.300 --> 00:12:25.360
And so I'm going to use a
composite operation for that.

00:12:25.360 --> 00:12:28.870
I'm going to composite this
effect with the original video.

00:12:29.050 --> 00:12:34.090
So to do that, I'm going to add another
instance of the video filter.

00:12:34.190 --> 00:12:35.830
And as you can see,
now we're back to just

00:12:35.830 --> 00:12:37.900
seeing the video filter.

00:12:37.990 --> 00:12:41.220
But the circular screen is
still on the stack of filters.

00:12:41.370 --> 00:12:44.820
So now what I next want to do is I want
to do a blend mode between these two.

00:12:44.910 --> 00:12:49.340
So I'm going to do a darken blend mode.

00:12:49.510 --> 00:12:52.260
Go down here to darken.

00:12:52.260 --> 00:12:55.570
And so now hopefully you can see
clearly we have an image that's sort

00:12:55.570 --> 00:12:59.740
of the combination of both the video,
its screened version of itself,

00:12:59.740 --> 00:13:01.660
and the original color.

00:13:01.690 --> 00:13:05.040
And we can go back and adjust the
parameters on any of these earlier

00:13:05.040 --> 00:13:08.370
filters in real time and see the effect.

00:13:09.340 --> 00:13:10.780
All right, so that's it.

00:13:10.990 --> 00:13:14.310
This is an application that will
have available a sample code,

00:13:14.390 --> 00:13:17.000
and you'll be able to use
this to try out filters.

00:13:17.000 --> 00:13:21.740
One other thing that we'll be showing
you next is how to add your own filters,

00:13:21.740 --> 00:13:24.060
which are based up upon
our built-in filters.

00:13:24.060 --> 00:13:28.140
And we'll just mention them briefly,
and we'll get to see them in more detail.

00:13:28.140 --> 00:13:30.970
We have some very fun effects,
which you'll be able to see in this

00:13:30.970 --> 00:13:33.080
application when you get the sample code.

00:13:33.080 --> 00:13:35.750
So how can you use
Core Image in your application?

00:13:35.760 --> 00:13:38.480
So as I mentioned before,
Core Image is an Objective-C API.

00:13:38.480 --> 00:13:39.430
It's very easy to use.

00:13:39.500 --> 00:13:42.080
And there's only really
three classes that you need

00:13:42.150 --> 00:13:43.800
to understand in Core Image.

00:13:43.840 --> 00:13:46.920
The first is the CI Filter class.

00:13:46.920 --> 00:13:49.910
In the CI Filter class,
this represents a mutable

00:13:49.910 --> 00:13:52.620
object that represents the
effect that you want to produce.

00:13:52.620 --> 00:13:56.810
And a filter has a set
of input parameters,

00:13:56.810 --> 00:13:59.980
which are either image parameters
or other numerical parameters.

00:14:01.810 --> 00:14:06.390
And the result of a filter is that
it produces an output image based on

00:14:06.390 --> 00:14:08.960
the current set of input parameters.

00:14:09.580 --> 00:14:13.040
The second key class
is the CI image class.

00:14:13.240 --> 00:14:17.120
And this is an immutable object that
represents the recipe for an image.

00:14:17.120 --> 00:14:21.170
And this CI image object can
either represent a file that comes

00:14:21.360 --> 00:14:25.060
directly from an input source
or the output of a CI filter.

00:14:27.430 --> 00:14:29.980
The third key class is
the CI context class.

00:14:30.270 --> 00:14:34.450
And this is the object which maintains
state and is the object through which

00:14:34.540 --> 00:14:36.900
Core Image will render its results.

00:14:36.900 --> 00:14:39.040
And the CI context,
one thing to keep in mind is it

00:14:39.040 --> 00:14:42.830
can be based on either a CPU or
a GPU-based implementation.

00:14:42.960 --> 00:14:47.690
And this is an interesting flexibility
of Core Image and we'll talk about that

00:14:47.690 --> 00:14:49.860
in a little bit more detail in a minute.

00:14:51.850 --> 00:14:54.530
So as I mentioned earlier,
most of what we're talking about

00:14:54.600 --> 00:14:58.220
in this presentation is equally
applicable to iOS and to MacÂ OS,

00:14:58.220 --> 00:15:01.100
and the basic API is very similar,
but there are a couple distinctions

00:15:01.100 --> 00:15:03.590
that are important to keep in mind.

00:15:03.960 --> 00:15:05.860
First of all, on our set of filters,
on iOS,

00:15:05.910 --> 00:15:11.070
we have 93 built-in filters that can be
combined in an infinite number of ways.

00:15:11.290 --> 00:15:14.130
On MacÂ OS, we have a few additional
filters which have additional

00:15:14.220 --> 00:15:15.590
performance constraints on them.

00:15:15.700 --> 00:15:20.690
We also have the ability to create
developer extendable kernels.

00:15:21.980 --> 00:15:25.140
The basic API is identical
between iOS and MacÂ OS.

00:15:25.260 --> 00:15:27.700
The key three classes
which I mentioned earlier,

00:15:27.770 --> 00:15:31.680
CI Filter, CI Image,
and CI Context are the same.

00:15:31.850 --> 00:15:33.530
On MacÂ OS,
there's a few additional classes

00:15:33.530 --> 00:15:36.220
that you need to be aware of,
CI kernel and CI filter shape,

00:15:36.320 --> 00:15:38.560
if you were writing
your own custom kernels.

00:15:38.560 --> 00:15:40.600
But again,
the vast majority of applications

00:15:40.600 --> 00:15:41.940
can use our built-in filters.

00:15:44.390 --> 00:15:48.700
In both cases,
we do render time optimization of the

00:15:48.700 --> 00:15:53.190
render graph in order to produce the
best possible performance on device.

00:15:53.810 --> 00:15:57.460
And in both cases,
we support both CPU and GPU rendering.

00:15:57.500 --> 00:16:01.970
One subtle difference is that on iOS,
our GPU rendering is based

00:16:02.280 --> 00:16:05.760
on the OpenGL ES 2.0 API,
whereas on MacÂ OS,

00:16:05.760 --> 00:16:08.990
it's based on the traditional OpenGL API.

00:16:09.490 --> 00:16:10.390
So those are the intros.

00:16:10.480 --> 00:16:12.490
Let me show you just how in a
few lines of code you can add

00:16:12.500 --> 00:16:13.770
Core Image to your application.

00:16:13.830 --> 00:16:15.790
It's actually very, very simple.

00:16:15.910 --> 00:16:18.400
First thing we want to do is we're
going to create a CI image object,

00:16:18.460 --> 00:16:20.270
and we're going to create that
by initializing it with the

00:16:20.290 --> 00:16:22.650
contents of a file on disk.

00:16:22.820 --> 00:16:25.710
So we call it image with contents of URL.

00:16:26.210 --> 00:16:29.170
Second thing we're going to do is
create an instance of a filter object.

00:16:29.280 --> 00:16:32.780
In this case, we're going to create a
filter of type sepia tone,

00:16:32.880 --> 00:16:34.420
and we're going to set
some parameters on it,

00:16:34.500 --> 00:16:37.400
which are the input
image and the parameter,

00:16:37.400 --> 00:16:40.490
the amount of the sepia
tone we want to apply.

00:16:41.370 --> 00:16:43.050
Third,
we're going to create a context object

00:16:43.200 --> 00:16:45.660
that we're going to render through.

00:16:45.740 --> 00:16:47.770
And fourth,
we're going to use that context

00:16:47.850 --> 00:16:50.160
to produce an output image.

00:16:50.270 --> 00:16:52.740
We're first going to ask the
filter for its output image,

00:16:52.820 --> 00:16:54.440
and then we're going to
ask the context to create a

00:16:54.440 --> 00:16:56.600
CG image from the output image.

00:16:56.680 --> 00:17:00.630
And this is one of several ways we
can get outputs out of Core Image.

00:17:00.720 --> 00:17:03.080
We'll talk about more of those later.

00:17:04.460 --> 00:17:07.140
So now that you kind of see how
easy it is and a few lines of code,

00:17:07.390 --> 00:17:10.200
let me talk in a little bit more
detail about how these three

00:17:10.200 --> 00:17:11.740
key classes in Core Image work.

00:17:11.990 --> 00:17:14.290
Again, CI image, CI filter,
and CI context.

00:17:14.360 --> 00:17:16.240
So, some more on CI image.

00:17:18.150 --> 00:17:21.430
So a CI image can be
instantiated in several key ways.

00:17:21.430 --> 00:17:24.550
The most common is you will
instantiate it from an image

00:17:24.550 --> 00:17:26.240
I/O supported file format.

00:17:26.370 --> 00:17:29.630
So, for example,
instantiate it with a URL or some data

00:17:29.750 --> 00:17:33.710
that represents a JPEG or a PNG or
a TIFF file or whatever the formats

00:17:33.750 --> 00:17:36.150
that are supported by image I/O.

00:17:36.280 --> 00:17:39.760
We can also instantiate a
CI image from several other key

00:17:39.810 --> 00:17:41.750
data types on iOS and Mac OS.

00:17:41.910 --> 00:17:43.950
We can create a CI image from a CG image.

00:17:44.190 --> 00:17:49.400
We can, on iOS,
create a CI image from a CV pixel buffer.

00:17:49.450 --> 00:17:53.000
And on Mac OS, you can create it from
the CV image buffer,

00:17:53.000 --> 00:17:57.480
which is slightly different,
and/or an I/O surface.

00:17:57.740 --> 00:18:01.300
We can also create a CI image
from an OpenGL texture.

00:18:01.300 --> 00:18:04.390
And we'll be talking about
that in much more detail in our

00:18:04.390 --> 00:18:06.330
second session after this one.

00:18:06.680 --> 00:18:08.520
And lastly,
you can create a CI image from raw

00:18:08.590 --> 00:18:11.440
pixel data if you have some other
means of generating an image data.

00:18:11.600 --> 00:18:16.000
So one key aspect to think about
with Core Image is color management.

00:18:16.070 --> 00:18:19.790
On both iOS and MacÂ OS,
there is automatic color management

00:18:19.790 --> 00:18:21.900
that's involved in Core Image.

00:18:21.970 --> 00:18:25.500
On MacÂ OS, a Core Image can be tagged
with any color space.

00:18:25.590 --> 00:18:28.880
And if an image is tagged,
it will be automatically converted

00:18:29.200 --> 00:18:34.340
before filters are applied into a linear
working space that all filters work in.

00:18:34.480 --> 00:18:37.320
And this allows all the filters to
work in a consistent way regardless

00:18:37.410 --> 00:18:41.690
of the input image's color space
or your destination color space.

00:18:41.790 --> 00:18:44.530
On iOS,
it's very similar but slightly different.

00:18:44.630 --> 00:18:48.260
A CI image can be tagged with device RGB,
which you can think of as

00:18:48.260 --> 00:18:50.550
effectively tagging it with sRGB.

00:18:50.780 --> 00:18:54.400
And if it is tagged,
then all the pixels are gamma corrected

00:18:55.080 --> 00:19:00.990
using the proper sRGB math into a
linear space before filters are applied.

00:19:02.600 --> 00:19:05.870
If you use any of the normal ways
of instantiating an image from

00:19:06.070 --> 00:19:09.110
either a URL or data via Image.io,
all of this is handled

00:19:09.110 --> 00:19:10.580
for you automatically.

00:19:10.600 --> 00:19:13.660
However, if you wish to override the
default behavior of Core Image,

00:19:13.670 --> 00:19:19.090
you can change the working space
for an image to something else.

00:19:19.100 --> 00:19:22.720
One key example of this is if you want to
turn off color management for an image,

00:19:22.720 --> 00:19:28.970
you can set the KCI image color space to
override the default to be NS null null.

00:19:29.600 --> 00:19:31.600
And that means that no management
will occur for that image if

00:19:31.600 --> 00:19:32.670
that's what you want to do.

00:19:32.680 --> 00:19:36.260
Another key thing about images we
all know these days is metadata.

00:19:36.260 --> 00:19:39.330
When you take a picture on your iPhone,
you're not just capturing

00:19:39.390 --> 00:19:41.700
a raster of pixels,
you're also capturing a wealth of

00:19:41.700 --> 00:19:43.420
metadata that goes along with that image.

00:19:43.420 --> 00:19:46.960
Such as when it was taken,
what type of camera it was taken with,

00:19:47.010 --> 00:19:51.140
what the orientation of the camera is,
and where the image was taken.

00:19:51.140 --> 00:19:53.820
And this is really handy
information for applications.

00:19:53.840 --> 00:19:58.180
And we expose that in CI image
through a filter properties API.

00:19:58.820 --> 00:20:02.000
So if you instantiate a
CI image using any of the

00:20:02.000 --> 00:20:06.540
Image.io based creation methods,
image with URL or image with data,

00:20:06.540 --> 00:20:11.020
you can ask for the filter properties
and you'll get a wealth of information.

00:20:11.020 --> 00:20:14.120
You'll get back a dictionary
that returns the same type of

00:20:14.120 --> 00:20:17.720
dictionary as you get if you were
to call the Image.io API CG image

00:20:17.720 --> 00:20:19.840
source copy properties at index.

00:20:22.070 --> 00:20:24.500
If you wish to override
the metadata for an image,

00:20:24.580 --> 00:20:28.370
you can do that by specifying when you
instantiate the CI image an optional

00:20:28.380 --> 00:20:32.760
value for the KCI image properties.

00:20:32.830 --> 00:20:34.950
This might be useful, for example,
if you're creating an image

00:20:35.020 --> 00:20:39.340
synthetically and yet you want to have
it be processed and still maintain

00:20:39.340 --> 00:20:42.280
some metadata that you've created.

00:20:42.830 --> 00:20:45.340
Second thing I want to talk
about is this other key class,

00:20:45.360 --> 00:20:46.280
which is CI filters.

00:20:46.360 --> 00:20:47.860
We've talked about the
variety of filters,

00:20:47.900 --> 00:20:51.850
but let's talk in a bit more detail
about how you use them programmatically.

00:20:52.910 --> 00:20:56.680
First, we have a variety of filters,
and we've grown significantly

00:20:56.680 --> 00:20:58.130
from iOS 5 to iOS 6.

00:20:58.230 --> 00:21:02.520
You can query using the filters
in category API what filters are

00:21:02.560 --> 00:21:04.830
currently installed on your system.

00:21:05.980 --> 00:21:08.780
Filters are--once you
have the list of filters,

00:21:08.780 --> 00:21:11.200
you can instantiate a filter by name.

00:21:11.300 --> 00:21:15.810
For example, you can instantiate a filter
with the name CICpiotone.

00:21:16.010 --> 00:21:19.160
Another nice API we have
is filter attributes.

00:21:19.160 --> 00:21:21.110
This is,
you can think of it as sort of run-time

00:21:21.110 --> 00:21:23.020
documentation for how a filter works.

00:21:23.020 --> 00:21:27.090
It will give you information about
all the inputs of a given filter.

00:21:27.100 --> 00:21:31.040
For example, it'll tell you what the name
of each key for each input is,

00:21:31.120 --> 00:21:35.230
the expected data type for each input,
such as whether it's a number

00:21:35.230 --> 00:21:36.840
or a vector or an image.

00:21:36.840 --> 00:21:40.300
And also it'll give you some
common values for each input,

00:21:40.320 --> 00:21:42.960
such as what the default
value is for that parameter,

00:21:42.960 --> 00:21:47.450
what the identity value is,
or minimum and maximum.

00:21:47.610 --> 00:21:49.640
These kind of properties are
really useful if you want to build

00:21:49.640 --> 00:21:54.420
an application that shows some
UI slider for a given parameter,

00:21:54.490 --> 00:21:56.300
such as the amount of sepia tone.

00:21:56.300 --> 00:22:00.170
You can query the sepia tone filter,
see what the range of the parameter is,

00:22:00.170 --> 00:22:03.720
and you can set up your sliders
to present that range to the user.

00:22:03.720 --> 00:22:07.150
Once you have instantiated a CI filter,
you can set its parameters using

00:22:07.230 --> 00:22:09.460
standard key value coding conventions.

00:22:09.460 --> 00:22:13.250
So, for example,
you can set the input image by saying

00:22:13.250 --> 00:22:16.210
set value image for key KCI input image.

00:22:16.960 --> 00:22:19.870
Similarly,
you can set numerical values as well.

00:22:19.880 --> 00:22:22.560
Once you've set all
the inputs on a filter,

00:22:22.560 --> 00:22:25.490
you can ask for the output,
and this can also be done

00:22:25.490 --> 00:22:27.740
using key value conventions.

00:22:27.740 --> 00:22:32.140
For example, you can get value for
key KCI output image key.

00:22:32.140 --> 00:22:35.880
On iOS, we have a couple other convenient
ways to do the same thing.

00:22:35.880 --> 00:22:39.670
They're semantically equivalent but
have slightly different coding styles.

00:22:39.680 --> 00:22:42.450
For example, you can just ask the filter
for its output image,

00:22:42.450 --> 00:22:44.860
or you can say filter.outputimage.

00:22:47.160 --> 00:22:50.540
One convenient shortcut is you
can actually combine everything

00:22:50.540 --> 00:22:52.680
I talked about on this slide
and the previous slide,

00:22:52.680 --> 00:22:54.540
instantiating the filter,
setting the parameters,

00:22:54.540 --> 00:22:56.980
and asking for its output
into a single line of code.

00:22:56.980 --> 00:23:02.150
So we have this helper function here,
which is filter, filter with name, keys,

00:23:02.150 --> 00:23:04.860
and values,
which allows you to instantiate a filter,

00:23:04.860 --> 00:23:06.760
set its values,
and then right after that you

00:23:06.760 --> 00:23:08.000
can ask for its output image.

00:23:08.000 --> 00:23:10.700
So this is a very compact
way of doing this,

00:23:10.750 --> 00:23:14.190
and for sake of brevity of our code,
we use this a lot in

00:23:14.190 --> 00:23:15.860
our slides to follow.

00:23:19.470 --> 00:23:24.380
As I alluded to earlier,
you can chain together multiple filters.

00:23:24.540 --> 00:23:26.400
So for example,
we can have an input image.

00:23:26.400 --> 00:23:29.910
And let's say we want to
apply just one filter first.

00:23:30.050 --> 00:23:32.900
We can apply the sepia tone to that.

00:23:33.230 --> 00:23:36.240
If we want to apply a second,
it's very easy to chain these together.

00:23:36.240 --> 00:23:41.240
All we do is we apply the next filter
as the input for the second filter.

00:23:41.240 --> 00:23:43.380
We give the output from
the previous filter.

00:23:45.150 --> 00:23:47.610
And one thing to keep in mind is
that there's actually no pixel

00:23:47.740 --> 00:23:51.660
processing that has occurred at the
time we've built up the filter graph.

00:23:51.740 --> 00:23:55.910
All the actual work of rendering
and optimization is done at the

00:23:55.950 --> 00:24:01.410
time you actually ask for the
final render to be requested.

00:24:01.590 --> 00:24:05.960
So that brings up a nice segue to talk
about rendering through a CI context.

00:24:06.720 --> 00:24:10.200
So CI contexts have a lot of
flexible ways of rendering.

00:24:10.200 --> 00:24:13.860
You can render into a CG image
ref for several other types,

00:24:13.860 --> 00:24:19.480
or you can render into a UI image
view or into an iPhoto library.

00:24:19.480 --> 00:24:20.590
There's several other ways.

00:24:20.600 --> 00:24:22.870
We'll talk about some of
these other methods in our

00:24:22.870 --> 00:24:27.140
second session this afternoon,
but this morning I want to first talk

00:24:27.250 --> 00:24:32.380
about how to render into a CG image ref
and what you can do with that approach.

00:24:32.380 --> 00:24:35.440
So let's say, for example,
you want to display the output

00:24:35.440 --> 00:24:36.920
of a filter into a UI image view.

00:24:36.920 --> 00:24:39.100
This is actually very easy
to do in your application.

00:24:39.130 --> 00:24:42.010
All you need to do is
create a CI context,

00:24:42.120 --> 00:24:44.460
get the output image
from your filter chain,

00:24:44.460 --> 00:24:47.530
render the output image
into a CG image ref,

00:24:47.600 --> 00:24:52.640
and then tell the UI image view to
use that CG image ref for its view.

00:24:54.170 --> 00:24:55.260
So what does this look like in code?

00:24:55.260 --> 00:24:57.820
Again, it's a very brief
amount of code you need.

00:24:57.820 --> 00:25:00.810
You just need to instantiate a
CI context with its default values.

00:25:03.320 --> 00:25:07.290
asked the filter for its output image.

00:25:07.360 --> 00:25:12.190
Tell the context to turn
that image into a CG image.

00:25:13.410 --> 00:25:18.030
Create a UI image from that
CG image and tell the view to

00:25:18.030 --> 00:25:20.780
use that UI image as a view.

00:25:22.070 --> 00:25:24.140
There's actually a
shortcut for all of this,

00:25:24.160 --> 00:25:25.500
which is convenient.

00:25:25.500 --> 00:25:27.560
We'll talk more about the
performance implications of

00:25:27.560 --> 00:25:28.970
this in our second session.

00:25:29.040 --> 00:25:31.290
But it's actually very easy on a UI.

00:25:31.300 --> 00:25:33.790
You can create a UI image
directly from a CI image,

00:25:33.800 --> 00:25:34.940
if you wish.

00:25:35.070 --> 00:25:38.040
And then all you need to do
is do that and then tell the

00:25:38.040 --> 00:25:39.660
view to use that UI image.

00:25:39.900 --> 00:25:41.670
Internally,
this is conceptually equivalent

00:25:41.720 --> 00:25:43.300
to the previous slide.

00:25:43.350 --> 00:25:45.500
Let's say you want to do something
a little bit more elaborate,

00:25:45.500 --> 00:25:50.790
which is you want to save results of
a CI filter into your photo library.

00:25:50.870 --> 00:25:52.840
So in this case,
we probably want to create

00:25:52.840 --> 00:25:54.100
a CPU-based CI context.

00:25:54.180 --> 00:25:54.490
Why?

00:25:54.930 --> 00:25:58.240
Well, when you're saving a
full effect on a photo,

00:25:58.240 --> 00:26:01.880
photos can actually be quite large,
and those images that we have on our

00:26:01.880 --> 00:26:05.940
cameras these days are actually bigger
than the GPU limits of our devices.

00:26:07.590 --> 00:26:11.180
So for that reason alone,
we would want to use a CPU context.

00:26:11.200 --> 00:26:14.650
Also, when you're saving a photo
into your photo roll,

00:26:14.650 --> 00:26:17.110
you might want to be able to have
this done as a background task

00:26:17.130 --> 00:26:19.790
so that the user can quit your
application while you're completing

00:26:19.790 --> 00:26:21.130
that save into the photo roll.

00:26:21.140 --> 00:26:24.850
And in order for this to be done,
you need to be using a CPU-based

00:26:24.850 --> 00:26:27.260
CI context rather than a GPU context.

00:26:28.690 --> 00:26:32.630
So for both of these reasons,
this is a good idea if you're working

00:26:32.630 --> 00:26:36.910
on large images or you want to be
able to have a task be backgrounded.

00:26:38.000 --> 00:26:38.790
So how do we do this?

00:26:38.860 --> 00:26:41.740
This is just a slight variation
on what we saw two slides ago.

00:26:41.740 --> 00:26:44.060
This time we're going
to create a context,

00:26:44.060 --> 00:26:46.560
but we're going to specify this time
that we want a software renderer.

00:26:46.560 --> 00:26:48.550
And this is very simple.

00:26:48.550 --> 00:26:53.950
All we need to do is provide an options
dictionary with the key KCI context,

00:26:53.990 --> 00:26:57.360
use software renderer, and specify yes.

00:26:58.000 --> 00:26:59.670
Once we have the context,
we're going to do

00:26:59.670 --> 00:27:01.020
everything we did as before.

00:27:01.020 --> 00:27:04.060
We're going to create an
output image from our filter.

00:27:04.170 --> 00:27:08.290
We're going to create a CG image from
that output image using the context.

00:27:08.360 --> 00:27:12.550
And then we can use the normal
assets library API to save

00:27:12.550 --> 00:27:15.170
that image into the photo roll.

00:27:15.170 --> 00:27:19.320
And then a completion callback
will be called when it is complete.

00:27:20.980 --> 00:27:23.090
So this is all very simple.

00:27:23.280 --> 00:27:26.040
Here's some tips and best practices
that you should be aware of.

00:27:26.050 --> 00:27:30.020
One thing to keep in mind is
like all Objective-C objects,

00:27:30.020 --> 00:27:34.870
CI images and CI filters are typically
created as auto-released objects.

00:27:35.780 --> 00:27:38.390
And this is convenient,
but you should be aware that

00:27:38.650 --> 00:27:41.790
these classes in particular
may hold on to large assets.

00:27:41.840 --> 00:27:46.110
So in the interest of keeping
your memory usage to a minimum,

00:27:46.110 --> 00:27:49.520
you will probably want to be
careful about using auto-release

00:27:49.520 --> 00:27:52.900
pools in critical areas so
as to avoid memory pressure.

00:27:54.520 --> 00:27:56.710
Another thing to keep in mind
is there's no need to create a

00:27:56.740 --> 00:27:58.100
context every time you render.

00:27:58.100 --> 00:28:00.500
If you're going to be doing a
lot of renders in a sequence,

00:28:00.500 --> 00:28:02.620
you probably want to
create the context once.

00:28:02.620 --> 00:28:05.770
There's setup costs associated
with the CI context.

00:28:05.820 --> 00:28:09.440
And by doing that,
you can reuse that context again on the

00:28:09.440 --> 00:28:12.020
same thread as many times as you wish.

00:28:12.020 --> 00:28:13.350
And that will help improve performance.

00:28:14.360 --> 00:28:18.200
It's also important to be aware that
both Core Image and Core Animation both

00:28:18.460 --> 00:28:20.400
leverage the GPU on our devices.

00:28:20.400 --> 00:28:25.250
And because Core Animation is critical
for Core Animation to provide smooth

00:28:25.270 --> 00:28:29.550
and fluid user interface animations,
you'll want to take care not

00:28:29.550 --> 00:28:33.280
to use Core Image aggressively
on the GPU if you're also doing

00:28:33.280 --> 00:28:35.320
Core Animation animations.

00:28:35.320 --> 00:28:38.740
So again,
this might be a case where you might

00:28:38.740 --> 00:28:41.580
want to use a CPU-based CI context.

00:28:44.070 --> 00:28:48.280
Another thing to keep in mind,
as I alluded to a little bit earlier,

00:28:48.280 --> 00:28:51.740
is that both CI/CPU and
CI/GPU contexts have limits on the

00:28:51.890 --> 00:28:54.400
maximum image that can be processed.

00:28:54.620 --> 00:28:58.110
There's an API you can ask once
you have a context instantiated,

00:28:58.110 --> 00:29:02.030
which will tell you what the maximum
input image size is and what the

00:29:02.150 --> 00:29:03.700
maximum output image size is.

00:29:03.750 --> 00:29:07.480
And this can change from device
to device and release to release.

00:29:09.120 --> 00:29:11.520
It's also important to remember
that whenever possible,

00:29:11.580 --> 00:29:12.700
it's good to use smaller images.

00:29:13.010 --> 00:29:17.440
Performance in CI is largely determined
by complexity of your graph and also,

00:29:17.830 --> 00:29:21.650
critically, the number of output pixels
that you're asking CI to render.

00:29:21.810 --> 00:29:25.180
So asking it to reduce the images'
output image size will have a

00:29:25.190 --> 00:29:27.700
direct effect on performance.

00:29:27.770 --> 00:29:30.050
One thing to keep in mind is
that there are several convenient

00:29:30.050 --> 00:29:33.350
APIs in both Core Graphics and
Image I/O that allow you to either

00:29:33.350 --> 00:29:35.100
crop or reduce an input image.

00:29:35.160 --> 00:29:38.050
So if you have an 8-megapixel
image but you're only showing

00:29:38.050 --> 00:29:41.000
the user a portion of that,
you can create a cropped region

00:29:41.000 --> 00:29:45.100
of that and process that very
efficiently using Core Image.

00:29:48.110 --> 00:29:52.200
So that's the end of my
first discussion for today.

00:29:52.200 --> 00:29:55.590
I'm going to pass the stage over to Alex,
who will be talking in much more detail

00:29:55.590 --> 00:29:58.580
about filters and how they can be
combined in some really interesting ways.

00:29:58.680 --> 00:29:59.500
Thanks.

00:29:59.530 --> 00:30:00.800
Okay.

00:30:00.800 --> 00:30:01.430
Well, good morning, everyone.

00:30:01.560 --> 00:30:03.900
My name is Alexandre Naaman.

00:30:04.000 --> 00:30:05.990
So, so far this morning,
we've had an overview

00:30:05.990 --> 00:30:07.060
of the API in general.

00:30:07.240 --> 00:30:11.000
And what I'm going to talk about now
is just how we can use the CI filter

00:30:11.100 --> 00:30:13.790
class to produce interesting effects.

00:30:14.010 --> 00:30:19.430
So on iOS 6,
we now have 93 built-in filters.

00:30:19.610 --> 00:30:22.660
And you can use those -- and if
you're wondering why we have so many,

00:30:22.660 --> 00:30:25.650
it's because you can use those,
combine them together in interesting

00:30:26.100 --> 00:30:27.980
ways to create effects of your own.

00:30:28.100 --> 00:30:31.660
So you can come up with recipes
that don't exist and aren't

00:30:31.660 --> 00:30:34.050
built-in and create new effects.

00:30:34.940 --> 00:30:36.470
So how can we do that?

00:30:36.670 --> 00:30:40.260
Well,
you can actually subclass CI filter.

00:30:40.260 --> 00:30:42.600
And this is the same thing
that we do internally.

00:30:42.600 --> 00:30:44.970
And in order to do that,
you have to override a few methods,

00:30:44.970 --> 00:30:48.970
declare your properties,
set the defaults, et cetera.

00:30:49.360 --> 00:30:51.750
And an example of that is,
as I was saying,

00:30:51.750 --> 00:30:56.810
we use this internally for certain
of the filters that we provide,

00:30:56.810 --> 00:30:59.230
such as CI Color Invert,
which just inverts colors.

00:30:59.240 --> 00:31:03.120
And this is the entirety of the
code that shows how you do that.

00:31:03.160 --> 00:31:05.800
This is a relatively simple example.

00:31:05.800 --> 00:31:10.820
What we're going to do now is go
over six more complicated examples.

00:31:10.820 --> 00:31:13.150
And I've got an overview
here of our inputs.

00:31:13.160 --> 00:31:15.580
And I'm going to click
and then don't blink.

00:31:16.250 --> 00:31:18.610
And we're going to go and see
what all the different effects

00:31:18.610 --> 00:31:20.930
we're going to generate today
are and go through each step.

00:31:21.000 --> 00:31:21.810
So here we go.

00:31:24.670 --> 00:31:27.100
So now we're going to go through each one
of those individually and talk about all

00:31:27.100 --> 00:31:31.310
the steps and different filters we use
to create the effects that we see here.

00:31:33.610 --> 00:31:36.220
So first things first,
we're going to start with chroma key,

00:31:36.220 --> 00:31:39.950
so green screen style process,
where we're going to remove

00:31:39.950 --> 00:31:45.140
the background by keying off a
certain color and then blend.

00:31:45.590 --> 00:31:47.840
with the background image.

00:31:47.920 --> 00:31:48.900
So how are we going to do that?

00:31:49.070 --> 00:31:51.040
Well, we're going to create a color cube,
so we're going to use

00:31:51.040 --> 00:31:53.900
a CI color cube class,
and we're going to tell it that we

00:31:53.900 --> 00:31:56.890
want certain colors to be transparent.

00:31:57.230 --> 00:31:59.500
We're going to use that data
that we've just created,

00:31:59.500 --> 00:32:02.670
that color cube,
as an input to the color cube filter.

00:32:03.060 --> 00:32:05.560
And then we're going to use
source over compositing to blend

00:32:05.940 --> 00:32:09.520
the result of our input image,
in this case the picture of me

00:32:09.520 --> 00:32:12.640
standing in front of a green screen,
with our background,

00:32:12.640 --> 00:32:14.790
the picture of the beach.

00:32:15.300 --> 00:32:17.650
So if we start with a color
cube that looks like this,

00:32:17.730 --> 00:32:20.770
which is just an identity,
so if we were to use this as a data,

00:32:20.770 --> 00:32:22.580
it would just pass the input
image straight through.

00:32:22.580 --> 00:32:26.640
It's effectively a 3D color lookup table,
but we wouldn't be modifying anything.

00:32:26.640 --> 00:32:29.210
And in order to get the
effect that we're looking for,

00:32:29.210 --> 00:32:31.880
what we want to do is remove
all of the green from the image

00:32:31.880 --> 00:32:33.520
and make that transparent.

00:32:33.520 --> 00:32:39.080
So we're going to want to take a slice,
basically, out of this cube and make all

00:32:39.240 --> 00:32:41.300
the alpha values go to zero.

00:32:41.940 --> 00:32:45.290
So this is easier to see if we,
instead of looking at

00:32:45.290 --> 00:32:48.550
this in RGB color model,
we look at this in HSV,

00:32:48.650 --> 00:32:51.460
so U-saturation value,
where we have a cone.

00:32:51.460 --> 00:32:54.150
And we're basically going to
take a slice out of this cone.

00:32:55.710 --> 00:32:59.070
And make a range of
angles become alpha zero,

00:32:59.100 --> 00:33:00.640
so transparent.

00:33:00.830 --> 00:33:05.430
So this, if we look at the
resulting cube that we get,

00:33:05.430 --> 00:33:09.710
we have basically a wedge that's
been taken out of the cube where

00:33:10.770 --> 00:33:14.240
everything that's been taken out is
alpha zero and everything that remains

00:33:14.240 --> 00:33:17.040
is alpha one in the original color,
so it just passes through,

00:33:17.040 --> 00:33:20.230
but all the green from the image is gone.

00:33:21.410 --> 00:33:25.370
So in terms of code,
it's relatively straightforward.

00:33:25.540 --> 00:33:27.740
First off,
we're going to allocate some memory.

00:33:27.740 --> 00:33:30.000
We've got some limits in terms of size.

00:33:30.000 --> 00:33:34.310
We're going to do a 64 by
64 by 64 cube in this case.

00:33:34.450 --> 00:33:37.430
And then we're going to populate
the cube by computing the red,

00:33:37.720 --> 00:33:38.660
green, blue values.

00:33:38.660 --> 00:33:46.760
So basically a simple gradient going
from zero to one in float values.

00:33:46.990 --> 00:33:53.330
Now, once we have our RGB value
for a given point,

00:33:53.330 --> 00:33:56.560
we're going to convert that to HSV.

00:33:56.820 --> 00:34:02.340
And then we're going to use the U value,
so the first component of the HSV,

00:34:02.410 --> 00:34:07.130
to determine whether or not that
RGB value is within the range of colors

00:34:07.140 --> 00:34:08.860
that we want to make transparent.

00:34:08.960 --> 00:34:10.700
And if it is,
we're going to set alpha to zero,

00:34:10.700 --> 00:34:13.340
and if it isn't,
we're going to set alpha to one.

00:34:13.430 --> 00:34:17.800
And then we populate the actual
RGB values by multiplying by alpha,

00:34:17.800 --> 00:34:22.680
because what you put in a color
cube is pre-multiplied alpha values.

00:34:23.990 --> 00:34:26.620
Once we have that,
we create some NSData with the

00:34:26.620 --> 00:34:28.940
memory that we just allocated.

00:34:28.940 --> 00:34:32.650
We create a CI color cube filter.

00:34:32.760 --> 00:34:35.540
We then tell the color cube
filter how large it is,

00:34:35.540 --> 00:34:40.600
in this case 64,
which is the dimension of our cube.

00:34:41.080 --> 00:34:47.600
And we set the NSData as the
input data for our color cube.

00:34:47.650 --> 00:34:51.520
Now, in terms of visually how this works,
if we were to create a

00:34:51.520 --> 00:34:54.380
CI color cube filter,
we've got our input image and we've

00:34:54.380 --> 00:34:58.100
got our color cube that we've created
which has all the green transparent,

00:34:58.100 --> 00:35:02.920
we apply that to our input
image and we'll get an image of,

00:35:03.040 --> 00:35:05.830
you know, someone standing in front
of a green background but

00:35:05.830 --> 00:35:07.360
with the green transparent.

00:35:07.360 --> 00:35:09.110
In this case,
we're going to be using gray

00:35:09.110 --> 00:35:12.990
and white checkered background
to indicate transparency.

00:35:13.910 --> 00:35:16.600
So now that we've got
our transparent image,

00:35:16.600 --> 00:35:20.720
we can take that image and use the
CI source over compositing filter,

00:35:20.870 --> 00:35:24.130
set that as the input image,
set another image as

00:35:24.130 --> 00:35:27.530
the background image,
and the result is the composited

00:35:27.530 --> 00:35:29.680
image that we were looking for.

00:35:29.930 --> 00:35:35.550
So it's really that easy to create a
brand new effect with built-in filters.

00:35:36.470 --> 00:35:38.370
Another example of how
you can use a color cube,

00:35:38.370 --> 00:35:41.220
and we'll be talking more about color
cubes in our second session today,

00:35:41.340 --> 00:35:43.860
is to do what we call the,
what's often referred to

00:35:43.860 --> 00:35:46.270
as the color accent mode,
which is common in digital

00:35:46.810 --> 00:35:48.540
cameras these days,
where you just want to

00:35:48.560 --> 00:35:49.300
highlight one color.

00:35:49.300 --> 00:35:53.540
So once again, if you were to look at the
colors in HSV and say you

00:35:53.540 --> 00:35:58.420
wanted to preserve only the red,
you could take the cone and say, well,

00:35:58.420 --> 00:36:02.260
I'm going to make everything
except for red be luminous,

00:36:02.260 --> 00:36:04.980
so gray, and just preserve the red.

00:36:04.980 --> 00:36:07.440
And if you do that,
and you create a color

00:36:07.440 --> 00:36:10.580
cube that looks like this,
your resulting image will

00:36:10.580 --> 00:36:12.540
be all gray except for red.

00:36:12.600 --> 00:36:15.270
So it's quite simple,
and it allows you to do a

00:36:15.330 --> 00:36:17.260
lot of interesting effects.

00:36:20.020 --> 00:36:22.880
So our next sample,
we're going to show how you can

00:36:22.880 --> 00:36:24.140
do a white vignetting effect.

00:36:24.140 --> 00:36:28.350
So on iOS, we have a vignetting effect,
but it does the opposite of

00:36:28.410 --> 00:36:29.580
what we're trying to do here.

00:36:29.580 --> 00:36:32.190
So how would you go about
creating a white vignette?

00:36:32.260 --> 00:36:35.020
We have a vignetting effect that darkens.

00:36:35.020 --> 00:36:38.020
We don't have a vignetting effect
that kind of creates a halo.

00:36:38.020 --> 00:36:40.610
So if we wanted to go from
this image to that image,

00:36:40.610 --> 00:36:41.860
how would we do that?

00:36:42.100 --> 00:36:44.370
Well, we can do this using
built-in filters once again.

00:36:44.380 --> 00:36:48.120
We're going to start by
finding the face in the image.

00:36:48.120 --> 00:36:49.180
Faces.

00:36:49.240 --> 00:36:53.260
We're going to create a base shading
map using a CI radial gradient centered

00:36:53.260 --> 00:36:54.860
on that face that we've just found.

00:36:54.860 --> 00:36:58.860
And then we're going to blend that
image with our original input image.

00:36:58.860 --> 00:37:00.380
And that's really all there is to it.

00:37:00.530 --> 00:37:02.740
So let's look at that in terms of code.

00:37:02.860 --> 00:37:06.000
We're going to use a new API that
we haven't talked about so

00:37:06.000 --> 00:37:07.660
far today called CI detector.

00:37:07.880 --> 00:37:09.680
So we're going to create a
CI detector and we're going to tell

00:37:09.680 --> 00:37:14.230
it that we're looking for faces.

00:37:15.340 --> 00:37:18.760
Then we're going to ask the detector
to find the features in the image,

00:37:18.810 --> 00:37:21.740
our input image,
which will look for the faces,

00:37:21.740 --> 00:37:23.560
and it's going to return to us an array.

00:37:23.660 --> 00:37:26.940
In this case, we'll just look for the
first face in the image,

00:37:27.080 --> 00:37:30.190
so we'll get the CI feature face.

00:37:30.310 --> 00:37:33.240
We're going to compute the center.

00:37:33.600 --> 00:37:38.940
of the rect that's returned and
create a vector which we'll then

00:37:38.940 --> 00:37:41.600
use to create our radial gradient.

00:37:41.720 --> 00:37:44.300
So in terms of how that
looks like visually,

00:37:44.300 --> 00:37:46.920
we've got our CR radial gradient filter.

00:37:47.210 --> 00:37:50.630
We're going to set the input radius to
be something relatively large compared

00:37:50.720 --> 00:37:52.700
to the overall size of the image.

00:37:52.780 --> 00:37:56.840
The input radius one to something
slightly larger than the radius

00:37:57.290 --> 00:38:00.210
of the face that we just found.

00:38:00.410 --> 00:38:04.210
input color zero is
going to be opaque white.

00:38:04.520 --> 00:38:06.760
So as we go out towards
the edge of the image,

00:38:06.760 --> 00:38:09.070
it's going to be completely white.

00:38:09.190 --> 00:38:12.520
And input color 1 is going
to be transparent white.

00:38:12.660 --> 00:38:15.520
And basically we're going to
transition in between those two

00:38:15.520 --> 00:38:18.920
values from the radius 0 to 1.

00:38:19.020 --> 00:38:22.350
And the input center is the
face rec that we found earlier.

00:38:22.620 --> 00:38:24.000
When we create that,
what we end up with is an

00:38:24.000 --> 00:38:24.960
image that looks like this.

00:38:24.960 --> 00:38:28.890
And again, the checkerboard pattern
indicates transparency.

00:38:29.660 --> 00:38:33.570
The radial gradient which is
centered on the face that we found

00:38:33.620 --> 00:38:40.890
and completely transparent around
that radius of 150 and completely

00:38:40.970 --> 00:38:43.610
opaque around the larger radius.

00:38:44.180 --> 00:38:50.150
Now all we have to do is take
that image and blend it with

00:38:50.210 --> 00:38:54.780
our original background using a
CI source over compositing filter.

00:38:55.200 --> 00:38:57.300
and we get the result
that we were looking for.

00:38:57.410 --> 00:39:01.990
Our next example is going to show
how we can do the tilt shift effect,

00:39:02.170 --> 00:39:04.470
which is something that we
showed how to do several years

00:39:04.480 --> 00:39:07.000
ago using custom kernels.

00:39:07.120 --> 00:39:09.300
And today we're going to show you
how you can do the exact same thing

00:39:09.790 --> 00:39:12.280
just by using built-in filters.

00:39:13.720 --> 00:39:15.080
So how are we going to do this?

00:39:15.300 --> 00:39:16.480
Well,
we're going to start off by creating

00:39:16.480 --> 00:39:18.840
a blurred version of the image.

00:39:18.960 --> 00:39:23.510
And then we're going to create two
linear gradients and blend them together.

00:39:24.020 --> 00:39:28.140
And we're going to composite the
results using blend with mask and

00:39:28.140 --> 00:39:30.200
it's going to help us determine
where we want the image to be blurred

00:39:30.200 --> 00:39:32.340
and where we want it to be sharp.

00:39:33.540 --> 00:39:37.750
So we're going to start
with CI Gaussian Blur,

00:39:37.770 --> 00:39:39.340
which is a new filter for iOS 6.

00:39:39.360 --> 00:39:42.000
And as David was mentioning earlier,
a lot of people have asked us for it.

00:39:42.000 --> 00:39:44.820
And it is very useful for creating
a lot of interesting effects,

00:39:44.820 --> 00:39:45.920
including the tilt-shift effect.

00:39:46.050 --> 00:39:49.070
So in this case,
we're going to take our input image.

00:39:49.730 --> 00:39:51.450
And we're going to blur
it by a certain amount.

00:39:51.560 --> 00:39:53.460
It shouldn't say input
background image there.

00:39:53.600 --> 00:39:56.700
It should say radius.

00:39:56.700 --> 00:39:58.260
And we're going to end
up with a blurred image.

00:40:00.200 --> 00:40:04.060
The blurred image is going to be
larger than our original image

00:40:04.060 --> 00:40:07.040
because the extents get larger,
so we're going to crop it a little bit

00:40:07.160 --> 00:40:10.590
to match the size of our input image.

00:40:12.530 --> 00:40:14.970
The next thing we're going to do is
we're going to create the two linear

00:40:14.970 --> 00:40:16.560
gradients that I spoke about earlier.

00:40:16.720 --> 00:40:19.950
So first things first,
we'll create one that goes

00:40:20.130 --> 00:40:21.840
from the top to the bottom.

00:40:21.850 --> 00:40:24.680
I'm just going to go through
all these little inputs.

00:40:25.770 --> 00:40:30.790
And what we end up here with is a green
image that's completely green and opaque

00:40:31.460 --> 00:40:35.180
from the top of the image till we get
to one quarter of the way through it.

00:40:35.320 --> 00:40:40.160
And then once we're at that spot,
we get to -- until we get to

00:40:40.160 --> 00:40:43.040
halfway through the image,
so 0.5 of the height,

00:40:43.190 --> 00:40:45.400
it becomes more and more transparent.

00:40:45.530 --> 00:40:47.200
And then completely
transparent after that.

00:40:47.320 --> 00:40:49.800
So that gives us a solid,
slightly transparent,

00:40:49.800 --> 00:40:53.100
completely transparent gradient.

00:40:53.240 --> 00:40:56.830
And we're going to do the same thing,
but starting from the bottom up.

00:40:58.130 --> 00:41:00.000
And we're going to use
the same color values.

00:41:00.000 --> 00:41:03.680
And I'll talk about why
we use green in a moment.

00:41:03.680 --> 00:41:04.940
So now we've got our two gradients.

00:41:04.940 --> 00:41:10.400
We're going to combine those
two together using a CI edition

00:41:10.470 --> 00:41:13.160
compositing filter that just sets

00:41:14.360 --> 00:41:19.570
We use these two images as the inputs
and we end up with our nice linear

00:41:19.570 --> 00:41:22.760
gradient which goes from solid green,
transparent,

00:41:22.800 --> 00:41:24.400
and then back to solid green.

00:41:24.470 --> 00:41:26.690
Once we have that,
we can use the CI blend with masks.

00:41:26.780 --> 00:41:29.400
So we've got our three input images.

00:41:30.210 --> 00:41:34.900
We're going to use the blurred
image as the input image.

00:41:34.900 --> 00:41:36.860
And then we're also going
to use the background image,

00:41:36.860 --> 00:41:39.690
the one that we haven't blurred,
our original input image,

00:41:39.690 --> 00:41:41.340
set that as the background image.

00:41:41.340 --> 00:41:44.590
And the mask image is going to
be the green image that we just

00:41:44.870 --> 00:41:46.600
created with the two blends.

00:41:46.600 --> 00:41:49.630
And the way this works is
CI Blend with Masks looks at the

00:41:49.630 --> 00:41:54.470
green channel to determine from
which image it should be sampling.

00:41:54.490 --> 00:41:57.630
So where it's completely
opaque and green,

00:41:57.650 --> 00:41:59.630
it's going to sample
from the blurred image.

00:41:59.780 --> 00:42:03.260
And where it's completely transparent,
it's going to sample from

00:42:03.300 --> 00:42:05.460
the background image.

00:42:05.460 --> 00:42:10.530
And it's going to transition in
between those based on the alpha.

00:42:10.530 --> 00:42:10.540
So...

00:42:10.760 --> 00:42:13.200
With that, we get the result that
we were looking for.

00:42:13.260 --> 00:42:16.700
And so it's that easy to
combine these filters together

00:42:16.700 --> 00:42:19.400
to get your tilt shift looked.

00:42:21.370 --> 00:42:24.670
Okay,
so now let's pretend for some reason

00:42:24.750 --> 00:42:28.240
you had to relocate your family due
to some witness relocation program

00:42:28.240 --> 00:42:30.630
or something along those lines,
and you wanted to quickly

00:42:30.630 --> 00:42:32.350
anonymize all your family photos.

00:42:32.350 --> 00:42:37.040
We can do that with
Core Image with relative ease.

00:42:37.590 --> 00:42:39.660
And I'm going to show you how to do that.

00:42:39.740 --> 00:42:41.030
So first things first,
we're going to create a

00:42:41.130 --> 00:42:43.520
pixelated version of the image.

00:42:43.620 --> 00:42:45.900
We're going to build a mask
using the face detector to find

00:42:45.900 --> 00:42:47.540
all the faces in the image.

00:42:47.650 --> 00:42:50.600
And then for each of those faces,
we're going to create another

00:42:50.600 --> 00:42:54.900
radial gradient like we did
earlier for the shading.

00:42:55.250 --> 00:42:58.860
And we're going to create a mask by
building one on top of the other.

00:42:58.940 --> 00:43:02.690
And then we're going to blend the
pixelated image with the original image

00:43:02.770 --> 00:43:05.200
using the mask that we've created,
which corresponds to the

00:43:05.200 --> 00:43:06.450
circles for the faces.

00:43:06.600 --> 00:43:08.450
Let's go over that process in depth.

00:43:08.630 --> 00:43:11.460
So first things first,
we're going to create a pixelated

00:43:11.460 --> 00:43:13.900
image by using a CI pixelate filter.

00:43:14.010 --> 00:43:17.210
Set the input image,
set the scale to something

00:43:17.360 --> 00:43:21.380
that we find pleasing,
and we end up with a pixelated image.

00:43:21.480 --> 00:43:24.080
The next thing we need to do is
find the faces and create the mask.

00:43:24.330 --> 00:43:26.610
So conceptually the way this
works is that once again

00:43:26.610 --> 00:43:30.100
we use a CI detector class,
and we ask that detector to find all

00:43:30.100 --> 00:43:32.650
the features of typeface in this image.

00:43:32.910 --> 00:43:35.010
In this case we're going
to find four images,

00:43:35.020 --> 00:43:37.620
and we're going to get rects that
are going to be returned to us.

00:43:37.670 --> 00:43:41.380
And for each one of those rects,
what we're going to do is create a

00:43:41.380 --> 00:43:44.160
circle that covers that rect completely.

00:43:44.440 --> 00:43:45.440
That is going to be our mask.

00:43:45.610 --> 00:43:49.460
That's going to tell us where we
want to use the pixelated image.

00:43:49.530 --> 00:43:52.110
And again, that's why we use green,
because we're going to be using

00:43:52.110 --> 00:43:55.570
a CI blend with mask filter,
which uses the green color component

00:43:55.570 --> 00:43:57.860
to determine where to sample from.

00:43:57.860 --> 00:44:00.950
So our mask is going to look like this.

00:44:01.820 --> 00:44:05.410
Now in terms of code,
and I think this is my last code slide,

00:44:05.410 --> 00:44:09.280
what this looks like is we've got
our mask image initially set to nil.

00:44:09.310 --> 00:44:11.760
And then we're going to
iterate over all the faces.

00:44:11.830 --> 00:44:14.080
We're going to find the center.

00:44:14.690 --> 00:44:18.580
for each face, computer radius for it.

00:44:18.580 --> 00:44:19.940
And then we're going to
create a radial gradient.

00:44:19.940 --> 00:44:23.060
We're using the shortcuts that
David showed us earlier to create

00:44:23.060 --> 00:44:26.820
a circle that is completely opaque
green in the center and then

00:44:26.820 --> 00:44:30.870
completely transparent outside
of where the face is located.

00:44:32.640 --> 00:44:36.170
Once we've created that filter,
we can ask for the CI image from it,

00:44:36.370 --> 00:44:38.100
so its output image.

00:44:38.230 --> 00:44:42.460
And then if this is the first image,
the first face that we found,

00:44:42.630 --> 00:44:45.320
our mask image is that image.

00:44:45.470 --> 00:44:49.280
If it isn't,
what we're going to do is composite

00:44:49.650 --> 00:44:53.960
the current circle image that
we've just created with the

00:44:54.060 --> 00:44:56.220
previous result that we got.

00:44:56.320 --> 00:44:57.860
And we just keep doing
that for all the faces.

00:44:57.860 --> 00:45:00.700
So we just keep compositing.

00:45:00.840 --> 00:45:03.080
And we end up with the mask
that we saw previously.

00:45:05.210 --> 00:45:08.460
So finally,
what we need to do is just use

00:45:08.460 --> 00:45:10.980
the CI Blend with Mask filter.

00:45:11.510 --> 00:45:12.660
And we're going to use our input image.

00:45:12.660 --> 00:45:16.280
We're going to set it to be the
pixelated image that we created earlier.

00:45:16.400 --> 00:45:21.050
Our mask image is what we just
created with that for loop

00:45:21.500 --> 00:45:23.390
iterating over all the faces.

00:45:23.590 --> 00:45:25.730
The background image.

00:45:25.920 --> 00:45:28.560
This is our original input image,
and when we do that,

00:45:28.720 --> 00:45:30.680
we get the desired result.

00:45:30.680 --> 00:45:33.550
Now, let's pretend you wanted
to create a transition,

00:45:33.770 --> 00:45:36.840
but what exists inside of
Core Image doesn't suit your needs.

00:45:36.880 --> 00:45:40.650
So you wanted to go from the image
on the left here to the image on

00:45:40.650 --> 00:45:43.300
the right of my boss's family.

00:45:43.300 --> 00:45:45.280
How would you go about creating
an interesting transition that

00:45:45.290 --> 00:45:48.340
looked like an arcade-style
effect where it's pixelated and

00:45:48.340 --> 00:45:50.680
dissolving all at the same time?

00:45:50.680 --> 00:45:56.710
We can do that by combining just
a few existing built-in filters.

00:45:58.300 --> 00:46:01.610
So, we're going to use a CI Dissolve
transition to blend between

00:46:01.640 --> 00:46:05.750
those images and then we're going
to pixelate the result of that

00:46:05.700 --> 00:46:16.500
[Transcript missing]

00:46:17.010 --> 00:46:19.130
Set our input image to the start image.

00:46:19.250 --> 00:46:22.330
Set our target image to the
image we want to end up at.

00:46:22.650 --> 00:46:25.010
Use some function for time
that's going to look like this.

00:46:25.020 --> 00:46:29.150
It's just a simple ramp
that's been clamped.

00:46:29.280 --> 00:46:32.570
And we get our dissolve transition.

00:46:33.390 --> 00:46:36.600
So that's the first part of the equation.

00:46:36.720 --> 00:46:40.100
The next thing we're going to do is
take the output that we've just gotten.

00:46:40.100 --> 00:46:42.600
So we've got our dissolve transition.

00:46:42.650 --> 00:46:44.560
We're going to use the
CI Pixelate filter,

00:46:44.620 --> 00:46:47.890
and we're going to change
the scale of the Pixelate

00:46:48.050 --> 00:46:49.580
Based on time.

00:46:49.580 --> 00:46:53.160
So we're going to vary that over time
from zero to one the same way we did

00:46:54.500 --> 00:46:56.960
with the transition filter.

00:46:57.130 --> 00:46:58.940
And in this case,
we're going to make the pixels go really,

00:46:58.940 --> 00:47:01.570
really big, and then we're going to
make them go back down.

00:47:01.580 --> 00:47:06.530
So we'll get this kind of big pixel
to small pixel effect that we had.

00:47:06.880 --> 00:47:08.960
And we do that,
combine everything together,

00:47:08.960 --> 00:47:09.800
we get the result we wanted.

00:47:09.800 --> 00:47:13.560
And that went by a little bit too quick,
but anyhow.

00:47:13.600 --> 00:47:16.140
Next thing we're going to
do is we're going to take

00:47:16.570 --> 00:47:20.500
A video and make it look
like it was old film.

00:47:20.500 --> 00:47:22.480
And we're going to do that by
-- this is the most complicated

00:47:22.510 --> 00:47:26.120
sample I have -- combining several
different filters and using a lot

00:47:26.260 --> 00:47:28.650
of different techniques together.

00:47:29.010 --> 00:47:32.750
And it's going to give us this kind of
old film look where we have speckles,

00:47:32.850 --> 00:47:39.160
white speckles and kind of dark streaks
and the sepia tone look to the video

00:47:39.160 --> 00:47:42.270
that's being processed by Core Image.

00:47:43.870 --> 00:47:44.740
So how are we going to do this?

00:47:44.800 --> 00:47:47.400
So first things first,
we're going to apply the sepia

00:47:47.680 --> 00:47:50.350
filter to our input source.

00:47:50.470 --> 00:47:53.200
We're going to create white specs.

00:47:53.300 --> 00:47:54.840
We're going to create dark scratches.

00:47:54.910 --> 00:47:57.620
And then we're going to
composite everything together.

00:47:59.670 --> 00:48:03.600
So first things first,
we use the CI sepia tone filter,

00:48:03.730 --> 00:48:06.880
set the input image,
in this case it could be video,

00:48:06.920 --> 00:48:10.980
set the intensity to one
to get the maximum effect,

00:48:10.980 --> 00:48:14.190
and we get our sepia toned image.

00:48:16.510 --> 00:48:18.730
The next thing we're going to do is
we're going to create the white specs,

00:48:18.730 --> 00:48:21.560
which are going to kind of
give it that noisy look to it.

00:48:21.770 --> 00:48:23.740
And in this case,
we're going to use a filter that

00:48:23.740 --> 00:48:27.450
we haven't used so far today
called the CI Random Generator,

00:48:27.550 --> 00:48:29.840
which, as David mentioned,
is a generator,

00:48:29.840 --> 00:48:34.330
so it doesn't have any input image,
but it generates an output.

00:48:34.440 --> 00:48:38.190
And in this case, it generates a very
colorful noise pattern.

00:48:38.290 --> 00:48:39.260
But we want white specs.

00:48:39.390 --> 00:48:41.100
We don't want colorful noise.

00:48:41.210 --> 00:48:45.900
So what we're going to do instead is
we're going to apply Color Matrix to it.

00:48:46.170 --> 00:48:50.760
And the result of this color matrix
is going to give us a very faint,

00:48:51.390 --> 00:48:55.880
like dark image,
mostly transparent with white specs.

00:48:58.460 --> 00:49:00.440
Which looks like this.

00:49:00.440 --> 00:49:05.900
And if we were to take the output from
the CI random generator and use an

00:49:05.900 --> 00:49:11.030
affine transform to move it over time,
we'll end up with something

00:49:11.030 --> 00:49:13.090
that looks like this.

00:49:13.220 --> 00:49:18.170
So that's starting to look like
what we want for the first --

00:49:18.580 --> 00:49:20.790
Addition to the video that we want.

00:49:20.790 --> 00:49:25.020
If we take that and we blend
it over our source image,

00:49:25.620 --> 00:49:28.140
Using the
CI Source Over Compositing filter,

00:49:28.430 --> 00:49:30.400
we set that as the input image.

00:49:30.520 --> 00:49:32.090
And again, it's mostly transparent.

00:49:32.180 --> 00:49:36.930
We used it as the background image,
our sepia tone image.

00:49:37.030 --> 00:49:39.460
We're going to start getting the
result that we're looking for.

00:49:39.540 --> 00:49:40.530
So now we've got our image.

00:49:40.530 --> 00:49:44.120
It's got the white specs applied to it.

00:49:44.980 --> 00:49:47.090
and the sepia.

00:49:47.280 --> 00:49:51.600
The next thing we need to do
is to add the dark scratches.

00:49:51.610 --> 00:49:53.930
So in order to do this,
we're going to once again

00:49:53.990 --> 00:49:56.290
use CI random generator.

00:49:56.640 --> 00:49:59.280
But as I mentioned earlier,
it creates very colorful noise.

00:49:59.390 --> 00:50:03.630
And contrary to the other filter
where we were looking for mostly black

00:50:03.810 --> 00:50:05.620
transparent and just white specs,
in this case,

00:50:05.710 --> 00:50:11.880
we're going to want to create a mostly
white image with just a few dark streaks.

00:50:12.050 --> 00:50:15.950
So what we're going to do,
first things first,

00:50:16.450 --> 00:50:18.440
is we're going to apply
an affine transform to it.

00:50:18.480 --> 00:50:21.440
And you can do this by calling CI image,
image by applying transform

00:50:21.440 --> 00:50:25.110
and providing a CG transform,
or by creating a CI affine

00:50:25.190 --> 00:50:26.700
transform filter.

00:50:26.770 --> 00:50:30.100
So in this case, we're going to apply a
filter that scales this,

00:50:30.120 --> 00:50:35.080
the result of the CI random generator
in both the X and Y directions.

00:50:35.320 --> 00:50:40.980
And what it's going to give us is
thick pixels and very long pixels.

00:50:41.160 --> 00:50:45.190
So we've elongated it by using
a scale in the Y direction of 25

00:50:45.190 --> 00:50:48.090
and in the X direction of 1.5.

00:50:49.270 --> 00:50:51.090
But it's still very colorful.

00:50:51.230 --> 00:50:55.810
So the next thing we're going to
do is apply color matrix to it.

00:50:55.980 --> 00:50:57.140
And in this case,
what we're going to do is we're

00:50:57.140 --> 00:50:59.690
going to blow out the values

00:50:59.930 --> 00:51:05.960
By applying a scale and a bias
vector that's going to make

00:51:05.960 --> 00:51:08.500
most of the image disappear,
basically.

00:51:08.500 --> 00:51:13.900
So now we've got an image that just has
what looks like some cyan highlights here

00:51:14.030 --> 00:51:17.240
and long and streaky cyan highlights.

00:51:18.610 --> 00:51:21.160
And then we're going to use a
CI minimum component filter.

00:51:21.210 --> 00:51:26.200
And this is really the last piece of
the recipe where what the CI minimum

00:51:26.200 --> 00:51:30.790
component filter does is it looks for
the minimum of the RGB values and it

00:51:30.790 --> 00:51:33.920
uses that to create a grayscale image.

00:51:34.350 --> 00:51:38.040
And if we do that,
we end up with our image with

00:51:38.650 --> 00:51:41.940
these black streaks in it,
or dark scratches.

00:51:41.940 --> 00:51:45.450
And again,
if we were to take the initial output

00:51:45.450 --> 00:51:50.930
from the random generator and if we
were to apply a transform such that we

00:51:50.930 --> 00:51:55.340
animate over time in the Y direction,
then these streaks will look

00:51:55.420 --> 00:51:59.510
like they're moving up and down,
or actually just down.

00:51:59.930 --> 00:52:06.200
And we're good to go in terms of taking
that and compositing it with our already

00:52:06.200 --> 00:52:12.790
white specs on top of the CPI image
using the CI multiply compositing,

00:52:12.790 --> 00:52:15.030
and we'll get our final result.

00:52:15.900 --> 00:52:20.390
And that's all we had to do to create
this relatively interesting effect.

00:52:20.410 --> 00:52:25.000
So that's all we have today so
far in terms of filter recipes.

00:52:25.060 --> 00:52:28.870
If you'd like additional information,
you can contact Alan Schaefer,

00:52:28.880 --> 00:52:31.340
who's our graphics and
imaging evangelist,

00:52:31.340 --> 00:52:33.280
at aschaefer@apple.com.

00:52:33.530 --> 00:52:37.280
Or you can go to the website,
devforums.apple.com.

00:52:37.350 --> 00:52:39.860
We also have another talk
immediately following this talk,

00:52:39.950 --> 00:52:42.050
which is going to go more in-depth
into some advanced techniques

00:52:42.050 --> 00:52:44.190
using Core Image and how you
can get the maximum performance

00:52:44.200 --> 00:52:45.780
out of your application.

00:52:45.910 --> 00:52:46.960
And that's all I have for today.

00:52:46.960 --> 00:52:48.240
So I'd like to thank you
once again for coming.

00:52:48.240 --> 00:52:50.960
And good luck with using Core Image.

00:52:50.960 --> 00:52:51.580
Thank you very much.