WEBVTT

00:00:10.060 --> 00:00:12.350
Hello, my name is Josh Graessley and
I'm going to be going over

00:00:12.350 --> 00:00:16.440
networking best practices today.

00:00:16.440 --> 00:00:18.400
Networking is a little bit different
from a lot of other things on the

00:00:18.500 --> 00:00:21.480
system where you're interacting
with an environment that you don't

00:00:21.480 --> 00:00:23.910
necessarily have a lot of control over.

00:00:23.980 --> 00:00:27.400
And it can be a real challenge
to know what you can modify to

00:00:27.420 --> 00:00:31.820
improve the situation and what
you just have to simply live with.

00:00:31.880 --> 00:00:34.230
You can't control the networks
that your users are going

00:00:34.230 --> 00:00:36.900
to use your applications on,
but you can control how well your

00:00:36.900 --> 00:00:38.800
applications perform on those networks.

00:00:38.800 --> 00:00:41.640
We're going to go into detail about
how networking actually works so

00:00:41.650 --> 00:00:44.660
that you'll have a better idea
about what you have control over and

00:00:44.700 --> 00:00:46.790
what you don't have control over.

00:00:48.850 --> 00:00:50.020
Networking can be really tricky.

00:00:50.170 --> 00:00:51.860
When we deal with a network
at the lowest layers,

00:00:51.960 --> 00:00:54.330
we have nothing but packets,
and packets can be reordered,

00:00:54.360 --> 00:00:57.640
packets can become corrupt,
packets can get dropped completely.

00:00:57.730 --> 00:00:59.810
Dealing with that complexity
can be a real challenge.

00:01:00.030 --> 00:01:04.590
Fortunately,
the system and the network in general

00:01:04.640 --> 00:01:10.940
provide a lot of abstractions that
hide a lot of that complexity from

00:01:10.940 --> 00:01:12.310
your application and give you a chance
to actually get something accomplished.

00:01:12.680 --> 00:01:16.040
The only downside to these abstractions
is that they tend to hide the true cost.

00:01:16.230 --> 00:01:18.410
There are some things that
end up leaking through,

00:01:18.470 --> 00:01:24.180
and if you don't understand how
these things work under the covers,

00:01:24.180 --> 00:01:24.180
then you can run into certain pitfalls.

00:01:24.360 --> 00:01:27.000
We're going to be going over the best
practices to avoid those pitfalls.

00:01:27.050 --> 00:01:30.950
We'll also talk about the best layer
that you can take advantage of.

00:01:32.260 --> 00:01:33.920
First we're going to
cover network performance.

00:01:33.990 --> 00:01:37.520
Network performance is something that
people usually run into trouble with.

00:01:37.540 --> 00:01:39.700
We're going to go into
details about how TCP works,

00:01:39.720 --> 00:01:42.260
and we'll also cover HTTP,
and we'll cover a lot of the APIs that

00:01:42.260 --> 00:01:46.070
are available on the system to
take advantage of these protocols.

00:01:46.110 --> 00:01:49.970
We're going to finish off with some
mobility and cost issues and also

00:01:49.970 --> 00:01:53.190
cover some debugging tips and tricks.

00:01:54.120 --> 00:01:56.880
First, network performance.

00:01:56.880 --> 00:01:59.370
There are two metrics to
a network's performance:

00:01:59.380 --> 00:02:00.300
bandwidth and latency.

00:02:00.490 --> 00:02:02.230
Bandwidth is something that
you read about all the time.

00:02:02.310 --> 00:02:06.000
All the ISPs advertise how many bits
per second you can send or receive.

00:02:06.100 --> 00:02:10.380
Everyone has a pretty good
idea about what bandwidth is.

00:02:10.770 --> 00:02:12.560
In this diagram,
we have an iPhone on one side,

00:02:12.560 --> 00:02:15.050
and we have a server that we're
talking to on the other side.

00:02:15.180 --> 00:02:17.500
We actually have to transit
a bunch of different links in

00:02:17.500 --> 00:02:18.860
order to get to that server.

00:02:18.980 --> 00:02:20.900
Our bandwidth is going to be
limited by what we're going

00:02:20.900 --> 00:02:22.100
to call the bottleneck link.

00:02:22.210 --> 00:02:25.970
In this particular case,
the DSL line is the one

00:02:25.970 --> 00:02:30.640
with the lowest bandwidth,
so that's our bottleneck.

00:02:30.640 --> 00:02:33.800
That's basically dictating the
maximum amount of bandwidth

00:02:33.800 --> 00:02:33.800
that we have available to
communicate with that server.

00:02:34.520 --> 00:02:36.150
Because it's not the
first link in the hop,

00:02:36.210 --> 00:02:39.320
we can't necessarily find out
how much bandwidth is available.

00:02:39.490 --> 00:02:41.370
There's also an issue that
we might be sharing that link

00:02:41.460 --> 00:02:44.050
with a bunch of other devices,
so we can't make assumptions about

00:02:44.100 --> 00:02:47.200
whether or not that bandwidth is
going to stay the same the whole time.

00:02:47.350 --> 00:02:54.620
The only way to know how much bandwidth
is available is to put some load on the

00:02:54.620 --> 00:02:54.620
network and then actually measure it
and see how much bandwidth we got back.

00:02:55.580 --> 00:02:57.700
When we're putting load on the network,
it's really important to make

00:02:57.710 --> 00:03:00.410
sure that we use that load
for something productive.

00:03:00.520 --> 00:03:04.040
We don't want to just download a whole
bunch of bytes that we throw away because

00:03:04.040 --> 00:03:07.450
it's going to cost us power and it may
end up costing the user some money.

00:03:07.780 --> 00:03:10.500
It's also really important to remember
that bandwidth may fluctuate over time,

00:03:10.500 --> 00:03:13.160
so we don't want to perform a test
and then make some assumptions

00:03:13.160 --> 00:03:15.940
that our bandwidth is going to
be the same all the way through.

00:03:16.060 --> 00:03:18.640
Netflix is actually a really good
example of an application that

00:03:18.640 --> 00:03:20.660
handles changes in bandwidth well.

00:03:20.660 --> 00:03:24.690
Netflix uses HTTP live streaming,
which has a bunch of different

00:03:24.690 --> 00:03:27.300
reference movies at different bit rates.

00:03:27.420 --> 00:03:29.610
When Netflix starts,
it picks a fairly conservative

00:03:29.610 --> 00:03:32.460
bit rate video to download,
and then if it's playing back

00:03:32.570 --> 00:03:34.860
slower than it's downloading,
it'll actually switch to a higher

00:03:34.860 --> 00:03:37.660
bit rate video to take advantage
of the additional bandwidth.

00:03:37.660 --> 00:03:41.000
If it's actually downloading
slower than it's playing back,

00:03:41.000 --> 00:03:44.260
it has to switch to a lower bit rate,
lower quality video.

00:03:44.450 --> 00:03:49.020
Netflix continues to do this over
time and it adapts very well.

00:03:49.020 --> 00:03:50.880
Compression is about the only
trick that you have to work

00:03:50.900 --> 00:03:52.330
around limited bandwidth.

00:03:52.410 --> 00:03:54.580
Other than that,
you're just going to end up having

00:03:54.580 --> 00:03:56.100
to wait for things to come down.

00:03:56.100 --> 00:03:58.230
In my mind,
the more interesting measure of a

00:03:58.310 --> 00:04:00.230
network's performance is the latency.

00:04:00.230 --> 00:04:02.970
The latency is the round trip
time between your device and

00:04:02.970 --> 00:04:04.520
the server you're talking to.

00:04:04.760 --> 00:04:08.080
This includes the time it takes to
transit all the links to the server

00:04:08.080 --> 00:04:09.800
and to transit all the way back.

00:04:09.950 --> 00:04:11.690
This is usually measured in milliseconds.

00:04:11.820 --> 00:04:15.050
The round trip time includes the
amount of time that the packets

00:04:15.120 --> 00:04:18.340
have to spend in queues as well
as the time spent on links.

00:04:18.420 --> 00:04:21.830
As the network congestion tends to go up,
the queues will be a little bit more full

00:04:21.870 --> 00:04:24.800
and your packets will end up spending
more time stuck in those queues before

00:04:24.800 --> 00:04:26.240
they get to go across the network.

00:04:26.340 --> 00:04:28.480
As the load and congestion
on the network goes up,

00:04:28.560 --> 00:04:30.310
the round trip times are going to go up.

00:04:30.560 --> 00:04:32.620
Latency is one place
where your application,

00:04:32.660 --> 00:04:34.640
if it's designed properly,
can do a lot more than

00:04:34.640 --> 00:04:34.640
just a few seconds.

00:04:34.690 --> 00:04:36.350
You can also use the high
latency network to hide a high

00:04:36.350 --> 00:04:36.630
latency network from the user.

00:04:36.640 --> 00:04:38.640
This is one place where you can make
some huge performance improvements.

00:04:38.640 --> 00:04:40.640
So we're going to go
over some techniques.

00:04:40.640 --> 00:04:44.130
The first and most important thing
to do is make sure that all of your

00:04:44.130 --> 00:04:46.640
networking is performed asynchronously.

00:04:46.640 --> 00:04:49.360
It's really important that you provide a
very responsive user interface while you

00:04:49.360 --> 00:04:52.630
have any networking operation going on.

00:04:52.650 --> 00:04:54.640
One trick you can use is placeholders.

00:04:54.640 --> 00:04:57.890
If you're going to show a list of users,
you can show the whole list of users

00:04:57.890 --> 00:05:00.640
with placeholders next to them for
icons that you don't have at the time.

00:05:00.640 --> 00:05:04.040
As the icons come in off the network,
you can fill in the placeholder.

00:05:04.040 --> 00:05:06.040
The user gets the whole
list very quickly,

00:05:06.040 --> 00:05:07.040
and they don't have to wait around.

00:05:07.040 --> 00:05:11.290
Another really important technique
is to use a single connection or the

00:05:11.290 --> 00:05:15.200
fewest possible connections and have
a number of outstanding concurrent

00:05:15.290 --> 00:05:17.040
requests on those connections.

00:05:17.040 --> 00:05:21.030
If you're using HTTP,
there's a technique called pipelining.

00:05:21.040 --> 00:05:23.990
If you can take advantage of pipelining,
this will handle this for you.

00:05:24.050 --> 00:05:27.040
We'll go into this in a
little bit depth later.

00:05:27.040 --> 00:05:30.270
Another thing that's really important
to remember is that the network will

00:05:30.270 --> 00:05:32.040
always add some delay to a request.

00:05:32.110 --> 00:05:33.440
If you know you need some resource,
you can always add some

00:05:33.440 --> 00:05:33.440
delay to a request.

00:05:33.440 --> 00:05:35.780
If you know you need some resource,
you should go ahead and request

00:05:35.780 --> 00:05:37.430
that as soon as you know you need
that as opposed to waiting longer.

00:05:37.440 --> 00:05:39.780
All you'll do is add to the
amount of time that it will

00:05:39.780 --> 00:05:41.400
take to get that resource back.

00:05:41.440 --> 00:05:44.850
Finally, if you're using caching well,
if you can fetch something out

00:05:44.850 --> 00:05:47.850
of the cache instead of having to
go out to the network to get it,

00:05:47.850 --> 00:05:49.440
that comes back much, much quicker.

00:05:49.440 --> 00:05:52.420
There's a kind of interesting interaction
between bandwidth and latency.

00:05:52.460 --> 00:05:57.510
If you were to write a fairly naive
application that would send a packet,

00:05:57.620 --> 00:05:59.440
and then when that packet
gets to the server,

00:05:59.440 --> 00:06:00.440
we get an acknowledgment back.

00:06:00.440 --> 00:06:02.780
When we get that acknowledgment back,
we send another packet.

00:06:02.850 --> 00:06:05.740
If we have a network with a 60
millisecond round trip time,

00:06:05.840 --> 00:06:09.840
we can send about 16 of
these round trips per second.

00:06:09.840 --> 00:06:13.200
If a packet has about 1500 bytes in it,
that works out to about

00:06:13.200 --> 00:06:14.840
200 kilobits a second.

00:06:14.840 --> 00:06:16.840
Most people have much faster networks.

00:06:16.840 --> 00:06:20.240
The only way to take full advantage
of all the throughput on a network

00:06:20.380 --> 00:06:23.800
is to have a lot of outstanding
in-flight data at any given time.

00:06:23.840 --> 00:06:26.680
You can use something called the
bandwidth delay product to calculate

00:06:26.680 --> 00:06:29.380
the amount of information you need
to have in flight in order to take

00:06:29.380 --> 00:06:30.810
full advantage of all the throughput.

00:06:30.900 --> 00:06:32.240
You can do this by
multiplying the throughput.

00:06:32.240 --> 00:06:35.200
In this case, 10 megabits per second
by the round trip time.

00:06:35.320 --> 00:06:37.240
In this case, 60 milliseconds.

00:06:37.240 --> 00:06:40.240
And you get about 60 kilobits that
need to be in flight at any given time.

00:06:40.390 --> 00:06:41.910
Most of the time,
your applications won't know

00:06:41.910 --> 00:06:43.240
how much bandwidth is available.

00:06:43.240 --> 00:06:46.240
So you don't have to worry
about the specific details here.

00:06:46.240 --> 00:06:48.670
The important thing to take
away is that you need to keep

00:06:48.670 --> 00:06:50.170
your socket send buffer full.

00:06:50.270 --> 00:06:53.240
You need to keep data
flowing all the time.

00:06:53.240 --> 00:06:57.150
The system actually resized the socket
send buffer and receive buffer based

00:06:57.160 --> 00:06:59.240
on the current bandwidth and delay.

00:06:59.240 --> 00:07:01.630
And I use the bandwidth
delay product calculation.

00:07:01.640 --> 00:07:03.640
So as a quick summary
of network performance,

00:07:03.640 --> 00:07:06.640
there are two metrics,
bandwidth and latency.

00:07:06.640 --> 00:07:09.610
And bandwidth is limited by
the minimum bottleneck link.

00:07:09.700 --> 00:07:11.820
In the case of latency,
that's affected by all the

00:07:11.910 --> 00:07:13.630
different links you have to cross.

00:07:13.640 --> 00:07:17.610
Hiding latency is where you can
get big wins in your application.

00:07:17.680 --> 00:07:20.640
If you want to take full advantage of
all the throughput that's available,

00:07:20.640 --> 00:07:23.980
you need to be aware of the bandwidth
delay product and make sure that you

00:07:23.980 --> 00:07:26.640
have as much data in flight as possible.

00:07:26.640 --> 00:07:28.910
Now we're going to jump into TCP.

00:07:29.620 --> 00:07:31.990
TCP stands for transmission
control protocol,

00:07:31.990 --> 00:07:34.960
and normally when you're
working with Internet traffic

00:07:34.960 --> 00:07:36.600
you're dealing with packets.

00:07:36.650 --> 00:07:38.560
TCP provides a nice abstraction.

00:07:38.560 --> 00:07:42.000
You get this virtual circuit or a
bidirectional serial byte stream.

00:07:42.100 --> 00:07:44.480
There's no such thing as a connection
on the Internet in general.

00:07:44.640 --> 00:07:46.860
Everything is sent as packets.

00:07:47.190 --> 00:07:50.950
With a TCP connection,
you can shove a whole bunch of bytes into

00:07:50.950 --> 00:07:54.780
the connection and come out in the server
on the other side in the same order.

00:07:54.780 --> 00:07:57.740
If they get lost somewhere,
TCP will take care of retransmitting it.

00:07:57.820 --> 00:07:59.970
If they become corrupt,
TCP will make sure that they get

00:08:00.060 --> 00:08:01.640
dropped so they'll get retransmitted.

00:08:01.740 --> 00:08:04.520
They come in out of order,
TCP will reorder all of it for you.

00:08:04.520 --> 00:08:06.920
It simplifies a lot of your life.

00:08:07.010 --> 00:08:08.180
It also provides flow control.

00:08:08.260 --> 00:08:11.030
The Internet doesn't have any
sort of built-in flow control.

00:08:11.080 --> 00:08:14.310
If you were to write an application
that spewed packets at the fastest

00:08:14.310 --> 00:08:16.990
rate the interface would support,
all of those packets will go out

00:08:16.990 --> 00:08:19.700
onto the network and then they'll
get dropped at the next hop.

00:08:19.700 --> 00:08:21.880
There aren't a lot of great ways to
get feedback to know how many of those

00:08:21.880 --> 00:08:25.550
packets are getting dropped or if any
of them are getting dropped at all.

00:08:25.840 --> 00:08:29.000
There is no such thing as a
connection on the Internet.

00:08:29.000 --> 00:08:32.880
All of the connection is stored in
state that's on both the device that's

00:08:32.880 --> 00:08:37.450
establishing the connection and the
device the connection was established to.

00:08:37.610 --> 00:08:39.930
There are some exceptions
like NATs and firewalls,

00:08:40.030 --> 00:08:42.340
but for the most part,
nothing on the Internet knows

00:08:42.340 --> 00:08:44.140
about your connection.

00:08:44.140 --> 00:08:46.860
This is really nice because if some
device that you're communicating

00:08:46.860 --> 00:08:50.690
through happens to crash or reboot,
the packets can be rerouted around that

00:08:50.730 --> 00:08:53.200
and your connection remains running.

00:08:54.210 --> 00:08:54.910
It's not all magic.

00:08:54.940 --> 00:08:57.560
There's a lot of work that happens
under the covers to make this happen,

00:08:57.560 --> 00:08:59.990
and there are some costs involved.

00:09:00.120 --> 00:09:02.820
The first thing to know is that we
can't connect directly to a host name.

00:09:02.850 --> 00:09:06.250
Most of the time we get from users
or from some other place a host

00:09:06.340 --> 00:09:08.300
name that we want to connect to.

00:09:08.410 --> 00:09:10.950
We first have to resolve that
to a list of addresses before

00:09:10.950 --> 00:09:12.590
we can establish a connection.

00:09:12.710 --> 00:09:14.980
So to do that,
we issue a DNS query and the

00:09:14.980 --> 00:09:20.270
DNS server responds with a reply,
and that'll give us a list of addresses.

00:09:20.300 --> 00:09:23.630
We'll pick one of those addresses,
and we'll use the TCP 3-way handshake

00:09:23.650 --> 00:09:25.200
to establish the connection.

00:09:25.360 --> 00:09:27.150
First,
we'll send a SYN packet to the server.

00:09:27.200 --> 00:09:31.300
The server will respond with a SYN ACK,
and then we'll respond with an ACK.

00:09:31.440 --> 00:09:34.100
The important thing to take away from
all of this is that for each of these

00:09:34.110 --> 00:09:37.890
operations—the DNS request and the
TCP 3-way handshake—this will take

00:09:37.950 --> 00:09:39.590
a minimum of one round-trip time.

00:09:39.600 --> 00:09:42.600
So on a high-latency network,
this can take a lot of time.

00:09:42.700 --> 00:09:45.960
If there's packet loss and we have
to count on a retransmit timer,

00:09:46.060 --> 00:09:48.600
that can also add even
more time and more cost.

00:09:48.600 --> 00:09:49.080
So anytime you establish
a new connection,

00:09:49.080 --> 00:09:49.600
you can send a SYN packet to the server.

00:09:49.600 --> 00:09:49.600
The server will respond with a SYN ACK,
and then we'll respond with an ACK.

00:09:49.600 --> 00:09:51.900
If you don't establish a new connection,
there's a time cost.

00:09:51.990 --> 00:09:55.540
If you can reuse existing connections,
you can sometimes avoid all of that

00:09:55.800 --> 00:09:57.890
and get some big performance gains.

00:09:57.910 --> 00:10:01.210
Once we have a connection established,
we need some way to keep track

00:10:01.210 --> 00:10:02.900
of the data that we're sending.

00:10:02.900 --> 00:10:05.900
TCP uses something called
sequence numbers for this.

00:10:05.900 --> 00:10:07.900
When TCP sends a packet
with some payload,

00:10:07.900 --> 00:10:10.900
it indicates the first sequence number
for the first byte of that payload,

00:10:10.900 --> 00:10:12.830
as well as the length.

00:10:12.900 --> 00:10:14.520
From that,
we can calculate the sequence number

00:10:14.590 --> 00:10:15.900
of all the bytes inside the payload.

00:10:16.030 --> 00:10:18.900
TCP uses this for the in-order delivery.

00:10:18.900 --> 00:10:20.830
When TCP sends out of order,
it can use these sequence numbers

00:10:20.830 --> 00:10:21.900
to properly reorder things.

00:10:22.030 --> 00:10:24.900
It can also detect if there
are gaps of missing data.

00:10:24.900 --> 00:10:27.960
It can use these sequence numbers
to acknowledge to the remote side,

00:10:27.980 --> 00:10:30.740
"I've got everything up to this
sequence number," so the remote side

00:10:30.740 --> 00:10:33.900
knows it no longer needs to hold
onto that data to retransmit it.

00:10:33.900 --> 00:10:35.740
One thing to be aware of with
the sequence numbers is that

00:10:35.740 --> 00:10:36.900
they don't start off with zero.

00:10:36.900 --> 00:10:39.900
They actually use a
pseudo-random initial value.

00:10:39.900 --> 00:10:42.880
If you're looking at
these values in tcpdump,

00:10:42.910 --> 00:10:46.900
tcpdump fortunately normalizes these,
so it's a lot easier.

00:10:46.900 --> 00:10:48.200
You can get a relative value.

00:10:48.200 --> 00:10:51.830
sequence number instead
of an absolute number.

00:10:53.770 --> 00:10:55.550
Once we have a connection
established and we know how we're

00:10:55.550 --> 00:10:57.530
going to send and receive data,
we still don't know how

00:10:57.530 --> 00:10:58.520
fast the network is.

00:10:58.620 --> 00:11:01.820
TCP uses something called a slow
start to effectively probe the

00:11:01.970 --> 00:11:05.550
network and slowly speed up until
it starts to get some packet loss.

00:11:05.550 --> 00:11:09.130
So when you establish a new connection
and you start to send a lot of data,

00:11:09.130 --> 00:11:10.940
you have to go through the slow start.

00:11:11.040 --> 00:11:14.940
If we issue an HTTP get request to a
server and it's for a large resource,

00:11:14.940 --> 00:11:17.770
the server can't just dump
all the packets on at once.

00:11:17.770 --> 00:11:20.000
It starts out by sending
us a few packets.

00:11:20.000 --> 00:11:22.560
When we acknowledge that,
we'll get a few more,

00:11:22.620 --> 00:11:26.420
and this keeps going until we get up to
the full speed available on the network.

00:11:26.420 --> 00:11:27.860
This isn't exactly accurate.

00:11:27.860 --> 00:11:29.390
It's a little bit more complex than that.

00:11:29.390 --> 00:11:31.490
But the important thing to
take away is that any time you

00:11:31.490 --> 00:11:33.630
create a new TCP connection,
you're going to have to go

00:11:33.640 --> 00:11:37.530
through the slow start again,
and that can take some time to speed up.

00:11:37.610 --> 00:11:40.660
So again, it's really important to reuse
an existing TCP connection as

00:11:40.660 --> 00:11:42.620
opposed to creating a new one.

00:11:42.690 --> 00:11:46.600
Looking at packets in TCP dump
can be pretty difficult,

00:11:46.600 --> 00:11:48.980
especially if you've got
10,000 packets to sort through.

00:11:49.110 --> 00:11:50.000
TCP dump just shows you the
number of packets that you've got.

00:11:50.000 --> 00:11:50.590
It shows you text.

00:11:50.590 --> 00:11:51.470
It shows you the time stamps.

00:11:51.570 --> 00:11:54.320
It shows you the sequence numbers
and a lot of other information.

00:11:54.400 --> 00:11:57.000
Trying to find problems
can be a real challenge.

00:11:57.020 --> 00:12:00.070
There's a wonderful open source tool
called TCP trace that generates these

00:12:00.070 --> 00:12:04.230
great graphs that help you visualize
what's going on with the TCP connection.

00:12:04.230 --> 00:12:07.250
This is a TCP trace time sequence graph.

00:12:07.310 --> 00:12:08.810
I'm going to go over some of the
details because we're going to

00:12:08.810 --> 00:12:10.900
look at two more of these graphs.

00:12:10.900 --> 00:12:13.560
At the beginning,
we have a sequence packet

00:12:13.560 --> 00:12:15.180
-- or a SYN packet.

00:12:15.180 --> 00:12:17.100
Shortly thereafter,
we get our SYN ACK from the server,

00:12:17.110 --> 00:12:20.000
and we immediately respond
with an ACK packet.

00:12:20.000 --> 00:12:20.000
On the second packet,
we get a SYN packet.

00:12:20.000 --> 00:12:21.340
On the top, we have the window.

00:12:21.500 --> 00:12:24.160
This is the remote side telling
us don't send us anything beyond

00:12:24.160 --> 00:12:27.040
this sequence number because
I don't have anywhere to store it.

00:12:27.040 --> 00:12:28.680
On the bottom,
we have a green light that's

00:12:28.970 --> 00:12:30.150
tracking the acknowledged number.

00:12:30.430 --> 00:12:34.750
This is the remote side telling us I've
received every sequence up to this point.

00:12:35.220 --> 00:12:37.970
Most importantly,
we have actual packets or

00:12:37.980 --> 00:12:39.900
payload we can see in here.

00:12:39.900 --> 00:12:43.070
We can see when the packets are sent,
and we can see how much data is in that

00:12:43.070 --> 00:12:45.000
packet based on the height of the line.

00:12:45.100 --> 00:12:47.960
We can also see the difference between
when the packet was sent and when

00:12:47.960 --> 00:12:49.600
it was acknowledged by the server.

00:12:49.790 --> 00:12:52.740
There's a lot of other great information
you can see by looking at these graphs.

00:12:52.880 --> 00:12:56.890
You can detect problems with
retransmits or out-of-order data.

00:12:56.890 --> 00:13:01.200
You can detect problems where the
server actually stopped reading,

00:13:01.210 --> 00:13:03.000
so your acknowledged data
actually runs into the window.

00:13:04.020 --> 00:13:06.740
If we look at a slow start,
this is an SCP connection.

00:13:06.740 --> 00:13:08.260
At the beginning,
there's a bit of key exchange,

00:13:08.410 --> 00:13:11.210
and then about 500 milliseconds in,
we start sending a lot of data.

00:13:11.300 --> 00:13:13.540
And we can see that TCP does
a nice job of ramping up,

00:13:13.710 --> 00:13:15.720
but it does take a few
hundred milliseconds.

00:13:15.870 --> 00:13:23.170
And this is on a really fast
network with a low round-trip time.

00:13:23.170 --> 00:13:23.610
If the round-trip time is higher,
there's higher latency,

00:13:23.610 --> 00:13:23.610
this will take even longer.

00:13:25.170 --> 00:13:28.540
Once TCP goes through slow start,
it switches over to the congestion

00:13:28.540 --> 00:13:31.560
avoidance algorithm that takes
pretty good advantage of all the

00:13:31.560 --> 00:13:34.580
bandwidth that's available on a
given network at any given time.

00:13:34.610 --> 00:13:38.520
As the network bandwidth fluctuates,
it will fluctuate with it.

00:13:38.620 --> 00:13:42.200
In this particular case,
we were able to take advantage of

00:13:42.200 --> 00:13:45.000
all 50 megabit to the remote machine.

00:13:45.810 --> 00:13:48.250
When a packet goes missing,
TCP needs some way to

00:13:48.260 --> 00:13:49.640
retransmit that data.

00:13:49.640 --> 00:13:55.520
If there's a lot of data
flowing at any given time,

00:13:55.520 --> 00:13:57.790
we've got a whole bunch of payload
packets that are going from

00:13:57.790 --> 00:13:57.790
the server to the client here,
and there's one in red that went missing.

00:13:58.000 --> 00:14:00.320
Every packet that comes in
after the one that went missing

00:14:00.320 --> 00:14:02.760
will trigger an immediate ACK,
and that ACK will say,

00:14:02.810 --> 00:14:05.340
"I got everything up to this
sequence number." When the

00:14:05.340 --> 00:14:08.070
server gets four acknowledgements
for the same sequence number,

00:14:08.070 --> 00:14:10.420
it triggers something
called a fast retransmit.

00:14:10.420 --> 00:14:13.570
The server immediately sends the
missing segment and continues

00:14:13.570 --> 00:14:15.000
on with what it was doing.

00:14:15.070 --> 00:14:19.160
In this particular case,
you can see we didn't really

00:14:19.160 --> 00:14:22.980
interfere with the speed at
which we were transmitting data.

00:14:22.980 --> 00:14:22.980
Everything just kept
going without a hiccup.

00:14:24.800 --> 00:14:26.690
If we only have a little
bit of data flowing in a

00:14:26.690 --> 00:14:29.820
TCP connection at any given time,
there's a good chance we may have

00:14:29.880 --> 00:14:31.680
to count on the retransmit timer.

00:14:31.680 --> 00:14:34.080
In this particular case,
we have a few payload packets

00:14:34.080 --> 00:14:35.560
and the last one went missing.

00:14:35.570 --> 00:14:37.790
We acknowledge all the data
that we have received so far,

00:14:37.810 --> 00:14:40.500
but the remote side doesn't know
whether that packet is still in

00:14:40.500 --> 00:14:43.500
flight somewhere so it waits for
the retransmit timer to fire.

00:14:43.510 --> 00:14:46.550
Sometime later,
at least 200 milliseconds later,

00:14:46.590 --> 00:14:48.540
it retransmits the missing segment.

00:14:48.740 --> 00:14:51.380
The important thing to keep in mind
here is that if you're using a bunch of

00:14:51.380 --> 00:14:54.860
different TCP connections and putting a
little bit of data over each connection,

00:14:54.860 --> 00:14:57.660
you're going to be running
into the retransmit timer

00:14:57.660 --> 00:14:59.260
a lot and that costs you.

00:14:59.260 --> 00:15:02.340
If you can try and move all that
traffic onto a single TCP connection,

00:15:02.340 --> 00:15:04.880
you can take advantage of the
fast retransmit timer and get

00:15:05.090 --> 00:15:06.330
some big performance wins.

00:15:08.710 --> 00:15:10.810
Another thing to be aware of
when you're working with TCP is

00:15:10.860 --> 00:15:12.800
something called a SOX proxy.

00:15:12.800 --> 00:15:15.550
Most of you probably don't
have SOX proxies you have to

00:15:15.550 --> 00:15:17.260
deal with on a regular basis.

00:15:17.260 --> 00:15:20.600
But some of your users may run
into one of these networks.

00:15:20.600 --> 00:15:23.150
On these networks,
there's a firewall and the firewall will

00:15:23.150 --> 00:15:26.400
block you from directly connecting to
the server that you're interested in.

00:15:26.500 --> 00:15:29.740
Instead of connecting to the server,
you have to connect to the SOX proxy.

00:15:29.860 --> 00:15:33.060
You then tell the SOX proxy you're
interested in connecting to some server.

00:15:33.210 --> 00:15:36.170
The SOX proxy establishes the connection
to the server for you and then it

00:15:36.300 --> 00:15:39.080
starts relaying data back and forth.

00:15:39.080 --> 00:15:41.530
When you're using TCP,
it's really important to

00:15:41.530 --> 00:15:43.370
remember to support SOX proxies.

00:15:43.390 --> 00:15:45.580
If you're using the right
frameworks in the system,

00:15:45.580 --> 00:15:47.220
it will handle SOX proxies for you.

00:15:47.220 --> 00:15:50.400
But if you're rolling your own or
working at the socket's layer directly,

00:15:50.400 --> 00:15:53.410
you need to make sure you have
SOX proxy support in there.

00:15:53.440 --> 00:15:56.070
So as a wrap-up of the best
practices when using TCP,

00:15:56.170 --> 00:15:57.600
first of all, use TCP.

00:15:57.600 --> 00:16:00.460
It provides a bunch of great
services and people have invested

00:16:00.510 --> 00:16:02.700
decades into improving TCP.

00:16:02.700 --> 00:16:05.140
It's really unlikely you're
going to do a better job than

00:16:05.250 --> 00:16:06.960
TCP does on a given network.

00:16:06.980 --> 00:16:10.660
It's really important to reuse
existing TCP connections.

00:16:10.660 --> 00:16:12.980
New connections cost a lot of time.

00:16:12.980 --> 00:16:15.190
Between the three-way handshake,
the slow start,

00:16:15.340 --> 00:16:18.420
and if there's packet loss,
if this is a high latency network,

00:16:18.450 --> 00:16:19.630
this can add up.

00:16:19.860 --> 00:16:22.300
It's also really important to
keep a lot of data in flight.

00:16:22.300 --> 00:16:24.780
The last four packets on the
TCP connection are the ones that

00:16:24.790 --> 00:16:25.900
are going to be sensitive to loss.

00:16:25.990 --> 00:16:29.440
If you can keep more than four
packets in flight at any given time,

00:16:29.570 --> 00:16:32.070
you're going to be able to take
advantage of the fast retransmit

00:16:32.190 --> 00:16:33.790
and things will flow much better.

00:16:33.910 --> 00:16:36.800
One technique you can use for this
is to double buffer operations.

00:16:36.900 --> 00:16:39.120
Instead of serial
assigning your requests,

00:16:39.120 --> 00:16:42.220
where you request something and
when the response comes back

00:16:42.220 --> 00:16:45.030
you request the next thing,
you can issue a request for

00:16:45.030 --> 00:16:47.930
multiple things so you always
have a lot of packets coming

00:16:47.930 --> 00:16:49.110
back to you at any given time.

00:16:50.690 --> 00:16:53.600
We're going to move into HTTP now.

00:16:53.600 --> 00:16:57.650
HTTP provides a very nice
request response-based protocol.

00:16:57.670 --> 00:16:59.670
All of the headers are based on text.

00:16:59.740 --> 00:17:01.060
Parsing text can be a little bit tricky.

00:17:01.160 --> 00:17:06.720
We have some great frameworks that will
handle this for you so you can avoid

00:17:06.720 --> 00:17:06.720
some of the pitfalls of parsing text.

00:17:06.930 --> 00:17:08.860
The nice thing about all of
these headers are that they

00:17:08.880 --> 00:17:11.980
provide some very rich metadata,
so you can get some great information.

00:17:12.240 --> 00:17:14.020
HTTP has support for caching.

00:17:14.240 --> 00:17:17.300
There's also support for
an HTTP-specific proxy,

00:17:17.300 --> 00:17:18.730
which we'll go into.

00:17:18.800 --> 00:17:21.330
HTTP has a few interesting
things—persistent connections

00:17:21.360 --> 00:17:24.040
and pipeline requests,
which we'll go into in more detail.

00:17:25.040 --> 00:17:27.360
If you're dealing with HTTP,
you need to support SOX proxies,

00:17:27.360 --> 00:17:30.420
and you also need to support
proxies called HTTP proxies.

00:17:30.420 --> 00:17:32.670
HTTP proxies are slightly different.

00:17:32.700 --> 00:17:36.170
When you talk to an HTTP proxy,
you don't tell it the server

00:17:36.190 --> 00:17:37.610
you're interested in connecting to.

00:17:37.680 --> 00:17:41.480
You actually hand the whole
HTTP request to the HTTP proxy.

00:17:41.480 --> 00:17:43.610
The HTTP proxy will
forward this to the server,

00:17:43.670 --> 00:17:46.540
or if it already has the resource
you're interested in cached,

00:17:46.540 --> 00:17:48.870
it'll give the response
directly back to you.

00:17:48.870 --> 00:17:51.650
If it comes back from the server,
it'll forward the response

00:17:51.660 --> 00:17:53.080
back to you from the server.

00:17:56.050 --> 00:17:59.570
HTTP 1.0 did not have support
for persistent connections.

00:17:59.690 --> 00:18:02.050
With HTTP 1.0, it was very simple.

00:18:02.160 --> 00:18:03.600
You opened a TCP connection.

00:18:03.770 --> 00:18:05.410
You issued your request.

00:18:05.520 --> 00:18:07.600
When you got a response back,
both you and the server

00:18:07.600 --> 00:18:08.440
closed the connection.

00:18:08.440 --> 00:18:11.940
If you wanted to do another request,
you had to open another TCP connection.

00:18:12.030 --> 00:18:15.470
As we alluded to earlier,
establishing new TCP connections

00:18:15.470 --> 00:18:17.580
is a really expensive operation.

00:18:17.670 --> 00:18:21.120
They fixed this in HTTP 1.1
with persistent connections.

00:18:21.140 --> 00:18:24.020
With a persistent connection,
we perform our three-way handshake

00:18:24.090 --> 00:18:25.570
and establish a connection.

00:18:25.690 --> 00:18:27.210
And then we issue our request.

00:18:27.460 --> 00:18:29.560
When we get the response back,
we can go ahead and

00:18:29.560 --> 00:18:30.660
issue another request.

00:18:30.820 --> 00:18:33.170
The only downside to this is
that because we're issuing

00:18:33.170 --> 00:18:36.100
all these requests serially,
we're having to pay at least one round

00:18:36.100 --> 00:18:39.180
trip time for every request response.

00:18:39.730 --> 00:18:43.260
HTTP has another technique
called pipelining.

00:18:43.260 --> 00:18:45.520
With pipelining,
you establish a TCP connection,

00:18:45.600 --> 00:18:47.790
and then you issue all the
requests at the same time,

00:18:47.790 --> 00:18:49.710
and then the responses come back to back.

00:18:50.010 --> 00:18:51.710
Instead of taking us
four round-trip times,

00:18:51.730 --> 00:18:53.400
this has taken us two round-trip times.

00:18:53.650 --> 00:18:55.060
This is a huge performance win.

00:18:55.190 --> 00:19:00.720
In addition, because all the responses
are coming back to back,

00:19:00.720 --> 00:19:04.110
we can take advantage
of fast retransmits.

00:19:04.110 --> 00:19:04.110
Any time you can,
take advantage of HTTP pipelining.

00:19:04.930 --> 00:19:07.140
If we look at this another way,
on the top,

00:19:07.260 --> 00:19:11.680
we have a serial persistent connection,
and on the bottom, we're using pipelining

00:19:11.680 --> 00:19:12.830
to get the same resource.

00:19:12.880 --> 00:19:15.250
First, we get the root document,
we parse it,

00:19:15.350 --> 00:19:17.380
we realize we need five resources.

00:19:17.380 --> 00:19:20.150
If we're using the persistent connection,
we issue a request for

00:19:20.150 --> 00:19:21.160
the first resource.

00:19:21.160 --> 00:19:23.590
When that comes back,
we issue a request for the second

00:19:23.600 --> 00:19:25.200
resource and so on and so forth.

00:19:25.200 --> 00:19:29.430
If the round trip times are
small on a low latency network,

00:19:29.430 --> 00:19:31.800
this isn't a really big deal.

00:19:31.800 --> 00:19:34.330
As the latencies get a lot bigger,
you can get a huge win by

00:19:34.330 --> 00:19:37.460
switching to pipelining where
you get your root document,

00:19:37.620 --> 00:19:40.400
you parse it,
you realize you need five resources,

00:19:40.400 --> 00:19:43.260
you issue the request for all
five resources at the same time,

00:19:43.260 --> 00:19:45.420
and they come back back to back.

00:19:45.420 --> 00:19:47.810
A really nice analogy is if you
were going to bake some cookies.

00:19:47.810 --> 00:19:49.660
You pull out the cookbook,
you open it up,

00:19:49.660 --> 00:19:51.030
you see that you need eggs.

00:19:51.100 --> 00:19:53.480
So you go to the refrigerator,
you don't have any eggs.

00:19:53.510 --> 00:19:55.930
You drive to the store,
you pick up the eggs, you come back,

00:19:55.930 --> 00:19:58.440
and you look at the next
ingredient and it's sugar.

00:19:58.530 --> 00:20:00.300
Now you go back into the car,
you drive to the store,

00:20:00.300 --> 00:20:01.210
you pick up the sugar.

00:20:01.240 --> 00:20:01.240
It's a really easy way to
get the next ingredient.

00:20:01.240 --> 00:20:01.240
You go to the store,
you pick up the eggs, you come back,

00:20:01.240 --> 00:20:01.360
and you look at the next ingredient,
and it's sugar.

00:20:01.360 --> 00:20:03.450
It's a really inefficient way to bake.

00:20:03.450 --> 00:20:05.370
You'll end up baking all day long.

00:20:05.480 --> 00:20:07.620
If you were to put together a
list of everything you needed,

00:20:07.630 --> 00:20:09.440
pay the round trip
time to the store once,

00:20:09.440 --> 00:20:13.360
you can get all of those things at
once and save yourself a lot of time.

00:20:13.610 --> 00:20:16.000
The iTunes store uses
HTTP on the back end,

00:20:16.000 --> 00:20:19.070
and they did some performance
tests and realized that by

00:20:19.070 --> 00:20:21.530
switching to using pipelining,
they were able to get almost a 3X

00:20:21.630 --> 00:20:23.400
performance improvement on some networks.

00:20:23.510 --> 00:20:25.450
So this isn't some small,
trivial improvement.

00:20:25.540 --> 00:20:27.610
This is huge.

00:20:28.940 --> 00:20:32.870
So wrapping up HTTP best practices,
when you're supporting HTTP,

00:20:32.880 --> 00:20:36.160
make sure that you support
HTTP and SOX proxies.

00:20:36.320 --> 00:20:37.760
You may never run into
one of these networks,

00:20:37.830 --> 00:20:39.870
but there's a good chance
some of your customers will,

00:20:39.870 --> 00:20:41.880
and they'll really appreciate
that you did the work to

00:20:41.880 --> 00:20:43.190
make sure it'll work there.

00:20:43.790 --> 00:20:46.400
Be sure that you support persistent
connections at the very least.

00:20:46.400 --> 00:20:49.620
If you can, add support for pipelining.

00:20:49.730 --> 00:20:51.780
Pipelining does require
server-side support.

00:20:51.890 --> 00:20:59.630
Most servers, I believe, will support it,
but you'll want to check

00:20:59.630 --> 00:20:59.630
with your IT department or if
you're running your own server,

00:20:59.630 --> 00:20:59.630
just make sure that that's going to work.

00:21:00.910 --> 00:21:03.360
Now we're going to go into the
APIs that you can use to take advantage

00:21:03.430 --> 00:21:05.940
of these protocols on the system.

00:21:06.080 --> 00:21:08.890
For TCP, the best API is CfSocketStream.

00:21:08.900 --> 00:21:14.450
CfSocketStream provides a really nice
CF run loop integrated TCP connection.

00:21:14.470 --> 00:21:17.180
It also works well with the CF types.

00:21:17.180 --> 00:21:19.760
It provides a nice
connect by host name API.

00:21:19.850 --> 00:21:22.840
If you're dealing with a sockets layer,
you're responsible for converting

00:21:22.840 --> 00:21:25.300
a host name to a list of addresses,
and then telling the system to

00:21:25.360 --> 00:21:26.860
connect to one of those addresses.

00:21:26.970 --> 00:21:29.380
With CfSocketStream,
you just pass the host name into us,

00:21:29.500 --> 00:21:31.110
and we'll take care of the rest for you.

00:21:31.260 --> 00:21:34.380
We do some really sophisticated things
under the covers to try and establish

00:21:34.380 --> 00:21:36.440
a connection in a short period of time.

00:21:36.600 --> 00:21:39.110
When we resolve the host name,
we'll get back a list of addresses.

00:21:39.190 --> 00:21:41.860
And we'll sort it based on
statistics and what we think is

00:21:41.860 --> 00:21:43.100
going to be the best address.

00:21:43.260 --> 00:21:46.220
We'll start a connection
attempt to what we believe is

00:21:46.310 --> 00:21:47.480
going to be the best address.

00:21:47.560 --> 00:21:50.880
We'll also start a timer based on how
long we expect that connection to take.

00:21:50.980 --> 00:21:54.400
If that connection doesn't succeed within
the time we expect for some reason,

00:21:54.400 --> 00:21:56.980
we'll actually start a second
connection attempt to the next

00:21:56.980 --> 00:21:59.500
best address while we leave that
first connection attempt going.

00:21:59.500 --> 00:22:02.750
We'll keep doing this until we've
run out of addresses to try or until

00:22:02.750 --> 00:22:04.460
we've established a connection.

00:22:04.540 --> 00:22:07.210
There's a new variant of this in
iOS 6 that we're going to talk about

00:22:07.350 --> 00:22:09.720
briefly soon called cellular fallback.

00:22:09.820 --> 00:22:12.510
You'll get all of this for free
if you're using CFSocketStream.

00:22:12.560 --> 00:22:14.870
If you try and roll your own,
it will take a long time

00:22:14.870 --> 00:22:16.190
and it's really hard.

00:22:16.280 --> 00:22:18.270
Some other benefits you get
from using CFSocketStream:

00:22:18.380 --> 00:22:20.710
we have cellular and
VPN on-demand support built in.

00:22:20.770 --> 00:22:23.840
So if you're using sockets directly
and you need to bring up the cellular

00:22:23.840 --> 00:22:26.450
interface in order to connect,
there's nothing at the sockets

00:22:26.460 --> 00:22:27.640
layer that will trigger that.

00:22:27.690 --> 00:22:29.060
The same goes for VPNs.

00:22:29.080 --> 00:22:31.330
Nothing at the sockets layer
will trigger the VPN to dial.

00:22:31.490 --> 00:22:34.700
If you're using CFSocketStream,
all of that is handled automatically.

00:22:34.750 --> 00:22:39.450
In addition, CFSocketStream has built-in
support for TLS and SSL.

00:22:39.560 --> 00:22:41.730
It handles both server and
client-side authentication,

00:22:41.740 --> 00:22:43.540
so you don't have to roll your own code.

00:22:43.600 --> 00:22:45.470
We also have support for SOCKS proxies.

00:22:45.590 --> 00:22:47.930
You won't have to write your
own SOCKS proxy support.

00:22:47.950 --> 00:22:50.250
Unfortunately,
it's not enabled by default.

00:22:50.330 --> 00:22:53.260
Your application is responsible
for calling a function to

00:22:53.300 --> 00:22:54.840
fetch the proxy settings out.

00:22:54.860 --> 00:22:57.820
And then you need to set the
CFStream property SOCKS proxy's

00:22:58.010 --> 00:23:01.490
setting on the CFSocketStream
before you establish the connection.

00:23:01.680 --> 00:23:04.660
A new feature in iOS 6 is
something called cellular fallback.

00:23:04.700 --> 00:23:08.130
With cellular fallback,
when we have the primary

00:23:08.390 --> 00:23:10.820
interface as Wi-Fi,
we'll start a connection

00:23:10.820 --> 00:23:12.700
attempt over Wi-Fi,
and we'll set up a timer.

00:23:12.700 --> 00:23:16.010
And if for some reason that
connection attempt doesn't succeed

00:23:16.010 --> 00:23:19.040
within a short period of time,
we'll actually start a parallel

00:23:19.050 --> 00:23:20.620
connection attempt over cellular.

00:23:20.710 --> 00:23:23.440
It turns out there are a lot
of Wi-Fi networks out there

00:23:23.440 --> 00:23:27.160
that work for most things,
but they block access to certain things.

00:23:27.200 --> 00:23:29.670
When we're on a Wi-Fi network,
we'd really like to use that

00:23:29.670 --> 00:23:32.200
Wi-Fi network for everything
that'll work over Wi-Fi,

00:23:32.200 --> 00:23:35.470
but we don't want to lose access to
all those things that will still work

00:23:35.470 --> 00:23:38.700
over cellular just because we happen to
be associated with this Wi-Fi network.

00:23:38.720 --> 00:23:42.700
Cellular fallback lets us do that,
where we'll try and connect over Wi-Fi,

00:23:42.700 --> 00:23:46.700
but if for some reason we can't,
we'll end up connecting over cellular.

00:23:46.700 --> 00:23:49.720
If your application is paying
attention to the WAN flag that you

00:23:49.730 --> 00:23:52.920
get back from SC Network Reachability
to indicate whether you're going

00:23:53.010 --> 00:23:54.860
to connect over cellular or not,
it might get a little bit

00:23:54.980 --> 00:23:56.700
tripped up by this new feature.

00:23:56.700 --> 00:23:59.570
We've added some new APIs in iOS
6 to make this a lot simpler.

00:23:59.700 --> 00:24:04.260
If your application absolutely
doesn't want to connect

00:24:04.260 --> 00:24:06.750
over the cellular interface,
you can set the CFStream property

00:24:06.750 --> 00:24:09.590
"no cellular" before you connect,
and whatever we do,

00:24:09.750 --> 00:24:12.700
we will not connect you
over the cellular interface.

00:24:12.700 --> 00:24:14.580
If, on the other hand,
all you're interested in

00:24:14.580 --> 00:24:17.660
is knowing after the fact,
did I end up connecting over cellular,

00:24:17.790 --> 00:24:21.250
you can use the CFStream property
"connection is cellular" to determine

00:24:21.290 --> 00:24:24.700
whether the connection ended up being
established over the cellular network.

00:24:26.740 --> 00:24:28.910
A lot of us use Cocoa to program,
and we'd really like to be

00:24:28.910 --> 00:24:31.900
able to use the NSInputStream
and NSOutputStream classes.

00:24:32.000 --> 00:24:34.040
Unfortunately,
there's not a great way to create

00:24:34.120 --> 00:24:35.480
these classes directly in Cocoa.

00:24:35.700 --> 00:24:40.160
You'll need to drop down to the
CF APIs to create these objects.

00:24:40.260 --> 00:24:42.520
What we recommend,
if you've got a host name

00:24:42.610 --> 00:24:45.210
you want to connect to,
use CFStreamCreatePair

00:24:45.480 --> 00:24:47.830
with socket to host.

00:24:47.930 --> 00:24:50.700
And if you have a Bonjour service,
go ahead and use CFStreamCreatePair

00:24:50.700 --> 00:24:52.610
with socket to NetService.

00:24:52.790 --> 00:24:55.360
These will give you back a
CFInputStream and a CFOutputStream,

00:24:55.360 --> 00:24:59.000
which you can then use as
NSInputStreams and NSOutputStreams.

00:24:59.110 --> 00:25:01.690
If you're using Arc,
it's really important to remember

00:25:01.820 --> 00:25:03.360
to use CFBridgingRelease.

00:25:03.470 --> 00:25:04.990
Another thing to be aware of is NSHost.

00:25:05.120 --> 00:25:08.660
It's only available on
OS X and not on iOS.

00:25:08.770 --> 00:25:12.190
It does do asynchronous blocking
resolve wherever it's instantiated,

00:25:12.280 --> 00:25:14.350
and for that reason,
we recommend that you avoid it and

00:25:14.350 --> 00:25:17.060
do your name lookups in another way.

00:25:18.850 --> 00:25:23.640
If you're trying to use HTTP or HTTPS,
the absolute best API on both

00:25:23.640 --> 00:25:26.120
iOS and OS X is NSURLConnection.

00:25:26.120 --> 00:25:28.870
There is an older
API called CFHTTPStream.

00:25:28.990 --> 00:25:31.810
Unfortunately,
CFHTTPStream has some behaviors

00:25:31.820 --> 00:25:34.760
that we'd like to improve,
but we can't because some

00:25:34.770 --> 00:25:37.040
clients may be depending on them.

00:25:37.120 --> 00:25:39.420
If you have existing code
that's using CFHTTPStream,

00:25:39.420 --> 00:25:42.680
we strongly recommend you switch
over to using NSURLConnection.

00:25:42.860 --> 00:25:46.450
If you're writing new code from scratch,
please use NSURLConnection.

00:25:46.570 --> 00:25:50.460
NSURLConnection provides a very
nice asynchronous event-based API.

00:25:50.570 --> 00:25:52.060
It has a lot of fantastic features.

00:25:52.060 --> 00:25:53.800
It supports persistent connections.

00:25:53.800 --> 00:25:55.250
It'll handle pipelining for you.

00:25:55.500 --> 00:25:59.360
It handles HTTP as well as
TLS and SSL authentication.

00:25:59.460 --> 00:26:00.730
It handles a lot of caching.

00:26:00.780 --> 00:26:01.940
It'll handle cookies.

00:26:01.940 --> 00:26:05.690
And it'll also take care of SOCKS and
HTTP proxies for you automatically.

00:26:05.790 --> 00:26:08.000
You won't have to write any code
to fetch settings or anything else.

00:26:08.080 --> 00:26:10.150
It just does what it's supposed to.

00:26:10.260 --> 00:26:11.950
It's great.

00:26:12.060 --> 00:26:14.930
NSURLConnection goes through
a fairly simple lifecycle.

00:26:14.970 --> 00:26:16.450
First, you create an NSURL request.

00:26:16.460 --> 00:26:19.460
The NSURL request says,
here's what I'm interested in.

00:26:19.460 --> 00:26:23.960
And then you pass the NSURL request
in to create the NSURL connection.

00:26:23.960 --> 00:26:25.460
You also specify a delegate.

00:26:25.460 --> 00:26:29.460
The delegate will get called as
soon as the request has been sent.

00:26:29.460 --> 00:26:31.910
And it'll get notified when
the response comes back.

00:26:31.960 --> 00:26:33.890
And it'll get notified as data comes in.

00:26:33.960 --> 00:26:36.880
And finally,
it'll get notified when you've

00:26:36.880 --> 00:26:40.270
got the end of the resource
or you've got an error.

00:26:40.610 --> 00:26:43.890
When you're working with NSURLConnection,
it's important to remember that an

00:26:43.990 --> 00:26:47.780
NSURLConnection does not necessarily
correspond to a TCP connection.

00:26:47.800 --> 00:26:50.840
NSURLConnection supports persistent
connections and pipelining.

00:26:50.890 --> 00:26:54.730
It means we're reusing a single
TCP connection for multiple requests.

00:26:54.730 --> 00:26:59.220
NSURLConnection does this by
maintaining a pool of connections.

00:26:59.220 --> 00:27:03.970
So when you put together a request,
it will actually go and dynamically

00:27:03.970 --> 00:27:06.540
allocate one of the existing connections,
if there is one,

00:27:06.540 --> 00:27:06.540
or create a new one from scratch.

00:27:07.200 --> 00:27:09.070
In some cases,
we may actually be giving you a

00:27:09.070 --> 00:27:11.910
response directly out of the cache,
so there is no TCP connection

00:27:12.010 --> 00:27:13.700
involved in there whatsoever.

00:27:13.700 --> 00:27:17.670
NSURLConnection has support for
HTTP authentication built in.

00:27:17.780 --> 00:27:21.100
It also handles SSL and
TLS authentication.

00:27:21.310 --> 00:27:27.590
For HTTP, it supports the basic digest
NTLS and OS X Kerberos methods.

00:27:27.710 --> 00:27:29.790
We also handle automatic
proxy authentication.

00:27:29.930 --> 00:27:33.810
Your process doesn't necessarily
get access to the credentials

00:27:33.870 --> 00:27:35.900
to authenticate to the proxy.

00:27:35.990 --> 00:27:37.990
NSURLConnection will take
care of all of it for you.

00:27:37.990 --> 00:27:39.490
It's really easy.

00:27:39.500 --> 00:27:42.900
If for some reason your application does
want to get involved in authentication,

00:27:43.030 --> 00:27:46.860
in your delegate,
you can specify a "will send request

00:27:47.010 --> 00:27:50.540
for authentication" challenge method,
and that will give you a chance to

00:27:50.540 --> 00:27:52.700
intervene in the default behavior.

00:27:52.700 --> 00:27:56.690
NSURLConnection does support pipelining,
but pipelining is not enabled by default.

00:27:56.760 --> 00:28:00.760
It's your application's
responsibility to enable pipelining.

00:28:00.880 --> 00:28:03.660
When you set up your NSURL request,
you can indicate that you're

00:28:03.660 --> 00:28:06.940
interested in pipelining by calling
"set HTTP should use pipelining."

00:28:07.000 --> 00:28:08.490
We strongly encourage you to do so.

00:28:08.630 --> 00:28:10.400
Any time you can take
advantage of pipelining,

00:28:10.400 --> 00:28:12.360
you'll get some huge performance wins.

00:28:12.480 --> 00:28:16.890
NSURLConnection has
automatic cache built in.

00:28:16.930 --> 00:28:18.690
It's a single shared cache.

00:28:18.820 --> 00:28:21.460
You can get it using
NSURLConnection shared URL cache.

00:28:21.560 --> 00:28:23.600
It's shared with
everything in your process,

00:28:23.700 --> 00:28:25.940
so that includes other frameworks
that you may call that use

00:28:25.940 --> 00:28:27.940
NSURLConnection under the covers.

00:28:28.060 --> 00:28:30.410
NSURLConnection doesn't really
know about the workload of

00:28:30.470 --> 00:28:32.950
your particular application,
so it uses some defaults that may

00:28:32.950 --> 00:28:33.500
not be tuned particularly well.

00:28:33.500 --> 00:28:38.670
But it works well for the default case.

00:28:39.390 --> 00:28:42.980
There is a small in-memory cache that is
about four megabytes and that overflows

00:28:42.980 --> 00:28:45.210
into about a 20 megabyte on disk cache.

00:28:45.250 --> 00:28:47.900
There is a limit that a single
item in the cache can't take

00:28:47.900 --> 00:28:49.480
more than 5% of the cache.

00:28:49.480 --> 00:28:52.320
Your application has a
chance to do some tuning.

00:28:52.320 --> 00:28:56.320
You can set the memory capacity
as well as the disk capacity.

00:28:56.320 --> 00:29:00.080
We recommend that you use
TCP dump and watch the traffic.

00:29:00.110 --> 00:29:03.080
Go ahead and run your application through
a typical workload and see if it's

00:29:03.140 --> 00:29:05.120
requesting the same resources over again.

00:29:05.120 --> 00:29:08.240
If it is, increase the cache until
that no longer happens.

00:29:08.240 --> 00:29:11.100
We have some new functionality in iOS 6.

00:29:11.100 --> 00:29:13.770
We now support on disk
cache for HTTPS resources.

00:29:13.870 --> 00:29:18.360
In the past, HTTPS resources were limited
only to the in-memory cache.

00:29:18.360 --> 00:29:21.060
If your application is interested
in displaying web content,

00:29:21.060 --> 00:29:23.890
actually rendering it,
the absolute best API is WebKit.

00:29:23.970 --> 00:29:27.080
It has support for everything
we've talked about so far.

00:29:27.080 --> 00:29:29.970
It has caching support,
it handles proxies, and on iOS,

00:29:30.060 --> 00:29:32.220
it actually does pipelining by default.

00:29:32.240 --> 00:29:32.600
It's a great API.

00:29:32.710 --> 00:29:34.740
If you're going to render web content,
go ahead and use this.

00:29:34.740 --> 00:29:39.980
Before we move on, I kind of wanted to
cover timeouts quickly.

00:29:39.980 --> 00:29:41.730
There is no such thing as a good timeout.

00:29:41.780 --> 00:29:44.750
Round trip times on a network
can be anywhere from less than a

00:29:44.750 --> 00:29:47.120
millisecond to well over 30 seconds.

00:29:47.470 --> 00:29:51.040
Giving up on some operation can
be a huge disservice to the user.

00:29:51.040 --> 00:29:54.190
If you're trying to order
WWDC tickets and the application

00:29:54.190 --> 00:29:57.640
had set a 10-second timeout,
and because the servers tend

00:29:57.650 --> 00:30:00.510
to be a little bit slower to
respond during that two hours

00:30:00.510 --> 00:30:03.280
where the WWDC tickets sell out,
the server takes maybe

00:30:03.280 --> 00:30:04.630
12 seconds to respond.

00:30:04.710 --> 00:30:06.160
If your application
timed out in 10 seconds,

00:30:06.160 --> 00:30:06.460
it's going to be a little
bit slower to respond.

00:30:06.460 --> 00:30:07.880
If your application did not respond in
10 seconds but it would have succeeded

00:30:07.880 --> 00:30:10.280
if it held on for another two seconds,
you're really doing

00:30:10.280 --> 00:30:11.460
your user a disservice.

00:30:11.660 --> 00:30:15.660
So it's important to remember not
to use timeouts and cancel things.

00:30:15.680 --> 00:30:17.670
It may seem like a good
idea to let the user know,

00:30:17.670 --> 00:30:19.280
ah, this probably isn't going to work.

00:30:19.380 --> 00:30:21.080
But if there's a chance
it would have worked,

00:30:21.160 --> 00:30:23.720
you haven't really helped out the user.

00:30:23.720 --> 00:30:27.010
The best technique is to allow
the user to handle the timeout.

00:30:27.010 --> 00:30:30.400
Let the user indicate to you they're
interested in something and then keep

00:30:30.520 --> 00:30:32.990
working on it until they indicate
they're no longer interested.

00:30:33.080 --> 00:30:35.350
This doesn't mean hammer the
network and try and connect every

00:30:35.350 --> 00:30:36.180
minute until you get a connection.

00:30:36.180 --> 00:30:38.100
You need to be smart about it.

00:30:38.220 --> 00:30:41.990
There's a great API in the system
called reachability that lets

00:30:42.080 --> 00:30:45.460
you register for notifications
of when the network changes.

00:30:45.470 --> 00:30:48.690
Go ahead and make your attempt and if
for some reason it doesn't succeed,

00:30:48.690 --> 00:30:51.400
watch for a reachability
change notification.

00:30:51.400 --> 00:30:53.640
Don't force the user to
hit refresh at some point.

00:30:53.640 --> 00:30:57.020
When you're on a new network,
go ahead and make an attempt again.

00:30:57.020 --> 00:30:58.100
Which brings us to mobility.

00:30:58.310 --> 00:31:02.260
And we'll also cover a
little bit of cost issues.

00:31:03.050 --> 00:31:04.670
We have a number of challenges.

00:31:04.680 --> 00:31:06.880
The computers these days fit in pockets.

00:31:06.880 --> 00:31:09.180
And they have multiple interfaces.

00:31:09.180 --> 00:31:12.530
Some MacBooks still have two interfaces,
Ethernet and Wi-Fi.

00:31:12.590 --> 00:31:15.490
A lot of iOS devices have
both Wi-Fi and cellular.

00:31:15.600 --> 00:31:19.800
Unfortunately,
the operating system can't just

00:31:19.830 --> 00:31:25.200
pick up connections from one
interface and move them to another.

00:31:25.200 --> 00:31:25.200
We would love to be able to do that.

00:31:25.200 --> 00:31:25.200
But the technology just
doesn't exist today.

00:31:25.500 --> 00:31:28.260
It's really important for your
application that you respond to

00:31:28.260 --> 00:31:31.510
network change notifications and
do the right thing and migrate.

00:31:31.510 --> 00:31:34.210
There's a number of use cases
where this is really important.

00:31:34.280 --> 00:31:37.600
If you have somebody on a train and
they've got a cellular data connection,

00:31:37.600 --> 00:31:39.760
when they go into a tunnel,
they're going to lose the

00:31:39.850 --> 00:31:41.140
Internet connectivity.

00:31:41.140 --> 00:31:43.530
If your application throws
up a dialogue and says,

00:31:43.530 --> 00:31:45.910
"Oh, my gosh, the Internet's gone," and
they have to dismiss it,

00:31:45.950 --> 00:31:46.980
they get frustrated.

00:31:46.980 --> 00:31:49.310
They probably already know that the
Internet's gone and they're not really

00:31:49.390 --> 00:31:52.260
happy about it and having a dialogue in
their face isn't making them any happier.

00:31:52.260 --> 00:31:55.560
So if you can avoid dialogues,
that's good.

00:31:55.560 --> 00:31:58.170
The other thing that's really important
is when they get back out of the tunnel,

00:31:58.170 --> 00:32:00.580
you don't want to have them have
to babysit your application.

00:32:00.580 --> 00:32:02.830
As soon as you see that there's
network connectivity again,

00:32:02.830 --> 00:32:04.490
you should go ahead and
reissue the request.

00:32:04.580 --> 00:32:06.820
Don't make them wait for the
connectivity to come back and

00:32:06.820 --> 00:32:08.080
then hit a refresh button.

00:32:08.200 --> 00:32:09.510
That's not a great experience.

00:32:09.520 --> 00:32:12.400
Another place where it's really
important to handle this correctly

00:32:12.410 --> 00:32:15.430
is when you're migrating from a
cellular network to a Wi-Fi network.

00:32:15.440 --> 00:32:18.710
If your application is running on a
device that has cellular connectivity,

00:32:18.710 --> 00:32:21.030
your connections are going
over the cellular interface,

00:32:21.030 --> 00:32:22.760
when you come into a home environment,
you're going to have a

00:32:22.760 --> 00:32:26.850
Wi-Fi interface that will come up,
but your connection doesn't

00:32:26.850 --> 00:32:28.480
move over automatically.

00:32:28.480 --> 00:32:31.520
Your existing connection over cellular
will continue to work just fine.

00:32:31.640 --> 00:32:33.960
The downside is it's probably
a little bit slower and it's

00:32:33.960 --> 00:32:37.260
probably a lot more expensive,
both in a power perspective and cost.

00:32:37.260 --> 00:32:40.980
It's your application's responsibility
to watch for change notifications

00:32:41.060 --> 00:32:43.890
and make the transition from
the cellular interface to the

00:32:43.890 --> 00:32:48.630
Wi-Fi interface when you get notified
that that new interface is available.

00:32:48.970 --> 00:32:51.120
So we're going to go
over how you handle that.

00:32:51.140 --> 00:32:53.040
When you're trying to
establish a connection,

00:32:53.040 --> 00:32:56.290
you want to create a reachability object
and then go ahead and make your attempt.

00:32:56.500 --> 00:32:59.960
Don't check the reachability object to
determine whether something's available.

00:32:59.960 --> 00:33:01.640
It can be deceptive in some cases.

00:33:01.750 --> 00:33:03.880
You want to just go ahead
and make the attempt anyhow.

00:33:03.980 --> 00:33:05.620
If you succeed, you're done.

00:33:05.750 --> 00:33:11.160
If you don't succeed,
you want to wait for another

00:33:11.410 --> 00:33:12.380
reachability change notification
before you attempt again.

00:33:13.210 --> 00:33:15.930
You keep doing this until you've
finally established a connection

00:33:15.930 --> 00:33:18.790
or until the user has indicated
they're no longer interested.

00:33:19.600 --> 00:33:23.640
Once you have a connection established,
you still have to stay on your toes.

00:33:23.640 --> 00:33:27.200
You want to keep using the reachability
object that you created initially

00:33:27.260 --> 00:33:29.000
to establish the connection.

00:33:29.400 --> 00:33:31.550
You'll get reachability
change notifications as new

00:33:31.550 --> 00:33:33.000
interfaces become available.

00:33:33.000 --> 00:33:35.900
This is the case where you might have
an established connection over cellular,

00:33:35.900 --> 00:33:38.130
but you come home and
Wi-Fi becomes available.

00:33:38.250 --> 00:33:40.440
When you get that reachability
change notification,

00:33:40.490 --> 00:33:42.540
you want to try and
establish a new connection.

00:33:42.620 --> 00:33:45.500
If you have an existing old connection,
you want to leave that alone and continue

00:33:45.500 --> 00:33:47.830
doing work on that old connection.

00:33:47.910 --> 00:33:50.970
If the new connection succeeds,
you want to transition all of your

00:33:50.970 --> 00:33:54.200
work over to the new connection
and tear down the old connection.

00:33:54.220 --> 00:33:56.990
If the new connection doesn't succeed,
no big deal.

00:33:57.000 --> 00:33:58.840
You've still got your
old connection working.

00:33:58.910 --> 00:34:01.370
You just go back to waiting for
another reachability change and

00:34:01.400 --> 00:34:03.850
continue working on the old connection.

00:34:06.860 --> 00:34:09.700
There are a lot of issues related to
cost when working on these devices.

00:34:09.820 --> 00:34:12.190
They have a finite
amount of battery power.

00:34:12.270 --> 00:34:16.490
And a lot of times the data can
actually cost the user a lot of money.

00:34:16.490 --> 00:34:21.030
So we need to be very careful about
whatever load we put on the network.

00:34:21.210 --> 00:34:25.300
There are a number of techniques we can
use to solve problems related to cost.

00:34:25.300 --> 00:34:27.860
The primary thing we do is
avoid sending and receiving

00:34:27.870 --> 00:34:29.650
any data that we don't have to.

00:34:29.700 --> 00:34:31.060
The first technique is to cache data.

00:34:31.120 --> 00:34:32.880
If we can fetch something
out of the cache,

00:34:32.880 --> 00:34:36.900
we don't have to pay the money or the
power to get it off of the network.

00:34:36.900 --> 00:34:39.130
Another thing that's really important
is making sure that we're fetching

00:34:39.130 --> 00:34:40.520
appropriately sized resources.

00:34:40.520 --> 00:34:43.170
If we're on a device that
doesn't have a retina display,

00:34:43.170 --> 00:34:46.560
there's no point in getting a higher
resolution image that's going to take

00:34:46.560 --> 00:34:48.090
more bytes to get across the network.

00:34:48.090 --> 00:34:51.690
We can save the user some money and some
power by fetching the lowest resolution

00:34:51.690 --> 00:34:54.530
image that's appropriate to their device.

00:34:54.660 --> 00:34:56.860
Another thing that's really
important is making sure that

00:34:56.860 --> 00:34:58.800
we only fetch what's necessary.

00:34:58.800 --> 00:35:00.920
There's no point in fetching data
that the user is never going to use.

00:35:00.940 --> 00:35:01.890
They have to pay for it.

00:35:01.950 --> 00:35:04.700
They're going to lose a little
bit of battery life for it.

00:35:04.700 --> 00:35:07.960
There is sort of a contradictory
technique for saving power,

00:35:08.040 --> 00:35:10.180
which is to fetch data in bursts.

00:35:10.180 --> 00:35:12.290
When it comes to power on
the cellular interface,

00:35:12.380 --> 00:35:15.870
the cellular interface goes into a low
power mode when it isn't sending data,

00:35:15.870 --> 00:35:17.520
and it does that based on an aisle timer.

00:35:17.520 --> 00:35:18.700
When it is sending data, it's in a very,
very low power mode.

00:35:18.700 --> 00:35:20.530
When it's sending data, it's in a very,
very high power mode that drains

00:35:20.530 --> 00:35:22.260
the battery fairly quickly.

00:35:22.260 --> 00:35:25.600
What you want to do is try and increase
the amount of time you're spending in

00:35:25.600 --> 00:35:28.700
low power mode and avoid the amount of
time you're spending in high power mode.

00:35:28.700 --> 00:35:31.740
So you can do that by trying to fetch
all of your data in a burst so you keep

00:35:31.840 --> 00:35:35.380
it in high power mode but you get as
much done as possible during that time,

00:35:35.380 --> 00:35:38.580
and then you stop all network activity.

00:35:38.580 --> 00:35:40.160
Pandora takes advantage of this.

00:35:40.160 --> 00:35:43.680
When Pandora runs, it downloads the whole
music file at the beginning.

00:35:43.680 --> 00:35:45.860
As it plays back,
the interface falls back

00:35:45.930 --> 00:35:47.550
into low power mode,
and it saves a lot of

00:35:47.580 --> 00:35:48.600
battery power that way.

00:35:48.870 --> 00:35:50.940
Pandora could have been written
differently so that it trickled

00:35:50.940 --> 00:35:53.050
the data at the bit rate that
it played back the music,

00:35:53.070 --> 00:35:56.140
but that would have forced the
cellular interface to stay in a high

00:35:56.220 --> 00:35:58.990
power mode for a very long time,
and the battery life

00:35:58.990 --> 00:36:00.540
would have been abysmal.

00:36:00.540 --> 00:36:03.810
Debugging network applications
can be a real challenge.

00:36:04.400 --> 00:36:06.300
So we're going to talk
about some techniques.

00:36:06.300 --> 00:36:08.140
One of the problems that you run
into with debugging networking

00:36:08.140 --> 00:36:11.430
applications is that if you stop
your application in the debugger

00:36:11.430 --> 00:36:15.040
and you're connected to a server,
there's a good chance the server's

00:36:15.040 --> 00:36:17.260
going to timeout the connection to you.

00:36:17.410 --> 00:36:19.270
Timeouts are evil.

00:36:19.850 --> 00:36:22.430
Some of the techniques that make
debugging a lot easier for networking

00:36:22.430 --> 00:36:26.940
applications is to add a lot of logging,
or basically resort to printf debugging.

00:36:26.940 --> 00:36:28.990
The system provides a whole
lot of logging for you.

00:36:29.030 --> 00:36:33.420
It's turned off by default,
but with some techniques,

00:36:33.420 --> 00:36:37.990
you can turn a lot of that on,
and you may be able to diagnose

00:36:37.990 --> 00:36:39.980
problems without even adding extra
logging to your own application.

00:36:39.980 --> 00:36:39.980
So we're going to go over the ways that
you can turn a lot of the logging on.

00:36:40.210 --> 00:36:42.800
Another thing that's really
important when debugging networking

00:36:42.810 --> 00:36:44.120
problems is packet traces.

00:36:44.120 --> 00:36:46.770
It's really important to look
at what your application is

00:36:46.770 --> 00:36:48.460
actually putting on the network.

00:36:48.520 --> 00:36:51.620
Looking at that in a TCP dump
can be a real challenge.

00:36:51.630 --> 00:36:53.960
Fortunately there's a great
tool out there called TCP trace

00:36:54.010 --> 00:36:55.200
which we'll cover as well.

00:36:55.200 --> 00:36:58.500
One technique that can be
really useful for debugging is

00:36:58.580 --> 00:37:00.340
to have a TLS or SSL bypass.

00:37:00.340 --> 00:37:02.750
It's really important that if you put
this in you don't ship it because it

00:37:02.750 --> 00:37:04.940
can become a security vulnerability.

00:37:04.950 --> 00:37:07.360
But when you're looking at packet traces,
if you're looking at ciphertext,

00:37:07.360 --> 00:37:08.780
it can be really hard.

00:37:08.780 --> 00:37:11.060
But if you're looking at the clear text,
it can make things a lot more

00:37:11.060 --> 00:37:13.540
clear and easier to understand.

00:37:13.540 --> 00:37:16.930
Another issue you run into when
debugging networking applications

00:37:16.930 --> 00:37:21.510
is that the network environment that
you run on is probably a really nice,

00:37:21.510 --> 00:37:23.540
fast network with low latency.

00:37:23.540 --> 00:37:25.680
This is a pretty unrealistic experience.

00:37:25.680 --> 00:37:27.950
Our users are out there running
on more realistic networks

00:37:27.950 --> 00:37:31.080
that have very high latency,
they have very little bandwidth.

00:37:31.080 --> 00:37:33.430
They're running into all kinds
of problems that we don't

00:37:33.430 --> 00:37:34.620
run into on a daily basis.

00:37:34.620 --> 00:37:39.590
Fortunately we have some tools so you can
simulate the less... The more realistic,

00:37:39.670 --> 00:37:42.590
less performant networks so you can
make sure that your application will

00:37:42.780 --> 00:37:44.410
perform well in those environments.

00:37:44.590 --> 00:37:46.520
For CF network,
there's a lot of debugging that you can

00:37:46.520 --> 00:37:48.780
get... A lot of logging you can get.

00:37:48.830 --> 00:37:53.100
You can enable a CF network
diagnostic environment variable on

00:37:53.100 --> 00:37:57.960
OS X and that will force CF network
to log all of this information to

00:37:57.980 --> 00:38:00.650
the system log as well as a file.

00:38:01.530 --> 00:38:05.990
This is a log information related to
connecting and data flow if you're using

00:38:05.990 --> 00:38:11.310
CFSocketStream or NSURLConnection or
basically anything above CFSocketStream.

00:38:11.920 --> 00:38:14.950
If you set this to 1,
it includes a lot of internal CF network

00:38:14.950 --> 00:38:16.770
and event and state information.

00:38:16.960 --> 00:38:19.310
If you set it to 2,
it adds a bunch of information about

00:38:19.310 --> 00:38:22.670
how it decides to reuse existing
connections or establish new connections,

00:38:22.770 --> 00:38:25.400
if you're using the persistent
connections or pipelining.

00:38:25.430 --> 00:38:28.140
If you set this to 3,
it has a very powerful feature

00:38:28.140 --> 00:38:32.360
where it will actually log all
the TLS and SSL decrypted content.

00:38:32.440 --> 00:38:34.290
This can be really useful
for debugging problems,

00:38:34.290 --> 00:38:35.760
but it's also very dangerous.

00:38:35.880 --> 00:38:37.860
Be very careful about how you use this.

00:38:37.920 --> 00:38:40.330
A lot of times,
the things that are encrypted with

00:38:40.420 --> 00:38:43.600
TLS and SSL are done so for a reason,
and with this logging turned on,

00:38:43.600 --> 00:38:46.760
it'll end up going to the system log,
which anybody can get access to.

00:38:46.760 --> 00:38:49.260
So you need to be kind
of careful with this.

00:38:49.350 --> 00:38:53.170
You can set another environment variable,
CFNetworkIO_LOG_FILE,

00:38:53.230 --> 00:38:57.550
and that'll force all of the clear text
to get output to that file instead.

00:38:59.210 --> 00:39:01.140
If you're having trouble
establishing a connection,

00:39:01.140 --> 00:39:05.510
a lot of that work happens at
the lib system network layer.

00:39:05.590 --> 00:39:10.900
If you're using CF socket
stream or any of those things,

00:39:10.930 --> 00:39:14.680
all of that goes through something in lib
system network to establish connections.

00:39:14.680 --> 00:39:16.700
This is where the host name
to address resolution occurs,

00:39:16.710 --> 00:39:19.440
this is where all of our logic for
how we sort those addresses and

00:39:19.440 --> 00:39:22.550
when we decide to try and connect
to different addresses happens.

00:39:22.670 --> 00:39:25.760
You can enable the logging on
OS X by using a default write,

00:39:25.760 --> 00:39:28.670
you can disable it by
using the default delete,

00:39:28.860 --> 00:39:33.180
and then you can actually
display the logs using syslog -w.

00:39:33.180 --> 00:39:36.120
Another really important technique
is actually using TCP dump to

00:39:36.120 --> 00:39:38.220
look at your packet traces.

00:39:38.220 --> 00:39:40.730
We have a new feature in Mountain Lion,
with TCP dump you can show

00:39:40.730 --> 00:39:43.920
the process ID of the process
that generated the traffic.

00:39:43.920 --> 00:39:46.120
You can use the -k command to do that.

00:39:46.120 --> 00:39:50.230
If you're using -k with the -w option to
write all of the packets out to a file,

00:39:50.320 --> 00:39:53.340
you can run into some problems
as -k does use a new -w.

00:39:53.340 --> 00:39:53.420
If you're using -k with the -w option to
write all of the packets out to a file,

00:39:53.420 --> 00:39:53.520
you can run into some problems
as -k does use a new lib

00:39:53.520 --> 00:39:56.750
pcap next generation format,
which may not be compatible

00:39:56.750 --> 00:39:57.680
with other things.

00:39:57.710 --> 00:39:59.520
So be careful if you're using -k with -w.

00:39:59.520 --> 00:40:02.680
On the iOS we don't have a command line,
so there's no way to run tcpdump,

00:40:02.680 --> 00:40:05.300
but it's still really
important to get packet traces.

00:40:05.300 --> 00:40:08.060
Fortunately, we have something called
remote packet capture.

00:40:08.060 --> 00:40:10.140
If you have the developer
tools installed,

00:40:10.140 --> 00:40:13.750
you can hook up an iOS
device using USB to your Mac,

00:40:13.750 --> 00:40:18.180
and you can create a virtual
interface for capturing packets.

00:40:18.280 --> 00:40:21.330
You do this using rvicontrol -s,
and you pass in the

00:40:21.330 --> 00:40:23.000
UDID of the iOS device.

00:40:23.000 --> 00:40:26.010
This will create a virtual
interface like rvi0,

00:40:26.010 --> 00:40:27.850
which you can run tcpdump on.

00:40:27.850 --> 00:40:32.090
tcpdump will then show you all of the
IPv4 and IPv6 packets going in and out of

00:40:32.140 --> 00:40:34.390
all of the interfaces on that iOS device.

00:40:34.390 --> 00:40:36.760
When you're all done,
you can use rvicontrol

00:40:36.760 --> 00:40:39.230
-x and pass in the UDID,
and it will tear down

00:40:39.230 --> 00:40:40.550
the virtual interface.

00:40:40.560 --> 00:40:44.000
When you're using tcpdump,
by default it will output a summary

00:40:44.000 --> 00:40:46.660
of each packet to the standard out.

00:40:46.660 --> 00:40:50.990
You can also have it write to a file
instead of outputting the packets.

00:40:50.990 --> 00:40:52.560
You can use the -w option to do so.

00:40:52.570 --> 00:40:56.360
And then that packet file can
be used for later analysis or

00:40:56.430 --> 00:40:58.540
to be passed into tcp trace.

00:40:58.550 --> 00:41:01.440
tcp trace is a fantastic
open source tool.

00:41:01.440 --> 00:41:02.660
You can download a copy.

00:41:02.700 --> 00:41:03.880
It builds fine on OS X.

00:41:03.880 --> 00:41:06.750
It comes from tcptrace.org.

00:41:06.920 --> 00:41:09.500
With TCP Trace,
we're going to capture packets using

00:41:09.500 --> 00:41:13.310
tcpdump and we're going to use -w to
save all those packets into a file.

00:41:13.420 --> 00:41:17.390
We're going to create xpl or xplot
files using TCP Trace from that

00:41:17.390 --> 00:41:19.980
packet trace file that we created.

00:41:19.980 --> 00:41:24.320
If you have just TCP packets,
you can run tcptrace -g and

00:41:24.320 --> 00:41:26.440
pass in the packet file.

00:41:26.440 --> 00:41:29.720
If you have HTTP traffic that
isn't encrypted using TLS or SSL,

00:41:29.720 --> 00:41:33.280
there's a really nice module
in TCP Trace called XHTTP.

00:41:33.280 --> 00:41:36.940
This will actually do some
analysis on the HTTP connections

00:41:36.940 --> 00:41:39.920
and it'll show you if you have a
persistent connection or pipelining,

00:41:39.920 --> 00:41:42.770
it'll break things down by each
connection and show you when requests

00:41:42.900 --> 00:41:45.920
go out and when responses come
back on each of those connections.

00:41:45.920 --> 00:41:47.240
It's really useful.

00:41:47.240 --> 00:41:49.560
When you run this tool,
it'll spit out the xpl files that

00:41:49.560 --> 00:41:52.360
you can then open in jplot or xplot.

00:41:52.870 --> 00:41:57.540
Finally, it's really important to test on
realistic network environments.

00:41:57.540 --> 00:42:01.300
The network link conditioner
is available on Mac OS X.

00:42:01.300 --> 00:42:01.300
If you download the link conditioner,
you can test it on any

00:42:01.300 --> 00:42:01.300
network environment.

00:42:01.300 --> 00:42:04.400
If you download the hardware I/O tools
for Xcode from developer.apple.com,

00:42:04.420 --> 00:42:08.060
there will be a network system
preference pane in the disk image.

00:42:08.220 --> 00:42:10.180
You double click on that,
it installs itself.

00:42:10.180 --> 00:42:13.190
You can turn it on and you can
simulate network environments that

00:42:13.320 --> 00:42:14.280
are worse than your current one.

00:42:14.280 --> 00:42:16.460
Unfortunately, you can't simulate better
network environments.

00:42:16.460 --> 00:42:18.140
We're still working on that.

00:42:18.140 --> 00:42:20.630
On iOS,
we have a new feature in iOS 6 where you

00:42:20.700 --> 00:42:22.890
can actually enable this on the device.

00:42:22.890 --> 00:42:25.710
If you enable your device
for development in Xcode,

00:42:25.720 --> 00:42:28.490
on the device,
you can go into settings under developer,

00:42:28.500 --> 00:42:31.240
there should be a network
link conditioner item.

00:42:31.240 --> 00:42:31.240
You can use it to run a
network link conditioner.

00:42:31.240 --> 00:42:33.740
You can use that to turn the
network link conditioner on and off.

00:42:33.740 --> 00:42:35.350
And you can set what kind of
network you want to simulate.

00:42:37.000 --> 00:44:04.600
[Transcript missing]

00:44:06.490 --> 00:44:08.370
There are some related sessions.

00:44:08.400 --> 00:44:12.280
The next session in this room is
simplifying networking with Bonjour.

00:44:12.360 --> 00:44:14.700
The best way to discover network
services is using Bonjour,

00:44:14.700 --> 00:44:17.360
and they're going to go over the best
practices for using Bonjour and talk

00:44:17.360 --> 00:44:19.030
about some cool technologies there.

00:44:19.130 --> 00:44:22.160
So as a quick summary,
go ahead and use TCP.

00:44:22.160 --> 00:44:24.270
It provides a lot of great services.

00:44:24.370 --> 00:44:27.830
Be sure to reuse
existing TCP connections.

00:44:28.280 --> 00:44:31.740
Try and perform multiple
concurrent requests on a single

00:44:31.740 --> 00:44:33.600
connection where you can.

00:44:33.600 --> 00:44:37.260
This lets you take advantage of
fast retransmits and hide latency.

00:44:37.290 --> 00:44:40.160
Be sure to make sure that
you support SOCKS proxies.

00:44:40.160 --> 00:44:43.370
If you're using HTTP,
make sure that you're using

00:44:43.370 --> 00:44:44.960
pipelining everywhere you can.

00:44:44.960 --> 00:44:47.870
Make sure that you're also
supporting SOCKS and HTTP proxies.

00:44:47.880 --> 00:44:49.830
Thank you very much.