WEBVTT

00:00:10.560 --> 00:00:13.260
Good afternoon, everyone.

00:00:13.260 --> 00:00:15.700
Welcome to session 505.

00:00:15.700 --> 00:00:16.920
My name is Torrey.

00:00:17.040 --> 00:00:19.050
I'm an engineer in the core audio team.

00:00:19.220 --> 00:00:24.420
And today I'll be talking with you about
audio session and multi route audio.

00:00:24.420 --> 00:00:27.480
Now, for those of you who have
written an application before

00:00:27.550 --> 00:00:31.040
that plays or records audio,
some of the information that

00:00:31.040 --> 00:00:34.400
I cover today about audio
session may seem familiar to you.

00:00:34.420 --> 00:00:38.570
However, there are a number of important
changes as well as some new

00:00:38.570 --> 00:00:42.180
functionality we think you're
going to want to take advantage of.

00:00:42.250 --> 00:00:45.100
And for those of you new to this,
welcome.

00:00:45.100 --> 00:00:49.620
This session will give you a basic
overview of using audio effectively

00:00:49.780 --> 00:00:53.460
on iOS and also will capitalize
on some new features that will

00:00:53.460 --> 00:00:55.740
really make your application sing.

00:00:56.370 --> 00:01:00.340
First, I'll give you an idea of how
this session is structured.

00:01:00.340 --> 00:01:05.160
We'll start with kind of a 30,000 foot
view of audio session before we drill

00:01:05.160 --> 00:01:09.930
down and look into the code to see what
it takes to configure the audio session.

00:01:10.280 --> 00:01:14.020
We'll take a moment to look at
the anatomy of an audio route

00:01:14.480 --> 00:01:17.810
and what it takes to handle
route change notifications.

00:01:18.640 --> 00:01:23.800
Then we'll talk about one of the
Objective-C APIs you can use,

00:01:23.980 --> 00:01:25.380
AV Audio Player.

00:01:25.680 --> 00:01:28.100
And during this talk,
we'll talk about the state

00:01:28.100 --> 00:01:32.970
of multichannel audio on iOS,
as well as how you can select

00:01:33.090 --> 00:01:35.710
channels for input and output now.

00:01:36.250 --> 00:01:39.200
Then we'll move on to the
all-new MultiRoute category,

00:01:39.200 --> 00:01:41.200
new to iOS 6.

00:01:41.380 --> 00:01:46.510
And then we'll wrap up the talk with a
discourse on using I/O units in various

00:01:46.510 --> 00:01:49.200
types of applications with Audio Session.

00:01:49.200 --> 00:01:52.190
So, what is Audio Session?

00:01:52.500 --> 00:01:56.570
Audio Session is a managed
audio experience on iOS.

00:01:56.720 --> 00:01:59.880
Now let's face it,
people use their devices everywhere.

00:01:59.880 --> 00:02:05.380
When they're hiking, at nightclubs,
in their cars, in the bathroom.

00:02:05.470 --> 00:02:08.460
Some of you are probably
using your devices now.

00:02:08.660 --> 00:02:13.610
And users have expectations as
to how the system behaves with

00:02:13.720 --> 00:02:17.520
respect to the hardware controls,
like the volume up and

00:02:17.820 --> 00:02:22.100
volume down buttons,
the ringer switch, the lock button,

00:02:22.190 --> 00:02:27.280
and how the system behaves when
you plug in or unplug headphones.

00:02:27.830 --> 00:02:30.660
So there's also a number of
different devices that are

00:02:30.660 --> 00:02:31.660
available on the market now.

00:02:31.660 --> 00:02:34.200
There are iPads, there are iPhones,
iPod touches,

00:02:34.200 --> 00:02:35.920
and there are numerous software updates.

00:02:35.920 --> 00:02:40.080
What you want to do is choose the
right APIs to communicate what

00:02:40.080 --> 00:02:42.330
your app wants to do with audio.

00:02:42.380 --> 00:02:46.250
When I say a managed audio experience,
I don't mean that we give

00:02:46.260 --> 00:02:50.120
you access to every knob,
switch, and dial in the system.

00:02:50.960 --> 00:02:54.510
On the contrary,
this allows you to opt in to a number

00:02:54.550 --> 00:02:59.440
of specific audio behaviors so you
don't have to reinvent the wheel.

00:02:59.780 --> 00:03:03.100
So,
we'll focus on the audio user experience.

00:03:03.150 --> 00:03:05.540
And by that,
what I mean is we'll make your

00:03:05.540 --> 00:03:09.900
app sounds behave the way that
users expect them to behave,

00:03:09.910 --> 00:03:15.270
and also consistent with the applications
that are already installed on the device.

00:03:15.620 --> 00:03:19.960
The way we'll do that is first
you'll categorize your application,

00:03:20.200 --> 00:03:23.180
you'll respond to any
interruptions that can occur,

00:03:23.260 --> 00:03:26.240
and you'll deal with
any audio route changes.

00:03:26.300 --> 00:03:28.250
Okay, let's get started.

00:03:28.340 --> 00:03:31.460
When I say audio session,
I am referring to the

00:03:31.460 --> 00:03:35.330
AV Audio Session Objective-C API,
which is part of the

00:03:35.330 --> 00:03:36.940
AV Foundation Framework.

00:03:37.010 --> 00:03:41.140
This API contains all audio
session functionality.

00:03:41.150 --> 00:03:44.820
And to use audio session,
there are five tasks that

00:03:44.890 --> 00:03:46.790
you'll need to execute.

00:03:47.040 --> 00:03:51.580
First, you'll set up the session and
you'll register for notifications.

00:03:51.660 --> 00:03:54.740
Second, you'll choose and set a category.

00:03:54.810 --> 00:03:57.940
Optionally,
you can choose and set a mode.

00:03:58.040 --> 00:04:01.170
Third, you'll make your session active.

00:04:02.190 --> 00:04:04.200
Fourth, you'll handle any interruptions.

00:04:04.200 --> 00:04:09.320
And fifth,
you'll deal with any audio route changes.

00:04:09.320 --> 00:04:11.850
All right, talk, talk, talk.

00:04:11.950 --> 00:04:12.760
Let's see some code, right?

00:04:14.830 --> 00:04:17.880
The AVAudioSession instance
is a global shared instance.

00:04:18.100 --> 00:04:22.630
You can retrieve it by using the class
method shared instance that will give you

00:04:22.630 --> 00:04:25.190
a pointer to the AVAudioSession object.

00:04:25.860 --> 00:04:28.710
Next you want to register
for notifications.

00:04:28.710 --> 00:04:31.750
There's an example here on
this slide of how to do that.

00:04:32.460 --> 00:04:34.900
In this example,
we're registering for AV audio

00:04:34.920 --> 00:04:39.910
session interruption notification,
so we'll know when we're getting

00:04:39.910 --> 00:04:42.360
interrupted in our session.

00:04:42.420 --> 00:04:45.710
Next, we'll choose and set a category.

00:04:46.870 --> 00:04:50.600
Categories have a variety of
different rules and behaviors

00:04:50.600 --> 00:04:53.720
associated with a category,
and you'll choose category

00:04:53.720 --> 00:04:57.960
based on how you intend to
use audio in your application.

00:04:58.020 --> 00:05:01.800
This may involve management of things
such as whether playback is allowed,

00:05:01.960 --> 00:05:05.580
whether recording is allowed,
whether or not your application's

00:05:05.670 --> 00:05:09.630
audio is allowed to mix with audio
played by other applications,

00:05:09.630 --> 00:05:13.480
and how the audio behaves when the
ringer switch is set to silent.

00:05:13.760 --> 00:05:18.480
There's also a brand new category
in iOS 6 called MultiRoute.

00:05:18.610 --> 00:05:22.400
We'll be discussing this in
detail later in the session.

00:05:22.550 --> 00:05:24.410
Back to the code.

00:05:25.220 --> 00:05:27.900
To set your category,
you'll send the message "Set

00:05:28.050 --> 00:05:30.540
Category" to the session object.

00:05:30.540 --> 00:05:32.790
In this example,
we're using play and record,

00:05:32.910 --> 00:05:37.100
so we'll be setting
AVAudioSessionCategoryPlayAndRecord.

00:05:37.100 --> 00:05:40.900
And ordinarily,
we deal with errors if there were any.

00:05:41.800 --> 00:05:44.700
Next, you can optionally set a mode.

00:05:44.780 --> 00:05:48.830
A mode is a way for a third-party
application to declare the

00:05:48.970 --> 00:05:52.840
class of that application,
so that it's treated like other

00:05:52.840 --> 00:05:55.070
applications in that class.

00:05:55.610 --> 00:05:59.490
Here we have voice chat, video recording,
measurement for people

00:05:59.500 --> 00:06:03.400
who want the rawest,
unprocessed audio data possible.

00:06:03.470 --> 00:06:07.380
Default is the behavior you'll
get if you don't specify a mode.

00:06:07.580 --> 00:06:11.200
And then there's a new mode in
iOS 6 called Movie Playback.

00:06:11.270 --> 00:06:15.350
As you might be able to guess,
Movie Playback will optimize the dynamics

00:06:15.410 --> 00:06:21.400
of video content for applications whose
primary purpose is playing movies.

00:06:21.460 --> 00:06:26.390
And modes and categories work together
to communicate how you're going

00:06:26.390 --> 00:06:28.490
to use audio in your application.

00:06:28.630 --> 00:06:30.000
Okay, the code for the mode.

00:06:30.020 --> 00:06:31.910
Ooh, that's a poem.

00:06:32.920 --> 00:06:35.630
This time we're going to set
the video recording mode.

00:06:35.750 --> 00:06:39.560
We can do that by sending the message
"Set Mode" to the session object with

00:06:39.560 --> 00:06:43.100
"AV Audio Session Mode Video Recording."

00:06:43.850 --> 00:06:46.390
We're now ready to make
our session active,

00:06:46.390 --> 00:06:51.600
which we can do by sending the message
"Set Active" "Yes" to the session object.

00:06:51.830 --> 00:06:54.550
And now we can configure
our AV audio player,

00:06:54.650 --> 00:06:59.020
our audio queue, our AU remote I/O,
whichever API we're going to be

00:06:59.020 --> 00:07:01.740
using to play or record audio.

00:07:02.880 --> 00:07:06.560
Okay, let's talk about
interruptions for a second.

00:07:06.620 --> 00:07:10.780
Your audio session may be
interrupted by higher priority audio,

00:07:10.890 --> 00:07:15.300
something like an incoming
phone call or a clock alarm.

00:07:15.330 --> 00:07:19.700
And when this happens,
your session will be made inactive.

00:07:19.880 --> 00:07:23.050
Now, this isn't a polite request
to say from the system saying,

00:07:23.150 --> 00:07:26.550
"Hey, can I play that cool little
video game Ringtone for a

00:07:26.550 --> 00:07:29.500
second if you'll just stop?" No,
priority has already

00:07:29.510 --> 00:07:31.670
been taken away from you,
and that's why it's

00:07:31.670 --> 00:07:33.180
called an interruption.

00:07:33.240 --> 00:07:35.910
So you want to be able to deal with this.

00:07:36.100 --> 00:07:40.500
After the interruption is over,
depending on the API that you're

00:07:40.610 --> 00:07:44.240
using to play or record audio,
you may need to reactivate

00:07:44.250 --> 00:07:47.290
a certain state,
and you may also want to reactivate

00:07:47.290 --> 00:07:51.560
the session if that's appropriate
for your type of application.

00:07:52.300 --> 00:07:55.070
The way you'll deal with
notifications is you'll get notified

00:07:55.070 --> 00:07:59.400
by registering for AV Audio Session
Interruption Notification.

00:08:00.880 --> 00:08:02.350
If you've dealt with
notifications before,

00:08:02.360 --> 00:08:05.040
this one has a user info dictionary,
which has two keys.

00:08:05.040 --> 00:08:09.110
The first key...

00:08:10.070 --> 00:08:13.100
is the type of interruption
that you received.

00:08:13.160 --> 00:08:16.990
There are two of these:
type began and type ended.

00:08:16.990 --> 00:08:22.140
And then the second key is AV audio
session interruption option key.

00:08:22.190 --> 00:08:24.740
It only applies to type ended.

00:08:24.790 --> 00:08:27.680
And if you have this option,
it will be AV audio session

00:08:27.680 --> 00:08:32.660
interruption options should resume,
which lets you know if it's okay to

00:08:32.660 --> 00:08:35.800
resume playback or recording of audio.

00:08:36.000 --> 00:08:38.350
A little more about these notifications.

00:08:39.770 --> 00:08:42.380
For AV audio session
interruption type began,

00:08:42.380 --> 00:08:44.260
that means that your audio
has already been stopped,

00:08:44.370 --> 00:08:45.860
you're already inactive.

00:08:45.860 --> 00:08:48.940
This is an opportunity
for you to change your UI,

00:08:48.940 --> 00:08:52.160
maybe by converting a play
button to a stop button,

00:08:52.160 --> 00:08:55.290
or graying something out to say
that you're not playing anymore.

00:08:55.340 --> 00:09:01.680
And this is a good time to point out that
not every type began notification has a

00:09:01.900 --> 00:09:04.900
corresponding type ended notification.

00:09:04.900 --> 00:09:08.430
This actually depends on what
actually interrupted your audio.

00:09:09.210 --> 00:09:11.500
For example,
the user's using your application,

00:09:11.500 --> 00:09:13.170
there's an incoming phone call.

00:09:13.180 --> 00:09:16.200
If the user decides to
take that phone call,

00:09:16.200 --> 00:09:19.550
you will not get a type ended
notification when they're done talking.

00:09:19.560 --> 00:09:24.760
However, if the user decides to let
that same call go to voicemail,

00:09:24.760 --> 00:09:27.300
you will get the type ended notification.

00:09:27.300 --> 00:09:31.000
This is an opportunity for you to
make your session active again.

00:09:31.000 --> 00:09:33.490
You can update your user interface.

00:09:33.500 --> 00:09:38.160
And if AV audio session
interruption option should resume,

00:09:38.560 --> 00:09:40.650
it's part of that dictionary,
it's okay for you to

00:09:40.740 --> 00:09:41.990
start playing audio again.

00:09:42.040 --> 00:09:45.410
This is one more notification
that we've added to iOS 6 that

00:09:45.410 --> 00:09:46.480
I want to let you know about.

00:09:46.700 --> 00:09:50.920
And it is AV audio session media
services were reset notification.

00:09:50.920 --> 00:09:52.730
Try saying that five times fast.

00:09:55.020 --> 00:09:58.500
So, if the media server goes
down for any reason,

00:09:58.500 --> 00:10:00.700
this is the notification that will fire.

00:10:01.220 --> 00:10:06.140
There's no user info dictionary for this,
and any objects that you are using

00:10:06.140 --> 00:10:11.300
to play or record audio are now
invalidated and they are zombies.

00:10:11.370 --> 00:10:14.600
So we don't want a zombie
apocalypse on your device.

00:10:14.750 --> 00:10:17.300
Please kill your zombies.

00:10:17.350 --> 00:10:19.860
The proper way to handle
this notification is to

00:10:19.910 --> 00:10:21.770
fully reconfigure your audio.

00:10:23.070 --> 00:10:25.300
Okay, let's talk about route changes.

00:10:25.430 --> 00:10:30.120
Users expect a behavior that we like
to call "last-in wins." What that

00:10:30.120 --> 00:10:34.070
means is your audio route is completely
determined by the last thing to be

00:10:34.070 --> 00:10:36.700
plugged in or unplugged into the system.

00:10:36.800 --> 00:10:40.210
For example, if someone is playing audio
out of a device and they

00:10:40.210 --> 00:10:44.060
plug in a set of headphones,
the user would expect the audio to

00:10:44.060 --> 00:10:49.100
be rerouted to the headphones and
to continue playing without pause.

00:10:49.200 --> 00:10:52.900
However, if they were to detach that
same set of headphones,

00:10:53.030 --> 00:10:55.660
they would expect the audio
to be rerouted to wherever

00:10:55.700 --> 00:10:58.900
it was playing before,
in this case, the built-in speaker,

00:10:58.960 --> 00:11:02.190
and for the audio to
pause in this situation.

00:11:03.910 --> 00:11:07.720
If there is a new route en route,
you will get AV Audio Session

00:11:07.720 --> 00:11:09.810
Route Change Notification.

00:11:10.150 --> 00:11:14.360
The user info dictionary for
this notification has two keys.

00:11:14.450 --> 00:11:18.840
The first is
AVAudioSessionRouteChangeReasonKey.

00:11:18.880 --> 00:11:21.140
This will tell you the reason
that that route change occurred.

00:11:21.410 --> 00:11:24.940
Could be something like there was
a new device that came online,

00:11:24.990 --> 00:11:27.210
or the category change.

00:11:27.730 --> 00:11:30.690
Next is the previous route key,
where it will give you

00:11:30.700 --> 00:11:32.100
back the previous route.

00:11:32.300 --> 00:11:35.100
And that is of type
AVAudioSessionRouteDescription.

00:11:35.100 --> 00:11:38.540
We're actually going to look at
the anatomy of that right now.

00:11:38.780 --> 00:11:42.710
So, inside querying the route,
you can actually get the route

00:11:42.810 --> 00:11:46.300
by sending the message current
route to the session object.

00:11:46.330 --> 00:11:49.560
This gives you an AV audio session
route description with detailed

00:11:49.560 --> 00:11:53.080
information about that device,
specifically a collection

00:11:53.150 --> 00:11:57.030
of inputs and outputs,
both of type AV audio

00:11:57.030 --> 00:11:59.930
session port description.

00:12:00.010 --> 00:12:01.800
So what's a port?

00:12:01.980 --> 00:12:07.590
A port is a single input
or output on a device.

00:12:08.780 --> 00:12:11.260
This port description has
four different properties.

00:12:11.350 --> 00:12:13.740
The first is the port type,
something like

00:12:14.290 --> 00:12:17.060
AVAudioSessionPortHeadphones.

00:12:17.150 --> 00:12:19.080
The second property is the port name.

00:12:19.240 --> 00:12:22.320
This is a human-readable
and localizable string,

00:12:22.400 --> 00:12:25.400
such as line out or headphones.

00:12:25.750 --> 00:12:28.680
There it is, the UID,
that's short for unique identifier.

00:12:28.820 --> 00:12:33.600
This is a system assigned
string that identifies the port.

00:12:33.630 --> 00:12:36.770
And finally,
there is an array of channels.

00:12:36.950 --> 00:12:40.410
which are of type AV Audio Session
Channel Description.

00:12:40.410 --> 00:12:42.080
So what's that look like?

00:12:42.760 --> 00:12:44.950
AV Audio Session Channel Description.

00:12:44.990 --> 00:12:48.260
Well, the channel descriptions are
just a description of a single

00:12:48.300 --> 00:12:50.170
channel on one of those ports.

00:12:50.240 --> 00:12:54.040
So, to give you an idea again,
we've got the route description,

00:12:54.170 --> 00:12:57.800
which has inputs and outputs,
which are ports,

00:12:57.820 --> 00:13:00.870
and each of those ports has channels.

00:13:01.230 --> 00:13:03.180
Now for these channels,
they have three properties.

00:13:03.180 --> 00:13:04.940
The first is the channel name.

00:13:04.940 --> 00:13:10.310
It's a human readable string,
like headphone left or headphone right.

00:13:11.260 --> 00:13:12.860
Next, there's the Owning Port UID.

00:13:12.860 --> 00:13:15.760
That's the unique identifier from
before in the port description.

00:13:17.650 --> 00:13:21.510
And finally, there's a channel number,
which is a one-based index into

00:13:21.540 --> 00:13:24.700
the array of channels on that port.

00:13:26.300 --> 00:13:28.440
And that's what you need to
know to use audio session.

00:13:28.540 --> 00:13:32.660
First, you'll set up the session,
you'll register for notifications.

00:13:32.790 --> 00:13:35.680
Second,
you'll categorize your application.

00:13:35.850 --> 00:13:37.840
You can also set a mode.

00:13:38.270 --> 00:13:40.640
Third, you'll make your session active.

00:13:40.800 --> 00:13:43.500
Fourth, you'll handle interruptions.

00:13:43.590 --> 00:13:46.850
And fifth,
you'll deal with any route changes.

00:13:46.950 --> 00:13:49.170
Now for those of you who
have written applications

00:13:49.170 --> 00:13:51.680
before and used audio session,
you may notice that a lot of

00:13:51.680 --> 00:13:54.230
this sounds different from
what you were doing before.

00:13:54.350 --> 00:13:57.270
The reason why is because
there's no more mix and match.

00:13:57.440 --> 00:14:01.020
The audio session services
C API has been deprecated.

00:14:01.110 --> 00:14:06.950
So you'll now want to move your apps over
to using the Objective-C API exclusively,

00:14:06.950 --> 00:14:08.260
AVAudioSession.

00:14:08.310 --> 00:14:11.890
But all the functionality
from the C API is there.

00:14:12.260 --> 00:14:14.500
A few more changes to let you know about.

00:14:14.540 --> 00:14:17.640
AV Audio Session Delegate
has been deprecated.

00:14:17.680 --> 00:14:20.510
Now remember we register
for notifications with

00:14:20.570 --> 00:14:22.180
NS Notification Center.

00:14:22.670 --> 00:14:26.440
Also, some of the properties have been
deprecated and renamed so that naming

00:14:26.440 --> 00:14:28.040
is consistent across the board.

00:14:29.860 --> 00:14:33.340
Now let's take a look at one
audio playback API we can use,

00:14:33.340 --> 00:14:34.570
AVAudioPlayer.

00:14:34.570 --> 00:14:36.900
If you want to get your app
up and running in a hurry and

00:14:36.900 --> 00:14:38.870
just playing an audio file,
AVAudioPlayer may be

00:14:38.870 --> 00:14:39.840
a good choice for you.

00:14:39.880 --> 00:14:42.840
It plays a number of
different audio file formats.

00:14:42.840 --> 00:14:45.870
It has the transport controls
that you would expect,

00:14:45.870 --> 00:14:47.900
play, pause, seek, and stop.

00:14:47.980 --> 00:14:50.940
If you want to play more than
one audio file at a time,

00:14:50.940 --> 00:14:51.810
that's easy.

00:14:51.810 --> 00:14:54.650
Just create multiple
AVAudioPlayer objects.

00:14:55.890 --> 00:14:59.990
And it supports volume, panning, looping,
and rate control,

00:15:00.000 --> 00:15:04.800
which is the speed at which
the audio file is played back.

00:15:04.960 --> 00:15:07.790
So if we wanted to create
one of these in code,

00:15:07.850 --> 00:15:10.400
we can do that using a file URL.

00:15:10.400 --> 00:15:14.940
In this example, we've supplied a URL,
we're allocating a player,

00:15:14.940 --> 00:15:19.290
and then we're initializing it
with the contents of that URL.

00:15:20.660 --> 00:15:25.340
and now new to iOS 6, finally,
you can play a file

00:15:25.340 --> 00:15:27.600
from the music library.

00:15:27.890 --> 00:15:31.960
The way you do this is you obtain a
reference to the MP Media item object

00:15:32.440 --> 00:15:33.800
from the device's music library.

00:15:33.800 --> 00:15:37.230
This is something that you can get from,
say, MP Media Picker Controller.

00:15:38.970 --> 00:15:41.540
In this example, we've got a media URL.

00:15:41.600 --> 00:15:45.460
Our MP Media Item object
is My Media Item.

00:15:45.520 --> 00:15:48.840
We'll get the URL for that,
and we'll allocate our player

00:15:49.040 --> 00:15:51.030
and initialize it with that URL.

00:15:51.380 --> 00:15:53.200
How about interruptions?

00:15:53.260 --> 00:15:56.890
Before, when I talked about
interruptions in audio session,

00:15:56.950 --> 00:15:59.560
I said you can register for
interruption notifications,

00:15:59.630 --> 00:16:00.420
and you should do that.

00:16:00.570 --> 00:16:04.550
However, if you're using AV Audio Player,
you can get by with using

00:16:04.550 --> 00:16:06.160
the delegate methods.

00:16:07.250 --> 00:16:11.000
They are completely analogous to
the interruption notifications

00:16:11.040 --> 00:16:12.210
from audio session.

00:16:12.340 --> 00:16:15.700
Here we have audio player
begin interruption.

00:16:15.700 --> 00:16:18.940
Like before,
this means playback has already stopped.

00:16:18.960 --> 00:16:19.950
You're already inactive.

00:16:20.130 --> 00:16:24.260
This is an opportunity for you to update
your UI to say you're not playing.

00:16:24.470 --> 00:16:28.480
And, once again,
you're not guaranteed to get this call.

00:16:28.730 --> 00:16:31.040
It depends on the type of notification.

00:16:31.100 --> 00:16:34.960
But there is an interruption,
and it also has the option

00:16:34.960 --> 00:16:38.880
AV Audio Session Interruption
option should resume.

00:16:38.920 --> 00:16:41.040
You update your user
interface at this point,

00:16:41.170 --> 00:16:43.460
and depending on whether
or not you have that flag,

00:16:43.500 --> 00:16:46.090
it's okay to resume playback.

00:16:47.310 --> 00:16:52.080
Let's talk about the state of
multi-channel audio on iOS.

00:16:52.120 --> 00:16:57.500
Specifically, when are you going to have
access to more than two channels?

00:16:57.900 --> 00:17:01.300
With USB, from iOS 5,
you've been able to access

00:17:01.400 --> 00:17:02.840
more than two channels.

00:17:02.960 --> 00:17:07.420
If you have a USB audio class
compliant device plugged into the

00:17:07.420 --> 00:17:10.080
camera connection kit of an iPad.

00:17:10.630 --> 00:17:15.080
Beginning with iOS 6,
you now have access to more than

00:17:15.120 --> 00:17:18.330
two channels for USB output as well.

00:17:18.450 --> 00:17:20.880
Now, with all these channels,
you may wonder,

00:17:20.880 --> 00:17:22.780
"Does that mean that I have to
do something special with my

00:17:22.780 --> 00:17:26.020
application?" Not necessarily,
but you should know what

00:17:26.090 --> 00:17:27.590
the default behavior is.

00:17:27.730 --> 00:17:33.230
If you decide to play stereo content,
and the currently selected route has

00:17:33.230 --> 00:17:36.080
more than two channels available,
it will play out of

00:17:36.080 --> 00:17:37.740
the first two channels.

00:17:37.860 --> 00:17:39.080
The same is true for mono.

00:17:39.120 --> 00:17:42.530
If you play back a mono file,
it will play the same mono

00:17:42.970 --> 00:17:45.660
data to the first two channels.

00:17:45.780 --> 00:17:48.580
However, if you're recording,
it will record from

00:17:48.620 --> 00:17:50.450
the first channel only.

00:17:50.820 --> 00:17:52.620
Now,
if these are not the channels you want,

00:17:52.820 --> 00:17:57.400
you'll want to use something we've added
to iOS that we call channel selection.

00:17:58.290 --> 00:18:01.030
You can choose the inputs and
outputs that you want to use.

00:18:01.130 --> 00:18:04.440
And the way you'll do that is
you'll set an array of AV audio

00:18:04.440 --> 00:18:06.240
session channel descriptions.

00:18:06.350 --> 00:18:08.960
Remember when we examined what
a route looked like earlier?

00:18:09.200 --> 00:18:11.600
It started with the
input and output ports,

00:18:11.690 --> 00:18:15.100
and then there were channels
associated with each of those ports.

00:18:15.200 --> 00:18:18.150
So you'll select an array of
those that you want to use and

00:18:18.150 --> 00:18:19.720
assign those to the object.

00:18:19.810 --> 00:18:23.040
And I'll show you how to do this in
code a little later in the session.

00:18:23.050 --> 00:18:27.390
You can use this with both
AV Audio Player and AV Audio Recorder.

00:18:27.470 --> 00:18:30.130
And there are congruent
channel selection methods for

00:18:30.600 --> 00:18:33.330
Audio Queue and AU Remote I/O.

00:18:33.720 --> 00:18:37.840
It also turns out this is not the only
way that you can get multi-channel

00:18:37.840 --> 00:18:40.300
audio on an iOS device now.

00:18:40.370 --> 00:18:44.540
I'd like to introduce you to
something we call MultiRoute Category.

00:18:45.310 --> 00:18:49.440
Remember when I talked to you earlier
about the behavior last in wins?

00:18:49.560 --> 00:18:52.060
That means the audio route is
completely determined by what

00:18:52.060 --> 00:18:53.880
was last plugged into the system.

00:18:54.050 --> 00:18:56.070
Take a look at this diagram.

00:18:57.160 --> 00:19:00.100
We've got headphones plugged
into the headphone port.

00:19:00.150 --> 00:19:04.030
And we've got a USB 2 in,
2 out device plugged into the camera

00:19:04.090 --> 00:19:06.950
connector kit in the bottom of the iPad.

00:19:07.360 --> 00:19:11.070
From simply looking at this diagram,
you don't necessarily know where

00:19:11.070 --> 00:19:14.240
your audio is going to or from,
and that's because you don't know

00:19:14.240 --> 00:19:15.360
the order they were plugged in.

00:19:15.400 --> 00:19:20.730
But you're going to get one or the other,
and that's the end of the story.

00:19:22.090 --> 00:19:25.230
So Last In Winds is still
the paradigm on iOS,

00:19:25.230 --> 00:19:30.400
but there is one new exception to it,
and that's called MultiRoute Category.

00:19:30.440 --> 00:19:35.780
When you set MultiRoute Category,
that same setup from before now

00:19:35.780 --> 00:19:39.790
appears as a single MultiRoute device.

00:19:40.070 --> 00:19:42.610
So now we have three inputs.

00:19:42.890 --> 00:19:47.540
That is the iPad built-in
microphone and the two USB inputs

00:19:47.600 --> 00:19:49.720
from the USB audio device.

00:19:49.850 --> 00:19:52.110
And now we have four outputs.

00:19:52.330 --> 00:19:59.730
That's headphone left, headphone right,
USB output 1, and USB output 2.

00:20:00.310 --> 00:20:04.000
Essentially from using two
very simple stereo devices,

00:20:04.000 --> 00:20:06.810
we're now in a multi-channel environment.

00:20:07.460 --> 00:20:10.460
I'd like to invite my colleague
Harry to the stage to give you a

00:20:10.480 --> 00:20:14.900
demonstration of how using MultiRoute
Category can work in your app.

00:20:15.030 --> 00:20:16.060
Harry?

00:20:16.190 --> 00:20:17.400
Hello, everyone.

00:20:17.560 --> 00:20:21.890
I now want to give a demonstration of an
application that uses the new MultiRoute

00:20:21.930 --> 00:20:24.930
Category with AV Audio Session.

00:20:25.340 --> 00:20:29.270
This application consists of four
instances of AV Audio Player,

00:20:29.340 --> 00:20:32.780
each of which has its own volume slider,
select channel button,

00:20:32.810 --> 00:20:36.590
select track button, play button,
and stop button.

00:20:36.710 --> 00:20:40.710
For the purpose of this demonstration,
we're going to play back four preselected

00:20:40.710 --> 00:20:47.030
audio files through the HDMI outputs
and headphone outputs simultaneously.

00:20:47.310 --> 00:20:49.090
Before we get to that part of the demo,
though,

00:20:49.100 --> 00:20:52.520
let me show you how you can use the
Select Channel button to configure an

00:20:52.520 --> 00:20:58.170
AV Audio Player instance at runtime
to play audio out a selected port.

00:20:59.390 --> 00:21:04.090
In this example here,
we have HDMI ports and headphone ports.

00:21:04.090 --> 00:21:06.300
So we can output audio
through the headphone left,

00:21:06.360 --> 00:21:10.300
headphone right, HDMI output one,
HDMI output two.

00:21:10.370 --> 00:21:14.780
I'm going to output this file
through the left headphone channel.

00:21:21.720 --> 00:21:26.700
I'm now going to play back audio
through the HDMI outputs and the

00:21:26.700 --> 00:21:30.800
left and right headphone outputs
simultaneously and adjust the volume so

00:21:30.800 --> 00:21:33.470
that you can differentiate between them.

00:21:38.840 --> 00:21:42.040
So that's just the HDMI outputs.

00:21:42.040 --> 00:21:43.520
I'm going to stop that.

00:21:43.530 --> 00:21:45.710
I'm now going to play.

00:21:49.900 --> 00:21:55.080
Left headphone.

00:21:55.150 --> 00:21:56.900
And the right headphone.

00:21:56.900 --> 00:21:58.850
And as you can see,

00:21:59.550 --> 00:22:02.340
Each of these channels are selectable.

00:22:02.340 --> 00:22:04.400
And that's it for the MultiRoute demo.

00:22:04.540 --> 00:22:05.420
Back over to you, Torrey.

00:22:05.620 --> 00:22:06.500
Thanks, Harry.

00:22:06.500 --> 00:22:10.000
Let's take a closer look at what
he just showed in this application.

00:22:10.080 --> 00:22:13.490
So in the MultiRoute demo,
before he set MultiRoute category,

00:22:13.570 --> 00:22:15.500
this was his configuration.

00:22:15.500 --> 00:22:18.720
He had an iPad with headphones
plugged into the top and

00:22:18.720 --> 00:22:20.760
HDMI was plugged into the bottom.

00:22:21.180 --> 00:22:23.500
Then he set MultiRoute category.

00:22:23.530 --> 00:22:26.130
Now, at least for output,
he's looking at a

00:22:26.180 --> 00:22:28.000
four-channel output device.

00:22:28.200 --> 00:22:33.990
It has headphone left, headphone right,
HDMI 1, and HDMI 2.

00:22:34.420 --> 00:22:36.830
Next, he set up some files.

00:22:36.830 --> 00:22:39.100
Two of the files were mono,
the one that said left channel,

00:22:39.100 --> 00:22:40.620
the one that said right channel.

00:22:40.620 --> 00:22:43.960
And then he also had a stereo music file.

00:22:46.280 --> 00:22:50.160
Last is, he chose which channels
he wanted it to go to.

00:22:50.210 --> 00:22:53.570
So sent one to headphone left,
one to headphone right,

00:22:53.570 --> 00:22:55.920
and the music came out of HDMI.

00:22:56.130 --> 00:22:58.750
Now why would you want to
use MultiRoute category?

00:22:58.800 --> 00:23:01.500
Well, how much control do you need?

00:23:01.620 --> 00:23:06.640
Maybe you're designing a DJ application,
and you want to have a stereo cue mix

00:23:06.770 --> 00:23:10.560
in your headphones that you can hear
independently from the stereo house mix.

00:23:10.650 --> 00:23:13.000
So while they're all grooving,
you can be beat matching

00:23:13.000 --> 00:23:16.410
before you move the crossfader.

00:23:16.710 --> 00:23:19.720
Maybe you're designing a digital
audio workstation application where

00:23:19.720 --> 00:23:22.840
it's very common to manipulate
multiple inputs and outputs.

00:23:24.350 --> 00:23:27.000
Maybe you've got an idea for a
multi-channel instrument and you want

00:23:27.000 --> 00:23:32.210
to play the audio to different outputs
or record from different inputs,

00:23:32.210 --> 00:23:33.300
more than two.

00:23:33.300 --> 00:23:35.910
And then maybe you've got ideas
for audio applications that

00:23:35.930 --> 00:23:37.280
we haven't even thought of.

00:23:37.280 --> 00:23:40.290
In fact, we're kind of counting on it.

00:23:41.040 --> 00:23:43.240
So how do you do this in code?

00:23:43.500 --> 00:23:46.180
Back to the AV Audio Player example.

00:23:46.510 --> 00:23:49.100
We've already retrieved our session,
and now we're going to

00:23:49.150 --> 00:23:50.330
register for notifications.

00:23:50.360 --> 00:23:52.500
This time we're going to
register for AV Audio Session

00:23:52.600 --> 00:23:54.050
Route Change Notifications.

00:23:55.710 --> 00:23:57.720
If you're going to use
MultiRoute category,

00:23:57.770 --> 00:24:01.690
it is absolutely critical that you
register for this notification.

00:24:01.810 --> 00:24:03.110
The reason why?

00:24:03.540 --> 00:24:08.180
Because any route change could
potentially invalidate part or all

00:24:08.370 --> 00:24:13.770
of the channels that you are playing
audio to or recording audio from.

00:24:14.230 --> 00:24:18.180
So, you'll register for AV Audio Session
Route Change Notification.

00:24:18.250 --> 00:24:21.540
Next,
we're going to set MultiRoute Category.

00:24:21.620 --> 00:24:26.140
We'll send the message "Set Category" to
the Session Object with "AV Audio Session

00:24:26.140 --> 00:24:30.660
Category MultiRoute." And we'd
deal with errors if there were any.

00:24:30.740 --> 00:24:32.740
Now we can set our session to active.

00:24:32.840 --> 00:24:38.390
This will trigger a route change with the
reason "Category Change." Now you want

00:24:38.390 --> 00:24:40.740
to see what's actually in your route.

00:24:40.780 --> 00:24:43.030
And you can do that by
sending the message current

00:24:43.030 --> 00:24:44.100
route to the session object.

00:24:45.730 --> 00:24:47.600
That'll give you a pointer
to the AV audio session

00:24:47.600 --> 00:24:49.840
route description object.

00:24:49.900 --> 00:24:53.740
And in this example, I've additionally
squirreled away the outputs.

00:24:53.810 --> 00:24:55.430
Now you're probably wondering
what this thing actually looks

00:24:55.440 --> 00:24:57.180
like if you were to print it out.

00:24:57.280 --> 00:25:00.240
So, if you can walk through
this slide with me,

00:25:00.310 --> 00:25:04.220
we're going to log what the
route description looks like.

00:25:04.420 --> 00:25:06.350
Top of the hierarchy, inputs and outputs.

00:25:06.430 --> 00:25:08.660
So now we're first looking at inputs.

00:25:10.350 --> 00:25:14.600
At index zero,
there is iPhone microphone.

00:25:14.640 --> 00:25:17.300
There is one channel at index zero.

00:25:17.300 --> 00:25:19.090
It's microphone built in.

00:25:19.450 --> 00:25:21.370
Channel number one.

00:25:22.270 --> 00:25:24.340
Now we move on to outputs.

00:25:24.370 --> 00:25:27.760
And by the way,
this is the type of route description

00:25:27.760 --> 00:25:31.500
you could expect to see if the user
has headphones plugged into the

00:25:31.500 --> 00:25:33.710
top of the iPad and nothing else.

00:25:34.920 --> 00:25:38.430
So, output port zero is headphones.

00:25:38.490 --> 00:25:39.400
The name is headphones.

00:25:39.400 --> 00:25:41.030
And there are two channels.

00:25:41.030 --> 00:25:43.660
Headphone left, which is channel one.

00:25:43.660 --> 00:25:46.020
And headphone right,
which is channel two.

00:25:48.690 --> 00:25:50.920
So, we're going to create our player.

00:25:50.950 --> 00:25:56.000
We'll allocate an AV audio player and
we'll initialize it with some URL.

00:25:56.340 --> 00:25:59.030
Then we're going to select
the channels we want to use.

00:25:59.620 --> 00:26:03.970
So I'm going to get, since I'm streaming,
I'm going to play an audio monofile.

00:26:03.970 --> 00:26:06.340
I'm just going to get one channel.

00:26:06.360 --> 00:26:11.490
So give me the outputs,
the object at index zero will give me

00:26:11.490 --> 00:26:15.360
the first output port of those channels.

00:26:15.360 --> 00:26:18.360
I want the object at index zero,
so give me the first channel

00:26:18.360 --> 00:26:21.370
of the first output port,
and that's my desired channel.

00:26:21.380 --> 00:26:24.680
Next, we want to create an array
of those desired channels.

00:26:24.730 --> 00:26:27.580
Now in this situation,
we're just playing a monofile,

00:26:27.580 --> 00:26:29.120
so it's a single channel.

00:26:29.610 --> 00:26:32.440
So I'll just say NSArray array
with object desired channel,

00:26:32.440 --> 00:26:35.780
and we'll squirrel that away in
channel descriptions as an array.

00:26:37.520 --> 00:26:40.070
Then we can assign channel
descriptions to our channel

00:26:40.070 --> 00:26:42.110
assignments for our player.

00:26:42.870 --> 00:26:44.790
Alright,
and then we're ready to play audio.

00:26:45.070 --> 00:26:46.990
Just as simple as that.

00:26:47.580 --> 00:26:48.720
Thanks for your time and attention.

00:26:48.800 --> 00:26:51.340
I'm now going to turn the stage
over to my colleague Bill,

00:26:51.420 --> 00:26:54.900
who's going to talk with you about
using IO units with audio session.

00:26:54.940 --> 00:26:55.500
Bill.

00:26:55.500 --> 00:26:56.480
Thank you, everybody.

00:26:56.500 --> 00:26:57.490
Thank you, Torrey.

00:26:57.500 --> 00:27:00.500
And thanks, Harry, for a good demo.

00:27:00.500 --> 00:27:05.840
What I'm going to go through today is
to go a little bit lower down into the

00:27:05.840 --> 00:27:13.500
system and look at IO units and then
how those IO units can interact with

00:27:13.500 --> 00:27:18.650
some of the concepts that Torrey has
gone through with audio session and

00:27:18.680 --> 00:27:22.500
the route descriptions and so forth.

00:27:22.500 --> 00:27:26.500
So an IO unit, there's two in the system.

00:27:26.500 --> 00:27:28.500
The main one is IU Remote IO.

00:27:28.500 --> 00:27:30.500
It's an audio unit.

00:27:30.500 --> 00:27:35.520
And it represents the lowest
level interaction that you can

00:27:35.520 --> 00:27:38.500
have with audio IO on the system.

00:27:38.670 --> 00:27:44.200
Now, because it's at a low level,
it is operating very

00:27:44.200 --> 00:27:46.710
much at a low latency.

00:27:46.770 --> 00:27:51.370
And you can, depending on routes,
depending on some of the

00:27:51.710 --> 00:27:55.110
devices that are plugged in,
depending on the settings that you have,

00:27:55.110 --> 00:27:59.870
you can get input to output latency
that can be less than 10 milliseconds.

00:27:59.890 --> 00:28:02.580
So we're looking at something
that's very serious,

00:28:02.630 --> 00:28:03.740
very responsive.

00:28:04.490 --> 00:28:07.460
And it does take a little bit of
extra work than just creating an

00:28:07.460 --> 00:28:09.400
AV audio player and playing a file.

00:28:09.400 --> 00:28:13.460
So it's important to understand when
you would use these sorts of things,

00:28:13.460 --> 00:28:16.000
when you want to understand about them,
know about them.

00:28:16.000 --> 00:28:20.820
Games will typically want to use
something that's lower latency and

00:28:20.820 --> 00:28:22.590
have some kind of control over it.

00:28:23.000 --> 00:28:25.500
Apple's OpenAL implementation does so.

00:28:25.500 --> 00:28:31.250
Games that typically provide their own
engines also will use the remote I.O.

00:28:31.250 --> 00:28:32.620
as their basis.

00:28:33.320 --> 00:28:40.270
Music apps like GarageBand, samplers,
guitar amp models, drum machines,

00:28:40.270 --> 00:28:43.400
all this kind of stuff will typically
want this type of functionality.

00:28:43.400 --> 00:28:47.100
And also VoIP apps where, of course,
you're communicating,

00:28:47.100 --> 00:28:50.020
you want that to be very responsive.

00:28:50.340 --> 00:28:52.720
So how do audio units work?

00:28:52.860 --> 00:28:56.130
We've done several sessions
in the past about audio units.

00:28:56.200 --> 00:28:59.680
I'm not going to go through
all of the details of them.

00:28:59.680 --> 00:29:03.520
Typically, you open them,
you do some configuration,

00:29:03.520 --> 00:29:07.420
you initialize them,
and then they're ready to be used and

00:29:07.420 --> 00:29:11.640
you can interact with them while they're
actually rendering and doing their work.

00:29:11.700 --> 00:29:16.690
An IO unit has some particular things
that you need to look at and to

00:29:16.720 --> 00:29:19.520
take care of when you're using it.

00:29:20.120 --> 00:29:25.320
So once you've opened the AU Remote IO,
you'll look at the IO formats.

00:29:25.430 --> 00:29:28.470
You'll look at both the
device side formats,

00:29:28.660 --> 00:29:32.160
the port formats in AV audio
session terminology,

00:29:32.160 --> 00:29:35.720
as well as the client formats,
which is the formats that

00:29:35.720 --> 00:29:38.530
you want to interact with
when you use the audio unit.

00:29:40.110 --> 00:29:42.770
So once you've set those formats up,
and that's the main

00:29:42.860 --> 00:29:47.000
configuration that you'll do,
then you would initialize the audio unit,

00:29:47.000 --> 00:29:50.270
and that causes the audio
unit to evaluate its state,

00:29:50.340 --> 00:29:53.580
to allocate buffers and so forth,
whatever it needs in

00:29:53.580 --> 00:29:55.000
order to do its work.

00:29:55.150 --> 00:29:58.270
And you'll also need to establish
your data connections and the

00:29:58.340 --> 00:30:01.320
mechanisms that you use for that,
and we'll take a look

00:30:01.380 --> 00:30:05.020
at that in some detail,
and then you start Audio.io.

00:30:05.240 --> 00:30:07.710
So what does this look like?

00:30:07.800 --> 00:30:11.220
So there is some complexity here.

00:30:11.220 --> 00:30:13.810
It's not quite Byzantine,
but it's probably getting that way.

00:30:13.840 --> 00:30:18.250
And the reason that it's this way is
because we are trying to give you one

00:30:18.250 --> 00:30:22.890
place to get audio input and output
for one particular period of time.

00:30:22.900 --> 00:30:27.070
And that means that you can
really get the low latency.

00:30:27.120 --> 00:30:31.050
So I'm going to try and walk you through
what this actually looks like as an

00:30:31.060 --> 00:30:34.930
audio unit and how you understand it
and then use it in your application.

00:30:34.960 --> 00:30:39.750
Now you can use input and output
separately or you can use them together.

00:30:39.760 --> 00:30:43.280
So this isn't something you've
got to do all or nothing.

00:30:43.380 --> 00:30:45.050
You can use the parts of it you want.

00:30:46.570 --> 00:30:50.290
So you see here, audio units have scopes.

00:30:50.290 --> 00:30:54.550
And the three main ones are global scope,
where an audio unit's going

00:30:54.650 --> 00:30:56.550
to keep state that's global.

00:30:56.750 --> 00:30:59.390
There's input scope,
which is where the audio unit

00:30:59.390 --> 00:31:03.360
is going to get input from,
you know, audio input.

00:31:03.360 --> 00:31:08.350
And then output scope,
which is what the audio

00:31:08.350 --> 00:31:08.350
unit is going to output.

00:31:08.390 --> 00:31:11.400
And elements are members of a scope.

00:31:11.520 --> 00:31:16.560
They're typically the same kind of
collection of objects that are the same.

00:31:16.760 --> 00:31:19.400
You can think of elements in,
if you think of a mixer,

00:31:19.400 --> 00:31:23.670
which could have many different
inputs and one single output.

00:31:23.760 --> 00:31:27.140
So in an audio unit,
that mixer will have many input

00:31:27.140 --> 00:31:29.670
elements and one output element.

00:31:30.070 --> 00:31:35.230
So when we're looking at an AI unit,
we're looking at an audio

00:31:35.230 --> 00:31:38.960
unit that has two inputs,
sorry, two elements,

00:31:38.960 --> 00:31:41.120
both on input and output scope.

00:31:41.120 --> 00:31:46.240
And element zero is the element you
interact with when you're doing output,

00:31:46.240 --> 00:31:48.220
when you're making sound.

00:31:48.220 --> 00:31:56.990
And a good way to kind of trigger this
in your mind is element zero and output,

00:31:57.240 --> 00:31:58.660
zero and O.

00:31:58.660 --> 00:32:02.560
And then element one is the element
that you interact with when you

00:32:02.560 --> 00:32:04.860
want to get audio input from,
you know,

00:32:04.860 --> 00:32:07.050
the outside world into your application.

00:32:07.170 --> 00:32:09.870
And you can,
there's a nice way of thinking

00:32:09.870 --> 00:32:11.520
about that is one and I.

00:32:12.950 --> 00:32:16.090
Now then,
the purple boxes here represent what

00:32:16.090 --> 00:32:20.460
we're going to call the virtual formats,
either output or input.

00:32:20.460 --> 00:32:23.700
And you can see what these look
like from AV audio sessions,

00:32:23.700 --> 00:32:26.430
port descriptions,
and they will represent

00:32:26.430 --> 00:32:30.300
whatever audio input and output
capabilities are available to your

00:32:30.300 --> 00:32:33.480
application when you are running.

00:32:33.480 --> 00:32:37.140
And then the green boxes
represent the client format.

00:32:38.060 --> 00:32:44.590
And the client format is the format of
the data that you want to provide to the

00:32:44.590 --> 00:32:48.920
audio unit or that you want to get from
the audio unit when you're getting input.

00:32:50.540 --> 00:32:55.110
And the yellow arrows between
these boxes represent audio

00:32:55.110 --> 00:32:57.040
conversions that can occur.

00:32:57.040 --> 00:33:00.980
And if you know the audio converter API,
that's actually the object

00:33:00.980 --> 00:33:02.640
that's being used internally.

00:33:02.640 --> 00:33:09.660
And that means that your client format
can be different than the virtual format,

00:33:09.660 --> 00:33:13.460
either on input or on output,
and we'll do the conversion for you.

00:33:13.480 --> 00:33:16.900
So how do you interact with this?

00:33:17.970 --> 00:33:23.120
So for setting your client formats,
you do the audio unit set property call,

00:33:23.120 --> 00:33:27.420
and audio units are generally
configured through a property mechanism,

00:33:27.420 --> 00:33:29.020
and there's lots of properties.

00:33:29.020 --> 00:33:32.110
You can have a look in
audiounitproperties.h

00:33:32.340 --> 00:33:34.580
for the exhaustive list.

00:33:34.620 --> 00:33:39.540
And then when you set the client format,
you set that for output on

00:33:39.540 --> 00:33:44.680
input scope and element zero,
because that's what you're going

00:33:44.730 --> 00:33:46.740
to give the audio unit to play.

00:33:47.700 --> 00:33:53.210
And then when you want to record audio,
you'll set the client format on

00:33:53.210 --> 00:33:57.220
the output scope of element one,
because you're going to pull

00:33:57.220 --> 00:34:00.710
that audio out of the audio unit,
and the audio that's coming

00:34:01.150 --> 00:34:05.300
into your application then will
come in through element one,

00:34:05.300 --> 00:34:06.980
and we'll look at that a little bit more.

00:34:09.210 --> 00:34:16.100
So what about audio routes and how
that interacts with the IA unit?

00:34:16.100 --> 00:34:19.340
And if we remember the
demo that Harry showed and

00:34:19.370 --> 00:34:24.540
what Torrey talked about,
we had an output of two channels

00:34:24.540 --> 00:34:28.290
of HDMI and two channels
through the headphone jack.

00:34:28.610 --> 00:34:34.100
So the AU Remote I/O unit on
the output scope on bus zero,

00:34:34.210 --> 00:34:36.400
it's going to see four channels.

00:34:36.520 --> 00:34:40.170
And if you look at
AV Audio Sessions route description,

00:34:40.170 --> 00:34:44.720
the current outputs will have
four channel descriptions.

00:34:44.860 --> 00:34:48.080
There will be two channels for
the headphone output channels

00:34:48.540 --> 00:34:51.630
and two channels for the HDMI.

00:34:52.760 --> 00:34:57.740
And so you get this format by looking,
by doing audio unit get property,

00:34:57.740 --> 00:35:01.900
and it's the same property
identifier as setting it previously,

00:35:01.900 --> 00:35:03.720
which is stream format.

00:35:03.720 --> 00:35:07.150
And in this case,
you're going to get it from the

00:35:07.150 --> 00:35:09.560
output scope on element zero.

00:35:09.560 --> 00:35:13.030
Now, on the purple boxes,
just as a side note,

00:35:13.030 --> 00:35:15.350
you can't set those formats.

00:35:15.440 --> 00:35:17.540
They're always just read-only properties.

00:35:17.800 --> 00:35:21.130
They're just going to tell
you what's available to your

00:35:21.130 --> 00:35:23.120
audio unit at any given time.

00:35:23.120 --> 00:35:27.370
And, of course, with route changes,
these values can change

00:35:27.370 --> 00:35:29.350
if devices come and go.

00:35:31.360 --> 00:35:35.840
So what does it look like if we kind
of pull this apart a little bit?

00:35:36.010 --> 00:35:39.520
So if we start at the bottom,
the purple box is what we

00:35:39.520 --> 00:35:42.670
see on the device side,
and it's on the output scope.

00:35:42.760 --> 00:35:46.200
And for the demo we showed,
we'll see four channels.

00:35:46.360 --> 00:35:51.970
And from AV Audio Sessions
channel descriptions and the

00:35:51.970 --> 00:35:56.790
order that they're presented,
we can see headphone left and right,

00:35:56.790 --> 00:35:56.790
HDMI 1 and 2.

00:35:57.400 --> 00:38:29.100
[Transcript missing]

00:38:29.900 --> 00:42:14.800
[Transcript missing]

00:42:15.380 --> 00:42:17.800
And like I said, they want to make sound.

00:42:17.800 --> 00:42:19.780
That's why they've run your application.

00:42:19.910 --> 00:42:25.300
So sound in these categories is going
to blow through the ringer switch.

00:42:25.300 --> 00:42:29.030
It will have no effect on
whether audio is played or not.

00:42:29.160 --> 00:42:32.940
Now there is one thing to understand
about AV Audio Session here,

00:42:33.070 --> 00:42:37.690
and that is the mix with others option.

00:42:38.140 --> 00:42:41.420
So we talked about with games
how you mix with others,

00:42:41.520 --> 00:42:44.860
and with a lot of music apps,
it is actually quite useful to mix

00:42:44.860 --> 00:42:49.840
with others because different users
will want to use different applications

00:42:49.840 --> 00:42:51.970
potentially at the same time.

00:42:52.530 --> 00:42:55.950
Maybe they want to play along
with their iPod application,

00:42:56.080 --> 00:43:00.070
or they want a drum machine going
in the background and then switch

00:43:00.070 --> 00:43:02.220
to a synth and make the synth go.

00:43:02.220 --> 00:43:06.680
And if you're not mixing with others,
then you have the potential to interrupt

00:43:06.680 --> 00:43:11.150
each other and you get into this kind of,
no, I want the system, no,

00:43:11.150 --> 00:43:13.660
I want the system sort of battle.

00:43:13.660 --> 00:43:19.610
So you would set the mix with others
when you set the category as an option.

00:43:19.620 --> 00:43:22.140
And you just would set AV audio session.

00:43:22.160 --> 00:43:24.570
Category, option, mix with others.

00:43:24.600 --> 00:43:27.480
And you can still play
audio in the background.

00:43:27.480 --> 00:43:31.600
It doesn't affect your application's
ability to keep playing audio in

00:43:31.600 --> 00:43:35.590
the background or keep playing
audio with the ringer switch set.

00:43:35.820 --> 00:43:41.320
It's all just about how you
cooperate with other applications.

00:43:41.320 --> 00:43:45.580
Now, you can imagine that there are
cases with music apps where they

00:43:45.760 --> 00:43:48.050
really want to be the primary app.

00:43:48.180 --> 00:43:51.120
They really want to exert some control.

00:43:51.800 --> 00:43:52.900
Over the system.

00:43:52.900 --> 00:43:56.920
Maybe they're very particular about the
sample rate the device is running at,

00:43:57.130 --> 00:44:00.260
about the latency
characteristics of the device.

00:44:00.390 --> 00:44:03.550
And they really want to
just assert that ownership.

00:44:03.680 --> 00:44:08.830
And so when they set the category,
play or play and record, or even record,

00:44:08.830 --> 00:44:12.100
for example, you just don't set the
mix with others options.

00:44:12.100 --> 00:44:17.080
If you consider that as a characteristic,
as a requirement for your app.

00:44:17.140 --> 00:44:19.660
And you could,
if you wanted to really give

00:44:19.660 --> 00:44:21.600
this as an option to your user.

00:44:21.660 --> 00:44:25.740
But we generally prefer to not have
the user have to do this sort of thing.

00:44:25.740 --> 00:44:30.380
But for you to understand how your app
is going to be used and just to take

00:44:30.490 --> 00:44:33.380
care of things as would be appropriate.

00:44:35.890 --> 00:44:38.660
Now, a couple of things that you
might be interested in at this,

00:44:38.720 --> 00:44:44.840
interacting with this sort of level with
AV audio session is the I/O duration.

00:44:44.840 --> 00:44:48.340
This can go down to as low
as under two milliseconds.

00:44:48.340 --> 00:44:51.760
It could be as high as
40 or 80 milliseconds.

00:44:51.770 --> 00:44:56.700
And this is the size of the
I/Os that we're going to do.

00:44:56.850 --> 00:45:01.930
So if you were to set a three
millisecond I/O at 48 kilohertz,

00:45:02.050 --> 00:45:09.760
you'll get about 128 samples to process
in your I/O unit's rendering cycle.

00:45:09.930 --> 00:45:13.360
And if you're a game, you know,
10 milliseconds might be good enough,

00:45:13.460 --> 00:45:16.300
given all the other latencies
involved in the game,

00:45:16.300 --> 00:45:17.960
or 20, or 5.

00:45:17.960 --> 00:45:18.960
It's really up to you.

00:45:18.960 --> 00:45:23.200
You can set this yourself
based on what you expect.

00:45:23.270 --> 00:45:24.040
Now, there is a cost.

00:45:24.180 --> 00:45:29.150
If you have lower latency I/Os,
you are going to be using more power.

00:45:29.300 --> 00:45:34.000
So just don't all go and set this to do,
to two milliseconds or something,

00:45:34.000 --> 00:45:36.670
because that's what you
think is going to be perfect.

00:45:36.770 --> 00:45:38.660
In some cases,
you really want to be smart

00:45:38.660 --> 00:45:40.560
about how you set this.

00:45:40.670 --> 00:45:44.920
And you may also have situations where
you want to understand the sample

00:45:45.030 --> 00:45:48.660
rate and have the sample rate set,
and there's an AV audio session

00:45:48.660 --> 00:45:50.860
property for you to do that.

00:45:50.980 --> 00:45:54.590
Now, if you're mixing with others,
you can make these, and they're requests.

00:45:54.720 --> 00:45:58.300
That's why the name is
preferred rather than required.

00:45:58.450 --> 00:46:02.710
But if your category is not,
not allowing you to mix with

00:46:02.850 --> 00:46:07.100
others when you go active,
you'll generally get these settings.

00:46:07.280 --> 00:46:11.200
And you'll generally get them in
the case where you're mixable.

00:46:11.200 --> 00:46:14.780
You just won't be as
guaranteed to get them.

00:46:14.920 --> 00:46:18.000
So that's the basic
AU Remote I/O and AV Audio session.

00:46:18.000 --> 00:46:21.130
I wanted to spend a little
bit of time looking at the

00:46:21.280 --> 00:46:23.440
voice processing audio unit.

00:46:23.440 --> 00:46:26.780
This is an extension of AU Remote I/O.

00:46:26.780 --> 00:46:31.180
And what it does is that to the
I/O mechanisms of AU Remote I/O,

00:46:31.180 --> 00:46:33.180
it adds voice processing.

00:46:33.180 --> 00:46:39.180
And the voice processing can be done
on the output as well as on the input.

00:46:39.490 --> 00:46:43.130
The types of voice processing that
it will do is echo cancellation,

00:46:43.240 --> 00:46:47.100
noise suppression,
gain correction to keep the input

00:46:47.100 --> 00:46:49.400
within a certain range of gain.

00:46:49.400 --> 00:46:53.800
And it's really designed for high
quality chat and it's optimized with

00:46:53.800 --> 00:46:58.200
different settings for different
routes like speaker or headphones

00:46:58.200 --> 00:47:00.950
and also for different use cases.

00:47:01.220 --> 00:47:04.740
Now while we're mainly
focusing on iOS in this talk,

00:47:04.960 --> 00:47:09.460
there is a version of this audio
unit that is available from Lion and

00:47:09.890 --> 00:47:12.580
you can use this as well there.

00:47:12.580 --> 00:47:14.560
And it works much the same way.

00:47:16.330 --> 00:47:18.400
So why would you use this?

00:47:18.470 --> 00:47:20.600
Why wouldn't you just do
your own echo counselor?

00:47:20.600 --> 00:47:21.000
Right?

00:47:21.000 --> 00:47:21.800
It's not that hard.

00:47:21.800 --> 00:47:23.730
Maybe it is that hard.

00:47:23.880 --> 00:47:27.560
So what I thought I'd do is to
actually go through and show you what's

00:47:27.700 --> 00:47:31.820
actually going on when you're in a
conference and why we would ask you to,

00:47:31.820 --> 00:47:34.800
or recommend that you
use this audio unit.

00:47:34.800 --> 00:47:38.200
So the two wavy lines there
represent the network.

00:47:38.200 --> 00:47:41.400
And we're having a conversation
between a far end talker,

00:47:41.400 --> 00:47:45.800
somebody somewhere else,
and a near end talker, which is,

00:47:45.980 --> 00:47:48.390
for the purpose of my talk, me.

00:47:48.400 --> 00:47:52.880
So on my phone,
what's going to come in from the

00:47:52.890 --> 00:47:58.400
network is the dark blue line that's to,
uh, yeah, that one.

00:47:58.400 --> 00:48:02.220
Um, and that's what I'm going
to hear out of my speaker.

00:48:02.400 --> 00:48:05.510
Now,
what I could hear out of my speaker is

00:48:05.610 --> 00:48:08.350
also other applications making sounds.

00:48:08.500 --> 00:48:11.390
It could be UI sounds,
I could be playing a game,

00:48:11.480 --> 00:48:16.400
I could be listening to music,
and so the downlink audio,

00:48:16.400 --> 00:48:18.400
the dark blue line
coming from the network,

00:48:18.400 --> 00:48:21.400
is going to be mixed with whatever
other sounds are on the system,

00:48:21.400 --> 00:48:24.390
and that's what's going
to come out of my speaker.

00:48:24.500 --> 00:48:29.000
And we try to represent this by the
light blue line because something else is

00:48:29.000 --> 00:48:31.400
there besides what went out the network.

00:48:31.680 --> 00:48:34.820
Now, when I'm talking,
the microphone is going to

00:48:34.820 --> 00:48:37.400
hear everything I can hear,
uh, uh,

00:48:37.530 --> 00:48:39.400
particularly if I'm on a speakerphone.

00:48:39.400 --> 00:48:43.900
And so the microphone is going to hear
what I'm... what is coming out of my

00:48:43.900 --> 00:48:46.230
device as well as what I'm saying to it.

00:48:46.400 --> 00:48:49.400
And so there's sort of
two sources of audio,

00:48:49.400 --> 00:48:55.400
what I'm talking, uh, my voice,
and what my device is playing,

00:48:55.400 --> 00:48:58.400
and we're representing this
coming into the microphone,

00:48:58.450 --> 00:49:00.950
mixing it together,
and we have this nice little

00:49:00.950 --> 00:49:04.400
magenta line that goes into
the voice processing block.

00:49:04.400 --> 00:49:07.020
Now, of course,
the role of the voice processing

00:49:07.020 --> 00:49:13.890
block is to take out the signal
that was played by the device and

00:49:14.100 --> 00:49:19.510
Basically subtract it and you end
up with what I was talking about,

00:49:19.550 --> 00:49:21.210
not what my device was playing.

00:49:21.220 --> 00:49:25.110
And that's the red line coming
out of the voice processing block.

00:49:25.170 --> 00:49:27.680
And we're trying to use color
here to key you to the fact that

00:49:27.720 --> 00:49:32.020
the goal of the voice processing
block is to extract my speech.

00:49:32.020 --> 00:49:35.400
And not to play,
not to include the blue line

00:49:35.820 --> 00:49:38.240
that came down from the network.

00:49:38.940 --> 00:49:42.970
Because if we don't do this,
then the far end talker is going to

00:49:43.030 --> 00:49:46.040
hear themselves talking with a delay.

00:49:46.040 --> 00:49:47.340
And that's why it's called an echo.

00:49:47.340 --> 00:49:48.750
It sounds just like an echo.

00:49:50.410 --> 00:49:53.730
Now the reason that this is important
to understand all of this is because

00:49:53.810 --> 00:49:59.000
other applications are mixing sound,
playing sound,

00:49:59.000 --> 00:50:02.910
and so you don't actually know in your
application other sound that is played.

00:50:02.910 --> 00:50:04.670
So you can't deal with it.

00:50:05.010 --> 00:50:05.810
You just can't.

00:50:05.890 --> 00:50:07.430
You don't know the audio that's there.

00:50:07.430 --> 00:50:10.370
And so you can't distinguish
between what was played and what

00:50:10.370 --> 00:50:12.050
was spoken in the environment.

00:50:14.550 --> 00:50:20.750
Okay, so to use the voice processing AU,
it's very similar to AU Remote I/O.

00:50:20.860 --> 00:50:27.080
You just look for the voice processing
AU and you make it and you set up the

00:50:27.180 --> 00:50:29.350
callbacks and everything the same way.

00:50:29.470 --> 00:50:32.650
Now if you're doing a VoIP app,
voice is primary and you

00:50:32.860 --> 00:50:36.400
want to make sure that that's
the best experience you can.

00:50:36.400 --> 00:50:40.400
So first of all, for setting up
AV Audio session with this,

00:50:40.400 --> 00:50:44.100
you'll need to set up the category
to do play and record because you

00:50:44.100 --> 00:50:46.400
want input and output simultaneously.

00:50:46.400 --> 00:50:48.400
And this is where the modes come in.

00:50:48.400 --> 00:50:53.120
You would set the voice chat mode
and that allows us to optimize

00:50:53.120 --> 00:50:55.330
the routes that may choose.

00:50:55.490 --> 00:50:59.580
It tells us, oh, there's, you know,
some things we should do in the

00:50:59.580 --> 00:51:03.400
audio system to make sure that
this is going to work well.

00:51:03.400 --> 00:51:05.400
And by using this mode,
you can set up the voice chat mode.

00:51:05.400 --> 00:51:06.400
And that allows us to optimize
the routes that may choose.

00:51:06.400 --> 00:51:10.080
And you get the same behavior in your
device that a phone call or FaceTime will

00:51:10.080 --> 00:51:13.400
get when they're running a VoIP app.

00:51:13.400 --> 00:51:17.430
So it makes for a consistent
user experience as well.

00:51:18.220 --> 00:51:20.880
Some of the things you might want
to do with the VoIP app is to

00:51:20.970 --> 00:51:22.770
set the preferred sample rate.

00:51:22.910 --> 00:51:25.530
Typically,
you would use this to match the sample

00:51:25.530 --> 00:51:32.620
rate of the VoIP that you're doing,
say 24 kilohertz or 16 kilohertz.

00:51:32.680 --> 00:51:35.870
And it just means that if
the sample rate is set,

00:51:35.960 --> 00:51:38.060
that there's less processing
done on the signal,

00:51:38.060 --> 00:51:42.670
and so it's going to keep
fidelity of the voice much better.

00:51:43.230 --> 00:51:47.450
You also might want to adjust
the preferred IO duration.

00:51:47.530 --> 00:51:50.460
And it's interesting here,
because if you're putting

00:51:50.460 --> 00:51:53.460
data on the network,
you're doing so in packets.

00:51:53.540 --> 00:51:57.170
And typically those packets
represent a span of time.

00:51:57.170 --> 00:51:58.560
Let's say 20 milliseconds.

00:51:58.560 --> 00:51:59.470
That's a common one.

00:51:59.520 --> 00:52:05.250
So it's really no use to
do IOs at 2 milliseconds,

00:52:05.260 --> 00:52:11.040
because you're running the system
at a very high rate of overhead.

00:52:11.560 --> 00:52:13.810
And all you're going to do
is accumulate that data until

00:52:13.810 --> 00:52:16.780
you've got 20 milliseconds,
and then you can encode it

00:52:16.780 --> 00:52:18.330
and put it on the network.

00:52:18.340 --> 00:52:22.220
So why not just do a 20
millisecond IO to begin with?

00:52:22.320 --> 00:52:24.620
Well, that's probably a good idea.

00:52:24.620 --> 00:52:28.460
So you can set preferred IO duration,
which is set in seconds,

00:52:28.460 --> 00:52:30.840
and set it to 20 milliseconds.

00:52:30.910 --> 00:52:32.830
And you can play with this.

00:52:32.940 --> 00:52:36.590
Maybe you want to do a little
more tweaking on the output side.

00:52:36.600 --> 00:52:38.420
You want a little less
latency on the output.

00:52:38.420 --> 00:52:39.680
It really depends on your app.

00:52:39.840 --> 00:52:43.280
But just don't assume that the
lowest IO setting is really

00:52:43.280 --> 00:52:45.390
necessary to get what you want.

00:52:45.420 --> 00:52:51.320
There's some other properties you might
like to look at in AV audio session.

00:52:51.320 --> 00:52:55.240
There's a property to override the route,
so you get speaker output,

00:52:55.240 --> 00:52:58.480
even though headphones are plugged in,
for example.

00:52:58.480 --> 00:53:01.260
And that's the classic speakerphone.

00:53:01.260 --> 00:53:04.660
There's some properties
in audio unit properties,

00:53:04.940 --> 00:53:07.020
that great tome of audio wisdom.

00:53:08.000 --> 00:53:11.820
And there are some properties
specifically there for the voice

00:53:11.820 --> 00:53:13.540
IO unit that you should look at.

00:53:13.620 --> 00:53:14.540
There's some comments there.

00:53:14.540 --> 00:53:15.680
I won't go into them today.

00:53:17.720 --> 00:53:20.650
Now, just to finish up,
I thought I'd just very briefly

00:53:20.870 --> 00:53:24.350
discuss a different scenario
where voice processing is used,

00:53:24.450 --> 00:53:27.420
and that is in the GameKit,
the GameChat case.

00:53:27.420 --> 00:53:32.420
And this is interesting because it shows
some of the flexibility of the system.

00:53:32.420 --> 00:53:35.690
And the difference here
is that with a VoIP app,

00:53:35.700 --> 00:53:38.580
audio, the conversation is primary.

00:53:38.580 --> 00:53:41.860
You want everything to be set
based on what your conversation is,

00:53:41.940 --> 00:53:44.490
going to be,
to make that an optimal experience.

00:53:44.840 --> 00:53:47.020
With the game, that's not the case.

00:53:47.130 --> 00:53:48.500
The chat is secondary.

00:53:48.500 --> 00:53:52.500
The game, the fidelity of the game,
the audio environment of the game,

00:53:52.500 --> 00:53:54.010
that's really primary.

00:53:54.020 --> 00:54:01.230
And so, typically, when a game's run,
the audio will be at 48 or 44.1,

00:54:01.240 --> 00:54:04.780
something that's going to
provide you with that rich

00:54:04.780 --> 00:54:07.120
audio experience for the game.

00:54:07.120 --> 00:54:10.260
But the chat's not at that sample rate.

00:54:10.260 --> 00:54:13.270
The chat's probably at 16
kilohertz or something much lower.

00:54:14.860 --> 00:54:20.160
And so the voice processing
I/O will take these into account.

00:54:20.160 --> 00:54:23.400
It will resample the audio coming in.

00:54:23.450 --> 00:54:27.790
We will optimize the system
around this kind of configuration.

00:54:27.950 --> 00:54:29.850
And it's not that it's
going to sound like crap,

00:54:29.850 --> 00:54:30.800
because it isn't.

00:54:30.800 --> 00:54:32.800
It's going to sound pretty good.

00:54:33.010 --> 00:54:37.710
But it's a different way of configuring
the system because really the game

00:54:37.710 --> 00:54:39.800
is more important than the chat.

00:54:39.800 --> 00:54:42.410
The chat is an ancillary,
it's a part of the game.

00:54:42.410 --> 00:54:43.740
It needs to sound good.

00:54:43.800 --> 00:54:45.710
It will sound good, but it's not primary.

00:54:45.860 --> 00:54:51.270
So this is some of the flexibility
that the audio system has.

00:54:51.500 --> 00:54:53.700
So that's the end of my talk.

00:54:53.940 --> 00:54:54.800
Thank you for listening.

00:54:54.800 --> 00:54:57.100
AB Audio session was covered.

00:54:57.100 --> 00:55:00.700
We hope in enough detail for you
to go and use multi-channels,

00:55:00.700 --> 00:55:03.420
to use multi-routes,
and we look forward to

00:55:03.420 --> 00:55:04.810
seeing what you do with that.

00:55:05.000 --> 00:55:08.080
IO units, low-level stuff,
hope you have a good

00:55:08.150 --> 00:55:09.910
understanding of that.

00:55:09.920 --> 00:55:11.920
This is where you can
get more information.

00:55:12.060 --> 00:55:15.850
Eric is the media
technologies evangelist.

00:55:16.060 --> 00:55:20.370
There's a lot of downloads of
sample code and documentation

00:55:20.490 --> 00:55:23.080
on the developerapple.com.

00:55:23.080 --> 00:55:26.320
And then there's the developer forums.

00:55:26.320 --> 00:55:27.140
Thank you very much.