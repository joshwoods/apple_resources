WEBVTT

00:00:17.250 --> 00:00:18.050
All right, good morning.

00:00:18.050 --> 00:00:22.670
Today, we want to spend some time talking
about some advanced things that you

00:00:22.670 --> 00:00:24.280
can do with UI Gesture Recognizer.

00:00:24.280 --> 00:00:29.820
And to really get into it and have a
good idea of how we got to where we

00:00:29.930 --> 00:00:34.100
are today from what gesture recognition
was before UI Gesture Recognizer,

00:00:34.100 --> 00:00:37.570
we want to do a little bit of backstory
and just give you a brief overview of

00:00:37.600 --> 00:00:41.280
the history of the gesture recognizer
system and sort of how it came to be

00:00:41.300 --> 00:00:44.580
from more of a technical standpoint,
the issues that were involved

00:00:44.580 --> 00:00:45.680
in coming up with it.

00:00:47.200 --> 00:00:49.390
And then from there,
once you kind of understand what the

00:00:49.390 --> 00:00:53.060
gesture recognizer system is about,
we want to talk a little more about

00:00:53.170 --> 00:00:56.100
gesture interaction because this
is one of the biggest points and

00:00:56.100 --> 00:00:59.640
the biggest reasons for the gesture
recognizer system to exist at all

00:00:59.640 --> 00:01:03.710
is to manage the interaction between
multiple different gesture recognizers.

00:01:03.710 --> 00:01:07.140
And then after we've gone over that,
Andy's going to spend some time

00:01:07.140 --> 00:01:09.080
talking about subclassing fundamentals.

00:01:09.080 --> 00:01:13.230
Once you understand really what the
gesture recognizer system is and how

00:01:13.230 --> 00:01:16.320
gestures interact with one another,
hopefully you'll have a really good idea

00:01:16.320 --> 00:01:17.180
of what the gesture recognizer system is.

00:01:17.180 --> 00:01:17.180
And then after we've gone over that,
Andy's going to spend some time

00:01:17.180 --> 00:01:17.320
talking about subclassing fundamentals.

00:01:17.320 --> 00:01:19.810
So, I think it's a really good idea
of why you also want to be writing

00:01:19.810 --> 00:01:22.030
your own UI Gesture Recognizers
when you're thinking about

00:01:22.050 --> 00:01:23.550
building your own custom gestures.

00:01:23.560 --> 00:01:26.140
And a big part of that is
going to be talking about the

00:01:26.140 --> 00:01:29.880
fundamentals for what you should
be doing while subclassing things.

00:01:29.880 --> 00:01:33.530
Now, most of the focus of that
section is going to be about some

00:01:33.530 --> 00:01:37.410
interesting things that you should
be thinking about and keeping

00:01:37.410 --> 00:01:41.020
in mind while you are subclassing,
rather than some of the basic

00:01:41.020 --> 00:01:43.220
mechanics of which method to override.

00:01:43.220 --> 00:01:46.580
So, if you're already familiar
with how subclassing works,

00:01:46.580 --> 00:01:48.340
there's... There's still some
even more interesting stuff that

00:01:48.420 --> 00:01:49.270
we'll be talking about there.

00:01:49.280 --> 00:01:52.170
And then finally,
we're going to end by talking

00:01:52.170 --> 00:01:54.870
about some pretty advanced signal
processing techniques that you

00:01:55.090 --> 00:01:57.620
might want to use when building
your own gesture recognizers.

00:01:57.620 --> 00:02:00.110
Some things that we've found
that we've used in our own

00:02:00.110 --> 00:02:02.730
gestures in certain places,
and stuff that hopefully when

00:02:02.730 --> 00:02:05.300
you're going to write your own,
you'll find these things to be

00:02:05.320 --> 00:02:06.800
pretty useful and interesting.

00:02:06.800 --> 00:02:10.040
So, let's start by talking about
the gesture recognizer system.

00:02:10.060 --> 00:02:16.370
A big part of the recognition of gestures
is thinking about state machines.

00:02:17.140 --> 00:02:19.770
And state machines are a pretty
easy and common way to end up

00:02:19.770 --> 00:02:21.530
thinking about how gestures work.

00:02:21.540 --> 00:02:25.610
So, let's take a simple example of just a
collection of gestures that we might

00:02:25.610 --> 00:02:30.110
decide that we wanted to recognize from
a basic app that you've seen on iOS,

00:02:30.210 --> 00:02:32.970
you know, plenty of times, the Maps app.

00:02:33.020 --> 00:02:36.110
So, Maps implements a few different
gestures and supports a

00:02:36.110 --> 00:02:37.770
number of different things.

00:02:37.800 --> 00:02:40.140
So, your users can put a
finger down on the screen,

00:02:40.140 --> 00:02:42.190
and they can move it
around to pan the map.

00:02:42.220 --> 00:02:47.120
They can put two fingers down and then
pinch to zoom in and out on that map.

00:02:47.120 --> 00:02:48.490
that.

00:02:48.910 --> 00:02:52.750
and then there's also a collection
of other things that interact with

00:02:52.830 --> 00:02:54.400
those as well or that are on the side.

00:02:54.400 --> 00:02:58.080
So you've kind of got your pan,
you've got pinching, you've got taps,

00:02:58.080 --> 00:03:00.800
double taps, two-finger taps,
but that's kind of the

00:03:00.800 --> 00:03:01.940
collection of them.

00:03:03.450 --> 00:03:08.180
So if you were to stop and think about
how you might implement this set of

00:03:08.320 --> 00:03:13.000
five gestures in an app like Maps,
and you didn't have gesture recognizers

00:03:13.000 --> 00:03:16.620
or didn't really know about them,
you might start thinking that you have

00:03:16.630 --> 00:03:20.550
to build a state machine to keep into
account what fingers are on the screen,

00:03:20.580 --> 00:03:23.800
how long they've been there,
and what they've been doing,

00:03:23.800 --> 00:03:25.110
that sort of thing.

00:03:25.120 --> 00:03:27.860
So you might start adding some states,
maybe a start state when

00:03:27.860 --> 00:03:30.330
nothing's happened yet,
a couple of states for tracking

00:03:30.330 --> 00:03:32.850
when one finger's down and
when two fingers are down.

00:03:34.330 --> 00:03:37.780
And that sort of gets you started,
but then you have to start tracking

00:03:37.780 --> 00:03:39.630
when things have not happened.

00:03:39.630 --> 00:03:42.360
So you have to know that a
one-finger tap is not possible

00:03:42.500 --> 00:03:44.490
even though a finger is still down.

00:03:44.500 --> 00:03:47.700
Or maybe two fingers are still down,
but that can't be a tap anymore.

00:03:47.700 --> 00:03:49.710
And then maybe you have to
handle also the case where

00:03:49.710 --> 00:03:51.100
there's more than two fingers.

00:03:51.100 --> 00:03:53.440
And we're starting to
get pretty many states,

00:03:53.440 --> 00:03:57.280
but we're not even done adding states
yet because now you might also have to be

00:03:57.280 --> 00:04:00.760
tracking things like one finger was down,
but it's not a double tap,

00:04:00.760 --> 00:04:03.860
but maybe it might still be,
or maybe it's not anymore.

00:04:04.200 --> 00:04:04.750
I don't know.

00:04:04.840 --> 00:04:05.810
Even more states.

00:04:05.860 --> 00:04:09.310
So it starts to get kind of out
of hand pretty quickly with even

00:04:09.310 --> 00:04:11.880
a fairly small number of gestures,
only five.

00:04:11.880 --> 00:04:14.650
But we haven't even really
reached the worst part yet because

00:04:14.650 --> 00:04:17.720
we didn't even talk about the
transitions between these states.

00:04:17.800 --> 00:04:20.620
You have to start defining which
ones of these states you can

00:04:20.670 --> 00:04:23.480
transition from at any given time,
which ones are valid to

00:04:23.480 --> 00:04:25.390
transition to from another state.

00:04:25.390 --> 00:04:28.000
And now all of a sudden,
you pretty much are screwed.

00:04:28.000 --> 00:04:30.110
There's really nothing you can do here.

00:04:30.120 --> 00:04:34.120
So this has gotten
incredibly complicated.

00:04:34.200 --> 00:04:36.500
And honestly,
that's actually the kind of thing

00:04:36.500 --> 00:04:40.210
we were dealing with with gesture
recognition in the Maps app in the early

00:04:40.210 --> 00:04:42.520
days of iOS before gesture recognizers.

00:04:42.520 --> 00:04:45.460
So we took a step back and thought
about what's the simplest state

00:04:45.460 --> 00:04:49.000
machine that we could build that would
represent the recognition of gestures

00:04:49.000 --> 00:04:52.100
without getting into that crazy
spaghetti thing that we could never

00:04:52.100 --> 00:04:53.910
maintain over any period of time.

00:04:53.920 --> 00:04:58.060
And so what we've got is the
gesture recognizer state machine.

00:04:58.060 --> 00:05:01.170
And every gesture recognizer
starts in state possible.

00:05:01.180 --> 00:05:05.540
From state possible, often,
and most commonly probably,

00:05:05.540 --> 00:05:08.300
we'll go to state failed,
indicating that the user did not

00:05:08.300 --> 00:05:11.870
recognize or perform whatever gesture
it was that we were looking for.

00:05:11.880 --> 00:05:14.660
And in the simplest case,
you'll have one state

00:05:14.810 --> 00:05:15.880
that's state recognized.

00:05:15.900 --> 00:05:19.170
And this is for sort of
discrete gesture recognizers,

00:05:19.270 --> 00:05:22.760
ones that they recognize at one period
of time after some certain event,

00:05:22.830 --> 00:05:23.620
and then they're done.

00:05:23.640 --> 00:05:27.500
So like a tap gesture recognizer
or a swipe gesture recognizer,

00:05:27.640 --> 00:05:29.640
either it happened or it didn't,
and that's all.

00:05:29.750 --> 00:05:32.000
So for those types of gestures,
this is really the entirety

00:05:32.000 --> 00:05:32.760
of the state machine.

00:05:33.750 --> 00:05:37.240
And that's way simpler than everything
we were talking about before.

00:05:37.470 --> 00:05:41.120
There is a slight bit more
complication when you start talking

00:05:41.120 --> 00:05:44.590
about more continuous gestures,
things that recognize over time,

00:05:44.600 --> 00:05:47.950
like pinches, rotations, pans,
that sort of thing.

00:05:48.100 --> 00:05:51.300
They report updates over a period of
time as the user keeps interacting.

00:05:51.340 --> 00:05:55.850
So those we add just four more states,
began, changed, and ended,

00:05:55.990 --> 00:05:59.170
and then a canceled state where we can,
if we've already started recognize,

00:05:59.210 --> 00:05:59.930
we can still cancel.

00:06:00.650 --> 00:06:03.700
But so with that,
that's all the possibilities.

00:06:03.700 --> 00:06:05.700
So we've got a lot of possibilities in
the UI gesture recognizer state machine,

00:06:05.700 --> 00:06:08.950
just those seven states,
so significantly fewer than

00:06:08.960 --> 00:06:12.460
we would have ever had if we
started trying to build it before.

00:06:12.480 --> 00:06:15.430
And a pretty small number
of transitions that we can

00:06:15.430 --> 00:06:17.110
easily track and keep in mind.

00:06:17.140 --> 00:06:20.420
But the really great thing
about this state machine,

00:06:20.420 --> 00:06:24.180
and the part that makes it so much better
than what we were talking about before,

00:06:24.200 --> 00:06:28.020
is that this state machine
represents one of those gestures.

00:06:28.020 --> 00:06:30.730
So that's the state machine, for example,
for pan.

00:06:30.800 --> 00:06:33.200
And you can think of
that and build that data,

00:06:33.200 --> 00:06:36.510
and build that gesture completely
independently of all the others.

00:06:36.520 --> 00:06:39.220
Each of those other gestures that
we're trying to recognize has its own

00:06:39.220 --> 00:06:42.680
version of that state machine that's
independent from each other one.

00:06:42.680 --> 00:06:45.240
And you don't have to have a
lot of crossover between them.

00:06:45.240 --> 00:06:46.800
In fact, they're all independent.

00:06:46.820 --> 00:06:49.920
So when you're thinking about how you'll
write your individual gesture recognizer,

00:06:49.920 --> 00:06:53.370
you just think about that one,
and then worry about interactions

00:06:53.370 --> 00:06:55.470
with other gestures after the fact.

00:06:55.480 --> 00:06:58.450
So it really lets you focus on
just the one thing you're trying

00:06:58.450 --> 00:07:01.860
to recognize at any given time,
and keeps the code much,

00:07:01.960 --> 00:07:02.870
much simpler and cleaner.

00:07:03.200 --> 00:07:08.060
So once you've got your
gesture written then,

00:07:08.210 --> 00:07:11.210
which, in the case of all of these,
UIKit provides all these

00:07:11.210 --> 00:07:13.160
gesture recognizers,
so you don't even have to think

00:07:13.250 --> 00:07:15.880
about the implementations of these,
because they're already

00:07:15.880 --> 00:07:16.990
being handled by UIKit.

00:07:17.200 --> 00:07:20.550
All you end up thinking about is the
five gestures that you want to recognize,

00:07:20.740 --> 00:07:23.000
and then defining the
relationships between them.

00:07:23.120 --> 00:07:25.630
So for example, pinch and pan.

00:07:25.990 --> 00:07:29.270
You really want the user to be able
to pinch and pan at the same time.

00:07:29.500 --> 00:07:32.780
Now the default behavior with all
UI gesture recognizers is that any

00:07:32.780 --> 00:07:36.510
UI gesture recognizer that's recognizing
will be recognizing by itself.

00:07:36.560 --> 00:07:39.200
No two will recognize at the same time.

00:07:39.260 --> 00:07:41.480
But that may not be what
you want in all cases,

00:07:41.480 --> 00:07:44.000
so we could set up that pinch
and pan should be allowed

00:07:44.040 --> 00:07:45.910
to recognize simultaneously.

00:07:46.000 --> 00:11:33.400
[Transcript missing]

00:11:33.700 --> 00:14:26.200
[Transcript missing]

00:14:26.710 --> 00:14:31.760
With that new behavior in place,
when the user taps in the UI button,

00:14:31.760 --> 00:14:35.090
the button will perform its action and
the tap gesture recognizer will mod.

00:14:35.120 --> 00:14:38.640
Now, that's probably actually
what you want in most cases.

00:14:38.640 --> 00:14:43.000
What we've done in UIKit and iOS 6 is
actually made that the default behavior.

00:14:43.000 --> 00:14:46.820
There are a few different controls
that have adopted behaviors like this.

00:14:46.820 --> 00:14:48.390
I just want to go
through them real quick.

00:14:48.400 --> 00:14:52.560
We've got UIButton, UIPageControl,
UISEgmentedControl, and UISTepper.

00:14:52.820 --> 00:14:55.410
The primary point of all of
those controls is to look for

00:14:55.510 --> 00:14:56.920
taps inside of themselves.

00:14:56.920 --> 00:14:59.640
So they will always
prevent single-finger,

00:14:59.640 --> 00:15:03.070
single taps that are attached to
a super view from recognizing if

00:15:03.070 --> 00:15:04.870
the tap is also in this control.

00:15:04.880 --> 00:15:08.250
This is probably what you wanted anyway,
and now you'll just get

00:15:08.290 --> 00:15:09.760
it by default on iOS 6.

00:15:15.140 --> 00:15:17.840
Sorry about that.

00:15:17.950 --> 00:15:21.140
And then one other thing that's
similar to this is UI slider.

00:15:21.140 --> 00:15:25.020
The primary point of UI slider is
to look for fingers that are down

00:15:25.100 --> 00:15:28.520
in the slider's thumb and slide
left and right to track the slider.

00:15:28.520 --> 00:15:32.480
If you have tried to put your sliders
in places where there are swipe gesture

00:15:32.480 --> 00:15:36.190
recognizers or pan gesture recognizers,
you have probably found that

00:15:36.300 --> 00:15:38.000
your sliders stop working.

00:15:38.000 --> 00:15:42.050
You may have found this, for example,
in UI split view controller in

00:15:42.100 --> 00:15:44.320
iOS 5 with the new swipe behavior.

00:15:44.910 --> 00:15:47.820
In iOS 6,
UI sliders will prevent any swipes

00:15:47.820 --> 00:15:51.630
or pans for fingers starting in
their thumbs if they're on the

00:15:51.670 --> 00:15:53.350
same axis as the slider itself.

00:15:53.390 --> 00:15:55.220
So that problem is now fixed.

00:15:55.220 --> 00:15:57.610
So anyway,
hopefully that gives you a really good

00:15:57.610 --> 00:16:01.140
idea of why you want to be playing
in the UI gesture recognizer system.

00:16:01.140 --> 00:16:05.120
If you use the system itself
and follow its state machines,

00:16:05.160 --> 00:16:09.670
then you'll get all these interactions
for free and you won't have to

00:16:09.670 --> 00:16:11.950
build all that stuff yourself.

00:16:11.960 --> 00:16:14.540
So to talk a little bit about
how you can subclass things,

00:16:14.610 --> 00:16:17.560
Andy's going to come up
and talk a little bit here.

00:16:20.890 --> 00:16:21.690
Thanks Josh!

00:16:21.790 --> 00:16:25.720
Now you folks are in a talk that
begins with the word advanced,

00:16:26.060 --> 00:16:29.660
and so I'm not going to tell
you how to subclass things,

00:16:29.660 --> 00:16:30.190
per se.

00:16:30.210 --> 00:16:34.320
It's more just that we've been
building a lot of gesture recognizers

00:16:34.780 --> 00:16:38.250
over the last couple years,
and you all have too.

00:16:38.290 --> 00:16:40.670
And in building those
gesture recognizers,

00:16:40.670 --> 00:16:42.090
we've run into some issues.

00:16:42.100 --> 00:16:46.070
And I know from being in the labs
and reading on certain mailing

00:16:46.120 --> 00:16:48.530
lists that you all have as well.

00:16:48.790 --> 00:16:53.220
And so rather than telling you which
methods to override and how the colon

00:16:53.220 --> 00:16:57.390
works in the @interface declaration,
I'm going to talk about some of

00:16:57.480 --> 00:17:01.230
the issues that we and you all have
run into so that I can help you

00:17:01.330 --> 00:17:05.560
avoid them when you're implementing
future gesture recognizers.

00:17:05.560 --> 00:17:10.030
We're going to talk about three issues,
and the first one is what should

00:17:10.030 --> 00:17:13.280
you do when your gesture recognizes?

00:17:13.280 --> 00:17:15.700
It seems like a really
elemental question,

00:17:15.700 --> 00:17:18.710
and it seems like you should
have a tremendous amount of

00:17:18.790 --> 00:17:20.230
control and liberty over this.

00:17:20.240 --> 00:17:22.920
I mean, you can do whatever you want
when your gesture recognizes.

00:17:22.920 --> 00:17:24.500
You can execute arbitrary code.

00:17:24.500 --> 00:17:27.220
That's what code is.

00:17:27.220 --> 00:17:31.170
But there are some issues
if you do just anything.

00:17:31.320 --> 00:17:33.940
So say that you have a gesture recognizer
that's going to try to recognize

00:17:34.010 --> 00:17:37.340
when the user draws in a circle.

00:17:37.640 --> 00:17:40.080
So it's a discrete gesture recognizer.

00:17:40.080 --> 00:17:44.530
And if you implement it in this fashion,
where you're just going

00:17:44.610 --> 00:17:47.340
to tell your delegate,
hey, I found a circle.

00:17:47.340 --> 00:17:48.180
The user drew it.

00:17:48.210 --> 00:17:51.580
That might seem like a really
straightforward approach.

00:17:51.580 --> 00:17:56.710
Because on Cocoa and Cocoa Touch,
we have this delegate design pattern

00:17:56.710 --> 00:18:02.880
wherein objects tell other interested
objects when interesting things happen.

00:18:02.900 --> 00:18:05.620
And so you might think, well,
the user drew a circle.

00:18:05.620 --> 00:18:07.860
That's what this is for.

00:18:07.860 --> 00:18:08.900
So that's what's interesting.

00:18:08.900 --> 00:18:12.580
And so I'm going to tell the
interested party about this thing.

00:18:12.580 --> 00:18:17.240
The problem with this approach is that
you don't get to take advantage of

00:18:17.340 --> 00:18:22.010
all of the fanciness that Josh just
got finished telling you about.

00:18:22.020 --> 00:18:25.370
So the whole point of the gesture
recognizer system is that you

00:18:25.370 --> 00:18:29.110
get to write these self-contained
little components and then define

00:18:29.110 --> 00:18:31.240
how they interact with each other.

00:18:31.660 --> 00:18:34.570
In order for those
interactions to work properly,

00:18:34.620 --> 00:18:39.380
like require gesture recognizer to fail
and should recognize simultaneously,

00:18:39.380 --> 00:18:41.660
and just the standard
exclusion behaviors,

00:18:41.660 --> 00:18:44.960
the system needs to understand what's
going on with your gesture recognizer.

00:18:44.960 --> 00:18:46.260
Is it recognized?

00:18:46.260 --> 00:18:47.330
Is it failing?

00:18:47.330 --> 00:18:48.710
What's happening?

00:18:48.750 --> 00:18:53.330
And so the number one responsibility
for you as a subclasser is to move your

00:18:53.330 --> 00:18:58.360
gesture recognizer through this state
machine that Josh was talking about.

00:18:58.360 --> 00:19:01.070
You need to tell the
system what's going on.

00:19:01.500 --> 00:19:05.230
So that it can make the other gestures,
which maybe you don't even control,

00:19:05.260 --> 00:19:06.580
react accordingly.

00:19:06.580 --> 00:19:09.760
For the example we just had,
it's pretty simple.

00:19:09.760 --> 00:19:13.550
Instead of messaging your delegate,
you just set the state of that

00:19:13.550 --> 00:19:15.840
gesture recognizer to recognized.

00:19:15.840 --> 00:19:21.420
And what was your delegate can
subscribe to an action resulting from

00:19:21.420 --> 00:19:27.790
that by just adding a target action
pair where the delegate is the target.

00:19:29.330 --> 00:19:31.930
You'll also have to import this
UI Gesture Recognizer subclass

00:19:31.930 --> 00:19:34.450
header if you weren't already,
because set state is not

00:19:34.510 --> 00:19:35.820
in the standard header.

00:19:35.820 --> 00:19:38.190
It's only for subclasses.

00:19:38.500 --> 00:19:41.530
But actually,
we aren't done yet because we told the

00:19:41.530 --> 00:19:46.660
system when the user is drawn a circle,
but we haven't explained to the system

00:19:46.880 --> 00:19:54.270
when exactly it is impossible that what
the user is doing presently is a circle.

00:19:55.110 --> 00:19:57.480
In particular,
what if the user lifts all his fingers

00:19:57.520 --> 00:19:58.550
and he hasn't drawn a circle yet?

00:19:58.710 --> 00:20:02.540
Or what if he's drawing with
his fingers and it turns into

00:20:02.540 --> 00:20:04.690
the system crumple gesture?

00:20:04.690 --> 00:20:07.790
That's not a circle anymore,
and we need to tell the gesture

00:20:07.790 --> 00:20:11.570
recognizer system about that so
that any gestures that are waiting

00:20:11.570 --> 00:20:15.710
for the circle-recognizing gesture
to fail are allowed to proceed.

00:20:35.960 --> 00:20:36.020
In particular,
what if the user lifts all his fingers

00:20:36.020 --> 00:20:36.020
and he hasn't drawn a circle yet?

00:20:36.020 --> 00:20:36.020
Or what if the gesture recognizer system
about that is not allowed to proceed?

00:20:36.020 --> 00:20:36.020
That's not a circle anymore,
and we need to tell the gesture

00:20:36.020 --> 00:20:36.020
recognizer system about that so
that any gestures that are waiting

00:20:36.020 --> 00:20:36.020
for the circle-recognizer system
to fail are allowed to proceed.

00:20:37.000 --> 00:20:39.940
For that circle recognizer,
for basically every recognizer,

00:20:40.010 --> 00:20:42.960
you're going to be doing a lot of math
with the locations of your touches.

00:20:42.960 --> 00:20:47.640
That's how you're going to determine,
is this the gesture that I'm looking for?

00:20:47.640 --> 00:20:51.310
When you're doing that math,
you have to pick a coordinate

00:20:51.310 --> 00:20:53.430
system in which you do the math.

00:20:53.530 --> 00:20:55.170
It's essentially a reference frame.

00:20:55.180 --> 00:20:58.560
And there's a number of different
choices you can make and a number of

00:20:58.560 --> 00:21:03.460
different consequences that will happen
if you choose any particular one.

00:21:03.480 --> 00:21:06.030
Let's look at this example here.

00:21:06.380 --> 00:21:09.660
Say that you've got a scroll view,
and in each of those little squares,

00:21:09.660 --> 00:21:11.120
there's a tap gesture recognizer.

00:21:13.060 --> 00:21:15.500
Let's talk about how we would
implement the Tap Gesture Recognizer,

00:21:15.500 --> 00:21:18.350
and I'm going to let you in on
a bug that we had in our initial

00:21:18.350 --> 00:21:20.920
implementation of Tap Gesture Recognizer.

00:21:21.110 --> 00:21:23.970
We made a mistake here,
and I'm going to try to help you

00:21:23.970 --> 00:21:25.920
avoid making the same mistake.

00:21:26.340 --> 00:21:31.960
Let's say that we're going to use the
views coordinate system to consider

00:21:31.960 --> 00:21:34.280
whether the user is tapped or not.

00:21:34.420 --> 00:21:37.640
We'll define a tap as the user's
put his finger down and then

00:21:37.640 --> 00:21:40.790
lifted it in mostly the same place.

00:21:42.100 --> 00:21:44.820
So if the user puts his finger down here,
remember we're considering

00:21:44.820 --> 00:21:47.500
the location of that touch in
the view's coordinate system.

00:21:47.500 --> 00:21:49.320
That's the teal square.

00:21:49.520 --> 00:21:52.170
And consequently,
the location of that touch will be

00:21:52.280 --> 00:21:55.510
considered relative to the upper
left-hand corner of that square.

00:21:55.580 --> 00:21:58.140
So we write down that location,
and then the user scrolls

00:21:58.160 --> 00:22:01.110
his finger up and lifts it,
but relative to the upper

00:22:01.110 --> 00:22:05.110
left-hand corner of that square,
it hasn't moved at all.

00:22:05.220 --> 00:22:07.980
So the system thinks, "Oh,
the user tapped."

00:22:08.430 --> 00:22:10.600
Not quite.

00:22:10.600 --> 00:22:11.730
That was a pan, not a tap.

00:22:11.920 --> 00:22:16.080
So in order to solve this issue,
we need a better reference frame for

00:22:16.080 --> 00:22:18.380
our touch than the gesture's view.

00:22:18.380 --> 00:22:23.890
We found that in most cases,
using the screen coordinate system to

00:22:23.890 --> 00:22:26.690
do your touch math makes the most sense.

00:22:26.820 --> 00:22:30.990
So here, in order to accomplish that,
I've converted the incoming

00:22:31.050 --> 00:22:36.850
touch's location to the window
of the gesture recognizer's view.

00:22:36.850 --> 00:22:40.680
And then I've used this UI window method
to convert the point from the window to

00:22:40.680 --> 00:22:43.060
the screen which contains the window.

00:22:43.060 --> 00:22:45.250
So now when the user
puts his finger down,

00:22:45.250 --> 00:22:48.910
we're considering that location
not relative to the upper left-hand

00:22:48.910 --> 00:22:51.540
corner of the teal square,
but rather to the upper

00:22:51.540 --> 00:22:53.590
left-hand corner of the screen.

00:22:53.880 --> 00:22:58.730
And so when the user moves his
finger... The tap gesture recognizer

00:22:58.730 --> 00:23:03.450
correctly sees that it didn't arrive
and lift in the same location,

00:23:03.570 --> 00:23:07.850
and it says, "Okay,
that's not a tap." It gets it right.

00:23:08.150 --> 00:23:10.400
So in general,
when you're doing a touch map,

00:23:10.400 --> 00:23:13.260
it's usually best to
use screen coordinates,

00:23:13.260 --> 00:23:18.340
not only for processing incoming touches
that are arriving and the touches began,

00:23:18.340 --> 00:23:21.710
moved, ended methods,
but also for any touches which you're

00:23:21.890 --> 00:23:26.800
saving as an instance variable in your
gesture recognizer to do math with later.

00:23:26.800 --> 00:23:31.390
It's best to save those
in screen coordinates.

00:23:33.030 --> 00:23:35.300
Shifting touch sets.

00:23:35.330 --> 00:23:38.480
They're a tricky issue because
you might have implemented a

00:23:38.500 --> 00:23:43.370
gesture recognizer to deal with a
single touch or maybe two touches,

00:23:43.370 --> 00:23:45.930
but what happens if the user
changes the number of touches

00:23:46.480 --> 00:23:48.870
while your gesture is in flight?

00:23:50.320 --> 00:23:56.410
Let's consider a novel gesture,
not included with UIKit, called the tap,

00:23:56.560 --> 00:24:00.500
pause, and pan gesture recognizer.

00:24:00.980 --> 00:24:03.810
So the user puts his finger
down in this square and pauses,

00:24:04.050 --> 00:24:06.100
pans across the screen.

00:24:06.150 --> 00:24:10.130
What we'd like to have happen is have
the square follow the user's finger.

00:24:10.420 --> 00:24:15.620
Maybe we're in some kind of outlining
application where this is the sane way

00:24:15.690 --> 00:24:18.560
to move items around on the canvas.

00:24:18.990 --> 00:24:22.100
So it's pretty easy to do this
for the single finger case.

00:24:22.230 --> 00:24:27.300
You just move the box by the
difference between the user's present

00:24:27.300 --> 00:24:30.540
location and his starting location.

00:24:30.660 --> 00:24:32.270
So all is well.

00:24:32.810 --> 00:24:35.960
But what if the user
puts two fingers down?

00:24:36.000 --> 00:24:37.040
What does current point mean?

00:24:37.040 --> 00:24:39.040
What does start point mean?

00:24:39.050 --> 00:24:40.290
It doesn't really mean anything anymore.

00:24:40.460 --> 00:24:42.670
You can't just pick one of them.

00:24:42.780 --> 00:24:45.840
So instead, we consider this thing
called the centroid,

00:24:45.870 --> 00:24:49.420
which is just the average of
all of the user's touches.

00:24:49.570 --> 00:24:52.700
And now, as the user slides those two
touches across the screen,

00:24:52.700 --> 00:24:58.950
we can consider the current centroid's
location minus the initial centroid

00:24:58.950 --> 00:25:02.620
location and move the box by that amount.

00:25:03.020 --> 00:25:04.800
But that issue with Accentroid
is actually not the one

00:25:04.800 --> 00:25:05.940
I wanted to talk about today.

00:25:05.940 --> 00:25:07.040
It's just some background.

00:25:08.800 --> 00:25:12.100
The real issue is,
what if the user puts a finger down,

00:25:12.170 --> 00:25:17.030
pauses a moment,
moves with that one finger to the right,

00:25:17.030 --> 00:25:19.190
and then puts a second finger down?

00:25:20.220 --> 00:25:23.570
Well, the current centroid is now
below the start centroid,

00:25:23.570 --> 00:25:25.600
so that pox is going to move down.

00:25:26.840 --> 00:25:28.440
And then if the user
lifts that second finger,

00:25:28.460 --> 00:25:30.540
it'll jump right back up.

00:25:30.570 --> 00:25:32.460
I don't know about you,
but when I see this

00:25:32.460 --> 00:25:35.330
happen in applications,
I like to just sit there messing with it,

00:25:35.560 --> 00:25:38.680
putting one finger down and
then lifting it up again,

00:25:38.740 --> 00:25:40.220
being very, very sad.

00:25:40.260 --> 00:25:41.030
Very, very sad.

00:25:41.110 --> 00:25:44.630
So let's talk about how
not to make this happen.

00:25:45.750 --> 00:25:48.450
A little bit of math.

00:25:48.510 --> 00:25:53.120
What we'd like to have happen here is
for the translation of the box before

00:25:53.370 --> 00:25:58.300
the user changes the number of touches
to be equal to the translation of the box

00:25:58.300 --> 00:26:01.570
after the user puts that new finger down.

00:26:01.580 --> 00:26:05.140
But we can't just set these two
equations to be equal to each other.

00:26:05.140 --> 00:26:09.060
We know that that start centroid term
is going to be the same in both cases.

00:26:09.320 --> 00:26:12.500
And we just saw the old centroid and
the new centroid are not the same.

00:26:12.500 --> 00:26:12.870
It moved.

00:26:12.870 --> 00:26:15.970
So there's no way to make
it work with just this.

00:26:16.090 --> 00:26:19.560
We have to add an extra term
that here I'll call shift.

00:26:19.560 --> 00:26:24.910
It's going to account for the change
over time in the centroid as the

00:26:24.920 --> 00:26:28.260
user changes the touch confirmation.

00:26:30.570 --> 00:26:33.470
So we have this extra term,
and now if we set these two

00:26:33.570 --> 00:26:36.330
equations to be equal to each other,
we can solve for this shift term

00:26:36.600 --> 00:26:40.680
and see that every time the user
changes the number of touches,

00:26:40.710 --> 00:26:45.210
we're going to shift the shift
term by the difference between the

00:26:45.210 --> 00:26:47.900
old centroid and the new centroid.

00:26:49.220 --> 00:26:53.240
I think this will make some
more sense graphically.

00:26:53.250 --> 00:26:55.590
The user puts one finger down.

00:26:56.240 --> 00:26:58.020
And then when he puts
another finger down,

00:26:58.050 --> 00:26:59.380
you'll see that arrow there.

00:26:59.410 --> 00:27:01.760
That represents shift.

00:27:02.520 --> 00:27:06.460
So the system's calculating the current
centroid minus the start centroid,

00:27:06.460 --> 00:27:09.090
which would move the box
down and to the right.

00:27:09.260 --> 00:27:15.450
But the shift balances that by
moving it back up and to the left.

00:27:15.800 --> 00:27:18.180
And what it's doing will become
even clearer as the user slides

00:27:18.280 --> 00:27:19.630
his finger across screen.

00:27:19.730 --> 00:27:23.050
Really,
it makes it so that what you end up

00:27:23.050 --> 00:27:28.210
considering is not the current centroid
of the current touch configuration,

00:27:28.300 --> 00:27:33.210
but rather where the centroid of the
initial touch configuration would have

00:27:33.220 --> 00:27:37.300
been had it stayed the same and moved
around the screen in the same way.

00:27:37.620 --> 00:27:41.920
So that translation arrow is always going
to point to the tip of the shift arrow.

00:27:41.920 --> 00:27:44.390
Even as we continue
changing the touch set,

00:27:44.520 --> 00:27:49.000
recalculating the shift arrow,
you see that now it's balancing

00:27:49.000 --> 00:27:54.120
the current centroid being just
that lower right touch to point

00:27:54.120 --> 00:27:59.840
to even further away so that the
translation doesn't change at all.

00:27:59.900 --> 00:28:03.130
We've talked about how to
make subclasses of gesture

00:28:03.230 --> 00:28:05.490
recognizers that work properly.

00:28:05.490 --> 00:28:07.600
Now that we've got them working.

00:28:07.620 --> 00:28:09.620
Let's make them awesome.

00:28:09.710 --> 00:28:12.630
Josh is going to give you some
great techniques to make your

00:28:12.740 --> 00:28:14.510
gesture recognizers even better.

00:28:15.940 --> 00:28:17.360
All right, thanks, Andy.

00:28:17.400 --> 00:28:20.710
So what I want to talk about now for
a little bit is low-pass filters.

00:28:20.730 --> 00:28:21.610
So what?

00:28:21.610 --> 00:28:22.110
Why?

00:28:22.550 --> 00:28:24.070
What does that mean?

00:28:24.080 --> 00:28:28.020
So what you may find sometimes
when you're writing your gesture

00:28:28.020 --> 00:28:32.310
recognizers is that certain values
that you're computing or things that

00:28:32.400 --> 00:28:35.750
you're looking at over a period of
time might have some jitter in them,

00:28:35.760 --> 00:28:38.210
things that aren't quite as smooth
as you would hope that they would be.

00:28:38.890 --> 00:28:41.970
And one common technique for
removing jitter from a value

00:28:42.010 --> 00:28:45.320
that you're processing over
time is a low-pass filter.

00:28:45.340 --> 00:28:48.890
So let's take a look
at what I mean by that.

00:28:48.960 --> 00:28:51.280
And some common things that
might use this are things

00:28:51.280 --> 00:28:54.610
like pinch gesture recognizer,
pan gesture recognizer, rotation.

00:28:54.620 --> 00:28:57.920
And the reason that you end up
seeing them in this case pretty often

00:28:57.920 --> 00:29:01.510
is just because of the fact that
there are multiple fingers involved.

00:29:01.560 --> 00:29:04.800
The presence of multiple fingers and
the fact that you would be computing

00:29:04.830 --> 00:29:08.540
values based on the positions of
those multiple fingers can introduce,

00:29:08.820 --> 00:29:11.530
additional jitter into some
of your computations than you

00:29:11.530 --> 00:29:13.770
might have initially had if
you were just looking at one.

00:29:13.820 --> 00:29:16.920
So to really understand
why that might happen,

00:29:16.920 --> 00:29:20.280
let's take a look at how we
would calculate pinch velocity,

00:29:20.420 --> 00:29:22.260
for example,
in a pinch gesture recognizer.

00:29:22.420 --> 00:29:26.260
So let's say that this is an incredibly
enlarged version of a screen and that

00:29:26.260 --> 00:29:28.440
each of those little squares is a pixel.

00:29:28.440 --> 00:29:31.970
And let's have our user put two
fingers down somewhere on our screen.

00:29:32.020 --> 00:29:36.180
Now, granted,
this is a little bit expanded beyond

00:29:36.200 --> 00:29:38.270
what you'd actually have in real life.

00:29:38.820 --> 00:29:41.260
But at some point,
that finger has to be determined

00:29:41.330 --> 00:29:42.810
to be at a particular pixel.

00:29:42.820 --> 00:29:47.580
The positions that are reported
to you for individual touches,

00:29:47.610 --> 00:29:49.780
while the type of the
position is CGFloat,

00:29:49.860 --> 00:29:54.090
well, CGPoint, which is two CG floats,
those floating point values have

00:29:54.090 --> 00:29:57.930
only the granularity of individual
pixels for their accuracy.

00:29:58.010 --> 00:30:01.420
So we don't actually
report locations mid-pixel.

00:30:01.560 --> 00:30:05.120
So that means that even though here it
looks like our fingers have come down

00:30:05.120 --> 00:30:07.370
near the edges of two different pixels,
the values that you're going to

00:30:07.370 --> 00:30:07.710
get are going to be the same as
the values that you're going to get

00:30:07.710 --> 00:30:08.060
when you're looking at the screen.

00:30:08.060 --> 00:30:08.060
So that means that even though here it
looks like our fingers have come down

00:30:08.060 --> 00:30:08.140
near the edges of two different pixels,
the values that you're going to

00:30:08.140 --> 00:30:08.290
get are going to be the same as
the values that you're going to get

00:30:08.290 --> 00:30:08.570
when you're looking at the screen.

00:30:08.670 --> 00:30:11.800
are just going to represent
the whole pixel in its offset.

00:30:11.800 --> 00:30:15.460
So if we tried to calculate how
far apart these two fingers were,

00:30:15.460 --> 00:30:18.280
we would have to calculate the
difference between these two pixels,

00:30:18.280 --> 00:30:20.620
because that's all the information
that we have as far as the

00:30:20.620 --> 00:30:22.100
actual locations of the fingers.

00:30:22.100 --> 00:30:25.450
So in this case, we've got three pixels
horizontally and seven vertically.

00:30:25.460 --> 00:30:29.120
Now, if we go and calculate the
actual distance between those,

00:30:29.120 --> 00:30:32.620
we would do that just using a squared
plus b squared equals c squared.

00:30:32.620 --> 00:30:37.200
So we've got square root of the sum of
the squares of the sides of this triangle

00:30:37.200 --> 00:30:38.580
gives us the distance between those two.

00:30:38.580 --> 00:30:38.890
So we've got two touches.

00:30:38.900 --> 00:30:41.580
And that's, in this case, just 7.6.

00:30:41.580 --> 00:30:44.060
So 7.6 pixels is about our distance.

00:30:44.060 --> 00:30:46.240
But of course,
what we were trying to measure

00:30:46.240 --> 00:30:49.050
was that blue line there,
the solid blue line.

00:30:49.060 --> 00:30:51.470
But what we've actually measured
is the distance between the

00:30:51.470 --> 00:30:54.530
centers of those two pixels,
which is really bigger than the truth.

00:30:54.600 --> 00:30:58.280
Now, as the user moves their
finger closer together,

00:30:58.280 --> 00:31:00.820
let's say that they're going to
cross some pixel boundaries here.

00:31:00.820 --> 00:31:03.320
And that's going to cause these
next two pixels to light up,

00:31:03.460 --> 00:31:05.120
because those are the ones
that we now think we're in.

00:31:05.120 --> 00:31:07.350
Now, of course,
we've moved a pretty small amount,

00:31:07.360 --> 00:31:09.520
but yet we thought,
we've moved a whole pixel,

00:31:09.520 --> 00:31:11.860
because that's all the accuracy
we have in our reporting.

00:31:11.860 --> 00:31:14.630
So if we do the same thing again,
now we've still got three

00:31:14.630 --> 00:31:17.340
pixels horizontally,
but now we've got five vertically.

00:31:17.340 --> 00:31:21.690
So our distance that we'd calculate now
between those two is about 5.8 pixels.

00:31:23.420 --> 00:31:25.160
Again,
now let's keep the user moving their

00:31:25.160 --> 00:31:26.620
fingers closer and closer together.

00:31:26.620 --> 00:31:29.700
And they've moved about the same amount,
not very much more than before.

00:31:29.700 --> 00:31:30.620
It's roughly equivalent.

00:31:30.620 --> 00:31:32.970
And let's say that they were
moving at a constant speed,

00:31:33.080 --> 00:31:35.820
so the time between those two
movements was about the same.

00:31:35.820 --> 00:31:37.620
Now let's calculate another delta.

00:31:37.700 --> 00:31:40.830
This time we only have one
pixel difference horizontally,

00:31:40.830 --> 00:31:42.610
but vertically we've got five.

00:31:42.640 --> 00:31:47.080
So if we calculate that delta now,
we've got about 5.1 pixels of movement.

00:31:47.380 --> 00:31:51.350
So the difference between our first
two samples was about 1.8 pixels.

00:31:51.350 --> 00:31:54.790
The difference between our
second two was only about 0.7.

00:31:54.850 --> 00:31:57.160
So it's less than half,
but we moved about the same

00:31:57.160 --> 00:32:00.420
amount of physical distance and we
were doing it at the same speed.

00:32:00.420 --> 00:32:04.340
So if we were calculating velocity here,
we would have calculated two pretty

00:32:04.340 --> 00:32:07.780
wildly different velocities for
those three individual samples,

00:32:07.780 --> 00:32:11.460
the two velocities we could have gotten,
even though physically the fingers

00:32:11.700 --> 00:32:13.820
were moving at about the same speed.

00:32:13.840 --> 00:32:17.720
So we kind of have a limitation here
in our ability to accurately... So if

00:32:17.720 --> 00:32:22.620
we end up with that and we were just to
graph it over a period of time that was

00:32:22.700 --> 00:32:25.670
longer than those three touch samples,
you might find that your velocities

00:32:25.670 --> 00:32:28.570
look something like this for what
would otherwise seem to the user

00:32:28.570 --> 00:32:30.440
to be continuous physical movement.

00:32:30.440 --> 00:32:33.670
So that's kind of not what you want.

00:32:33.680 --> 00:32:37.190
And if this physical movement somehow
became visible to the user somehow,

00:32:37.220 --> 00:32:39.410
whatever the output of
this calculation was,

00:32:39.480 --> 00:32:42.850
was something that was reflected back
in the user interface in some way,

00:32:42.850 --> 00:32:46.340
say by tracking an object or something,
it might be noticeably

00:32:46.340 --> 00:32:47.360
jittery to the user.

00:32:47.360 --> 00:32:50.260
The fact that these are the
calculations we ended up performing.

00:32:50.260 --> 00:32:52.940
So we could apply a low-pass
filter to this data,

00:32:53.060 --> 00:32:57.090
which would smooth out some of these
high-frequency vibrations in the data

00:32:57.090 --> 00:32:59.660
and make it a much more consistent value.

00:32:59.660 --> 00:33:02.090
And that would end up looking
something a little more like that,

00:33:02.090 --> 00:33:04.000
which is much,
much closer to a constant velocity

00:33:04.000 --> 00:33:06.710
that the user actually thought
they were moving their finger at.

00:33:06.740 --> 00:33:09.380
So clearly,
that would improve our situation as far

00:33:09.380 --> 00:33:11.410
as the quality of the data that we got.

00:33:11.450 --> 00:33:12.870
So how would we do that?

00:33:12.950 --> 00:33:14.220
Like this.

00:33:14.220 --> 00:33:15.410
It's really easy.

00:33:15.420 --> 00:33:18.800
No, actually, I probably... I promise it
actually is really easy.

00:33:18.890 --> 00:33:21.500
I just threw a bunch of math up there to,
you know, scare you a little bit.

00:33:21.500 --> 00:33:25.800
But we're going to calculate the
velocity based on a particular time.

00:33:25.800 --> 00:33:28.480
So here we've got an equation
for the velocity at time t.

00:33:28.480 --> 00:33:34.620
All we have to do is pick some constant
that we're going to use as a multiplier.

00:33:34.900 --> 00:33:36.260
And here we've called that alpha.

00:33:36.400 --> 00:33:39.180
So alpha will be some
value between zero and one.

00:33:39.340 --> 00:33:42.870
And that's going to represent a
weighting towards the previous velocity.

00:33:42.880 --> 00:33:46.060
So you might pick any
value between zero and one,

00:33:46.060 --> 00:33:48.570
depending on how much you'd want to
weight towards the previous velocity

00:33:48.620 --> 00:33:49.720
that you had been calculating before.

00:33:49.720 --> 00:33:52.440
And we'll multiply that
times the previous velocity,

00:33:52.440 --> 00:33:53.950
v at t minus one.

00:33:53.960 --> 00:33:56.080
So what we had calculated one sample ago.

00:33:56.080 --> 00:33:58.470
So we're taking some percentage
of the previous velocity and

00:33:58.470 --> 00:33:59.710
using that as the new velocity.

00:33:59.720 --> 00:34:02.240
And then to that,
we're going to add the opposite

00:34:02.300 --> 00:34:05.620
percentage of the new velocity that
we just took as the current sample.

00:34:05.620 --> 00:34:07.180
So one minus that alpha.

00:34:07.180 --> 00:34:11.380
So if the alpha before had been 0.75,
this one would be 0.25.

00:34:11.380 --> 00:34:14.540
And we'd multiply that times
the current velocity sample.

00:34:14.540 --> 00:34:17.340
So the velocity we calculated based
on the difference between our...

00:34:17.340 --> 00:34:18.680
our most recent two touch points.

00:34:18.680 --> 00:34:20.940
And we'd add that in to our new velocity.

00:34:20.940 --> 00:34:23.320
So basically,
we've taken some percentage of

00:34:23.360 --> 00:34:26.140
the old velocity and added some
percentage of the new velocity.

00:34:26.140 --> 00:34:29.770
And now we've calculated what
we'll actually use as our value.

00:34:29.780 --> 00:34:32.460
So if that's not entirely
clear from the math,

00:34:32.560 --> 00:34:34.020
let's look at what it
would look like in code.

00:34:34.020 --> 00:34:37.740
You'd probably have some constant
value to represent alpha.

00:34:37.740 --> 00:34:40.200
So let's say we'll call it
previous velocity weight here.

00:34:40.200 --> 00:34:42.620
And that's just going to
be a constant CG float.

00:34:42.620 --> 00:34:43.880
Here I've picked 0.75.

00:34:43.880 --> 00:34:47.600
So then we'll add a new method
that we're going to call... every

00:34:47.600 --> 00:34:49.310
time we calculate a new velocity.

00:34:49.320 --> 00:34:52.820
So every new touch move that we get,
we're going to calculate an instant...

00:34:52.820 --> 00:34:55.970
a current velocity sample from
the current point and the previous

00:34:56.100 --> 00:34:57.320
point and the time between them.

00:34:57.400 --> 00:35:00.300
And then we'll pass it in to
this add velocity sample method.

00:35:00.320 --> 00:35:04.780
And what that's going to do is just
perform this alpha calculation.

00:35:04.860 --> 00:35:08.510
So we're going to multiply the
previous velocity weight times

00:35:08.890 --> 00:35:13.190
whatever our instance variable was
that was tracking our velocity.

00:35:13.410 --> 00:35:17.300
So let's say we had a... Let's
say we had an instance variable

00:35:17.300 --> 00:35:19.300
called... current velocity.

00:35:19.300 --> 00:35:21.300
That's what we're using to
track the velocity over time.

00:35:21.350 --> 00:35:23.220
So that's our previous velocity.

00:35:23.330 --> 00:35:25.300
We'll multiply that times
previous velocity weight.

00:35:25.300 --> 00:35:29.300
And to that we'll add in the factor
of the current velocity sample.

00:35:29.300 --> 00:35:31.830
So we're going to add to
our current velocity 1 minus

00:35:31.830 --> 00:35:33.300
previous velocity weight.

00:35:33.320 --> 00:35:35.300
That's the 1 minus alpha.

00:35:35.390 --> 00:35:37.300
Times that new velocity
sample that we just took.

00:35:37.300 --> 00:35:39.290
So it's really just two lines of code.

00:35:39.300 --> 00:35:41.300
It's not as complicated as
it seems like it might be.

00:35:41.300 --> 00:35:44.300
And really that's all there is to
implementing this low pass filter.

00:35:44.400 --> 00:35:47.280
And that would give us that smoother
line that we saw on that previous sample.

00:35:47.280 --> 00:35:49.090
previous graph.

00:35:49.270 --> 00:35:51.420
So we talked about what it
would look like if the user did

00:35:51.420 --> 00:35:54.490
this while moving their finger
at a really constant velocity.

00:35:54.520 --> 00:35:57.160
But what happens if the velocity changes?

00:35:57.160 --> 00:35:59.900
So let's say now that the
user was moving their finger,

00:35:59.900 --> 00:36:02.900
constant velocity, well, really two,
because we're talking

00:36:02.900 --> 00:36:03.760
about pinch velocity.

00:36:03.760 --> 00:36:06.830
And then at some point,
they just changed their speed,

00:36:06.830 --> 00:36:10.300
but they moved to a new, faster,
but still constant speed.

00:36:10.300 --> 00:36:13.240
The data, the raw data,
might have looked something like this.

00:36:13.240 --> 00:36:16.100
We had a velocity that was
pretty constant at the bottom,

00:36:16.200 --> 00:36:17.660
but we were getting jitter.

00:36:18.110 --> 00:36:20.830
And then they sped up, so it moved up,
but still jittery up there.

00:36:20.840 --> 00:36:24.420
So if we used our low-pass filter
and picked that value of 0.75

00:36:24.420 --> 00:36:27.510
that we've been talking about,
what we'd actually end up getting

00:36:27.510 --> 00:36:29.120
would look something more like this.

00:36:29.120 --> 00:36:31.640
So as you can see,
it's kind of now taking a little while

00:36:31.720 --> 00:36:35.030
to catch up to the new speed that
the user's moving their finger at.

00:36:35.060 --> 00:36:38.330
As I said, in this sample,
the user actually increased

00:36:38.360 --> 00:36:40.180
their velocity instantly.

00:36:40.180 --> 00:36:42.470
They just quickly started going faster.

00:36:42.480 --> 00:36:45.230
But our sampled low-pass
filtered velocity seems to

00:36:45.230 --> 00:36:46.880
take a while to get up there.

00:36:46.880 --> 00:36:48.770
This is the trade-off that you get.

00:36:48.880 --> 00:36:50.880
When you start implementing
this low-pass filter,

00:36:50.880 --> 00:36:53.510
it's going to take a little time
for the value that you're actually

00:36:53.620 --> 00:36:55.340
filtering to track up to the new value.

00:36:55.380 --> 00:36:58.300
Now, the time that it takes, though,
will be based on the value

00:36:58.400 --> 00:36:59.790
of alpha that you've chosen.

00:36:59.800 --> 00:37:04.520
So this kind of becomes an
individual choice for you,

00:37:04.520 --> 00:37:07.160
depending on what kind of
value you're trying to filter.

00:37:07.160 --> 00:37:09.980
If it's something that isn't
immediately visible to the user,

00:37:10.030 --> 00:37:12.560
what the value is,
you might be able to get away

00:37:12.560 --> 00:37:14.950
with a larger value of alpha,
because the fact that it's catching up

00:37:14.950 --> 00:37:16.120
a little slower may not be a good thing.

00:37:16.120 --> 00:37:18.090
Maybe you're just using it internally
for some other calculations.

00:37:18.120 --> 00:37:23.110
But if the user is going to really
notice directly whether or not,

00:37:23.120 --> 00:37:23.120
you know,
if there's lag introduced by this

00:37:23.120 --> 00:37:24.110
calculation you're performing,
then you probably want to use

00:37:24.120 --> 00:37:29.120
a smaller value for alpha,
because that will avoid some of this.

00:37:29.120 --> 00:37:33.090
So, for example,
if we had chosen 0.5 instead of 0.75,

00:37:33.200 --> 00:37:38.120
we'd get this green line,
which is much closer tracking towards the

00:37:38.120 --> 00:37:38.120
actual velocity the user was going at.

00:37:38.120 --> 00:37:40.120
It's, you know,
higher up there than the white line.

00:37:40.120 --> 00:37:42.120
But the downside is that we've
lost some of that green line.

00:37:42.200 --> 00:37:44.120
So we're going to have to do
a little bit more of that.

00:37:44.120 --> 00:37:46.120
So we're going to have to do
a little bit more of that.

00:37:46.120 --> 00:37:48.110
And that's kind of the
benefit of the filter.

00:37:48.160 --> 00:37:50.650
It gets there faster,
but it also has more of the original

00:37:50.650 --> 00:37:52.080
jitter still in that signal.

00:37:52.160 --> 00:37:55.610
If you had chosen a bigger
velocity of -- sorry,

00:37:55.610 --> 00:37:58.850
a bigger value of alpha, say 0.9,
it would take even longer to

00:37:58.850 --> 00:38:01.110
catch up and would look probably
something more like that.

00:38:01.120 --> 00:38:03.120
So there's tradeoffs.

00:38:03.120 --> 00:38:05.500
And really,
if you're using this in your own apps,

00:38:05.500 --> 00:38:07.580
I would, you know,
try different values for

00:38:07.640 --> 00:38:09.110
your particular use cases.

00:38:09.160 --> 00:38:11.840
You may find that one feels better
than another in a particular case,

00:38:11.860 --> 00:38:14.040
depending on what it is that
you're trying to filter.

00:38:14.120 --> 00:38:16.110
But that's the general idea.

00:38:16.120 --> 00:38:18.820
And hopefully gives you an idea of
what kind of things you might decide

00:38:18.820 --> 00:38:22.100
to try if you're finding that you're
seeing some jitter in your applications.

00:38:22.120 --> 00:38:25.430
So with that in mind,
Andy's going to come up and show us

00:38:25.430 --> 00:38:30.090
another advanced signal processing
technique for smoothing curves.

00:38:31.900 --> 00:38:33.700
Thanks.

00:38:33.700 --> 00:38:37.940
So Josh just taught you about
how to smooth out data over time.

00:38:38.040 --> 00:38:41.500
Let's talk about how to
smooth out data over space.

00:38:41.690 --> 00:38:45.800
Say that you're implementing something
which requires showing the user a

00:38:45.870 --> 00:38:50.700
visual representation of the path
that their fingers traced on screen.

00:38:50.830 --> 00:38:52.720
You're writing a
handwriting recognition app.

00:38:52.830 --> 00:38:55.480
You're writing an app for
casting magical spells,

00:38:55.480 --> 00:38:59.700
and you need to draw some ancient rune
and show the user what they're doing.

00:38:59.840 --> 00:39:02.710
So this section is for you.

00:39:02.860 --> 00:39:05.060
Say that the user draws a
beautiful squiggle just like

00:39:05.060 --> 00:39:06.200
the one I've created here.

00:39:06.310 --> 00:39:08.330
That's lovely,
and we would love to have our

00:39:08.420 --> 00:39:11.570
application reflect the beautiful
squiggle back at the user so

00:39:11.670 --> 00:39:14.030
that he can see what he's doing.

00:39:14.130 --> 00:39:16.450
There's just one problem,
which is that your application doesn't

00:39:16.450 --> 00:39:18.100
receive the beautiful squiggle.

00:39:18.220 --> 00:39:22.800
Your application receives six points,
because that's all the temporal

00:39:22.800 --> 00:39:24.690
resolution that we have.

00:39:24.970 --> 00:39:28.940
and from those six points,
it's now your job to try to reconstruct

00:39:29.440 --> 00:39:33.610
as close an approximation as you
can of that beautiful squiggle.

00:39:33.680 --> 00:39:37.170
Of course, there's no way to actually
do this perfectly,

00:39:37.170 --> 00:39:40.650
but hopefully with what I show you,
you can get a little bit closer.

00:39:40.860 --> 00:39:44.430
This is what most people tend to do,
is connect the dots.

00:39:44.780 --> 00:39:50.810
And if I were the user and I saw this,
I would be a little upset.

00:39:51.220 --> 00:39:52.720
This isn't what I drew.

00:39:52.730 --> 00:39:54.600
You're making me look bad.

00:39:54.620 --> 00:39:57.270
This isn't my magical spell at all.

00:39:57.720 --> 00:39:58.580
It's very sad.

00:39:58.580 --> 00:40:01.750
So with what I'm going to show you,
it'll end up looking a

00:40:01.750 --> 00:40:03.740
little bit more like this.

00:40:03.740 --> 00:40:07.020
No, it isn't exactly
tracking the orange line,

00:40:07.090 --> 00:40:07.780
but that's impossible.

00:40:07.780 --> 00:40:10.450
You don't have enough information
to exactly track the orange line.

00:40:10.680 --> 00:40:14.330
So what we're going to do
is make some trade-offs,

00:40:14.330 --> 00:40:18.710
and we're going to track it
less closely in some places and

00:40:18.710 --> 00:40:23.870
more closely in other places,
and just like with the low-pass filter,

00:40:23.870 --> 00:40:23.870
make some kind of smooth approximation.

00:40:24.120 --> 00:40:30.890
We're going to do that with this thing
called UiPezierPath Quadratic Curves.

00:40:30.890 --> 00:40:32.940
You can see the indication at
the top of the screen there.

00:40:32.940 --> 00:40:36.750
Let's talk in a little more depth
about what the heck those are.

00:40:36.880 --> 00:40:40.730
Previously,
when you had a series of touch samples

00:40:40.740 --> 00:40:46.010
and you just connected the dots,
you drew lines between each point.

00:40:46.210 --> 00:40:51.520
and the parameters that specified that
line were the start and end points.

00:40:51.790 --> 00:40:54.200
That's all you need to draw a line.

00:40:54.320 --> 00:40:57.620
But with a quadratic Bezier curve,
there's a third point.

00:40:57.740 --> 00:40:59.240
There's this control point.

00:40:59.360 --> 00:41:01.080
Here it's a circle.

00:41:01.220 --> 00:41:02.480
And the line doesn't
go through the circle.

00:41:02.480 --> 00:41:04.520
The control point does something else.

00:41:04.700 --> 00:41:08.880
It specifies a few things about
the properties of the curve.

00:41:09.230 --> 00:41:13.900
First, the further that the control
point is from the line connecting

00:41:13.900 --> 00:41:16.610
the start and end points,
the sharper the curve

00:41:16.740 --> 00:41:18.880
connecting them is going to be.

00:41:19.280 --> 00:41:23.460
And then second, the closer the control
point is to one side,

00:41:23.460 --> 00:41:27.320
the more the curve is going
to be skewed that way.

00:41:27.960 --> 00:41:30.070
Now that you have an
intuitive explanation,

00:41:30.080 --> 00:41:31.320
let's talk about code.

00:41:31.320 --> 00:41:34.440
You can make this happen in
your application by moving a

00:41:34.440 --> 00:41:37.140
UI Bezier path to the start point.

00:41:37.140 --> 00:41:40.260
And then instead of
saying add line to point,

00:41:40.260 --> 00:41:42.790
you can say add quad curve to point.

00:41:42.790 --> 00:41:46.900
And then there's this extra
control point argument.

00:41:48.130 --> 00:41:52.410
These Bezier paths have a lot of
really nice mathematical properties,

00:41:52.410 --> 00:41:54.220
and those have helped me
understand them over time.

00:41:54.220 --> 00:41:57.510
One that I really like,
that helps me get a good

00:41:57.510 --> 00:42:02.000
grasp on what this thing is,
is that the curve which results

00:42:02.000 --> 00:42:05.480
from the code like this,
it's the only parabola that passes

00:42:05.980 --> 00:42:11.860
through the start and the endpoints,
but which has the tangent at the endpoint

00:42:11.860 --> 00:42:15.600
and the tangent at the start point both
passing through the control points.

00:42:16.160 --> 00:42:18.730
So now going back to this,
we have to figure out how to

00:42:18.830 --> 00:42:23.200
turn those touch samples into a
series of quadratic Bezier curves,

00:42:23.220 --> 00:42:25.970
which means essentially
figuring out start,

00:42:25.970 --> 00:42:29.580
end, and control points,
given these six input points.

00:42:31.440 --> 00:42:33.310
What should we use as the control points?

00:42:33.490 --> 00:42:36.640
Well,
if we use the midpoints between each

00:42:36.660 --> 00:42:39.980
of the touch samples that we have,
then we'll just get a straight line.

00:42:40.040 --> 00:42:42.200
Because remember,
the further the control point is from the

00:42:42.200 --> 00:42:46.170
line connecting the start and end points,
the more curvy the curve is.

00:42:46.320 --> 00:42:48.480
So instead, what we're going to do

00:42:49.190 --> 00:42:55.170
is we're going to use the actual touch
samples the system gave us as midpoints.

00:42:55.720 --> 00:42:58.470
And sorry, as control points,
we're going to use the touch samples

00:42:58.470 --> 00:43:00.180
the system gave us as control points.

00:43:00.180 --> 00:43:04.850
And we're going to use the midpoints
between the touch samples the system

00:43:04.850 --> 00:43:07.570
gave us as the start and end locations.

00:43:07.580 --> 00:43:10.790
And that way we won't exactly
curve through the touch samples

00:43:11.000 --> 00:43:14.140
that the system gave us,
but we'll sort of curve around them,

00:43:14.460 --> 00:43:17.560
taking a little bit on one side
and giving it back on the other,

00:43:17.560 --> 00:43:21.090
creating a more smooth
approximation of the user's curve.

00:43:22.120 --> 00:43:25.110
This has been a lot of talk,
but in our industry, talk is cheap.

00:43:25.110 --> 00:43:26.010
Let's code.

00:43:28.190 --> 00:43:33.980
This is a spellcasting application,
and here is my magical rune.

00:43:35.110 --> 00:43:40.420
The only problem with my magical rune
is that it's really ugly and blocky,

00:43:40.500 --> 00:43:42.000
and it makes me look bad.

00:43:42.000 --> 00:43:47.150
Let's try to fix this situation
up using what we've just learned.

00:43:49.430 --> 00:43:53.000
To give you a brief tour
of the project here,

00:43:53.000 --> 00:43:58.340
the only code that we really care
about is in this curve renderer class.

00:43:58.500 --> 00:44:01.890
This curve renderer class
has one public method,

00:44:01.890 --> 00:44:07.410
which renders a set of location samples
into an image of a particular size.

00:44:09.180 --> 00:44:12.570
And all that method does
is create the image,

00:44:12.640 --> 00:44:17.390
set some drawing parameters,
fetch a path, a UI Bezier path,

00:44:17.650 --> 00:44:18.980
and then stroke it.

00:44:19.170 --> 00:44:22.620
So the real part that we care
about here is this method which

00:44:22.620 --> 00:44:25.160
generates the UI Bezier path.

00:44:25.720 --> 00:44:28.790
And right now,
it's generating a UI Bezier

00:44:28.870 --> 00:44:32.000
path that connects the dots,
like I was showing you in

00:44:32.010 --> 00:44:33.210
the slides a moment ago.

00:44:33.330 --> 00:44:36.030
And that's why my path looks so bad.

00:44:36.900 --> 00:44:41.620
So this generates a path which
starts at the first location,

00:44:41.620 --> 00:44:44.800
then looping through all of
the rest of the locations,

00:44:44.830 --> 00:44:46.370
just adds a line to each one.

00:44:46.400 --> 00:44:49.920
We're going to replace this
with an implementation which

00:44:50.290 --> 00:44:52.440
uses quadratic Bezier curves.

00:44:54.800 --> 00:44:57.130
Now we still want to start
with the first location,

00:44:57.130 --> 00:44:58.490
so this line can stay.

00:44:58.610 --> 00:45:02.990
And if there's only one location sample,
we can just have a dot,

00:45:03.150 --> 00:45:07.490
which we get by having a line starting at
one point and ending at the same point.

00:45:07.490 --> 00:45:08.840
So this code can stay too.

00:45:08.940 --> 00:45:13.520
What we care about is
this else statement.

00:45:13.550 --> 00:45:16.330
So it's actually going to
start basically the same way,

00:45:16.330 --> 00:45:17.260
with a straight line.

00:45:17.260 --> 00:45:19.360
This is a detail I didn't
show you in the slides,

00:45:19.460 --> 00:45:24.760
but it's one that emerges when you
try to actually implement this thing.

00:45:24.760 --> 00:45:28.680
I said that we were going
to use the midpoints

00:45:29.200 --> 00:45:42.500
[Transcript missing]

00:45:42.610 --> 00:45:47.000
The problem with that is what do
we do with the first midpoint?

00:45:47.010 --> 00:45:49.620
I said the midpoints are going
to be the start and endpoints.

00:45:49.720 --> 00:45:53.060
So how do we get from the first
touch sample to the first midpoint?

00:45:53.090 --> 00:45:55.450
We don't know how curvy it should be.

00:45:56.200 --> 00:46:00.950
The easy solution, one solution,
is to just draw a straight line.

00:46:01.000 --> 00:46:04.550
So we're going to draw a straight
line from the first touch sample to

00:46:04.850 --> 00:46:09.360
the first midpoint and from the last
midpoint to the last touch sample.

00:46:09.360 --> 00:46:11.940
And then we'll curve between
everything in between.

00:46:14.650 --> 00:46:16.140
So that's all we're doing here.

00:46:16.140 --> 00:46:19.600
I'm using a little helper function
here called CGPointMid that just

00:46:19.600 --> 00:46:23.230
calculates the midpoint between two
CG points by adding together each of the

00:46:23.240 --> 00:46:25.660
components and then dividing them by two.

00:46:26.010 --> 00:46:28.380
So I fetch the second location.

00:46:28.400 --> 00:46:30.780
I get the midpoint between
the first and second location,

00:46:30.850 --> 00:46:33.130
and I draw a straight line to that point.

00:46:34.240 --> 00:46:36.590
Once I've done that,
we're going to loop over all

00:46:36.590 --> 00:46:38.400
of the remaining locations.

00:46:38.490 --> 00:46:42.000
But because I said we're going to
draw a straight line from the last

00:46:42.130 --> 00:46:45.040
midpoint to the last touch sample,
we're going to leave out

00:46:45.240 --> 00:46:47.340
the last touch sample.

00:46:50.510 --> 00:46:54.720
So for each location
that the system gives us,

00:46:54.720 --> 00:46:57.840
we're going to calculate
the midpoint between that

00:46:57.850 --> 00:47:00.690
location and the next location.

00:47:00.830 --> 00:47:04.300
And like I said,
once we've got that midpoint,

00:47:04.300 --> 00:47:09.900
we're going to add a quadratic Bezier
path connecting the last point we were

00:47:10.140 --> 00:47:15.550
at and that midpoint using the current
location the actual touch sample the

00:47:15.550 --> 00:47:20.410
system gave us as the control point,
which will control how

00:47:20.410 --> 00:47:22.970
curvy the line should be.

00:47:23.100 --> 00:47:26.170
This is all there is for
creating the quadratic curves.

00:47:27.330 --> 00:47:31.250
Once we've done that,
I add a straight line from the last

00:47:31.250 --> 00:47:34.170
midpoint to the last touch sample.

00:47:34.930 --> 00:47:38.220
If we build and run,
then we'll see much nicer curves when

00:47:38.220 --> 00:47:40.680
I scribble furiously on the screen.

00:47:42.000 --> 00:49:39.600
[Transcript missing]

00:49:40.320 --> 00:49:44.930
The Event Handling Guide for iOS
contains more wonderful pieces of

00:49:45.100 --> 00:49:47.760
knowledge and so do your heads,
so you can help each other

00:49:47.770 --> 00:49:48.770
on the developer forums.

00:49:48.770 --> 00:49:51.660
The link is down below.

00:49:51.920 --> 00:49:54.210
There's one session that
may be useful to you,

00:49:54.340 --> 00:49:56.300
and it's the session that just passed.

00:49:56.400 --> 00:49:58.150
So maybe catch it on video.

00:49:58.260 --> 00:50:01.030
It's just called "What's
New with Gestures?" But it's

00:50:01.030 --> 00:50:05.100
actually about MacOSX,
which has some new gesture stuff.

00:50:05.100 --> 00:50:07.900
And so if you're doing cross-platform
things or you're an iOS developer

00:50:07.900 --> 00:50:11.740
who's maybe interested in the Mac,
you might check out that video to

00:50:11.890 --> 00:50:14.270
learn about what's going on over there.

00:50:14.550 --> 00:50:16.700
Enjoy the rest of your week at WWDC.

00:50:16.700 --> 00:50:18.500
Thank you for coming.