WEBVTT

00:00:29.716 --> 00:00:30.086
>> Thank you.

00:00:30.856 --> 00:00:31.806
Good afternoon, everyone.

00:00:32.546 --> 00:00:34.146
Welcome to the session "What's

00:00:34.146 --> 00:00:35.166
New in Audio?"

00:00:36.156 --> 00:00:37.486
I'm Akshatha Nagesh, from the

00:00:37.486 --> 00:00:39.786
Audio Team, and today, I would

00:00:39.786 --> 00:00:41.626
like to share with you all the

00:00:41.626 --> 00:00:43.706
new, exciting features we have

00:00:43.706 --> 00:00:45.606
in audio in this year's OS

00:00:45.606 --> 00:00:45.996
releases.

00:00:46.636 --> 00:00:49.906
I'll begin with a quick overview

00:00:50.076 --> 00:00:50.956
of the audio stack.

00:00:52.216 --> 00:00:54.126
Audio frameworks offer a wide

00:00:54.276 --> 00:00:56.426
variety of APIs, and our main

00:00:56.426 --> 00:00:58.556
goal is to help you deliver an

00:00:58.556 --> 00:01:00.436
exceptional audio experience to

00:01:00.436 --> 00:01:01.826
the end user, through your apps.

00:01:03.326 --> 00:01:04.946
At the top, we have the AV

00:01:04.946 --> 00:01:06.826
foundation framework, with APIs

00:01:06.826 --> 00:01:09.576
like AVAudioSession, Engine,

00:01:09.826 --> 00:01:11.756
Player, Recorder, etcetera.

00:01:12.736 --> 00:01:14.486
And these APIs cater to the

00:01:14.486 --> 00:01:16.086
needs of most of the apps.

00:01:17.216 --> 00:01:18.426
But if you wanted to further

00:01:18.426 --> 00:01:20.496
customize the experience, you

00:01:20.496 --> 00:01:22.196
could use our other frameworks

00:01:22.196 --> 00:01:24.546
and APIs like AUAudioUnits,

00:01:24.756 --> 00:01:26.696
Audio Codecs, in Audio Toolbox

00:01:26.696 --> 00:01:28.926
framework, Code Mini framework,

00:01:29.396 --> 00:01:31.366
AudioHAL framework, etcetera.

00:01:32.786 --> 00:01:34.266
In our last year's talk here at

00:01:34.266 --> 00:01:36.676
WWDC, we did a walkthrough of

00:01:36.726 --> 00:01:38.526
all these APIs and more,

00:01:38.776 --> 00:01:39.626
throughout the stack.

00:01:40.106 --> 00:01:41.856
And I highly encourage you to

00:01:41.886 --> 00:01:43.086
check that out.

00:01:43.796 --> 00:01:45.496
Now, let's see what's on the

00:01:45.496 --> 00:01:46.486
agenda for today.

00:01:47.076 --> 00:01:49.526
We will see the new features

00:01:49.526 --> 00:01:51.396
we've added in some of these

00:01:51.396 --> 00:01:53.646
APIs, starting with the ones in

00:01:53.646 --> 00:01:54.806
AVFoundation framework.

00:01:55.506 --> 00:01:56.596
And that includes,

00:01:56.596 --> 00:01:58.846
AVAudioEngine, AVAudioSession,

00:01:59.206 --> 00:02:00.776
and the enhancements we have in

00:02:00.776 --> 00:02:02.876
AVFoundation on watchOS 4.

00:02:04.236 --> 00:02:06.276
Later on, we'll move over to the

00:02:06.276 --> 00:02:08.175
Audio Toolbox world, and see the

00:02:08.175 --> 00:02:10.786
enhancements in AUAudioUnits and

00:02:10.786 --> 00:02:11.636
Audio Formats.

00:02:12.376 --> 00:02:13.966
And finally, we'll wrap up

00:02:14.056 --> 00:02:15.786
today's session with an update

00:02:15.946 --> 00:02:17.336
on Inter-Device Audio Mode.

00:02:18.776 --> 00:02:20.906
We also have a few demos along

00:02:20.906 --> 00:02:22.876
the way, to show you many of

00:02:22.876 --> 00:02:25.126
these new features in action.

00:02:25.996 --> 00:02:27.266
So, let's begin with

00:02:27.306 --> 00:02:28.446
AVAudioEngine.

00:02:29.896 --> 00:02:31.746
And here's a quick recap of the

00:02:31.746 --> 00:02:32.106
API.

00:02:33.246 --> 00:02:35.436
AVAudioEngine is a powerful

00:02:35.436 --> 00:02:37.926
Objective-C and Swift based API

00:02:37.926 --> 00:02:38.186
set.

00:02:38.946 --> 00:02:40.676
And the main goal of this API,

00:02:41.046 --> 00:02:42.996
is to simplify dealing with real

00:02:42.996 --> 00:02:45.306
time audio, and to make it

00:02:45.306 --> 00:02:46.816
really easy for you to write

00:02:46.936 --> 00:02:49.336
code to perform various audio

00:02:49.336 --> 00:02:50.906
tasks, ranging from simple

00:02:50.906 --> 00:02:53.026
playback, to recording, to even

00:02:53.056 --> 00:02:54.596
complex tasks like audio

00:02:54.596 --> 00:02:56.956
processing, mixing, and even 3D

00:02:56.956 --> 00:02:57.996
audio specialization.

00:02:59.136 --> 00:03:00.626
And again, in our previous

00:03:00.626 --> 00:03:03.866
year's talk here at WWDC, we

00:03:03.866 --> 00:03:05.956
have covered this API in detail.

00:03:06.306 --> 00:03:08.046
So, please check those out if

00:03:08.046 --> 00:03:09.876
you're not familiar with this

00:03:10.416 --> 00:03:10.516
API.

00:03:11.376 --> 00:03:13.566
The Engine manages a graph of

00:03:13.626 --> 00:03:15.736
nodes, and a node is the basic

00:03:15.736 --> 00:03:17.126
building block of the Engine.

00:03:18.076 --> 00:03:19.826
So, here's a sample Engine setup

00:03:20.116 --> 00:03:21.636
and this is a classic karaoke

00:03:21.636 --> 00:03:22.186
example.

00:03:22.186 --> 00:03:24.286
As you can see, there are

00:03:24.286 --> 00:03:25.896
various nodes connected

00:03:25.896 --> 00:03:27.496
together, to form the processing

00:03:27.496 --> 00:03:27.816
graph.

00:03:28.986 --> 00:03:31.346
We have the InputNode that is

00:03:31.346 --> 00:03:33.146
implicitly connected to the

00:03:33.496 --> 00:03:34.866
[inaudible] and is capturing

00:03:35.006 --> 00:03:35.776
user's voice.

00:03:36.726 --> 00:03:38.286
This is being processed through

00:03:38.286 --> 00:03:39.856
an EffectNode which could be for

00:03:39.856 --> 00:03:42.326
example, an EQ.

00:03:42.326 --> 00:03:43.926
We also have something called a

00:03:44.086 --> 00:03:45.296
[inaudible] on the InputNode

00:03:45.686 --> 00:03:47.026
through which we could be

00:03:47.106 --> 00:03:48.826
analyzing user's voice to see

00:03:48.826 --> 00:03:50.646
how he's performing, and based

00:03:50.646 --> 00:03:52.296
on that, we could be playing out

00:03:52.296 --> 00:03:53.366
some cues to the user through a

00:03:53.576 --> 00:03:54.416
PlayerNode.

00:03:55.796 --> 00:03:57.206
And we have another PlayerNode

00:03:57.356 --> 00:03:58.716
that is playing the backing

00:03:58.716 --> 00:04:00.406
track as the user is singing.

00:04:00.736 --> 00:04:03.456
All of these signals are mixed

00:04:03.456 --> 00:04:05.536
together, in a MixerNode and

00:04:05.536 --> 00:04:07.386
finally, given to the OutputNode

00:04:07.666 --> 00:04:09.066
which plays it out through the

00:04:09.066 --> 00:04:09.786
output hardware.

00:04:10.896 --> 00:04:13.386
This is a simple example of the

00:04:13.386 --> 00:04:15.466
engine setup, but with all the

00:04:15.466 --> 00:04:16.866
nodes and the features the

00:04:16.866 --> 00:04:18.606
Engine actually offers, you

00:04:18.606 --> 00:04:20.326
could build a lot more complex

00:04:20.396 --> 00:04:21.856
processing graph, based on your

00:04:21.976 --> 00:04:22.676
app's needs.

00:04:23.446 --> 00:04:25.656
So, that was a recap of the

00:04:25.656 --> 00:04:26.206
Engine.

00:04:26.336 --> 00:04:27.976
Now, let's see what's new in the

00:04:27.976 --> 00:04:29.006
Engine this year.

00:04:30.356 --> 00:04:31.956
We have a couple of new modes,

00:04:32.316 --> 00:04:34.226
namely the Manual Rendering Mode

00:04:34.436 --> 00:04:36.546
and Auto Shutdown Mode, and

00:04:36.546 --> 00:04:38.146
also, we have some enhancements

00:04:38.146 --> 00:04:40.326
in AVAudioPlayerNode, related to

00:04:40.326 --> 00:04:41.636
the file and buffer completion

00:04:41.636 --> 00:04:42.216
callbacks.

00:04:43.246 --> 00:04:44.916
We'll see each of these, one by

00:04:44.916 --> 00:04:46.896
one, starting with the Manual

00:04:47.156 --> 00:04:48.406
Rendering Mode.

00:04:50.656 --> 00:04:52.506
So, this is the karaoke example

00:04:52.506 --> 00:04:53.356
that we just saw.

00:04:54.486 --> 00:04:56.536
And as you can see, the Input

00:04:56.536 --> 00:04:58.136
and the OutputNodes here, are

00:04:58.206 --> 00:05:00.226
connected to the audio hardware,

00:05:00.676 --> 00:05:02.056
and hence, the Engine

00:05:02.246 --> 00:05:03.816
automatically renders in real

00:05:03.816 --> 00:05:03.936
time.

00:05:03.936 --> 00:05:07.406
The IO here is driven by the

00:05:07.406 --> 00:05:07.886
hardware.

00:05:08.846 --> 00:05:10.956
But what if you wanted the

00:05:10.956 --> 00:05:12.676
Engine to render, not to the

00:05:12.676 --> 00:05:13.846
device, but to the app?

00:05:14.626 --> 00:05:16.626
And say, at the rate faster than

00:05:16.626 --> 00:05:16.886
real time?

00:05:18.496 --> 00:05:19.946
So, here is Manual Rendering

00:05:19.946 --> 00:05:21.606
Mode which enables you to do

00:05:21.606 --> 00:05:21.886
that.

00:05:23.236 --> 00:05:24.986
And as you can see, under this

00:05:24.986 --> 00:05:26.466
mode, the Input and the

00:05:26.466 --> 00:05:27.836
OutputNodes, will not be

00:05:27.836 --> 00:05:29.666
connected to any audio device,

00:05:30.436 --> 00:05:32.546
and the app will be responsible

00:05:32.546 --> 00:05:33.826
for pulling the Engine for

00:05:33.906 --> 00:05:36.436
Output and to provide the Input

00:05:36.666 --> 00:05:38.146
to the Engine which will be

00:05:38.216 --> 00:05:39.776
optionally through the InputNode

00:05:40.286 --> 00:05:41.846
or PlayerNode, etcetera.

00:05:43.046 --> 00:05:45.526
So, the app drives the IO in

00:05:45.526 --> 00:05:46.556
Manual Rendering Mode.

00:05:47.056 --> 00:05:50.476
We have two variants under

00:05:50.476 --> 00:05:51.336
Manual Rendering.

00:05:51.826 --> 00:05:53.796
That is the Offline and Real

00:05:53.796 --> 00:05:55.546
Time Manual Rendering Modes.

00:05:56.086 --> 00:05:57.356
And again, we'll see each of

00:05:57.356 --> 00:05:59.756
these in detail and also, later

00:05:59.756 --> 00:06:01.416
in this section, I'll show you a

00:06:01.416 --> 00:06:03.366
demo of the Offline Manual

00:06:03.366 --> 00:06:04.056
Rendering Mode.

00:06:04.476 --> 00:06:09.266
Under the Offline Manual

00:06:09.266 --> 00:06:11.586
Rendering Mode, the Engine and

00:06:11.676 --> 00:06:13.396
all the nodes in your processing

00:06:13.396 --> 00:06:15.266
graph, operate under no

00:06:15.266 --> 00:06:16.426
deadlines or real-time

00:06:16.426 --> 00:06:17.106
constraints.

00:06:18.126 --> 00:06:19.866
And because of this flexibility,

00:06:20.186 --> 00:06:22.476
a node may choose to say use a

00:06:22.476 --> 00:06:24.346
more expensive signal processing

00:06:24.346 --> 00:06:26.816
algorithm when it's offline, or

00:06:27.156 --> 00:06:28.826
a node for example, a player

00:06:28.826 --> 00:06:30.826
node, may choose to block on the

00:06:30.826 --> 00:06:32.806
render thread, until all the

00:06:32.806 --> 00:06:34.446
data that it needs as input,

00:06:34.676 --> 00:06:35.366
becomes ready.

00:06:36.586 --> 00:06:38.306
But these things may not -- will

00:06:38.306 --> 00:06:40.106
not happen with the nodes are

00:06:40.106 --> 00:06:41.696
actually rendering in real time,

00:06:42.066 --> 00:06:43.026
as we'll see soon.

00:06:43.276 --> 00:06:46.406
So, let's consider a simple

00:06:46.406 --> 00:06:48.576
example where we could use the

00:06:48.576 --> 00:06:49.926
offline mode.

00:06:51.236 --> 00:06:53.906
So, here's an example where an

00:06:53.906 --> 00:06:55.986
app wants to process the audio

00:06:55.986 --> 00:06:57.216
data in a source file.

00:06:57.216 --> 00:06:59.396
I'll place some effects onto

00:06:59.396 --> 00:07:01.256
that data, and dump the process

00:07:01.286 --> 00:07:03.056
output to a destination file.

00:07:03.586 --> 00:07:05.886
As you can see, there is no

00:07:05.886 --> 00:07:07.616
rendering to the device involved

00:07:07.696 --> 00:07:07.886
here.

00:07:08.226 --> 00:07:10.276
And hence, the app can now use

00:07:10.276 --> 00:07:12.586
the Engine in the offline mode.

00:07:13.516 --> 00:07:15.006
So, it could set up a very

00:07:15.006 --> 00:07:17.056
simple graph in the Engine, like

00:07:17.056 --> 00:07:17.416
this.

00:07:18.056 --> 00:07:20.126
It could use the PlayerNode to

00:07:20.126 --> 00:07:21.376
read the data from the source

00:07:21.376 --> 00:07:23.576
file, process it through an

00:07:23.576 --> 00:07:24.816
EffectNode, which could be for

00:07:24.816 --> 00:07:26.856
example a [inaudible], and then,

00:07:27.106 --> 00:07:28.236
pull the data out of the

00:07:28.236 --> 00:07:30.166
OutputNode and drive the process

00:07:30.166 --> 00:07:31.726
data into a destination file.

00:07:32.916 --> 00:07:34.736
And we will soon see a demo of

00:07:34.736 --> 00:07:36.926
this exact setup in a couple of

00:07:36.926 --> 00:07:38.016
slides.

00:07:38.886 --> 00:07:42.096
There are many more applications

00:07:42.266 --> 00:07:43.536
where you can use the offline

00:07:43.536 --> 00:07:43.766
mode.

00:07:44.416 --> 00:07:45.536
And some of these are listed

00:07:45.596 --> 00:07:45.746
here.

00:07:46.586 --> 00:07:48.436
Apart from post-processing of

00:07:48.476 --> 00:07:49.696
audio files that I just

00:07:49.696 --> 00:07:51.666
mentioned, you could also use

00:07:51.666 --> 00:07:54.086
offline mode to say mix audio

00:07:54.086 --> 00:07:54.476
files.

00:07:55.556 --> 00:07:57.686
You could use it for offline

00:07:57.686 --> 00:07:59.646
processing using a very CPU

00:07:59.646 --> 00:08:01.246
intensive or a higher quality

00:08:01.346 --> 00:08:02.806
algorithm, which may not be

00:08:02.806 --> 00:08:04.346
feasible to use in real time.

00:08:05.386 --> 00:08:06.936
Or simply, you could use the

00:08:06.936 --> 00:08:09.496
offline mode, to test, debug, or

00:08:09.636 --> 00:08:11.756
tune your live Engine setup.

00:08:12.306 --> 00:08:15.766
So, that concludes the offline

00:08:15.766 --> 00:08:17.486
mode and as promised, I'll show

00:08:17.486 --> 00:08:20.936
you a demo of this in action.

00:08:21.886 --> 00:08:27.056
Alright so, what I have here is

00:08:27.056 --> 00:08:28.126
an [inaudible] Playground.

00:08:29.136 --> 00:08:31.776
And this is the example where we

00:08:31.776 --> 00:08:33.486
will post-process the audio data

00:08:33.596 --> 00:08:36.126
in a source file, apply a

00:08:36.366 --> 00:08:37.226
[inaudible] effect on the data,

00:08:37.635 --> 00:08:39.186
and dump the output into a

00:08:39.186 --> 00:08:40.076
destination file.

00:08:40.645 --> 00:08:42.876
I have some code snippets here

00:08:42.876 --> 00:08:43.936
and [inaudible] on [inaudible].

00:08:44.076 --> 00:08:47.326
So, the first thing I do here,

00:08:48.466 --> 00:08:51.716
is set up the Engine to render

00:08:51.956 --> 00:08:53.706
in a live mode to the device,

00:08:53.706 --> 00:08:55.976
just to see how the source file

00:08:55.976 --> 00:08:58.536
sounds without having added any

00:08:58.536 --> 00:08:59.826
effect to it.

00:09:01.516 --> 00:09:04.506
So, I'm first opening up the

00:09:04.506 --> 00:09:06.176
source file, which I want to

00:09:06.226 --> 00:09:06.486
read.

00:09:07.116 --> 00:09:10.706
And then, I'm creating and

00:09:10.706 --> 00:09:11.816
configuring my Engine.

00:09:12.506 --> 00:09:14.546
So, I have an Engine and a

00:09:14.706 --> 00:09:15.536
PlayerNode.

00:09:16.486 --> 00:09:17.836
And I'm going to take the player

00:09:18.296 --> 00:09:19.676
to the main mixer node of the

00:09:19.676 --> 00:09:21.406
Engine, which is implicitly

00:09:21.436 --> 00:09:24.206
connected to the OutputNode of

00:09:25.356 --> 00:09:25.726
the Engine.

00:09:25.726 --> 00:09:27.006
Then I'm scheduling the source

00:09:27.006 --> 00:09:28.766
file that I have on the player

00:09:28.976 --> 00:09:30.176
so that it can read the data

00:09:30.176 --> 00:09:30.976
from the source file.

00:09:31.686 --> 00:09:34.116
And then I'm starting the Engine

00:09:34.116 --> 00:09:34.996
and starting the player.

00:09:35.866 --> 00:09:37.216
So, as I mentioned, the Engine

00:09:37.216 --> 00:09:38.966
is now in a live mode, and this

00:09:38.966 --> 00:09:41.256
will render to the device.

00:09:41.636 --> 00:09:43.476
So, let's see how the source

00:09:43.476 --> 00:09:45.416
file sounds without any effects.

00:09:46.516 --> 00:09:54.716
[ Music ]

00:09:55.216 --> 00:09:56.776
Okay, so that's how the source

00:09:56.776 --> 00:09:59.146
file sounds like.

00:09:59.236 --> 00:10:01.586
So, now what I'll do is, add a

00:10:01.586 --> 00:10:04.096
reverb effect to process the

00:10:04.096 --> 00:10:04.366
data.

00:10:05.516 --> 00:10:07.156
So, I'll remove the player to

00:10:07.156 --> 00:10:09.406
main mixer connection, and I'll

00:10:09.506 --> 00:10:10.736
insert the reverb.

00:10:11.806 --> 00:10:13.406
So, here I've created a reverb

00:10:14.196 --> 00:10:16.026
and I'm setting the parameters

00:10:16.026 --> 00:10:16.596
of the reverb.

00:10:16.796 --> 00:10:18.926
And in this example, I'm using a

00:10:18.926 --> 00:10:22.096
factory preset and wetDryMix of

00:10:22.396 --> 00:10:23.206
70%.

00:10:24.106 --> 00:10:25.176
And then I'm inserting the

00:10:25.176 --> 00:10:27.436
reverb in the playback part in

00:10:27.436 --> 00:10:28.816
between the player and the main

00:10:28.816 --> 00:10:29.196
mixer.

00:10:30.386 --> 00:10:32.786
So, now if I run the example, we

00:10:32.786 --> 00:10:34.886
can see how the processed output

00:10:34.976 --> 00:10:36.426
will sound like.

00:10:37.516 --> 00:10:45.816
[ Music ]

00:10:46.316 --> 00:10:48.776
Okay, so now at this point, if I

00:10:48.776 --> 00:10:50.386
want, I could go ahead and tune

00:10:50.386 --> 00:10:51.916
my reverb parameter so that it

00:10:51.916 --> 00:10:53.326
sounds exactly as I want.

00:10:53.786 --> 00:10:55.026
So, suppose I'm happy with all

00:10:55.026 --> 00:10:56.736
the parameters and then now I

00:10:56.736 --> 00:10:58.136
want to completely export my

00:10:58.136 --> 00:10:59.686
source file into a destination

00:10:59.686 --> 00:10:59.906
file.

00:11:00.306 --> 00:11:01.546
And this is where the offline

00:11:01.546 --> 00:11:02.526
mode comes into picture.

00:11:03.876 --> 00:11:07.246
So, what I'll first do is, I'll

00:11:07.246 --> 00:11:08.806
enable -- I'll switch the Engine

00:11:08.806 --> 00:11:10.026
from the live mode to the

00:11:10.026 --> 00:11:10.646
offline mode.

00:11:10.646 --> 00:11:17.816
So, what I've done here is I'm

00:11:18.076 --> 00:11:22.126
calling an Enable Manual

00:11:22.416 --> 00:11:24.466
Rendering Mode API, and I'm

00:11:24.466 --> 00:11:26.056
saying, "It needs to be the

00:11:26.056 --> 00:11:27.236
offline variant of it."

00:11:28.256 --> 00:11:30.156
I'm specifying a format of the

00:11:30.216 --> 00:11:31.956
output which I want the Engine

00:11:32.086 --> 00:11:32.706
to give me.

00:11:33.236 --> 00:11:34.696
And this is, in this example,

00:11:34.696 --> 00:11:36.256
same as the format of the input.

00:11:36.716 --> 00:11:39.056
And then I'm specifying a

00:11:39.056 --> 00:11:40.336
certain maximum number of

00:11:40.336 --> 00:11:42.526
frames, which is the maximum

00:11:42.666 --> 00:11:43.836
number of frames that you will

00:11:43.836 --> 00:11:45.786
ever ask the Engine to render in

00:11:45.786 --> 00:11:47.056
a single rendered call.

00:11:47.696 --> 00:11:49.476
And in this example, the value's

00:11:49.476 --> 00:11:50.536
4096.

00:11:50.756 --> 00:11:52.556
But you can configure this as

00:11:52.556 --> 00:11:52.966
you wish.

00:11:53.516 --> 00:11:57.576
So, now if I go ahead and run

00:11:58.086 --> 00:11:59.836
this example, nothing will

00:11:59.836 --> 00:12:01.536
happen because the Engine is now

00:12:01.536 --> 00:12:03.186
in the offline mode, and it's

00:12:03.186 --> 00:12:04.066
ready to render.

00:12:04.356 --> 00:12:05.586
But of course, it's waiting for

00:12:05.586 --> 00:12:08.016
the app to pull the Engine for

00:12:08.016 --> 00:12:08.466
output.

00:12:09.556 --> 00:12:11.816
So, what we'll do next is to

00:12:11.816 --> 00:12:13.296
actually pull the Engine for

00:12:13.296 --> 00:12:13.776
output.

00:12:16.636 --> 00:12:18.466
So, here I'm creating an output

00:12:18.466 --> 00:12:21.586
file to which I want to dump the

00:12:21.586 --> 00:12:22.296
process data.

00:12:22.956 --> 00:12:26.326
And I'm creating an output

00:12:26.326 --> 00:12:28.706
buffer to which I'll ask the

00:12:28.706 --> 00:12:30.666
Engine to render sequentially in

00:12:30.706 --> 00:12:31.696
every rendered call.

00:12:32.676 --> 00:12:34.326
And the format of this buffer is

00:12:34.326 --> 00:12:35.766
the same format that as I

00:12:35.766 --> 00:12:37.616
mentioned, when enabling the

00:12:37.616 --> 00:12:38.536
offline mode.

00:12:39.046 --> 00:12:42.206
And then comes the rendered loop

00:12:42.396 --> 00:12:44.236
where I'll [inaudible] pull the

00:12:44.236 --> 00:12:45.496
engine for output.

00:12:46.216 --> 00:12:47.676
Now, in this example, I have a

00:12:47.676 --> 00:12:49.006
source file which is about three

00:12:49.006 --> 00:12:49.816
minutes long.

00:12:50.556 --> 00:12:52.026
So, I really don't want to

00:12:52.026 --> 00:12:54.076
allocate a huge output buffer

00:12:54.246 --> 00:12:55.846
and ask the Engine to render the

00:12:55.846 --> 00:12:57.516
entire three minutes of data in

00:12:57.516 --> 00:12:58.486
a single rendered call.

00:12:58.996 --> 00:13:00.596
And that's why what I'm doing is

00:13:00.676 --> 00:13:02.756
allocating an output buffer of a

00:13:02.756 --> 00:13:05.206
very reasonable size, but

00:13:05.206 --> 00:13:05.986
[inaudible] pulling the Engine

00:13:05.986 --> 00:13:07.836
for output into the same buffer,

00:13:07.836 --> 00:13:09.266
and then dumping the output to

00:13:09.266 --> 00:13:10.186
the destination file.

00:13:10.676 --> 00:13:13.786
So, in every iteration, I'll

00:13:13.786 --> 00:13:16.216
decide the number of frames to

00:13:16.216 --> 00:13:17.336
render in this particular

00:13:17.366 --> 00:13:17.906
rendered call.

00:13:18.566 --> 00:13:20.266
And I call the rendered offline

00:13:20.416 --> 00:13:21.176
[inaudible] around the Engine,

00:13:21.326 --> 00:13:23.076
asking it to render those many

00:13:23.076 --> 00:13:24.636
number of frames, and giving it

00:13:24.636 --> 00:13:26.456
the output buffer that we just

00:13:26.456 --> 00:13:26.986
allocated.

00:13:27.916 --> 00:13:29.466
And depending on the status, if

00:13:29.466 --> 00:13:32.086
it rendered success, the data

00:13:32.086 --> 00:13:33.706
was rendered successfully and I

00:13:33.706 --> 00:13:35.506
can go ahead and drag the data

00:13:35.616 --> 00:13:37.896
into my output file, and in case

00:13:37.896 --> 00:13:39.146
it rendered an error, then

00:13:39.146 --> 00:13:40.496
something went wrong, so you can

00:13:40.496 --> 00:13:42.886
check the error code for more

00:13:42.886 --> 00:13:43.456
information.

00:13:44.636 --> 00:13:45.686
So, finally, when the

00:13:45.686 --> 00:13:47.316
rendering's done, I'll stop the

00:13:47.316 --> 00:13:49.276
player and I'll stop the Engine.

00:13:50.146 --> 00:13:51.476
So, now if I go ahead and run

00:13:51.476 --> 00:13:53.536
this example, the entire source

00:13:53.536 --> 00:13:55.066
file will get exported and the

00:13:55.066 --> 00:13:56.376
data will be dumped into the

00:13:56.376 --> 00:13:57.196
destination file.

00:13:57.876 --> 00:14:02.596
So, let's do that.

00:14:02.816 --> 00:14:04.366
Okay, so as you may have

00:14:04.366 --> 00:14:06.736
observed, the three-minute

00:14:07.036 --> 00:14:09.566
length long source file got

00:14:09.566 --> 00:14:11.266
rendered into an output file,

00:14:11.746 --> 00:14:13.106
way faster than real time.

00:14:13.486 --> 00:14:14.646
And that is one of the main

00:14:14.646 --> 00:14:15.866
applications of the offline

00:14:15.866 --> 00:14:16.416
rendering mode.

00:14:17.416 --> 00:14:19.796
So, what we'll do next is again,

00:14:19.796 --> 00:14:21.916
listen to the source file, and

00:14:23.046 --> 00:14:25.396
the destination file, and make

00:14:25.396 --> 00:14:28.946
sure that the data was indeed

00:14:29.006 --> 00:14:29.396
processed.

00:14:30.116 --> 00:14:31.636
So, that is my source file.

00:14:33.146 --> 00:14:35.216
And this is my destination file.

00:14:35.796 --> 00:14:40.636
So, first we'll listen to the

00:14:40.636 --> 00:14:41.866
source file.

00:14:42.516 --> 00:14:48.766
[ Music ]

00:14:49.266 --> 00:14:51.786
So, as you saw, it is pretty

00:14:51.786 --> 00:14:52.156
dry.

00:14:53.096 --> 00:14:54.946
And now, the processed file.

00:14:55.516 --> 00:15:03.746
[ Music ]

00:15:04.246 --> 00:15:06.156
Okay, so as expected, the

00:15:06.186 --> 00:15:07.876
processed data has reverb effect

00:15:07.876 --> 00:15:08.426
added to it.

00:15:09.746 --> 00:15:12.066
So, that concludes the offline

00:15:12.066 --> 00:15:13.446
rendering demo.

00:15:13.616 --> 00:15:15.316
And I'll switch back to the

00:15:16.086 --> 00:15:16.246
slides.

00:15:19.516 --> 00:15:24.666
[ Applause ]

00:15:25.166 --> 00:15:26.136
So, as I mentioned, there are

00:15:26.136 --> 00:15:27.606
many more applications to the

00:15:27.756 --> 00:15:28.526
rendering mode.

00:15:28.976 --> 00:15:31.446
And I'm also happy to announce

00:15:31.506 --> 00:15:33.856
that the sample code for this

00:15:33.906 --> 00:15:35.676
example, is already available on

00:15:35.676 --> 00:15:37.316
our Sessions Homepage, and we'll

00:15:37.316 --> 00:15:39.336
show you a link to that homepage

00:15:39.336 --> 00:15:40.426
at the end of presentation.

00:15:42.436 --> 00:15:44.356
Now, going to the second variant

00:15:44.356 --> 00:15:45.606
of the Manual Rendering Mode.

00:15:46.396 --> 00:15:47.746
The real time Manual Entering

00:15:47.746 --> 00:15:47.916
Mode.

00:15:48.696 --> 00:15:50.516
As the name itself suggests,

00:15:50.626 --> 00:15:52.556
under this mode, the Engine and

00:15:52.556 --> 00:15:53.966
all the nodes in your processing

00:15:53.966 --> 00:15:55.836
graph, assume that they are

00:15:55.886 --> 00:15:57.276
rendering under a real-time

00:15:57.346 --> 00:15:57.886
context.

00:15:58.376 --> 00:15:59.736
And hence, the they honor the

00:15:59.776 --> 00:16:01.026
real-time constraints.

00:16:01.766 --> 00:16:03.756
That is, they will not make any

00:16:03.756 --> 00:16:05.776
kind of a blocking calls on the

00:16:05.806 --> 00:16:06.396
render thread.

00:16:07.046 --> 00:16:08.556
For example, they will not call

00:16:08.556 --> 00:16:09.556
any libdispatch.

00:16:10.146 --> 00:16:12.036
They will not allocate memory or

00:16:12.076 --> 00:16:13.416
wait to block on a mutex.

00:16:14.346 --> 00:16:15.836
And because of this constraint,

00:16:16.106 --> 00:16:17.916
suppose the input data for node

00:16:18.046 --> 00:16:19.396
is not ready in time.

00:16:20.016 --> 00:16:22.046
A node has no other choice, but

00:16:22.046 --> 00:16:23.756
the say, "Drop the data for that

00:16:23.796 --> 00:16:25.516
particular render cycle, or

00:16:25.746 --> 00:16:27.406
assume zeros and proceed."

00:16:29.696 --> 00:16:31.486
Now, let's see where you would

00:16:31.486 --> 00:16:32.826
use the Engine in the real-time

00:16:32.826 --> 00:16:34.546
Manual Rendering Mode.

00:16:35.236 --> 00:16:37.436
Suppose you have a custom AU

00:16:37.436 --> 00:16:38.086
audio unit.

00:16:38.986 --> 00:16:41.286
That is, in the live playback

00:16:41.376 --> 00:16:43.456
part, and within the internal

00:16:43.456 --> 00:16:45.116
render block of your audio unit,

00:16:45.416 --> 00:16:46.836
you would like to process the

00:16:46.836 --> 00:16:48.386
data that is going through,

00:16:48.736 --> 00:16:50.746
using some other audio unit or

00:16:50.796 --> 00:16:52.066
audio units.

00:16:52.906 --> 00:16:54.996
In that case, you can set up the

00:16:54.996 --> 00:16:57.316
Engine to use those other audio

00:16:57.316 --> 00:16:59.716
units and process the data in

00:16:59.716 --> 00:17:01.186
the real-time Manual Rendering

00:17:01.726 --> 00:17:01.826
Mode.

00:17:02.596 --> 00:17:04.236
The second example would be,

00:17:04.366 --> 00:17:05.746
suppose you wanted to process

00:17:05.746 --> 00:17:07.415
the audio data that belongs to a

00:17:07.415 --> 00:17:09.286
movie or video, as it is

00:17:09.286 --> 00:17:10.636
streaming or playing back.

00:17:11.526 --> 00:17:12.516
Because this happens in the

00:17:12.516 --> 00:17:14.016
real-time, you could use the

00:17:14.016 --> 00:17:15.656
Engine in real-time Manual

00:17:15.656 --> 00:17:17.306
Rendering Mode, to do that audio

00:17:17.306 --> 00:17:17.846
processing.

00:17:18.516 --> 00:17:19.986
And now, let's consider the

00:17:19.986 --> 00:17:22.386
second use case and see how to

00:17:22.386 --> 00:17:24.756
set up and use the Engine both

00:17:24.756 --> 00:17:26.445
as an example an in code.

00:17:27.106 --> 00:17:30.926
So, here's the app that's

00:17:30.926 --> 00:17:33.416
receiving input movie stream,

00:17:33.596 --> 00:17:35.236
and displaying back in

00:17:35.236 --> 00:17:37.046
real-time, say to a TV.

00:17:37.656 --> 00:17:39.016
But what it wants to do is

00:17:39.236 --> 00:17:42.406
process the audio data as it in

00:17:42.406 --> 00:17:44.046
the input, before it goes to the

00:17:44.046 --> 00:17:44.466
output.

00:17:45.776 --> 00:17:47.736
So, now it can use the Engine in

00:17:47.736 --> 00:17:49.456
the real-time Manual Rendering

00:17:49.456 --> 00:17:49.796
Mode.

00:17:50.766 --> 00:17:52.586
So, it could set up a processing

00:17:52.586 --> 00:17:53.896
graph like this.

00:17:53.896 --> 00:17:55.656
It can provide the input through

00:17:55.856 --> 00:17:58.016
the input node, process it

00:17:58.186 --> 00:17:59.836
through an effect node, and then

00:17:59.886 --> 00:18:01.306
pull the data from the output

00:18:01.356 --> 00:18:04.626
node and then play it back to

00:18:05.356 --> 00:18:07.116
the device.

00:18:07.246 --> 00:18:09.156
Now, let's see a code example on

00:18:09.156 --> 00:18:11.396
how to set up and use the Engine

00:18:11.436 --> 00:18:11.956
in this mode.

00:18:16.336 --> 00:18:17.616
So, here's the code.

00:18:17.996 --> 00:18:20.246
And note that the setting up the

00:18:20.246 --> 00:18:22.136
Engine itself, happens from a

00:18:22.136 --> 00:18:23.626
non-real-time context.

00:18:23.946 --> 00:18:25.886
And it's only rendering part

00:18:26.026 --> 00:18:27.276
that actually happens from a

00:18:27.276 --> 00:18:28.286
real-time context.

00:18:28.836 --> 00:18:30.596
So, here's the setup code, where

00:18:30.596 --> 00:18:32.706
you first cleared the Engine,

00:18:33.186 --> 00:18:36.306
and by default, on creation, the

00:18:36.306 --> 00:18:38.036
Engine will be ready to render

00:18:38.206 --> 00:18:40.026
to the device until you switch

00:18:40.026 --> 00:18:41.536
it over to the Manual Rendering

00:18:41.536 --> 00:18:41.746
Mode.

00:18:42.846 --> 00:18:44.376
So, you cleared the Engine, make

00:18:44.376 --> 00:18:45.946
your required connections, and

00:18:45.946 --> 00:18:47.796
then switch it over to the

00:18:47.796 --> 00:18:48.796
Manual Rendering Mode.

00:18:49.636 --> 00:18:51.116
So, this is the same API that we

00:18:51.116 --> 00:18:52.876
saw in the demo, except that we

00:18:52.876 --> 00:18:55.536
are now saying -- now asking the

00:18:55.536 --> 00:18:57.106
Engine to operate under

00:18:57.106 --> 00:18:58.556
real-time Manual Rendering Mode.

00:18:59.326 --> 00:19:01.296
And specifying the format for

00:19:01.296 --> 00:19:03.076
the output and maximum number of

00:19:03.076 --> 00:19:03.556
frames.

00:19:04.546 --> 00:19:07.946
The next thing you do is session

00:19:08.056 --> 00:19:09.566
cache, something called a

00:19:09.566 --> 00:19:10.396
surrender block.

00:19:10.926 --> 00:19:12.546
Now, because the rendering of

00:19:12.626 --> 00:19:13.966
the Engine happens from a

00:19:13.966 --> 00:19:16.076
real-time context, you will not

00:19:16.116 --> 00:19:17.496
be able to use the render

00:19:17.596 --> 00:19:19.496
offline Objective-C or Swift

00:19:19.496 --> 00:19:20.966
meta that we saw in the demo.

00:19:21.346 --> 00:19:23.076
And that is because, it is not

00:19:23.146 --> 00:19:25.226
safe to use Objective-C or Swift

00:19:25.226 --> 00:19:26.286
runtime from a real-time

00:19:26.286 --> 00:19:26.896
context.

00:19:27.436 --> 00:19:28.976
So, instead, the engine itself

00:19:28.976 --> 00:19:30.826
provides you a render block that

00:19:30.826 --> 00:19:32.506
you can search and cache, and

00:19:32.506 --> 00:19:34.086
then later use this render block

00:19:34.286 --> 00:19:35.626
to render the engine from the

00:19:35.626 --> 00:19:36.686
real-time context.

00:19:38.256 --> 00:19:40.456
The next thing is -- to do, is

00:19:40.456 --> 00:19:42.016
to set up your input node so

00:19:42.016 --> 00:19:43.386
that you can provide your input

00:19:43.386 --> 00:19:44.646
data to the Engine.

00:19:45.416 --> 00:19:48.156
And here, you specify the format

00:19:48.156 --> 00:19:49.786
of the input that you will

00:19:49.786 --> 00:19:51.536
provide, and this can be a

00:19:51.536 --> 00:19:52.586
different format than the

00:19:52.626 --> 00:19:53.046
output.

00:19:54.016 --> 00:19:55.916
And you also provide a block

00:19:55.916 --> 00:19:57.396
which the Engine will call,

00:19:57.546 --> 00:19:59.076
whenever it needs the input

00:19:59.186 --> 00:19:59.546
data.

00:20:01.696 --> 00:20:03.716
And when this block gets called,

00:20:03.716 --> 00:20:05.476
the Engine will let you know how

00:20:05.476 --> 00:20:07.136
many number of input frames it

00:20:07.136 --> 00:20:07.936
actually needs.

00:20:08.606 --> 00:20:10.616
And at that point, if you have

00:20:10.616 --> 00:20:12.986
the data, you'll fill up an

00:20:12.986 --> 00:20:14.646
input audio buffer list and

00:20:14.646 --> 00:20:15.986
return it to the engine.

00:20:16.846 --> 00:20:18.416
But if you don't have data, you

00:20:18.416 --> 00:20:20.096
can return nil at this point.

00:20:21.446 --> 00:20:22.876
Now note that the input node can

00:20:22.876 --> 00:20:25.156
be used both in the offline and

00:20:25.276 --> 00:20:26.696
real-time Manual Rendering Mode.

00:20:27.246 --> 00:20:28.886
But when you're using it in the

00:20:28.886 --> 00:20:30.316
real-time Manual Rendering Mode,

00:20:30.686 --> 00:20:32.576
this input block also gets

00:20:32.576 --> 00:20:34.366
called from a real-time context,

00:20:34.746 --> 00:20:36.146
which means that you need to

00:20:36.146 --> 00:20:38.096
take care not to make any kind

00:20:38.096 --> 00:20:39.936
of blocking calls within this

00:20:40.556 --> 00:20:42.026
input block.

00:20:43.356 --> 00:20:45.236
The next part of the setup is to

00:20:45.236 --> 00:20:47.586
clear your output buffer, and

00:20:47.586 --> 00:20:49.386
the difference here is you will

00:20:49.386 --> 00:20:51.956
create an AVAudioPCMBuffer and

00:20:51.956 --> 00:20:53.806
fetch its audio buffer list

00:20:54.006 --> 00:20:55.726
which is what you'll use in the

00:20:55.726 --> 00:20:57.206
real-time render logic.

00:20:57.726 --> 00:21:00.206
And finally, you'll go ahead and

00:21:00.206 --> 00:21:00.976
start the Engine.

00:21:01.546 --> 00:21:03.286
So, now the Engine is all set up

00:21:03.286 --> 00:21:04.646
and ready to render, and is

00:21:04.646 --> 00:21:06.706
waiting for the app to pull for

00:21:06.776 --> 00:21:08.076
the output data.

00:21:08.616 --> 00:21:12.846
Now here comes the actual render

00:21:12.886 --> 00:21:13.346
logic.

00:21:13.916 --> 00:21:15.626
And note that this part of the

00:21:15.666 --> 00:21:17.836
chord is written in C++, and

00:21:17.836 --> 00:21:19.516
that is because as I mentioned,

00:21:19.716 --> 00:21:21.546
we are -- it's not safe to use

00:21:21.546 --> 00:21:24.046
Objective-C or Swift runtime

00:21:24.096 --> 00:21:25.386
from a real-time context.

00:21:26.546 --> 00:21:28.166
So, what we're doing first is

00:21:28.716 --> 00:21:30.156
calling the render block that we

00:21:30.246 --> 00:21:32.516
cached earlier, and asking the

00:21:32.516 --> 00:21:33.626
Engine to render a certain

00:21:33.626 --> 00:21:35.296
number or frames, and giving it

00:21:35.296 --> 00:21:36.606
the outputBufferList that we

00:21:36.606 --> 00:21:37.076
created.

00:21:38.086 --> 00:21:39.606
And finally, depending on the

00:21:39.606 --> 00:21:41.856
status, if you get a success, it

00:21:41.856 --> 00:21:43.426
means everything went fine and

00:21:43.426 --> 00:21:44.726
the data was rendered to the

00:21:44.726 --> 00:21:45.416
output buffer.

00:21:46.216 --> 00:21:47.976
But you could also get an

00:21:47.976 --> 00:21:49.736
insufficient data from input

00:21:49.736 --> 00:21:51.776
note as a status, which means

00:21:51.776 --> 00:21:54.846
that when your input block was

00:21:54.896 --> 00:21:56.526
called by the Engine for input

00:21:56.526 --> 00:21:58.386
data, you did not have enough

00:21:58.386 --> 00:22:00.276
data in your written nil from

00:22:00.276 --> 00:22:01.056
that input block.

00:22:01.946 --> 00:22:03.816
And note that in this case, in

00:22:03.816 --> 00:22:05.696
case you have other sources in

00:22:05.696 --> 00:22:07.116
your processing graph, for

00:22:07.116 --> 00:22:08.576
example, you have some of the

00:22:08.606 --> 00:22:08.946
[inaudible] notes.

00:22:09.396 --> 00:22:10.666
Those notes could have still

00:22:10.666 --> 00:22:12.446
rendered the input data, so you

00:22:12.446 --> 00:22:14.176
may still have some output in

00:22:14.176 --> 00:22:15.096
your output buffer.

00:22:15.446 --> 00:22:17.256
So, you can check the sizes of

00:22:17.306 --> 00:22:19.076
your output buffer, to determine

00:22:19.136 --> 00:22:20.876
whether or not it has any data.

00:22:22.276 --> 00:22:23.936
And of course, you handle the

00:22:23.936 --> 00:22:26.326
other status which includes the

00:22:26.326 --> 00:22:28.196
error, and that is pretty much

00:22:28.196 --> 00:22:30.246
the render logic in real-time

00:22:30.246 --> 00:22:31.866
Manual Rendering Mode.

00:22:33.896 --> 00:22:37.106
Now, lastly a note on the render

00:22:37.176 --> 00:22:37.546
cause.

00:22:38.276 --> 00:22:39.396
In the offline mode, because

00:22:39.396 --> 00:22:40.456
there are no deadlines or

00:22:40.506 --> 00:22:42.056
real-time constraints, you can

00:22:42.056 --> 00:22:43.796
use either the Objective-C or

00:22:43.796 --> 00:22:45.606
the Swift render of line method,

00:22:45.966 --> 00:22:47.666
or you could use the render

00:22:47.666 --> 00:22:49.246
block based render call in order

00:22:49.246 --> 00:22:50.176
to render the Engine.

00:22:50.776 --> 00:22:52.116
But in real-time Manual

00:22:52.116 --> 00:22:53.956
Rendering Mode, you must use the

00:22:53.956 --> 00:22:55.276
block based render call.

00:22:55.946 --> 00:22:58.646
So, that brings us to the end of

00:22:58.706 --> 00:22:59.866
Manual Rendering Mode.

00:23:00.196 --> 00:23:03.836
Now let's now see the next new

00:23:03.836 --> 00:23:05.356
mode we have in the Engine,

00:23:05.356 --> 00:23:07.306
which is the Auto Shutdown Mode.

00:23:09.046 --> 00:23:10.476
Now, normally it is the

00:23:10.476 --> 00:23:12.496
responsibility of the app to

00:23:12.576 --> 00:23:14.576
pause or stop the Engine when it

00:23:14.576 --> 00:23:16.306
is not in use in order to

00:23:16.306 --> 00:23:16.976
conserve power.

00:23:16.976 --> 00:23:19.766
For example, say we have a music

00:23:19.766 --> 00:23:21.236
app that is using one of the

00:23:21.276 --> 00:23:22.906
player nodes for playing back

00:23:23.626 --> 00:23:26.106
some file, and say the user

00:23:26.106 --> 00:23:27.346
stops the playback.

00:23:28.156 --> 00:23:29.986
Now the app, should not only

00:23:30.126 --> 00:23:32.316
pause or stop the player node,

00:23:32.596 --> 00:23:34.356
but it should also pause or stop

00:23:34.356 --> 00:23:36.246
the Engine in order to prevent

00:23:36.246 --> 00:23:37.436
it from running idle.

00:23:38.496 --> 00:23:39.836
But in the past, we have seen

00:23:39.836 --> 00:23:41.726
that not all the apps actually

00:23:41.726 --> 00:23:43.846
do this, and especially that's

00:23:43.846 --> 00:23:44.646
true on watchOS.

00:23:45.396 --> 00:23:47.166
And hence, we are now adding the

00:23:47.166 --> 00:23:49.546
safety net in order to conserve

00:23:49.806 --> 00:23:51.486
power with this auto shutdown

00:23:51.486 --> 00:23:51.716
mode.

00:23:52.866 --> 00:23:54.136
When the Engine is operating

00:23:54.136 --> 00:23:56.246
under this mode, it will

00:23:56.246 --> 00:23:58.076
continuously monitor and if it

00:23:58.076 --> 00:24:00.276
detects that the Engine is

00:24:00.276 --> 00:24:01.826
running idle for a certain

00:24:01.826 --> 00:24:03.656
duration, it will go ahead and

00:24:03.656 --> 00:24:05.176
stop the audio hardware and

00:24:05.176 --> 00:24:05.506
delete.

00:24:06.286 --> 00:24:07.966
And later on, suppose any of the

00:24:07.966 --> 00:24:09.796
sources become active again, it

00:24:09.796 --> 00:24:11.166
will start the audio hardware

00:24:11.166 --> 00:24:11.786
dynamically.

00:24:12.376 --> 00:24:13.666
And all of this happens under

00:24:13.666 --> 00:24:13.966
the hood.

00:24:15.196 --> 00:24:16.266
And this is the enforced

00:24:16.266 --> 00:24:18.436
behavior on watchOS, but it can

00:24:18.436 --> 00:24:20.186
also be optionally enabled on

00:24:20.186 --> 00:24:20.986
other platforms.

00:24:23.316 --> 00:24:26.106
Now, next onto the enhancements

00:24:26.106 --> 00:24:27.326
in AV Audio Player Node.

00:24:27.946 --> 00:24:31.196
AV Audio Player Node is one of

00:24:31.196 --> 00:24:32.726
the source nodes in the Engine,

00:24:33.066 --> 00:24:34.536
through which you could schedule

00:24:34.536 --> 00:24:36.466
a buffer or file for playback.

00:24:36.966 --> 00:24:39.696
And the existing [inaudible]

00:24:39.696 --> 00:24:41.396
methods, take a completion

00:24:41.436 --> 00:24:42.956
handler and they call the

00:24:42.956 --> 00:24:44.806
completion handler when the data

00:24:44.806 --> 00:24:46.246
that you have provided has been

00:24:46.246 --> 00:24:47.546
consumed by the player.

00:24:49.056 --> 00:24:50.996
We are now adding new completion

00:24:50.996 --> 00:24:52.436
handler and new types of

00:24:52.526 --> 00:24:54.526
callbacks, in order for you to

00:24:54.666 --> 00:24:56.516
know various stages of

00:24:56.556 --> 00:24:57.236
completion.

00:24:57.776 --> 00:25:01.836
The first new callback type is

00:25:01.836 --> 00:25:03.196
the data consumed type.

00:25:03.686 --> 00:25:05.396
And this is exactly same as the

00:25:05.396 --> 00:25:06.776
existing completion handler.

00:25:07.246 --> 00:25:09.536
That is, when the completion

00:25:09.536 --> 00:25:11.326
handler gets called, it means

00:25:11.326 --> 00:25:12.786
the data has been consumed by

00:25:12.786 --> 00:25:13.236
the player.

00:25:13.236 --> 00:25:15.386
So, at that point, if you

00:25:15.446 --> 00:25:17.106
wanted, you could recycle that

00:25:17.106 --> 00:25:19.606
buffer, or if you have more data

00:25:19.866 --> 00:25:21.376
to schedule on the player, you

00:25:21.416 --> 00:25:21.936
could do that.

00:25:22.796 --> 00:25:24.746
The second type of callback is

00:25:24.746 --> 00:25:26.076
the data rendered callback.

00:25:26.466 --> 00:25:27.896
And that means that the data

00:25:28.256 --> 00:25:29.726
that you provided, has been

00:25:29.906 --> 00:25:31.316
rendered when the completion

00:25:31.316 --> 00:25:32.196
handler gets called.

00:25:33.136 --> 00:25:34.446
And this does not account for

00:25:34.446 --> 00:25:36.226
any downstream signal processing

00:25:36.226 --> 00:25:38.776
latencies in your processing

00:25:39.516 --> 00:25:39.666
graph.

00:25:40.236 --> 00:25:42.496
The last type is the data played

00:25:42.496 --> 00:25:44.016
back type, which is the most

00:25:44.016 --> 00:25:44.786
interesting one.

00:25:45.286 --> 00:25:46.736
And this means that when your

00:25:46.786 --> 00:25:48.226
completion handler gets called,

00:25:48.526 --> 00:25:50.176
the buffer or the file that you

00:25:50.176 --> 00:25:52.146
scheduled, has actually finished

00:25:52.246 --> 00:25:53.476
playing from the listener's

00:25:53.516 --> 00:25:54.186
perspective.

00:25:55.016 --> 00:25:56.626
And this is applicable only when

00:25:56.626 --> 00:25:57.906
the Engine is rendering to the

00:25:57.906 --> 00:25:58.396
device.

00:25:59.086 --> 00:26:00.546
And this accounts for all the

00:26:00.546 --> 00:26:02.026
signal processing latencies,

00:26:02.236 --> 00:26:03.846
downstream of the player in your

00:26:03.876 --> 00:26:06.246
processing graph, as well as any

00:26:06.246 --> 00:26:07.826
latency in the audio playback

00:26:07.886 --> 00:26:08.326
device.

00:26:09.506 --> 00:26:12.216
So, as a code example, let's see

00:26:12.646 --> 00:26:14.416
a scheduled file method through

00:26:14.416 --> 00:26:15.666
which you can schedule a file

00:26:15.666 --> 00:26:16.386
for playback.

00:26:17.266 --> 00:26:19.066
So, here, I'm scheduling a file

00:26:19.066 --> 00:26:20.816
for playback and indicating that

00:26:20.816 --> 00:26:22.186
I'm interested to know when the

00:26:22.186 --> 00:26:23.856
data has played back.

00:26:25.186 --> 00:26:26.566
That me -- and I'm providing a

00:26:26.566 --> 00:26:27.406
completion handler.

00:26:28.076 --> 00:26:29.336
So, when the completion handler

00:26:29.336 --> 00:26:31.056
gets called, it means that my

00:26:31.056 --> 00:26:32.756
file has finished playing, and

00:26:32.756 --> 00:26:33.966
at this point, I can say,

00:26:33.966 --> 00:26:35.846
"Notify my UI thread to update

00:26:35.846 --> 00:26:38.326
the UI," or I can notify my main

00:26:38.326 --> 00:26:39.676
thread to go ahead and stop the

00:26:39.676 --> 00:26:40.836
Engine, if that's applicable.

00:26:41.446 --> 00:26:45.566
So, that brings us to the end of

00:26:45.616 --> 00:26:47.086
the enhancements we have in AV

00:26:47.086 --> 00:26:47.726
Audio Engine.

00:26:48.376 --> 00:26:49.916
At this point, I would also like

00:26:49.966 --> 00:26:52.026
to mention that we will soon be

00:26:52.026 --> 00:26:54.726
deprecating the AU Graph API in

00:26:54.726 --> 00:26:56.076
the Audio Toolbox framework, in

00:26:56.146 --> 00:26:59.256
2018, so please move over to

00:26:59.256 --> 00:27:01.076
using AV Audio Engine instead of

00:27:01.126 --> 00:27:02.916
AU Graph if you've not already

00:27:02.916 --> 00:27:03.926
done that.

00:27:06.456 --> 00:27:08.466
Now let's go to the second set

00:27:08.466 --> 00:27:10.016
of API in the AV Foundation

00:27:10.016 --> 00:27:11.666
framework, AV Audio Session.

00:27:12.076 --> 00:27:15.866
AirPlay 2 is a brand-new

00:27:15.866 --> 00:27:17.946
technology in this year's iOS,

00:27:17.946 --> 00:27:19.396
tvOS, and macOS [inaudible].

00:27:19.396 --> 00:27:22.486
And this lets you do multi-room

00:27:22.646 --> 00:27:24.546
audio with AirPlay 2 capable

00:27:24.546 --> 00:27:26.336
devices, which is for example,

00:27:26.336 --> 00:27:26.886
the Homepod.

00:27:27.466 --> 00:27:30.036
So, there is a separate

00:27:30.036 --> 00:27:31.676
dedicated session called

00:27:31.676 --> 00:27:32.946
"Interviews in AirPlay 2,"

00:27:33.036 --> 00:27:34.906
happening this Thursday at 4:10

00:27:34.956 --> 00:27:37.826
p.m. to go over all the features

00:27:37.826 --> 00:27:39.216
of this technology.

00:27:39.446 --> 00:27:40.646
So, you can catch that if you're

00:27:40.646 --> 00:27:42.826
interested in knowing more

00:27:44.096 --> 00:27:44.286
details.

00:27:44.406 --> 00:27:45.946
Also seated with AirPlay 2 is

00:27:45.946 --> 00:27:47.406
something called Long-Form

00:27:47.406 --> 00:27:47.746
audio.

00:27:48.486 --> 00:27:49.876
And this is a category of

00:27:49.996 --> 00:27:52.536
content, for example music or

00:27:52.666 --> 00:27:55.246
podcast, which is typically more

00:27:55.246 --> 00:27:57.426
than a few minutes long, and

00:27:57.426 --> 00:27:59.116
whose playback can be shared

00:27:59.286 --> 00:27:59.776
with others.

00:28:01.046 --> 00:28:02.316
For example, say you have a

00:28:02.316 --> 00:28:04.036
party at home, and you are

00:28:04.036 --> 00:28:05.566
playing back a music playlist

00:28:05.566 --> 00:28:07.236
through an AirPlay device.

00:28:07.546 --> 00:28:09.656
Now that is categorized as --

00:28:09.656 --> 00:28:10.976
that can be categorized as a

00:28:10.976 --> 00:28:12.276
long-form audio content.

00:28:13.376 --> 00:28:15.856
Now with AirPlay 2 and long-form

00:28:15.856 --> 00:28:18.616
audio, we now get a separate

00:28:18.616 --> 00:28:20.966
shared route for the long-form

00:28:20.966 --> 00:28:22.806
audio apps to the AirPlay 2

00:28:22.806 --> 00:28:23.306
devices.

00:28:23.896 --> 00:28:26.426
And I'll explain about that in a

00:28:26.426 --> 00:28:27.696
little more detail.

00:28:28.986 --> 00:28:30.766
And right -- and now, we have

00:28:30.766 --> 00:28:33.216
new API in AV Audio Session, for

00:28:33.216 --> 00:28:35.496
an app to identify itself as

00:28:35.496 --> 00:28:37.056
being long-form and take

00:28:37.056 --> 00:28:38.736
advantage of this separate

00:28:39.516 --> 00:28:41.146
shared audio route.

00:28:42.416 --> 00:28:45.046
So, let's consider the example I

00:28:45.046 --> 00:28:45.766
just mentioned.

00:28:45.766 --> 00:28:47.626
So, say you have a party at

00:28:47.626 --> 00:28:49.056
home, and you're playing back

00:28:49.056 --> 00:28:50.776
music to an AirPlay device.

00:28:51.476 --> 00:28:52.666
We'll contrast the current

00:28:52.666 --> 00:28:54.546
behavior and see how the

00:28:54.546 --> 00:28:56.436
behavior changes with long-form

00:28:56.436 --> 00:28:57.066
audio routing.

00:28:57.456 --> 00:28:58.636
So, here is the current

00:28:58.636 --> 00:28:59.076
behavior.

00:28:59.606 --> 00:29:01.206
So, you -- the music is now

00:29:01.206 --> 00:29:03.476
playing back through the AirPlay

00:29:03.476 --> 00:29:05.826
device, and suppose you now get

00:29:05.826 --> 00:29:07.896
a phone call.

00:29:08.116 --> 00:29:10.586
What happens is, at this point,

00:29:10.586 --> 00:29:11.926
your music playback gets

00:29:11.926 --> 00:29:13.786
interrupted and it stops.

00:29:14.416 --> 00:29:16.286
And the phone call gets routed

00:29:16.476 --> 00:29:17.856
to the system audio which could

00:29:17.856 --> 00:29:18.586
be receiver or [inaudible]

00:29:18.586 --> 00:29:19.186
speaker.

00:29:20.236 --> 00:29:21.826
And only when the phone call

00:29:21.826 --> 00:29:23.706
ends, is when the music gets a

00:29:23.736 --> 00:29:25.936
resumable [inaudible] and it

00:29:25.936 --> 00:29:27.026
resumes the playback.

00:29:28.186 --> 00:29:30.166
So, as you can see, a phone call

00:29:30.166 --> 00:29:32.106
interrupting your party music is

00:29:32.106 --> 00:29:34.396
not really an ideal scenario.

00:29:35.126 --> 00:29:36.546
So, we'll now see how the

00:29:36.546 --> 00:29:38.956
behavior changes with long-form

00:29:38.956 --> 00:29:39.566
audio routing.

00:29:41.256 --> 00:29:43.586
So lets see the same example.

00:29:43.586 --> 00:29:45.536
So, now that we have music

00:29:45.756 --> 00:29:47.196
playing back through an AirPlay

00:29:47.266 --> 00:29:48.546
2 capable device.

00:29:49.416 --> 00:29:51.966
And then, a phone call comes in.

00:29:52.706 --> 00:29:54.316
Now because the phone call is

00:29:54.316 --> 00:29:56.776
not a long-form audio, it does

00:29:56.776 --> 00:29:58.316
not interrupt your music

00:29:58.316 --> 00:30:00.256
playback, and it gets routed

00:30:00.256 --> 00:30:02.136
independently to the system

00:30:02.136 --> 00:30:03.976
audio without any issues.

00:30:04.526 --> 00:30:06.216
So, with long-form audio

00:30:06.246 --> 00:30:08.636
routing, two of the sessions can

00:30:08.636 --> 00:30:10.696
coexist without interrupting

00:30:10.956 --> 00:30:12.826
each other, and as you can see,

00:30:12.876 --> 00:30:14.666
this is definitely an enhanced

00:30:14.786 --> 00:30:15.756
user experience.

00:30:16.856 --> 00:30:16.946
So,-- .

00:30:18.516 --> 00:30:22.746
[ Applause ]

00:30:23.246 --> 00:30:25.206
So, to summarize, with long-form

00:30:25.206 --> 00:30:27.606
audio routing, all the apps that

00:30:27.606 --> 00:30:29.396
identified themselves as being

00:30:29.396 --> 00:30:31.136
long-form, which is for example,

00:30:31.276 --> 00:30:33.876
music, podcast, or any other

00:30:33.876 --> 00:30:36.396
music streaming app, they get

00:30:36.396 --> 00:30:38.126
the dedicated -- they get a

00:30:38.126 --> 00:30:39.656
separate shared route to the

00:30:39.656 --> 00:30:41.196
AirPlay 2 capable device.

00:30:42.006 --> 00:30:43.046
Now, note that there is a

00:30:43.046 --> 00:30:44.746
session arbitrated in between.

00:30:45.146 --> 00:30:48.036
And that ensures that only one

00:30:48.086 --> 00:30:50.006
of these apps is playing to the

00:30:50.006 --> 00:30:51.436
AirPlay device at the time.

00:30:51.646 --> 00:30:53.776
So, these apps cannot mix with

00:30:53.776 --> 00:30:54.546
each other.

00:30:55.056 --> 00:30:57.226
And all the other apps that use

00:30:57.226 --> 00:30:58.486
the system route, which are

00:30:58.486 --> 00:31:00.486
non-long-form, can either

00:31:00.616 --> 00:31:02.276
interrupt each other or mix with

00:31:02.276 --> 00:31:04.466
each other, and they get routed

00:31:04.606 --> 00:31:06.446
to the system audio without

00:31:06.446 --> 00:31:07.956
interrupting your long-form

00:31:07.956 --> 00:31:08.606
audio playback.

00:31:10.336 --> 00:31:13.886
Now, let's see how an app can

00:31:13.946 --> 00:31:15.496
identify itself as being

00:31:15.496 --> 00:31:17.136
long-form and take advantage of

00:31:17.186 --> 00:31:17.796
this routing.

00:31:19.176 --> 00:31:21.956
So, on iOS and tvOS, the code is

00:31:21.956 --> 00:31:22.646
really simple.

00:31:23.006 --> 00:31:24.926
You get shared instance of your

00:31:25.026 --> 00:31:26.996
AVAudio session, and you use

00:31:27.046 --> 00:31:28.806
this new API to set your

00:31:28.806 --> 00:31:31.206
category as playback and route

00:31:31.206 --> 00:31:36.096
sharing policy as long-form.

00:31:36.276 --> 00:31:38.496
Now, moving over to the macOS,

00:31:39.216 --> 00:31:41.726
the routing is very similar to

00:31:41.726 --> 00:31:43.026
the iOS and tvOS.

00:31:43.376 --> 00:31:45.236
All the long-form audio apps,

00:31:45.236 --> 00:31:47.386
for example your iTunes and any

00:31:47.386 --> 00:31:49.966
other music streaming app, gets

00:31:50.176 --> 00:31:52.216
routed to the AirPlay 2 capable

00:31:52.216 --> 00:31:54.506
device, and of course, there is

00:31:54.506 --> 00:31:55.856
an arbitrator in between.

00:31:57.046 --> 00:31:59.566
And the other system apps like

00:31:59.926 --> 00:32:02.626
GarageBand, Safari, or Game App,

00:32:02.626 --> 00:32:04.476
do not interrupt your long-form

00:32:04.476 --> 00:32:06.506
audio apps, and they always mix

00:32:06.506 --> 00:32:08.216
with each other and get routed

00:32:08.396 --> 00:32:09.686
to the default device.

00:32:10.836 --> 00:32:12.576
And to enable the support of

00:32:12.576 --> 00:32:13.926
long-form audio routing on

00:32:13.926 --> 00:32:15.696
macOS, we are now bringing a

00:32:15.696 --> 00:32:17.596
very small subset of AVAudio

00:32:17.596 --> 00:32:19.066
Session to macOS.

00:32:19.666 --> 00:32:21.496
So, as an app, in order to

00:32:21.496 --> 00:32:23.056
identify yourself as being

00:32:23.056 --> 00:32:25.056
long-form, you again get the

00:32:25.056 --> 00:32:27.066
shared and sense of your AVAudio

00:32:27.066 --> 00:32:28.576
Session, and set the route

00:32:28.576 --> 00:32:30.116
sharing policy as being

00:32:30.116 --> 00:32:30.636
long-form.

00:32:31.166 --> 00:32:34.586
So, that is the end of AVAudio

00:32:34.586 --> 00:32:36.476
Session enhancements, and let's

00:32:36.476 --> 00:32:38.226
now see the last section in the

00:32:38.226 --> 00:32:39.736
AV Foundation framework, that is

00:32:39.736 --> 00:32:40.986
the enhancement on watchOS.

00:32:41.606 --> 00:32:45.936
So, we introduced the AV -- we

00:32:45.936 --> 00:32:47.936
made AVAudio Player API

00:32:48.016 --> 00:32:50.336
available in watchOS 3.1SDK.

00:32:50.926 --> 00:32:51.786
And this is the first time we

00:32:51.786 --> 00:32:53.546
get to mention it at WWDC.

00:32:54.116 --> 00:32:55.366
And the nice thing about using

00:32:55.366 --> 00:32:57.256
the AVAudio Player for playback

00:32:57.536 --> 00:32:59.266
is that it comes associated with

00:32:59.266 --> 00:33:01.026
its AVAudio Session, so you

00:33:01.026 --> 00:33:02.766
could use the session category

00:33:02.766 --> 00:33:04.326
options like [inaudible] or mix

00:33:04.376 --> 00:33:06.816
with others, to describe your

00:33:06.816 --> 00:33:07.646
app's behavior.

00:33:08.396 --> 00:33:10.836
Now starting watchOS 4, we are

00:33:11.466 --> 00:33:13.476
exposing more APIs in order to

00:33:13.476 --> 00:33:14.896
do recording.

00:33:15.176 --> 00:33:17.066
That is, we are making AVAudio

00:33:17.096 --> 00:33:19.576
Recorder and AVAudio Input Node

00:33:19.576 --> 00:33:21.386
and AVAudio Engine, available.

00:33:22.836 --> 00:33:24.186
And with these, comes the

00:33:24.186 --> 00:33:25.646
AVAudio recording permissions,

00:33:25.816 --> 00:33:27.146
through which an app can

00:33:27.146 --> 00:33:28.786
[inaudible] the user permission

00:33:28.786 --> 00:33:29.286
to record.

00:33:30.126 --> 00:33:31.656
Now, [inaudible] to this you

00:33:31.656 --> 00:33:33.136
could use the watch [inaudible]

00:33:33.396 --> 00:33:35.186
framework to do the recording,

00:33:35.436 --> 00:33:37.106
using the Apple UI.

00:33:37.296 --> 00:33:39.786
But now, with these APIs, you

00:33:39.786 --> 00:33:42.406
could do the recording with your

00:33:42.406 --> 00:33:43.226
own UI.

00:33:44.306 --> 00:33:45.946
With AVAudio Recorder, you could

00:33:45.946 --> 00:33:47.656
record to a file, or if you

00:33:47.656 --> 00:33:49.046
wanted to get access to the

00:33:49.046 --> 00:33:50.256
microphone [inaudible] directly,

00:33:50.436 --> 00:33:51.996
you could use the AVAudio Input

00:33:51.996 --> 00:33:53.916
Node, and also optionally, write

00:33:53.916 --> 00:33:54.506
it to a file.

00:33:55.546 --> 00:33:57.056
And here are the formats that

00:33:57.056 --> 00:33:58.976
are supported on watchOS, both

00:33:58.976 --> 00:34:00.376
for playback and recording.

00:34:01.576 --> 00:34:03.816
A last note on the recording

00:34:03.816 --> 00:34:04.346
policies.

00:34:05.276 --> 00:34:06.966
The recording can start only

00:34:06.966 --> 00:34:08.255
when the app is in foreground.

00:34:08.846 --> 00:34:10.246
But it is allowed to continue

00:34:10.246 --> 00:34:12.326
recording in the background, but

00:34:12.326 --> 00:34:13.946
-- and the right microphone icon

00:34:13.996 --> 00:34:15.676
will be displayed at the top so

00:34:15.676 --> 00:34:17.076
that the user is aware of it.

00:34:18.366 --> 00:34:20.255
And recording in background is

00:34:20.525 --> 00:34:22.275
CPU limited, similar to the

00:34:22.856 --> 00:34:23.936
[inaudible] sessions and you can

00:34:23.936 --> 00:34:25.696
refer to this URL for more

00:34:25.696 --> 00:34:26.136
details.

00:34:28.005 --> 00:34:29.476
Now, let's move over to the

00:34:29.476 --> 00:34:31.246
Audio Toolbox world and look at

00:34:31.246 --> 00:34:33.085
the enhancements in AUAudio Unit

00:34:33.315 --> 00:34:34.706
and audio formats.

00:34:35.235 --> 00:34:38.516
We have two main enhancements in

00:34:38.516 --> 00:34:39.246
AUAudio Unit.

00:34:40.126 --> 00:34:41.466
And at the end of this section,

00:34:41.496 --> 00:34:42.996
we will also show you a demo

00:34:43.196 --> 00:34:44.726
with those two new features in

00:34:47.826 --> 00:34:47.985
action.

00:34:48.166 --> 00:34:49.956
Now, Audio Unit host

00:34:49.956 --> 00:34:51.646
applications choose various

00:34:51.646 --> 00:34:53.656
strategies in order to recommend

00:34:53.766 --> 00:34:56.116
how to display the UI for AU.

00:34:56.426 --> 00:34:58.816
They can decide to say embed the

00:34:58.816 --> 00:35:01.696
AU's UI in their own UI, or they

00:35:01.696 --> 00:35:03.076
could present a full screen

00:35:03.076 --> 00:35:05.146
separate UI for the AU.

00:35:06.106 --> 00:35:07.596
Now, this presents mainly a

00:35:07.626 --> 00:35:08.726
challenge on the [inaudible]

00:35:08.806 --> 00:35:10.706
devices because currently, the

00:35:10.706 --> 00:35:13.006
view sizes are not defined, and

00:35:13.006 --> 00:35:14.716
the audio unit is expected to

00:35:14.716 --> 00:35:17.036
adapt to any UI size that the

00:35:17.036 --> 00:35:18.656
host has actually chosen.

00:35:19.856 --> 00:35:21.056
In order to overcome this

00:35:21.056 --> 00:35:23.126
limitation, we're now adding a

00:35:23.156 --> 00:35:25.506
way in which the host and the AU

00:35:25.656 --> 00:35:27.076
can negotiate with each other

00:35:27.506 --> 00:35:29.556
and the AU can inform the host

00:35:29.846 --> 00:35:30.766
about all the view

00:35:30.766 --> 00:35:32.186
configurations that it actually

00:35:32.186 --> 00:35:32.746
supports.

00:35:33.096 --> 00:35:34.906
Now, let's see how this

00:35:35.256 --> 00:35:38.196
negotiation can take place.

00:35:38.366 --> 00:35:41.336
The host first compiles a list

00:35:41.336 --> 00:35:43.126
of all the available view

00:35:43.126 --> 00:35:45.986
configurations for the AU, and

00:35:45.986 --> 00:35:49.536
then hands the audio over to the

00:35:49.536 --> 00:35:49.603
AU.

00:35:50.006 --> 00:35:51.206
The AU can then [inaudible]

00:35:51.206 --> 00:35:52.616
through all these available

00:35:52.616 --> 00:35:54.376
configurations, and then let the

00:35:54.376 --> 00:35:56.576
host know about the

00:35:57.006 --> 00:35:58.326
configuration that it actually

00:35:58.326 --> 00:35:58.876
supports.

00:35:59.696 --> 00:36:01.466
And then, the host can choose

00:36:01.466 --> 00:36:02.556
one of the supported

00:36:02.596 --> 00:36:04.276
configurations and then it will

00:36:04.276 --> 00:36:06.086
let the AU know about the final

00:36:06.086 --> 00:36:07.266
selected configuration.

00:36:08.416 --> 00:36:10.456
Now, let's see a code example on

00:36:10.456 --> 00:36:12.216
how this negotiation takes

00:36:12.216 --> 00:36:12.546
place.

00:36:13.006 --> 00:36:14.616
We'll first look at the audio

00:36:14.616 --> 00:36:15.996
unit extension site.

00:36:16.596 --> 00:36:19.566
The first thing the AU has to do

00:36:20.356 --> 00:36:22.236
is to override the supported

00:36:22.236 --> 00:36:24.186
view configuration method from

00:36:24.186 --> 00:36:24.846
the base class.

00:36:25.516 --> 00:36:27.156
And this is called by the host

00:36:27.446 --> 00:36:28.986
with the list of all the

00:36:28.986 --> 00:36:31.016
available configurations.

00:36:32.276 --> 00:36:34.526
Then, the AU can iterate through

00:36:34.566 --> 00:36:36.566
each of these configurations and

00:36:36.566 --> 00:36:38.426
decide which ones it actually

00:36:38.426 --> 00:36:38.966
supports.

00:36:39.466 --> 00:36:41.696
Now, the configuration itself,

00:36:41.876 --> 00:36:43.806
contains a width and a height,

00:36:44.066 --> 00:36:46.846
which recommends the view size.

00:36:47.186 --> 00:36:48.906
And also, it has a host test

00:36:48.906 --> 00:36:49.736
controller flag.

00:36:50.636 --> 00:36:52.576
And that flag indicates whether

00:36:52.576 --> 00:36:54.886
or not the host is presenting

00:36:54.886 --> 00:36:56.716
its own controller in this

00:36:56.716 --> 00:36:58.496
particular view configuration.

00:36:59.006 --> 00:37:00.696
So, depending on all these

00:37:00.696 --> 00:37:03.166
factors, an AU can choose

00:37:03.246 --> 00:37:04.396
whether it supports that

00:37:04.466 --> 00:37:05.536
particular configuration.

00:37:06.826 --> 00:37:08.366
Note that there is a wild card

00:37:08.366 --> 00:37:11.466
configuration which is 0x0, and

00:37:11.466 --> 00:37:12.586
that means -- and that

00:37:12.586 --> 00:37:14.976
represents a full default size

00:37:15.296 --> 00:37:17.056
that the AU can support.

00:37:17.696 --> 00:37:19.946
And on macOS, this actually

00:37:19.946 --> 00:37:21.756
translates to a separate,

00:37:21.916 --> 00:37:23.766
resizable window -- full size,

00:37:23.766 --> 00:37:26.996
resizable window, for the AU's

00:37:27.036 --> 00:37:27.296
UI.

00:37:28.156 --> 00:37:31.576
So, the AU has its own logic to

00:37:31.576 --> 00:37:32.966
decide which configuration it

00:37:32.966 --> 00:37:34.796
supports, and then finally, it

00:37:34.906 --> 00:37:36.656
compares a list of the indices

00:37:37.036 --> 00:37:39.466
corresponding to the ones that

00:37:39.466 --> 00:37:40.846
it supports, and [inaudible]

00:37:40.876 --> 00:37:43.746
this index set back to the host.

00:37:44.966 --> 00:37:46.866
The last thing that the AU has

00:37:46.946 --> 00:37:49.266
to do, is to override select

00:37:49.416 --> 00:37:51.116
method, which is called by the

00:37:51.116 --> 00:37:53.086
host with the configuration that

00:37:53.086 --> 00:37:55.206
it has finally selected, and

00:37:55.206 --> 00:37:57.596
then, the AU can let its view

00:37:57.596 --> 00:37:59.346
controller know about the final

00:37:59.346 --> 00:38:00.566
selected configuration.

00:38:02.166 --> 00:38:03.886
Now, let's go to the host site

00:38:04.086 --> 00:38:06.266
and see how the code looks like.

00:38:07.296 --> 00:38:10.566
The host has to compile the list

00:38:10.566 --> 00:38:12.226
of available configurations, and

00:38:12.226 --> 00:38:13.706
in this example, it is saying

00:38:13.926 --> 00:38:15.826
that it has a large and a small

00:38:15.826 --> 00:38:17.096
configuration available.

00:38:17.716 --> 00:38:19.606
And in the last configuration,

00:38:19.796 --> 00:38:21.316
the host is saying it's not

00:38:21.506 --> 00:38:23.586
presenting its controller, so

00:38:23.586 --> 00:38:25.246
the host has controller flag as

00:38:25.346 --> 00:38:25.676
false.

00:38:26.016 --> 00:38:27.326
And in the small configuration,

00:38:27.536 --> 00:38:29.356
the host does present its

00:38:29.356 --> 00:38:30.866
controller, so the flag is true.

00:38:32.096 --> 00:38:34.526
The host then calls the

00:38:34.526 --> 00:38:36.066
supported view configurations

00:38:36.066 --> 00:38:38.626
method on the AU, and provides

00:38:38.626 --> 00:38:40.496
this list of configurations.

00:38:40.976 --> 00:38:42.556
And depending on the return set

00:38:42.556 --> 00:38:44.556
of indices, it goes ahead and

00:38:44.556 --> 00:38:45.596
selects one of the

00:38:45.596 --> 00:38:46.416
configurations.

00:38:46.656 --> 00:38:48.196
And in this particular example,

00:38:48.396 --> 00:38:49.726
the host is just toggling

00:38:49.866 --> 00:38:51.306
between the large and the small

00:38:51.306 --> 00:38:51.986
configuration.

00:38:52.456 --> 00:38:55.576
So, that is end of the preferred

00:38:55.726 --> 00:38:57.286
view configuration negotiation.

00:38:57.706 --> 00:38:59.086
Now, let's see the second main

00:38:59.216 --> 00:39:01.596
new feature we have, which is

00:39:01.596 --> 00:39:03.486
the support for MIDI output in

00:39:03.486 --> 00:39:04.626
an audio unit extension.

00:39:05.916 --> 00:39:07.966
We have now support for an AU to

00:39:07.966 --> 00:39:10.186
emit MIDI output synchronized

00:39:10.306 --> 00:39:11.376
with its audio output.

00:39:12.056 --> 00:39:13.906
And this mainly useful if the

00:39:13.906 --> 00:39:16.146
host wants to record and edit

00:39:16.306 --> 00:39:17.926
both the MIDI performance, as

00:39:17.926 --> 00:39:19.616
well as the audio output, from

00:39:19.766 --> 00:39:20.686
the AU.

00:39:20.996 --> 00:39:23.366
So, the host installs a MIDI

00:39:23.366 --> 00:39:25.176
output event block on the AU,

00:39:25.406 --> 00:39:26.876
and the AU should call this

00:39:26.926 --> 00:39:29.326
block every render cycle and

00:39:29.326 --> 00:39:31.176
provide the MIDI output for that

00:39:31.236 --> 00:39:32.286
particular render cycle.

00:39:34.596 --> 00:39:36.796
We also have a couple of other

00:39:36.796 --> 00:39:37.896
enhancements in the Audio

00:39:37.896 --> 00:39:38.836
Toolbox framework.

00:39:39.136 --> 00:39:40.516
The first one is related to a

00:39:40.516 --> 00:39:42.366
privacy enhancement.

00:39:43.136 --> 00:39:46.346
So, starting iOS 11 SDK, all the

00:39:46.346 --> 00:39:48.166
audio unit extension host apps

00:39:48.746 --> 00:39:50.436
will need the inter-app-audio

00:39:50.436 --> 00:39:51.966
entitlement to be able to

00:39:51.966 --> 00:39:53.626
communicate with the audio unit

00:39:53.626 --> 00:39:54.206
extensions.

00:39:55.166 --> 00:39:57.546
And we also have a new API for

00:39:57.936 --> 00:40:00.926
an AU to publish a very

00:40:00.926 --> 00:40:03.076
meaningful short name so that

00:40:03.076 --> 00:40:05.676
the host say, can use this short

00:40:05.676 --> 00:40:07.356
name if it has to display the

00:40:07.356 --> 00:40:10.286
list of AU names in a space

00:40:10.286 --> 00:40:12.466
constraint list.

00:40:13.826 --> 00:40:17.086
So, that brings us to the end of

00:40:17.086 --> 00:40:18.386
all the enhancements in Audio

00:40:18.386 --> 00:40:19.856
Toolbox framework, and as

00:40:19.946 --> 00:40:23.116
promised, we have a demo to show

00:40:23.116 --> 00:40:24.526
these new features in action.

00:40:24.526 --> 00:40:26.286
And I call upon Bela for that.

00:40:27.516 --> 00:40:33.076
[ Applause ]

00:40:33.576 --> 00:40:38.106
>> Thank you, Akshatha and good

00:40:38.106 --> 00:40:39.006
afternoon everyone.

00:40:39.006 --> 00:40:40.716
My name is Bela Balazs and I am

00:40:40.716 --> 00:40:43.746
an engineer on the Core Audio

00:40:43.746 --> 00:40:44.436
Team.

00:40:44.436 --> 00:40:47.086
Today, we would like to show you

00:40:47.086 --> 00:40:48.956
an application of our newly

00:40:48.956 --> 00:40:50.656
introduced APIs.

00:40:51.116 --> 00:40:52.476
For this purpose, we have

00:40:52.476 --> 00:40:54.226
developed an example audio unit,

00:40:54.316 --> 00:40:55.276
which has the following

00:40:55.276 --> 00:40:56.126
capabilities.

00:40:57.156 --> 00:40:58.986
It supports its preferred view

00:40:58.986 --> 00:41:00.346
configuration with the Audio

00:41:00.346 --> 00:41:01.696
Unit host application.

00:41:02.556 --> 00:41:03.836
It supports multiple view

00:41:03.836 --> 00:41:05.806
configurations, and it uses the

00:41:05.806 --> 00:41:09.286
newly bridged MIDI output API in

00:41:09.286 --> 00:41:11.526
order to pass on MIDI data to

00:41:11.526 --> 00:41:13.266
the Audio Unit host application

00:41:13.266 --> 00:41:14.496
for recording purposes.

00:41:15.746 --> 00:41:17.306
So, here I have an upcoming

00:41:17.306 --> 00:41:18.506
version of GarageBand.

00:41:19.286 --> 00:41:20.926
And I have loaded my example

00:41:20.926 --> 00:41:22.106
audio unit to a track.

00:41:22.756 --> 00:41:24.986
Here you can see the custom view

00:41:24.986 --> 00:41:27.146
of my audio unit, together with

00:41:27.146 --> 00:41:28.256
the GarageBand keyboard.

00:41:28.676 --> 00:41:31.196
In this reconfiguration, I rely

00:41:31.196 --> 00:41:32.576
on the GarageBand keyboard to

00:41:32.576 --> 00:41:33.446
play my instrument.

00:41:34.236 --> 00:41:35.776
I have mapped out three drum

00:41:35.776 --> 00:41:36.936
samples on the keyboard.

00:41:37.166 --> 00:41:39.296
I have a kick, I have a snare,

00:41:39.826 --> 00:41:40.706
and I have a high hat.

00:41:41.486 --> 00:41:43.236
In addition to these, on the

00:41:43.236 --> 00:41:45.206
view of my audio unit, I also

00:41:45.206 --> 00:41:46.796
have a volume slider to control

00:41:46.796 --> 00:41:48.926
the volume of these samples.

00:41:51.476 --> 00:41:53.756
However, my audio unit also has

00:41:53.756 --> 00:41:55.526
a different view configuration,

00:41:55.576 --> 00:41:57.246
and I can switch to it using

00:41:57.246 --> 00:41:58.816
this newly added button on the

00:41:58.816 --> 00:42:00.966
right -- lower, right section of

00:42:00.966 --> 00:42:01.496
the screen.

00:42:02.106 --> 00:42:04.086
When I activate that button, I

00:42:04.086 --> 00:42:05.766
get taken to the large view of

00:42:05.766 --> 00:42:07.556
my audio unit and the GarageBand

00:42:07.556 --> 00:42:08.516
keyboard disappears.

00:42:09.336 --> 00:42:11.226
When I activate it again, I get

00:42:11.286 --> 00:42:12.786
taken back to the small view of

00:42:12.786 --> 00:42:13.536
my audio unit.

00:42:14.086 --> 00:42:15.416
This is made possible by

00:42:15.416 --> 00:42:18.576
GarageBand's publishing all the

00:42:18.576 --> 00:42:20.216
available view configurations to

00:42:20.216 --> 00:42:22.706
my audio unit, and my audio unit

00:42:22.706 --> 00:42:24.226
goes through that list and marks

00:42:24.226 --> 00:42:25.846
each of them as supported or

00:42:25.846 --> 00:42:27.786
unsupported, and at the end of

00:42:27.786 --> 00:42:29.356
this process, GarageBand knows

00:42:29.356 --> 00:42:30.936
that my audio unit supports two

00:42:30.936 --> 00:42:33.076
view configurations and it can

00:42:33.076 --> 00:42:34.096
toggle between them.

00:42:35.176 --> 00:42:36.806
In case my audio unit only

00:42:36.806 --> 00:42:37.766
supported one view

00:42:37.766 --> 00:42:39.956
configuration, then this button

00:42:39.956 --> 00:42:41.396
could be hidden by GarageBand,

00:42:41.396 --> 00:42:42.846
but my audio unit could still

00:42:42.846 --> 00:42:44.036
take full advantage of the

00:42:44.036 --> 00:42:46.396
negotiation process to negotiate

00:42:46.396 --> 00:42:48.446
the preferred view configuration

00:42:48.446 --> 00:42:49.416
for that one view.

00:42:50.226 --> 00:42:53.446
In this small view, the host has

00:42:53.446 --> 00:42:55.276
controller flag as set to true,

00:42:56.026 --> 00:42:57.286
and that is why the GarageBand

00:42:57.286 --> 00:42:58.266
keyboard is visible.

00:42:58.566 --> 00:42:59.596
In the larger view

00:42:59.596 --> 00:43:01.056
configuration, the GarageBand

00:43:01.056 --> 00:43:03.286
keyboard is hidden because that

00:43:03.286 --> 00:43:04.636
flag is set to false.

00:43:05.246 --> 00:43:06.696
In this view configuration, my

00:43:06.696 --> 00:43:08.986
audio unit has its own playing

00:43:08.986 --> 00:43:11.046
surface, which I can use to play

00:43:11.046 --> 00:43:11.726
my instrument.

00:43:12.066 --> 00:43:14.346
I have a kick, a snare, and a

00:43:14.346 --> 00:43:14.826
high hat.

00:43:15.986 --> 00:43:17.486
And in addition to these three

00:43:17.486 --> 00:43:21.086
buttons, I also have a new

00:43:21.086 --> 00:43:22.496
button on the right-hand side

00:43:22.556 --> 00:43:23.716
called Repeat Note.

00:43:23.986 --> 00:43:25.496
And this allows me to repeat

00:43:25.496 --> 00:43:27.996
each sample at the certain rate.

00:43:28.606 --> 00:43:30.126
And I can set those rates

00:43:30.186 --> 00:43:31.516
independently from each other

00:43:31.516 --> 00:43:32.486
using the sliders.

00:43:33.436 --> 00:43:38.436
And I can toggle each sample in

00:43:38.436 --> 00:43:39.556
and out of the drum loop.

00:43:40.516 --> 00:43:50.776
[ Drums playing ]

00:43:51.276 --> 00:43:52.976
This allows me to easily

00:43:52.976 --> 00:43:54.326
construct drum loops that

00:43:54.526 --> 00:43:56.306
respect the tempo of my track.

00:43:57.726 --> 00:43:59.696
So, let's use the MIDI output

00:43:59.696 --> 00:44:01.976
API to record the output of this

00:44:01.976 --> 00:44:03.316
audio unit extension.

00:44:04.046 --> 00:44:05.436
I have the synchronized rates

00:44:05.436 --> 00:44:07.516
button here, which sets my rates

00:44:07.516 --> 00:44:09.766
to 110 BPM.

00:44:09.766 --> 00:44:11.806
And first, I will record a kick,

00:44:11.936 --> 00:44:13.396
snare drum loop.

00:44:13.396 --> 00:44:14.636
And then when the recording

00:44:14.636 --> 00:44:16.406
wraps around, I will add my high

00:44:16.406 --> 00:44:16.806
hats.

00:44:17.236 --> 00:44:18.606
This is made possible by

00:44:18.606 --> 00:44:20.376
GarageBand's merge recording

00:44:20.376 --> 00:44:20.876
feature.

00:44:21.656 --> 00:44:22.826
So, let's do just that.

00:44:23.516 --> 00:44:26.556
[ Drums playing ]

00:44:27.056 --> 00:44:28.686
I will just record four bars of

00:44:28.866 --> 00:44:29.996
that.

00:44:30.476 --> 00:44:36.626
And then add my high hats.

00:44:37.516 --> 00:44:44.176
[ Drums playing ]

00:44:44.676 --> 00:44:46.636
My high hats have been added to

00:44:46.636 --> 00:44:47.326
the recording.

00:44:47.906 --> 00:44:50.876
And now we can go to the track

00:44:50.876 --> 00:44:52.086
view and take a look at our

00:44:52.086 --> 00:44:53.236
recorded media output.

00:44:54.136 --> 00:44:58.826
And I can quantize the track.

00:44:59.516 --> 00:45:05.086
And then we can play it back.

00:45:05.546 --> 00:45:09.076
And we have the full MIDI

00:45:09.076 --> 00:45:10.426
editing capabilities of

00:45:10.426 --> 00:45:12.096
GarageBand at our disposal to

00:45:12.096 --> 00:45:13.476
construct our drum track.

00:45:14.366 --> 00:45:15.716
And this concludes my demo.

00:45:15.766 --> 00:45:16.656
Thank you very much for your

00:45:16.656 --> 00:45:17.066
attention.

00:45:17.066 --> 00:45:18.176
And I would like to hand it back

00:45:18.176 --> 00:45:19.276
to my colleague, Akshatha.

00:45:19.846 --> 00:45:20.156
Thank you.

00:45:21.516 --> 00:45:25.516
[ Applause ]

00:45:26.016 --> 00:45:29.696
>> Thank you, Bela.

00:45:29.886 --> 00:45:31.596
So, now, onto the last set of

00:45:31.726 --> 00:45:32.686
enhancements in the Audio

00:45:32.686 --> 00:45:34.246
Toolbox framework, related to

00:45:34.246 --> 00:45:35.206
the audio formats.

00:45:36.626 --> 00:45:38.396
We now have support for two of

00:45:38.656 --> 00:45:40.286
the popular formats, namely the

00:45:40.286 --> 00:45:42.056
FLAC and the Opus format.

00:45:42.056 --> 00:45:44.706
On the FLAC side, we have the

00:45:44.756 --> 00:45:46.566
codec, file, and the streaming

00:45:46.566 --> 00:45:48.496
support, and for Opus, we have

00:45:48.496 --> 00:45:49.976
the codec, and the file I/O

00:45:49.976 --> 00:45:51.416
support using the code audio

00:45:51.416 --> 00:45:52.266
format container.

00:45:54.376 --> 00:45:56.336
From audio formats to spatial

00:45:56.336 --> 00:45:58.346
audio formats, those of you who

00:45:58.346 --> 00:45:59.326
are interested in [inaudible]

00:45:59.326 --> 00:46:02.096
audio, AR, and VR applications,

00:46:02.416 --> 00:46:04.026
you may be happy to know that we

00:46:04.026 --> 00:46:05.456
now support ambisonics.

00:46:06.106 --> 00:46:07.886
And for those of you who may not

00:46:07.886 --> 00:46:09.016
be really familiar with

00:46:09.016 --> 00:46:11.586
ambisonics like me, ambisonics

00:46:11.686 --> 00:46:14.006
is also a multichannel format,

00:46:14.536 --> 00:46:16.256
but the difference is that the

00:46:16.256 --> 00:46:18.006
traditional surround formats

00:46:18.006 --> 00:46:20.306
that we know of, for example 5.1

00:46:20.466 --> 00:46:22.946
or 7.1, have the signals that

00:46:23.086 --> 00:46:24.606
actually represent the speaker

00:46:24.606 --> 00:46:24.986
layout.

00:46:25.596 --> 00:46:28.466
Whereas ambisonics provide a

00:46:28.606 --> 00:46:29.696
speaker independent

00:46:29.696 --> 00:46:31.176
representation of the sound

00:46:32.226 --> 00:46:32.536
feed.

00:46:32.536 --> 00:46:34.236
So, they are by nature,

00:46:34.346 --> 00:46:35.036
[inaudible] from the playback

00:46:35.036 --> 00:46:35.486
system.

00:46:36.156 --> 00:46:38.256
And at the time of rendering, is

00:46:38.256 --> 00:46:40.076
when they can be decoded to the

00:46:40.076 --> 00:46:41.686
listener's speaker setup.

00:46:42.326 --> 00:46:43.306
And this provides more

00:46:43.306 --> 00:46:44.746
flexibility for the content

00:46:44.746 --> 00:46:45.256
producers.

00:46:46.436 --> 00:46:48.166
We now support the first order

00:46:48.166 --> 00:46:49.856
ambisonics which is called the

00:46:49.856 --> 00:46:52.646
B-format and higher ordered

00:46:52.646 --> 00:46:55.416
ambisonics with the Order N, can

00:46:55.416 --> 00:46:57.696
range from 1 through 254.

00:46:58.076 --> 00:46:59.896
And depending on the order, the

00:47:00.036 --> 00:47:02.276
channels itself can go from zero

00:47:02.516 --> 00:47:03.966
-- the ambisonic channel number

00:47:04.046 --> 00:47:06.986
can go from zero to 65,024.

00:47:07.826 --> 00:47:09.266
And we support two of the

00:47:09.526 --> 00:47:11.576
popular normalized streams,

00:47:12.066 --> 00:47:13.966
namely the SN3D and the N3D

00:47:13.966 --> 00:47:16.336
streams, and we support decoding

00:47:16.336 --> 00:47:19.716
ambisonics to any arbitrary

00:47:19.876 --> 00:47:21.576
speaker layout, and conversion

00:47:21.576 --> 00:47:23.276
between the B-format and these

00:47:23.276 --> 00:47:24.076
normalized streams.

00:47:24.696 --> 00:47:28.906
The last enhancement is on the

00:47:28.906 --> 00:47:30.146
AU Spatial Mixer side.

00:47:30.516 --> 00:47:32.306
So, this is an Apple built-in

00:47:32.556 --> 00:47:34.716
spatial mixer, which is used for

00:47:34.716 --> 00:47:36.236
3D audio spatialization.

00:47:37.006 --> 00:47:39.216
And the AVAudio Environment

00:47:39.216 --> 00:47:40.636
Node, which is a node in the

00:47:40.636 --> 00:47:42.656
AVAudio Engine, also uses the

00:47:42.656 --> 00:47:44.266
Spatial Mixer underneath.

00:47:44.856 --> 00:47:47.046
And we now have a new rendering

00:47:47.046 --> 00:47:48.826
algorithm in this Spatial Mixer,

00:47:49.086 --> 00:47:52.136
called HRTFHQ, high quality.

00:47:52.546 --> 00:47:54.236
And this differs from the

00:47:54.236 --> 00:47:56.946
current existing HRTF algorithm

00:47:57.176 --> 00:47:58.256
in the sense that it has a

00:47:58.256 --> 00:47:59.996
better frequency response and

00:47:59.996 --> 00:48:01.646
better localization of sources

00:48:01.646 --> 00:48:02.566
in the 3D space.

00:48:03.816 --> 00:48:05.056
So, that concludes all the

00:48:05.056 --> 00:48:06.366
enhancements in the Audio

00:48:06.366 --> 00:48:08.266
Toolbox framework and now, I

00:48:08.266 --> 00:48:09.996
hand it over to Torrey to take

00:48:09.996 --> 00:48:11.666
it away from here, and give you

00:48:11.666 --> 00:48:14.016
an update on inter-device audio

00:48:14.386 --> 00:48:14.646
mode.

00:48:15.516 --> 00:48:20.066
[ Applause ]

00:48:20.566 --> 00:48:21.396
>> Thank you, Akshatha.

00:48:21.496 --> 00:48:23.236
I am Torrey Holbrook Walker, and

00:48:23.236 --> 00:48:24.456
I'm going to take you home today

00:48:24.456 --> 00:48:26.236
with inter-device audio mode, or

00:48:26.236 --> 00:48:27.326
if you want to be cool, you can

00:48:27.326 --> 00:48:28.776
just say IDAM for short.

00:48:29.236 --> 00:48:30.386
And you remember IDAM.

00:48:30.596 --> 00:48:32.356
You take your iOS device.

00:48:32.356 --> 00:48:33.326
You plug it into your Mac.

00:48:33.326 --> 00:48:35.006
You open up Audio MIDI setup and

00:48:35.006 --> 00:48:36.216
then it shows right up there in

00:48:36.216 --> 00:48:38.096
the Audio Device Window, you can

00:48:38.136 --> 00:48:38.986
-- there's a button next to it

00:48:38.986 --> 00:48:39.656
that says Enable.

00:48:39.656 --> 00:48:41.076
And if you click it, boom,

00:48:41.266 --> 00:48:42.526
you've immediately got the

00:48:42.526 --> 00:48:44.176
capability to record audio

00:48:44.176 --> 00:48:46.056
digitally over the USB lightning

00:48:46.056 --> 00:48:47.226
cable that came with the device,

00:48:47.636 --> 00:48:49.586
and it looks just like a USB

00:48:49.586 --> 00:48:51.576
audio input to the Mac host.

00:48:51.576 --> 00:48:53.316
So, it uses the same driver, the

00:48:53.316 --> 00:48:54.466
same low latency driver, that's

00:48:54.466 --> 00:48:56.506
used on MacOS 4, class-compliant

00:48:56.506 --> 00:48:57.266
audio devices.

00:48:57.586 --> 00:48:58.936
And you've been able to do this

00:48:58.936 --> 00:49:01.566
since El Capitan and iOS 9.

00:49:01.956 --> 00:49:03.476
Well, today we would like to

00:49:03.476 --> 00:49:06.046
wave a fond farewell to IDAM.

00:49:06.106 --> 00:49:07.936
So, wave goodbye IDAM.

00:49:07.936 --> 00:49:08.966
Goodbye IDAM.

00:49:09.436 --> 00:49:10.736
And while you're waving, say

00:49:10.736 --> 00:49:12.676
hello to IDAM, Inter Device

00:49:12.676 --> 00:49:13.646
Audio and MIDI.

00:49:14.386 --> 00:49:15.936
So, this year, we are adding

00:49:16.046 --> 00:49:18.366
MIDI to IDAM configuration, and

00:49:18.366 --> 00:49:19.956
that will allow you to send and

00:49:19.956 --> 00:49:21.936
receive your musical instrument

00:49:21.936 --> 00:49:23.986
data to your iOS device using

00:49:23.986 --> 00:49:25.296
the same cable that came with

00:49:25.296 --> 00:49:25.846
the device.

00:49:26.206 --> 00:49:28.016
It's class-compliant once again,

00:49:28.276 --> 00:49:31.266
so on the iOS side, you will see

00:49:31.386 --> 00:49:33.086
a MIDI source and destination

00:49:33.086 --> 00:49:34.046
representing the Mac.

00:49:34.046 --> 00:49:35.266
On the Mac, you will see a

00:49:35.266 --> 00:49:36.216
source and destination

00:49:36.216 --> 00:49:37.766
representing your iOS device.

00:49:38.436 --> 00:49:40.806
Now, this will require iOS 11,

00:49:40.806 --> 00:49:42.706
but you can do it as far back as

00:49:42.706 --> 00:49:44.466
MacOS El Capitan or later,

00:49:44.506 --> 00:49:45.616
because it's a class-compliant

00:49:45.616 --> 00:49:46.316
implementation.

00:49:46.846 --> 00:49:47.546
And you don't have to do

00:49:47.546 --> 00:49:48.746
anything special to get MIDI.

00:49:48.746 --> 00:49:49.446
You're going to get it

00:49:49.446 --> 00:49:51.106
automatically anytime you enter

00:49:51.106 --> 00:49:52.286
the item configuration by

00:49:52.286 --> 00:49:53.036
clicking Enable.

00:49:53.036 --> 00:49:54.466
Do you need to do anything to

00:49:54.466 --> 00:49:55.986
your app to support that?

00:49:55.986 --> 00:49:57.256
No. It will just work if it

00:49:57.256 --> 00:49:58.076
works with MIDI.

00:49:59.006 --> 00:50:00.376
So, while you're in the IDAM

00:50:00.376 --> 00:50:01.786
configuration, your device will

00:50:01.786 --> 00:50:03.526
be able to charge and sync, but

00:50:03.526 --> 00:50:04.916
you will temporarily lose the

00:50:04.916 --> 00:50:06.536
ability to photo import and

00:50:06.536 --> 00:50:06.836
tether.

00:50:07.076 --> 00:50:07.986
You can get that back by

00:50:07.986 --> 00:50:09.276
clicking the Disable button or

00:50:09.276 --> 00:50:12.006
hot plugging the device on your

00:50:12.006 --> 00:50:12.356
Mac.

00:50:12.356 --> 00:50:13.796
The input, the audio input, side

00:50:13.796 --> 00:50:15.066
of this can be aggregated, so if

00:50:15.066 --> 00:50:16.616
you've got multiple iOS devices,

00:50:16.616 --> 00:50:18.776
like I do, say, your iPhone and

00:50:18.776 --> 00:50:20.286
your iPad and your kid's iPad,

00:50:20.606 --> 00:50:22.946
you could say enable IDAM

00:50:22.946 --> 00:50:23.966
configuration on all three of

00:50:23.966 --> 00:50:25.256
these and aggregate them into a

00:50:25.256 --> 00:50:27.156
single, six-channel audio input

00:50:27.156 --> 00:50:28.386
device that your digital audio

00:50:28.386 --> 00:50:28.976
workstation can see.

00:50:29.106 --> 00:50:30.996
And because the MIDI

00:50:30.996 --> 00:50:32.336
communication is bidirectional,

00:50:32.626 --> 00:50:34.636
you can use it as -- you could

00:50:34.636 --> 00:50:37.636
say for example, "Send MIDI to a

00:50:37.636 --> 00:50:39.796
synthesizer application," and

00:50:39.796 --> 00:50:41.136
record the audio back from it.

00:50:41.456 --> 00:50:43.056
Or you could just design a MIDI

00:50:43.056 --> 00:50:44.476
controller application for an

00:50:44.476 --> 00:50:45.626
iPad, that magical piece of

00:50:45.626 --> 00:50:47.176
glass, and you could use that to

00:50:47.176 --> 00:50:47.926
control your [inaudible].

00:50:48.396 --> 00:50:50.106
But talk is cheap, and demos pay

00:50:50.106 --> 00:50:50.566
the bills.

00:50:50.856 --> 00:50:53.906
So, let's see this in action.

00:50:54.496 --> 00:50:56.186
So, before I actually bring up

00:50:56.186 --> 00:50:57.816
my demo machine here, I want to

00:50:57.816 --> 00:51:00.006
show you the application that

00:51:00.006 --> 00:51:00.946
I'm going to use here.

00:51:02.306 --> 00:51:04.576
And it is called Feud Machine.

00:51:05.066 --> 00:51:07.296
So, I've got Feud Machine open

00:51:07.296 --> 00:51:07.516
here.

00:51:07.626 --> 00:51:10.156
And on Feud Machine, this is a

00:51:10.156 --> 00:51:12.026
multi-playhead MIDI sequencer.

00:51:12.376 --> 00:51:13.416
So, that means that you can

00:51:13.416 --> 00:51:15.726
actually use one MIDI sequence

00:51:15.766 --> 00:51:17.216
and use different playheads,

00:51:17.506 --> 00:51:18.596
perhaps moving at different

00:51:18.596 --> 00:51:20.646
times, in different directions,

00:51:21.046 --> 00:51:23.136
and use that to create a complex

00:51:23.266 --> 00:51:26.026
arpeggio using phasing and a

00:51:26.026 --> 00:51:26.886
timing relationship.

00:51:27.286 --> 00:51:28.886
So, I'm just going to play this

00:51:28.886 --> 00:51:29.506
pattern here.

00:51:29.606 --> 00:51:31.516
And there are a lot of

00:51:31.516 --> 00:51:33.816
playheads.

00:51:33.816 --> 00:51:36.026
I'll just stop some of them.

00:51:36.026 --> 00:51:40.206
So, this is just one.

00:51:40.206 --> 00:51:43.126
I'll add another.

00:51:43.126 --> 00:51:45.096
Add another.

00:51:45.366 --> 00:51:46.366
As you see, we can create

00:51:46.366 --> 00:51:48.086
arpeggios very easily this way.

00:51:48.646 --> 00:51:49.556
So, there are other patterns

00:51:49.556 --> 00:51:50.456
that I could use.

00:51:50.646 --> 00:51:52.186
For example, this one's called

00:51:52.186 --> 00:51:52.436
"Dotted".

00:51:52.436 --> 00:51:56.206
This one's "Triplet."

00:51:56.206 --> 00:51:59.156
But we'll still with this one,

00:51:59.156 --> 00:52:00.666
and we're going to use this

00:52:00.776 --> 00:52:02.756
actually to control a project

00:52:02.756 --> 00:52:04.016
that we're working on in Logic.

00:52:04.366 --> 00:52:05.356
So, now, I'll move over to my

00:52:05.356 --> 00:52:06.056
demo machine.

00:52:06.786 --> 00:52:08.036
I'm going to click Enable here.

00:52:08.856 --> 00:52:11.136
And I'll see it come up as a USB

00:52:11.136 --> 00:52:12.386
audio input, and if I look at

00:52:12.386 --> 00:52:14.186
the MIDI studio window, I'll

00:52:14.186 --> 00:52:16.116
also see that it shows up here

00:52:16.116 --> 00:52:17.556
as a MIDI source and destination

00:52:17.556 --> 00:52:18.516
that I can use in Logic.

00:52:18.946 --> 00:52:20.136
So, if I launch a project that

00:52:20.136 --> 00:52:21.846
I've been working on here -- now

00:52:26.156 --> 00:52:28.016
this is a short, four-bar loop

00:52:28.016 --> 00:52:29.436
that I'm working on for a gaming

00:52:29.436 --> 00:52:30.246
scoring screen.

00:52:30.246 --> 00:52:32.706
So, after this video game level

00:52:32.706 --> 00:52:34.386
is completed, the player can

00:52:34.386 --> 00:52:35.576
look at their results and they

00:52:35.576 --> 00:52:36.626
will be listening to this loop.

00:52:37.296 --> 00:52:39.496
And the loop right now, before

00:52:39.496 --> 00:52:40.426
I've added anything to it,

00:52:40.426 --> 00:52:40.976
sounds like this.

00:52:41.516 --> 00:52:51.546
[ Music ]

00:52:52.046 --> 00:52:54.316
Now, I want to add the arpeggio

00:52:54.316 --> 00:52:55.286
part over this.

00:52:55.596 --> 00:52:56.566
So, what I'm going to do is I'm

00:52:56.566 --> 00:52:57.526
just going to double-click here

00:52:57.526 --> 00:52:58.466
to add another track.

00:52:58.466 --> 00:53:00.796
I'm going to choose an arpeggio,

00:53:01.686 --> 00:53:03.296
maybe something like a square.

00:53:06.356 --> 00:53:07.126
There we go.

00:53:07.526 --> 00:53:09.236
I'll do percussive squares here.

00:53:09.316 --> 00:53:10.456
And in the channel strip, you

00:53:10.456 --> 00:53:11.696
can actually see an arpeggiator.

00:53:11.696 --> 00:53:12.646
I'm not going to need that

00:53:12.646 --> 00:53:13.676
because I'm going to play this

00:53:13.676 --> 00:53:14.466
with Feud Machine.

00:53:14.936 --> 00:53:17.596
So, if I record enable this, and

00:53:17.596 --> 00:53:20.276
I arm my sequence here, I'll be

00:53:20.276 --> 00:53:23.096
able to hear Feud Machine play

00:53:23.206 --> 00:53:25.296
the soft synth here in Logic.

00:53:26.026 --> 00:53:29.856
So, I'll solo that.

00:53:29.976 --> 00:53:31.516
This is all four playheads

00:53:31.516 --> 00:53:33.016
moving at the same time.

00:53:33.016 --> 00:53:34.136
I could turn them off.

00:53:34.196 --> 00:53:35.616
I could just have one playhead

00:53:35.616 --> 00:53:37.526
if I wanted to.

00:53:37.606 --> 00:53:39.156
Or as many as all four.

00:53:39.156 --> 00:53:40.636
So, I'm going to record this

00:53:40.636 --> 00:53:42.676
into my track, and we'll see

00:53:42.676 --> 00:53:44.276
what that sounds like in

00:53:44.276 --> 00:53:45.056
context.

00:53:45.596 --> 00:53:52.796
Oops, sorry about that.

00:53:52.796 --> 00:53:55.946
I have to record arm here and

00:53:56.636 --> 00:53:56.866
play.

00:53:57.516 --> 00:54:06.546
[ Music ]

00:54:07.046 --> 00:54:11.286
Okay, so I've recorded my

00:54:11.286 --> 00:54:14.266
automation here, and I can use

00:54:14.266 --> 00:54:15.846
this automation and I can

00:54:16.006 --> 00:54:19.246
playback from the iPad here.

00:54:19.246 --> 00:54:20.096
So, if I listen to this in

00:54:20.096 --> 00:54:21.336
context, it sounds like this.

00:54:21.406 --> 00:54:26.466
So, now I've got MIDI going -- a

00:54:26.466 --> 00:54:28.136
MIDI start command going to Feud

00:54:28.136 --> 00:54:28.576
Machine.

00:54:28.576 --> 00:54:30.136
Feud Machine's playing our soft

00:54:30.136 --> 00:54:30.926
synth here.

00:54:30.996 --> 00:54:32.506
And I've got some automation

00:54:32.506 --> 00:54:34.446
here for the recording.

00:54:34.446 --> 00:54:37.116
And that concludes my demo for

00:54:37.116 --> 00:54:39.546
MIDI over IDAM configuration.

00:54:40.666 --> 00:54:41.886
Let's head back to the slides.

00:54:42.516 --> 00:54:46.216
[ Applause ]

00:54:46.716 --> 00:54:47.736
Okay, we've talked about a lot

00:54:47.736 --> 00:54:48.356
of things today.

00:54:48.356 --> 00:54:49.806
We've talked about enhancements

00:54:49.806 --> 00:54:51.046
to AVAudio Engine, including

00:54:51.046 --> 00:54:52.226
Manual Rendering which you can

00:54:52.226 --> 00:54:53.706
now do offline, or you can do

00:54:53.706 --> 00:54:54.246
real-time.

00:54:54.726 --> 00:54:55.866
There's AirPlay 2 support.

00:54:55.866 --> 00:54:57.096
There'll be an entirely other

00:54:57.096 --> 00:54:58.876
session on AirPlay 2 down the

00:54:58.876 --> 00:55:00.226
road in the conference.

00:55:00.226 --> 00:55:01.306
Please make sure to check that

00:55:01.306 --> 00:55:02.176
out if you're interested.

00:55:02.376 --> 00:55:04.506
Watch OS 4, you can now record.

00:55:04.506 --> 00:55:05.236
We've talked about the

00:55:05.236 --> 00:55:07.036
capabilities and the limitations

00:55:07.036 --> 00:55:08.506
and policies regarding that.

00:55:08.506 --> 00:55:09.956
For AUAudio Units, you can now

00:55:09.956 --> 00:55:10.786
negotiate your view

00:55:10.786 --> 00:55:12.076
configurations and you can also

00:55:12.076 --> 00:55:13.576
synchronize your MIDI output

00:55:13.576 --> 00:55:15.186
with your audio output for your

00:55:15.186 --> 00:55:15.253
AU.

00:55:15.253 --> 00:55:16.396
We've talked about some other

00:55:16.396 --> 00:55:18.996
audio enhancements including new

00:55:18.996 --> 00:55:20.906
supported formats, ambisonics,

00:55:20.906 --> 00:55:22.496
head related transfer functions,

00:55:22.826 --> 00:55:24.136
and we wrapped up with talking

00:55:24.136 --> 00:55:25.816
about IDAM, which now stands for

00:55:25.816 --> 00:55:27.176
Inter Device Audio and MIDI.

00:55:27.746 --> 00:55:29.536
The central URL for information

00:55:29.536 --> 00:55:31.646
regarding this particular talk

00:55:31.646 --> 00:55:32.146
is here.

00:55:32.726 --> 00:55:34.696
And if you're interested in

00:55:34.696 --> 00:55:37.206
audio, you may also be

00:55:37.206 --> 00:55:40.006
interested in these related

00:55:40.006 --> 00:55:41.586
sessions later on in the week.

00:55:42.116 --> 00:55:44.636
We thank you very much for your

00:55:44.636 --> 00:55:45.806
time and attention, and have a

00:55:45.806 --> 00:55:46.976
fantastic conference.

00:55:47.516 --> 00:55:51.500
[ Applause ]