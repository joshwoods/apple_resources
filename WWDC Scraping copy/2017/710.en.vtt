WEBVTT

00:00:27.066 --> 00:00:27.856
>> Good morning, everyone.

00:00:28.616 --> 00:00:30.316
My name is Krishna and I'm from

00:00:30.316 --> 00:00:31.556
the Core ML Engineering team,

00:00:32.026 --> 00:00:33.836
and today we're going to talk

00:00:33.836 --> 00:00:36.286
about Core ML in Depth.

00:00:37.176 --> 00:00:39.046
This year, we introduced Core

00:00:39.096 --> 00:00:39.366
ML.

00:00:39.846 --> 00:00:41.776
It's the easiest way for you to

00:00:41.776 --> 00:00:42.876
integrate machine learning

00:00:42.876 --> 00:00:44.566
models in your applications.

00:00:45.566 --> 00:00:49.266
Core ML is available on macOS,

00:00:49.266 --> 00:00:51.936
iOS, watchOS, and tvOS.

00:00:52.096 --> 00:00:55.786
We had a session on Tuesday that

00:00:55.786 --> 00:00:56.616
introduced Core ML.

00:00:56.616 --> 00:00:58.346
For those of you that missed

00:00:58.346 --> 00:00:59.956
that session, let's just take a

00:00:59.956 --> 00:01:01.726
couple moments to recap some of

00:01:01.726 --> 00:01:02.816
the key things we learned in

00:01:02.816 --> 00:01:03.346
that session.

00:01:04.376 --> 00:01:06.366
Now the first and the most

00:01:06.366 --> 00:01:08.926
important thing about Core ML is

00:01:08.926 --> 00:01:09.976
that you can think of your

00:01:09.976 --> 00:01:11.816
machine learning models just

00:01:11.816 --> 00:01:14.076
like code, and you interact with

00:01:14.076 --> 00:01:16.466
them just like any other Swift

00:01:17.706 --> 00:01:17.876
class.

00:01:18.286 --> 00:01:20.076
Your workflow looks a bit like

00:01:20.076 --> 00:01:20.296
this.

00:01:21.136 --> 00:01:22.056
You start with a machine

00:01:22.056 --> 00:01:24.126
learning model, you drag and

00:01:24.126 --> 00:01:26.896
drop that model into Xcode,

00:01:26.896 --> 00:01:28.086
Xcode will automatically

00:01:28.086 --> 00:01:29.996
generate a Swift or an Objective

00:01:29.996 --> 00:01:31.956
C interface for you to program

00:01:31.956 --> 00:01:32.896
against that model.

00:01:33.726 --> 00:01:35.466
You write your application code,

00:01:35.466 --> 00:01:36.346
you build it.

00:01:37.026 --> 00:01:39.356
Xcode will bundle both the code

00:01:39.356 --> 00:01:40.906
as well as the model in your

00:01:41.696 --> 00:01:41.766
app.

00:01:43.016 --> 00:01:45.036
In that session, we also saw a

00:01:45.036 --> 00:01:46.616
little demo of a flower

00:01:46.616 --> 00:01:47.036
predictor.

00:01:47.826 --> 00:01:49.176
It was an application where

00:01:49.176 --> 00:01:51.126
given a picture, let's say this

00:01:51.126 --> 00:01:53.286
pink rose, the application is

00:01:53.326 --> 00:01:54.586
supposed to tell you what kind

00:01:54.586 --> 00:01:55.886
of a flower it was and how

00:01:55.886 --> 00:01:56.956
confident it was.

00:01:58.526 --> 00:02:00.586
We saw that in order to use that

00:02:00.586 --> 00:02:02.026
or build that application, it

00:02:02.026 --> 00:02:03.426
just took a few lines of code.

00:02:04.126 --> 00:02:06.156
One line of code to instantiate

00:02:06.156 --> 00:02:08.346
the model, and one line of code

00:02:08.586 --> 00:02:10.606
to make a prediction from that

00:02:11.536 --> 00:02:11.706
model.

00:02:11.836 --> 00:02:13.426
So in this session, we're going

00:02:13.426 --> 00:02:14.386
to pick up from where we left

00:02:14.386 --> 00:02:15.786
off and we're going to talk a

00:02:15.786 --> 00:02:16.656
little bit more about the

00:02:16.656 --> 00:02:17.996
different kinds of use cases,

00:02:17.996 --> 00:02:19.296
all the cool stuff you guys can

00:02:19.296 --> 00:02:20.046
do with Core ML.

00:02:20.726 --> 00:02:22.986
We're then going to talk about

00:02:22.986 --> 00:02:25.086
how Core ML is optimized for the

00:02:25.086 --> 00:02:26.736
hardware on which it runs for or

00:02:26.736 --> 00:02:28.596
runs on, and what that means for

00:02:28.596 --> 00:02:30.336
you as a developer.

00:02:30.996 --> 00:02:32.546
Finally, we're going to talk

00:02:32.546 --> 00:02:34.106
about how you can obtain Core ML

00:02:34.106 --> 00:02:35.456
models for use in all your

00:02:35.456 --> 00:02:36.056
applications.

00:02:36.256 --> 00:02:38.036
So it's going to be a fun

00:02:38.086 --> 00:02:39.386
session with a couple demos,

00:02:39.906 --> 00:02:40.676
let's get started.

00:02:41.826 --> 00:02:43.556
So you've already seen an

00:02:43.556 --> 00:02:45.196
example of an app that used

00:02:45.196 --> 00:02:46.656
images, the flower predictor.

00:02:47.296 --> 00:02:48.426
But with Core ML you can do a

00:02:48.426 --> 00:02:49.836
lot more than just images.

00:02:50.636 --> 00:02:52.106
You can work with gestures,

00:02:52.456 --> 00:02:53.966
let's say handwriting detection

00:02:53.966 --> 00:02:54.586
on the watch.

00:02:55.766 --> 00:02:57.176
You can work with video, let's

00:02:57.176 --> 00:02:58.186
say you want to do credit card

00:02:58.186 --> 00:02:58.606
detection.

00:02:59.876 --> 00:03:02.346
You can work with audio, and you

00:03:02.346 --> 00:03:04.016
can even work with text.

00:03:05.366 --> 00:03:07.086
Now by taking inputs of all of

00:03:07.086 --> 00:03:08.806
these different types, you can

00:03:08.806 --> 00:03:10.136
build a large variety of

00:03:10.136 --> 00:03:10.876
applications.

00:03:12.306 --> 00:03:13.456
Let's say you want to build an

00:03:13.456 --> 00:03:14.786
application that as you type

00:03:14.786 --> 00:03:16.756
some text it tells you if it's a

00:03:16.756 --> 00:03:19.116
happy text or a sad text or a

00:03:19.116 --> 00:03:20.426
passive aggressive text or

00:03:20.426 --> 00:03:21.106
angry.

00:03:22.206 --> 00:03:23.246
You can do that with Sentiment

00:03:23.246 --> 00:03:25.186
Analysis, and we'll see a little

00:03:25.376 --> 00:03:27.536
demo of that today.

00:03:27.706 --> 00:03:29.026
You can -- with Style Transfer

00:03:29.026 --> 00:03:30.366
you can even make pictures of

00:03:30.366 --> 00:03:31.756
your family look like Vincent

00:03:31.756 --> 00:03:32.556
Van Gogh paintings.

00:03:34.086 --> 00:03:35.396
And with Gesture Recognition,

00:03:35.656 --> 00:03:37.216
you can have a whole new way to

00:03:37.216 --> 00:03:38.056
take inputs to your

00:03:38.056 --> 00:03:38.746
applications.

00:03:39.626 --> 00:03:41.306
Now all of these are amazing

00:03:41.306 --> 00:03:43.566
possibilities because with Core

00:03:43.566 --> 00:03:45.936
ML you can use a large variety

00:03:45.936 --> 00:03:46.556
of models.

00:03:47.656 --> 00:03:49.116
You can use Classical Machine

00:03:49.116 --> 00:03:50.616
Learning Models like Generalized

00:03:50.616 --> 00:03:52.116
Linear Models, Trees, and

00:03:52.176 --> 00:03:53.176
Support Vector Machines.

00:03:53.896 --> 00:03:55.626
Now these ones are great because

00:03:55.686 --> 00:03:57.656
they are small, you can make

00:03:57.656 --> 00:03:58.996
fast predictions with them and

00:03:58.996 --> 00:03:59.906
they are on any device.

00:04:00.936 --> 00:04:03.116
But you can also work with a

00:04:03.116 --> 00:04:04.796
large variety of Neural

00:04:05.196 --> 00:04:05.576
Networks.

00:04:05.576 --> 00:04:07.166
We have support for over 30

00:04:07.166 --> 00:04:08.586
different layer types and that's

00:04:08.776 --> 00:04:09.186
huge.

00:04:09.986 --> 00:04:10.946
You can do things like

00:04:10.946 --> 00:04:12.296
Feedforward and Convolution

00:04:12.296 --> 00:04:13.516
Linear Networks for all your

00:04:13.516 --> 00:04:14.616
image and video-based

00:04:14.616 --> 00:04:16.606
applications, and you can also

00:04:16.606 --> 00:04:17.916
do things like Recurrent Neural

00:04:17.916 --> 00:04:19.606
Networks or LSDMs for all of

00:04:19.606 --> 00:04:21.106
your text-based applications.

00:04:22.016 --> 00:04:23.526
We'll take a look at Recurrent

00:04:23.526 --> 00:04:24.946
Neural Networks in today's

00:04:25.666 --> 00:04:25.986
session.

00:04:26.636 --> 00:04:29.386
In fact, with Core ML you can

00:04:29.386 --> 00:04:31.016
also combine models of various

00:04:31.016 --> 00:04:31.696
different types.

00:04:31.696 --> 00:04:33.646
So you can take, let's say, a

00:04:33.646 --> 00:04:35.056
Neural Network and combine it

00:04:35.056 --> 00:04:37.126
with a Tree and then you can get

00:04:37.126 --> 00:04:38.276
one big model with that.

00:04:38.616 --> 00:04:39.816
So this concept is called a

00:04:39.816 --> 00:04:40.366
Pipeline.

00:04:40.786 --> 00:04:44.706
But most importantly for you as

00:04:44.706 --> 00:04:46.166
a developer, we want you to

00:04:46.166 --> 00:04:47.636
focus on the code that you're

00:04:47.636 --> 00:04:49.306
writing in your apps and not on

00:04:49.306 --> 00:04:50.796
the specific complexities of the

00:04:50.796 --> 00:04:51.826
model that's running there.

00:04:52.426 --> 00:04:55.996
And we achieve that by giving

00:04:55.996 --> 00:04:57.596
you a functional abstraction

00:04:57.596 --> 00:04:58.236
viewer models.

00:04:58.786 --> 00:05:00.446
So all you need to care is your

00:05:00.446 --> 00:05:02.296
models are prediction functions

00:05:02.296 --> 00:05:04.326
that take in some inputs and

00:05:04.326 --> 00:05:05.286
give out some outputs.

00:05:06.186 --> 00:05:08.256
And these inputs and outputs can

00:05:08.256 --> 00:05:09.716
be of five different types;

00:05:10.406 --> 00:05:13.726
numeric, categorical, images,

00:05:14.376 --> 00:05:16.076
arrays, and dictionaries.

00:05:17.476 --> 00:05:19.086
Now let's just take a little

00:05:19.086 --> 00:05:20.086
look at each of these five

00:05:20.136 --> 00:05:21.616
different types.

00:05:22.136 --> 00:05:23.986
So numerics and categories are

00:05:23.986 --> 00:05:25.956
exposed to you in Swift as

00:05:26.056 --> 00:05:28.106
doubles, integers or strings.

00:05:28.106 --> 00:05:29.126
So it's very natural.

00:05:30.036 --> 00:05:31.896
We have a little example of an

00:05:31.896 --> 00:05:33.306
application that uses these two

00:05:33.306 --> 00:05:35.026
types on developer.apple.com.

00:05:35.556 --> 00:05:37.096
It's an application that does

00:05:37.096 --> 00:05:38.086
house price prediction.

00:05:38.996 --> 00:05:40.156
So some of the inputs to this

00:05:40.156 --> 00:05:41.936
model are numeric, that is

00:05:41.936 --> 00:05:43.166
they're continuous so you can go

00:05:43.166 --> 00:05:44.706
from zero to infinity.

00:05:45.606 --> 00:05:47.686
And some of them are categorical

00:05:47.806 --> 00:05:50.196
or discrete, so you go zero, 1,

00:05:50.246 --> 00:05:52.936
2, 3, 4.

00:05:53.146 --> 00:05:54.566
You've already seen an example

00:05:54.566 --> 00:05:55.376
of using images.

00:05:55.946 --> 00:05:57.226
Now these images are exposed to

00:05:57.226 --> 00:05:58.876
you as CVPixelBuffers.

00:05:59.666 --> 00:06:02.786
For the more complex things like

00:06:02.856 --> 00:06:04.456
gestures, audio and video, we

00:06:04.456 --> 00:06:06.286
have a new type called

00:06:06.286 --> 00:06:08.926
MLMultiArray to encapsulate a

00:06:08.926 --> 00:06:10.126
multidimensional array.

00:06:10.666 --> 00:06:13.356
And for a lot of your text-based

00:06:13.356 --> 00:06:14.796
applications, you'll be

00:06:14.796 --> 00:06:16.136
interacting with dictionaries.

00:06:16.866 --> 00:06:17.756
Here are the dictionaries.

00:06:17.756 --> 00:06:19.166
The keys are either strings or

00:06:19.166 --> 00:06:21.096
integers, and the values are

00:06:21.156 --> 00:06:21.486
doubles.

00:06:22.746 --> 00:06:24.536
Let's take a little look at

00:06:24.536 --> 00:06:26.136
using Text and working with

00:06:26.136 --> 00:06:26.646
Dictionaries.

00:06:27.326 --> 00:06:30.656
And we're going to do that with

00:06:30.656 --> 00:06:32.446
an application of Sentiment

00:06:32.446 --> 00:06:32.946
Analysis.

00:06:33.886 --> 00:06:35.206
Now I've always wanted this app

00:06:35.246 --> 00:06:36.966
where if I type some text I want

00:06:36.966 --> 00:06:38.686
the UI to pop and reflect the

00:06:38.686 --> 00:06:39.496
mood that I'm in.

00:06:40.006 --> 00:06:42.086
So if I say Core ML is awesome!

00:06:42.086 --> 00:06:42.926
I love using it!

00:06:43.136 --> 00:06:44.286
I want it to go green and I

00:06:44.286 --> 00:06:47.226
want, like, a happy face.

00:06:47.226 --> 00:06:49.006
And if I talk to you about, say,

00:06:49.006 --> 00:06:49.936
how bad the lunch was.

00:06:49.936 --> 00:06:50.936
Like, today's lunch was

00:06:50.936 --> 00:06:52.036
disappointing and sad.

00:06:52.036 --> 00:06:52.776
I want it to go red.

00:06:52.776 --> 00:06:55.586
So that's what I want to do.

00:06:55.916 --> 00:06:57.916
So what does it take to build an

00:06:57.916 --> 00:06:58.896
application like this?

00:06:59.466 --> 00:07:00.486
So I'm going to start with an

00:07:00.486 --> 00:07:02.456
app shell where the user can

00:07:02.456 --> 00:07:03.226
type in some text.

00:07:04.676 --> 00:07:05.986
As soon as the user hits the

00:07:05.986 --> 00:07:07.656
space bar, I'm going to take all

00:07:07.656 --> 00:07:09.326
of that text, give it to a

00:07:09.326 --> 00:07:11.086
machine learning model, and get

00:07:11.086 --> 00:07:12.516
back a sentiment prediction.

00:07:13.616 --> 00:07:14.776
So the sentiment prediction is

00:07:14.776 --> 00:07:16.316
either going to be happy,

00:07:16.316 --> 00:07:17.436
neutral or sad.

00:07:18.526 --> 00:07:19.726
As soon as I get back this

00:07:19.776 --> 00:07:21.136
prediction, I'm going to go back

00:07:21.136 --> 00:07:23.506
and quickly update the UI to

00:07:23.506 --> 00:07:24.496
reflect the mode I'm in.

00:07:25.666 --> 00:07:26.936
The most important thing for you

00:07:26.936 --> 00:07:28.426
to note is all of this can

00:07:28.426 --> 00:07:30.626
happen real time on the device

00:07:30.626 --> 00:07:32.526
as the user is typing, so it

00:07:32.526 --> 00:07:34.156
makes for an amazing experience.

00:07:34.766 --> 00:07:37.466
So let's see how you can go

00:07:37.466 --> 00:07:38.496
ahead and build that app.

00:07:39.316 --> 00:07:40.436
Well, the most important thing

00:07:40.436 --> 00:07:42.796
here is the model, and for this

00:07:42.796 --> 00:07:43.836
we're going to use a Sentiment

00:07:43.836 --> 00:07:44.576
Analysis model.

00:07:45.276 --> 00:07:46.206
But for this sent Sentiment

00:07:46.206 --> 00:07:47.286
Analysis model is going to

00:07:47.286 --> 00:07:49.406
operate on word counts not on

00:07:49.406 --> 00:07:50.846
the raw text, but on word

00:07:50.846 --> 00:07:51.346
counts.

00:07:52.066 --> 00:07:53.366
So these word counts will be

00:07:53.366 --> 00:07:54.906
represented as dictionaries

00:07:55.876 --> 00:07:57.966
where the keys are the words and

00:07:57.966 --> 00:07:59.326
the values are the number of

00:07:59.326 --> 00:08:00.606
times that word appears in a

00:08:00.646 --> 00:08:01.006
sentence.

00:08:01.796 --> 00:08:03.446
So Core ML is awesome.

00:08:03.446 --> 00:08:04.276
I love using it.

00:08:04.276 --> 00:08:05.656
Translates to a dictionary that

00:08:05.656 --> 00:08:06.466
looks a bit like this.

00:08:07.816 --> 00:08:09.376
So once I have my Word Counts I

00:08:09.466 --> 00:08:10.856
can pass that to my Sentiment

00:08:10.856 --> 00:08:12.796
Analysis model and I can get

00:08:12.796 --> 00:08:13.446
back a prediction.

00:08:13.976 --> 00:08:16.356
In this case it's "happy".

00:08:16.556 --> 00:08:17.756
But you might wonder, okay, how

00:08:17.756 --> 00:08:19.346
do I go for my raw text to word

00:08:19.346 --> 00:08:19.786
count.

00:08:20.486 --> 00:08:21.616
Well, you might have already

00:08:21.616 --> 00:08:23.336
seen the session on NLP, but you

00:08:23.416 --> 00:08:25.356
can use the already existing

00:08:25.356 --> 00:08:27.646
tools in the NSLinguisticTagger

00:08:27.776 --> 00:08:29.366
to tokenize and count number of

00:08:29.366 --> 00:08:29.696
words.

00:08:30.196 --> 00:08:32.856
So I'll use NLP to preprocess my

00:08:32.856 --> 00:08:34.265
texts, specifically the

00:08:34.265 --> 00:08:36.186
NSLinguisticTagger, and then I'm

00:08:36.186 --> 00:08:37.496
going to get my word counts

00:08:37.946 --> 00:08:39.326
which I'll then give to a model

00:08:39.696 --> 00:08:40.726
and get a prediction out of it.

00:08:41.836 --> 00:08:43.306
So with that, you can build an

00:08:43.306 --> 00:08:44.236
application like this.

00:08:44.766 --> 00:08:46.236
But let's not just talk about

00:08:46.236 --> 00:08:47.196
it, let's go ahead and do it.

00:08:48.376 --> 00:08:51.986
So I'm going to walk over and

00:08:51.986 --> 00:08:56.906
open up Xcode.

00:08:57.036 --> 00:08:59.426
So what I have here is Xcode and

00:08:59.426 --> 00:09:00.036
a simulator.

00:09:00.736 --> 00:09:02.186
The simulator is now running an

00:09:02.186 --> 00:09:02.626
app shell.

00:09:03.146 --> 00:09:04.106
The app shell doesn't have the

00:09:04.106 --> 00:09:05.306
model in there, so if I type

00:09:05.306 --> 00:09:07.806
something, let's say, Core ML is

00:09:09.036 --> 00:09:11.826
amazing, amazing fun, nothing

00:09:11.826 --> 00:09:13.266
really happens to the UI.

00:09:13.806 --> 00:09:14.946
So what we're going to do right

00:09:14.946 --> 00:09:16.376
now is we're going to go ahead

00:09:16.376 --> 00:09:17.416
and incorporate the machine

00:09:17.416 --> 00:09:19.216
learning model in here so that

00:09:19.216 --> 00:09:20.526
this app is going to become much

00:09:20.526 --> 00:09:21.216
more vibrant.

00:09:21.216 --> 00:09:24.296
So the first thing I'm going to

00:09:24.296 --> 00:09:27.716
do is open up Finder and drag

00:09:27.716 --> 00:09:29.286
the Sentiment Analysis model

00:09:29.526 --> 00:09:30.246
into Xcode.

00:09:30.786 --> 00:09:33.726
Let's go take a look at what

00:09:33.726 --> 00:09:34.346
this model is.

00:09:35.276 --> 00:09:38.246
So as you can see, this is a

00:09:38.246 --> 00:09:39.486
Sentiment Analysis model.

00:09:40.206 --> 00:09:41.256
The type of this model is a

00:09:41.256 --> 00:09:43.026
Pipeline Classifier, so it does

00:09:43.026 --> 00:09:44.206
a couple different things before

00:09:44.206 --> 00:09:45.326
it gives the final prediction.

00:09:46.686 --> 00:09:49.136
It's only 167 kilobytes, so it's

00:09:49.136 --> 00:09:49.876
pretty tiny.

00:09:51.256 --> 00:09:53.456
And the inputs to this model are

00:09:53.456 --> 00:09:55.356
word counts, and the word counts

00:09:55.456 --> 00:09:58.476
are dictionaries where the key

00:09:58.476 --> 00:09:59.576
is the word and the value is the

00:09:59.576 --> 00:10:00.796
number of time that word

00:10:00.796 --> 00:10:01.186
appeared.

00:10:01.916 --> 00:10:03.206
And I get two outputs from this

00:10:03.206 --> 00:10:05.556
model, a Sentiment Label, that's

00:10:05.556 --> 00:10:06.366
one of two things.

00:10:06.616 --> 00:10:08.676
It's either good or bad.

00:10:08.676 --> 00:10:11.546
And a Sentiment Score, which is

00:10:11.546 --> 00:10:13.696
a probability associated with

00:10:13.696 --> 00:10:15.326
the good sentiment or the bad

00:10:15.326 --> 00:10:15.716
sentiment.

00:10:16.756 --> 00:10:17.656
So that's a dictionary.

00:10:18.346 --> 00:10:19.646
So what I'm going to use in this

00:10:19.646 --> 00:10:20.926
application is I'm going to use

00:10:20.926 --> 00:10:23.146
the Sentiment Score to determine

00:10:23.416 --> 00:10:25.306
within a range of zero to 1 how

00:10:25.306 --> 00:10:26.866
nice this text was, and that's

00:10:26.866 --> 00:10:27.936
what I'm going to be using to

00:10:27.936 --> 00:10:29.426
update my UI.

00:10:30.716 --> 00:10:32.846
So let me go ahead and include

00:10:33.196 --> 00:10:34.786
this model in the target of my

00:10:34.786 --> 00:10:37.766
application, and then Xcode will

00:10:37.766 --> 00:10:39.066
automatically generate a nice

00:10:39.066 --> 00:10:39.956
interface for me.

00:10:40.616 --> 00:10:41.706
So I can go back to my

00:10:41.706 --> 00:10:43.466
ViewController and now I'm going

00:10:43.466 --> 00:10:44.536
to implement the logic to

00:10:44.896 --> 00:10:45.996
incorporate this Machine

00:10:45.996 --> 00:10:46.866
Learning Model in there.

00:10:47.566 --> 00:10:48.566
So for that, I'm going to

00:10:48.566 --> 00:10:50.236
implement this function, predict

00:10:50.236 --> 00:10:51.886
SentimentScoreFromRawText.

00:10:52.236 --> 00:10:53.456
So this function is going to

00:10:53.456 --> 00:10:54.666
take a sentence which is the

00:10:54.666 --> 00:10:55.816
entire string.

00:10:56.526 --> 00:10:57.816
It gets called every time the

00:10:57.816 --> 00:11:00.006
user types a space, and what it

00:11:00.006 --> 00:11:01.446
returns is a double value

00:11:01.786 --> 00:11:03.406
between zero and 1, where zero

00:11:03.406 --> 00:11:05.216
is really, really sad and 1 is

00:11:05.216 --> 00:11:05.986
really, really happy.

00:11:07.906 --> 00:11:09.086
So the first thing I want to do

00:11:09.086 --> 00:11:10.256
is I'm going to instantiate this

00:11:10.256 --> 00:11:11.746
model, and I can simply do that

00:11:11.746 --> 00:11:13.236
by saying let model =

00:11:13.286 --> 00:11:14.286
SentimentAnalysis.

00:11:15.376 --> 00:11:16.956
And then I'm going to predict

00:11:16.956 --> 00:11:19.156
use this model to make this

00:11:19.186 --> 00:11:19.656
prediction.

00:11:19.976 --> 00:11:21.076
But as you can see, the input

00:11:21.076 --> 00:11:22.676
here is a sentence but what I

00:11:22.676 --> 00:11:24.116
really want is a word count.

00:11:24.996 --> 00:11:26.146
So I've already implemented this

00:11:26.146 --> 00:11:26.896
function called

00:11:26.896 --> 00:11:28.106
tokenizeAndCountWords.

00:11:28.546 --> 00:11:29.536
This function uses the

00:11:29.536 --> 00:11:31.176
NSLinguisticTagger to tokenize

00:11:31.176 --> 00:11:32.256
the sentence and then count the

00:11:32.256 --> 00:11:33.876
number of tokens in that

00:11:33.876 --> 00:11:34.296
sentence.

00:11:34.636 --> 00:11:35.696
So I'm going to skip over that

00:11:35.696 --> 00:11:38.546
and I'm just going to call that

00:11:38.546 --> 00:11:38.996
function.

00:11:38.996 --> 00:11:39.856
So I'm going to say let

00:11:39.856 --> 00:11:41.486
WordCounts =

00:11:41.776 --> 00:11:43.786
tokenizeAndCountWords sentence.

00:11:44.896 --> 00:11:46.036
And then I'm going to use this

00:11:46.036 --> 00:11:47.316
word count and provide that to

00:11:47.316 --> 00:11:47.776
my model.

00:11:47.776 --> 00:11:49.686
So I'm going to say if let

00:11:49.686 --> 00:11:52.116
prediction = try

00:11:52.116 --> 00:11:54.166
model.prediction(wordCounts),

00:11:54.736 --> 00:11:56.246
and simply pass that wordCount

00:11:56.246 --> 00:11:56.526
there.

00:11:57.456 --> 00:11:59.116
And if this succeeds, I'm going

00:11:59.116 --> 00:12:01.456
to use the prediction object to

00:12:01.456 --> 00:12:03.186
get out the sentiment score, but

00:12:03.186 --> 00:12:04.466
because I want a value between

00:12:04.466 --> 00:12:05.646
zero and 1 I'm going to get the

00:12:05.646 --> 00:12:06.666
score and not the label.

00:12:07.176 --> 00:12:08.406
So I'll take the sentiment score

00:12:08.406 --> 00:12:09.726
associated with the sentiment

00:12:09.726 --> 00:12:11.286
"good" and I'll return that to

00:12:11.286 --> 00:12:11.666
my UI.

00:12:11.666 --> 00:12:13.606
And if this fails, by any

00:12:13.606 --> 00:12:14.766
chance, I'm going to go down

00:12:14.766 --> 00:12:15.446
0.5.

00:12:15.636 --> 00:12:16.486
So I have a little error

00:12:16.486 --> 00:12:19.636
handling here as well.

00:12:19.836 --> 00:12:20.986
So I'm going to go ahead and

00:12:20.986 --> 00:12:21.926
build that application.

00:12:22.326 --> 00:12:23.846
So during this process, as you

00:12:23.846 --> 00:12:25.196
might be aware, the model and

00:12:25.196 --> 00:12:26.626
the code are both getting

00:12:26.626 --> 00:12:28.536
packaged and getting shipped to

00:12:28.536 --> 00:12:29.116
the device.

00:12:29.776 --> 00:12:31.516
Another thing to note is that

00:12:31.516 --> 00:12:33.236
the compiler, the Core ML

00:12:33.236 --> 00:12:35.346
compiler gets shipped as part of

00:12:35.346 --> 00:12:36.376
the Xcode pool chain.

00:12:36.546 --> 00:12:37.646
So if you want to compile them

00:12:37.646 --> 00:12:38.876
all or run the code generator

00:12:38.876 --> 00:12:40.306
yourself, you can use the

00:12:40.306 --> 00:12:41.046
compiler directly.

00:12:42.616 --> 00:12:44.826
So now let's go use this app and

00:12:44.826 --> 00:12:45.836
let's type something nice.

00:12:46.716 --> 00:12:49.466
Let's type "Core ML is amazing

00:12:49.506 --> 00:12:49.706
fun."

00:12:49.706 --> 00:12:50.356
That's what I want to write.

00:12:51.186 --> 00:12:53.606
"Core ML is amazing fun and I

00:12:53.606 --> 00:12:54.546
love using it."

00:12:55.546 --> 00:12:56.846
So immediately you saw the UI

00:12:56.916 --> 00:12:58.236
popped and I got a little green

00:12:58.236 --> 00:12:59.486
and I'm happy and, you know,

00:12:59.636 --> 00:13:00.156
this is great.

00:13:01.516 --> 00:13:03.706
[ Applause ]

00:13:04.206 --> 00:13:05.846
But now I want to type something

00:13:05.846 --> 00:13:07.356
bad, but I don't really want to

00:13:07.356 --> 00:13:08.526
make fun of anything or anyone

00:13:08.526 --> 00:13:09.606
so I want to talk about how my

00:13:09.606 --> 00:13:11.186
life is terrible without CoreML.

00:13:12.516 --> 00:13:15.356
"Life without CoreML is sloppy,

00:13:16.516 --> 00:13:19.896
terrible and sad."

00:13:20.806 --> 00:13:22.396
So obviously the UI is really

00:13:22.476 --> 00:13:23.716
sad because, you know, life

00:13:23.716 --> 00:13:25.106
without Core ML is really sad.

00:13:26.046 --> 00:13:27.746
So what we really saw was a

00:13:27.916 --> 00:13:30.486
seamless integration between NLP

00:13:30.486 --> 00:13:32.056
and Core ML, so I built this

00:13:32.056 --> 00:13:33.586
Sentiment Analysis Model and I

00:13:33.586 --> 00:13:35.256
was able to make my application

00:13:35.256 --> 00:13:36.506
a lot more vibrant.

00:13:36.626 --> 00:13:38.256
And all of this was happening in

00:13:38.256 --> 00:13:39.976
real time on the device as the

00:13:39.976 --> 00:13:40.696
user typed it.

00:13:42.076 --> 00:13:45.996
So that was pretty cool.

00:13:46.196 --> 00:13:48.256
Let's go recap the two main

00:13:48.256 --> 00:13:49.296
things that we talked about in

00:13:49.296 --> 00:13:49.716
this demo.

00:13:50.446 --> 00:13:52.196
So the first thing was that the

00:13:52.196 --> 00:13:54.136
preprocess text we use the

00:13:54.136 --> 00:13:55.046
NSLinguisticTagger.

00:13:55.516 --> 00:13:58.586
The second thing was that once I

00:13:58.586 --> 00:14:00.106
got those word counts I could

00:14:00.106 --> 00:14:01.546
then give it to a model and get

00:14:01.546 --> 00:14:03.536
a prediction out of it.

00:14:03.846 --> 00:14:05.126
And this is a pattern you're

00:14:05.126 --> 00:14:06.886
going to encounter a lot with

00:14:06.886 --> 00:14:08.756
text based applications because

00:14:08.756 --> 00:14:11.066
most text space applications do

00:14:11.066 --> 00:14:13.106
not work directly on raw text.

00:14:13.666 --> 00:14:15.836
There's always a little bit of

00:14:15.836 --> 00:14:16.946
preprocessing that you have to

00:14:16.946 --> 00:14:17.396
do for it.

00:14:17.966 --> 00:14:20.616
But that was really a simple

00:14:20.616 --> 00:14:21.126
example.

00:14:21.126 --> 00:14:22.436
It was an introductory example.

00:14:22.966 --> 00:14:24.276
Let's step our game, let's get

00:14:24.276 --> 00:14:24.966
to the next level.

00:14:25.666 --> 00:14:26.726
Let's talk about something

00:14:26.726 --> 00:14:28.296
you've all interacted with on a

00:14:28.296 --> 00:14:29.246
daily basis.

00:14:29.916 --> 00:14:31.506
This is the Apple keyboard.

00:14:32.496 --> 00:14:33.916
Now, when you type words in the

00:14:33.916 --> 00:14:35.526
Apple keyboard, as you might all

00:14:35.526 --> 00:14:36.866
be aware, you get very

00:14:36.866 --> 00:14:38.816
contextual predictions of what's

00:14:38.876 --> 00:14:40.336
the next most likely word you're

00:14:40.336 --> 00:14:40.726
going to type.

00:14:41.416 --> 00:14:43.176
So if I say, "I'm not sure if

00:14:43.176 --> 00:14:45.876
Oliver will eat oysters, but he

00:14:45.876 --> 00:14:46.526
will."

00:14:46.666 --> 00:14:48.216
They keyboard tells you "so",

00:14:48.216 --> 00:14:50.066
"totally" and "love" are three

00:14:50.066 --> 00:14:52.196
likely words you're going to

00:14:52.776 --> 00:14:53.166
type next.

00:14:53.166 --> 00:14:54.766
So how do you go about building

00:14:54.766 --> 00:14:56.166
something as sophisticated as

00:14:56.166 --> 00:14:56.416
this?

00:14:57.256 --> 00:14:58.416
So this is a predictive

00:14:58.416 --> 00:15:00.356
keyboard, and the machine

00:15:00.356 --> 00:15:02.856
learning task here is to make a

00:15:02.856 --> 00:15:05.106
prediction for the next word.

00:15:05.816 --> 00:15:07.706
The model that's being used here

00:15:07.786 --> 00:15:08.986
or the model that will be used

00:15:08.986 --> 00:15:11.046
in an application like this is

00:15:11.486 --> 00:15:13.116
usually a model that takes the

00:15:13.246 --> 00:15:14.146
sequence of words.

00:15:14.386 --> 00:15:16.316
So "I'm not sure Oliver will eat

00:15:16.316 --> 00:15:17.536
oysters, but he will."

00:15:17.536 --> 00:15:18.746
is a sequence of words.

00:15:18.746 --> 00:15:20.586
I give that as input to the

00:15:20.586 --> 00:15:22.046
model and I get a prediction.

00:15:23.186 --> 00:15:24.616
So you might wonder, okay,

00:15:24.616 --> 00:15:26.426
what's the difference between

00:15:26.426 --> 00:15:28.046
this model that we just saw and

00:15:28.046 --> 00:15:29.136
the Sentiment Analysis one?

00:15:29.136 --> 00:15:30.556
They look the same to me.

00:15:31.496 --> 00:15:34.266
The key difference is that here

00:15:34.336 --> 00:15:35.926
the input is a sequence of

00:15:35.926 --> 00:15:36.236
words.

00:15:36.866 --> 00:15:38.546
So if you jumble up the words

00:15:38.546 --> 00:15:39.946
and give it to the model you're

00:15:39.946 --> 00:15:41.066
going to get a completely

00:15:41.066 --> 00:15:41.766
different prediction.

00:15:43.536 --> 00:15:44.876
And to do something like this,

00:15:44.876 --> 00:15:46.246
most machine learning models

00:15:46.446 --> 00:15:48.166
will have a notion of state

00:15:48.166 --> 00:15:50.086
that's associated with them, and

00:15:50.086 --> 00:15:50.996
that's how they get this

00:15:50.996 --> 00:15:51.456
behavior.

00:15:52.166 --> 00:15:54.186
And the state gets passed along

00:15:54.416 --> 00:15:55.766
as every prediction is made.

00:15:56.246 --> 00:15:58.136
So it's like a baton in a relay

00:15:58.136 --> 00:15:58.406
race.

00:15:58.626 --> 00:15:59.246
Every time you make a

00:15:59.246 --> 00:16:00.656
prediction, take the state and

00:16:00.656 --> 00:16:02.906
pass it along.

00:16:03.056 --> 00:16:04.416
We're going to do something like

00:16:04.416 --> 00:16:06.616
this using an LSDM, usually.

00:16:06.886 --> 00:16:08.546
Specifically, like a [inaudible]

00:16:08.546 --> 00:16:09.256
network.

00:16:09.696 --> 00:16:11.056
But with Core ML, all of this is

00:16:11.056 --> 00:16:12.026
going to be a lot easier.

00:16:12.606 --> 00:16:13.766
So, let's take a look at what

00:16:13.766 --> 00:16:16.056
you do but we'll do it with a

00:16:16.056 --> 00:16:17.356
little more fun application.

00:16:17.736 --> 00:16:18.756
We'll do it with a Shakespeare

00:16:18.756 --> 00:16:19.136
Keyboard.

00:16:19.786 --> 00:16:20.706
So instead of a regular

00:16:20.706 --> 00:16:22.376
keyboard, this keyboard is going

00:16:22.376 --> 00:16:23.066
to make me sound like

00:16:23.066 --> 00:16:23.476
Shakespeare.

00:16:24.176 --> 00:16:26.336
So if I say, "Shall I compare?"

00:16:26.656 --> 00:16:28.216
It should say "thee", "summers",

00:16:28.216 --> 00:16:29.316
"day" are the next three words

00:16:29.316 --> 00:16:31.846
I'm likely to type.

00:16:32.026 --> 00:16:33.626
So, what's really the difference

00:16:33.626 --> 00:16:35.256
between the Shakespeare Keyboard

00:16:35.256 --> 00:16:36.466
and the regular keyboard?

00:16:36.466 --> 00:16:38.716
It's really the model that's

00:16:38.766 --> 00:16:39.976
predicting the next word.

00:16:40.506 --> 00:16:42.076
So one of those models is

00:16:42.136 --> 00:16:43.636
trained on Shakespeare data and

00:16:44.126 --> 00:16:45.936
another one is just trained on

00:16:45.936 --> 00:16:47.046
regular English data.

00:16:47.956 --> 00:16:49.386
So this concept is the Language

00:16:49.386 --> 00:16:49.686
Model.

00:16:50.576 --> 00:16:52.316
So I just threw so many new

00:16:52.316 --> 00:16:53.536
concepts at you, a Language

00:16:53.536 --> 00:16:54.856
Model, Sequences, LSDM, but

00:16:54.856 --> 00:16:57.196
don't worry, with Core ML this

00:16:57.196 --> 00:16:58.256
should be a lot easier.

00:16:58.796 --> 00:16:59.616
Let's see how you would do

00:16:59.616 --> 00:17:00.236
something like this.

00:17:01.406 --> 00:17:04.096
So I start with a model and I'm

00:17:04.096 --> 00:17:05.476
going to give it the first word,

00:17:05.476 --> 00:17:07.185
let's say in this case, "Shall".

00:17:08.266 --> 00:17:09.606
That's the current word.

00:17:10.596 --> 00:17:12.236
And what I'll get back from the

00:17:12.236 --> 00:17:13.526
model are two things.

00:17:14.646 --> 00:17:16.236
A set of choices for the next

00:17:16.236 --> 00:17:16.526
word.

00:17:16.826 --> 00:17:19.316
So in this case I get basically

00:17:19.316 --> 00:17:20.726
a probability associated with

00:17:20.726 --> 00:17:23.266
all the set of next words, and

00:17:23.776 --> 00:17:25.415
I'm also going to get a state

00:17:25.715 --> 00:17:27.256
associated with this prediction.

00:17:28.616 --> 00:17:29.986
So I'll take these next word

00:17:29.986 --> 00:17:31.596
choices and I'll give them to

00:17:31.596 --> 00:17:32.016
the user.

00:17:32.016 --> 00:17:34.376
The user will either select one

00:17:34.376 --> 00:17:35.816
of those three words or maybe

00:17:35.816 --> 00:17:37.176
they'll type their own word.

00:17:37.176 --> 00:17:38.916
Either way I get a next word.

00:17:40.336 --> 00:17:41.906
I'll use that next word, pass it

00:17:41.906 --> 00:17:42.976
back to the model for the next

00:17:42.976 --> 00:17:44.786
prediction, and I'm also going

00:17:44.786 --> 00:17:46.106
to take the state, pass it back

00:17:46.106 --> 00:17:47.016
to the model for the next

00:17:47.016 --> 00:17:47.386
prediction.

00:17:48.406 --> 00:17:50.226
So in steady state every time

00:17:50.226 --> 00:17:51.166
you're going to do two things.

00:17:51.646 --> 00:17:52.576
You're going to take the current

00:17:52.576 --> 00:17:53.846
word in the state and give it to

00:17:53.846 --> 00:17:55.536
the model, and what you'll get

00:17:55.536 --> 00:17:57.026
back are the set of choices for

00:17:57.026 --> 00:17:58.356
the next word and some state.

00:17:59.256 --> 00:18:00.016
And the second thing you're

00:18:00.016 --> 00:18:00.726
going to do is you're going to

00:18:00.726 --> 00:18:02.036
pass that all back to the model

00:18:02.036 --> 00:18:02.816
for the next prediction.

00:18:03.236 --> 00:18:04.296
So, it's pretty simple.

00:18:05.076 --> 00:18:06.066
Let's see what the code would

00:18:06.066 --> 00:18:07.946
look like to do something like

00:18:08.856 --> 00:18:08.956
that.

00:18:09.186 --> 00:18:10.686
So I'm going to start by saying

00:18:10.686 --> 00:18:11.536
let output =

00:18:11.536 --> 00:18:12.666
model.prediction(input).

00:18:12.666 --> 00:18:15.766
I'll take the probabilities

00:18:15.766 --> 00:18:17.056
associated with the next word

00:18:17.056 --> 00:18:18.686
and I'll give it to a function

00:18:18.686 --> 00:18:20.486
say displayTopPredictions which

00:18:20.826 --> 00:18:22.286
says selects the top 3 and gives

00:18:22.286 --> 00:18:23.696
that to the user.

00:18:24.636 --> 00:18:26.196
The user is either going to

00:18:26.236 --> 00:18:27.576
select one of those 3 words or

00:18:27.576 --> 00:18:29.236
maybe type their own, either way

00:18:29.236 --> 00:18:30.696
I'll get that from this function

00:18:30.696 --> 00:18:33.006
getWordFromUser and I'll pass

00:18:33.006 --> 00:18:34.346
that back to the input as the

00:18:34.346 --> 00:18:34.906
current word.

00:18:35.396 --> 00:18:36.826
I'll take the state, pass it

00:18:36.826 --> 00:18:38.696
along to the model again.

00:18:39.246 --> 00:18:41.406
So in just a few lines of code,

00:18:41.706 --> 00:18:43.276
you can integrate a more less

00:18:43.326 --> 00:18:44.986
complex as an LSDM that involves

00:18:44.986 --> 00:18:46.876
state, the language model,

00:18:46.876 --> 00:18:48.296
keyboard, all sorts of things in

00:18:48.296 --> 00:18:49.296
just a few lines of code.

00:18:49.846 --> 00:18:51.036
So that was about the different

00:18:51.036 --> 00:18:52.406
sets of use cases and a little

00:18:52.406 --> 00:18:53.246
bit about text.

00:18:54.416 --> 00:18:55.736
Now let's talk about how Core ML

00:18:56.236 --> 00:18:58.006
is optimized for the hardware on

00:18:58.006 --> 00:18:59.526
which it runs and most

00:18:59.526 --> 00:19:01.106
importantly what that means for

00:19:01.106 --> 00:19:02.196
all of you when you're building

00:19:03.146 --> 00:19:03.276
apps.

00:19:04.096 --> 00:19:05.506
So we're going to motivate that

00:19:05.506 --> 00:19:07.576
with a little video of real time

00:19:07.576 --> 00:19:08.366
object detection.

00:19:09.336 --> 00:19:10.926
What's important to note here is

00:19:10.926 --> 00:19:13.976
that the camera feed is live

00:19:13.976 --> 00:19:15.556
going to a model, and a

00:19:15.556 --> 00:19:17.236
relatively powerful model, and

00:19:17.236 --> 00:19:18.196
you're getting accurate

00:19:18.196 --> 00:19:20.306
predictions as you see, live.

00:19:21.196 --> 00:19:22.846
And this is only possible

00:19:23.006 --> 00:19:24.366
because Core ML is super

00:19:24.366 --> 00:19:25.796
optimized for the hardware on

00:19:25.796 --> 00:19:26.416
which it runs.

00:19:27.126 --> 00:19:28.586
And in this case, the model runs

00:19:28.586 --> 00:19:30.156
in about, say, under 50

00:19:30.156 --> 00:19:30.816
milliseconds.

00:19:31.486 --> 00:19:34.936
I was hoping nobody laugh

00:19:34.936 --> 00:19:36.606
because this joke has been said

00:19:36.716 --> 00:19:37.676
7 times already.

00:19:38.516 --> 00:19:41.866
[ Laughter and Applause ]

00:19:42.366 --> 00:19:44.236
So what really matters for you

00:19:44.236 --> 00:19:45.646
is that Core ML is built on top

00:19:45.646 --> 00:19:46.926
of the performance primitives,

00:19:47.326 --> 00:19:49.096
Accelerate and MPS.

00:19:49.626 --> 00:19:50.816
But more importantly, it

00:19:50.816 --> 00:19:52.356
completely hides the hardware

00:19:52.356 --> 00:19:53.456
from you so you don't have to

00:19:53.456 --> 00:19:54.696
worry about whether it's running

00:19:54.696 --> 00:19:56.636
on the CPU or the GPU.

00:19:57.226 --> 00:19:58.606
So that demo that you saw, you

00:19:58.606 --> 00:19:59.926
might ask, okay, how many knobs

00:19:59.926 --> 00:20:01.126
did I have to turn to get that

00:20:01.126 --> 00:20:01.526
to work?

00:20:01.526 --> 00:20:02.916
Well it's zero.

00:20:03.146 --> 00:20:04.076
That's the performance you'll

00:20:04.076 --> 00:20:05.136
get out of the box.

00:20:06.516 --> 00:20:11.766
[ Applause ]

00:20:12.266 --> 00:20:14.406
So specifically that demo that

00:20:14.406 --> 00:20:16.356
you saw and flower predictor

00:20:16.356 --> 00:20:18.146
that you saw earlier, those two

00:20:18.146 --> 00:20:20.696
were compute heavy tasks, and we

00:20:20.696 --> 00:20:22.366
knew that so we showed you them

00:20:22.366 --> 00:20:23.246
on the GPU.

00:20:24.046 --> 00:20:25.526
Whereas some of the text based

00:20:25.526 --> 00:20:27.316
demos like Sentiment Analysis

00:20:27.316 --> 00:20:29.146
and Next Word Prediction, these

00:20:29.146 --> 00:20:30.756
were memory heavy tasks and

00:20:30.756 --> 00:20:32.246
that's why we showed you them on

00:20:32.246 --> 00:20:32.826
the CPU.

00:20:33.906 --> 00:20:35.346
But most importantly, they all

00:20:35.396 --> 00:20:36.796
just run on Core ML so you don't

00:20:36.796 --> 00:20:38.006
have to worry about where it's

00:20:38.006 --> 00:20:38.306
running.

00:20:38.486 --> 00:20:39.636
We've got your back.

00:20:40.396 --> 00:20:42.296
And this kind of abstraction

00:20:42.296 --> 00:20:43.746
lets us do powerful things.

00:20:44.376 --> 00:20:46.006
So for the Image Captioning, for

00:20:46.006 --> 00:20:47.706
example, where part of that

00:20:47.706 --> 00:20:49.596
model is compute heavy and part

00:20:49.596 --> 00:20:51.336
of that model is memory heavy,

00:20:51.536 --> 00:20:53.096
we automatically contact Switch

00:20:53.096 --> 00:20:55.346
from the GPU to the CPU so that

00:20:55.346 --> 00:20:56.906
you can get the best of both

00:20:57.546 --> 00:20:57.696
worlds.

00:20:58.836 --> 00:21:01.136
So this was all about use cases

00:21:01.136 --> 00:21:03.656
and performance, but Core ML is

00:21:03.656 --> 00:21:04.646
much more than just the

00:21:04.646 --> 00:21:05.236
framework.

00:21:05.686 --> 00:21:06.896
It's a file format and a

00:21:06.956 --> 00:21:08.796
collection of tools to help you

00:21:08.796 --> 00:21:10.126
get more and more models that

00:21:10.126 --> 00:21:11.186
you can use in your apps.

00:21:11.706 --> 00:21:12.936
And to talk about that, I'd like

00:21:12.936 --> 00:21:13.866
to invite my friend and

00:21:13.866 --> 00:21:14.866
colleague, Zach.

00:21:16.516 --> 00:21:22.736
[ Applause ]

00:21:23.236 --> 00:21:23.876
>> Thanks, Krishna.

00:21:25.036 --> 00:21:27.176
Hi. My name is Zach and I'm an

00:21:27.176 --> 00:21:29.506
engineer on the Core ML

00:21:29.506 --> 00:21:30.186
Engineering Team.

00:21:31.516 --> 00:21:33.996
[ Applause ]

00:21:34.496 --> 00:21:35.676
And I'm really excited to talk

00:21:35.726 --> 00:21:37.856
to you today about the Core ML

00:21:38.006 --> 00:21:39.716
Model Format and where you can

00:21:39.716 --> 00:21:41.526
get models in this format for

00:21:41.526 --> 00:21:43.356
use in your apps.

00:21:44.176 --> 00:21:46.136
So by now, you've seen this

00:21:46.136 --> 00:21:48.006
diagram many times and this

00:21:48.006 --> 00:21:50.146
shows how easy it is to use a

00:21:50.146 --> 00:21:51.206
Machine Learning Model.

00:21:51.386 --> 00:21:52.816
Simply drag and drop it into

00:21:53.076 --> 00:21:54.106
Xcode and you get a code

00:21:54.106 --> 00:21:54.596
interface.

00:21:55.326 --> 00:21:56.356
But by now you're probably

00:21:56.356 --> 00:21:58.356
wondering where do these models

00:21:58.356 --> 00:21:58.856
come from?

00:21:59.306 --> 00:22:02.076
Well, there are really two

00:22:02.076 --> 00:22:04.146
places you can look for Machine

00:22:04.146 --> 00:22:05.486
Learning Models in the Core ML

00:22:05.486 --> 00:22:06.076
Model Format.

00:22:06.926 --> 00:22:09.216
The first is the example models

00:22:09.436 --> 00:22:10.966
on developer.apple.com.

00:22:11.686 --> 00:22:13.146
These are a variety of

00:22:13.206 --> 00:22:15.336
pre-trained models already in

00:22:15.476 --> 00:22:17.316
the Core ML Model Format and

00:22:17.316 --> 00:22:18.636
this is the easiest way to get

00:22:18.636 --> 00:22:20.086
started if you're new to machine

00:22:20.086 --> 00:22:20.326
learning.

00:22:21.426 --> 00:22:23.456
But we also know there's a whole

00:22:23.456 --> 00:22:24.816
wide world of machine learning

00:22:24.816 --> 00:22:25.296
out there.

00:22:25.996 --> 00:22:27.196
There are a lot of existing

00:22:27.256 --> 00:22:29.196
popular training tools and a lot

00:22:29.196 --> 00:22:31.006
of existing models out there in

00:22:31.006 --> 00:22:32.056
these formats already.

00:22:32.626 --> 00:22:33.976
So we want to make it possible

00:22:34.186 --> 00:22:35.796
to take machine learning models,

00:22:36.086 --> 00:22:37.546
trained using the most popular

00:22:37.546 --> 00:22:40.146
tools, and use them in your apps

00:22:40.146 --> 00:22:40.486
today.

00:22:42.156 --> 00:22:44.276
So to that end, we've created

00:22:44.536 --> 00:22:45.546
Core ML Tools.

00:22:46.236 --> 00:22:47.946
It's a converter package that

00:22:47.946 --> 00:22:49.706
takes models in a variety of

00:22:49.746 --> 00:22:51.606
popular formats and converts

00:22:51.656 --> 00:22:53.056
them into the Core ML Model

00:22:53.056 --> 00:22:56.546
Format and it's open source.

00:22:57.516 --> 00:23:02.786
[ Applause ]

00:23:03.286 --> 00:23:04.566
We've released Core ML Tools

00:23:04.566 --> 00:23:06.416
under the permissive BSD license

00:23:06.736 --> 00:23:09.416
so that there are no barriers to

00:23:12.086 --> 00:23:12.296
adoption.

00:23:12.426 --> 00:23:14.846
So to get a model off the

00:23:14.846 --> 00:23:16.056
internet somewhere, you're going

00:23:16.056 --> 00:23:17.396
to start with a model in a

00:23:17.396 --> 00:23:18.116
different format.

00:23:18.116 --> 00:23:18.806
Let's say Caffe.

00:23:19.926 --> 00:23:21.316
So Caffe is a really popular

00:23:21.316 --> 00:23:22.586
deep learning training library.

00:23:23.126 --> 00:23:25.076
If you're starting with a model

00:23:25.076 --> 00:23:26.946
in, say, Caffe Format, the way

00:23:26.946 --> 00:23:28.136
that you get it into Core ML

00:23:28.136 --> 00:23:29.476
Model Format and to use it in

00:23:29.476 --> 00:23:31.106
your application is to run it

00:23:31.196 --> 00:23:32.966
through a converter from Core ML

00:23:32.966 --> 00:23:33.336
Tools.

00:23:34.206 --> 00:23:36.156
Or if you don't find a model out

00:23:36.156 --> 00:23:37.386
there that does what you want,

00:23:37.916 --> 00:23:38.996
you can start with your own

00:23:38.996 --> 00:23:40.826
training data and use any of a

00:23:40.826 --> 00:23:42.416
variety of these popular tools

00:23:42.636 --> 00:23:43.946
to train your own model in that

00:23:43.946 --> 00:23:44.326
format.

00:23:44.826 --> 00:23:46.326
From there, again, you run the

00:23:46.326 --> 00:23:48.186
converter to produce a model in

00:23:48.186 --> 00:23:49.796
Core ML Model Format and the

00:23:49.796 --> 00:23:51.146
rest of the workflow stays

00:23:51.146 --> 00:23:51.996
exactly the same.

00:23:52.406 --> 00:23:53.686
Simply drag and drop the model

00:23:53.686 --> 00:23:55.066
into Xcode and you get a code

00:23:55.066 --> 00:23:55.726
interface.

00:23:56.516 --> 00:24:01.500
[ Applause ]

00:24:04.046 --> 00:24:06.296
Using Core ML Tools is as easy

00:24:06.296 --> 00:24:08.716
as pip install coremltools which

00:24:08.746 --> 00:24:09.726
downloads and installs the

00:24:09.726 --> 00:24:10.306
package.

00:24:10.886 --> 00:24:12.546
This is a python package with

00:24:12.596 --> 00:24:14.296
converters for a variety of

00:24:14.356 --> 00:24:16.166
popular training tools, and most

00:24:16.166 --> 00:24:17.826
of these tools are already in

00:24:17.826 --> 00:24:18.336
python.

00:24:18.596 --> 00:24:19.776
So to be part of that machine

00:24:19.776 --> 00:24:21.396
learning ecosystem, this is a

00:24:21.396 --> 00:24:25.036
python library as well.

00:24:25.236 --> 00:24:26.796
Let's look at the breakdown of

00:24:26.796 --> 00:24:28.116
what's inside this package.

00:24:28.866 --> 00:24:30.486
At the very top are each of the

00:24:30.486 --> 00:24:32.466
converters, and this is a set of

00:24:32.556 --> 00:24:34.586
converters, one for each popular

00:24:34.586 --> 00:24:35.386
training library.

00:24:36.616 --> 00:24:38.436
Underneath that, we have Core ML

00:24:38.436 --> 00:24:40.076
bindings and a converter

00:24:40.076 --> 00:24:41.636
library, and this is what we've

00:24:41.636 --> 00:24:43.056
used to build all of the

00:24:43.056 --> 00:24:43.646
converters.

00:24:43.986 --> 00:24:45.806
So here the Core ML bindings

00:24:46.166 --> 00:24:47.956
allow you to call directly into

00:24:47.956 --> 00:24:49.746
Core ML from python and get

00:24:49.746 --> 00:24:51.216
backup prediction, and that's

00:24:51.386 --> 00:24:53.046
really useful to verify that the

00:24:53.246 --> 00:24:54.676
prediction you get for a

00:24:54.676 --> 00:24:56.156
converted model is exactly the

00:24:56.156 --> 00:24:57.596
same as the prediction you would

00:24:57.596 --> 00:24:59.146
get with the original training

00:24:59.146 --> 00:24:59.646
framework.

00:25:00.486 --> 00:25:01.516
We also have a converter

00:25:01.516 --> 00:25:03.196
library, which is a high-level

00:25:03.196 --> 00:25:05.296
API for building converters, and

00:25:05.296 --> 00:25:06.696
its shared code among all of

00:25:06.696 --> 00:25:08.016
these converters so that make it

00:25:08.016 --> 00:25:09.246
really easy to build new

00:25:09.246 --> 00:25:10.736
converters for new formats.

00:25:12.196 --> 00:25:13.806
Underneath all of that is the

00:25:13.806 --> 00:25:15.136
Core ML Specification.

00:25:15.976 --> 00:25:18.146
This is a read and write API to

00:25:18.146 --> 00:25:20.426
the Core ML Model Format

00:25:20.426 --> 00:25:20.956
directly.

00:25:21.466 --> 00:25:23.266
So all of the individual fields

00:25:23.416 --> 00:25:26.556
can be accessed here.

00:25:27.016 --> 00:25:28.266
We've designed the package this

00:25:28.266 --> 00:25:30.836
way so that it's compatible and

00:25:30.836 --> 00:25:31.506
extensible.

00:25:32.126 --> 00:25:33.906
At the top level, the converters

00:25:33.906 --> 00:25:36.756
give Core ML compatibility with

00:25:36.756 --> 00:25:38.236
a variety of popular tools.

00:25:39.776 --> 00:25:41.546
Underneath that, the Core ML

00:25:41.546 --> 00:25:43.556
Bindings, Converter Library, and

00:25:43.686 --> 00:25:45.536
the Core ML Specification make

00:25:45.536 --> 00:25:47.596
this package extensible so it's

00:25:47.596 --> 00:25:49.686
easy to build new converters and

00:25:49.716 --> 00:25:51.696
to build converters for a lot of

00:25:51.696 --> 00:25:52.896
existing formats that aren't

00:25:52.926 --> 00:25:53.266
there yet.

00:25:53.916 --> 00:25:55.686
And because this is open source,

00:25:56.176 --> 00:25:57.856
it's easy to take this package

00:25:58.166 --> 00:25:59.636
and even integrate it into

00:25:59.636 --> 00:26:01.476
another open source library and

00:26:01.476 --> 00:26:02.736
build new converters on top.

00:26:02.736 --> 00:26:03.766
And there are no restrictions

00:26:03.766 --> 00:26:04.016
here.

00:26:04.126 --> 00:26:06.976
This is BSD licensed.

00:26:07.516 --> 00:26:10.500
[ Applause ]

00:26:13.226 --> 00:26:15.266
The Core ML Model Format is a

00:26:15.266 --> 00:26:17.256
single document format and it

00:26:17.256 --> 00:26:19.216
encapsulates both the functional

00:26:19.216 --> 00:26:20.736
description of the model in

00:26:20.736 --> 00:26:22.536
terms of its inputs and outputs,

00:26:22.966 --> 00:26:24.126
as well as the trained

00:26:24.156 --> 00:26:25.176
parameters of the model.

00:26:25.576 --> 00:26:27.656
So to look at an example, for a

00:26:27.656 --> 00:26:29.086
simple model like a Linear

00:26:29.086 --> 00:26:30.716
Regression, this would be the

00:26:30.716 --> 00:26:32.056
set of weights and offset that

00:26:32.056 --> 00:26:33.166
are learned at training time.

00:26:33.676 --> 00:26:35.246
And for a more complex model

00:26:35.246 --> 00:26:36.676
like a Neural Network, this

00:26:36.676 --> 00:26:38.476
actually encapsulates both the

00:26:38.476 --> 00:26:40.406
structure of the network as well

00:26:40.406 --> 00:26:41.866
as the learned weights at

00:26:41.866 --> 00:26:42.416
training time.

00:26:43.236 --> 00:26:44.976
And this is a public file format

00:26:45.146 --> 00:26:46.596
and it's fully documented on

00:26:46.596 --> 00:26:51.186
developer.apple.com.

00:26:51.746 --> 00:26:53.016
When you look at a Machine

00:26:53.016 --> 00:26:55.266
Learning Model in Xcode, you see

00:26:55.266 --> 00:26:56.546
a view something like this.

00:26:56.546 --> 00:26:57.776
You get all of the metadata and

00:26:57.866 --> 00:26:59.936
the functional interface, and

00:27:00.046 --> 00:27:02.116
what we now see is that that's

00:27:02.116 --> 00:27:04.086
entirely powered by this Core ML

00:27:04.086 --> 00:27:04.706
Model Format.

00:27:04.766 --> 00:27:06.126
So the Single Document Format

00:27:06.206 --> 00:27:07.526
contains all the information

00:27:07.776 --> 00:27:09.506
Xcode needs to give you a UI on

00:27:09.686 --> 00:27:11.316
top of this model and to let

00:27:11.316 --> 00:27:12.816
your code call it and then to

00:27:12.816 --> 00:27:14.846
execute it on device.

00:27:16.356 --> 00:27:18.876
The Core ML converters all work

00:27:18.876 --> 00:27:19.446
in the same way.

00:27:20.096 --> 00:27:21.886
They start by taking a model in

00:27:21.886 --> 00:27:23.466
a source format, for instance

00:27:23.526 --> 00:27:25.936
Caffe, and converting it into

00:27:25.936 --> 00:27:27.066
the Core ML Model Format.

00:27:28.246 --> 00:27:30.426
There's a set of unified APIs to

00:27:30.426 --> 00:27:31.906
convert these models from a

00:27:31.906 --> 00:27:33.656
variety of formats into Core ML

00:27:33.656 --> 00:27:34.046
Format.

00:27:34.446 --> 00:27:35.506
So if you know how to convert

00:27:35.506 --> 00:27:36.956
from one format, you know how to

00:27:36.996 --> 00:27:38.366
convert from all formats.

00:27:39.026 --> 00:27:43.366
Let's take an example and look

00:27:43.366 --> 00:27:44.916
more closely at how we would

00:27:44.916 --> 00:27:46.416
convert a Caffe model.

00:27:47.466 --> 00:27:48.916
Caffe works a bit like this.

00:27:49.146 --> 00:27:50.626
It has several files to

00:27:50.626 --> 00:27:51.546
represent the model.

00:27:52.236 --> 00:27:54.556
The .caffemodel file represents

00:27:54.716 --> 00:27:56.036
the learned weights in that

00:27:56.126 --> 00:27:58.846
model which the .prototxt file

00:27:59.126 --> 00:28:00.626
represents the structure of the

00:28:00.626 --> 00:28:01.276
Neural Network.

00:28:02.516 --> 00:28:04.166
When Caffe is doing inference,

00:28:04.806 --> 00:28:06.126
you would start by taking an

00:28:06.126 --> 00:28:07.876
image, say, like a rose like

00:28:07.916 --> 00:28:10.156
this, and you'd pass it into

00:28:10.156 --> 00:28:11.206
Caffe with these two files.

00:28:11.796 --> 00:28:13.346
And Caffe would give back an

00:28:13.426 --> 00:28:15.146
index of a class label like,

00:28:15.246 --> 00:28:16.236
say, 74.

00:28:17.186 --> 00:28:18.696
Then there's a third file, a

00:28:18.696 --> 00:28:21.226
labels.txt that maps those

00:28:21.226 --> 00:28:23.356
indices to string class labels

00:28:23.576 --> 00:28:24.186
like "Rose".

00:28:25.066 --> 00:28:26.606
So it's important to note that

00:28:26.656 --> 00:28:28.886
those 3 files really encapsulate

00:28:28.886 --> 00:28:30.296
together all of the information

00:28:30.296 --> 00:28:31.716
in the model, and so that's

00:28:31.716 --> 00:28:33.156
what's needed for conversion

00:28:33.156 --> 00:28:34.226
into the Core ML Format.

00:28:35.896 --> 00:28:38.606
So now, let's look at an example

00:28:38.606 --> 00:28:40.396
of converting a Caffe model into

00:28:40.396 --> 00:28:42.526
a Core ML Model.

00:28:43.516 --> 00:28:46.500
[ Applause ]

00:28:51.066 --> 00:28:52.706
I'm going to start by opening an

00:28:52.706 --> 00:28:54.226
interactive python prompt here.

00:28:54.696 --> 00:28:56.466
So we can type python code and

00:28:56.466 --> 00:28:58.716
see the output in the real time.

00:28:59.536 --> 00:29:00.846
So I'm going to start by

00:29:00.906 --> 00:29:02.646
importing coremltools.

00:29:02.646 --> 00:29:03.836
Again, this is the name of that

00:29:03.916 --> 00:29:04.786
package in python.

00:29:04.786 --> 00:29:09.276
And as soon as that's done, I

00:29:09.276 --> 00:29:11.006
can just type coremltools.

00:29:11.466 --> 00:29:12.706
And when I'm working with a new

00:29:12.706 --> 00:29:14.506
python package, the first thing

00:29:14.506 --> 00:29:16.436
I like to do is tab complete on

00:29:16.556 --> 00:29:17.736
it and see what's available in

00:29:17.736 --> 00:29:18.136
the API.

00:29:19.446 --> 00:29:21.466
So here on tab complete, we can

00:29:21.526 --> 00:29:23.316
see that coremltools contains

00:29:23.416 --> 00:29:25.026
converters which is each of

00:29:25.026 --> 00:29:26.356
those high-level converters from

00:29:26.356 --> 00:29:27.906
another format into the Core ML

00:29:27.906 --> 00:29:30.646
Format, as well as models,

00:29:30.816 --> 00:29:32.736
specification version and utils

00:29:33.196 --> 00:29:34.506
which are the framework bindings

00:29:34.576 --> 00:29:36.256
and the converter library, and

00:29:36.286 --> 00:29:37.636
together with those you can

00:29:37.636 --> 00:29:38.946
build a new converter and test

00:29:39.196 --> 00:29:40.036
that it gives the same

00:29:40.036 --> 00:29:41.216
predictions as the original

00:29:41.216 --> 00:29:41.986
training framework.

00:29:42.646 --> 00:29:44.956
And the .protonamesbase which

00:29:44.956 --> 00:29:46.686
contains the read and write APIs

00:29:46.896 --> 00:29:48.266
for the Core ML Model Format.

00:29:49.126 --> 00:29:50.156
Today we're going to focus on

00:29:50.156 --> 00:29:50.746
the converters.

00:29:51.546 --> 00:29:53.176
So again, if I do .converters

00:29:53.276 --> 00:29:54.736
and then tab complete once more,

00:29:55.136 --> 00:29:56.566
I can see all of the converters

00:29:56.566 --> 00:29:57.746
that are available in this name

00:29:57.746 --> 00:29:58.546
space right now.

00:29:58.616 --> 00:30:00.846
So there's caffe, keras, libsvn,

00:30:01.066 --> 00:30:02.646
scikit-learn, and xgboost.

00:30:03.046 --> 00:30:04.066
And today we're going to focus

00:30:04.066 --> 00:30:04.626
on Caffe.

00:30:05.446 --> 00:30:07.416
So once more I'll do .caffe and

00:30:07.576 --> 00:30:08.606
tab complete and see what's

00:30:08.606 --> 00:30:09.116
available.

00:30:09.116 --> 00:30:10.346
And it just tab completed for

00:30:10.346 --> 00:30:10.546
me.

00:30:10.756 --> 00:30:12.396
Convert. So it's that simple.

00:30:12.396 --> 00:30:13.486
There's just one function in

00:30:13.486 --> 00:30:15.426
here called convert, and let's

00:30:15.426 --> 00:30:17.226
look at how we would use that.

00:30:18.756 --> 00:30:22.596
So first I'm going to start by

00:30:22.676 --> 00:30:23.676
setting up the inputs.

00:30:24.006 --> 00:30:25.766
So I know I have a Caffe model

00:30:26.666 --> 00:30:27.716
defined by two files.

00:30:27.786 --> 00:30:29.516
So I'm going to say caffemodel =

00:30:29.636 --> 00:30:30.786
and I'm going to give a two pole

00:30:31.066 --> 00:30:32.506
of two strings pointing to the

00:30:32.506 --> 00:30:34.196
file names of that Caffe Model,

00:30:34.476 --> 00:30:37.326
which are flowers.caffemodel and

00:30:37.396 --> 00:30:38.876
flowers.prototxt.

00:30:39.046 --> 00:30:40.786
And together those represent the

00:30:40.786 --> 00:30:42.536
learned weights in the network

00:30:42.536 --> 00:30:43.426
as well as the network

00:30:43.426 --> 00:30:43.936
structure.

00:30:44.486 --> 00:30:48.636
Next I'm going to set up a class

00:30:48.686 --> 00:30:49.356
label file.

00:30:49.356 --> 00:30:52.666
So I'm going to say labels = and

00:30:52.666 --> 00:30:54.436
I have labels.txt here.

00:30:55.356 --> 00:30:56.816
And that represents the mapping

00:30:56.906 --> 00:30:58.706
of numeric indices to string

00:30:58.706 --> 00:30:59.446
class labels.

00:31:00.886 --> 00:31:02.216
Now to run the converter.

00:31:02.486 --> 00:31:03.376
It's very simple.

00:31:03.686 --> 00:31:05.126
All I have to do is say

00:31:05.236 --> 00:31:10.286
coremlmodel = coremltools

00:31:10.676 --> 00:31:13.626
.converters.caffe.convert and it

00:31:13.626 --> 00:31:16.496
all tab completes, and I'm just

00:31:16.496 --> 00:31:18.466
going to pass in that caffemodel

00:31:19.066 --> 00:31:21.286
and classlabels = labels.

00:31:21.856 --> 00:31:22.886
So I'm just passing in those

00:31:22.886 --> 00:31:23.596
three files.

00:31:24.376 --> 00:31:27.426
And when the converter finishes,

00:31:27.766 --> 00:31:29.416
what I get back is a Core ML

00:31:29.416 --> 00:31:29.736
Model.

00:31:30.516 --> 00:31:32.116
Right here in python, I can

00:31:32.116 --> 00:31:33.996
print out the model and see the

00:31:33.996 --> 00:31:36.396
interface that I get with that

00:31:36.396 --> 00:31:36.716
model.

00:31:37.286 --> 00:31:38.516
So I can see that it has one

00:31:38.516 --> 00:31:41.156
input named "data" and that

00:31:41.156 --> 00:31:43.236
input is a multi-array which

00:31:43.236 --> 00:31:46.406
shaped 3 by 227 by 227 and typed

00:31:46.486 --> 00:31:46.856
double.

00:31:47.096 --> 00:31:49.166
And we'll get back to that in a

00:31:49.166 --> 00:31:49.436
minute.

00:31:50.176 --> 00:31:51.566
It also has 2 outputs.

00:31:52.126 --> 00:31:54.046
One is named "prob" and it's a

00:31:54.046 --> 00:31:56.096
dictionary with string keys, so

00:31:56.096 --> 00:31:57.176
that's going to represent the

00:31:57.176 --> 00:31:59.276
probabilities for each possible

00:31:59.276 --> 00:31:59.976
class label.

00:32:00.966 --> 00:32:02.386
And another output named

00:32:02.386 --> 00:32:03.906
classLabel as a string, and

00:32:04.006 --> 00:32:05.186
that's simply going to be the

00:32:05.186 --> 00:32:06.346
most likely class label.

00:32:06.536 --> 00:32:07.686
So for convenience, you don't

00:32:07.686 --> 00:32:08.366
have to look at all the

00:32:08.366 --> 00:32:09.746
probabilities to find out which

00:32:09.746 --> 00:32:10.656
one is the most likely.

00:32:13.276 --> 00:32:15.696
But looking at this, I know that

00:32:15.696 --> 00:32:17.706
this input type is not quite the

00:32:17.706 --> 00:32:19.146
interface that I wanted the

00:32:19.146 --> 00:32:21.436
model to have, so I can go back

00:32:21.826 --> 00:32:22.856
and run the converter with

00:32:22.856 --> 00:32:24.726
another parameter to modify the

00:32:24.726 --> 00:32:26.366
input type because instead of a

00:32:26.366 --> 00:32:28.216
multi-array, I would like for

00:32:28.216 --> 00:32:29.976
this model to take an image as

00:32:29.976 --> 00:32:30.246
input.

00:32:31.896 --> 00:32:33.666
So I'm going to go back and add

00:32:34.336 --> 00:32:36.306
image input names = data.

00:32:36.916 --> 00:32:38.246
And again, just looking at the

00:32:38.246 --> 00:32:39.446
output here, you can see that

00:32:39.476 --> 00:32:41.356
the input name is data, so it's

00:32:41.356 --> 00:32:42.786
going to know what to do with

00:32:43.846 --> 00:32:44.936
that input.

00:32:45.156 --> 00:32:46.736
If I run the converter once more

00:32:47.126 --> 00:32:48.156
and then again print out the

00:32:48.156 --> 00:32:50.816
model interface, now I see that

00:32:50.816 --> 00:32:52.666
the input named data is an image

00:32:52.936 --> 00:32:55.486
with width 227, height 227, and

00:32:55.526 --> 00:32:56.636
color space RGB.

00:32:59.516 --> 00:33:03.726
[ Applause ]

00:33:04.226 --> 00:33:05.376
Now that we have a Core ML

00:33:05.376 --> 00:33:07.666
Model, let's check and make sure

00:33:07.666 --> 00:33:09.056
that the conversion succeeded

00:33:09.376 --> 00:33:10.646
and thus we get correct

00:33:10.756 --> 00:33:12.126
predictions with this Core ML

00:33:12.126 --> 00:33:12.466
Model.

00:33:13.826 --> 00:33:15.486
I'm going to start by importing

00:33:15.486 --> 00:33:16.966
the python image library so that

00:33:16.966 --> 00:33:18.696
I can work with images and pass

00:33:18.696 --> 00:33:19.886
an image directly into the

00:33:19.886 --> 00:33:20.226
model.

00:33:20.856 --> 00:33:23.096
So I'm going to say from PIL

00:33:23.546 --> 00:33:28.196
input Image and then Rose =

00:33:28.326 --> 00:33:30.946
Image.open rose.jpg.

00:33:31.736 --> 00:33:34.126
And just to prove to you I've

00:33:34.126 --> 00:33:36.756
got nothing up my sleeve, I'm

00:33:36.756 --> 00:33:39.976
going to call rose.show and show

00:33:39.976 --> 00:33:41.896
you that this is indeed a

00:33:41.896 --> 00:33:43.566
picture of a rose.

00:33:47.036 --> 00:33:49.036
[ Applause ]

00:33:49.056 --> 00:33:49.966
You don't need to clap for that.

00:33:50.516 --> 00:33:52.716
[ Laughter ]

00:33:53.216 --> 00:33:55.446
So now that I've shown that this

00:33:55.446 --> 00:33:56.846
image actually does represent a

00:33:56.846 --> 00:33:58.176
rose, let's see if the model

00:33:58.176 --> 00:33:58.706
agrees.

00:33:59.486 --> 00:34:01.476
So checking the prediction is as

00:34:01.476 --> 00:34:02.806
easy as calling

00:34:02.906 --> 00:34:06.466
coremlmodel.predict, and this is

00:34:06.526 --> 00:34:08.596
that Core ML framework binding

00:34:08.696 --> 00:34:09.856
that we talked about earlier.

00:34:10.956 --> 00:34:11.856
And we're going to pass the

00:34:11.856 --> 00:34:14.766
input named data the value rose.

00:34:16.416 --> 00:34:17.585
And immediately we get back a

00:34:17.585 --> 00:34:20.096
prediction of class label rose.

00:34:21.516 --> 00:34:26.196
[ Applause ]

00:34:26.696 --> 00:34:27.726
But let's make sure the model --

00:34:27.726 --> 00:34:29.206
let's make sure it's not a fluke

00:34:29.206 --> 00:34:30.176
and let's make sure the model

00:34:30.176 --> 00:34:31.335
really knows that this is a

00:34:31.335 --> 00:34:31.686
rose.

00:34:32.016 --> 00:34:32.976
So we're going to scroll down

00:34:32.976 --> 00:34:34.396
through the class probabilities

00:34:34.985 --> 00:34:36.376
until we see rose here.

00:34:37.936 --> 00:34:39.136
And we can see that the model is

00:34:39.136 --> 00:34:40.456
actually very confident that

00:34:40.456 --> 00:34:41.096
this is a rose.

00:34:41.096 --> 00:34:44.025
So this is .991 out of 1

00:34:44.456 --> 00:34:45.926
confidence that this is a rose.

00:34:45.985 --> 00:34:47.396
So I'm going to conclude that

00:34:47.446 --> 00:34:49.196
probably this model did convert

00:34:49.196 --> 00:34:49.656
correctly.

00:34:50.426 --> 00:34:51.826
If I was doing this in a real

00:34:51.826 --> 00:34:53.295
application, I would want to

00:34:53.295 --> 00:34:54.466
actually test this a bit more

00:34:54.466 --> 00:34:55.826
rigorously so I would provide

00:34:55.826 --> 00:34:57.396
more than one example and I

00:34:57.426 --> 00:34:59.036
would also want to check that

00:34:59.076 --> 00:35:00.406
the predictions that I get here

00:35:00.406 --> 00:35:02.016
from Core ML are exactly the

00:35:02.106 --> 00:35:03.696
same as the predictions that

00:35:03.846 --> 00:35:05.176
Caffe would have given me for

00:35:05.176 --> 00:35:06.716
the same input, and that's how

00:35:06.716 --> 00:35:07.816
we know that the conversion has

00:35:07.856 --> 00:35:08.366
succeeded.

00:35:09.176 --> 00:35:10.526
But that will take too long for

00:35:10.526 --> 00:35:12.526
this demo so let's move on.

00:35:13.186 --> 00:35:15.126
What I'm going to do now is save

00:35:15.286 --> 00:35:16.966
the model out and then look at

00:35:16.966 --> 00:35:17.806
it in Xcode.

00:35:18.386 --> 00:35:18.966
So I'm, going to say

00:35:18.966 --> 00:35:21.426
coremlmodel.save, and I'm going

00:35:21.426 --> 00:35:21.816
to call it

00:35:21.896 --> 00:35:23.886
FlowerPredictor.mlmodel.

00:35:24.566 --> 00:35:27.736
And then I'm just going to open

00:35:27.736 --> 00:35:29.076
the current directory and finder

00:35:29.516 --> 00:35:31.186
and double-click that model to

00:35:31.186 --> 00:35:33.646
open it in Xcode.

00:35:33.786 --> 00:35:36.656
And what we can see here is that

00:35:36.656 --> 00:35:37.926
it's a Machine Learning Model

00:35:37.926 --> 00:35:39.326
with name FlowerPredictor.

00:35:39.326 --> 00:35:40.356
Type is Neural Network

00:35:40.356 --> 00:35:43.846
Classifier and its size is 229.1

00:35:43.846 --> 00:35:44.266
megabytes.

00:35:45.346 --> 00:35:46.306
But there's a lot of missing

00:35:46.306 --> 00:35:47.186
information, too.

00:35:47.186 --> 00:35:48.686
It doesn't know the author, the

00:35:48.686 --> 00:35:51.216
license, the description or the

00:35:51.216 --> 00:35:52.616
descriptions for the inputs and

00:35:52.616 --> 00:35:52.936
outputs.

00:35:53.896 --> 00:35:55.346
So while this is a working

00:35:55.346 --> 00:35:57.256
model, it's not necessarily one

00:35:57.256 --> 00:35:58.286
I would want to give to a

00:35:58.286 --> 00:35:59.666
colleague or put on the internet

00:36:00.096 --> 00:36:01.696
because it's not quite as useful

00:36:01.696 --> 00:36:03.066
if it doesn't really declare

00:36:03.066 --> 00:36:04.196
what it's supposed to do and how

00:36:04.196 --> 00:36:04.646
to use it.

00:36:05.336 --> 00:36:06.136
So I'm going to be a good

00:36:06.186 --> 00:36:07.656
citizen and go back and give

00:36:07.656 --> 00:36:08.846
this model some metadata.

00:36:14.066 --> 00:36:15.836
Back in the python prompt, I can

00:36:15.836 --> 00:36:17.436
just mutate the model right here

00:36:17.976 --> 00:36:19.816
by assigning to fields at the

00:36:19.876 --> 00:36:20.396
top level.

00:36:20.396 --> 00:36:24.076
So I can say author = "Zach

00:36:24.976 --> 00:36:25.126
Nation".

00:36:25.896 --> 00:36:29.736
coremlmodel.license = "BSD".

00:36:31.646 --> 00:36:35.916
coremlmodel.shortdescription = a

00:36:36.026 --> 00:36:37.686
flower classifier.

00:36:39.286 --> 00:36:41.396
And let's set the help text for

00:36:41.396 --> 00:36:42.606
those inputs and outputs as

00:36:42.606 --> 00:36:44.376
well, because not only does that

00:36:44.376 --> 00:36:46.536
show up in the Xcode view, but

00:36:46.536 --> 00:36:48.536
when the generated code is there

00:36:48.536 --> 00:36:50.036
and you can call into it that

00:36:50.036 --> 00:36:51.976
actually becomes documentation

00:36:52.066 --> 00:36:53.476
comments in the generated code.

00:36:53.916 --> 00:36:55.306
So when your tab completing an

00:36:55.556 --> 00:36:56.796
Xcode this is what someone

00:36:56.796 --> 00:36:58.166
consuming this mode will see.

00:36:58.826 --> 00:37:00.656
So I'm going to say

00:37:00.906 --> 00:37:03.506
coremlmodel.inputdescription for

00:37:03.506 --> 00:37:07.816
"data" is an image of a flower.

00:37:09.466 --> 00:37:09.836
And

00:37:09.836 --> 00:37:11.996
coremlmodel.outputdescription

00:37:11.996 --> 00:37:16.006
"prob" is the probabilities for

00:37:16.006 --> 00:37:20.516
each flower type, for the given

00:37:20.516 --> 00:37:20.986
input.

00:37:21.656 --> 00:37:21.746
And

00:37:23.276 --> 00:37:26.486
coremlmodel.outputdescription

00:37:26.546 --> 00:37:30.516
"classLabel" is "The most likely

00:37:30.546 --> 00:37:33.126
type of flower, for the given

00:37:33.176 --> 00:37:33.486
input."

00:37:34.066 --> 00:37:37.056
And now we can just save that

00:37:37.056 --> 00:37:39.796
model once again and I'm just

00:37:41.106 --> 00:37:42.516
going to clobber the file that

00:37:42.516 --> 00:37:44.256
was there because now I want the

00:37:44.256 --> 00:37:44.936
one with metadata.

00:37:44.936 --> 00:37:46.936
So I'm going to just save it

00:37:46.936 --> 00:37:47.946
right on top of the file that

00:37:47.946 --> 00:37:49.926
was there before and open that

00:37:49.926 --> 00:37:51.226
directory and finder again.

00:37:52.046 --> 00:37:53.176
And now when I double-click the

00:37:53.176 --> 00:37:55.546
model and open it in Xcode, we

00:37:55.546 --> 00:37:57.176
can see that it contains useful

00:37:57.176 --> 00:37:58.996
metadata describing how the

00:37:58.996 --> 00:38:00.536
model is intended should be used

00:38:00.786 --> 00:38:02.506
and what the inputs and outputs

00:38:02.576 --> 00:38:02.816
do.

00:38:04.516 --> 00:38:09.500
[ Applause ]

00:38:13.076 --> 00:38:16.996
So to recap, what we saw is that

00:38:16.996 --> 00:38:18.706
using Core ML Tools to convert a

00:38:18.706 --> 00:38:21.266
model is as easy as import

00:38:21.266 --> 00:38:23.526
coremltools, setting up the

00:38:23.526 --> 00:38:25.566
inputs, and then calling a

00:38:25.646 --> 00:38:27.186
simple high-level convert

00:38:27.186 --> 00:38:29.316
function to get back a model in

00:38:29.316 --> 00:38:30.356
Core ML Model Format.

00:38:31.096 --> 00:38:32.756
And the best part is, let's say

00:38:32.756 --> 00:38:33.946
you switch training frameworks

00:38:34.226 --> 00:38:36.676
from Caffe to Keras, switching

00:38:36.676 --> 00:38:38.416
converters is as easy as

00:38:38.476 --> 00:38:40.366
updating the name space because

00:38:40.366 --> 00:38:41.646
all of the convert functions

00:38:41.816 --> 00:38:43.826
share the same high-level API

00:38:47.516 --> 00:38:51.796
[ Applause ]

00:38:52.296 --> 00:38:54.926
Core ML Tools supports Caffe and

00:38:54.956 --> 00:38:57.026
Keras models as Neural Networks.

00:38:57.486 --> 00:38:58.966
Scikit-Learn for Pipelines.

00:39:00.146 --> 00:39:02.066
Scikit-Learn and XGBoost for

00:39:02.066 --> 00:39:04.876
Tree Ensembles, and LIBSVM and

00:39:05.066 --> 00:39:06.876
Scikit-Learn for Linear Models

00:39:07.026 --> 00:39:08.366
and Support Vector Machines.

00:39:09.136 --> 00:39:10.346
It's also worth noting that

00:39:10.506 --> 00:39:12.196
Keras is a really powerful

00:39:12.376 --> 00:39:14.216
high-level interface to several

00:39:14.216 --> 00:39:15.506
popular deep learning training

00:39:15.506 --> 00:39:17.056
tools, including TensorFlow.

00:39:17.646 --> 00:39:18.446
So if you're training a

00:39:18.446 --> 00:39:20.406
TensorFlow Model in Keras, you

00:39:20.406 --> 00:39:22.356
can use Core ML Tools to convert

00:39:22.356 --> 00:39:24.606
it into Core ML Model Format.

00:39:26.516 --> 00:39:31.196
[ Applause ]

00:39:31.696 --> 00:39:34.046
Obtaining models, you want to

00:39:34.046 --> 00:39:35.176
look in two places.

00:39:35.816 --> 00:39:37.936
One is the set of example models

00:39:37.936 --> 00:39:39.466
on developer.apple.com.

00:39:39.846 --> 00:39:40.766
And again, these are

00:39:40.896 --> 00:39:42.526
pre-training models already in

00:39:42.526 --> 00:39:44.206
the Core ML Model Format and so

00:39:44.206 --> 00:39:45.466
this is the easiest way to get

00:39:45.466 --> 00:39:46.916
started if you're new to Machine

00:39:46.916 --> 00:39:48.516
Learning or if one of these

00:39:48.516 --> 00:39:50.256
models does the task that you're

00:39:50.256 --> 00:39:51.516
trying to do in your app.

00:39:51.956 --> 00:39:52.946
But because there's a whole

00:39:52.946 --> 00:39:54.066
world of machine learning out

00:39:54.126 --> 00:39:55.836
there and a variety of models in

00:39:55.836 --> 00:39:57.266
use cases in a variety of

00:39:57.266 --> 00:39:59.236
formats, we've created Core ML

00:39:59.236 --> 00:40:01.056
Tools to allow you to convert

00:40:01.246 --> 00:40:02.376
from any of these popular

00:40:02.376 --> 00:40:04.236
formats into the Core ML Model

00:40:05.096 --> 00:40:05.286
Format.

00:40:06.516 --> 00:40:11.306
[ Applause ]

00:40:11.806 --> 00:40:13.526
So, in summary, what we've

00:40:13.526 --> 00:40:15.826
learned today is that Core ML

00:40:15.826 --> 00:40:17.396
makes it really easy to

00:40:17.396 --> 00:40:18.356
integrate Machine Learning

00:40:18.356 --> 00:40:19.486
Models into your app.

00:40:19.886 --> 00:40:22.016
Simply drag and drop into Xcode

00:40:22.016 --> 00:40:23.336
and you get a code interfaced to

00:40:23.336 --> 00:40:23.736
the model.

00:40:25.176 --> 00:40:26.976
Core ML has rich datatype

00:40:27.046 --> 00:40:28.876
support for a variety of use

00:40:28.946 --> 00:40:30.336
cases and it deals with

00:40:30.336 --> 00:40:31.486
datatypes that you're already

00:40:31.486 --> 00:40:33.566
familiar with from your app

00:40:35.316 --> 00:40:35.436
code.

00:40:35.626 --> 00:40:37.226
Core ML is hardware optimized

00:40:37.406 --> 00:40:38.486
and it's built on top of

00:40:38.536 --> 00:40:39.796
performance primitives like

00:40:39.796 --> 00:40:41.296
Metal Performance Shaders and

00:40:41.296 --> 00:40:42.976
Accelerate so that you get the

00:40:42.976 --> 00:40:44.526
best possible performance on

00:40:44.526 --> 00:40:45.066
device.

00:40:45.656 --> 00:40:49.526
And through Core ML Tools, Core

00:40:49.526 --> 00:40:51.116
ML is compatible with the most

00:40:51.156 --> 00:40:53.376
popular Machine Learning Formats

00:40:53.726 --> 00:40:54.896
and more will be added over

00:40:55.746 --> 00:40:55.836
time.

00:40:57.286 --> 00:40:59.106
For more information, please see

00:40:59.106 --> 00:41:00.986
developer.apple.com with our

00:41:00.986 --> 00:41:02.556
session number 710.

00:41:03.116 --> 00:41:05.236
We have a couple of related

00:41:05.236 --> 00:41:06.496
sessions coming up you may be

00:41:06.496 --> 00:41:07.336
interested in.

00:41:07.526 --> 00:41:08.516
To look at some low-level

00:41:08.516 --> 00:41:09.896
details about how we get such

00:41:09.896 --> 00:41:11.016
good performance on this

00:41:11.016 --> 00:41:12.266
hardware, check out the

00:41:12.266 --> 00:41:14.026
Accelerate and Metal 2 sessions.

00:41:14.436 --> 00:41:14.796
Thank you.

00:41:15.516 --> 00:41:20.500
[ Applause ]