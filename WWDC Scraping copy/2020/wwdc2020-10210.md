# Wwdc2020 10210

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Modernize PCI and SCSI drivers with DriverKitKeep code out of the kernel and give your customers a more secure and reliable experience with accessories using DriverKit. Discover how to create low-level drivers that support PCI devices or SCSI controllers. And find out how you can achieve great performance with DriverKit on macOS Big Sur.ResourcesSystem Extensions and DriverKitHD VideoSD VideoRelated VideosWWDC22Bring your driver to iPad with DriverKitWWDC21Create audio drivers with DriverKitWWDC19System Extensions and DriverKit

Keep code out of the kernel and give your customers a more secure and reliable experience with accessories using DriverKit. Discover how to create low-level drivers that support PCI devices or SCSI controllers. And find out how you can achieve great performance with DriverKit on macOS Big Sur.

System Extensions and DriverKit

HD VideoSD Video

HD Video

SD Video

Bring your driver to iPad with DriverKit

Create audio drivers with DriverKit

System Extensions and DriverKit

Search this video…Hello and welcome to WWDC.Hi my name is Kevin and I'll be joined later by my colleague Madhu.Today we'll be going over what's new in DriverKit.First I will give a brief recap of System Extensions with DriverKit.Then I'll talk about the new PCIDriverKit framework. Then I'll hand it overto Madhu who'll be going in-depth on writing a SCSI Controller driverusing PCIDriverKit and the new SCSIControllerDriverKit framework.Then she'll be showing us a demo of these new frameworks in action.Finally I'll wrap things up with a summary of everything that we went over today.Last year we introduced DriverKit, a replacement for IOKit device drivers.DriverKit brought a new way to extend the operating system that is morereliable, more secure, and easier to develop. Driver extensions allow developersto make powerful and innovative apps without the pitfalls of writing codethat runs in the kernel. For an in-depth look at DriverKit and how itworks please check out last year's video titled System Extensions andDriverKit on the Apple Developer website. DriverKit System Extensionsrun in user space, not kernel space. Like other apps they have to followthe rules of the system security policy. Unlike other apps, System Extensionsare granted special privileges to do special jobs. For example they havedirect control of specific hardware devices or special APIs to interfacedirectly with the kernel. Because DriverKit drivers are in user space,their access is limited and the resources are separate from the rest ofthe systems resources. When a driver extension crashes, the kernel andthe rest of the system keep running. The development cycle is much faster.We can build, test, and debug on one machine whereas kernel extensions bringalong security implications — a bug in a kext can compromise the entire kernel.A kext has access to all of the computers resources, not just a specific pieceof hardware or resource. When a kernel extension crashes, the kernelpanics and takes down the entire machine. Debugging and development canbe slow. We need multiple machines and we'll need to reboot on every crash.Another great benefit to driver extensions is installation is much easier.Your driver extension stays in your app bundle. You should not copy yourdriver extension directly to any system folders. To install your app you'lluse SystemExtensions framework and create an activationRequest, to requestthe extension to be made available to the system. A system administratorwould need to approve this request. Most apps should create anactivationRequest during app launch so the extension is made available right away.However, you may wish to activate your System Extension at different pointsin your app's lifecycle such as after the user has agreed to a licenseagreement, or made an in-app purchase if that's required for your system extension.You can get started writing DriverKit drivers right away before they'reready to go into the App Store without a provisioning profile. To do this,you'll need to disable system integrity protection, sign your dexts torun locally, and be sure to include all the entitlements needed for your driver.Last year when DriverKit first launched, there was support for USB, serial,network interface controllers, and human interface devices. Then later PCIsupport was introduced. And now SCSI Controller support has been added as well.Because DriverKit brings so many great improvements over kernel extensions,we recommend migrating to DriverKit immediately for available frameworks.Catalina was the last released to fully support kexts without any compromises.We've begun deprecating kernel extensions that can perform the same functionas a system extension including the device families supported by DriverKit.In macOS Big Sur, kexts that were deprecated in macOS Catalina will not loadby default. We will continue to add more types of system extensions andmore device families to DriverKit. In turn, kernel extensions of these kindswill also be deprecated. This year we have added support for PCI and SCSIController drivers. This means kext support is now deprecated for PCI andSCSI controller device families, for kernel extensions that can performthe same function as a system extension. This also means PCI and SCSIcontroller kexts will not load by default in a future macOS release.Now we'll talk about one of the exciting new additions to DriverKit:PCIDriverKit. I'll show you some of the key differences and driver modelsbetween PCI driver extensions and kernel extensions. Then I'll be showingsome code examples almost every PCIDriverKit driver will need. PCIeis used to expand the capabilities of a machine as though they are builtinto the system. PCIe brings a lot of advantages as it can handle themost demanding high performance jobs.Some common PCIe devices include serial, Ethernet, and SCSI controllers.Users can add PCIe devices through Thunderbolt or through PCIe slots suchas in the latest Mac Pro. As with all driver extensions PCIDriverKit requiresentitlements to grant access to your PCI devices. This is to ensure anotherapp or malicious software can not access your PCI device. The new entitlementuses the same IOPCIFamily driver-matching criteria as the Info.plist.However you can make the entitlements more generic if you need to supportmultiple devices. In this example, I have an entitlement that will allowyou to access any device with a provided vendor ID. In this case we'regoing to use ABCD. The PCI entitlement takes a list of PCI matching dictionaries.You can be as specific or generic as you want by using the IOPCIFamily matching categories.In this case we're doing a primary match which means we'll be comparingthe primary vendor ID and device ID of the device to the entry that wehave in our dictionary.By using the ampersand we can have a mask that allows the matching dictionaryto be more generic. This effectively removes the device ID from the matchingdictionary allowing the driver extension to be entitled for all devicesof this vendor ID.With PCIDriverKit you will likely need to interact with one of themany other DriverKit frameworks. This is an example of what your entitlementswill be if you wanted to write a custom Ethernet NIC driver. In thiscase you'll add the networking family entitlement. With this family entitlement,you can now use the Networking DriverKit framework to interact with a networkingstack as well. With PCIDriverKit the only class in the framework is theIOPCI device. This class is not intended to be subclassed. You'll usethis class as the PCI provider to access all of your PCI resources.Here's what your driver extension may look like using our network interface controller example.The user space IOPCIDevice will do the PCI-related communication neededwith the kernel. Your driver will use the IOPCI device for any PCI resource access.Your driver can then use the PCI device resources to talk to the networkingfamily and other user clients. The layering structure for the driver extensionis mostly the same as the kernel extension, however almost everything isuser space. While encouraged in kernel extensions, PCIDriverKit mandates thatprior to accessing the PCI device you must successfully call Open on the device.Once Open return successfully, your driver has exclusive access to the PCI device.If your device has resources that are intended to be shared by multipleclients, you will need to design your driver extension in a way that hasa single PCI resource manager that distributes its resources amongst allof its clients. This is to enforce good design and allows the systemto handle driver extension crashes more gracefully. When done using the devicesuch as during the driver stop routine, You'll need to call Close on the device.You should not expect the state of the device to remain after calling Close.For instance the PCI stack will disable bus mastering and memory spaceonce Close has successfully completed. Another driver may open the deviceand change its state if it's entitled to do so. Another difference betweenPCI kernel extensions and PCIDriverKit is that PCIDriverKit frameworktakes care of all the device mappings for you. There are new APIs thatall memory accesses will use. This allows developers to take advantageof any future optimizations Apple may explore. It removes the need forany device memory management and will also allow more observeabiltty anddebuggability. With a single point of access You can now use programs suchas dtrace to observe all device memory accesses. This can be especiallyhelpful when debugging PCI issues in a multi-threaded environment.The APIs work by passing a memory index of the memory space you wish to accessalong with the offset. I will go over what the difference between a memoryindex is versus a base address register index now. This is a diagram ofthe PCI device's base address registers or BARs. For 32-bit BARs, the memoryIndexand the BAR index are the exact same.For example with 32-bit addresses, if you want to access BAR2 you'd use2 as the memoryIndex because it's the same index into the device'sBAR space. 64-bit BARs are where the memoryIndex and BAR index can differ. ThememoryIndex is the index for each memory entry. All memory indexes are base zero.So, for example, if BAR0 and BAR1 combined are one 64-bit address, your memoryIndexwould be 0 because it's the first memory entry. Then if BAR2and BAR3 are another 64-bit address, they'd be at memoryIndex=1because it's the second memory entry in the device's BAR table.Accessing configuration space of your device is mostly a one-to-one mapping andstill works the same with just a new name. The major difference betweenPCIDriverKit and kernel extensions for configuration space is thatyou will first need to have an open session to read or write any configurationspace registers. Next I'll be going over some examples of common code you'lllikely need. First is how you enable bus mastering and memory space.These will be needed in order to access memory on your device, along withenabling your device to issue I/O. Previously there were explicit kernel APIsfor each of these operations. Now, in order to achieve the same result,you'll first read the command register and write back to it with the bus masterand memory space bit set. This example is what most PCI drivers will look like.In their Start routine, they will first start a session with the PCI provider.Then they will read the PCI device's command register. Set the bus masterand memory enable bits, then write the values back to the PCI device.This will need to be done before issuing any memory reads or writes.All these offsets and definitions can be found in the PCIDriverKit frameworkheaders. To disable bus mastering the processes are the same but insteadof setting the bits, the driver will mask them out. In this example, Close isalso called in the Stop routine. This means that we are done talkingto the PCI device and can close our session. Now we'll be going over how tosetup an interrupt handler. First we'll need to declare an InterruptOccuredmethod in our iig header file. Then the definition of our interrupt handlerwill be using an implementation definition. In this example when we getan interrupt the handler will clear the interrupt by writing a registerin MMIO space to one of the device's memory indexes. Now we need to dothe setup to make it so our interruptOccurred method gets called when aninterrupt fires. First thing we'll need to do is find out which interrupt indexwe want to use. To do this we'll iterate through all the interrupt indexesassociated with the PCI device. Then we'll check its interruptType. In this examplewe want to handle the device's msiInterrupts. So that means we wantto break out of the loop once we found the interrupt index that supports MSIs.Then we'll need to choose which DispatchQueue the interrupt will be handled in.For this example we're going to keep everything single threaded and usethe default DispatchQueue. If you want to create a new DispatchQueuejust for interrupt handling, that's supported as well.Next we will create the dispatch source by specifying the interruptersfor the PCI device at the interrupt index we found earlier, and our defaultDispatchQueue. Then we'll need to create an interrupt action for our newly createdsource to use to handle the interrupts. Once the source is enabled, ourinterrupt handler will get called when our device triggers an interrupt.Lastly we'll go over how to set up a DMA transfer for your PCI device. First we'llcreate a buffer memory descriptor. We'll need to set the length of thebuffer prior to writing to the buffer. And then here's an example of howyou can take the virtual address of our segment and write some data to it.Next, in order to give the PCI device access to our buffer, we'll need tocreate an IODMACommand. First we'll set up the DMA specification thatdescribes our hardware's DMA capabilities. Then we'll create the IODMACommandspecifying this is for our PCI device. This is to ensure the correctmemory mapper is used for all of your transfers.Next we're going to take the DMACommand and prepare our buffer memorydescriptor so we get a physical address to give to our PCI device.Then we can use the result of the physicalAddressSegment to get the buffer'sphysical address to write it to our PCI device. Once our transfer is finishedwe'll need to call Complete on our DMA command so that the physical memory canbe used by another process or device. That was a brief introduction tothe new PCIDriverKit framework. Now I'd like to hand it over to Madhu,who will be going into detail on how to write a SCSI driver using DriverKit.Hi, I'm Madhu and I'm going to be talking about the SCSIControllerDriverKit.framework. It's a brand new framework in DriverKit to build driver extensionsfor SCSI controllers. Let's start with an overview. SCSIControllerDriverKitframework is available today in macOS Big Sur. It supports allIOKit-based device-driver featuresthat SCSI kexts had supported in the past. This framework is goingto serve as a replacement for IOSCSIParallelInterfaceController implementationwhich was being used until now for kext development. The framework has beenbuilt keeping performance as a top priority. It is highly optimized tominimize interactions between the user space and the kernel in the I/O performance path.It can support a variety of SCSI based devices like Fibre Channel controllers,RAID Controllers, serial attached SCSI, and more. Since these will be PCIe basedcontrollers, we've made sure our framework is fully compatible with the PCIDriverKit framework.IOUserSCSIParallelInterfaceController is a new class defined in the iiginterface file. SCSI dexts are required to subclass this and implementits functions. Now we have tried to maintain similar API structure herecompared to the kernel class, with the prefix "User" added to API names.For example, UserProcessParallelTask is the new API, dexts need to implementto submit I/O requests to the hardware. It is quite simple to determinewhich framework functions to override in the dext. Just override all thefunctions that are marked pure virtual. These functions are calls made bythe framework into the dext to get controller specific information or to performspecific tasks. For example the framework calls UserDoesHBAPerformAutoSenseto check if the HBA supports auto-sense. It calls UserInitializeControllerto initialize the controller and dext data structures. All non pure virtualfunctions get invoked by the dext to perform specific tasks like creatinga SCSI target with a unique ID, or setting target properties for a specific target.The implementations of these functions will be present in the kernel.Like we already know, entitlements are required to be added before we build andload driver extensions. Other than the generic DriverKit entitlement andthe transport-specific entitlement, we have added a new family entitlementfor SCSI controllers. A SCSI dext needs to add this entitlement torun and have full access to the framework. With that, let's create an exampleSCSI dext. I have divided this into four important phases. In each phase,I will show how to override some important functions,discuss some guidelines, and share some performance tips. Let's begin withstart and initialization. The kernel is going to control the start andinitialization phase of the dext by making a whole bunch of calls.Other than making calls to initialize the controller, it is also going tobe making a number of calls to gather controller specific information likemaximum task count supported, highest supported device ID, etc, and sets upall the kernel data structures accordingly. Let's see what happens whena SCSI controller device is plugged in. IOKit matching kicks off andan IOService object of the type IOUserSCSIParallelInterfaceControllerstarts up in the kernel. IOKit's IOService implementationwill now start creating resources required to start the dext in the user space.It initializes the IOUserServer IPC layer and creates a process hostingthe dext with its DriverKit classes initialized. DriverKit SCSI deviceis loaded and IOUserSCSIParallelInterfaceController willfirst call its Start implementation. It will then call a whole bunch ofother functions like UserInitializeController  and UserStartControllerto finish the Start and initialization phase.Let's start implementing. I'm only going to be discussing some importantframework functions that the dext needs to implement. The first one beingUserInitializeController. We are first going to be opening a new sessionwith PCIDriverKit like Kevin discussed before. The DriverKit framework alreadycreates a default DispatchQueue for us. We are going to be creating andsetting up two additional DispatchQueues here. We are also going to createan InterruptDispatchSource and register a handler to process interrupts.This brings us to the queuing model we would like you to follow while buildingyour dext. We suggest having three DispatchQueues in total — the DefaultQueue, which is created for you by the DriverKit environment, additionally anInterrupt Queue and an Auxiliary Queue. Default Queue will run all the callsthat originate from the kernel — for example, UserInitializeController,UserProcessParallelTask, and so on. It helps to have a separate queueto service interrupts. Since DriverKit dispatch queues are serial, interruptsand I/Os won't be competing with each other to run.This will give a huge performance boost as well. This queue can also beused to service dexts' IOTimeoutHandlers. A separate Auxiliary Queueneeds to be setup to create SCSI targets. As part of creating targets,kernel makes a number of calls to the dext to help initialize the target.Since these calls will run on the Default Queue the dext needs to createthe SCSI target from a separate Auxiliary Queue. The kernel is going tobe maintaining a list of IODMACommands, SCSIParallelTask in this case,based on the total outstanding commands the controller can support at a time.Every time it creates a new SCSIParallelTask object, it callsUserMapHBAData implementation of the dext. The dext can use this opportunityto create its controller-specific taskData structure. And maintain alist of them. Here are some implementation details of my example SCSI dext.I have created an idle buffer memory descriptor object for my controller-specific taskData structure. I have also mapped the buffer memory descriptorin my dext's address space. It is important to do any kind of pre-processinglike this here before we start serving I/Os. Doing this in the I/O pathcan negatively impact performance. I add this task data to my taskData list.I also assign a unique taskID to this task so that the kernel can correlatethis with its corresponding SCSIParallelTask object. Next, in my UserStartControllerimplementation I enable interrupts on the hardware. I thenenable the interrupt dispatch source. Returning Success from UserStartControllerindicates to the kernel the dext is up and ready to serve I/Os.That brings us to the most interesting part of any storage driver, the I/O path.Let's first refresh our memory a little and review how this works in the kernel today.Before, the kext would override the function ProcessParallelTask and wouldhave access to SCSIParallelTask object. SCSIParallelTask is asubclass of IODMACommand. The kext was responsible to prepare the IODMACommandand generate physical segments for DMA to happen. It would callCompleteParallelTask once it receives the interrupt completion for the I/O.We have changed a whole lot of this behavior with the dext. The kernel willnow call the dext's UserProcessParallelTask implementation to submit an I/O.As part of this call, it'll send a copy of SCSIUserParallelTask object tothe dext.This object will contain all the information the dext will need to performthis I/O, and the dext will not have to make any more calls to the kernel.Like I mentioned in the beginning, this framework has been built keepingI/O performance as a top priority. Note that the dext does not have accessto SCSIParallelTask object. The kernel will do all of the heavy liftingof preparing the IODMACommand and generating physical segments for the dext.This way of letting the kernel handle all of the operations required to preparean I/O for DMA, has obvious performance benefits. Preparing an IODMACommandin the user space will result in additional IPC calls being made to thekernel and we would want to avoid that at any cost in the performance path.After the I/O is submitted, dext's interrupt handler gets invoked wheneverthe hardware sends an interrupt completion. It will then have to callParallelTaskCompletion which is an OS action callback to complete this I/O.Here are the two main functions we need to care about. The dext needs toimplement UserProcessParallelTask function for I/O submission, and needsto call ParallelTaskCompletion to indicate I/O completion. We already discussedabout SCSIUserParallelTask a little. As we can see it contains a lot of informationabout an I/O like the CDB, data transfer count, data transfer direction, etc.An important field in this structure is fBufferIOVMAddr. Like I mentionedbefore the kernel generates DMA physical segment for us, fBufferIOVMAddr isgoing to be the start physical address of this segment. It is guaranteedthat the kernel is going to generate one long contiguous segment that canfit all of the buffer data.The dext needs to send this response object as part of ParallelTaskCompletion callback.It needs to have all the relevant information for the specific I/O completion,like completion status, number of bytes transferred, etc. And sense data,If any.Let's look at our example implementation. I first fetch the specific taskDatafor the taskID from my list. I set all the metadata for this I/Oin my taskData. The kernel is going to generate one long physical segmentwith fBufferIOVMAddr as the start address. Feel free to prepare yourown ScatterGatherList if your hardware specification requires you tochop this up into multiple segments. I retain and stash away the completioncallback object for later. I post a request to the hardware, and send anappropriate response back to the kernel. Once I receive an interrupt completion,I process the interrupt response and fill out the SCSIUserParallelResponse structure.I then invoke the completion callback. We now have I/O submission andcompletion logic implemented in our example dext. Let's move on to thenext phase of our driver development: power management. Supporting power statetransitions in DriverKit is as simple as overriding SetPowerState functionand implementing your hardware-specific functionalities for every powerstate supported. DriverKit framework today supports three power states: an off statean on state, and a low-power state. For PCIe-based devices we need to mainlycare about the off and the on states. Off state for when device is enteringsleep state, like during system sleep or even doing a PCI pause operation.And on state for when device is fully powered on, called during System Wake.Delayed acknowledgement of power state transition is also possible in DriverKit.Let's look at an example. Here I have overridden SetPowerState and to keep itbrief I have only shown PowerStateOn transition. For my hardware I'm goingto be issuing a hard reset to change the power state to on. I then returnthe call back to the kernel. Since I issued a hard reset my driver startsa complete SCSITargetRescan on the hardware. I make sure all my targetsare up and then acknowledge the power state transition by issuing a SUPERDISPATCHSetPowerState call. I now have power management support implemented inmy example dext. Let's finish by discussing termination. DriverKit terminationis quite straightforward. Just override Stop method and tear everythingdown in there. We have made it simpler for you.The dext is not responsible for completing any outstanding I/O requests.The kernel handles all of that for you. Let's look at an example. In myStop implementation I first close my outstanding PCI session. I then cancelall of my dispatch queues and sources. I release them in a finalize codeblock which gets called by the framework once the Cancel call completes.That's it! We now have all the major features of our example SCSI dext implemented.Now I know what you all must be thinking — here we have a system where everysingle I/O that is coming down from the file system in the kernel gets sentto the dext running in the user space via an IPC call. The interrupt handleris getting invoked via an IPC call from the kernel.And the dext I/O completion is sent from user space back to the kernel viaan IPC call. This sounds like a lot of overhead. Will this affect mydext's performance? Will my dext be able to achieve the same throughputas my kext? Can I still run pro workloads on these devices like I used to?These are all great questions. We had the same concerns when we starteddeveloping this framework. Like I have mentioned a couple of times already,we designed and implemented this framework keeping performance as a top priority.I'm happy to report that SCSIControllerDriverKit can handle thesame workloads as kexts. Let's run a realistic workload on our example SCSIdext and see how it performs. My device setup includes a four gigabits-per-second Fibre Channel host bus adapter connected to a RAID disc array.I have connected this setup to a MacBook Pro here via Thunderbolt 3.To build and install my example SCSI dext I made sure I added all therequired entitlements and packaged it inside a System Extension app.I also made sure my System Extension app created an activation request duringapp launch so that my dext is available right away. I then built my SystemExtension app and code signed it appropriately. I have already installedmy System Extension app on this system.Let's peek into the I/O registry and see if our dext has matched. There it is:our example SCSI dext has started successfully and is running.Our Fibre Channel controller in this case is actually a multifunction PCI device,so we see two separate instances of ExampleSCSIDext running.Let's open Disk Utility to see if our dext is providing any disks. Looks like wehave one external disk here with a Fibre Channel interface. The disk isformatted to have one APFS volume, the volume is already mounted aswe can see here on the Desktop. We thought it would be a great idea todemonstrate performance by running an actual pro workload. I have a FinalCut Pro library on this external SCSI disk, let's open that.Video processing and playback can be CPU and disc intensive. While servingI/Os if our dext's CPU utilization increases for any reason it is going toshow. Our dext process can steal CPU time from the actual video playbackwhich would result in frame drops. Our goal here is to make sure our dextis able to stream this video without any frame drops. Just to be surewe'll see if this happens, I'll enable this option here so that we getwarned about frame drops because of disc performance. Let's start playingthe video.I'm also going to open Activity Monitor on the side so we can see disk usage.I have already selected the Final Cut Pro process here. We have this beautifulvideo playing in Apple ProRes format. This video has a maximum disc throughputof around 350 megabytes per second which is quite close to the maximumthroughput that our four gigabits-per-second Fibre Channel controller can support.Our dext is doing great so far.This entire video was streamed from our example SCSI dext running in user space.How cool is that? And we did not get alerted of any frame drops, which meansour dext was able to handle this pro workload like a pro. There we have it.All the advantages of DriverKit like security, ease of development, anddebugging, without compromising on performance. So that was a brief overviewof SCSIControllerDriverKit framework. A brand-new framework tobuild driver extensions for SCSI controllers. Back to you, Kevin. Thanks, Madhu.Today we briefly went over DriverKit System Extensions and saw how youcan adopt the new PCIDriverKit and SCSIControllerDriverKit frameworksfor your devices. We went over an in-depth example of writing a SCSIcontroller driver over PCI and got to see a real-world demo of how youcan use these frameworks. With the new SCSI controller and PCIDriverKitframeworks, SCSI controller and PCI kernel drivers are now deprecatedwhen a System Extension can perform the same function. For an in-depthlook at DriverKit, please check out last year's System Extensions and DriverKitsession on the Developer website. I encourage developers to startadopting DriverKit immediately for the device families that are available.Please go and download the latest DriverKit SDK and let us know any feedbackyou have through Feedback Assistant. We'd love to hear from you and areexcited to see what you'll create.

Hello and welcome to WWDC.Hi my name is Kevin and I'll be joined later by my colleague Madhu.Today we'll be going over what's new in DriverKit.First I will give a brief recap of System Extensions with DriverKit.Then I'll talk about the new PCIDriverKit framework. Then I'll hand it overto Madhu who'll be going in-depth on writing a SCSI Controller driverusing PCIDriverKit and the new SCSIControllerDriverKit framework.

Then she'll be showing us a demo of these new frameworks in action.

Finally I'll wrap things up with a summary of everything that we went over today.Last year we introduced DriverKit, a replacement for IOKit device drivers.DriverKit brought a new way to extend the operating system that is morereliable, more secure, and easier to develop. Driver extensions allow developersto make powerful and innovative apps without the pitfalls of writing codethat runs in the kernel. For an in-depth look at DriverKit and how itworks please check out last year's video titled System Extensions andDriverKit on the Apple Developer website. DriverKit System Extensionsrun in user space, not kernel space. Like other apps they have to followthe rules of the system security policy. Unlike other apps, System Extensionsare granted special privileges to do special jobs. For example they havedirect control of specific hardware devices or special APIs to interfacedirectly with the kernel. Because DriverKit drivers are in user space,their access is limited and the resources are separate from the rest ofthe systems resources. When a driver extension crashes, the kernel andthe rest of the system keep running. The development cycle is much faster.We can build, test, and debug on one machine whereas kernel extensions bringalong security implications — a bug in a kext can compromise the entire kernel.A kext has access to all of the computers resources, not just a specific pieceof hardware or resource. When a kernel extension crashes, the kernelpanics and takes down the entire machine. Debugging and development canbe slow. We need multiple machines and we'll need to reboot on every crash.Another great benefit to driver extensions is installation is much easier.Your driver extension stays in your app bundle. You should not copy yourdriver extension directly to any system folders. To install your app you'lluse SystemExtensions framework and create an activationRequest, to requestthe extension to be made available to the system. A system administratorwould need to approve this request. Most apps should create anactivationRequest during app launch so the extension is made available right away.However, you may wish to activate your System Extension at different pointsin your app's lifecycle such as after the user has agreed to a licenseagreement, or made an in-app purchase if that's required for your system extension.

You can get started writing DriverKit drivers right away before they'reready to go into the App Store without a provisioning profile. To do this,you'll need to disable system integrity protection, sign your dexts torun locally, and be sure to include all the entitlements needed for your driver.

Last year when DriverKit first launched, there was support for USB, serial,network interface controllers, and human interface devices. Then later PCIsupport was introduced. And now SCSI Controller support has been added as well.

Because DriverKit brings so many great improvements over kernel extensions,we recommend migrating to DriverKit immediately for available frameworks.

Catalina was the last released to fully support kexts without any compromises.We've begun deprecating kernel extensions that can perform the same functionas a system extension including the device families supported by DriverKit.In macOS Big Sur, kexts that were deprecated in macOS Catalina will not loadby default. We will continue to add more types of system extensions andmore device families to DriverKit. In turn, kernel extensions of these kindswill also be deprecated. This year we have added support for PCI and SCSIController drivers. This means kext support is now deprecated for PCI andSCSI controller device families, for kernel extensions that can performthe same function as a system extension. This also means PCI and SCSIcontroller kexts will not load by default in a future macOS release.

Now we'll talk about one of the exciting new additions to DriverKit:PCIDriverKit. I'll show you some of the key differences and driver modelsbetween PCI driver extensions and kernel extensions. Then I'll be showingsome code examples almost every PCIDriverKit driver will need. PCIeis used to expand the capabilities of a machine as though they are builtinto the system. PCIe brings a lot of advantages as it can handle themost demanding high performance jobs.Some common PCIe devices include serial, Ethernet, and SCSI controllers.

Users can add PCIe devices through Thunderbolt or through PCIe slots suchas in the latest Mac Pro. As with all driver extensions PCIDriverKit requiresentitlements to grant access to your PCI devices. This is to ensure anotherapp or malicious software can not access your PCI device. The new entitlementuses the same IOPCIFamily driver-matching criteria as the Info.plist.However you can make the entitlements more generic if you need to supportmultiple devices. In this example, I have an entitlement that will allowyou to access any device with a provided vendor ID. In this case we'regoing to use ABCD. The PCI entitlement takes a list of PCI matching dictionaries.You can be as specific or generic as you want by using the IOPCIFamily matching categories.

In this case we're doing a primary match which means we'll be comparingthe primary vendor ID and device ID of the device to the entry that wehave in our dictionary.

By using the ampersand we can have a mask that allows the matching dictionaryto be more generic. This effectively removes the device ID from the matchingdictionary allowing the driver extension to be entitled for all devicesof this vendor ID.

With PCIDriverKit you will likely need to interact with one of themany other DriverKit frameworks. This is an example of what your entitlementswill be if you wanted to write a custom Ethernet NIC driver. In thiscase you'll add the networking family entitlement. With this family entitlement,you can now use the Networking DriverKit framework to interact with a networkingstack as well. With PCIDriverKit the only class in the framework is theIOPCI device. This class is not intended to be subclassed. You'll usethis class as the PCI provider to access all of your PCI resources.Here's what your driver extension may look like using our network interface controller example.

The user space IOPCIDevice will do the PCI-related communication neededwith the kernel. Your driver will use the IOPCI device for any PCI resource access.

Your driver can then use the PCI device resources to talk to the networkingfamily and other user clients. The layering structure for the driver extensionis mostly the same as the kernel extension, however almost everything isuser space. While encouraged in kernel extensions, PCIDriverKit mandates thatprior to accessing the PCI device you must successfully call Open on the device.Once Open return successfully, your driver has exclusive access to the PCI device.If your device has resources that are intended to be shared by multipleclients, you will need to design your driver extension in a way that hasa single PCI resource manager that distributes its resources amongst allof its clients. This is to enforce good design and allows the systemto handle driver extension crashes more gracefully. When done using the devicesuch as during the driver stop routine, You'll need to call Close on the device.You should not expect the state of the device to remain after calling Close.For instance the PCI stack will disable bus mastering and memory spaceonce Close has successfully completed. Another driver may open the deviceand change its state if it's entitled to do so. Another difference betweenPCI kernel extensions and PCIDriverKit is that PCIDriverKit frameworktakes care of all the device mappings for you. There are new APIs thatall memory accesses will use. This allows developers to take advantageof any future optimizations Apple may explore. It removes the need forany device memory management and will also allow more observeabiltty anddebuggability. With a single point of access You can now use programs suchas dtrace to observe all device memory accesses. This can be especiallyhelpful when debugging PCI issues in a multi-threaded environment.The APIs work by passing a memory index of the memory space you wish to accessalong with the offset. I will go over what the difference between a memoryindex is versus a base address register index now. This is a diagram ofthe PCI device's base address registers or BARs. For 32-bit BARs, the memoryIndexand the BAR index are the exact same.For example with 32-bit addresses, if you want to access BAR2 you'd use2 as the memoryIndex because it's the same index into the device'sBAR space. 64-bit BARs are where the memoryIndex and BAR index can differ. ThememoryIndex is the index for each memory entry. All memory indexes are base zero.

So, for example, if BAR0 and BAR1 combined are one 64-bit address, your memoryIndexwould be 0 because it's the first memory entry. Then if BAR2and BAR3 are another 64-bit address, they'd be at memoryIndex=1because it's the second memory entry in the device's BAR table.Accessing configuration space of your device is mostly a one-to-one mapping andstill works the same with just a new name. The major difference betweenPCIDriverKit and kernel extensions for configuration space is thatyou will first need to have an open session to read or write any configurationspace registers. Next I'll be going over some examples of common code you'lllikely need. First is how you enable bus mastering and memory space.These will be needed in order to access memory on your device, along withenabling your device to issue I/O. Previously there were explicit kernel APIsfor each of these operations. Now, in order to achieve the same result,you'll first read the command register and write back to it with the bus masterand memory space bit set. This example is what most PCI drivers will look like.In their Start routine, they will first start a session with the PCI provider.Then they will read the PCI device's command register. Set the bus masterand memory enable bits, then write the values back to the PCI device.This will need to be done before issuing any memory reads or writes.All these offsets and definitions can be found in the PCIDriverKit frameworkheaders. To disable bus mastering the processes are the same but insteadof setting the bits, the driver will mask them out. In this example, Close isalso called in the Stop routine. This means that we are done talkingto the PCI device and can close our session. Now we'll be going over how tosetup an interrupt handler. First we'll need to declare an InterruptOccuredmethod in our iig header file. Then the definition of our interrupt handlerwill be using an implementation definition. In this example when we getan interrupt the handler will clear the interrupt by writing a registerin MMIO space to one of the device's memory indexes. Now we need to dothe setup to make it so our interruptOccurred method gets called when aninterrupt fires. First thing we'll need to do is find out which interrupt indexwe want to use. To do this we'll iterate through all the interrupt indexesassociated with the PCI device. Then we'll check its interruptType. In this examplewe want to handle the device's msiInterrupts. So that means we wantto break out of the loop once we found the interrupt index that supports MSIs.

Then we'll need to choose which DispatchQueue the interrupt will be handled in.

For this example we're going to keep everything single threaded and usethe default DispatchQueue. If you want to create a new DispatchQueuejust for interrupt handling, that's supported as well.

Next we will create the dispatch source by specifying the interruptersfor the PCI device at the interrupt index we found earlier, and our defaultDispatchQueue. Then we'll need to create an interrupt action for our newly createdsource to use to handle the interrupts. Once the source is enabled, ourinterrupt handler will get called when our device triggers an interrupt.Lastly we'll go over how to set up a DMA transfer for your PCI device. First we'llcreate a buffer memory descriptor. We'll need to set the length of thebuffer prior to writing to the buffer. And then here's an example of howyou can take the virtual address of our segment and write some data to it.

Next, in order to give the PCI device access to our buffer, we'll need tocreate an IODMACommand. First we'll set up the DMA specification thatdescribes our hardware's DMA capabilities. Then we'll create the IODMACommandspecifying this is for our PCI device. This is to ensure the correctmemory mapper is used for all of your transfers.

Next we're going to take the DMACommand and prepare our buffer memorydescriptor so we get a physical address to give to our PCI device.Then we can use the result of the physicalAddressSegment to get the buffer'sphysical address to write it to our PCI device. Once our transfer is finishedwe'll need to call Complete on our DMA command so that the physical memory canbe used by another process or device. That was a brief introduction tothe new PCIDriverKit framework. Now I'd like to hand it over to Madhu,who will be going into detail on how to write a SCSI driver using DriverKit.Hi, I'm Madhu and I'm going to be talking about the SCSIControllerDriverKit.framework. It's a brand new framework in DriverKit to build driver extensionsfor SCSI controllers. Let's start with an overview. SCSIControllerDriverKitframework is available today in macOS Big Sur. It supports allIOKit-based device-driver featuresthat SCSI kexts had supported in the past. This framework is goingto serve as a replacement for IOSCSIParallelInterfaceController implementationwhich was being used until now for kext development. The framework has beenbuilt keeping performance as a top priority. It is highly optimized tominimize interactions between the user space and the kernel in the I/O performance path.

It can support a variety of SCSI based devices like Fibre Channel controllers,RAID Controllers, serial attached SCSI, and more. Since these will be PCIe basedcontrollers, we've made sure our framework is fully compatible with the PCIDriverKit framework.

IOUserSCSIParallelInterfaceController is a new class defined in the iiginterface file. SCSI dexts are required to subclass this and implementits functions. Now we have tried to maintain similar API structure herecompared to the kernel class, with the prefix "User" added to API names.For example, UserProcessParallelTask is the new API, dexts need to implementto submit I/O requests to the hardware. It is quite simple to determinewhich framework functions to override in the dext. Just override all thefunctions that are marked pure virtual. These functions are calls made bythe framework into the dext to get controller specific information or to performspecific tasks. For example the framework calls UserDoesHBAPerformAutoSenseto check if the HBA supports auto-sense. It calls UserInitializeControllerto initialize the controller and dext data structures. All non pure virtualfunctions get invoked by the dext to perform specific tasks like creatinga SCSI target with a unique ID, or setting target properties for a specific target.The implementations of these functions will be present in the kernel.Like we already know, entitlements are required to be added before we build andload driver extensions. Other than the generic DriverKit entitlement andthe transport-specific entitlement, we have added a new family entitlementfor SCSI controllers. A SCSI dext needs to add this entitlement torun and have full access to the framework. With that, let's create an exampleSCSI dext. I have divided this into four important phases. In each phase,I will show how to override some important functions,discuss some guidelines, and share some performance tips. Let's begin withstart and initialization. The kernel is going to control the start andinitialization phase of the dext by making a whole bunch of calls.

Other than making calls to initialize the controller, it is also going tobe making a number of calls to gather controller specific information likemaximum task count supported, highest supported device ID, etc, and sets upall the kernel data structures accordingly. Let's see what happens whena SCSI controller device is plugged in. IOKit matching kicks off andan IOService object of the type IOUserSCSIParallelInterfaceControllerstarts up in the kernel. IOKit's IOService implementationwill now start creating resources required to start the dext in the user space.

It initializes the IOUserServer IPC layer and creates a process hostingthe dext with its DriverKit classes initialized. DriverKit SCSI deviceis loaded and IOUserSCSIParallelInterfaceController willfirst call its Start implementation. It will then call a whole bunch ofother functions like UserInitializeController  and UserStartControllerto finish the Start and initialization phase.

Let's start implementing. I'm only going to be discussing some importantframework functions that the dext needs to implement. The first one beingUserInitializeController. We are first going to be opening a new sessionwith PCIDriverKit like Kevin discussed before. The DriverKit framework alreadycreates a default DispatchQueue for us. We are going to be creating andsetting up two additional DispatchQueues here. We are also going to createan InterruptDispatchSource and register a handler to process interrupts.

This brings us to the queuing model we would like you to follow while buildingyour dext. We suggest having three DispatchQueues in total — the DefaultQueue, which is created for you by the DriverKit environment, additionally anInterrupt Queue and an Auxiliary Queue. Default Queue will run all the callsthat originate from the kernel — for example, UserInitializeController,UserProcessParallelTask, and so on. It helps to have a separate queueto service interrupts. Since DriverKit dispatch queues are serial, interruptsand I/Os won't be competing with each other to run.

This will give a huge performance boost as well. This queue can also beused to service dexts' IOTimeoutHandlers. A separate Auxiliary Queueneeds to be setup to create SCSI targets. As part of creating targets,kernel makes a number of calls to the dext to help initialize the target.

Since these calls will run on the Default Queue the dext needs to createthe SCSI target from a separate Auxiliary Queue. The kernel is going tobe maintaining a list of IODMACommands, SCSIParallelTask in this case,based on the total outstanding commands the controller can support at a time.

Every time it creates a new SCSIParallelTask object, it callsUserMapHBAData implementation of the dext. The dext can use this opportunityto create its controller-specific taskData structure. And maintain alist of them. Here are some implementation details of my example SCSI dext.

I have created an idle buffer memory descriptor object for my controller-specific taskData structure. I have also mapped the buffer memory descriptorin my dext's address space. It is important to do any kind of pre-processinglike this here before we start serving I/Os. Doing this in the I/O pathcan negatively impact performance. I add this task data to my taskData list.I also assign a unique taskID to this task so that the kernel can correlatethis with its corresponding SCSIParallelTask object. Next, in my UserStartControllerimplementation I enable interrupts on the hardware. I thenenable the interrupt dispatch source. Returning Success from UserStartControllerindicates to the kernel the dext is up and ready to serve I/Os.

That brings us to the most interesting part of any storage driver, the I/O path.

Let's first refresh our memory a little and review how this works in the kernel today.

Before, the kext would override the function ProcessParallelTask and wouldhave access to SCSIParallelTask object. SCSIParallelTask is asubclass of IODMACommand. The kext was responsible to prepare the IODMACommandand generate physical segments for DMA to happen. It would callCompleteParallelTask once it receives the interrupt completion for the I/O.We have changed a whole lot of this behavior with the dext. The kernel willnow call the dext's UserProcessParallelTask implementation to submit an I/O.

As part of this call, it'll send a copy of SCSIUserParallelTask object tothe dext.

This object will contain all the information the dext will need to performthis I/O, and the dext will not have to make any more calls to the kernel.

Like I mentioned in the beginning, this framework has been built keepingI/O performance as a top priority. Note that the dext does not have accessto SCSIParallelTask object. The kernel will do all of the heavy liftingof preparing the IODMACommand and generating physical segments for the dext.

This way of letting the kernel handle all of the operations required to preparean I/O for DMA, has obvious performance benefits. Preparing an IODMACommandin the user space will result in additional IPC calls being made to thekernel and we would want to avoid that at any cost in the performance path.

After the I/O is submitted, dext's interrupt handler gets invoked wheneverthe hardware sends an interrupt completion. It will then have to callParallelTaskCompletion which is an OS action callback to complete this I/O.

Here are the two main functions we need to care about. The dext needs toimplement UserProcessParallelTask function for I/O submission, and needsto call ParallelTaskCompletion to indicate I/O completion. We already discussedabout SCSIUserParallelTask a little. As we can see it contains a lot of informationabout an I/O like the CDB, data transfer count, data transfer direction, etc.

An important field in this structure is fBufferIOVMAddr. Like I mentionedbefore the kernel generates DMA physical segment for us, fBufferIOVMAddr isgoing to be the start physical address of this segment. It is guaranteedthat the kernel is going to generate one long contiguous segment that canfit all of the buffer data.

The dext needs to send this response object as part of ParallelTaskCompletion callback.

It needs to have all the relevant information for the specific I/O completion,like completion status, number of bytes transferred, etc. And sense data,If any.

Let's look at our example implementation. I first fetch the specific taskDatafor the taskID from my list. I set all the metadata for this I/Oin my taskData. The kernel is going to generate one long physical segmentwith fBufferIOVMAddr as the start address. Feel free to prepare yourown ScatterGatherList if your hardware specification requires you tochop this up into multiple segments. I retain and stash away the completioncallback object for later. I post a request to the hardware, and send anappropriate response back to the kernel. Once I receive an interrupt completion,I process the interrupt response and fill out the SCSIUserParallelResponse structure.

I then invoke the completion callback. We now have I/O submission andcompletion logic implemented in our example dext. Let's move on to thenext phase of our driver development: power management. Supporting power statetransitions in DriverKit is as simple as overriding SetPowerState functionand implementing your hardware-specific functionalities for every powerstate supported. DriverKit framework today supports three power states: an off statean on state, and a low-power state. For PCIe-based devices we need to mainlycare about the off and the on states. Off state for when device is enteringsleep state, like during system sleep or even doing a PCI pause operation.

And on state for when device is fully powered on, called during System Wake.Delayed acknowledgement of power state transition is also possible in DriverKit.Let's look at an example. Here I have overridden SetPowerState and to keep itbrief I have only shown PowerStateOn transition. For my hardware I'm goingto be issuing a hard reset to change the power state to on. I then returnthe call back to the kernel. Since I issued a hard reset my driver startsa complete SCSITargetRescan on the hardware. I make sure all my targetsare up and then acknowledge the power state transition by issuing a SUPERDISPATCHSetPowerState call. I now have power management support implemented inmy example dext. Let's finish by discussing termination. DriverKit terminationis quite straightforward. Just override Stop method and tear everythingdown in there. We have made it simpler for you.

The dext is not responsible for completing any outstanding I/O requests.

The kernel handles all of that for you. Let's look at an example. In myStop implementation I first close my outstanding PCI session. I then cancelall of my dispatch queues and sources. I release them in a finalize codeblock which gets called by the framework once the Cancel call completes.That's it! We now have all the major features of our example SCSI dext implemented.

Now I know what you all must be thinking — here we have a system where everysingle I/O that is coming down from the file system in the kernel gets sentto the dext running in the user space via an IPC call. The interrupt handleris getting invoked via an IPC call from the kernel.

And the dext I/O completion is sent from user space back to the kernel viaan IPC call. This sounds like a lot of overhead. Will this affect mydext's performance? Will my dext be able to achieve the same throughputas my kext? Can I still run pro workloads on these devices like I used to?These are all great questions. We had the same concerns when we starteddeveloping this framework. Like I have mentioned a couple of times already,we designed and implemented this framework keeping performance as a top priority.

I'm happy to report that SCSIControllerDriverKit can handle thesame workloads as kexts. Let's run a realistic workload on our example SCSIdext and see how it performs. My device setup includes a four gigabits-per-second Fibre Channel host bus adapter connected to a RAID disc array.I have connected this setup to a MacBook Pro here via Thunderbolt 3.

To build and install my example SCSI dext I made sure I added all therequired entitlements and packaged it inside a System Extension app.I also made sure my System Extension app created an activation request duringapp launch so that my dext is available right away. I then built my SystemExtension app and code signed it appropriately. I have already installedmy System Extension app on this system.

Let's peek into the I/O registry and see if our dext has matched. There it is:our example SCSI dext has started successfully and is running.Our Fibre Channel controller in this case is actually a multifunction PCI device,so we see two separate instances of ExampleSCSIDext running.Let's open Disk Utility to see if our dext is providing any disks. Looks like wehave one external disk here with a Fibre Channel interface. The disk isformatted to have one APFS volume, the volume is already mounted aswe can see here on the Desktop. We thought it would be a great idea todemonstrate performance by running an actual pro workload. I have a FinalCut Pro library on this external SCSI disk, let's open that.

Video processing and playback can be CPU and disc intensive. While servingI/Os if our dext's CPU utilization increases for any reason it is going toshow. Our dext process can steal CPU time from the actual video playbackwhich would result in frame drops. Our goal here is to make sure our dextis able to stream this video without any frame drops. Just to be surewe'll see if this happens, I'll enable this option here so that we getwarned about frame drops because of disc performance. Let's start playingthe video.

I'm also going to open Activity Monitor on the side so we can see disk usage.

I have already selected the Final Cut Pro process here. We have this beautifulvideo playing in Apple ProRes format. This video has a maximum disc throughputof around 350 megabytes per second which is quite close to the maximumthroughput that our four gigabits-per-second Fibre Channel controller can support.Our dext is doing great so far.

This entire video was streamed from our example SCSI dext running in user space.How cool is that? And we did not get alerted of any frame drops, which meansour dext was able to handle this pro workload like a pro. There we have it.All the advantages of DriverKit like security, ease of development, anddebugging, without compromising on performance. So that was a brief overviewof SCSIControllerDriverKit framework. A brand-new framework tobuild driver extensions for SCSI controllers. Back to you, Kevin. Thanks, Madhu.

Today we briefly went over DriverKit System Extensions and saw how youcan adopt the new PCIDriverKit and SCSIControllerDriverKit frameworksfor your devices. We went over an in-depth example of writing a SCSIcontroller driver over PCI and got to see a real-world demo of how youcan use these frameworks. With the new SCSI controller and PCIDriverKitframeworks, SCSI controller and PCI kernel drivers are now deprecatedwhen a System Extension can perform the same function. For an in-depthlook at DriverKit, please check out last year's System Extensions and DriverKitsession on the Developer website. I encourage developers to startadopting DriverKit immediately for the device families that are available.

Please go and download the latest DriverKit SDK and let us know any feedbackyou have through Feedback Assistant. We'd love to hear from you and areexcited to see what you'll create.

## Code Samples

