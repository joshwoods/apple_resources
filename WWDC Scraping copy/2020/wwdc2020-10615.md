# Wwdc2020 10615

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Build GPU binaries with MetalPower up your shader pipeline with enhancements to the Metal shader compilation model — all leading to a dramatic reduction in Pipeline State Object (PSO) loading time, especially upon first launch. Learn about explicit PSO caching and sharing of GPU binaries using Metal binary archives and dynamic libraries. And we'll detail the toolchain to create libraries and improve your shader compilation workflow.ResourcesCreating a Metal Dynamic LibraryMetalMetal Developer Tools on WindowsHD VideoSD VideoRelated VideosWWDC23Bring your game to Mac, Part 2: Compile your shadersWWDC22Target and optimize GPU binaries with Metal 3WWDC21Discover compilation workflows in MetalWWDC20Bring your Metal app to Apple silicon MacsDebug GPU-side errors in MetalOptimize Metal Performance for Apple silicon Macs

Power up your shader pipeline with enhancements to the Metal shader compilation model — all leading to a dramatic reduction in Pipeline State Object (PSO) loading time, especially upon first launch. Learn about explicit PSO caching and sharing of GPU binaries using Metal binary archives and dynamic libraries. And we'll detail the toolchain to create libraries and improve your shader compilation workflow.

Creating a Metal Dynamic Library

Metal

Metal Developer Tools on Windows

HD VideoSD Video

HD Video

SD Video

Bring your game to Mac, Part 2: Compile your shaders

Target and optimize GPU binaries with Metal 3

Discover compilation workflows in Metal

Bring your Metal app to Apple silicon Macs

Debug GPU-side errors in Metal

Optimize Metal Performance for Apple silicon Macs

Search this video…Hello and welcome to WWDC. Hello and welcome to WWDC. My name is Kyle Piddington,I'm an engineer and Apple's GPUSW Software Technology Group.In this session, my colleague Ravi and I are going to show you some of thenew advancements to ship your new or existing precompiled GPU code.This talk will consist of four parts. First up I'll provide an overview of Metal'scurrent Shader compilation model. Next I'm going to introduce Metal BinaryArchives, a new way for you to take control over shader caching, and shipprecompile GPU executables to your users. I'm excited to share thenew support for dynamic libraries in metal. This feature will allow youto link your compute shaders against utility libraries dynamically.And finally Ravi will present in detail the set of tools that you have in yourWe'll begin with a review of the shader and pipeline compilation processon Apple platforms.As you know the metal shading language is our programming language for shaders.Metal compiles this code into Apple's Intermediate Representation alsoknown as AIR. This can be done off-line, in Xcode, or at runtime on thetarget device itself. Building off-line avoids the runtime cost of compilingsource code to AIR. In both cases, however when creating pipeline state objects.this intermediate representation is further compiled on device to generatemachine specific code needed for each particular GPU. This process occursfor every pipeline state. To accelerate recompilation and recreation ofpipelines we cache the Metal Function variants produced in this step forfuture pipeline creation. This process is great, and has served us wellof building pipeline objects early on to provide a hitch-free experience,this process can potentially result in long loading screens.Additionally under this model apps are unable to re-use any previously generated machinecode subroutines across different pipeline state objects. We've gathered feedbackcoming in from our ecosystem of developers and have been able to identifya concrete set of needs that would enable you to address these challenges.You might want a way to save the entire time cost of pipeline state compilation,from source, to AIR, to a GPU binary. You might also want a mechanism thatenables sharing common subroutines and utility functions without the needof compiling the same code twice or having it loaded in memory more than once.Having the ability to ship apps that already include the final compiledcode for executables as well as libraries, gives you the tools to providea fantastic first-time launch experience. And allowing you to share theseexecutables and libraries with other developers make their development easier.One of the ways we're addressing these needs is via the Metal Binary Archives.Since the beginnings of Metal, apps have benefited from a system-wide shadercache that accelerates creating pipeline objects that have been createdfrom previous runs of the application. With Metal Binary Archives, explicitcontrol over pipeline state caching is being provided to you. This directcontrol over caching gives you the opportunity to manually collect compiledpipeline state objects, organize them into different archives based offyour usage or need, and even harvest them from a device and distributethem to other compatible devices. Binary archives can be thought of asany other asset type. You have full control over the binary archive lifetimesand these persist as long as desired. Binary Archives are a feature ofthe Metal GPU family, Apple3 and Mac1. Creating a binary archiveis simple. For this feature, we created a new descriptor type for binary archives.I use this descriptor to create a new MTLBinaryArchive from the device.This descriptor contains a URL property and this is used to determineif I want to create a new, empty archive or if I want to load one from disk.When we request a new archive be loaded, this file will be memory-mappedin and we can immediately start to use these loaded archives to accelerateour subsequent pipeline build requests. The binary archive API allows meto directly add pipelines I'm interested in to the archive. I can add Render,Compute, and tileRender pipelines. Adding a pipeline to the binary archivecauses a backend compilation of the shader source, generating the machinecode to be stored in the archive. Finally, once I'm done collecting allthe pipeline objects I'm interested in, I call serializeToURLto save the archive to disk. Once I have my binary archives on disk, I canharvest them from device and deploy them on other compatible devices toaccelerate their pipeline state builds. The only requirement is that theseother devices have the same GPU, and are running the same operating system build.If there's a mismatch the Metal framework will fall back on runtime compilationof the pipeline functions. Once I have my binary archive populated, reusinga cached pipeline is straightforward. When creating a pipeline I set thepipeline descriptor's binary archives property to an array of archives.The framework will then search the array linearly for the function binaries.If the pipeline is found in any of the binary archives on the list it willbe returned to you. Avoiding the compilation process entirely and willnot impact the Metal Shader Cache. In the case of the pipeline is not foundthe OS's MTLCompilerService will kick into gear and compile my AIRsource to machine code, return the result, and cache the result in theMetal Shader Cache. This process takes time but the pipeline will be cashedin the Metal Shader Cache to accelerate any subsequent pipeline build requests.Now that I've gone over the workflow let's take a look at the API to accomplish it.First I create the MTLBinaryArchiveDescriptor. This is used to determinewhether I want to create a new, empty archive or to load an existing one.Creating a binary archive is always done from a descriptor.In this case, I set the URL to nil and the device will create a new,empty archive.Finally I call the function makeBinaryArchive to create it. Next I'll populatea binary archive using pipeline descriptors. I can add Render, Compute andtileRender descriptors to the binary archive. Reusing compiled functionsfrom binary archive allows me to skip the back end function compilation.I can create my pipeline descriptors just as I always have and use thenew binaryArchives property to indicate which archives be searched.I want to do this before creating the pipeline. Once you have collectedall the pipelines you're interested in. You can serialize the binary archiveto a rideable file location on disk. Using the method 'serialize.' Here II'm serializing the archive to my applications 'documents' directory.On the next run of my app I can now deserialize the archive to avoid recompilingthe pipelines that were previously added and serialized. I simplyset the URL to point to the location of an existing pre-populated cacheon disk. Now, one final note about archive search. Depending on your usecase you may find it helpful to be able to short circuit the fallbackbehavior of compiling a pipeline when it's not found in the archive.In this case you can specify the Pipeline. Compile Option failOnBinaryArchiveMiss.If the pipeline is found in any of the archives it is returned to you as usual.However in the case that it's not found the device will return nil.One use case I recommend, is using this workflow for debugging purposes. Avoidingthe compilation process will let you diagnose any problems in your app'slogic, or your archive's data. Let's take a moment to discuss the memoryconsiderations of using binary archives. As mentioned before, it is importantto note that the binary archive file is memory-mapped in. This means thatwe need to reserve a range of virtual memory in order to access the archive's contents.This virtual memory range will be released when you release your cache,so it's important to close any binary archives that are no longer neededfor optimal use of the virtual address space. When collecting new pipelinesBinary Archives present a similar memory footprint to using the system'sMetal Shader Cache. But unlike when using the Metal Shader Cache, we havethe chance to free up this memory. Having explicit control over archivelifetime allows you to serialize and release a Metal Binary Archivewhen you are done collecting pipelined state objects. In addition, when youreuse an existing archive the pipelines in this archive do not count againstyour active app memory. You can serialize and then reopen this archiveand only use it for retrieving cache pipelines, effectively freeing thememory that was used in the collection process. This is not possible whenrelying on the system's Metal Shader Cache. I'd like to wrap up this partof the session by discussing some of the best practices for working withBinary Archives. Although there's no size limit for Binary Archives, I recommenddividing your game assets into several different caches. Games are an excellentcandidate for breaking up caches into a frequently used pipelines andper-level pipelines. Dividing the cache gives you the opportunity to completely releaseno longer needed caches. This will free memory, in case we've collectedany new pipelines as well as a virtual memory range in use. When followingthis guidance, Binary Archives gives you granular control and should befavored over pre-warming the Metal Shader Cache. Modern apps often havetoo many unique permutations of shader variants that are generated basedoff of user choices. With Metal Binary Archives you can now capture themall at runtime. Let's take a look how this all comes together in practice.We've partnered with Epic Games to quantify exactly how reusing apre-harvested binary archive can help improve pipelined state object creationtimes, as well as the developer workflow in the context of Unreal Engine.For this test, we use the pipeline state workload of a AAA title, fortnight.Fortnite is a large game. It's got a big world and many character and itemcustomization options. This makes for a large number of shader functionvariants and pipeline state objects over 11,000 in fact.Epic Games follows the Metal best practices and compiles any needed pipelinestate objects at load time which allows minimizing hitching at runtime,and delivers the smoothest experience possible to users. But apps as wementioned can not benefit from the Metal Shader Cache before it's been populated,so the upfront compilation time adds up potentially making the first timelaunch experience take longer than desired. By preceding a harvested MetalBinary Archive that had collected function variants from seventeen hundredpipelined state objects we observed a massive speedup in the creation timeswhen we compare against starting with an empty Metal Shader Cache. Theseresults are measured on a six core three gigahertz MAC mini with 32 gigabytesof RAM. When we focus on pipeline build times, we go from spending oneminute and twenty six seconds building pipelines to just three seconds.Overall a speed up of over twenty eight times.To summarize Metal Binary Archives allow you to manually manage pipeline caches.These can be harvested from a device and deployed on other, compatible devicesto dramatically reduce the pipeline creation times the first time a gameor app is installed and after a device reboots in the case of iOS.AAA games and other apps bound by a very large number of pipelined stateobjects can benefit from this feature to obtain extra ordinary gains inpipelined creation times under these conditions. Building and shippingGPU executable binaries with your application allows you to accelerateyour first-time launch experience and cold-boot app experiences. I hopeyou take advantage of this new feature. And that's it for Metal Binary Archives.Next I'm going to talk about another new feature we're bringing to thecompilation model, Dynamic Libraries. Metal Dynamic Libraries are a newfeature that will allow you to build well abstracted and reusable computeshader library code for your applications. I'll be discussing the concept,execution, and details of dynamic libraries. Today developers may chooseto create utility libraries of Metal functions to compile with their kernels.Offline compilation can save time while generating these libraries,but there's still two costs that occur when using a utility library.Every app pays the costs of generating machine code for the utility libraryat PSO generation. In addition, compiling multiple pipelines with the sameutility library results in duplicated machine code for subroutines. Thiscan result in longer pipeline load times due to back end compilation andincreased memory usage. And this year we're introducing a solution to this problem.The Metal Dynamic Library. The MTLDynamicLibrary enables you to dynamicallylink, load, and share utility functions in the form of machine code.This code is reusable between multiple compute pipelines eliminating duplicatecompilation and the storing of shared subroutines. In addition much likethe MTLBinaryArchive, the MTLDynamicLibrary is serializable, andshippable as an asset in your application. Before we dive into the API,let's talk about what a MTLDynamicLibrary is. A MTLDynamicLibraryis a collection of exported functions that can be called from multiplecompute pipelines. Later we'll discuss which functions in your dylibare exported and how to manage them. Unlike an executable MTLLibrary,dynamic libraries can not be used to create MTLFunctions. However, standardMTLLibraries can import functions that are implemented in a dynamic library.At pipeline creation time, the dynamic library is linked to resolve anyimported functions much like a dynamic library is used in a typical application.So why might you want to use dynamic libraries. If your application canbe structured into or relies on a shared utility code base, dynamic librariesare for you. Using dynamic libraries in your app prevents recompilingand duplicating machine code across pipeline states. If you're interestedin developing Metal Middleware, dynamic libraries provide you the abilityto ship a utility library to your users. Unlike before where you wouldhave to ship sources to developers or compile their code with a staticMetal library, a dynamic library can be provided and updated without requiringusers to rebuild their own Metallib files. Finally dynamic libraries giveyou the power to expose hooks for your users to create custom kernels.The Metal API exposes the ability to change which libraries are loadedat pipeline creation time allowing you the ability to inject user definedbehavior into your shaders, without creating the MTLLibrary andMTLFunctions containing your entry points. To determine if male dynamic librariesare supported for your GPU, check the feature query 'supportsDynamicLibraries."In the next few slides we'll work through an example of how to create adynamic library, how symbols are resolved, and some more advanced linking scenarios.A standard MTLLibrary is compiled to AIR through either a makeLibrarywith source call at runtime or through compiling your library with theMetal toolchain. To create a MTLDynamicLibrary we begin with a similar workflow.We start by creating a MTLLibrary. But when doing so, we specify thatwe'd like this library to be used as a dynamic library. Next we call thefunction makeDynamicLibrary which will backend compile our Metal codeto machine code. This is the only time you will need to compile the dynamic library.We need one more bit of information: a unique install-name. At pipeline creation time,these names are used by the linker to load the dynamic library. The linkersupports two relative paths @executable_path, which refers to the Metallibcontaining an executable kernel and @loader_path which refers tothe Metallib containing the load command. An absolute path can also be used.With an installName and a libraryType I'm now ready to created a dynamic library.Once I've set the compile options I create a MTLLibrary which willcompile my library from source to AIR. Then I called the API methodmakeDynamicLibrary on the MTLDevice which will compile my dynamic libraryinto machine code. Now that we've covered how to create a dynamic library,let's take a look at how we can use it. In these next few examples,I'll be discussing how we can link dynamic libraries at runtime. These operationscan also be achieved when compiling metal libraries offline. And we'lldiscuss our offline workflow later in the session. To link a dynamic librarywhen compiling a MetalLib from source, add the dynamic library to the 'libraries'property of the MTLCompileOptions, before you compile your library.The specified library will be linked at pipeline creation time. Howeversymbol resolution will be checked at compile time to make sure at leastone implementation of the function exists. To review these steps: when creatinga MetalLib from source, source files should include headers that definefunctions available in your dynamic libraries. At compile time dynamiclibraries included in the 'libraries' option are searched for at least onematching function signature, if no signature is found, compilation willfail explaining which symbols are missing. However, unlike when compilingwith static libraries, or header libraries, this compilation does notbind the function call to the function implementation. At pipeline creation time,libraries are linked and loaded and a function implementation is chosen.We'll go over the case where multiple dynamic libraries export the samefunction in just a moment. In addition to executable MTLLibraries linkingdynamic libraries, dynamic libraries can also reference other dynamic libraries.If all these libraries were created from source at runtime, linking Dylib2to and Dylib3 to Dylib1 is as simple as setting the MTLCcompileOptions'libraries' property on creation. And to reiterate one more time, dylibsare shared between kernels. Although multiple kernels link the same dylib,only one instance of the dylib exists in memory. Because linking isdeferred to pipeline creation time, we can replace functions, or even fulllibraries with new implementations by using the insertLibraries propertyof the compute pipeline descriptor. Setting this option is comparable tosetting the DYLD_INSERT_LIBRARIES environment variable. At pipelinecreation time the linker will first search through inserted libraries tofind imported symbols, before looking through the kernel's linked librariesfor any remaining imported symbols. In this example dylib A exportsthe function foo(). And when we create the compute pipelined state food willbe linked to the implementation in dylib A. When we use insertLibrariesboth dylib A and dylib D export the function foo. When we create thepipeline state, we walk down the list of imported libraries to resolve thesymbol, and instead of linking the implementation of foo() in dylib A, we willinstead link from foo() in dylib D. Finally, let's discuss distributingyour dynamic libraries. Much like Binary Archives, Compiled Dynamic Librariescan be serialized out to URL. Both the pre-compiled binary and the genericAIR for the MTLLibrary are serialized. If you end up distributing thedynamic library as an asset in your project, the metal framework will recompilethe AIR slice into machine code if the target device can not use the pre-compiled binary. This would occur when loading your dylib on a differentarchitecture or OS. This compilation is not added to the Metal ShaderCache so make sure to serialize, and load your library next time to savecompilation time. To help you adopt this API and to work through a small example,we've provided a simple example Xcode project available on developer.apple.com.The sample uses a compute shader to apply a full-screen post processing effect.The compute shader calls into a dynamic library to determine the pixelcolor. At runtime, we demonstrate how insertLibraries can be used tochange which function is linked against. If you're interested in runningthis code yourself, head to developer.apple.com and download theMetal Dynamic Library sample. We're really excited to bring these new features.Dynamic libraries allow you to write reusable library code without payingthe cost in time or memory of recompiling your utilities. And like Binary Archives,Dynamic Libraries are serializable and shippable. In the sample codewe've demonstrated how you can use dynamic libraries to allow users towrite their own methods without requiring users to write their own kernelentry points. This feature is supported this year in iOS and macOS. Checkthe feature query on your device to see if your GPU supports and dynamic libraries.So far we've talked about some of the ways we're updating our shader modelin Metal this year and the final part of our talk, we'll be discussingadditional updates to our offline tool chains. To help me cover this topic,I'm going to hand you over to my colleague Ravi.Thank you Kyle, and hello everyone. In the previous sections we heard abouthow to create and use Binary Archives and Dynamic Libraries using the Metal API.I'm Ravi Ramaseshan from the Metal Frontend Compiler Team. And in thissection I'm going to talk to you about how to create and manipulate theseobjects using the Metal Developer Tools. With a small code base you canput all your code into a couple of Metal files and build a MetalLib usinga command line like the one shown below. As your code base grows, you keepadding files to the same command line, but it becomes hard to track dependenciesbetween all your shader sources. To address this we are bringing librariesto Metal! Libraries come in three flavors. The kind of MetalLibs thatyou've been building, up until now. The ones you use to create your MetalFunctionsare what we call executable MetalLibs. For your non-entrypoint,or utility code, you can now create Static or Dynamic Libraries. Along withMetal libraries we are also bringing more tools to metal which mimic theCPU toolchain. All these tools together form the Metal Developer Toolswhich can be found in your Xcode toolchain. We'll see how to use thesetools to improve your shader compilation workflows. To get started let'suse the Metal compiler on our Metal sources to get the correspondingAIR files using the command line below. With that out of the way let'suse a new tool in the tool chain. 'metal-libtool' which like its CPUcounterpart is used to build libraries. The 'static' option archivesall the AIR files together to build a static library. We'll then run the linker,through the Metal compiler to link the AIR files with the static libraryto create our executable MetalLibs. The 'lowercase-L' option, followed bya name is how you get the linker to link against your library. You canalso use the 'uppercase-L' option to get the linker to search directoriesin addition to the default system paths. The way to think about staticlinking is that each of your executable MetalLib's has a copy of the static library.This has a few implications. On the bright side your MetalLibs are self-containedand easy to deploy since they have no runtime dependencies. Also the compilerand linker have access to the concrete implementations of your libraryso they can perform link- time optimizations resulting in potentiallysmaller and faster code. On the downside, you may be duplicating the libraryinto each of your MetalLibs resulting in a larger app bundle.Fortunately dynamic linking is a powerful mechanism to address this problem. To createdynamic libraries we'll invoke the linker by using the '-dynamiclib' option.The '-instal-name' option to the linker is the toolchain counterpart of theMetal API you saw earlier. The install name is recorded in to the MetalLib.for the loader to find the library at runtime. Now, we'll link the utilitylibrary with our AIR files to get our executable MetalLibs. With dynamiclinking the utility library does not get copied in to the executable MetalLibsbut instead has to be deployed on the target system separately. Let's seehow the loader finds the dynamic library at runtime. It starts when you buildthe library. The linker uses the install_name of the dylib to embed aload command into the resulting MetalLib. Think of it as a reference to thedyllib that this MetalLib depends on. The load command is how the loaderlocates and loads the dylib at runtime. You can have multiple of theseload commands if you link with more than one library. Finally let's revisitthe 'instal_name' option we used when building our dylib, and see how acouple of special names work. Let's assume that libUtility dependson another dylib and focus on how the loader resolves these special namesin the load command for LibUtility. At runtime the loader finds the libraryto be loaded using the install name but replaces @loader_path with thepath of the MetalLib. containing the load command. Metal also supports@executable_path which the loader resolves to the path of the executableMetalLib containing the entrypoint function. You can probably see thatfor executable MetalLibs, both these special names resolved to the same location.Through load commands, each of your MetalLibs record only a referenceto the dylib. Binding an implementation of the symbol to its referenceis done at runtime by the loader. This too has some implications. On thepositive side using dynamic libraries solves the duplication problem wesaw with static libraries. The downside is that at runtime the dylibneeds to exist for your executable MetalLib to work and the loader mustbe able to find it. Since libraries can be written by multiple authorsyou run the risk of name collisions between the libraries. Like in thisexample the two libraries unintentionally export the same symbol, 'calculate.'The expected behavior was for each library to use its own 'calculate' function.In fact, with static linking you would have gotten an error at build time.However with dynamic linking the loader just picks one definition and bindsall references to it. Because of this you may only get an incorrect resultobserved at runtime and can be quite hard to track down. So why does the'calculate' function participate in dynamic linking? That's because justlike with the CPU compiler and linker, by default Metal exports all thesymbols in your library. You can quickly check the symbols in your libraryusing 'metal-nm' which like its CPU counterpart, lets you inspect the namesof the symbols that are exported by your MetalLib. The question then ishow do we control what symbols are exported by our library? Just like onthe CPU side you can use the static keyword, anonymous namespaces, andthe visibility attributes, to control which symbols are exported by your library.It's also a good idea to use namespaces when defining your interfaces.And finally, we support the 'exported- symbols-list' linker option. For moredetails there's some great documentation on our developer Web site on Dynamic Libraries.The other exciting concept that we introduced you earlier was harvestingfully compiled binaries from the device. We've harvested such a MetalLib forLibUtility on an A13 device using the Metal API that we saw in the previous section.To work with such objects does a new tool called 'metal-lipo'. Let's useit to peek into what's in the MetalLib that we just harvested using the 'info' option.The tool reports that this MetalLib contains two architectures. The way tothink about that is it is a fat binary that really contains two independentMetalLibs called slices. The A13 slice which is back back-end compiledand the generic AIR slice. When the harvested MetalLib. is deployed onNon A13 devices, Metal will use the AIR slice just as it does today.That means spinning up the Metal Compiler Service and invoking the back endcompiler to build your pipeline. This allows the MetalLib to be usedon all iOS devices, not just A13- based ones. However if the same MetalLibis downloaded on an A13 device, metal will use the A13 slice, skip backend compilation completely, and potentially improve your app's loading performance.Now let's say you want to improve the experience of your app users thatare also on A12 devices. Besides the A13 device let's also harvest a MetalLibfrom an A12 device. To simplify your App deployment you might wantto bundle all the slices into a single MetalLib. 'metal-lipo' allows youto do just that and create an even fatter universal binary. This techniquecan even be used with Binary Archives. Obviously the more slices that youpack into your binary the larger your app bundle becomes. So keep thatin mind when deciding which slices you want to pack into your universal binary.So let's do a quick recap of the different workflows we've seen today.We started by using the Metal compiler to turn our Metal sources into AIR files.We then used 'metal-libtool' to create static libraries, a new workflowto replace your existing 'metal-ar' based one. We then built a new kindof MetalLib, a dynamic library. We also saw how to combine AIR, static,and dynamic libraries to create executable MetalLibs. Along the way wealso saw using 'metal-nm' to inspect the symbols exported by a MetalLib.And finally we used 'metal-lipo' to work with slices in our harvested MetalLibs.The last thing we want to show you is a use case shared to us by some ofour game developers. Here's a high- level view of their workflow. As youcan see they use a variety of tools including the CPU and GPU toolchainsto build the app bundle. In some cases developers have pooled theirmachines together into a server farm that they use to build their assets.This workflow works great, as long as these tools run on Mac OS.However some of these developers have established game and graphic asset creationpipelines that are based on Microsoft Windows infrastructure. In orderto support these developers, this year we are introducing the Metal DeveloperTools on Windows. With this, you will now have the flexibility to buildyour MetalLibs targeting Apple platforms from macOS, Windows, or evena hybrid setup. The tools are available as a Windows installer and canbe downloaded from the Apple developer Web site today. All the workflowsthat are supported by the toolchain we release with Xcode are also supportedby the Windows hosted tools. That brings us to the end of this session.Let's recap what we covered here. We introduced you to Binary Archivesa mechanism which you can employ to avoid spending time on back end compilationfor some of your critical pipelines. We then presented Dynamic Librariesin Metal as an efficient and flexible way to decouple your library codefrom your shaders. And finally we went over some new and important compilationworkflows by directly using the Metal Developer Tools. We hope this presentationgets you started with adopting the new compilation model for your new and existing workflows.Thanks for watching this session.
And enjoy the rest of WW DC.

Hello and welcome to WWDC. Hello and welcome to WWDC. My name is Kyle Piddington,I'm an engineer and Apple's GPUSW Software Technology Group.In this session, my colleague Ravi and I are going to show you some of thenew advancements to ship your new or existing precompiled GPU code.This talk will consist of four parts. First up I'll provide an overview of Metal'scurrent Shader compilation model. Next I'm going to introduce Metal BinaryArchives, a new way for you to take control over shader caching, and shipprecompile GPU executables to your users. I'm excited to share thenew support for dynamic libraries in metal. This feature will allow youto link your compute shaders against utility libraries dynamically.And finally Ravi will present in detail the set of tools that you have in yourWe'll begin with a review of the shader and pipeline compilation processon Apple platforms.As you know the metal shading language is our programming language for shaders.Metal compiles this code into Apple's Intermediate Representation alsoknown as AIR. This can be done off-line, in Xcode, or at runtime on thetarget device itself. Building off-line avoids the runtime cost of compilingsource code to AIR. In both cases, however when creating pipeline state objects.this intermediate representation is further compiled on device to generatemachine specific code needed for each particular GPU. This process occursfor every pipeline state. To accelerate recompilation and recreation ofpipelines we cache the Metal Function variants produced in this step forfuture pipeline creation. This process is great, and has served us wellof building pipeline objects early on to provide a hitch-free experience,this process can potentially result in long loading screens.Additionally under this model apps are unable to re-use any previously generated machinecode subroutines across different pipeline state objects. We've gathered feedbackcoming in from our ecosystem of developers and have been able to identifya concrete set of needs that would enable you to address these challenges.You might want a way to save the entire time cost of pipeline state compilation,from source, to AIR, to a GPU binary. You might also want a mechanism thatenables sharing common subroutines and utility functions without the needof compiling the same code twice or having it loaded in memory more than once.

Having the ability to ship apps that already include the final compiledcode for executables as well as libraries, gives you the tools to providea fantastic first-time launch experience. And allowing you to share theseexecutables and libraries with other developers make their development easier.

One of the ways we're addressing these needs is via the Metal Binary Archives.Since the beginnings of Metal, apps have benefited from a system-wide shadercache that accelerates creating pipeline objects that have been createdfrom previous runs of the application. With Metal Binary Archives, explicitcontrol over pipeline state caching is being provided to you. This directcontrol over caching gives you the opportunity to manually collect compiledpipeline state objects, organize them into different archives based offyour usage or need, and even harvest them from a device and distributethem to other compatible devices. Binary archives can be thought of asany other asset type. You have full control over the binary archive lifetimesand these persist as long as desired. Binary Archives are a feature ofthe Metal GPU family, Apple3 and Mac1. Creating a binary archiveis simple. For this feature, we created a new descriptor type for binary archives.I use this descriptor to create a new MTLBinaryArchive from the device.

This descriptor contains a URL property and this is used to determineif I want to create a new, empty archive or if I want to load one from disk.

When we request a new archive be loaded, this file will be memory-mappedin and we can immediately start to use these loaded archives to accelerateour subsequent pipeline build requests. The binary archive API allows meto directly add pipelines I'm interested in to the archive. I can add Render,Compute, and tileRender pipelines. Adding a pipeline to the binary archivecauses a backend compilation of the shader source, generating the machinecode to be stored in the archive. Finally, once I'm done collecting allthe pipeline objects I'm interested in, I call serializeToURLto save the archive to disk. Once I have my binary archives on disk, I canharvest them from device and deploy them on other compatible devices toaccelerate their pipeline state builds. The only requirement is that theseother devices have the same GPU, and are running the same operating system build.If there's a mismatch the Metal framework will fall back on runtime compilationof the pipeline functions. Once I have my binary archive populated, reusinga cached pipeline is straightforward. When creating a pipeline I set thepipeline descriptor's binary archives property to an array of archives.The framework will then search the array linearly for the function binaries.

If the pipeline is found in any of the binary archives on the list it willbe returned to you. Avoiding the compilation process entirely and willnot impact the Metal Shader Cache. In the case of the pipeline is not foundthe OS's MTLCompilerService will kick into gear and compile my AIRsource to machine code, return the result, and cache the result in theMetal Shader Cache. This process takes time but the pipeline will be cashedin the Metal Shader Cache to accelerate any subsequent pipeline build requests.Now that I've gone over the workflow let's take a look at the API to accomplish it.First I create the MTLBinaryArchiveDescriptor. This is used to determinewhether I want to create a new, empty archive or to load an existing one.Creating a binary archive is always done from a descriptor.

In this case, I set the URL to nil and the device will create a new,empty archive.

Finally I call the function makeBinaryArchive to create it. Next I'll populatea binary archive using pipeline descriptors. I can add Render, Compute andtileRender descriptors to the binary archive. Reusing compiled functionsfrom binary archive allows me to skip the back end function compilation.I can create my pipeline descriptors just as I always have and use thenew binaryArchives property to indicate which archives be searched.I want to do this before creating the pipeline. Once you have collectedall the pipelines you're interested in. You can serialize the binary archiveto a rideable file location on disk. Using the method 'serialize.' Here II'm serializing the archive to my applications 'documents' directory.On the next run of my app I can now deserialize the archive to avoid recompilingthe pipelines that were previously added and serialized. I simplyset the URL to point to the location of an existing pre-populated cacheon disk. Now, one final note about archive search. Depending on your usecase you may find it helpful to be able to short circuit the fallbackbehavior of compiling a pipeline when it's not found in the archive.In this case you can specify the Pipeline. Compile Option failOnBinaryArchiveMiss.

If the pipeline is found in any of the archives it is returned to you as usual.However in the case that it's not found the device will return nil.One use case I recommend, is using this workflow for debugging purposes. Avoidingthe compilation process will let you diagnose any problems in your app'slogic, or your archive's data. Let's take a moment to discuss the memoryconsiderations of using binary archives. As mentioned before, it is importantto note that the binary archive file is memory-mapped in. This means thatwe need to reserve a range of virtual memory in order to access the archive's contents.This virtual memory range will be released when you release your cache,so it's important to close any binary archives that are no longer neededfor optimal use of the virtual address space. When collecting new pipelinesBinary Archives present a similar memory footprint to using the system'sMetal Shader Cache. But unlike when using the Metal Shader Cache, we havethe chance to free up this memory. Having explicit control over archivelifetime allows you to serialize and release a Metal Binary Archivewhen you are done collecting pipelined state objects. In addition, when youreuse an existing archive the pipelines in this archive do not count againstyour active app memory. You can serialize and then reopen this archiveand only use it for retrieving cache pipelines, effectively freeing thememory that was used in the collection process. This is not possible whenrelying on the system's Metal Shader Cache. I'd like to wrap up this partof the session by discussing some of the best practices for working withBinary Archives. Although there's no size limit for Binary Archives, I recommenddividing your game assets into several different caches. Games are an excellentcandidate for breaking up caches into a frequently used pipelines andper-level pipelines. Dividing the cache gives you the opportunity to completely releaseno longer needed caches. This will free memory, in case we've collectedany new pipelines as well as a virtual memory range in use. When followingthis guidance, Binary Archives gives you granular control and should befavored over pre-warming the Metal Shader Cache. Modern apps often havetoo many unique permutations of shader variants that are generated basedoff of user choices. With Metal Binary Archives you can now capture themall at runtime. Let's take a look how this all comes together in practice.We've partnered with Epic Games to quantify exactly how reusing apre-harvested binary archive can help improve pipelined state object creationtimes, as well as the developer workflow in the context of Unreal Engine.For this test, we use the pipeline state workload of a AAA title, fortnight.

Fortnite is a large game. It's got a big world and many character and itemcustomization options. This makes for a large number of shader functionvariants and pipeline state objects over 11,000 in fact.

Epic Games follows the Metal best practices and compiles any needed pipelinestate objects at load time which allows minimizing hitching at runtime,and delivers the smoothest experience possible to users. But apps as wementioned can not benefit from the Metal Shader Cache before it's been populated,so the upfront compilation time adds up potentially making the first timelaunch experience take longer than desired. By preceding a harvested MetalBinary Archive that had collected function variants from seventeen hundredpipelined state objects we observed a massive speedup in the creation timeswhen we compare against starting with an empty Metal Shader Cache. Theseresults are measured on a six core three gigahertz MAC mini with 32 gigabytesof RAM. When we focus on pipeline build times, we go from spending oneminute and twenty six seconds building pipelines to just three seconds.Overall a speed up of over twenty eight times.

To summarize Metal Binary Archives allow you to manually manage pipeline caches.

These can be harvested from a device and deployed on other, compatible devicesto dramatically reduce the pipeline creation times the first time a gameor app is installed and after a device reboots in the case of iOS.AAA games and other apps bound by a very large number of pipelined stateobjects can benefit from this feature to obtain extra ordinary gains inpipelined creation times under these conditions. Building and shippingGPU executable binaries with your application allows you to accelerateyour first-time launch experience and cold-boot app experiences. I hopeyou take advantage of this new feature. And that's it for Metal Binary Archives.Next I'm going to talk about another new feature we're bringing to thecompilation model, Dynamic Libraries. Metal Dynamic Libraries are a newfeature that will allow you to build well abstracted and reusable computeshader library code for your applications. I'll be discussing the concept,execution, and details of dynamic libraries. Today developers may chooseto create utility libraries of Metal functions to compile with their kernels.Offline compilation can save time while generating these libraries,but there's still two costs that occur when using a utility library.

Every app pays the costs of generating machine code for the utility libraryat PSO generation. In addition, compiling multiple pipelines with the sameutility library results in duplicated machine code for subroutines. Thiscan result in longer pipeline load times due to back end compilation andincreased memory usage. And this year we're introducing a solution to this problem.The Metal Dynamic Library. The MTLDynamicLibrary enables you to dynamicallylink, load, and share utility functions in the form of machine code.This code is reusable between multiple compute pipelines eliminating duplicatecompilation and the storing of shared subroutines. In addition much likethe MTLBinaryArchive, the MTLDynamicLibrary is serializable, andshippable as an asset in your application. Before we dive into the API,let's talk about what a MTLDynamicLibrary is. A MTLDynamicLibraryis a collection of exported functions that can be called from multiplecompute pipelines. Later we'll discuss which functions in your dylibare exported and how to manage them. Unlike an executable MTLLibrary,dynamic libraries can not be used to create MTLFunctions. However, standardMTLLibraries can import functions that are implemented in a dynamic library.

At pipeline creation time, the dynamic library is linked to resolve anyimported functions much like a dynamic library is used in a typical application.

So why might you want to use dynamic libraries. If your application canbe structured into or relies on a shared utility code base, dynamic librariesare for you. Using dynamic libraries in your app prevents recompilingand duplicating machine code across pipeline states. If you're interestedin developing Metal Middleware, dynamic libraries provide you the abilityto ship a utility library to your users. Unlike before where you wouldhave to ship sources to developers or compile their code with a staticMetal library, a dynamic library can be provided and updated without requiringusers to rebuild their own Metallib files. Finally dynamic libraries giveyou the power to expose hooks for your users to create custom kernels.The Metal API exposes the ability to change which libraries are loadedat pipeline creation time allowing you the ability to inject user definedbehavior into your shaders, without creating the MTLLibrary andMTLFunctions containing your entry points. To determine if male dynamic librariesare supported for your GPU, check the feature query 'supportsDynamicLibraries."In the next few slides we'll work through an example of how to create adynamic library, how symbols are resolved, and some more advanced linking scenarios.

A standard MTLLibrary is compiled to AIR through either a makeLibrarywith source call at runtime or through compiling your library with theMetal toolchain. To create a MTLDynamicLibrary we begin with a similar workflow.We start by creating a MTLLibrary. But when doing so, we specify thatwe'd like this library to be used as a dynamic library. Next we call thefunction makeDynamicLibrary which will backend compile our Metal codeto machine code. This is the only time you will need to compile the dynamic library.

We need one more bit of information: a unique install-name. At pipeline creation time,these names are used by the linker to load the dynamic library. The linkersupports two relative paths @executable_path, which refers to the Metallibcontaining an executable kernel and @loader_path which refers tothe Metallib containing the load command. An absolute path can also be used.

With an installName and a libraryType I'm now ready to created a dynamic library.Once I've set the compile options I create a MTLLibrary which willcompile my library from source to AIR. Then I called the API methodmakeDynamicLibrary on the MTLDevice which will compile my dynamic libraryinto machine code. Now that we've covered how to create a dynamic library,let's take a look at how we can use it. In these next few examples,I'll be discussing how we can link dynamic libraries at runtime. These operationscan also be achieved when compiling metal libraries offline. And we'lldiscuss our offline workflow later in the session. To link a dynamic librarywhen compiling a MetalLib from source, add the dynamic library to the 'libraries'property of the MTLCompileOptions, before you compile your library.

The specified library will be linked at pipeline creation time. Howeversymbol resolution will be checked at compile time to make sure at leastone implementation of the function exists. To review these steps: when creatinga MetalLib from source, source files should include headers that definefunctions available in your dynamic libraries. At compile time dynamiclibraries included in the 'libraries' option are searched for at least onematching function signature, if no signature is found, compilation willfail explaining which symbols are missing. However, unlike when compilingwith static libraries, or header libraries, this compilation does notbind the function call to the function implementation. At pipeline creation time,libraries are linked and loaded and a function implementation is chosen.We'll go over the case where multiple dynamic libraries export the samefunction in just a moment. In addition to executable MTLLibraries linkingdynamic libraries, dynamic libraries can also reference other dynamic libraries.If all these libraries were created from source at runtime, linking Dylib2to and Dylib3 to Dylib1 is as simple as setting the MTLCcompileOptions'libraries' property on creation. And to reiterate one more time, dylibsare shared between kernels. Although multiple kernels link the same dylib,only one instance of the dylib exists in memory. Because linking isdeferred to pipeline creation time, we can replace functions, or even fulllibraries with new implementations by using the insertLibraries propertyof the compute pipeline descriptor. Setting this option is comparable tosetting the DYLD_INSERT_LIBRARIES environment variable. At pipelinecreation time the linker will first search through inserted libraries tofind imported symbols, before looking through the kernel's linked librariesfor any remaining imported symbols. In this example dylib A exportsthe function foo(). And when we create the compute pipelined state food willbe linked to the implementation in dylib A. When we use insertLibrariesboth dylib A and dylib D export the function foo. When we create thepipeline state, we walk down the list of imported libraries to resolve thesymbol, and instead of linking the implementation of foo() in dylib A, we willinstead link from foo() in dylib D. Finally, let's discuss distributingyour dynamic libraries. Much like Binary Archives, Compiled Dynamic Librariescan be serialized out to URL. Both the pre-compiled binary and the genericAIR for the MTLLibrary are serialized. If you end up distributing thedynamic library as an asset in your project, the metal framework will recompilethe AIR slice into machine code if the target device can not use the pre-compiled binary. This would occur when loading your dylib on a differentarchitecture or OS. This compilation is not added to the Metal ShaderCache so make sure to serialize, and load your library next time to savecompilation time. To help you adopt this API and to work through a small example,we've provided a simple example Xcode project available on developer.apple.com.The sample uses a compute shader to apply a full-screen post processing effect.The compute shader calls into a dynamic library to determine the pixelcolor. At runtime, we demonstrate how insertLibraries can be used tochange which function is linked against. If you're interested in runningthis code yourself, head to developer.apple.com and download theMetal Dynamic Library sample. We're really excited to bring these new features.Dynamic libraries allow you to write reusable library code without payingthe cost in time or memory of recompiling your utilities. And like Binary Archives,Dynamic Libraries are serializable and shippable. In the sample codewe've demonstrated how you can use dynamic libraries to allow users towrite their own methods without requiring users to write their own kernelentry points. This feature is supported this year in iOS and macOS. Checkthe feature query on your device to see if your GPU supports and dynamic libraries.

So far we've talked about some of the ways we're updating our shader modelin Metal this year and the final part of our talk, we'll be discussingadditional updates to our offline tool chains. To help me cover this topic,I'm going to hand you over to my colleague Ravi.

Thank you Kyle, and hello everyone. In the previous sections we heard abouthow to create and use Binary Archives and Dynamic Libraries using the Metal API.I'm Ravi Ramaseshan from the Metal Frontend Compiler Team. And in thissection I'm going to talk to you about how to create and manipulate theseobjects using the Metal Developer Tools. With a small code base you canput all your code into a couple of Metal files and build a MetalLib usinga command line like the one shown below. As your code base grows, you keepadding files to the same command line, but it becomes hard to track dependenciesbetween all your shader sources. To address this we are bringing librariesto Metal! Libraries come in three flavors. The kind of MetalLibs thatyou've been building, up until now. The ones you use to create your MetalFunctionsare what we call executable MetalLibs. For your non-entrypoint,or utility code, you can now create Static or Dynamic Libraries. Along withMetal libraries we are also bringing more tools to metal which mimic theCPU toolchain. All these tools together form the Metal Developer Toolswhich can be found in your Xcode toolchain. We'll see how to use thesetools to improve your shader compilation workflows. To get started let'suse the Metal compiler on our Metal sources to get the correspondingAIR files using the command line below. With that out of the way let'suse a new tool in the tool chain. 'metal-libtool' which like its CPUcounterpart is used to build libraries. The 'static' option archivesall the AIR files together to build a static library. We'll then run the linker,through the Metal compiler to link the AIR files with the static libraryto create our executable MetalLibs. The 'lowercase-L' option, followed bya name is how you get the linker to link against your library. You canalso use the 'uppercase-L' option to get the linker to search directoriesin addition to the default system paths. The way to think about staticlinking is that each of your executable MetalLib's has a copy of the static library.This has a few implications. On the bright side your MetalLibs are self-containedand easy to deploy since they have no runtime dependencies. Also the compilerand linker have access to the concrete implementations of your libraryso they can perform link- time optimizations resulting in potentiallysmaller and faster code. On the downside, you may be duplicating the libraryinto each of your MetalLibs resulting in a larger app bundle.Fortunately dynamic linking is a powerful mechanism to address this problem. To createdynamic libraries we'll invoke the linker by using the '-dynamiclib' option.

The '-instal-name' option to the linker is the toolchain counterpart of theMetal API you saw earlier. The install name is recorded in to the MetalLib.for the loader to find the library at runtime. Now, we'll link the utilitylibrary with our AIR files to get our executable MetalLibs. With dynamiclinking the utility library does not get copied in to the executable MetalLibsbut instead has to be deployed on the target system separately. Let's seehow the loader finds the dynamic library at runtime. It starts when you buildthe library. The linker uses the install_name of the dylib to embed aload command into the resulting MetalLib. Think of it as a reference to thedyllib that this MetalLib depends on. The load command is how the loaderlocates and loads the dylib at runtime. You can have multiple of theseload commands if you link with more than one library. Finally let's revisitthe 'instal_name' option we used when building our dylib, and see how acouple of special names work. Let's assume that libUtility dependson another dylib and focus on how the loader resolves these special namesin the load command for LibUtility. At runtime the loader finds the libraryto be loaded using the install name but replaces @loader_path with thepath of the MetalLib. containing the load command. Metal also supports@executable_path which the loader resolves to the path of the executableMetalLib containing the entrypoint function. You can probably see thatfor executable MetalLibs, both these special names resolved to the same location.

Through load commands, each of your MetalLibs record only a referenceto the dylib. Binding an implementation of the symbol to its referenceis done at runtime by the loader. This too has some implications. On thepositive side using dynamic libraries solves the duplication problem wesaw with static libraries. The downside is that at runtime the dylibneeds to exist for your executable MetalLib to work and the loader mustbe able to find it. Since libraries can be written by multiple authorsyou run the risk of name collisions between the libraries. Like in thisexample the two libraries unintentionally export the same symbol, 'calculate.'The expected behavior was for each library to use its own 'calculate' function.In fact, with static linking you would have gotten an error at build time.

However with dynamic linking the loader just picks one definition and bindsall references to it. Because of this you may only get an incorrect resultobserved at runtime and can be quite hard to track down. So why does the'calculate' function participate in dynamic linking? That's because justlike with the CPU compiler and linker, by default Metal exports all thesymbols in your library. You can quickly check the symbols in your libraryusing 'metal-nm' which like its CPU counterpart, lets you inspect the namesof the symbols that are exported by your MetalLib. The question then ishow do we control what symbols are exported by our library? Just like onthe CPU side you can use the static keyword, anonymous namespaces, andthe visibility attributes, to control which symbols are exported by your library.

It's also a good idea to use namespaces when defining your interfaces.And finally, we support the 'exported- symbols-list' linker option. For moredetails there's some great documentation on our developer Web site on Dynamic Libraries.

The other exciting concept that we introduced you earlier was harvestingfully compiled binaries from the device. We've harvested such a MetalLib forLibUtility on an A13 device using the Metal API that we saw in the previous section.

To work with such objects does a new tool called 'metal-lipo'. Let's useit to peek into what's in the MetalLib that we just harvested using the 'info' option.

The tool reports that this MetalLib contains two architectures. The way tothink about that is it is a fat binary that really contains two independentMetalLibs called slices. The A13 slice which is back back-end compiledand the generic AIR slice. When the harvested MetalLib. is deployed onNon A13 devices, Metal will use the AIR slice just as it does today.That means spinning up the Metal Compiler Service and invoking the back endcompiler to build your pipeline. This allows the MetalLib to be usedon all iOS devices, not just A13- based ones. However if the same MetalLibis downloaded on an A13 device, metal will use the A13 slice, skip backend compilation completely, and potentially improve your app's loading performance.

Now let's say you want to improve the experience of your app users thatare also on A12 devices. Besides the A13 device let's also harvest a MetalLibfrom an A12 device. To simplify your App deployment you might wantto bundle all the slices into a single MetalLib. 'metal-lipo' allows youto do just that and create an even fatter universal binary. This techniquecan even be used with Binary Archives. Obviously the more slices that youpack into your binary the larger your app bundle becomes. So keep thatin mind when deciding which slices you want to pack into your universal binary.

So let's do a quick recap of the different workflows we've seen today.We started by using the Metal compiler to turn our Metal sources into AIR files.

We then used 'metal-libtool' to create static libraries, a new workflowto replace your existing 'metal-ar' based one. We then built a new kindof MetalLib, a dynamic library. We also saw how to combine AIR, static,and dynamic libraries to create executable MetalLibs. Along the way wealso saw using 'metal-nm' to inspect the symbols exported by a MetalLib.

And finally we used 'metal-lipo' to work with slices in our harvested MetalLibs.

The last thing we want to show you is a use case shared to us by some ofour game developers. Here's a high- level view of their workflow. As youcan see they use a variety of tools including the CPU and GPU toolchainsto build the app bundle. In some cases developers have pooled theirmachines together into a server farm that they use to build their assets.This workflow works great, as long as these tools run on Mac OS.However some of these developers have established game and graphic asset creationpipelines that are based on Microsoft Windows infrastructure. In orderto support these developers, this year we are introducing the Metal DeveloperTools on Windows. With this, you will now have the flexibility to buildyour MetalLibs targeting Apple platforms from macOS, Windows, or evena hybrid setup. The tools are available as a Windows installer and canbe downloaded from the Apple developer Web site today. All the workflowsthat are supported by the toolchain we release with Xcode are also supportedby the Windows hosted tools. That brings us to the end of this session.Let's recap what we covered here. We introduced you to Binary Archivesa mechanism which you can employ to avoid spending time on back end compilationfor some of your critical pipelines. We then presented Dynamic Librariesin Metal as an efficient and flexible way to decouple your library codefrom your shaders. And finally we went over some new and important compilationworkflows by directly using the Metal Developer Tools. We hope this presentationgets you started with adopting the new compilation model for your new and existing workflows.

Thanks for watching this session.
And enjoy the rest of WW DC.

6:19 -Creating an empty archive

6:47 -Populating an archive

6:56 -Reusing compiled functions

7:15 -Serialization

7:26 -Deserialization

17:18 -Runtime compiled dynamic library

17:59 -Compiling with a dynamic library

## Code Samples

```swift
let
 descriptor 
=
 
MTLBinaryArchiveDescriptor
()
descriptor.url 
=
 
nil


let
 binaryArchive 
=
 
try
 device.makeBinaryArchive(descriptor:descriptor)
```

```swift
// Render pipelines


try
 binaryArchive.addRenderPipelineFunctions(with: renderPipelineDescriptor)


// Compute pipelines


try
 binaryArchive.addComputePipelineFunctions(with: computePipelineDescriptor)


// Tile render pipelines


try
 binaryArchive.addTileRenderPipelineFunctions(with: tileRenderPipelineDescriptor)
```

```swift
// Reusing compiled functions to build a pipeline state object from a file



let
 renderPipelineDescriptor 
=
 
MTLRenderPipelineDescriptor
()

// ...

renderPipelineDescriptor.binaryArchives 
=
 [ binaryArchive ]


let
 renderPipeline 
=
 
try
 device.makeRenderPipelineState(descriptor:  
                                                          renderPipelineDescriptor)
```

```swift
let
 documentsURL 
=
 
FileManager
.default.urls(for: .documentDirectory, in: .userDomainMask).first
!


let
 archiveURL 
=
 documentsURL.appendingPathComponent(
"binaryArchive.metallib"
)


try
 binaryArchive.serialize(to: 
NSURL
.fileURL(withPath: archiveURL))
```

```swift
let
 documentsURL 
=
 
FileManager
.default.urls(for: .documentDirectory, in: .userDomainMask).first
!


let
 serializeURL 
=
 documentsURL.appendingPathComponent(
"binaryArchive.metallib"
)


let
 descriptor 
=
 
MTLBinaryArchiveDescriptor
()
descriptor.url 
=
 
NSURL
.fileURL(withPath: serializeURL)

let
 binaryArchive 
=
 
try
 device.makeBinaryArchive(descriptor: descriptor)
```

```swift
let
 options 
=
 
MTLCompileOptions
();
options.libraryType 
=
 .dynamic;
options.installName 
=
 
"@executable_path/myDynamicLibrary.metallib"


let
 utilityLib 
=
 
try
 device.makeLibrary(source: dylibSrc, options: options)

let
 utilityDylib 
=
 
try
 device.makeDynamicLibrary(library: utilityLib)
```

```swift
let
 options 
=
 
MTLCompileOptions
()
options.libraries 
=
 [ utilityDylib ]

let
 library 
=
 
try
 device.makeLibrary(source: kernelStr, options: options)
```

