WEBVTT

00:00:01.516 --> 00:00:04.500
[ Music ]

00:00:08.516 --> 00:00:17.546
[ Applause ]

00:00:18.046 --> 00:00:19.896
>> Hello. Welcome everyone.

00:00:20.656 --> 00:00:22.786
My name is Gaurav and today

00:00:22.786 --> 00:00:24.306
we're going to talk about What's

00:00:24.396 --> 00:00:27.456
New in Machine Learning.

00:00:29.696 --> 00:00:31.316
Machine Learning is used by

00:00:31.406 --> 00:00:32.326
thousands of apps.

00:00:33.356 --> 00:00:35.556
The apps that you are making are

00:00:35.556 --> 00:00:36.436
amazing.

00:00:37.006 --> 00:00:38.896
They're touching every aspect of

00:00:38.946 --> 00:00:39.846
a user's life.

00:00:40.456 --> 00:00:45.086
In hospitals, doctors are using

00:00:45.086 --> 00:00:47.326
apps such as Butterfly iQ to do

00:00:47.326 --> 00:00:50.356
medical diagnostics in real

00:00:52.096 --> 00:00:52.206
time.

00:00:52.416 --> 00:00:54.866
In sports, coaches are using

00:00:54.866 --> 00:00:57.186
apps such as HomeCourt to train

00:00:57.186 --> 00:00:57.646
their players.

00:00:58.576 --> 00:01:02.896
In creativity, apps such as

00:01:02.896 --> 00:01:04.936
Pixelmator Pro are helping other

00:01:04.936 --> 00:01:06.366
users to augment their

00:01:06.366 --> 00:01:07.686
creativity using ML.

00:01:08.746 --> 00:01:10.366
These are just a few examples,

00:01:10.576 --> 00:01:12.446
and we would like all of these

00:01:12.446 --> 00:01:14.746
apps you guys should also make

00:01:14.746 --> 00:01:17.396
these kind of apps.

00:01:17.656 --> 00:01:19.446
So now the question is what's

00:01:19.486 --> 00:01:19.686
new?

00:01:20.556 --> 00:01:24.736
Let me begin by saying a lot.

00:01:25.576 --> 00:01:28.896
We have so much material that we

00:01:28.896 --> 00:01:30.746
can hardly cover it one session

00:01:30.746 --> 00:01:31.556
or two sessions.

00:01:32.126 --> 00:01:35.746
We need ten sessions to cover

00:01:35.746 --> 00:01:36.856
the entire material.

00:01:38.316 --> 00:01:39.606
We also have a session

00:01:39.776 --> 00:01:41.616
intersecting the design in

00:01:41.616 --> 00:01:43.216
machine learning.

00:01:44.556 --> 00:01:47.216
We also have Daily Labs where

00:01:47.216 --> 00:01:49.496
you can meet and discuss your

00:01:49.496 --> 00:01:51.006
ideas with Apple Machine

00:01:51.006 --> 00:01:51.746
Learning engineers.

00:01:53.116 --> 00:01:55.156
All of us are here to remove any

00:01:55.156 --> 00:01:56.956
roadblocks that you might be

00:01:56.956 --> 00:01:58.966
facing while integrating Machine

00:01:59.026 --> 00:02:00.326
Learning in your app.

00:02:02.876 --> 00:02:04.776
In all of these sessions, you

00:02:04.776 --> 00:02:06.366
will see that we follow simple

00:02:06.366 --> 00:02:07.016
principles.

00:02:08.356 --> 00:02:11.246
We want Machine Learning to be

00:02:11.246 --> 00:02:12.976
as easy to use as possible.

00:02:12.976 --> 00:02:14.336
We are laser focused on doing

00:02:15.006 --> 00:02:15.106
that.

00:02:15.736 --> 00:02:17.766
We want to make it flexible so

00:02:17.766 --> 00:02:20.466
you can do it by variety of

00:02:21.436 --> 00:02:22.926
tasks, and we want to make it

00:02:22.976 --> 00:02:25.506
powerful so you can run state of

00:02:25.506 --> 00:02:27.246
the art Machine Learning models

00:02:27.336 --> 00:02:28.136
on your devices.

00:02:28.876 --> 00:02:32.976
It is truly Machine Learning for

00:02:32.976 --> 00:02:35.036
everyone whether you are a

00:02:35.036 --> 00:02:36.606
researcher or someone new to

00:02:36.606 --> 00:02:37.286
Machine Learning.

00:02:38.776 --> 00:02:40.046
With Create ML app you can

00:02:40.046 --> 00:02:41.236
make state of the art,

00:02:41.236 --> 00:02:42.816
task-focused ML models.

00:02:44.526 --> 00:02:45.846
The next big pillar of our

00:02:45.846 --> 00:02:47.286
offering is Domain APIs.

00:02:49.256 --> 00:02:50.746
Domain APIs allow you to

00:02:50.746 --> 00:02:52.106
leverage Apple's built-in

00:02:52.106 --> 00:02:53.346
intelligence and models.

00:02:54.266 --> 00:02:55.506
So you don't have to worry about

00:02:55.506 --> 00:02:56.916
collecting the data and building

00:02:56.916 --> 00:02:57.426
the model.

00:02:57.646 --> 00:03:00.296
Simply call the API and be done.

00:03:02.696 --> 00:03:04.326
This year we are significantly

00:03:04.356 --> 00:03:05.806
expanding our Domain APIs.

00:03:06.256 --> 00:03:08.676
We have Domain APIs in Vision,

00:03:09.106 --> 00:03:13.196
Text, Speech and Sound.

00:03:13.406 --> 00:03:15.226
Now let's take a sneak peek of

00:03:15.276 --> 00:03:16.386
some of these APIs.

00:03:17.146 --> 00:03:19.746
Let's start with Vision.

00:03:20.976 --> 00:03:22.906
Vision allows you to reason

00:03:23.016 --> 00:03:24.716
about the content of the image.

00:03:26.206 --> 00:03:27.386
One of the new features this

00:03:27.386 --> 00:03:29.036
year is Image Saliency.

00:03:30.096 --> 00:03:31.576
Image Saliency can help you

00:03:31.576 --> 00:03:33.536
identify the most relevant

00:03:33.536 --> 00:03:35.256
region in your image.

00:03:36.106 --> 00:03:39.466
In this case, the region around

00:03:39.636 --> 00:03:40.146
the person.

00:03:41.936 --> 00:03:43.056
You can use it to generate

00:03:43.056 --> 00:03:44.996
thumbnails or to make image

00:03:44.996 --> 00:03:49.196
cropping, generate memories,

00:03:49.196 --> 00:03:49.976
guide camera et cetera.

00:03:50.046 --> 00:03:53.786
Another big feature we are

00:03:53.786 --> 00:03:55.406
introducing this year is Text

00:03:55.466 --> 00:03:56.126
Recognition.

00:03:57.666 --> 00:03:59.516
You can now take a picture of

00:03:59.516 --> 00:04:01.476
the document, perform

00:04:01.476 --> 00:04:03.556
perspective correction, lighting

00:04:03.556 --> 00:04:05.566
correction and reorganize the

00:04:05.616 --> 00:04:06.976
text on the device.

00:04:07.516 --> 00:04:13.986
[ Applause ]

00:04:14.486 --> 00:04:18.106
This is huge, but that's not

00:04:18.106 --> 00:04:18.666
all.

00:04:18.666 --> 00:04:19.796
We have Image inbuilt

00:04:19.796 --> 00:04:22.016
classifier, human detector, pet

00:04:22.016 --> 00:04:24.036
detector, and we are going to

00:04:24.036 --> 00:04:26.166
cover them in detail in our two

00:04:26.166 --> 00:04:27.046
Vision sessions.

00:04:31.036 --> 00:04:33.106
Next domain is Natural Language.

00:04:33.656 --> 00:04:36.356
Just like you use Vision to

00:04:36.356 --> 00:04:38.376
reason about images you can use

00:04:38.376 --> 00:04:41.046
Natural Language to reason about

00:04:42.056 --> 00:04:43.076
the text.

00:04:43.256 --> 00:04:44.906
New this year is inbuilt

00:04:44.906 --> 00:04:46.166
Sentiment Analysis.

00:04:46.166 --> 00:04:48.626
So you can use to analyze the

00:04:48.686 --> 00:04:50.616
sentiment of the text in real

00:04:50.616 --> 00:04:52.636
time on the device in a privacy

00:04:52.636 --> 00:04:53.216
friendly way.

00:04:53.836 --> 00:04:55.296
So, for example, if somebody

00:04:55.296 --> 00:04:56.486
types something like this I was

00:04:56.566 --> 00:04:57.926
so excited about the season

00:04:57.926 --> 00:04:59.406
finale that's a positive

00:05:00.256 --> 00:05:02.656
sentiment, but it was a bit

00:05:02.656 --> 00:05:04.386
disappointing at the end it's a

00:05:04.386 --> 00:05:05.406
negative sentiment.

00:05:06.056 --> 00:05:08.656
So you can provide this kind of

00:05:08.656 --> 00:05:10.006
feedback in real time.

00:05:10.526 --> 00:05:14.516
For the first time we are also

00:05:14.516 --> 00:05:16.826
exposing inbuilt Word

00:05:16.826 --> 00:05:17.386
Embeddings.

00:05:18.606 --> 00:05:20.096
Word Embeddings can allow you to

00:05:20.166 --> 00:05:21.666
find semantically similar words.

00:05:21.666 --> 00:05:23.426
So, for example, the word

00:05:23.426 --> 00:05:25.246
thunderstorm is very close to

00:05:25.246 --> 00:05:27.496
cloudy but it is very far away

00:05:27.496 --> 00:05:28.406
from shoes and boots.

00:05:28.896 --> 00:05:30.486
One of the big use case of Word

00:05:30.486 --> 00:05:31.486
Embeddings is semantic search

00:05:31.486 --> 00:05:33.636
and we are going to give you an

00:05:34.246 --> 00:05:35.246
example soon.

00:05:35.456 --> 00:05:36.546
Natural Language will be

00:05:36.546 --> 00:05:38.446
discussed in detail in Advances

00:05:38.446 --> 00:05:39.666
in Natural Language Framework

00:05:39.716 --> 00:05:40.086
session.

00:05:40.636 --> 00:05:45.836
The third way user interacts

00:05:45.836 --> 00:05:47.476
with your app is through speech

00:05:47.826 --> 00:05:48.426
and sound.

00:05:49.566 --> 00:05:51.076
Now we have an on-device speech

00:05:51.106 --> 00:05:52.496
support so you can transcribe

00:05:52.546 --> 00:05:54.986
the text on the device so you no

00:05:54.986 --> 00:05:56.226
longer have to rely on the

00:05:56.226 --> 00:05:59.266
network connection, and we also

00:05:59.266 --> 00:06:01.086
have new Voice Analytics API

00:06:01.436 --> 00:06:03.066
that can tell you not only what

00:06:03.066 --> 00:06:05.926
is spoken but how it is spoken.

00:06:05.926 --> 00:06:07.066
So you can differentiate between

00:06:07.066 --> 00:06:08.486
a normal voice and a high

00:06:08.576 --> 00:06:09.986
jittery voice.

00:06:11.016 --> 00:06:12.916
We also have a brand-new Sound

00:06:12.916 --> 00:06:14.396
Analysis Framework, that we will

00:06:14.396 --> 00:06:15.936
discuss in Create ML session.

00:06:16.416 --> 00:06:21.496
There's a lot more in each of

00:06:21.496 --> 00:06:24.146
these domains and another thing

00:06:24.146 --> 00:06:25.606
you can do to combine these

00:06:25.606 --> 00:06:27.396
domains almost seamlessly.

00:06:28.216 --> 00:06:29.246
Let me show you an example.

00:06:30.026 --> 00:06:33.176
Let's just say you want to build

00:06:33.176 --> 00:06:34.616
a feature that does Semantic

00:06:34.616 --> 00:06:35.566
Search on Images.

00:06:35.676 --> 00:06:36.896
That's a very complex feature.

00:06:36.896 --> 00:06:38.746
So if a user searches for

00:06:38.746 --> 00:06:41.056
thunderstorm, you want to

00:06:41.056 --> 00:06:42.366
provide them the results not

00:06:42.366 --> 00:06:43.886
only for thunderstorm but also

00:06:44.026 --> 00:06:46.716
for sky and cloudy.

00:06:46.836 --> 00:06:49.756
Now, you can combine Vision with

00:06:49.756 --> 00:06:51.336
Natural Language to implement

00:06:51.336 --> 00:06:53.376
this feature in very few lines

00:06:53.376 --> 00:06:53.806
of code.

00:06:55.176 --> 00:06:56.206
This is how you will do it.

00:06:56.206 --> 00:06:58.146
You will run your Image

00:06:58.146 --> 00:07:02.056
Classifier on images or you can

00:07:02.056 --> 00:07:03.606
have them use inbuilt Image

00:07:03.606 --> 00:07:05.286
Classifier to generate the tags.

00:07:06.016 --> 00:07:08.886
When the user types the word

00:07:08.936 --> 00:07:10.356
something like thunderstorm, you

00:07:10.356 --> 00:07:11.926
can use Word Embeddings to

00:07:11.926 --> 00:07:15.226
generate similar words and find

00:07:15.226 --> 00:07:16.576
the images that matches these

00:07:16.646 --> 00:07:16.896
tags.

00:07:17.626 --> 00:07:21.896
And that's not all.

00:07:21.896 --> 00:07:23.756
You can also combine the custom

00:07:23.756 --> 00:07:24.936
models that you made using

00:07:24.936 --> 00:07:26.746
Create ML with Domain APIs, and

00:07:27.036 --> 00:07:28.646
we are going to show an example

00:07:28.646 --> 00:07:30.686
of that in our Creating Great

00:07:30.686 --> 00:07:32.496
Apps Using Core ML and ARKit

00:07:32.606 --> 00:07:32.996
session.

00:07:33.546 --> 00:07:37.426
So to summarize, Domain APIs

00:07:37.426 --> 00:07:38.766
allow you to leverage Apple's

00:07:38.896 --> 00:07:40.576
built-in intelligence and model

00:07:40.856 --> 00:07:42.586
using API so you don't have to

00:07:42.586 --> 00:07:43.856
collect the data and make the

00:07:43.856 --> 00:07:44.266
models.

00:07:44.736 --> 00:07:45.776
And this year we have a

00:07:45.866 --> 00:07:48.046
significant expansion in our

00:07:48.046 --> 00:07:49.276
Vision Natural Language and

00:07:49.276 --> 00:07:49.976
Speech and Sound APIs.

00:07:56.336 --> 00:07:58.176
Now let's talk about Core ML 3,

00:07:58.526 --> 00:08:00.136
the third big pillar of our

00:08:00.846 --> 00:08:01.016
offering.

00:08:03.536 --> 00:08:06.106
Core ML is now supported across

00:08:06.196 --> 00:08:10.156
all our platforms.

00:08:10.216 --> 00:08:11.396
All the work is done on the

00:08:11.396 --> 00:08:13.046
device so user's privacy is

00:08:13.076 --> 00:08:13.936
maintained.

00:08:14.716 --> 00:08:16.686
Core ML is hardware accelerated

00:08:16.686 --> 00:08:18.466
so you can do, you can use it

00:08:18.466 --> 00:08:19.726
for realtime Machine Learning

00:08:20.646 --> 00:08:22.586
and you don't need a server and

00:08:22.586 --> 00:08:23.656
it always available.

00:08:24.356 --> 00:08:29.666
Core ML has always supported a

00:08:29.666 --> 00:08:31.056
wide variety of Machine Learning

00:08:31.056 --> 00:08:33.006
models ranging from classical

00:08:33.006 --> 00:08:34.566
generalized linear models, tree

00:08:34.566 --> 00:08:35.976
ensembles and support vector

00:08:35.976 --> 00:08:38.275
machines as well as neural

00:08:38.275 --> 00:08:40.395
networks such as Convolution

00:08:40.395 --> 00:08:41.946
Neural Network and Recurrent

00:08:41.946 --> 00:08:43.155
Neural Networks.

00:08:46.236 --> 00:08:48.596
New in Core ML is model

00:08:48.596 --> 00:08:50.146
flexibility and model

00:08:50.146 --> 00:08:51.046
personalization.

00:08:51.626 --> 00:08:53.196
So let's take a look at both of

00:08:53.926 --> 00:08:54.016
them.

00:08:55.956 --> 00:08:58.226
Core ML has expanded support for

00:08:58.226 --> 00:09:01.036
Data Neural Networks and we have

00:09:01.036 --> 00:09:03.686
added a support for more than

00:09:03.686 --> 00:09:06.106
100+ Neural Network layers.

00:09:07.356 --> 00:09:09.046
This means that you can bring

00:09:09.046 --> 00:09:11.186
almost, you can bring the most

00:09:11.186 --> 00:09:13.456
cutting-edge Machine Learning

00:09:13.456 --> 00:09:15.486
models into your app such as

00:09:15.486 --> 00:09:16.926
ELMo, BERT, Wavenet.

00:09:17.816 --> 00:09:18.586
What does that mean?

00:09:20.136 --> 00:09:21.716
Let's just say you have an app

00:09:21.716 --> 00:09:22.906
and you want to integrate a

00:09:22.906 --> 00:09:24.056
state of the art Question and

00:09:24.056 --> 00:09:26.476
Answer system in your app so

00:09:26.476 --> 00:09:28.156
that when a user asks a question

00:09:28.156 --> 00:09:29.556
how many sessions will there be

00:09:29.556 --> 00:09:30.606
at WWDC this year?

00:09:31.196 --> 00:09:32.896
You can do it by using BERT

00:09:32.966 --> 00:09:33.336
model.

00:09:34.536 --> 00:09:35.796
So the model can analyze the

00:09:35.796 --> 00:09:38.116
statement and gives feedback the

00:09:38.146 --> 00:09:43.956
result over 100 is the answer.

00:09:43.956 --> 00:09:45.286
Besides Natural Language you can

00:09:45.286 --> 00:09:47.756
also run the latest advances in

00:09:47.756 --> 00:09:49.166
Vision such as Instance

00:09:49.166 --> 00:09:51.666
Segmentation as well as latest

00:09:51.666 --> 00:09:53.256
advances in Audio Generation.

00:09:56.876 --> 00:09:58.606
And to take full advantage of

00:09:58.606 --> 00:10:00.216
this expanded support of Core

00:10:00.266 --> 00:10:03.146
ML, we are updating our

00:10:03.146 --> 00:10:03.556
converters.

00:10:03.556 --> 00:10:04.986
So we will have a brand new

00:10:04.986 --> 00:10:06.276
TensorFlow Core ML converter and

00:10:06.276 --> 00:10:08.676
ONNX support ML converter will

00:10:08.676 --> 00:10:09.566
be coming soon.

00:10:10.176 --> 00:10:14.756
We are also updating our Model

00:10:14.756 --> 00:10:16.326
Gallery importing some of these

00:10:16.366 --> 00:10:18.726
research models on our Model

00:10:18.726 --> 00:10:20.596
Gallery so you can start using

00:10:20.596 --> 00:10:21.566
them immediately.

00:10:22.686 --> 00:10:24.466
So Core ML 3 with this new model

00:10:24.466 --> 00:10:26.016
representation and embedded

00:10:26.056 --> 00:10:27.666
converters with Model Gallery

00:10:28.196 --> 00:10:29.526
can help you bring the cutting

00:10:29.526 --> 00:10:31.316
edge ML research into your app.

00:10:32.216 --> 00:10:33.476
Now a big feature, Model

00:10:33.476 --> 00:10:34.456
Personalization.

00:10:35.146 --> 00:10:36.836
So let me explain what it is.

00:10:37.336 --> 00:10:39.086
So up to now you have seen, you

00:10:39.086 --> 00:10:41.106
have used Create ML to build the

00:10:41.106 --> 00:10:44.006
models and Core ML to deploy the

00:10:44.006 --> 00:10:47.616
models, but new in Core ML 3 is

00:10:47.846 --> 00:10:49.806
On-Device Model Personalization.

00:10:50.266 --> 00:10:52.726
You can fine tune the model on

00:10:52.726 --> 00:10:53.236
the device.

00:10:53.966 --> 00:10:58.196
And we use this kind of

00:10:58.196 --> 00:11:00.466
technology in Face ID and

00:11:00.466 --> 00:11:01.276
setting Watch Face.

00:11:02.026 --> 00:11:05.536
So this is how it happens.

00:11:05.756 --> 00:11:08.506
Today you have data, you make an

00:11:08.566 --> 00:11:11.526
ML model, you ship it to your

00:11:11.736 --> 00:11:13.776
app and all of your users

00:11:13.776 --> 00:11:15.136
download the same model.

00:11:15.706 --> 00:11:19.716
And this is great because now

00:11:20.196 --> 00:11:21.596
users don't have to upload their

00:11:21.596 --> 00:11:21.986
photos.

00:11:22.346 --> 00:11:24.166
You can directly take photos,

00:11:24.646 --> 00:11:25.956
run through the model on the

00:11:25.956 --> 00:11:28.466
device and get inference such as

00:11:31.516 --> 00:11:31.616
dog.

00:11:31.836 --> 00:11:34.126
But what if you are trying to

00:11:34.126 --> 00:11:35.496
deal with a concept that is

00:11:35.496 --> 00:11:36.526
unique to each user?

00:11:37.096 --> 00:11:38.826
Say the concept of My Dog.

00:11:39.696 --> 00:11:41.006
You might want users to find

00:11:41.006 --> 00:11:42.866
pictures of their own dog in the

00:11:42.916 --> 00:11:44.456
photo library and not all dog

00:11:44.456 --> 00:11:47.216
photos they've taken.

00:11:47.336 --> 00:11:48.696
And each user's dog looks

00:11:48.696 --> 00:11:49.156
different.

00:11:49.156 --> 00:11:50.426
For example, someone may have

00:11:50.486 --> 00:11:51.706
Golden Retriever, someone may

00:11:52.196 --> 00:11:54.386
have this Bulldog, ah, and this

00:11:54.386 --> 00:11:56.976
is my crazy dog.

00:11:58.976 --> 00:12:01.546
So, how do we do that?

00:12:02.746 --> 00:12:05.106
So what we want is for user 1 we

00:12:05.106 --> 00:12:06.936
need image classifier that takes

00:12:06.936 --> 00:12:08.806
this dog and says it's their

00:12:08.806 --> 00:12:09.076
dog.

00:12:10.286 --> 00:12:12.326
For user 2, that's the English

00:12:12.326 --> 00:12:14.906
Bulldog and this the third dog.

00:12:18.576 --> 00:12:21.286
So in order to do that, one

00:12:21.286 --> 00:12:23.196
approach would be to use Server

00:12:23.196 --> 00:12:23.886
Based Approach.

00:12:23.916 --> 00:12:26.126
So you may ask each of your

00:12:26.636 --> 00:12:30.366
users to upload the photos in

00:12:31.836 --> 00:12:32.476
the Cloud.

00:12:32.476 --> 00:12:34.496
Server generates model for each

00:12:34.496 --> 00:12:37.526
of the users and then sends it

00:12:39.056 --> 00:12:39.466
back.

00:12:39.466 --> 00:12:41.826
Unfortunately, this approach has

00:12:41.826 --> 00:12:42.606
privacy concerns.

00:12:42.606 --> 00:12:45.006
Your user may not be very happy

00:12:45.266 --> 00:12:47.236
uploading their photo to your

00:12:47.236 --> 00:12:48.496
server and you may also not be

00:12:48.496 --> 00:12:49.516
okay taking their photo.

00:12:50.606 --> 00:12:51.866
You have to setup the server so

00:12:51.916 --> 00:12:53.296
there is some cost involved.

00:12:53.846 --> 00:12:56.346
Let us say you have a million

00:12:56.346 --> 00:12:58.036
users, which we sincerely hope

00:12:58.036 --> 00:12:59.396
you do, you have to make

00:12:59.396 --> 00:13:00.776
millions such models and keep

00:13:00.836 --> 00:13:02.966
track of them over time.

00:13:05.176 --> 00:13:07.356
With Core ML 3 you can do more

00:13:07.356 --> 00:13:09.186
personalization on the device.

00:13:09.396 --> 00:13:11.776
So if you have a training data

00:13:11.776 --> 00:13:13.886
on the device, you can just

00:13:13.886 --> 00:13:15.906
simply use it to fine tune the

00:13:15.906 --> 00:13:17.146
model on the device.

00:13:17.946 --> 00:13:23.366
So previously you take LMH and

00:13:23.366 --> 00:13:27.156
you do the inference and now you

00:13:27.156 --> 00:13:28.936
can take the label data feedback

00:13:28.936 --> 00:13:30.396
from the user, provide some kind

00:13:30.396 --> 00:13:32.386
of training data and fine tune

00:13:32.386 --> 00:13:34.276
the model on the device.

00:13:35.516 --> 00:13:42.226
[ Applause ]

00:13:42.726 --> 00:13:44.256
You have a personalized model

00:13:44.406 --> 00:13:46.006
for each user.

00:13:48.176 --> 00:13:50.826
We respect user's privacy and

00:13:50.826 --> 00:13:52.696
you don't need to put server.

00:13:53.386 --> 00:13:56.386
So Core ML 3 supports On-Device

00:13:56.386 --> 00:13:58.116
Personalization for Neural

00:13:58.936 --> 00:13:59.326
Networks.

00:13:59.786 --> 00:14:01.146
We're also supporting Nearest

00:14:01.276 --> 00:14:03.346
Neighbor and you can do it in

00:14:03.346 --> 00:14:05.246
the background at night.

00:14:08.536 --> 00:14:10.276
So to summarize and end our

00:14:10.356 --> 00:14:13.046
session we saw Create ML a brand

00:14:13.046 --> 00:14:16.006
new app to build ML models, we

00:14:16.006 --> 00:14:17.556
have a significant expansion in

00:14:17.556 --> 00:14:21.126
our Domain APIs and Core ML is

00:14:21.196 --> 00:14:22.586
much more flexible and now

00:14:22.586 --> 00:14:23.706
supports On-Device

00:14:23.706 --> 00:14:24.666
Personalization.

00:14:25.206 --> 00:14:29.016
You can find more information on

00:14:29.016 --> 00:14:30.796
our Developer Website Session

00:14:30.796 --> 00:14:33.966
209 and we hope you are as

00:14:33.996 --> 00:14:35.636
excited about these technologies

00:14:35.636 --> 00:14:36.176
as we are.

00:14:36.566 --> 00:14:37.876
I look forward to seeing you in

00:14:37.876 --> 00:14:38.226
the labs.

00:14:38.366 --> 00:14:38.706
Thank you.

00:14:39.516 --> 00:14:43.500
[ Applause ]