WEBVTT

00:00:00.506 --> 00:00:04.500
[ Music ]

00:00:07.516 --> 00:00:14.026
[ Applause ]

00:00:14.526 --> 00:00:15.626
>> Hello, everyone.

00:00:15.836 --> 00:00:16.516
Good afternoon.

00:00:17.316 --> 00:00:18.456
Welcome to the session.

00:00:19.796 --> 00:00:20.836
My name is Tao.

00:00:21.246 --> 00:00:22.446
I'm from Core ML Team.

00:00:23.276 --> 00:00:25.016
Today we're super excited to

00:00:25.016 --> 00:00:26.916
talk about a few new features we

00:00:26.916 --> 00:00:28.676
added to Create ML this year.

00:00:29.016 --> 00:00:30.136
In What's New in Machine

00:00:30.136 --> 00:00:31.536
Learning Session, you were

00:00:31.536 --> 00:00:33.286
introduced to the brand-new

00:00:33.336 --> 00:00:34.986
Create ML app.

00:00:34.986 --> 00:00:36.336
It's a great new tool designed

00:00:36.336 --> 00:00:38.226
by Apple to guide you through

00:00:38.226 --> 00:00:40.146
the essential steps of training

00:00:40.146 --> 00:00:41.206
of machine learning models.

00:00:42.226 --> 00:00:43.806
We believe this makes your

00:00:43.806 --> 00:00:46.016
machine learning workflow easy

00:00:46.016 --> 00:00:46.756
and approachable.

00:00:48.206 --> 00:00:49.366
Now, let's start with Text

00:00:49.366 --> 00:00:49.976
Classification.

00:00:52.546 --> 00:00:53.956
What is Text Classification?

00:00:54.536 --> 00:00:55.966
It's a machine learning task

00:00:56.346 --> 00:00:58.796
that classifies input text to a

00:00:58.886 --> 00:01:00.446
set of predefined labels.

00:01:03.136 --> 00:01:04.566
You can use it for sentiment

00:01:04.566 --> 00:01:07.626
analysis, like classifying text

00:01:07.626 --> 00:01:09.936
as positive or negative.

00:01:11.396 --> 00:01:12.756
Or doing spam detection.

00:01:12.756 --> 00:01:16.096
Or more complicated things like

00:01:16.386 --> 00:01:18.596
topic analysis, classifying text

00:01:18.596 --> 00:01:21.786
as food, politics, or science.

00:01:23.146 --> 00:01:24.556
Now, Text Classification has

00:01:24.556 --> 00:01:25.976
been supported since last year,

00:01:26.516 --> 00:01:28.296
but this year we're adding the

00:01:28.296 --> 00:01:30.076
support for the state of the art

00:01:30.076 --> 00:01:30.776
transfer learning.

00:01:31.636 --> 00:01:33.156
Today, I'm going to give you a

00:01:33.156 --> 00:01:35.206
concrete example of how you can

00:01:35.206 --> 00:01:37.346
train a Text Classifier using

00:01:37.346 --> 00:01:38.046
Transfer Learning.

00:01:39.446 --> 00:01:41.336
To train such a model, the first

00:01:41.336 --> 00:01:42.566
thing you'll want to do is

00:01:42.886 --> 00:01:44.616
collect some training data.

00:01:46.336 --> 00:01:48.386
Once you have the data, you can

00:01:48.386 --> 00:01:50.066
organize in an easy way.

00:01:51.116 --> 00:01:53.676
I have sports, entertainment and

00:01:53.676 --> 00:01:54.056
nature.

00:01:55.166 --> 00:01:56.996
Under each folder, I have a few

00:01:56.996 --> 00:01:57.626
text files.

00:01:58.236 --> 00:02:00.316
And each one of them is a single

00:02:00.316 --> 00:02:02.996
training example, and its label

00:02:03.146 --> 00:02:04.996
is simply the name of the folder

00:02:04.996 --> 00:02:05.406
they are in.

00:02:05.946 --> 00:02:07.786
And that's it.

00:02:07.786 --> 00:02:08.806
That's all you need to do with

00:02:08.806 --> 00:02:09.186
the data.

00:02:10.156 --> 00:02:11.636
I'll give you a quick demo to

00:02:11.636 --> 00:02:12.576
show how you can do this.

00:02:12.776 --> 00:02:15.606
On my desktop, I have a training

00:02:15.606 --> 00:02:15.956
data folder.

00:02:20.386 --> 00:02:21.456
So, I decided to have a little

00:02:21.456 --> 00:02:22.026
bit of fun.

00:02:22.716 --> 00:02:24.356
Instead of using plain text as

00:02:24.356 --> 00:02:26.546
the label, I used a few emojis.

00:02:27.426 --> 00:02:29.116
For example, for entertainment I

00:02:29.116 --> 00:02:30.306
use a camcorder.

00:02:31.106 --> 00:02:33.216
For sport, I'm using an American

00:02:33.216 --> 00:02:33.836
football.

00:02:35.196 --> 00:02:36.836
For nature, I'm using this cute

00:02:36.836 --> 00:02:39.486
little tent besides a great pine

00:02:40.856 --> 00:02:40.966
tree.

00:02:41.186 --> 00:02:42.536
You notice there is also this

00:02:42.656 --> 00:02:43.306
other folder.

00:02:44.186 --> 00:02:45.686
This is the training data that I

00:02:45.686 --> 00:02:46.936
actually don't want.

00:02:46.936 --> 00:02:49.466
I want my model to learn such

00:02:49.466 --> 00:02:51.326
that anything that's not one of

00:02:51.326 --> 00:02:53.416
the three intended class, I want

00:02:53.416 --> 00:02:55.756
my model to classify them into

00:02:56.726 --> 00:02:58.516
this class.

00:02:58.686 --> 00:03:00.286
So, let's take a look at a few

00:03:00.286 --> 00:03:00.936
examples here.

00:03:01.766 --> 00:03:05.186
For example if you read this

00:03:05.186 --> 00:03:06.056
sentence, there's something

00:03:06.056 --> 00:03:07.586
about writer and IMDB.

00:03:07.586 --> 00:03:09.026
It's clearly something related

00:03:09.026 --> 00:03:09.806
to entertainment.

00:03:13.006 --> 00:03:15.066
If I go into other folder, this

00:03:15.926 --> 00:03:19.086
is not one of the three intended

00:03:19.856 --> 00:03:20.006
class.

00:03:24.536 --> 00:03:25.546
That's about data.

00:03:25.796 --> 00:03:32.446
Now, I'll go to Create ML app.

00:03:34.436 --> 00:03:36.806
To do that, I go to Developer

00:03:36.806 --> 00:03:39.356
Tools and find the Create ML.

00:03:42.116 --> 00:03:43.256
But I'm going to do a new

00:03:43.256 --> 00:03:48.336
document and go to text.

00:03:48.496 --> 00:03:49.496
I'll name it like that.

00:03:50.736 --> 00:03:53.906
Create. So, I'm sure you have

00:03:53.906 --> 00:03:56.476
seen this user interface in the

00:03:56.476 --> 00:03:58.096
earlier session, Object

00:03:58.096 --> 00:03:58.776
Connection and

00:03:58.846 --> 00:03:59.916
Subclassification.

00:04:00.226 --> 00:04:01.466
So, I'm just going to drag my

00:04:01.466 --> 00:04:02.826
training data in directly here.

00:04:03.446 --> 00:04:05.956
So, it gives you some feedback

00:04:05.956 --> 00:04:06.926
about your training data.

00:04:07.366 --> 00:04:08.606
But what's new about Text

00:04:08.606 --> 00:04:10.306
Classifier is this particular

00:04:10.306 --> 00:04:11.236
parameter section.

00:04:11.866 --> 00:04:15.026
So, for today's demo, I'm going

00:04:15.026 --> 00:04:16.296
to select Transfer Learning.

00:04:17.736 --> 00:04:19.065
If we take a look at it, the

00:04:19.065 --> 00:04:20.596
first two algorithms actually

00:04:20.596 --> 00:04:21.995
have been supported since last

00:04:21.995 --> 00:04:22.136
year.

00:04:22.776 --> 00:04:23.826
And this year we're adding

00:04:23.826 --> 00:04:24.606
Transfer Learning.

00:04:25.096 --> 00:04:27.086
And for the demo I'm going to

00:04:27.086 --> 00:04:28.546
use this feature extractor

00:04:28.546 --> 00:04:29.826
called Dynamic Embedding.

00:04:30.156 --> 00:04:32.496
I'll go into the detail about

00:04:32.496 --> 00:04:33.946
what is Transfer Learning a bit

00:04:33.946 --> 00:04:35.936
later after the demo, but all

00:04:35.936 --> 00:04:37.846
you need to know now is Transfer

00:04:37.846 --> 00:04:39.256
Learning with Dynamic Embedding

00:04:39.676 --> 00:04:41.686
is actually an algorithm that

00:04:41.686 --> 00:04:43.096
pays attention to the semantic

00:04:43.096 --> 00:04:45.446
meaning of your input text.

00:04:47.036 --> 00:04:48.216
I'll start training.

00:04:49.346 --> 00:04:50.506
So, in general, Transfer

00:04:50.506 --> 00:04:52.326
Learning takes a bit longer to

00:04:52.326 --> 00:04:52.726
train.

00:04:53.516 --> 00:04:54.716
For this particular data set,

00:04:55.176 --> 00:04:57.416
it'll take about five minutes on

00:04:57.416 --> 00:04:58.316
this particular machine.

00:04:59.376 --> 00:05:01.196
So, I'm not going to wait.

00:05:02.666 --> 00:05:04.636
Instead, I have my pre-picked

00:05:04.966 --> 00:05:07.116
solution here that's trained on

00:05:07.116 --> 00:05:08.386
exactly the same data.

00:05:08.956 --> 00:05:12.286
Once the model has been trained,

00:05:12.286 --> 00:05:14.996
the accuracy test gives you a

00:05:14.996 --> 00:05:16.846
good summary about how your

00:05:16.846 --> 00:05:18.786
model performs on different

00:05:18.786 --> 00:05:21.266
data, broken down into different

00:05:21.266 --> 00:05:21.676
classes.

00:05:22.666 --> 00:05:24.216
It looks my model has done a

00:05:24.216 --> 00:05:26.246
good job on training validation

00:05:26.246 --> 00:05:26.836
and testing data.

00:05:27.486 --> 00:05:30.446
So, I will directly jump to the

00:05:30.446 --> 00:05:31.196
output tab.

00:05:31.946 --> 00:05:34.566
This preview pane gives you some

00:05:34.636 --> 00:05:37.116
summary about the model as well

00:05:37.116 --> 00:05:38.906
as a few different ways for you

00:05:38.906 --> 00:05:40.506
to do some quick experiments.

00:05:41.286 --> 00:05:42.836
For example, if you go to the

00:05:42.836 --> 00:05:44.576
lower right-hand side corner,

00:05:45.246 --> 00:05:47.526
you can directly add File to do

00:05:47.526 --> 00:05:50.166
a quick test.

00:05:50.336 --> 00:05:56.016
Or you can track a folder that

00:05:56.016 --> 00:05:57.756
the model will be able to make

00:05:57.756 --> 00:05:59.496
prediction of all the text file

00:05:59.526 --> 00:06:00.406
within that folder.

00:06:01.256 --> 00:06:02.696
The model actually will use the

00:06:02.696 --> 00:06:04.856
entire body of the text in each

00:06:04.856 --> 00:06:06.276
file to make a single

00:06:06.276 --> 00:06:06.776
prediction.

00:06:07.306 --> 00:06:10.336
But there is another way for you

00:06:10.336 --> 00:06:12.416
to do quick experiment which is

00:06:12.826 --> 00:06:13.626
manually typing.

00:06:16.446 --> 00:06:19.356
So in this particular text input

00:06:19.506 --> 00:06:22.066
section, when you, when I type

00:06:22.376 --> 00:06:25.566
each space, or if I stop typing

00:06:25.616 --> 00:06:27.406
for a little while, the model

00:06:27.406 --> 00:06:28.436
will make a prediction.

00:06:29.186 --> 00:06:30.966
So, let's see how that works.

00:06:33.136 --> 00:06:35.336
What a comeback win.

00:06:36.076 --> 00:06:40.886
Sport. Let's try something

00:06:40.926 --> 00:06:41.546
different.

00:06:42.896 --> 00:06:46.796
The season finale adds a twist

00:06:47.486 --> 00:06:48.966
to the plot.

00:06:49.456 --> 00:06:52.076
Which seems about right.

00:06:52.386 --> 00:06:52.966
Entertainment.

00:06:53.516 --> 00:06:56.826
[ Applause ]

00:06:57.326 --> 00:06:58.516
I actually also want to try

00:06:58.516 --> 00:07:00.086
something more recent and more

00:07:00.086 --> 00:07:00.566
relevant.

00:07:01.006 --> 00:07:03.166
This just came to me last night.

00:07:04.266 --> 00:07:14.356
The Raptors are on top of the

00:07:15.616 --> 00:07:15.976
mountain.

00:07:18.316 --> 00:07:18.796
Nature [laughter].

00:07:20.476 --> 00:07:21.856
Well, if I switch context.

00:07:26.016 --> 00:07:27.096
[ Applause ]

00:07:27.096 --> 00:07:27.946
It predicts sport.

00:07:28.516 --> 00:07:32.926
[ Applause ]

00:07:33.426 --> 00:07:35.206
So, I'm pretty happy with the

00:07:35.206 --> 00:07:35.966
model performance.

00:07:36.766 --> 00:07:38.276
Now I'm ready to deploy.

00:07:38.556 --> 00:07:40.186
So, I just simply drag it out

00:07:40.536 --> 00:07:42.086
and I can put it on my iOS

00:07:42.146 --> 00:07:42.626
devices.

00:07:51.556 --> 00:07:53.186
That's how you can train a Text

00:07:53.186 --> 00:07:54.876
Classifier using Transfer

00:07:54.876 --> 00:07:55.146
Learning.

00:07:56.366 --> 00:07:58.286
But you might want to ask what

00:07:58.286 --> 00:07:59.856
is Transfer Learning?

00:08:02.196 --> 00:08:03.896
Transfer Learning is a powerful

00:08:03.896 --> 00:08:05.736
machine learning technique where

00:08:05.736 --> 00:08:07.526
a model trained on a huge amount

00:08:07.526 --> 00:08:09.516
of data for one particular task

00:08:10.086 --> 00:08:11.936
can be repurposed for another

00:08:11.936 --> 00:08:15.226
task so that you, as developers,

00:08:15.226 --> 00:08:17.226
only need to prepare limited

00:08:17.226 --> 00:08:19.486
amount of data and still get

00:08:19.486 --> 00:08:20.786
your customized machine learning

00:08:20.786 --> 00:08:21.256
model.

00:08:21.706 --> 00:08:25.816
Create ML actually uses Transfer

00:08:25.816 --> 00:08:26.646
Learning for image

00:08:26.646 --> 00:08:27.866
classification today.

00:08:28.326 --> 00:08:30.206
And now we're bringing it to

00:08:31.166 --> 00:08:31.536
text.

00:08:32.426 --> 00:08:34.296
Well, to train a good Transfer

00:08:34.296 --> 00:08:36.866
Learning model for text, the

00:08:36.866 --> 00:08:37.796
problem is a little bit

00:08:37.796 --> 00:08:38.256
different.

00:08:39.176 --> 00:08:40.796
If you read this sentence, "I

00:08:41.056 --> 00:08:43.856
was able to park my car near the

00:08:43.856 --> 00:08:44.806
park entrance."

00:08:46.736 --> 00:08:48.936
For a model that's trained with

00:08:49.506 --> 00:08:51.776
conventional technique or study

00:08:51.776 --> 00:08:54.726
embedding, these two parts will

00:08:54.726 --> 00:08:57.586
look exactly the same.

00:08:57.766 --> 00:08:59.386
But for a model trained with

00:08:59.386 --> 00:09:01.036
Transfer Learning with Dynamic

00:09:01.036 --> 00:09:03.706
Embedding, because it pays

00:09:03.706 --> 00:09:04.916
attention to the semantic

00:09:04.916 --> 00:09:06.716
meaning of the overall context,

00:09:07.406 --> 00:09:09.826
it is able to figure out these

00:09:09.826 --> 00:09:11.216
two parts actually mean

00:09:11.216 --> 00:09:12.666
different things.

00:09:16.136 --> 00:09:18.206
To train such a good model, you

00:09:18.206 --> 00:09:19.586
need to do it on many texts.

00:09:20.056 --> 00:09:21.586
That's exactly what we did.

00:09:22.566 --> 00:09:26.716
We trained on billions of text

00:09:26.876 --> 00:09:28.096
and shipped that pretrained

00:09:28.096 --> 00:09:29.586
model to your mobile devices.

00:09:30.066 --> 00:09:31.956
And more importantly, we

00:09:31.956 --> 00:09:34.446
optimized its performance so

00:09:34.446 --> 00:09:38.316
that you only need to prepare

00:09:38.466 --> 00:09:40.126
your limited amount of raw text,

00:09:40.626 --> 00:09:43.686
send it in to Create ML app.

00:09:44.006 --> 00:09:46.286
Underneath it, it'll interact

00:09:46.286 --> 00:09:47.736
with the model that's already

00:09:47.736 --> 00:09:50.956
part of your OS and gives your

00:09:50.956 --> 00:09:52.816
customized text classifier.

00:09:55.696 --> 00:09:57.236
And you can deploy the same

00:09:57.236 --> 00:09:59.116
model on your iOS devices

00:09:59.436 --> 00:10:01.386
seamlessly because the

00:10:01.386 --> 00:10:03.116
pretrained model is already

00:10:03.116 --> 00:10:06.166
there for you to use.

00:10:06.476 --> 00:10:09.216
Now, that's the workflow to use

00:10:09.216 --> 00:10:11.016
the Create ML app to train your

00:10:11.016 --> 00:10:12.116
Text Classifier.

00:10:13.216 --> 00:10:14.816
If you're also interested in

00:10:15.056 --> 00:10:17.396
writing code, it's also very

00:10:17.396 --> 00:10:17.706
easy.

00:10:18.816 --> 00:10:20.106
To use the Transfer Learning

00:10:20.106 --> 00:10:22.136
with Dynamic Embedding, the only

00:10:22.136 --> 00:10:23.496
thing you need to specify is

00:10:23.496 --> 00:10:24.816
this model parameter.

00:10:25.616 --> 00:10:27.096
The rest of the code is exactly

00:10:27.096 --> 00:10:27.976
the same as last year.

00:10:32.986 --> 00:10:35.246
Now, I've shown you how to train

00:10:35.246 --> 00:10:37.756
Text Classifier, but I'd like to

00:10:37.756 --> 00:10:39.866
give you a few simple tips to

00:10:39.866 --> 00:10:41.906
get the most out of your Text

00:10:41.906 --> 00:10:42.476
Classifier.

00:10:45.086 --> 00:10:47.876
Now, choose an algorithm which

00:10:47.876 --> 00:10:49.206
suits your use case.

00:10:50.296 --> 00:10:51.836
Transfer Learning is only one of

00:10:51.836 --> 00:10:53.966
the three algorithms that Text

00:10:53.966 --> 00:10:55.256
Classifier supports.

00:10:57.656 --> 00:10:58.726
Different algorithms have

00:10:58.806 --> 00:10:59.556
different tradeoffs.

00:11:00.676 --> 00:11:02.236
To find out which one fits your

00:11:02.236 --> 00:11:04.596
use case best, please go to the

00:11:04.596 --> 00:11:05.926
Natural Language session that

00:11:05.926 --> 00:11:10.156
happens after this.

00:11:10.346 --> 00:11:11.816
Provide balanced classes.

00:11:12.196 --> 00:11:13.256
This is very important.

00:11:14.376 --> 00:11:15.686
In the particular example that I

00:11:15.686 --> 00:11:17.606
showed you, because each text

00:11:17.606 --> 00:11:19.146
file is a single training

00:11:19.146 --> 00:11:19.756
example.

00:11:20.526 --> 00:11:22.076
So, I roughly kept the same

00:11:22.076 --> 00:11:24.146
amount of text files in each of

00:11:24.146 --> 00:11:24.646
the folders.

00:11:28.086 --> 00:11:29.126
Data consistency.

00:11:29.626 --> 00:11:31.256
If you expect your Text

00:11:31.256 --> 00:11:33.226
Classifier to mostly work on

00:11:33.226 --> 00:11:35.876
short sentences, like I do, your

00:11:35.876 --> 00:11:37.336
training data should be mostly

00:11:37.336 --> 00:11:39.026
consisting of such examples.

00:11:39.906 --> 00:11:42.876
If you expect your Text

00:11:42.876 --> 00:11:44.196
Classifier to work on short

00:11:44.196 --> 00:11:47.076
words, paragraphs, or even an

00:11:47.076 --> 00:11:49.866
entire article, you also want to

00:11:49.866 --> 00:11:51.236
make sure your training data

00:11:51.236 --> 00:11:52.626
cover these cases as well.

00:11:53.516 --> 00:11:58.506
[ Applause ]