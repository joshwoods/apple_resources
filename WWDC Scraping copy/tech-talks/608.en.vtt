WEBVTT

00:00:00.767 --> 00:00:02.302
Jaap van Muijden: Welcome
to Metal Enhancements

00:00:02.302 --> 00:00:04.338
for A13 Bionic.

00:00:04.338 --> 00:00:05.973
My name is
Jaap van Muijden,

00:00:05.973 --> 00:00:08.976
from the GPU Software team
at Apple.

00:00:08.976 --> 00:00:12.913
Today I’m going to introduce you
to the latest Apple-designed GPU

00:00:12.913 --> 00:00:14.581
in the A13 Bionic,

00:00:14.581 --> 00:00:17.084
and the new Metal features
it enables.

00:00:17.084 --> 00:00:19.586
I will then then show you
how to use those features

00:00:19.586 --> 00:00:21.355
to reduce your app’s
memory usage,

00:00:21.355 --> 00:00:25.459
and optimize its run-time
performance.

00:00:25.459 --> 00:00:28.896
The new A13 Bionic
continues the rapid evolution

00:00:28.896 --> 00:00:30.264
of Apple-designed GPUs

00:00:30.264 --> 00:00:33.033
by focusing
on three major areas:

00:00:33.033 --> 00:00:35.836
general performance,
architectural improvements

00:00:35.836 --> 00:00:38.805
that better meet the evolving
needs of modern apps,

00:00:38.805 --> 00:00:41.141
and advanced Metal features.

00:00:41.141 --> 00:00:43.710
Let’s take a look at each.

00:00:43.710 --> 00:00:47.314
The GPU in A13 Bionic
is almost three times faster

00:00:47.314 --> 00:00:50.117
than the A10 Fusion
in general performance,

00:00:50.117 --> 00:00:52.352
and builds on the great
performance improvements

00:00:52.352 --> 00:00:55.789
of the A11 and A12 Bionic GPUs.

00:00:55.789 --> 00:00:58.625
Existing apps run faster
on the A13

00:00:58.625 --> 00:01:01.128
and can complete
each frame in less time,

00:01:01.128 --> 00:01:03.263
which in turn
leads to power savings

00:01:03.263 --> 00:01:06.266
and extended app usage.

00:01:06.266 --> 00:01:09.503
The Apple-designed GPU
architecture has quickly evolved

00:01:09.503 --> 00:01:11.972
to better meet the demands
of modern apps.

00:01:11.972 --> 00:01:13.407
Beginning with the A11,

00:01:13.407 --> 00:01:16.944
the 16-bit floating point and
texturing rates were increased

00:01:16.944 --> 00:01:19.346
to alleviate common
bottlenecks in games,

00:01:19.346 --> 00:01:20.814
and the numerical accuracy

00:01:20.814 --> 00:01:23.583
of 32-bit floating point
operations were improved

00:01:23.583 --> 00:01:26.553
to better handle
advanced compute workloads.

00:01:26.553 --> 00:01:30.057
The A12 GPU greatly improves
memory bandwidth

00:01:30.057 --> 00:01:33.427
by losslessly compressing and
decompressing texture content

00:01:33.427 --> 00:01:34.928
to and from memory.

00:01:34.928 --> 00:01:38.565
It also adds dedicated hardware
to support the user interface,

00:01:38.565 --> 00:01:40.701
ensuring even faster
response times,

00:01:40.701 --> 00:01:44.604
but also reducing the impact of
UI elements on foreground apps.

00:01:44.604 --> 00:01:48.141
And the A12 and later GPUs
enhance the iPad experience

00:01:48.141 --> 00:01:51.345
by sharing its resources
between apps more efficiently.

00:01:51.345 --> 00:01:54.948
And now we have the A13 GPU.

00:01:54.948 --> 00:01:58.251
The A13 GPU architecture
greatly improves the processing

00:01:58.251 --> 00:02:01.021
of high dynamic range content
on the GPU,

00:02:01.021 --> 00:02:03.824
by doubling the rate of 16-bit
floating point operations

00:02:03.824 --> 00:02:06.526
and adding support
for small 16-bit numbers

00:02:06.526 --> 00:02:08.762
that better preserve
black levels.

00:02:08.762 --> 00:02:12.432
The A13 GPU also provides
significantly better support

00:02:12.432 --> 00:02:14.001
for independent compute work

00:02:14.001 --> 00:02:17.504
that executes concurrently
with rendering workloads.

00:02:17.504 --> 00:02:19.673
Apple-designed GPUs
have supported

00:02:19.673 --> 00:02:23.110
this asynchronous compute
capability since the A9,

00:02:23.110 --> 00:02:26.179
but the A13 GPU
takes it to the next level

00:02:26.179 --> 00:02:29.182
by adding more hardware
channels and minimizing impact

00:02:29.182 --> 00:02:32.019
to the more deadline-sensitive
rendering tasks.

00:02:32.019 --> 00:02:35.856
Now before we describe the
new Metal features of the A13,

00:02:35.856 --> 00:02:38.725
let’s also quickly recap
some of the major Metal features

00:02:38.725 --> 00:02:43.163
introduced on the A11
and A12 GPUs.

00:02:43.163 --> 00:02:45.565
Let’s start with the A11.

00:02:45.565 --> 00:02:49.136
Tile shading, imageblocks, and
persistent threadgroup memory

00:02:49.136 --> 00:02:51.872
all are features
designed to explicitly leverage

00:02:51.872 --> 00:02:54.808
Apple’s tile-based
deferred rendering architecture

00:02:54.808 --> 00:02:57.544
and work together
to optimize the bandwidth usage

00:02:57.544 --> 00:03:00.013
of many modern
rendering techniques.

00:03:00.013 --> 00:03:02.816
Rasterization order groups
allow you to manage complex,

00:03:02.816 --> 00:03:05.018
per-pixel data structures
on the GPU,

00:03:05.018 --> 00:03:06.219
and color rate control

00:03:06.219 --> 00:03:09.156
optimizes the use of
multi-sample anti-aliasing

00:03:09.156 --> 00:03:12.359
in advanced
rendering algorithms.

00:03:12.359 --> 00:03:14.661
And now on to the A12.

00:03:14.661 --> 00:03:17.364
Layered rendering
lets each rendered primitive

00:03:17.364 --> 00:03:20.367
target a unique slice
of a 2D texture array,

00:03:20.367 --> 00:03:23.570
while multi-viewport rendering
lets each primitive do the same

00:03:23.570 --> 00:03:26.973
for up to 16 viewports
and scissor rectangles.

00:03:26.973 --> 00:03:29.076
Stencil feedback
lets each fragment

00:03:29.076 --> 00:03:31.244
set a unique
stencil reference value

00:03:31.244 --> 00:03:33.413
for advanced per-pixel effects,

00:03:33.413 --> 00:03:36.416
while stencil resolve
allows for stencil buffer reuse

00:03:36.416 --> 00:03:40.020
across MSAA and non-MSAA passes.

00:03:40.020 --> 00:03:41.555
And although
lossless compression

00:03:41.555 --> 00:03:43.723
is enabled by default
wherever possible,

00:03:43.723 --> 00:03:45.926
Metal also provides
direct control

00:03:45.926 --> 00:03:48.195
over in-place compression
and decompression

00:03:48.195 --> 00:03:50.130
of shared storage mode textures

00:03:50.130 --> 00:03:52.432
when optimal readback
is required.

00:03:52.432 --> 00:03:55.735
So now let’s introduce
the new Apple GPU Family 6

00:03:55.735 --> 00:03:58.738
that supports the A13 GPU.

00:03:58.738 --> 00:04:01.808
Sparse textures enable
higher-quality texture streaming

00:04:01.808 --> 00:04:04.611
for open-world games
at a fixed memory budget,

00:04:04.611 --> 00:04:07.214
by tracking the most important
regions of each texture

00:04:07.214 --> 00:04:09.950
and then mapping only those
regions to memory.

00:04:09.950 --> 00:04:12.486
Rasterization rate
maps focus high-quality

00:04:12.486 --> 00:04:15.589
rasterization and shading to the
image areas that matter most,

00:04:15.589 --> 00:04:17.224
while reducing rates elsewhere,

00:04:17.224 --> 00:04:19.892
saving both memory
and performance.

00:04:19.892 --> 00:04:23.563
Vertex amplification eliminates
redundant vertex processing

00:04:23.563 --> 00:04:24.898
that would otherwise occur

00:04:24.898 --> 00:04:27.567
with layered renders
that share geometry.

00:04:27.567 --> 00:04:30.270
GPU-driven pipelines
enable you to draw larger

00:04:30.270 --> 00:04:33.707
and more immersive scenes,
and with argument buffer tier 2,

00:04:33.707 --> 00:04:36.009
apps can execute
their GPU-driven workloads

00:04:36.009 --> 00:04:38.612
more flexibly than ever before.

00:04:38.612 --> 00:04:40.280
SIMD group instructions

00:04:40.280 --> 00:04:42.149
optimize sharing
and synchronization

00:04:42.149 --> 00:04:45.252
among the threads of
an SIMD group during shading.

00:04:45.252 --> 00:04:49.122
And ASTC HDR brings
high-quality lossy compression

00:04:49.122 --> 00:04:50.924
to high-dynamic range textures,

00:04:50.924 --> 00:04:53.860
saving significant
memory and bandwidth.

00:04:53.860 --> 00:04:55.829
Let’s look at each of these
in more detail,

00:04:55.829 --> 00:04:58.431
starting with sparse textures.

00:04:58.431 --> 00:05:00.700
Sparse textures
is a brand new feature

00:05:00.700 --> 00:05:02.836
introduced
on the A13 GPU

00:05:02.836 --> 00:05:06.173
that let you control the storage
and residency of Metal textures

00:05:06.173 --> 00:05:08.642
at a fine granularity.

00:05:08.642 --> 00:05:11.378
Sparse textures are not
fully resident in memory.

00:05:11.378 --> 00:05:13.647
But instead, you can allocate
sections of them

00:05:13.647 --> 00:05:16.316
on a special memory heap
called a sparse heap.

00:05:16.316 --> 00:05:18.485
Here you can see
two sparse textures

00:05:18.485 --> 00:05:21.821
that have parts of their data
allocated in such a sparse heap.

00:05:21.821 --> 00:05:23.390
A single heap
can provide storage

00:05:23.390 --> 00:05:24.658
for many sparse textures,

00:05:24.658 --> 00:05:27.928
all sharing a single
pre-allocated pool of memory.

00:05:27.928 --> 00:05:31.565
All sparse textures are split up
in units called sparse tiles,

00:05:31.565 --> 00:05:33.066
which have the same
memory footprint

00:05:33.066 --> 00:05:36.069
independent of texture
resolution or pixel format.

00:05:36.069 --> 00:05:38.772
So what are the applications
of this feature?

00:05:38.772 --> 00:05:40.840
One of them
is texture streaming.

00:05:40.840 --> 00:05:44.411
Texture streaming lets you
render incredibly large scenes

00:05:44.411 --> 00:05:46.079
with a fixed memory footprint

00:05:46.079 --> 00:05:47.847
by loading only
the texture mipmaps

00:05:47.847 --> 00:05:49.649
that are needed
for the current view.

00:05:49.649 --> 00:05:51.418
With traditional
texture streaming,

00:05:51.418 --> 00:05:53.920
individual mipmaps
are loaded when required

00:05:53.920 --> 00:05:55.855
and evicted
when no longer needed,

00:05:55.855 --> 00:05:58.825
or when more important textures
need the memory.

00:05:58.825 --> 00:06:02.262
Texture streaming traditionally
manages texture residency

00:06:02.262 --> 00:06:04.164
at mipmap granularity.

00:06:04.164 --> 00:06:06.833
The lowest levels of the
mipmap pyramid are kept resident

00:06:06.833 --> 00:06:09.202
in case a higher quality
mipmap is requested,

00:06:09.202 --> 00:06:10.804
but not yet streamed in.

00:06:10.804 --> 00:06:12.339
It may not be available yet

00:06:12.339 --> 00:06:14.507
because the loading operation
has not completed,

00:06:14.507 --> 00:06:17.310
or there is insufficient
allocated streaming memory.

00:06:17.310 --> 00:06:19.446
Having the lowest level
mipmaps available

00:06:19.446 --> 00:06:22.249
ensures that there is always
some valid data to sample,

00:06:22.249 --> 00:06:24.718
even though
it is of lower resolution.

00:06:24.718 --> 00:06:26.553
Metal’s sparse texture feature

00:06:26.553 --> 00:06:30.290
improves on this texture
streaming model in two ways.

00:06:30.290 --> 00:06:33.860
First, sparse textures
provide texture access counters

00:06:33.860 --> 00:06:35.295
that you can use to determine

00:06:35.295 --> 00:06:38.331
how often each region
of a sparse texture is accessed.

00:06:38.331 --> 00:06:40.333
This lets you prioritize
texture loading,

00:06:40.333 --> 00:06:42.836
as regions that are accessed
more often by the renderer

00:06:42.836 --> 00:06:45.772
are generally more visible
in the current view.

00:06:45.772 --> 00:06:48.208
Secondly, residency
can be managed

00:06:48.208 --> 00:06:51.745
at the sparse tile granularity
instead of mipmap granularity.

00:06:51.745 --> 00:06:53.446
This lets you
be even more efficient

00:06:53.446 --> 00:06:54.581
with your texture memory,

00:06:54.581 --> 00:06:58.585
and allows for more visible
texture detail where it counts.

00:06:58.585 --> 00:07:00.820
Taken together, sparse textures

00:07:00.820 --> 00:07:02.522
let you stream
more visible detail

00:07:02.522 --> 00:07:05.392
with the same memory budget,
improving quality.

00:07:05.392 --> 00:07:07.460
Now let’s look at
how you create and use

00:07:07.460 --> 00:07:09.863
sparse textures in Metal.

00:07:09.863 --> 00:07:13.600
To start using sparse textures,
you first create a sparse heap

00:07:13.600 --> 00:07:16.303
and then allocate
one or more textures from it.

00:07:16.303 --> 00:07:18.505
New sparse textures
are created initially

00:07:18.505 --> 00:07:20.640
without any mapped sparse tiles.

00:07:20.640 --> 00:07:23.376
You need to request memory
mappings from the heap

00:07:23.376 --> 00:07:25.045
using the GPU.

00:07:25.045 --> 00:07:27.814
The memory is mapped
in tile-sized units

00:07:27.814 --> 00:07:31.685
called sparse tiles,
similar to virtual memory pages.

00:07:31.685 --> 00:07:35.288
Likewise, you need request
the GPU to unmap tiles

00:07:35.288 --> 00:07:36.956
when they are no longer needed.

00:07:36.956 --> 00:07:40.093
Sampling a sparse texture works
just like a regular texture,

00:07:40.093 --> 00:07:43.430
and sampling unmapped regions
return zeros.

00:07:43.430 --> 00:07:45.432
Finally, the texture
access counters

00:07:45.432 --> 00:07:47.133
can be read back
from a sparse texture,

00:07:47.133 --> 00:07:50.603
to get estimates for
how often each tile is accessed,

00:07:50.603 --> 00:07:53.139
so that you can precisely
control and prioritize

00:07:53.139 --> 00:07:55.475
when you map tiles
for your textures.

00:07:55.475 --> 00:07:58.745
Let’s look at each
of these steps in more detail.

00:07:58.745 --> 00:08:00.080
Here we have some Metal code

00:08:00.080 --> 00:08:01.848
that creates
a sparse texture heap

00:08:01.848 --> 00:08:03.783
with a given memory size.

00:08:03.783 --> 00:08:05.752
We first calculate
the size of our heap,

00:08:05.752 --> 00:08:08.855
and make sure it is a multiple
of the sparse tile size.

00:08:08.855 --> 00:08:10.423
Here we use
a local helper function

00:08:10.423 --> 00:08:11.791
to round up our data size

00:08:11.791 --> 00:08:15.028
to the nearest multiple
of the sparse tile size.

00:08:15.028 --> 00:08:17.397
We can then generate
the sparse heap descriptor;

00:08:17.397 --> 00:08:19.299
we set the heap type to sparse,

00:08:19.299 --> 00:08:22.635
and specify the size
of our heap in bytes.

00:08:22.635 --> 00:08:27.707
We then create the sparse heap
using our MTLDevice object.

00:08:27.707 --> 00:08:30.677
Creating a sparse texture
is very easy.

00:08:30.677 --> 00:08:33.480
First, we create
a texture descriptor as normal,

00:08:33.480 --> 00:08:37.583
and then we create the texture
using the sparse heap object.

00:08:37.583 --> 00:08:40.587
Now that we have seen how you
can create the sparse texture,

00:08:40.587 --> 00:08:44.557
let’s take a look at how
to map regions onto memory.

00:08:44.557 --> 00:08:47.193
The mapping and unmapping
of regions of a texture

00:08:47.193 --> 00:08:49.896
is done by encoding
map and unmap commands

00:08:49.896 --> 00:08:52.632
in a resource state
command encoder.

00:08:52.632 --> 00:08:54.300
This encoder
can be used to schedule

00:08:54.300 --> 00:08:57.370
the map and unmap operations
on the GPU timeline,

00:08:57.370 --> 00:09:00.607
similar to encoding other
render commands in Metal.

00:09:00.607 --> 00:09:03.777
Let’s see how this looks
in code.

00:09:03.777 --> 00:09:06.479
First we create the encoder.

00:09:06.479 --> 00:09:09.082
And then we simply
encode a map operation;

00:09:09.082 --> 00:09:11.384
we specify the texture
and what regions,

00:09:11.384 --> 00:09:14.921
slice, and mip level
of the texture we want to map.

00:09:14.921 --> 00:09:16.856
The region is now mapped,
and you can blit

00:09:16.856 --> 00:09:20.360
or create your texture data
onto the mapped memory.

00:09:20.360 --> 00:09:23.196
To unmap a section,
we follow the same procedure;

00:09:23.196 --> 00:09:26.399
the only difference is the mode
of the update we encode.

00:09:26.399 --> 00:09:28.902
Now that you have created
and mapped our texture data,

00:09:28.902 --> 00:09:32.705
let’s move on to
the sampling of sparse textures.

00:09:32.705 --> 00:09:34.941
Sampling from a sparse texture
is no different

00:09:34.941 --> 00:09:36.943
than sampling
from a normal texture.

00:09:36.943 --> 00:09:38.411
There is well-defined behavior

00:09:38.411 --> 00:09:40.814
in case an unmapped section
is accessed.

00:09:40.814 --> 00:09:43.983
Sampling an unmapped region
returns a vector of zeroes,

00:09:43.983 --> 00:09:46.052
and any writes are discarded.

00:09:46.052 --> 00:09:48.354
In addition to the standard
sampling functions,

00:09:48.354 --> 00:09:50.623
Metal provides
a sparse_sample function

00:09:50.623 --> 00:09:54.360
that can be used in shaders
to test for unmapped regions.

00:09:54.360 --> 00:09:56.663
Now that you’ve seen
how to create, map,

00:09:56.663 --> 00:09:58.298
and sample sparse textures,

00:09:58.298 --> 00:10:01.668
let’s look at
a simple implementation.

00:10:01.668 --> 00:10:04.471
One way to efficiently sample
sparse textures

00:10:04.471 --> 00:10:06.906
is to perform fallback sampling.

00:10:06.906 --> 00:10:09.776
In your shader, you can
first try to fetch texels

00:10:09.776 --> 00:10:12.378
using the sparse_sample method,
and if that fails,

00:10:12.378 --> 00:10:15.215
you can fall back
to a lower-level mipmap.

00:10:15.215 --> 00:10:17.450
By always keeping
the lower mipmap loaded,

00:10:17.450 --> 00:10:20.753
you are guaranteed
to find a valid sample.

00:10:20.753 --> 00:10:23.256
And to better support
fallback sampling,

00:10:23.256 --> 00:10:26.359
the Metal shading language
also supports a new argument

00:10:26.359 --> 00:10:29.395
on texture methods
called min LOD clamp.

00:10:29.395 --> 00:10:31.331
Min LOD clamp lets you set

00:10:31.331 --> 00:10:34.334
the highest mipmap in the chain
that can be accessed.

00:10:34.334 --> 00:10:36.669
This lets you guarantee
a valid sample

00:10:36.669 --> 00:10:40.306
by specifying the highest mipmap
that you know you have data for.

00:10:40.306 --> 00:10:43.076
Let’s look at that in code.

00:10:43.076 --> 00:10:44.911
Here we have a fragment shader

00:10:44.911 --> 00:10:47.480
that samples
from a sparse texture.

00:10:47.480 --> 00:10:49.215
You start sampling
your sparse texture

00:10:49.215 --> 00:10:51.084
using the sparse_sample method,

00:10:51.084 --> 00:10:53.953
which returns
a sparse_color object.

00:10:53.953 --> 00:10:56.656
You can then call the resident
method on the returned object

00:10:56.656 --> 00:10:59.726
to determine if the GPU
sampled mapped data.

00:10:59.726 --> 00:11:03.429
If it did, you retrieve
the sampled value and return it.

00:11:03.429 --> 00:11:05.999
Otherwise you sample
the sparse texture again,

00:11:05.999 --> 00:11:08.101
but this time with an LOD clamp

00:11:08.101 --> 00:11:10.670
to force the sampler
to bypass higher mipmaps.

00:11:10.670 --> 00:11:12.305
Since you guaranteed
that this mipmap

00:11:12.305 --> 00:11:14.173
and lower mipmaps have data,

00:11:14.173 --> 00:11:18.177
the second sampling call is made
using the normal sample method.

00:11:18.177 --> 00:11:19.712
Now that you’ve seen
the functions

00:11:19.712 --> 00:11:22.448
for mapping and sampling
sparse texture data,

00:11:22.448 --> 00:11:24.884
let’s talk a little bit
about how to decide

00:11:24.884 --> 00:11:29.188
when to map or free
sparse texture tiles.

00:11:29.188 --> 00:11:30.924
Traditional texture streaming
systems

00:11:30.924 --> 00:11:33.393
manually collect
app-level statistics

00:11:33.393 --> 00:11:36.029
to help prioritize
texture residency.

00:11:36.029 --> 00:11:37.997
These methods are often coarse

00:11:37.997 --> 00:11:40.099
at the mipmap
or mesh granularity

00:11:40.099 --> 00:11:41.935
to help manage the overhead.

00:11:41.935 --> 00:11:44.971
Metal instead supports
a fine-grained solution

00:11:44.971 --> 00:11:46.940
called texture access counters.

00:11:46.940 --> 00:11:48.975
These counters accurately track

00:11:48.975 --> 00:11:51.744
how often sparse tiles
are accessed by the GPU

00:11:51.744 --> 00:11:53.513
with very low overhead.

00:11:53.513 --> 00:11:56.215
Texture access counters
are queried from the GPU.

00:11:56.215 --> 00:11:59.052
Let’s look at how this works.

00:11:59.052 --> 00:12:02.221
This Metal example will collect
the texture access counters

00:12:02.221 --> 00:12:03.556
from the GPU.

00:12:03.556 --> 00:12:07.660
You start by creating a buffer
to contain the sampled counters.

00:12:07.660 --> 00:12:09.829
And then you encode a blit
to copy the counters

00:12:09.829 --> 00:12:12.231
from our sparse texture
to our buffer,

00:12:12.231 --> 00:12:16.402
specifying the mip level, slice,
and region you’re interested in.

00:12:16.402 --> 00:12:18.237
Traditional texture
streaming techniques

00:12:18.237 --> 00:12:20.406
have served us very well
over the years,

00:12:20.406 --> 00:12:22.008
and given a fixed memory budget,

00:12:22.008 --> 00:12:25.878
we can stream in the mip levels
for the textures that user sees.

00:12:25.878 --> 00:12:27.847
When the texture budget
gets exhausted,

00:12:27.847 --> 00:12:30.516
we can no longer stream
in higher resolution mip levels

00:12:30.516 --> 00:12:33.620
and we start seeing
uniformly blurry textures.

00:12:33.620 --> 00:12:35.321
But with sparse textures,

00:12:35.321 --> 00:12:37.523
you can now get a better usage
of your memory.

00:12:37.523 --> 00:12:39.392
You can map the memory
to make room

00:12:39.392 --> 00:12:41.928
for the individual texture tiles
that the user sees,

00:12:41.928 --> 00:12:44.530
at the quality level that is
most appropriate

00:12:44.530 --> 00:12:47.533
for each texture tile
within a given mip level.

00:12:47.533 --> 00:12:49.902
This allows you
to distribute texture memory

00:12:49.902 --> 00:12:52.705
for the tiles that make
the most visual impact.

00:12:52.705 --> 00:12:55.241
Additionally, this feature
saves bandwidth

00:12:55.241 --> 00:12:58.144
when streaming textures,
as the sparse texture API

00:12:58.144 --> 00:13:01.147
allows you to map and unmap
individual tiles

00:13:01.147 --> 00:13:03.049
instead of having to copy
and rearrange

00:13:03.049 --> 00:13:06.152
entire mipmap chains in memory
during streaming.

00:13:06.152 --> 00:13:07.820
That’s it for sparse textures,

00:13:07.820 --> 00:13:09.656
a really important
memory optimization

00:13:09.656 --> 00:13:12.492
that will also improve
texture streaming quality.

00:13:12.492 --> 00:13:15.161
Now let’s move on to the runtime
optimization technique

00:13:15.161 --> 00:13:17.363
called rasterization rate maps.

00:13:17.363 --> 00:13:18.765
Rasterization rate maps

00:13:18.765 --> 00:13:21.034
let you make better use
of Retina displays

00:13:21.034 --> 00:13:24.671
by rasterizing and shading
the image areas that matter most

00:13:24.671 --> 00:13:26.039
at highest resolution,

00:13:26.039 --> 00:13:29.575
while reducing quality
where it's not perceived.

00:13:29.575 --> 00:13:30.910
Rasterization rate maps

00:13:30.910 --> 00:13:33.913
let you rasterize and shade
at multiple resolutions

00:13:33.913 --> 00:13:37.483
by defining both a screen space
and physical render target size,

00:13:37.483 --> 00:13:40.219
and a nonuniform mapping
between the two spaces,

00:13:40.219 --> 00:13:42.488
to control the quality
of each region.

00:13:42.488 --> 00:13:45.158
The physical resolution is
smaller than the screen space,

00:13:45.158 --> 00:13:47.960
saving bandwidth and reducing
the memory footprint.

00:13:47.960 --> 00:13:49.529
And the nonuniform mapping

00:13:49.529 --> 00:13:51.330
results in higher-quality
visuals

00:13:51.330 --> 00:13:53.599
than the uniform upscale
often used in games

00:13:53.599 --> 00:13:56.269
at a fraction of the cost
of rendering the entire screen

00:13:56.269 --> 00:13:57.970
at native resolution.

00:13:57.970 --> 00:14:01.507
Let’s take a closer look
at how this works.

00:14:01.507 --> 00:14:03.309
Here is a screenshot
of a diffuse layer

00:14:03.309 --> 00:14:05.945
from the g-buffer
of a sample renderer.

00:14:05.945 --> 00:14:07.880
Traditional rendering
draws geometry

00:14:07.880 --> 00:14:10.650
by calculating the screen space
coordinates of each vertex,

00:14:10.650 --> 00:14:12.518
and then rasterizing
the resulting primitives

00:14:12.518 --> 00:14:15.221
in screen space
to produce fragments.

00:14:15.221 --> 00:14:17.990
These screen space coordinates
have a one-to-one mapping

00:14:17.990 --> 00:14:20.193
to the coordinates of
the physical render target

00:14:20.193 --> 00:14:21.928
during rasterization.

00:14:21.928 --> 00:14:25.698
With rasterization rate maps,
you can configure the rasterizer

00:14:25.698 --> 00:14:29.135
to map screen space coordinates
unevenly when creating fragments

00:14:29.135 --> 00:14:31.871
thus reducing the number
of total fragments produced

00:14:31.871 --> 00:14:35.341
and simultaneously rendering
to a smaller render target.

00:14:35.341 --> 00:14:37.677
In both images,
the white grid corresponds

00:14:37.677 --> 00:14:40.513
to an evenly spaced grid
in virtual screen space.

00:14:40.513 --> 00:14:42.014
But as you can see here,

00:14:42.014 --> 00:14:44.817
it is distributed unevenly
in physical space.

00:14:44.817 --> 00:14:47.854
In this example, we’ve used
rasterization rate maps

00:14:47.854 --> 00:14:50.556
to keep the screen resolution
in the center of the screen,

00:14:50.556 --> 00:14:53.092
but reducing it towards
the edges of the screen.

00:14:53.092 --> 00:14:54.494
To see this more clearly,

00:14:54.494 --> 00:14:57.897
let’s zoom in
on one of the center tiles.

00:14:57.897 --> 00:15:00.032
The resolution
of this physical tile

00:15:00.032 --> 00:15:02.335
matches the resolution
of the same region

00:15:02.335 --> 00:15:03.703
within the g-buffer.

00:15:03.703 --> 00:15:05.905
But as you move towards
the edge of the screen,

00:15:05.905 --> 00:15:07.373
the quality is reduced

00:15:07.373 --> 00:15:09.509
by effectively reducing
the physical space

00:15:09.509 --> 00:15:11.244
dedicated to that tile.

00:15:11.244 --> 00:15:13.913
This leads to a distorted image
in your physical image,

00:15:13.913 --> 00:15:15.481
but we will show
that this mapping

00:15:15.481 --> 00:15:19.118
can be reversed to create
an undistorted final image.

00:15:19.118 --> 00:15:22.922
But first, let’s take a look
at how the mappings are defined.

00:15:22.922 --> 00:15:26.058
The mapping is defined
as two 1D functions

00:15:26.058 --> 00:15:28.995
in the X and Y axes
of the screen space.

00:15:28.995 --> 00:15:30.963
You describe these functions
in Metal

00:15:30.963 --> 00:15:32.799
using a series of control points

00:15:32.799 --> 00:15:35.001
defining the quality
requirements.

00:15:35.001 --> 00:15:37.870
In this image, we can see
the effective rasterization rate

00:15:37.870 --> 00:15:39.038
across the screen,

00:15:39.038 --> 00:15:41.874
given our two 1D functions
along the axis.

00:15:41.874 --> 00:15:45.478
A quality level of one means
that fragment shader is invoked

00:15:45.478 --> 00:15:48.447
for every screen space pixel
along the axis.

00:15:48.447 --> 00:15:50.116
And a quality level of .5

00:15:50.116 --> 00:15:52.585
means that for at least
50 percent of the pixels,

00:15:52.585 --> 00:15:55.354
a fragment shader
is invoked along a given axis.

00:15:55.354 --> 00:15:57.790
A quality level of zero means
that each fragment shader

00:15:57.790 --> 00:16:00.993
will be invoked at the minimum
rate supported by Metal.

00:16:00.993 --> 00:16:02.895
Metal will resample
these control points

00:16:02.895 --> 00:16:04.997
to create a final rate map.

00:16:04.997 --> 00:16:07.466
Even though you don’t control
the final mapping directly,

00:16:07.466 --> 00:16:11.304
Metal guarantees that your
minimum quality is preserved.

00:16:11.304 --> 00:16:13.539
Now let’s create this mapping
with Metal.

00:16:13.539 --> 00:16:14.974
Here is the Metal code

00:16:14.974 --> 00:16:18.544
that builds the rasterization
rate map you just saw.

00:16:18.544 --> 00:16:21.480
First, you define
the rasterization function.

00:16:21.480 --> 00:16:25.051
In this example we will use the
five values we showed previously

00:16:25.051 --> 00:16:28.221
for both the horizontal
and vertical axis of our map.

00:16:28.221 --> 00:16:29.956
You then fill
the layer descriptor

00:16:29.956 --> 00:16:33.426
to describe the quality across
our rasterization rate map.

00:16:33.426 --> 00:16:34.493
You then create one

00:16:34.493 --> 00:16:37.997
by providing the horizontal
and vertical quality functions.

00:16:37.997 --> 00:16:40.466
With your quality defined,
you now create

00:16:40.466 --> 00:16:42.668
a Metal rasterization
rate map descriptor

00:16:42.668 --> 00:16:43.903
from the layer descriptor

00:16:43.903 --> 00:16:46.339
and our final screen space
resolution.

00:16:46.339 --> 00:16:48.841
Finally, you use your
Metal device

00:16:48.841 --> 00:16:51.611
to instantiate
a rasterization rate map object

00:16:51.611 --> 00:16:53.279
using that descriptor.

00:16:53.279 --> 00:16:55.648
Next we need to create
the physical render target

00:16:55.648 --> 00:16:58.117
for this map.

00:16:58.117 --> 00:17:00.353
Because the actual
rasterization rate map rates

00:17:00.353 --> 00:17:02.054
are implementation dependent,

00:17:02.054 --> 00:17:04.824
you need to first query the
physical size of the resource

00:17:04.824 --> 00:17:06.157
from the map.

00:17:06.157 --> 00:17:08.761
You then create the physical
render target as usual:

00:17:08.761 --> 00:17:11.329
specify the correct usage
and storage properties,

00:17:11.329 --> 00:17:15.300
and instantiate the texture
using your Metal device object.

00:17:15.300 --> 00:17:18.604
Finally, you combine the created
texture and rasterization map

00:17:18.604 --> 00:17:22.708
to set up your render pass
and render as usual.

00:17:22.708 --> 00:17:23.509
And with that,

00:17:23.509 --> 00:17:26.112
you have rasterized
your g-buffer nonuniformly.

00:17:26.112 --> 00:17:29.248
But what about shading
the g-buffer in later passes?

00:17:29.248 --> 00:17:31.784
With a traditional
deferred shading pipeline,

00:17:31.784 --> 00:17:33.119
you can continue lighting

00:17:33.119 --> 00:17:34.720
with the same
rasterization rate map

00:17:34.720 --> 00:17:37.657
because your light geometry
will get correctly rasterized

00:17:37.657 --> 00:17:40.493
in the same screen space
as your g-buffer.

00:17:40.493 --> 00:17:42.061
With tiled deferred renderers,

00:17:42.061 --> 00:17:44.063
you will need to do
a little more work.

00:17:44.063 --> 00:17:45.331
If you’re not already familiar

00:17:45.331 --> 00:17:46.799
with the tiled deferred
rendering,

00:17:46.799 --> 00:17:52.104
please see our Modern Rendering
with Metal talk at WWDC 2019.

00:17:52.104 --> 00:17:53.606
With tiled deferred,

00:17:53.606 --> 00:17:55.441
your render target's
physical space

00:17:55.441 --> 00:17:57.610
is split into equally sized
blocks of pixels

00:17:57.610 --> 00:18:01.080
and each block performs
light tile culling and shading.

00:18:01.080 --> 00:18:04.250
In the presented image,
our sample code shows a heat map

00:18:04.250 --> 00:18:08.020
for the number of lights
per block of 32 by 32 pixels.

00:18:08.020 --> 00:18:11.190
Because screen space no longer
corresponds to physical space,

00:18:11.190 --> 00:18:13.426
integrating rasterization
rate maps

00:18:13.426 --> 00:18:16.729
with tiled deferred renderers
requires one additional step.

00:18:16.729 --> 00:18:18.564
The lighting shader
will need to transform

00:18:18.564 --> 00:18:20.466
the pixel coordinates
in physical space

00:18:20.466 --> 00:18:22.201
to the virtual screen space.

00:18:22.201 --> 00:18:25.438
This is the reverse mapping
used during rasterization.

00:18:25.438 --> 00:18:28.107
Let’s take a look at how you
can perform this reverse mapping

00:18:28.107 --> 00:18:29.842
in your shaders.

00:18:29.842 --> 00:18:31.077
First you have to make

00:18:31.077 --> 00:18:32.745
the rasterization rate map
parameters

00:18:32.745 --> 00:18:34.413
accessible to the shader.

00:18:34.413 --> 00:18:36.916
To do this, first you
create a MTLBuffer

00:18:36.916 --> 00:18:39.085
that can hold the parameters.

00:18:39.085 --> 00:18:40.553
You then copy
the parameter data

00:18:40.553 --> 00:18:42.788
into a MTLBuffer.

00:18:42.788 --> 00:18:45.691
And finally, bind the MTLBuffer
to your shader.

00:18:45.691 --> 00:18:48.661
Now that the map is bound,
let’s use it.

00:18:48.661 --> 00:18:50.162
In the shader,
you now have access

00:18:50.162 --> 00:18:52.598
to a rasterization_rate_map_data
object

00:18:52.598 --> 00:18:55.134
at the corresponding
buffer bind point.

00:18:55.134 --> 00:18:57.069
You can use that object
to instantiate

00:18:57.069 --> 00:18:59.805
a rasterization_rate_map
_decoder object.

00:18:59.805 --> 00:19:01.073
And then use the decoder

00:19:01.073 --> 00:19:04.377
to transform between the
physical and screen coordinates.

00:19:04.377 --> 00:19:06.746
Returning to our tiled
deferred renderer,

00:19:06.746 --> 00:19:08.881
we use the decoder
to perform tile culling

00:19:08.881 --> 00:19:11.650
in the virtual screen space.

00:19:11.650 --> 00:19:14.420
Adapting your light culling
to virtual screen space

00:19:14.420 --> 00:19:16.288
means your tiles
are no longer square,

00:19:16.288 --> 00:19:19.225
but now follow the correct area
in screen space.

00:19:19.225 --> 00:19:20.559
Let’s compare this heat map

00:19:20.559 --> 00:19:23.863
to the full, uniform
resolution render.

00:19:23.863 --> 00:19:26.766
And back to the
rasterization rate map version.

00:19:26.766 --> 00:19:29.402
As you can see,
with rasterization rate maps,

00:19:29.402 --> 00:19:32.171
we’ve significantly reduced
the amount of shaded tiles

00:19:32.171 --> 00:19:34.106
on our screen.

00:19:34.106 --> 00:19:36.909
Finally, let’s consider
how rasterization rate maps

00:19:36.909 --> 00:19:41.147
are prepared for compositing
and final presentation.

00:19:41.147 --> 00:19:43.282
Before displaying
the final image to the screen,

00:19:43.282 --> 00:19:45.718
you need to unwrap it
using a full screen pass

00:19:45.718 --> 00:19:47.486
that transforms
the physical space texture

00:19:47.486 --> 00:19:49.355
to a high-resolution surface

00:19:49.355 --> 00:19:51.891
using the shader mapping
just described.

00:19:51.891 --> 00:19:53.059
As you can see,

00:19:53.059 --> 00:19:56.095
it is very difficult
to notice the quality trade-offs

00:19:56.095 --> 00:19:57.897
despite the aggressive falloffs

00:19:57.897 --> 00:20:01.067
that were chosen
for this sample.

00:20:01.067 --> 00:20:02.868
We expect
rasterization rate maps

00:20:02.868 --> 00:20:04.637
to be combined
with other techniques,

00:20:04.637 --> 00:20:06.205
such as depth of field,

00:20:06.205 --> 00:20:08.441
to hide the quality tradeoff.

00:20:08.441 --> 00:20:10.209
That’s it for
rasterization rate maps.

00:20:10.209 --> 00:20:14.747
Let’s move on
to vertex amplification.

00:20:14.747 --> 00:20:17.950
Vertex amplification lets you
reduce geometry processing

00:20:17.950 --> 00:20:20.719
in multi-view rendering cases.

00:20:20.719 --> 00:20:22.988
Multi-layer and multi-viewport
rendering

00:20:22.988 --> 00:20:24.757
reduce the number
of draw calls needed

00:20:24.757 --> 00:20:27.359
to target each view
using instancing.

00:20:27.359 --> 00:20:29.261
But that doesn’t
eliminate the GPU cost

00:20:29.261 --> 00:20:32.064
of processing
each of these instances.

00:20:32.064 --> 00:20:33.532
Many multi-layer
and multi-viewport

00:20:33.532 --> 00:20:36.669
rendering techniques share
geometry between views.

00:20:36.669 --> 00:20:39.105
For example, between the
cascades of shadow maps

00:20:39.105 --> 00:20:41.607
or the sides
of an environment map.

00:20:41.607 --> 00:20:42.775
Each of those instances

00:20:42.775 --> 00:20:44.477
typically transform
that geometry

00:20:44.477 --> 00:20:46.245
in almost the same way.

00:20:46.245 --> 00:20:49.048
So even though
the position is unique per view,

00:20:49.048 --> 00:20:51.650
attributes such as
normals, tangents,

00:20:51.650 --> 00:20:54.320
and texture coordinates
are identical.

00:20:54.320 --> 00:20:56.455
Vertex amplification
lets you process

00:20:56.455 --> 00:20:58.724
those shared attributes
only once,

00:20:58.724 --> 00:21:01.727
increasing the efficiency
of your vertex shading.

00:21:01.727 --> 00:21:04.663
Let’s consider the use case
of cascaded shadow maps

00:21:04.663 --> 00:21:06.799
in more detail.

00:21:06.799 --> 00:21:08.367
Depending on the view distance,

00:21:08.367 --> 00:21:10.069
a renderer might
split its shadow maps

00:21:10.069 --> 00:21:14.607
into one, two, or three or more
overlapping shadow cascades.

00:21:14.607 --> 00:21:16.675
As we increase
the number of cascades,

00:21:16.675 --> 00:21:19.145
we also increase the size
of the virtual world

00:21:19.145 --> 00:21:21.080
that each cascade covers.

00:21:21.080 --> 00:21:24.150
This causes the larger,
more distant cascades

00:21:24.150 --> 00:21:25.918
to accumulate
more geometry in them,

00:21:25.918 --> 00:21:28.521
compared to closer cascades.

00:21:28.521 --> 00:21:31.290
And with more cascades,
the number of objects

00:21:31.290 --> 00:21:34.527
that render into more than one
cascade increases.

00:21:34.527 --> 00:21:36.562
Now let’s consider
how cascaded shadow maps

00:21:36.562 --> 00:21:40.633
are traditionally rendered
and the associated costs.

00:21:40.633 --> 00:21:42.067
Before multi-view rendering,

00:21:42.067 --> 00:21:44.870
you would simply draw
into each cascade separately.

00:21:44.870 --> 00:21:48.340
This increased both
the GPU and CPU overhead.

00:21:48.340 --> 00:21:51.277
Each vertex must be fetched
and shaded multiple times,

00:21:51.277 --> 00:21:54.680
and each vertex
is also output multiple times.

00:21:54.680 --> 00:21:57.550
Multi-view instance rendering
uses the instance ID

00:21:57.550 --> 00:22:00.953
to map each primitive
to its destination view.

00:22:00.953 --> 00:22:03.923
It eliminates the CPU cost
of multiple draw calls,

00:22:03.923 --> 00:22:06.392
but the GPU cost
remains the same.

00:22:06.392 --> 00:22:08.694
Using instancing
for layered rendering

00:22:08.694 --> 00:22:11.931
also complicates rendering
of actual instanced geometry,

00:22:11.931 --> 00:22:14.300
since instance ID
now has to encode

00:22:14.300 --> 00:22:18.037
both the actual instance ID
and the target layer.

00:22:18.037 --> 00:22:20.806
Vertex amplification
eliminates the duplicate fetch,

00:22:20.806 --> 00:22:22.474
shading, and output.

00:22:22.474 --> 00:22:25.477
It also provides
a separate amplification ID.

00:22:25.477 --> 00:22:29.381
Let’s take a look at a vertex
amplification in action.

00:22:29.381 --> 00:22:31.850
Existing vertex functions
can be easily adapted

00:22:31.850 --> 00:22:33.986
to vertex amplification.

00:22:33.986 --> 00:22:35.955
In this example,
we’re going to calculate

00:22:35.955 --> 00:22:38.357
a unique position
per amplification,

00:22:38.357 --> 00:22:42.261
but share the color calculation
across all amplifications.

00:22:42.261 --> 00:22:44.463
We start by declaring
our VertexOutput

00:22:44.463 --> 00:22:46.265
with two attributes.

00:22:46.265 --> 00:22:47.900
The compiler can usually infer

00:22:47.900 --> 00:22:50.436
if an attribute
is unique or shared,

00:22:50.436 --> 00:22:53.205
but for complicated shaders,
you can also be explicit

00:22:53.205 --> 00:22:55.674
about which attributes
are shared.

00:22:55.674 --> 00:22:57.409
The compiler
will report an error

00:22:57.409 --> 00:22:59.111
when shared
attribute calculations

00:22:59.111 --> 00:23:02.248
are dependent
on amplification ID.

00:23:02.248 --> 00:23:03.916
Next we declare
a function argument

00:23:03.916 --> 00:23:06.018
holding the amplification ID.

00:23:06.018 --> 00:23:08.187
Any calculations
associated with this ID

00:23:08.187 --> 00:23:11.023
are amplified
per shader invocation.

00:23:11.023 --> 00:23:13.759
The color attribute is not
associated with that ID

00:23:13.759 --> 00:23:16.228
so it will only
be executed once.

00:23:16.228 --> 00:23:18.364
But the position
is dependent on the ID

00:23:18.364 --> 00:23:20.466
to look up the correct
view projection matrix,

00:23:20.466 --> 00:23:23.636
and so the entire
expression is amplified.

00:23:23.636 --> 00:23:25.004
That’s it for the shader code.

00:23:25.004 --> 00:23:29.008
Now let's see how we set up
the amplified draw calls.

00:23:29.008 --> 00:23:31.477
Let’s start by creating
a pipeline state object

00:23:31.477 --> 00:23:33.946
that enables amplification.

00:23:33.946 --> 00:23:36.582
The maximum amplification factor
supported by Metal

00:23:36.582 --> 00:23:38.517
can be queried
from the device.

00:23:38.517 --> 00:23:42.554
In this case, let’s say you want
an amplification factor of two.

00:23:42.554 --> 00:23:45.257
If supported, you set
to maximum amplification factor

00:23:45.257 --> 00:23:46.959
for the pipeline.

00:23:46.959 --> 00:23:48.994
If not supported,
you can fall back

00:23:48.994 --> 00:23:51.230
to traditional multi-view
through instancing

00:23:51.230 --> 00:23:53.966
or rely on doing
multiple draw calls.

00:23:53.966 --> 00:23:56.335
Finally, you create
the pipeline.

00:23:56.335 --> 00:23:57.903
Once the pipeline is created,

00:23:57.903 --> 00:24:00.005
and assuming that amplification
is supported,

00:24:00.005 --> 00:24:02.107
you can start
to encode your draws.

00:24:02.107 --> 00:24:04.076
Drawing with amplification
requires

00:24:04.076 --> 00:24:07.946
setting the amplification count
and binding the viewMappings.

00:24:07.946 --> 00:24:11.350
viewMappings describe
how to map the amplification ID

00:24:11.350 --> 00:24:13.619
to target layer or viewport.

00:24:13.619 --> 00:24:16.088
If the vertex shader
also exports a render target

00:24:16.088 --> 00:24:17.790
or viewport array index,

00:24:17.790 --> 00:24:19.858
that index will serve
as a base offset

00:24:19.858 --> 00:24:22.027
into the viewMappings array.

00:24:22.027 --> 00:24:24.296
Now you can set
the desired amplification

00:24:24.296 --> 00:24:26.632
and encode the draws.

00:24:26.632 --> 00:24:29.868
Let’s take a closer look through
the Metal frame debugger.

00:24:29.868 --> 00:24:32.705
In this sample render,
we use VertexAmplification

00:24:32.705 --> 00:24:34.873
to amplify all the draws
that are rendered

00:24:34.873 --> 00:24:37.676
to both cascades 2 and 3.

00:24:37.676 --> 00:24:40.446
Here we see that this draw call
is rendered with a ViewMapping

00:24:40.446 --> 00:24:42.981
that specifies
two render targets.

00:24:42.981 --> 00:24:44.750
The mesh is rendered
simultaneously

00:24:44.750 --> 00:24:46.952
into the second cascade
shown on the left,

00:24:46.952 --> 00:24:49.288
and the third cascade,
shown both on the right

00:24:49.288 --> 00:24:51.256
and in the geometry viewer.

00:24:51.256 --> 00:24:53.292
That’s it for vertex
amplification.

00:24:53.292 --> 00:24:55.194
Let’s move on
to argument buffers

00:24:55.194 --> 00:24:59.131
and how they’ve
been extended for the A13.

00:24:59.131 --> 00:25:02.000
We introduced argument buffers
with Metal 2.

00:25:02.000 --> 00:25:04.970
Argument buffers allow you
to encode constants, textures,

00:25:04.970 --> 00:25:07.973
samplers, and buffer arguments
into MTLBuffers.

00:25:08.674 --> 00:25:10.743
By encoding all your
draw arguments

00:25:10.743 --> 00:25:12.878
into a single Metal
argument buffer,

00:25:12.878 --> 00:25:16.548
you can render complex scenes
with minimal CPU overhead.

00:25:16.548 --> 00:25:19.118
Once encoded,
you can reuse argument buffers

00:25:19.118 --> 00:25:22.421
to avoid repeated redundant
resource binding.

00:25:22.421 --> 00:25:24.189
Argument buffers
are also necessary

00:25:24.189 --> 00:25:26.492
to enable GPU-driven pipelines,

00:25:26.492 --> 00:25:29.461
by providing access to the
entire scene’s draw arguments

00:25:29.461 --> 00:25:31.029
on the GPU.

00:25:31.029 --> 00:25:34.299
You can then modify argument
buffers in compute functions

00:25:34.299 --> 00:25:38.070
to dynamically configure
your scene, just in time.

00:25:38.070 --> 00:25:40.472
Tier 2 argument buffers
dramatically enhance

00:25:40.472 --> 00:25:42.508
the capabilities
of argument buffers.

00:25:42.508 --> 00:25:45.878
With A13, your Metal functions
can sample or write

00:25:45.878 --> 00:25:48.046
to any texture
in an argument buffer.

00:25:48.046 --> 00:25:51.216
You can also access a virtually
unlimited number of textures

00:25:51.216 --> 00:25:53.051
and many samplers.

00:25:53.051 --> 00:25:55.254
And argument buffers
can now also reference

00:25:55.254 --> 00:25:58.857
other argument buffers with
multiple levels of indirection.

00:25:58.857 --> 00:26:01.994
This unlocks the ability to
encode a single argument buffer

00:26:01.994 --> 00:26:05.297
for all your scene data
and access it in your draw

00:26:05.297 --> 00:26:07.933
without needing to assemble
argument buffers ahead of time

00:26:07.933 --> 00:26:10.068
on GPU or CPU.

00:26:10.068 --> 00:26:11.870
Let’s look at an example.

00:26:11.870 --> 00:26:15.007
Here is an example scene
object model hierarchy.

00:26:15.007 --> 00:26:16.475
We showed a similar example at

00:26:16.475 --> 00:26:21.113
our Modern Rendering with Metal
talk at WWDC 2019.

00:26:21.113 --> 00:26:23.415
The hierarchy describes
all your geometry data,

00:26:23.415 --> 00:26:25.584
materials, and model data.

00:26:25.584 --> 00:26:26.785
With argument buffers,

00:26:26.785 --> 00:26:29.087
we can encode
this object model directly.

00:26:29.087 --> 00:26:30.456
But with Tier 2 support

00:26:30.456 --> 00:26:33.325
we can also use the hierarchy
directly during rendering.

00:26:33.325 --> 00:26:36.295
Let’s take a look
at an example shader.

00:26:36.295 --> 00:26:39.164
To start,
recall that our argument buffers

00:26:39.164 --> 00:26:41.133
are declared
in the Metal shading language

00:26:41.133 --> 00:26:45.838
as structures of constants,
textures, samplers, and buffers.

00:26:45.838 --> 00:26:47.372
These declarations
directly mirror

00:26:47.372 --> 00:26:50.008
the example object hierarchy
just described.

00:26:50.008 --> 00:26:52.544
The first is our
material representation,

00:26:52.544 --> 00:26:54.246
and the second is our scene

00:26:54.246 --> 00:26:58.750
that references the set of
meshes, materials, and models.

00:26:58.750 --> 00:27:01.320
OK, so now let’s take a look
at a fragment function

00:27:01.320 --> 00:27:03.789
that shades using
our scene directly.

00:27:03.789 --> 00:27:07.259
The first function parameter
is our scene argument buffer.

00:27:07.259 --> 00:27:11.129
The second function parameter
is our per-draw constants.

00:27:11.129 --> 00:27:14.132
In this example, it encodes
the model ID for this draw,

00:27:14.132 --> 00:27:16.535
as well as the discrete
level of detail,

00:27:16.535 --> 00:27:19.404
both chosen
in an earlier compute pass.

00:27:19.404 --> 00:27:21.206
We then use these IDs

00:27:21.206 --> 00:27:23.275
to fetch our material
from the scene

00:27:23.275 --> 00:27:25.677
using the IDs computed earlier.

00:27:25.677 --> 00:27:28.747
And we calculate the fragment
color using the textures,

00:27:28.747 --> 00:27:32.684
constants, and samplers
from the nested argument buffer.

00:27:32.684 --> 00:27:33.819
And that’s it!

00:27:33.819 --> 00:27:37.122
No more intervening compute pass
to gather material parameters

00:27:37.122 --> 00:27:39.658
into per-draw argument buffers.

00:27:39.658 --> 00:27:40.559
The fragment shader

00:27:40.559 --> 00:27:43.395
just uses the scene
argument buffer directly.

00:27:43.395 --> 00:27:44.696
Before we move on though,

00:27:44.696 --> 00:27:46.899
I’d like to highlight
the robust tool support

00:27:46.899 --> 00:27:48.934
for argument buffers.

00:27:48.934 --> 00:27:51.637
With argument buffers
and GPU-driven pipelines,

00:27:51.637 --> 00:27:53.972
your scene setup
moves to the GPU,

00:27:53.972 --> 00:27:55.974
and so does any debugging.

00:27:55.974 --> 00:28:00.078
The Metal frame debugger allows
you to easily debug and inspect

00:28:00.078 --> 00:28:03.649
both argument buffers
and the shaders that use them.

00:28:03.649 --> 00:28:06.685
You can use the buffer viewer
to inspect all resources

00:28:06.685 --> 00:28:07.886
in your argument buffer,

00:28:07.886 --> 00:28:10.422
and quickly jump
to these resources

00:28:10.422 --> 00:28:12.424
for further inspection.

00:28:12.424 --> 00:28:14.459
You can also use
the shader debugger

00:28:14.459 --> 00:28:17.362
to understand how your shaders
are accessing or building

00:28:17.362 --> 00:28:19.131
argument buffers.

00:28:19.131 --> 00:28:21.133
This is especially important

00:28:21.133 --> 00:28:23.168
when calculating
argument buffer indices

00:28:23.168 --> 00:28:26.572
or modifying argument buffers
on the GPU.

00:28:26.572 --> 00:28:29.007
That's it for Tier 2
argument buffers.

00:28:29.007 --> 00:28:30.742
Now let’s move on to a new class

00:28:30.742 --> 00:28:34.313
of shader optimization
techniques.

00:28:34.313 --> 00:28:36.815
SIMD group functions
are a powerful tool

00:28:36.815 --> 00:28:39.851
for optimizing compute
and graphics functions.

00:28:39.851 --> 00:28:42.087
They allow a GPU workload
to share data

00:28:42.087 --> 00:28:43.622
and control flow information

00:28:43.622 --> 00:28:46.792
by leveraging the architecture
of the GPU.

00:28:46.792 --> 00:28:48.994
Let's unpack that
by quickly reviewing

00:28:48.994 --> 00:28:52.264
the SIMD execution model
in Metal.

00:28:52.264 --> 00:28:56.068
Metal has always organized
threads into SIMD groups

00:28:56.068 --> 00:28:58.103
to exploit
the single Instruction,

00:28:58.103 --> 00:29:00.973
multiple data nature of GPUs.

00:29:00.973 --> 00:29:02.441
You may have leveraged
SIMD groups

00:29:02.441 --> 00:29:03.909
in Metal compute functions

00:29:03.909 --> 00:29:05.711
to reduce the costs
of synchronizing

00:29:05.711 --> 00:29:09.514
entire threadgroups by using
SIMD group barriers instead.

00:29:09.514 --> 00:29:12.351
The threads of a SIMD group
execute in lockstep,

00:29:12.351 --> 00:29:14.987
so execution barriers
are not needed.

00:29:14.987 --> 00:29:16.788
A SIMD group barrier therefore

00:29:16.788 --> 00:29:19.958
only synchronizes
memory operations.

00:29:19.958 --> 00:29:23.228
SIMD group functions
exploit this lockstep execution

00:29:23.228 --> 00:29:25.464
to share data
between its threads

00:29:25.464 --> 00:29:28.200
using registers instead of
threadgroup memory,

00:29:28.200 --> 00:29:30.535
and can significantly improve
performance

00:29:30.535 --> 00:29:32.671
when threadgroup memory bound.

00:29:32.671 --> 00:29:36.174
They’re also available for both
compute and render functions.

00:29:36.174 --> 00:29:37.909
And as we’ll see in a bit,
this enables

00:29:37.909 --> 00:29:40.812
a very interesting render
optimization technique.

00:29:40.812 --> 00:29:43.315
Let’s first start by building
a better intuition

00:29:43.315 --> 00:29:46.618
for SIMD execution
with an example.

00:29:46.618 --> 00:29:50.622
Down the left side we represent
a SIMD group as 32 lanes

00:29:50.622 --> 00:29:52.024
starting with Lane 0.

00:29:52.024 --> 00:29:54.926
A lane is a single thread
in a SIMD group.

00:29:54.926 --> 00:29:57.429
Now let’s make this SIMD group
perform some work.

00:29:57.429 --> 00:30:01.133
First we have all lanes
index an array, A, by its laneID

00:30:01.133 --> 00:30:04.336
and store the result
in a variable X.

00:30:04.336 --> 00:30:07.639
Note how each lane
has its own value of X.

00:30:07.639 --> 00:30:09.007
In this execution model,

00:30:09.007 --> 00:30:12.544
the instruction to load the data
from A is only fetched once

00:30:12.544 --> 00:30:15.547
and executed simultaneously
by 32 threads

00:30:15.547 --> 00:30:17.549
that have their own indices.

00:30:17.549 --> 00:30:21.019
Now we read a second array, B,
indexed by laneID

00:30:21.019 --> 00:30:23.155
and store the result in Y.

00:30:23.155 --> 00:30:26.692
Finally we store the result
of multiplying X and Y

00:30:26.692 --> 00:30:28.660
in a third array, C.

00:30:28.660 --> 00:30:31.596
Since the instruction executed
is only fetched once

00:30:31.596 --> 00:30:32.964
for the whole group,

00:30:32.964 --> 00:30:35.901
all SIMD group threads
execute in lockstep.

00:30:35.901 --> 00:30:38.637
SIMD group functions
allow each thread in the group

00:30:38.637 --> 00:30:41.840
to inspect register values
of the entire SIMD group

00:30:41.840 --> 00:30:43.608
with minimal overhead.

00:30:43.608 --> 00:30:46.211
This ability allows
for some interesting functions.

00:30:47.546 --> 00:30:52.117
First let’s introduce simd_max
and apply it to variable Y.

00:30:52.117 --> 00:30:56.054
Each thread gets a Z value
with the largest value from Y,

00:30:56.054 --> 00:30:58.623
as seen by any thread
in the SIMD group.

00:30:58.623 --> 00:31:01.993
Next we have broadcast
and apply it to X.

00:31:01.993 --> 00:31:05.230
In this example, we broadcast
the value of Lane 0

00:31:05.230 --> 00:31:08.333
to all the other lanes
in a single operation.

00:31:08.333 --> 00:31:10.001
Metal for A13 supports

00:31:10.001 --> 00:31:13.138
many other similarly operating
SIMD functions

00:31:13.138 --> 00:31:17.476
such as shuffle, permute,
and rotate across all lanes.

00:31:17.476 --> 00:31:20.746
For our final example
we’ll take a look at simd_all,

00:31:20.746 --> 00:31:22.314
which tells each lane

00:31:22.314 --> 00:31:25.617
whether an expression evaluates
the same for all lanes.

00:31:25.617 --> 00:31:30.255
In this example the Z variable
is indeed nine for all lanes,

00:31:30.255 --> 00:31:32.524
and we therefore return true.

00:31:32.524 --> 00:31:36.628
Likewise, simd_any tells whether
an expression evaluates to true

00:31:36.628 --> 00:31:37.863
for any lane.

00:31:37.863 --> 00:31:41.366
You can use simd_all to reduce
divergence in your shaders

00:31:41.366 --> 00:31:43.502
by choosing to take
a more optimal path

00:31:43.502 --> 00:31:45.437
when all threads
have the same need.

00:31:45.437 --> 00:31:47.572
Let’s take a look
at an example.

00:31:47.572 --> 00:31:49.941
Here is our fragment shader
from earlier

00:31:49.941 --> 00:31:53.111
with some optimizations
using SIMD group functions.

00:31:53.111 --> 00:31:55.747
To recap,
this function takes as inputs

00:31:55.747 --> 00:31:57.983
the scene encoded
as an argument buffer,

00:31:57.983 --> 00:32:00.552
uniforms, and the vertex
stage_in.

00:32:00.552 --> 00:32:03.688
Typically, lighting functions
evaluate various components

00:32:03.688 --> 00:32:06.691
of the final color differently
for transparent fragments

00:32:06.691 --> 00:32:10.529
and thus require dynamic
control flow at various points.

00:32:10.529 --> 00:32:14.533
Now, instead of evaluating
the opacity for every fragment,

00:32:14.533 --> 00:32:17.035
here we use simd_all
to check dynamically

00:32:17.035 --> 00:32:19.104
if all the threads
in the SIMD group

00:32:19.104 --> 00:32:22.440
are computing the lighting
for opaque fragments.

00:32:22.440 --> 00:32:24.609
If they are,
we take an optimal path

00:32:24.609 --> 00:32:27.312
that assumes
only opaque objects.

00:32:27.312 --> 00:32:30.448
And if not,
we fall back to the earlier path

00:32:30.448 --> 00:32:33.752
that can light both opaque
and transparent fragments.

00:32:33.752 --> 00:32:37.155
That’s it for SIMD group
functions on A13.

00:32:37.155 --> 00:32:38.456
Let’s switch gears

00:32:38.456 --> 00:32:44.296
and look at some of the exciting
additions to ASTC on A13.

00:32:44.296 --> 00:32:45.764
As mentioned earlier
in the video,

00:32:45.764 --> 00:32:48.200
the A13 GPU doubles the rate

00:32:48.200 --> 00:32:50.235
of 16-bit floating point
operations

00:32:50.235 --> 00:32:52.938
and adds support
for small 16-bit numbers

00:32:52.938 --> 00:32:55.473
to better handle HDR processing.

00:32:55.473 --> 00:32:57.108
Apps take advantage
of these improvements

00:32:57.108 --> 00:32:58.944
without any modification;

00:32:58.944 --> 00:33:03.648
HDR processing on the GPU just
gets faster and more accurate.

00:33:03.648 --> 00:33:07.485
Apple Family 6 also adds support
for a new set of pixel formats

00:33:07.485 --> 00:33:11.656
that support the efficient
storage and sampling of HDR data

00:33:11.656 --> 00:33:14.459
called ASTC HDR.

00:33:14.459 --> 00:33:17.596
ASTC is a texture compression
technology

00:33:17.596 --> 00:33:19.331
supported on many platforms,

00:33:19.331 --> 00:33:21.433
providing high texture
image quality

00:33:21.433 --> 00:33:24.069
at a fraction of the bandwidth
and memory.

00:33:24.069 --> 00:33:26.404
It does so by supporting
multiple bit rates

00:33:26.404 --> 00:33:28.073
and input formats.

00:33:28.073 --> 00:33:30.709
The ASTC
low dynamic range profile

00:33:30.709 --> 00:33:33.178
has been supported
since Apple GPU Family 2

00:33:33.178 --> 00:33:35.614
and is appropriate
for compressing values

00:33:35.614 --> 00:33:37.515
in the zero to one range.

00:33:37.515 --> 00:33:39.851
If your app is not already
using ASTC

00:33:39.851 --> 00:33:41.620
to save memory
and bandwidth,

00:33:41.620 --> 00:33:44.322
we highly encourage you
to do so.

00:33:44.322 --> 00:33:46.825
The high dynamic range profile
is needed

00:33:46.825 --> 00:33:50.695
to encode the larger brightness
values found in HDR images.

00:33:50.695 --> 00:33:54.232
Without ASTC HDR,
such images are typically stored

00:33:54.232 --> 00:33:56.835
in 16-bit floating
point pixel formats

00:33:56.835 --> 00:33:59.170
at much higher memory cost.

00:33:59.170 --> 00:34:03.141
So how much storage
can ASTC HDR save?

00:34:03.141 --> 00:34:04.175
A lot.

00:34:04.175 --> 00:34:05.944
Let’s consider an example.

00:34:05.944 --> 00:34:09.179
HDR games often use
low-resolution cube map textures

00:34:09.179 --> 00:34:11.516
to represent high dynamic range
environment maps

00:34:11.516 --> 00:34:12.550
to light their scene,

00:34:12.550 --> 00:34:14.686
and typically place
many such probes

00:34:14.686 --> 00:34:16.788
across the game world or level.

00:34:16.788 --> 00:34:18.822
Without ASTC HDR,

00:34:18.822 --> 00:34:21.393
each probe can consume
a significant amount of memory,

00:34:21.393 --> 00:34:23.661
and all such probes
can easily consume

00:34:23.661 --> 00:34:26.264
a large portion
of your game’s memory budget.

00:34:26.264 --> 00:34:30.768
In this example, a 256 by 256
probe cube map alone

00:34:30.768 --> 00:34:32.704
consumes 3MB.

00:34:32.704 --> 00:34:34.438
With ASTC HDR,

00:34:34.438 --> 00:34:37.609
the same probe would consume
many times less memory.

00:34:37.609 --> 00:34:41.413
You can even vary the bit rate
to really reduce the footprint.

00:34:41.413 --> 00:34:46.184
Creating an HDR texture is
as simple as an LDR equivalent.

00:34:46.184 --> 00:34:51.255
In this example, we’re creating
a four by four ASTC LDR texture.

00:34:51.255 --> 00:34:55.025
There is matching HDR format
for every LDR format

00:34:55.025 --> 00:34:57.595
so converting this
to an HDR texture

00:34:57.595 --> 00:35:00.332
just requires changing
the pixel format.

00:35:00.332 --> 00:35:03.034
All right, that wraps up
the new Metal features

00:35:03.034 --> 00:35:04.903
for the A13 GPU.

00:35:04.903 --> 00:35:07.872
Let’s recap what we’ve learned.

00:35:07.872 --> 00:35:10.241
It enables higher quality
texture streaming

00:35:10.241 --> 00:35:11.609
with sparse textures.

00:35:11.609 --> 00:35:14.412
It lets you focus expensive
shading to where needed

00:35:14.412 --> 00:35:16.181
with rasterization rate maps,

00:35:16.181 --> 00:35:18.516
and eliminate redundant
vertex processing

00:35:18.516 --> 00:35:20.819
with vertex amplification.

00:35:20.819 --> 00:35:23.755
It also enables more flexible
GPU-driven pipelines

00:35:23.755 --> 00:35:26.825
with argument buffer Tier 2,
and SIMD group sharing

00:35:26.825 --> 00:35:29.227
with shuffle
and ballot instructions.

00:35:29.227 --> 00:35:33.331
And finally, Metal now lets you
save memory in HDR pipelines

00:35:33.331 --> 00:35:35.500
with ASTC.

00:35:35.500 --> 00:35:37.168
For more information
about Metal,

00:35:37.168 --> 00:35:38.603
the A13 GPU,

00:35:38.603 --> 00:35:40.905
and to find our
latest sample code,

00:35:40.905 --> 00:35:44.576
please visit
developer.apple.com.

00:35:44.576 --> 00:35:46.578
Thank you.