WEBVTT

00:00:01.019 --> 00:00:03.450
Srividya: Hello, my name is Srividya Karumuri

00:00:03.450 --> 00:00:05.823
and I'm a GPU Compiler Engineer at Apple.

00:00:06.720 --> 00:00:08.730
Today I'm here to share some tips

00:00:08.730 --> 00:00:11.480
that can improve the performance of your Metal shaders.

00:00:13.710 --> 00:00:15.990
The new Apple Family 9 GPU

00:00:15.990 --> 00:00:18.780
in M3 and A17 Pro have some new advancements

00:00:18.780 --> 00:00:21.390
that you could apply to your application.

00:00:21.390 --> 00:00:25.170
I have some recommendations for Apple Family 9 GPUs.

00:00:25.170 --> 00:00:26.880
In addition to guidance tips

00:00:26.880 --> 00:00:30.063
and tricks that apply to all Apple GPU generations.

00:00:31.590 --> 00:00:33.600
You can improve your shader's performance

00:00:33.600 --> 00:00:34.920
by reducing their runtime

00:00:34.920 --> 00:00:37.120
with features in the Metal shading language,

00:00:38.100 --> 00:00:41.040
increasing parallelism by improving resource utilization

00:00:41.040 --> 00:00:41.883
from the shader,

00:00:43.350 --> 00:00:45.780
and making the most of the ray tracing acceleration

00:00:45.780 --> 00:00:48.303
hardware in the Apple Family 9 GPUs.

00:00:50.610 --> 00:00:51.960
Metal has several features

00:00:51.960 --> 00:00:55.410
that can minimize the shader's runtime including,

00:00:55.410 --> 00:00:57.930
function constants, which can efficiently specialize

00:00:57.930 --> 00:01:02.250
a shader, function groups which can optimize shaders

00:01:02.250 --> 00:01:04.083
using indirect function calls.

00:01:05.250 --> 00:01:06.570
The Metal function constants

00:01:06.570 --> 00:01:09.210
features specializes the shader efficiently

00:01:09.210 --> 00:01:11.860
and removes the code that isn't reachable at runtime.

00:01:12.720 --> 00:01:15.120
For example, uber shaders typically benefit

00:01:15.120 --> 00:01:16.533
from function constants.

00:01:18.990 --> 00:01:21.120
An uber shader is often complex

00:01:21.120 --> 00:01:23.790
because it can handle many different possibilities

00:01:23.790 --> 00:01:27.210
at runtime, such as rendering different material types

00:01:27.210 --> 00:01:28.563
in a 3D application.

00:01:29.940 --> 00:01:32.010
Developers sometimes make uber shaders

00:01:32.010 --> 00:01:35.310
that read material parameters from a buffer

00:01:35.310 --> 00:01:38.520
and then a material shader chooses different control parts

00:01:38.520 --> 00:01:41.043
at runtime based on the buffer's contents.

00:01:42.870 --> 00:01:46.200
This approach lets the shader render a new material effect

00:01:46.200 --> 00:01:49.320
without recompiling because the only changes

00:01:49.320 --> 00:01:50.853
are parameters in the buffer.

00:01:53.730 --> 00:01:57.480
For example, this uber shader in a pipeline

00:01:57.480 --> 00:01:58.920
renders a glossy material

00:01:58.920 --> 00:02:01.320
because a Metal buffer in the draw command

00:02:01.320 --> 00:02:05.100
has an is_glossy parameter that's equal to true.

00:02:05.100 --> 00:02:08.430
The same shader can also render a matte material

00:02:08.430 --> 00:02:11.673
when the buffer's is_glossy parameter is equal to false.

00:02:13.890 --> 00:02:17.280
The render pipeline is the same for both material effects

00:02:17.280 --> 00:02:20.373
because the behavior change comes from what's in the buffer.

00:02:22.140 --> 00:02:25.620
This responsive approach is great during development,

00:02:25.620 --> 00:02:29.460
however, the shader has to account for several possibilities

00:02:29.460 --> 00:02:31.560
and read from additional buffers

00:02:31.560 --> 00:02:33.513
which may affect an app's performance.

00:02:34.440 --> 00:02:36.570
Another approach is to specialize the shader

00:02:36.570 --> 00:02:39.270
at compile time instead of at runtime.

00:02:39.270 --> 00:02:41.130
By building the shader variance offline

00:02:41.130 --> 00:02:42.693
with preprocessor macros.

00:02:45.330 --> 00:02:48.543
This is an uber shader specialized using macros.

00:02:49.650 --> 00:02:52.710
Each specialized shader has its own render pipeline

00:02:52.710 --> 00:02:54.330
and only has the code it needs

00:02:54.330 --> 00:02:56.553
for rendering a specific material effect.

00:02:58.440 --> 00:03:01.440
This approach means you have to compile all the possible

00:03:01.440 --> 00:03:03.900
variant combinations offline.

00:03:03.900 --> 00:03:07.110
For example, a glossy variant could be the combination

00:03:07.110 --> 00:03:11.310
of enabling both is_glossy and use_shadows macros,

00:03:11.310 --> 00:03:13.263
by disabling the remaining macros.

00:03:14.850 --> 00:03:18.240
Similarly, a matte function variant could be a combination

00:03:18.240 --> 00:03:21.153
of the use_shadows and has_reflections macros.

00:03:23.070 --> 00:03:26.610
And a glossy reflections variant enables the is_glossy

00:03:26.610 --> 00:03:29.133
and has_reflections macros and so on.

00:03:30.750 --> 00:03:32.220
Implementing an uber shader

00:03:32.220 --> 00:03:34.830
with macros can mean compiling a large number

00:03:34.830 --> 00:03:37.080
of variants, such as one variant

00:03:37.080 --> 00:03:39.453
for each possible macro combination.

00:03:40.320 --> 00:03:42.573
Some of which your app may never use.

00:03:44.040 --> 00:03:47.220
Even if you compile them offline ahead of time,

00:03:47.220 --> 00:03:50.610
each variant adds up which can significantly increase

00:03:50.610 --> 00:03:53.040
the size of your Metal library.

00:03:53.040 --> 00:03:54.900
It can also increase compile time

00:03:54.900 --> 00:03:57.240
because each shade of variant has to be compiled

00:03:57.240 --> 00:03:58.683
starting from Metal source.

00:04:02.160 --> 00:04:04.380
Function constants can provide another way

00:04:04.380 --> 00:04:05.970
to specialize the shaders.

00:04:05.970 --> 00:04:09.660
Compared to using macros, it can reduce both compile time

00:04:09.660 --> 00:04:12.090
and the size of the Metal library.

00:04:12.090 --> 00:04:13.380
With function constants,

00:04:13.380 --> 00:04:15.990
you compile an uber shader one time from source

00:04:15.990 --> 00:04:17.733
to an intermediate Metal function.

00:04:18.570 --> 00:04:21.180
From that function, you only create the variance

00:04:21.180 --> 00:04:24.573
your app needs based on function constants you define.

00:04:27.480 --> 00:04:29.760
Function constants give you the flexibility

00:04:29.760 --> 00:04:32.280
to both create multiple specialized variants

00:04:32.280 --> 00:04:34.320
on the go as needed

00:04:34.320 --> 00:04:36.450
and reuse an intermediate Metal function

00:04:36.450 --> 00:04:38.463
for all remaining possibilities.

00:04:39.720 --> 00:04:41.970
With this approach, you can save time

00:04:41.970 --> 00:04:44.730
and space by creating only the shader variance

00:04:44.730 --> 00:04:46.443
and render pipelines you need.

00:04:47.700 --> 00:04:49.770
You can create these specialized variance

00:04:49.770 --> 00:04:53.070
by declaring function constants in your Metal function code

00:04:53.070 --> 00:04:55.230
and then defining each of their values

00:04:55.230 --> 00:04:57.003
as you create Metal functions.

00:04:58.770 --> 00:05:01.200
You can also use function constants

00:05:01.200 --> 00:05:03.600
to initialize program scope variables

00:05:03.600 --> 00:05:05.973
that you declare in the constant address space.

00:05:07.170 --> 00:05:09.840
You can enable different code parts in the shader

00:05:09.840 --> 00:05:11.700
with these function constants instead

00:05:11.700 --> 00:05:13.863
of reading values from Metal buffers.

00:05:15.180 --> 00:05:17.940
With function constants, Metal can fold these

00:05:17.940 --> 00:05:19.470
as constant Booleans

00:05:19.470 --> 00:05:22.383
as it compiles the shader's specialization variant,

00:05:24.030 --> 00:05:25.800
as well as other optimizations,

00:05:25.800 --> 00:05:28.593
such as eliminating unreachable code parts.

00:05:30.120 --> 00:05:32.583
And that can remove unused control flow.

00:05:33.960 --> 00:05:36.750
By specializing shader with function constants,

00:05:36.750 --> 00:05:38.700
you don't need to query material parameters

00:05:38.700 --> 00:05:40.590
from buffers anymore.

00:05:40.590 --> 00:05:42.900
This approach reduces the shaders runtime

00:05:42.900 --> 00:05:44.970
by simplifying its control flow

00:05:44.970 --> 00:05:47.043
and removing unused code parts.

00:05:48.090 --> 00:05:51.810
I encourage you to watch, "Optimize GPU renders with Metal,"

00:05:51.810 --> 00:05:53.970
which goes over the details on how to set

00:05:53.970 --> 00:05:56.370
function constant values at runtime.

00:05:56.370 --> 00:05:58.260
It also goes over how to mitigate

00:05:58.260 --> 00:05:59.970
the runtime compilation overhead

00:05:59.970 --> 00:06:01.683
with a synchronous compilation.

00:06:03.900 --> 00:06:05.940
You can also reduce your shaders runtime

00:06:05.940 --> 00:06:07.740
by adding the function group's attribute

00:06:07.740 --> 00:06:09.393
for indirect function calls.

00:06:11.310 --> 00:06:13.890
An indirect function is a function the shader calls

00:06:13.890 --> 00:06:16.830
without directly invoking by its name,

00:06:16.830 --> 00:06:21.243
such as with function pointers or visible function tables.

00:06:22.290 --> 00:06:25.320
A shader can call an indirect function through static

00:06:25.320 --> 00:06:29.220
or dynamic linking, indirect function calls make the code

00:06:29.220 --> 00:06:33.660
extensible and give your app more options for flexibility.

00:06:33.660 --> 00:06:36.780
However, indirect function calls can prevent Metal

00:06:36.780 --> 00:06:38.760
from fully optimizing the shader,

00:06:38.760 --> 00:06:40.473
especially around the call site.

00:06:42.450 --> 00:06:44.490
For statically linked functions,

00:06:44.490 --> 00:06:47.040
you can use the Metal function group's feature,

00:06:47.040 --> 00:06:49.050
which lets Metal optimize the shader

00:06:49.050 --> 00:06:50.673
with indirect function calls.

00:06:52.770 --> 00:06:55.560
This shader invokes three different indirect functions

00:06:55.560 --> 00:06:58.710
including calls through function pointers for lighting,

00:06:58.710 --> 00:07:00.540
and a material.

00:07:00.540 --> 00:07:02.100
Metal can't optimize across

00:07:02.100 --> 00:07:04.140
these function pointer call sites

00:07:04.140 --> 00:07:06.540
because it has no visibility which functions

00:07:06.540 --> 00:07:08.310
the shader is calling.

00:07:08.310 --> 00:07:09.750
However, when you know

00:07:09.750 --> 00:07:12.390
that the function pointers can only point to one

00:07:12.390 --> 00:07:14.640
of the specific group of functions,

00:07:14.640 --> 00:07:17.460
you can use the function group's attribute.

00:07:17.460 --> 00:07:20.610
For example, the only functions the shader could call

00:07:20.610 --> 00:07:23.913
are all the linked functions in the shaders pipeline state,

00:07:25.950 --> 00:07:28.830
and you may know that the lighting function can only invoke

00:07:28.830 --> 00:07:32.430
the area, spot or sphere functions.

00:07:32.430 --> 00:07:34.560
In that case, you can group these functions

00:07:34.560 --> 00:07:36.960
into your lighting function group.

00:07:36.960 --> 00:07:40.530
Similarly, if the material function pointer can only invoke

00:07:40.530 --> 00:07:43.410
the wood, glass or metal functions,

00:07:43.410 --> 00:07:46.310
then you can group them into your material function group.

00:07:47.400 --> 00:07:49.320
You can give Metal a hint on how

00:07:49.320 --> 00:07:51.390
to optimize an indirect call

00:07:51.390 --> 00:07:54.333
by adding the function group's attribute at the call site.

00:07:57.390 --> 00:08:00.090
You define the function groups by assigning a dictionary

00:08:00.090 --> 00:08:02.730
to a linked functions group's property.

00:08:02.730 --> 00:08:05.910
Each dictionary entry is a string key, which is the name

00:08:05.910 --> 00:08:09.780
of the function group, and the value is an area of functions

00:08:09.780 --> 00:08:11.790
that belong to that group.

00:08:11.790 --> 00:08:14.430
Note that this approach only helps for functions

00:08:14.430 --> 00:08:17.730
that you statically link, functions you compile

00:08:17.730 --> 00:08:20.583
to a binary library will not benefit from this.

00:08:22.500 --> 00:08:24.000
Check out these two videos

00:08:24.000 --> 00:08:26.550
to learn more about the Metal function pointers

00:08:26.550 --> 00:08:28.713
and the various compilation workflows.

00:08:30.510 --> 00:08:33.540
In summary, two ways to reduce a shader's runtime

00:08:33.540 --> 00:08:35.670
are function constants,

00:08:35.670 --> 00:08:37.560
which can create a specialized variant

00:08:37.560 --> 00:08:39.153
of the shader efficiently,

00:08:40.020 --> 00:08:42.480
and function groups that can optimize the shader

00:08:42.480 --> 00:08:44.523
where it invokes indirect functions.

00:08:46.980 --> 00:08:48.750
Having looked at some Metal features

00:08:48.750 --> 00:08:51.900
that can reduce the shader's execution time,

00:08:51.900 --> 00:08:54.900
let's see some ways to improve the resource utilization

00:08:54.900 --> 00:08:56.943
leading to increased parallelism.

00:08:58.500 --> 00:09:01.110
Increasing the thread occupancy is very important

00:09:01.110 --> 00:09:03.903
to improve latency hiding in shader execution.

00:09:04.920 --> 00:09:07.230
Thread occupancy really depends on the amount

00:09:07.230 --> 00:09:11.553
of available resources, be it registers or memory.

00:09:12.630 --> 00:09:15.030
So optimized usage of data from the shader

00:09:15.030 --> 00:09:16.803
can increase thread occupancy.

00:09:17.940 --> 00:09:21.060
Apple Family 9 GPUs have new advancements related

00:09:21.060 --> 00:09:23.070
to occupancy management.

00:09:23.070 --> 00:09:25.297
For more details, please check out,

00:09:25.297 --> 00:09:29.097
"Explore GPU advancements in M3 and A17 Pro."

00:09:30.420 --> 00:09:31.950
And to learn how to triage

00:09:31.950 --> 00:09:35.227
the lower thread occupancy bottlenecks, please check out,

00:09:35.227 --> 00:09:37.200
"Discover new Metal profiling tools

00:09:37.200 --> 00:09:39.297
for M3 and A17 Pro."

00:09:40.530 --> 00:09:43.260
The address space of memory objects

00:09:43.260 --> 00:09:45.870
and the data type used in ALU operations

00:09:45.870 --> 00:09:47.973
can impact the resource utilization.

00:09:49.680 --> 00:09:51.090
Choosing the right address space

00:09:51.090 --> 00:09:53.160
for a memory object is very important

00:09:53.160 --> 00:09:54.990
for better memory utilization

00:09:54.990 --> 00:09:56.883
and to improve the thread occupancy.

00:09:58.920 --> 00:10:01.950
In Metal shading language, address spaces are designed

00:10:01.950 --> 00:10:03.910
to support different access patterns

00:10:04.920 --> 00:10:06.720
and to specify the region of memory

00:10:06.720 --> 00:10:08.973
from where memory objects are allocated.

00:10:10.380 --> 00:10:13.050
Picking the right address space will directly impact

00:10:13.050 --> 00:10:15.120
the performance of shaders.

00:10:15.120 --> 00:10:18.930
We are going to focus our attention on constant device

00:10:18.930 --> 00:10:20.643
and threadgroup address spaces.

00:10:21.600 --> 00:10:24.630
Constant address space allows you to create memory objects

00:10:24.630 --> 00:10:25.773
that are read only.

00:10:27.270 --> 00:10:29.610
These accesses are optimized for data

00:10:29.610 --> 00:10:31.890
that is constant across all thread software

00:10:31.890 --> 00:10:33.183
dispatch or draw.

00:10:34.590 --> 00:10:36.900
If the size of the object is fixed,

00:10:36.900 --> 00:10:40.350
and if the object is read many times by different threads,

00:10:40.350 --> 00:10:43.263
then create those objects in constant address space.

00:10:45.240 --> 00:10:48.333
You can create read/write buffers in device address space.

00:10:49.230 --> 00:10:53.190
If the data being accessed is varying across the threads

00:10:53.190 --> 00:10:56.100
or if the size of the buffer is not fixed,

00:10:56.100 --> 00:10:59.073
then you can create such buffers in device address space.

00:11:00.780 --> 00:11:02.850
Check out, "Optimize Metal Performance

00:11:02.850 --> 00:11:05.910
for Apple silicon Macs," for more details on constant

00:11:05.910 --> 00:11:08.943
and device address space recommendations with examples.

00:11:12.840 --> 00:11:13.673
Threadgroup address space

00:11:13.673 --> 00:11:16.260
is for read/write memory objects too.

00:11:16.260 --> 00:11:18.300
Threads in the threadgroup can work together

00:11:18.300 --> 00:11:20.703
by sharing data in the threadgroup memory.

00:11:22.140 --> 00:11:24.483
They're often faster in most cases.

00:11:25.740 --> 00:11:28.530
In some use cases, threadgroup memory is used

00:11:28.530 --> 00:11:32.850
as a software-managed cache of device or constant buffers.

00:11:32.850 --> 00:11:36.210
For example, blocks of device memory are copied

00:11:36.210 --> 00:11:38.850
into threadgroup memory to operate with.

00:11:38.850 --> 00:11:41.103
It can be faster in some cases.

00:11:43.650 --> 00:11:46.740
With the new advancements in Apple Family 9 GPUs

00:11:46.740 --> 00:11:50.130
shader code memory, the trade-offs on when to use

00:11:50.130 --> 00:11:53.193
threadgroup memory might be different from prior GPUs.

00:11:54.390 --> 00:11:56.640
In your shader, if the use of threadgroup memory

00:11:56.640 --> 00:12:00.600
is primarily to use as a software-managed cache of device

00:12:00.600 --> 00:12:04.350
or constant buffers, then it may be more performant to read

00:12:04.350 --> 00:12:07.260
directly from those buffers instead of copying

00:12:07.260 --> 00:12:08.360
to threadgroup memory.

00:12:09.900 --> 00:12:13.410
With Apple Family 9 GPUs dynamic shader core memory

00:12:13.410 --> 00:12:16.490
and flexible on-chip memory features,

00:12:16.490 --> 00:12:19.410
threadgroup device constant memory types are using

00:12:19.410 --> 00:12:21.003
the same cache hierarchy,

00:12:21.960 --> 00:12:25.380
so if your working set size fits in the cache,

00:12:25.380 --> 00:12:28.230
then both the buffer and threadgroup memory access

00:12:28.230 --> 00:12:31.680
might have similar performance characteristics.

00:12:31.680 --> 00:12:34.710
In those cases, instead of creating copies of memory

00:12:34.710 --> 00:12:38.040
in threadgroup and device or constant address space,

00:12:38.040 --> 00:12:41.340
shader can just operate with the device or constant buffers

00:12:41.340 --> 00:12:43.920
and avoid the latencies involved with copying

00:12:43.920 --> 00:12:45.020
to threadgroup memory.

00:12:46.410 --> 00:12:48.540
Additional guidance on whether keeping the data

00:12:48.540 --> 00:12:52.560
just in device or constant buffers is beneficial or not,

00:12:52.560 --> 00:12:54.840
can be evaluated by profiling the workload

00:12:54.840 --> 00:12:56.943
using Metal debugger in Xcode.

00:12:58.350 --> 00:13:00.360
Similar to address-based selection,

00:13:00.360 --> 00:13:02.790
data type can impact the performance too.

00:13:02.790 --> 00:13:05.700
For instance, 16-bit data types can help reduce

00:13:05.700 --> 00:13:07.533
the register and memory footprint.

00:13:08.760 --> 00:13:12.090
Using 16-bit data types such as half and short

00:13:12.090 --> 00:13:15.783
over float and int when possible allows better performance.

00:13:16.740 --> 00:13:20.250
Conversions are free, so don't worry about converting

00:13:20.250 --> 00:13:22.983
between types such as between half and float.

00:13:23.910 --> 00:13:26.950
Bfloat is a 16-bit truncated version of float

00:13:28.020 --> 00:13:31.593
best suited for accelerating machine learning applications.

00:13:33.090 --> 00:13:36.190
It allows wide range of values at a lower precision

00:13:37.290 --> 00:13:41.103
Bfloat data type has been supported since Metal 3.1.

00:13:42.090 --> 00:13:44.970
If your application has precision requirements that match

00:13:44.970 --> 00:13:48.660
with what is supported by bfloat, it is highly recommended

00:13:48.660 --> 00:13:49.893
to use this data type.

00:13:51.420 --> 00:13:55.260
Using 16-bit data types rather than 32-bit data types

00:13:55.260 --> 00:13:58.560
results in shader using fewer registers.

00:13:58.560 --> 00:14:00.690
If that data is stored in memory,

00:14:00.690 --> 00:14:03.300
it can also help reduce the memory footprint

00:14:03.300 --> 00:14:05.280
and improve bandwidth.

00:14:05.280 --> 00:14:09.930
As a result, it can lead to better thread occupancy.

00:14:09.930 --> 00:14:14.223
Using 16-bit data types also improves the energy efficiency.

00:14:16.530 --> 00:14:18.600
When writing expressions that are meant

00:14:18.600 --> 00:14:22.260
to be evaluated at half decision, be sure

00:14:22.260 --> 00:14:25.380
to use 'h' suffix on any literals.

00:14:25.380 --> 00:14:28.170
Otherwise, the entire expression will be evaluated

00:14:28.170 --> 00:14:31.620
at a float precision and that will lose the benefits

00:14:31.620 --> 00:14:33.183
of using smaller types.

00:14:35.370 --> 00:14:38.550
In some shaders, it can result in better instruction mix

00:14:38.550 --> 00:14:40.260
by using half type,

00:14:40.260 --> 00:14:42.120
such as having a mix of float,

00:14:42.120 --> 00:14:45.000
half and int type instructions.

00:14:45.000 --> 00:14:46.890
This can result in better utilization

00:14:46.890 --> 00:14:50.010
of ALU pipelines in Apple Family 9 GPU,

00:14:50.010 --> 00:14:52.310
and it can improve the instruction throughput.

00:14:54.180 --> 00:14:57.300
To summarize, improve resource utilization

00:14:57.300 --> 00:14:58.920
by choosing the right address space

00:14:58.920 --> 00:15:00.813
based on the memory usage pattern.

00:15:01.650 --> 00:15:05.430
Choosing 16-bit data types can help reduce the register

00:15:05.430 --> 00:15:08.550
and memory footprint and in some cases it can result

00:15:08.550 --> 00:15:11.160
in better utilization of the ALU parallelism

00:15:11.160 --> 00:15:13.113
in Apple Family 9 GPUs.

00:15:13.980 --> 00:15:15.840
For ray tracing shaders too,

00:15:15.840 --> 00:15:18.630
it is important to reduce shader execution time

00:15:18.630 --> 00:15:20.760
and improve resource utilization in order

00:15:20.760 --> 00:15:22.113
to improve the performance.

00:15:24.360 --> 00:15:27.300
To render with Metal ray tracing, the first step

00:15:27.300 --> 00:15:29.550
is to define your scene geometry

00:15:29.550 --> 00:15:31.500
and build an acceleration structure

00:15:31.500 --> 00:15:33.543
to allow efficient intersection.

00:15:35.430 --> 00:15:38.040
Intersection is performed from a GPU function

00:15:38.040 --> 00:15:39.750
that creates a ray.

00:15:39.750 --> 00:15:42.450
This GPU function makes an intersector object

00:15:42.450 --> 00:15:43.983
to perform intersection.

00:15:44.970 --> 00:15:46.770
The result returned from intersection

00:15:46.770 --> 00:15:49.890
will have all the information you may need to either shade

00:15:49.890 --> 00:15:51.993
the pixel or process it further.

00:15:54.960 --> 00:15:57.240
The intersector component of this process

00:15:57.240 --> 00:16:00.813
is hardware accelerated on Apple Family 9 GPUs.

00:16:02.130 --> 00:16:04.500
The hardware intersector is responsible

00:16:04.500 --> 00:16:07.170
for traversing the acceleration structure,

00:16:07.170 --> 00:16:09.240
invoking intersection functions

00:16:09.240 --> 00:16:11.460
and updating the state of the traversal

00:16:11.460 --> 00:16:13.953
based upon the result of intersection.

00:16:15.000 --> 00:16:17.871
The intersector is the fundamental API

00:16:17.871 --> 00:16:19.050
for Metal ray tracing.

00:16:19.050 --> 00:16:22.320
Using intersection functions, ray payload,

00:16:22.320 --> 00:16:25.740
intersection tags and the intersection in optimal way

00:16:25.740 --> 00:16:27.843
can improve the ray tracing performance.

00:16:29.070 --> 00:16:32.130
Custom intersection functions are a powerful way to define

00:16:32.130 --> 00:16:34.650
how rays hit surfaces,

00:16:34.650 --> 00:16:38.133
but use custom intersection functions only when necessary.

00:16:39.540 --> 00:16:41.640
Custom intersection functions are important

00:16:41.640 --> 00:16:44.580
for implementing features like alpha testing.

00:16:44.580 --> 00:16:47.880
Alpha testing is used to add more geometric detail

00:16:47.880 --> 00:16:51.453
to the scene, like in the chains and leaves from this image.

00:16:52.350 --> 00:16:53.760
Alpha testing is implemented

00:16:53.760 --> 00:16:56.133
by using a custom intersection function.

00:16:58.110 --> 00:17:00.450
The logic inside custom intersection functions

00:17:00.450 --> 00:17:04.140
is responsible for accepting or rejecting intersections

00:17:04.140 --> 00:17:06.663
as the ray traverses the acceleration structure.

00:17:08.310 --> 00:17:11.250
In this case, the custom intersection function logic

00:17:11.250 --> 00:17:13.263
will reject the first intersection,

00:17:14.520 --> 00:17:16.920
but it will accept the second intersection

00:17:16.920 --> 00:17:19.593
since an opaque surface has been intersected.

00:17:21.060 --> 00:17:24.060
Custom intersection functions can enable additional logic

00:17:24.060 --> 00:17:26.460
to be executed on the shader course.

00:17:26.460 --> 00:17:28.233
Use it only when necessary.

00:17:29.190 --> 00:17:32.583
The opaque triangle intersectors are the fastest path.

00:17:34.380 --> 00:17:36.780
If you need custom intersection functions,

00:17:36.780 --> 00:17:38.760
note that the hardware will be sorting

00:17:38.760 --> 00:17:41.250
and grouping by intersection function.

00:17:41.250 --> 00:17:44.220
Having a lot of intersection functions will make it harder

00:17:44.220 --> 00:17:45.903
to find matches and group,

00:17:47.010 --> 00:17:49.440
so avoid duplicate intersection functions

00:17:49.440 --> 00:17:51.423
to help in grouping optimally.

00:17:52.950 --> 00:17:55.650
And take advantage of the Metal intersection function

00:17:55.650 --> 00:17:58.920
table indexing mechanism to create simple tables

00:17:58.920 --> 00:18:00.723
with one entry per function.

00:18:02.070 --> 00:18:05.520
To run the intersection test, the hardware intersection

00:18:05.520 --> 00:18:08.070
creates SIMDgroup for multiple rays

00:18:08.070 --> 00:18:10.830
and then each ray is tested against multiple

00:18:10.830 --> 00:18:12.063
primitives in parallel.

00:18:14.640 --> 00:18:16.530
Since the custom intersection functions

00:18:16.530 --> 00:18:19.800
are running in parallel, they will need to be serialized

00:18:19.800 --> 00:18:23.400
if they perform any operation that has side effects.

00:18:23.400 --> 00:18:25.890
This includes memory writes to the payload

00:18:25.890 --> 00:18:27.543
or other device memory.

00:18:28.470 --> 00:18:32.280
Similarly, any operations that introduce divergence

00:18:32.280 --> 00:18:35.190
such as indirect function calls will also reduce

00:18:35.190 --> 00:18:38.223
the parallelism of the intersection function execution.

00:18:39.360 --> 00:18:42.840
It's best to perform these operations as late as possible

00:18:42.840 --> 00:18:44.070
in the intersection function

00:18:44.070 --> 00:18:46.773
to allow maximum parallelism until that point.

00:18:49.260 --> 00:18:52.890
In this example, ray payload is updated first

00:18:52.890 --> 00:18:54.480
and then some work unrelated

00:18:54.480 --> 00:18:56.373
to the payload update is performed.

00:18:57.990 --> 00:18:59.640
This will cause all the code

00:18:59.640 --> 00:19:02.610
after payload update to be run serially.

00:19:02.610 --> 00:19:05.550
Instead, you can modify the intersection function

00:19:05.550 --> 00:19:08.460
to have all the work unrelated to the payload update

00:19:08.460 --> 00:19:12.330
to be done first and then update the payload.

00:19:12.330 --> 00:19:15.453
This will maximize the intersection function parallelism.

00:19:17.760 --> 00:19:20.460
Returning to the hardware intersector model,

00:19:20.460 --> 00:19:22.530
this flow chart explains the process,

00:19:22.530 --> 00:19:25.083
but it is overlooking one vital element.

00:19:26.490 --> 00:19:29.280
During intersection, ray trace scratch space

00:19:29.280 --> 00:19:32.190
is used to store the state of the traversal

00:19:32.190 --> 00:19:35.523
and return results to the GPU function calling intersect.

00:19:37.920 --> 00:19:41.460
The intersector API supports a payload for each ray.

00:19:41.460 --> 00:19:43.440
The larger the payload structure is

00:19:43.440 --> 00:19:46.743
the more impact it will have on ray tracing performance.

00:19:47.910 --> 00:19:49.470
When it comes to ray payload,

00:19:49.470 --> 00:19:52.740
the intersection result may have most of the data you need

00:19:52.740 --> 00:19:55.383
and it is best to avoid using any ray payload.

00:19:56.370 --> 00:19:57.780
If you need a payload,

00:19:57.780 --> 00:20:00.120
avoid a global uber payload structure.

00:20:00.120 --> 00:20:04.023
Instead, specialize the structure for each intersect call.

00:20:05.490 --> 00:20:09.120
Minimize the size of the structure with packed data types

00:20:09.120 --> 00:20:11.940
and remove any fields that are not needed.

00:20:11.940 --> 00:20:14.220
Optimizing ray payload usage will result

00:20:14.220 --> 00:20:16.083
in more rays being processed.

00:20:17.160 --> 00:20:19.860
For example, consider a basic payload

00:20:19.860 --> 00:20:21.870
with the intersection position,

00:20:21.870 --> 00:20:25.500
a flag to indicate a hit, and a color.

00:20:25.500 --> 00:20:28.353
In memory, the fields would be laid out like this.

00:20:31.320 --> 00:20:34.140
The position member would be at the start

00:20:34.140 --> 00:20:36.600
and due to its size and alignment,

00:20:36.600 --> 00:20:39.483
the hit flag would be 16 bytes from the start,

00:20:40.650 --> 00:20:44.670
but then the RGB member is at a byte offset of 32,

00:20:44.670 --> 00:20:47.703
making an overall struct size of 48 bytes.

00:20:49.710 --> 00:20:51.660
By changing the flow three values

00:20:51.660 --> 00:20:53.370
to their packed equivalence,

00:20:53.370 --> 00:20:55.653
there is less space lost to alignment.

00:20:56.610 --> 00:20:59.940
The hit flag can be removed since it is not needed

00:20:59.940 --> 00:21:02.163
when using the Metal ray tracing API,

00:21:03.030 --> 00:21:04.320
you can just check the type

00:21:04.320 --> 00:21:07.020
of intersection in the intersection result.

00:21:07.020 --> 00:21:09.360
This is easy to use and more performant,

00:21:09.360 --> 00:21:13.053
especially for visibility rays like shadows and occlusion.

00:21:14.040 --> 00:21:17.010
Similarly, the position can be computer-based

00:21:17.010 --> 00:21:19.680
on the ray's origin, direction

00:21:19.680 --> 00:21:21.980
and the intersection distance from the result.

00:21:25.230 --> 00:21:27.390
And then to reduce the size further,

00:21:27.390 --> 00:21:29.130
the RGB color can be packed

00:21:29.130 --> 00:21:32.430
to four bytes in the intersection function using the packing

00:21:32.430 --> 00:21:34.353
methods in Metal shading language.

00:21:36.240 --> 00:21:39.840
In this example, ray data payload structure started off

00:21:39.840 --> 00:21:44.490
with the size of 48 bytes and reduced to four bytes.

00:21:44.490 --> 00:21:47.610
By using such methods, you can optimize your array payload

00:21:47.610 --> 00:21:49.683
to improve the rate tracing performance.

00:21:51.090 --> 00:21:54.450
Like ray payload, intersection tags also affect

00:21:54.450 --> 00:21:56.673
ray tracing performance in a similar way.

00:21:58.560 --> 00:22:01.440
Another contributor to ray tracing scratch usage

00:22:01.440 --> 00:22:04.920
is the intersection tags on the intersector.

00:22:04.920 --> 00:22:06.930
These tags are the additional state

00:22:06.930 --> 00:22:08.673
for the traversal to track.

00:22:09.720 --> 00:22:13.020
The world space data tag in this declaration means

00:22:13.020 --> 00:22:14.580
that the object to world

00:22:14.580 --> 00:22:18.870
and world to object matrices have to be stored for each ray.

00:22:18.870 --> 00:22:21.570
This adds to the retracing scratch usage

00:22:21.570 --> 00:22:24.573
and will impact occupancy during the intersect call.

00:22:27.270 --> 00:22:29.580
The other important thing to note with the tags

00:22:29.580 --> 00:22:32.610
is that they need to match between the intersector

00:22:32.610 --> 00:22:35.283
and the intersection functions that it calls.

00:22:37.350 --> 00:22:39.750
Intersector is better than intersection query

00:22:39.750 --> 00:22:42.510
because of how the intersection query API impacts

00:22:42.510 --> 00:22:44.043
the ray tracing performance.

00:22:45.360 --> 00:22:48.570
Looking at the hardware intersector model, it is a great fit

00:22:48.570 --> 00:22:51.063
for the intersector in the shading language.

00:22:52.080 --> 00:22:54.210
An intersection query defines an object

00:22:54.210 --> 00:22:57.540
that does not use custom intersection functions.

00:22:57.540 --> 00:22:59.460
The intersection code is executed

00:22:59.460 --> 00:23:01.470
in the original GPU function

00:23:01.470 --> 00:23:03.720
and the hardware intersector needs to wait

00:23:03.720 --> 00:23:07.527
until the code completes before continuing the traversal.

00:23:09.605 --> 00:23:11.550
If you choose to use intersection query,

00:23:11.550 --> 00:23:14.460
the hardware has no custom intersection functions to sort

00:23:14.460 --> 00:23:16.353
and cannot group the execution.

00:23:17.430 --> 00:23:20.672
It also needs to use more ray tracing scratch memory

00:23:20.672 --> 00:23:22.772
to allow it to return to the GPU function.

00:23:24.780 --> 00:23:27.030
Intersection query is the alternative model

00:23:27.030 --> 00:23:29.460
for ray intersection to support portability

00:23:29.460 --> 00:23:31.680
from other shading languages.

00:23:31.680 --> 00:23:35.220
Since intersector aligns with the hardware implementation,

00:23:35.220 --> 00:23:37.773
prefer intersector over intersection query.

00:23:39.360 --> 00:23:41.730
If you do need to use intersection query,

00:23:41.730 --> 00:23:44.373
use as few query objects as possible.

00:23:45.210 --> 00:23:47.850
If multiple intersection queries are necessary,

00:23:47.850 --> 00:23:51.150
try to reuse the query object, but change the properties.

00:23:51.150 --> 00:23:55.650
This enables reuse of the ray tracing scratch for one query.

00:23:55.650 --> 00:23:59.280
For example, if you have an intersection query object IQ1

00:23:59.280 --> 00:24:01.230
for doing some ray tracing work,

00:24:01.230 --> 00:24:03.780
and then if you need to do more ray tracing work

00:24:03.780 --> 00:24:05.850
with the opaque opacity set,

00:24:05.850 --> 00:24:09.720
then instead of creating new intersection query object,

00:24:09.720 --> 00:24:11.670
simply use the intersection params

00:24:11.670 --> 00:24:14.730
to reset the existing intersection query object

00:24:14.730 --> 00:24:16.053
with opaque opacity.

00:24:17.370 --> 00:24:20.283
This way you can reuse the ray tracing scratch memory.

00:24:23.430 --> 00:24:26.190
When using multiple intersection queries,

00:24:26.190 --> 00:24:27.480
avoid switching between them

00:24:27.480 --> 00:24:29.880
and overlapping their traversal.

00:24:29.880 --> 00:24:31.920
This avoids expensive swaps

00:24:31.920 --> 00:24:34.383
between the in-progress hardware traversals.

00:24:35.730 --> 00:24:38.010
For example, in your ray tracing work,

00:24:38.010 --> 00:24:40.890
instead of switching from IQ1 to IQ2

00:24:40.890 --> 00:24:43.260
and then back to IQ1.

00:24:43.260 --> 00:24:46.680
Continue with IQ1 and complete the ray tracing work

00:24:46.680 --> 00:24:49.790
with it before switching to IQ2.

00:24:49.790 --> 00:24:52.080
To summarize ray tracing best practices,

00:24:52.080 --> 00:24:55.173
use custom intersection function only when necessary.

00:24:56.280 --> 00:24:57.723
Optimize ray payload.

00:24:59.100 --> 00:25:01.413
Minimize the number of intersection tags.

00:25:02.580 --> 00:25:05.283
Use intersector over intersection query.

00:25:06.390 --> 00:25:09.030
To learn more about ray tracing with Metal,

00:25:09.030 --> 00:25:12.270
please watch, "Your guide to Metal ray tracing."

00:25:12.270 --> 00:25:14.880
And to learn how to use new ray tracing counters

00:25:14.880 --> 00:25:16.950
from Metal debugger in Xcode,

00:25:16.950 --> 00:25:20.663
check out, "Discover new Metal profiling tools for M3

00:25:20.663 --> 00:25:21.897
and A17 Pro."

00:25:23.280 --> 00:25:25.740
To recap, in order to improve performance

00:25:25.740 --> 00:25:29.190
of your Metal shaders, you can reduce shader execution time

00:25:29.190 --> 00:25:31.710
by using Metal features like function constants

00:25:31.710 --> 00:25:33.360
and function groups.

00:25:33.360 --> 00:25:36.090
Using such features can enable more optimization

00:25:36.090 --> 00:25:39.900
opportunities in Metal, improve thread occupancy

00:25:39.900 --> 00:25:43.113
with better resource utilization to increase parallelism.

00:25:44.670 --> 00:25:47.700
Apply the best practices for intersection function,

00:25:47.700 --> 00:25:49.860
ray payload, intersection tags,

00:25:49.860 --> 00:25:52.260
and the intersector to make the best use

00:25:52.260 --> 00:25:54.423
of the hardware accelerated ray tracing.

00:25:55.500 --> 00:25:56.553
Thank you very much.