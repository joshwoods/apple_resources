WEBVTT

00:00:09.060 --> 00:00:12.500
Hi, I'm Eryk Vershen,
Media Technologies Evangelist.

00:00:12.500 --> 00:00:16.240
In this video, you'll learn all about
video playback in iOS,

00:00:16.360 --> 00:00:19.560
how to handle remote control events,
and a brief introduction

00:00:19.560 --> 00:00:22.630
to AV Foundation,
essential knowledge for

00:00:22.630 --> 00:00:24.910
incorporating video in your iOS app.

00:00:25.030 --> 00:00:28.950
This talk is going to get you
started on video if you're new to it.

00:00:29.000 --> 00:00:32.370
It's going to get you to add
functionality if you're already

00:00:32.370 --> 00:00:33.720
using video in your app.

00:00:34.210 --> 00:00:37.860
And it's going to introduce you
to some of the more advanced APIs.

00:00:38.100 --> 00:00:41.000
You're going to learn how to do
basic movie playback and recording.

00:00:41.000 --> 00:00:43.950
You're going to learn
about notifications,

00:00:43.950 --> 00:00:47.520
remote control, AV output,
and a brief introduction

00:00:47.520 --> 00:00:48.940
to AV Foundation.

00:00:50.760 --> 00:00:53.110
So let's look at the technology
frameworks that we're going

00:00:53.190 --> 00:00:54.300
to be talking about here.

00:00:54.320 --> 00:00:55.890
There's three frameworks in particular.

00:00:55.890 --> 00:00:59.220
The first one is the
Media Player Framework.

00:00:59.250 --> 00:01:04.040
The Media Player Framework is responsible
for simple basic movie playback as

00:01:04.040 --> 00:01:09.120
well as playing back of songs that
you might have in your iPod app.

00:01:09.150 --> 00:01:11.740
Now we're not going to talk
about playing back songs.

00:01:11.750 --> 00:01:14.080
We're just going to talk
about the movie playback.

00:01:14.100 --> 00:01:18.140
Now underneath the Media Player Framework
is the UI Kit Framework.

00:01:18.170 --> 00:01:22.670
The UI Kit Framework is a very
large framework and has to do with

00:01:22.670 --> 00:01:26.930
everything that presents UI in iOS.

00:01:27.210 --> 00:01:33.110
A small portion of UI Kit has to do with
presenting media and I'll be talking

00:01:33.110 --> 00:01:35.420
about those classes in this talk.

00:01:35.510 --> 00:01:39.090
Underneath that at a level
below is AV Foundation.

00:01:39.290 --> 00:01:42.820
AV Foundation is another
very large framework.

00:01:42.920 --> 00:01:47.960
It was introduced in iOS 4.0 and it's
what you need to use if you're going

00:01:47.960 --> 00:01:50.120
to do more advanced things with video.

00:01:52.000 --> 00:01:54.720
In the diagram you'll see that
I've mentioned several other

00:01:54.720 --> 00:02:00.380
frameworks below AV Foundation:
Core Audio, Core Media, Core Animation.

00:02:00.470 --> 00:02:04.380
I won't be talking in detail
about those frameworks,

00:02:04.390 --> 00:02:07.280
but I wanted to give you a sense
that AV Foundation is built on

00:02:07.280 --> 00:02:09.810
a lot of other technologies.

00:02:10.260 --> 00:02:13.350
So these three frameworks on the top,
Media Player, UI Kit,

00:02:13.350 --> 00:02:16.480
and AV Foundation is what
we're going to talk about.

00:02:16.640 --> 00:02:19.150
First, let's talk about playback.

00:02:19.610 --> 00:02:23.800
Basic movie playback is when
you're taking over the entire

00:02:23.800 --> 00:02:26.730
screen to play back your movie.

00:02:26.760 --> 00:02:28.690
And in this case,
you're going to be using

00:02:28.690 --> 00:02:30.100
Media Player Framework.

00:02:30.160 --> 00:02:34.200
The first class you want to know
about is MPMoviePlayerViewController.

00:02:34.290 --> 00:02:37.560
MPMoviePlayerViewController is
what you're going to use if you're

00:02:37.560 --> 00:02:42.130
going to do simple movie playback,
where you want to take over the

00:02:42.130 --> 00:02:44.490
entire screen of your iOS device.

00:02:44.750 --> 00:02:49.520
Now, MPMoviePlayerViewController
is a UIViewController.

00:02:49.590 --> 00:02:51.460
And you use it modally.

00:02:51.530 --> 00:02:56.440
That is, it's going to be the only thing
interacting on your iOS device.

00:02:56.500 --> 00:03:00.000
But rather than using the standard
present and dismiss methods,

00:03:00.000 --> 00:03:04.520
you have to use special methods that
are customized for UIViewController.

00:03:04.580 --> 00:03:08.200
Now,
this is going to use the entire screen.

00:03:08.270 --> 00:03:12.740
So, what you're going to do is
you're going to add a method to

00:03:12.740 --> 00:03:15.410
your UIViewController subclass.

00:03:16.000 --> 00:03:19.120
This method would be called
something like PlayMovieAtURL.

00:03:19.120 --> 00:03:23.340
You'll pass it a URL of the
content that you want to play.

00:03:23.460 --> 00:03:25.590
Obviously the first thing you're
going to do is you need to allocate

00:03:25.650 --> 00:03:30.930
that MPMoviePlayerViewController
and init it with your content.

00:03:31.140 --> 00:03:34.000
The next thing you're going to do
is you're going to register for

00:03:34.000 --> 00:03:36.660
the playback finish notification.

00:03:36.790 --> 00:03:39.540
Now, one of the things you want to
notice here is that the object

00:03:39.540 --> 00:03:43.320
you're going to get notifications
on is not your view controller.

00:03:43.490 --> 00:03:49.040
Instead, it's the movie player that's
associated with the view controller.

00:03:49.310 --> 00:03:52.980
And the notification you're going
to register for is MPMoviePlayer

00:03:53.380 --> 00:03:55.040
Playback Did Finish notification.

00:03:55.070 --> 00:03:58.990
And this is what you're going to
get when your movie stops playing.

00:03:59.760 --> 00:04:03.560
Now once you've done that,
you simply tell the view controller to

00:04:03.680 --> 00:04:06.840
present the movie player view controller.

00:04:06.910 --> 00:04:11.710
You're calling that method which
goes ahead and has this new view

00:04:11.710 --> 00:04:14.300
controller take over the screen.

00:04:14.380 --> 00:04:18.220
And at that point,
all you do is initiate movie playback.

00:04:18.330 --> 00:04:20.580
Now notice that this is asynchronous.

00:04:20.630 --> 00:04:23.440
The movie doesn't start
playing immediately,

00:04:23.440 --> 00:04:26.060
but the method does return immediately.

00:04:26.760 --> 00:04:30.600
Now the other piece of code that you
need to create is the method that's

00:04:30.680 --> 00:04:34.650
going to be called by that notification.

00:04:34.860 --> 00:04:38.960
In this case I've called
it myMovieFinishedCallback.

00:04:39.030 --> 00:04:42.040
Now it's going to get a notification
object like any notification

00:04:42.040 --> 00:04:44.880
and the first thing I'm going
to do is I'm going to get rid

00:04:44.880 --> 00:04:48.000
of the notification that I created.

00:04:48.080 --> 00:04:51.740
And notice that in this case what
I'm getting back as an object is

00:04:51.740 --> 00:04:56.400
not the view controller but is
instead the movie player that's

00:04:56.400 --> 00:04:58.890
associated with that view controller.

00:04:59.170 --> 00:05:04.500
Once I've gotten rid of the notification,
I dismiss the modal view and

00:05:04.500 --> 00:05:07.500
then release the instance.

00:05:08.180 --> 00:05:11.200
Now,
the other class that we're going to be

00:05:11.200 --> 00:05:15.300
interested in is MPMoviePlayerController.

00:05:15.390 --> 00:05:19.870
MPMoviePlayerController is one I use
when I want to only take over part

00:05:19.870 --> 00:05:23.130
of the screen of my iOS device.

00:05:23.800 --> 00:05:28.180
Now, in this case,
rather than being a view controller,

00:05:28.190 --> 00:05:31.460
it has a view property
associated with it.

00:05:31.590 --> 00:05:36.240
And that means we need to install
this view into our view hierarchy

00:05:36.680 --> 00:05:42.920
And the frame of that view needs to
match the bounds of its parent view.

00:05:43.020 --> 00:05:46.260
So let's look at the method
we're going to create.

00:05:46.340 --> 00:05:49.100
Again, let's call it something
like PlayMovieAtURL.

00:05:49.180 --> 00:05:51.840
Now in the beginning here,
I'm going to do very similar things.

00:05:51.840 --> 00:05:55.660
I'm going to go and create
my MPMoviePlayer controller.

00:05:55.730 --> 00:06:00.080
I'm going to save it away
somewhere in my class.

00:06:00.270 --> 00:06:03.960
I'm going to set the content to
be the URL that I'm interested in.

00:06:04.060 --> 00:06:07.340
And then the important piece that
I've highlighted here is I'm going to

00:06:07.420 --> 00:06:14.740
add the view that's associated with
that movie player controller into the

00:06:14.740 --> 00:06:18.050
view hierarchy that already exists.

00:06:18.400 --> 00:06:33.600
[Transcript missing]

00:06:33.930 --> 00:06:39.020
So that's our two classes
that exist in Media Player.

00:06:39.110 --> 00:06:41.350
MPMoviePlayerViewController.

00:06:41.360 --> 00:06:42.550
It's a view controller.

00:06:42.810 --> 00:06:45.880
You use it modally and it
takes over the whole screen.

00:06:45.960 --> 00:06:50.600
And MPMoviePlayerController
instead has a view property.

00:06:50.670 --> 00:06:55.320
You install it in your view hierarchy
and make sure that the bounds match.

00:06:55.400 --> 00:06:59.640
Now one thing I want to
mention is prior to iOS 3.2,

00:06:59.780 --> 00:07:03.200
MPMoviePlayerController
worked differently.

00:07:03.310 --> 00:07:08.920
In that case it took over the whole
screen and the modal playback wasn't

00:07:09.100 --> 00:07:10.120
presented with a special method.

00:07:10.120 --> 00:07:14.220
Instead it happened automatically
when you played and was dismissed

00:07:14.220 --> 00:07:16.870
automatically when the movie finished.

00:07:17.190 --> 00:07:19.500
Now,
the only reason I mention this is if you

00:07:19.500 --> 00:07:26.420
have to port some code that's pre-3.2,
or if you feel you need, for some reason,

00:07:26.420 --> 00:07:31.960
to still support users who
are on iOS 3.1 or earlier.

00:07:32.090 --> 00:07:37.570
This behavior is deprecated and doesn't
occur in newer versions of the OS.

00:07:38.730 --> 00:07:42.350
Now I'd like to turn to what
you can do in terms of enhancing

00:07:42.450 --> 00:07:44.420
your support for movies.

00:07:44.950 --> 00:07:47.980
I'm going to talk about
five different things here.

00:07:48.040 --> 00:07:51.800
What you can do with your user
interface in terms of customization,

00:07:51.850 --> 00:07:55.580
the various notifications
that exist around movies.

00:07:56.050 --> 00:07:59.240
How to handle remote control events.

00:07:59.240 --> 00:08:05.110
How you can get video output
from iOS and about AirPlay.

00:08:05.640 --> 00:08:08.500
So let's talk about user interface.

00:08:08.580 --> 00:08:14.550
Now when I'm playing a video,
say with MP Movie Player View Controller,

00:08:14.550 --> 00:08:19.100
it's in an embedded view and I have
a very limited set of controls.

00:08:19.210 --> 00:08:24.820
A play/pause button, an airplay button,
and a button that allows

00:08:24.830 --> 00:08:26.420
me to go in full screen.

00:08:26.660 --> 00:08:30.170
Now once I go into full screen,
I have a lot more controls.

00:08:30.200 --> 00:08:34.020
I have a volume slider,
a next fast forward button,

00:08:34.180 --> 00:08:40.760
a previous rewind button, done button,
the scrubber bar and play head,

00:08:40.760 --> 00:08:45.090
and a button that allows me to
change the scaling of the video.

00:08:45.470 --> 00:08:50.740
Now for certain kinds of media,
file-based media, I have a few other

00:08:51.130 --> 00:08:52.850
controls that will show up.

00:08:53.090 --> 00:08:58.590
There's a control for subtitle and
alternate audio menu and a control

00:08:58.590 --> 00:09:01.710
that shows the chapter list menu.

00:09:02.220 --> 00:09:05.570
In terms of customizing
the UI for movie playback,

00:09:05.580 --> 00:09:08.310
really your only choice is
to turn off the controls.

00:09:08.490 --> 00:09:12.650
You do that with the
MPMovie control style none.

00:09:13.010 --> 00:09:15.600
Now you can resynthesize
most of the controls.

00:09:15.750 --> 00:09:21.550
The exceptions are the AirPlay control,
the subtitle and alternate audio button,

00:09:21.750 --> 00:09:22.900
and the chapter list.

00:09:24.590 --> 00:09:29.940
It is possible to get airplay
by using the MPVolumeView class.

00:09:30.050 --> 00:09:33.690
This gives you a volume
slider and an airplay button.

00:09:33.690 --> 00:09:36.600
Using the MPVolumeView is
pretty straightforward.

00:09:36.770 --> 00:09:43.050
You allocate the class associating
with the particular parent view's

00:09:43.050 --> 00:09:45.680
bounds and add it as a subview.

00:09:46.050 --> 00:09:48.740
Now I'd like to turn to the
various notifications that

00:09:48.740 --> 00:09:50.500
are associated with movies.

00:09:50.670 --> 00:09:53.220
There are quite a
number of notifications,

00:09:53.230 --> 00:09:56.200
so I've broken them into several groups.

00:09:56.350 --> 00:09:59.260
The first group I'd like to talk
about is those that are associated

00:09:59.260 --> 00:10:00.890
directly with movie playback.

00:10:01.030 --> 00:10:04.860
The first one you've seen before,
MPMoviePlayerPlaybackDidFinishNot

00:10:04.900 --> 00:10:05.810
ification.

00:10:05.810 --> 00:10:09.190
That's a notification you
get when your movie's done.

00:10:09.390 --> 00:10:13.720
The other ones here have to do with
notifications that you'd like to

00:10:13.740 --> 00:10:21.260
get when some part of your app isn't
directly involved with movie playback.

00:10:21.400 --> 00:10:24.770
For instance,
if you want to use the same movie

00:10:24.770 --> 00:10:29.920
player to play multiple different URLs,
that is, different content,

00:10:30.000 --> 00:10:33.190
you can have part of your
app register for the "Now

00:10:33.300 --> 00:10:36.220
Playing Movie Did Change" notification.

00:10:36.500 --> 00:10:40.300
That part of your app will
get this notification when you

00:10:40.390 --> 00:10:42.960
change the URL that's associated.

00:10:43.810 --> 00:10:46.650
The next group of notifications
I'd like to talk about all have

00:10:46.650 --> 00:10:49.930
to do with the movie content.

00:10:50.100 --> 00:10:54.900
The first four have to do with values
that are associated with a movie

00:10:55.280 --> 00:11:00.560
that aren't necessarily available
when you first initialize your movie.

00:11:00.770 --> 00:11:03.760
For instance,
the system may not know exactly

00:11:03.910 --> 00:11:09.230
the duration of your movie
when you initialize the object.

00:11:09.430 --> 00:11:15.350
If some part of your application
needs to know these values exactly,

00:11:15.350 --> 00:11:18.750
you should register for one of
these notifications so that you

00:11:18.840 --> 00:11:21.520
can find out once the system knows.

00:11:21.880 --> 00:11:26.510
The next two notifications here
have to do with things that

00:11:26.510 --> 00:11:30.230
can change that are part of the
presentation state of the movie.

00:11:30.600 --> 00:11:33.600
For instance, scaling mode did changed.

00:11:33.670 --> 00:11:38.190
If the user is allowed to
change the scaling of the movie,

00:11:38.190 --> 00:11:43.520
that is what the aspect ratio is
of the movie as it's going along,

00:11:43.600 --> 00:11:48.320
your application will get notified with
a scaling mode did change notification.

00:11:48.430 --> 00:11:55.070
The last one in this group is the
time to metadata updated notification.

00:11:55.480 --> 00:12:00.170
Now, this notification only
occurs on HTTP live streams.

00:12:00.310 --> 00:12:03.660
Time metadata is metadata that's
associated with particular

00:12:03.900 --> 00:12:09.860
points in time in the movie,
say 35 seconds in or 42 seconds in.

00:12:10.090 --> 00:12:13.450
The time metadata is sent as a
notification because this makes

00:12:13.600 --> 00:12:18.380
it easier for your application
to react to that metadata.

00:12:18.480 --> 00:12:22.510
The next group of notifications
all have to do with going

00:12:22.620 --> 00:12:24.560
into and out of full screen.

00:12:24.730 --> 00:12:27.610
Now this is a very
typical pattern in iOS.

00:12:27.730 --> 00:12:32.800
You get will enter, did enter, will exit,
did exit.

00:12:32.930 --> 00:12:36.300
And these should be quite familiar
from other parts of the system.

00:12:36.400 --> 00:12:40.030
The last notification I want to
talk about is the thumbnail image

00:12:40.510 --> 00:12:43.590
request did finish notification.

00:12:43.830 --> 00:12:47.870
You used this notification when
you wanted to get a still image for

00:12:47.980 --> 00:12:50.970
one or more frames in your movie.

00:12:51.090 --> 00:12:53.700
These things have to be
done asynchronously by

00:12:53.810 --> 00:12:55.340
the system on your behalf.

00:12:55.440 --> 00:12:58.570
So the system's going to send
you a notification when those

00:12:58.680 --> 00:13:00.910
thumbnails are completed.

00:13:01.740 --> 00:13:05.820
Now I'd like to talk
about remote control.

00:13:05.960 --> 00:13:10.760
Why do you want your app to
respond to remote control events?

00:13:10.910 --> 00:13:14.510
Well, principally you want to respond
to remote control events

00:13:14.550 --> 00:13:16.640
because of the Apple earphones.

00:13:16.810 --> 00:13:20.690
The Apple earphones have a
remote control on them and this

00:13:20.690 --> 00:13:27.010
control allows the user to play,
pause, switch to the next track or

00:13:27.020 --> 00:13:30.910
go back to the previous track,
among other things.

00:13:31.410 --> 00:13:32.870
Why do you want to respond to these?

00:13:32.990 --> 00:13:40.120
Well, if your user is listening to and
watching the video in your app

00:13:40.550 --> 00:13:44.400
while they're on the subway or
riding in a car with other people,

00:13:44.400 --> 00:13:47.930
they don't want to disturb
their neighbors with the audio.

00:13:48.100 --> 00:13:51.000
And if they've got that remote
control available to them,

00:13:51.000 --> 00:13:52.700
they want to be able to use it.

00:13:52.820 --> 00:13:56.150
Now there's a couple other
reasons that you might want to

00:13:56.150 --> 00:13:58.620
support the remote control events.

00:13:59.790 --> 00:14:06.550
If you decide to have the audio portion
of your movie play in the background,

00:14:06.580 --> 00:14:11.410
then there are two ways
that the user can control.

00:14:11.550 --> 00:14:16.420
When the screen is in the locked state,
if the user double clicks,

00:14:16.420 --> 00:14:19.380
they can get the playback controls.

00:14:19.440 --> 00:14:22.180
Or if the user is using another app,

00:14:22.500 --> 00:14:26.570
and goes to look at their
most recently used apps list,

00:14:26.570 --> 00:14:31.250
they can swipe over and actually
have another set of controls that

00:14:31.250 --> 00:14:34.110
we call the Now Playing controls.

00:14:34.310 --> 00:14:37.100
So how do you support
remote control events?

00:14:37.200 --> 00:14:39.230
Well, first of all,
your View or ViewController

00:14:39.240 --> 00:14:44.440
class needs to implement the
canBecomeFirstResponder method.

00:14:44.470 --> 00:14:46.430
Return yes.

00:14:46.800 --> 00:14:50.550
And then you need to do something
when your view appears and

00:14:50.550 --> 00:14:52.700
when your view disappears.

00:14:52.820 --> 00:14:56.700
When your view appears,
you need to tell UI application

00:14:56.700 --> 00:15:00.500
that you're ready to begin
receiving remote control events.

00:15:00.610 --> 00:15:03.900
And you need to become
the first responder.

00:15:04.040 --> 00:15:07.300
Only the first responder gets
the remote control events.

00:15:07.470 --> 00:15:11.660
Now when your view disappears,
you need to undo these things.

00:15:11.810 --> 00:15:15.270
Tell UI application that you no
longer want to receive remote control

00:15:15.270 --> 00:15:18.400
events and resign first responder.

00:15:18.490 --> 00:15:22.730
Now when you get a remote control event,
your method called remote

00:15:22.930 --> 00:15:26.650
control received with event
is what's going to be called.

00:15:27.020 --> 00:15:31.700
You're going to look and see that the
received event is a remote control.

00:15:31.790 --> 00:15:34.710
And you're going to look at
its subtype to see what kind

00:15:34.710 --> 00:15:36.610
of remote control event it is.

00:15:36.990 --> 00:15:40.130
The one that I've highlighted
here is UI Event Subtype

00:15:40.330 --> 00:15:42.820
Remote Control Toggle Play Pause.

00:15:42.910 --> 00:15:46.240
This is the most important
one to respond to.

00:15:46.530 --> 00:15:50.390
Typically, whenever you,
the play/pause button in

00:15:50.620 --> 00:15:55.030
all of these interfaces is
going to give you this event.

00:15:55.180 --> 00:15:57.290
On the slide,
I've listed a couple of other events,

00:15:57.550 --> 00:16:01.400
the previous and next track events,
but there are several other

00:16:01.400 --> 00:16:03.470
events that you should handle,
and you need to refer to

00:16:03.470 --> 00:16:05.880
the documentation for those.

00:16:06.070 --> 00:16:09.650
The next thing I'd like to talk
about is how you can get video

00:16:09.740 --> 00:16:12.890
output from your application.

00:16:13.750 --> 00:16:17.110
Now, with the iOS devices,
you're not actually

00:16:17.110 --> 00:16:18.160
getting a video output.

00:16:18.160 --> 00:16:21.040
Instead, you're getting a second screen.

00:16:21.200 --> 00:16:24.990
And this happens whether you're
using the VGA connector or the

00:16:24.990 --> 00:16:27.840
composite or component AV cables.

00:16:27.970 --> 00:16:32.770
In terms of your application,
what you're seeing is a second screen.

00:16:32.770 --> 00:16:35.420
And that screen is just another view.

00:16:36.200 --> 00:16:40.020
To handle UI screen,
you need to register for screen

00:16:40.020 --> 00:16:41.940
connection and disconnection.

00:16:42.030 --> 00:16:45.020
And then when you want to
display content on that screen,

00:16:45.070 --> 00:16:49.470
you create a window and
simply associate the screen,

00:16:49.470 --> 00:16:53.140
that external screen, with that window.

00:16:53.230 --> 00:16:57.560
You add whatever views you're interested
in and show the window to the user.

00:16:57.700 --> 00:16:59.780
So let's take a look at that.

00:16:59.860 --> 00:17:03.060
Registering for screen connection
and disconnection should look a

00:17:03.060 --> 00:17:05.790
lot like what we've seen before.

00:17:06.020 --> 00:17:09.160
We're just adding another observer,
in this case for the

00:17:09.260 --> 00:17:13.360
UIScreenDidConnect notification,
and there's no object

00:17:13.360 --> 00:17:15.170
associated with this.

00:17:15.290 --> 00:17:18.700
We'll also register for
screen disconnection.

00:17:18.830 --> 00:17:21.510
Now let's look at our method
that we're going to use for

00:17:21.510 --> 00:17:23.490
handling the screen connection.

00:17:23.630 --> 00:17:27.010
The notification object associated
with the notification is going to be

00:17:27.060 --> 00:17:30.060
that new screen that's been connected.

00:17:30.510 --> 00:17:33.210
We're going to allocate a
window associated with that

00:17:33.210 --> 00:17:37.500
screen and set the screen as the
screen object for that window.

00:17:37.650 --> 00:17:40.420
Once we've done that,
all we need to do is tell our

00:17:40.420 --> 00:17:46.220
application to adjust the UI for
having that second screen.

00:17:46.350 --> 00:17:49.000
Now, when we get a screen
disconnection notification,

00:17:49.250 --> 00:17:50.640
we essentially do the inverse.

00:17:50.790 --> 00:17:54.260
We need to hide that window,
get rid of it,

00:17:54.400 --> 00:17:59.320
and update our UI to reflect that
that window is no longer there.

00:18:00.390 --> 00:18:02.000
Next, I'd like to talk about AirPlay.

00:18:02.180 --> 00:18:05.930
Now, AirPlay was something
that we added in iOS 4,

00:18:05.930 --> 00:18:10.330
but now in iOS 4.3,
your application has the ability

00:18:10.490 --> 00:18:12.410
to send video over AirPlay.

00:18:12.420 --> 00:18:17.690
Now, one thing that trips some people
up is that you always will see

00:18:17.720 --> 00:18:23.010
the AirPlay button whenever
there's an AirPlay device around,

00:18:23.010 --> 00:18:25.820
even if that's only an
AirPlay audio device.

00:18:26.340 --> 00:18:29.640
AirPlay audio is something that
you don't opt in or out of.

00:18:29.640 --> 00:18:30.870
It's always there.

00:18:30.900 --> 00:18:34.760
You do, however,
have to opt in to AirPlay video.

00:18:34.760 --> 00:18:38.420
You do this with the Allows
AirPlay property on the

00:18:38.420 --> 00:18:40.810
MP Movie Player controller.

00:18:40.840 --> 00:18:41.980
You simply set it to true.

00:18:41.980 --> 00:18:47.050
Now, do remember that AirPlay in
your app requires updated

00:18:47.100 --> 00:18:49.640
software on your Apple TV.

00:18:49.640 --> 00:18:54.050
You can use AirPlay with web
content by setting the appropriate

00:18:54.050 --> 00:18:56.320
attributes in your HTML5.

00:18:56.320 --> 00:18:59.270
And while it's supported
with Media Player,

00:18:59.270 --> 00:19:02.780
it's not supported in
AV Foundation at this time.

00:19:04.360 --> 00:19:09.710
You can use it with HTTP live streams,
but if your stream is using encryption,

00:19:09.710 --> 00:19:12.610
that's not going to work over AirPlay.

00:19:12.930 --> 00:19:16.000
And one thing you have to remember
is it's streaming the movie,

00:19:16.030 --> 00:19:16.870
not the screen.

00:19:17.080 --> 00:19:22.220
If you're doing overlays or backgrounds,
those things are not going to

00:19:22.220 --> 00:19:24.510
show up on your AirPlay device.

00:19:25.410 --> 00:19:29.290
So, I've talked about five different
enhancements about how you can

00:19:29.330 --> 00:19:35.390
customize your user interface,
about the extensive movie notifications,

00:19:35.530 --> 00:19:38.500
handling remote control
events in your app,

00:19:38.660 --> 00:19:43.210
how you can use a second screen,
and AirPlay.

00:19:44.420 --> 00:19:47.400
Now I'd like to make a few digressions.

00:19:47.550 --> 00:19:49.540
First of all,
I'd like to go back to our technology

00:19:49.540 --> 00:19:54.160
framework and talk about another
framework that I didn't mention before.

00:19:54.220 --> 00:19:56.540
And that's the Audio Toolbox framework.

00:19:56.590 --> 00:19:59.650
Now the Audio Toolbox
framework lives underneath the

00:19:59.650 --> 00:20:02.720
AV Foundation framework and Media Player.

00:20:02.790 --> 00:20:06.750
And the reason I'm mentioning
Audio Toolbox is because of what's

00:20:06.850 --> 00:20:09.290
called the Audio Session category.

00:20:10.230 --> 00:20:12.100
The audio session category.

00:20:12.220 --> 00:20:12.600
What is it?

00:20:12.600 --> 00:20:17.940
It's an identifier that tells the
system how your application uses audio.

00:20:18.100 --> 00:20:21.960
It tells the system what kind of
behavior your application expects.

00:20:22.030 --> 00:20:28.270
Do you want to receive audio
input or produce audio output?

00:20:28.380 --> 00:20:31.180
Do you want to honor
the ring silence switch?

00:20:31.180 --> 00:20:36.370
And do you want to mix with any other
audio that may be on the system?

00:20:36.900 --> 00:20:40.170
You have to remember that
you're in an audio environment,

00:20:40.170 --> 00:20:41.710
whether you like it or not.

00:20:43.420 --> 00:20:48.580
The user may have been playing some other
audio before they switched to your app,

00:20:48.610 --> 00:20:55.170
and it may be appropriate for your app
to allow that audio to continue playing.

00:20:56.200 --> 00:20:58.760
So there are six audio
session categories.

00:20:58.850 --> 00:21:00.980
And remember,
you set these based on the role

00:21:00.980 --> 00:21:03.970
that audio takes in your app.

00:21:04.230 --> 00:21:06.920
The first one is playback.

00:21:06.950 --> 00:21:10.920
If you're doing audio or video playback,
that's where you should be.

00:21:10.960 --> 00:21:15.360
If you're simply recording,
you want to use the record category.

00:21:15.390 --> 00:21:18.460
Now, if you're doing something where
you're doing a combination

00:21:18.460 --> 00:21:21.960
of playback and record,
for instance, a voice over IP app,

00:21:21.990 --> 00:21:25.250
you'd want to use the
play and record category.

00:21:25.630 --> 00:21:28.450
If you happen to be doing
something just with audio,

00:21:28.550 --> 00:21:34.390
some offline processing of audio,
you'd use the audio processing category.

00:21:34.610 --> 00:21:38.490
And the last two categories,
Ambient and Solo Ambient,

00:21:38.490 --> 00:21:41.940
are mostly for games
and productivity apps.

00:21:42.040 --> 00:21:47.010
Now these are the only two categories,
Ambient and Solo Ambient,

00:21:47.100 --> 00:21:49.140
that honor the Ring Silent Switch.

00:21:49.250 --> 00:21:52.990
And the reason they do so is by
using one of these categories,

00:21:52.990 --> 00:21:56.770
you're telling the system that audio
is not that important to your app

00:21:56.850 --> 00:21:59.620
and it's all right if it be silenced.

00:21:59.720 --> 00:22:04.680
The important takeaway here is you need
to understand the audio session category

00:22:05.160 --> 00:22:08.980
because the default is Solo Ambient.

00:22:09.100 --> 00:22:11.470
And if you're playing movies,
that's probably not the

00:22:11.470 --> 00:22:12.570
right thing for you.

00:22:13.740 --> 00:22:17.740
The next thing I want to mention
is differences in movie containers

00:22:18.220 --> 00:22:22.140
have effects that percolate
all the way up to the API.

00:22:22.370 --> 00:22:25.400
Now, there are really two
different kinds of formats.

00:22:25.500 --> 00:22:29.840
There's HTTP live streams
and other formats.

00:22:29.910 --> 00:22:31.540
Now,
rather than saying something that long,

00:22:31.540 --> 00:22:34.350
I typically talk about HTTP live
streams just as streams

00:22:34.730 --> 00:22:36.500
and other formats as files.

00:22:36.580 --> 00:22:40.660
Now, this is a bit of a misnomer,
but it's good enough for our purposes.

00:22:40.740 --> 00:22:44.180
If you haven't used HTTP live
streaming previously,

00:22:44.260 --> 00:22:48.900
I recommend that you visit our page
dedicated to HTTP live streaming,

00:22:48.980 --> 00:22:55.220
developer.apple.com/resources/http-stream
ing.

00:22:55.290 --> 00:22:58.790
This has pointers to all
of the documentation,

00:22:59.090 --> 00:23:05.040
videos, and sample code,
and the specs related

00:23:05.070 --> 00:23:07.280
to HTTP live streaming.

00:23:07.580 --> 00:23:10.700
Now,
streams and files have a lot in common,

00:23:10.710 --> 00:23:13.500
but there are some differences.

00:23:13.640 --> 00:23:17.280
For instance, streams and files can be
in different locations.

00:23:17.670 --> 00:23:22.190
Streams have to be fetched
with HTTP or HTTPS.

00:23:22.320 --> 00:23:25.310
Files, on the other hand,
can be local on your device

00:23:25.310 --> 00:23:27.210
or fetched over the network.

00:23:27.370 --> 00:23:28.910
There are also differences in features.

00:23:28.970 --> 00:23:34.140
The kinds of tracks and other
aspects of the movie are different

00:23:34.240 --> 00:23:35.740
between streams and files.

00:23:36.920 --> 00:23:39.980
And lastly,
these differences do percolate

00:23:39.980 --> 00:23:43.900
into your code and make
differences in how you code.

00:23:44.150 --> 00:23:48.400
Let's talk about the commonalities
between streams and files.

00:23:48.590 --> 00:23:50.700
First of all, the preferred codecs.

00:23:50.850 --> 00:23:55.520
For video, it's H.264, and for audio,
it's AAC.

00:23:55.640 --> 00:23:58.520
Yes,
there are other codecs that we support,

00:23:58.650 --> 00:24:01.520
but these are the sweet spot,
if you will.

00:24:01.660 --> 00:24:06.160
In your video, you can go up to 720p and
up to 30 frames per second.

00:24:06.260 --> 00:24:10.440
And the audio,
48 kilohertz sample rate and up to

00:24:10.440 --> 00:24:13.750
160 kilobits per second data rate.

00:24:15.330 --> 00:24:20.990
In terms of differences,
with streams you can have timed metadata,

00:24:20.990 --> 00:24:26.260
that is metadata that's associated
with particular moments in your video.

00:24:26.300 --> 00:24:28.760
This doesn't exist in files.

00:24:28.810 --> 00:24:31.580
On the other hand,
with files you can have

00:24:31.620 --> 00:24:35.380
multiple soundtracks,
you can have subtitles,

00:24:35.380 --> 00:24:38.540
in fact multiple subtitles,
and you can have chapter markers.

00:24:38.540 --> 00:24:42.300
These things don't exist
with HTTP live streams.

00:24:42.320 --> 00:24:48.250
Now in both streams and files
you can have closed captioning.

00:24:49.160 --> 00:24:54.980
The next digression I want to talk about
is you need to think asynchronously.

00:24:55.220 --> 00:24:59.710
In video, lots of things are
happening behind your back,

00:24:59.710 --> 00:25:02.130
being done by the system.

00:25:02.810 --> 00:25:05.240
For instance,
when you get to AV Foundation,

00:25:05.240 --> 00:25:07.950
you're going to use something called
asynchronous key value loading,

00:25:08.340 --> 00:25:12.800
where you ask the system to
fetch a value out of your movie.

00:25:12.800 --> 00:25:17.360
You're going to get a reply
asynchronously with the information.

00:25:17.360 --> 00:25:20.050
As I mentioned when I was
talking about notifications,

00:25:20.130 --> 00:25:22.610
if you're generating still
images from your movie,

00:25:22.610 --> 00:25:24.860
that's going to happen asynchronously.

00:25:24.860 --> 00:25:28.070
You're going to get an asynchronous
notification that those still

00:25:28.280 --> 00:25:29.740
images have been created.

00:25:30.180 --> 00:25:32.650
If you're making another
copy of your movie,

00:25:32.650 --> 00:25:37.290
exporting it in some different bit rate,
again, you're going to ask the system

00:25:37.290 --> 00:25:39.860
to do that on your behalf,
and it's going to notify

00:25:39.860 --> 00:25:41.260
you asynchronously.

00:25:41.260 --> 00:25:43.920
And in AV Foundation,
you're going to be using

00:25:43.920 --> 00:25:47.900
key value observing,
which by its very nature is asynchronous.

00:25:49.690 --> 00:25:53.250
The other piece of
asynchrony is multitasking.

00:25:53.580 --> 00:25:57.870
Your app is going to live
with other apps on the system,

00:25:57.870 --> 00:26:02.200
and your app may be pushed into
the background by the user.

00:26:02.670 --> 00:26:08.530
You have to realize that if the user
starts up another app that does playback,

00:26:08.540 --> 00:26:11.090
that's going to interrupt any
export you may have asked the

00:26:11.090 --> 00:26:13.600
system to start on your behalf.

00:26:13.650 --> 00:26:17.160
Even if you're in the foreground,
if you get a phone call,

00:26:17.170 --> 00:26:20.390
that's going to interrupt
any exports you have.

00:26:20.590 --> 00:26:23.600
Remember that when your
app is in the background,

00:26:23.640 --> 00:26:28.260
you're not going to be able to record
or process video from the camera.

00:26:28.320 --> 00:26:30.160
Now, some things won't be interrupted.

00:26:30.340 --> 00:26:32.240
For instance,
if you're using asynchronous

00:26:32.350 --> 00:26:34.700
key value loading,
that's not going to be interrupted

00:26:34.700 --> 00:26:37.260
by multitasking switches.

00:26:37.680 --> 00:26:40.980
Now I mentioned before that
the audio portion of your movie

00:26:40.980 --> 00:26:43.800
can play in the background.

00:26:44.380 --> 00:26:47.430
If you have a movie that's
actually audio only,

00:26:47.430 --> 00:26:51.380
then that will play automatically
when you switch into the background.

00:26:51.450 --> 00:26:56.640
Any other movie that contains some
video will have to be restarted once

00:26:56.640 --> 00:26:58.700
your app switches into the background.

00:26:58.780 --> 00:27:01.780
There's a very good
technical note about this,

00:27:02.280 --> 00:27:05.980
technical note 1668,
which is specifically about how

00:27:05.980 --> 00:27:10.140
to play audio in the background
with MP Movie Player Controller.

00:27:10.680 --> 00:27:13.570
Now let's talk about advanced playback.

00:27:13.780 --> 00:27:16.140
This means we're talking
about AV Foundation.

00:27:16.210 --> 00:27:19.560
Remember,
AV Foundation is a lower level framework.

00:27:19.630 --> 00:27:24.840
In AV Foundation,
your movie is represented by an AV asset.

00:27:24.930 --> 00:27:27.800
So rather than the
case with Media Player,

00:27:27.940 --> 00:27:32.140
where presentation state and everything
was wrapped up with a single object,

00:27:32.210 --> 00:27:36.260
we now have an object that's just
there to represent our movie.

00:27:36.610 --> 00:27:39.790
Because movies consist
of a number of tracks,

00:27:39.790 --> 00:27:45.680
there's also an AVAssetTrack object for
each particular track inside the movie.

00:27:45.750 --> 00:27:49.730
When we want to play back a
movie using AV Foundation,

00:27:49.890 --> 00:27:52.110
we're going to use AVPlayer.

00:27:52.480 --> 00:27:57.360
With the AV Player,
we of course start with an AV Asset,

00:27:57.380 --> 00:27:59.320
which has AV Asset tracks.

00:27:59.440 --> 00:28:02.140
But these don't have any
of the presentation state.

00:28:02.270 --> 00:28:06.780
So we have another object,
the AV Player Item and

00:28:06.990 --> 00:28:11.020
AV Player Item tracks,
which control the presentation

00:28:11.020 --> 00:28:12.550
state for the movie.

00:28:13.070 --> 00:28:17.510
This means that if I want to show
the movie in two different ways,

00:28:17.520 --> 00:28:21.820
I would have two different player items,
one for each way I'm

00:28:21.820 --> 00:28:23.880
presenting the movie.

00:28:23.960 --> 00:28:27.300
Now the AVPlayerItem is what
I give to the AVPlayerObject,

00:28:27.460 --> 00:28:31.980
which is the object that
controls the entire playback.

00:28:32.070 --> 00:28:35.070
That's the object that
you'll be telling to play.

00:28:35.160 --> 00:28:39.380
But once I've given the
AVPlayer item to AVPlayer,

00:28:39.420 --> 00:28:41.810
it's still not on my screen.

00:28:41.850 --> 00:28:47.140
I need to have an AV Player later,
which is a kind of core animation layer,

00:28:47.140 --> 00:28:51.840
which is where AV Player is
actually going to display the movie.

00:28:52.190 --> 00:28:57.540
But I'm still not done because in
order for the user to see that movie,

00:28:57.540 --> 00:29:00.730
it has to be inside my view hierarchy.

00:29:00.850 --> 00:29:04.390
Now, if you look at any of our sample
code around AV Foundation,

00:29:04.410 --> 00:29:10.030
you'll see that we typically
make AV Player layer the layer

00:29:10.380 --> 00:29:13.660
object for a subclass of UIView.

00:29:14.500 --> 00:29:18.480
So there's some important considerations
when you're using AV Foundation.

00:29:18.620 --> 00:29:23.000
The first one is if you're
using HTTP live streaming,

00:29:23.120 --> 00:29:28.240
you can't create an AV asset directly
from an HTTP live stream URL.

00:29:28.380 --> 00:29:31.580
You need to create an
AV player item from that URL,

00:29:31.730 --> 00:29:34.820
and then you can extract
the asset from that.

00:29:35.020 --> 00:29:38.260
If you're familiar with core animation,
don't try to use render in

00:29:38.300 --> 00:29:39.960
context with an AV player layer.

00:29:39.960 --> 00:29:42.170
It's not going to work.

00:29:42.490 --> 00:29:46.720
And AVPlayer can only have
one layer associated with it.

00:29:46.720 --> 00:29:51.100
Yes, you can have your layer tree there,
but remember that only one

00:29:51.100 --> 00:29:53.980
of those layers is actually
associated with the AVPlayer layer.

00:29:55.410 --> 00:29:59.020
So to summarize playback,
I've talked about two simple classes,

00:29:59.020 --> 00:30:02.870
MPMoviePlayerViewController
and MPMoviePlayerController,

00:30:02.870 --> 00:30:05.520
and I've mentioned a few of
the classes in AV Foundation,

00:30:05.520 --> 00:30:12.320
AVPlayer, AVPlayerLayer, AVPlayerItem,
and AVPlayerItemTrack.

00:30:12.780 --> 00:30:15.400
Now let's talk about recording.

00:30:15.550 --> 00:30:18.870
So the Media Player Framework doesn't
have anything to do with recording.

00:30:19.130 --> 00:30:26.140
Instead, UIKit hosts the classes that
are associated with recording.

00:30:26.140 --> 00:30:30.360
And of course, AV Foundation has a number
of classes around recording.

00:30:30.810 --> 00:30:33.650
So when we're recording
from our iOS device,

00:30:33.650 --> 00:30:39.300
say an iPhone, we of course have a
camera and a microphone.

00:30:39.420 --> 00:30:41.300
And remember because
you have a microphone,

00:30:41.300 --> 00:30:44.590
you need to pay attention to your
audio session category and make

00:30:44.630 --> 00:30:47.010
sure you're setting that correctly.

00:30:47.530 --> 00:30:53.640
Now, you can record video with
audio on iOS devices since 3.0.

00:30:53.760 --> 00:30:56.390
And remember that the recording
is under user control.

00:30:56.520 --> 00:31:02.080
You give the user control and you wait
for the user to give you back the result.

00:31:02.250 --> 00:31:07.300
So the basic way to record video
is with UI Image Picker Controller.

00:31:07.420 --> 00:31:09.340
And what you're going to do is
you're going to allocate your

00:31:09.340 --> 00:31:12.080
UI image picker controller object.

00:31:12.120 --> 00:31:14.810
And you're going to tell it that
your source type is a camera.

00:31:15.090 --> 00:31:17.570
If you look at this slide,
you'll see that we are

00:31:17.570 --> 00:31:19.820
specifying the media types.

00:31:19.840 --> 00:31:22.090
We give it an array,
but in this case just a

00:31:22.110 --> 00:31:25.210
single item in that array,
which tells the system

00:31:25.210 --> 00:31:27.300
that we just want a movie.

00:31:27.320 --> 00:31:32.100
You can tell it that you want both
either a movie or a still image.

00:31:32.140 --> 00:31:35.960
We indicate that we want to allow
editing and we tell the system

00:31:36.440 --> 00:31:38.300
what our delicate class is.

00:31:38.340 --> 00:31:41.260
At that point,
all we have to do is tell our

00:31:41.260 --> 00:31:45.660
controller to present this view modally.

00:31:46.320 --> 00:31:48.440
There's two methods that will be called.

00:31:48.560 --> 00:31:53.200
Image picker controller did
finish picking media with info.

00:31:53.420 --> 00:31:56.720
This is what's called when the
user's actually giving you back

00:31:56.760 --> 00:31:58.800
a movie as opposed to canceling.

00:31:58.970 --> 00:32:01.330
The first thing you're going to
do is you're going to look in

00:32:01.400 --> 00:32:05.310
that info dictionary for the media
type and make sure they've given

00:32:05.310 --> 00:32:07.000
you back what you're expecting.

00:32:07.130 --> 00:32:11.870
If you have been given a movie,
you're then going to look in the info

00:32:11.870 --> 00:32:16.980
dictionary for the URL that's associated
with that movie and do whatever it

00:32:16.980 --> 00:32:18.990
is you want to do with the movie.

00:32:19.280 --> 00:32:22.340
Once you've done that,
you dismiss the modal view that

00:32:22.340 --> 00:32:25.000
was there and release the picker.

00:32:25.000 --> 00:32:29.290
Now, if the user cancels,
your method image picker controller

00:32:29.290 --> 00:32:32.000
did cancel is going to be called.

00:32:32.000 --> 00:32:35.460
In this case,
all you need to do is dismiss the modal

00:32:35.460 --> 00:32:38.480
view controller and release the picker.

00:32:38.900 --> 00:32:43.370
Now, AV Foundation has a number of
classes associated with recording.

00:32:43.590 --> 00:32:49.720
AV Capture Session, AV Capture Device,
AV Capture Input, AV Capture Output,

00:32:49.830 --> 00:32:52.490
and AV Capture Connection.

00:32:52.840 --> 00:32:57.700
Let's look at a picture that will give
us a better idea of what's going on here.

00:32:57.940 --> 00:33:02.500
So I have my iPhone and
I want to capture some video.

00:33:02.800 --> 00:33:07.700
I'm going to want to see that on
my display as I'm capturing it.

00:33:07.860 --> 00:33:10.700
And I may want to capture
some still images.

00:33:10.700 --> 00:33:14.700
I may want to look at
the frames as they go by.

00:33:15.010 --> 00:33:19.580
I may want to save the
frames out to a movie file.

00:33:19.590 --> 00:33:23.900
But I'm also going to have some audio,
and I might want to either save

00:33:23.900 --> 00:33:28.460
that audio by itself or save
it as part of my movie file.

00:33:29.230 --> 00:33:32.840
Now the class that ties everything
together is AV Capture Session.

00:33:32.980 --> 00:33:37.080
AV Capture Session controls
the entire recording and

00:33:37.930 --> 00:33:40.750
organizes all the other classes.

00:33:41.120 --> 00:33:43.890
The input devices,
my camera and my microphone,

00:33:43.900 --> 00:33:47.340
are going to have AV Capture Input
subclasses associated with them.

00:33:47.530 --> 00:33:51.330
The view that I'm getting on my
screen is going to have an AV Capture

00:33:51.360 --> 00:33:54.210
Video Preview layer associated with it.

00:33:54.370 --> 00:33:57.250
This is another core animation layer.

00:33:57.780 --> 00:34:03.420
And the various kinds of outputs will
all be subclasses of AV Capture output.

00:34:03.520 --> 00:34:08.620
The important considerations with
recording in AV Foundation are:

00:34:08.740 --> 00:34:13.070
You can only use one of AV Capture
movie file output and AV Capture

00:34:13.120 --> 00:34:15.420
video data output at the same time.

00:34:15.530 --> 00:34:21.140
The system isn't capable of handing you
the video frames in real time and writing

00:34:21.170 --> 00:34:23.300
them out to movie at the same time.

00:34:23.390 --> 00:34:28.630
The other point is documentation
currently states that AV Capture video

00:34:28.630 --> 00:34:31.140
data output can support compressed data.

00:34:31.230 --> 00:34:33.900
This is not the case in iOS 4.3.

00:34:33.900 --> 00:34:36.860
It's still only uncompressed data.

00:34:37.670 --> 00:34:42.230
Okay, to summarize the classes I've
talked about for recording,

00:34:42.280 --> 00:34:45.900
UI Image Picker Controller is your
main class for basic recording.

00:34:46.020 --> 00:34:48.210
And of course you have a
delegate associated with that,

00:34:48.400 --> 00:34:51.210
your UI Image Picker Controller delegate.

00:34:51.510 --> 00:34:53.580
Now there are several
classes in AV Foundation.

00:34:53.610 --> 00:34:58.450
I mentioned just a few of them:
AV Capture Session, AV Capture Device,

00:34:58.620 --> 00:35:04.600
AV Capture Input, AV Capture Output,
and AV Capture Connection.

00:35:04.720 --> 00:35:06.980
Now let's talk about editing.

00:35:07.380 --> 00:35:12.930
So again with editing, the classes are in
UIKit and in AV Foundation.

00:35:13.310 --> 00:35:17.170
For basic editing, what we're really only
doing is trimming the movie.

00:35:17.280 --> 00:35:18.960
That is,
we're trimming portions from either

00:35:18.960 --> 00:35:22.600
the beginning or end of the movie.

00:35:23.350 --> 00:35:26.510
What this does is it allows
the user to trim those frames.

00:35:26.660 --> 00:35:31.000
Your program isn't making any
decision about where that cut happens.

00:35:31.160 --> 00:35:34.940
Now, this same class also allows
you to re-encode your video

00:35:34.940 --> 00:35:36.000
at another quality level.

00:35:36.210 --> 00:35:39.620
You need to look for UI Image Picker
Controller Quality Type.

00:35:39.690 --> 00:35:41.340
That's how you control that.

00:35:41.430 --> 00:35:45.660
The two classes here are
UI Video Editor Controller and the

00:35:45.660 --> 00:35:48.820
UI Video Editor Controller Delegate.

00:35:48.870 --> 00:35:52.280
I'm not going to talk about the interface
here in detail because it's very,

00:35:52.280 --> 00:35:56.060
very similar to the
UI Image Picker Controller.

00:35:56.150 --> 00:36:01.780
Now, you can also do editing as part of
your UI Image Picker Controller.

00:36:01.900 --> 00:36:06.460
There's a property on the UI Image Picker
Controller allows editing.

00:36:06.460 --> 00:36:10.580
Set that to true and the user
will be able to do trims.

00:36:11.010 --> 00:36:14.050
The interface is very
simple for the user.

00:36:14.110 --> 00:36:17.650
A couple of controls that
allow them to move where the

00:36:17.840 --> 00:36:20.620
beginning trim and end trim is.

00:36:20.740 --> 00:36:23.950
And a button to either accept or cancel.

00:36:24.310 --> 00:36:29.510
Now, AV Foundation has quite a
few classes used for editing.

00:36:29.590 --> 00:36:32.580
I'm going to mention each
of these very briefly.

00:36:32.920 --> 00:36:35.550
So if I want to generate
still images from my movie,

00:36:35.630 --> 00:36:39.420
I'm going to use AVAssetImageGenerator.

00:36:39.550 --> 00:36:44.390
If I want to re-encode my movie
or export a version in a different

00:36:45.010 --> 00:36:50.200
aspect ratio or something,
I'm going to use AVAssetExportSession.

00:36:50.470 --> 00:36:54.970
If I simply want to read frames
from an existing movie file,

00:36:54.970 --> 00:36:57.000
I'll use AVAssetReader.

00:36:57.040 --> 00:37:02.300
If I want to create a new movie file,
I'll use AVAssetWriter.

00:37:02.590 --> 00:37:07.400
Now, while I'm outputting my movie,
if I want to change the sound level,

00:37:07.400 --> 00:37:10.370
so I'm going to use AV Audio Mix,

00:37:10.830 --> 00:37:14.380
If I wanted to do
straight cuts in my movie,

00:37:14.380 --> 00:37:20.040
no transitions or fades or wipes,
then I'm going to use AV Composition.

00:37:20.040 --> 00:37:23.810
It allows me to do
simple cuts-only editing.

00:37:24.280 --> 00:37:28.800
I'll use AV Video Composition if I do
want to have some sort of transition,

00:37:28.800 --> 00:37:29.650
a fade or a wipe.

00:37:29.910 --> 00:37:36.670
Now, I can also include core animations
in with my movie in AV Foundation.

00:37:36.790 --> 00:37:42.040
Core animation can be used to
generate titles or other images.

00:37:42.140 --> 00:37:46.350
And when I do that, I need to use another
core animation subclass,

00:37:46.510 --> 00:37:48.000
AV Synchronized Layer.

00:37:48.130 --> 00:37:52.600
And further, when I'm exporting a movie
that's used core animation,

00:37:52.690 --> 00:37:57.600
I need to use the AV Video Composition
Core Animation tool.

00:37:57.780 --> 00:38:03.130
The important consideration when editing
with AV Foundation is that AV Asset

00:38:03.130 --> 00:38:06.090
Reader is not a real-time class.

00:38:06.260 --> 00:38:10.800
Don't expect to be able to read frames
from a movie and deliver them to the

00:38:10.800 --> 00:38:13.890
user in real-time using this class.

00:38:14.120 --> 00:38:19.480
The other consideration is AV Composition
and AV Video Composition are meant for

00:38:19.480 --> 00:38:22.530
two very different sorts of situations.

00:38:22.740 --> 00:38:27.620
AV Composition is when you're
doing simple cuts only editing.

00:38:27.710 --> 00:38:32.190
AV Video Composition is when you
want to make some sort of transition.

00:38:32.460 --> 00:38:34.620
Okay, now I'd like to wrap up.

00:38:34.930 --> 00:38:39.780
If you want more depth on AV Foundation,
you should listen to the talks

00:38:39.900 --> 00:38:44.000
that we gave at WWDC 2010.

00:38:44.090 --> 00:38:49.200
They're excellent talks on
AV Foundation and specifically

00:38:49.330 --> 00:38:51.800
on recording and editing.

00:38:51.890 --> 00:38:53.500
So there you have it.

00:38:53.580 --> 00:38:58.090
I'm Eryk Vershen and my email
address is evershen@apple.com.

00:38:58.180 --> 00:39:03.690
I look forward to seeing your app
really taking advantage of video in iOS.