WEBVTT

00:00:20.970 --> 00:00:23.140
Hello, I'm Allan Schaffe,
the graphics and media

00:00:23.230 --> 00:00:24.880
technology evangelist at Apple.

00:00:25.070 --> 00:00:29.170
This presentation is Part 2 of
Mastering OpenGL ES for iPhone.

00:00:29.310 --> 00:00:32.340
In Part 1, focused on the environment
around OpenGL ES,

00:00:32.440 --> 00:00:35.230
covering versions, the display system,
the rendering loop,

00:00:35.300 --> 00:00:37.320
and the processor architecture.

00:00:37.520 --> 00:00:41.270
And Part 2 goes deep into
mastering OpenGL ES itself.

00:00:41.320 --> 00:00:45.500
I explain the architecture and the
capabilities of the graphics processors,

00:00:45.680 --> 00:00:49.220
and then dive deep into specific
performance recommendations for

00:00:49.260 --> 00:00:51.120
optimizing texture and geometry.

00:00:51.160 --> 00:00:51.990
So, welcome back.

00:00:52.310 --> 00:00:53.570
Let's continue.

00:00:55.740 --> 00:00:59.330
So I begin this presentation with
a deep look into the capabilities

00:00:59.360 --> 00:01:03.080
of the graphics processors and the
specific differences between the

00:01:03.190 --> 00:01:07.410
PowerVR MBX Lite and the PowerVR SGX.

00:01:07.660 --> 00:01:11.500
And as I do this, you should keep in mind
this chart from Part 1,

00:01:11.500 --> 00:01:15.510
outlining the platforms where
each of those GPUs are supported.

00:01:15.650 --> 00:01:21.070
The PowerVR SGX is used in the iPhone
3GS and the third generation iPod touch,

00:01:21.070 --> 00:01:24.360
and the PowerVR MBX Lite is
used in the iPhone,

00:01:24.560 --> 00:01:28.650
the iPhone 3G, and the first and second
generation iPod touch.

00:01:28.750 --> 00:01:33.000
So, let's start with the
details of the MBX Lite.

00:01:34.160 --> 00:01:38.330
Now, as I said in Part 1,
the MBX Lite supports the fixed function

00:01:38.340 --> 00:01:41.240
rendering pipeline of OpenGL ES 1.1.

00:01:41.280 --> 00:01:46.090
And its architecture is what's known
as a tile-based deferred renderer.

00:01:46.170 --> 00:01:47.930
And I'll describe this in just a moment.

00:01:47.980 --> 00:01:51.970
Now, the same devices that support
the MBX Lite are also very

00:01:52.340 --> 00:01:54.770
sensitive to memory bandwidth.

00:01:54.780 --> 00:01:58.130
And you'll notice that a lot of the
optimization strategies that I talk

00:01:58.130 --> 00:02:02.060
about later in the presentation have
to do with reducing the pressure on

00:02:02.060 --> 00:02:04.110
memory bandwidth for this reason.

00:02:05.710 --> 00:02:08.710
There's a number of implementation
limits on the MBX Lite,

00:02:08.710 --> 00:02:12.390
but one that deserves special
mention is the 24 megabyte limit

00:02:12.690 --> 00:02:14.020
on textures and render buffers.

00:02:14.020 --> 00:02:18.200
This isn't an on-board limit per se,
but rather is reflecting the

00:02:18.300 --> 00:02:21.920
fact that the MBX Lite can
only address a contiguous 24

00:02:22.020 --> 00:02:24.370
megabytes region in system RAM.

00:02:24.380 --> 00:02:28.250
So we always load the textures
and surfaces into that region.

00:02:28.260 --> 00:02:31.240
And again, here's another reminder
about the platforms.

00:02:34.670 --> 00:02:39.670
Now, in addition to supporting the core
functionality of OpenGL ES 1.1,

00:02:39.670 --> 00:02:43.000
the MBX Lite also supports
a number of extensions,

00:02:43.000 --> 00:02:44.220
and I've listed them here.

00:02:44.220 --> 00:02:47.270
And you can see there's
a number of multi-vendor

00:02:47.270 --> 00:02:49.310
extensions with the prefix EXT.

00:02:49.940 --> 00:02:52.770
There's a few extensions from
Imagination Technologies,

00:02:52.830 --> 00:02:57.460
those are the ones with the IMG prefix,
and a large number of standard

00:02:57.570 --> 00:03:00.130
extensions with the OES prefix.

00:03:00.350 --> 00:03:04.900
Here I've highlighted a few
particular extensions of interest.

00:03:05.040 --> 00:03:08.830
The extension for PVRTC,
texture compression,

00:03:08.830 --> 00:03:12.620
is very important and a great way
to reduce memory bandwidth usage,

00:03:12.740 --> 00:03:16.230
since the texture actually
remains compressed even after

00:03:16.230 --> 00:03:18.360
it's loaded into system memory.

00:03:18.440 --> 00:03:23.400
I'll talk a lot more about PVRTC when
we get to the texture section.

00:03:23.800 --> 00:03:29.280
BGRA 8888 happens to be a native
32-bit texture format for the device.

00:03:29.280 --> 00:03:33.000
This avoids a byte swizzle,
so it's a bit faster to load.

00:03:33.000 --> 00:03:35.240
And framebuffer objects.

00:03:35.330 --> 00:03:38.090
As I mentioned in Part 1,
framebuffer objects are

00:03:38.140 --> 00:03:41.690
absolutely fundamental to how we
do all rendering on the iPhone.

00:03:41.700 --> 00:03:44.660
All of your rendering gets
directed to the color render buffer

00:03:44.660 --> 00:03:47.710
attachment of a framebuffer object,
and this is picked up by

00:03:47.820 --> 00:03:50.710
your CA Eagle layer and the
rest of the display system.

00:03:51.240 --> 00:03:55.410
Or you can have a texture attachment
to your framebuffer object and

00:03:55.580 --> 00:03:59.740
perform a render to texture,
and then use that texture in another pass

00:03:59.740 --> 00:04:02.540
that's bound to the color render buffer.

00:04:02.810 --> 00:04:05.130
But in any case,
anytime you're using these

00:04:05.130 --> 00:04:08.230
extensions or the ones coming
up in the next few slides,

00:04:08.250 --> 00:04:12.990
you should code defensively and
always query for the presence of the

00:04:13.030 --> 00:04:16.980
extension and provide some fallback or
error case in case it's not present.

00:04:20.110 --> 00:04:24.470
Next, here are some of the standard
implementation limits for the MBX Lite.

00:04:24.480 --> 00:04:29.020
The maximum texture size is 1K by 1K,
and as I'd mentioned,

00:04:29.020 --> 00:04:31.760
there's a 24MB limit for
textures and surfaces.

00:04:31.760 --> 00:04:34.900
On the MBX,
your texture dimensions must be a

00:04:34.900 --> 00:04:39.430
power of 2 for both width and height,
and you have two texture units

00:04:39.470 --> 00:04:41.520
available for multi-texturing.

00:04:41.520 --> 00:04:44.660
Then,
getting into the more detailed limits,

00:04:44.660 --> 00:04:48.000
your point size can be
from 1 to 64 pixels,

00:04:48.520 --> 00:04:52.760
your line width can be up to 64 pixels,
and your maximum LOD bias.

00:04:52.760 --> 00:04:56.870
This is if you're generating texture
mipmaps and want to artificially

00:04:56.870 --> 00:05:00.860
bias which mipmap level is chosen,
your maximum bias value is 2.

00:05:01.000 --> 00:05:04.770
And the matrix palette extension
supports up to 9 palette

00:05:04.910 --> 00:05:06.820
indices and 3 vertex units.

00:05:06.920 --> 00:05:09.210
And finally, there's one user clip plane.

00:05:09.320 --> 00:05:13.410
So, that's the MBX Lite,
the general capabilities,

00:05:13.660 --> 00:05:16.880
the extensions available,
and the limits that are enforced.

00:05:16.880 --> 00:05:20.980
Now,
let's contrast that with the PowerVR SGX.

00:05:21.870 --> 00:05:25.830
So the SGX is also a
tile-based deferred renderer.

00:05:25.830 --> 00:05:28.430
And as I said in Part 1,
it supports both the fixed

00:05:28.430 --> 00:05:33.290
function pipeline of OpenGL ES 1.1
and the programmable shading

00:05:33.290 --> 00:05:35.580
pipeline of OpenGL ES 2.0.

00:05:35.840 --> 00:05:39.840
The 2.0 pipeline is what's
supported natively by the hardware.

00:05:39.840 --> 00:05:43.250
And actually,
we express the 1.1 pipeline in hardware

00:05:43.250 --> 00:05:45.750
through some specially written shaders.

00:05:47.290 --> 00:05:49.470
Now,
the devices with the PowerVR SGX have

00:05:49.670 --> 00:05:52.680
higher memory bandwidth,
so they'll be less sensitive to some

00:05:52.680 --> 00:05:55.890
of the memory bandwidth concerns
that I'll be discussing later.

00:05:55.920 --> 00:05:58.480
And also,
these devices have no particular

00:05:58.480 --> 00:06:00.810
limit on texture and surface memory.

00:06:00.820 --> 00:06:04.240
But the next three capabilities
are very important.

00:06:04.240 --> 00:06:08.390
First is vertex buffer object
acceleration in hardware.

00:06:08.420 --> 00:06:13.580
Now, both the MBX and SGX support
vertex buffer objects.

00:06:13.580 --> 00:06:16.420
But on the SGX,
you should see a significant difference.

00:06:16.490 --> 00:06:18.710
And there's a significant
performance benefit from using

00:06:18.760 --> 00:06:20.220
them due to the hardware support.

00:06:20.560 --> 00:06:24.720
There's also hardware support for
stencil with an 8-bit stencil buffer.

00:06:24.830 --> 00:06:28.250
And textures on the SGX can
have any arbitrary dimensions

00:06:28.250 --> 00:06:30.380
up to the maximum texture size.

00:06:30.380 --> 00:06:32.380
They don't have to be a power of two.

00:06:32.450 --> 00:06:35.980
And just remember,
the SGX is the graphics processor

00:06:35.980 --> 00:06:40.380
used in the iPhone 3GS and the
third-generation iPod Touch.

00:06:41.850 --> 00:06:45.660
Now, when your OpenGL ES 1.1
application happens to be

00:06:45.660 --> 00:06:50.020
running on a device with ESGX,
a number of new extensions appear.

00:06:50.020 --> 00:06:51.370
I've highlighted them here.

00:06:51.380 --> 00:06:55.720
There are several new extensions dealing
with blending and the blend equation.

00:06:55.720 --> 00:06:59.880
You now have the ability to bind
MIPMAP levels to a framebuffer

00:06:59.880 --> 00:07:03.660
object and do a render to
texture directly to a MIPMAP.

00:07:03.720 --> 00:07:07.710
There's support for the stencil buffer,
either separate or interleaved

00:07:07.720 --> 00:07:09.140
with the depth buffer.

00:07:09.680 --> 00:07:13.440
And our extension for limited
non-power-of-two texture dimensions.

00:07:14.910 --> 00:07:19.340
So, let me emphasize,
these are new extensions or added

00:07:19.340 --> 00:07:24.740
features that your existing OpenGL ES 1.1
application can take advantage of.

00:07:25.240 --> 00:07:28.680
Anytime one of your users happens
to be using an iPhone 3GS or

00:07:28.680 --> 00:07:30.820
third generation iPod touch.

00:07:30.820 --> 00:07:34.920
If your application could take
advantage of non-Power of 2 textures,

00:07:34.920 --> 00:07:38.690
for example, they're just there now and
you can just make use of them.

00:07:39.490 --> 00:07:42.400
Just make sure that you always query
for the presence of any extensions

00:07:42.430 --> 00:07:45.820
you're using and conditionally
handle the case where you're

00:07:45.820 --> 00:07:47.720
running on a device with the SGX.

00:07:50.340 --> 00:07:53.740
Now here are the implementation
limits you'll see when running an

00:07:53.780 --> 00:07:57.140
OpenGL ES 1.1 application on the SGX.

00:07:57.310 --> 00:08:01.120
The maximum texture size
is now up to 2K by 2K,

00:08:01.270 --> 00:08:04.720
and that 24 megabyte limit for
textures and surfaces is gone.

00:08:04.740 --> 00:08:08.120
There's no set limit for
textures and surfaces.

00:08:08.290 --> 00:08:12.560
Your texture dimensions can be any
arbitrary value up to the maximum size,

00:08:12.720 --> 00:08:16.500
so either non-power of 2 or power of 2.

00:08:16.690 --> 00:08:20.470
And now you have eight texture
units available for multi-texturing.

00:08:20.480 --> 00:08:22.900
Then again, the more detailed limits.

00:08:22.920 --> 00:08:25.560
Your point size can now
go up to 511 pixels.

00:08:25.560 --> 00:08:28.180
Your line width is now up to 16 pixels.

00:08:28.180 --> 00:08:31.540
Your maximum LOD bias is 4 instead of 2.

00:08:31.540 --> 00:08:35.640
And the matrix palette extension
supports up to 11 palette

00:08:35.650 --> 00:08:37.760
indices and 4 vertex units.

00:08:37.840 --> 00:08:40.780
And you have up to 6 user clip planes.

00:08:41.950 --> 00:08:44.610
Okay,
so that's the SGX with an application

00:08:44.950 --> 00:08:47.820
that's created an OpenGL ES 1.1 context.

00:08:47.940 --> 00:08:51.840
Next, let's take a look at what
happens with a 2.0 context.

00:08:54.500 --> 00:08:55.990
First, here's the extensions.

00:08:55.990 --> 00:08:59.100
Now, these are, of course,
extensions on top of the

00:08:59.240 --> 00:09:02.320
OpenGL ES 2.0 baseline specification.

00:09:02.320 --> 00:09:05.760
And there is a tremendous
amount of new functionality

00:09:05.760 --> 00:09:08.160
in the core of OpenGL ES 2.0.

00:09:08.640 --> 00:09:13.210
Things like programmable shaders or frame
buffer objects are now part of the core.

00:09:13.220 --> 00:09:17.660
And this is a list of extensions that
are provided in addition to that.

00:09:17.830 --> 00:09:19.810
So most of these we've already seen.

00:09:19.880 --> 00:09:24.560
Render to MIP maps,
pack depth and stencil, PVRTC, and so on.

00:09:24.600 --> 00:09:27.220
But the one that's new
is standard derivatives.

00:09:27.220 --> 00:09:28.980
This is a shader extension.

00:09:28.980 --> 00:09:32.360
It provides DXDY and
FWITH functions in your shaders.

00:09:34.350 --> 00:09:37.660
And here are the limits that
apply when you're using a 2.0

00:09:37.660 --> 00:09:39.290
context and programmable shaders.

00:09:39.300 --> 00:09:43.080
As before,
your maximum texture size is 2K by 2K,

00:09:43.080 --> 00:09:47.040
and you can sample from a maximum of
eight textures in your fragment shaders.

00:09:47.040 --> 00:09:51.640
You can have up to 16 vertex attributes,
eight varyings,

00:09:51.640 --> 00:09:57.080
128 uniforms in vertex shaders,
and 64 uniforms in fragment shaders.

00:09:57.080 --> 00:10:00.580
And then point size and line width
ranges are the same as before.

00:10:03.660 --> 00:10:06.700
Next thing I'd like to do is to
briefly describe the tile-based

00:10:06.700 --> 00:10:08.450
deferred renderer architecture.

00:10:08.460 --> 00:10:11.920
Both the MBX and SGX have
this architecture,

00:10:11.930 --> 00:10:15.360
and it's different than what you
may be accustomed to if you came

00:10:15.360 --> 00:10:18.570
to OpenGL ES from the desktop,
where you typically

00:10:18.570 --> 00:10:19.970
have a stream renderer.

00:10:19.980 --> 00:10:24.400
The basic way a tile-based renderer
works is to spatially divide your

00:10:24.400 --> 00:10:28.290
screen into a number of tiles,
and as OpenGL commands arrive,

00:10:28.370 --> 00:10:31.760
they'll be distributed to the
appropriate tile on screen.

00:10:32.650 --> 00:10:35.850
Each tile will be building up
and buffering a list of commands

00:10:35.850 --> 00:10:37.370
to be drawn within itself.

00:10:37.540 --> 00:10:40.450
And then when we're done
at the end of the frame,

00:10:40.720 --> 00:10:44.730
each tile will perform what amounts
to a hidden surface removal pass

00:10:44.950 --> 00:10:46.580
over the commands in its buffer.

00:10:46.590 --> 00:10:50.410
And it will only rasterize the
geometry that's actually visible.

00:10:50.500 --> 00:10:52.400
So you get a huge benefit.

00:10:52.530 --> 00:10:56.820
This architecture just tremendously
reduces the depth complexity in your

00:10:56.820 --> 00:10:59.010
scene in a typical 3D rendering.

00:10:59.060 --> 00:11:02.430
And reducing the depth
complexity lightens the fragment

00:11:02.430 --> 00:11:05.500
processing burden quite a lot,
which would otherwise be

00:11:05.500 --> 00:11:06.840
a significant bottleneck.

00:11:09.460 --> 00:11:11.390
But of course,
this is a different architecture,

00:11:11.400 --> 00:11:13.850
different than what's been
broadly used in desktop hardware.

00:11:13.860 --> 00:11:17.190
So many of the desktop assumptions
about what's fast or slow may

00:11:17.230 --> 00:11:19.130
have changed in some instances.

00:11:19.140 --> 00:11:22.230
In particular,
on a tile-based architecture,

00:11:22.230 --> 00:11:25.120
it's relatively expensive
to change your scissoring,

00:11:25.120 --> 00:11:29.240
viewport, or dither state mid-frame,
as those can lead to changes in the tile

00:11:29.240 --> 00:11:31.300
layout that would have to be managed.

00:11:31.360 --> 00:11:35.870
Likewise, binding a different frame
buffer attachment mid-frame,

00:11:35.870 --> 00:11:39.890
or calling GL read pixels,
introduces a synchronization

00:11:39.890 --> 00:11:42.550
point between the CPU and
the graphics processor,

00:11:42.560 --> 00:11:46.980
and this lessens the very deep pipelining
that would be achievable otherwise.

00:11:48.600 --> 00:11:52.060
And finally,
calls like GL Text Subimage to subload a

00:11:52.060 --> 00:11:54.800
texture or update a portion of a texture.

00:11:54.800 --> 00:11:58.730
These can have unintended
consequences in a deferred renderer.

00:11:58.830 --> 00:12:02.520
We may actually need to keep a
copy of the texture as it existed

00:12:02.520 --> 00:12:06.260
before the change and also make
a second copy with your changes,

00:12:06.260 --> 00:12:09.570
since we won't actually start
rasterizing those pixels and

00:12:09.570 --> 00:12:13.770
sampling from the textures until
the entire frame has been submitted.

00:12:14.660 --> 00:12:18.070
So if you're doing any of these things,
they actually need to be very

00:12:18.070 --> 00:12:22.570
carefully scheduled as to where in the
timeline of submitting commands for

00:12:22.570 --> 00:12:24.180
a new frame you'll put these calls.

00:12:24.280 --> 00:12:26.520
And I'll show you how to
do this in just a moment,

00:12:26.530 --> 00:12:28.380
but there's one other topic first.

00:12:29.850 --> 00:12:34.520
I just want to make one more point about
the hidden surface removal calculation.

00:12:34.700 --> 00:12:38.040
The thing to understand is
that on a per pixel basis,

00:12:38.180 --> 00:12:43.380
that calculation is only effective for as
long as we're drawing something opaque.

00:12:43.500 --> 00:12:47.320
As soon as we draw a non-opaque object,
an alpha blended object,

00:12:47.460 --> 00:12:51.610
that invalidates the pixel and everything
that follows for that pixel isn't going

00:12:51.610 --> 00:12:56.280
to be able to take advantage of the
hidden surface removal calculations.

00:12:56.510 --> 00:12:59.580
So that means you should draw
all of your opaque objects first

00:12:59.640 --> 00:13:02.770
so that all of them can take
advantage of HIN surface removal.

00:13:02.780 --> 00:13:05.660
And you should draw all your
alpha blended objects last,

00:13:05.660 --> 00:13:07.470
sorting those from back to front.

00:13:07.690 --> 00:13:10.130
Now,
there's actually one other category to

00:13:10.130 --> 00:13:14.380
draw in between these other two groups,
and that's any geometry that's

00:13:14.380 --> 00:13:18.210
drawn along with a shader that's
using the discard command to throw

00:13:18.260 --> 00:13:19.740
away fragments conditionally.

00:13:19.740 --> 00:13:23.510
So when it does come time in your
frame for submitting geometry,

00:13:23.650 --> 00:13:26.380
you should draw all your
opaque objects first.

00:13:26.430 --> 00:13:27.770
Sorted by state, of course.

00:13:27.800 --> 00:13:31.350
And then any objects using discard,
also sorted by state.

00:13:31.550 --> 00:13:34.860
And finally, any alpha blended objects
sorted back to front.

00:13:35.100 --> 00:13:38.270
And this can sound
counterintuitive to beginners.

00:13:38.280 --> 00:13:41.360
You would think that if you were, say,
drawing a bunch of cars,

00:13:41.360 --> 00:13:43.600
you'd prefer to draw
all of the first car,

00:13:43.600 --> 00:13:46.360
and then all the next car,
all the third car, and so on.

00:13:46.460 --> 00:13:48.040
But that's not optimal.

00:13:48.040 --> 00:13:51.860
Once you've calculated which
cars are actually on screen,

00:13:51.860 --> 00:13:56.850
what's optimal is to draw all the opaque
parts of all the visible cars first,

00:13:57.170 --> 00:13:57.930
sorted by state.

00:13:58.080 --> 00:14:01.370
So the wheels of all the cars,
the bodies of all the cars, and so on.

00:14:01.380 --> 00:14:04.840
And then to draw all the
alpha blended parts last,

00:14:04.920 --> 00:14:05.870
sorted back to front.

00:14:05.930 --> 00:14:08.960
So the windows of the car that's
furthest away from the eye point,

00:14:08.960 --> 00:14:12.800
and the windows of the next closest car,
and the next closest, and so on.

00:14:14.820 --> 00:14:17.580
So in terms of the frame
architecture that we'd suggest,

00:14:17.720 --> 00:14:19.000
it would look something like this.

00:14:19.000 --> 00:14:21.870
Imagine if you were doing all
the things I just mentioned,

00:14:21.880 --> 00:14:24.090
the good ones and the
ones to be careful about.

00:14:24.120 --> 00:14:27.710
This will show you where in the sequence
of commands you should put those calls.

00:14:27.780 --> 00:14:32.340
If you're calling GL text subimage
to update a subregion of a texture,

00:14:32.340 --> 00:14:35.850
then the best place to call that
would be before you've submitted any

00:14:35.850 --> 00:14:38.120
commands actually using that texture.

00:14:38.120 --> 00:14:41.550
This allows us to avoid making
a copy since you actually

00:14:41.550 --> 00:14:43.650
haven't used that texture yet.

00:14:45.000 --> 00:14:48.450
If you're binding a framebuffer object,
then this is a sync point,

00:14:48.480 --> 00:14:51.460
and you generally want to put any
sync points at the very beginning

00:14:51.730 --> 00:14:54.150
or very end of your frame,
since those are natural

00:14:54.190 --> 00:14:56.720
sync points anyways,
and it will minimize any impact

00:14:56.720 --> 00:14:58.210
on the command pipelining.

00:14:58.240 --> 00:15:01.530
You can then draw all your
objects as I've just explained,

00:15:01.530 --> 00:15:04.970
opaque first, then discard,
then alpha blended last.

00:15:04.980 --> 00:15:07.440
And at that point,
you'll have presumably made the

00:15:07.440 --> 00:15:09.320
last drawing command in this frame.

00:15:09.700 --> 00:15:11.620
So now we're at the
very end of the frame,

00:15:11.620 --> 00:15:15.770
and only then it might be okay to
issue a command like GL read pixels,

00:15:15.780 --> 00:15:19.540
since this will introduce a sync
point and cause all the tiles to

00:15:19.600 --> 00:15:21.760
execute their command buffers.

00:15:21.760 --> 00:15:25.280
But so would have present render buffers,
so in this case, it's okay.

00:15:27.260 --> 00:15:29.830
Now, one more platform to mention
is the iPhone Simulator.

00:15:29.850 --> 00:15:33.900
In terms of its feature set,
it's very similar to an iPhone 3GS.

00:15:33.990 --> 00:15:38.240
It supports both OpenGL ES 1.1
and 2.0-based applications.

00:15:38.240 --> 00:15:41.510
But it's also very different
because it's running on your Mac.

00:15:41.510 --> 00:15:44.960
It does not have a tile-based
deferred renderer architecture.

00:15:44.960 --> 00:15:49.840
It does not enforce the memory
limitations you find on an actual device.

00:15:50.260 --> 00:15:53.080
It does not actually try to
achieve pixel-for-pixel parity

00:15:53.210 --> 00:15:54.890
with what you see on the device.

00:15:54.890 --> 00:15:56.730
And obviously,
it doesn't fit in your pocket.

00:15:56.740 --> 00:15:59.450
But it's really a great
tool for debugging,

00:15:59.450 --> 00:16:02.830
and not just in the obvious
way that you might expect.

00:16:02.990 --> 00:16:07.070
Rather, it's wonderful for comparative
debugging and trying to isolate

00:16:07.070 --> 00:16:08.530
the source of a problem.

00:16:08.580 --> 00:16:12.090
So imagine you have a texture that's
always showing up white on the device

00:16:12.090 --> 00:16:13.880
when it should contain an image.

00:16:13.880 --> 00:16:17.610
Well, you can try your app in the
simulator and compare the results.

00:16:18.280 --> 00:16:21.320
If that texture still shows
up white in the simulator,

00:16:21.330 --> 00:16:24.570
then you know that the problem is
probably in your code and related to

00:16:24.570 --> 00:16:26.560
the way that you're using OpenGL ES.

00:16:26.820 --> 00:16:30.050
But if the result is different,
even this is interesting.

00:16:30.050 --> 00:16:33.520
It's not a case where you should
jump to conclusions and assume

00:16:33.520 --> 00:16:35.130
you found a bug in OpenGL.

00:16:35.160 --> 00:16:37.750
Instead,
this can be frequently a telltale

00:16:37.750 --> 00:16:41.740
sign that you've tried to set a mode
that isn't supported or exceeded

00:16:41.740 --> 00:16:45.250
a limit of the implementation
for that specific device.

00:16:46.340 --> 00:16:49.630
So using the simulator for these
sorts of clues can really help you.

00:16:49.720 --> 00:16:52.230
We all make these kinds of mistakes,
but the simulator can be

00:16:52.230 --> 00:16:53.730
really helpful in finding them.

00:16:56.210 --> 00:16:58.490
Now,
in terms of the specific capabilities,

00:16:58.600 --> 00:17:02.500
the simulator supports the complete
OpenGL ES 1.1 implementation.

00:17:02.630 --> 00:17:06.580
And as for the extensions,
the only ones not supported that

00:17:06.580 --> 00:17:11.330
was on the list for SGX is the
Pack Depth Stencil extension.

00:17:11.530 --> 00:17:14.060
And then likewise,
it also provides a full implementation

00:17:14.140 --> 00:17:17.580
of the OpenGL ES 2.0 pipeline,
but emits two of the

00:17:17.690 --> 00:17:20.500
extensions we saw on the SGX,
packed up stencil again

00:17:20.500 --> 00:17:22.020
and standard derivatives.

00:17:22.020 --> 00:17:25.630
So to summarize, again,
to master OpenGL ES,

00:17:25.690 --> 00:17:29.470
you really need to code
your app defensively.

00:17:29.480 --> 00:17:33.400
Rather than reading the device name
and making assumptions based on that,

00:17:33.400 --> 00:17:37.790
you should check the list of extensions
directly for any that you need to use.

00:17:38.620 --> 00:17:42.410
And query the limits of the device
that you happen to be running on.

00:17:42.480 --> 00:17:47.560
And then have code in your app that takes
advantage of the expanded capabilities of

00:17:47.560 --> 00:17:52.320
the SGX when it finds them and provides
a fallback when it doesn't for the MBX.

00:17:55.140 --> 00:17:59.550
Now, we're going to change gears and go
very deep into optimizing texture.

00:17:59.610 --> 00:18:01.050
And there's six topics to cover.

00:18:01.050 --> 00:18:03.910
The recommended formats,
the details about

00:18:03.920 --> 00:18:07.760
non-power-of-two textures,
and I'll talk about compression, atlases,

00:18:07.760 --> 00:18:10.280
mipmaps,
and then have a number of specific best

00:18:10.280 --> 00:18:12.380
practices that you'll need to adopt.

00:18:14.100 --> 00:18:17.320
So, I'll start with texture formats,
and this is pretty simple.

00:18:17.460 --> 00:18:22.100
There's a variety of texture formats
supported across both the MBX and SGX,

00:18:22.160 --> 00:18:23.940
and they're listed here on the right.

00:18:24.060 --> 00:18:27.720
There's a few 32-bit formats,
several 16-bit formats,

00:18:27.720 --> 00:18:30.680
a couple 8-bit formats,
and then the compressed

00:18:30.790 --> 00:18:32.620
formats for PBRTC.

00:18:32.820 --> 00:18:36.240
Now, I should clarify that when
we're discussing formats,

00:18:36.370 --> 00:18:40.290
we're talking about the actual formatting
of the image in system memory and

00:18:40.720 --> 00:18:44.160
not image file formats like TIFF,
JPEG, or PNG.

00:18:44.160 --> 00:18:48.120
All those file formats end up
with the image itself just being

00:18:48.120 --> 00:18:52.500
expanded in memory out to its
full native depth and resolution.

00:18:53.890 --> 00:18:56.950
We really recommend
using PVRTC if you can.

00:18:57.120 --> 00:19:01.490
So again, particularly systems with the
MBX Lite are more sensitive

00:19:01.490 --> 00:19:05.160
to memory bandwidth pressure,
and PVRTC is the only format

00:19:05.160 --> 00:19:09.590
that's able to remain compressed
even when it's in memory.

00:19:09.710 --> 00:19:14.560
The graphics processor is able to decode
it directly from its compressed format.

00:19:14.660 --> 00:19:17.410
And I'll cover this a lot
more in just a moment.

00:19:17.600 --> 00:19:20.280
Then all the way on the flip side,
as I'd mentioned earlier,

00:19:20.370 --> 00:19:25.230
BGRA 8888 is the native
format for the device,

00:19:25.250 --> 00:19:29.000
enabling you to avoid a particular
swizzle as we set up that texture.

00:19:29.020 --> 00:19:33.960
But really, all these formats are native,
with the exception of RGB 8888.

00:19:34.490 --> 00:19:39.130
That format, you might just think it
could have a 24-bit packing,

00:19:39.130 --> 00:19:43.460
but really it just gets padded out to
32 bits per pixel by the implementation.

00:19:46.300 --> 00:19:48.990
Now, remember in the previous section,
I'd said that the MBX only

00:19:49.140 --> 00:19:52.440
supports textures whose
dimensions are a power of two,

00:19:52.490 --> 00:19:56.540
and the SGX supports both power of two
and non-power of two size textures.

00:19:56.540 --> 00:20:00.640
So, there's several important things
to know about both of these.

00:20:00.640 --> 00:20:03.820
Power of two textures have
some additional flexibility.

00:20:03.820 --> 00:20:07.740
They're able to support MIMMAP generation
and sample from the MIMMAP stack

00:20:07.740 --> 00:20:10.930
as they're being rasterized,
and they're more flexible in

00:20:10.930 --> 00:20:12.460
terms of their ramp modes.

00:20:12.460 --> 00:20:15.300
They support repeat as
well as clamp to edge.

00:20:16.020 --> 00:20:18.210
But, of course,
the dimensions are fixed to

00:20:18.510 --> 00:20:20.010
values that are a power of two.

00:20:20.020 --> 00:20:26.070
So, these are sizes like 512 by
512 or 64 by 128 and so on.

00:20:26.300 --> 00:20:29.260
And none of these sizes are
perfectly matched to the size

00:20:29.260 --> 00:20:31.030
of the screen on the iPhone.

00:20:31.040 --> 00:20:33.800
So, there's always either
going to be some scaling,

00:20:33.800 --> 00:20:37.590
or if you size the textures to
maintain a one-to-one mapping

00:20:37.680 --> 00:20:41.210
of textiles with pixels,
then there will always be some region

00:20:41.210 --> 00:20:43.170
of the texture that's not being used.

00:20:43.230 --> 00:20:48.630
By contrast, non-power of two textures,
of course, remove this restriction

00:20:48.630 --> 00:20:49.840
on their dimensions.

00:20:49.840 --> 00:20:54.460
So, they can be perfectly sized for the
screen dimensions at 480 by 320.

00:20:54.680 --> 00:20:56.820
And there's a number
of advantages to that.

00:20:56.820 --> 00:21:00.540
Particularly for cases where
you want to render to texture,

00:21:00.540 --> 00:21:04.200
or you just want some source
imagery that maintains a one-to-one

00:21:04.200 --> 00:21:08.220
textile to pixel mapping without
the unused region you'd get with,

00:21:08.220 --> 00:21:09.660
say, 512 by 512.

00:21:09.930 --> 00:21:12.870
But just bear in mind that
non-power of two textures

00:21:13.030 --> 00:21:15.430
aren't necessarily as versatile.

00:21:15.910 --> 00:21:20.210
They don't support MIMAPs and
they only support clamp to edge.

00:21:20.720 --> 00:21:23.820
The third topic is
compression with PVRTC.

00:21:23.820 --> 00:21:27.640
So this is the ability
to take a source image,

00:21:27.640 --> 00:21:30.680
say a 32-bit ping image
of a particular size,

00:21:30.680 --> 00:21:34.670
and perform a lossy compression
that reduces it to either

00:21:34.670 --> 00:21:36.600
2 or 4 bits per pixel.

00:21:36.600 --> 00:21:40.680
And that's a huge savings,
either 8 to 1 or 16 to 1.

00:21:41.110 --> 00:21:44.290
And the GPU is able to directly
sample from the compressed

00:21:44.410 --> 00:21:47.950
representation in memory,
which means that far fewer bytes

00:21:47.950 --> 00:21:51.960
are being pushed around in a given
frame to draw with a PVRTC texture.

00:21:53.580 --> 00:21:55.100
Now there are some requirements.

00:21:55.240 --> 00:21:57.330
In our implementation,
the dimensions of the

00:21:57.330 --> 00:22:01.020
texture must be square,
the size must be a power of two,

00:22:01.100 --> 00:22:03.920
and the height and width of the base
level must be at least eight pixels.

00:22:03.940 --> 00:22:08.130
We provide a compression tool with
the iPhone SDK that will take any of

00:22:08.210 --> 00:22:13.020
the variety of desktop image formats
supported by Image.io on your Mac and

00:22:13.220 --> 00:22:15.330
compress them into PVRTC images.

00:22:15.930 --> 00:22:16.900
And here's the path again.

00:22:16.900 --> 00:22:23.510
On your Mac, it's developer platforms,
iPhoneOS.platform/developer-user-bin-te

00:22:23.510 --> 00:22:24.790
xture-tool.

00:22:26.020 --> 00:22:29.620
Now, here's a comparison between an
original image and some versions

00:22:29.620 --> 00:22:31.700
that were compressed with PVRTC.

00:22:31.800 --> 00:22:34.580
So, on the left is the original
uncompressed image.

00:22:34.660 --> 00:22:38.630
This was a 32-bit ping
that was 256 by 256.

00:22:38.770 --> 00:22:43.080
So, that one takes up 256K of RAM.

00:22:43.160 --> 00:22:46.380
Then in the middle is the
same image compressed to

00:22:46.380 --> 00:22:51.490
PVRTC with 4 bits per pixel,
which totals to 32K of RAM.

00:22:51.610 --> 00:22:55.050
And on the right is
PVRTC with 2 bits per pixel,

00:22:55.050 --> 00:22:56.520
that's 16K.

00:22:56.620 --> 00:22:58.580
And the quality is really pretty good.

00:22:58.670 --> 00:23:00.880
If we blow up the images
and really compare them,

00:23:00.930 --> 00:23:03.880
here's the original,
then here's the PVRTC at

00:23:03.880 --> 00:23:07.450
4 bits per pixel,
and that's really a close comparison.

00:23:07.570 --> 00:23:12.600
And I find that the 4-bit PVRTC is
great for this kind of image.

00:23:12.870 --> 00:23:15.840
And here's the PVRTC with
two bits per pixel.

00:23:15.950 --> 00:23:21.120
So this entire image fits in 16K of RAM,
but I see some artifacts when we

00:23:21.120 --> 00:23:22.860
get down to two bits per pixel.

00:23:22.880 --> 00:23:27.320
But depending on the usage,
even this might be okay for you.

00:23:27.620 --> 00:23:32.100
So now a bit of guidance for when
PVRTC will be most appropriate.

00:23:32.150 --> 00:23:36.540
It's really well suited for
images from our analog world,

00:23:36.540 --> 00:23:40.180
things like wood and gravel,
smoke or skin.

00:23:40.260 --> 00:23:44.520
But it's not really made for images
that come from the digital world,

00:23:44.630 --> 00:23:47.440
images with really
high contrast line art,

00:23:47.630 --> 00:23:51.370
for example,
or fonts and symbols and so on.

00:23:51.680 --> 00:23:55.770
And one last thought to leave you
with about PVRTC is instead of doing a

00:23:55.770 --> 00:24:01.130
direct comparison between an original
32-bit image and its PVRTC equivalent,

00:24:01.140 --> 00:24:04.860
consider doing a comparison
between images that fit

00:24:04.860 --> 00:24:07.000
into a fixed memory budget.

00:24:07.030 --> 00:24:09.980
A lot of the time,
the decision you're making is

00:24:09.980 --> 00:24:13.900
really going to be between a
16-bit version of the original

00:24:13.900 --> 00:24:16.940
texture and a 4-bit PVRTC version.

00:24:17.460 --> 00:24:21.260
So at the sizes that I'm showing here,
both of these would require

00:24:21.400 --> 00:24:24.600
the same amount of RAM,
128K in this case.

00:24:24.600 --> 00:24:27.230
But quite frequently,
the PVRTC image will

00:24:27.230 --> 00:24:28.770
actually look better.

00:24:30.850 --> 00:24:33.360
All right,
our next topic for texture optimization

00:24:33.360 --> 00:24:35.620
is the concept of texture atlases.

00:24:35.640 --> 00:24:40.160
And what these are intended to
solve is the very common mistake

00:24:40.170 --> 00:24:44.320
of defining a whole bunch of
really small individual textures.

00:24:44.320 --> 00:24:47.890
And then when you go to draw them,
you end up doing something like this.

00:24:47.900 --> 00:24:50.410
You bind the first little
texture and draw the shark.

00:24:50.530 --> 00:24:53.670
Then bind the second little
texture and draw the character.

00:24:53.680 --> 00:24:55.790
And bind the third
texture and draw the moon,

00:24:55.790 --> 00:24:56.360
and so on.

00:24:56.400 --> 00:25:00.610
And this is really inefficient
because of all these state changes.

00:25:00.700 --> 00:25:05.570
every texture bind you do is going
to chip away at your performance.

00:25:06.220 --> 00:25:08.600
So instead,
you take all these little textures

00:25:08.600 --> 00:25:13.440
and combine them together into a
big texture mosaic or texture atlas.

00:25:13.650 --> 00:25:17.430
The concept is really simple but
very important because now you can

00:25:17.520 --> 00:25:19.820
just bind that big texture once.

00:25:19.980 --> 00:25:22.270
And by setting your texture
coordinates correctly,

00:25:22.350 --> 00:25:25.390
draw the shark, draw the character,
and draw the moon without

00:25:25.390 --> 00:25:27.160
ever changing textures.

00:25:27.380 --> 00:25:31.690
And over the course of a whole frame,
this can be a big savings.

00:25:32.130 --> 00:25:34.710
Now even better,
to combine this with something I'll be

00:25:34.780 --> 00:25:39.500
talking about in the geometry section,
is to use texture atlases in combination

00:25:39.500 --> 00:25:42.540
with combined geometry arrays.

00:25:42.650 --> 00:25:45.140
So now to draw all
three of these objects,

00:25:45.170 --> 00:25:49.610
we just bind the texture once
and we submit a single combined

00:25:49.610 --> 00:25:52.340
array with all the geometry.

00:25:52.370 --> 00:25:56.800
And this is orders of magnitude more
efficient than that first example

00:25:56.800 --> 00:26:01.340
where we were binding each texture
and then just drawing one little quad.

00:26:02.080 --> 00:26:05.110
So, we highly recommend
using texture atlases.

00:26:05.110 --> 00:26:07.420
And here's a few things to keep in mind.

00:26:07.600 --> 00:26:10.750
You'll have to modify the texture
coordinates on your geometry.

00:26:10.890 --> 00:26:12.070
And I hope this is obvious.

00:26:12.190 --> 00:26:15.230
For example,
on the shark image on the left,

00:26:15.310 --> 00:26:19.480
in terms of S and T,
its T coordinates run from 0 to 1.

00:26:19.620 --> 00:26:23.190
But in the atlas shown on the right,
it only takes up the top

00:26:23.190 --> 00:26:25.070
half of that larger image.

00:26:25.270 --> 00:26:29.390
So, its T coordinates run from 0.5 to 1.

00:26:29.650 --> 00:26:33.250
Also, you need at least a pixel of
padding between the elements so

00:26:33.330 --> 00:26:37.400
that any sampling just off the edge
of one part doesn't pick up any

00:26:37.410 --> 00:26:39.930
colors from a neighboring region.

00:26:40.140 --> 00:26:42.210
You can't use the repeat wrap mode.

00:26:42.230 --> 00:26:43.570
You have to use clamp.

00:26:43.570 --> 00:26:47.470
And that's also so you don't sample off
the edge of one region into a neighbor.

00:26:47.480 --> 00:26:51.800
And since they tend to be larger images,
texture atlases are really

00:26:51.800 --> 00:26:54.080
best suited for static texture.

00:26:56.410 --> 00:26:59.310
Here's an example of some
texture atlases from the game

00:26:59.440 --> 00:27:01.190
Pocket God from Bolt Interactive.

00:27:01.200 --> 00:27:03.290
These are some really great examples.

00:27:03.300 --> 00:27:05.230
They're both 1K by 1K.

00:27:05.240 --> 00:27:08.900
The image on the left has
more than 300 elements in it,

00:27:08.950 --> 00:27:11.140
and the one on the right has over 175.

00:27:11.140 --> 00:27:13.540
So just think about this.

00:27:13.540 --> 00:27:18.750
What they're able to do is first bind
the left-hand image and draw all the

00:27:18.750 --> 00:27:23.280
objects in their scene that are using
any of the textures in this atlas.

00:27:23.380 --> 00:27:25.610
In one draw call, perhaps.

00:27:26.300 --> 00:27:30.030
And then bind the right-hand image and
draw all the objects in their scene

00:27:30.030 --> 00:27:31.900
that are using any of those elements.

00:27:31.970 --> 00:27:33.950
Again, in one or just a few draw calls.

00:27:33.980 --> 00:27:38.660
So using this technique can really
reduce both the number of state

00:27:38.660 --> 00:27:42.480
changes and the number of draw
calls you make in a given frame.

00:27:42.540 --> 00:27:45.540
And both of those things can
really improve your performance.

00:27:48.770 --> 00:27:50.240
Next topic is mipmaps.

00:27:50.240 --> 00:27:54.980
So this is just the concept of
taking an original large texture,

00:27:54.990 --> 00:27:58.220
call that your base level texture,
and then creating a series

00:27:58.220 --> 00:28:01.570
of successively smaller
and smaller copies of it.

00:28:01.620 --> 00:28:05.070
The first copy, half the size in each
dimension of the original.

00:28:05.070 --> 00:28:08.520
The next copy, half the size in each
dimension of that first one.

00:28:08.520 --> 00:28:10.590
The next one, half of that, and so on.

00:28:10.590 --> 00:28:13.410
All the way down to where you
end up with a texture that's

00:28:13.410 --> 00:28:15.320
just one pixel by one pixel.

00:28:15.320 --> 00:28:20.180
And then when it's time to draw,
the graphics processor will choose

00:28:20.180 --> 00:28:24.200
which of those copies most closely
matches essentially the size that

00:28:24.200 --> 00:28:27.340
your texture is being scaled to
when it's presented on screen.

00:28:27.340 --> 00:28:31.170
And it'll sample the actual
textiles from whichever level

00:28:31.170 --> 00:28:32.860
or whichever copy it chooses.

00:28:32.860 --> 00:28:38.780
So this is very useful and we recommend
generating and using mipmaps anytime

00:28:38.900 --> 00:28:41.540
you're presenting textures in a 3D scene.

00:28:41.660 --> 00:28:45.340
The only time you shouldn't
bother with this is if you're only

00:28:45.510 --> 00:28:47.990
presenting unscaled images in 2D.

00:28:49.140 --> 00:28:54.200
The benefits are that using mipmaps
improves image quality in your scene.

00:28:54.200 --> 00:28:56.600
And actually,
since you're potentially sampling

00:28:56.600 --> 00:28:59.900
fewer actual texels when you're
using one of the smaller levels,

00:28:59.900 --> 00:29:01.980
it can help you with memory bandwidth.

00:29:01.980 --> 00:29:05.100
And that's potentially a nice win,
especially on the MBX.

00:29:05.100 --> 00:29:08.680
There's two filtering modes,
either linear mipmap linear

00:29:08.820 --> 00:29:10.600
or linear mipmap nearest.

00:29:10.600 --> 00:29:14.350
And these have either a quality
or performance tradeoff.

00:29:15.050 --> 00:29:17.570
And of course,
there's the tradeoff of those extra

00:29:17.580 --> 00:29:19.830
smaller copies of your original texture.

00:29:19.830 --> 00:29:24.300
If you sum up the sizes of the copies,
it comes out to an additional

00:29:24.300 --> 00:29:29.480
one-third memory usage compared to
just having the original base texture.

00:29:30.280 --> 00:29:33.510
Now, just a couple more tips before
we wrap up this section.

00:29:33.510 --> 00:29:37.620
First is a special note
about GL Text Parameter.

00:29:37.780 --> 00:29:42.500
Starting in iPhone OS 3.1 and only
on devices with the PowerVR SGX,

00:29:42.500 --> 00:29:46.970
there's a benefit to putting any
calls you make to GL Text Parameter

00:29:47.100 --> 00:29:49.820
before the call to GL Text Image 2D.

00:29:50.290 --> 00:29:54.680
So, you use GL Text Parameter to
configure texture filter settings,

00:29:54.860 --> 00:29:56.860
and of course,
you use GL Text Image 2D to

00:29:56.860 --> 00:29:57.960
load the texture.

00:29:57.960 --> 00:30:01.580
But if you put the
GL Text Parameter calls first,

00:30:01.580 --> 00:30:05.910
that will effectively act as a hint to
the implementation for how to lay out

00:30:06.060 --> 00:30:08.400
the texture that's about to be loaded.

00:30:08.400 --> 00:30:11.270
And this will briefly
improve its memory usage,

00:30:11.270 --> 00:30:14.060
avoiding a copy,
and improve its load time.

00:30:15.760 --> 00:30:17.920
A second tip, this one about UI image.

00:30:17.920 --> 00:30:21.800
So UI image is what many
OpenGL based applications are

00:30:21.800 --> 00:30:23.160
using to load their images.

00:30:23.180 --> 00:30:27.350
You load an image from the file system,
you get the CG image from it,

00:30:27.380 --> 00:30:31.440
you render that into a CG bitmap context,
and now you finally have

00:30:31.440 --> 00:30:35.290
the pixels that you can hand
directly off to GL Text Image 2D.

00:30:36.920 --> 00:30:39.720
A second tip, this one about UI image.

00:30:39.720 --> 00:30:43.400
So UI image is what many
OpenGL based applications are

00:30:43.460 --> 00:30:45.520
using to load their images.

00:30:45.520 --> 00:30:49.900
You load that into a CG bitmap context,
and now you finally have

00:30:49.900 --> 00:30:54.670
the pixels that you can hand
directly off to GL Text Image 2D.

00:30:55.320 --> 00:30:57.460
So we've said a lot about texture.

00:30:57.460 --> 00:31:01.160
And to summarize,
we really recommend using PVRTC if your

00:31:01.160 --> 00:31:03.360
content is suited for lossy compression.

00:31:03.380 --> 00:31:07.530
Otherwise,
consider using one of the 16-bit color

00:31:07.690 --> 00:31:11.470
formats like RGBA 5551 or RGB 565.

00:31:11.560 --> 00:31:13.880
We recommend generating mipmaps.

00:31:13.880 --> 00:31:16.460
We recommend using texture atlases.

00:31:17.050 --> 00:31:19.270
And when you're running
on the SGX hardware,

00:31:19.680 --> 00:31:25.230
note that non-PowerF2 textures are
supported even in an OpenGL ES 1.1 app.

00:31:25.320 --> 00:31:26.980
Then those tips.

00:31:26.980 --> 00:31:30.020
Set up your texture parameters
before you load the texture

00:31:30.340 --> 00:31:34.240
and use the UI image image with
contents of file factory method.

00:31:35.760 --> 00:31:36.770
But actually, we're not done yet.

00:31:36.980 --> 00:31:39.540
As I mentioned in the
architecture section,

00:31:39.540 --> 00:31:43.370
doing any texture sub-loads in the
middle of a frame can be expensive.

00:31:43.380 --> 00:31:46.410
So if you're doing this,
we recommend putting those calls at the

00:31:46.430 --> 00:31:50.370
start of the frame before you've used
the texture that you're about to modify.

00:31:50.380 --> 00:31:53.390
On the MBX hardware,
it's imperative that you stay

00:31:53.480 --> 00:31:57.200
below the 24 megabyte limit
for textures and surfaces.

00:31:57.200 --> 00:32:00.020
And then there's two things
I hadn't covered yet.

00:32:00.110 --> 00:32:03.760
The first is to pre-load and
warm all of your textures.

00:32:04.540 --> 00:32:08.080
So the work done by the driver
to actually prepare a texture

00:32:08.080 --> 00:32:12.910
for rendering is deferred until
the first time you actually go to

00:32:12.910 --> 00:32:14.830
draw something with that texture.

00:32:14.860 --> 00:32:20.280
And sometimes this lazy loading is okay,
but many applications are really

00:32:20.280 --> 00:32:25.200
trying hard to maintain a steady frame
rate and would rather take that hit

00:32:25.220 --> 00:32:29.810
up front rather than at some arbitrary
time while the render loop is running.

00:32:29.840 --> 00:32:34.480
So the practical advice is to
run through all your textures.

00:32:34.540 --> 00:32:35.860
And then the next step is to take
the textures in the beginning

00:32:35.860 --> 00:32:36.650
of your app and draw something.

00:32:36.670 --> 00:32:39.120
It can be just one pixel
and it can be off screen.

00:32:39.130 --> 00:32:39.850
It doesn't matter.

00:32:39.880 --> 00:32:43.940
But just draw something from each
texture to get them all pre-loaded.

00:32:44.060 --> 00:32:48.120
Now, an obvious place you might think
to put that work would be in your

00:32:48.240 --> 00:32:50.800
application did finish launching method.

00:32:50.800 --> 00:32:53.350
But actually,
that's not a good place since you

00:32:53.690 --> 00:32:58.080
want to return from that as quickly as
possible during application startup.

00:32:58.100 --> 00:33:00.140
So you'll have to get clever.

00:33:00.140 --> 00:33:03.380
And this is something that apps will have
to figure out on a case-by-case basis.

00:33:03.380 --> 00:33:03.380
So you'll have to get clever.

00:33:03.380 --> 00:33:03.480
And this is something that apps will have
to figure out on a case-by-case basis.

00:33:03.480 --> 00:33:03.550
So you'll have to get clever.

00:33:03.600 --> 00:33:03.620
And this is something that apps will have
to figure out on a case-by-case basis.

00:33:03.650 --> 00:33:07.330
If after your app starts up,
you're sitting on the menu screen,

00:33:07.340 --> 00:33:09.910
for instance, and waiting for the user
to start their game,

00:33:09.940 --> 00:33:13.610
then that's an ideal time
to be warming your textures.

00:33:13.620 --> 00:33:16.440
And if you don't get through them all,
well, that's okay.

00:33:16.440 --> 00:33:17.380
Every little bit will help.

00:33:18.660 --> 00:33:22.810
And finally, the last bit of advice for
texturing is to remember that the

00:33:22.960 --> 00:33:27.750
call to GLTECHIMAGE2D will make
its own copy of your image data.

00:33:27.760 --> 00:33:32.170
So you should free your copy of that
image data immediately afterwards.

00:33:32.220 --> 00:33:35.420
All right, wow,
so that was a lot to absorb.

00:33:35.420 --> 00:33:39.620
But now we're going to go even
deeper into optimizing geometry.

00:33:39.660 --> 00:33:42.220
And there's seven topics to cover.

00:33:42.600 --> 00:33:46.720
First, the fundamental data structures,
vertex arrays, triangle strips,

00:33:46.810 --> 00:33:49.190
indexed arrays, and VBOs.

00:33:49.280 --> 00:33:52.940
Then, the optimizations on those
structures through interleaving,

00:33:52.960 --> 00:33:55.140
smaller data types, and proper alignment.

00:33:56.900 --> 00:34:00.900
The starting point is to
talk about vertex arrays.

00:34:01.010 --> 00:34:05.580
These are the method for
defining geometry with OpenGL ES,

00:34:05.710 --> 00:34:09.960
and they form the foundation of indexed
arrays and vertex buffer objects.

00:34:10.080 --> 00:34:13.660
But I'm not going to teach the basics
of how to create a vertex array.

00:34:13.730 --> 00:34:16.290
I bring them up simply
to give you a reminder.

00:34:16.630 --> 00:34:20.340
They're called arrays for
a very important reason.

00:34:20.460 --> 00:34:24.120
And it's to encourage you to
fill them with a lot of data,

00:34:24.260 --> 00:34:29.980
to enable the implementation to do a bulk
data transfer into the graphics pipeline.

00:34:30.100 --> 00:34:34.660
And I see a lot of applications that
are creating really short vertex arrays,

00:34:34.660 --> 00:34:37.510
sometimes just one or two
triangles in an array,

00:34:37.520 --> 00:34:42.060
and submitting one or two triangles
at a time to the graphics pipeline.

00:34:42.180 --> 00:34:45.100
If you're doing this,
you're dropping orders of magnitude

00:34:45.100 --> 00:34:46.590
of performance on the floor.

00:34:46.920 --> 00:34:51.380
So developers who have really
mastered OpenGL ES become very

00:34:51.510 --> 00:34:55.550
focused on maximizing the length,
of their vertex arrays and

00:34:55.550 --> 00:34:59.220
managing state very carefully,
to allow them to pack yet

00:34:59.300 --> 00:35:01.580
more data into those arrays.

00:35:01.790 --> 00:35:05.960
All with the goal of having
just a few very long arrays,

00:35:06.180 --> 00:35:09.050
rather than a lot of shorter ones.

00:35:09.290 --> 00:35:13.030
Now, depending on your dataset,
one optimization you might be

00:35:13.030 --> 00:35:16.510
able to apply to your vertex
arrays is to batch up individual

00:35:16.540 --> 00:35:18.480
triangles into triangle strips.

00:35:18.480 --> 00:35:22.220
This is a method of reducing
the number of vertices that need

00:35:22.220 --> 00:35:26.130
to be submitted to the graphics
processor without any change to the

00:35:26.130 --> 00:35:28.050
number of triangles being rendered.

00:35:28.210 --> 00:35:31.270
So, here in this diagram,
we see that the vertices on the

00:35:31.330 --> 00:35:34.700
inside edges of these coincident
triangles are really just

00:35:34.700 --> 00:35:36.660
duplicates and can be removed.

00:35:37.350 --> 00:35:41.450
and all three of these triangles
batched up into a single strip.

00:35:41.750 --> 00:35:46.380
And the reason why this is so helpful
is because it is again a way of reducing

00:35:46.380 --> 00:35:49.740
the number of bytes that you need to
be pushing around to render a frame.

00:35:49.780 --> 00:35:52.870
And here you see that just
in these three triangles,

00:35:52.880 --> 00:35:55.170
we go from nine vertices down to five.

00:35:55.340 --> 00:35:59.490
And if each vertex is defined
to be 48 bytes in size following

00:35:59.490 --> 00:36:03.430
this formula on the bottom,
then this takes us from

00:36:03.430 --> 00:36:06.820
432 bytes down to 240.

00:36:07.860 --> 00:36:11.400
Now, something that comes up once you
start creating triangle strips

00:36:11.530 --> 00:36:15.460
is that each strip requires
its own call to GLDrawArrays.

00:36:15.560 --> 00:36:19.150
And yet we really want to reduce
the number of calls to draw arrays

00:36:19.240 --> 00:36:22.680
and basically get all our drawing
done from a big long array.

00:36:22.820 --> 00:36:25.320
Well,
there's a technique that can help you

00:36:25.320 --> 00:36:27.600
with this called degenerate triangles.

00:36:27.760 --> 00:36:31.240
And the idea is that we'll
actually add vertices,

00:36:31.270 --> 00:36:35.310
a copy of the last vertex of the
first array and a copy of the

00:36:35.410 --> 00:36:37.780
first vertex of the next array.

00:36:37.840 --> 00:36:42.480
And that will join these two separate
strips together into one without changing

00:36:42.480 --> 00:36:44.210
what's actually rendered on screen.

00:36:44.570 --> 00:36:47.310
And it's because these
degenerate triangles we've

00:36:47.310 --> 00:36:49.220
created won't be rasterized.

00:36:49.600 --> 00:36:57.010
The reason is this, the vertices ABC,
BCD and CDE each define a valid triangle.

00:36:57.290 --> 00:37:01.200
But DEE, that's a line,
it's not a triangle.

00:37:01.310 --> 00:37:05.350
So it won't be drawn if our array
is defined to consist of triangles.

00:37:06.330 --> 00:37:11.380
Likewise, EEF, EFF, FFG,
all those are just more

00:37:11.380 --> 00:37:12.810
lines and won't be drawn.

00:37:13.230 --> 00:37:17.710
But then FGH,
GHI and HIJ are valid triangles

00:37:17.710 --> 00:37:20.420
again and will be rendered normally.

00:37:20.420 --> 00:37:24.720
So this actually causes a net
increase in the number of vertices

00:37:24.820 --> 00:37:30.430
and the number of bytes in the array,
but it eliminates a call to GLDrawArrays,

00:37:30.430 --> 00:37:32.290
which is a big deal.

00:37:32.900 --> 00:37:35.320
Then the third topic is indexed arrays.

00:37:35.320 --> 00:37:39.450
And again, this will be very dependent
on your actual data set.

00:37:39.450 --> 00:37:42.700
But if you have data that
ultimately defines a mesh,

00:37:42.950 --> 00:37:47.270
then the inner vertices within that
mesh will generally be shared among

00:37:47.270 --> 00:37:49.800
a large number of triangles each.

00:37:49.800 --> 00:37:52.690
So in this example,
the vertices in the middle each

00:37:52.690 --> 00:37:54.750
touch six different triangles.

00:37:54.770 --> 00:37:58.600
Now, if I were to define this
mesh as a triangle strip,

00:37:58.600 --> 00:38:02.680
I'd have a partial strip
containing the blue triangle,

00:38:02.680 --> 00:38:02.680
the blue triangle, and the blue triangle.

00:38:02.700 --> 00:38:06.200
Then some degenerate vertices,
and then another partial strip

00:38:06.270 --> 00:38:08.000
with the purple triangles.

00:38:08.000 --> 00:38:11.990
But all the shared vertices in the
middle would have to be duplicated

00:38:12.080 --> 00:38:13.970
in both of the partial strips.

00:38:14.040 --> 00:38:19.150
So instead, if we create just one array
containing all the vertices here,

00:38:19.150 --> 00:38:22.380
with each vertex only
listed once in that array,

00:38:22.460 --> 00:38:27.890
and then a separate index array that
defines the triangles or triangle strips,

00:38:28.030 --> 00:38:31.820
then over a large mesh,
I can have a huge net savings.

00:38:32.270 --> 00:38:38.260
Here, I'm drawing a total of 16 triangles
and only using 742 bytes to do it.

00:38:38.580 --> 00:38:42.820
And you remember on the previous
slide with the degenerate triangles,

00:38:42.820 --> 00:38:46.450
that was only six triangles,
and it took 576 bytes.

00:38:48.810 --> 00:38:51.460
And finally,
the ultimate optimization generally

00:38:51.530 --> 00:38:53.860
comes from using vertex buffer objects.

00:38:53.860 --> 00:38:56.460
And as I mentioned in
the devices section,

00:38:56.480 --> 00:39:01.160
these are a huge win on
SGX because they're directly

00:39:01.160 --> 00:39:02.260
supported by the hardware.

00:39:02.280 --> 00:39:05.730
Now, on the MBX,
we basically just treat VBOs as

00:39:05.730 --> 00:39:10.640
an indexed array since there isn't
any special hardware for them.

00:39:10.640 --> 00:39:14.520
So you don't see the same performance
differential just from using

00:39:14.520 --> 00:39:16.520
them like you should on the SGX.

00:39:16.520 --> 00:39:18.340
But they don't hurt at all.

00:39:18.700 --> 00:39:21.760
So it's still considered a
highly recommended practice.

00:39:21.760 --> 00:39:25.500
And bear in mind,
even if you're tuning for the MBX,

00:39:25.500 --> 00:39:29.780
if your user just happens to have an SGX,
they'll be able to take

00:39:29.780 --> 00:39:32.850
advantage of VBO hardware
automatically from the same binary.

00:39:34.190 --> 00:39:39.710
Now, the way VBOs work is to essentially
take the vertex array API and

00:39:39.710 --> 00:39:41.550
add an object model to it.

00:39:41.640 --> 00:39:46.050
So, rather than you just providing
OpenGL with a pointer to an array

00:39:46.050 --> 00:39:50.570
that you might be changing any time,
you give OpenGL that array and then let

00:39:50.590 --> 00:39:53.420
it act as the gatekeeper for any changes.

00:39:53.460 --> 00:39:57.780
So, let's contrast VBOs with
vertex or indexed arrays.

00:39:58.560 --> 00:40:01.980
Any time you just use a vertex
array or an indexed array,

00:40:01.980 --> 00:40:06.700
all the data in that array will be
copied to the GPU every single frame.

00:40:06.760 --> 00:40:08.110
So, that's right.

00:40:08.160 --> 00:40:12.780
So, if you're not using VBOs,
a copy of your vertex data will

00:40:12.780 --> 00:40:16.180
be made every frame and then
discarded once it's been rendered.

00:40:16.200 --> 00:40:20.160
So, this is how all rendering
happens on the MBX,

00:40:20.160 --> 00:40:23.900
and it's true for any
non-VBO rendering on the SGX.

00:40:23.900 --> 00:40:27.830
And if you had wondered what copy index
data was all about in instruments,

00:40:27.880 --> 00:40:28.980
for example, this is it.

00:40:29.060 --> 00:40:32.700
Now, there is a silver
lining to that approach.

00:40:32.700 --> 00:40:35.880
It means that making changes
to your vertex array really

00:40:35.880 --> 00:40:39.510
can happen without any penalty,
since the implementation is just going

00:40:39.510 --> 00:40:41.200
to make its own copy of it anyways.

00:40:41.220 --> 00:40:45.540
But now, instead,
if you use vertex buffer objects,

00:40:45.540 --> 00:40:48.660
then on the SGX,
this data gets copied once and

00:40:48.660 --> 00:40:51.110
then reused in subsequent frames.

00:40:51.180 --> 00:40:53.850
This has a great effect on performance.

00:40:53.880 --> 00:40:57.390
The data is faster to access,
and it's faster for you to draw a frame.

00:40:58.520 --> 00:41:00.730
But the question becomes,
how about making changes?

00:41:00.740 --> 00:41:03.850
Well, you do this by calling map buffer.

00:41:03.860 --> 00:41:07.360
And as I said,
OpenGL acts as the gatekeeper

00:41:07.360 --> 00:41:09.930
for data once you define VBOs.

00:41:09.980 --> 00:41:12.460
But actually,
since we have a unified memory

00:41:12.460 --> 00:41:15.590
architecture on the iPhone,
there's really no extra

00:41:15.680 --> 00:41:17.780
overhead of a map buffer call.

00:41:17.780 --> 00:41:21.940
It's just giving you a pointer to
the wired system memory that's being

00:41:21.980 --> 00:41:23.500
directly referenced by the GPU.

00:41:23.500 --> 00:41:27.440
So, we really,
really recommend that you define your

00:41:27.540 --> 00:41:31.600
vertex data with a vertex buffer object.

00:41:33.230 --> 00:41:37.440
Now, changing gears from vertex
optimization to the organization

00:41:37.440 --> 00:41:39.200
of the arrays themselves.

00:41:39.320 --> 00:41:45.180
It's very typical for a 3D object to
be defined by an array of vertices

00:41:45.180 --> 00:41:48.620
and a separate array of normals,
another separate array

00:41:48.620 --> 00:41:50.720
of texture coordinates,
and so on.

00:41:50.760 --> 00:41:53.640
This tends to be how you find
data organized in some of

00:41:53.640 --> 00:41:55.570
the popular 3D file formats.

00:41:55.580 --> 00:41:59.410
It's also an easy way to
print and understand sample

00:41:59.480 --> 00:42:01.340
code in a book and so on.

00:42:01.510 --> 00:42:04.170
So it's just a routine practice
that's seen quite a lot.

00:42:04.420 --> 00:42:08.070
But actually, it's not the most optimal
way of submitting that data

00:42:08.070 --> 00:42:09.920
to the graphics processor.

00:42:09.920 --> 00:42:15.310
And the reason is because to load the
attributes for one vertex requires

00:42:15.370 --> 00:42:19.050
fetches from all these separate arrays,
which probably don't have

00:42:19.130 --> 00:42:22.370
good locality and probably
aren't all in cache and so on.

00:42:22.460 --> 00:42:26.320
What's better is if you can
interleave each vertex attribute

00:42:26.370 --> 00:42:28.540
and construct a single array.

00:42:28.560 --> 00:42:31.480
So now when we go to fetch
the data for a 3D object,

00:42:31.480 --> 00:42:33.500
and we go to fetch the data
for a particular vertex,

00:42:33.620 --> 00:42:37.090
there's excellent locality and
the array is likely to wind up

00:42:37.090 --> 00:42:38.970
in cache as we walk through it.

00:42:38.980 --> 00:42:42.480
And this has nice benefits
for both the MBX and SGX.

00:42:42.530 --> 00:42:46.630
Now, on the MBX,
there's even an optimal order

00:42:46.630 --> 00:42:48.480
for the interleaved attributes.

00:42:48.480 --> 00:42:52.480
And it's vertices, then normals,
then colors, then texture coordinates.

00:42:52.640 --> 00:42:55.530
On the SGX, the order doesn't matter.

00:42:56.940 --> 00:43:00.170
Now, an exception for interleaving
your vertex array is if you have

00:43:00.170 --> 00:43:01.450
a lot of dynamic attributes.

00:43:01.500 --> 00:43:05.890
Meaning you plan to run through one
of the attribute lists every frame,

00:43:05.930 --> 00:43:08.510
let's say the texture coordinates,
and update all of them.

00:43:08.600 --> 00:43:12.450
Well, this can be a lot of work since
you have to move along the

00:43:12.450 --> 00:43:14.700
array with a particular stride.

00:43:14.760 --> 00:43:18.060
So in that case,
we recommend that you separate

00:43:18.060 --> 00:43:20.220
out any dynamic attributes.

00:43:20.300 --> 00:43:22.800
Leave all the other
attributes interleaved,

00:43:22.850 --> 00:43:26.060
but take the ones that you plan
to update out of the interleaving,

00:43:26.060 --> 00:43:29.240
or any that you might share
among multiple objects.

00:43:30.930 --> 00:43:33.600
And then really getting
now into some specifics.

00:43:33.600 --> 00:43:37.100
You remember in my example
that I had defined a single

00:43:37.100 --> 00:43:38.750
vertex as being 48 bytes.

00:43:38.820 --> 00:43:41.930
And that was because I used
floats for all my attributes.

00:43:41.990 --> 00:43:46.100
Well, you should actually try to use
smaller data types if you can,

00:43:46.120 --> 00:43:49.600
like shorts for the vertices
and normals and perhaps just

00:43:49.600 --> 00:43:51.470
bytes to define the colors.

00:43:51.560 --> 00:43:56.490
It's common for colors to be
defined from 0 to 255 per component,

00:43:56.490 --> 00:43:57.620
for example.

00:43:57.620 --> 00:44:00.780
And since texture coordinates
are frequently just 0 to 255,

00:44:00.780 --> 00:44:00.780
you can use them to define the colors.

00:44:00.800 --> 00:44:03.800
from 0 to 1,
you can sometimes quantize them

00:44:03.800 --> 00:44:06.040
into bytes or at least use shorts.

00:44:06.040 --> 00:44:08.460
So, here's a couple of examples.

00:44:08.460 --> 00:44:11.750
At first,
I started out with 48 bytes per vertex

00:44:11.840 --> 00:44:16.140
with every attribute defined as a float,
which are four bytes each.

00:44:16.140 --> 00:44:19.510
And then, in the middle example,
I've reduced my color

00:44:19.510 --> 00:44:22.990
attributes to bytes,
and my texture coordinates to shorts,

00:44:23.050 --> 00:44:26.160
and this cuts a single
vertex down to 32 bytes,

00:44:26.280 --> 00:44:30.190
or two thirds the size of the original,
and that's great.

00:44:30.420 --> 00:44:34.450
Now, I'll go even further using shorts
for the vertices and normals,

00:44:34.600 --> 00:44:37.900
bytes for the colors,
and shorts for the texture coordinates.

00:44:37.980 --> 00:44:40.780
This takes me down to
20 bytes per vertex,

00:44:40.780 --> 00:44:45.360
which would be fantastic,
but there's a problem with

00:44:45.460 --> 00:44:48.810
it that actually would ruin
everything if we left it this way.

00:44:48.860 --> 00:44:52.690
And the attributes in
that case are misaligned.

00:44:54.410 --> 00:44:57.420
So here I'll just stack those
vertices into an interleaved

00:44:57.420 --> 00:44:59.160
array to show the problem.

00:44:59.290 --> 00:45:04.420
The issue is that each attribute
group must start at a 4-byte boundary.

00:45:04.510 --> 00:45:08.540
And you can see that the normals don't
start at a 4-byte boundary in this case.

00:45:08.610 --> 00:45:11.620
They're starting at byte 6,
and that throws everything

00:45:11.620 --> 00:45:14.010
off for the rest of the array.

00:45:14.210 --> 00:45:18.270
So, if you were to do this,
we actually have to correct it for you.

00:45:18.270 --> 00:45:21.340
The implementation will
fall off the fast path,

00:45:21.390 --> 00:45:25.520
make a copy of your array,
and pad it to fix your alignment problem.

00:45:25.520 --> 00:45:29.450
And remember, this will have to happen
every single frame.

00:45:29.450 --> 00:45:32.560
So, don't leave this to the
implementation to fix.

00:45:32.560 --> 00:45:35.510
Just when you choose the
size of your attributes,

00:45:35.510 --> 00:45:40.020
make sure each attribute group will
always start on a 4-byte boundary.

00:45:40.450 --> 00:45:42.580
And this is nothing complicated.

00:45:42.580 --> 00:45:47.740
Instead of the vertices being defined as,
say, short vertex sub 3,

00:45:47.740 --> 00:45:53.900
I'm saying to make it short vertex sub
4 and leave the fourth element unused.

00:45:53.900 --> 00:45:58.510
To basically add the padding that the
driver would have had to do for you.

00:45:58.600 --> 00:46:01.530
And so, with this fixed,
our size per vertex

00:46:01.530 --> 00:46:05.650
gets down to 24 bytes,
which is half the original size.

00:46:05.660 --> 00:46:10.220
Half as many bytes to copy each frame
for a vertex array or index array.

00:46:10.220 --> 00:46:13.310
And half as much memory bandwidth
being used to submit this

00:46:13.310 --> 00:46:15.450
geometry to the graphics pipeline.

00:46:15.460 --> 00:46:16.900
So, it's a huge win.

00:46:18.320 --> 00:46:21.200
So let's summarize what
we've covered for geometry.

00:46:21.350 --> 00:46:23.390
Long vertex arrays are
the starting point,

00:46:23.390 --> 00:46:26.820
and you should strive to create
just a few very long arrays

00:46:26.840 --> 00:46:29.740
rather than a lot of short arrays.

00:46:29.920 --> 00:46:31.820
Use vertex buffer objects.

00:46:31.970 --> 00:46:34.240
Even if your current
test platform is the MBX,

00:46:34.240 --> 00:46:38.350
where you won't see the benefit,
your users who happen to have

00:46:38.350 --> 00:46:40.660
a device with the SGX will.

00:46:40.870 --> 00:46:44.430
Interleave your vertex data,
but separate out any dynamic

00:46:44.430 --> 00:46:46.940
data from the interleave list.

00:46:47.110 --> 00:46:50.640
Use smaller types if you can,
and you almost always can for

00:46:50.770 --> 00:46:52.450
colors and texture coordinates.

00:46:52.570 --> 00:46:57.380
And if you do use smaller types,
make sure that the alignment is perfect.

00:46:57.490 --> 00:47:01.800
Ensure that each attribute group
starts on a 4-byte boundary.

00:47:03.970 --> 00:47:06.490
All right,
so that brings us to the end of Part 2.

00:47:06.500 --> 00:47:07.880
We've covered a lot of ground.

00:47:07.940 --> 00:47:11.130
And I hope this series has been
helpful for you in giving you a lot

00:47:11.130 --> 00:47:14.350
of platform-specific information
that you can put into use right away.

00:47:14.430 --> 00:47:16.690
In the meantime,
here's my contact information

00:47:16.690 --> 00:47:19.320
if you have questions about
the content presented here,

00:47:19.320 --> 00:47:22.120
and a link to the iPhone
Dev Center for documentation,

00:47:22.120 --> 00:47:24.420
sample code, and our developer forums.

00:47:24.420 --> 00:47:25.540
Thank you for watching.