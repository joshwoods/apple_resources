WEBVTT

00:00:00.200 --> 00:00:01.969
Dave Roberts: Hi.
I'm Dave Roberts

00:00:01.969 --> 00:00:04.204
from the GPU Software team
at Apple.

00:00:04.204 --> 00:00:07.341
I'm really excited to share
some of the updates to the GPU

00:00:07.341 --> 00:00:10.878
in the new
Apple A15 Bionic chip.

00:00:10.878 --> 00:00:13.013
Later on, Katelyn Hinson,

00:00:13.013 --> 00:00:15.249
my colleague
on the GPU Software team,

00:00:15.249 --> 00:00:18.785
will tell you all about the new
Metal features of the GPU.

00:00:18.785 --> 00:00:20.520
She'll also show you
how to use those features

00:00:20.520 --> 00:00:25.192
in your Metal apps while
exploring some cool use cases.

00:00:25.192 --> 00:00:28.095
The A15 Bionic is
a powerful new platform

00:00:28.095 --> 00:00:29.796
for your Metal apps and games,

00:00:29.796 --> 00:00:34.167
with updates to the CPU, GPU,
Neural Engine, and other

00:00:34.167 --> 00:00:37.871
user experience-enhancing
technologies.

00:00:37.871 --> 00:00:42.075
The A15 GPU builds upon the same
tile-based deferred renderer

00:00:42.075 --> 00:00:46.146
and unified memory architecture
as the A14 Bionic.

00:00:46.146 --> 00:00:48.715
While we've made many
microarchitectural improvements

00:00:48.715 --> 00:00:50.083
in various areas,

00:00:50.083 --> 00:00:52.119
there are some important changes
for performance

00:00:52.119 --> 00:00:54.688
that I should highlight.

00:00:54.688 --> 00:00:58.091
The A15's GPU has
up to five shader cores,

00:00:58.091 --> 00:01:00.360
and that fifth core provides
a performance boost

00:01:00.360 --> 00:01:04.731
of 25 percent at the same
GPU core frequency.

00:01:04.731 --> 00:01:06.133
The shader cores now have double

00:01:06.133 --> 00:01:08.468
the F32 floating-point
math units

00:01:08.468 --> 00:01:12.239
which can boost GPU performance
on math-heavy workloads.

00:01:12.239 --> 00:01:16.109
The A15's GPU also makes the UI
even more responsive

00:01:16.109 --> 00:01:18.645
and extends battery life
even further.

00:01:18.645 --> 00:01:20.647
And you get all of these
great improvements for free

00:01:20.647 --> 00:01:23.750
without any modifications
to your code.

00:01:23.750 --> 00:01:25.052
But that's not everything!

00:01:25.052 --> 00:01:27.854
We brought some brand-new
features to the A15 GPU

00:01:27.854 --> 00:01:31.391
that you can use to make
your Metal apps even better.

00:01:31.391 --> 00:01:33.327
And all of these
new capabilities

00:01:33.327 --> 00:01:38.966
belong to a new Metal feature
set known as AppleGPUFamily8.

00:01:38.966 --> 00:01:40.200
For the rest of the talk,

00:01:40.200 --> 00:01:42.469
Katelyn and I will focus
on these new features

00:01:42.469 --> 00:01:45.639
and explain what they are,
why they are useful,

00:01:45.639 --> 00:01:48.275
and cover the changes
to the new Metal API

00:01:48.275 --> 00:01:50.811
and shading language
that support them.

00:01:50.811 --> 00:01:57.284
First up, the A15's new
graphics processing features.

00:01:57.284 --> 00:02:00.620
Lossy compression, which uses
your app's texture memory usage

00:02:00.620 --> 00:02:03.824
with minimal impact
on image quality.

00:02:03.824 --> 00:02:06.126
This new A15 feature
gives you the same

00:02:06.126 --> 00:02:09.796
texture memory bandwidth savings
as lossless compression.

00:02:09.796 --> 00:02:12.933
I'll show you how to use lossy
compression in your Metal apps

00:02:12.933 --> 00:02:15.836
with some more details
in a moment.

00:02:15.836 --> 00:02:19.406
Later on, Katelyn will show you
how the A15 GPU

00:02:19.406 --> 00:02:22.242
extends existing support
for sparse textures

00:02:22.242 --> 00:02:24.811
by including rendering
to both sparse depth

00:02:24.811 --> 00:02:27.247
and stencil textures.

00:02:27.247 --> 00:02:30.250
Katelyn will also cover
a new compute specific feature:

00:02:30.250 --> 00:02:32.853
SIMD group shuffle and fill.

00:02:32.853 --> 00:02:34.554
The A15 adds these
new instructions

00:02:34.554 --> 00:02:37.090
to the GPU core instruction set.

00:02:37.090 --> 00:02:38.325
She'll explain this feature

00:02:38.325 --> 00:02:41.061
and show you how to improve
your app performance

00:02:41.061 --> 00:02:43.663
by reducing
compute kernel execution time

00:02:43.663 --> 00:02:47.801
for applicable use cases
such as image processing.

00:02:47.801 --> 00:02:51.972
I'll start by taking a closer
look at lossy compression.

00:02:51.972 --> 00:02:54.007
To better understand
lossy compression,

00:02:54.007 --> 00:02:57.377
it's worth revisiting
lossless compression.

00:02:57.377 --> 00:02:59.146
The A12 Bionic first introduced

00:02:59.146 --> 00:03:03.083
lossless texture compression
in 2018, and the A14 Bionic

00:03:03.083 --> 00:03:06.620
added further improvements
to the feature in 2020.

00:03:06.620 --> 00:03:09.389
Lossless texture compression
saves memory bandwidth,

00:03:09.389 --> 00:03:10.991
which in turn saves power,

00:03:10.991 --> 00:03:14.961
so your apps can do even more
on a single battery charge.

00:03:14.961 --> 00:03:16.163
Lossless compression

00:03:16.163 --> 00:03:19.332
ensures that it always
preserves texture detail.

00:03:19.332 --> 00:03:21.201
In fact, your apps might already
take advantage

00:03:21.201 --> 00:03:24.871
of lossless compression
on the A12 Bionic and later.

00:03:24.871 --> 00:03:26.206
Check out the tech talk,

00:03:26.206 --> 00:03:29.309
"Discover Metal enhancements
for A14 Bionic"

00:03:29.309 --> 00:03:31.611
and the "Optimizing
Texture Data" article

00:03:31.611 --> 00:03:33.613
on developer.apple.com

00:03:33.613 --> 00:03:37.651
for more details about
lossless compression.

00:03:37.651 --> 00:03:40.487
Lossy takes texture compression
to the next level

00:03:40.487 --> 00:03:43.123
on the A15 Bionic.

00:03:43.123 --> 00:03:44.691
In addition
to the bandwidth savings

00:03:44.691 --> 00:03:46.526
that lossless compression
gives you,

00:03:46.526 --> 00:03:49.429
lossy compression uses
just half the memory footprint

00:03:49.429 --> 00:03:51.665
of an uncompressed texture.

00:03:51.665 --> 00:03:53.767
Lossy compression
preserves texture quality

00:03:53.767 --> 00:03:55.435
wherever it's possible.

00:03:55.435 --> 00:03:57.871
And best of all,
you can easily apply this

00:03:57.871 --> 00:03:59.739
to your render targets
on the A15

00:03:59.739 --> 00:04:03.677
to take full advantage
of those memory savings.

00:04:03.677 --> 00:04:05.212
You can enable lossy compression

00:04:05.212 --> 00:04:07.647
by simply setting
a texture descriptor's

00:04:07.647 --> 00:04:11.585
new compression type property
to lossy.

00:04:11.585 --> 00:04:13.887
So why use lossy compression?

00:04:13.887 --> 00:04:15.422
Well, compression saves

00:04:15.422 --> 00:04:17.390
significant texture
memory bandwidth,

00:04:17.390 --> 00:04:20.961
whether you choose to use
lossless or lossy.

00:04:20.961 --> 00:04:23.230
It's the compression unit
that saves the bandwidth

00:04:23.230 --> 00:04:26.867
by compressing textured data
before it's written to memory.

00:04:26.867 --> 00:04:28.668
When you use
lossless compression,

00:04:28.668 --> 00:04:31.705
the GPU must perfectly
preserve texture detail.

00:04:31.705 --> 00:04:34.674
So Metal cannot guarantee
any amount of compression

00:04:34.674 --> 00:04:36.309
and must allocate enough memory

00:04:36.309 --> 00:04:39.913
to cover the full uncompressed
texture size.

00:04:39.913 --> 00:04:42.315
However, when you use
lossy compression,

00:04:42.315 --> 00:04:46.086
textures use just half the
memory footprint of lossless.

00:04:46.086 --> 00:04:48.989
If the A15 GPU cannot
losslessly compress a texture

00:04:48.989 --> 00:04:52.559
to fit within that 50 percent
smaller memory footprint,

00:04:52.559 --> 00:04:55.462
it'll reduce the fidelity
of regions of the texture

00:04:55.462 --> 00:04:57.864
so that it does.

00:04:57.864 --> 00:05:02.269
Lossy compression supports most
pixel formats and texture types,

00:05:02.269 --> 00:05:04.804
and you can use it
on your render targets.

00:05:04.804 --> 00:05:06.806
In many cases, you can
enable it on textures

00:05:06.806 --> 00:05:10.110
without any further
modifications to your app.

00:05:10.110 --> 00:05:12.679
I recommend your apps
enable lossy compression

00:05:12.679 --> 00:05:16.349
wherever the quality tradeoff
is acceptable to you.

00:05:16.349 --> 00:05:19.686
The easiest place to enable it
is your final render target

00:05:19.686 --> 00:05:23.023
where you're least likely
to notice a loss in quality.

00:05:23.023 --> 00:05:26.092
Consider using lossy compression
for intermediate render targets

00:05:26.092 --> 00:05:28.161
and use that memory saving
for other things,

00:05:28.161 --> 00:05:30.797
such as increasing
texture resolution.

00:05:30.797 --> 00:05:33.366
And be sure to review
your postprocessing change

00:05:33.366 --> 00:05:35.368
to find render target candidates

00:05:35.368 --> 00:05:38.371
that may benefit
from lossy compression.

00:05:38.371 --> 00:05:42.676
Here are some of the use cases
in detail.

00:05:42.676 --> 00:05:44.844
Take a look
at the visual difference

00:05:44.844 --> 00:05:46.646
if I enable a lossy compression

00:05:46.646 --> 00:05:49.349
for just the final
render target.

00:05:49.349 --> 00:05:52.118
This split image compares
lossless on the left

00:05:52.118 --> 00:05:53.587
to lossy on the right,

00:05:53.587 --> 00:05:56.289
and the differences
are pretty subtle.

00:05:56.289 --> 00:05:58.458
He's an image that shows
the per-pixel differences

00:05:58.458 --> 00:06:01.394
between lossless
and lossy compression.

00:06:01.394 --> 00:06:03.630
The black pixels
represent no difference;

00:06:03.630 --> 00:06:06.466
blue to green represent
small differences;

00:06:06.466 --> 00:06:09.569
and red represent
the biggest changes.

00:06:09.569 --> 00:06:11.838
The red and yellow pixels
in this image

00:06:11.838 --> 00:06:14.007
illustrate a few
isolated regions

00:06:14.007 --> 00:06:16.776
that have the largest difference
in the final render.

00:06:16.776 --> 00:06:19.746
If I zoom into one of
the regions with the scooter,

00:06:19.746 --> 00:06:21.615
I have a hard time
seeing any difference

00:06:21.615 --> 00:06:24.884
between the left
and the right images.

00:06:24.884 --> 00:06:26.586
Intermediate render targets

00:06:26.586 --> 00:06:29.522
also work well
with lossy compression.

00:06:29.522 --> 00:06:32.459
Here's a side-by-side view
of the puddle's reflection

00:06:32.459 --> 00:06:36.129
that compares lossless
and lossy compression.

00:06:36.129 --> 00:06:39.566
If I switch to the per-pixel
difference representation again,

00:06:39.566 --> 00:06:41.368
the lossy compressed reflection

00:06:41.368 --> 00:06:44.604
has only minimal differences
from the lossless version.

00:06:44.604 --> 00:06:47.007
Plus you can increase
the resolution of the texture

00:06:47.007 --> 00:06:49.376
to add more detail
with the memory you save

00:06:49.376 --> 00:06:51.211
with lossy compression.

00:06:51.211 --> 00:06:54.281
For example, here's
a high-resolution reflection

00:06:54.281 --> 00:06:57.250
that shows more detail
than the lossless version,

00:06:57.250 --> 00:07:01.554
all while using
the same amount of memory.

00:07:01.554 --> 00:07:04.557
The right side of this demo
uses lossy compression

00:07:04.557 --> 00:07:07.661
for every renderable texture
in the scene.

00:07:07.661 --> 00:07:10.830
When it's in motion,
the scene looks very stable,

00:07:10.830 --> 00:07:12.899
and it's very difficult
to detect the difference

00:07:12.899 --> 00:07:17.837
if you compare it to the
lossless version on the left.

00:07:17.837 --> 00:07:22.208
Metal makes it easy to use
lossy compression in your apps.

00:07:22.208 --> 00:07:24.944
Here's how.

00:07:24.944 --> 00:07:28.348
Start by initializing a texture
descriptor as usual,

00:07:28.348 --> 00:07:32.118
then set the compression type
property to lossy.

00:07:32.118 --> 00:07:34.788
Next, set the storage mode
to private.

00:07:34.788 --> 00:07:36.690
Finally, create the texture.

00:07:36.690 --> 00:07:38.992
And your app can now
take full advantage

00:07:38.992 --> 00:07:42.329
of lossy compression
and the savings it offers.

00:07:42.329 --> 00:07:44.931
Note that you can create
textures for lossy compression

00:07:44.931 --> 00:07:48.668
for most configurations
with a few exceptions.

00:07:48.668 --> 00:07:50.603
For example, you can
use lossy compression

00:07:50.603 --> 00:07:52.472
for most common texture types,

00:07:52.472 --> 00:07:55.842
including 2D, 3D,
array, and cube.

00:07:55.842 --> 00:07:59.746
But the feature doesn't support
some of the less common types.

00:07:59.746 --> 00:08:02.015
Similarly, lossy compression
supports

00:08:02.015 --> 00:08:04.818
most common pixel formats,
but not the formats

00:08:04.818 --> 00:08:07.854
with packed color channels.

00:08:07.854 --> 00:08:11.624
Lossy compression supports
textures as render targets,

00:08:11.624 --> 00:08:13.126
in blit operations,

00:08:13.126 --> 00:08:16.262
and when you access them with
sample and read operations.

00:08:16.262 --> 00:08:19.065
However, note that you cannot
populate a lossy texture

00:08:19.065 --> 00:08:22.302
with shader write operations.

00:08:22.302 --> 00:08:24.504
Lossy compression
only supports textures

00:08:24.504 --> 00:08:25.972
in private storage.

00:08:25.972 --> 00:08:30.009
You cannot use shared
or managed storage nodes.

00:08:30.009 --> 00:08:33.413
And lastly, lossy textures work
with other common features

00:08:33.413 --> 00:08:37.884
like MSAA, sRGB,
and mipmapping.

00:08:37.884 --> 00:08:41.588
Check out the Metal feature set
tables on developer.apple.com

00:08:41.588 --> 00:08:45.792
for more details about
lossy compression support.

00:08:45.792 --> 00:08:49.362
So in summary, lossy compression
saves the same bandwidth

00:08:49.362 --> 00:08:51.564
as lossless compression
while also saving

00:08:51.564 --> 00:08:54.768
50 percent
of the texture memory.

00:08:54.768 --> 00:08:56.803
You can save significant
amounts of memory

00:08:56.803 --> 00:08:59.372
depending on the use case
and how much you choose

00:08:59.372 --> 00:09:01.941
to use lossy compression
in your apps.

00:09:01.941 --> 00:09:04.844
Lossy compression aims
to preserve texture detail

00:09:04.844 --> 00:09:07.213
but only slightly reducing
the quality for regions

00:09:07.213 --> 00:09:09.783
where the compressed
texture data doesn't fit.

00:09:09.783 --> 00:09:12.185
And lastly,
lossy compression supports

00:09:12.185 --> 00:09:15.255
common texture types,
common pixel formats,

00:09:15.255 --> 00:09:19.192
and all GPU access modes
other than shader writes,

00:09:19.192 --> 00:09:22.829
making it easy for you
to use lossy compression.

00:09:22.829 --> 00:09:27.333
Thanks for listening, and now
I'll hand over to Katelyn.

00:09:27.333 --> 00:09:28.501
Katelyn Hinson:
Thanks, Dave.

00:09:28.501 --> 00:09:31.805
I'm excited to introduce the new
sparse textures extensions

00:09:31.805 --> 00:09:33.840
in the A15 Bionic.

00:09:33.840 --> 00:09:35.809
Sparse textures are
a great way to create

00:09:35.809 --> 00:09:37.343
high-resolution textures

00:09:37.343 --> 00:09:40.046
while managing
your memory budget in Metal.

00:09:40.046 --> 00:09:43.583
A13 Bionic first introduced
sparse texture support,

00:09:43.583 --> 00:09:46.820
allowing you to map and unmap
texture tiles

00:09:46.820 --> 00:09:48.621
on the GPU timeline.

00:09:48.621 --> 00:09:52.125
For more details on how to use
sparse textures in your apps,

00:09:52.125 --> 00:09:56.463
refer to the talks
from fall 2019 and 2020.

00:09:56.463 --> 00:09:59.032
A15 Bionic extends
sparse support

00:09:59.032 --> 00:10:01.968
by including depth
and stencil attachments.

00:10:01.968 --> 00:10:04.504
The guiding principle
of a sparse texture is,

00:10:04.504 --> 00:10:07.607
"Don't allocate
what you won't use."

00:10:07.607 --> 00:10:10.643
For example, this app
doesn't need to map the tiles

00:10:10.643 --> 00:10:12.846
behind the UI elements.

00:10:12.846 --> 00:10:15.548
With sparse depth
and stencil textures,

00:10:15.548 --> 00:10:20.820
this app can always leave these
obscured tiles unmapped.

00:10:20.820 --> 00:10:24.290
You can optimize shadow maps
with sparse depth attachments.

00:10:24.290 --> 00:10:26.192
If you're not familiar
with shadow mapping,

00:10:26.192 --> 00:10:28.428
check out Metal's
deferred lighting sample

00:10:28.428 --> 00:10:30.663
which uses this technique.

00:10:30.663 --> 00:10:32.899
A shadow pass renders
the shadow map

00:10:32.899 --> 00:10:34.601
from the light's perspective,

00:10:34.601 --> 00:10:37.003
and the lighting pass
reads it back.

00:10:37.003 --> 00:10:38.972
The texels sampled
from the shadow map

00:10:38.972 --> 00:10:41.875
are always within
the projected frustum.

00:10:41.875 --> 00:10:45.512
This scenario is a perfect
candidate for a sparse texture.

00:10:45.512 --> 00:10:47.514
A large portion
of the shadow texture

00:10:47.514 --> 00:10:49.182
does not need to be mapped,

00:10:49.182 --> 00:10:52.685
as the lighting pass
does not sample these tiles.

00:10:52.685 --> 00:10:54.787
Here's a scene
that uses shadow mapping

00:10:54.787 --> 00:10:56.890
and its rendered shadow map.

00:10:56.890 --> 00:10:59.125
The app can recover
the memory in the tiles

00:10:59.125 --> 00:11:01.628
outside the view frustum
since it doesn't need

00:11:01.628 --> 00:11:05.098
to write or read back
from those tiles.

00:11:05.098 --> 00:11:07.500
Cascaded shadow mapping
is a more advanced technique

00:11:07.500 --> 00:11:10.803
for shadows that use
multiple individual shadow maps

00:11:10.803 --> 00:11:12.939
to cover the scene
more efficiently.

00:11:12.939 --> 00:11:16.643
It allocates higher resolution
shadow maps near the camera

00:11:16.643 --> 00:11:20.313
and lower resolution maps
farther from the camera.

00:11:20.313 --> 00:11:24.484
For example, this scene uses
three overlapping shadow maps.

00:11:24.484 --> 00:11:27.487
Each shadow map has
the same texture resolution

00:11:27.487 --> 00:11:30.056
and is mapped to increasingly
larger areas

00:11:30.056 --> 00:11:32.725
the further it is
from the camera.

00:11:32.725 --> 00:11:34.928
The green highlighted areas
in the shadow map

00:11:34.928 --> 00:11:38.598
represent the texels
that the lighting pass samples.

00:11:38.598 --> 00:11:42.168
The lighting pass nonuniformly
samples from these tiles --

00:11:42.168 --> 00:11:43.670
represented as a heat map --

00:11:43.670 --> 00:11:48.308
with blue tiles undersampled
and red oversampled.

00:11:48.308 --> 00:11:50.209
You can use sparse tiled
shadow maps

00:11:50.209 --> 00:11:52.679
to replace these textures
with a single surface

00:11:52.679 --> 00:11:57.584
that has adjustable resolution
based on sampling rate.

00:11:57.584 --> 00:12:00.286
With sparse tiled shadow maps --
or STSM --

00:12:00.286 --> 00:12:03.389
you create a single
sparse depth surface.

00:12:03.389 --> 00:12:05.758
Instead of using
a fixed-resolution texture,

00:12:05.758 --> 00:12:09.796
the surface has mapped tiles
across the sparse mipmap chain.

00:12:09.796 --> 00:12:12.298
This technique
only maps the tiles needed

00:12:12.298 --> 00:12:14.834
to match the desired
sampling rate.

00:12:14.834 --> 00:12:17.303
Here's an illustration
of the physical resolution

00:12:17.303 --> 00:12:21.207
for each tile
in its relative mip level.

00:12:21.207 --> 00:12:22.709
You can freely and efficiently

00:12:22.709 --> 00:12:26.045
adjust the resolution of your
shadow map across a scene

00:12:26.045 --> 00:12:29.248
by mapping tiles
across different mips.

00:12:29.248 --> 00:12:32.485
Here are the main steps
of the STSM technique.

00:12:32.485 --> 00:12:37.190
First, generate the density map
based on the sampling rate.

00:12:37.190 --> 00:12:39.659
Then construct the surface
and map tiles

00:12:39.659 --> 00:12:42.695
according to the density map.

00:12:42.695 --> 00:12:46.799
And then render to and sample
from the adaptive surface.

00:12:46.799 --> 00:12:48.468
To generate the density map,

00:12:48.468 --> 00:12:51.504
the geometry pass populates
a density map buffer

00:12:51.504 --> 00:12:53.306
for the other passes.

00:12:53.306 --> 00:12:55.408
The first step is to get
the sampling rate

00:12:55.408 --> 00:12:57.610
across the shadow map.

00:12:57.610 --> 00:13:00.580
The expected sample density
is calculated by tracking

00:13:00.580 --> 00:13:04.283
the shadow space derivatives
of rendered geometry.

00:13:04.283 --> 00:13:07.553
The fragment shader uses atomics
to store the derivatives

00:13:07.553 --> 00:13:09.055
in a 2D grid,

00:13:09.055 --> 00:13:13.192
collecting the sampling rates
across the shadowUV space.

00:13:13.192 --> 00:13:15.061
Once you have the density map,

00:13:15.061 --> 00:13:18.431
use it to lay out the tiles
for your sparse depth texture

00:13:18.431 --> 00:13:21.300
and generate
a table of contents buffer.

00:13:21.300 --> 00:13:22.702
This table of contents buffer

00:13:22.702 --> 00:13:25.204
will be used
by your lighting pass.

00:13:25.204 --> 00:13:27.874
First, map the tiles
of the depth texture

00:13:27.874 --> 00:13:30.109
by iteratively dividing
the surface

00:13:30.109 --> 00:13:32.645
and scheduling the mapping
of each mip level,

00:13:32.645 --> 00:13:35.081
starting with the bottom mip.

00:13:35.081 --> 00:13:37.016
To figure out
which tiles to map,

00:13:37.016 --> 00:13:39.852
start by checking the sampling
rate of the current mip

00:13:39.852 --> 00:13:41.754
from the density map.

00:13:41.754 --> 00:13:43.156
In this example,

00:13:43.156 --> 00:13:46.693
the density map indicates
the current mip is inadequate,

00:13:46.693 --> 00:13:49.562
but the next mip level
is a good fit.

00:13:49.562 --> 00:13:51.631
In this case,
you promote the whole tile

00:13:51.631 --> 00:13:55.435
by mapping the next mip
and unmap the current mip.

00:13:55.435 --> 00:13:58.137
Here's another, more
complicated scenario.

00:13:58.137 --> 00:14:01.374
The density map indicates
the current mip is satisfactory

00:14:01.374 --> 00:14:03.876
for at least one quadrant.

00:14:03.876 --> 00:14:05.645
For the next mip,
the sample rate

00:14:05.645 --> 00:14:09.248
and the density map meets
the target for two quadrants,

00:14:09.248 --> 00:14:12.685
while the remaining two
are under the target rate.

00:14:12.685 --> 00:14:15.555
In this case, map the tile
in the current mip

00:14:15.555 --> 00:14:18.391
and map half the tiles
in the next.

00:14:18.391 --> 00:14:21.327
Next a compute shader
writes a 2D table

00:14:21.327 --> 00:14:24.330
that translates between
UV and mip levels,

00:14:24.330 --> 00:14:28.367
which is stored in our table
of contents or TOC buffer.

00:14:28.367 --> 00:14:31.471
Before sampling a texel
from the STSM,

00:14:31.471 --> 00:14:34.507
the TOC buffer is read
by the lighting pass

00:14:34.507 --> 00:14:37.477
by indexing the table
to get the mip.

00:14:37.477 --> 00:14:40.880
The mip is then used as
an explicit LOD parameter

00:14:40.880 --> 00:14:43.549
when you sample
the shadow map.

00:14:43.549 --> 00:14:46.652
The next step is to render
the sparse shadow map.

00:14:46.652 --> 00:14:50.456
First, cull the shadows
by using the TOC buffer,

00:14:50.456 --> 00:14:52.525
then encode
the indirect draw commands

00:14:52.525 --> 00:14:55.228
to render
to the sparse depth texture.

00:14:55.228 --> 00:14:58.331
Render the surface by filling
each mip map individually

00:14:58.331 --> 00:15:00.967
with an indirect command buffer.

00:15:00.967 --> 00:15:03.536
ICBs are the perfect fit
for this task

00:15:03.536 --> 00:15:07.273
since compute passes can,
in parallel, cull and sort

00:15:07.273 --> 00:15:11.144
each shadow geometry mesh
against the resident areas.

00:15:11.144 --> 00:15:15.114
The compute shader encodes draw
commands into individual ICBs

00:15:15.114 --> 00:15:19.519
by testing meshes against the
bounding volumes of the tiles.

00:15:19.519 --> 00:15:22.955
For large objects that stretch
across the shadow map,

00:15:22.955 --> 00:15:25.825
the shader tests the object
against the relevant tiles

00:15:25.825 --> 00:15:27.760
of each mip;

00:15:27.760 --> 00:15:31.030
and it encodes a draw command
to the mip's ICB

00:15:31.030 --> 00:15:34.567
if at least one tile overlaps.

00:15:34.567 --> 00:15:37.336
If a mip doesn't have
any tiles that overlap,

00:15:37.336 --> 00:15:42.108
don't emit a draw command for
the object to that mip's ICB.

00:15:42.108 --> 00:15:44.944
The optimized set of draw
commands for each object

00:15:44.944 --> 00:15:47.880
is encoded by the shadow
cull compute pass

00:15:47.880 --> 00:15:49.782
by running all
intersection tests

00:15:49.782 --> 00:15:52.552
in parallel compute threads.

00:15:52.552 --> 00:15:55.121
Since the red mesh was
closest to the camera,

00:15:55.121 --> 00:15:59.392
it had the biggest impact
at 11 tiles on our shadow map.

00:15:59.392 --> 00:16:02.929
Compare that to the orange mesh,
the furthest from the camera,

00:16:02.929 --> 00:16:06.732
which had the smallest impact
at three tiles.

00:16:06.732 --> 00:16:09.101
Once the indirect draw command
is complete,

00:16:09.101 --> 00:16:13.606
the STSM is ready to be sampled
in the lighting pass.

00:16:13.606 --> 00:16:16.676
This table compares STSM
to shadow mapping

00:16:16.676 --> 00:16:19.312
and cascaded shadow mapping.

00:16:19.312 --> 00:16:22.181
The STSM sample rate
and effective quality

00:16:22.181 --> 00:16:24.951
is about the same
as the single shadow map

00:16:24.951 --> 00:16:27.086
but uses far less memory.

00:16:27.086 --> 00:16:30.823
In fact, it uses less than a
percent of the memory footprint

00:16:30.823 --> 00:16:33.192
for the same resolution.

00:16:33.192 --> 00:16:35.328
I hope this deep dive
gives you some ideas

00:16:35.328 --> 00:16:38.097
on how to create efficient,
high-quality shadows

00:16:38.097 --> 00:16:42.602
in your Metal apps
with sparse tiled shadow maps.

00:16:42.602 --> 00:16:45.371
Lastly, I'm excited to
introduce the new additions

00:16:45.371 --> 00:16:50.076
to Metal compute in A15:
SIMD shuffle and fill.

00:16:50.076 --> 00:16:52.044
In modern image processing,

00:16:52.044 --> 00:16:55.681
convolution kernels are applied
for filters like edge detection,

00:16:55.681 --> 00:16:57.884
blur, and sharpen.

00:16:57.884 --> 00:17:00.086
Here's a convolution
applied to an image

00:17:00.086 --> 00:17:02.355
from our modern rendering demo.

00:17:02.355 --> 00:17:04.924
Workloads like this one
are typically limited

00:17:04.924 --> 00:17:08.361
by texture sampling or reading
from thread group memory,

00:17:08.361 --> 00:17:11.597
leaving the GPU's
math units underutilized.

00:17:11.597 --> 00:17:14.767
Apple silicon provides
a rich set of SIMD instructions

00:17:14.767 --> 00:17:16.736
that can be used
in Metal compute shaders

00:17:16.736 --> 00:17:19.138
to help optimize
these workloads.

00:17:19.138 --> 00:17:22.775
As threads of a SIMD group
run concurrently in lockstep,

00:17:22.775 --> 00:17:26.112
SIMD group functions exploit
this lockstep execution

00:17:26.112 --> 00:17:28.414
to share data
between its threads.

00:17:28.414 --> 00:17:31.617
For more information
about existing SIMD functions,

00:17:31.617 --> 00:17:35.488
please see the talks for
A13 Bionic and A14 Bionic,

00:17:35.488 --> 00:17:37.657
where they were introduced.

00:17:37.657 --> 00:17:41.861
Now let's discuss the new
SIMD instructions available.

00:17:41.861 --> 00:17:43.462
New to A15 Bionic

00:17:43.462 --> 00:17:47.233
is the support for SIMD
and quad shuffle and fill.

00:17:47.233 --> 00:17:48.768
These instructions are designed

00:17:48.768 --> 00:17:51.871
to improve sliding-window
image operations,

00:17:51.871 --> 00:17:55.508
like the edge detection
convolution previously shown.

00:17:55.508 --> 00:17:57.944
These functions optimize
compute workloads

00:17:57.944 --> 00:17:59.946
by sharing data across
neighboring threads

00:17:59.946 --> 00:18:03.282
in a given SIMD group
without using memory.

00:18:03.282 --> 00:18:06.519
First let's look at the behavior
for quad shuffle down,

00:18:06.519 --> 00:18:09.088
first supported in A13.

00:18:09.088 --> 00:18:13.259
The data buffer has contents
A, B, C, and D,

00:18:13.259 --> 00:18:14.894
which is loaded
into the registers

00:18:14.894 --> 00:18:19.699
of a quad's threads:
zero, one, two, and three.

00:18:19.699 --> 00:18:22.435
When applying a shuffle down
on a shift of one,

00:18:22.435 --> 00:18:25.671
the register data in thread
zero, one, and two

00:18:25.671 --> 00:18:29.642
get the data from threads
one, two, and three.

00:18:29.642 --> 00:18:32.745
The computed quad lane ID
doesn't wrap around,

00:18:32.745 --> 00:18:37.083
so thread three in the result
has the unshifted value D.

00:18:37.083 --> 00:18:40.820
Instead, if the quad shuffle and
fill down instruction is used,

00:18:40.820 --> 00:18:42.321
a fill buffer is provided

00:18:42.321 --> 00:18:45.324
to update thread three
in the result.

00:18:45.324 --> 00:18:48.694
Now the fill data of thread zero
is shuffled to the output data

00:18:48.694 --> 00:18:51.197
in thread three.

00:18:51.197 --> 00:18:55.835
Similarly, for a quad shuffle
up and fill with shift of two,

00:18:55.835 --> 00:19:00.139
we see A and B are shuffled
to threads two and three,

00:19:00.139 --> 00:19:01.807
and the data
from the fill buffer

00:19:01.807 --> 00:19:05.378
is shuffled into
the output's lower lanes.

00:19:05.378 --> 00:19:09.482
On Apple silicon, SIMD groups
are composed of 32 threads.

00:19:09.482 --> 00:19:12.251
And the same shuffle and fill
behavior can be applied

00:19:12.251 --> 00:19:15.321
across our SIMD lane,
where the lower delta lanes

00:19:15.321 --> 00:19:18.791
are filled with the upper lanes
of the fill data.

00:19:18.791 --> 00:19:22.228
The new SIMD and quad
shuffle and fill instructions

00:19:22.228 --> 00:19:25.264
also have an optional
modulo argument.

00:19:25.264 --> 00:19:28.467
This allows for user-specified
vector widths.

00:19:28.467 --> 00:19:29.969
For a module of eight,

00:19:29.969 --> 00:19:33.739
the SIMD group is effectively
split into four vectors.

00:19:33.739 --> 00:19:36.709
The data buffer values are
first shuffled up two indices,

00:19:36.709 --> 00:19:41.313
and the fill data is shuffled
into each set of eight threads.

00:19:41.313 --> 00:19:44.850
Let's use these new instructions
in an example

00:19:44.850 --> 00:19:47.153
where the kernel used
for edge detection

00:19:47.153 --> 00:19:50.022
of our modern rendering image
can be optimized

00:19:50.022 --> 00:19:53.059
using SIMD shuffle and fill.

00:19:53.059 --> 00:19:55.227
In order to generate
the final result,

00:19:55.227 --> 00:19:57.897
a 5-by-5 convolution
kernel is applied

00:19:57.897 --> 00:20:00.199
to the input image.

00:20:00.199 --> 00:20:03.469
The output image is split
into a set of SIMD groups,

00:20:03.469 --> 00:20:06.272
where each SIMD group
is a 4-by-8 chunk,

00:20:06.272 --> 00:20:09.542
each thread writing
to a single output.

00:20:09.542 --> 00:20:13.846
Let's focus on generating the
output for a single SIMD group.

00:20:13.846 --> 00:20:15.781
For the 5-by-5 convolution,

00:20:15.781 --> 00:20:19.585
each thread must read
5 by 5 pixels from the input.

00:20:19.585 --> 00:20:21.687
For each 4-by-8 SIMD group,

00:20:21.687 --> 00:20:25.591
an 8-by-12 region must be
sampled in the compute shader.

00:20:25.591 --> 00:20:28.327
The naive implementation
of this convolution

00:20:28.327 --> 00:20:31.864
would require 25 samples
for each output thread.

00:20:31.864 --> 00:20:35.801
This results in great overlap
across our SIMD group.

00:20:35.801 --> 00:20:39.371
This can be optimized by the
shuffle and fill instructions,

00:20:39.371 --> 00:20:42.541
eliminating duplicate samples
within a SIMD group

00:20:42.541 --> 00:20:45.845
and sharing data
through register shuffles.

00:20:45.845 --> 00:20:49.582
Let's see why we would need
to read from these locations.

00:20:49.582 --> 00:20:52.852
First A is loaded,
which is a 4-by-8 window

00:20:52.852 --> 00:20:56.856
where each thread in the SIMD
group samples a single pixel;

00:20:56.856 --> 00:21:00.960
then B for the top-right window,
C for the bottom left,

00:21:00.960 --> 00:21:03.996
and finally D
for the bottom right.

00:21:03.996 --> 00:21:07.333
The red outline rectangle
indicates the destination region

00:21:07.333 --> 00:21:10.302
of our SIMD group
for the output image.

00:21:10.302 --> 00:21:12.238
Through four samples per thread,

00:21:12.238 --> 00:21:16.075
the 8-by-12 input region was
loaded across our SIMD group

00:21:16.075 --> 00:21:19.145
without any overlapping samples.

00:21:19.145 --> 00:21:22.515
Refocusing on the 5-by-5 region
for thread zero,

00:21:22.515 --> 00:21:26.752
these samples can be represented
as a 5-by-5 neighborhood.

00:21:26.752 --> 00:21:28.988
Quad shuffle and fill down
can be used

00:21:28.988 --> 00:21:31.357
to access the first row
of neighbors,

00:21:31.357 --> 00:21:36.328
first shuffling down A's data
and filling with B's data.

00:21:36.328 --> 00:21:39.398
Then the 32 wide vectors
from the previous row

00:21:39.398 --> 00:21:42.201
are shuffled down
for the next row.

00:21:42.201 --> 00:21:44.870
As the data is shuffled
down a full row,

00:21:44.870 --> 00:21:47.339
a fill vector is needed
to shuffle the samples

00:21:47.339 --> 00:21:51.610
from C and D in the upper lanes
of the 32-wide vector.

00:21:51.610 --> 00:21:55.414
Using the same approach,
SIMD and quad shuffle down

00:21:55.414 --> 00:22:00.286
can be used to get the remaining
samples in the 5-by-5 region.

00:22:00.286 --> 00:22:03.022
Once the full neighborhood
has been shuffled,

00:22:03.022 --> 00:22:04.924
these samples are used
as the input

00:22:04.924 --> 00:22:08.294
to the edge detection algorithm.

00:22:08.294 --> 00:22:10.963
While the naive implementation
sampled the full neighborhood

00:22:10.963 --> 00:22:12.331
for each thread,

00:22:12.331 --> 00:22:15.901
with the new SIMD and quads
shuffle and fill instructions,

00:22:15.901 --> 00:22:18.137
the number of samples
for each SIMD group

00:22:18.137 --> 00:22:20.406
is reduced by 84 percent,

00:22:20.406 --> 00:22:24.510
eliminating overlapping samples
across neighboring threads.

00:22:24.510 --> 00:22:28.747
Using the new SIMD operations,
many common image processing

00:22:28.747 --> 00:22:32.051
and machine learning algorithms
can apply the same approach

00:22:32.051 --> 00:22:36.322
to optimize shared data
across SIMD groups.

00:22:36.322 --> 00:22:39.758
And that's it
for SIMD shuffle and fill.

00:22:39.758 --> 00:22:42.728
Let's recap what we've learned.

00:22:42.728 --> 00:22:45.764
Lossy compression
is an easy-to-enable feature

00:22:45.764 --> 00:22:48.300
that saves memory
footprint and bandwidth

00:22:48.300 --> 00:22:52.504
while maintaining quality
for your textures.

00:22:52.504 --> 00:22:54.607
Sparse depth
and stencil textures

00:22:54.607 --> 00:22:58.510
help you create efficient,
high-quality shadow maps.

00:22:58.510 --> 00:23:01.480
New compute instructions
SIMD shuffle and fill

00:23:01.480 --> 00:23:05.684
reduce overlap and improve
sliding-window image operations

00:23:05.684 --> 00:23:10.022
for machine learning and image
processing applications.

00:23:10.022 --> 00:23:13.392
And finally, all Metal apps
get an additional boost

00:23:13.392 --> 00:23:17.129
in performance, responsiveness,
and power savings

00:23:17.129 --> 00:23:19.598
from the overall
architectural improvements

00:23:19.598 --> 00:23:22.167
of the A15 Bionic GPU.

00:23:22.167 --> 00:23:24.169
Thank you for watching.