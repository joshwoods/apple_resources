WEBVTT

00:00:00.630 --> 00:00:03.690
Welcome to Metal updates
for the A14 Bionic.

00:00:03.840 --> 00:00:08.940
My name is Anand Poovekurussi and
I work in GPU software at Apple.

00:00:09.520 --> 00:00:14.570
The A14 Bionic is at the heart of
iPhone 12 and the new iPad Air.

00:00:14.570 --> 00:00:16.880
In this video,
my colleague Swami and I will

00:00:16.880 --> 00:00:22.000
introduce you to the GPU capabilities
of the A14 Bionic and the new

00:00:22.000 --> 00:00:24.630
Metal features that it enables.

00:00:25.150 --> 00:00:29.490
The A14 has big updates to our CPU, GPU,
Neural Engine and other

00:00:29.770 --> 00:00:33.840
custom technologies that
drive the iOS experience.

00:00:33.960 --> 00:00:37.350
It uses breakthrough
5nm process technology,

00:00:37.360 --> 00:00:40.450
which brings new features,
increased performance and even

00:00:40.450 --> 00:00:44.580
more power efficiency in nearly
every aspect of the chip.

00:00:45.240 --> 00:00:49.090
We have built a world-class
mobile GPU into the A14 Bionic.

00:00:49.190 --> 00:00:53.810
It has four cores,
scaled to deliver the maximum sustainable

00:00:53.810 --> 00:00:56.670
performance at the lowest possible power.

00:00:57.540 --> 00:01:00.910
Now, in terms of Metal,
there are some specific changes

00:01:00.910 --> 00:01:05.400
in the A14 that will improve the
performance of your Metal apps.

00:01:05.530 --> 00:01:08.640
Starting off with GPU-driven pipelines.

00:01:08.750 --> 00:01:13.770
Indirect command buffers in Metal enable
you to move work to the GPU and let you

00:01:13.770 --> 00:01:16.500
encode commands on the GPU timeline.

00:01:16.630 --> 00:01:21.590
This frees up valuable CPU time for you
to perform other tasks in your apps.

00:01:21.730 --> 00:01:27.030
The A14 GPU architecture makes
such usage models more efficient.

00:01:27.600 --> 00:01:29.670
Next,
we have made significant performance

00:01:29.670 --> 00:01:32.730
improvements to the design of
GPU Thread Group memory to better

00:01:32.920 --> 00:01:34.540
support parallel computing.

00:01:34.540 --> 00:01:39.510
We expect synchronization primitives
such as Thread Group scoped atomics

00:01:39.510 --> 00:01:43.750
to see great performance benefits
as a result of these changes.

00:01:44.280 --> 00:01:48.870
Finally, the ability to conserve memory
bandwidth continues to be a significant

00:01:48.870 --> 00:01:51.200
design advantage of our platforms.

00:01:51.230 --> 00:01:54.670
The A14 GPU leverages brand
new compression hardware,

00:01:54.670 --> 00:01:57.860
which brings even more
bandwidth savings to your apps.

00:01:58.080 --> 00:02:02.920
Frame buffer compression is expected
to improve by 15% or more on average,

00:02:02.920 --> 00:02:07.180
and depth buffers should see 40%
or more improvement on average.

00:02:08.430 --> 00:02:13.900
All the new capabilities of the A14
GPU belong to a new Metal feature set,

00:02:13.900 --> 00:02:16.000
called Apple GPU Family 7.

00:02:18.350 --> 00:02:21.000
Here’s what we’ll be
covering in this video.

00:02:21.180 --> 00:02:25.400
First up, I will talk about barycentric
coordinates and primitive ID.

00:02:25.400 --> 00:02:29.370
I will also show you how both of
these features can be used together to

00:02:29.400 --> 00:02:33.870
implement deferred rendering techniques
such as the visibility buffer.

00:02:34.460 --> 00:02:36.580
After that,
I will quickly introduce the new

00:02:36.580 --> 00:02:39.490
texture addressing modes in A14.

00:02:39.970 --> 00:02:44.340
We also have brand new features
for apps doing compute.

00:02:44.450 --> 00:02:47.710
In the second section of the talk,
my colleague Swami will talk about

00:02:47.710 --> 00:02:51.830
the new SIMD reduction instructions
that provide an efficient way for

00:02:52.050 --> 00:02:56.500
applications to perform reduction
operations at SIMD group scope.

00:02:56.810 --> 00:03:01.940
He will also cover the new SIMD matrix
multiply instructions in Metal on A14.

00:03:02.030 --> 00:03:04.940
These new instructions provide
significant performance boost for

00:03:04.940 --> 00:03:10.130
large matrix multiplies that are used
in machine learning and image compute.

00:03:10.620 --> 00:03:14.420
Let’s look at each of
these in more detail.

00:03:14.480 --> 00:03:18.370
Starting with barycentric
coordinates and primitive ID.

00:03:19.340 --> 00:03:24.630
Apple GPU Family 7 now provides access to
barycentric coordinates and primitive ID.

00:03:24.640 --> 00:03:27.830
Barycentric coordinates
define the exact location of

00:03:27.940 --> 00:03:29.440
a fragment within a primitive.

00:03:29.440 --> 00:03:33.740
And now you can access these coordinates
right in your fragment shader.

00:03:33.760 --> 00:03:36.090
As you can see in the
picture on the right,

00:03:36.320 --> 00:03:40.250
the location of the fragment at point
P is defined as a weighted sum of

00:03:40.310 --> 00:03:45.110
the vertices that form the triangle,
where the sum of the weights is 1.

00:03:45.900 --> 00:03:48.440
In the Metal shading language,
the barycentric coordinates

00:03:48.440 --> 00:03:51.650
of the fragment are exposed
as a vector of floats.

00:03:51.800 --> 00:03:55.010
Let’s take a look at a technique
which can benefit from using

00:03:55.100 --> 00:03:56.740
barycentric coordinates.

00:03:58.310 --> 00:04:00.900
Procedural generation is a
class of techniques used to

00:04:00.900 --> 00:04:05.290
algorithmically generate models,
animations, and effects.

00:04:05.290 --> 00:04:08.670
You can do all sorts of procedural
effects on the surface of the

00:04:08.670 --> 00:04:13.080
primitives such as particle systems,
terrains, or vegetation on the fly.

00:04:13.210 --> 00:04:16.630
Drawing custom lines is one such example.

00:04:16.720 --> 00:04:20.570
Let’s take a look at how barycentric
coordinates can be used for this.

00:04:21.180 --> 00:04:24.830
Let’s say you wanted to use
procedural generation to draw custom,

00:04:25.070 --> 00:04:29.410
high-quality anti-alias lines
and borders on triangles.

00:04:29.590 --> 00:04:31.910
To do this,
you can apply interesting mathematical

00:04:31.910 --> 00:04:36.340
functions on the distance of the fragment
from the edges of your primitive.

00:04:36.560 --> 00:04:41.870
Barycentric coordinates of your
fragment in essence give you

00:04:41.870 --> 00:04:41.870
the distance from the edges.

00:04:42.300 --> 00:04:46.220
The examples above show some interesting
functions applied on the barycentric

00:04:46.220 --> 00:04:50.960
coordinates in your fragment shader
to generate on-the-fly effects.

00:04:51.890 --> 00:04:55.420
Another new feature of
Metal on A14 is primitive ID.

00:04:55.420 --> 00:04:59.270
Primitive ID tells you which
primitive the current fragment

00:04:59.280 --> 00:05:01.160
corresponds to in the input geometry.

00:05:01.160 --> 00:05:04.380
On the right,
the IDs listed on triangles will

00:05:04.380 --> 00:05:08.000
be returned when primitive ID is
fetched for any fragment within that

00:05:08.000 --> 00:05:09.920
triangle in your fragment shader.

00:05:10.980 --> 00:05:13.520
Now, if the triangle gets
clipped by the hardware,

00:05:13.570 --> 00:05:16.510
a child triangle inherits the
primitive ID of its parent.

00:05:16.550 --> 00:05:20.200
And in the presence of tessellation,
the primitive ID simply

00:05:20.200 --> 00:05:22.900
corresponds to the patch ID.

00:05:23.000 --> 00:05:26.670
In the Metal shading language,
primitive ID is an unsigned integer.

00:05:27.490 --> 00:05:31.190
Let’s take a look at a
use case for primitive ID.

00:05:32.350 --> 00:05:35.180
Temporal anti-aliasing is a
technique that reduces the

00:05:35.180 --> 00:05:39.100
ghosting and shimmering artifacts
caused by motion between frames.

00:05:39.100 --> 00:05:42.160
It works by accumulating pixel
data from the previous frame

00:05:42.480 --> 00:05:45.260
and blending it with the current
render results for the fragment.

00:05:45.300 --> 00:05:49.010
Primitive ID can be used with
temporal anti-aliasing to validate

00:05:49.010 --> 00:05:51.290
the sample from the previous frame.

00:05:51.290 --> 00:05:54.100
So, how would you actually
do this in practice?

00:05:54.300 --> 00:05:58.620
First, in your fragment shader,
you reproject the results from the

00:05:58.620 --> 00:06:01.300
previous frame to fetch pixel history.

00:06:01.540 --> 00:06:04.230
Then, you introspect the pixel
to ensure that the data is

00:06:04.240 --> 00:06:06.110
consistent with the current frame.

00:06:06.300 --> 00:06:10.260
This can be done by comparing the
primitive IDs of the two samples.

00:06:10.290 --> 00:06:12.960
If the IDs match,
you can choose to accumulate the

00:06:12.960 --> 00:06:15.300
contribution from the previous frame.

00:06:15.300 --> 00:06:19.390
The pixel history can be accumulated
or reset post-introspection,

00:06:19.650 --> 00:06:22.470
forwarding the results
onto the next frame.

00:06:23.480 --> 00:06:26.450
Now that we have introduced barycentric
coordinates and primitive ID,

00:06:26.770 --> 00:06:29.090
let’s take a deeper dive.

00:06:29.400 --> 00:06:32.310
Starting with deferred rendering,
a technique you are likely

00:06:32.310 --> 00:06:33.730
already familiar with.

00:06:33.850 --> 00:06:36.970
Deferred rendering classically
operates in two stages.

00:06:36.970 --> 00:06:40.090
The first stage,
generating a surface attribute

00:06:40.090 --> 00:06:42.760
buffer called the G-buffer,
and the second stage,

00:06:42.760 --> 00:06:45.860
which consumes the G-buffer and
applies lighting on the scene.

00:06:46.030 --> 00:06:50.020
But if you are running at high
resolution or using multi-sampling,

00:06:50.200 --> 00:06:52.220
the size of the G-buffer
can be quite large,

00:06:52.250 --> 00:06:57.290
and reading and writing of these buffers
could have prohibitive bandwidth costs.

00:06:57.290 --> 00:07:00.740
To address this problem,
the G-buffer could be

00:07:00.740 --> 00:07:03.740
replaced with a thin buffer,
which contains the minimal

00:07:03.740 --> 00:07:05.380
set of surface attributes.

00:07:05.380 --> 00:07:09.780
This buffer is called
the visibility buffer.

00:07:11.120 --> 00:07:14.910
The visibility buffer minimizes the
work in the geometry stage by greatly

00:07:14.910 --> 00:07:18.000
simplifying the output from this stage.

00:07:18.170 --> 00:07:21.210
All the material logic you would
typically perform in the fragment

00:07:21.260 --> 00:07:24.950
shader in deferred rendering to generate
material properties in the G-Buffer

00:07:25.180 --> 00:07:26.880
are now moved to the lighting phase.

00:07:27.000 --> 00:07:30.270
By doing this,
we no longer have to store all material

00:07:30.270 --> 00:07:33.000
properties in the intermediate buffer.

00:07:33.350 --> 00:07:35.690
Without material function,
the complexity of the geometry

00:07:35.720 --> 00:07:38.830
stage is greatly reduced,
allowing for a high fill rate and

00:07:38.830 --> 00:07:43.000
minimum traffic between the vertex
shader and the fragment shader.

00:07:43.650 --> 00:07:46.400
This technique adds a new
reconstruction step during the

00:07:46.400 --> 00:07:50.510
lighting pass to reconstruct the
material inputs from the minimal data

00:07:50.510 --> 00:07:52.500
set inside the visibility buffer.

00:07:52.740 --> 00:07:56.680
Let’s take a look at what the
visibility buffer will contain.

00:07:57.250 --> 00:08:01.220
The visibility buffer only needs
to contain two attributes to

00:08:01.220 --> 00:08:03.640
facilitate geometry reconstruction.

00:08:03.750 --> 00:08:06.790
The primitive ID can be used
to manually retrieve vertex

00:08:06.840 --> 00:08:10.010
data from the vertex buffer,
effectively doing a

00:08:10.010 --> 00:08:11.810
deferred vertex fetch.

00:08:12.140 --> 00:08:15.030
Barycentric coordinates are
used to interpolate vertex

00:08:15.030 --> 00:08:16.820
data for the current fragment.

00:08:16.870 --> 00:08:19.880
As mentioned before,
you can access these attributes

00:08:19.880 --> 00:08:22.100
in your fragment shader on A14.

00:08:22.120 --> 00:08:26.940
Let’s take a closer look at the two
stages of the visibility buffer pipeline.

00:08:27.620 --> 00:08:31.260
At a high level, the visibility buffer
approach has two stages:

00:08:31.430 --> 00:08:34.620
the geometry stage,
which produces the visibility buffer,

00:08:34.620 --> 00:08:37.180
and the lighting stage that consumes it.

00:08:37.300 --> 00:08:40.170
In the geometry stage,
the vertex shader's transformation

00:08:40.570 --> 00:08:43.930
only generates the position
needed for rasterization.

00:08:44.070 --> 00:08:47.080
The fragment stage can generate
the primitive ID and barycentric

00:08:47.120 --> 00:08:51.120
coordinates with the new A14
Metal shading language attributes,

00:08:51.120 --> 00:08:55.010
without the need for any
additional variances.

00:08:55.580 --> 00:08:58.720
In the lighting stage,
a new reconstruction step will

00:08:58.720 --> 00:09:02.630
use a deferred vertex fetch
based on the primitive ID,

00:09:02.630 --> 00:09:06.420
and interpolate the vertex data
using barycentric coordinates to

00:09:06.420 --> 00:09:08.550
generate material function inputs.

00:09:08.920 --> 00:09:12.120
The material and lighting shaders
are effectively untouched and

00:09:12.120 --> 00:09:16.200
are identical to the deferred
rendering implementations.

00:09:16.310 --> 00:09:21.150
Let’s take a look at how interfaces
between these stages have been minimized.

00:09:22.280 --> 00:09:26.840
The vertex shader only requires
the position to rasterize.

00:09:26.920 --> 00:09:30.070
The fragment shader generates the
surface ID and barycentric coordinates

00:09:30.160 --> 00:09:34.140
for the visibility buffer that is
fed into the reconstruction step.

00:09:34.220 --> 00:09:38.420
And only after the reconstruction step
do we have the large reconstructed

00:09:38.420 --> 00:09:42.080
material input data in memory,
which is used by the material

00:09:42.080 --> 00:09:44.210
model and the lighting functions.

00:09:44.390 --> 00:09:46.540
Now that we have
introduced the interfaces,

00:09:46.750 --> 00:09:51.400
let’s take a look at the shaders that
are generating these inputs and outputs.

00:09:52.220 --> 00:09:55.980
Let’s start with the geometry phase,
which has a simple vertex

00:09:55.980 --> 00:09:57.470
and fragment shader.

00:09:57.860 --> 00:10:02.140
The vertex shader only needs to
transform and output the position.

00:10:02.200 --> 00:10:05.240
In the fragment shader,
we make use of the new primitive ID and

00:10:05.240 --> 00:10:08.560
barycentric coordinates available
in the Metal shading language.

00:10:08.630 --> 00:10:11.910
We combine the primitive
ID and additional draw index

00:10:11.910 --> 00:10:15.610
into our surface identifier,
so we can identify primitives

00:10:15.640 --> 00:10:18.960
across vertex buffers,
as we will see later.

00:10:19.030 --> 00:10:22.180
Now,
let's take a look at the lighting stage.

00:10:22.880 --> 00:10:25.640
At a high level,
the lighting stage has three steps:

00:10:25.710 --> 00:10:29.400
Reconstruction,
Material Model and Lighting Function.

00:10:29.480 --> 00:10:33.340
The Reconstruction step will reconstruct
material input from our surface

00:10:33.340 --> 00:10:35.790
identifier and barycentric coordinates.

00:10:35.960 --> 00:10:40.060
Then we can execute our material model
steps as we do in our deferred shader.

00:10:40.060 --> 00:10:42.960
And finally,
we apply our lighting function

00:10:42.960 --> 00:10:45.020
to write out the final lit pixel.

00:10:45.020 --> 00:10:49.090
As mentioned previously,
the material and the lighting stages

00:10:49.090 --> 00:10:51.180
are identical to classic deferred.

00:10:51.180 --> 00:10:56.950
So, let’s take a look at the
reconstruction step in more detail.

00:10:58.190 --> 00:11:01.560
The main purpose of the reconstruction
step is the transformation of

00:11:01.630 --> 00:11:05.900
the incoming visibility buffer
fragment to material inputs.

00:11:06.260 --> 00:11:10.030
First, this requires generating vertex
data for a given fragment using

00:11:10.060 --> 00:11:14.580
primitive ID and draw ID contained
in the surface identifier.

00:11:14.720 --> 00:11:18.150
An additional index facilitates
having different vertex

00:11:18.150 --> 00:11:20.020
buffers across fragments.

00:11:20.160 --> 00:11:24.590
For this, we use a draw identifier
to reference the draw call.

00:11:25.090 --> 00:11:28.050
Second,
the barycentric coordinates are used for

00:11:28.050 --> 00:11:30.830
interpolation in the reconstruction step.

00:11:30.830 --> 00:11:33.380
Let’s examine the dereferencing tree.

00:11:33.920 --> 00:11:37.930
Here, we show the dereferencing tree
needed to resolve a visibility

00:11:37.960 --> 00:11:42.670
buffer pixel back to the original
interpolated vertex attributes.

00:11:43.090 --> 00:11:46.160
The visibility buffer contains
two barycentric coordinates.

00:11:46.250 --> 00:11:49.500
The third coordinate can be
retrieved from the other two since

00:11:49.500 --> 00:11:51.380
the sum of all three is unity.

00:11:52.120 --> 00:11:55.950
It also contains a combination
of the draw ID and primitive

00:11:55.950 --> 00:11:57.630
ID as mentioned before.

00:11:57.690 --> 00:12:00.290
From the draw ID,
the draw state can be retrieved,

00:12:00.600 --> 00:12:05.310
allowing access to per draw properties
such as view projection matrix.

00:12:05.650 --> 00:12:07.590
From there,
we can retrieve the vertex and the

00:12:07.700 --> 00:12:09.330
index buffer from the mesh state.

00:12:09.330 --> 00:12:14.130
These indices are needed
to fetch the vertex data.

00:12:14.550 --> 00:12:17.280
And we can also use the
same path to retrieve

00:12:17.280 --> 00:12:19.840
material-specific data that we need.

00:12:20.290 --> 00:12:22.840
Now, if our material model
becomes more complicated,

00:12:22.840 --> 00:12:27.870
we can add a material function pointer
to execute specific material logic.

00:12:28.920 --> 00:12:33.340
Let’s take a look at how
reconstruction looks in shader code.

00:12:33.340 --> 00:12:35.910
The first thing to do in your
reconstruction function is

00:12:35.910 --> 00:12:39.580
to retrieve the primitive ID,
draw ID, and barycentric coordinates

00:12:39.580 --> 00:12:41.400
from the visibility buffer.

00:12:41.650 --> 00:12:44.160
After that,
you can proceed to retrieve the mesh

00:12:44.160 --> 00:12:46.520
ID from the draw state using the draw ID.

00:12:46.520 --> 00:12:51.610
The index buffer needs to be
dereferenced to retrieve the vertex

00:12:51.610 --> 00:12:56.090
indices within the vertex buffers
using primitive ID and mesh ID.

00:12:56.430 --> 00:12:59.650
Then, the vertex buffer data can be
read and interpolated across

00:12:59.690 --> 00:13:02.160
barycentric coordinates.

00:13:02.530 --> 00:13:05.340
Additionally,
matrices and other ProDraw info

00:13:05.340 --> 00:13:09.440
can be retrieved to do deferred
vertex transformations on geometry

00:13:09.480 --> 00:13:12.200
such as normals and tangents.

00:13:12.990 --> 00:13:15.100
Once the material input
has been generated,

00:13:15.240 --> 00:13:18.430
the data is fed into the material
logic and lighting functions

00:13:18.530 --> 00:13:20.860
as discussed previously.

00:13:20.960 --> 00:13:24.540
Let’s take a look at
Visibility Buffer in action.

00:13:25.450 --> 00:13:28.110
Here’s a modern rendering scene
that is using the visibility

00:13:28.110 --> 00:13:30.300
buffer running on the iPhone.

00:13:30.410 --> 00:13:34.360
It is implementing a tile lighting
technique that makes use of multiple

00:13:34.360 --> 00:13:36.970
materials and a scene filled with lights.

00:13:37.110 --> 00:13:40.240
Normally in classic deferred,
this would have required multiple

00:13:40.280 --> 00:13:43.990
G-Buffer channels such as normal,
albedo, roughness, etc.

00:13:44.250 --> 00:13:46.820
accounting for quite a large G-Buffer.

00:13:46.960 --> 00:13:51.260
But with visibility buffer,
we only need a surface ID and

00:13:51.260 --> 00:13:53.390
barycentric coordinates.

00:13:54.260 --> 00:13:56.780
First, we store the generated
surface identifier,

00:13:56.910 --> 00:14:02.290
visualized here with a brightness and
a hue showing draw ID and primitive ID,

00:14:02.320 --> 00:14:03.410
respectively.

00:14:04.600 --> 00:14:07.510
Second,
we store the barycentric coordinates,

00:14:07.510 --> 00:14:12.370
visualized here, with the red,
green and blue color channels.

00:14:12.610 --> 00:14:15.840
These two properties are enough
to efficiently reconstruct the

00:14:15.840 --> 00:14:20.300
geometry and apply deferred material
shading and lighting models.

00:14:20.910 --> 00:14:24.180
With this technique,
the G buffer size is significantly

00:14:24.180 --> 00:14:28.440
reduced on the A14 using
the thin visibility buffer.

00:14:28.560 --> 00:14:32.270
In our example,
we save more than 40% of our G buffer

00:14:32.270 --> 00:14:34.750
size compared to classic deferred.

00:14:35.130 --> 00:14:40.520
So, that wraps up our deep dive on
barycentric coordinates and primitive ID.

00:14:41.110 --> 00:14:46.670
Now, let’s take a quick look at the new
texture addressing modes in A14.

00:14:46.830 --> 00:14:49.690
These modes specify how to
handle texture coordinates that

00:14:49.850 --> 00:14:53.130
are outside the sampling range,
and are quite handy when

00:14:53.170 --> 00:14:55.330
you’re using Texture Atlas.

00:14:56.130 --> 00:15:00.960
We’ve added two new addressing
modes in Metal for A14.

00:15:00.960 --> 00:15:03.280
With Mirror Clamped to
Edge Addressing mode,

00:15:03.440 --> 00:15:05.870
the texture coordinates within
the range of the extents are

00:15:05.870 --> 00:15:08.760
mirrored across the axis,
and when they fall outside,

00:15:08.760 --> 00:15:10.920
they’re clamped.

00:15:10.920 --> 00:15:13.320
You can see this in the
picture on the right.

00:15:13.320 --> 00:15:17.900
We’ve also added Border Color Clamp mode,
where you can choose one of the

00:15:17.900 --> 00:15:22.860
presets between transparent black,
opaque black and opaque white.

00:15:22.860 --> 00:15:25.430
The usage is fairly simple.

00:15:25.690 --> 00:15:29.800
First, you need to create a
sampler descriptor object.

00:15:29.840 --> 00:15:32.470
Then, you can specify the
clamp modes for depth,

00:15:32.660 --> 00:15:34.470
width,
and height coordinates independently

00:15:34.670 --> 00:15:37.200
by setting the address modes.

00:15:37.230 --> 00:15:40.360
If you’re using clamp-to-border color,
you can set one of the

00:15:40.360 --> 00:15:42.490
presets supported in Metal.

00:15:42.580 --> 00:15:44.870
After this,
you can create the sampler state

00:15:45.150 --> 00:15:47.420
object with the sampler descriptor.

00:15:48.070 --> 00:15:53.590
So, that was an overview of the
new graphics features in A14.

00:15:54.000 --> 00:15:57.100
Now, I would like to hand it off to
my colleague Swami to describe

00:15:57.100 --> 00:16:00.760
the new compute features
that the A14 GPU enables,

00:16:00.760 --> 00:16:03.170
starting with SIMD reduction.

00:16:03.670 --> 00:16:04.740
Thank you, Anaand.

00:16:04.790 --> 00:16:08.840
I am Swaminathan Narayanan,
and I work for GPU Software.

00:16:08.910 --> 00:16:12.350
Metal is designed to enable
high-performance graphics as well as

00:16:12.410 --> 00:16:16.850
to perform data parallel calculations,
and it provides a variety of advanced

00:16:16.950 --> 00:16:20.920
compute features that leverage
the tremendous power of the GPU.

00:16:20.970 --> 00:16:23.850
On the A14 Bionic,
Metal now provides SIMD scope

00:16:23.940 --> 00:16:27.730
reduction instructions,
which provide a way for apps to perform

00:16:27.730 --> 00:16:30.670
reductions incredibly efficiently.

00:16:31.360 --> 00:16:35.100
To understand how they work,
let’s briefly review parallel

00:16:35.100 --> 00:16:36.780
reduction operations.

00:16:36.780 --> 00:16:39.750
Reduction operations are used
to reduce the elements of

00:16:39.830 --> 00:16:41.500
an array to a single result.

00:16:41.500 --> 00:16:44.320
For example,
a sum reduction is used to add

00:16:44.320 --> 00:16:46.740
up all the elements of an array.

00:16:46.740 --> 00:16:49.740
This can be useful for
computing averages.

00:16:49.790 --> 00:16:53.290
Another example is to compute
the min and max values of a seam.

00:16:53.500 --> 00:16:57.970
Those values can then be used
in tone mapping algorithms.

00:16:57.980 --> 00:17:03.360
Classically, all these operations were
computed severely on the CPU.

00:17:03.600 --> 00:17:08.330
However, Metal can take advantage of the
parallel nature of the GPU to compute

00:17:08.330 --> 00:17:11.170
reductions much more efficiently.

00:17:12.090 --> 00:17:15.390
On the A14 GPU,
Metal now supports several

00:17:15.400 --> 00:17:18.140
SIMD-scope reduction instructions.

00:17:18.650 --> 00:17:22.780
SIMD sum and SIMD product generate
the sum and product of a variable

00:17:22.940 --> 00:17:25.760
across all sets in the SIMD group.

00:17:26.690 --> 00:17:32.200
SIMD minimum and SIMD maximum can be used
to find the minimum and maximum values.

00:17:32.240 --> 00:17:36.960
These four instructions work on
floating point and integer types.

00:17:38.250 --> 00:17:40.990
In addition,
Metal now supports reductions

00:17:40.990 --> 00:17:43.850
using bitwise operators AND,
OR and XOR.

00:17:43.850 --> 00:17:47.860
Naturally,
these work only on integer types.

00:17:48.020 --> 00:17:51.060
Before going over the reduction
operations in more detail,

00:17:51.250 --> 00:17:55.820
let’s look at how threads are organized
into thread groups and SIMD groups.

00:17:56.970 --> 00:18:00.930
Compute Dispatches launch a
set of individual threads that

00:18:00.930 --> 00:18:02.750
are represented as a grid.

00:18:03.390 --> 00:18:06.750
This grid of threads are
divided into smaller subgrids

00:18:06.750 --> 00:18:08.670
that are called thread groups.

00:18:09.390 --> 00:18:13.220
Thread groups are further
organized into groups of 32 threads

00:18:13.220 --> 00:18:15.050
that are called SIMD groups.

00:18:15.150 --> 00:18:18.960
The threads of a SIMD group
run concurrently in lockstep.

00:18:19.220 --> 00:18:22.980
SIMD group functions exploit
this lockstep execution to

00:18:22.980 --> 00:18:25.170
share data between its threads.

00:18:25.550 --> 00:18:28.910
Now that we’ve seen how SIMD groups
and Thread groups are organized,

00:18:29.110 --> 00:18:33.140
let’s take a look at how Threads
are executed in SIMD groups.

00:18:34.250 --> 00:18:39.170
The SIMD group has 32 lanes that are
represented down the left side here.

00:18:39.170 --> 00:18:43.090
Each of these lanes will run a
thread from the compute dispatch.

00:18:43.550 --> 00:18:46.510
Now, let’s have all the threads
in the SIMD group store their

00:18:46.510 --> 00:18:48.560
lane IDs into the variable x.

00:18:49.330 --> 00:18:53.090
Notice how each lane
has its own value of x.

00:18:54.150 --> 00:18:58.550
In the SIMD Group execution model,
the instruction that sets the variable

00:18:58.550 --> 00:19:03.140
x to the lane ID is only fetched once
and is then executed simultaneously

00:19:03.140 --> 00:19:05.640
in log step by the 32 threads.

00:19:05.750 --> 00:19:09.260
SIMD Group functions allow each
of its threads to inspect and use

00:19:09.260 --> 00:19:13.550
variables of the other threads in
the SIMD Group with minimal overhead.

00:19:13.740 --> 00:19:19.030
Let’s take a look at SIMD-SUM,
one of the new instructions added in A14.

00:19:20.440 --> 00:19:24.370
SIMD sum adds up values of a
variable across all active threads

00:19:24.370 --> 00:19:28.860
in the SIMD group and broadcasts
the sum back to all the threads.

00:19:28.860 --> 00:19:32.280
Here we are adding the values
of the variable x across the

00:19:32.280 --> 00:19:34.150
32 lanes of the SIMD group.

00:19:34.580 --> 00:19:38.470
Once the instruction is executed,
the resulting sum is then

00:19:38.470 --> 00:19:40.380
available in the variable f.

00:19:40.830 --> 00:19:44.510
Note that all active threads can
inspect their copy of the variable

00:19:44.630 --> 00:19:48.180
f to get at the computed sum of 496.

00:19:48.590 --> 00:19:51.540
Inactive threads are skipped
in the computation correctly.

00:19:51.680 --> 00:19:54.350
They do not contribute to the final sum.

00:19:55.480 --> 00:19:58.740
Now let’s take a look at how we
can use SIMDsum to speed up adding

00:19:58.740 --> 00:20:00.900
the elements of a large array.

00:20:01.040 --> 00:20:04.100
Here the input array is in device memory.

00:20:04.450 --> 00:20:08.580
Each SIMD group reads a sub-region
of the input array and computes its

00:20:08.580 --> 00:20:11.500
sum using the SIMD Summon function.

00:20:11.630 --> 00:20:15.340
This sum is then written to
an array in Z-group memory.

00:20:15.370 --> 00:20:18.930
Every SIMD group has a distinct
ID that it can use to index

00:20:19.030 --> 00:20:21.390
into the Z-group sum array.

00:20:22.110 --> 00:20:25.770
The last executing SIMD group in
the thread group uses the SIMDsum

00:20:25.770 --> 00:20:28.800
instruction again to get the final sum.

00:20:28.920 --> 00:20:31.290
By using SIMDsum,
we have decreased the number of

00:20:31.470 --> 00:20:34.790
thread group barriers and the
usage of thread group memory.

00:20:34.900 --> 00:20:39.300
The SIMDsum instruction also gets
executed only once to compute the sum

00:20:39.300 --> 00:20:41.700
of all the threads in the SIMD group.

00:20:41.810 --> 00:20:45.290
Now let’s go to the implementation
of the compute kernel.

00:20:45.770 --> 00:20:50.320
Here we have the code that implements
parallel reduction using SIMDsum.

00:20:50.460 --> 00:20:52.800
Each thread in the SIMD group
reads its corresponding

00:20:52.800 --> 00:20:55.600
element from the input array.

00:20:55.770 --> 00:21:00.570
Then it computes a first SIMD group
sum using the SIMDsum instruction.

00:21:01.290 --> 00:21:04.320
This sum is then written to
an array in Z-group memory,

00:21:04.390 --> 00:21:08.220
which is indexed using the SIMD group ID.

00:21:08.220 --> 00:21:12.910
Note that we need a barrier before we
can access the array in Z-group memory.

00:21:13.620 --> 00:21:17.400
The last SIMD group in each thread
group then uses the SIMD sum

00:21:17.400 --> 00:21:19.960
instruction again to get the final sum.

00:21:21.240 --> 00:21:24.860
Let us take a look at the other reduction
operations we have introduced in A14.

00:21:24.860 --> 00:21:29.860
We’ve already seen SIMD sum,
which adds up the values of x

00:21:29.860 --> 00:21:32.550
across all the active lanes.

00:21:32.990 --> 00:21:36.720
Now let’s look at SIMDmax and
apply it to the variable x.

00:21:36.790 --> 00:21:40.220
Early lane then gets the maximum value,
which is 31,

00:21:40.220 --> 00:21:43.010
across all the threads in the SIMD group.

00:21:43.580 --> 00:21:46.590
Similarly,
SIMD Mint stores the minimum value of x,

00:21:46.900 --> 00:21:51.520
which happens to be 0 in this case,
across all the active lanes.

00:21:51.970 --> 00:21:56.380
Finally, we have SIMD product,
which multiplies up all the values of x.

00:21:56.420 --> 00:21:58.780
As one of the variables
happens to be zero,

00:21:58.780 --> 00:22:01.960
the final product that
is broadcast is zero.

00:22:02.010 --> 00:22:05.390
These instructions work on
both integer and floating

00:22:05.390 --> 00:22:07.380
point scalar and vector types.

00:22:08.170 --> 00:22:13.810
Reduction operations are also supported
for bitwise operations on integral types.

00:22:13.810 --> 00:22:17.760
Each lane now has a bitfield
value manufactured using

00:22:17.770 --> 00:22:19.680
the lane ID as shown here.

00:22:20.090 --> 00:22:23.930
We can then use the
SIMD ALL instruction on the variable x.

00:22:24.070 --> 00:22:28.040
The values of x across all the
active lanes are all together and

00:22:28.080 --> 00:22:30.700
broadcasted back to the variable f.

00:22:30.770 --> 00:22:35.290
This final value happens
to be 0x1f3 in our example.

00:22:35.750 --> 00:22:39.050
Similarly,
SIMD XOR computes the XOR values of X and

00:22:39.050 --> 00:22:44.550
broadcasts back the resulting value,
which turns out to be 0x0.

00:22:45.080 --> 00:22:48.820
Finally, we have SIMD_AND,
which ANDs up all the values of x across

00:22:49.100 --> 00:22:51.500
all the threads in the SIMD group.

00:22:51.550 --> 00:22:54.660
This turns out to be the constant 0x3.

00:22:55.330 --> 00:22:58.730
That was an overview of the new
SIMD scope reduction instructions

00:22:58.730 --> 00:23:00.340
available in the A14 GPU.

00:23:02.760 --> 00:23:06.850
Now, let’s take a look at a new set of
SIMD scope instructions that greatly

00:23:06.850 --> 00:23:09.610
improves matrix multiplication.

00:23:09.680 --> 00:23:13.240
Matrix multiplication is a very
common operation for GPU compute

00:23:13.570 --> 00:23:17.750
and is the basic building block for
many parallel computing workloads.

00:23:17.910 --> 00:23:22.780
For example, in machine learning,
it is used when computing convolution

00:23:22.890 --> 00:23:25.270
and fully connected neuron layers.

00:23:25.470 --> 00:23:30.280
Linear algebra is used to represent
and solve systems of equations.

00:23:30.280 --> 00:23:34.310
The A14 introduces a brand new
set of SIMD scope instructions,

00:23:34.390 --> 00:23:39.150
which allows you to implement large
matrix multipliers very efficiently.

00:23:39.870 --> 00:23:42.260
Like the reduction
operations we saw before,

00:23:42.450 --> 00:23:44.330
these are SIMD group scoped operations.

00:23:44.340 --> 00:23:48.450
You can now easily build larger,
more sophisticated functions on

00:23:48.450 --> 00:23:50.080
top of these building blocks.

00:23:50.180 --> 00:23:54.500
In the Metal shading language,
we now have SIMD group

00:23:54.500 --> 00:23:58.580
scoped data structures that
represent 8x8 and 4x4 matrices.

00:23:58.580 --> 00:24:03.570
You can then use multiply or
multiply accumulate versions of the

00:24:03.580 --> 00:24:05.770
SIMD group scoped matrix operations.

00:24:05.860 --> 00:24:11.150
Let’s look at an example of
multiplying through 16x16 matrices

00:24:11.150 --> 00:24:13.780
in a Z-group using these functions.

00:24:14.580 --> 00:24:19.260
We’re going to use the 8x8 SIMD group
matrix operation to build a 16x16

00:24:19.270 --> 00:24:22.170
clear group matrix multiplication.

00:24:22.410 --> 00:24:26.360
First, we partition the result matrix
across four SIMD groups.

00:24:26.360 --> 00:24:32.050
Each SIMD group will be responsible for
computing one 8x8 quadrant of the result.

00:24:32.290 --> 00:24:35.070
Next,
we partition the first input matrix.

00:24:35.210 --> 00:24:39.770
Here, each SIMD group in a row
shares a single block column.

00:24:40.100 --> 00:24:42.440
Then, we partition the second input.

00:24:42.580 --> 00:24:47.030
Here, each SIMD group in a column
shares a single block row.

00:24:47.570 --> 00:24:50.870
Then we will accumulate the
products from the first set

00:24:50.870 --> 00:24:53.640
of 8x8 results and the second.

00:24:53.700 --> 00:24:57.380
Now let's look at how to write
this in the Metal shading language.

00:24:57.440 --> 00:25:00.810
With A14,
we have introduced new SIMD group matrix

00:25:00.810 --> 00:25:05.020
objects and multiplication operations
into the Metal shading language.

00:25:05.090 --> 00:25:08.620
These new parameters will greatly
improve the performance of your

00:25:08.620 --> 00:25:11.000
matrix multiplications in your shader.

00:25:11.060 --> 00:25:15.840
It's easy to use and can be done
with just a few lines of shader code.

00:25:16.370 --> 00:25:20.340
Here we define three objects to
represent 8x8 matrices with data

00:25:20.340 --> 00:25:23.100
in 32-bit loading point format.

00:25:23.100 --> 00:25:27.520
We have a matrix for each of our
inputs and one for our result.

00:25:28.000 --> 00:25:31.780
Next, we perform the address arithmetic
necessary to partition our

00:25:31.780 --> 00:25:35.630
four SIMD groups across
each quadrant of the result.

00:25:35.760 --> 00:25:39.140
Then we accumulate sub-matrices
from each source matrix,

00:25:39.260 --> 00:25:43.510
broadcasting the appropriate row
and column to each SIMD group.

00:25:43.980 --> 00:25:46.430
Finally, we store the results.

00:25:46.490 --> 00:25:50.110
You can see how easy it is to
construct more complex shaders

00:25:50.110 --> 00:25:52.280
using these new primitives.

00:25:52.910 --> 00:25:55.040
If you are using
Metal performance heaters,

00:25:55.220 --> 00:25:59.450
you will benefit from SIMD group
scope matrix multipliers to accelerate

00:25:59.450 --> 00:26:04.040
not only matrix multiplication
but also CNN convolutions.

00:26:04.110 --> 00:26:08.180
Matrix multiplication for
arbitrary sizes can be performed

00:26:08.180 --> 00:26:10.520
using MPS matrix multiplication.

00:26:10.840 --> 00:26:15.940
Here we are encoding a kernel to compute
a result with M rows and M columns.

00:26:16.260 --> 00:26:21.080
CNN convolutions can be performed
using MPS-CNN convolution.

00:26:21.160 --> 00:26:25.400
Here we are encoding a convolution
kernel or a batch of images.

00:26:25.450 --> 00:26:30.160
Both of these kernels are available
using the new Metal Performance Shaders

00:26:30.160 --> 00:26:32.960
Graph introduced this year with iOS 14.

00:26:33.570 --> 00:26:37.500
MPS Graph allows you to take these
basic kernels and build complex

00:26:37.530 --> 00:26:39.020
machine learning networks with them.

00:26:39.020 --> 00:26:42.220
As an example,
let’s look at how the matrix

00:26:42.220 --> 00:26:46.610
multiplication kernel from
earlier can be used in the graph.

00:26:46.860 --> 00:26:49.420
Here, we’ll initialize a new
graph for our operation.

00:26:49.420 --> 00:26:55.180
Then we define nodes to
represent our two input matrices.

00:26:55.320 --> 00:26:58.980
Then we construct a new result
node from our input using a

00:26:58.980 --> 00:27:01.410
matrix multiplication operation.

00:27:02.210 --> 00:27:04.600
Finally, we execute the graph.

00:27:04.710 --> 00:27:08.510
For more details on how to use
MPS kernels and graph operations,

00:27:08.740 --> 00:27:13.180
please refer to previously
available WWDC presentations.

00:27:13.240 --> 00:27:17.520
As mentioned before,
MPS will automatically take advantage

00:27:17.730 --> 00:27:19.890
of A14 for these operations.

00:27:23.090 --> 00:27:26.750
Here we can see the improved
throughput of general matrix

00:27:26.760 --> 00:27:30.100
multiplications on A14 relative to A13.

00:27:30.420 --> 00:27:34.370
On A14, using the new SIMD group
matrix multiplier operations,

00:27:34.720 --> 00:27:38.530
average performance is improved by 37%.

00:27:38.770 --> 00:27:45.910
CNN conclusions on A14 show an
average improvement of 36% from A13.

00:27:45.910 --> 00:27:48.570
And when we look at training
a full machine learning

00:27:48.920 --> 00:27:54.840
network like Inception V3,
A14 improves by 22%. That wraps up

00:27:54.840 --> 00:27:57.100
SIMD group scope matrix multiplication.

00:27:58.940 --> 00:28:01.970
Let’s recap the new
Metal features for the A14.

00:28:01.980 --> 00:28:06.150
Baricentric coordinates
and primitive ID enable new

00:28:06.150 --> 00:28:10.800
deferred rendering techniques,
including visibility buffer rendering.

00:28:11.200 --> 00:28:16.740
New texture addressing modes which
are useful when using texture atlases.

00:28:16.740 --> 00:28:20.540
SIMD group scope reduction
instructions that enable better

00:28:20.540 --> 00:28:22.680
communication between threads.

00:28:22.860 --> 00:28:25.870
We also include compute and
machine learning performance

00:28:26.200 --> 00:28:30.090
with SIMD Group Scope
Matrix Multiply instructions.

00:28:30.150 --> 00:28:33.360
And finally,
Metal on A14 takes advantage of a

00:28:33.360 --> 00:28:37.100
host of architectural improvements,
saving bandwidth with

00:28:37.100 --> 00:28:41.580
improved lossless compression,
faster and more efficient local memory,

00:28:41.650 --> 00:28:44.580
and better GPU-driven pipelines.

00:28:44.660 --> 00:28:45.580
Thank you for watching.