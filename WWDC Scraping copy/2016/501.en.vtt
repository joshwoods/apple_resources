WEBVTT

00:00:08.516 --> 00:00:17.500
[ Music ]

00:00:23.216 --> 00:00:24.276
>> Good morning.

00:00:25.666 --> 00:00:27.896
Morning everyone and
welcome to session 501.

00:00:28.526 --> 00:00:29.466
I'm Brad Ford.

00:00:29.686 --> 00:00:30.816
I work on the Core Media

00:00:30.816 --> 00:00:32.986
and AV Foundation
Capture Teams at Apple.

00:00:34.726 --> 00:00:37.206
And this session is all
about the iOS camera.

00:00:37.416 --> 00:00:38.836
Hopefully you've
figured that out by now.

00:00:38.986 --> 00:00:41.366
This is the most popular
camera in the world.

00:00:41.536 --> 00:00:43.616
And it's also about photography.

00:00:43.866 --> 00:00:47.316
If you develop a photography
app, or even just thinking

00:00:47.316 --> 00:00:48.856
about developing
a photography app,

00:00:49.276 --> 00:00:51.366
then this is a very
good OS for you.

00:00:51.506 --> 00:00:54.666
I think you and iOS 10 are
about to become fast friends.

00:00:55.666 --> 00:00:58.196
Today we'll be focusing on
the AV Foundation framework,

00:00:58.306 --> 00:01:01.336
which is our lowest level
and most powerful framework

00:01:01.336 --> 00:01:02.446
for accessing the camera.

00:01:02.446 --> 00:01:05.025
AV Foundation is broad and deep.

00:01:05.316 --> 00:01:08.016
If you're new to camera
capture on iOS, I invite you

00:01:08.016 --> 00:01:12.376
to review our past WWC camera
presentation videos listed here.

00:01:13.076 --> 00:01:16.046
They give you a good base for
today's presentation and plus,

00:01:16.046 --> 00:01:17.636
you get to watch
me age gracefully.

00:01:18.116 --> 00:01:22.086
Here's what we're going to
do for the next 58 minutes.

00:01:22.876 --> 00:01:26.006
I'll present a brand
new AVCaptureOutput

00:01:26.206 --> 00:01:29.166
for capturing photographic
content, and then we're going

00:01:29.166 --> 00:01:30.986
to focus on four feature areas.

00:01:30.986 --> 00:01:34.096
We're going to focus
on Live Photos.

00:01:34.266 --> 00:01:36.166
You'll learn how to capture
Live Photos in your app,

00:01:36.426 --> 00:01:38.106
just like Apple's camera app.

00:01:38.916 --> 00:01:41.976
You'll learn how to capture
bare RAW images and store them

00:01:41.976 --> 00:01:45.236
to DNG files, which is a
first on our platform in iOS.

00:01:46.146 --> 00:01:47.636
You'll learn about
how to get preview

00:01:47.636 --> 00:01:51.006
or thumbnail images along with
your regular photo captures

00:01:51.006 --> 00:01:52.286
for a more responsive UI.

00:01:53.766 --> 00:01:56.196
And lastly, you'll learn
how to capture gorgeous,

00:01:56.256 --> 00:01:58.416
vivid images in wide color.

00:01:58.976 --> 00:01:59.676
Let's get started.

00:02:00.476 --> 00:02:01.436
Here's a quick refresher

00:02:01.436 --> 00:02:03.716
on how AV Foundation's
capture classes work.

00:02:04.216 --> 00:02:06.216
At the center of our
capture universe is

00:02:06.216 --> 00:02:07.636
the AVCaptureSession.

00:02:08.106 --> 00:02:10.795
This is the object you tell
it to start or stop running.

00:02:11.466 --> 00:02:14.776
In order to do anything useful,
though, it needs some inputs.

00:02:14.776 --> 00:02:17.066
Inputs like a camera
or a microphone.

00:02:17.476 --> 00:02:19.476
And they provide
data to the session.

00:02:19.746 --> 00:02:22.086
And it also needs outputs
to receive the data,

00:02:22.476 --> 00:02:25.686
such as a StillImageOutput
which can capture still images

00:02:26.036 --> 00:02:27.796
or a QuickTime movie
file output,

00:02:27.866 --> 00:02:29.316
which records QuickTime movies.

00:02:30.156 --> 00:02:34.736
There are also connections, and
these are represented in the API

00:02:34.876 --> 00:02:36.506
as AVCaptureConnections.

00:02:36.866 --> 00:02:38.496
That's our overall object graph.

00:02:38.496 --> 00:02:40.866
You've kind of seen how we
all put things together.

00:02:42.006 --> 00:02:43.596
All of these features,
I just mentioned,

00:02:43.596 --> 00:02:45.076
relate to taking still images.

00:02:45.076 --> 00:02:47.516
So we might expect that we'd
be spending a lot of time

00:02:47.516 --> 00:02:51.586
in the AVCaptureStillImageOutput
today but you'd be wrong.

00:02:53.196 --> 00:02:56.696
Today we're introducing a brand
new CaptureOutput in iOS 10.

00:02:56.696 --> 00:02:58.966
And it's called the
AVCapturePhotoOutput,

00:02:59.406 --> 00:03:01.936
emphasizing the fact that
our photos are much more

00:03:01.936 --> 00:03:03.416
than static still images now.

00:03:04.496 --> 00:03:09.236
AVCapturePhotoOutput addresses
AVStillImageOutput's design

00:03:09.236 --> 00:03:11.736
challenges in four main areas.

00:03:12.446 --> 00:03:14.906
It features a functional
programming model.

00:03:15.196 --> 00:03:16.476
There are clear delineations

00:03:16.476 --> 00:03:18.546
between mutable and
immutable data.

00:03:19.456 --> 00:03:21.236
We've encapsulated
photo settings

00:03:21.236 --> 00:03:23.636
into a distinct object
unto itself.

00:03:24.556 --> 00:03:27.846
And the PhotoOutput can
track your photo's progress

00:03:27.846 --> 00:03:29.186
from request to completion

00:03:29.506 --> 00:03:32.196
through a delegate-style
interface of callbacks.

00:03:32.726 --> 00:03:36.456
And lastly, it resolves your
indeterminate photo settings

00:03:36.456 --> 00:03:37.896
early in the capture process,

00:03:38.166 --> 00:03:39.716
so you know what you're
going to be getting.

00:03:39.776 --> 00:03:42.916
Let's talk a little bit more
about that last feature there.

00:03:44.276 --> 00:03:46.356
Here's what an
AVCapturePhotoOutput looks like.

00:03:46.666 --> 00:03:49.736
Even with all its new features,
it's a very thin interface,

00:03:49.826 --> 00:03:52.536
smaller even than
AVCaptureStillImageOutput.

00:03:52.976 --> 00:03:55.236
It has a small set of
read-only properties

00:03:55.556 --> 00:03:57.896
that tell you whether particular
features are supported,

00:03:58.196 --> 00:04:00.626
such as is
LivePhotoCaptureSupported?

00:04:01.346 --> 00:04:04.536
It has a smaller set of writable
properties that let you opt

00:04:04.536 --> 00:04:07.586
in for particular
features when supported.

00:04:07.766 --> 00:04:10.876
Some capture features affect how
the capture render pipeline is

00:04:10.876 --> 00:04:13.716
built, so you have to
specify them upfront.

00:04:14.126 --> 00:04:16.216
One such is
HighResolutionCapture.

00:04:16.286 --> 00:04:18.995
If you ever intend to capture
high-resolution photos,

00:04:18.995 --> 00:04:23.486
such as five-megapixel
selfies on the iPhone 6s,

00:04:24.066 --> 00:04:26.806
you have to opt-in for the
feature first before calling

00:04:26.806 --> 00:04:28.666
startRunning on the
AVCapture Session.

00:04:29.486 --> 00:04:32.806
Lastly, there's a single
method that you can call

00:04:32.936 --> 00:04:34.286
to kick off a photo capture.

00:04:35.056 --> 00:04:35.796
Just one verb.

00:04:35.876 --> 00:04:36.246
That's it.

00:04:36.896 --> 00:04:39.306
Now you're probably asking
yourself, well what happened

00:04:39.306 --> 00:04:40.746
to all the per photo state?

00:04:40.886 --> 00:04:43.356
How do I request
the flash capture?

00:04:43.356 --> 00:04:44.786
How do I get BGRA?

00:04:44.786 --> 00:04:46.496
How do I get still
image stabilization?

00:04:47.386 --> 00:04:49.276
These features and
others have moved

00:04:49.276 --> 00:04:52.456
to a new object called
AVCapturePhotoSettings.

00:04:53.026 --> 00:04:55.356
This object contains all
the settings that pertain

00:04:55.356 --> 00:04:57.946
to one single photo
capture request.

00:04:58.136 --> 00:05:01.666
Think of it like the
list of options to choose

00:05:01.666 --> 00:05:04.966
from when you're buying a MAC
on the Apple online store.

00:05:05.416 --> 00:05:07.436
You fill out the online
form with all the features

00:05:07.436 --> 00:05:10.096
that you want and then you
hit the place order button.

00:05:10.646 --> 00:05:13.496
And placing the order is
like calling capturePhoto,

00:05:13.766 --> 00:05:15.656
passing the
AVCapturePhotoSettings

00:05:15.656 --> 00:05:16.766
as your first parameter.

00:05:17.796 --> 00:05:19.436
Now when you place
an order online,

00:05:19.566 --> 00:05:21.996
the store needs your email
address to communicate

00:05:21.996 --> 00:05:23.316
with you about your order.

00:05:24.376 --> 00:05:26.396
Within AVCapturePhotoOutput's
world,

00:05:26.446 --> 00:05:30.236
the email address you provide
is an object conforming

00:05:30.236 --> 00:05:33.476
to AVCapturePhotoCaptureDelegate
protocol.

00:05:34.056 --> 00:05:36.716
This delegate gets called
back as events related

00:05:36.716 --> 00:05:38.336
to your photo capture occur.

00:05:39.016 --> 00:05:41.406
This object gets passed
as your second parameter

00:05:41.406 --> 00:05:42.276
to CapturePhoto.

00:05:43.686 --> 00:05:46.146
Okay, so what's good about
AVCapturePhotoSettings?

00:05:46.526 --> 00:05:48.326
First of all, they are atomic.

00:05:48.856 --> 00:05:51.736
All settings are
encapsulated in a single object.

00:05:52.026 --> 00:05:54.996
There's no potential for
settings getting out of sync

00:05:55.496 --> 00:05:58.456
because they are not properties
of the AVCapturePhotoOutput,

00:05:58.656 --> 00:06:00.816
but rather, a per-settings
object.

00:06:01.396 --> 00:06:02.036
They're unique.

00:06:02.636 --> 00:06:05.966
Each photo settings instance
has a unique ID property.

00:06:06.356 --> 00:06:09.136
You're only allowed to use
one photo settings once

00:06:09.376 --> 00:06:10.166
and never again.

00:06:10.406 --> 00:06:13.186
So you'll receive
exactly one set of results

00:06:13.186 --> 00:06:14.996
for each photo capture request.

00:06:16.836 --> 00:06:19.716
After requesting a photo
capture with a set of settings,

00:06:19.716 --> 00:06:22.666
you can hold onto it and
validate results against it

00:06:22.666 --> 00:06:23.686
as they're returned to you.

00:06:23.746 --> 00:06:26.206
Sort of like making a
copy of your order form,

00:06:26.206 --> 00:06:27.346
your online order form.

00:06:28.666 --> 00:06:30.836
So then, what's good
about the photo delegates?

00:06:31.776 --> 00:06:33.526
Well, it's a single
set of callbacks.

00:06:33.556 --> 00:06:35.896
Again, per photo settings.

00:06:36.696 --> 00:06:38.076
The ordering is documented.

00:06:38.146 --> 00:06:39.966
You know exactly which
callbacks you're going to get

00:06:39.966 --> 00:06:41.766
and at what time
and in what order.

00:06:42.436 --> 00:06:45.386
And it's a vehicle for resolving
indeterminate settings.

00:06:45.846 --> 00:06:48.246
That one I think I need to
explain a little bit more.

00:06:48.876 --> 00:06:51.756
Let's say your app requests
the photo right here

00:06:51.886 --> 00:06:54.016
on this timeline.

00:06:54.366 --> 00:06:56.936
You've specified photo
settings with auto flash

00:06:57.186 --> 00:06:59.446
and auto still image
stabilization.

00:06:59.566 --> 00:07:01.996
I shortened still image
stabilization to SIS

00:07:01.996 --> 00:07:03.876
so it would fit on
the slide better.

00:07:04.096 --> 00:07:08.006
You're telling the PhotoOutput
I want you to use flash or SIS

00:07:08.006 --> 00:07:09.566
but only if you need to, only

00:07:09.566 --> 00:07:10.776
if they're appropriate
for the scene.

00:07:11.926 --> 00:07:14.286
So very soon after
you make the request,

00:07:14.386 --> 00:07:16.886
the PhotoOutput calls your
delegates first callback,

00:07:17.156 --> 00:07:19.916
which is willBegin
CaptureFor ResolvedSettings.

00:07:20.506 --> 00:07:23.316
This callback is always,
always, always called first.

00:07:23.646 --> 00:07:25.486
It's sort of like the
courtesy email you get

00:07:25.486 --> 00:07:28.076
from Apple saying we've
received your order.

00:07:28.516 --> 00:07:29.716
Here's what we'll
be sending you.

00:07:30.376 --> 00:07:32.366
The callback passes
you an instance

00:07:32.366 --> 00:07:36.886
of a new object called
AVCapturePhotoResolvedSettings.

00:07:37.546 --> 00:07:39.946
It's just like the photo
settings you filled out,

00:07:39.946 --> 00:07:41.576
except now everything
is resolved.

00:07:42.586 --> 00:07:43.996
They have the same unique ID.

00:07:43.996 --> 00:07:45.746
Your unresolved version

00:07:45.746 --> 00:07:47.796
and resolved version
share a unique ID,

00:07:47.796 --> 00:07:49.026
so you compare them together.

00:07:49.496 --> 00:07:52.396
It also tells you what features
the photo output picked for you.

00:07:52.866 --> 00:07:55.806
So notice, in this case,
flash has been resolved to on

00:07:56.246 --> 00:07:57.926
and SIS has been
resolved to off.

00:07:58.106 --> 00:08:00.136
So clearly we're in a
very low light situation

00:08:00.136 --> 00:08:01.116
such as this conference room.

00:08:01.506 --> 00:08:04.576
Next comes willCapture
PhotoFor ResolvedSettings.

00:08:04.996 --> 00:08:07.466
It's delivered right when
the photo is being taken,

00:08:07.726 --> 00:08:10.376
or like when the virtual
camera shudder is closing

00:08:10.716 --> 00:08:12.276
and the shudder sound
is being played.

00:08:12.276 --> 00:08:15.286
If you want to perform some
sort of a shudder animation,

00:08:15.286 --> 00:08:16.916
this is the appropriate
time to do it.

00:08:17.906 --> 00:08:20.946
And then shortly thereafter
comes didCapture PhotoFor

00:08:20.946 --> 00:08:23.896
ResolvedSettings, just after
the image has been fully exposed

00:08:23.896 --> 00:08:26.146
and read out, and the
virtual shudder opens.

00:08:27.486 --> 00:08:29.276
Then some time has to pass

00:08:29.276 --> 00:08:31.046
because the image
is being processed,

00:08:31.046 --> 00:08:32.765
applying all the features
that you asked for.

00:08:33.416 --> 00:08:34.976
And when the photo
is finally ready,

00:08:35.186 --> 00:08:37.515
you get the
didProcessingPhotoSampleBuffer

00:08:37.515 --> 00:08:40.726
callback, along with an
ImageSampleBuffer you've been

00:08:40.726 --> 00:08:41.246
waiting for.

00:08:41.246 --> 00:08:43.876
So, yay. It's like getting the
shiny new MAC on your doorstep.

00:08:44.716 --> 00:08:48.336
And finally, you get
the didFinish CaptureFor

00:08:48.336 --> 00:08:49.576
ResolvedSettings callback,

00:08:49.576 --> 00:08:51.516
which is guaranteed
to be delivered last.

00:08:52.426 --> 00:08:54.016
It's like the follow-up
email that you get

00:08:54.016 --> 00:08:57.236
from Apple saying all your
packages have been delivered.

00:08:57.236 --> 00:08:59.076
A pleasure doing business
with you over and out.

00:08:59.796 --> 00:09:02.886
This is a good time to clean up
any of your per-photo storage.

00:09:04.196 --> 00:09:06.976
So let's talk about those
delegates in specifics.

00:09:07.526 --> 00:09:10.556
The callbacks track a single
photo capture request.

00:09:11.466 --> 00:09:14.926
The photo output holds a weak
reference to your delegate,

00:09:14.966 --> 00:09:17.176
so it will not keep that
object alive for you.

00:09:17.676 --> 00:09:19.966
Remember to keep a strong
reference to it in your code.

00:09:20.806 --> 00:09:24.026
All the callbacks in this
protocol are marked optional,

00:09:24.406 --> 00:09:26.466
but some of them become
required at runtime,

00:09:26.466 --> 00:09:27.786
depending on your
photo settings.

00:09:27.786 --> 00:09:30.526
For instance, when you're
capturing a compressed run

00:09:30.526 --> 00:09:32.396
compressed photo,
your delegate has

00:09:32.396 --> 00:09:34.976
to implement the one callback
where you get the photo.

00:09:35.256 --> 00:09:37.356
Otherwise, we would have
nowhere to deliver it.

00:09:38.016 --> 00:09:39.266
The rules are clearly spelled

00:09:39.266 --> 00:09:41.516
out in the
AVCapturePhotoOutput.h

00:09:41.516 --> 00:09:42.076
headerDoc.

00:09:43.236 --> 00:09:45.016
All callbacks pass an instance

00:09:45.016 --> 00:09:47.286
of that nice
ResolvedPhotoSettingsObject I

00:09:47.286 --> 00:09:47.946
talked to you about.

00:09:47.946 --> 00:09:48.876
So you always know what you're

00:09:48.876 --> 00:09:49.976
about to get or what
you just got.

00:09:53.936 --> 00:09:56.566
So speaking of settings, let's
look at some code showing how

00:09:56.566 --> 00:09:57.846
to initiate photo captures

00:09:57.846 --> 00:10:00.446
with various
AVCapturePhotoSettings features.

00:10:01.236 --> 00:10:03.676
Okay, the first one,
takeHighResolutionPhoto,

00:10:04.266 --> 00:10:06.036
as I said before, the
front facing camera

00:10:06.036 --> 00:10:10.316
on iPhone 6s supports
five-megapixel high resolution

00:10:10.316 --> 00:10:13.526
selfies, but it can't
stream at five megapixels.

00:10:13.586 --> 00:10:15.826
It can only do individual
high res stills.

00:10:16.486 --> 00:10:19.196
So you have to create
a PhotoSettingsObject,

00:10:19.456 --> 00:10:23.246
opting in for the HighResolution
Photo CaptureEnabled.

00:10:23.596 --> 00:10:26.626
This gives you the
default constructor,

00:10:26.626 --> 00:10:29.056
AVCapturePhotoSettings,
with friends.

00:10:29.636 --> 00:10:33.016
And then, by default, it sets
the output format to JPEG

00:10:33.016 --> 00:10:35.526
and opts you in for still
image stabilization.

00:10:36.436 --> 00:10:38.436
I then set
isHighResolutionPhotoEnabled

00:10:38.436 --> 00:10:40.666
to true and then
call CapturePhoto.

00:10:41.556 --> 00:10:45.866
In the second example,
takeFlashPhoto.

00:10:45.866 --> 00:10:47.786
Notice that the flashMode
is now a property

00:10:47.786 --> 00:10:48.946
of the settings object.

00:10:48.946 --> 00:10:50.836
If you've worked with
StillImageOutput in the past,

00:10:50.836 --> 00:10:54.346
you'll know that Flash was
part of the AVCapture device,

00:10:54.666 --> 00:10:55.986
so we had a problem
there that you had

00:10:55.986 --> 00:10:58.866
to access two different objects
in order to set settings.

00:10:58.996 --> 00:11:01.686
Here, it's all part of
one single atomic object.

00:11:02.076 --> 00:11:06.776
Nice. The final sample here
uses a more complex constructor

00:11:06.776 --> 00:11:08.206
of AVCapturePhotoSettings.

00:11:08.206 --> 00:11:11.986
This time we're going to pass
the output format that we want.

00:11:11.986 --> 00:11:14.536
In this case, we want an
uncompressed BGRA format.

00:11:14.906 --> 00:11:17.826
So we make a dictionary of
CV pixel buffer attributes

00:11:18.356 --> 00:11:19.686
and then pass it

00:11:19.686 --> 00:11:22.666
as the parameter
AVCapturePhotoSettings,

00:11:23.096 --> 00:11:23.806
and we're good to go.

00:11:24.496 --> 00:11:26.146
Now when you call capturePhoto,

00:11:26.496 --> 00:11:28.796
AVCapturePhotoOutput will
validate your settings

00:11:28.796 --> 00:11:31.006
and make sure you haven't
asked for crazy stuff.

00:11:31.006 --> 00:11:34.706
It'll ensure self-consistency,
and it'll ensure that the stuff

00:11:34.706 --> 00:11:36.406
that you've asked for
is actually supported.

00:11:36.696 --> 00:11:38.586
And if it's not, it
will throw an exception.

00:11:40.416 --> 00:11:44.096
Result settings, as you might
expect, are entirely immutable.

00:11:44.366 --> 00:11:45.916
All the properties
are read-only.

00:11:46.076 --> 00:11:47.656
They're purely for
your information.

00:11:47.926 --> 00:11:50.466
Again, this is the functional
programming immutable part.

00:11:51.066 --> 00:11:53.076
It has a unique ID
that you compare

00:11:53.076 --> 00:11:55.186
with the unresolved settings
object that you have.

00:11:55.706 --> 00:11:56.666
This is kind of a nice feature.

00:11:56.666 --> 00:11:58.696
It tells you the dimensions
of the photo you're going

00:11:58.696 --> 00:12:00.106
to get before you get it.

00:12:00.636 --> 00:12:03.476
So you can plan, do
some allocations,

00:12:03.476 --> 00:12:04.526
whatever you need to do.

00:12:05.656 --> 00:12:08.466
It tells you whether it was
resolved to flash on or off.

00:12:08.826 --> 00:12:10.896
And still image stabilization
on or off.

00:12:12.166 --> 00:12:14.516
It also supports
bracketed capture.

00:12:14.856 --> 00:12:16.386
It's a specialized
type of capture

00:12:16.386 --> 00:12:18.256
where you request
a number of images,

00:12:18.476 --> 00:12:20.476
sometimes with differing
exposure values.

00:12:20.846 --> 00:12:22.396
This might be done, for
instance, if you wanted

00:12:22.396 --> 00:12:25.026
to fuse differently
exposed images together

00:12:25.336 --> 00:12:28.736
to produce an effect
such as an HDR effect.

00:12:28.736 --> 00:12:30.166
I spoke at length
about these kinds

00:12:30.166 --> 00:12:32.846
of captures in 2014 Session 508.

00:12:33.566 --> 00:12:35.526
Go check that video
out for a refresher.

00:12:36.286 --> 00:12:38.486
As with
AVCaptureStillImageOutput,

00:12:38.686 --> 00:12:40.876
we support auto exposure
brackets

00:12:41.036 --> 00:12:43.016
and custom exposure brackets.

00:12:43.856 --> 00:12:47.016
But the new way to request
a bracketed capture is

00:12:47.016 --> 00:12:50.876
to instantiate an
AVCapturePhotoBracketSettings.

00:12:51.006 --> 00:12:53.146
So it's like the photo
settings but it's a subclass,

00:12:53.146 --> 00:12:54.806
and it has the extra
stuff that you would need

00:12:54.806 --> 00:12:56.416
for doing a bracketed capture.

00:12:57.286 --> 00:13:01.046
When you create one of
these you specify an array

00:13:01.286 --> 00:13:03.496
of AVCapture BracketedStill
ImageSettings.

00:13:03.496 --> 00:13:05.206
This is an existing object

00:13:05.206 --> 00:13:07.546
from the
AVCaptureStillImageOutput days.

00:13:08.266 --> 00:13:10.306
You specify one of
these per exposure.

00:13:10.306 --> 00:13:14.886
For instance, -2EV, +2EV, 0EV.

00:13:15.586 --> 00:13:18.976
Also, if you're on
an iPhone 6+ or 6s+,

00:13:18.976 --> 00:13:22.416
you can optionally enable
lens stabilization using the

00:13:22.416 --> 00:13:24.176
isLensStabilizationEnabled
property.

00:13:24.696 --> 00:13:26.866
So you recall the
timeline I just showed you

00:13:26.866 --> 00:13:28.836
on the previous slide, where
the photo was delivered

00:13:28.836 --> 00:13:31.946
to didFinish ProcessingPhoto
SampleBuffer callback.

00:13:32.476 --> 00:13:35.076
When you request a bracket
of say three images,

00:13:35.316 --> 00:13:37.286
that callback is going
to be called three times.

00:13:37.286 --> 00:13:38.386
Once per image.

00:13:38.726 --> 00:13:41.136
And the fifth parameter
tells you

00:13:41.136 --> 00:13:42.886
which particular
bracket settings

00:13:42.926 --> 00:13:45.886
in this image request
this corresponds to.

00:13:46.916 --> 00:13:50.486
Okay. So we like the new
AVCapturePhotoOutput so much

00:13:50.646 --> 00:13:52.626
that we want you to move
over to it right away.

00:13:52.936 --> 00:13:56.766
And so we're deprecating in iOS
10 the AVCaptureStillImageOutput

00:13:57.126 --> 00:14:00.436
and all of the flash-related
properties of AVCaptureDevice,

00:14:00.746 --> 00:14:03.236
and instead, this is
what you should use.

00:14:03.706 --> 00:14:07.286
Like I said, there are parts
of flash capture that are part

00:14:07.286 --> 00:14:09.886
and parcel to the
photo settings and so,

00:14:09.886 --> 00:14:11.506
it's a much better
programming interface.

00:14:11.876 --> 00:14:13.146
Move over as soon as you can.

00:14:14.416 --> 00:14:16.666
The last item is -- let's talk

00:14:16.666 --> 00:14:19.546
about the photo benefits
before we move on.

00:14:20.566 --> 00:14:22.026
They're good for
easier bookkeeping.

00:14:22.856 --> 00:14:24.496
Immediate settings resolution.

00:14:25.266 --> 00:14:26.786
Confident request tracking.

00:14:27.336 --> 00:14:28.896
And it's good for Apple.

00:14:28.896 --> 00:14:31.306
It's good for us because
it's an expandable palette

00:14:31.306 --> 00:14:32.596
of callbacks for us.

00:14:32.596 --> 00:14:35.196
We can add new ways to
call you back in the future

00:14:35.716 --> 00:14:38.976
and that last little bit is
important to the next feature

00:14:38.976 --> 00:14:40.946
that I'm going to talk
about, which is Live Photos.

00:14:41.356 --> 00:14:44.906
So Apple.com has a
great little blurb

00:14:45.026 --> 00:14:46.926
on Live Photos and
what they are.

00:14:46.926 --> 00:14:50.466
It says, "A still photo captures
an instant frozen in time.

00:14:51.106 --> 00:14:53.096
With Live Photos, you
can turn those instants

00:14:53.146 --> 00:14:55.516
into unforgettable
living memories."

00:14:56.896 --> 00:14:59.656
The beautiful thing about Live
Photos is that they appreciate

00:14:59.656 --> 00:15:02.016
in value the further
you get from the memory.

00:15:02.806 --> 00:15:05.306
So, in this picture, this
is a great still image

00:15:05.306 --> 00:15:06.236
in and of itself.

00:15:06.966 --> 00:15:10.436
Huge disgusting sand crabs my
nephew dug up on the beach.

00:15:10.436 --> 00:15:11.246
A great photo.

00:15:11.586 --> 00:15:12.926
But if I 3D touch it --

00:15:13.516 --> 00:15:16.656
[ Inaudible ]

00:15:17.156 --> 00:15:18.356
Okay. So now I remember.

00:15:18.416 --> 00:15:19.656
It was a freezing day.

00:15:19.656 --> 00:15:22.116
He'd never been in the ocean
before and his lips were blue.

00:15:22.116 --> 00:15:24.106
He'd been in for too long
and his hands were shaking.

00:15:24.326 --> 00:15:26.796
And I also hear my brother's
voice speaking at the beginning.

00:15:27.086 --> 00:15:29.386
So all of these things
aid in memory recall

00:15:29.686 --> 00:15:32.986
because I have more
senses being activated.

00:15:33.976 --> 00:15:35.976
Then there are people
finding inventive ways

00:15:35.976 --> 00:15:38.656
to use Live Photos as an
artistic medium unto itself.

00:15:38.656 --> 00:15:40.946
This shot is a twist
on the selfie.

00:15:41.446 --> 00:15:44.296
Our camera products team calls
this The Doughnut Selfie.

00:15:44.856 --> 00:15:48.426
A high degree of
difficulty to do it well.

00:15:48.996 --> 00:15:51.966
Also popular is the
spinning swivel chair selfie

00:15:52.386 --> 00:15:53.146
with Live Photo.

00:15:53.256 --> 00:15:53.906
Try that one out.

00:15:54.976 --> 00:15:57.806
I'm a big fan of the
surprise reveal live photo,

00:15:58.146 --> 00:15:59.976
but unfortunately,
my kids are too.

00:16:06.426 --> 00:16:08.406
A three-second window
is just way too tempting

00:16:08.406 --> 00:16:10.226
for my natural-borne
photobombers.

00:16:10.226 --> 00:16:14.096
So Live Photos began life
as a thought experiment

00:16:14.096 --> 00:16:15.336
from Apple's design studio.

00:16:15.406 --> 00:16:18.056
The premise was, even though
we've got these remarkable

00:16:18.056 --> 00:16:20.626
screens now for sharing
and viewing content,

00:16:21.056 --> 00:16:25.106
the photo experience itself has
remained static for 150 years.

00:16:25.706 --> 00:16:28.436
JPEGs that we swipe through
on the screen are just digital

00:16:28.436 --> 00:16:30.636
versions of the chemicals
on paper that we leaf

00:16:30.666 --> 00:16:32.876
through in our shoeboxes.

00:16:32.876 --> 00:16:34.056
And yet, it's the primary way

00:16:34.056 --> 00:16:35.306
that people store
their memories.

00:16:35.306 --> 00:16:37.586
So isn't there something
better that we can do?

00:16:37.586 --> 00:16:40.566
And after a lot of
experimentation and prototyping,

00:16:40.566 --> 00:16:43.146
we converged on what this
new media experience is.

00:16:43.756 --> 00:16:44.716
A moment or a memory.

00:16:45.016 --> 00:16:48.076
Well, first of all and
foremost it is a still photo.

00:16:48.456 --> 00:16:50.786
It's still as good
quality as before.

00:16:50.786 --> 00:16:54.286
It's a 12-megapixel JPEG
full resolution still image,

00:16:54.566 --> 00:16:57.886
and it has the same
quality as non-Live Photos.

00:16:57.886 --> 00:16:59.396
Let me emphasize that again.

00:16:59.916 --> 00:17:02.316
Live Photos get all
the great secret sauce

00:17:02.316 --> 00:17:04.086
that Apple's non-Live Photos do,

00:17:04.226 --> 00:17:08.846
so you are not sacrificing
anything by turning it on.

00:17:08.965 --> 00:17:11.935
Also a big deal was the idea
of frictionless capture.

00:17:12.396 --> 00:17:14.306
That means there's
nothing new to learn.

00:17:14.435 --> 00:17:16.566
You take photos the same
way you always have.

00:17:17.106 --> 00:17:20.286
Still the same spontaneous
frame the shot, push a button,

00:17:20.626 --> 00:17:21.976
nothing additional
to think about.

00:17:23.516 --> 00:17:25.685
A Live Photo is also
a memory, though.

00:17:26.066 --> 00:17:28.666
It has to engage more senses
than the static image.

00:17:28.666 --> 00:17:30.416
It has to aid in memory recall.

00:17:31.536 --> 00:17:34.656
So it's nominally a short
movie, a three-second movie

00:17:34.656 --> 00:17:37.886
with 1.5 seconds coming before
the still and 1.5 coming

00:17:37.886 --> 00:17:39.966
after the still, and we take it

00:17:39.966 --> 00:17:43.786
at about screen resolution
or targeting 1080p.

00:17:45.286 --> 00:17:47.136
And it includes audio.

00:17:48.576 --> 00:17:50.866
And we're constantly
improving on the design.

00:17:50.926 --> 00:17:54.046
In iOS 9.1, we added
this great feature

00:17:54.046 --> 00:17:55.936
of automatically
trimming Live Photos

00:17:55.936 --> 00:17:58.556
in case you did a sweeping
movement towards your shoes

00:17:58.556 --> 00:17:59.276
or your pockets.

00:17:59.546 --> 00:18:01.726
So now we'll auto trim them
and get rid of the parts

00:18:01.726 --> 00:18:03.076
that you don't want
see in the movie.

00:18:03.836 --> 00:18:05.836
New in iOS 10, we've
made it even better.

00:18:05.956 --> 00:18:08.976
Now all of the Live Photo
movies are stabilized.

00:18:10.276 --> 00:18:11.596
Also new in iOS 10,

00:18:11.626 --> 00:18:13.286
interruption-free
music during captures.

00:18:13.286 --> 00:18:13.976
So if you happen
to be playing --

00:18:14.516 --> 00:18:18.006
[ Applause ]

00:18:18.506 --> 00:18:19.346
Yeah. That's a good one.

00:18:19.406 --> 00:18:20.056
I like that one, too.

00:18:21.886 --> 00:18:24.576
So in order to be both
a moment and a memory,

00:18:24.706 --> 00:18:27.186
a Live Photo consists of two
assets, as you would expect.

00:18:27.186 --> 00:18:29.156
JPEG file, QuickTime Movie file.

00:18:29.566 --> 00:18:31.566
These two assets
share a common UUID

00:18:31.566 --> 00:18:33.396
that uniquely pairs
them together.

00:18:33.776 --> 00:18:35.566
The JPEG file's UUID is stored

00:18:35.566 --> 00:18:37.016
within the Apple Maker
Note of the [inaudible].

00:18:37.016 --> 00:18:40.436
And the movie asset
is, like I said,

00:18:40.436 --> 00:18:43.306
nominally three seconds
long, has a video track,

00:18:43.306 --> 00:18:46.556
roughly 1080p, with a
forward by 3 aspect ratio.

00:18:47.206 --> 00:18:50.676
It contains a timed metadata
track with one single sample

00:18:50.676 --> 00:18:53.666
in it that corresponds to the
exact time of the still photo

00:18:53.906 --> 00:18:55.046
within the movie's timeline.

00:18:55.626 --> 00:18:58.136
It also contains a piece
of top level movie metadata

00:18:58.136 --> 00:19:00.496
that pairs it with
the JPEG's metadata

00:19:00.756 --> 00:19:03.686
and that's called the
QuickTime content identifier.

00:19:04.086 --> 00:19:06.326
And its value is a
UUID-style stream.

00:19:08.006 --> 00:19:10.666
Okay. So what do you have to
do to capture Live Photos?

00:19:11.456 --> 00:19:12.976
In AVCapturePhotoOutput,

00:19:12.976 --> 00:19:17.306
there is a property called
isLivePhotoCaptureSupported?

00:19:17.306 --> 00:19:18.376
You have to make
sure it's supported.

00:19:18.376 --> 00:19:19.986
It's not supported
on all devices.

00:19:20.566 --> 00:19:22.046
And currently it's
only supported

00:19:22.046 --> 00:19:24.596
when you're using
the preset photo.

00:19:25.716 --> 00:19:29.206
You opt in for it using
AVCapture PhotoOutput.isLive

00:19:29.206 --> 00:19:32.446
PhotoCaptureEnabled,
setting it to true.

00:19:32.446 --> 00:19:35.496
You have to opt in for it before
you start the session running.

00:19:35.566 --> 00:19:37.966
Otherwise, it will cause a
disruptive reconfiguration

00:19:37.966 --> 00:19:40.976
of the session, and
you don't want that.

00:19:40.976 --> 00:19:44.686
Also if you want audio in
your Live Photo movies,

00:19:44.686 --> 00:19:46.806
you have to add an
AVCaptureDeviceInput

00:19:46.806 --> 00:19:47.716
for the microphone.

00:19:48.176 --> 00:19:48.786
Very important.

00:19:48.836 --> 00:19:49.556
Don't forget to do that.

00:19:50.466 --> 00:19:53.626
Also not supported is
simultaneous recording

00:19:53.626 --> 00:19:57.136
of regular movies using
AVCaptureMovieOutput

00:19:57.136 --> 00:19:58.876
and Live Photos at
the same time.

00:19:59.156 --> 00:20:00.546
So if you have a
movie file output

00:20:00.546 --> 00:20:04.856
in your session's topology, it
will disable LivePhotoCapture.

00:20:04.896 --> 00:20:08.446
You configure a LivePhotoCapture
the usual way.

00:20:09.106 --> 00:20:11.716
It's got the default
constructors you would expect,

00:20:12.166 --> 00:20:17.086
but additionally you specify a
URL, a LivePhotoMovieFileURL.

00:20:17.386 --> 00:20:20.206
This is where you want
us to write the movie to.

00:20:20.346 --> 00:20:21.816
And it has to be
in your sandbox,

00:20:21.816 --> 00:20:23.456
and it has to be
accessible to you.

00:20:23.576 --> 00:20:28.366
You're not required to specify
any livePhotoMovieMetadata

00:20:28.366 --> 00:20:29.616
but you can if you'd like to.

00:20:30.086 --> 00:20:33.936
Here I gave an example of
using the author metadata.

00:20:33.936 --> 00:20:35.716
And I set myself as the author,

00:20:35.716 --> 00:20:37.616
so that the world will
know that it's my movie.

00:20:37.966 --> 00:20:39.636
But you could also
do interesting stuff

00:20:39.636 --> 00:20:42.296
like add GPS tagging
to your movie.

00:20:42.636 --> 00:20:45.526
So now let's talk about Live
Photo-related delegate methods.

00:20:45.946 --> 00:20:48.186
Like I said, we have
this expandable palette

00:20:48.186 --> 00:20:50.126
of delegate callbacks,
and we're going to use it.

00:20:50.846 --> 00:20:52.176
When capturing a Live Photo,

00:20:52.176 --> 00:20:53.866
your first callback
lets you know

00:20:53.866 --> 00:20:55.726
that a Live Photo
will be recorded,

00:20:56.126 --> 00:20:58.796
by telling you the movie's
resolved dimensions.

00:20:58.796 --> 00:21:01.316
See that? Now, in addition
to just the photo dimensions,

00:21:01.316 --> 00:21:03.916
you also know what dimensions
the Live Photo is going to be.

00:21:04.336 --> 00:21:06.016
You receive the expected
callbacks,

00:21:06.066 --> 00:21:10.036
including a JPEG being delivered
to you in memory as before.

00:21:10.036 --> 00:21:11.916
But now we're going to
give you some new ones.

00:21:12.826 --> 00:21:15.796
A Live Photo movie is
nominally three seconds

00:21:15.856 --> 00:21:17.616
with a still image
right in the middle.

00:21:17.966 --> 00:21:22.206
So that means up to 1.5 seconds
after your capture request,

00:21:22.476 --> 00:21:24.226
you're going to receive
a new callback.

00:21:24.226 --> 00:21:25.436
And this one has a strange name,

00:21:25.946 --> 00:21:28.906
didFinishRecording
LivePhotoMovieFor

00:21:28.906 --> 00:21:31.146
EventualFileAtURL.

00:21:31.836 --> 00:21:33.516
Try to parse that.

00:21:33.516 --> 00:21:37.026
It means the file hasn't been
written yet but all the samples

00:21:37.026 --> 00:21:38.096
that need to be collected

00:21:38.096 --> 00:21:40.086
for the movie are
done being collected.

00:21:40.236 --> 00:21:44.586
In other words, if you have a
Live Photo badge up in your UI,

00:21:44.906 --> 00:21:46.946
this is an appropriate
time to take it down.

00:21:46.986 --> 00:21:48.926
Let people know that they don't
need to hold still anymore.

00:21:49.496 --> 00:21:52.346
A good time to dismiss
the Live Photo badge.

00:21:53.116 --> 00:21:57.336
And soon after, the movie file
will be finished being written.

00:21:57.636 --> 00:21:59.386
And you'll get the
didFinishProcessing

00:21:59.386 --> 00:22:01.336
LivePhotoTo MovieFileAtURL.

00:22:01.896 --> 00:22:04.416
That is a required callback,
if you're doing Live Photos.

00:22:04.846 --> 00:22:06.516
And now the movie's
ready to be consumed.

00:22:07.906 --> 00:22:10.696
Lastly you get the
thumbs up, all done.

00:22:10.696 --> 00:22:13.976
We've delivered everything
that we're going to.

00:22:14.606 --> 00:22:15.956
So note that the JPEG portion

00:22:15.956 --> 00:22:18.416
of the LivePhotoCapture is
delivered in the same way

00:22:18.416 --> 00:22:20.016
as static still photos.

00:22:20.016 --> 00:22:22.716
It comes as a sample
buffer in memory,

00:22:23.136 --> 00:22:25.326
using didFinishing
ProcessingPhoto SampleBuffer

00:22:25.326 --> 00:22:26.776
callback, as we've already seen.

00:22:26.776 --> 00:22:30.836
If you want to write this
to disk, it's a trivial job.

00:22:31.726 --> 00:22:34.146
We have a class method
in AVCapturePhotoOutput

00:22:34.146 --> 00:22:38.316
for rewriting JPEGs as a
Data, that's with a capital D,

00:22:38.716 --> 00:22:41.936
that's suitable for writing
to a JPEG file on disk.

00:22:42.296 --> 00:22:43.556
And you can see it
in action here.

00:22:43.556 --> 00:22:46.966
I'm going to gloss over
the second parameter

00:22:46.966 --> 00:22:49.046
to that function, the
previewPhotoSampleBuffer.

00:22:49.046 --> 00:22:50.366
We'll discuss it
in a little while.

00:22:51.856 --> 00:22:55.686
So here's a suggestion for you
when you're doing Live Photos.

00:22:56.136 --> 00:22:58.706
LivePhotoCapture is an
example of the kind of capture

00:22:58.706 --> 00:23:00.436
that delivers multiple assets.

00:23:00.436 --> 00:23:03.506
Sort of like a multi-order,
where you're going

00:23:03.506 --> 00:23:05.056
to get the computer in one
order, and you're going

00:23:05.056 --> 00:23:07.336
to get the dongle
in another order.

00:23:07.556 --> 00:23:10.916
So when it delivers multiple
assets, we have found it handy,

00:23:10.916 --> 00:23:12.786
in our own test apps
that we've written,

00:23:13.216 --> 00:23:18.266
to instantiate a new
AVCapturePhotoDelegate object

00:23:18.266 --> 00:23:21.296
for each photo request
in this situation.

00:23:21.686 --> 00:23:24.516
So then, within that
object, you can aggregate all

00:23:24.516 --> 00:23:25.556
of the things that
you're getting.

00:23:25.556 --> 00:23:29.056
The sample buffer, the movie,
et cetera, for this request.

00:23:29.056 --> 00:23:31.626
And then, there's a convenient
place to dispose of that object

00:23:31.626 --> 00:23:33.146
when you get the
thumbs up callback,

00:23:33.146 --> 00:23:33.906
saying that we're done.

00:23:34.466 --> 00:23:35.806
That's just a helpful tip there.

00:23:37.286 --> 00:23:39.016
Once your assets have
been written to disk,

00:23:39.016 --> 00:23:41.456
there are still several more
steps that you need to take

00:23:41.796 --> 00:23:43.866
to get the full live
photo experience.

00:23:43.926 --> 00:23:46.566
Though the video complement
is a standard QuickTime movie,

00:23:46.906 --> 00:23:48.756
it's not meant to be
played start to finish

00:23:48.756 --> 00:23:51.136
with an AV Player like
you would a regular movie.

00:23:51.496 --> 00:23:53.406
There's a special recipe
for playing it back.

00:23:53.786 --> 00:23:58.396
It's supposed to ease in and out
of the photo still image time.

00:23:58.436 --> 00:24:01.316
When you swipe between
them, these particular kinds

00:24:01.316 --> 00:24:03.546
of assets have a little bit
of movement in the photos app.

00:24:04.236 --> 00:24:06.526
So to get the full Live
Photo playback experience,

00:24:06.526 --> 00:24:09.506
you need to use the photos
and photos UI frameworks.

00:24:09.886 --> 00:24:12.086
And there are classes
relating to Live Photo,

00:24:12.426 --> 00:24:15.656
to ingest your RAW assets
into the photo library

00:24:15.956 --> 00:24:17.656
and properly play them
back, for instance,

00:24:17.656 --> 00:24:18.866
with the LivePhotoView.

00:24:20.186 --> 00:24:21.516
And new in iOS 10,

00:24:21.516 --> 00:24:24.816
photos framework lets you
edit Live Photo content just

00:24:24.816 --> 00:24:27.756
as you would a still
photo, and that's great news

00:24:28.076 --> 00:24:28.966
and I'd like to demo it.

00:24:36.346 --> 00:24:40.186
Okay. So we have a bit of sample
code here, the venerable AVCam,

00:24:40.186 --> 00:24:41.816
which has been out
for five years,

00:24:42.506 --> 00:24:44.616
but now we have spruced it up,

00:24:44.616 --> 00:24:47.526
so that it has a specific
photo mode and a movie mode.

00:24:47.926 --> 00:24:50.596
That's because you can only
do Live Photos in photo mode.

00:24:51.006 --> 00:24:53.156
And notice it's got some badging
at the top that tells you

00:24:53.156 --> 00:24:55.076
that Live Photo mode
is on or off.

00:24:56.036 --> 00:24:57.546
And you can switch cameras.

00:24:57.806 --> 00:25:00.006
I'm going to try to do the
difficult doughnut selfie.

00:25:00.006 --> 00:25:01.516
Let's see how successful I am.

00:25:01.806 --> 00:25:05.236
So you have to start and
then take it somewhere

00:25:05.236 --> 00:25:07.566
in the middle and then finish.

00:25:07.896 --> 00:25:09.996
So notice, while I was doing
that, there was a live badge

00:25:09.996 --> 00:25:12.126
that came up, and that's
using the callbacks

00:25:12.126 --> 00:25:13.866
that I talked to
you about earlier.

00:25:15.406 --> 00:25:16.126
So here it is.

00:25:16.126 --> 00:25:18.926
It was written to the
Photos Library and --

00:25:18.926 --> 00:25:21.946
then take it somewhere in
the middle -- nice, right?

00:25:22.396 --> 00:25:24.266
But that's not all we
can do with it now.

00:25:24.386 --> 00:25:26.826
In iOS 9, when you tried
to edit a Live Photo,

00:25:26.826 --> 00:25:28.426
you would lose the
movie portion of it.

00:25:28.816 --> 00:25:34.026
But now we can either, in the
photos app natively or with code

00:25:34.026 --> 00:25:35.256
that you provide in your app,

00:25:35.596 --> 00:25:38.346
such as this little sample
called LivePhotoEditor

00:25:38.346 --> 00:25:42.106
that I've included as a
photo editing extension,

00:25:42.916 --> 00:25:45.876
I can apply a simple
filter or trim the movie.

00:25:46.376 --> 00:25:48.016
This just does a
really simple thing

00:25:48.016 --> 00:25:49.626
of applying a tonal filter,

00:25:49.896 --> 00:25:51.596
but notice it didn't
get rid of the movie.

00:25:51.596 --> 00:25:53.956
I can still play it --
and then take it somewhere

00:25:53.956 --> 00:25:55.176
in the middle -- so, nice.

00:25:55.176 --> 00:25:55.976
You can now edit
your Live Photos.

00:25:56.516 --> 00:26:03.306
[ Applause ]

00:26:03.806 --> 00:26:04.166
All right.

00:26:04.266 --> 00:26:07.616
AVCam. Now, like I
said, has separate video

00:26:07.616 --> 00:26:08.946
and photo recording modes,

00:26:08.946 --> 00:26:10.876
so you get the best
photo experience.

00:26:10.876 --> 00:26:12.876
You get the best
movie-making experience.

00:26:13.266 --> 00:26:15.446
And it shows the proper
live badging technique

00:26:15.446 --> 00:26:16.336
that I was talking about.

00:26:16.706 --> 00:26:19.316
It also shows you how to
write it to the Assets Library

00:26:19.696 --> 00:26:21.596
and that sample code
is available right now.

00:26:21.636 --> 00:26:24.276
If you go to our sessions'
page, you'll find it.

00:26:25.306 --> 00:26:26.466
It was even Swiftified.

00:26:26.696 --> 00:26:28.896
If you want to know more
about Live Photo editing,

00:26:29.166 --> 00:26:32.086
please come to session
505 on Thursday at 11.

00:26:32.336 --> 00:26:34.926
You'll hear all about it.

00:26:35.186 --> 00:26:37.306
Okay. We also support
a feature called

00:26:37.306 --> 00:26:39.146
LivePhotoCaptureSuspension.

00:26:39.326 --> 00:26:42.616
Here's a quick example of
when this might be useful.

00:26:43.106 --> 00:26:45.196
Let's say you have an
app that takes pictures

00:26:45.196 --> 00:26:47.646
and makes obnoxious
foghorn sounds.

00:26:48.896 --> 00:26:50.226
Okay, just go with
me on this one.

00:26:50.726 --> 00:26:52.156
It takes pictures.

00:26:52.406 --> 00:26:53.946
Makes obnoxious foghorn sounds.

00:26:54.236 --> 00:26:55.706
Now let's say that
on a timeline,

00:26:55.746 --> 00:26:57.706
your user takes a
Live Photo here

00:26:58.416 --> 00:27:01.906
and then they play an
obnoxious foghorn sound here.

00:27:02.006 --> 00:27:05.696
And then after it's done
playing they take another Live

00:27:05.696 --> 00:27:06.286
Photo there.

00:27:07.736 --> 00:27:11.686
So this is a problem because
since the movie portions

00:27:11.726 --> 00:27:14.166
of photos one and two overlap

00:27:14.336 --> 00:27:16.066
with the obnoxious
foghorn sound,

00:27:16.566 --> 00:27:19.116
you have now ruined
two Live Photo movies.

00:27:19.486 --> 00:27:22.056
You're going to hear the end
of the foghorn in one of them

00:27:22.056 --> 00:27:24.876
and the beginning of the
foghorn in the other.

00:27:25.016 --> 00:27:25.706
That's no good.

00:27:25.806 --> 00:27:27.296
So to cope with this problem,

00:27:27.726 --> 00:27:30.596
you can set
isLivePhotoCaptureSuspended

00:27:30.756 --> 00:27:33.516
to true, just before you
do your obnoxious thing.

00:27:34.166 --> 00:27:37.096
And that will cause any
Live Photos in progress

00:27:37.346 --> 00:27:39.896
to abruptly be trimmed
right to that point.

00:27:40.356 --> 00:27:41.516
And you can do the same thing

00:27:41.516 --> 00:27:43.336
by setting
isLivePhotoCaptureSuspended

00:27:43.336 --> 00:27:46.876
to false, and that will
cause a nice clean break

00:27:46.876 --> 00:27:50.116
on the endpoint, so
that no content earlier

00:27:50.116 --> 00:27:53.746
than that point will appear in
your movies when you unsuspend.

00:27:53.856 --> 00:27:54.776
A nice little feature.

00:27:56.316 --> 00:27:57.806
So let's talk about support.

00:27:57.806 --> 00:27:59.686
Where do we support
LivePhotoCapture?

00:28:00.466 --> 00:28:04.346
We support it on all the recent
iOS devices, and the easy way

00:28:04.346 --> 00:28:07.486
to remember it is every device
that has a 12-megapixel camera,

00:28:07.716 --> 00:28:09.376
that's where we support
Live Photos.

00:28:11.596 --> 00:28:14.556
All right, onto our next
major feature of the day

00:28:14.556 --> 00:28:16.036
and that's RAW Photo Capture.

00:28:16.576 --> 00:28:21.656
So to explain what RAW
images are, I need to start

00:28:21.656 --> 00:28:25.166
with a very high level overview
of how CMOS sensors work.

00:28:26.086 --> 00:28:28.586
CMOS sensors collect
photons of light

00:28:28.586 --> 00:28:31.136
through two-dimensional
arrays of detectors.

00:28:32.096 --> 00:28:35.356
The top layer of the array is
called a color filter array

00:28:36.056 --> 00:28:38.256
and as light passes
through from the top,

00:28:38.496 --> 00:28:41.336
it only allows one color
component through, either red,

00:28:41.506 --> 00:28:43.696
green or blue, in
a Bayer pattern.

00:28:44.416 --> 00:28:46.936
Green is twice as prevalent in
this little checkerboard here

00:28:46.936 --> 00:28:50.046
because our eyes are twice
as sensitive to green light

00:28:50.046 --> 00:28:51.396
as they are to the other colors.

00:28:52.256 --> 00:28:54.766
The bottom layer here is
known as the sensor array.

00:28:55.966 --> 00:29:00.686
Now what actually gets stored
in a RAW file is the intensity

00:29:00.686 --> 00:29:03.096
of the amount of either
red, green or blue light

00:29:03.136 --> 00:29:07.776
that hit the sensor through each
of those detectors also needs

00:29:07.776 --> 00:29:09.676
to be stored that Bayer pattern.

00:29:09.676 --> 00:29:13.096
In other words, the arrangement
of reds, greens and blues,

00:29:13.466 --> 00:29:15.446
so that later on it
can be demosaiced.

00:29:15.446 --> 00:29:18.736
You have to store a lot
of other metadata too

00:29:18.736 --> 00:29:20.986
about color information,
exposure information.

00:29:22.416 --> 00:29:25.006
And so RAW converters
have a really hard job.

00:29:25.256 --> 00:29:27.896
A RAW converter that basically
takes all of this stuff

00:29:27.896 --> 00:29:29.646
and turns it into an RGB image.

00:29:30.316 --> 00:29:33.166
Demosaicing is just
the tip of the iceberg.

00:29:33.296 --> 00:29:35.526
A lot of stuff needs to
happen before it can be

00:29:35.746 --> 00:29:37.226
presented onscreen.

00:29:38.416 --> 00:29:41.806
So to draw an analogy,
storing a RAW file is a lot

00:29:41.806 --> 00:29:44.216
like storing the ingredients
to bake a cake, okay?

00:29:44.736 --> 00:29:47.046
And then you have to
carry the ingredients

00:29:47.046 --> 00:29:48.296
around with you wherever you go.

00:29:48.296 --> 00:29:50.256
It's kind of heavy.

00:29:50.356 --> 00:29:51.426
It's kind of awkward.

00:29:51.946 --> 00:29:55.556
It takes some time to
bake it every time.

00:29:55.556 --> 00:29:56.986
If you ask two different bakers

00:29:57.146 --> 00:29:59.006
to bake the cake using
the same ingredients,

00:29:59.006 --> 00:30:01.976
you might get a slightly
different tasting cake.

00:30:02.396 --> 00:30:04.786
But there are also some
huge advantages to RAW.

00:30:05.136 --> 00:30:09.086
First and foremost, you have
bake-time flexibility, right?

00:30:09.086 --> 00:30:11.186
So you're carrying
the ingredients around

00:30:11.186 --> 00:30:14.246
but you can make a
better cake next year.

00:30:15.186 --> 00:30:17.436
There's no compression involved

00:30:17.586 --> 00:30:21.396
like there would
be in BGRA or 420.

00:30:21.396 --> 00:30:22.736
You have more bits to work with.

00:30:22.986 --> 00:30:25.806
It's a 10-bit sensor
RAW packaged

00:30:25.806 --> 00:30:28.636
in 14 bits per pixel
instead of eight.

00:30:30.176 --> 00:30:32.036
Also, you have lots of
headroom for editing.

00:30:33.216 --> 00:30:35.136
And some greater
artistic freedom

00:30:35.136 --> 00:30:37.916
to make different
decisions in post.

00:30:37.916 --> 00:30:39.686
So basically you're just
deferring the baking

00:30:39.686 --> 00:30:40.316
until later.

00:30:41.206 --> 00:30:42.716
Okay? Now what's JPEG?

00:30:43.306 --> 00:30:45.486
RAW images offer many benefits

00:30:45.486 --> 00:30:47.796
but they're not the
be-all-end-all of existence.

00:30:47.796 --> 00:30:49.036
It's important to understand

00:30:49.036 --> 00:30:51.576
that there are tradeoffs
involved when you choose RAW

00:30:51.856 --> 00:30:56.086
and that JPEGs are still
a very attractive option.

00:30:56.086 --> 00:31:00.846
JPEGs are the cake, the lovingly
baked Apple cake, just for you,

00:31:00.996 --> 00:31:03.086
and it's a pretty good cake.

00:31:03.206 --> 00:31:06.206
It's got all of the
Apple goodness in it.

00:31:07.146 --> 00:31:08.206
Much faster rendering.

00:31:08.206 --> 00:31:11.346
You don't have to carry as
many ingredients around.

00:31:11.486 --> 00:31:15.486
You also get some secret
sauce, like stabilization.

00:31:15.686 --> 00:31:19.366
As I mentioned, we use multiple
image fusion for stabilization.

00:31:19.756 --> 00:31:21.486
You can't get that with
a single RAW image,

00:31:21.486 --> 00:31:24.136
no matter how good it is,
because we're taking --

00:31:24.136 --> 00:31:25.986
I guess it's kind of
like a multilayer cake.

00:31:26.626 --> 00:31:29.256
Okay? So yeah, you can't do
that with a single image.

00:31:30.176 --> 00:31:32.136
Also you get smaller file size.

00:31:33.476 --> 00:31:36.746
So all of these things make JPEG
a really attractive alternative

00:31:36.826 --> 00:31:39.276
and you should decide
which one you want to use,

00:31:39.276 --> 00:31:40.216
which is better for your app.

00:31:41.256 --> 00:31:44.146
We identify RAW formats
using four-character codes,

00:31:44.146 --> 00:31:46.396
just like we do for
regular pixel formats

00:31:46.436 --> 00:31:47.936
in the Core Video framework.

00:31:48.346 --> 00:31:51.596
We've added four new
constants to CVPixelBuffer.h

00:31:51.596 --> 00:31:53.896
to describe the four
different Bayer patterns

00:31:54.226 --> 00:31:56.146
that you'll encounter
on our cameras,

00:31:56.426 --> 00:31:57.306
and they're listed there.

00:31:57.366 --> 00:31:59.216
Basically they describe
the order of the reds,

00:31:59.216 --> 00:32:00.846
greens and blues in
the checkerboard.

00:32:02.266 --> 00:32:05.196
How do you capture RAW
with AVCapturePhotoOutput?

00:32:05.556 --> 00:32:06.306
It's pretty simple.

00:32:07.086 --> 00:32:10.526
RAW is only supported when
using the photo format,

00:32:10.526 --> 00:32:13.096
the preset photo,
same as Live Photo.

00:32:14.036 --> 00:32:16.016
It's only supported
on the rear camera.

00:32:17.276 --> 00:32:21.526
And we do support RAW brackets,
so you can take a bracket

00:32:21.526 --> 00:32:23.706
of three RAW images,
for instance.

00:32:24.806 --> 00:32:26.146
To request a RAW capture,

00:32:26.296 --> 00:32:28.686
you create an
AVCapturePhotoSettings object

00:32:28.686 --> 00:32:30.976
but surprise, surprise,
there's a different instructor.

00:32:31.546 --> 00:32:33.586
This one takes a
RAW pixel format.

00:32:34.486 --> 00:32:37.716
So how do you decide which
RAW format you should ask it

00:32:37.716 --> 00:32:38.716
to deliver to you?

00:32:38.996 --> 00:32:41.716
Well you can ask the
PhotoOutput itself.

00:32:41.716 --> 00:32:44.366
It'll tell you here are my
available RAW photo pixel

00:32:44.566 --> 00:32:48.086
formats, and you can
select one of those.

00:32:49.416 --> 00:32:52.666
The RAW format you specify has
to be supported by the hardware.

00:32:52.666 --> 00:32:57.046
Now also important is that
in these RAW settings,

00:32:57.686 --> 00:33:02.306
SIS has no meaning because
it's not a multiple image

00:33:02.496 --> 00:33:03.836
fusion scenario.

00:33:04.276 --> 00:33:07.086
So autoStillImage
StabilizationEnabled has

00:33:07.086 --> 00:33:09.146
to be set to no or it
will throw an exception.

00:33:09.646 --> 00:33:12.096
And also
highResolutionPhotoEnabled is

00:33:12.096 --> 00:33:14.776
meaningless because you're
just getting the sense of RAW,

00:33:15.426 --> 00:33:16.956
so it also must be set to false.

00:33:18.276 --> 00:33:19.926
There's a separate
delegate callback

00:33:19.926 --> 00:33:25.476
for RAW photos called didFinish
ProcessingRAW PhotoSampleBuffer.

00:33:25.866 --> 00:33:29.276
And if you are really sharp-eyed
and really fast, you'll notice

00:33:29.276 --> 00:33:31.426
that it has exactly
the same parameters

00:33:31.566 --> 00:33:35.396
as the previous callback,
where you get the regular kind

00:33:35.396 --> 00:33:37.076
of image, the didFinish
ProcessingRAW

00:33:37.076 --> 00:33:38.296
PhotoSampleBuffer callback.

00:33:38.746 --> 00:33:42.136
So now you might ask yourself
why did we bother making a whole

00:33:42.136 --> 00:33:45.346
new delegate callback
for RAW sample buffers

00:33:45.346 --> 00:33:48.336
if it has the same exact
parameters as the other one?

00:33:48.856 --> 00:33:55.386
There's a good reason, and that
reason is RAW plus processed

00:33:55.386 --> 00:33:56.066
image support.

00:33:56.226 --> 00:33:59.626
So we do support, just
like on DSLR cameras,

00:33:59.626 --> 00:34:03.036
mirrorless cameras, a workflow
where you can get both RAW

00:34:03.036 --> 00:34:04.956
and JPEG simultaneously.

00:34:05.046 --> 00:34:06.516
That's what I mean
by processed image.

00:34:07.226 --> 00:34:09.186
The ability to shoot
RAW and JPEG is kind

00:34:09.186 --> 00:34:10.916
of a professional feature,
kind of a big deal.

00:34:11.255 --> 00:34:14.916
So you can get RAW
plus a processed image.

00:34:14.916 --> 00:34:17.866
It doesn't have to be a
JPEG, it could be BGRA, 420.

00:34:18.775 --> 00:34:22.005
The processed image is
delivered to the other callback,

00:34:22.076 --> 00:34:24.516
the didFinish ProcessingPhoto
SampleBuffer callback,

00:34:24.956 --> 00:34:30.246
and the RAW is delivered to
the one with RAW in the name.

00:34:30.246 --> 00:34:33.255
RAW plus processed
brackets are supported,

00:34:33.255 --> 00:34:34.606
so see if you can wrap
your head around that.

00:34:34.766 --> 00:34:36.106
That would be --
I'm doing a bracket

00:34:36.106 --> 00:34:38.176
and I'm asking for
RAW plus JPEG.

00:34:38.396 --> 00:34:40.246
So if I'm doing a
bracket of three,

00:34:40.246 --> 00:34:42.565
I'm going to get three
RAWs and three JPEGs.

00:34:43.096 --> 00:34:46.676
RAW plus still image
stabilization,

00:34:46.676 --> 00:34:47.916
though, is not supported.

00:34:49.525 --> 00:34:53.076
Okay, so to capture RAW plus
JPEG, as you might expect,

00:34:53.076 --> 00:34:56.446
there's yet another constructor
of AVCapturePhotoSettings.

00:34:56.835 --> 00:34:59.806
In this one, you specify
both the RAW pixel format

00:34:59.806 --> 00:35:02.126
and the processed
format that you want.

00:35:02.786 --> 00:35:07.776
Here I'm choosing JPEG as the
output format and a RAW format.

00:35:09.656 --> 00:35:12.296
Now when you select JPEGPlusRAW,

00:35:12.296 --> 00:35:14.936
HighResolutionPhotoEnabled
does mean something.

00:35:14.936 --> 00:35:17.146
Because now it's
applying to the JPEG.

00:35:19.136 --> 00:35:19.796
All right.

00:35:20.016 --> 00:35:21.736
Let's talk about
storing RAW buffers.

00:35:21.996 --> 00:35:23.396
They're not that useful

00:35:23.396 --> 00:35:25.506
if all you can do is
work with them in memory.

00:35:26.356 --> 00:35:29.456
So rather than introduce an
Apple proprietary RAW file

00:35:29.456 --> 00:35:32.776
format, like so many other
camera vendors do, we've elected

00:35:32.776 --> 00:35:36.236
to use Adobe's digital
negative format for storage.

00:35:36.836 --> 00:35:40.906
DNG is a standard way of just
storing bits and metadata.

00:35:41.036 --> 00:35:43.576
It doesn't imply a file
format in any other way.

00:35:43.706 --> 00:35:48.646
So going back to our cake-baking
analogy, a DNG is just

00:35:48.646 --> 00:35:51.346
like a standard box for
holding ingredients.

00:35:52.056 --> 00:35:55.176
It's still up to individual
RAW converters to decide how

00:35:55.176 --> 00:35:56.546
to interpret those ingredients.

00:35:56.916 --> 00:36:00.866
So DNGs opened by one third
party app might look different

00:36:00.866 --> 00:36:03.686
than DNGs opened
in a different app.

00:36:03.896 --> 00:36:05.726
So storing in DNG
is pretty trivial.

00:36:06.416 --> 00:36:10.326
You just call the class function
dngPhotoDataRepresentation,

00:36:11.116 --> 00:36:12.866
passing the RAW buffer
you received

00:36:13.006 --> 00:36:14.076
in the delegate callback.

00:36:14.656 --> 00:36:17.916
This creates a capital
D Data in memory

00:36:18.376 --> 00:36:19.556
that can be written to file.

00:36:20.536 --> 00:36:23.866
And this API always writes
[inaudible] compressed DNG files

00:36:23.866 --> 00:36:24.976
to save space.

00:36:28.756 --> 00:36:29.126
All right.

00:36:29.126 --> 00:36:29.976
I feel a demo coming on.

00:36:36.986 --> 00:36:40.746
Okay. So for RAW capture, we've
updated another venerable piece

00:36:40.746 --> 00:36:42.786
of sample code and
that's AVCamManual.

00:36:43.356 --> 00:36:45.516
We released this one in 2014,

00:36:45.516 --> 00:36:48.576
when we showed off our
manual control APIs.

00:36:48.646 --> 00:36:53.986
So it lets you choose focus,
exposure, white balance,

00:36:54.306 --> 00:36:57.536
and you can manually
or auto control those.

00:36:58.046 --> 00:37:02.046
And then there's a new thing
in the HUD on the left side

00:37:02.326 --> 00:37:04.616
that lets you select
either RAW off or on.

00:37:05.326 --> 00:37:08.806
So you can choose to shoot
RAW photos in this app.

00:37:09.496 --> 00:37:10.916
Let's go to exposure.

00:37:10.916 --> 00:37:14.166
Let me see if I can purposely
overexpose a little bit,

00:37:14.166 --> 00:37:16.596
and then I'll take a photo.

00:37:16.666 --> 00:37:19.346
And now I'm going
to leave the app.

00:37:20.426 --> 00:37:24.236
I'm going to go to an
app called RAWExpose.

00:37:24.236 --> 00:37:26.096
Now this was not written
by the AV Foundation Team.

00:37:26.096 --> 00:37:27.716
This was written by
the Core Image Team,

00:37:27.716 --> 00:37:30.666
but they graciously let
me borrow it for my demo.

00:37:30.776 --> 00:37:34.036
And we'll go down and we can see
the picture that we just took.

00:37:34.876 --> 00:37:37.536
Now this one is a RAW.

00:37:37.666 --> 00:37:39.666
It's reading the DNG file.

00:37:40.216 --> 00:37:42.796
And we can do things with
it that we could never do

00:37:42.796 --> 00:37:48.966
with the JPEGs, like we restore
the EV to a more same value.

00:37:49.286 --> 00:37:53.866
We can adjust the
temperature and tint.

00:37:53.866 --> 00:37:55.856
All of these things
are being done in post

00:37:55.856 --> 00:37:57.106
and are completely reversible.

00:37:57.586 --> 00:38:00.596
You can also look and see
what it looks like with

00:38:00.596 --> 00:38:01.796
or without noise reduction.

00:38:02.066 --> 00:38:03.586
So all of these are part

00:38:03.586 --> 00:38:06.176
of a new Core image
API for editing RAW.

00:38:06.176 --> 00:38:06.976
Okay, let's go back to slides.

00:38:13.706 --> 00:38:18.156
The AVCamManual sample code
is available right now.

00:38:18.156 --> 00:38:18.816
You can go get it.

00:38:18.816 --> 00:38:21.746
It's associated with
this session's slides.

00:38:22.406 --> 00:38:25.716
And also, if you want to
learn more about RAW editing,

00:38:25.786 --> 00:38:28.276
you need to come to that
same session as I talked

00:38:28.276 --> 00:38:31.336
about before, session 505, where
they talk about both of these.

00:38:31.416 --> 00:38:34.026
The second part is RAW
Processing with Core Image.

00:38:34.326 --> 00:38:37.196
It's a great session.

00:38:37.346 --> 00:38:39.406
Where is RAW photo
capture supported?

00:38:40.566 --> 00:38:43.326
By happy coincidence, it's
exactly the same products

00:38:43.326 --> 00:38:46.346
as where we support Live Photos.

00:38:46.836 --> 00:38:48.946
So anything with a
12-megapixel camera is

00:38:48.946 --> 00:38:50.326
where you can do RAW photos.

00:38:51.556 --> 00:38:55.366
Onto our next topic, which
is capturing preview images,

00:38:55.656 --> 00:38:57.536
also known as thumbnails.

00:38:57.746 --> 00:39:01.296
Photography apps commonly
take pictures and want

00:39:01.296 --> 00:39:03.396
to quickly show a
preview of the results,

00:39:03.836 --> 00:39:05.586
such as Apple Zone camera app.

00:39:06.266 --> 00:39:07.976
So take a look in the bottom
left while this is playing.

00:39:14.026 --> 00:39:17.256
And you see, as soon as it
hits the shutter button,

00:39:17.256 --> 00:39:19.816
almost instantaneously
you have a preview

00:39:19.816 --> 00:39:21.936
in the image well
on the bottom left.

00:39:22.046 --> 00:39:22.636
That's good.

00:39:22.636 --> 00:39:24.276
That's comforting to
your users to know

00:39:24.276 --> 00:39:26.076
that what they did just worked.

00:39:26.656 --> 00:39:28.646
It gives them instant feedback.

00:39:29.346 --> 00:39:31.906
Also a number of image
processing algorithms

00:39:31.906 --> 00:39:34.696
such as Core Images,
CI Rectangle Detector

00:39:34.996 --> 00:39:38.976
or CI QR Code Detector work
better with smaller images,

00:39:39.076 --> 00:39:40.546
smaller uncompressed images.

00:39:40.546 --> 00:39:43.996
They don't need the full
12-megapixel JPEG to find faces.

00:39:45.386 --> 00:39:50.176
Unfortunately there is an
inherit impedance mismatch here.

00:39:51.066 --> 00:39:53.106
You request a high-quality JPEG

00:39:53.446 --> 00:39:55.896
because that's what you
want to store on disk.

00:39:55.896 --> 00:39:59.466
That's what you want to
survive, but you also want

00:39:59.466 --> 00:40:00.976
to get a preview on
screen really fast.

00:40:02.166 --> 00:40:03.746
So if you have to do
that work yourself,

00:40:03.746 --> 00:40:05.116
you're decompressing the JPEG.

00:40:05.116 --> 00:40:06.096
You're downscaling it.

00:40:06.306 --> 00:40:07.386
And finally displaying it.

00:40:08.216 --> 00:40:09.346
All of this takes time

00:40:09.346 --> 00:40:11.296
and buffer copies
and added complexity.

00:40:12.036 --> 00:40:15.806
Nicer would be to get both the
high-quality JPEG for storage

00:40:15.876 --> 00:40:18.786
and if the camera could give
you a smaller version of it,

00:40:19.186 --> 00:40:22.376
directly from the camera, not
decompressed from the JPEG.

00:40:23.626 --> 00:40:26.266
Then you could skip all those
steps and go straight to display

00:40:26.266 --> 00:40:27.166
with the preview image.

00:40:28.136 --> 00:40:30.346
And this is exactly the
workflow that we support

00:40:30.346 --> 00:40:31.566
in AVCapturePhotoOutput.

00:40:32.436 --> 00:40:32.966
The delegate --

00:40:33.516 --> 00:40:36.856
[ Applause ]

00:40:37.356 --> 00:40:37.976
I'll pander.

00:40:38.256 --> 00:40:38.756
I'll pander.

00:40:39.106 --> 00:40:42.716
The delegate callback can
deliver a preview image along

00:40:42.716 --> 00:40:44.656
with the processed or RAW image.

00:40:45.306 --> 00:40:49.046
The preview is uncompressed,
so it's 420fv

00:40:49.046 --> 00:40:50.596
or BGRA, you're choice.

00:40:50.776 --> 00:40:52.966
If you know the size you want,

00:40:53.266 --> 00:40:56.356
you can specify the
dimensions that you want.

00:40:56.756 --> 00:40:58.866
Or if you're not sure what
a good preview size would be

00:40:58.866 --> 00:41:00.206
for this current platform,

00:41:00.456 --> 00:41:02.866
the PhotoOutput can pick a
good default size for you.

00:41:04.656 --> 00:41:07.986
Here's some sample code showing
how to request a preview image.

00:41:08.496 --> 00:41:11.406
After creating a photo
settings instance in one

00:41:11.406 --> 00:41:15.276
of the usual ways, you can
select a previewPixelType.

00:41:15.666 --> 00:41:19.476
Again, the photo settings
themselves can tell you

00:41:19.916 --> 00:41:23.246
which formats are
available, and they are sorted

00:41:23.546 --> 00:41:25.626
so that the most
optimal one is first.

00:41:25.786 --> 00:41:28.186
So here, I'm getting the very
first one from the array.

00:41:28.816 --> 00:41:31.246
And when I say optimal,
I mean the one

00:41:31.246 --> 00:41:33.176
that requires the
fewest conversions

00:41:33.356 --> 00:41:34.756
from the native camera.

00:41:36.346 --> 00:41:39.246
You create a CVPixelBuffer
attributes dictionary

00:41:39.246 --> 00:41:43.666
with that format type key, and
that first part is required.

00:41:43.666 --> 00:41:46.056
So if you want preview images,

00:41:46.056 --> 00:41:48.936
you have to at least specify
the format that you want.

00:41:49.606 --> 00:41:53.546
Optionally, you can also
specify a width and a height,

00:41:54.646 --> 00:41:56.196
if you want to custom size.

00:41:56.676 --> 00:41:59.826
And you don't need to know
exactly the aspect ratio

00:41:59.826 --> 00:42:00.936
of the image that
you're getting.

00:42:01.406 --> 00:42:03.826
Here I just specified
160 by 160.

00:42:03.856 --> 00:42:07.396
I don't really expect to get
a box out, but I'm using those

00:42:07.396 --> 00:42:09.546
as the max for both
width and height.

00:42:09.906 --> 00:42:12.136
And AVCapturePhotoOutput
will do the job

00:42:12.136 --> 00:42:15.626
of resizing the preview image
so that it fits in the box,

00:42:15.936 --> 00:42:17.046
preserving aspect ratio.

00:42:18.976 --> 00:42:21.626
Retrieving preview images is
also very straightforward.

00:42:22.146 --> 00:42:27.886
Here we've requested a JPEG plus
a preview image at 160 by 160.

00:42:28.926 --> 00:42:31.736
So when we get our first
callback saying we've received

00:42:31.736 --> 00:42:37.586
your order, you get a willBegin
CaptureFor ResolvedSettings

00:42:38.676 --> 00:42:41.686
and a ResolvedPhotoSettings
object which, if you notice,

00:42:41.686 --> 00:42:46.126
the previewPhotoDimensions
are not 160 by 160.

00:42:46.126 --> 00:42:49.566
They're 160 by 120
because it's been resolved

00:42:49.746 --> 00:42:52.156
to something that's
aspect ratio appropriate

00:42:52.156 --> 00:42:58.886
for the 12-megapixel
photo that you want.

00:42:58.886 --> 00:43:02.956
When the didFinish
ProcessingPhoto SampleBuffer

00:43:02.956 --> 00:43:05.346
callback finally comes, you
get not one but two images.

00:43:05.346 --> 00:43:07.886
The full-sized JPEG is
the first parameter,

00:43:08.096 --> 00:43:14.506
and the previewPhotoSampleBuffer
is the second.

00:43:14.506 --> 00:43:15.686
So if you're following
along here

00:43:15.686 --> 00:43:17.206
and adding things
up in your mind.

00:43:17.206 --> 00:43:19.446
If you do a RAW plus bracket
plus JPEG plus preview image,

00:43:19.476 --> 00:43:20.976
then you're going to get mRAWs,
mJPEGs and mpreview images.

00:43:25.656 --> 00:43:28.156
Another great use of
the preview image is

00:43:28.216 --> 00:43:32.636
as an embedded thumbnail in your
high-quality JPEG or DNG files.

00:43:33.446 --> 00:43:36.366
In this code sample, I'm using
the previewPhotoSampleBuffer

00:43:36.366 --> 00:43:40.036
parameter of my didFinish
ProcessingRAW PhotoSampleBuffer

00:43:40.036 --> 00:43:44.076
callback as an embedded
thumbnail to the DNG file.

00:43:44.666 --> 00:43:48.546
So when I call PhotoOutput's
dngPhotoDataRepresentation,

00:43:48.856 --> 00:43:51.006
I'm passing that as
the second parameter.

00:43:51.606 --> 00:43:53.496
You should always do this, okay?

00:43:53.996 --> 00:43:56.716
Embedding a thumbnail
image is always a good idea

00:43:56.926 --> 00:43:59.106
because you don't know where
it's going to be viewed.

00:43:59.646 --> 00:44:05.786
Some apps can handle
looking at the DNG bits,

00:44:05.816 --> 00:44:07.196
the RAW bits, and some can't.

00:44:07.566 --> 00:44:09.286
But if you have an
embedded thumbnail in there,

00:44:09.356 --> 00:44:10.906
everyone's going to be
able to look at something.

00:44:10.906 --> 00:44:13.656
You definitely want to do
it if you're adding a DNG

00:44:13.656 --> 00:44:16.146
to the Photo Library so
that it can give you a nice

00:44:16.146 --> 00:44:16.846
quick preview.

00:44:18.786 --> 00:44:21.976
Preview image delivery
is supported everywhere.

00:44:25.376 --> 00:44:29.736
All right, onto the last topic
of the day, which is wide color.

00:44:30.046 --> 00:44:32.976
And as you might suspect,
it's a wide topic.

00:44:37.566 --> 00:44:40.806
You've no doubt heard about the
beautiful new true toned display

00:44:40.906 --> 00:44:43.176
on our iPad Pro 9.7 inch.

00:44:43.766 --> 00:44:46.986
It's a wide-gamut
display and it's on par

00:44:46.986 --> 00:44:50.346
with the 4K and 5K iMax.

00:44:50.346 --> 00:44:53.476
It's capable of displaying
strikingly vivid reds

00:44:53.476 --> 00:44:57.406
and yellows and deeply
saturated cyans and greens.

00:44:58.446 --> 00:45:01.476
To take advantage of the
display's extended color range,

00:45:01.646 --> 00:45:05.406
we introduced color management
for the first time in iOS 9.3.

00:45:05.406 --> 00:45:06.866
I'm not sure if you
were aware of that,

00:45:06.906 --> 00:45:10.766
but we're now color managed
for the iPad Pro 9.7.

00:45:11.736 --> 00:45:15.126
And with displays this
pretty, it only makes sense

00:45:15.126 --> 00:45:17.936
to also capture photos
with equally wide color

00:45:18.426 --> 00:45:20.246
so that we enhance the
viewing experience.

00:45:20.246 --> 00:45:22.836
And so that when you look at
those several years from now,

00:45:22.836 --> 00:45:24.496
you've got more color
information.

00:45:25.116 --> 00:45:27.886
Beginning in iOS
10, photo captures

00:45:27.886 --> 00:45:30.916
on the iPad Pro 9.7 will
magically become wide

00:45:30.916 --> 00:45:31.686
color captures.

00:45:32.916 --> 00:45:35.816
Let me give you a brief overview
of what wide color means,

00:45:35.816 --> 00:45:37.766
wide color terminology, starting

00:45:37.766 --> 00:45:39.816
with the concept
of a color space.

00:45:40.456 --> 00:45:44.416
A color space describes
an environment

00:45:44.416 --> 00:45:49.766
in which colors are represented,
ordered, compared, or computed.

00:45:49.766 --> 00:45:51.896
And the most common
color space used

00:45:51.896 --> 00:45:54.186
in computer displays is sRGB.

00:45:54.456 --> 00:45:56.916
The s stands for
standards, so standard RGB.

00:45:57.716 --> 00:46:01.616
It's based on an
international spec ITU 709.

00:46:02.346 --> 00:46:06.956
It has a gamma of roughly
2.2 and a white point

00:46:06.956 --> 00:46:09.216
of 6500 degrees Kelvin.

00:46:09.706 --> 00:46:14.216
sRGB does a really good job of
representing many common colors,

00:46:14.276 --> 00:46:19.326
like faces, sky, grass,
but there are many colors

00:46:19.326 --> 00:46:21.916
that sRGB does not
reproduce very well.

00:46:21.916 --> 00:46:24.956
For instance, more than 40%

00:46:24.956 --> 00:46:28.746
of pro football jerseys are
outside of the sRBG gamut.

00:46:29.466 --> 00:46:36.376
Who knew? The iPad Pro 9.7
supports wide color using a new

00:46:36.376 --> 00:46:38.606
color space that
we call Display P3.

00:46:38.606 --> 00:46:42.736
It's similar to the
SMPTE standard DCI P3.

00:46:42.736 --> 00:46:47.356
That's a color space that's used
in digital cinema projectors.

00:46:47.526 --> 00:46:52.626
The color primaries are the same
as DCI P3, but then it differs

00:46:52.626 --> 00:46:54.136
in gamma and white point.

00:46:55.686 --> 00:46:59.776
The gamma and white point
are identical to sRGBs.

00:47:00.866 --> 00:47:02.046
Why would we do that?

00:47:02.656 --> 00:47:07.026
The reason for that is that the
DCI P3 white point is slanted

00:47:07.026 --> 00:47:08.086
toward the green side.

00:47:08.086 --> 00:47:10.966
It was chosen to
maximize brightness

00:47:11.046 --> 00:47:15.026
in dark home theater
situations and we found

00:47:15.026 --> 00:47:16.866
that with the white
point at 6500,

00:47:16.866 --> 00:47:20.576
we get a more compatible
superset of the sRGB standard.

00:47:20.806 --> 00:47:25.086
So here on this slide you
can see, in gray, the sRGB

00:47:25.086 --> 00:47:27.206
and then you can
see, super-imposed

00:47:27.206 --> 00:47:28.406
around it, the Display P3.

00:47:28.406 --> 00:47:30.776
And it does a nice job of kind

00:47:30.776 --> 00:47:33.496
of broadly covering
the superset of sRGB.

00:47:33.496 --> 00:47:36.426
And that's why we chose it.

00:47:36.696 --> 00:47:39.556
Using Apple's color
sync utility on OS 10,

00:47:39.646 --> 00:47:42.266
you can see a visual
representation of Display P3.

00:47:42.266 --> 00:47:46.076
So I took a little screen
capture here to show you.

00:47:46.126 --> 00:47:49.166
You can compare it with
sRGB in three dimensions.

00:47:49.516 --> 00:47:51.476
So here I'm selecting
Display P3,

00:47:51.476 --> 00:47:53.966
and then I do the hold
for comparison thing.

00:47:53.966 --> 00:47:54.636
That's a neat trick.

00:47:54.636 --> 00:47:56.676
And then I select sRGB.

00:47:56.676 --> 00:47:59.726
And then I see the one
super-imposed on top

00:47:59.726 --> 00:48:03.136
of the other, so you can see
sRGB inside and Display P3

00:48:03.136 --> 00:48:05.006
on the outside, and
you get a feel

00:48:05.006 --> 00:48:10.126
for just how wide the Display
P3 is compared to sRGB.

00:48:10.126 --> 00:48:12.976
And the range of representable
colors is visibly bigger.

00:48:16.766 --> 00:48:18.616
So now let's get down
to the nuts and bolts

00:48:18.616 --> 00:48:20.446
of capturing Display P3 content.

00:48:20.446 --> 00:48:24.326
For highest fidelity, the color
space of capture content has

00:48:24.326 --> 00:48:26.246
to be determined at the source.

00:48:26.616 --> 00:48:29.696
That's not something that
can flow down in sRGB

00:48:29.696 --> 00:48:31.886
and then be up-converted
to the wide.

00:48:31.886 --> 00:48:32.926
It has to start wide.

00:48:33.616 --> 00:48:35.086
So, as you might expect,

00:48:35.086 --> 00:48:37.516
the color space is
fundamentally a property

00:48:37.516 --> 00:48:40.126
of the AVCaptureDevice,
the source.

00:48:40.916 --> 00:48:42.346
So we're going to
spend some time talking

00:48:42.346 --> 00:48:44.656
about the AVCaptureDevice
and we're also going to talk

00:48:44.656 --> 00:48:46.086
about the AVCaptureSession.

00:48:46.626 --> 00:48:50.106
The session is where automatic
wide color selection can be

00:48:50.106 --> 00:48:54.216
determined for the whole session
configuration as a whole.

00:48:54.386 --> 00:48:58.786
Okay. AVCaptureDevice is how AV
Foundation represents a camera

00:48:59.336 --> 00:48:59.806
or a mic.

00:49:00.786 --> 00:49:03.706
Each AVCaptureDevice
has a format property.

00:49:04.176 --> 00:49:08.006
Formats is an array of
AVCaptureDevice formats.

00:49:08.006 --> 00:49:11.286
They are objects themselves,
and they represent the formats

00:49:11.286 --> 00:49:12.906
that the device can capture in.

00:49:13.726 --> 00:49:16.116
They come in pairs,
as you see here.

00:49:16.116 --> 00:49:18.856
For each resolution
and frame rate,

00:49:19.036 --> 00:49:23.216
there's a 402v version
and a 420f.

00:49:23.426 --> 00:49:27.666
That stands for v for
video range, 16 to 235

00:49:28.146 --> 00:49:31.276
or f for full range,
the 0 to 255.

00:49:32.436 --> 00:49:33.936
So new in iOS 10,

00:49:34.506 --> 00:49:37.456
AVCaptureDevice formats
have a new supported color

00:49:37.456 --> 00:49:38.656
spaces property.

00:49:39.336 --> 00:49:43.006
It's an array of numbers
with the possible values of 0

00:49:43.006 --> 00:49:46.996
for sRGB or 1 for P3 D65.

00:49:47.676 --> 00:49:51.496
We refer to it as Display P3
but in the API, it's referred

00:49:51.496 --> 00:49:57.346
to as P3 D65, the d
standing for display and 65

00:49:57.346 --> 00:50:01.346
for the 6500 Kelvin white point.

00:50:01.486 --> 00:50:06.916
On an iPad Pro 9.7, the 420v
formats only support sRGB.

00:50:07.966 --> 00:50:12.156
But the full-range 420f
formats support either sRGB

00:50:12.476 --> 00:50:13.546
or Display P3.

00:50:13.546 --> 00:50:17.756
The device has a settable
active format property.

00:50:17.756 --> 00:50:18.456
That's not new.

00:50:19.156 --> 00:50:20.716
So that one of the formats

00:50:20.716 --> 00:50:22.726
in the list is always
the activeFormat.

00:50:23.016 --> 00:50:24.876
As you can see here,
I've put a yellow box

00:50:24.876 --> 00:50:26.016
around the one that is active.

00:50:26.366 --> 00:50:29.456
It happens to be the
12-megapixel 30 FPS version.

00:50:29.456 --> 00:50:34.066
And if that activeFormat,
the f format,

00:50:34.376 --> 00:50:38.376
happens to support Display P3,
then there's a new property

00:50:38.376 --> 00:50:40.976
that you can set
called activeColorSpace.

00:50:40.976 --> 00:50:45.176
And if the activeFormat supports
it, you get wide color flowing

00:50:45.176 --> 00:50:47.946
from your source to all
outputs in the session.

00:50:49.286 --> 00:50:52.156
That was longwinded, but what
I wanted you to take home

00:50:52.156 --> 00:50:54.776
from this is hopefully you
don't have to do any of this.

00:50:55.106 --> 00:50:56.336
Most clients will never need

00:50:56.336 --> 00:50:58.986
to set the activeColorSpace
directly and that's

00:50:58.986 --> 00:51:01.346
because AVCaptureSession
will try to do it

00:51:01.346 --> 00:51:02.246
for you automatically.

00:51:02.846 --> 00:51:07.686
So in iOS 10, AVCaptureSession
has a new property that's long,

00:51:08.026 --> 00:51:12.066
automaticallyConfigures
CaptureDeviceForWideColor.

00:51:13.016 --> 00:51:15.356
When does it want to
choose wide color for you?

00:51:16.516 --> 00:51:20.046
Wide color, in iOS 10,
is only for photography.

00:51:20.416 --> 00:51:21.446
Let me say that again.

00:51:22.396 --> 00:51:26.716
Wide color, in iOS 10, is only
for photography, not for video.

00:51:26.716 --> 00:51:29.436
I'll explain why in a minute.

00:51:30.696 --> 00:51:31.876
It can automatically,

00:51:31.876 --> 00:51:33.906
the session can automatically
choose whether

00:51:33.906 --> 00:51:37.526
to configure the whole session
configuration for wide color.

00:51:37.806 --> 00:51:41.516
It will set the activeColorSpace
of your device on your behalf

00:51:41.516 --> 00:51:43.696
to P3, depending on your config.

00:51:44.356 --> 00:51:46.276
You have to have a PhotoOutput

00:51:46.276 --> 00:51:47.836
in your session for
this to happen.

00:51:48.296 --> 00:51:49.586
If you don't have a PhotoOutput,

00:51:49.806 --> 00:51:51.406
you're obviously not
doing photography,

00:51:51.616 --> 00:51:52.726
so you don't need wide color.

00:51:52.876 --> 00:51:56.126
There are some caveats here.

00:51:56.216 --> 00:51:58.786
Like, if you start adding
other outputs to your session,

00:51:59.096 --> 00:52:01.336
maybe it's not as clear
what you're trying to do.

00:52:02.256 --> 00:52:05.016
If you add an
AVCaptureVideoPreviewLayer,

00:52:05.456 --> 00:52:10.756
the session will automatically
still pick Display P3 for you

00:52:11.166 --> 00:52:13.746
because you're just previewing
and also doing photography.

00:52:13.746 --> 00:52:15.926
If you have a MovieFileOutput

00:52:16.016 --> 00:52:18.546
and a PhotoOutput,
now it's ambiguous.

00:52:18.546 --> 00:52:20.336
You might really care
more about movies,

00:52:20.566 --> 00:52:24.096
so it will not automatically
pick Display P3 for you.

00:52:24.596 --> 00:52:28.656
VideoDataOutput is a special
case where we deliver buffers

00:52:28.656 --> 00:52:31.226
to you via a callback and there,

00:52:31.356 --> 00:52:33.146
the session will
only pick Display P3

00:52:33.146 --> 00:52:35.356
if you're using the
photo preset.

00:52:35.856 --> 00:52:38.196
It's pretty sure if you're
doing that that you mean

00:52:38.196 --> 00:52:40.656
to do photography stuff
with those display buffers.

00:52:41.926 --> 00:52:45.566
If you really, really want to,
you can force the capture device

00:52:45.566 --> 00:52:47.636
to do wide color and here's how.

00:52:47.886 --> 00:52:51.346
First you would tell the
session stop automatically doing

00:52:51.346 --> 00:52:52.096
that thing for me.

00:52:52.096 --> 00:52:52.956
Get out of my way.

00:52:54.036 --> 00:52:56.386
And then you would
go to the device

00:52:56.386 --> 00:52:57.936
and set the active
format yourself

00:52:57.936 --> 00:52:59.626
to a format that's
supports wide color.

00:53:00.156 --> 00:53:03.656
And then you would set the
activeColorSpace to P3.

00:53:04.466 --> 00:53:09.216
Once you do this, wide color
buffers will flow to all outputs

00:53:09.246 --> 00:53:10.416
that accept video data.

00:53:10.606 --> 00:53:13.326
That includes VideoDataOutput,
MovieFileOutput,

00:53:13.706 --> 00:53:16.546
even the deprecated
AVCaptureStillImageOutput.

00:53:18.196 --> 00:53:22.256
So while you can forcibly set
the device's activeColorSpace

00:53:22.256 --> 00:53:25.676
to display P3, I want
to strongly caution you

00:53:25.676 --> 00:53:27.506
against doing it
unless you really,

00:53:27.506 --> 00:53:28.476
really know what you're doing.

00:53:29.546 --> 00:53:32.546
The reason is wide
color is for photos

00:53:32.726 --> 00:53:36.486
because we have a good photo
ecosystem story for wide color,

00:53:36.836 --> 00:53:38.536
not so much for video.

00:53:39.186 --> 00:53:41.616
So the main worry with
Display P3 content is

00:53:41.616 --> 00:53:44.226
that the consumer has
to be wide color-aware

00:53:44.526 --> 00:53:46.746
or your content will
be rendered as sRGB,

00:53:46.746 --> 00:53:48.356
and the colors will
all look wrong.

00:53:48.776 --> 00:53:49.766
They'll be rendered badly.

00:53:50.456 --> 00:53:53.286
Most video playback
services are not color-aware.

00:53:53.586 --> 00:53:59.046
So if you store a wide Display
P3 movie and then you try

00:53:59.046 --> 00:54:01.456
to play it back with
some service,

00:54:01.826 --> 00:54:03.986
it will likely render
the colors wrong.

00:54:05.126 --> 00:54:06.776
So if you do choose to do this,

00:54:06.776 --> 00:54:09.636
make sure that your
VideoDataOutput is color-aware.

00:54:10.136 --> 00:54:11.736
That it's propagating
the color tags.

00:54:11.736 --> 00:54:13.336
That it's doing something
sensible.

00:54:13.336 --> 00:54:14.126
That it's color-aware.

00:54:14.746 --> 00:54:19.336
And if you do choose to capture
Display P3 movies using the

00:54:19.336 --> 00:54:21.426
MovieFileOutput, just be aware

00:54:21.426 --> 00:54:25.376
that they may render
incorrectly on other platforms.

00:54:25.376 --> 00:54:28.496
This is -- we do allow this,
though, because we recognize

00:54:28.496 --> 00:54:33.436
that it's important for some
pro workflows to be able

00:54:33.436 --> 00:54:35.326
to do wide color movies as well.

00:54:36.266 --> 00:54:39.576
So now dire warnings out
of the way, I can tell you

00:54:39.576 --> 00:54:42.176
that we do have a very
good solution for photos

00:54:42.316 --> 00:54:43.896
in sharing wide colors.

00:54:44.556 --> 00:54:47.756
We should be aware that wide
color JPEGs use a Display P3

00:54:47.756 --> 00:54:50.996
profile and consumers of
these images also need

00:54:50.996 --> 00:54:51.876
to be color-aware.

00:54:52.366 --> 00:54:56.426
The good news is photo services,
in general, are photo color --

00:54:56.576 --> 00:54:58.086
they are color-aware these days.

00:54:58.636 --> 00:55:00.516
iCloud Photo Library
is one of them.

00:55:00.696 --> 00:55:05.086
It can intelligently convert
your images to sRGB on devices

00:55:05.086 --> 00:55:06.296
that don't support wide color,

00:55:06.996 --> 00:55:10.416
but store the nice wide
color in the cloud.

00:55:10.416 --> 00:55:14.026
We're also an industry
in transition right now,

00:55:14.026 --> 00:55:17.836
so some photo services
don't understand wide color,

00:55:17.836 --> 00:55:19.806
but most of them at
least are smart enough

00:55:19.806 --> 00:55:22.296
to render it as sRGB.

00:55:23.476 --> 00:55:25.416
For mixed sharing scenarios,

00:55:25.416 --> 00:55:28.666
like say sending a photo
via Messages or Mail.

00:55:28.976 --> 00:55:30.066
You don't know where it's going.

00:55:30.196 --> 00:55:31.996
It might be going
to multiple devices.

00:55:32.416 --> 00:55:34.066
Some of them might
support wide color.

00:55:34.066 --> 00:55:34.786
Some might not.

00:55:35.226 --> 00:55:40.266
So for this situation, we have
added a new service called Apple

00:55:40.266 --> 00:55:42.206
Wide Color Sharing Profile.

00:55:42.986 --> 00:55:47.966
Your content can be
manipulated in a way

00:55:47.966 --> 00:55:52.926
that we generate a content
specific table-based ICC profile

00:55:53.236 --> 00:55:56.556
that's specific to
that particular JPEG.

00:55:57.306 --> 00:56:00.496
And what's nice about it is
if it's rendered by someone

00:56:00.496 --> 00:56:02.646
who doesn't know about
wide color, the part that's

00:56:02.646 --> 00:56:05.526
in the sRGB gamut renders
absolutely correctly.

00:56:06.016 --> 00:56:08.046
The extra information is carried

00:56:08.296 --> 00:56:11.056
in the extra ICC profile
information in a way

00:56:11.056 --> 00:56:14.176
that they can recover the
wide color information

00:56:14.176 --> 00:56:15.976
with minimal quality loss.

00:56:16.316 --> 00:56:20.096
You can learn more about how
to share wide color content

00:56:20.096 --> 00:56:24.246
in sessions 505 and 712.

00:56:24.326 --> 00:56:25.586
Both of those are on Thursday.

00:56:25.906 --> 00:56:27.896
I've talked about the
first one three times now.

00:56:28.316 --> 00:56:31.226
The working with wide color one
is also an excellent session.

00:56:32.936 --> 00:56:34.936
On iPad Pro 9.7,

00:56:35.036 --> 00:56:38.216
the AVCapturePhotoOutput
supports wide color broadly.

00:56:38.436 --> 00:56:44.476
It supports it in 420f, BGRA
and JPEG, just not for 420v.

00:56:44.506 --> 00:56:49.386
So if you have your session
configured to give Display P3

00:56:49.386 --> 00:56:51.986
but then you say you
want a 420v image,

00:56:52.306 --> 00:56:56.306
it will be converted to sRGB.

00:56:56.306 --> 00:56:59.146
Live Photos support wide color.

00:56:59.386 --> 00:57:01.066
Both the still and the movie.

00:57:01.266 --> 00:57:02.446
These are special movies.

00:57:02.446 --> 00:57:03.816
This is part of the
Apple ecosystem.

00:57:03.816 --> 00:57:05.476
So those are just
going to be wide color.

00:57:06.976 --> 00:57:09.836
And bracketed captures also
support wide color, too.

00:57:12.236 --> 00:57:14.256
Here's an interesting twist.

00:57:14.256 --> 00:57:17.076
While I've been talking
about iPad Pro, iPad Pro,

00:57:17.076 --> 00:57:20.136
iPad Pro, we support RAW.

00:57:20.496 --> 00:57:25.946
And RAW capture is inherently
wide color because it has all

00:57:25.946 --> 00:57:27.486
of those extra bits
of information.

00:57:27.976 --> 00:57:29.916
We store it in the
sensor primaries

00:57:30.426 --> 00:57:32.576
and there is enough
color information there

00:57:32.576 --> 00:57:36.986
to be either rendered
as wide or sRGB.

00:57:37.066 --> 00:57:40.066
Again, you're carrying the
ingredients around with you.

00:57:40.066 --> 00:57:43.756
You can decide later if you want
to render it as wide or sRGB.

00:57:44.266 --> 00:57:46.676
So shooting RAW and
rendering in post,

00:57:47.106 --> 00:57:50.216
you can produce wide
color content on lots

00:57:50.216 --> 00:57:51.976
of iOS devices, not
just iPad Pro.

00:57:55.066 --> 00:57:59.456
As I just said, you can learn
more on wide color, in general,

00:57:59.456 --> 00:58:01.906
not just sharing but
all about wide color.

00:58:02.066 --> 00:58:04.806
The best session to view is
the working with wide color one

00:58:04.906 --> 00:58:05.916
on Thursday afternoon.

00:58:08.026 --> 00:58:11.606
Use AVCapturePhotoOutput
for improved usability.

00:58:12.676 --> 00:58:14.916
And we talked about four
main feature areas today.

00:58:14.916 --> 00:58:16.466
We talked about capturing
Live Photos

00:58:16.466 --> 00:58:21.266
in your app, RAW,
RAW + JPEG, DNG.

00:58:22.216 --> 00:58:24.966
Nice little preview images
for faster rendering.

00:58:25.676 --> 00:58:27.346
And wide color photos.

00:58:28.646 --> 00:58:32.056
And believe it or not,
one hour was not enough

00:58:32.056 --> 00:58:33.626
to cover everything
that we wanted to cover.

00:58:33.626 --> 00:58:36.326
So we've done an
addendum to this session.

00:58:36.326 --> 00:58:37.736
It's already recorded.

00:58:37.816 --> 00:58:39.146
It should already be online.

00:58:39.766 --> 00:58:41.766
It's a slide plus
voiceover thing

00:58:41.766 --> 00:58:44.126
that we're calling a Chalk Talk.

00:58:44.126 --> 00:58:46.896
And it tells you
about in-depth topics

00:58:46.896 --> 00:58:48.006
that we didn't have time for.

00:58:48.456 --> 00:58:51.016
Scene monitoring in
AVCapturePhotoOutput.

00:58:51.696 --> 00:58:54.086
Resource preparation
and reclamation.

00:58:54.406 --> 00:58:56.886
And then an unrelated topic,

00:58:56.886 --> 00:59:00.046
changes to camera
privacy policy in iOS 10.

00:59:00.046 --> 00:59:01.436
So please take a
look at that video.

00:59:01.436 --> 00:59:02.556
It's about 20 minutes long.

00:59:04.426 --> 00:59:05.346
More information.

00:59:05.526 --> 00:59:07.686
All you need to remember
is the 501 at the end.

00:59:07.876 --> 00:59:10.596
Go to that and you'll find,
I believe, seven pieces

00:59:10.596 --> 00:59:13.446
of sample code as well
as new documentation

00:59:13.446 --> 00:59:14.786
for AVCapturePhotoOutput.

00:59:14.836 --> 00:59:17.186
The documentation folks
have been working very hard

00:59:17.186 --> 00:59:20.186
and they've documented
the heck out of it.

00:59:20.436 --> 00:59:22.806
And here are the related
sessions one more time.

00:59:23.466 --> 00:59:25.466
The one that is the Chalk Talk,

00:59:25.466 --> 00:59:27.936
we're calling
AVCapturePhotoOutput beyond

00:59:27.936 --> 00:59:28.606
the basics.

00:59:29.046 --> 00:59:30.536
And you can look at
that any time you want.

00:59:30.536 --> 00:59:30.716
All right.

00:59:30.716 --> 00:59:32.976
Have a great rest of the show,
and thank you for coming.

00:59:33.508 --> 00:59:35.508
[ Applause ]