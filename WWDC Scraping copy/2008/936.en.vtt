WEBVTT

00:00:12.770 --> 00:00:13.400
Well, good morning.

00:00:13.400 --> 00:00:17.620
My name is James Reinders,
and I work for Intel.

00:00:17.780 --> 00:00:21.250
I have the pleasure this morning
of starting off a couple of

00:00:21.330 --> 00:00:25.140
talks on how to use parallelism,
some things about parallelism.

00:00:25.140 --> 00:00:30.290
I'm going to talk this
morning first about,

00:00:30.290 --> 00:00:30.290
um,

00:00:31.200 --> 00:00:53.700
[Transcript missing]

00:00:54.150 --> 00:00:57.000
for more than a couple of decades.

00:00:57.000 --> 00:01:01.120
I've worked on small-level parallelism,
large-level parallelism,

00:01:01.120 --> 00:01:06.160
and I guess I didn't think that the
day would come when all of us would

00:01:06.160 --> 00:01:08.870
get a chance to work with parallelism.

00:01:08.880 --> 00:01:10.360
I'm having fun with it.

00:01:10.360 --> 00:01:13.190
I have two quad core
machines at home already,

00:01:13.190 --> 00:01:16.090
and I expect that
number to keep going up.

00:01:16.090 --> 00:01:19.520
It's fun to have some parallelism,
even at home.

00:01:19.570 --> 00:01:22.330
Of course,
my wonderful Apple laptop's a dual core,

00:01:22.430 --> 00:01:24.760
so that's pretty cool.

00:01:24.770 --> 00:01:30.560
So hopefully what you get from my talk
this morning is a way to judge the

00:01:30.950 --> 00:01:34.380
different ways to use parallelism,
the likelihood of being

00:01:34.500 --> 00:01:39.180
successful with it for now and
carrying it into the future.

00:01:39.480 --> 00:01:42.400
Herb Sutter likes to talk about
the concurrency land rush.

00:01:42.400 --> 00:01:46.420
I think that's something he blogged about
and it amused me because you're just

00:01:46.560 --> 00:01:48.400
starting to see a lot of announcements.

00:01:48.400 --> 00:01:50.240
Hey, try this for parallelism.

00:01:50.240 --> 00:01:51.550
Use this, use that.

00:01:51.560 --> 00:01:57.280
So hopefully I can give a little bit of a
perspective on the questions you can ask

00:01:57.280 --> 00:02:01.100
back about is this the solution for me,
what will work.

00:02:01.150 --> 00:02:06.510
And what's fun is there are a lot of
great solutions today already available,

00:02:06.510 --> 00:02:09.280
but there's many more to come.

00:02:11.400 --> 00:02:20.800
So let me start off and sort of level
set what we're talking about here.

00:02:20.940 --> 00:02:27.000
So beginning off the week,
I heard a comment that's pretty common.

00:02:27.000 --> 00:02:32.850
People often just say, hey,
processors are going

00:02:32.850 --> 00:02:35.070
multi-core because of power.

00:02:35.820 --> 00:02:43.470
James Reiners:
That's a good reason to keep in mind,

00:02:43.470 --> 00:02:44.900
but there's actually three problems
microprocessors were having with

00:02:44.900 --> 00:02:45.700
ever-increasing clock rates.

00:02:45.930 --> 00:02:48.360
And to me,
the reason it's important to know

00:02:48.360 --> 00:02:51.740
that there were three reasons and
not just one is that we aren't

00:02:51.740 --> 00:02:54.740
going to get a breakthrough one
day on one of these and suddenly

00:02:54.740 --> 00:02:56.700
go back to single-core processors.

00:02:57.040 --> 00:03:12.060
So the three reasons are power is one.

00:03:13.170 --> 00:03:13.200
Every time we doubled the
frequency on a processor,

00:03:13.200 --> 00:03:13.200
the power consumption quadrupled.

00:03:13.200 --> 00:03:13.200
Well, we would shrink it in half,
so it only doubled.

00:03:13.200 --> 00:03:13.200
So every time we increased the frequency,
the power doubled.

00:03:13.280 --> 00:03:14.960
But the other thing is,
we were getting into more

00:03:14.960 --> 00:03:17.040
and more trouble where when
you increase the frequency,

00:03:17.040 --> 00:03:18.160
what are you trying to do with it?

00:03:18.160 --> 00:03:20.740
You're trying to execute more
instructions in parallel,

00:03:20.740 --> 00:03:22.760
instruction level parallelism.

00:03:22.800 --> 00:03:25.340
And that was getting
harder and harder to find,

00:03:25.380 --> 00:03:27.800
at least at the clock
rates we're talking about.

00:03:27.860 --> 00:03:29.950
And then memory's not getting faster.

00:03:30.020 --> 00:03:32.540
So lo and behold,
the faster we make a processor,

00:03:32.540 --> 00:03:35.100
the more we wait for memory.

00:03:35.100 --> 00:03:38.090
These three walls,

00:03:38.330 --> 00:03:45.680
We're putting the damper on,
increasing clock frequency.

00:03:45.680 --> 00:03:45.680
So we're doing...

00:03:45.990 --> 00:03:53.070
James Reiners: So,
we're going to talk about

00:03:53.090 --> 00:03:53.330
multi-core processors as a solution.

00:03:53.330 --> 00:03:53.640
And we see that in
several different domains.

00:03:53.640 --> 00:03:58.080
And one thing that is useful
to think about is GPUs,

00:03:58.430 --> 00:04:01.300
as they get talked about,
are actually multi-core processors.

00:04:01.300 --> 00:04:05.840
So, there were some graphs earlier this
week that drive me a little nuts.

00:04:05.930 --> 00:04:06.900
Some of you may have seen them.

00:04:06.900 --> 00:04:09.780
CPUs flatline, GPUs going faster.

00:04:09.780 --> 00:04:14.650
Well, that's kind of cool,
but the GPUs were growing at Moore's Law,

00:04:14.650 --> 00:04:15.880
doubling about every 18 months.

00:04:15.900 --> 00:04:17.340
And the CPU was flat.

00:04:17.340 --> 00:04:18.940
And why was that?

00:04:18.960 --> 00:04:22.150
Well, it was because they weren't
counting the multi-core aspects.

00:04:22.330 --> 00:04:25.280
Unfortunately,
when you say that GPUs are speeding up,

00:04:25.310 --> 00:04:27.520
you're giving them credit
for their multi-core aspects.

00:04:27.600 --> 00:04:29.900
When you flatline CPUs,
you're not giving them credit.

00:04:29.900 --> 00:04:34.210
Eh, you know, maybe a nit,
but it may overstate how much fun

00:04:34.210 --> 00:04:36.850
GPUs are compared to multi-core.

00:04:37.080 --> 00:04:39.160
But I'll get back to
that about programming,

00:04:39.290 --> 00:04:42.280
because there's a lot of fun
in architecture ahead of time.

00:04:42.960 --> 00:04:49.200
So when we were doubling the clock
frequency every 18 months or so,

00:04:49.350 --> 00:04:52.500
programs just got faster, sort of.

00:04:52.560 --> 00:04:56.780
I never quite saw a program run
twice as fast on a 2 gigahertz

00:04:56.880 --> 00:04:59.930
machine as it did on a 1,
but close enough.

00:05:00.980 --> 00:05:04.820
But now with multi-core,
obviously we need to see

00:05:04.820 --> 00:05:07.220
parallelism at some level.

00:05:07.230 --> 00:05:10.980
Multiple programs running,
one program using multiple threads,

00:05:11.040 --> 00:05:17.730
whatever.

00:05:18.830 --> 00:05:18.830
So this has been called
the free lunch is over.

00:05:18.830 --> 00:05:18.830
Pretty basic stuff.

00:05:19.460 --> 00:05:20.680
And how fast is it happening?

00:05:20.680 --> 00:05:24.440
Well, you know, Intel didn't invent
multi-core processors.

00:05:24.440 --> 00:05:28.240
Putting two cores on a die or multiple
threads has been around a while,

00:05:28.240 --> 00:05:32.310
but if you look at
Intel architecture at x86,

00:05:32.350 --> 00:05:37.260
dual cores come out in 2005,
followed by quad cores in 2006.

00:05:37.260 --> 00:05:40.260
We'll be shipping six-core
processors this year.

00:05:40.260 --> 00:05:43.220
Eight-core processors
will be not far behind.

00:05:43.220 --> 00:05:45.960
The trend is there.

00:05:45.960 --> 00:05:50.050
And it's not very difficult to get a
four- or an eight-core machine or even

00:05:50.050 --> 00:05:54.180
16-core these days because you just
put a few of the processors together.

00:05:54.180 --> 00:05:57.160
So parallelism is really, really here.

00:05:57.160 --> 00:06:00.320
In fact,
to go a little further and -- well,

00:06:00.320 --> 00:06:03.010
we demoed an 80-core research chip.

00:06:03.010 --> 00:06:05.280
But going a little further and say,
you know,

00:06:05.510 --> 00:06:21.010
James Reiners: A prediction.

00:06:21.010 --> 00:06:21.010
This is not a roadmap announcement.

00:06:21.010 --> 00:06:21.010
Of course, it's an NDA event,
so don't run off and, you know,

00:06:21.010 --> 00:06:21.010
blog too much.

00:06:21.010 --> 00:06:21.010
But within two years,
you're going to be able to walk

00:06:21.010 --> 00:06:21.010
down to your favorite store,
and I just listed a bunch.

00:06:21.320 --> 00:06:40.780
James Reiners: And you'll be able to buy
machines with more than 16 cores.

00:06:40.780 --> 00:06:40.780
And I'm not talking exotic,
super expensive machines.

00:06:40.780 --> 00:06:40.780
In fact, I'll go further.

00:06:40.780 --> 00:06:40.780
I actually think that inside three years,
it's going to be closer to 40 cores.

00:06:40.780 --> 00:06:40.780
Now, that may sound a little audacious.

00:06:41.330 --> 00:06:56.680
James Reiners:
So I think that graphics is going

00:06:56.680 --> 00:06:58.960
to drive a desire for multi-core.

00:06:58.990 --> 00:07:03.000
I think you're already seeing hints of
that with the interest in using GPUs,

00:07:03.050 --> 00:07:09.100
but I think it's actually long-term going
to be a question of multi-core CPUs.

00:07:11.030 --> 00:07:13.290
So here's, you know, your basic graph.

00:07:13.410 --> 00:07:14.250
Free lunch is over.

00:07:14.300 --> 00:07:16.660
It means we've got to
do some concurrency.

00:07:16.690 --> 00:07:18.750
Now,
a couple of things I want to point out,

00:07:18.760 --> 00:07:25.700
the way I draw this graph is we're going
from a gigahertz era to a multi-core era.

00:07:26.030 --> 00:07:28.860
Multi-core to me is two, four,
eight processors.

00:07:28.860 --> 00:07:32.460
But then I have this
mysterious term on here,

00:07:32.460 --> 00:07:33.610
many-core.

00:07:33.940 --> 00:07:36.240
While we're all trying to
figure out how to take our

00:07:36.240 --> 00:07:40.600
applications and start using two,
four, eight cores,

00:07:40.640 --> 00:07:45.970
out there looming is this idea of what
I call "many core." And many core,

00:07:45.970 --> 00:07:48.870
to me, is more than 16 cores.

00:07:49.660 --> 00:07:52.140
And I'm going to go through
some of the fundamental issues

00:07:52.140 --> 00:07:55.000
we face with parallelism,
and one of them is scalability.

00:07:55.000 --> 00:07:58.500
And let me tell you,
when you get past 16 cores,

00:07:58.500 --> 00:08:01.280
you really have to have your
act together with parallelism.

00:08:01.280 --> 00:08:02.840
You can't get away with band-aids.

00:08:02.840 --> 00:08:07.800
And this many-core,
or I actually called it tera-scale here,

00:08:07.800 --> 00:08:11.150
it's another term that's
popularly thrown around for this,

00:08:11.150 --> 00:08:16.510
tera-scale, more than 16 cores,
it's going to be a reality,

00:08:16.510 --> 00:08:21.900
and it's going to be a reality before the
whole industry is embracing multi-core.

00:08:21.900 --> 00:08:25.490
To me, that's very exciting,
but it really drives home the point

00:08:25.490 --> 00:08:27.860
we need to worry about parallelism.

00:08:27.860 --> 00:08:31.940
In fact, within a decade,
being a programmer and saying,

00:08:31.940 --> 00:08:32.820
I don't do parallelism.

00:08:32.840 --> 00:08:34.810
Really bad idea.

00:08:34.810 --> 00:08:36.300
Really bad idea.

00:08:36.300 --> 00:08:39.800
You might as well just go find another
profession in 10 years if you don't

00:08:39.840 --> 00:08:42.220
know something about parallelism.

00:08:42.220 --> 00:08:44.340
So, are we ready for this?

00:08:46.180 --> 00:08:48.710
It's Friday morning.

00:08:48.980 --> 00:08:51.040
It's been a long week.

00:08:51.040 --> 00:08:52.190
So I thought I'd have a little fun.

00:08:52.300 --> 00:08:54.060
Let's grab some mail.

00:08:54.140 --> 00:08:56.980
And hopefully this is
not too corny for us all,

00:08:56.980 --> 00:08:58.350
but wake you up a little bit.

00:08:58.440 --> 00:09:04.460
So these are, I've changed the names
to protect the innocent.

00:09:06.280 --> 00:09:10.340
James Reiners: So I completely rewrote my
code again for octa-core.

00:09:10.340 --> 00:09:13.690
It ran great on dual-core,
but it ran terrible on octa-core.

00:09:13.790 --> 00:09:15.530
Actually,
I think I saw something like this on

00:09:15.540 --> 00:09:17.200
the Apple performance mailing list.

00:09:17.200 --> 00:09:20.940
And I also don't understand Joe's code.

00:09:21.370 --> 00:09:25.200
So it's easier,
my new code's easy for me to read,

00:09:25.330 --> 00:09:26.980
but no one else will understand it.

00:09:27.100 --> 00:09:29.920
This is a very common
thing in parallelism is,

00:09:29.920 --> 00:09:33.000
you know,
you get something tuned on a few cores,

00:09:33.110 --> 00:09:34.820
it doesn't work on a few more.

00:09:35.180 --> 00:09:36.180
I can't read your code,
I can't read your code.

00:09:36.200 --> 00:09:39.020
So I call it spaghetti threading.

00:09:39.030 --> 00:09:41.860
It's a term that seems
to make sense to people.

00:09:41.860 --> 00:09:43.840
And when you see spaghetti threading,
you know it.

00:09:43.840 --> 00:09:46.570
This is when you are
tweaking all these things,

00:09:46.580 --> 00:09:48.650
you're playing with P threads,
and you're just getting

00:09:48.720 --> 00:09:50.900
a little too exotic,
a little too smart for yourself.

00:09:51.070 --> 00:09:54.110
So in any case,
code that looks like spaghetti,

00:09:54.140 --> 00:09:59.760
code that's been crafted really
close to the hardware and so forth,

00:09:59.760 --> 00:10:04.560
very difficult to debug, hard to scale.

00:10:04.560 --> 00:10:04.560
So

00:10:04.970 --> 00:10:07.730
The first key point I want to make
is you really need to look for

00:10:07.730 --> 00:10:10.720
ways to abstract your parallelism.

00:10:11.030 --> 00:10:15.800
One of the things I think that most
people have come to agree is that we

00:10:15.800 --> 00:10:21.010
need to program in tasks and not threads.

00:10:21.100 --> 00:12:12.100
[Transcript missing]

00:12:13.950 --> 00:12:18.540
So I do have my three favorite
things to talk about when people say,

00:12:18.540 --> 00:12:20.100
what should I use for parallelism?

00:12:20.100 --> 00:12:22.900
Threaded libraries.

00:12:22.900 --> 00:12:25.900
No particular threaded library.

00:12:25.900 --> 00:12:30.220
I just like the concept that if my
work can get done in parallel and

00:12:30.220 --> 00:12:34.560
someone else can write the code,
I might as well let them do it.

00:12:34.980 --> 00:12:37.840
So, you know,
there's some excellent examples.

00:12:37.840 --> 00:12:41.600
Scientific people can use
different math libraries.

00:12:41.600 --> 00:12:43.960
Intel has a math kernel library.

00:12:43.960 --> 00:12:49.230
If you're doing animation, you know,
you can rely on the Apple core

00:12:49.240 --> 00:12:54.370
animation capabilities and let
Apple do the work getting those to

00:12:54.370 --> 00:12:57.340
run in parallel and you call them.

00:12:57.340 --> 00:12:58.940
So it's kind of funny.

00:12:58.940 --> 00:13:02.380
The reason I put this one first
is it's the easiest to do.

00:13:02.380 --> 00:13:04.960
It doesn't apply to a lot of your work.

00:13:04.960 --> 00:13:07.900
It doesn't apply to all of
your program necessarily.

00:13:07.900 --> 00:13:09.740
But it's also often overlooked.

00:13:09.740 --> 00:13:11.880
You know,
it's really a lot of fun to take

00:13:11.880 --> 00:13:14.930
a program and make a few calls
to a better threaded library

00:13:14.930 --> 00:13:16.510
and have it run a lot faster.

00:13:16.510 --> 00:13:17.870
Don't overlook it.

00:13:17.940 --> 00:13:20.610
Another capability is OpenMP.

00:13:20.610 --> 00:13:25.170
This is available in many,
many different compilers.

00:13:25.170 --> 00:13:27.800
It's a C and Fortran construct.

00:13:27.820 --> 00:13:32.540
It's been around for
about 11 or 12 years now.

00:13:32.540 --> 00:13:37.520
And it's a... It's hints to the compiler.

00:13:37.520 --> 00:13:40.420
Compilers aren't quite smart
enough to run stuff in parallel.

00:13:40.420 --> 00:13:43.240
You put a few hints before
a loop and off you go.

00:13:43.240 --> 00:13:45.980
Again, really easy to use.

00:13:45.980 --> 00:13:47.100
Very practical.

00:13:47.180 --> 00:13:48.160
It scales.

00:13:48.160 --> 00:13:51.040
It tends to keep you away
from programming bugs,

00:13:51.040 --> 00:13:51.810
so forth.

00:13:51.820 --> 00:13:54.790
Finally, we've got Intel threading
building blocks.

00:13:54.820 --> 00:13:59.960
Been a very successful way to
extend C++ for parallelism.

00:13:59.960 --> 00:14:02.040
Very aimed at C++ programmers.

00:14:02.040 --> 00:14:04.820
Addresses key issues
of thread separation.

00:14:04.980 --> 00:14:06.130
Safe data structures.

00:14:06.220 --> 00:14:08.390
How to program and task.

00:14:08.500 --> 00:14:10.800
How to do scalable memory allocation.

00:14:10.830 --> 00:14:13.380
Definitely worth a look.

00:14:15.340 --> 00:14:19.790
Threading Building Blocks,
full disclosure here, yes,

00:14:19.930 --> 00:14:22.070
this is my O'Reilly book on
Threading Building Blocks.

00:14:22.070 --> 00:14:29.140
It's a really aggressive,
fun way to thread C++ code.

00:14:29.140 --> 00:14:33.420
We've had some fantastic programs
come out over the last year.

00:14:33.420 --> 00:14:36.160
It's been ported to many, many platforms.

00:14:36.160 --> 00:14:41.510
It's been on Mac since the first days.

00:14:41.510 --> 00:14:45.280
It's on G5 machines as well as Intel.

00:14:45.340 --> 00:14:47.580
It's been ported to Intel-based machines.

00:14:47.580 --> 00:14:48.960
It's been ported to Xbox.

00:14:48.960 --> 00:14:50.880
It's been ported to Spark machines.

00:14:50.950 --> 00:14:53.880
It's widely available on many,
many different processors

00:14:53.880 --> 00:14:55.560
and many operating systems.

00:14:55.560 --> 00:14:59.720
So it's quick becoming a very common
way to get parallelism in C++.

00:14:59.720 --> 00:15:02.730
Very worthwhile looking at
if you're a C++ programmer

00:15:02.730 --> 00:15:04.550
looking to add parallelism.

00:15:08.310 --> 00:15:11.070
Hmm, more mail.

00:15:11.150 --> 00:15:16.400
My program crashes mysteriously,
but only some of the time.

00:15:16.400 --> 00:15:19.580
And it always works when
I run it inside the debugger.

00:15:19.640 --> 00:15:20.960
What shall I do?

00:15:20.960 --> 00:15:24.000
Signed into omittant.

00:15:25.600 --> 00:15:29.610
I'd love to get some customers
up on stage of our tools,

00:15:29.720 --> 00:15:34.460
because Intel does a variety of tools,
including some that can find

00:15:34.460 --> 00:15:36.950
race conditions and deadlock.

00:15:37.000 --> 00:15:43.220
This is a very common problem,
and it's worth talking about a little.

00:15:43.270 --> 00:15:46.340
You write a parallel program and
then it becomes intermittent.

00:15:46.340 --> 00:15:48.180
It doesn't run the same all the time.

00:15:48.180 --> 00:15:53.700
And the two key issues are
race conditions and deadlock.

00:15:53.970 --> 00:15:59.160
A race condition happens when you don't
synchronize the way that you should,

00:15:59.160 --> 00:16:03.050
and deadlock is when you're
over-synchronized or your one

00:16:03.060 --> 00:16:04.790
part is waiting for another part.

00:16:04.800 --> 00:16:10.010
But what really is important here
is there are actually some ways to

00:16:10.010 --> 00:16:14.120
program that are more likely to run
into these problems and other ways not.

00:16:14.600 --> 00:16:17.600
If you're calling a threaded library,
if you're doing OpenMP,

00:16:17.600 --> 00:16:19.010
if you're doing Threading
Building Blocks,

00:16:19.010 --> 00:16:23.460
if you're doing NSOperation
or Grand Central Dispatch,

00:16:23.520 --> 00:16:25.320
if you're calling the
Core Animation Library,

00:16:25.320 --> 00:16:28.430
you're probably doing
things that will avoid,

00:16:28.430 --> 00:16:31.140
in general, causing these problems.

00:16:31.160 --> 00:16:35.160
If you're diving into Pthreads
and doing your mutexes yourself,

00:16:35.160 --> 00:16:39.380
you're doing a general-purpose
attempt at parallel programming,

00:16:39.380 --> 00:16:42.900
you're much more likely to
run into these problems.

00:16:43.740 --> 00:16:47.410
I'm not saying that you have to use
techniques that completely avoid these,

00:16:47.410 --> 00:16:51.840
but the more that you use
techniques that can occur these,

00:16:51.960 --> 00:16:54.500
the more you need to pay attention
to how are you going to debug these.

00:16:54.500 --> 00:16:58.210
So there are getting to be some
excellent tools in the marketplace,

00:16:58.290 --> 00:17:01.070
including some from Intel,
that can help find race

00:17:01.070 --> 00:17:02.790
conditions and deadlock.

00:17:02.800 --> 00:17:04.840
I expect to see a lot more in the future.

00:17:04.870 --> 00:17:08.240
I don't think there's nearly
enough of this currently in the

00:17:08.240 --> 00:17:11.630
marketplace to help with these,
but it's really important

00:17:11.630 --> 00:17:12.810
to look at this.

00:17:12.880 --> 00:17:15.580
And again,
if you use a higher-level abstraction,

00:17:15.580 --> 00:17:18.000
you're less likely to hit these problems.

00:17:18.000 --> 00:17:22.750
So when you see different solutions
for parallelism advertised,

00:17:22.750 --> 00:17:27.810
you should think about, is it abstract,
and does it help me avoid these

00:17:27.880 --> 00:17:30.160
parallel programming bugs?

00:17:30.160 --> 00:17:34.700
So when people ask my opinion about
different parallel languages and

00:17:34.700 --> 00:17:39.500
things being touted and committees
being formed to go work on things,

00:17:39.500 --> 00:17:43.430
I commonly come back to this and say,
you know, it either is going to help us

00:17:43.440 --> 00:17:45.250
solve this problem or it's not.

00:17:45.260 --> 00:17:49.230
And I'm not a big fan of new
parallelism initiatives that

00:17:49.230 --> 00:17:51.740
don't help solve this problem.

00:17:51.740 --> 00:17:55.990
I think that they just don't help us
get more parallelism in applications.

00:17:58.090 --> 00:17:59.680
All right, I think I got one more letter.

00:17:59.920 --> 00:18:04.500
My program actually runs slower on an
octa-core than on a quad-core machine.

00:18:04.610 --> 00:18:06.600
And someone said scaling was a factor.

00:18:06.630 --> 00:18:09.510
No, it doesn't have to do with fish.

00:18:12.630 --> 00:18:16.590
This is how I look at scaling.

00:18:16.720 --> 00:18:20.340
You'd like a program perhaps to
run eight times as fast on an

00:18:20.460 --> 00:18:24.770
octa-core as it did on one core,
but it's not going to.

00:18:24.870 --> 00:18:27.850
That would be called ideal scaling.

00:18:28.920 --> 00:18:32.100
But did you expect a machine to
run eight times as fast on an

00:18:32.100 --> 00:18:35.230
eight megahertz processor as it
did on a one megahertz processor?

00:18:35.250 --> 00:18:36.280
Probably not.

00:18:36.340 --> 00:18:41.370
So multi-core is not really new
in that what you're trying to

00:18:41.370 --> 00:18:44.820
do is write a program so that
it speeds up as you add cores,

00:18:44.820 --> 00:18:47.980
but you don't need to be
hung up on making it ideal.

00:18:48.980 --> 00:18:52.440
I mean, if something runs four
times as fast on octa-core,

00:18:52.440 --> 00:18:55.730
but it also runs eight times
as fast on 16 cores and 16

00:18:55.730 --> 00:18:59.280
times as fast on 32 cores,
you're in really good shape.

00:18:59.360 --> 00:19:01.350
A lot better than most people think.

00:19:01.360 --> 00:19:03.930
The killer, though,
is that if you write your program

00:19:03.930 --> 00:19:10.390
in a way that doesn't scale,
this is a really common problem as well.

00:19:11.050 --> 00:19:15.390
This is a real example of
a 3D ray tracing program.

00:19:15.510 --> 00:19:18.240
We took some work.

00:19:18.240 --> 00:19:23.970
We had one of our experts do a
very nice job and hand thread

00:19:23.970 --> 00:19:26.700
the code using P-threads.

00:19:27.400 --> 00:19:30.840
James Reiners:
And if he only had a quad-core

00:19:30.840 --> 00:19:34.140
machine to run it on,
it looked pretty darn good,

00:19:34.140 --> 00:19:43.960
because what you've got is you've
got speedups on quad-core of 3.76.

00:19:43.960 --> 00:19:47.300
On one example, the hand-coded was 3.47.

00:19:47.300 --> 00:19:51.650
So a 3.5x speedup on
quad-core sounds pretty good,

00:19:51.650 --> 00:19:53.760
and that was the hand-coded program here.

00:19:53.760 --> 00:19:58.700
The problem is that somewhere
around five or six processors,

00:19:58.700 --> 00:20:00.050
the speedup tapered out.

00:20:00.050 --> 00:20:02.870
In fact, if you keep running it
on more and more cores,

00:20:02.870 --> 00:20:03.970
it gets slower.

00:20:04.570 --> 00:20:08.500
James Reiners:
And it's a global bottlenecking problem.

00:20:08.500 --> 00:20:11.880
It was a very nice little program
the way that it was written to

00:20:11.880 --> 00:20:16.560
scale by hand with P-threads,
but he used a central computation

00:20:16.560 --> 00:20:19.170
and divided the work up evenly.

00:20:19.270 --> 00:20:21.790
And it turns out that that
works pretty well until you get

00:20:21.790 --> 00:20:23.260
to a higher number of cores.

00:20:23.300 --> 00:20:26.770
Brilliantly written program has
to be completely rewritten once

00:20:26.770 --> 00:20:31.360
you get on an octa-core machine
because it just doesn't scale.

00:20:31.570 --> 00:20:35.470
Now, this particular example,

00:20:35.800 --> 00:20:39.100
James Reiners:
I did with threading building blocks.

00:20:39.100 --> 00:20:42.530
I get identical operations
on this example with OpenMP.

00:20:42.670 --> 00:20:45.580
So really the key here is abstraction.

00:20:45.680 --> 00:20:47.680
Now what's really,
really frustrating about this

00:20:47.710 --> 00:20:53.860
is that the code on the left,
using Pthreads,

00:20:54.020 --> 00:20:58.100
shows that I had to add a whole lot
of code to get it to run in parallel.

00:20:58.180 --> 00:21:01.980
The code on the right shows I barely
had to add any code at all to get

00:21:01.980 --> 00:21:05.180
my application to run in parallel
using Threading Building Blocks.

00:21:05.950 --> 00:21:08.520
And the reason is I've circled the code.

00:21:08.710 --> 00:21:10.920
I know you can't read it,
but it's just a little loop.

00:21:11.040 --> 00:21:13.010
It does the ray tracing.

00:21:13.600 --> 00:21:15.000
That's the core algorithm.

00:21:15.000 --> 00:21:15.870
It's a few loops.

00:21:16.010 --> 00:21:18.610
It does the operations.

00:21:20.180 --> 00:21:23.540
All I want to say to my machine is,
run that in parallel.

00:21:23.540 --> 00:21:24.750
Just do it.

00:21:24.750 --> 00:21:26.020
You know, go.

00:21:26.020 --> 00:21:29.400
And that's basically what
you do in a good abstraction.

00:21:29.400 --> 00:21:30.660
Go run it.

00:21:30.740 --> 00:21:34.930
Now, this is, Threading Building Blocks,
it mostly includes statements.

00:21:35.020 --> 00:21:39.270
I think I had to add 17 lines of code
to the entire program to get it to work.

00:21:40.340 --> 00:21:43.610
On the other hand,
the complete transformation to

00:21:43.610 --> 00:21:46.740
Pthreads was almost 200 lines of code.

00:21:46.740 --> 00:21:50.310
And it's not hard code, you know,
create some Pthreads,

00:21:50.750 --> 00:21:55.160
create some mutexes, compute some bounds,
kick them off, wait for them to finish,

00:21:55.160 --> 00:21:57.820
shut down the Pthreads,
shut down the mutexes,

00:21:57.820 --> 00:21:59.060
send them all away.

00:21:59.080 --> 00:22:02.360
But it just isn't value-added code.

00:22:02.360 --> 00:22:04.700
So when you start
hearing things suggested,

00:22:04.700 --> 00:22:10.070
Threading Building Blocks,
or you look at the Grand Central.

00:22:10.340 --> 00:22:14.420
The Grand Central Dispatch,
the BlockTs and the NSOperation things

00:22:14.480 --> 00:22:18.350
that were talked about this week,
those are aimed at giving you an

00:22:18.500 --> 00:22:22.030
abstraction layer where you just say,
run it in parallel.

00:22:22.030 --> 00:22:22.900
Just go.

00:22:22.900 --> 00:22:26.220
If you're spending your time writing
a lot of code setting this up,

00:22:26.280 --> 00:22:28.940
I can promise you that's
not the way of the future.

00:22:28.940 --> 00:22:32.070
That's not what parallel
programming is going to look like.

00:22:32.070 --> 00:22:35.170
So you might as well find the
abstractions that avoid doing that

00:22:35.170 --> 00:22:38.070
and look for them really hard,
even if you have to invest

00:22:38.070 --> 00:22:39.730
a bit learning and so forth.

00:22:39.810 --> 00:22:40.320
You don't want to do that.

00:22:40.340 --> 00:22:43.720
You don't want to be writing code
where you've got hundreds of lines

00:22:43.720 --> 00:22:46.680
of code just setting up to run
a few lines of code in parallel.

00:22:47.060 --> 00:22:49.670
Now, remember,
this is the application I had

00:22:49.670 --> 00:22:53.570
that doesn't scale past octa-core,
so that's really frustrating.

00:22:53.750 --> 00:22:58.670
It added a couple hundred lines of code,
and the program didn't scale.

00:22:58.840 --> 00:23:04.700
And the reason is because Threading
Building Blocks uses a very sophisticated

00:23:04.700 --> 00:23:09.670
algorithm to divvy up the work and
load balance it across multiple cores.

00:23:09.840 --> 00:23:14.490
The same thing you can expect to
see from multiple operating system

00:23:14.490 --> 00:23:16.650
vendors in the future as well.

00:23:16.840 --> 00:23:20.220
We're really at a point where everybody's
trying to solve the same problem.

00:23:20.340 --> 00:23:22.670
They'll eventually come
together and get unified.

00:23:22.840 --> 00:23:26.780
We don't have specific plans right
now for Threading Building Blocks to

00:23:26.840 --> 00:23:31.950
sit on top of Grand Central Dispatch,
but my prediction would be in the future,

00:23:31.950 --> 00:23:33.840
that's the sort of thing we would do.

00:23:33.840 --> 00:23:37.340
All tool vendors would
move on top of that.

00:23:37.340 --> 00:23:39.330
There's equivalent
things going on in Linux.

00:23:39.340 --> 00:23:42.430
There's equivalent things
going on in Linux and things

00:23:42.460 --> 00:23:45.340
going on in Microsoft OS as
well where they're saying,

00:23:45.340 --> 00:23:47.750
"Hey, we need to provide this
core functionality where

00:23:47.750 --> 00:23:51.310
we distribute the work,
and we're responsible for load

00:23:51.350 --> 00:23:55.340
balancing." And that can lend to
the scalability that you want.

00:23:55.340 --> 00:24:00.160
So you need to look to not program
that hard into your program.

00:24:00.360 --> 00:24:03.640
If you're looking and starting
your program up and saying,

00:24:03.680 --> 00:24:05.310
"How many cores are there?

00:24:05.360 --> 00:24:08.840
I'm going to kick off a bunch of
threads," you've already lost.

00:24:08.980 --> 00:24:13.240
If I haven't convinced you just
thinking about octa-core and so on,

00:24:13.240 --> 00:24:15.740
this stretches further into GPUs.

00:24:15.920 --> 00:24:20.940
So an ideal programming language
that load balances across CPUs and

00:24:20.960 --> 00:24:25.820
GPUs wouldn't worry about exactly
what they can do differently

00:24:25.850 --> 00:24:26.840
or how powerful they were.

00:24:26.840 --> 00:24:29.840
It would just say,
"Run this in parallel."

00:24:29.840 --> 00:24:33.830
And something in your runtime
would dispatch and divvy things up.

00:24:33.840 --> 00:24:38.330
I'm quite confident that's the
way programming is going to be.

00:24:38.340 --> 00:24:39.510
Thank you.

00:24:39.710 --> 00:24:42.980
Even forgetting GPUs for a moment,
future CPUs,

00:24:42.980 --> 00:24:47.320
if and when Intel builds a 100-core CPU,
it's not going to look

00:24:47.320 --> 00:24:48.640
like our quad cores.

00:24:48.640 --> 00:24:52.070
Our quad cores are four identical cores.

00:24:52.080 --> 00:24:57.580
Powerful, out-of-order execution engines,
just lots of cash.

00:24:57.600 --> 00:25:00.980
The day that we wake up
and build a 100-core CPU,

00:25:00.980 --> 00:25:05.460
most of them are going to be itty-bitty
cores with out-of-order and so on

00:25:05.460 --> 00:25:06.460
because they're more efficient.

00:25:07.570 --> 00:25:11.880
When you write a program
that can use 100 cores,

00:25:11.880 --> 00:25:15.260
you don't need each of
those 100 cores to be big,

00:25:15.260 --> 00:25:19.070
fat, power-hungry things doing a
lot of out-of-order scheduling

00:25:19.070 --> 00:25:20.070
to try to speed you up.

00:25:20.160 --> 00:25:26.080
What you'd rather do is use that silicon
area to have a processor that was lean,

00:25:26.080 --> 00:25:27.890
mean, and ran fast.

00:25:27.900 --> 00:25:31.090
And if I can give you two or three
of those cores in the same die area,

00:25:31.090 --> 00:25:34.000
you'd rather have that
because your program scales.

00:25:34.830 --> 00:25:38.980
There's no way we're going to build a
100-core machine without all out-of-order

00:25:39.430 --> 00:25:42.030
engines like we do for quad-core.

00:25:42.080 --> 00:25:44.830
If we build a 100-core machine,
or when we do,

00:25:44.830 --> 00:25:48.930
and that's not going to be tomorrow,
you can count on the fact

00:25:49.030 --> 00:25:51.520
there'll probably be a few
big out-of-order engines,

00:25:51.590 --> 00:25:54.390
but there'll be a bunch of smaller ones,
maybe specialty ones.

00:25:54.420 --> 00:25:56.570
Again, go back to this example.

00:25:56.710 --> 00:25:58.280
How should I write this example?

00:25:58.300 --> 00:26:02.600
I should write this example
to say run it in parallel.

00:26:02.680 --> 00:26:04.800
And then in 10 years,
when it's running on a machine

00:26:04.800 --> 00:26:09.990
that has 80 little cores and 20 big
cores and maybe 10 specialty cores,

00:26:09.990 --> 00:26:12.770
I don't have to rewrite my program again.

00:26:13.250 --> 00:26:15.400
Sometimes we use the
term future-proofing,

00:26:15.470 --> 00:26:18.630
which maybe is a little bit
more of a promise than anything,

00:26:18.630 --> 00:26:22.300
but it's, you definitely want to write
your program so that you're not

00:26:22.300 --> 00:26:25.820
down mucking in the details of
exactly how to dispatch things.

00:26:25.820 --> 00:26:28.890
And if your program starts up and says,
how many cores are there,

00:26:28.890 --> 00:26:31.520
and then you divide the work
up evenly across the cores,

00:26:31.520 --> 00:26:33.740
you're going to fail
for multiple reasons.

00:26:35.840 --> 00:26:38.410
One reason is you don't have
exclusive use of the machine,

00:26:38.410 --> 00:26:40.760
and a few of the cores are going
to get busy doing something else,

00:26:40.760 --> 00:26:44.920
and your whole program's going to
run only as fast as the weakest link.

00:26:44.940 --> 00:26:47.620
You'll already see that
on a quad-core machine.

00:26:47.620 --> 00:26:49.980
If you divide up the work
evenly among four cores,

00:26:49.980 --> 00:26:52.660
I think there were some really
great animated graphics on

00:26:52.660 --> 00:26:55.740
Monday that showed this,
you know, with little ping-pong balls

00:26:55.740 --> 00:26:58.560
going in troughs and moving
around depending on the workload.

00:26:59.360 --> 00:27:03.090
Again, the key idea there was write your
program in terms of ping-pong balls

00:27:03.200 --> 00:27:05.120
and throw them into these troughs.

00:27:05.150 --> 00:27:07.670
Don't write your program
in terms of there are,

00:27:07.720 --> 00:27:09.200
how many cores are there?

00:27:09.200 --> 00:27:10.500
Divide the work up evenly.

00:27:10.500 --> 00:27:11.760
Not a good idea.

00:27:11.760 --> 00:27:13.900
So I wanted to show you a little bit.

00:27:13.900 --> 00:27:18.530
We've done some surveying of developers,
and...

00:27:20.000 --> 00:29:08.300
[Transcript missing]

00:29:08.770 --> 00:29:10.680
James Reiners: And if I had done that
a couple years ago,

00:29:10.680 --> 00:29:12.640
the people would have said,
"It's too hard.

00:29:12.640 --> 00:29:17.600
We don't see the need for it."
Only 27% of the people we talked to,

00:29:17.600 --> 00:29:20.540
and we talked to some
pretty good developers here,

00:29:20.800 --> 00:29:23.890
very influential group,
only 27% were willing to say that

00:29:23.890 --> 00:29:25.600
they didn't think it was needed.

00:29:25.730 --> 00:29:27.600
Now, I think there's a little
bit of shyness here.

00:29:27.600 --> 00:29:29.050
I think that people
are starting to think,

00:29:29.110 --> 00:29:30.600
"Oh, my gosh, multi-core is coming.

00:29:30.600 --> 00:29:32.600
Even if I don't know
what I'm going to do,

00:29:32.600 --> 00:29:35.410
I'm not going to tell someone
who's surveying me that I don't

00:29:35.410 --> 00:29:38.600
need parallelism." Okay,
I understand.

00:29:38.600 --> 00:29:39.680
There's some of that going on.

00:29:39.680 --> 00:29:41.580
But for three-quarters of
the developers to be saying,

00:29:41.600 --> 00:29:43.980
"Hey,
we're going to do something," more than

00:29:43.980 --> 00:29:47.610
50% of them blaming it on schedule,
saying, "I just haven't figured out how

00:29:47.730 --> 00:29:51.730
to fit it in my release schedule,
how to allocate people for it."

00:29:52.430 --> 00:29:55.740
One other fuzzy detail,
at Intel we try to track

00:29:55.740 --> 00:30:00.090
how many applications,
influential applications,

00:30:00.090 --> 00:30:06.120
that's ones that we think sell silicon
or cause people to buy machines.

00:30:06.560 --> 00:30:09.020
By our estimates,
the number of applications on the

00:30:09.020 --> 00:30:12.460
market at the end of last year that
used parallelism was about twice what

00:30:12.460 --> 00:30:15.600
it was at the beginning of the year,
which is rather phenomenal,

00:30:15.600 --> 00:30:18.740
because at the beginning of the year,
those were the applications

00:30:18.820 --> 00:30:21.290
using parallelism that
had been developed since,

00:30:21.290 --> 00:30:23.570
you know, the beginning of time,
basically.

00:30:23.640 --> 00:30:25.200
It doubled last year.

00:30:25.200 --> 00:30:27.660
We're just seeing a
tremendous rush towards this.

00:30:27.660 --> 00:30:32.080
And, yeah, if you're curious,
this was around-the-world phenomenon.

00:30:32.080 --> 00:30:35.100
This happened to be the distribution
of the people we talked to,

00:30:35.100 --> 00:30:38.290
but when we looked at the data,
we didn't see a difference in the

00:30:38.290 --> 00:30:39.860
trend in any particular geography.

00:30:39.940 --> 00:30:42.200
Now.

00:30:45.980 --> 00:30:51.780
I promised I'd try to keep
things reasonably high level and

00:30:51.910 --> 00:30:55.260
The talk right after me,
they said not to promise too much coding,

00:30:55.260 --> 00:30:59.400
but I know they're going to dive down a
bit and show some examples and things,

00:30:59.490 --> 00:31:01.780
because that's very important.

00:31:03.320 --> 00:31:09.320
But I'm constantly amazed
when we work with companies

00:31:09.600 --> 00:31:15.920
Some companies that, you know, again,
have fantastic programmers in them,

00:31:16.040 --> 00:31:20.580
that they get detached from
these three key things.

00:31:20.580 --> 00:31:23.130
They get enamored with
a particular technology.

00:31:23.220 --> 00:31:26.650
They're going to rush off and implement
something with P-threads or whatever.

00:31:26.660 --> 00:31:30.860
And we often bring them back and say,
look, you've got to look at

00:31:30.860 --> 00:31:32.220
the fundamentals here.

00:31:32.220 --> 00:31:35.100
And the three fundamentals are scaling.

00:31:35.100 --> 00:31:38.800
Do you have a plan,
as we continue to throw more and

00:31:38.940 --> 00:31:42.560
more cores at your application,
do you have an idea how

00:31:42.560 --> 00:31:43.520
it's going to scale?

00:31:44.870 --> 00:31:47.300
A second one is,
do you have something you're doing

00:31:47.300 --> 00:31:49.000
to keep the debugging under control?

00:31:49.000 --> 00:31:52.090
Because intermittent programs are bad.

00:31:52.770 --> 00:31:55.930
I know one company in
particular that shipped an app,

00:31:56.060 --> 00:31:57.070
hugely popular app.

00:31:57.140 --> 00:32:00.540
Again, they won't come on stage and say,
"Hi, I'm here from such and such company.

00:32:00.540 --> 00:32:05.220
We wrote a bad app." But they
had customers saying that the

00:32:05.220 --> 00:32:08.630
program ran 90 times out of 100.

00:32:09.420 --> 00:32:16.300
James Reiners:
They still love the app so much,

00:32:16.300 --> 00:32:16.300
but they just begged them,
"Would you please make this thing

00:32:16.300 --> 00:32:19.730
reliable?" And then future-proofing,
you know, are you adopting a technique

00:32:20.440 --> 00:32:24.500
that isn't just a fad,
something that's tightly

00:32:24.630 --> 00:32:28.020
tied to today's hardware,
doesn't really liberate

00:32:28.020 --> 00:32:29.790
you as a programmer,
doesn't really give you the

00:32:29.790 --> 00:32:34.250
opportunity to expect to take care
of a very rich future in hardware?

00:32:34.300 --> 00:32:37.300
I'm not just talking
about Intel hardware here.

00:32:37.300 --> 00:32:39.530
It's, you know,
if Intel doesn't build really

00:32:39.530 --> 00:32:43.030
interesting chips that we all use,
someone else will.

00:32:43.380 --> 00:32:45.000
Nothing's going to stop
the chips getting very,

00:32:45.000 --> 00:32:46.290
very interesting in the future.

00:32:46.350 --> 00:32:52.300
So we might as well, as programmers,
not go hug the hardware and write in a,

00:32:52.300 --> 00:32:55.300
you know,
in a language or a technique that's

00:32:55.300 --> 00:33:00.300
just specific for today's hardware,
or not invest a whole lot in that.

00:33:03.540 --> 00:33:06.980
So I wanted to shift gears just
a little bit and talk about it

00:33:06.980 --> 00:33:09.410
from a different angle because

00:33:10.150 --> 00:33:12.210
I hope you'll give the
thought to the scaling,

00:33:12.210 --> 00:33:13.960
the debugging, the correctness.

00:33:14.030 --> 00:33:16.300
You know,
when you're working on your applications,

00:33:16.300 --> 00:33:20.400
when you're advocating techniques,
when somebody comes and gives you a talk,

00:33:20.510 --> 00:33:22.770
you should use this technique
instead of that one.

00:33:22.780 --> 00:33:24.950
You know, I give lots of talks on
threading building blocks.

00:33:25.020 --> 00:33:26.820
I say, you know, it solves everything.

00:33:27.100 --> 00:33:31.310
Well, when I do a talk like that,
you should be thinking, you know, James,

00:33:31.310 --> 00:33:34.570
can you explain to me why you
think this helps with scaling

00:33:34.570 --> 00:33:36.360
or why this is future-proof?

00:33:36.500 --> 00:33:40.840
Can you describe how it would be used on
a future machine with hundreds of cores?

00:33:40.840 --> 00:33:42.450
And the answer is yes, yes, yes.

00:33:42.450 --> 00:33:46.120
And I can try to do that for any
technique being offered out there.

00:33:46.120 --> 00:33:49.560
And so I'd encourage you to
think about that with scaling,

00:33:49.560 --> 00:33:52.280
correctness, and the future-proofing.

00:33:54.960 --> 00:34:00.840
But shifting gears a bit,
I wrote an article last year for Dr.

00:34:00.840 --> 00:34:05.710
Dobbs that was pretty popular in

00:34:05.970 --> 00:34:09.950
What I did is I tried to sit
down and write out eight tips.

00:34:10.030 --> 00:34:12.970
And this is a pretty easy
article to find online,

00:34:12.970 --> 00:34:16.620
Google for my name and
Rules for Parallelism.

00:34:16.660 --> 00:34:21.730
It's a short article and so, you know,
when you're rushing to write code,

00:34:21.730 --> 00:34:24.000
instead of giving these
really abstract scaling and

00:34:24.000 --> 00:34:29.220
correctness and future-proofing,
can you give me something a little bit

00:34:29.220 --> 00:34:31.730
more specific I can sink my teeth into?

00:34:31.900 --> 00:34:34.370
So the first thing,

00:34:36.500 --> 00:34:39.160
As programmers, we need to think about
where the parallelism is.

00:34:39.160 --> 00:34:42.600
You need to fundamentally
get used to figuring out what

00:34:42.600 --> 00:34:45.230
is parallel in your program.

00:34:45.630 --> 00:34:48.940
Now one thing that's real interesting
to me about that is one of the things

00:34:48.940 --> 00:34:55.340
I know we've learned is that nested
parallelism is fantastically important.

00:34:55.530 --> 00:34:58.170
When you stare at one part
of your program and say,

00:34:58.180 --> 00:35:02.760
"How can I make this run in parallel?"
Your eyes will pop out of your head.

00:35:02.760 --> 00:35:04.860
It's so frustrating.

00:35:05.020 --> 00:35:08.300
But if you apply that at a high level of
your program and then lower levels have

00:35:08.400 --> 00:35:13.020
parallelism and you can keep expressing
the parallelism wherever it happens,

00:35:13.180 --> 00:35:16.220
you get a lot better scaling,
a lot better performance.

00:35:16.370 --> 00:35:21.060
There are not very many programming
techniques out there right now that

00:35:21.500 --> 00:35:24.600
will help you with nested parallelism.

00:35:24.910 --> 00:35:27.490
I guess that would be one
reason I advocate threading

00:35:27.490 --> 00:35:28.900
building blocks a lot.

00:35:28.930 --> 00:35:34.080
OpenMP has added a few things,
and there are other programming

00:35:34.080 --> 00:35:35.590
techniques that need to look at this.

00:35:35.600 --> 00:35:42.510
If you look at all the GPU languages
that are being proposed out there,

00:35:42.510 --> 00:35:47.500
whether it be CUDA or OpenCL,
you'll find that a

00:35:47.590 --> 00:35:53.760
thread or a task cannot,
in general, create more.

00:35:54.770 --> 00:35:58.300
And that's a mistake,
because it means that you can't

00:35:58.300 --> 00:36:00.030
embody nested parallelism.

00:36:00.210 --> 00:36:02.150
So it's a critique of
quite a few languages,

00:36:02.230 --> 00:36:03.520
what I just said.

00:36:03.550 --> 00:36:07.160
And again, my prediction in the
future is that they either,

00:36:07.280 --> 00:36:11.860
all techniques either need to
correct that or they'll die off.

00:36:11.970 --> 00:36:16.120
So we've really learned that nested
parallelism is way more important,

00:36:16.120 --> 00:36:19.660
I think, than any of us thought
it would be in practice.

00:36:19.700 --> 00:36:21.950
That if you want a scaling app,
it needs to be able to

00:36:22.030 --> 00:36:23.200
express parallelism.

00:36:23.290 --> 00:36:25.690
So after you kick off a task,
if it realizes it's got

00:36:25.690 --> 00:36:29.520
a lot of work to do,
it can break itself up into more tasks.

00:36:29.650 --> 00:36:32.380
So my tip started off with, you know,
think about the parallelism,

00:36:32.380 --> 00:36:33.600
know where it is.

00:36:33.700 --> 00:36:37.220
And the reason I talked about nesting
is if your brain starts saying,

00:36:37.220 --> 00:36:39.020
hey, well,
I've got this to run in parallel,

00:36:39.020 --> 00:36:43.820
but some parts of what I'm thinking
about might be parallelism themselves,

00:36:43.820 --> 00:36:45.400
good, no problem.

00:36:45.530 --> 00:36:47.220
You should be able to code that.

00:36:47.290 --> 00:36:50.440
The other thing is you need to be
able to program using abstractions.

00:36:50.710 --> 00:36:53.020
I already talked about why.

00:36:53.210 --> 00:36:54.480
Very important.

00:36:54.480 --> 00:36:57.980
You should program at a level of task,
not threads.

00:36:57.980 --> 00:37:01.480
To me, a thread is, you know,
when you're programming saying, hey,

00:37:01.480 --> 00:37:04.280
I'm going to have one
thread for each processor,

00:37:04.280 --> 00:37:06.540
and I'm going to figure
out what each thread does.

00:37:06.540 --> 00:37:07.920
That's what I mean by threads.

00:37:07.920 --> 00:37:09.780
Don't do that.

00:37:09.780 --> 00:37:12.620
Liberate yourself and say, hey,
I want to do this, I want to do that,

00:37:12.620 --> 00:37:14.480
I want to do that.

00:37:14.480 --> 00:37:19.680
You know, I find it very compelling to
talk about task and to get going.

00:37:19.680 --> 00:37:22.540
And you saw some great animations at
the beginning of the week that sort

00:37:22.540 --> 00:37:24.340
of illustrate how you think about it.

00:37:24.340 --> 00:37:30.340
And these block T extensions to
Objective C try to capture that.

00:37:30.340 --> 00:37:36.400
The C++ standard undoubtedly will
add lambdas and will add futures.

00:37:36.400 --> 00:37:39.860
So you'll see this trend in many,
many languages and so forth to

00:37:39.970 --> 00:37:43.900
say let's start talking in task,
not threads.

00:37:46.310 --> 00:37:50.800
Now, a surprising one,
or one that I cannot overemphasize

00:37:50.800 --> 00:37:54.200
how much important I think this
turns out to be in practice is,

00:37:54.200 --> 00:37:59.310
don't write a parallel app
that can't run sequentially.

00:38:01.710 --> 00:38:03.500
Once you get into parallelism,
it's really cool.

00:38:03.500 --> 00:38:07.600
You can write applications
that can't be run sequentially.

00:38:07.720 --> 00:38:10.030
Well, you might as well shoot
yourself in the head now.

00:38:10.120 --> 00:38:14.180
It's just not a lot of fun
to debug an app that can

00:38:14.180 --> 00:38:17.100
only be debugged in parallel.

00:38:17.160 --> 00:38:18.940
Frankly,

00:38:19.440 --> 00:38:20.890
James Reiners: I'm a programmer.

00:38:20.890 --> 00:38:23.060
Programmers that aren't
perfect like myself,

00:38:23.100 --> 00:38:27.330
I occasionally have to fix a loose
pointer or a mistake or something

00:38:27.480 --> 00:38:30.040
in my code that's just a no-brainer.

00:38:30.070 --> 00:38:35.160
Really easy to do when the
program's running sequentially.

00:38:35.210 --> 00:38:37.400
I get a memory fault or whatever,
I can figure it out.

00:38:37.400 --> 00:38:40.000
I can run it ten times,
it keeps failing the same way.

00:38:40.110 --> 00:38:43.570
When I run it in parallel and
it starts doing bizarre things,

00:38:43.570 --> 00:38:47.240
I start thinking,
"It's a parallel programming bug." No,

00:38:47.280 --> 00:38:49.990
most of my bugs are not
parallel programming bugs,

00:38:50.000 --> 00:38:52.090
they're still the ordinary bugs.

00:38:52.120 --> 00:38:55.150
And I find it much easier to debug
them if I'm running the program and

00:38:55.150 --> 00:38:59.000
it's not expressing itself in parallel,
at least the part I'm trying to debug.

00:38:59.000 --> 00:39:01.430
So I pay attention and
I think programmers,

00:39:01.430 --> 00:39:05.640
experienced programmers pay attention to,
"Okay, I've done all this work to

00:39:05.760 --> 00:39:09.000
make it run in parallel,
how can I force it to be sequentially

00:39:09.000 --> 00:39:12.880
debuggable?" Because I want to
get past this debugging phase,

00:39:12.880 --> 00:39:16.600
I don't want to spend a week tracking
down a bug that I thought was a

00:39:16.720 --> 00:39:21.000
race condition and it turned out
to be the use of the wrong pointer.

00:39:21.370 --> 00:39:24.350
Something that I used to
be able to debug quickly.

00:39:25.210 --> 00:39:27.590
So I had a few other tips,
but I want to zoom ahead.

00:39:27.630 --> 00:39:33.090
You want to understand locks,
you want to get cool tools,

00:39:33.090 --> 00:39:34.910
you want to use scalable
memory allocators.

00:39:34.920 --> 00:39:37.880
You read my article, think about that.

00:39:37.910 --> 00:39:42.820
But I wanted to go ahead and do
another one that is a subtle tea.

00:39:44.390 --> 00:39:46.840
That I think as experts
in parallel programming,

00:39:46.850 --> 00:39:49.410
you need to be really well versed in.

00:39:51.050 --> 00:39:56.070
So what if someone walks up to you,
now this has happened to me, and says,

00:39:56.070 --> 00:39:59.380
"Amdahl's law proves that
this is all a bad idea."

00:39:59.900 --> 00:40:19.400
[Transcript missing]

00:40:19.710 --> 00:40:23.500
So what you want to do is you
want to make sure that as you're

00:40:23.500 --> 00:40:26.910
thinking about parallelism,
you pay attention to the fact

00:40:27.030 --> 00:40:32.200
that we're constantly giving more
workload to our applications.

00:40:32.240 --> 00:40:34.500
I'll come back and give you some
examples on that in a little bit,

00:40:34.500 --> 00:40:38.150
but let me start by
talking about Amdahl's Law.

00:40:38.530 --> 00:40:41.510
James Reiners: This is, you know,
this is one of those topics

00:40:41.560 --> 00:40:43.210
at least over beers sometimes.

00:40:43.210 --> 00:40:45.320
So let's assume we have an application.

00:40:45.320 --> 00:40:46.320
It has five parts.

00:40:46.340 --> 00:40:48.410
They each take 100 seconds to run.

00:40:48.530 --> 00:40:50.080
They run one after the other.

00:40:50.080 --> 00:40:53.390
Let's say that I know how to make
a couple of them run in parallel.

00:40:53.390 --> 00:40:56.690
Well, if we take a look at Amdahl's Law,
when I get to dual-core,

00:40:56.690 --> 00:41:00.180
I can get a 25% speedup in my program,
and when I go to quad-core,

00:41:00.180 --> 00:41:02.220
I can get a 40% speedup.

00:41:02.260 --> 00:41:06.200
In fact, if I keep making those
two parts run in parallel,

00:41:06.200 --> 00:41:09.140
I can eventually get them
effectively to run in no time.

00:41:09.690 --> 00:41:12.260
Unfortunately, my program still takes
300 seconds to run.

00:41:12.260 --> 00:41:16.300
I only get a 70% speedup
even if I use this,

00:41:16.300 --> 00:41:20.220
you know, one million-core machine on
a couple parts of my program.

00:41:20.220 --> 00:41:26.220
Okay, so this is the high-level proof
that multi-core is doomed.

00:41:26.220 --> 00:41:28.220
Nobody's going to succeed.

00:41:28.220 --> 00:41:30.220
We'll all just go home.

00:41:30.420 --> 00:41:32.220
Amdahl's Law.

00:41:32.610 --> 00:41:36.900
So this is based on a paper
written by Amdahl in 1967.

00:41:36.940 --> 00:41:40.300
What he actually said is that the
effort spent on making parts of your

00:41:40.400 --> 00:41:45.770
program run faster and faster are going
to have diminishing value unless you do

00:41:45.770 --> 00:41:48.440
something about the sequential parts.

00:41:48.460 --> 00:41:52.800
And so for years, this was used as,
this is why parallelism

00:41:52.800 --> 00:41:54.960
won't work on a large scale.

00:41:55.380 --> 00:41:57.620
And not everybody took
them completely seriously,

00:41:57.720 --> 00:42:03.140
but no one really articulated well
why this doom and gloom scenario

00:42:03.140 --> 00:42:06.170
that I just showed wasn't correct.

00:42:07.260 --> 00:42:11.890
21 years later, John Gustafson said,
"Hey,

00:42:12.020 --> 00:42:17.920
you really ought to measure the speed up,
not just by fixing the problem size,

00:42:17.990 --> 00:42:20.920
but by scaling the problem size up."

00:42:21.450 --> 00:42:23.240
So let me illustrate.

00:42:23.300 --> 00:42:27.150
What if when I run in parallel,
I'm able to give more data,

00:42:27.280 --> 00:42:30.400
more work to these parallel sections?

00:42:30.460 --> 00:42:32.490
Now this is not...

00:42:32.690 --> 00:42:35.040
This is not a completely
contrived example.

00:42:35.040 --> 00:42:39.240
Imagine that these sections are the loops
that are walking through my image and I'm

00:42:39.240 --> 00:42:43.360
increasing the image size or the number
of images I'm processing or something,

00:42:43.500 --> 00:42:48.820
and that the other sequential
work is mostly not a lot of work.

00:42:48.920 --> 00:42:51.760
And I increase the amount of work to do.

00:42:51.760 --> 00:42:54.960
Now I've got a 40%
speedup just on dual-core,

00:42:54.960 --> 00:42:56.400
at least ideally.

00:42:56.400 --> 00:42:59.360
2.2x speedup if I go to quad-core.

00:42:59.360 --> 00:43:02.580
In fact, this just continues
to scale indefinitely.

00:43:02.580 --> 00:43:07.150
It's about, I don't remember,
60% efficient or 70% efficient.

00:43:07.150 --> 00:43:08.420
You can do the math.

00:43:08.420 --> 00:43:10.060
But this program scales.

00:43:10.060 --> 00:43:14.350
Throw as many cores at it as you want
and you can keep throwing more data at

00:43:14.350 --> 00:43:17.020
your application and it'll go faster.

00:43:20.510 --> 00:43:23.640
This one escapes a lot
of people and it's not,

00:43:23.750 --> 00:43:25.390
it needs to be intuitive.

00:43:25.390 --> 00:43:28.780
I used to have a,

00:43:29.000 --> 00:43:31.020
40 megahertz laptop.

00:43:31.100 --> 00:43:33.880
I think my laptop now is 2
point something gigahertz.

00:43:33.930 --> 00:43:38.210
That's at least a 50x
improvement in clock rate.

00:43:38.230 --> 00:43:42.880
I'm trying to figure out what
runs 50 times faster on my laptop.

00:43:42.880 --> 00:43:44.500
It doesn't feel that much faster.

00:43:44.500 --> 00:43:46.980
But what happened to that performance?

00:43:47.080 --> 00:43:48.210
Where did it go?

00:43:48.210 --> 00:43:51.950
Oh, I'm doing Wi-Fi negotiations.

00:43:51.950 --> 00:43:53.910
I'm doing encrypt, decrypt.

00:43:53.910 --> 00:43:55.520
I'm doing smooth fonts.

00:43:55.520 --> 00:43:57.120
I'm doing smooth scrolling.

00:43:57.120 --> 00:44:01.350
My screen has, you know, 4,
8x the pixels that it did before.

00:44:01.350 --> 00:44:03.320
That's a lot more processing.

00:44:03.320 --> 00:44:06.170
You know, thank goodness for HDTV, right?

00:44:06.170 --> 00:44:09.650
Because all these applications
we wrote to run on PAL and

00:44:09.650 --> 00:44:12.160
NTSC now need to scale their data.

00:44:12.160 --> 00:44:17.290
So Intel needs to build faster processors
to help us play with high definition.

00:44:17.290 --> 00:44:20.240
And audio's doing the same thing,
you know?

00:44:20.240 --> 00:44:24.090
Give you more processing power,
we'll process more audio.

00:44:24.150 --> 00:44:30.040
It's not that I'm going to
process my DVD and iDVD faster.

00:44:30.430 --> 00:44:31.990
It's I'm going to add more effects.

00:44:31.990 --> 00:44:43.060
I'm going to do high definition content,
so on.

00:44:44.160 --> 00:44:44.290
So as you look to adding
parallelism in your program,

00:44:44.290 --> 00:44:44.290
think a little bit forward.

00:44:44.290 --> 00:44:44.290
What would you like
to do to process more?

00:44:45.250 --> 00:44:48.710
That may be the easiest place or
the most beneficial place to put

00:44:48.710 --> 00:44:50.320
parallelism into your application.

00:44:50.320 --> 00:44:53.290
There's a balance.

00:44:53.290 --> 00:44:57.110
You often look at a program and say, wow,
I can speed this up and my

00:44:57.110 --> 00:44:58.380
program will run faster.

00:44:58.380 --> 00:45:03.550
But the other place to look for it
with phenomenal results is where can

00:45:03.550 --> 00:45:08.310
you add things that process more data,
look ahead, do things that you wouldn't

00:45:08.310 --> 00:45:11.880
have considered before
because it was too expensive,

00:45:11.920 --> 00:45:15.310
but now you can add with
the power of parallelism.

00:45:15.320 --> 00:45:17.200
That's what we're really going to see.

00:45:17.200 --> 00:45:21.250
That's why my 40 megahertz laptop's
not fast enough for me anymore and

00:45:21.390 --> 00:45:25.030
I need a 2 gigahertz is I'm too
used to the barrage of extra data,

00:45:25.030 --> 00:45:28.260
extra processing that my
machine's doing for me.

00:45:28.670 --> 00:45:31.680
not that any one program

00:45:31.860 --> 00:45:32.800
You can just help me.

00:45:32.800 --> 00:45:36.500
My mail program, for instance,
is not running 50x faster,

00:45:36.500 --> 00:45:37.440
that's for sure.

00:45:37.630 --> 00:45:40.880
I'm quite confident it was faster before.

00:45:41.490 --> 00:45:46.280
So let me show you,
this is a foil that our CTO uses.

00:45:46.280 --> 00:45:48.610
I've seen foils like
this from other people.

00:45:48.880 --> 00:45:51.120
They show, oh,
the world's gonna be taken over,

00:45:51.120 --> 00:45:53.140
you know,
more processing power and so on.

00:45:53.160 --> 00:45:57.460
What's really interesting is,

00:45:57.740 --> 00:46:00.520
The graph here,
and this is a very common sort of graph,

00:46:00.660 --> 00:46:04.380
shows data size and performance going up.

00:46:04.410 --> 00:46:06.210
There's a reason for that.

00:46:06.460 --> 00:46:09.640
You really don't just make
the performance go up.

00:46:09.800 --> 00:46:14.330
The performance goes up as long as
you assume the data sizes get bigger.

00:46:14.500 --> 00:46:35.000
[Transcript missing]

00:46:39.050 --> 00:46:40.860
I wanted to highlight
a couple of websites,

00:46:41.000 --> 00:46:46.060
some places that I think are
useful to getting more information.

00:46:46.310 --> 00:46:50.030
One of them's for dealing with today.

00:46:50.040 --> 00:46:53.740
Again,
I'll plug Threading Building Blocks.

00:46:53.740 --> 00:46:56.710
We've got some forums there and so forth.

00:46:56.780 --> 00:46:58.860
It's a fun place to go and sort of chat.

00:46:58.870 --> 00:47:03.160
If you're a C++ programmer,
I'm recommending this for.

00:47:03.190 --> 00:47:06.070
Open source.

00:47:06.290 --> 00:47:09.960
- And it's just an
interesting place to start.

00:47:09.960 --> 00:47:14.070
C++ programmers,
I highly recommend taking a look at this.

00:47:16.540 --> 00:47:21.010
Now, if you're more into the, wow,
I wonder where the world's going to go.

00:47:21.010 --> 00:47:24.560
James didn't talk about
really exotic technologies.

00:47:24.560 --> 00:47:29.470
Yeah, I usually try to emphasize
practical things because,

00:47:29.470 --> 00:47:32.980
you know, if you're going to run out and
try to write a program today

00:47:32.980 --> 00:47:36.330
that runs on lots of machines,
you really need to look at these

00:47:36.330 --> 00:47:38.640
things that may sound a little boring.

00:47:38.640 --> 00:47:41.990
I kept emphasizing threaded libraries,
open MP, threading building blocks.

00:47:42.960 --> 00:47:46.620
But that doesn't mean that there isn't
a lot of exciting work going on saying,

00:47:46.720 --> 00:47:48.760
how could we really change the world?

00:47:48.760 --> 00:47:51.480
One of them is something
called transactional memory or

00:47:51.480 --> 00:47:53.340
software transactional memory.

00:47:53.340 --> 00:47:58.680
This, in short, you know, I hate locks,
so let's do something different.

00:47:58.680 --> 00:48:01.280
Databases seem to have
figured out how to,

00:48:01.280 --> 00:48:03.240
you know, do transactions.

00:48:03.240 --> 00:48:07.410
Wouldn't it be cool if when I have a data
structure and I'm going to update it,

00:48:07.410 --> 00:48:10.390
in order to be thread safe,
if it was updated in a

00:48:10.390 --> 00:48:11.780
transactional fashion?

00:48:12.820 --> 00:48:14.540
This concept's not going to go away.

00:48:14.540 --> 00:48:17.320
We're going to keep beating our heads
against the wall until we figure out how

00:48:17.410 --> 00:48:19.040
to put this in software and in hardware.

00:48:20.480 --> 00:48:23.000
But frankly, nobody knows how to
put it in hardware yet.

00:48:23.000 --> 00:48:26.080
Nobody really knows how to get
it right in software completely.

00:48:26.080 --> 00:48:28.580
There are some nice
little implementations.

00:48:28.580 --> 00:48:34.940
Intel's had a project to put software
transaction memory into C and C++,

00:48:35.100 --> 00:48:38.660
and we have a free version of our
compiler on our website that does that.

00:48:38.700 --> 00:48:42.380
I am not advocating going and
downloading it and using it in

00:48:42.380 --> 00:48:46.700
your next program that you're
going to ship or put in production.

00:48:46.700 --> 00:48:48.030
Please don't.

00:48:49.110 --> 00:48:53.450
But we put a website together where
we're putting some of our experiments

00:48:53.450 --> 00:48:57.250
up for people to give feedback,
to play community feedback.

00:48:57.370 --> 00:49:00.600
So we've got some experiments
on futures and spawn.

00:49:00.600 --> 00:49:04.220
We've got this experiment
on transactional memory.

00:49:04.220 --> 00:49:08.770
We've got some exotic adaptive
library techniques that I think

00:49:08.770 --> 00:49:11.370
are extraordinarily promising.

00:49:11.370 --> 00:49:14.310
And I love to peruse things like this.

00:49:17.610 --> 00:49:18.560
We've got a lot of stuff on parallelism.

00:49:18.560 --> 00:49:30.370
That's what makes it really
a little more unique,

00:49:30.460 --> 00:49:32.970
although it's got some other things
not to do with parallelism as well.

00:49:32.980 --> 00:49:36.520
Very cool place to go if you
want to kind of get a flavor of

00:49:36.520 --> 00:49:40.950
what researchers are looking at,
what problems we might solve that

00:49:41.080 --> 00:49:43.400
make parallelism even easier.

00:49:43.600 --> 00:49:57.700
[Transcript missing]

00:50:02.800 --> 00:52:34.100
[Transcript missing]