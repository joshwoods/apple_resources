WEBVTT

00:00:20.720 --> 00:00:21.620
Good afternoon.

00:00:21.780 --> 00:00:24.840
Welcome to
Advanced Performance Analysis with Shark.

00:00:24.840 --> 00:00:27.240
I'm Eric Miller with the
Architecture Performance Group.

00:00:27.240 --> 00:00:29.110
We're the authors of Shark.

00:00:29.320 --> 00:00:32.310
We're here today because you
care about the efficiency of your

00:00:32.310 --> 00:00:34.980
programs and their performance,
and we care about the

00:00:34.980 --> 00:00:36.870
efficiency of your programs.

00:00:37.300 --> 00:00:39.640
Most of you have probably
used Shark before,

00:00:39.760 --> 00:00:43.360
maybe messed with the basic controls,
taken a time profile,

00:00:43.490 --> 00:00:46.660
and reviewed the session and made some
optimizations in your applications.

00:00:46.660 --> 00:00:51.980
Well, we're here today because Shark does
a lot more than simple time profiles.

00:00:54.170 --> 00:00:58.170
We'll go over the windowed time facility,
which changes the way Shark collects

00:00:58.170 --> 00:01:01.100
data with a circular buffer for samples.

00:01:01.270 --> 00:01:05.360
And there are five other ways to actually
start and stop Shark besides using the

00:01:05.360 --> 00:01:08.100
start button that we'll go over briefly.

00:01:08.200 --> 00:01:12.920
Most of our talk will be devoted to two
other methods for examining performance

00:01:12.920 --> 00:01:15.100
issues that are not time related.

00:01:15.100 --> 00:01:18.030
And at the end,
we'll give you a sneak peak of Shark's

00:01:18.030 --> 00:01:20.270
future and what that means for you.

00:01:22.440 --> 00:01:24.780
So first, the window of time facility.

00:01:24.940 --> 00:01:29.110
In the normal mode of using Shark,
you simply start Shark and let it run.

00:01:29.110 --> 00:01:34.540
The buffer collects samples endlessly
until you stop Shark and examine the

00:01:34.540 --> 00:01:36.000
samples that are collected in between.

00:01:36.000 --> 00:01:41.810
And that's fine for probably 90% of the
time you'll use Shark and take samples.

00:01:41.810 --> 00:01:46.250
But there are times when you don't know
exactly when you should start and stop.

00:01:46.310 --> 00:01:49.520
And there are other times when
you just can't pin down a problem

00:01:49.520 --> 00:01:51.740
because it's difficult to reproduce.

00:01:52.400 --> 00:01:55.040
That's where the window of
time facility comes into play.

00:01:55.040 --> 00:02:00.470
You simply start Shark in window of time
facility mode and let it run forever.

00:02:00.670 --> 00:02:03.450
The sample window will
fill full of samples,

00:02:03.450 --> 00:02:05.290
and as new samples come
in and fill the buffer,

00:02:05.290 --> 00:02:07.140
the old samples are rejected.

00:02:07.140 --> 00:02:10.030
This process will continue,
always having the latest

00:02:10.030 --> 00:02:13.840
buffer of samples available,
until some time where something occurs

00:02:13.840 --> 00:02:17.510
and you want to catch those samples,
or you reach a point in your

00:02:17.510 --> 00:02:21.590
application where you want
to stop and take a session.

00:02:24.520 --> 00:02:27.510
So, like I said,
you can profile indefinitely with

00:02:27.550 --> 00:02:30.100
Window Time Facility because you'll
never run out of memory because

00:02:30.100 --> 00:02:31.250
your sample buffer got too big.

00:02:31.260 --> 00:02:31.970
It's fixed size.

00:02:32.040 --> 00:02:35.140
You can use the Window Time Facility
with any of the trigger

00:02:35.140 --> 00:02:36.740
methods that I mentioned.

00:02:38.140 --> 00:02:42.060
and you can use the window time
facilities built into the time profile

00:02:42.070 --> 00:02:44.130
and system trace configurations.

00:02:46.230 --> 00:02:50.420
You can also change the size of the
sample window with configuration options.

00:02:50.420 --> 00:02:53.570
Here you can see that there's
a 10,000 sample window by

00:02:53.680 --> 00:02:55.220
default for time profile.

00:02:55.350 --> 00:02:59.660
The system trace buffer
is a million events.

00:03:00.380 --> 00:03:04.140
So keep window time facility in
mind when you're using Shark.

00:03:04.160 --> 00:03:06.750
I'm going to talk about some
different ways to trigger Shark.

00:03:06.850 --> 00:03:09.420
But first,
a brief word about the Start button.

00:03:09.460 --> 00:03:10.880
It's right there on the front of Shark.

00:03:10.910 --> 00:03:19.170
It's really easy to find and easy to use,
but you do actually have to

00:03:19.170 --> 00:03:19.170
click the button to initiate
sampling and to stop sampling.

00:03:19.380 --> 00:03:21.850
That means that the shortest
assumption you're going to be able to

00:03:21.850 --> 00:03:25.140
collect is a couple of button clicks,
and most of that data

00:03:25.140 --> 00:03:26.780
is going to be the UI.

00:03:27.490 --> 00:03:31.530
So that leaves some accuracy behind,
but still that's fine

00:03:31.530 --> 00:03:32.600
for most of your work.

00:03:32.640 --> 00:03:35.100
But when you need to get more efficient,
that's when these other

00:03:35.100 --> 00:03:36.440
trigger methods come in.

00:03:36.600 --> 00:03:40.130
The first method is
the hotkey combination,

00:03:40.140 --> 00:03:42.740
which is listed right
above the start key,

00:03:42.870 --> 00:03:47.220
the start button rather, and by default,
the option Escape.

00:03:47.360 --> 00:03:49.880
Now that's more accurate
than just pressing Start and

00:03:49.880 --> 00:03:52.860
Stop because Shark can be in the
background of your Windows stack,

00:03:52.860 --> 00:03:56.770
it can be iconified,
and you can still trigger sampling.

00:03:58.140 --> 00:04:01.440
But you do, like the start button,
you do need to be logged into the

00:04:01.440 --> 00:04:04.880
system in order to use this facility.

00:04:05.260 --> 00:04:08.720
And if you happen to be using the
option escape key in your program,

00:04:08.720 --> 00:04:11.300
or maybe you just want the hot key to
be on the other side of the keyboard,

00:04:11.300 --> 00:04:15.750
you can configure it off of
Shark's Sampling Preference tab.

00:04:17.090 --> 00:04:20.400
The next way that's more accurate
still is the Launch Panel in Shark.

00:04:20.430 --> 00:04:24.060
And you can access that by setting
Shark's target menu to Process,

00:04:24.060 --> 00:04:28.070
which makes a new menu that
the first entry will be Launch.

00:04:28.090 --> 00:04:30.340
And when you select Launch,
you'll notice that the

00:04:30.420 --> 00:04:32.220
Start button will gain an ellipsis.

00:04:32.220 --> 00:04:36.280
That means when you actually press Start,
you'll get the Launch Panel,

00:04:36.280 --> 00:04:38.650
where you can fill in
your executable path,

00:04:38.750 --> 00:04:43.190
its working directory, shell variables,
and arguments you might need.

00:04:44.010 --> 00:04:47.580
Then when you press OK,
Shark will immediately begin sampling

00:04:47.680 --> 00:04:49.980
and then launch your application.

00:04:49.980 --> 00:04:52.890
So you can sample the
startup of a program,

00:04:53.110 --> 00:04:56.610
and you can also sample
any short-lived program.

00:04:57.310 --> 00:05:01.450
Next is the unresponsive app trigger,
because we all know how much we

00:05:01.450 --> 00:05:04.230
hate the spinning pizza of death.

00:05:05.000 --> 00:05:07.680
So what you do here is you
put Shark in this mode and

00:05:07.680 --> 00:05:12.610
Shark automatically begins sampling
when the spinning pizza comes on screen.

00:05:13.430 --> 00:05:16.590
The session will then show you
which applications are where

00:05:16.600 --> 00:05:18.990
while that pizza's on screen.

00:05:20.100 --> 00:05:23.000
So because it's in
everything mode by default,

00:05:23.000 --> 00:05:24.910
you can also filter on application names.

00:05:24.930 --> 00:05:29.370
The only applications in the filter
list will be the ones Shark samples.

00:05:29.590 --> 00:05:31.500
And of course,
you can set the minimum amount of time

00:05:31.500 --> 00:05:35.690
that Shark should wait before it begins
sampling when the spinning pizza appears.

00:05:35.690 --> 00:05:38.260
By default, it's a half second.

00:05:38.700 --> 00:05:41.480
Now this is your most important
trigger method for this week.

00:05:41.560 --> 00:05:44.040
That's the network iPhone triggering.

00:05:44.200 --> 00:05:46.910
In this mode, once you select it,

00:05:47.330 --> 00:05:50.700
Shark uses Bonjour to
discover new machines,

00:05:50.700 --> 00:05:54.870
and you can use a Mac running
Shark in shared mode on your local

00:05:54.870 --> 00:05:58.360
network and any iPhones that happen
to be tethered to your machine.

00:05:58.360 --> 00:05:59.940
They show up in the list.

00:05:59.990 --> 00:06:04.140
Once you connect to them,
pressing the Start button on the local

00:06:04.140 --> 00:06:08.540
machine causes Shark in remote mode
to start sampling and stop sampling

00:06:08.890 --> 00:06:11.020
on the iPod or on the network Mac.

00:06:11.880 --> 00:06:15.010
Now, one of the differences here is
that sessions that are created

00:06:15.010 --> 00:06:18.140
will be delivered right to your
local machine's desktop as opposed

00:06:18.220 --> 00:06:19.780
to remaining on the other machine.

00:06:19.780 --> 00:06:23.600
So not only do you want to use
this for your iPhone and your

00:06:23.710 --> 00:06:26.960
iPod and for network Macs,
you can log into a Mac on the

00:06:26.960 --> 00:06:30.320
network and collect samples
from a full-screen application.

00:06:30.320 --> 00:06:33.840
And it's also really useful for
clusters of servers and single

00:06:33.840 --> 00:06:37.610
servers where you don't have
access to the display directly.

00:06:39.910 --> 00:06:42.500
And lastly is Remote Control.

00:06:42.500 --> 00:06:45.660
It says Programmatic
Remote Control because the way you

00:06:45.660 --> 00:06:49.600
use this is you actually have to add
code to your application to start

00:06:49.600 --> 00:06:53.300
and stop Shark at your convenience.

00:06:54.100 --> 00:06:57.450
So when you use those
methods in your code,

00:06:57.590 --> 00:07:00.030
of course you have to link
with the Chud framework.

00:07:00.130 --> 00:07:03.170
If that's not a possibility,
we also have a command line

00:07:03.170 --> 00:07:08.260
utility called Chud Remote Control,
which has command line arguments

00:07:08.260 --> 00:07:13.160
for starting and stopping
Shark to sample your application.

00:07:13.220 --> 00:07:16.590
This is the most precise
way to control Shark.

00:07:18.300 --> 00:07:22.390
Here's a simple programmatic
example that's included when

00:07:22.390 --> 00:07:25.000
we ship Shark as an example.

00:07:25.000 --> 00:07:28.750
We're going to instrument the
Towers of Hanoi solver every time

00:07:28.750 --> 00:07:30.280
the Hanoi function is called.

00:07:30.440 --> 00:07:33.160
So we slip a little code in.

00:07:33.160 --> 00:07:36.200
And the first thing you want to do,
these are your five important lines

00:07:36.200 --> 00:07:38.800
for using programmatic remote sampling.

00:07:38.800 --> 00:07:41.110
Initialize the framework.

00:07:41.440 --> 00:07:44.890
And called chat acquire remote access,
this ensures that Shark is ready for

00:07:44.980 --> 00:07:48.290
profiling and essentially that means
that you've selected the sampling

00:07:48.290 --> 00:07:49.770
programmatic remote in Shark.

00:07:49.840 --> 00:07:54.570
Then right before the Hanoi function,
we'll call start remote perf monitor,

00:07:54.570 --> 00:07:56.040
which takes a label.

00:07:56.040 --> 00:07:59.270
That label string will be the title
of the session that Shark creates.

00:07:59.360 --> 00:08:02.790
Then we run the function,
then we call stop remote perf monitor,

00:08:02.790 --> 00:08:05.030
and every time we do
that through the loop,

00:08:05.030 --> 00:08:06.370
we get a new session.

00:08:07.220 --> 00:08:11.350
When you finish with remote profiling,
remember to call release remote access.

00:08:11.700 --> 00:08:14.890
That way another program
can connect to Shark.

00:08:15.480 --> 00:08:18.270
Here's a better example,
maybe more concrete,

00:08:18.270 --> 00:08:21.030
that uses that window of time facility.

00:08:21.320 --> 00:08:24.060
We did this with Final Cut Pro.

00:08:24.080 --> 00:08:27.840
Put Shark in programmatic mode,
choose a config that has that

00:08:27.860 --> 00:08:31.280
window time facility enabled,
and then add some code to your

00:08:31.280 --> 00:08:34.980
program that'll stop profiling if you
find some kind of performance issue.

00:08:34.980 --> 00:08:39.700
So you can see here we start
sampling before we enter a work loop.

00:08:39.770 --> 00:08:42.590
And then in the work loop,
the only time we call stop

00:08:42.590 --> 00:08:46.020
remote proof monitor is if
there's some kind of reason to.

00:08:46.440 --> 00:08:49.440
If a slowdown is detected,
or in the case of Final Cut Pro,

00:08:49.440 --> 00:08:54.050
a dropped frame,
this way you can let Shark run all night.

00:08:54.140 --> 00:08:57.030
And at some point,
it may collect a session.

00:08:57.050 --> 00:08:59.200
You come back in the morning,
and everything's good.

00:08:59.200 --> 00:09:00.030
You have sessions.

00:09:00.030 --> 00:09:02.860
Hopefully you don't have sessions,
but you need to drop your frames.

00:09:02.880 --> 00:09:07.070
So I want to mention batch mode,
because batch mode isn't a trigger mode,

00:09:07.070 --> 00:09:10.390
but it really enhances the
other modes by instead of having

00:09:10.390 --> 00:09:14.140
sessions popping up on your screen,
the sessions are listed in

00:09:14.200 --> 00:09:15.880
order as they're created.

00:09:16.600 --> 00:09:19.950
This allows you to then choose
which of the sessions you want to

00:09:19.950 --> 00:09:23.530
open instead of having a lasagna
of windows on your desktop from

00:09:23.530 --> 00:09:25.510
dozens of sessions coming in.

00:09:25.540 --> 00:09:27.290
And that will happen.

00:09:29.430 --> 00:09:32.500
Lastly, I'd just like to mention the
command line version of Shark,

00:09:32.660 --> 00:09:36.530
which is really quite similar to Shark,
except it adds a couple of text

00:09:36.630 --> 00:09:40.560
file output reports and some
comma separate value reports

00:09:40.560 --> 00:09:42.990
depending on the configuration.

00:09:43.360 --> 00:09:46.480
You can use the same
hotkey as the application.

00:09:46.550 --> 00:09:49.940
However, if you run the application
and the command line at the

00:09:49.940 --> 00:09:53.300
same time on the same machine,
you can never be sure which of

00:09:53.300 --> 00:09:55.450
the two will get the hotkey first.

00:09:55.900 --> 00:09:59.650
So if you use Shark and you log into a
remote system with Command Line Shark,

00:09:59.710 --> 00:10:03.280
you can use Control Backslash
to toggle sampling.

00:10:03.790 --> 00:10:05.940
With Command Line Shark,
there are a host of command

00:10:05.940 --> 00:10:09.650
line options to start sampling
and launch your application.

00:10:09.790 --> 00:10:14.700
Command Line Shark can also attach to
your running application and sample that.

00:10:15.020 --> 00:10:18.260
In network mode,
as I mentioned the iPhone network,

00:10:18.390 --> 00:10:20.940
that was the control
system in the application.

00:10:20.940 --> 00:10:24.300
In network mode, the command line is
always the shared version.

00:10:24.300 --> 00:10:27.690
It's the other side, the client,
if you will.

00:10:28.070 --> 00:10:30.020
And lastly,
if you're using the remote triggering

00:10:30.020 --> 00:10:34.190
that I mentioned with the programmatic,
you can avoid using the chud calls

00:10:34.190 --> 00:10:37.600
at all because the command line
version of Shark actually responds

00:10:37.600 --> 00:10:41.960
to Unix signal SIG user 1 to start
Shark and SIG user 2 to stop Shark.

00:10:42.010 --> 00:10:45.870
So after that brief run through,
I'd like to turn things over to Lance to

00:10:45.870 --> 00:10:48.080
talk about a couple ways to use Shark.

00:10:55.690 --> 00:10:56.800
Thank you, Eric.

00:10:56.900 --> 00:11:00.320
So now that we know many ways to start
and stop Shark in different ways,

00:11:00.470 --> 00:11:03.270
let's look at how we can use
Shark to move beyond the basic

00:11:03.270 --> 00:11:06.800
time profiling of your CPU-bound
applications and go in and analyze

00:11:06.800 --> 00:11:10.070
the performance of your multi-threaded
applications that with today's Macs

00:11:10.070 --> 00:11:11.890
you inevitably will have to be doing.

00:11:11.900 --> 00:11:14.070
So the first part of this,
we're going to go in and look

00:11:14.310 --> 00:11:17.120
at a configuration in Shark that
you may not have used before,

00:11:17.120 --> 00:11:19.650
which helps you track down the
idle time in your application and

00:11:19.650 --> 00:11:21.260
figure out where it's coming from.

00:11:21.280 --> 00:11:23.900
We call it time profiling
all thread states.

00:11:25.420 --> 00:11:27.870
So, if you're here in this session,
we assume you've probably

00:11:27.870 --> 00:11:28.800
used Shark before.

00:11:28.800 --> 00:11:32.960
Otherwise, you might want to consider our
session in two days at the same time.

00:11:32.960 --> 00:11:35.790
And hence,
you've probably seen this tabular browser

00:11:35.800 --> 00:11:38.010
window pop up on your screen many times.

00:11:38.080 --> 00:11:40.380
And, well, you know, this is great.

00:11:40.420 --> 00:11:44.520
It summarizes what exactly the CPUs in
your program are doing in a very simple,

00:11:44.520 --> 00:11:45.260
concise format.

00:11:45.260 --> 00:11:49.500
And moreover, right up to the top,
just screaming, hey, optimize me,

00:11:49.500 --> 00:11:52.010
look here,
are the things that are executing the

00:11:52.080 --> 00:11:54.140
most in your application and telling you,
hey,

00:11:54.140 --> 00:11:55.220
that's where you need to go optimize.

00:11:55.400 --> 00:11:57.140
That's wonderful and all.

00:11:57.140 --> 00:12:00.030
But unfortunately,
in today's multi-threaded applications,

00:12:00.030 --> 00:12:01.490
it's not the only situation.

00:12:01.500 --> 00:12:04.100
Instead,
our application performance can really

00:12:04.110 --> 00:12:08.090
suffer because of what the CPUs are not
doing and when nothing is happening.

00:12:08.100 --> 00:12:11.110
You know, it can be as simple as,
you know, blocked waiting for I.O.,

00:12:11.110 --> 00:12:13.460
timers and things like that,
or even page faults.

00:12:13.460 --> 00:12:16.500
But moreover, in your actual
multi-threaded applications,

00:12:16.500 --> 00:12:20.240
it's more likely to be your threads
are synchronizing from one to another.

00:12:20.240 --> 00:12:24.250
And they're waiting for locks, barriers,
and other synchronization

00:12:24.250 --> 00:12:25.380
events to occur.

00:12:25.400 --> 00:12:28.520
And unfortunately,
if you just take a time

00:12:28.540 --> 00:12:32.330
profile of the whole system,
all you'll see is this idle

00:12:32.610 --> 00:12:34.440
time pop up to the top.

00:12:34.500 --> 00:12:36.650
And that really doesn't tell
you what you need to optimize.

00:12:36.660 --> 00:12:39.420
Moreover, if you take a time
profile of your process,

00:12:39.420 --> 00:12:41.290
you'd simply get no or few samples.

00:12:42.980 --> 00:12:44.580
So therefore,
we're going to suggest that you

00:12:44.610 --> 00:12:48.320
use Time Profile All Thread States,
which is a lot like Time Profile.

00:12:48.320 --> 00:12:51.680
It does almost the exact same thing
in that it comes in and samples

00:12:51.680 --> 00:12:54.710
your application very frequently,
or it can sample the entire

00:12:54.710 --> 00:12:55.740
system if you prefer.

00:12:55.740 --> 00:12:58.370
But unlike Time Profile,
which just simply records

00:12:58.410 --> 00:13:01.340
what's happening on the CPU,
All Thread States records not

00:13:01.430 --> 00:13:04.250
only the CPU-bound threads,
but also all those threads

00:13:04.250 --> 00:13:07.150
that are just sitting around
waiting to run and records,

00:13:07.220 --> 00:13:09.070
well, what they're not doing.

00:13:10.200 --> 00:13:12.830
And so, you know,
a really simple example of how we could

00:13:12.870 --> 00:13:15.970
use this is let's say your program is
running along and it completely deadlocks

00:13:15.970 --> 00:13:17.380
and nothing appears to be happening.

00:13:17.380 --> 00:13:20.940
If you would take a Time Profile of this,
well, you'd probably get no

00:13:20.940 --> 00:13:22.630
samples or very few samples.

00:13:22.660 --> 00:13:26.180
With a Time Profile All Thread States,
we can actually see and get samples

00:13:26.180 --> 00:13:29.040
of what all these threads are
not doing and see where they are

00:13:29.040 --> 00:13:32.720
deadlocked at and get a feeling for,
you know, how our program managed to get

00:13:32.720 --> 00:13:34.480
all pretzeled up in this way.

00:13:34.500 --> 00:13:36.670
And moreover,
you could also see if you have one thread

00:13:36.670 --> 00:13:40.160
that's running out there all by itself
and the other threads aren't responding.

00:13:40.160 --> 00:13:41.520
So, if you have one thread that's running
out there all by itself and the

00:13:41.520 --> 00:13:42.770
other threads aren't responding,
you actually will get samples

00:13:42.830 --> 00:13:43.530
from that thread being live.

00:13:43.580 --> 00:13:45.990
So, this is nice as a debugging tool.

00:13:46.000 --> 00:13:48.680
But let's see how we can use
this to performance analysis.

00:13:48.700 --> 00:13:51.470
So, for that,
we'll give a little simple example here.

00:13:51.480 --> 00:13:54.350
Let's say we have this
small loop in our program,

00:13:54.350 --> 00:13:56.980
which happens to be a
very important loop.

00:13:57.020 --> 00:13:59.320
And we want to make our
program thread safe.

00:13:59.320 --> 00:14:02.020
And the simplest way to make
serial code thread safe is,

00:14:02.020 --> 00:14:04.240
well,
let's just slap a lock around it and say,

00:14:04.290 --> 00:14:07.100
okay, only one thread at a
time going through here.

00:14:07.100 --> 00:14:09.480
And this is often actually sufficient.

00:14:10.180 --> 00:14:12.070
So, let's say we have enough
of these locks and they're

00:14:12.070 --> 00:14:13.420
covering small enough regions.

00:14:13.420 --> 00:14:16.020
But what you might find is
if you put some of this in,

00:14:16.190 --> 00:14:18.310
you try to measure your performance and,
well,

00:14:18.310 --> 00:14:20.280
it doesn't seem to be improving at all.

00:14:20.420 --> 00:14:21.580
So, what can we do?

00:14:21.810 --> 00:14:24.220
Well, if you just simply use
a time profile on this,

00:14:24.220 --> 00:14:27.180
well, you'll get this hot spot
in the middle of the loop.

00:14:27.380 --> 00:14:29.120
That's pretty much what you'd expect.

00:14:29.120 --> 00:14:30.860
You know, that's the code that's
executing the most.

00:14:30.860 --> 00:14:32.700
It's doing a lot of floating
point math and the like.

00:14:32.700 --> 00:14:34.980
But unfortunately,
it's not really telling you what your

00:14:35.090 --> 00:14:36.690
performance problem is coming from.

00:14:36.700 --> 00:14:39.350
For that, instead,
you need to know that the

00:14:39.350 --> 00:14:39.840
real problem is all the time.

00:14:39.840 --> 00:14:39.840
So, let's say we have a lot of time.

00:14:39.840 --> 00:14:40.000
Well,
that's pretty much what you'd expect.

00:14:40.000 --> 00:14:40.080
You know, that's the code that's
executing the most.

00:14:40.180 --> 00:14:42.820
All the threads getting piled up
on this lock at the entry point,

00:14:42.820 --> 00:14:45.260
trying to get in here and just
wasting their time waiting.

00:14:45.260 --> 00:14:49.220
And to know this, you need to use a time
profile on thread states.

00:14:51.230 --> 00:14:53.560
Well, you know, heck,
you could have probably just

00:14:53.590 --> 00:14:55.550
taken a time profile and gone,
well, yeah,

00:14:55.550 --> 00:14:56.910
that's the hotspot in my program.

00:14:56.920 --> 00:14:58.550
You know,
the lock right in front of it is going

00:14:58.550 --> 00:14:59.970
to be where everything is waiting.

00:14:59.970 --> 00:15:01.860
I can kind of figure
that out by inspection.

00:15:01.860 --> 00:15:05.050
Well, you know,
that works on an example that's trivial.

00:15:05.060 --> 00:15:07.780
But in a real program, of course,
this is only going to be

00:15:07.780 --> 00:15:10.100
one little spot in your big,
huge program.

00:15:10.100 --> 00:15:12.130
And instead,
you're going to have a lot of other

00:15:12.130 --> 00:15:14.170
blocking points scattered around as well.

00:15:15.040 --> 00:15:17.980
And, well, you know,
those might not have any correlation

00:15:17.980 --> 00:15:21.320
whatsoever with the hotspots
identified by the time profile.

00:15:21.320 --> 00:15:23.760
But all thread states let
you go and identify all

00:15:23.760 --> 00:15:25.510
these other hotspots as well.

00:15:27.440 --> 00:15:28.680
So, hey, this sounds wonderful.

00:15:28.680 --> 00:15:30.690
This shows both the
hotspots we're executing,

00:15:30.690 --> 00:15:31.540
where we're not executing.

00:15:31.540 --> 00:15:33.340
Hey, Ash, forget time profile.

00:15:33.340 --> 00:15:34.120
Let's just use this.

00:15:34.120 --> 00:15:38.340
That's not always the best idea either,
because there are a couple caveats here.

00:15:38.340 --> 00:15:41.260
First off, if you think about it,
we're recording the state of

00:15:41.370 --> 00:15:44.330
all the threads in your system,
whether they're running or not.

00:15:44.330 --> 00:15:48.180
So there is inevitably higher overhead
associated with taking each sample.

00:15:48.180 --> 00:15:50.400
And if you're taking a
high enough sampling rate,

00:15:50.400 --> 00:15:53.270
this therefore can cause Shark to
actually eat up a fair number of

00:15:53.270 --> 00:15:56.760
CPU cycles and may have some impact
on the performance of your program.

00:15:57.500 --> 00:16:00.420
So that might not always be desirable.

00:16:00.930 --> 00:16:04.280
But the more important part is that
unlike with the basic time profile

00:16:04.280 --> 00:16:06.860
where all this important stuff
comes right up to the top and says,

00:16:06.920 --> 00:16:10.300
hey, optimize me, well,
with all thread states, unfortunately,

00:16:10.300 --> 00:16:11.440
that doesn't always happen.

00:16:11.440 --> 00:16:13.650
Because we're actually
sampling from all the threads,

00:16:13.650 --> 00:16:15.040
whether they're blocked or not.

00:16:15.070 --> 00:16:17.470
And, well,
there's usually a bunch of blocked

00:16:17.490 --> 00:16:21.050
threads in Mac OS X processes that are,
you know, just sitting around

00:16:21.050 --> 00:16:23.440
minding their own business,
and they're supposed to

00:16:23.440 --> 00:16:24.290
be sitting there blocked.

00:16:24.400 --> 00:16:26.150
You know,
typically things like waiting for

00:16:26.150 --> 00:16:27.540
UI events to occur and the like.

00:16:27.540 --> 00:16:30.060
And, frankly, you know,
you could care less about those.

00:16:31.300 --> 00:16:44.600
[Transcript missing]

00:16:45.490 --> 00:16:48.270
So let's give you an example of the
kind of thinking process you'll have to

00:16:48.270 --> 00:16:51.220
use whenever you're trying to parse one
of these all-threaded state displays.

00:16:51.220 --> 00:16:53.820
So up here on screen,
we've got a simple little

00:16:53.830 --> 00:16:56.480
example of how you might have
a multi-threaded application.

00:16:56.480 --> 00:17:00.260
And then we've got a master thread,
which is running along and forking off

00:17:00.260 --> 00:17:02.340
work to a variety of worker threads.

00:17:02.360 --> 00:17:06.210
So if we look at how this
executes over the course of time,

00:17:06.210 --> 00:17:09.240
what's going to happen is the master
thread will execute for a while.

00:17:09.240 --> 00:17:13.170
And then when it reaches a point where
it can fork off some parallel work,

00:17:13.170 --> 00:17:17.040
it will, at the start line barrier where
all the workers are waiting,

00:17:17.040 --> 00:17:18.760
it'll say, hey, everyone, go.

00:17:18.760 --> 00:17:22.390
They'll go and start executing in
parallel for a while until they

00:17:22.690 --> 00:17:24.370
finish their parallel region.

00:17:24.380 --> 00:17:27.650
And then they'll all pile up at
this finish line barrier until all

00:17:27.650 --> 00:17:29.530
of them are done with their work.

00:17:29.540 --> 00:17:32.820
And then they'll let the master
start up its serial execution again.

00:17:32.840 --> 00:17:35.960
This is a really simple and common
parallel programming paradigm.

00:17:37.760 --> 00:17:38.780
How can we optimize this?

00:17:38.780 --> 00:17:41.270
First off,
you'll definitely want to go in

00:17:41.270 --> 00:17:43.930
and optimize all this active time
that you see up here in blue.

00:17:43.930 --> 00:17:46.420
Just the stuff that time
profile was telling you to

00:17:46.540 --> 00:17:49.720
do in multi-threaded domain,
that's still very important.

00:17:49.720 --> 00:17:51.940
You still want to go in and optimize it,
no question about it.

00:17:52.080 --> 00:17:54.680
But with the block time here,
it's important,

00:17:54.780 --> 00:17:56.660
but it's not quite as straightforward.

00:17:57.620 --> 00:18:00.460
So, for example,
the time that workers are spent

00:18:00.460 --> 00:18:03.840
waiting at the finish line barrier,
this is caused by load

00:18:03.840 --> 00:18:07.240
imbalance among threads,
some of them finishing too early.

00:18:07.240 --> 00:18:10.080
And frankly,
by waiting around for some parallel

00:18:10.080 --> 00:18:13.890
threads longer than others,
we're actually wasting our time.

00:18:13.900 --> 00:18:17.700
If we could take some of the work being
done by that third longer thread and

00:18:17.700 --> 00:18:21.670
move it over to one of the fast ones,
we could actually reach that finish line

00:18:21.700 --> 00:18:23.940
barrier sooner with all four threads.

00:18:23.980 --> 00:18:27.600
So we really want to minimize
this to reduce load imbalance.

00:18:27.620 --> 00:18:29.020
points.

00:18:29.610 --> 00:18:31.020
Secondly,
we have the time that the workers

00:18:31.050 --> 00:18:33.930
spend at their start line barrier,
just simply waiting for

00:18:33.930 --> 00:18:35.420
work to be given to them.

00:18:35.560 --> 00:18:37.740
Well, you know,
we do want to minimize this, but,

00:18:37.800 --> 00:18:40.490
you know, frankly,
the information we're getting here from

00:18:40.540 --> 00:18:43.810
Shark is maybe not as useful because,
really, it's pretty redundant.

00:18:43.870 --> 00:18:46.270
It's just simply the same time
that the master spend is working,

00:18:46.280 --> 00:18:47.680
you know, multiplied by four here.

00:18:47.930 --> 00:18:52.580
So it's nice,
but it's not really any new information.

00:18:52.810 --> 00:18:54.970
And then we had the time that the
master spends waiting and blocked.

00:18:55.030 --> 00:18:58.060
And frankly, who cares about this?

00:18:58.060 --> 00:18:59.100
It doesn't make any difference.

00:18:59.100 --> 00:19:02.080
We want the parallel workers to
be working as much as possible.

00:19:02.080 --> 00:19:04.150
We want the master to be
sitting around waiting for them.

00:19:04.160 --> 00:19:06.230
So, you know, you can ignore this.

00:19:06.260 --> 00:19:08.660
Going back and looking
at our original code,

00:19:08.660 --> 00:19:11.920
therefore, well,
these hotspots will appear when we

00:19:11.920 --> 00:19:14.280
do a time profile all thread states,
but we don't actually

00:19:14.280 --> 00:19:15.380
care about all of them.

00:19:15.420 --> 00:19:18.840
If we go in and think about
the analysis we just did and

00:19:18.840 --> 00:19:21.570
apply it to what we see here,
you can actually realize

00:19:21.790 --> 00:19:25.150
that these top two hotspots,
poof, we can just ignore those altogether

00:19:25.160 --> 00:19:27.040
because those are things which
we really don't care about.

00:19:27.080 --> 00:19:29.130
Instead,
we care about the time that the workers

00:19:29.130 --> 00:19:33.570
are actually working and about the
time that they're waiting at the finish

00:19:33.690 --> 00:19:35.690
line barrier caused by load imbalance.

00:19:35.730 --> 00:19:37.740
And those are what's
really important for us.

00:19:39.780 --> 00:19:43.020
Okay, so now that I've kind of given
you a view as to what time

00:19:43.030 --> 00:19:47.490
profile threat states can do,
let's make this a little more concrete.

00:19:47.580 --> 00:19:51.290
So last year in our session,
we demonstrated how we took

00:19:51.500 --> 00:19:55.400
the reference code from the
internet for the MPEG-2 decoder.

00:19:55.470 --> 00:20:00.300
And just doing serial optimizations,
we were able to speed it up by about 6x.

00:20:00.330 --> 00:20:01.300
Pretty decent.

00:20:01.370 --> 00:20:04.630
But we were only using one core,
and today's Macs have

00:20:04.630 --> 00:20:06.190
several cores to use.

00:20:06.840 --> 00:20:10.160
So unfortunately we
found going beyond that,

00:20:10.160 --> 00:20:14.100
the parallelizing was either
easy or pretty hard depending on

00:20:14.150 --> 00:20:16.340
which loops we were looking at.

00:20:16.340 --> 00:20:20.630
We found that the pixel operations,
which we took entire frames of pixels and

00:20:20.630 --> 00:20:25.340
did operations over the entire frames,
those were pretty easy to parallelize.

00:20:25.340 --> 00:20:28.430
And that we can just
simply take the frames and,

00:20:28.430 --> 00:20:32.580
you know, pass them out,
pass out chunks into the cores and use a

00:20:32.590 --> 00:20:37.080
synchronization routine just like you saw
in a couple of slides back with barriers

00:20:37.110 --> 00:20:39.370
at the beginning and end of each frame.

00:20:39.680 --> 00:20:43.040
Unfortunately,
the actual decoding loops were much

00:20:43.150 --> 00:20:47.330
harder because we had in between
the actual decoding operations,

00:20:47.370 --> 00:20:51.100
we're actually accessing the
movie file itself on disk.

00:20:51.100 --> 00:20:55.530
And that's a serial operation
because we're reading variable length

00:20:55.640 --> 00:20:57.650
chunks for each bit of picture.

00:20:57.750 --> 00:21:01.890
So, you know, we wondered, well,
do we really have to do this?

00:21:01.990 --> 00:21:03.970
That looks like a lot of work.

00:21:03.970 --> 00:21:05.320
Let's see if we can just simply
do the easy parallelization

00:21:05.320 --> 00:21:05.320
and leave it at that.

00:21:05.900 --> 00:21:14.500
[Transcript missing]

00:21:21.310 --> 00:21:31.660
So this is an eight core machine
and I want to... One thing,

00:21:31.670 --> 00:21:33.860
if you want to use the
processor pref pane,

00:21:33.880 --> 00:21:35.410
we get a lot of requests for this.

00:21:35.510 --> 00:21:40.080
It's actually buried nowadays off in
developer extras preference panes.

00:21:40.080 --> 00:21:43.120
It's not actually installed by
default when you install Shark.

00:21:43.190 --> 00:21:48.960
So this is a really good trick to
know if you want to actually play

00:21:48.960 --> 00:21:50.760
with different numbers of processors.

00:21:51.300 --> 00:21:53.860
On the same computer and
see how the number of cores

00:21:53.860 --> 00:21:55.360
actually affects your work.

00:21:55.480 --> 00:21:57.920
I'm going to look at this
right now with just four cores,

00:21:57.960 --> 00:22:00.400
just to see how this goes.

00:22:00.830 --> 00:22:04.130
So first off,
if we go back to look at our decoder,

00:22:04.130 --> 00:22:08.000
well, it started out,
this is running about real time with

00:22:08.000 --> 00:22:10.140
these seals swimming around in circles.

00:22:10.140 --> 00:22:13.480
And so, you know, I think, well,
that's not too bad.

00:22:13.480 --> 00:22:16.500
But this is, of course,
using an entire processor on

00:22:16.500 --> 00:22:18.280
a high-end Mac Pro machine.

00:22:18.680 --> 00:22:20.690
So, you know,
we really will typically want to

00:22:20.790 --> 00:22:23.500
just use a very small amount of
processors so we can do multiple,

00:22:23.540 --> 00:22:26.120
we can do like high-definition video,
because this is just a

00:22:26.160 --> 00:22:29.120
standard definition video,
or we can do multiple streams at once,

00:22:29.120 --> 00:22:31.330
or, hey,
we can do other things like shutting down

00:22:31.330 --> 00:22:33.620
the processor and letting it save power.

00:22:34.970 --> 00:22:39.190
So we first took this and, like I said,
last year we managed to speed

00:22:39.290 --> 00:22:42.250
it up pretty well just by
doing serial optimizations.

00:22:42.320 --> 00:22:44.890
So now these, just by working with
serial optimizations,

00:22:44.890 --> 00:22:46.920
we're able to get these seals
going considerably faster,

00:22:46.930 --> 00:22:51.020
now to about 144,
140-ish frames a second.

00:22:51.210 --> 00:22:52.360
Pretty good.

00:22:52.430 --> 00:22:56.910
But we wondered, can we make that,
can we do better with multiple cores?

00:22:57.300 --> 00:23:04.190
So, let me change this to use four cores
and just doing the easy optimizations.

00:23:04.250 --> 00:23:06.190
Let's try this out.

00:23:06.460 --> 00:23:11.160
Well, it's definitely faster,
but that's not very much faster.

00:23:11.160 --> 00:23:13.670
That's only about 10
frames per second faster.

00:23:13.670 --> 00:23:17.430
So let's use Shark to
go and analyze this.

00:23:17.440 --> 00:23:21.060
So first I'll switch from time profile
to time profile all thread states.

00:23:21.060 --> 00:23:23.980
And I'm going to look at
my MPEG-2 decode process.

00:23:23.980 --> 00:23:25.950
So I'll start that out.

00:23:26.010 --> 00:23:28.520
And let these guys do a couple laps.

00:23:28.520 --> 00:23:31.610
And then I'll use the hotkey
that Eric was discussing

00:23:31.610 --> 00:23:33.260
to go ahead and quit that.

00:23:34.500 --> 00:23:38.640
And clear this out of the way
to let Shark analyze faster.

00:23:38.670 --> 00:23:41.460
So what we're going to see here in
a moment is a browser display that

00:23:41.470 --> 00:23:46.300
looks much like you just saw from any
normal time profile that you might do.

00:23:46.300 --> 00:23:48.480
And it looks pretty familiar here.

00:23:48.480 --> 00:23:54.070
The one big difference is that
you can see up here at the top,

00:23:54.460 --> 00:23:58.160
are several symbols that you
may not be familiar with.

00:23:58.160 --> 00:24:00.660
A lot of semaphore stuff and so on.

00:24:00.690 --> 00:24:05.490
And what these are from are symbols
from anything which is blocked,

00:24:05.670 --> 00:24:07.260
threads that are blocked.

00:24:07.290 --> 00:24:09.520
And you can see when we look
down here at all the threads,

00:24:09.540 --> 00:24:12.400
where on a time profile,
we'd see a couple of decoding threads,

00:24:12.610 --> 00:24:16.000
here we have a lot of
threads all piled up.

00:24:16.030 --> 00:24:18.700
'Cause a lot of these threads were just
simply sitting around doing nothing.

00:24:18.700 --> 00:24:20.580
But we took samples from them.

00:24:20.740 --> 00:24:23.170
And as you can see here,
most all the threads had the

00:24:23.170 --> 00:24:26.000
same number of samples because we
were taking a sample from every

00:24:26.030 --> 00:24:27.680
single thread every single time.

00:24:27.830 --> 00:24:30.680
And this is sort of a hallmark of
a time profile all threads stays.

00:24:30.710 --> 00:24:33.390
Except you see this one guy down here,
well, that was a thread that was

00:24:33.390 --> 00:24:35.760
actually created or destroyed
while we were sampling.

00:24:35.760 --> 00:24:39.070
And hence it doesn't have
the same number of samples.

00:24:39.570 --> 00:24:42.380
So going in and looking at these,
we can pop some of these open,

00:24:42.400 --> 00:24:44.660
and if you dig down a few
levels through this list,

00:24:44.660 --> 00:24:48.580
well, eventually we reach a point where,
well, let's see, this looks, oh, man,

00:24:48.580 --> 00:24:50.840
that's like some UI garbage or something.

00:24:50.840 --> 00:24:52.470
I don't really want to know about that.

00:24:52.500 --> 00:24:54.070
You can keep digging through here.

00:24:54.070 --> 00:24:55.150
This can take a while.

00:24:55.160 --> 00:24:59.090
So what I really recommend you do is if
you hold down the Option key at any time,

00:24:59.090 --> 00:25:02.560
either with all thread states or
with a time profile one as well,

00:25:02.560 --> 00:25:05.000
you click, boom,
these are just all open at once,

00:25:05.020 --> 00:25:08.170
sometimes giving you more
information than you really want.

00:25:08.880 --> 00:25:10.460
But it makes it,
when you're digging through

00:25:10.460 --> 00:25:12.560
these really deep stacks,
it makes it a lot easier.

00:25:12.560 --> 00:25:14.820
And we can just see at
a quick glance here,

00:25:14.820 --> 00:25:17.870
that's from a bunch of, like,
UI threads and so on.

00:25:17.910 --> 00:25:19.160
So I really don't care about that either.

00:25:19.160 --> 00:25:23.100
And really, we have to dig down through
a few of these before,

00:25:23.100 --> 00:25:26.170
oh, okay,
now we're getting into weight points

00:25:26.210 --> 00:25:28.490
that our code actually called.

00:25:28.490 --> 00:25:33.280
And in fact, we can see these are various
points in our program.

00:25:33.280 --> 00:25:35.690
And to kind of try to
reduce the clutter somewhat,

00:25:35.690 --> 00:25:38.470
I'm going to go in and look
at one of the various worker

00:25:38.470 --> 00:25:42.300
threads that I use to actually
do parallel work in this program.

00:25:42.300 --> 00:25:45.220
And we can now see at a glance that,
well,

00:25:45.220 --> 00:25:51.420
these worker threads are spending 88%
of the time just waiting for work to do.

00:25:51.540 --> 00:25:51.820
Hmm.

00:25:51.820 --> 00:25:56.290
Well, let's see, why are they waiting?

00:25:56.290 --> 00:25:56.290
If I pop this open,

00:25:56.710 --> 00:25:59.720
We can now -- I've actually labeled
the routines here so you can see

00:25:59.720 --> 00:26:03.480
here's the start line barrier and
here's the finish line barrier.

00:26:03.480 --> 00:26:07.580
So the finish line barrier,
we're having a couple percent there.

00:26:07.720 --> 00:26:12.320
That's, you know, that's not zero,
but it's not horrible either.

00:26:12.430 --> 00:26:15.220
Most of our time, unfortunately,
is here at the start line barrier.

00:26:15.240 --> 00:26:17.880
We're waiting there
ridiculous amounts of time.

00:26:17.880 --> 00:26:21.260
So unfortunately what we're seeing here
is that we probably just can't get away

00:26:21.260 --> 00:26:23.100
with doing those easy parallelizations.

00:26:23.100 --> 00:26:26.480
This is really dropping way
too much time on the floor.

00:26:26.480 --> 00:26:29.060
Also I'll point out that when your
symbol names don't tell you this

00:26:29.060 --> 00:26:32.900
really clearly right off the bat,
you can go -- if you have, say,

00:26:32.900 --> 00:26:35.180
multiple synchronization
points in a single function,

00:26:35.320 --> 00:26:39.070
you can just double click on these just
like you can with time profile and it

00:26:39.070 --> 00:26:41.230
will toss you into the source code.

00:26:41.430 --> 00:26:43.910
As you see here,
I kind of just tossed randomly about

00:26:43.910 --> 00:26:45.570
and there aren't any highlights.

00:26:45.760 --> 00:26:49.200
That's because only the sort
self column is highlighted.

00:26:49.260 --> 00:26:52.300
So I'm going to go over here and
show the advanced settings drawer.

00:26:52.300 --> 00:26:54.550
You want to make sure you have this
-- you want to make sure you have this

00:26:54.550 --> 00:26:56.340
show total column checkbox clicked.

00:26:56.360 --> 00:26:58.040
Now we added the total column.

00:26:58.230 --> 00:27:01.110
And if we move around,
now we can actually see the

00:27:01.110 --> 00:27:06.310
synchronization points where we were
calling into routines and blocking.

00:27:06.330 --> 00:27:08.220
And they've now been highlighted
so we can see exactly where

00:27:08.220 --> 00:27:10.540
those were and where we were
spending all our time waiting.

00:27:12.220 --> 00:27:16.260
Okay, so going back to the slides,
what we learned here was

00:27:16.260 --> 00:27:20.340
that we're probably going to
need to do some more work.

00:27:20.340 --> 00:27:25.240
So, well, you know,
we'll look at that more in a little bit.

00:27:25.290 --> 00:27:30.750
But for now, I want to look at trying to
simplify down some of that clutter.

00:27:31.040 --> 00:27:34.260
You saw with just that little
session looking at this,

00:27:34.260 --> 00:27:38.270
well, fairly simple example application,
there was a whole lot of clutter

00:27:38.270 --> 00:27:41.010
to dig through in that display
because there was a lot of blocking

00:27:41.010 --> 00:27:42.550
calls in any real application.

00:27:42.560 --> 00:27:45.930
And if you have, you know,
a full large-scale application,

00:27:45.930 --> 00:27:48.470
it can be just a nightmare
to dig through it.

00:27:48.520 --> 00:27:52.800
So, to try to dig through some of that,
we're going to use options we call data

00:27:52.800 --> 00:27:56.890
mining in Shark to actually go and look
just at what you're interested in by

00:27:56.920 --> 00:28:00.980
doing things like hiding symbols or,
in fact, entire libraries.

00:28:01.040 --> 00:28:04.770
which are not of interest
to us at any point in time.

00:28:05.000 --> 00:28:41.700
[Transcript missing]

00:28:42.580 --> 00:28:46.100
So just to give you a little reminder
of what Shark is doing under the covers,

00:28:46.110 --> 00:28:49.310
what it's actually doing is
recording call stacks over

00:28:49.750 --> 00:28:51.530
time at each sample point.

00:28:51.610 --> 00:28:55.090
And it then goes and takes these
call stacks and processes them,

00:28:55.220 --> 00:28:57.700
starting from the root,
going up to the top,

00:28:57.700 --> 00:29:00.720
and building up a tree of what
all functions are being called

00:29:00.750 --> 00:29:02.970
and who's calling each other.

00:29:03.450 --> 00:29:06.130
These trees are then what's used
to display the browsers and get

00:29:06.200 --> 00:29:08.240
the various trees you see there.

00:29:08.320 --> 00:29:12.530
Moreover, you may have noticed the total
and self columns in your browser.

00:29:12.710 --> 00:29:14.730
Well,
these are actually done by the-- Shark is

00:29:14.730 --> 00:29:18.320
doing accounting under the covers as
it's counting up all these functions.

00:29:18.390 --> 00:29:22.390
And what we have here is self is
the actual number of samples that

00:29:22.390 --> 00:29:25.090
fall within a particular function.

00:29:25.330 --> 00:29:29.200
While total is the number of samples
that fall either within that function,

00:29:29.200 --> 00:29:31.710
the self samples,
or in any of the functions

00:29:31.710 --> 00:29:33.840
that it calls underneath.

00:29:35.680 --> 00:29:38.770
So with this kind of understanding,
keep an eye on this and you'll

00:29:38.770 --> 00:29:41.800
see how this changes as we
data mine in different ways.

00:29:42.170 --> 00:29:44.980
So first, and probably foremost,
it's one of the first things

00:29:45.020 --> 00:29:47.410
I almost always do here when
looking at a complicated

00:29:47.410 --> 00:29:49.420
Shark session is charging libraries.

00:29:49.420 --> 00:29:53.240
So, for example, up here in this tree,
we have some code from, like,

00:29:53.240 --> 00:29:55.220
system libraries provided by Apple.

00:29:55.220 --> 00:29:58.040
And that's code you can't actually
touch and modify yourself.

00:29:58.040 --> 00:30:00.150
So, you know,
you'd really rather just not

00:30:00.150 --> 00:30:03.120
worry about the fact that the
samples fell deep in there.

00:30:03.120 --> 00:30:05.710
You're instead worried about your
own code that you can actually change

00:30:05.710 --> 00:30:07.250
that's calling into these libraries.

00:30:07.260 --> 00:30:09.520
So let's try to get rid of some of those.

00:30:10.300 --> 00:30:14.060
What we can do is we can charge
the lib system calls under here,

00:30:14.060 --> 00:30:15.030
get rid of them.

00:30:15.060 --> 00:30:18.300
But since we do want to know which
of our functions we're spending

00:30:18.300 --> 00:30:20.730
time calling into those libraries,
because we may want to

00:30:20.730 --> 00:30:23.930
optimize those functions,
we can have Shark take all those

00:30:23.930 --> 00:30:28.080
samples and coalesce them up into your
functions that are making the calls.

00:30:28.080 --> 00:30:31.200
So we can still see that
those functions are important.

00:30:31.200 --> 00:30:33.050
And they may, in fact,
then pop up to the top

00:30:33.050 --> 00:30:34.690
of the list and say,
hey, look at me,

00:30:34.690 --> 00:30:36.070
I'm the most important part here.

00:30:38.180 --> 00:30:41.780
And as you can see here,
what we have is that

00:30:41.980 --> 00:30:45.430
up in the baz function,
after we've done this coalescing,

00:30:45.470 --> 00:30:48.320
all the samples that have been brought
up from below are actually mixed in

00:30:48.320 --> 00:30:49.700
with the ones that are already there.

00:30:49.830 --> 00:30:53.390
So now the self number
in baz is pretty high.

00:30:53.720 --> 00:30:55.880
Well, in fact, you may not actually
want that at all times.

00:30:55.880 --> 00:30:57.970
What you may want is something
a little less aggressive.

00:30:57.970 --> 00:31:01.130
And so for that, you might want to do
flattening of your libraries.

00:31:01.130 --> 00:31:03.980
So in this case, like, let's say,
you know, we don't really care about

00:31:04.090 --> 00:31:06.620
all the guts of the library,
but we do want to know what samples we're

00:31:06.670 --> 00:31:08.800
having that are calling lock and unlock.

00:31:08.800 --> 00:31:12.870
So let's simplify by getting
everything below the lock and unlock,

00:31:12.870 --> 00:31:17.660
but keeping the actual calls themselves
so we know when we're making calls.

00:31:17.660 --> 00:31:20.550
So now we just take those
samples and we bring them up

00:31:20.550 --> 00:31:22.640
into the first level of callers.

00:31:24.220 --> 00:31:27.650
and Chris Higgins will be joining
us for a sneak peak at how Shark is

00:31:27.660 --> 00:31:29.500
evolving for future releases.

00:31:31.660 --> 00:31:33.160
Another thing you might
want to do is say,

00:31:33.160 --> 00:31:36.080
you know, I don't want to worry about
this portion of my trace

00:31:36.130 --> 00:31:37.860
profile at this point in time.

00:31:37.860 --> 00:31:39.990
I want to focus in on
this part over here.

00:31:40.000 --> 00:31:42.330
Well, let's just simply remove it.

00:31:42.400 --> 00:31:44.720
Like, let's say we don't care about
the bar function at all.

00:31:44.720 --> 00:31:47.370
Let's just get rid of that because
I want to focus in on what's happening

00:31:47.370 --> 00:31:48.950
over at the other side of the tree.

00:31:50.030 --> 00:31:52.590
And so we can just
simply cross those out,

00:31:52.590 --> 00:31:53.900
nuke them entirely.

00:31:53.900 --> 00:31:59.740
And what will happen here is that unlike
the previous flattening and so on,

00:31:59.740 --> 00:32:02.400
where we're coalescing samples,
we're going to take the totals and drop

00:32:02.560 --> 00:32:05.610
them down because these three samples
are now removed from the profile,

00:32:05.740 --> 00:32:08.870
at least from the view you're
currently getting with data mining.

00:32:11.110 --> 00:32:14.020
Well, okay, that works pretty well,
but what if instead of trying to

00:32:14.030 --> 00:32:17.200
knock out one symbol at a time,
we instead want to go in and

00:32:17.200 --> 00:32:19.320
look at one particular symbol?

00:32:19.320 --> 00:32:23.180
Let's say bar is actually what we decided
was really the most important thing.

00:32:23.200 --> 00:32:25.070
Let's go in and focus on that.

00:32:25.080 --> 00:32:29.080
And once we focus in on bar, well,
then all the other

00:32:29.080 --> 00:32:30.860
samples will disappear.

00:32:30.860 --> 00:32:37.580
And we'll drop the totals for the
remaining callers down appropriately.

00:32:37.580 --> 00:32:39.020
We remove those four samples.

00:32:40.200 --> 00:32:42.880
And one thing I really want to
point out here is that all the

00:32:42.900 --> 00:32:45.420
self samples from Baz are gone.

00:32:45.440 --> 00:32:48.340
All the self samples didn't
actually involve bar.

00:32:48.340 --> 00:32:51.100
So hence,
since bar is not in the call stack,

00:32:51.100 --> 00:32:52.470
those are removed.

00:32:54.680 --> 00:32:55.670
Okay, that's pretty good.

00:32:55.690 --> 00:33:00.120
But what focusing actually does more
than just simply removing samples.

00:33:00.120 --> 00:33:05.860
It also takes the tree and hides
the part of it above your symbol.

00:33:05.860 --> 00:33:08.430
So all that stuff like start
and main and whatnot that's

00:33:08.430 --> 00:33:10.720
all at the root of the tree,
you know, frankly,

00:33:10.720 --> 00:33:13.470
if you're focusing on that symbol,
you probably don't care

00:33:13.560 --> 00:33:14.800
so much about those.

00:33:14.800 --> 00:33:17.420
You want to know about your
symbol and everything below it

00:33:17.500 --> 00:33:19.200
and what it's actually calling.

00:33:19.200 --> 00:33:24.230
Or at other times, you might want to know
how it's being reached,

00:33:24.230 --> 00:33:24.560
what's going on.

00:33:24.640 --> 00:33:28.800
So if you do actually want to know
about all that start and main and so on,

00:33:28.800 --> 00:33:31.320
well, you can do focus callers instead.

00:33:31.320 --> 00:33:35.510
And that will go in and show you just
the paths down to your function while

00:33:35.510 --> 00:33:37.790
leaving out everything below it.

00:33:38.090 --> 00:33:38.980
Okay, that's all pretty good.

00:33:39.000 --> 00:33:42.810
Well, but in a real application,
just doing one or two of

00:33:42.810 --> 00:33:45.350
these options probably won't
simplify things down enough.

00:33:45.350 --> 00:33:48.040
So really, you're going to want to mix
and match a lot of them.

00:33:48.040 --> 00:33:49.510
And Shark's able to do that.

00:33:49.560 --> 00:33:52.850
It can go and apply many of
these operations serially,

00:33:52.960 --> 00:33:55.790
one after another,
as you've selected them.

00:33:56.520 --> 00:34:00.500
And so, for example,
let's say we want to focus in on foo.

00:34:00.500 --> 00:34:01.920
That's our area of most interest.

00:34:01.920 --> 00:34:03.860
So that chops out part of the tree.

00:34:03.860 --> 00:34:06.200
But, you know,
we also don't care about the stuff

00:34:06.200 --> 00:34:07.780
inside the lib system as well.

00:34:07.780 --> 00:34:10.040
So let's go ahead and
flatten that out as well.

00:34:10.040 --> 00:34:12.580
And now by applying these
two operations at once,

00:34:12.580 --> 00:34:16.090
we've now taken our big tree there
and simplified it down to just a small

00:34:16.160 --> 00:34:19.650
section that we can really focus our
attention in on and figure out how

00:34:19.650 --> 00:34:21.880
to optimize that part of the program.

00:34:24.460 --> 00:34:26.260
Well, okay, so this is a lot of stuff.

00:34:26.260 --> 00:34:29.020
You know,
how can we actually control all this?

00:34:29.020 --> 00:34:32.950
Well, there's a data mining menu that you
may have seen up in the menu bar,

00:34:32.950 --> 00:34:34.140
potentially ignored.

00:34:34.250 --> 00:34:37.420
And all these commands are
just simply up in that menu.

00:34:37.420 --> 00:34:40.530
You just need to select your
symbol in the browser display

00:34:40.530 --> 00:34:42.160
and go up and choose the menu.

00:34:42.160 --> 00:34:44.890
Or if you have a two-button
mouse or a control click,

00:34:44.890 --> 00:34:48.600
you can pull up a contextual menu
on any symbol in the profile browser

00:34:48.600 --> 00:34:51.910
displays and choose to go in and
do any of these options on that

00:34:52.040 --> 00:34:55.140
particular symbol our library.

00:34:55.980 --> 00:34:57.900
But, hey, there's more as well.

00:34:57.900 --> 00:35:01.000
So if you go over here to
the Advanced Settings drawer,

00:35:01.000 --> 00:35:04.170
you'll notice that whenever
you have any view in Shark,

00:35:04.170 --> 00:35:07.910
some sort of profile browser from
many different configurations

00:35:07.960 --> 00:35:11.910
where data mining can occur,
well, this pane over here will actually

00:35:11.910 --> 00:35:13.960
appear so that you can use it.

00:35:14.540 --> 00:35:17.360
And it actually provides
a lot of useful controls.

00:35:17.360 --> 00:35:21.260
First off, there's just the on/off
control at the very top.

00:35:21.380 --> 00:35:24.860
It's really great to just simply
flick that on and off to kind of see

00:35:24.860 --> 00:35:27.780
a quick before and after comparison
because when you flick it off,

00:35:27.780 --> 00:35:29.770
it won't forget the sequence
of data mining options.

00:35:29.810 --> 00:35:32.320
So you can actually
just go back and forth.

00:35:32.540 --> 00:35:35.440
Also, there are several preset
really useful techniques.

00:35:35.440 --> 00:35:38.680
Charging and flattening system libraries,
like I mentioned,

00:35:38.680 --> 00:35:41.270
are just right there so you
can get them at a click.

00:35:41.530 --> 00:35:50.330
and I will be joined by Eric Miller,
Lance Hammond, Rick Altherr,

00:35:50.330 --> 00:35:57.390
Rick Altherr,
and I will be joined by Eric Miller.

00:35:57.850 --> 00:36:00.500
Also, you can say, okay, well,
kernel samples, well,

00:36:00.520 --> 00:36:03.100
I can't change the kernel unless
I work at Apple all of a sudden.

00:36:03.100 --> 00:36:07.480
So just forget those and I'll go and
worry about those at another time.

00:36:09.130 --> 00:36:11.560
There are also a couple unique features
that are only available through

00:36:11.560 --> 00:36:12.800
the Advanced Settings drawer here.

00:36:12.800 --> 00:36:15.220
One is you can flatten recursion.

00:36:15.220 --> 00:36:18.800
So if you have a really long list
of recursive functions that when

00:36:18.800 --> 00:36:20.970
you go to the profile browser
and you do that option click,

00:36:21.030 --> 00:36:22.680
they just zip down forever.

00:36:22.680 --> 00:36:26.000
Well, you can just simply click
on Flatten Recursion,

00:36:26.000 --> 00:36:28.010
and Shark will notice that, hey,
that's the same function

00:36:28.010 --> 00:36:30.130
being called over and over,
and it'll flatten that stack

00:36:30.270 --> 00:36:31.320
down to the first entry.

00:36:32.440 --> 00:36:35.690
Also, you can tell Shark to knock
out any lightweight symbols,

00:36:35.690 --> 00:36:39.440
and you can actually select the
number of samples that you want

00:36:39.500 --> 00:36:43.330
to allow as the cutoff point in
order to get rid of symbols where

00:36:43.330 --> 00:36:46.880
you only have a couple of samples,
so it's really not that important.

00:36:46.880 --> 00:36:48.900
It may even be
statistically insignificant.

00:36:51.370 --> 00:36:54.440
Okay, now going back to our demo.

00:36:54.530 --> 00:36:59.260
Okay, so we went in and based on
the information we saw before,

00:36:59.360 --> 00:37:01.440
we went, well, okay,
we've got to bite the bullet.

00:37:01.440 --> 00:37:06.010
We need to parallelize that decode.

00:37:06.170 --> 00:37:09.440
And so we went in and found the
picture slice loop in it and

00:37:09.440 --> 00:37:11.980
went in and parallelized on that.

00:37:12.430 --> 00:37:14.910
In order to do that,
we had to go and find all of the

00:37:14.910 --> 00:37:18.810
reading of the file and concentrate
that all at the beginning of the slice

00:37:18.810 --> 00:37:23.080
in order to prevent that serial code
from preventing parallel execution.

00:37:23.080 --> 00:37:27.980
That was a fair amount of work,
but ultimately, it did seem to work out.

00:37:28.020 --> 00:37:32.750
But we were really concerned that because
different slices of the picture will be

00:37:32.750 --> 00:37:37.840
of different portions of the picture,
and hence maybe showing different items,

00:37:37.840 --> 00:37:40.690
and so some things may require more
or less encoding depending on how

00:37:40.690 --> 00:37:42.270
complicated the picture is there.

00:37:42.380 --> 00:37:44.950
We were worried about load imbalance
between these different slices.

00:37:44.980 --> 00:37:47.360
So we actually made two
slightly different versions.

00:37:47.440 --> 00:37:52.950
The sequenced version takes the slices
of the pictures and assigns them to

00:37:52.950 --> 00:37:56.070
threads in our parallel loop in order.

00:37:56.080 --> 00:37:57.730
In the order that they
were in the original file,

00:37:57.730 --> 00:37:59.880
they get assigned to our threads, 1, 2,
3, 4.

00:37:59.880 --> 00:38:02.220
And this allows very
simple synchronization.

00:38:02.220 --> 00:38:06.660
It's kind of the best analogy as to
like relay runners at the Olympics.

00:38:06.660 --> 00:38:10.440
You know, they take the baton,
they read their portion of the file,

00:38:10.440 --> 00:38:12.230
and they pass the baton off to the next.

00:38:12.350 --> 00:38:15.350
And then they go off and do
their parallel decoding work.

00:38:15.360 --> 00:38:17.870
And the threads just keep
passing the baton as they

00:38:17.870 --> 00:38:19.460
need to do their file access.

00:38:21.250 --> 00:38:21.970
simple enough.

00:38:21.970 --> 00:38:24.040
We also wanted to look
at the unordered case.

00:38:24.170 --> 00:38:29.400
As soon as the thread finishes up with
reading its portion of the file it says,

00:38:29.400 --> 00:38:32.530
hey, whoever is free,
come in and go ahead and

00:38:32.530 --> 00:38:34.240
grab the next slice here.

00:38:34.240 --> 00:38:35.960
It's ready for you to go.

00:38:35.960 --> 00:38:39.300
And this should in theory tolerate
load imbalance better because if we

00:38:39.300 --> 00:38:42.810
have a slice which is really short,
that thread can zip through its

00:38:42.860 --> 00:38:46.840
short slice and then be free and
immediately go and grab a new thread.

00:38:46.840 --> 00:38:54.640
So we wondered which is better and also
a little bit about why once we saw that.

00:38:54.640 --> 00:38:57.800
So going back over here
to the demo machine.

00:39:01.040 --> 00:39:05.850
Here we have our application again,
and we went and did

00:39:05.870 --> 00:39:07.460
the all parallel case.

00:39:07.460 --> 00:39:08.600
And here's the unordered case.

00:39:08.600 --> 00:39:09.880
So we can see it play it.

00:39:10.110 --> 00:39:13.370
And now those seals are zipping
around considerably faster.

00:39:13.370 --> 00:39:16.650
They've gone from about 150
frames per second up to about

00:39:16.650 --> 00:39:18.840
300 by going with four threads.

00:39:18.840 --> 00:39:21.010
2x performance increase of four threads.

00:39:21.040 --> 00:39:25.390
That's actually not bad if you
look at a lot of parallel programs.

00:39:25.880 --> 00:39:32.990
But let's see if we can figure
out a little bit more about why.

00:39:32.990 --> 00:39:32.990
So let's use our hot key
again and start sampling.

00:39:33.300 --> 00:39:39.850
Do do do do do do,
it's on a new lap or two.

00:39:39.850 --> 00:39:39.850
And now what we're going to do is

00:39:40.370 --> 00:39:45.320
go through and we will be analyzing
to see why how the parallel decode

00:39:45.320 --> 00:39:47.930
loop was affecting our performance.

00:39:47.930 --> 00:39:52.150
So the browser here looks a lot like what
we just saw before with a lot of these,

00:39:52.290 --> 00:39:55.390
you know, kind of strange blocking
calls up at the top.

00:39:55.390 --> 00:39:58.150
And again,
we could go in and click on them and go,

00:39:58.150 --> 00:40:00.750
well, let's see,
that's a whole bunch of UI stuff.

00:40:00.750 --> 00:40:02.910
No, I don't really care about that.

00:40:02.920 --> 00:40:04.690
But let's do something about it.

00:40:04.690 --> 00:40:08.440
Let's use some data mining to
try to clear out this clutter.

00:40:08.440 --> 00:40:11.960
So the first thing I like to do is
get rid of the system libraries.

00:40:11.960 --> 00:40:15.870
You can charge them in some cases,
but I do actually care about, you know,

00:40:15.870 --> 00:40:18.220
when I'm in the various
locking and waiting calls,

00:40:18.220 --> 00:40:20.500
I do want to know that that's blocking,
not running.

00:40:20.530 --> 00:40:23.080
I'm just going to flatten
those libraries instead.

00:40:23.080 --> 00:40:25.780
And now you'll see that the
view changes a little bit here.

00:40:25.780 --> 00:40:28.800
The speech ball comes up as
Shark thinks a bit about what

00:40:28.800 --> 00:40:30.720
all these system libraries are.

00:40:30.720 --> 00:40:33.590
And now you can see that instead
of the name of library routine

00:40:33.590 --> 00:40:36.000
is deep inside the libraries,
we're instead seeing a lot of

00:40:36.000 --> 00:40:36.520
the data that we're getting
from the system libraries.

00:40:36.520 --> 00:40:36.520
And so we're going to go ahead
and do a little bit of a search.

00:40:36.520 --> 00:40:36.520
And we're going to go
ahead and do a search.

00:40:36.520 --> 00:40:36.620
And we're going to go ahead and
do a little bit of a search.

00:40:36.620 --> 00:40:36.640
And we're going to go ahead and
do a little bit of a search.

00:40:36.640 --> 00:40:36.740
And we're going to go ahead and
do a little bit of a search.

00:40:36.740 --> 00:40:36.740
And we're going to go ahead and
do a little bit of a search.

00:40:36.740 --> 00:40:36.740
And we're going to go ahead and
do a little bit of a search.

00:40:36.740 --> 00:40:36.760
And we're going to go ahead and
do a little bit of a search.

00:40:36.760 --> 00:40:36.760
And we're going to go ahead and
do a little bit of a search.

00:40:36.760 --> 00:40:36.780
And we're going to go ahead and
do a little bit of a search.

00:40:36.780 --> 00:40:36.860
And we're going to go ahead and
do a little bit of a search.

00:40:36.860 --> 00:40:36.860
And we're going to go ahead and
do a little bit of a search.

00:40:36.860 --> 00:40:36.920
And we're going to go
ahead and do a search.

00:40:36.920 --> 00:40:36.920
And we're going to go ahead and
do a little bit of a search.

00:40:36.920 --> 00:40:38.810
And we're going to go ahead and do
a names of routines which were the

00:40:38.810 --> 00:40:42.240
ones that we were actually calling,
pthread_con_wait,

00:40:42.240 --> 00:40:45.220
select pthread_con_timed_wait
and the like.

00:40:45.220 --> 00:40:47.030
We can now dig into these.

00:40:47.030 --> 00:40:52.660
And well, we're still seeing that -- hmm,
yeah, that's like UI stuff, okay.

00:40:52.670 --> 00:40:57.470
Well, I'm going to go and just simply
tell Shrk to remove that symbol.

00:40:57.540 --> 00:41:00.040
It's clearly stuff I don't care about.

00:41:00.040 --> 00:41:01.340
Pop this down.

00:41:01.340 --> 00:41:03.850
That's a bunch of UI stuff, too.

00:41:03.850 --> 00:41:04.460
Okay.

00:41:04.460 --> 00:41:09.200
And then if I hold down the
control key here or right click,

00:41:09.230 --> 00:41:12.770
we can go in and say remove that as well.

00:41:13.200 --> 00:41:37.300
[Transcript missing]

00:41:37.550 --> 00:41:41.310
and with this you can actually
see the sequence of operations

00:41:41.310 --> 00:41:44.500
and maybe take notes for later on.

00:41:45.200 --> 00:41:47.250
Okay,
there's also a restore button down here

00:41:47.250 --> 00:41:48.920
if you want to get rid of all those.

00:41:48.920 --> 00:41:51.090
Okay, well, we can continue the,
you know,

00:41:51.090 --> 00:41:52.700
removing symbols here for a while.

00:41:52.760 --> 00:41:55.350
But I happen to know, you know,
I'm really interested

00:41:55.350 --> 00:41:57.620
in that parallel decode,
and I really don't care

00:41:57.660 --> 00:41:58.650
about anything else.

00:41:58.760 --> 00:42:01.120
So I'd rather go in and
focus in on parallel decode.

00:42:01.180 --> 00:42:02.760
Well, first of all, to find it.

00:42:02.760 --> 00:42:05.640
Finding it is usually,
for a high-level function like this,

00:42:05.640 --> 00:42:07.840
is usually easier if
I switch to the tree view.

00:42:07.950 --> 00:42:10.030
So now I'm starting at
the top and working down.

00:42:10.120 --> 00:42:14.110
And indeed, if I go at thread start here,
parallel worker shell, parallel worker,

00:42:14.110 --> 00:42:18.180
aha, there's parallel decode
just a few levels down.

00:42:18.470 --> 00:42:26.070
So I'm going to go and right click on
this and do focus in on parallel decode.

00:42:26.520 --> 00:42:28.400
Okay,
so now everything above parallel decode,

00:42:28.400 --> 00:42:31.290
as I said,
is chopped off and thrown away.

00:42:31.290 --> 00:42:34.490
And we're just looking at it
from parallel decode on down.

00:42:34.960 --> 00:42:36.700
So let's see, I'm going to go in.

00:42:36.780 --> 00:42:40.440
This is to actually see
where we're spending time.

00:42:40.440 --> 00:42:42.400
I'm going to flip back to heavy view.

00:42:42.610 --> 00:42:44.560
And now we can see,

00:42:45.420 --> 00:42:49.120
that, well,
we're spending our -- wherever

00:42:49.120 --> 00:42:52.700
we're in parallel decoding,
we're spending about 27%

00:42:52.780 --> 00:42:57.090
of the time waiting here,
about 1% in locking, and most of the rest

00:42:57.210 --> 00:42:58.910
we're actually executing.

00:42:58.920 --> 00:43:01.010
And, frankly, this is not too bad.

00:43:01.060 --> 00:43:03.480
There's a little bit of
spin locks and so on.

00:43:03.570 --> 00:43:07.780
So we're getting something
like 30% of the time waiting.

00:43:07.780 --> 00:43:11.740
And it would be interesting
to compare that against what

00:43:11.740 --> 00:43:14.540
we can do in the ordered case.

00:43:14.540 --> 00:43:18.000
So I'll do Let's do a quick session here.

00:43:19.580 --> 00:43:21.260
That's pretty similar.

00:43:21.260 --> 00:43:22.460
Maybe not quite as fast.

00:43:22.540 --> 00:43:26.110
Maybe a few frames per second slower,
but it's in the same ballpark.

00:43:26.160 --> 00:43:29.990
So I'm going to start that.

00:43:33.710 --> 00:43:37.880
We'll get another session here,
which should look pretty much the same.

00:43:37.970 --> 00:43:42.800
And now also, I can see just what I've
been doing here before.

00:43:42.940 --> 00:43:45.560
So I'm going to apply the same
operations really quickly.

00:43:45.670 --> 00:43:47.260
So here I've got Flattened
System Libraries.

00:43:47.260 --> 00:43:49.320
It's already been checked for
me now that Shark has seen

00:43:49.320 --> 00:43:51.030
that that's what I like to do.

00:43:51.470 --> 00:43:55.310
And so I'm going to go in and
just flip over to Tree View and

00:43:55.380 --> 00:43:57.110
go to pop this guy open.

00:43:57.220 --> 00:43:58.940
There's Parallel Decode.

00:43:58.940 --> 00:44:01.660
I'll go in and focus on that.

00:44:01.950 --> 00:44:04.660
and flip back over again.

00:44:04.660 --> 00:44:08.850
And we can see here that, well, you know,
these are actually looking a lot alike.

00:44:08.900 --> 00:44:15.000
What we see with the sequence
case is we're getting just a few

00:44:15.000 --> 00:44:16.520
percent more time spent waiting.

00:44:16.520 --> 00:44:19.560
You know,
it's only a few frames per second,

00:44:19.560 --> 00:44:21.190
but it is noticeable.

00:44:21.190 --> 00:44:24.440
So that's kind of an interesting finding.

00:44:24.440 --> 00:44:26.860
And we were able to find that
and narrow it down and isolate

00:44:26.860 --> 00:44:28.870
it exactly for that loop,
just with a few quick

00:44:28.990 --> 00:44:30.350
data mining options here.

00:44:30.780 --> 00:44:34.190
Instead of having this buried in among
all sorts of data from all of our

00:44:34.190 --> 00:44:36.460
various loops and operations throughout.

00:44:36.460 --> 00:44:39.330
So what did we learn?

00:44:39.640 --> 00:44:43.330
Going back to slides,
what we've learned really

00:44:43.330 --> 00:44:47.780
is that with data mining,
instead of having to dig through

00:44:47.780 --> 00:44:51.720
all this information painfully,
routine by routine,

00:44:51.760 --> 00:44:54.250
we were able to go in and have
Shark isolate this parallel

00:44:54.250 --> 00:44:56.160
decode function really easily.

00:44:56.300 --> 00:45:01.800
So we could precisely examine just that
loop while excluding everything else.

00:45:02.280 --> 00:45:05.390
And also what we saw looking
at the application is unordered

00:45:05.390 --> 00:45:07.300
is a bit faster on four cores.

00:45:07.320 --> 00:45:09.160
Almost the same, just a bit faster.

00:45:09.290 --> 00:45:11.660
So, you know,
it kind of leads us to think, well,

00:45:11.660 --> 00:45:14.100
maybe load imbalance
is the bigger problem.

00:45:14.310 --> 00:45:17.200
But to actually figure out
exactly why that's the case,

00:45:17.200 --> 00:45:18.820
we're going to need a new tool.

00:45:18.820 --> 00:45:23.480
Because while time profile on all thread
states is great for going in and finding

00:45:23.480 --> 00:45:27.120
which blocking operations are important,
and it's great because you can go in and

00:45:27.120 --> 00:45:30.660
you can lower the sample rate and sample
over large portions of your application

00:45:30.660 --> 00:45:34.020
and get a real overview as to where your
application is working and synchronizing,

00:45:34.020 --> 00:45:37.220
it can't really give you enough
information to go in and debug

00:45:37.220 --> 00:45:40.800
individual locking and blocking
operations in your code.

00:45:41.390 --> 00:45:45.990
You often need to know how and why
the synchronization and serialization

00:45:46.040 --> 00:45:48.580
is occurring between your threads,
and so you need to see the time

00:45:48.580 --> 00:45:52.500
sequencing of how these threads are
passing off from one thread to another.

00:45:52.500 --> 00:45:56.140
And for that, we need another tool,
System Trace,

00:45:56.140 --> 00:45:59.260
which allows you to see the system and
threading interaction very precisely.

00:46:01.310 --> 00:46:04.560
So what a system trace is,
it's an exact trace of all the

00:46:04.560 --> 00:46:06.500
OS entry points in your program.

00:46:06.500 --> 00:46:09.260
And this includes all the blocking,
because whenever your threads block,

00:46:09.260 --> 00:46:10.700
they go into the kernel.

00:46:10.720 --> 00:46:13.430
So instead of with the time
profile view where we get these

00:46:13.430 --> 00:46:17.140
evenly spaced samples throughout,
system trace will instead record data

00:46:17.140 --> 00:46:19.100
whenever we go in and out of the kernel.

00:46:19.160 --> 00:46:21.300
So like this very first
entry point into the kernel,

00:46:21.300 --> 00:46:25.440
this small red square on the left,
we'll actually see that instead

00:46:25.440 --> 00:46:27.410
of having it fall between samples.

00:46:27.630 --> 00:46:30.440
This is a lot better than, say,
taking your time profile and cranking

00:46:30.440 --> 00:46:31.640
up the sample rate really high.

00:46:31.640 --> 00:46:34.750
We've encountered several
developers who've cranked the

00:46:34.750 --> 00:46:37.040
sample rate to 20 microseconds,
which,

00:46:37.120 --> 00:46:39.630
while you can see a lot of information,
it really blows through

00:46:39.640 --> 00:46:41.960
memory really fast,
and you can't actually

00:46:41.960 --> 00:46:43.490
take very long sessions.

00:46:43.500 --> 00:46:45.910
And it gives you a whole lot of data,
which is hard to dig through.

00:46:45.910 --> 00:46:49.720
System Price gives you this a lot more
efficiently and presents it a lot better.

00:46:50.560 --> 00:46:53.690
So you can go in and you can
examine these multi-threaded

00:46:53.690 --> 00:46:56.020
applications really in close behavior.

00:46:56.020 --> 00:46:59.240
So you can see all the lock
contention events that occur.

00:46:59.240 --> 00:47:01.700
Anytime a lock is contended,
it'll pop up.

00:47:01.780 --> 00:47:03.960
If a lock doesn't have contention,
it actually won't be

00:47:03.960 --> 00:47:05.800
visible on a system trace,
because in Mac OS X,

00:47:05.800 --> 00:47:08.300
you don't go into the kernel if
there's no contention for a lock,

00:47:08.300 --> 00:47:10.110
only if there's actually contention.

00:47:10.140 --> 00:47:12.450
But just with this,
we can go in and see how our

00:47:12.450 --> 00:47:15.660
semaphores are communicating
and how threads are waiting and

00:47:15.660 --> 00:47:17.980
releasing and blocking and blocking.

00:47:17.980 --> 00:47:20.260
And see the patterns of
how we're communicating.

00:47:20.560 --> 00:47:24.680
Back and forth from one thread to another
and running from one thread to another.

00:47:24.680 --> 00:47:27.520
You can also see some other things here,
too.

00:47:27.520 --> 00:47:30.550
How your thread is going in
and interacting with Mac OS X.

00:47:30.550 --> 00:47:34.390
System calls, page faults, and so on.

00:47:34.400 --> 00:47:38.660
And moreover, just like time profile or
time profile thread states,

00:47:38.660 --> 00:47:42.210
you don't have to use any
modifications to your source code

00:47:42.210 --> 00:47:44.140
in order to use system trace.

00:47:44.220 --> 00:47:46.620
You can just simply run it out
of the box and users can use it.

00:47:46.740 --> 00:47:50.220
But if you like,
you can actually go in and put tweaks.

00:47:50.560 --> 00:47:52.230
And you can use the tweaks in
your code to do things like

00:47:52.230 --> 00:47:54.660
starting and stopping shark with
the programmatic remote control.

00:47:54.660 --> 00:47:55.560
That still works.

00:47:57.870 --> 00:48:00.740
Okay, well,
once you've actually used System Trace,

00:48:00.810 --> 00:48:04.480
what will pop up is there are
several views that are possible.

00:48:04.600 --> 00:48:06.700
But in general,
for really detailed analysis,

00:48:06.750 --> 00:48:09.020
I usually prefer to use the
timeline view shown here,

00:48:09.030 --> 00:48:14.310
which shows the threads executing over
the course of time and allows you to

00:48:14.640 --> 00:48:20.000
actually go in and click on the various
events and examine them in detail.

00:48:20.350 --> 00:48:22.760
If you're interested in learning
more about the other displays,

00:48:22.780 --> 00:48:26.850
I recommend you come to our introductory
session on Thursday because the second

00:48:26.860 --> 00:48:30.000
half of that talk is going to go in
and give you a very detailed tour

00:48:30.000 --> 00:48:31.950
of all the aspects of System Trace.

00:48:32.060 --> 00:48:35.180
But given the limited time we have today,
I'm going to go in and focus

00:48:35.180 --> 00:48:36.740
in on just a few elements.

00:48:37.130 --> 00:48:41.080
So in particular,
the events are of most interest to me.

00:48:41.250 --> 00:48:44.150
So various system call events are
indicated by these little telephones,

00:48:44.150 --> 00:48:48.900
and we can see both non-blocking system
calls and blocking system calls when we

00:48:48.900 --> 00:48:51.540
bridge between two thread-run intervals.

00:48:51.540 --> 00:48:54.320
Most importantly for any
multi-threaded program,

00:48:54.320 --> 00:48:56.900
you're going to want to
probably note the locks,

00:48:56.900 --> 00:49:00.310
which show up as these little lock
icons and indicate that you're

00:49:00.310 --> 00:49:03.670
doing various multi-threaded
operations and you're actually

00:49:03.670 --> 00:49:06.090
locking and having lock contention.

00:49:07.640 --> 00:49:09.760
You can also see virtual memory events.

00:49:09.760 --> 00:49:10.920
Page faults appear here.

00:49:10.920 --> 00:49:13.380
Most significantly,
these are usually page in and out

00:49:13.380 --> 00:49:16.480
operations where you have to actually
go and wait for the disk to occur.

00:49:16.480 --> 00:49:18.890
But in modern
multi-threaded applications,

00:49:18.920 --> 00:49:21.340
a lot of these other faults can
actually come up in places where

00:49:21.390 --> 00:49:22.740
you might not think about them.

00:49:22.950 --> 00:49:26.880
Because oftentimes the OS communicates
between different threads by

00:49:26.880 --> 00:49:30.710
actually page faulting data and
moving entire pages from one

00:49:30.710 --> 00:49:33.240
thread's address space to another.

00:49:33.240 --> 00:49:35.760
So you can get actually sequences
of these faults when you're doing a

00:49:35.760 --> 00:49:37.340
lot of inter-process communication.

00:49:38.950 --> 00:49:41.720
Also,
Leopard has added a couple new faults,

00:49:41.720 --> 00:49:45.110
guard and failed,
which indicate when we're actually

00:49:45.110 --> 00:49:48.000
having problems in our program
and we're simply not fail,

00:49:48.000 --> 00:49:50.520
VM events are simply not
working for some reason,

00:49:50.520 --> 00:49:52.630
such as, say, a segmentation fault.

00:49:54.740 --> 00:49:57.570
You can also see things like interrupts,
any hardware interrupts that come

00:49:57.570 --> 00:50:00.560
in from things like IO operations,
complete DMAs,

00:50:00.560 --> 00:50:02.690
timer interrupts and the like.

00:50:02.750 --> 00:50:06.350
And if you like,
you can actually go in and add events to

00:50:06.380 --> 00:50:09.150
your code using what we call signposts.

00:50:09.290 --> 00:50:11.500
These come in two big varieties.

00:50:11.500 --> 00:50:15.580
First are the point signposts,
which just simply say, "Hey,

00:50:15.580 --> 00:50:17.100
here's where I am.

00:50:17.100 --> 00:50:20.960
Look here." So that way,
if you have any area in your code

00:50:21.040 --> 00:50:25.980
which doesn't normally do system calls,
you can actually have a record of

00:50:25.980 --> 00:50:26.570
that on the system trace showing,
"Here's where I am.

00:50:26.570 --> 00:50:26.570
Here's where I am.

00:50:26.570 --> 00:50:26.570
Here's where I am."

00:50:26.770 --> 00:50:29.290
Also,
if you want to measure sequences of time,

00:50:29.290 --> 00:50:32.200
you can use interval signposts, which,
just like the system calls,

00:50:32.240 --> 00:50:35.460
have a beginning and end
with a little underbar.

00:50:36.010 --> 00:50:38.300
With each signpost,
you can record up to four

00:50:38.300 --> 00:50:41.900
integer auxiliary values,
which can then be displayed in

00:50:41.910 --> 00:50:44.150
Shark when you click on the event.

00:50:44.320 --> 00:50:47.640
And you can pretty much put
these in anywhere you want,

00:50:47.640 --> 00:50:51.480
but keeping in mind that there
is some time penalty involved.

00:50:51.480 --> 00:50:54.720
If you put it in user code,
it's about 20 to 50

00:50:54.720 --> 00:50:56.890
microseconds or so per signpost.

00:50:56.890 --> 00:50:59.780
So you have to be a little
careful about these.

00:50:59.780 --> 00:51:02.590
In the kernel,
where you can put them in KEXT as

00:51:02.590 --> 00:51:06.940
well if you're a KEXT developer,
the overhead is pretty insignificant

00:51:06.940 --> 00:51:08.740
because you're already in the kernel,
but there is a little bit.

00:51:08.740 --> 00:51:08.740
So you can't just put
a bazillion of them in.

00:51:09.040 --> 00:51:10.260
How can we use this?

00:51:10.360 --> 00:51:12.780
Let's say we have a key loop in our
program that we're really interested

00:51:12.780 --> 00:51:15.210
in seeing on the system trace,
but we're not doing

00:51:15.210 --> 00:51:17.820
any system calls in it,
so normally no events appear.

00:51:17.820 --> 00:51:19.280
Well, let's add some.

00:51:19.320 --> 00:51:23.640
What you can do is let's put
in a couple of signposts here.

00:51:23.650 --> 00:51:25.770
So first off,
let's put in one which is simply

00:51:25.770 --> 00:51:27.160
a timer for the whole loop.

00:51:27.240 --> 00:51:30.820
So we can put in a beginning and an
interval signpost around the entire loop,

00:51:30.820 --> 00:51:33.530
and we can see how long that
loop takes very precisely.

00:51:34.780 --> 00:51:38.490
Also, then we can put point signposts in
at the beginning of each iteration,

00:51:38.530 --> 00:51:41.760
so we can at a glance tell where
each loop iteration is starting,

00:51:41.760 --> 00:51:44.610
and this will all appear on the timeline.

00:51:44.800 --> 00:52:15.400
[Transcript missing]

00:52:15.730 --> 00:52:18.450
and any auxiliary values
that we want to supply.

00:52:18.670 --> 00:52:21.230
Or just a zero if you don't want one.

00:52:21.460 --> 00:52:23.280
That's all there is to it.

00:52:23.280 --> 00:52:25.580
Of course, in some cases,
you may not necessarily want to

00:52:25.580 --> 00:52:26.840
link with the ChED framework.

00:52:26.840 --> 00:52:29.090
For example,
if it doesn't exist on your system

00:52:29.090 --> 00:52:32.880
intentionally for one reason or another,
well, you can do this without

00:52:32.970 --> 00:52:36.620
linking to the ChED framework
by using direct syscalls here.

00:52:36.630 --> 00:52:40.100
These are a little uglier looking,
but they do the exact same thing.

00:52:40.100 --> 00:52:43.280
No linking with the
ChED framework necessary.

00:52:43.870 --> 00:52:47.510
or if you're down in the KEXT, you can't,
in a KEXT of any kind,

00:52:47.530 --> 00:52:51.080
you can't actually link with
the CHED framework down there,

00:52:51.080 --> 00:52:54.860
so you just use the kernel debug
facility directly down there.

00:52:54.860 --> 00:52:58.770
It's almost exactly like doing
the sys calls up in user space.

00:52:59.130 --> 00:53:03.370
And I should point out that for this
session we have sample code associated,

00:53:03.370 --> 00:53:08.000
which has these exact samples from the
slides and also the two that Eric had.

00:53:08.000 --> 00:53:11.980
So you can go in and actually download
this and then use this as a starting

00:53:11.980 --> 00:53:15.610
point to go in and put in your own
code in case of the do work functions

00:53:15.780 --> 00:53:18.190
and start working with these directly.

00:53:19.420 --> 00:53:21.520
Of course, there is one more little
thing we need to do.

00:53:21.530 --> 00:53:24.560
We need to actually tell
Shark which signposts are important.

00:53:24.560 --> 00:53:28.320
So when Shark starts,
it automatically scans the

00:53:28.320 --> 00:53:31.990
Library Application Support Shark KDebug
Codes folder and looks for any

00:53:31.990 --> 00:53:36.150
text files in this particular format,
which consists of these hex numbers

00:53:36.150 --> 00:53:38.180
and the names of your signposts.

00:53:38.180 --> 00:53:40.180
And when it reads those in, it will go,
"Okay,

00:53:40.180 --> 00:53:44.040
these are the signposts that you're
interested in." And when you're sampling,

00:53:44.040 --> 00:53:46.480
if it gets any signposts
with those values,

00:53:46.480 --> 00:53:48.930
it will record them and then
present them on the screen by

00:53:48.940 --> 00:53:50.320
name when you click on them.

00:53:50.320 --> 00:53:52.160
If it gets any signposts
with different values,

00:53:52.160 --> 00:53:54.490
it will assume that you're not
interested in those particular

00:53:54.490 --> 00:53:55.980
signposts and will discard them.

00:53:55.980 --> 00:53:58.350
So this way,
you can actually filter which signposts

00:53:58.440 --> 00:54:02.020
are of interest if you have a lot of them
that you start adding to your program.

00:54:02.950 --> 00:54:06.460
Okay, to kind of show you how you can
actually use this for reality,

00:54:06.500 --> 00:54:10.940
let's go in and look at how we
did our MPEG-2 decode program and

00:54:10.940 --> 00:54:13.770
look at it on a microscopic level.

00:54:14.550 --> 00:54:17.210
Well, so we could see just from
what you saw in the demo,

00:54:17.210 --> 00:54:19.610
the unordered parallel decoding
is a little bit better,

00:54:19.610 --> 00:54:20.840
just a hair better.

00:54:20.840 --> 00:54:23.120
And this is probably
because of load imbalance.

00:54:23.120 --> 00:54:26.930
But, you know,
we want to verify that our intuition

00:54:26.930 --> 00:54:29.810
here is exactly what's really
happening on the real system.

00:54:29.820 --> 00:54:32.160
Because, of course,
as I'm sure all of you have determined,

00:54:32.160 --> 00:54:35.180
you know, everybody's intuition is
always exactly right when it

00:54:35.200 --> 00:54:36.140
comes to performance problems.

00:54:36.140 --> 00:54:42.900
So, well, let's go and use
System Trace to examine this.

00:54:43.500 --> 00:54:46.600
As it happens,
in our parallel decode program,

00:54:46.600 --> 00:54:50.880
we actually do make several system
calls in any parallel decoding segment.

00:54:50.880 --> 00:54:53.470
So we actually just went in and
looked around in the timeline

00:54:53.510 --> 00:54:56.560
until we found these segments where
when we clicked on the events,

00:54:56.560 --> 00:54:59.840
up in the call stacks,
parallel decode was in the call stack.

00:54:59.890 --> 00:55:03.090
And we could see where we were and, oh,
yes, this is actually a parallel decoding

00:55:03.090 --> 00:55:04.670
slice illustrated here on screen.

00:55:06.230 --> 00:55:09.400
Now, if we didn't have all those
conveniently placed system calls,

00:55:09.450 --> 00:55:12.600
well, this would have been a perfect spot
to go in and add signposts to say,

00:55:12.600 --> 00:55:14.580
hey, we're beginning a parallel
decode slice here,

00:55:14.580 --> 00:55:16.910
we're ending a parallel
decode slice here,

00:55:16.910 --> 00:55:17.810
and the like.

00:55:18.390 --> 00:55:22.210
And then once we can see this, well,
we can now look back at our code

00:55:22.500 --> 00:55:25.730
and figure out exactly what it
was doing here on the timeline.

00:55:25.810 --> 00:55:29.060
In particular,
the baton was being handed to us.

00:55:29.180 --> 00:55:32.460
We were told that, hey,
the file is ready for this slice to read.

00:55:32.520 --> 00:55:35.050
Then we did a little bit
of serial file access.

00:55:35.340 --> 00:55:38.180
Then we handed off the baton
to the next thread and said,

00:55:38.180 --> 00:55:39.400
okay, I'm done with the file.

00:55:39.530 --> 00:55:40.440
It's your turn.

00:55:40.550 --> 00:55:45.490
Well, we went on and did some parallel
decoding work for the slice.

00:55:46.020 --> 00:55:47.140
Pretty simple.

00:55:47.160 --> 00:55:50.080
Let's look and see how
that actually works.

00:55:50.080 --> 00:55:53.920
Well, what we can see here,
just from a quick view of this,

00:55:53.940 --> 00:55:57.910
and I went in and picked this out
and put it up on a slide because,

00:55:57.990 --> 00:56:00.870
unfortunately,
it does take a few minutes to

00:56:00.950 --> 00:56:04.510
go through and find just the
right spot in the timeline,

00:56:04.510 --> 00:56:08.280
and I figured you probably
didn't want to watch me move back

00:56:08.280 --> 00:56:09.670
and forth for several minutes.

00:56:09.670 --> 00:56:09.670
But feel free to come to the lab,
and I'll be happy to

00:56:09.670 --> 00:56:09.670
demonstrate in person.

00:56:10.010 --> 00:56:12.800
What we can see here is that, well,
you know,

00:56:12.800 --> 00:56:18.170
the sequence timeline actually looks
almost better because it's just

00:56:18.170 --> 00:56:22.240
smoothly passing from one thread
to the next as we do the serial

00:56:22.240 --> 00:56:24.680
region here highlighted in orange.

00:56:24.980 --> 00:56:27.520
The Unordered, on the other hand,
comes in and you have the

00:56:27.520 --> 00:56:30.200
threads popping up and say,
"Hey, I want to try to--" Oh, no,

00:56:30.200 --> 00:56:31.380
you got it first.

00:56:31.540 --> 00:56:32.970
Oops, oh well.

00:56:33.060 --> 00:56:36.090
So there's this fighting action,
which is making it look a little messier.

00:56:36.240 --> 00:56:38.840
Yet the sequence is going faster.

00:56:38.910 --> 00:56:41.350
Well, this is looking at one
spot on the timeline.

00:56:41.540 --> 00:56:45.260
If we scroll a little further,
you can actually see that the OS X is

00:56:45.290 --> 00:56:50.580
pulling a little operation on us and
that it's actually occasionally stealing

00:56:50.580 --> 00:56:53.180
a processor out to do other stuff.

00:56:53.630 --> 00:56:56.790
And so what can happen
here is that in this case,

00:56:56.910 --> 00:57:01.000
when we go and see where the
serial regions are occurring,

00:57:01.000 --> 00:57:05.010
well, now the unordered case looks a
lot better and a lot smoother

00:57:05.010 --> 00:57:06.480
than the sequence case.

00:57:06.600 --> 00:57:09.630
Because the sequence one has four
threads that are all fighting over three

00:57:09.630 --> 00:57:13.330
processors and continually knocking
one another off of the processors.

00:57:13.340 --> 00:57:16.250
While in the unordered case,
three threads are smoothly

00:57:16.370 --> 00:57:19.150
using the processors,
while the fourth thread just sits

00:57:19.190 --> 00:57:22.100
here running along and going,
"Oh, well, there's no space for me.

00:57:22.220 --> 00:57:25.690
Okay, I'll just simply, you know,
lay back and let you guys handle the

00:57:25.690 --> 00:57:29.460
work until I actually have some room to
get on a processor." And then that way,

00:57:29.460 --> 00:57:34.330
no threads have to be hopping
continuously from processor to processor.

00:57:34.670 --> 00:57:37.820
And with this, we're able to get a
small percentage better,

00:57:37.870 --> 00:57:40.060
because while the unordered
is messier in general,

00:57:40.160 --> 00:57:43.110
it can deal with this percentage
of time when OS X steals a

00:57:43.120 --> 00:57:45.470
processor out from under us better.

00:57:45.980 --> 00:57:47.410
Now, there's another thing,
if you were looking

00:57:47.500 --> 00:57:49.010
closely at this display,
that we could also tell from

00:57:49.090 --> 00:57:50.160
looking at the system trace.

00:57:50.160 --> 00:57:54.320
And that is, at the four-core level,
our parallelism is really

00:57:54.360 --> 00:57:55.760
limited by the serial code.

00:57:55.760 --> 00:57:58.900
This is why I reduced the number
of cores down to four before.

00:57:58.900 --> 00:58:03.670
Because what we're seeing here,
with four cores, these serial regions,

00:58:03.670 --> 00:58:05.480
if we bring them down and
I'll put them in line,

00:58:05.480 --> 00:58:07.940
actually form a continuous line across.

00:58:07.940 --> 00:58:09.330
This is now the critical path.

00:58:09.400 --> 00:58:11.360
And if we actually go
to more cores than this,

00:58:11.360 --> 00:58:14.020
we're simply, you know,
this is going to be the bottleneck and

00:58:14.090 --> 00:58:16.020
we're not going to get any more speed up.

00:58:16.100 --> 00:58:18.190
In fact,
it slows down as synchronization gets

00:58:18.190 --> 00:58:20.030
more fighting and battling going on.

00:58:22.490 --> 00:58:27.040
Now, to give you another example,
we were given a case where we found

00:58:27.040 --> 00:58:29.280
signal handling was a problem.

00:58:29.300 --> 00:58:32.280
So there was a video
conferencing application we

00:58:32.280 --> 00:58:36.230
were given a trace to look at,
and it was noted that the CPU utilization

00:58:36.230 --> 00:58:39.760
was much higher than expected,
which caused the power consumption

00:58:39.760 --> 00:58:40.800
to go through the roof.

00:58:40.880 --> 00:58:43.200
So, you know, what was happening here?

00:58:43.200 --> 00:58:46.710
Well, with our system trace here,
we could see that, well,

00:58:46.710 --> 00:58:48.880
not to be expected,
kind of to be expected.

00:58:48.880 --> 00:58:51.970
You had lots of threads running,
and they were running a lot.

00:58:52.420 --> 00:58:55.160
And this is kind of unusual for a
video application where you tend

00:58:55.160 --> 00:58:57.330
to have some decoding occurs,
and then you get to wait

00:58:57.330 --> 00:58:59.380
until the next frame,
and then some decoding occurs,

00:58:59.380 --> 00:59:00.890
and it waits for a little while,
and so on.

00:59:00.900 --> 00:59:03.160
So we went in and zoomed
in and looked at this.

00:59:03.160 --> 00:59:06.470
And what you can see is here
is we have almost entire lines,

00:59:06.480 --> 00:59:08.590
solid lines, of failed faults occurring.

00:59:08.600 --> 00:59:10.820
That surely wasn't
what we were expecting.

00:59:10.820 --> 00:59:13.800
And also, when you think about this,
these are coming in at hundreds

00:59:13.810 --> 00:59:15.070
of thousands per second.

00:59:15.080 --> 00:59:18.040
So in each one of these is
maybe a microsecond or so.

00:59:18.040 --> 00:59:20.460
You can do the math here,
and this is actually taking

00:59:20.530 --> 00:59:23.150
a pretty big chunk of time,
handling these failed faults

00:59:23.220 --> 00:59:24.310
and basically doing nothing.

00:59:24.320 --> 00:59:26.290
This kind of puzzled us a bit.

00:59:26.320 --> 00:59:28.180
So we went and switched
to the trace view,

00:59:28.180 --> 00:59:30.380
which gives a complete
listing of all these events.

00:59:30.380 --> 00:59:32.910
And it's normally not the first
place you want to go in and try

00:59:32.910 --> 00:59:34.350
to look at your system trace.

00:59:34.380 --> 00:59:36.470
But once you've kind of figured
out a sequence of interest,

00:59:36.510 --> 00:59:39.680
it lets you go in and actually
examine those sequences in

00:59:39.680 --> 00:59:41.810
detail and see all the layout.

00:59:41.820 --> 00:59:43.760
And what we can see
here in this big table,

00:59:43.760 --> 00:59:46.940
if we go and look at the address column,
well, all these faults are coming

00:59:46.940 --> 00:59:48.020
into the same address.

00:59:48.140 --> 00:59:50.320
One after another, boom, boom, boom,
boom, boom.

00:59:52.160 --> 00:59:55.490
And what we see is that the
address column is actually

00:59:55.490 --> 00:59:56.390
going to be the same address.

00:59:56.400 --> 00:59:58.880
So we can see that the address column
is going to be the same address.

00:59:58.880 --> 01:00:01.040
And what we see is that the address
column is going to be the same address.

01:00:01.040 --> 01:00:02.440
So we can see that the address column
is going to be the same address.

01:00:02.440 --> 01:00:06.370
And what we see is that the address
column is going to be the same address.

01:00:06.750 --> 01:00:10.080
So what we saw here is basically all this
power consumption is happening because

01:00:10.370 --> 01:00:12.140
something was almost always running.

01:00:12.140 --> 01:00:15.200
You know, there's nothing, you know,
there's no idle time as a result.

01:00:15.230 --> 01:00:17.390
And so the power chip,
processor chip could never

01:00:17.390 --> 01:00:18.700
power down and let us,
you know,

01:00:18.700 --> 01:00:21.180
let us cool down between frames.

01:00:21.190 --> 01:00:23.380
And it's caused by all
these failing page faults.

01:00:23.390 --> 01:00:26.330
And basically instead of
sleeping between frames,

01:00:26.330 --> 01:00:29.430
our threads were getting stuck
in this cycle of sitting on these

01:00:29.520 --> 01:00:32.370
failing page faults until another
thread or network event finally

01:00:32.370 --> 01:00:34.210
came in and knocked them out.

01:00:34.300 --> 01:00:36.900
And so effectively,
what should have been idle time was

01:00:36.980 --> 01:00:38.940
spinning here in the fault handler.

01:00:39.070 --> 01:00:42.540
And really, it wasn't necessarily the
fault of the guys who did this.

01:00:42.540 --> 01:00:44.860
What we think happened was
that a change was made in the

01:00:44.860 --> 01:00:47.180
OS between Tiger and Leopard,
and all of a sudden,

01:00:47.320 --> 01:00:50.490
their signal handler,
which was catching an occasional

01:00:50.500 --> 01:00:53.610
mistake happening now and then,
all of a sudden came to hide this big,

01:00:53.610 --> 01:00:56.480
huge problem, which they otherwise
wouldn't have noticed.

01:00:56.690 --> 01:00:59.420
But still,
the signal handling was causing them

01:00:59.470 --> 01:01:02.200
a lot of grief until we came along.

01:01:02.570 --> 01:01:06.780
and the QuickTime team came to
us and asked us to help them

01:01:06.780 --> 01:01:09.260
with their high definition video.

01:01:09.260 --> 01:01:14.340
So they found with 720p playback on
one of the early MacBook prototypes,

01:01:14.340 --> 01:01:17.160
they were dropping frames left and right.

01:01:17.160 --> 01:01:20.260
And given the processor speeds
and everything we were supporting,

01:01:20.280 --> 01:01:22.100
this didn't make any sense.

01:01:22.100 --> 01:01:26.120
And also the power consumption was going
through the roof and well even standard

01:01:26.120 --> 01:01:29.540
defection was pretty power hungry,
much more so than expected.

01:01:29.540 --> 01:01:32.880
So hey, the QuickTime guys had
been using time profiles,

01:01:32.880 --> 01:01:36.130
going in, banging their head,
optimizing their decoder like crazy.

01:01:36.200 --> 01:01:37.410
It wasn't helping.

01:01:37.410 --> 01:01:41.000
Well, we pulled out System Trace
and went in and looked at it.

01:01:41.000 --> 01:01:43.420
The problem jumped out
really fast in that,

01:01:43.510 --> 01:01:46.090
well, all their effort on the decoder,
well,

01:01:46.090 --> 01:01:48.160
it was actually -- they did a good job.

01:01:48.160 --> 01:01:51.230
It was decoding and getting
out of there right away.

01:01:51.230 --> 01:01:54.730
The problem was instead all the
rest of the time where we were

01:01:54.730 --> 01:01:57.850
trying to take that information
from the frame and move it up on

01:01:57.850 --> 01:02:00.340
screen so you could actually see it.

01:02:00.470 --> 01:02:02.880
And up in the standard definition case,
it was taking like half the

01:02:02.880 --> 01:02:05.940
screen time just to move this
video frame up to the screen.

01:02:05.940 --> 01:02:08.630
And with the high definition case,
it was actually dropping frames because

01:02:08.630 --> 01:02:12.980
it was taking longer than an entire frame
time just to move one frame up on screen.

01:02:13.150 --> 01:02:14.350
And this seemed a little weird.

01:02:14.430 --> 01:02:17.140
You'll notice how this is kind
of lightly colored on here,

01:02:17.250 --> 01:02:17.410
too.

01:02:17.410 --> 01:02:20.960
If you actually go in and
magnify it and zoom in on it,

01:02:20.960 --> 01:02:22.130
well, that's all that's happening.

01:02:22.170 --> 01:02:24.770
Little bit, little bit, little bit.

01:02:24.780 --> 01:02:28.190
And needless to say,
that's not very efficient.

01:02:28.740 --> 01:02:30.810
Well, so, you know, basically,
just with a couple of

01:02:30.810 --> 01:02:33.140
quick system traces,
we were able to figure out that

01:02:33.140 --> 01:02:34.610
decoding was not the problem.

01:02:34.610 --> 01:02:38.680
No, instead it actually turned out to be
a GPU driver problem with a new GPU.

01:02:38.680 --> 01:02:41.300
And instead, it was having problems.

01:02:41.310 --> 01:02:43.880
It was just simply allocating VRAM.

01:02:43.880 --> 01:02:46.280
And so not only was that process slow,
moreover,

01:02:46.280 --> 01:02:50.000
it was tying up the CPU in knots because
the CPU was busy pulling it and saying,

01:02:50.000 --> 01:02:50.830
are you done yet?

01:02:50.920 --> 01:02:51.820
Are you done yet?

01:02:51.820 --> 01:02:52.720
Are you done yet?

01:02:52.730 --> 01:02:53.980
The whole time.

01:02:53.980 --> 01:02:57.280
And those little gaps between
were so closely together,

01:02:57.280 --> 01:02:58.550
the CPU could never actually pull it out.

01:02:58.600 --> 01:03:00.610
So,
we just simply sat there spinning along,

01:03:00.610 --> 01:03:01.850
burning power like crazy.

01:03:01.850 --> 01:03:04.060
Well, you know,
once we pointed this out to them,

01:03:04.060 --> 01:03:06.380
that really helped them a
lot with their debugging.

01:03:06.400 --> 01:03:08.350
And moreover,
it didn't just help them their

01:03:08.350 --> 01:03:11.000
debugging just by knowing it as fact,
but also by knowing which

01:03:11.010 --> 01:03:12.970
thread to go and look at,
the thread that was

01:03:12.970 --> 01:03:14.200
actually moving the data.

01:03:14.200 --> 01:03:17.170
They could actually go back and
look at their original time profiles

01:03:17.180 --> 01:03:18.820
and time profile all thread states.

01:03:18.820 --> 01:03:21.950
And actually, instead of looking at the
decoder thread that they'd been

01:03:21.950 --> 01:03:24.170
spending all their time on,
they looked instead at

01:03:24.170 --> 01:03:26.770
those threads and went,
oh, hey, we can get a whole lot more

01:03:26.770 --> 01:03:28.530
information out of this.

01:03:28.610 --> 01:03:30.090
And so, we were able to get a lot more
information out of these profiles

01:03:30.270 --> 01:03:34.640
that we didn't actually know before.

01:03:34.640 --> 01:03:34.640
And it really helped them a lot.

01:03:34.890 --> 01:03:36.970
So with that,
I'm going to pass the baton over

01:03:37.010 --> 01:03:40.420
to our esteemed Rick Altherr,
who's going to talk to you about the

01:03:40.420 --> 01:03:42.860
future of CHUD and what to expect.

01:03:49.800 --> 01:03:52.310
Thank you, Lance.

01:03:52.380 --> 01:03:54.590
So before we talk about
where Chud is headed,

01:03:54.620 --> 01:03:57.790
let's take a brief look at where
Chud's history has come from,

01:03:57.800 --> 01:04:00.670
where this all originated.

01:04:00.750 --> 01:04:04.860
- Chud was originally created as
a collection of internal tools to

01:04:04.860 --> 01:04:09.050
aid in the initial bring up and
performance analysis of G3 systems.

01:04:09.120 --> 01:04:10.950
At the time,
a lot of performance improvements

01:04:11.050 --> 01:04:15.020
revolved around making these low-level,
machine-specific optimizations

01:04:15.860 --> 01:04:17.840
within the OS and its frameworks.

01:04:17.840 --> 01:04:21.440
And so we wrote a collection of tools
that basically collected low-level,

01:04:21.440 --> 01:04:24.390
machine-specific information
and aggregated it and showed

01:04:24.630 --> 01:04:25.720
it in a variety of ways.

01:04:25.850 --> 01:04:31.220
And this was really useful,
But over time, things have changed a bit.

01:04:32.380 --> 01:04:37.250
We gained a couple of new architectures,
most recently the Intel architecture.

01:04:37.250 --> 01:04:40.170
And Chud was enhanced for these
new architectures and then used

01:04:40.280 --> 01:04:44.470
extensively within Apple to ensure
that performance on these new

01:04:44.570 --> 01:04:46.290
platforms would be phenomenal.

01:04:46.420 --> 01:04:48.940
We also gained support for
both Tiger and Leopard,

01:04:48.970 --> 01:04:51.650
64-bit applications,
as well as a change to the

01:04:51.650 --> 01:04:53.220
Dwarf debugging format.

01:04:54.100 --> 01:04:57.020
Today, Chud's been extended
for the new platform,

01:04:57.020 --> 01:05:00.540
the iPhone, including the arm and
thumb architectures,

01:05:00.540 --> 01:05:05.000
as well as gained a lot of enhancement
for dealing with multi-core processors.

01:05:05.410 --> 01:05:08.740
Looking towards the future,
we're also going to be gaining a 64-bit

01:05:08.740 --> 01:05:11.880
kernel and a huge increase in the use
of multithreading within applications.

01:05:11.880 --> 01:05:15.810
So once again,
Shad will adapt and gain some

01:05:15.850 --> 01:05:19.280
support for providing performance
analysis of these new directions.

01:05:19.280 --> 01:05:20.790
But why stop where?

01:05:20.790 --> 01:05:21.940
We could do a little bit better.

01:05:23.860 --> 01:05:26.900
Today I'm introducing Chud 5,
codenamed Hawaii.

01:05:26.980 --> 01:05:30.550
Hawaii has been designed from the ground
up to support multiple architectures.

01:05:30.670 --> 01:05:34.330
This way, that same low-level,
machine-specific detail that

01:05:34.330 --> 01:05:38.290
we've had in Shark all along now
extends uniformly to all of the

01:05:38.290 --> 01:05:42.740
different architectures supported
by the OS X and iPhone platforms.

01:05:42.990 --> 01:05:45.600
Hawaii has also been written
exclusively for Snow Leopard.

01:05:45.660 --> 01:05:47.980
We're going to use many of
the same features that you

01:05:47.980 --> 01:05:50.880
as developers will be using,
like enhanced multi-core

01:05:50.880 --> 01:05:52.800
support in Snow Leopard.

01:05:52.850 --> 01:05:54.700
Hawaii also gains
support for coexistence.

01:05:54.710 --> 01:05:57.900
Now,
this was introduced with Xcode last year,

01:05:57.920 --> 01:06:00.200
and it basically lets you install
multiple versions of the tools

01:06:00.200 --> 01:06:02.600
on the same OS installation.

01:06:02.770 --> 01:06:08.130
Further, you can also relocate
Hawaii onto non-OS partitions,

01:06:08.140 --> 01:06:10.820
like external drives,
so you can use it between

01:06:10.820 --> 01:06:13.670
OS installations or even move the
external drive to a completely

01:06:13.670 --> 01:06:16.300
different system and use it over there.

01:06:16.800 --> 01:06:19.470
We're also going to consolidate
the functionality of Chud

01:06:19.490 --> 01:06:21.230
into two applications.

01:06:21.410 --> 01:06:23.520
We're going to use Shark for
all the profiling needs,

01:06:23.570 --> 01:06:27.600
and we're going to use Reggie for
doing the direct hardware access.

01:06:27.660 --> 01:06:31.930
Well, this is all great,
but we could still add a little bit more.

01:06:32.480 --> 01:06:34.930
We're also going to fundamentally
change how we collect the

01:06:34.930 --> 01:06:36.540
performance information.

01:06:36.640 --> 01:06:41.670
We're going to separate the "when to
record" from the "what to record."

01:06:41.890 --> 01:06:43.790
The when become known as triggers.

01:06:43.870 --> 01:06:45.780
These are events that
occur in the system,

01:06:45.780 --> 01:06:49.060
things like OS events, timers,
hardware events.

01:06:49.060 --> 01:06:51.340
And we're going to call
the what to record,

01:06:51.340 --> 01:06:53.070
we're going to call actions.

01:06:53.070 --> 01:06:55.790
And these are very specific
types of information.

01:06:55.790 --> 01:06:59.430
We want to collect specific things,
call stacks, event counts,

01:06:59.430 --> 01:07:01.040
what process was running.

01:07:01.040 --> 01:07:04.650
And what we want to let you do is hook
multiple actions to a single trigger.

01:07:04.760 --> 01:07:07.960
So every time an event comes in,
you'll collect multiple types of data.

01:07:07.960 --> 01:07:10.930
Okay, let's look at a few examples
of how this might work.

01:07:12.470 --> 01:07:14.970
L2 cache miss profile of everything.

01:07:14.970 --> 01:07:18.630
This exists in CHUD 4 today,
works reasonably well.

01:07:18.630 --> 01:07:21.290
Let's look at how we
would do this in Hawaii.

01:07:21.300 --> 01:07:25.190
We simply take a timer trigger
and attach and record L2

01:07:25.190 --> 01:07:27.430
cache miss count action to it.

01:07:27.490 --> 01:07:29.640
Really simple, really easy.

01:07:29.640 --> 01:07:32.860
Let's make it a little
bit more challenging.

01:07:32.860 --> 01:07:36.670
Let's look at a time profile of Safari,
just Safari.

01:07:37.660 --> 01:07:40.200
Well, again,
we take a timer and we take a call

01:07:40.200 --> 01:07:42.360
stack action and we link them up,
but we add this other

01:07:42.360 --> 01:07:43.100
piece in the middle.

01:07:43.100 --> 01:07:44.330
We add a conditional.

01:07:44.330 --> 01:07:48.600
We say, only record a sample if Safari is
actually running on the processor

01:07:48.600 --> 01:07:50.400
when the timer event occurs.

01:07:52.100 --> 01:07:55.760
Okay, we can do this in CHUD 4 already,
so let's take it one step further.

01:07:55.760 --> 01:07:59.560
What if you wanted to take a
system trace of just the main

01:07:59.560 --> 01:08:00.860
thread in your application?

01:08:00.860 --> 01:08:05.020
Again,
we simply take a system call trigger,

01:08:05.020 --> 01:08:06.680
add two conditionals to it.

01:08:06.860 --> 01:08:07.560
Is it my app?

01:08:07.560 --> 01:08:09.490
Is it the main thread in my app?

01:08:09.520 --> 01:08:13.550
And if so, and only if so,
do we actually record the call stack?

01:08:13.610 --> 01:08:16.560
This is a bit different from
how we do things in CHUD 4.

01:08:16.560 --> 01:08:19.870
Now, instead of recording everything
and filling up your sample

01:08:19.910 --> 01:08:22.330
buffer very quickly and then
filtering it out at the end,

01:08:22.330 --> 01:08:23.940
we're just not going to
record it in the first place.

01:08:23.940 --> 01:08:26.980
So you'll get even lower overhead
when doing things like system trace.

01:08:28.960 --> 01:08:33.860
Of course, this is all great,
but let's go one step further.

01:08:33.920 --> 01:08:35.430
How about we do all three
of them at the same time?

01:08:35.430 --> 01:08:40.890
Yes, we can finally do time profile
and system trace at the same time

01:08:40.890 --> 01:08:41.970
and display the results together.

01:08:47.960 --> 01:08:50.240
Now, Hawaii is still currently
under development,

01:08:50.280 --> 01:08:52.300
so expect more to come out of this.

01:08:52.340 --> 01:08:54.810
But I wanted to give you
a brief introduction.

01:08:55.230 --> 01:08:59.420
So let's do a quick summary
of what we've learned today.

01:08:59.500 --> 01:09:03.780
We talked mainly about a variety of ways
to actually trigger recording in Shark.

01:09:03.810 --> 01:09:06.060
This way you can look more
specifically at what you're

01:09:06.070 --> 01:09:11.220
interested in and also have more
accurate control over when you record.

01:09:11.240 --> 01:09:15.910
We also talked about how you can use
Shark to look at multi-threaded programs

01:09:15.920 --> 01:09:19.540
using time-profile thread states and
system trace to get both an overview

01:09:19.820 --> 01:09:23.610
and a very detailed look at what's
actually happening on the system.

01:09:23.790 --> 01:09:25.560
and we introduced Hawaii.

01:09:25.590 --> 01:09:29.050
Please look forward to many
improvements in performance

01:09:29.070 --> 01:09:30.780
analysis on the OS X platform.

01:09:30.830 --> 01:09:32.400
And with that,

01:09:32.990 --> 01:09:34.790
Please feel free to
contact Michael Jurowicz,

01:09:34.910 --> 01:09:37.100
our evangelist, with any questions.

01:09:37.100 --> 01:09:39.400
His email address is jurowicz@apple.com.

01:09:39.450 --> 01:09:41.440
You can also send us feedback directly.

01:09:41.460 --> 01:09:44.580
It's at
perftools-feedback@group.apple.com.

01:09:44.650 --> 01:09:48.000
We like both good and bad feedback.

01:09:51.270 --> 01:09:55.740
We'd also like to invite you to,
ask you to invite your coworkers,

01:09:55.740 --> 01:09:57.700
people that might not
be familiar with Shark,

01:09:57.700 --> 01:10:01.820
to our introductory session
on Thursday at 5:00.

01:10:02.050 --> 01:10:03.500
We'll also be in a variety of labs.

01:10:03.650 --> 01:10:06.510
We'll be in the OS X and
iPhone Performance Labs.

01:10:06.660 --> 01:10:10.890
We'll also be kind of mulling around
in the open hours in the various labs.