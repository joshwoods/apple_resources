WEBVTT

00:00:21.220 --> 00:00:25.520
So what we're going to do is sort of take
a look at sort of a 60,000-foot level,

00:00:25.520 --> 00:00:29.700
and we're going to look at, you know,
what Mac OS X's graphics sort of feel.

00:00:29.720 --> 00:00:32.470
It's a sort of a very immersive
environment where you can have,

00:00:32.470 --> 00:00:34.300
you know, different windows,
different levels,

00:00:34.310 --> 00:00:38.060
all integrated together with a dock
in your picture that you see there.

00:00:38.060 --> 00:00:41.640
You know, you have video, you have 3D,
you have normal 2D content.

00:00:42.740 --> 00:00:45.460
Over time,
different features have been available,

00:00:45.520 --> 00:00:49.300
or we've made different features
available based on primarily some of the

00:00:49.350 --> 00:00:51.600
architectural decisions that we made.

00:00:51.620 --> 00:00:53.280
So it doesn't really matter
whether it's a window.

00:00:53.280 --> 00:00:55.400
It doesn't matter
whether it's video or 3D.

00:00:55.400 --> 00:00:57.990
It just seamlessly sort of
integrates and flows together,

00:00:57.990 --> 00:01:00.060
and Expose was basically
an example of that.

00:01:00.100 --> 00:01:04.700
The other feature that sort of evolved
over time was sort of dashboard,

00:01:04.700 --> 00:01:07.790
where we have more rich content coming
in and overlaid and dimmed in the

00:01:07.790 --> 00:01:11.940
background and really sort of very rich
sort of graphic environment from the,

00:01:11.950 --> 00:01:12.720
you know, from the top of the screen.

00:01:12.720 --> 00:01:14.950
From the user's perspective,
when they look at their desktop.

00:01:14.960 --> 00:01:17.610
Another feature that was
recently added was Spaces.

00:01:17.620 --> 00:01:19.560
It's more of a usability, right?

00:01:19.560 --> 00:01:22.830
So Windows, the same thing,
just moving them around, and, you know,

00:01:22.920 --> 00:01:25.660
we can get all these
different features for you.

00:01:25.710 --> 00:01:30.090
So let's take a look at what
architecturally actually happens.

00:01:30.120 --> 00:01:32.840
So we have these buffers, right?

00:01:32.840 --> 00:01:35.290
You have an application that's
either a 2D application or a 3D

00:01:35.320 --> 00:01:36.900
application or a video application.

00:01:36.900 --> 00:01:39.840
It deposits its data
into its backing buffers,

00:01:39.840 --> 00:01:42.860
and then the core, its compositor,
basically blends them all together and

00:01:43.000 --> 00:01:47.330
puts the frame inside the frame buffer,
and the display sort of syncs out at VBL.

00:01:47.340 --> 00:01:50.820
And that's kind of how
all the information flows.

00:01:50.930 --> 00:01:56.560
So obviously with the advent of GPU,
we definitely have video on the GPU.

00:01:56.560 --> 00:01:58.100
We have 3D on the GPU.

00:01:58.100 --> 00:02:02.450
And the rest of the stuff
back in maybe Mac OS 10.1,

00:02:02.450 --> 00:02:04.990
2 was done totally in software.

00:02:05.000 --> 00:02:09.160
So then came Quartz Extreme,
where Quartz Extreme basically said,

00:02:09.230 --> 00:02:10.880
take the compositor
and put it on the GPU.

00:02:10.880 --> 00:02:14.120
So everything now in terms of
video content coming through,

00:02:14.120 --> 00:02:17.270
as well as your backing buffers,
they get uploaded onto the video card,

00:02:17.280 --> 00:02:20.540
composited together with
a Quartz compositor,

00:02:20.860 --> 00:02:23.060
and display to the screen.

00:02:23.180 --> 00:02:24.970
So that's cool.

00:02:25.370 --> 00:02:28.010
But as time went on,
a lot of these graphics architectures

00:02:28.010 --> 00:02:31.550
and hardware acceleration started
to show up in different frameworks,

00:02:31.550 --> 00:02:35.790
whether it be Core Animation that you've
heard about or whether it's Core Image.

00:02:35.800 --> 00:02:38.810
So a lot of these different
architectures for your 2D drawing,

00:02:38.820 --> 00:02:41.890
whether it be image
processing or just animation,

00:02:41.890 --> 00:02:45.030
they're all done on the GPU also.

00:02:45.170 --> 00:02:47.160
Over time, we talk about multi-core.

00:02:47.180 --> 00:02:51.300
All of these frameworks effectively use
multi-core in one form or the other,

00:02:51.350 --> 00:02:55.290
whether it's via GCD or whether it's
basically creating separate threads to

00:02:55.290 --> 00:02:59.240
supply video on one thread decompression
and sending it out the frames.

00:02:59.280 --> 00:03:01.850
You know,
multi-threaded GL is also another example

00:03:01.850 --> 00:03:03.800
of taking advantage of multi-core.

00:03:04.590 --> 00:03:07.440
So basically over time,
we've got this sort of synergistic

00:03:07.720 --> 00:03:14.440
conclusion where we have these resources,
whether they're CPU,

00:03:14.440 --> 00:03:16.200
whether they're multi-core,
whether they're GPU,

00:03:16.200 --> 00:03:21.440
and we sort of at the framework levels,
you know, whether it's video or 3D or

00:03:21.440 --> 00:03:24.980
2D or animation or whatever,
we get to take advantage of all these

00:03:24.980 --> 00:03:28.740
resources to bring this sort of,
you know, rich user experience to one,

00:03:28.880 --> 00:03:30.640
your apps, and two, to users.

00:03:30.680 --> 00:03:33.340
So while we went off and
did all of this stuff,

00:03:33.340 --> 00:03:34.520
along the way, we got to take advantage
of all of these resources.

00:03:34.520 --> 00:03:35.000
So while we went off and
did all of this stuff,

00:03:35.020 --> 00:03:36.960
along the way, we decided that, hey,
you know, all of these different

00:03:36.960 --> 00:03:39.710
features are really cool,
and we would like to somehow

00:03:39.940 --> 00:03:43.620
expose them to applications,
developers, so you can take advantage of

00:03:43.620 --> 00:03:45.750
these features that we develop
with inside of the windowing

00:03:45.750 --> 00:03:48.020
system and the graphics system,
and you can simply put

00:03:48.020 --> 00:03:49.090
it inside of your app.

00:03:49.140 --> 00:03:52.960
So a lot of what you're learning about
in this year or even in last year

00:03:52.960 --> 00:03:57.090
was about this process of moving all
these rich technologies forward for

00:03:57.090 --> 00:03:59.440
you to take advantage of directly.

00:04:00.990 --> 00:04:03.650
So we're going to talk a little
bit from a different perspective.

00:04:03.680 --> 00:04:05.380
Now you know how stuff
gets to the screen.

00:04:05.620 --> 00:04:08.860
What we're going to talk about is
how stuff actually gets rendered

00:04:09.000 --> 00:04:13.020
within your application and what
the stacking and the levels are.

00:04:13.130 --> 00:04:16.250
So obviously at the bottom,
there's the CPU and the GPU.

00:04:16.310 --> 00:04:18.240
And then further up from that,
there's the Quartz

00:04:18.240 --> 00:04:19.860
family of technologies.

00:04:19.900 --> 00:04:23.000
Those are sort of the low-level
graphics technologies.

00:04:23.060 --> 00:04:25.790
Above that is the application kit, Cocoa.

00:04:25.860 --> 00:04:29.610
It's how you form your applications,
how you create your user interfaces,

00:04:29.630 --> 00:04:31.620
how you fetch files,
how you do preferences,

00:04:31.750 --> 00:04:35.260
how you interact with the system
as an application as a whole.

00:04:35.830 --> 00:04:38.990
So going back to the bottom,
we obviously have

00:04:38.990 --> 00:04:41.370
OpenGL at the lowest level,
and we have OpenCL,

00:04:41.370 --> 00:04:44.180
which we just introduced
first in the leper.

00:04:44.310 --> 00:04:47.580
Further up in the graphics stack,
we have Core Graphics, Core Image,

00:04:47.580 --> 00:04:48.620
and Core Video.

00:04:48.680 --> 00:04:49.910
Names speak for themselves.

00:04:49.940 --> 00:04:52.980
One for graphics, one for images,
and one for video.

00:04:53.110 --> 00:04:55.760
Further up from that is Core Animation.

00:04:55.760 --> 00:04:56.880
Speaks for itself.

00:04:57.050 --> 00:04:58.240
Animation Engine.

00:04:58.410 --> 00:05:00.100
And then Quartz Composer.

00:05:00.110 --> 00:05:01.500
Slightly different kind of beast.

00:05:01.550 --> 00:05:04.240
It is really something that takes
advantage of basically all the

00:05:04.260 --> 00:05:08.590
technologies and allows you to do
some visually rich programming.

00:05:08.820 --> 00:05:10.630
Further up the stack, the App Kit.

00:05:10.870 --> 00:05:14.010
This is the infrastructure, basically,
of an application.

00:05:14.160 --> 00:05:16.360
And on top of that,
there's a bunch of other graphic

00:05:16.470 --> 00:05:22.340
type kits that we have that allow
you to do various different things

00:05:22.350 --> 00:05:24.580
to handle different types of media.

00:05:24.690 --> 00:05:27.650
So let's sort of peel away the
onion and take a look at the top.

00:05:27.820 --> 00:05:29.670
What we're really looking for
is the juicy part in the middle,

00:05:29.670 --> 00:05:31.440
but we'll start from the top.

00:05:31.530 --> 00:05:36.120
So here we are at the application level,
and we have Image Kit.

00:05:36.160 --> 00:05:42.480
Image Kit is a really great application
framework for managing lots of images,

00:05:42.560 --> 00:05:46.360
managing different types of images,
managing browsing, managing editing.

00:05:46.400 --> 00:05:50.770
All these simple features we use inside
of our applications to do image browsing.

00:05:50.930 --> 00:05:54.190
So it doesn't really matter whether
or not you're simply trying to

00:05:54.310 --> 00:05:57.030
do an edit of a single image,
or whether or not you're dealing

00:05:57.060 --> 00:06:00.180
with hundreds of images or
browsing hundreds of files.

00:06:00.200 --> 00:06:03.780
Image Kit is definitely the kit you want
to use to do sort of image handling,

00:06:03.810 --> 00:06:05.810
rather than going off and
writing all this code and doing

00:06:05.810 --> 00:06:06.120
caching and doing all this stuff.

00:06:06.120 --> 00:06:07.360
So you can do a lot of
different things with this.

00:06:07.360 --> 00:06:09.000
You can do color matching
and color matching,

00:06:09.050 --> 00:06:11.160
and just use Image Kit.

00:06:11.440 --> 00:06:12.400
PDFKit.

00:06:12.410 --> 00:06:14.880
PDFKit is also pretty complicated, right?

00:06:14.910 --> 00:06:18.320
In terms of, I shouldn't say PDFKit,
but PDFs are also pretty complicated.

00:06:18.350 --> 00:06:21.470
There are annotations, there's viewing,
browsing, scrolling, all these different

00:06:21.560 --> 00:06:22.380
things are all handled.

00:06:22.380 --> 00:06:24.870
You just simply take your PDF view,
stick it in your application,

00:06:24.870 --> 00:06:27.380
and away you go,
you have full PDF support.

00:06:29.390 --> 00:06:31.740
WebKit, HTML is complicated.

00:06:31.910 --> 00:06:33.440
You don't want to have to deal with that.

00:06:33.610 --> 00:06:37.580
Safari uses it,
WebMail uses it for their HTML content.

00:06:37.760 --> 00:06:40.820
You can simply just create these,
use WebKit to sort of

00:06:40.840 --> 00:06:45.020
deal with all these,
the web content,

00:06:45.170 --> 00:06:47.420
as well as it takes advantages
of advances that we make,

00:06:47.420 --> 00:06:49.430
whether it's the more
complicated cascading style

00:06:49.430 --> 00:06:52.120
sheet with all the animations,
you just get this all for

00:06:52.120 --> 00:06:53.740
free by using this kit.

00:06:54.290 --> 00:06:55.720
Then there's QtKit.

00:06:55.750 --> 00:06:58.620
If you went to the State of Union and
saw the latter part of it that

00:06:58.620 --> 00:07:02.100
had to do with media handling,
we've been encouraging developers to move

00:07:02.100 --> 00:07:07.680
to PDFKit because it's primarily geared,
it's cross-platform, it's the way to deal

00:07:07.680 --> 00:07:09.620
with mid-video playback.

00:07:09.630 --> 00:07:14.080
And 99% of the time,
that's what you're actually doing.

00:07:14.200 --> 00:07:17.250
So instead of going and mucking
around with all the low-level

00:07:17.250 --> 00:07:21.230
frameworks to do video handling,
simply use QtKit and you'll

00:07:21.280 --> 00:07:23.310
get exactly what you wanted.

00:07:23.900 --> 00:10:54.800
[Transcript missing]

00:10:55.310 --> 00:10:57.960
So that's sort of the
hardware abstraction layer.

00:10:58.030 --> 00:11:00.920
So now we're gonna sort of focus
a little bit more on the middle,

00:11:01.010 --> 00:11:01.860
the juicy part.

00:11:01.960 --> 00:11:06.810
So now, let's talk a little bit
about the fundamental guy,

00:11:06.840 --> 00:11:07.690
the core graphics guy.

00:11:07.870 --> 00:11:09.720
How do you do 2D?

00:11:10.760 --> 00:11:12.160
Basically, what's Core Graphics?

00:11:12.230 --> 00:11:15.170
Core Graphics is a 2D rendering engine.

00:11:15.530 --> 00:11:18.710
It has a rich set of primitives
for both shape processing

00:11:19.020 --> 00:11:21.370
as well as image process,
sorry,

00:11:21.490 --> 00:11:25.380
shape processing in the forms of lines,
rectangles, path, text, masks.

00:11:25.540 --> 00:11:28.220
You can simply set those up,
fill some color through it,

00:11:28.260 --> 00:11:30.580
as well as there's a rich set
of sort of colorized primitives,

00:11:30.590 --> 00:11:33.990
which is images, patterns, gradients,
and shadings.

00:11:34.430 --> 00:11:36.050
It's device independent.

00:11:36.130 --> 00:11:39.430
It doesn't matter whether or not you're
drawing to a window or a printer,

00:11:39.520 --> 00:11:42.300
we will take your content,
and we will faithfully reproduce it

00:11:42.300 --> 00:11:46.970
on the device that you've targeted,
bitmaps, PDF, all the same thing.

00:11:47.560 --> 00:11:50.140
In addition to it being device dependent,
it's also,

00:11:50.140 --> 00:11:53.000
when we say device independent,
we go into a little bit more

00:11:53.000 --> 00:11:56.120
detail of talking about resolution,
depth, and color.

00:11:56.120 --> 00:11:59.460
So if you're talking about
your content going to a PDF,

00:11:59.460 --> 00:12:03.400
sorry, a printer,
whether it's raster-based or ProScript,

00:12:03.400 --> 00:12:08.200
whether it's 100 DPI or 16,000 DPI,
your content would be faithfully

00:12:08.330 --> 00:12:09.760
represented on that device.

00:12:09.760 --> 00:12:14.120
Windows, they have a smaller DPI,
ranging from 72 to maybe 150.

00:12:14.820 --> 00:12:15.660
Bitmaps, any.

00:12:15.660 --> 00:12:19.790
You just set it up, and you can draw it,
and it will just record that data

00:12:19.790 --> 00:12:21.220
and fill the data appropriately.

00:12:23.010 --> 00:12:24.900
We're also depth independent.

00:12:24.930 --> 00:12:28.130
Doesn't matter whether or not the
destination is 8 bits or 16 bits

00:12:28.140 --> 00:12:31.030
or 32 bit flow per component.

00:12:31.110 --> 00:12:32.440
As well as we're color independent.

00:12:32.550 --> 00:12:34.740
You could be drawing
onto gray destination,

00:12:34.790 --> 00:12:36.370
RGB destination, CMYK.

00:12:36.630 --> 00:12:39.620
We'll do all the correct color
management to reproduce on the device

00:12:39.660 --> 00:12:43.180
that you're talking about or talking to.

00:12:44.620 --> 00:12:48.500
Features associated with Quartz
is definitely anti-aliasing.

00:12:48.530 --> 00:12:52.390
A lot of people like it,
and transparency support.

00:12:52.510 --> 00:12:56.030
Transparency support on any device,
whether it be a printer or not.

00:12:56.270 --> 00:13:03.670
Transparency on a printer may
not have been supported maybe,

00:13:03.670 --> 00:13:04.460
I don't know, five, ten years ago,
but it's supported with

00:13:04.460 --> 00:13:04.460
Quartz or Core Graphics.

00:13:05.490 --> 00:13:11.480
Also, when it comes to UI drawing and
a lot of graphic rich content,

00:13:11.480 --> 00:13:13.530
images are really the king.

00:13:13.550 --> 00:13:16.030
A lot of stuff is
actually done with images.

00:13:16.090 --> 00:13:18.410
And there are a lot of
image formats out there.

00:13:18.410 --> 00:13:24.680
And what we provide is the ability to
read and write to many different formats.

00:13:24.780 --> 00:13:27.390
Now, these different formats
have different features.

00:13:27.450 --> 00:13:30.160
It might be that they're deeper
in depth in terms of the ability

00:13:30.160 --> 00:13:31.780
to represent different things.

00:13:31.780 --> 00:13:34.020
They might have transparency.

00:13:34.460 --> 00:13:36.780
And we might have thumbnails.

00:13:36.780 --> 00:13:39.970
And we might have metadata
associated with the image.

00:13:39.980 --> 00:13:43.820
All of these sort of features are
part and parcel of doing proper image

00:13:43.830 --> 00:13:46.050
handling regardless of the format.

00:13:46.050 --> 00:13:48.720
So we have support for metadata,
thumbnails,

00:13:48.730 --> 00:13:52.760
and with incremental loading where
people can read data incrementally

00:13:52.760 --> 00:13:54.750
and supply it to their devices.

00:13:54.800 --> 00:13:59.250
So for instance, when you're on the web,
Safari uses Image.io to do this

00:13:59.430 --> 00:14:03.270
incremental loading as the data
comes in off of the network and we

00:14:03.290 --> 00:14:07.710
can decompress the data on the fly,
streaming down, and load it.

00:14:07.720 --> 00:14:12.550
So we provide lots of great features
with Image.io and handling of many

00:14:12.550 --> 00:14:14.960
different image formats for you.

00:14:16.800 --> 00:14:18.200
It's platform independent.

00:14:18.230 --> 00:14:20.750
It doesn't really matter whether
it's Mac OS X or whether it's

00:14:20.750 --> 00:14:23.730
the phone or Safari and Windows.

00:14:24.230 --> 00:14:28.300
And of course, it leverages the GPU and
CPU capabilities,

00:14:28.330 --> 00:14:34.010
whether it's multicore or vectorized
instructions for SIMD or the GPU itself.

00:14:34.670 --> 00:14:37.510
So not only can you do sort
of rich user interfaces,

00:14:37.510 --> 00:14:42.640
whether it be mail or some other video
app or just the graphics applications,

00:14:42.660 --> 00:14:45.550
you can do business graphics, right?

00:14:45.900 --> 00:14:50.420
All pretty good quality,
and they're faithfully represented

00:14:50.420 --> 00:14:54.030
on different types of devices,
print or display.

00:14:54.140 --> 00:14:57.640
Not only can you do that,
you can do more comprehensive

00:14:57.640 --> 00:15:02.660
sort of richer environments for
pre-press types in situations,

00:15:02.660 --> 00:15:04.100
doing the magazine.

00:15:04.190 --> 00:15:05.830
It's all device independent.

00:15:05.860 --> 00:15:08.280
Doesn't matter whether your
printer is huge DPI or whether

00:15:08.280 --> 00:15:10.470
you're just running to display,
you get a faithful

00:15:10.470 --> 00:15:12.170
reproduction on that device.

00:15:14.030 --> 00:15:17.050
Applications that use it, Pages,
that's a good one,

00:15:17.050 --> 00:15:18.200
that's sort of pre-priced.

00:15:18.200 --> 00:15:25.560
Keynote, this presentation was done using
Core Graphics to do the representation.

00:15:25.620 --> 00:15:29.350
And Safari, so you know it's fast,
it has to go fast too.

00:15:29.770 --> 00:15:32.280
Okay, so let's,
so that was Core Graphics.

00:15:32.380 --> 00:15:33.800
Hopefully you have a
sort of understanding.

00:15:33.800 --> 00:15:36.260
At this point, I'm really telling you
about what's on the menu.

00:15:36.260 --> 00:15:39.240
We start to talk about
pairing things later.

00:15:39.980 --> 00:15:40.790
Core Image.

00:15:40.790 --> 00:15:45.410
Core Image, basically it's an image
processing engine,

00:15:45.410 --> 00:15:46.260
right?

00:15:46.260 --> 00:15:49.110
You have your input data,
you send it through some filter,

00:15:49.150 --> 00:15:50.780
and it comes out the other side.

00:15:50.810 --> 00:15:52.820
It doesn't necessarily
have to be image data.

00:15:52.820 --> 00:15:54.790
It could be a gradient field.

00:15:54.790 --> 00:15:58.730
It could be just some arbitrary
data that you can have.

00:15:58.730 --> 00:16:00.960
And you can run it through
different filters of your

00:16:00.960 --> 00:16:03.820
design to produce your output,
physics simulations, et cetera,

00:16:03.820 --> 00:16:04.480
et cetera.

00:16:04.480 --> 00:16:09.960
So what we do is we basically say
we can chain the filters together.

00:16:09.980 --> 00:16:13.010
You have a kernel operation that
is supposed to manipulate something

00:16:13.010 --> 00:16:16.380
from one thing to the next,
and you can then do another operation

00:16:16.390 --> 00:16:18.850
that takes that thing to something else.

00:16:18.900 --> 00:16:21.510
So here we have an example of an
image that was applied with CPTone,

00:16:21.510 --> 00:16:22.790
and then it was hue adjusted.

00:16:22.860 --> 00:16:24.610
So conceptually, it looks like that.

00:16:24.610 --> 00:16:27.150
But what we actually do is
something slightly different.

00:16:27.170 --> 00:16:29.160
We actually chain the filters together.

00:16:29.160 --> 00:16:32.540
So you have your input image,
and you then run it through two filters,

00:16:32.540 --> 00:16:34.260
and you get your output image.

00:16:34.260 --> 00:16:36.590
In the first example,
you'd be actually writing data

00:16:36.610 --> 00:16:38.100
twice and reading data twice.

00:16:38.100 --> 00:16:39.960
In this example,
you'd be reading data once.

00:16:39.990 --> 00:16:41.560
And you'd be reading data
twice and writing it once.

00:16:41.560 --> 00:16:45.890
So it's a much better sort of result.

00:16:46.140 --> 00:16:49.570
So fundamentally,

00:16:49.950 --> 00:16:52.360
It's really just a pixel engine, right?

00:16:52.530 --> 00:16:56.240
Conceptually, you think of the data,
which is your source image data,

00:16:56.240 --> 00:16:59.790
being applied through the filters
and getting into your destination.

00:16:59.980 --> 00:17:03.720
But what's actually happening is
that the destination is requesting

00:17:03.870 --> 00:17:05.890
the pixels from the source.

00:17:07.180 --> 00:17:08.640
And it's at a pixel level.

00:17:08.970 --> 00:17:11.430
So you can do these things
more or less in parallel.

00:17:11.550 --> 00:17:13.440
Doesn't matter whether or
not you're making fetches

00:17:13.500 --> 00:17:15.170
for one pixel or 50 pixels.

00:17:15.280 --> 00:17:17.240
They all can be done in parallel.

00:17:17.330 --> 00:17:20.380
And because this sort of pixel
chain happens from the destination

00:17:20.390 --> 00:17:23.180
all the way through the source,
running inside of this kernel,

00:17:23.230 --> 00:17:26.150
we can have sort of a minimal
loss of information where the

00:17:26.150 --> 00:17:29.200
actual depth of the pipeline,
in terms of the resolution

00:17:29.200 --> 00:17:32.110
of the pipeline,
is actually the data, the resolution,

00:17:32.110 --> 00:17:36.590
or the precision, I should say,
of your calculations.

00:17:38.280 --> 00:17:45.080
So basically Core Image has
a very large set of filters.

00:17:45.120 --> 00:17:47.640
It's about 150, I think,
the last time I checked.

00:17:47.720 --> 00:17:49.930
And they fall into different
types of categories.

00:17:49.990 --> 00:17:55.060
You can have sort of pixel and color,
which is sort of the diagram

00:17:55.070 --> 00:17:57.190
that you see there with the blur.

00:17:57.220 --> 00:17:59.720
It's a blur and actually
hue being applied to it.

00:17:59.820 --> 00:18:02.960
As well as you have sort of geometric
transformations or distortions.

00:18:03.040 --> 00:18:06.060
Here's a page curl
filter that you can do.

00:18:06.100 --> 00:18:08.360
And then we have sort of stylized
filters where you can do,

00:18:08.360 --> 00:18:10.060
in this particular case, it's pixelate.

00:18:10.100 --> 00:18:11.750
There's crystallize and pointalize.

00:18:11.780 --> 00:18:13.860
And there's a whole bunch of
stylized things to give you

00:18:13.860 --> 00:18:15.890
different types of effects.

00:18:16.150 --> 00:18:19.240
But not only can you use
the built-in set of filters,

00:18:19.240 --> 00:18:22.460
just basically as building blocks,
you can create your own custom filters,

00:18:22.600 --> 00:18:22.820
right?

00:18:22.940 --> 00:18:25.780
And a custom filter consists
basically of a little kernel program,

00:18:25.830 --> 00:18:28.340
which basically says what
you're doing to the pixel.

00:18:28.370 --> 00:18:33.340
And it's an OpenGL shader-based
language subset.

00:18:33.460 --> 00:18:36.680
And you then also specify some
sort of parameter marshaling,

00:18:36.730 --> 00:18:38.240
where you're saying, "Okay,
here's my inputs.

00:18:38.260 --> 00:18:41.160
I'm gonna take my inputs,
and I'm going to put them and feed

00:18:41.160 --> 00:18:43.420
my kernel in that particular way."

00:18:43.710 --> 00:18:46.500
Another interesting point is the
separation between executable

00:18:46.500 --> 00:18:48.940
and non-executable filters.

00:18:49.060 --> 00:18:52.340
Executable filters are CPU-based
code that will actually run.

00:18:52.360 --> 00:18:53.550
It's code that will run.

00:18:53.620 --> 00:18:56.990
And sometimes it's not the
thing that you trust the most.

00:18:57.090 --> 00:18:59.760
So we have this other concept
of non-executable filters.

00:18:59.760 --> 00:19:04.040
What you do is you simply describe a
sort of restricted set of a kernel,

00:19:04.110 --> 00:19:08.390
as well as a declarative
meaning or understanding of

00:19:08.460 --> 00:19:12.000
what the parameter set is,
and how the parameters

00:19:12.100 --> 00:19:14.200
get passed to the kernel.

00:19:14.360 --> 00:19:15.110
Those are secure.

00:19:15.260 --> 00:19:16.550
You can put them in any application.

00:19:16.580 --> 00:19:18.070
You don't have to worry.

00:19:18.140 --> 00:19:19.040
The right thing will get done.

00:19:19.040 --> 00:19:25.900
You don't have to worry about
somebody doing RM in your kernel.

00:19:26.530 --> 00:19:30.830
Feature-wise, this is all standard stuff.

00:19:31.010 --> 00:19:33.980
We use multi-core when possible,
threading.

00:19:34.040 --> 00:19:36.540
As we talk about pixel pipeline,
it doesn't matter how many

00:19:36.540 --> 00:19:37.420
pixels we're processing.

00:19:37.450 --> 00:19:39.140
We can all do it in parallel.

00:19:39.250 --> 00:19:43.460
We have, you know, SIMD sort of support,
you know, runtime-generated code

00:19:43.460 --> 00:19:44.660
that's all vectorized.

00:19:44.790 --> 00:19:47.850
And we have full-fledged GPU support.

00:19:47.950 --> 00:19:50.830
So definitely it leverages
both the resources of the

00:19:50.830 --> 00:19:53.600
CPU and the GPU effectively.

00:19:53.710 --> 00:19:56.150
Examples of that are the menu bar.

00:19:56.680 --> 00:19:58.970
Some people like it, some people don't.

00:19:59.090 --> 00:20:01.150
But it's a pretty complicated filter,
that menu.

00:20:01.290 --> 00:20:03.100
It's got about eight
different stages on it,

00:20:03.150 --> 00:20:06.970
all sort of manipulating the background,
doing dodges, and moving stuff around.

00:20:07.010 --> 00:20:11.840
It's a perfect example of Core Image just
right in the windowing system,

00:20:11.870 --> 00:20:16.630
used to give you a very rich
sort of visual appearance.

00:20:16.940 --> 00:20:20.350
Dashboard is another example
with a ripple effect.

00:20:20.510 --> 00:20:23.760
This is actually sort of a simulation,
but you get my point.

00:20:23.760 --> 00:20:26.140
You've seen it.

00:20:26.900 --> 00:20:29.600
Sheets and menus,
if you look really closely

00:20:29.600 --> 00:20:32.080
behind sheets and menus,
you see that the background

00:20:32.080 --> 00:20:33.000
is actually blurred.

00:20:33.000 --> 00:20:34.960
That's the Core Image filter.

00:20:36.310 --> 00:20:37.630
So that's Core Image.

00:20:37.860 --> 00:20:39.680
So now we're gonna talk a
little bit about Core Video,

00:20:39.680 --> 00:20:42.780
but not so much,
but merely so that to give you sort of,

00:20:42.780 --> 00:20:46.280
as I said, you know,
to show you what's on the menu.

00:20:46.400 --> 00:20:48.630
So let's take a look at Core Video.

00:20:48.730 --> 00:20:50.010
What is Core Video?

00:20:50.120 --> 00:20:53.380
It's basically a digital
video pipeline model.

00:20:53.460 --> 00:20:56.640
It assumes that there's going
to be some source of frames,

00:20:56.700 --> 00:20:59.320
which is your video source,
and there's going to be some sort of

00:20:59.420 --> 00:21:03.710
filter processing that has to happen,
i.e., for instance, color matching,

00:21:03.800 --> 00:21:06.020
and then there's going to
be a final output stage,

00:21:06.070 --> 00:21:07.800
which is rendering.

00:21:08.340 --> 00:21:11.800
You can provide your own filter, sorry,
video source.

00:21:11.800 --> 00:21:17.580
You can provide your own filtering,
and you can deal with the frames and

00:21:17.620 --> 00:21:21.040
produce it whether or not you're writing
out bitmaps to something or sending it

00:21:21.050 --> 00:21:23.260
across the web or something or network.

00:21:23.280 --> 00:21:29.440
Not only does it have this sort of model,
it also handles display synchronization.

00:21:29.600 --> 00:21:33.040
So if your output is actually a display,
we actually feed it back into the

00:21:33.130 --> 00:21:36.400
pipeline to make sure that frames
are delivered in a timely fashion,

00:21:36.420 --> 00:21:38.950
all synchronized and whatever.

00:21:39.170 --> 00:21:43.040
In addition to that, as you know,
with video, it's just tons and tons of

00:21:43.040 --> 00:21:44.300
buffers flying around the place.

00:21:44.300 --> 00:21:46.260
So we have efficient buffer management.

00:21:46.260 --> 00:21:48.970
If something needs to be on the card,
the video card,

00:21:48.980 --> 00:21:53.120
then we try to ensure that the frames,
since we know what the destination is,

00:21:53.120 --> 00:21:55.860
the data is actually put in the
right place such that the video

00:21:55.860 --> 00:21:56.920
card can gain access to it.

00:21:56.940 --> 00:21:59.160
So this infrastructure
is there for you to use.

00:21:59.160 --> 00:22:01.330
You just put in your
pieces wherever you want.

00:22:01.360 --> 00:22:05.430
You can use it just to move data around,
or you can move it to supply a source

00:22:05.440 --> 00:22:07.020
or add your own filter processing.

00:22:07.540 --> 00:22:10.580
but you can be part of
this sort of video chain.

00:22:12.340 --> 00:22:15.590
So that was Core Video,
and if you want to learn a

00:22:15.590 --> 00:22:19.300
lot more about this stuff,
you can go up to the QT sessions

00:22:19.300 --> 00:22:21.850
and find out more about it.

00:22:22.010 --> 00:22:24.620
So let's take a look at Core Animation.

00:22:24.830 --> 00:22:28.280
Core Animation is the animator guy.

00:22:28.450 --> 00:22:30.780
He combines a lot of
different technologies,

00:22:30.780 --> 00:22:34.570
and he's a little bit above
that level that we just talked

00:22:34.580 --> 00:22:36.300
about with graphics and imaging.

00:22:36.310 --> 00:22:42.250
And it's more about animation
and user interactivity.

00:22:43.500 --> 00:22:48.100
So at the basic level,
it's really a compositing engine.

00:22:48.120 --> 00:22:53.060
It's just a bunch of stacked layers that
all can just be composited together.

00:22:53.720 --> 00:22:58.800
It also has 3D transforms,
2.5D transforms.

00:22:58.800 --> 00:23:01.940
It allows you to do perspective,
move stuff in space, in 3D space,

00:23:01.960 --> 00:23:02.890
move them around.

00:23:02.900 --> 00:23:06.350
You've seen lots of examples
of it in some of the demos in

00:23:06.350 --> 00:23:09.210
previous WWDCs and recently.

00:23:10.290 --> 00:23:13.700
It also has different
types of animation types.

00:23:13.740 --> 00:23:16.510
You can set stuff
explicitly or implicitly,

00:23:16.600 --> 00:23:19.060
and all you do simply say is,
"I want this to do this,"

00:23:19.080 --> 00:23:20.080
and you forget about it.

00:23:20.080 --> 00:23:22.550
It'll actually do all the animations.

00:23:22.680 --> 00:23:25.830
Not only does it do that,
it has a rich set of content types.

00:23:25.950 --> 00:23:28.800
Here you see a QC,

00:23:28.820 --> 00:23:38.070
- I'm a Quartz Composer media,
as well as a movie that just flew by.

00:23:38.070 --> 00:23:38.070
And then there's also different types of,
ooh.

00:23:38.400 --> 00:24:02.600
[Transcript missing]

00:24:16.440 --> 00:24:20.340
But the whole point of that last
slide was that you can set a

00:24:20.340 --> 00:24:23.500
distortion filter on your movie
as it's playing when it went by.

00:24:23.500 --> 00:24:28.780
So yes, so basically feature-wise,
it's an implicit and

00:24:28.780 --> 00:24:30.440
explicit animation model.

00:24:30.440 --> 00:24:33.160
You can either implicitly just set
things and it'll happen for you,

00:24:33.160 --> 00:24:35.230
or you can explicitly control
exactly how it happens.

00:24:35.280 --> 00:24:37.950
It's got a good layer and
constraint sort of management,

00:24:37.950 --> 00:24:40.170
pins and struts kind of,
so things are void.

00:24:40.180 --> 00:24:42.060
If you move stuff around,
things move away.

00:24:42.700 --> 00:24:45.580
And it's got sort of transaction
management that allows you to do

00:24:45.650 --> 00:24:48.230
both transactions and modifying
several things all at the same time.

00:24:51.270 --> 00:24:55.830
As it says, there's rich media support,
whether it be Quartz Drawing,

00:24:55.830 --> 00:24:59.590
or whether it's a PDF document,
or whether it's OpenGL content,

00:24:59.600 --> 00:25:01.490
or whether it's QuickTime or
Quartz Composer.

00:25:01.630 --> 00:25:05.500
Just deals with them all and
animates them all seamlessly,

00:25:05.500 --> 00:25:07.580
except for the problem.

00:25:07.720 --> 00:25:11.270
It's platform-independent in the
sense that it runs on the phone,

00:25:11.270 --> 00:25:14.030
and it runs on Mac OS X,
and all those smooth animations that

00:25:14.030 --> 00:25:16.380
you see on the phone that we all love,
all the scrolling,

00:25:16.430 --> 00:25:18.040
it's all done with Core Animation.

00:25:18.140 --> 00:25:21.020
You know, really easy to use.

00:25:21.720 --> 00:25:23.920
It's all GPU and CPU capable.

00:25:24.100 --> 00:25:25.770
It takes advantage of
the GPU in a sense that,

00:25:25.770 --> 00:25:29.040
you know,
your rendering is done on the GPU.

00:25:29.220 --> 00:25:32.420
It takes advantage of multi-core
because you're actually making

00:25:32.420 --> 00:25:35.560
changes to the layer tree,
and it's actually doing the

00:25:35.560 --> 00:25:36.840
work on a separate thread.

00:25:36.880 --> 00:25:40.000
And, you know, in cases when we need to,
we have full support for

00:25:40.000 --> 00:25:43.100
all the SIME-type things,
all codes vectorized.

00:25:43.550 --> 00:25:46.130
Examples of it in the OS, the Dock.

00:25:46.200 --> 00:25:50.340
The Dock for Leopard was actually
a Core Animation application.

00:25:50.920 --> 00:25:51.800
Preview.

00:25:51.800 --> 00:25:54.470
Preview uses Core Animation primarily
for the display,

00:25:54.530 --> 00:25:56.760
so you get this asynchronous
display when files are slow

00:25:56.760 --> 00:25:59.230
or long or whatever or big,
as well as does the

00:25:59.230 --> 00:26:02.260
multi-level sort of handling,
where you go from zoom one,

00:26:02.260 --> 00:26:03.320
zoom level to the next.

00:26:03.320 --> 00:26:09.690
The fetching of the data at the
different resolution for the

00:26:09.740 --> 00:26:12.300
zoomed-in content is actually done
asynchronously by Core Animation,

00:26:12.300 --> 00:26:12.300
and it shows up seamlessly.

00:26:12.560 --> 00:26:14.790
Other examples, CoverFlow on the phone,
as I said.

00:26:14.860 --> 00:26:17.010
If you use it by the phone,
all the flicking around and

00:26:17.010 --> 00:26:20.530
all the smooth animations,
all Core Animation.

00:26:20.620 --> 00:26:22.270
Time Machine is our example.

00:26:22.320 --> 00:26:25.290
Time Machine is also
using Core Animation.

00:26:26.780 --> 00:26:30.730
So Core Animation is definitely a
technology that is extremely useful for

00:26:30.840 --> 00:26:36.700
any type of sort of immersive visual
user feedback and just general graphics.

00:26:36.800 --> 00:26:39.990
And it's a great compositing engine,
something that you should definitely

00:26:40.060 --> 00:26:43.070
consider using if you're going to be
going down the route of doing sort of

00:26:43.100 --> 00:26:46.280
this visual feedback user interactivity.

00:26:46.550 --> 00:26:47.950
Quartz Composer.

00:26:48.090 --> 00:26:49.950
Quartz Composer is a little
bit of a Swiss Army knife.

00:26:49.950 --> 00:26:53.740
It basically does anything to
anything and handles anything.

00:26:53.740 --> 00:26:58.770
But primarily, it's a very good visual
programming environment.

00:26:58.770 --> 00:27:01.880
It's really simple, easy to use,
and the programming

00:27:01.880 --> 00:27:03.050
model is very intuitive.

00:27:04.050 --> 00:27:06.570
Basically,
it just consists of a bunch of patches,

00:27:06.580 --> 00:27:08.480
and those patches represent
some unit of work.

00:27:08.480 --> 00:27:12.790
And you supply inputs to the patches,
and you accept outputs from the patches.

00:27:12.790 --> 00:27:14.650
Here we have an example of Around.

00:27:14.730 --> 00:27:17.290
That's one of the
patches that's available.

00:27:18.750 --> 00:27:22.690
Other things are more,
you can make more complicated

00:27:22.780 --> 00:27:27.240
patches called compositions by simply
connecting different patches together.

00:27:27.240 --> 00:27:29.790
This particular example is
basically taking an image and

00:27:29.820 --> 00:27:33.680
putting a crystallized effect
and putting it to the display,

00:27:33.710 --> 00:27:36.330
and what it's doing is basically
chasing the mouse around and

00:27:36.330 --> 00:27:37.690
locking an image to a grid.

00:27:37.700 --> 00:27:41.170
So there we have an example
of interacting with a

00:27:41.310 --> 00:27:44.840
human interface device,
doing some graphic manipulation,

00:27:44.850 --> 00:27:48.580
and presenting it to the screen
with some logic in the middle.

00:27:49.830 --> 00:27:55.140
So there's a rich set of
patches that QC supports,

00:27:55.140 --> 00:27:57.680
and they fall into different
types of categories.

00:27:57.730 --> 00:28:00.270
There's source,
whether it's image or QuickTime, audio,

00:28:00.500 --> 00:28:01.580
all of those different things.

00:28:01.620 --> 00:28:03.980
There's controller type
and network type patches,

00:28:04.050 --> 00:28:05.750
which have to do with
human interface devices,

00:28:05.760 --> 00:28:10.080
MIDI, stuff like that, Bonjour,
RSS speeds, stuff like that.

00:28:10.110 --> 00:28:13.820
And processor and filter is sort of math,
logic's sort of a mux,

00:28:13.820 --> 00:28:17.570
if you want to say on this thing,
start doing this instead of that.

00:28:17.640 --> 00:28:18.660
There's all those different things.

00:28:18.660 --> 00:28:21.360
And it's all in a sort of a
visual programming sort of thing.

00:28:21.360 --> 00:28:23.100
You just simply build
these blocks together,

00:28:23.150 --> 00:28:25.720
and you get the output,
set up the conditions, et cetera,

00:28:25.720 --> 00:28:26.400
et cetera.

00:28:26.520 --> 00:28:29.590
As well as there's sort of more
extensive programability in a sense

00:28:29.680 --> 00:28:31.180
that you can actually write code.

00:28:31.220 --> 00:28:34.080
If you can't satisfy your
particular logic request,

00:28:34.090 --> 00:28:34.900
you can actually write code.

00:28:34.900 --> 00:28:37.530
Or even if you wanted to make a filter,
a different type of filter.

00:28:37.620 --> 00:28:39.450
You have GLSL or OpenCL.

00:28:39.540 --> 00:28:43.180
You can make all of those things,
patches that you can integrate

00:28:43.180 --> 00:28:44.860
within your compositions.

00:28:45.260 --> 00:28:48.210
Now, not only can you sort of use
the built-in set of patches,

00:28:48.220 --> 00:28:49.860
you can make your own, right?

00:28:49.860 --> 00:28:53.000
You can have a composition
effectively become a patch.

00:28:53.000 --> 00:28:55.980
So you may, one developer may have
done this patch that says,

00:28:55.980 --> 00:28:59.740
you know, I'm going to do some physics
simulation or whatever and say,

00:28:59.740 --> 00:29:01.620
I want to export that as a macro patch.

00:29:01.620 --> 00:29:04.990
And that macro patch can be used
in anybody else's application

00:29:04.990 --> 00:29:08.540
as long as they sort of provide
the inputs and get the outputs.

00:29:08.540 --> 00:29:12.100
It's just this way of
having this extensibility.

00:29:13.040 --> 00:29:16.890
Not only can you do that in
terms of making a patch as a,

00:29:16.950 --> 00:29:19.120
consisting of a building
blocks of other patches,

00:29:19.120 --> 00:29:22.000
which is just looked at from the
outside as just a black box where

00:29:22.110 --> 00:29:25.440
you put in inputs and get inputs,
you can actually write custom patches,

00:29:25.460 --> 00:29:27.740
like executable code, right?

00:29:27.740 --> 00:29:30.280
Where you supply your inputs,
you supply your outputs,

00:29:30.280 --> 00:29:32.870
and you do your little logic
inside of your little module,

00:29:32.870 --> 00:29:36.150
and that module becomes a patch that
people can use within Quartz Composer

00:29:36.150 --> 00:29:38.380
and within their different applications.

00:29:41.020 --> 00:29:45.560
Of course, the mantra today,
we use the GPU, we use SIMD,

00:29:45.640 --> 00:29:48.680
we use multi-core,
we use OpenCL in this example.

00:29:48.740 --> 00:29:52.480
You can create patches that
are OpenCL patches and OpenGL.

00:29:53.810 --> 00:29:55.590
Examples of it, iTunes Visualizer.

00:29:55.640 --> 00:29:59.390
Clearly something that somebody wouldn't
really want to write by themselves.

00:29:59.410 --> 00:30:02.530
It takes the input, this input is audio,
and it does something and

00:30:02.530 --> 00:30:03.900
creates graphics for the output.

00:30:03.900 --> 00:30:05.800
Perfect example of Quartz Composer.

00:30:05.810 --> 00:30:08.450
Sorry, Quartz Composition.

00:30:08.800 --> 00:30:10.490
PhotoBoot.

00:30:10.490 --> 00:30:14.350
PhotoBoot,
examples of different features,

00:30:14.350 --> 00:30:16.950
and where picture is actually MC,
MC Graphics.

00:30:18.890 --> 00:30:21.950
The screen saver, RSS screen saver.

00:30:22.370 --> 00:30:24.030
Now the point here is not
that it's a screen saver.

00:30:24.050 --> 00:30:28.090
The point is that it's getting
RSS feeds and actually representing

00:30:28.100 --> 00:30:29.930
that on the screen as a screen saver.

00:30:30.040 --> 00:30:32.050
So here you have,
you're interacting not only

00:30:32.050 --> 00:30:34.850
with some device that is a
user sort of keyboard thing,

00:30:34.860 --> 00:30:37.850
but it's actually fetching stuff
from the network in order to add to

00:30:37.990 --> 00:30:40.940
your composition and make it richer.

00:30:42.280 --> 00:30:46.440
So hopefully now you sort of have
a little taste of sort of where

00:30:46.500 --> 00:30:49.950
things are and how they are sort of
constructed and where they're used.

00:30:50.040 --> 00:30:53.790
And what we're going to sort of take
a look at is how they sort of interact

00:30:53.870 --> 00:30:55.970
and interoperate with each other.

00:30:55.980 --> 00:31:00.480
This is where we actually start after
I've told you what's on the menu.

00:31:00.480 --> 00:31:03.230
Now we're beginning to pair wine
with what you're going to order.

00:31:03.250 --> 00:31:05.560
So now we're going to
talk a little bit more.

00:31:05.580 --> 00:31:09.000
You look at that graph and you say, oh,
that's pretty complicated.

00:31:09.000 --> 00:31:10.080
In fact, it kind of is.

00:31:10.080 --> 00:31:11.480
It's just basically a cycle.

00:31:12.270 --> 00:31:13.720
Everything depends on everything else.

00:31:13.720 --> 00:31:17.050
But what we're going to do is sort
of decompose it into some smaller

00:31:17.050 --> 00:31:18.960
units and take nibbles at a time.

00:31:18.960 --> 00:31:21.150
So let's focus a little
bit on core graphics.

00:31:23.300 --> 00:31:26.610
So Core Graphics basically has
a bunch of fundamental types,

00:31:26.610 --> 00:31:29.390
and they are the fundamental
medium of exchange between

00:31:29.390 --> 00:31:31.000
all of the other frameworks.

00:31:31.010 --> 00:31:33.630
One type is the context.

00:31:33.660 --> 00:31:36.990
Another one is an image,
which is we spoke about images,

00:31:37.040 --> 00:31:39.000
and layers.

00:31:39.190 --> 00:31:40.460
So what's a context?

00:31:40.490 --> 00:31:43.990
Well, it represents a thing
by which you can draw.

00:31:44.150 --> 00:31:45.660
It's your drawing context.

00:31:45.670 --> 00:31:47.550
It's like the pen and paper analogy.

00:31:47.560 --> 00:31:48.400
It's your pen.

00:31:48.400 --> 00:31:50.930
You have your pen with your ink,
and you can tell it to do things.

00:31:50.990 --> 00:31:51.960
It's got state.

00:31:52.160 --> 00:31:54.970
It's got features inside
of it to set up masks,

00:31:55.060 --> 00:31:57.170
tell the pen to move from
one place to the other,

00:31:57.200 --> 00:31:57.960
put down a spot.

00:31:58.040 --> 00:31:59.220
You can dash lines.

00:31:59.240 --> 00:32:01.530
All these different things you can do.

00:32:01.720 --> 00:32:02.900
So great, we've got our pen.

00:32:02.960 --> 00:32:04.890
So how do you make one?

00:32:05.170 --> 00:32:05.940
It's pretty simple.

00:32:05.940 --> 00:32:08.080
If you have a pen and you want
to point it at some raster data,

00:32:08.080 --> 00:32:09.820
you say, okay, great, I got a bitmap.

00:32:09.890 --> 00:32:12.100
It's got wide times
high times color space.

00:32:12.120 --> 00:32:13.060
You set it up.

00:32:13.130 --> 00:32:16.000
You know,
the parameters are not important here.

00:32:16.000 --> 00:32:19.400
The point is that these functions exist,
and they're really easy to use.

00:32:19.400 --> 00:32:22.010
If you are sort of
inside of a view method,

00:32:22.110 --> 00:32:25.210
you're responding to a
view callback to draw,

00:32:25.220 --> 00:32:28.190
you can obtain the current graphics
context by simply asking the current

00:32:28.190 --> 00:32:29.860
graphics context for its graphics board.

00:32:29.900 --> 00:32:32.660
You've got your CG context,
and you can start drawing into it.

00:32:32.670 --> 00:32:36.040
At Carbon, slightly different model,
you would have to ask the

00:32:36.040 --> 00:32:37.580
event for its CG context.

00:32:37.580 --> 00:32:41.830
All very simple,
easy to use to get at these contexts.

00:32:42.190 --> 00:32:42.720
Images.

00:32:43.000 --> 00:32:44.290
Well, we all know what images are.

00:32:44.290 --> 00:32:45.980
They're just a big bucket of pixel data.

00:32:46.050 --> 00:32:48.430
They've got color and they've got alpha.

00:32:48.660 --> 00:32:50.180
What if you wanted to make one?

00:32:50.230 --> 00:32:52.820
Well, you make one by simply
specifying its width,

00:32:52.820 --> 00:32:54.980
height, color space,
and the data pointer, and say,

00:32:54.980 --> 00:32:55.580
"Here you go.

00:32:55.580 --> 00:32:58.230
I want you to make me an image,
and I've described it

00:32:58.290 --> 00:33:00.760
fully." If you had a context,
for instance,

00:33:00.790 --> 00:33:04.310
the bitmap context that you had,
you can simply ask the bitmap context.

00:33:04.500 --> 00:33:06.900
After you've done your
drawing with your CG context,

00:33:06.900 --> 00:33:11.210
you can ask your context, "Hey,
I'd like an image of what I just drew."

00:33:13.360 --> 00:33:15.200
With Image.io,
we spoke about understanding

00:33:15.200 --> 00:33:17.600
different types of formats,
file formats.

00:33:17.710 --> 00:33:20.800
So previously,
we were talking about bits.

00:33:20.800 --> 00:33:23.410
Now we're actually talking about, well,
you didn't manufacture the bits.

00:33:23.470 --> 00:33:25.120
You have to fetch the bits from the disk.

00:33:25.120 --> 00:33:29.520
Fundamental types are basically an
image source and an image destination.

00:33:29.740 --> 00:33:33.650
They merely represent references
or proxies for the repository.

00:33:33.670 --> 00:33:38.640
You can create an image source or
destination with just a block of data,

00:33:38.710 --> 00:33:40.640
or you can create one with a URL.

00:33:40.640 --> 00:33:42.080
That's fine.

00:33:42.080 --> 00:33:44.660
You can get the reference to it,
but you can't really do anything.

00:33:44.660 --> 00:33:46.780
You actually have to start
fetching stuff out of it.

00:33:46.800 --> 00:33:51.430
So here you have an example of how
to create an image or a thumbnail

00:33:51.440 --> 00:33:56.590
for a particular image at some
index inside of your image source.

00:33:56.590 --> 00:34:00.000
Simply ask the image source,
I'd like to get an image or a thumbnail,

00:34:00.000 --> 00:34:01.910
and this is the index frame number six.

00:34:01.940 --> 00:34:03.060
Give me that image.

00:34:03.120 --> 00:34:05.970
Similarly, if you have an image,
whether it was one that you

00:34:05.970 --> 00:34:09.040
got from something else,
let's say you got it from a TIFF file

00:34:09.100 --> 00:34:12.480
and you wanted to put it into a PNG file,
you simply say,

00:34:12.480 --> 00:34:20.000
create my image destination and add this
image that I just got from my TIFF file,

00:34:20.000 --> 00:34:22.130
and I write it to my image destination.

00:34:22.250 --> 00:34:25.740
I add that image to the destination,
and then the image will get written

00:34:25.780 --> 00:34:27.070
out inside of the ping file.

00:34:27.110 --> 00:34:29.990
Pretty easy to use.

00:34:31.290 --> 00:34:33.400
So let's talk a little bit about layers.

00:34:33.450 --> 00:34:34.930
So that was images,
now we're talking about layers.

00:34:34.940 --> 00:34:38.670
Layers are sort of a hybrid in
a way that they really kind of

00:34:38.670 --> 00:34:42.040
are images in a sense that they
sometimes can be device dependent,

00:34:42.040 --> 00:34:42.040
right?

00:34:42.080 --> 00:34:44.600
Or they can be device independent.

00:34:44.630 --> 00:34:48.850
You will create a layer by
specifying some context.

00:34:48.870 --> 00:34:52.220
You had a bitmap context,
you say layer create with context,

00:34:52.220 --> 00:34:53.600
and you give it a bitmap context.

00:34:53.740 --> 00:34:56.500
And what will actually happen is
that we will end up creating a

00:34:56.500 --> 00:35:00.580
layer of a user-specified size
that matches completely in terms

00:35:00.580 --> 00:35:03.500
of resolution and depth and format.

00:35:03.570 --> 00:35:09.740
So you may have gotten a CG context,
but it was drawing to 128-bit pixel.

00:35:09.750 --> 00:35:13.180
And when you ask for its layer,
you'll actually get back a layer that's

00:35:13.180 --> 00:35:15.480
compatible with that destination.

00:35:16.320 --> 00:35:20.100
So once you've constructed your layer,
you then need to say, I've got a layer,

00:35:20.100 --> 00:35:22.160
which is basically a sheet of acetate.

00:35:22.160 --> 00:35:22.600
It's clean.

00:35:22.600 --> 00:35:23.590
It has got nothing in it.

00:35:23.620 --> 00:35:26.230
And what you want to do
is now provide drawing.

00:35:26.230 --> 00:35:28.250
So you need to get a context
from the layer so that you

00:35:28.250 --> 00:35:29.440
can provide your drawing.

00:35:29.460 --> 00:35:31.790
So once you do that,
you can draw whatever

00:35:31.800 --> 00:35:33.050
you want to draw on.

00:35:33.060 --> 00:35:33.770
Then you have a layer.

00:35:33.770 --> 00:35:37.460
You now have a reference to a sort
of a representation of your drawing.

00:35:37.460 --> 00:35:39.670
Now you can take that and pass
that to the system and say,

00:35:39.670 --> 00:35:40.850
here, you can use that.

00:35:42.080 --> 00:35:44.370
Now, similarly, too, once you've finished
drawing your content,

00:35:44.370 --> 00:35:45.980
you actually want to
draw the layer itself.

00:35:46.050 --> 00:35:48.970
You can simply say, hey, layer,
draw this layer to the context

00:35:48.970 --> 00:35:50.390
at a point or a destination.

00:35:50.390 --> 00:35:51.580
All very simple to use.

00:35:51.580 --> 00:35:54.710
So in that way,
you are provided with an ability to,

00:35:54.710 --> 00:35:57.760
whether it be a bitmap context,
do some drawing and

00:35:57.760 --> 00:36:00.820
then have that drawing,
ask for the bitmap context

00:36:00.820 --> 00:36:02.620
for an image and draw it.

00:36:02.640 --> 00:36:05.220
Or you can use the layer model
where you don't have to worry about

00:36:05.290 --> 00:36:08.260
what the depth should be or how
compatible it is with the context.

00:36:08.260 --> 00:36:10.600
You simply create the layer,
draw your content into it.

00:36:10.640 --> 00:36:11.980
Then you can take that layer and draw it.

00:36:11.980 --> 00:36:12.480
it anywhere.

00:36:15.420 --> 00:36:18.300
So let's talk a little
bit about Quartz GL.

00:36:18.390 --> 00:36:20.490
Quartz GL is basically
hardware acceleration for

00:36:20.490 --> 00:36:22.060
all your Quartz operations.

00:36:22.220 --> 00:36:26.490
It offloads all of the burden of
doing the rendering onto the GPU.

00:36:26.630 --> 00:36:30.330
And in a lot of cases,
it makes for a better story

00:36:30.330 --> 00:36:33.900
when integrating with other
GPU-based technologies.

00:36:33.980 --> 00:36:35.870
But more on that later.

00:36:36.940 --> 00:36:38.740
How do you enable it in your application?

00:36:38.990 --> 00:36:40.960
Well, you can enable it application-wide.

00:36:40.960 --> 00:36:43.560
Basically fill in the
plist entry list and say,

00:36:43.560 --> 00:36:46.510
hey, I want to be enabled,
and your entire application is

00:36:46.510 --> 00:36:49.020
going to start being QuartzGL,
every single window.

00:36:49.020 --> 00:36:55.650
That's a great way of doing it, I guess,
but sometimes it's not the best.

00:36:55.660 --> 00:36:59.290
But it does give you a very
easy way of turning it on,

00:36:59.290 --> 00:37:00.780
seeing how it performs right away.

00:37:00.800 --> 00:37:04.900
The preferred method is to
actually sort of analyze and

00:37:04.950 --> 00:37:06.440
understand exactly what you want.

00:37:06.600 --> 00:37:09.140
If it is that you want your main window,
which is typically where

00:37:09.140 --> 00:37:12.140
it should be enabled,
you can actually explicitly say,

00:37:12.140 --> 00:37:18.010
I prefer to have my main window in video
memory to take advantage of QuartzGL,

00:37:18.180 --> 00:37:21.750
but my little tooltip or my color wheel,
I don't really think I care about that.

00:37:21.810 --> 00:37:24.890
The menus, I don't think, sheets, no,
maybe I don't.

00:37:24.920 --> 00:37:27.970
All I care about is my main contents
because that's where all of my

00:37:27.970 --> 00:37:29.520
intensive drawing is going to be done.

00:37:29.540 --> 00:37:33.300
So the preferred method is to
explicitly say which window you

00:37:33.300 --> 00:37:39.130
want to actually turn it on,
is also quite fine too.

00:37:40.770 --> 00:37:45.060
So that was a little
bit about core graphics.

00:37:45.100 --> 00:37:47.970
And you realize that it's
sort of the underpinnings of

00:37:47.980 --> 00:37:50.520
this medium type of exchange,
where you have these primitives

00:37:50.590 --> 00:37:52.830
and you exchange these
primitives with other people.

00:37:52.900 --> 00:37:55.310
So now we're going to talk a
little bit about core image.

00:37:55.410 --> 00:38:01.200
As you see, core image depends on core
graphics from this level of it.

00:38:01.620 --> 00:38:04.540
Fundamental types in
Core Image is a CI context,

00:38:04.540 --> 00:38:06.380
kind of the same model as a CG context.

00:38:06.380 --> 00:38:08.470
It represents a pen.

00:38:08.660 --> 00:38:13.120
It's got a CI image, which is basically a
proxy for an image data,

00:38:13.230 --> 00:38:15.310
and it's got filters.

00:38:16.300 --> 00:38:19.700
How do you create a CI context?

00:38:19.720 --> 00:38:24.000
If you have a CG context,
let's say the CG context that you

00:38:24.110 --> 00:38:27.240
got back from your view method,
or even the CG context that you were

00:38:27.240 --> 00:38:32.120
rendering into as a bitmap context,
you can simply say, CI context,

00:38:32.150 --> 00:38:35.640
create with CG context, and away you go,
you have your CI context,

00:38:35.660 --> 00:38:38.760
you can now start drawing CI drawing.

00:38:38.820 --> 00:38:44.100
And as I said before, alluded to earlier,
if it's QuartzGL enabled,

00:38:44.110 --> 00:38:47.140
then that context gets
complete hardware pass-through.

00:38:47.160 --> 00:38:49.860
So if your filters and your images
were all residing in hardware,

00:38:49.860 --> 00:38:53.060
and your context, destination context,
was QuartzGL enabled,

00:38:53.070 --> 00:38:54.560
all of that stuff would all happen.

00:38:54.600 --> 00:38:57.540
All the image processing
will happen on the GPU.

00:38:58.960 --> 00:39:02.110
Similarly too,
if you actually have an OpenGL context,

00:39:02.170 --> 00:39:04.140
and that's the mode in
which you are running in,

00:39:04.140 --> 00:39:06.080
and you wanted to create
a CI context with it,

00:39:06.090 --> 00:39:08.490
that's the call you would kind of use.

00:39:09.600 --> 00:39:14.120
CI Images, same representations as
same kind of constructors.

00:39:14.130 --> 00:39:16.520
We just basically,
you can create it with data,

00:39:16.610 --> 00:39:19.100
give it its pitch and its
size and the color space,

00:39:19.100 --> 00:39:20.800
or you can create it with a URL.

00:39:20.820 --> 00:39:26.520
In that case, what actually happens is we
go behind the scenes and go

00:39:26.520 --> 00:39:26.520
ask Image.io to open the URL.

00:39:27.450 --> 00:39:29.890
You can create with the CG image
that you may have been constructed.

00:39:29.900 --> 00:39:32.500
Whether or not that image was
constructed from bits you made,

00:39:32.500 --> 00:39:39.620
or whether or not you fetched them
from a bitmap context by that previous

00:39:39.620 --> 00:39:44.290
call that I showed you earlier,
you can get back a CI image

00:39:44.290 --> 00:39:44.290
that represents a CG image.

00:39:44.290 --> 00:39:44.290
And similarly too with a layer.

00:39:45.140 --> 00:39:48.090
If you have an OpenGL texture,
let's say you were an OpenGL application

00:39:48.120 --> 00:39:50.740
and you wanted to use CI to do
some sort of filtering on it,

00:39:50.740 --> 00:39:53.970
you could simply say, "Here,
give me a CI image with this that

00:39:53.990 --> 00:39:56.170
represents this OpenGL texture."

00:39:57.380 --> 00:39:58.290
That's great.

00:39:58.340 --> 00:39:59.960
You've got your image now,
and you want to draw it.

00:39:59.960 --> 00:40:01.160
Pretty simple, too.

00:40:01.160 --> 00:40:05.420
You simply say, CI context,
draw this image in this rect.

00:40:05.520 --> 00:40:09.800
If you wanted to actually render bits,
whether or not the CI filter

00:40:09.860 --> 00:40:13.840
was running inside of the
CPU or on the CPU or on the GPU,

00:40:13.840 --> 00:40:17.320
and you wanted to get a raster
representation to do something with it,

00:40:17.420 --> 00:40:19.810
you know, like, whatever,
write it out to disk,

00:40:19.860 --> 00:40:24.590
then you simply make those calls to get
the image and draw it into your raster.

00:40:25.960 --> 00:40:31.090
As well as you can ask the
CI context to make a...

00:40:31.550 --> 00:40:34.690
CG image from your CI image.

00:40:34.760 --> 00:40:37.060
Pretty simple APIs to use.

00:40:38.670 --> 00:40:41.280
So that's great,
but that's just for images.

00:40:41.300 --> 00:40:43.740
What about what we really
want to use Core Image for?

00:40:43.930 --> 00:40:47.140
We want to actually
change and modify filters,

00:40:47.140 --> 00:40:50.010
or change and modify
images by applying filters.

00:40:50.110 --> 00:40:53.940
Asking for filters, you simply say,
"I want you to create a

00:40:54.050 --> 00:40:57.470
filter with a particular name,
"whether it's KCI, Crystallize,

00:40:57.470 --> 00:41:00.480
or Pointalize, "or HueAdjust,
or whatever." You specify

00:41:00.480 --> 00:41:02.280
your filter name,
and it'll load the filter.

00:41:02.280 --> 00:41:03.940
You get back your filter.

00:41:03.970 --> 00:41:06.430
The next thing you do after that
is you need to initialize a filter.

00:41:06.500 --> 00:41:11.300
So you set it defaults and you can
supply inputs for your filters.

00:41:13.740 --> 00:41:16.810
Once you've constructed the filter,
the filter is just the

00:41:17.560 --> 00:41:19.260
recipe for the modification.

00:41:19.260 --> 00:41:20.600
It's a hue adjustment.

00:41:20.600 --> 00:41:22.900
It has parameters of how
it should adjust the hue,

00:41:22.900 --> 00:41:24.540
but it doesn't actually
have any inputs or outputs.

00:41:24.600 --> 00:41:26.590
You need to supply those inputs.

00:41:26.600 --> 00:41:30.680
So you simply say,
I want you to set my input

00:41:30.680 --> 00:41:35.870
value to be my CI image,
and I want to then take my filter and

00:41:35.940 --> 00:41:39.240
ask my CI filter for its output image.

00:41:39.240 --> 00:41:45.990
And then you have a CI image that
really represents the transformed

00:41:45.990 --> 00:41:51.230
image from the source through
the filter to the output image.

00:41:51.280 --> 00:41:57.170
is an example of creating a filter
and simply setting its input image

00:41:57.200 --> 00:41:59.200
and asking for its output image.

00:41:59.200 --> 00:42:03.510
You get back your CI image and you can
now draw your CI image using the methods

00:42:03.520 --> 00:42:06.360
we spoke about earlier on the CI context.

00:42:08.520 --> 00:42:10.040
An example.

00:42:10.170 --> 00:42:13.200
Have a CI context, CI image,
you want to draw it inside of some rect,

00:42:13.200 --> 00:42:15.500
and you want to apply a filter.

00:42:16.300 --> 00:42:20.430
You simply set the filter's input image,
and you ask the filter

00:42:20.530 --> 00:42:23.380
for its output image,
and then you say, CI context,

00:42:23.380 --> 00:42:25.180
draw image in rect, and you're done.

00:42:25.200 --> 00:42:26.920
You get your hue-adjusted image.

00:42:28.920 --> 00:42:32.120
If you want to apply multiple filters,
you have an array of filters,

00:42:32.120 --> 00:42:33.800
and you want to apply
them and chain together.

00:42:33.800 --> 00:42:35.600
You simply step through a loop.

00:42:35.630 --> 00:42:39.200
You say, first filter, set its input,
ask for its output.

00:42:39.250 --> 00:42:43.320
Second filter, set its input to be the
output of the previous filter,

00:42:43.360 --> 00:42:44.800
ask for its output.

00:42:44.840 --> 00:42:49.190
Third filter, set its input filter to
be the previous output,

00:42:49.220 --> 00:42:50.500
and so on and so on.

00:42:50.530 --> 00:42:53.100
You get back your CI image
at the end of your chain,

00:42:53.120 --> 00:42:56.780
and you simply draw your
image into the context.

00:42:56.890 --> 00:42:58.430
Pretty simple.

00:42:59.870 --> 00:43:02.000
When should we use it?

00:43:02.070 --> 00:43:04.800
Definitely if you have
transmogrifications of your images.

00:43:04.850 --> 00:43:08.380
You want to do some hue adjustment and
a whole bunch of different things to it.

00:43:08.450 --> 00:43:13.820
Or if you have just basically
some processing data that actually

00:43:13.820 --> 00:43:18.150
needs to be rerun on your-- you
have your own custom filter.

00:43:18.280 --> 00:43:20.420
But if you're doing things
like just an affine transform,

00:43:20.450 --> 00:43:22.160
or you're trying to draw
an image color matched,

00:43:22.180 --> 00:43:24.500
you don't necessarily need to use CI.

00:43:24.530 --> 00:43:28.010
So definitely you should figure
out whether or not it is something

00:43:28.020 --> 00:43:32.800
that you really want to do in terms
of really manipulating filters

00:43:32.800 --> 00:43:36.020
and trying to manipulate your
data with complicated filters,

00:43:36.080 --> 00:43:38.770
or whether it's just something simple.

00:43:39.250 --> 00:43:44.680
So you can also use it whenever
you want if you're dealing with

00:43:44.790 --> 00:43:46.600
sort of arrays and streams of data.

00:43:46.600 --> 00:43:49.950
You have some gradient feeler,
you're doing some physics simulation,

00:43:49.950 --> 00:43:51.330
you can also do it then.

00:43:51.340 --> 00:43:55.660
And it's important to note
that CI is more about sort

00:43:55.660 --> 00:43:59.470
of a building block approach,
in terms of there are all

00:43:59.690 --> 00:44:01.820
these things that you have,
and you can chain them

00:44:01.820 --> 00:44:04.070
together and build blocks,
and you can create whatever

00:44:04.070 --> 00:44:05.330
you want to create out of them.

00:44:05.340 --> 00:44:07.080
You can add different types of filters.

00:44:07.710 --> 00:44:10.360
So it's really a cookie cutter kind of,
oh, I got these blocks,

00:44:10.360 --> 00:44:12.030
and I'll assemble them together,
and I get my result.

00:44:12.080 --> 00:44:15.400
Whereas in contrast,
OpenCL is slightly different.

00:44:15.400 --> 00:44:17.810
OpenCL allows you to actually
do everything explicitly.

00:44:17.840 --> 00:44:23.300
So you might make a choice for OpenCL,
or you might make a

00:44:23.310 --> 00:44:25.410
choice for Core Image,
whichever one is simpler.

00:44:25.420 --> 00:44:26.920
If the blocks that are
available in Core Image,

00:44:26.920 --> 00:44:28.580
you can definitely use
those blocks together,

00:44:28.580 --> 00:44:31.080
build them up, and create the effect
you want on your image.

00:44:31.080 --> 00:44:35.740
Another interesting point is about
sort of explicitly making data.

00:44:37.270 --> 00:44:40.240
Example, you can create a CI filter,
I'm sorry.

00:44:40.350 --> 00:44:43.370
You can create a CI filter
that represents your,

00:44:43.370 --> 00:44:47.630
let's say, a professional photo
manipulation application.

00:44:47.640 --> 00:44:52.680
And you want it to sort of say, look,
the user is going to modify and do

00:44:52.700 --> 00:44:56.200
certain hue adjustments and whatever,
because he needs the image that

00:44:56.200 --> 00:44:59.330
I've just taken with my camera,
and I want to actually

00:44:59.330 --> 00:45:02.380
distribute it to something else,
but I want to do some modifications.

00:45:02.380 --> 00:45:06.030
You don't actually have to run
the filter and make the data.

00:45:07.320 --> 00:45:09.970
And store that as a separate
image and then export that image.

00:45:10.080 --> 00:45:12.900
You can simply just say,
"I've got my input image,

00:45:13.010 --> 00:45:17.540
and I can create my filter chain," which
is the modifications that the user did,

00:45:17.610 --> 00:45:20.040
and you can actually
store the modifications,

00:45:20.140 --> 00:45:21.090
just the filter chain.

00:45:21.310 --> 00:45:22.580
That's what you store on disk.

00:45:22.660 --> 00:45:24.760
You leave the original image alone.

00:45:24.830 --> 00:45:27.380
When the user wants to see it again,
you simply apply those

00:45:27.380 --> 00:45:30.550
filters onto the image,
and boom, you get the result.

00:45:30.650 --> 00:45:34.260
So that's a way of doing it,
rather than explicitly running it through

00:45:34.260 --> 00:45:37.020
and actually physically making the data.

00:45:38.530 --> 00:45:40.460
So that's Core Image.

00:45:40.500 --> 00:45:44.100
And now we know how to sort of
make images and make graphics,

00:45:44.100 --> 00:45:46.900
and what we really want to take a
look at now is how do we animate

00:45:46.900 --> 00:45:48.800
all of this stuff together.

00:45:48.820 --> 00:45:51.580
This is what Core Animation is for.

00:45:52.980 --> 00:45:55.800
The fundamental types
are basically a layer.

00:45:56.010 --> 00:45:58.680
They're sort of layers floating in space.

00:45:58.690 --> 00:46:00.290
As well as there's a basic animation.

00:46:00.300 --> 00:46:03.220
It's the thing that allows you
to move your layer properties or

00:46:03.220 --> 00:46:05.720
change your layer properties around.

00:46:05.740 --> 00:46:07.870
And then there are transactions.

00:46:08.430 --> 00:46:11.100
Every layer has properties
to do with contents,

00:46:11.220 --> 00:46:13.540
whether it's background, foreground.

00:46:13.720 --> 00:46:17.080
They have geometry,
perspective transforms, rotations,

00:46:17.180 --> 00:46:19.130
and they have filters and styles.

00:46:19.130 --> 00:46:24.810
You can add opacity, shadows,
or you can set a CI filter.

00:46:25.780 --> 00:46:28.640
So let's talk about layers.

00:46:28.750 --> 00:46:29.570
Create a layer.

00:46:29.690 --> 00:46:30.610
You can create a layer.

00:46:30.720 --> 00:46:32.480
I got a layer.

00:46:32.660 --> 00:46:35.990
If I wanted to now take that layer,
the layer has nothing in it,

00:46:35.990 --> 00:46:38.470
it's just an empty layer,
and you want to now set

00:46:38.470 --> 00:46:42.400
it on your view and say,
"I want this view in my application to

00:46:42.400 --> 00:46:47.190
have this layer," you can set the view's
layer to be the layer you just created.

00:46:47.500 --> 00:46:50.700
And then you tell the
view that the layer,

00:46:50.700 --> 00:46:53.340
that the view wants a layer.

00:46:53.430 --> 00:46:57.510
So you can set your layer up,
and you can check it into your view.

00:46:58.220 --> 00:47:02.900
You can also make layers of other layers,
or sub-layers of other layers.

00:47:02.970 --> 00:47:05.860
So in the same way you can inject
your root layer into a view,

00:47:06.110 --> 00:47:10.580
you can inject a layer into a root layer,
and make chains of layers,

00:47:10.630 --> 00:47:14.930
and build them up hierarchically,
where a layer has sub-layers.

00:47:17.420 --> 00:47:20.870
Useful method for layers,
setting a content to the image.

00:47:21.010 --> 00:47:24.020
Lots of the times, that's exactly what
you're gonna wanna do.

00:47:24.210 --> 00:47:25.980
I got an image,
I wanna stick it inside of a layer.

00:47:25.980 --> 00:47:29.330
I can just simply set its contents,
and that would be it.

00:47:30.060 --> 00:47:33.640
If you want to provide
contents by drawing context,

00:47:33.640 --> 00:47:36.400
what you actually have to do is
actually subclass the layer and

00:47:36.400 --> 00:47:38.580
implement the drawing context.

00:47:38.620 --> 00:47:40.720
And what will happen is,
as it's animating,

00:47:40.750 --> 00:47:44.410
and the Quartz Core Animation requires
data from the layer,

00:47:44.420 --> 00:47:46.320
it simply gives you
this callback and says,

00:47:46.360 --> 00:47:48.380
I want you to draw contents.

00:47:48.430 --> 00:47:50.260
And you simply draw your contents.

00:47:50.330 --> 00:47:53.610
So whether the layer is scaled down
to a thumbnail or whether it's large,

00:47:53.660 --> 00:47:54.860
you don't have to change anything.

00:47:54.860 --> 00:47:59.310
You simply provide the data,
and it will be captured correctly.

00:48:01.950 --> 00:48:05.780
Animations, how do you perform those?

00:48:05.840 --> 00:48:09.410
A lot of properties on layers
are implicitly animated.

00:48:09.750 --> 00:48:12.190
You simply set the value.

00:48:12.640 --> 00:48:15.970
You set its new position,
and it'll automatically animate.

00:48:16.550 --> 00:48:21.260
Sometimes you actually might want to
do explicit animations where you say,

00:48:21.310 --> 00:48:25.340
I'd like to create an animation,
and I want you specify

00:48:25.400 --> 00:48:29.220
some property path,
which is basically the path to

00:48:29.220 --> 00:48:30.490
the attribute you want modified.

00:48:30.500 --> 00:48:33.570
You set its from value,
you set its to value,

00:48:33.580 --> 00:48:35.540
and you set its duration.

00:48:35.540 --> 00:48:39.570
And then you take that basic
animation and you add it to the layer.

00:48:39.580 --> 00:48:43.460
And lo and behold,
it will happen for you explicitly.

00:48:44.230 --> 00:48:46.570
Once you're done,
you can simply remove the animation

00:48:46.570 --> 00:48:50.400
by removing the animation that
you added by that particular key.

00:48:50.420 --> 00:48:53.690
And that's how you can
perform explicit animations.

00:48:56.230 --> 00:48:59.300
Now, you can also set filters.

00:48:59.410 --> 00:49:01.790
We talked about, uh...

00:49:02.030 --> 00:49:07.180
The image, the movie that stopped.

00:49:08.330 --> 00:49:10.490
That was really basically a
layer with a filter on it.

00:49:10.500 --> 00:49:11.660
I had a pinch filter.

00:49:11.680 --> 00:49:14.440
And you can do the same
thing with your layers.

00:49:14.440 --> 00:49:19.340
You can add any type of filter on it,
whether it be a filter

00:49:19.340 --> 00:49:22.010
that is a content filter,
meaning you want to actually

00:49:22.010 --> 00:49:24.700
distort the content or pixelate
the content or do something,

00:49:24.710 --> 00:49:27.660
as well as you can add something
like a blur to the background,

00:49:27.660 --> 00:49:31.300
meaning that when the layer is drawn,
it's going to try and ask the background,

00:49:31.300 --> 00:49:33.430
and once it fetches the background,
it's gonna say, "Okay, well,

00:49:33.430 --> 00:49:36.650
I want you to do sort of a glass
distortion on the background."

00:49:36.870 --> 00:49:39.860
All you have to do is simply set
the filters to the appropriate

00:49:39.920 --> 00:49:42.300
attribute that you want modified.

00:49:44.810 --> 00:49:47.290
Transactions.

00:49:47.370 --> 00:49:49.440
Basically,
every sort of implicit animation

00:49:49.440 --> 00:49:50.940
is more or less a transaction.

00:49:50.960 --> 00:49:52.600
It gets generated for you.

00:49:52.600 --> 00:49:54.200
You don't have to worry about it.

00:49:54.230 --> 00:49:56.800
But if you actually wanted to
perform an explicit transaction,

00:49:56.800 --> 00:50:03.740
meaning you wanted to modify several
objects all at the same time,

00:50:03.740 --> 00:50:06.110
you can simply say, transaction begin,
make your mods, and done.

00:50:06.110 --> 00:50:06.110
And by the way, they're nested.

00:50:07.980 --> 00:50:09.300
Subclasses of sort of layer.

00:50:09.330 --> 00:50:11.980
There's text layer,
simply plain or attributed text,

00:50:11.980 --> 00:50:12.680
really easy.

00:50:12.870 --> 00:50:15.060
Tile layer,
when we spoke about preview earlier,

00:50:15.070 --> 00:50:16.980
we talked about multi-level of detail.

00:50:16.980 --> 00:50:20.740
The tile layer allows you
to do that seamlessly,

00:50:20.740 --> 00:50:24.390
where you simply provide your
callback and your data is drawn

00:50:24.600 --> 00:50:28.100
at the specific resolutions,
and Core Animation will

00:50:28.100 --> 00:50:30.090
just do the rest from there.

00:50:30.780 --> 00:50:33.850
Scroll layer, similarly there,
if you're talking about

00:50:33.860 --> 00:50:36.350
scrolling content,
Core Animation will go and ask

00:50:36.360 --> 00:50:39.580
for the newly fetched data,
evict the old data,

00:50:39.580 --> 00:50:43.260
and so all the scrolling stuff
that you see on the phone,

00:50:43.270 --> 00:50:45.970
stuff like that,
is all done with scroll layers.

00:50:47.060 --> 00:50:47.660
OpenGL.

00:50:47.660 --> 00:50:49.780
That's a typo.

00:50:49.780 --> 00:50:53.150
OpenGL,
if you have OpenGL content and you want

00:50:53.200 --> 00:50:57.170
to provide OpenGL content to a layer,
you use that class.

00:50:57.200 --> 00:51:00.180
It's CA OpenGL layer, no space.

00:51:00.180 --> 00:51:02.920
And what you do is you really
basically subclass it and you

00:51:02.920 --> 00:51:04.430
implement the draw method.

00:51:04.460 --> 00:51:06.570
Draw in GL context.

00:51:06.570 --> 00:51:09.720
So when the layer,
when Core Animation needs your content,

00:51:09.720 --> 00:51:11.820
it will simply call
your subclass and say,

00:51:11.820 --> 00:51:15.120
provide the content now,
and gives you the context to draw into.

00:51:15.120 --> 00:51:16.200
Pretty simple.

00:51:18.900 --> 00:51:20.960
We've talked about Qt Kit.

00:51:20.980 --> 00:51:23.440
You can provide Qt
movies by simply saying,

00:51:23.440 --> 00:51:25.440
create a Qt layer or a capture layer.

00:51:25.490 --> 00:51:26.280
Pretty simple.

00:51:27.300 --> 00:51:30.570
Once you have that, you have your layer,
you can basically add it into your tree,

00:51:30.570 --> 00:51:35.160
insert it as a sub-layer,
or add it as a root of your view.

00:51:35.200 --> 00:51:36.570
Done.

00:51:37.500 --> 00:51:39.640
Quartz Composer.

00:51:39.780 --> 00:51:43.640
Simply, you can basically say,
"I want a layer that has

00:51:43.690 --> 00:51:45.520
a composition in it."

00:51:47.630 --> 00:51:50.920
create a Quartz composition layer,
and you supply the Quartz composition.

00:51:50.920 --> 00:51:52.830
There you got your layer,
and you can insert it

00:51:52.870 --> 00:51:53.980
into your layer tree.

00:51:54.000 --> 00:51:55.980
All very simple to use.

00:51:56.750 --> 00:51:58.600
When should you use it?

00:51:58.690 --> 00:52:02.830
Definitely if you have layering
to do and compositing to do.

00:52:02.900 --> 00:52:04.500
Animations to do.

00:52:04.590 --> 00:52:05.450
There's an alternate.

00:52:05.650 --> 00:52:08.250
You can actually use the
AppKit's implicit animations.

00:52:08.520 --> 00:52:11.380
They also have a lot of
features for animations,

00:52:11.420 --> 00:52:14.270
and you may not actually need to
dive down to Core Animation because

00:52:14.320 --> 00:52:17.420
the animation support
inside of the kit might be,

00:52:17.420 --> 00:52:19.190
you know, just as good.

00:52:19.470 --> 00:52:23.480
If you're doing things
that are really simple,

00:52:23.480 --> 00:52:25.500
potentially you may not
want to use Core Animation.

00:52:25.500 --> 00:52:28.050
If it is that you just
want to fade something,

00:52:28.050 --> 00:52:30.820
and that's the only
animation inside your view,

00:52:30.820 --> 00:52:34.400
you may not need to basically
start using Core Animation.

00:52:34.400 --> 00:52:37.350
It does come with a resource,
and you have to be willing to

00:52:37.450 --> 00:52:39.400
understand what that resource is.

00:52:39.400 --> 00:52:42.390
And if it is that you're just trying to
pulse a button or something like that,

00:52:42.390 --> 00:52:45.960
it may not be appropriate for you
to have Core Animation running

00:52:45.980 --> 00:52:47.940
just to pulse that button.

00:52:49.580 --> 00:52:51.540
So that's Core Animation and
its dependencies,

00:52:51.540 --> 00:52:54.580
and how you interact
and how you can use it.

00:52:54.640 --> 00:52:57.340
So now we're going to talk
about the Swiss Army knife

00:52:57.340 --> 00:52:59.990
of the Quartz technologies.

00:53:01.470 --> 00:53:04.220
Fundamental types basically
has a composition.

00:53:04.360 --> 00:53:07.270
Remember,
we spoke about patches and connecting

00:53:07.300 --> 00:53:08.960
patches and supplying inputs.

00:53:09.110 --> 00:53:11.530
That result is a composition.

00:53:11.780 --> 00:53:16.390
QC view is the view that you inject
inside of your user interface.

00:53:16.460 --> 00:53:20.710
And a QC renderer basically allows
you to control the actual rendering

00:53:20.830 --> 00:53:23.970
of a composition more explicitly.

00:53:25.730 --> 00:53:29.360
So you can create a composition
off of disk or a file,

00:53:29.470 --> 00:53:33.380
specify the URL, and/or specify the data.

00:53:33.530 --> 00:53:36.530
That way you have now this
representation of this composition.

00:53:36.590 --> 00:53:40.480
Compositions by itself only describes,
like filters,

00:53:40.490 --> 00:53:42.920
a description of what needs to be done.

00:53:43.100 --> 00:53:46.220
So you can query the
composition for its attributes.

00:53:46.380 --> 00:53:48.380
You get back a dictionary and
you can query the attributes,

00:53:48.460 --> 00:53:52.280
who the author is, what the name is,
and you can query for its input keys.

00:53:52.310 --> 00:53:54.530
Oh, it wants the input to be a float.

00:53:54.580 --> 00:53:57.360
It wants,
and its output is a rounded float,

00:53:57.360 --> 00:53:58.720
et cetera, et cetera.

00:53:58.740 --> 00:54:02.320
Now you can understand a little
bit about what the composition

00:54:02.320 --> 00:54:03.710
will do when you supply the inputs.

00:54:03.800 --> 00:54:06.480
But the composition by itself
doesn't really do anything just yet.

00:54:06.510 --> 00:54:09.920
You actually have to attach it
to something in order to do that.

00:54:09.980 --> 00:54:13.150
So let's say you created your QC view,
and you put it inside

00:54:13.150 --> 00:54:14.830
of your user interface,
and now you want it to

00:54:14.830 --> 00:54:18.070
load the composition that's
associated with the view.

00:54:18.320 --> 00:54:20.480
Once you load the composition
associated with you,

00:54:20.480 --> 00:54:22.970
the view is now attached,
it has an output destination,

00:54:22.970 --> 00:54:25.200
and we know what's going to be happening.

00:54:25.330 --> 00:54:30.400
So you ask the view at that point to
get its input keys and its output keys.

00:54:30.530 --> 00:54:35.280
You supply those, and your composition is
now set up for rendering.

00:54:35.740 --> 00:54:38.230
And then you just say call, call start.

00:54:38.250 --> 00:54:41.870
Then the composition runs,
and it shows up in your application.

00:54:43.150 --> 00:54:46.900
Similarly to with a QC renderer, right?

00:54:46.990 --> 00:54:50.030
It's not a composition, it's not a view.

00:54:50.570 --> 00:54:52.260
It's an execution engine.

00:54:52.270 --> 00:54:53.740
It's a renderer.

00:54:53.780 --> 00:54:58.460
You also have to create it and
load the composition into it.

00:54:58.540 --> 00:55:02.230
These particular methods allow
you to create it for a particular

00:55:02.230 --> 00:55:03.820
type of output destination.

00:55:04.140 --> 00:55:06.410
If it is that you're just
doing a processing filter,

00:55:06.410 --> 00:55:09.340
in a sense you just want to
-- it's calculating some math.

00:55:09.380 --> 00:55:11.800
It doesn't really do anything but
give you back a spit out the output.

00:55:11.890 --> 00:55:14.020
Here's the average of these numbers,
for example.

00:55:14.090 --> 00:55:17.090
You can just create a
pro-processing renderer.

00:55:17.190 --> 00:55:20.310
If it is that you want to
do output to OpenGL context,

00:55:20.450 --> 00:55:22.820
you will create it with
the OpenGL context,

00:55:22.880 --> 00:55:25.780
and you load it,
you pass in the composition parameter.

00:55:25.840 --> 00:55:28.540
Or you can create it for an off-screen.

00:55:28.600 --> 00:55:30.760
Let's say you wanted to grab
frames from the composition.

00:55:30.900 --> 00:55:33.810
You create a QC renderer,
and you would initialize

00:55:33.810 --> 00:55:36.320
it with the composition,
set it all up,

00:55:36.530 --> 00:55:39.730
and you'd actually be able to
start rendering off-screen frames

00:55:39.980 --> 00:55:43.740
so you capture them and write them
out to a video file or something.

00:55:44.850 --> 00:55:48.720
So once you've gotten the
composition and you've loaded it up,

00:55:48.720 --> 00:55:51.260
just like a view,
which is an actual connection between

00:55:51.260 --> 00:55:53.960
the composition and the output,
similarly with a renderer,

00:55:54.100 --> 00:55:56.350
you have an output,
you have the composition,

00:55:56.360 --> 00:55:58.490
you now have made an executable thing.

00:55:58.540 --> 00:56:00.810
So now you have to supply its inputs.

00:56:00.860 --> 00:56:02.180
Same type of API.

00:56:02.180 --> 00:56:04.960
Values for input keys and
values for output keys.

00:56:04.960 --> 00:56:07.240
You can set the values
for its input keys.

00:56:07.940 --> 00:56:11.930
And with a renderer, the QC renderer,
you can actually start stepping

00:56:11.930 --> 00:56:13.840
the renderer at particular frames.

00:56:13.840 --> 00:56:16.180
Say I want frame one, frame two,
frame three,

00:56:16.180 --> 00:56:17.240
which is different than the view.

00:56:17.240 --> 00:56:17.950
It just runs.

00:56:18.000 --> 00:56:20.460
So in that way,
if you wanted to actually use

00:56:20.470 --> 00:56:24.590
compositions and actually get
individual frames and tightly control,

00:56:24.590 --> 00:56:28.320
this is an example of how you would
do it in the APIs that we use.

00:56:34.480 --> 00:56:39.480
Not only can you create compositions,
you can do a lot of

00:56:39.510 --> 00:56:41.160
interesting things with them.

00:56:41.220 --> 00:56:45.400
Basically, Quartz Composer is used to
experiment with CI filters.

00:56:45.440 --> 00:56:47.600
If you wanted to make
your own little CI filter,

00:56:47.640 --> 00:56:50.320
and you have your little
understanding of what you want to do,

00:56:50.320 --> 00:56:53.280
you can simply just say,
"I want to make a Core Image filter,

00:56:53.330 --> 00:56:56.670
and here is the filter that
I want it to do." And you can

00:56:56.720 --> 00:56:57.950
make a complete experiment.

00:56:58.070 --> 00:56:58.660
You can change it.

00:56:58.760 --> 00:57:00.540
I don't like the color of that red.

00:57:00.620 --> 00:57:01.430
You change the code.

00:57:01.440 --> 00:57:02.050
You modify it.

00:57:02.150 --> 00:57:03.110
It's all live.

00:57:03.380 --> 00:57:05.780
You sit there,
I mean it's miraculous sometimes

00:57:06.040 --> 00:57:08.120
what you can do with it.

00:57:09.810 --> 00:57:12.280
Here's an example of
something that I just built.

00:57:12.290 --> 00:57:13.170
It was pretty easy to do.

00:57:13.210 --> 00:57:16.670
As I said, I was kind of,
it was kind of mind blowing.

00:57:16.670 --> 00:57:17.790
So I got this movie.

00:57:17.900 --> 00:57:19.860
It's a roller coaster movie
on the developer examples.

00:57:19.870 --> 00:57:21.510
And great, I got a movie.

00:57:21.510 --> 00:57:25.860
So, you know, in the graphics world,
things are kind of problematic,

00:57:25.860 --> 00:57:28.070
and it's like a little
bit of a roller coaster.

00:57:28.070 --> 00:57:32.030
So I got this movie, and I put it in,
and I said great.

00:57:32.040 --> 00:57:34.540
So now what I want to do is
I want to sort of blur it,

00:57:34.540 --> 00:57:37.340
because this is what really
roller coasters look like

00:57:37.340 --> 00:57:39.120
when you're flying down them.

00:57:39.730 --> 00:57:41.440
Down the roller coaster,
it's all very blurred.

00:57:41.590 --> 00:57:44.280
So I simply just added
a blur filter to it.

00:57:44.310 --> 00:57:45.130
That's all I had to do.

00:57:45.140 --> 00:57:47.430
Just take that, connect the inputs,
put it to the output.

00:57:47.530 --> 00:57:49.180
That was it.

00:57:49.780 --> 00:57:51.760
So now I said, OK, great.

00:57:51.780 --> 00:57:53.640
This is the graphics world
that I'm accustomed to.

00:57:53.790 --> 00:57:54.720
It's a roller coaster.

00:57:54.810 --> 00:57:56.140
So I said, welcome to my world.

00:57:56.140 --> 00:57:59.480
It's a PDF document that has text,
welcome to my world.

00:57:59.510 --> 00:58:03.200
All I did was then took that movie,
which is blurred in the background,

00:58:03.200 --> 00:58:05.160
masked it, and that was my output.

00:58:05.190 --> 00:58:07.980
All I need to do is
add those two patches,

00:58:07.990 --> 00:58:09.660
all live.

00:58:09.810 --> 00:58:14.670
So then we say, okay, great, that's cool,
but let's actually put a pinch on it.

00:58:14.720 --> 00:58:18.020
So all I did was then just
added a pinch to that output,

00:58:18.020 --> 00:58:19.810
and that went to the...

00:58:20.110 --> 00:58:23.530
And then, this is great,
even though my world is a

00:58:23.560 --> 00:58:29.460
completely blurred roller coaster,
I do think about the sunset and

00:58:29.470 --> 00:58:30.720
the vacation that I want to go.

00:58:30.930 --> 00:58:34.280
So I basically sobered the text,
threw the text with the pinch,

00:58:34.310 --> 00:58:37.190
and then put it on top of
a movie that was a sunset,

00:58:37.270 --> 00:58:39.100
my favorite beach.

00:58:39.110 --> 00:58:40.890
And that was it.

00:58:43.500 --> 00:58:48.420
So an example of the QC renderer,
for example, is the video wall.

00:58:48.610 --> 00:58:50.530
You all saw that last year.

00:58:50.610 --> 00:58:52.940
What's actually happening there
is you have one composition,

00:58:52.950 --> 00:58:57.090
and that composition is being
farmed over multiple GPUs that

00:58:57.300 --> 00:59:19.500
[Transcript missing]

00:59:21.940 --> 00:59:22.930
Appropriateness.

00:59:23.140 --> 00:59:26.210
Well, anytime you want to do sort
of immersive visualization,

00:59:26.210 --> 00:59:30.100
anytime you want to do experimentations
with the Quartz technologies,

00:59:30.100 --> 00:59:32.290
whether it is you want to have
an image or a movie and see

00:59:32.350 --> 00:59:34.880
what kind of effect it is,
it's great for rapid

00:59:34.880 --> 00:59:36.910
prototyping of CI filters.

00:59:36.920 --> 00:59:39.330
It's great for rapid
prototyping of just saying,

00:59:39.330 --> 00:59:41.360
well, does this GL slang thing work?

00:59:42.060 --> 00:59:47.260
I mean, it's a great tool that allows you
to sort of efficiently go through,

00:59:47.260 --> 00:59:49.720
prototype things,
find out what the final product is,

00:59:49.720 --> 00:59:51.190
and it's not just for prototyping.

00:59:51.200 --> 00:59:53.400
You can actually,
once you've created this composition,

00:59:53.570 --> 00:59:55.080
you can then sort of say,
this is how I want to

00:59:55.080 --> 00:59:56.180
deal with my workflow.

00:59:56.180 --> 00:59:58.080
I then want to put it
inside my application,

00:59:58.080 --> 00:59:59.650
and that's how I process my data.

00:59:59.660 --> 01:00:04.450
And you don't need to write code, really,
except if you're doing a GL filter,

01:00:04.450 --> 01:00:06.800
a GL slang filter or a JavaScript.

01:00:06.830 --> 01:00:10.100
You can just basically,
there's tons of little patches that

01:00:10.100 --> 01:00:12.040
you can connect together and do.

01:00:12.060 --> 01:00:15.780
logic so you may not
ever need to write code.

01:00:17.130 --> 01:00:20.760
So that was the Swiss Army Nice of
a Quartz technology.

01:00:20.770 --> 01:00:22.260
That was Quartz Composer.

01:00:22.390 --> 01:00:26.930
So hopefully, you know,
hopefully the goal of this session

01:00:26.930 --> 01:00:30.640
is to have you leave here and say,
I think this stuff is really cool.

01:00:30.640 --> 01:00:35.600
I want to go to session X, session Y,
session Z, because this is the area

01:00:35.600 --> 01:00:38.480
that I want to look at,
instead of going blindly and say, well,

01:00:38.510 --> 01:00:39.810
when do I use Core Image?

01:00:39.820 --> 01:00:41.590
When do I use Core Animation?

01:00:41.750 --> 01:00:42.760
Do I use V-Image?

01:00:42.830 --> 01:00:45.020
Do I, you know,
this is kind of the information

01:00:45.020 --> 01:00:46.920
that we're supposed to give you.

01:00:46.920 --> 01:00:50.200
You have to then order
the thing on the menu.

01:00:50.230 --> 01:00:51.960
So I told you what was on the menu.

01:00:52.070 --> 01:00:54.520
I told you how to pair
your menu with your wines,

01:00:54.520 --> 01:00:58.110
and you have to figure out what
you want to actually do with it

01:00:58.110 --> 01:01:01.060
and what sessions you need to go
and find out more information.

01:01:01.060 --> 01:01:04.670
So the 2D graphics session,

01:01:04.960 --> 01:01:08.330
where you learn about Core Image and
a little bit of Core Animation is

01:01:08.330 --> 01:01:10.100
on Wednesday at 9:00.

01:01:10.190 --> 01:01:14.700
High Performance Image Processing,
which is about Core Image,

01:01:14.770 --> 01:01:17.400
that's at 9:00 a.m.

01:01:17.400 --> 01:01:19.040
also on Wednesday.

01:01:19.880 --> 01:01:21.240
Oh, wow.

01:01:21.360 --> 01:01:23.930
And Core Animation Techniques.

01:01:24.070 --> 01:01:26.380
Learning about Core Animation.

01:01:26.520 --> 01:01:26.880
Go to that.

01:01:26.970 --> 01:01:28.050
That's at Wednesday at 2.

01:01:28.150 --> 01:01:28.780
No conflict there.

01:01:28.780 --> 01:01:31.720
And then Integrating
with Quartz Composer.

01:01:31.720 --> 01:01:33.580
That's on Thursday.

01:01:35.520 --> 01:01:39.950
Labs, open hours,
in the graphics and media labs,

01:01:39.970 --> 01:01:42.500
but specifically to do
with the Quartz 2D lab.

01:01:42.500 --> 01:01:44.500
That's definitely a Tuesday or two.

01:01:44.650 --> 01:01:49.110
So hopefully you have gotten
a sort of an appetite,

01:01:49.340 --> 01:01:52.440
your appetite has been wet for the
different types of graphics technologies,

01:01:52.440 --> 01:01:54.900
and you'd like to learn about them all.

01:01:54.970 --> 01:01:58.630
So what I'd like to do is...

01:01:58.700 --> 01:02:20.200
[Transcript missing]