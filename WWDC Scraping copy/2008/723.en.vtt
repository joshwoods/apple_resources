WEBVTT

00:00:20.270 --> 00:00:21.130
Hello, everyone.

00:00:21.260 --> 00:00:22.450
I'm Chris Niederauer.

00:00:22.650 --> 00:00:26.560
I'm on the GPU software team.

00:00:26.560 --> 00:00:29.470
I'm a senior engineer there,
senior software engineer.

00:00:29.660 --> 00:00:33.340
And I'm going to be presenting
on tuning your applications for

00:00:33.340 --> 00:00:36.520
OpenGL on the Macintosh platform.

00:00:39.080 --> 00:00:42.760
So, the summary of what we're going to be
doing today is I'm going to go over the

00:00:42.770 --> 00:00:47.440
tools that you can use on our platform,
some of the MacÂ OS X-specific

00:00:47.540 --> 00:00:52.440
tools that make it really easy to
debug and help with performance

00:00:52.520 --> 00:00:53.620
in your OpenGL applications.

00:00:53.620 --> 00:00:57.390
And then we're going to talk
a little bit about basically

00:00:57.390 --> 00:01:01.740
building a good foundation for
your applications and a lot about

00:01:01.740 --> 00:01:04.370
the OpenGL pipeline bottlenecks.

00:01:04.380 --> 00:01:07.570
And special this year,
which we haven't really done in the past,

00:01:07.600 --> 00:01:12.490
is we're actually inviting... We're
actually inviting up people who work

00:01:12.490 --> 00:01:16.230
on the NVIDIA and the Intel GPUs,
and they're going to be giving

00:01:16.240 --> 00:01:21.400
hints on how to use their GPUs in
particular as efficiently as possible.

00:01:21.400 --> 00:01:25.300
But everything that they're going
to be saying is good for everybody.

00:01:25.350 --> 00:01:30.020
So, it's a lot of good information.

00:01:31.670 --> 00:01:34.050
So the tools on our
platform that we have.

00:01:34.130 --> 00:01:36.540
We have, first of all,
the OpenGL Profiler,

00:01:36.590 --> 00:01:43.720
which is basically an application-level
debugger performance tuning application.

00:01:43.720 --> 00:01:45.470
And I'll go over these in a little bit.

00:01:45.540 --> 00:01:49.440
And then the OpenGL Driver Monitor,
which, unlike OpenGL Profiler,

00:01:49.570 --> 00:01:51.780
it's looking at the
driver side of things,

00:01:51.780 --> 00:01:54.850
so sort of the information
that's reported by the driver

00:01:54.850 --> 00:01:58.240
and potentially even some things
reported by the video card,

00:01:58.250 --> 00:02:00.330
as you'll see in NVIDIA slides.

00:02:00.840 --> 00:02:06.920
And then new in the seed that you have is
a new version of OpenGL Shader Builder,

00:02:07.200 --> 00:02:09.620
which I'll show you in a second.

00:02:09.620 --> 00:02:13.680
And then finally, our good old buddies,
Shark and Instruments.

00:02:13.680 --> 00:02:17.460
So let's go over OpenGL Profiler.

00:02:17.460 --> 00:02:20.170
So I was saying it's an
application-level debugger,

00:02:20.170 --> 00:02:22.650
so it lets you do things
like set breakpoints on all

00:02:22.750 --> 00:02:24.300
of your GL function calls.

00:02:24.300 --> 00:02:28.290
So if you want to set a
breakpoint on CGL flush drawable,

00:02:28.320 --> 00:02:32.080
you can basically see each
frame as it happens and look at

00:02:32.080 --> 00:02:35.870
things like resources and state.

00:02:36.080 --> 00:02:40.410
And then there's also special
breakpoints like software fallback.

00:02:40.460 --> 00:02:45.440
So like here,
I set it to break on software fallback.

00:02:45.460 --> 00:02:49.460
And then also thread
conflicts and geo errors.

00:02:49.460 --> 00:02:54.180
So you don't have to stick a geo
get error in your code to check

00:02:54.300 --> 00:02:59.320
for errors if you -- you know,
for performance reasons,

00:02:59.320 --> 00:02:59.320
you don't need to stick that
geo get error in your code.

00:02:59.320 --> 00:03:04.670
You can just run it with OpenGL Profiler,
say break on geo error,

00:03:04.710 --> 00:03:08.170
and it will tell you exactly
when you get an error and what

00:03:08.230 --> 00:03:09.690
kind of type of error it is.

00:03:09.700 --> 00:03:12.620
And then also here in the
upper right-hand corner,

00:03:12.680 --> 00:03:16.700
I'm showing the trace view,
which is showing all the OpenGL calls

00:03:16.700 --> 00:03:21.220
that are happening and what context
they're coming from and the timing

00:03:21.220 --> 00:03:26.600
that the application is spending while
waiting for that function to return.

00:03:28.050 --> 00:03:31.770
So OpenGL Driver Monitor,
I'll just go over this really quickly.

00:03:31.860 --> 00:03:35.880
Eric Klein from NVIDIA is going to go
over it a little bit more in depth.

00:03:36.060 --> 00:03:38.710
But here we're seeing it show,
for instance,

00:03:38.820 --> 00:03:40.670
the CPU wait time for the GPU.

00:03:40.670 --> 00:03:44.590
And it also can show you things like
the amount of free video memory,

00:03:44.680 --> 00:03:47.510
number of textures, things like that.

00:03:48.400 --> 00:04:27.500
[Transcript missing]

00:04:28.800 --> 00:04:29.780
Shark.

00:04:29.890 --> 00:04:32.180
So everyone's probably
really familiar with this.

00:04:32.320 --> 00:04:34.270
Hopefully they are.

00:04:34.560 --> 00:04:36.940
But I just wanted-- I'm not
going to go over this in depth,

00:04:36.940 --> 00:04:41.800
but it basically gives a CPU overview
of what's happening on the CPU.

00:04:41.940 --> 00:04:43.930
And I just want to throw
out a few symbols that you

00:04:43.930 --> 00:04:45.580
should be on the lookout for.

00:04:45.730 --> 00:04:50.800
So for our software render library,
there's do render float.

00:04:50.800 --> 00:04:52.120
So you'd see that in the library column.

00:04:52.120 --> 00:04:53.720
And if you see that,
that means you're basically

00:04:53.720 --> 00:04:57.170
somehow using a software render,
potentially for fallback.

00:04:57.260 --> 00:05:00.120
That's not something that
you want to be doing.

00:05:00.120 --> 00:05:05.150
Also, there's a synchronization command
with the multi-threaded OpenGL engine,

00:05:05.190 --> 00:05:07.700
which is gle-finish-command-buffer.

00:05:07.830 --> 00:05:13.890
And this is when you are synchronizing,
like you're trying to get

00:05:14.030 --> 00:05:17.280
information from the OpenGL thread.

00:05:17.430 --> 00:05:20.220
And it has to basically cause a
pipeline stall at this point to

00:05:20.280 --> 00:05:24.840
get everything through to that
point to get some information.

00:05:24.940 --> 00:05:26.840
And then finally, LLVM symbols.

00:05:26.840 --> 00:05:32.080
We used to have C functions,
like GLG process pixels,

00:05:32.170 --> 00:05:34.900
whenever you'd have a
texture conversion from,

00:05:34.900 --> 00:05:36.990
say, one format to another format.

00:05:37.100 --> 00:05:42.670
But now, for the software render and also
for pixel format conversions,

00:05:42.670 --> 00:05:47.620
that sort of stuff now shows
up in SHARC as LLVM symbols.

00:05:47.640 --> 00:05:49.360
Like here, we have an address.

00:05:49.360 --> 00:05:53.870
And it says unknown after it.

00:05:54.180 --> 00:05:56.460
So here we see the geo render float.

00:05:56.460 --> 00:05:58.520
library as well.

00:05:59.750 --> 00:06:02.200
And then instruments.

00:06:02.260 --> 00:06:04.270
Hopefully everyone's pretty
familiar with instruments.

00:06:04.340 --> 00:06:09.700
It's recently just added the ability
to have the exact same statistics

00:06:09.700 --> 00:06:13.720
you have in driver monitor are
integrated into instruments.

00:06:13.770 --> 00:06:16.810
And so you can basically
look at those side by side,

00:06:17.060 --> 00:06:20.450
you know,
look at how the CPU usage is compared to

00:06:20.450 --> 00:06:23.370
exactly what the driver is doing at any

00:06:24.190 --> 00:06:27.540
And so I'm going to hand
it off to Eric Klein from

00:06:27.540 --> 00:06:32.660
NVIDIA to go over optimizing
applications for NVIDIA hardware.

00:06:32.800 --> 00:06:34.400
Thanks, Chris.

00:06:38.000 --> 00:06:39.160
All right, my name's Eric Klein.

00:06:39.160 --> 00:06:41.680
I'm a senior engineer,
senior software engineer with

00:06:41.690 --> 00:06:45.840
NVIDIA on the Apple OpenGL team.

00:06:45.840 --> 00:06:49.890
Today, the things that I really want to
talk about are understanding how the

00:06:49.890 --> 00:06:52.760
driver works with modern GPU hardware.

00:06:52.890 --> 00:06:54.450
Specifically,
I want to talk about the fast

00:06:54.580 --> 00:06:58.250
paths through the driver and how to
avoid falling off the fast paths,

00:06:58.310 --> 00:06:59.500
performance cliffs.

00:06:59.500 --> 00:07:03.440
One example of that that I want
to mention is old optimizations.

00:07:03.470 --> 00:07:07.690
Things that might have been really smart
to do in 2003 aren't smart necessarily

00:07:07.690 --> 00:07:09.440
to do today on modern hardware.

00:07:09.440 --> 00:07:13.440
And we'll talk more about that later,
what that means.

00:07:13.440 --> 00:07:18.370
But I also want to note the people
this is really geared for are

00:07:18.380 --> 00:07:22.190
Mac OpenGL developers who might not be
perfectly familiar with NVIDIA hardware

00:07:22.190 --> 00:07:24.030
and NVIDIA drivers and how we work.

00:07:24.080 --> 00:07:27.060
Also any Windows developers who are
new to the Mac who might be familiar

00:07:27.060 --> 00:07:31.200
with NVIDIA stuff but not particular
to the NVIDIA driver on the Mac.

00:07:31.220 --> 00:07:32.440
And the difference is there.

00:07:32.440 --> 00:07:33.440
Because it's not completely there.

00:07:33.440 --> 00:07:35.080
the same.

00:07:35.810 --> 00:07:38.660
From a high level,
the two things that I want

00:07:38.660 --> 00:07:42.810
to cover are NVIDIA-specific
strategies for optimization,

00:07:42.950 --> 00:07:45.520
and I'm really focusing on
the latest hardware here,

00:07:45.520 --> 00:07:46.700
GeForce 8 and beyond.

00:07:46.700 --> 00:07:49.690
A lot of this applies
to previous hardware,

00:07:49.690 --> 00:07:51.540
but it's really tailored to GeForce 8.

00:07:51.700 --> 00:07:54.010
And I'll be talking, too,
about some of the

00:07:54.010 --> 00:07:56.700
real-world cases we've seen,
do's and don'ts,

00:07:56.700 --> 00:08:00.680
things that we've seen matter
in the field performance-wise.

00:08:00.700 --> 00:08:03.290
I'll follow that up with some
profiling techniques that we're

00:08:03.340 --> 00:08:04.700
actually using internally.

00:08:04.700 --> 00:08:06.950
You know,
when we get an application and we

00:08:07.010 --> 00:08:10.490
find that there's a performance bug,
I'll be talking about the things

00:08:10.490 --> 00:08:12.300
that we sit down and do first.

00:08:12.950 --> 00:08:15.640
So first, optimizations.

00:08:15.770 --> 00:08:17.390
Top five performance issues we see.

00:08:17.500 --> 00:08:20.240
Number one, poor memory usage.

00:08:20.330 --> 00:08:23.030
This is huge.

00:08:23.160 --> 00:08:26.130
On modern hardware,
a lot of the work we do in the driver is

00:08:26.130 --> 00:08:29.780
actually managing the memory and trying
to do it as efficiently as possible.

00:08:30.290 --> 00:08:33.280
There's actually a lot that you can
do in your code to use the memory

00:08:33.280 --> 00:08:35.910
either efficiently or inefficiently,
and it can make a huge

00:08:36.060 --> 00:08:37.170
difference in performance.

00:08:37.180 --> 00:08:42.180
When I say huge, to give you an idea,
it can be between good and bad.

00:08:42.180 --> 00:08:44.630
It can be an order of
magnitude in your application,

00:08:44.670 --> 00:08:45.560
depending on what you're doing.

00:08:45.560 --> 00:08:49.120
I think in the worst case I've ever seen,
we might have seen two orders

00:08:49.120 --> 00:08:52.430
of magnitude for good memory
usage versus bad memory usage.

00:08:52.440 --> 00:08:57.180
So we'll talk a lot about ways that you
can avoid falling off the fast path here,

00:08:57.180 --> 00:08:58.680
but this is the number one thing.

00:08:58.680 --> 00:09:00.180
Number two and three?

00:09:00.180 --> 00:09:01.240
Thank you.

00:09:01.670 --> 00:09:03.260
Well, yeah, you get the idea.

00:09:03.260 --> 00:09:05.820
Obviously, you know,
there's other things wrong,

00:09:05.820 --> 00:09:09.120
but if you don't get this right,
the other things almost don't matter.

00:09:10.560 --> 00:09:12.460
Excessive state changes.

00:09:12.560 --> 00:09:14.500
This can be very expensive.

00:09:14.500 --> 00:09:17.740
There's a lot of reasons
why it's expensive,

00:09:17.740 --> 00:09:20.920
but this is something you really want
to avoid and we'll talk about why

00:09:20.920 --> 00:09:22.710
it's expensive and how to avoid it.

00:09:22.810 --> 00:09:24.520
And lastly, poor use of shaders.

00:09:24.640 --> 00:09:27.030
Modern hardware,
everything runs in shaders.

00:09:27.240 --> 00:09:30.100
You know, vertex, geometry, fragment.

00:09:30.140 --> 00:09:33.710
And if you're not using shaders or
you're not using them appropriately,

00:09:33.710 --> 00:09:36.090
you're going to get
hurt performance-wise.

00:09:36.510 --> 00:09:38.800
All right, so memory usage.

00:09:39.170 --> 00:09:41.130
When I talk about memory,
I'm really talking about

00:09:41.400 --> 00:09:43.040
three things primarily.

00:09:43.160 --> 00:09:45.780
Textures, vertex data, and shaders.

00:09:45.920 --> 00:09:47.840
Shaders I'll talk more about later,
so I'm mostly going to

00:09:47.840 --> 00:09:49.040
ignore them at this point.

00:09:49.110 --> 00:09:51.530
This is really focused on
textures and vertex data,

00:09:51.670 --> 00:09:54.400
but it applies to, you know,
any buffer object.

00:09:54.610 --> 00:09:59.100
VBO, PBO, FBO, transform feedback,
you know, whatever you're using,

00:09:59.100 --> 00:10:00.540
it applies to this.

00:10:00.660 --> 00:10:03.140
So the things that are
extremely expensive for us,

00:10:03.250 --> 00:10:06.400
and this applies whether you're
talking about VRAM or SRAM.

00:10:06.510 --> 00:10:09.550
Is creating and destroying
texture resou-- or,

00:10:09.550 --> 00:10:12.400
well, memory resources and
mapping and unmapping.

00:10:12.400 --> 00:10:14.370
When I talk about create and destroy,
that's pretty easy.

00:10:14.500 --> 00:10:16.400
That's something that you
see in your application.

00:10:16.430 --> 00:10:22.540
You know, when you create a texture,
you call-- Well, whether it's a texture

00:10:22.630 --> 00:10:25.440
or vertex or whatever,
when you create it, when you destroy it,

00:10:25.440 --> 00:10:26.400
you have good visibility over that.

00:10:26.400 --> 00:10:28.270
That's expensive.

00:10:28.470 --> 00:10:30.400
You want to do as little
of that as possible.

00:10:30.400 --> 00:10:34.400
You want to set that up up front in
your application and not touch it again.

00:10:34.400 --> 00:10:36.400
Mapping and unmapping,
that's a little less expensive.

00:10:36.470 --> 00:10:40.400
That's something that is--you
have some control over.

00:10:40.400 --> 00:10:42.400
The last presentation,
if you were here for that,

00:10:42.400 --> 00:10:44.350
you saw some of the
mapping and unmapping.

00:10:44.460 --> 00:10:46.400
But there's more than just that.

00:10:46.400 --> 00:10:48.400
There's a lot that goes on
behind the scenes in the driver.

00:10:48.400 --> 00:10:52.400
And with modern graphics hardware,
that can actually be somewhat expensive.

00:10:52.410 --> 00:10:56.340
So you want to reduce things that
are going to cause map and unmap.

00:10:56.430 --> 00:10:58.400
And we'll talk in a little
bit about how to do that.

00:10:58.400 --> 00:11:01.200
But it's very important to keep
in mind that map and unmap are not

00:11:01.210 --> 00:11:02.400
free and that they're to be avoided.

00:11:02.400 --> 00:11:06.400
So the big things to
avoid--or not to avoid,

00:11:06.400 --> 00:11:08.400
but the big things to avoid--
or the big solutions to this,

00:11:08.400 --> 00:11:10.400
ways to get around these, number one,
reuse memory objects.

00:11:10.400 --> 00:11:12.390
Make sure that you're
very stingy about them.

00:11:12.400 --> 00:11:16.370
Create as few as you can get away with
and reuse them as much as possible.

00:11:16.450 --> 00:11:20.090
So we'll talk about pooling quite a bit.

00:11:20.540 --> 00:11:25.480
If you find that you're using a lot of
different textures and any given texture

00:11:25.480 --> 00:11:28.400
you might only use for a little bit,
pool the textures.

00:11:28.400 --> 00:11:30.400
Don't create them when you need them,
destroy them when you're done with them.

00:11:30.400 --> 00:11:32.400
Put them into a pool,
release them when you're done,

00:11:32.400 --> 00:11:34.400
and pull something out of
the pool when you're done.

00:11:34.400 --> 00:11:36.400
Obviously,
that's not going to work if you

00:11:36.400 --> 00:11:38.300
have-- wildly different texture sizes.

00:11:38.400 --> 00:11:42.400
You know, if you're using one moment,
you know, 1920 by 1080,

00:11:42.400 --> 00:11:44.340
and the next moment
you're using 256 by 256,

00:11:44.420 --> 00:11:49.400
that doesn't make sense to pool if you
have really strange situations like that.

00:11:49.400 --> 00:11:51.400
But in general, pool if you can.

00:11:51.400 --> 00:11:53.400
Keep data on the GPU.

00:11:53.400 --> 00:11:55.400
This is kind of a no-brainer.

00:11:55.400 --> 00:11:58.400
Any time that you can avoid
transferring things over the bus,

00:11:58.650 --> 00:12:00.850
that's going to save
you pretty good-- well,

00:12:00.850 --> 00:12:02.400
that's going to save you a
pretty good performance hit

00:12:02.400 --> 00:12:04.250
if you can keep it on the GPU.

00:12:04.400 --> 00:12:07.040
It's also going to reduce
map speed and it's going to

00:12:07.040 --> 00:12:08.390
reduce mapping and unmapping.

00:12:08.490 --> 00:12:12.400
The longer something stays on the GPU and
the less it transfers back and forth,

00:12:12.500 --> 00:12:15.390
the less mapping and unmapping
cost you're going to have.

00:12:15.520 --> 00:12:21.400
And FBO, VBO, PBO, transform feedback,
geometry shader, these are all great ways

00:12:21.400 --> 00:12:23.400
to keep things on the GPU.

00:12:23.400 --> 00:12:25.400
Dynamically generated data, great.

00:12:25.510 --> 00:12:28.150
The last thing is,
if you absolutely have to

00:12:28.150 --> 00:12:30.470
create things per frame,

00:12:30.750 --> 00:12:31.920
Do it at the start of the frame.

00:12:31.990 --> 00:12:33.670
Do everything together.

00:12:33.780 --> 00:12:39.200
The reason why is that allows the driver
to essentially batch everything up.

00:12:39.200 --> 00:12:42.600
And we can kind of amortize the
cost of all of these things.

00:12:42.600 --> 00:12:45.490
If we can put them together,
it's going to reduce the cost a lot.

00:12:45.640 --> 00:12:50.010
So if you do have to do
things somewhat frequently,

00:12:50.010 --> 00:12:51.300
batch them.

00:12:51.550 --> 00:12:53.740
All right, note on texture formats.

00:12:53.740 --> 00:12:55.720
We talked a little bit in
the last presentation about

00:12:55.720 --> 00:12:56.940
recommended texture formats.

00:12:56.990 --> 00:12:59.620
Here's a really quick list
looking through our driver of

00:12:59.620 --> 00:13:01.230
hardware-supported formats.

00:13:01.350 --> 00:13:04.870
There's a lot more than is on this list,
but these are kind of

00:13:04.870 --> 00:13:06.540
the most common ones.

00:13:06.540 --> 00:13:09.630
One thing I want to point out, too,
just as a quick note,

00:13:09.740 --> 00:13:13.880
you'll notice on the depth components,
I didn't list depth 16.

00:13:14.660 --> 00:13:18.530
16-bit depth components or
16-bit depth on modern hardware

00:13:18.890 --> 00:13:19.860
isn't supported in the hardware.

00:13:19.900 --> 00:13:24.400
That means that if you are trying to use
16-bit depth as a way to avoid on space,

00:13:24.400 --> 00:13:29.270
as a way to avoid costs on space,
that's not going to help you because

00:13:29.270 --> 00:13:33.020
we actually use a 24-bit depth on the
hardware and we have to do conversion,

00:13:33.020 --> 00:13:35.530
which is going to cost you.

00:13:36.440 --> 00:13:39.000
All right, here's the big one, locality.

00:13:39.050 --> 00:13:41.470
People talk about locality to
mean a lot of different things.

00:13:41.480 --> 00:13:43.800
They could mean spatial locality,
temporal locality,

00:13:43.800 --> 00:13:44.900
lots of things like that.

00:13:44.970 --> 00:13:46.520
I'm not talking about that here.

00:13:46.550 --> 00:13:48.910
This is really locality
about where this lives.

00:13:49.080 --> 00:13:50.120
Is it in the VRAM?

00:13:50.430 --> 00:13:52.700
Is it in the SRAM?

00:13:52.820 --> 00:13:54.320
And so on like that.

00:13:54.600 --> 00:13:57.680
And how it's moved back and forth,
how it's stored.

00:13:57.680 --> 00:14:01.000
You have a couple options
for controlling locality.

00:14:01.000 --> 00:14:03.500
We recommend that you use VBOs and PBOs.

00:14:03.530 --> 00:14:07.340
And if you are,
the usage controls the locality.

00:14:07.340 --> 00:14:09.840
So for example,
if you call GL buffer data,

00:14:09.840 --> 00:14:12.600
the usage argument that you pass
in there is going to control that.

00:14:12.640 --> 00:14:14.950
Also,
you can use the Apple Client Storage and

00:14:14.950 --> 00:14:16.540
the Texture Range extensions.

00:14:16.580 --> 00:14:21.690
Those also give you storage hints to
specify where this is going to be stored.

00:14:21.820 --> 00:14:24.780
So the three locality types,
and I'll talk about these right away,

00:14:24.810 --> 00:14:28.170
are default, cached, and shared.

00:14:28.460 --> 00:14:30.400
Default's exactly what you would expect.

00:14:30.410 --> 00:14:33.370
If you don't do anything,
if you have just a plain, normal texture,

00:14:33.550 --> 00:14:36.400
it gets a default format
or default locality.

00:14:36.660 --> 00:14:42.380
You can see the--I've got kind of icons
next to each of the different layers,

00:14:42.450 --> 00:14:43.400
a little silver icon.

00:14:43.480 --> 00:14:47.280
That shows you each layer that can
keep a copy of the data around.

00:14:47.480 --> 00:14:49.900
So right away,
you can see that in system memory,

00:14:50.050 --> 00:14:54.400
we can potentially keep three copies of
the data around for default locality.

00:14:54.400 --> 00:14:56.390
That's kind of inefficient, right?

00:14:56.390 --> 00:14:57.580
I mean...

00:14:58.440 --> 00:15:01.830
Potentially,
if you have a texture that's 10 megs,

00:15:01.830 --> 00:15:04.270
we're going to take up 30 megs
just in system memory for that.

00:15:04.350 --> 00:15:05.580
Potentially.

00:15:05.580 --> 00:15:08.040
And then in VRAM, of course,
you'll have another 10 megs.

00:15:08.140 --> 00:15:10.640
Also, we'll have to do copies.

00:15:10.660 --> 00:15:13.540
The client's going to have
potentially its own copy.

00:15:13.540 --> 00:15:16.620
When it tells the driver about this,
we copy it to the driver,

00:15:16.620 --> 00:15:19.780
and then we have to upload it to the GPU,
so that's another copy.

00:15:19.780 --> 00:15:22.950
So that's not the best
in certain circumstances.

00:15:22.980 --> 00:15:25.840
Where this really shines, however,
is static data.

00:15:26.310 --> 00:15:28.980
If you have data that you only
are going to send to the GPU once

00:15:29.020 --> 00:15:32.970
and then use over and over again,
or if you have dynamically modified

00:15:32.970 --> 00:15:36.640
data that the GPU is going to
be updating over and over again,

00:15:36.640 --> 00:15:37.520
this is great.

00:15:37.520 --> 00:15:38.690
This is actually pretty good.

00:15:38.700 --> 00:15:40.860
We're fairly efficient about this.

00:15:40.880 --> 00:15:45.380
And the one thing I do want to point
out is that with this locality type,

00:15:45.710 --> 00:15:49.500
there's no pointers from the driver
back to the client's application space,

00:15:49.500 --> 00:15:52.560
which allows the driver to
optimize in certain ways.

00:15:52.560 --> 00:15:55.400
It's possible, and this isn't something
the driver does right now,

00:15:55.460 --> 00:15:57.460
but it's something that we're
talking about for the future,

00:15:57.460 --> 00:15:59.970
it's possible the driver
could actually automatically

00:16:00.070 --> 00:16:02.250
pull these resources for you,
so that if you're doing a

00:16:02.250 --> 00:16:05.010
lot of create and destroy,
we might be able to cut out that cost

00:16:05.020 --> 00:16:07.080
for you if you use this locality type.

00:16:07.080 --> 00:16:09.370
The other locality types,
you don't have that option,

00:16:09.410 --> 00:16:10.480
and I'll tell you why in a minute.

00:16:10.580 --> 00:16:13.430
Alright, next one is cached.

00:16:13.470 --> 00:16:16.180
Cached is very similar to the default.

00:16:16.180 --> 00:16:18.160
It's got a lot of the same use cases.

00:16:18.200 --> 00:16:21.610
You want to use it for fairly
static data or GPU modified data.

00:16:21.620 --> 00:16:25.160
The way this helps is we
only keep a copy of the data,

00:16:25.160 --> 00:16:27.150
and the application space, essentially.

00:16:27.250 --> 00:16:30.720
There's some caveats to that,
but basically we keep one

00:16:30.720 --> 00:16:35.160
system memory copy of the data,
and one VRAM copy of the data.

00:16:35.160 --> 00:16:40.500
The only copy that ever happens in this
case is from system RAM to video RAM.

00:16:40.670 --> 00:16:46.150
It's very efficient,
and it can make a big difference

00:16:46.160 --> 00:16:48.650
for applications that are
significantly memory bound.

00:16:48.660 --> 00:16:51.650
Specifically, we've seen a problem
with 32-bit applications.

00:16:51.700 --> 00:16:54.660
We've seen some 32-bit
applications that will use,

00:16:54.860 --> 00:17:00.360
um, up their entire 4-gig memory
range just with textures,

00:17:00.450 --> 00:17:03.360
and if you go to this,
you can cut that out significantly.

00:17:03.370 --> 00:17:04.860
There are some limitations, though.

00:17:05.000 --> 00:17:07.480
First of all,
the driver has a pointer going back,

00:17:07.560 --> 00:17:11.860
potentially,
to the client's memory space,

00:17:11.860 --> 00:17:14.350
so we can't automatically
pool these for you.

00:17:14.410 --> 00:17:19.000
If you're going to use a lot of these,
you need to pool them yourself.

00:17:19.280 --> 00:17:20.460
Also, limitations.

00:17:20.460 --> 00:17:22.700
You have to use a
hardware-supported texture format.

00:17:22.820 --> 00:17:25.740
If we have to convert from your
texture format to a texture

00:17:25.740 --> 00:17:27.980
format the GPU supports,
we can't use this.

00:17:28.080 --> 00:17:31.340
We have to fall back to a standard type,
or the default type.

00:17:31.390 --> 00:17:34.280
No MIP maps, no cube maps.

00:17:34.730 --> 00:17:36.170
Those are the big points for this one.

00:17:36.370 --> 00:17:38.600
Finally, shared locality.

00:17:38.640 --> 00:17:39.700
No VRAM.

00:17:39.730 --> 00:17:41.700
This is entirely in system memory.

00:17:41.820 --> 00:17:43.500
There's a couple implications of that.

00:17:43.630 --> 00:17:46.200
First of all,
this is only highly dynamic data.

00:17:46.250 --> 00:17:49.500
This is stuff that you're basically
going to modify in the CPU,

00:17:49.540 --> 00:17:51.200
use in the GPU, discard.

00:17:51.200 --> 00:17:55.200
Modify in the CPU, use in the GPU,
discard.

00:17:55.320 --> 00:18:00.410
Or at least not--if not discard,
then update in the CPU again.

00:18:01.430 --> 00:18:04.080
Again, if you're going to use these,
pool these.

00:18:04.400 --> 00:18:07.220
Only use these for highly dynamic,
and they have the same limitations

00:18:07.340 --> 00:18:08.850
as previously mentioned.

00:18:09.160 --> 00:18:12.290
Hardware supported format, no mipmap,
no kubemaps.

00:18:12.300 --> 00:18:15.960
And I'll talk a little bit more
about one of the implications

00:18:16.030 --> 00:18:17.670
of this in a little bit.

00:18:18.420 --> 00:18:19.740
Pagey Unlocking.

00:18:19.890 --> 00:18:26.380
So if you've coded for OpenGL on
other systems like Linux or XP,

00:18:26.410 --> 00:18:32.540
we don't have a virtual
VRAM system on those.

00:18:32.550 --> 00:18:35.140
Whereas with OS X, we do.

00:18:35.330 --> 00:18:42.410
What that means is if your card only
has 64 megs of VRAM or 128 or 1.5 gigs,

00:18:42.410 --> 00:18:45.580
whatever it is,
your application essentially thinks

00:18:45.670 --> 00:18:47.500
it's got an unlimited amount of VRAM.

00:18:47.530 --> 00:18:51.540
That's great if you need to do something
that's more than your card can support

00:18:51.540 --> 00:18:54.940
in terms of total overall VRAM.

00:18:55.000 --> 00:18:58.220
The problem is this leads to paging.

00:18:58.360 --> 00:19:01.540
Paging is essentially if we
need more VRAM than we've got,

00:19:01.550 --> 00:19:04.500
we've got to save off some of
the data that we have in VRAM,

00:19:04.500 --> 00:19:07.660
back to system RAM, reallocate.

00:19:07.670 --> 00:19:11.090
This gets very expensive quickly because
we're doing a lot of allocations,

00:19:11.190 --> 00:19:13.180
we're doing a lot of
mapping and unmapping,

00:19:13.180 --> 00:19:14.980
we're doing a lot of bus transfers.

00:19:15.110 --> 00:19:18.580
So although this allows things
that are never possible before,

00:19:18.580 --> 00:19:22.940
this also gives you performance penalties
that never rose their heads before.

00:19:22.940 --> 00:19:25.570
So you want to avoid
paging as much as possible.

00:19:25.700 --> 00:19:30.700
You want to live within your
means essentially for VRAM.

00:19:30.820 --> 00:19:33.490
A lot of games go to great pains
to make sure that they live

00:19:33.490 --> 00:19:35.710
within the VRAM on the card,
and they get very good

00:19:35.710 --> 00:19:36.700
performance because of that.

00:19:36.700 --> 00:19:39.630
Because if you can avoid paging,
you'll avoid most of the

00:19:39.630 --> 00:19:45.900
mapping and unmapping activity
that we see in a lot of cases.

00:19:45.900 --> 00:19:50.140
The other point I want to make here
is that for shared allocations,

00:19:50.150 --> 00:19:52.900
allocations that have no VRAM,
those need to be mapped

00:19:52.900 --> 00:19:55.970
into the GPU's address space
before the GPU can use that.

00:19:56.140 --> 00:19:59.930
If you're not using these continually,
you know, update on CPU,

00:19:59.940 --> 00:20:03.340
use on GPU right away,
update immediately again, back and forth,

00:20:03.340 --> 00:20:06.540
in a very quick manner,
the driver is aggressive about

00:20:06.540 --> 00:20:09.360
unmapping these because all of these,
when they're mapped,

00:20:09.840 --> 00:20:11.420
essentially wire down system memory.

00:20:11.420 --> 00:20:13.700
Wired system memory is basically bad.

00:20:13.700 --> 00:20:15.780
I won't go into a lot of details on that,
but we do.

00:20:15.780 --> 00:20:18.300
We try and limit wired
memory as much as possible.

00:20:18.420 --> 00:20:20.940
So if you are going to
use shared allocations,

00:20:20.960 --> 00:20:24.260
make sure that you're continually
using them as much as possible.

00:20:24.280 --> 00:20:27.260
Otherwise, you're going to have a lot of
mapping and unmapping activity,

00:20:27.260 --> 00:20:29.300
and that's going to cost you.

00:20:30.130 --> 00:20:32.630
All right, state optimization.

00:20:32.810 --> 00:20:37.700
The bottom line with this is don't
change state any more than you need to.

00:20:37.820 --> 00:20:41.730
You want to organize your code so
that chunks of primitives that use

00:20:41.730 --> 00:20:43.840
the same state render together.

00:20:43.840 --> 00:20:47.240
If you're changing state a lot,
that's going to cause a lot of

00:20:47.240 --> 00:20:49.860
extra activity in the driver,
what we call validation.

00:20:50.000 --> 00:20:53.620
Validation is basically code that
the driver runs before it can send

00:20:53.770 --> 00:20:57.240
commands to the GPU that makes sure
that all of the state is consistent

00:20:57.240 --> 00:20:59.670
and in a format that the GPU can use.

00:20:59.830 --> 00:21:02.300
That includes things
like compiling shaders,

00:21:02.360 --> 00:21:06.100
making sure that the textures
are completely consistent

00:21:06.100 --> 00:21:07.580
and so forth like that.

00:21:07.670 --> 00:21:11.470
It's definitely not free,
so any time you can avoid validation,

00:21:11.780 --> 00:21:13.510
that's good.

00:21:13.800 --> 00:21:16.230
Another thing is GL flush and GL finish.

00:21:16.350 --> 00:21:18.100
These are extremely costly.

00:21:18.120 --> 00:21:20.360
You shouldn't use them
unless you really have to.

00:21:20.360 --> 00:21:22.690
And GL finish, there are very,
very few good reasons

00:21:22.690 --> 00:21:23.860
to ever use GL finish.

00:21:23.860 --> 00:21:28.100
If you find that you need to do that,
you can use the Apple Fence extension.

00:21:28.100 --> 00:21:29.270
I'll talk about that in a moment.

00:21:29.280 --> 00:21:33.520
The reason these are so costly is
because we build up a command buffer

00:21:33.520 --> 00:21:37.840
in the driver and it gets longer and
longer and longer the longer you go

00:21:37.840 --> 00:21:40.320
without a flush or a finish or a swap.

00:21:40.660 --> 00:21:42.600
And as soon as you call flush,
finish or swap,

00:21:42.710 --> 00:21:45.090
we have to send that command
buffer down to the driver.

00:21:45.100 --> 00:21:48.090
Every new command buffer that
we get has a certain amount of

00:21:48.090 --> 00:21:50.310
overhead that's pretty much constant.

00:21:50.320 --> 00:21:51.380
That's a context switch.

00:21:51.380 --> 00:21:53.720
And that's expensive for us.

00:21:53.720 --> 00:21:55.930
It's not hugely expensive,
but it's something you

00:21:55.980 --> 00:21:57.250
want to avoid if you can.

00:21:57.260 --> 00:22:01.980
The Apple Fence extension lets you
essentially insert a marker and say,

00:22:01.980 --> 00:22:04.920
all right, at this point,
I'm going to check later and see

00:22:04.920 --> 00:22:06.740
if we've finished to this point.

00:22:06.740 --> 00:22:09.890
And it's actually fairly
effective and very efficient.

00:22:10.660 --> 00:22:14.890
The one caveat I would say to
that is avoid calling GL finish,

00:22:14.890 --> 00:22:19.730
Fence Apple before you've
called flush or swap.

00:22:19.740 --> 00:22:22.120
If you do that,
that's essentially going to force a

00:22:22.120 --> 00:22:25.380
flush and you've lost your benefit
unless you really need to do it.

00:22:25.440 --> 00:22:28.440
Again, all these things,
if you really need to do something,

00:22:28.440 --> 00:22:30.170
do it, but be careful about it.

00:22:30.870 --> 00:22:31.260
Textures.

00:22:31.300 --> 00:22:33.190
We talked a little bit
about textures with memory,

00:22:33.190 --> 00:22:36.360
but there's some other things that
are also worth thinking about.

00:22:36.380 --> 00:22:40.020
In the past,
it was most efficient to use Power of

00:22:40.020 --> 00:22:45.270
Two and non-rectangle formats because
of certain spatial locality tricks

00:22:45.340 --> 00:22:46.260
that we could do in the hardware.

00:22:46.260 --> 00:22:49.640
Today, with modern hardware,
this isn't true so much anymore.

00:22:49.640 --> 00:22:52.280
You don't need to stick to Power of Two.

00:22:52.280 --> 00:22:53.720
You don't need to stick to rectangle.

00:22:53.720 --> 00:22:56.680
We're very efficient about
how we use things spatial

00:22:56.680 --> 00:22:58.580
locality-wise in the driver.

00:22:58.880 --> 00:23:02.760
And also, it's perfectly efficient these
days to render to an FBO.

00:23:02.760 --> 00:23:07.010
It used to be that with an FBO,
it wasn't as efficient to render to as,

00:23:07.010 --> 00:23:10.330
for example, a normal drawable.

00:23:10.340 --> 00:23:11.610
That's not the case anymore.

00:23:11.620 --> 00:23:15.750
Rendering to an FBO today is pretty
much the same cost as a drawable.

00:23:15.760 --> 00:23:17.740
So don't be shy about that
if that was a concern.

00:23:17.760 --> 00:23:19.320
Float formats?

00:23:19.370 --> 00:23:20.590
Use them if you need them.

00:23:20.600 --> 00:23:22.830
Floats are great,
but if you don't need floats,

00:23:22.900 --> 00:23:24.240
if you don't need that
level of precision,

00:23:24.240 --> 00:23:25.250
don't use it.

00:23:25.280 --> 00:23:27.970
It's going to cost you more in
the shader and also the cache.

00:23:27.980 --> 00:23:28.450
Float formats are great,
but if you don't need floats,

00:23:28.450 --> 00:23:28.860
if you don't need that
level of precision,

00:23:28.860 --> 00:23:28.860
don't use it.

00:23:28.860 --> 00:23:31.320
The float formats are just larger,
and so you're going to fit a lot

00:23:31.320 --> 00:23:33.580
less of the texture in the cache.

00:23:33.870 --> 00:23:35.540
A couple obvious things.

00:23:35.600 --> 00:23:36.000
Textures.

00:23:36.000 --> 00:23:39.500
Anytime you change the size, the format,
number of MIP levels,

00:23:39.500 --> 00:23:42.080
things like that with the texture,
that triggers a lot of work.

00:23:42.160 --> 00:23:44.860
So with textures,
set them up the way you need

00:23:44.970 --> 00:23:46.790
them and leave them alone.

00:23:46.790 --> 00:23:49.290
Do all that sort of stuff at
the start of your application.

00:23:49.300 --> 00:23:54.080
Also, when you're copying things,
if you need to use copy text image,

00:23:54.130 --> 00:23:57.560
text image, anything like that,
use the subversion.

00:23:57.560 --> 00:24:00.930
If you can stick to small regions,
that's obviously going to be a better

00:24:00.930 --> 00:24:02.610
win than doing the whole thing.

00:24:02.640 --> 00:24:04.640
Fairly obvious.

00:24:05.240 --> 00:24:06.640
Programmability.

00:24:06.640 --> 00:24:07.140
This is a basic point.

00:24:07.520 --> 00:24:10.100
Everything in the
hardware today is shaders.

00:24:10.140 --> 00:24:13.140
The hardware natively
uses microcode for vertex,

00:24:13.140 --> 00:24:16.800
geometry, fragment, anything like that.

00:24:17.390 --> 00:24:19.680
If you're still using fixed
function for any reason,

00:24:19.850 --> 00:24:21.140
you're taking a perf hit.

00:24:21.190 --> 00:24:22.800
You might think that, well,
it's really simple,

00:24:22.800 --> 00:24:25.640
it's really straightforward,
obviously that's going to be efficient.

00:24:25.640 --> 00:24:29.160
It's not, because the driver actually
has to create a fixed function

00:24:29.160 --> 00:24:30.670
shader and compile it for you.

00:24:30.670 --> 00:24:33.870
If you change that fixed function state,
it's very expensive.

00:24:33.900 --> 00:24:37.960
That means texture environment,
register combiner, texture shader,

00:24:37.960 --> 00:24:41.830
materials, fog, hardware fog type things,
all that, that's not a fixed

00:24:42.510 --> 00:24:45.160
function thing anymore,
so you don't want to use it.

00:24:45.760 --> 00:24:48.260
And by the way,
that's true for GeForce 6 and beyond,

00:24:48.260 --> 00:24:49.940
not just GeForce 8 and beyond.

00:24:49.940 --> 00:24:52.550
Lastly,
for programmability and validation,

00:24:52.580 --> 00:24:56.370
this is kind of an obvious point,
but change your shaders

00:24:56.370 --> 00:24:57.300
as little as possible.

00:24:57.310 --> 00:24:59.930
Every time you change the shader,
that causes a recompile.

00:24:59.940 --> 00:25:02.520
A little bit less obviously,
some kinds of state,

00:25:02.520 --> 00:25:05.680
when you change state,
also causes the shader recompile.

00:25:05.680 --> 00:25:08.470
Certain texture features,
things like that, if you change,

00:25:08.470 --> 00:25:10.180
it causes the shader recompile.

00:25:10.180 --> 00:25:14.200
So really the big point is set everything
up in the beginning and leave it alone.

00:25:14.220 --> 00:25:16.210
I know I keep saying that,
but that's huge.

00:25:16.220 --> 00:25:21.190
One last minor,
minor point is priming GLBGN.

00:25:21.220 --> 00:25:24.220
When you set up a lot of state,
including your shaders,

00:25:24.220 --> 00:25:27.240
we don't necessarily do a lot of
work in the driver at that point.

00:25:27.240 --> 00:25:30.140
A lot of the work in the driver
happens when you go to do the first

00:25:30.140 --> 00:25:32.230
rendering command that uses that state.

00:25:32.320 --> 00:25:35.100
We've seen actually in some real
world cases that if you wait

00:25:35.100 --> 00:25:38.240
until your application's actually
running to use this stuff,

00:25:38.240 --> 00:25:42.680
you can get a stutter on your first
frame or the first frame that uses this.

00:25:42.680 --> 00:25:46.860
So if you want to avoid that,
you can send down just a bogus little

00:25:46.860 --> 00:25:49.680
GLBGN to draw some minor quad that's
going to force this state to be

00:25:49.680 --> 00:25:49.680
validated and the shader to be compiled.

00:25:49.700 --> 00:25:56.370
For most people it doesn't matter,
but it might matter for your application.

00:25:57.190 --> 00:25:58.640
Last couple general optimizations.

00:25:58.770 --> 00:26:00.120
We talked about context switching.

00:26:00.220 --> 00:26:02.320
Context switching is very
expensive and you want to avoid it.

00:26:02.410 --> 00:26:04.700
Well,
one really simple way to avoid that is

00:26:04.700 --> 00:26:07.290
don't use more contexts than you need.

00:26:07.300 --> 00:26:11.380
We've seen some real-world examples
of apps using a lot of contexts.

00:26:11.400 --> 00:26:14.210
I mean, in some cases,
we've seen one context per frame.

00:26:14.370 --> 00:26:18.800
The idea is trying to isolate
state from one frame to another,

00:26:18.860 --> 00:26:21.080
but that's a huge performance cliff.

00:26:21.140 --> 00:26:22.280
I mean, it's really massive.

00:26:22.430 --> 00:26:23.650
So don't do that.

00:26:23.920 --> 00:26:25.840
That thrashes memory,
that thrashes state,

00:26:25.900 --> 00:26:28.900
that thrashes all kinds of
things and you're going to hurt.

00:26:29.070 --> 00:26:31.030
Another thing,
this is kind of a favor to some

00:26:31.030 --> 00:26:32.900
people internally on our driver team.

00:26:32.900 --> 00:26:34.700
This is a pet peeve that
we get all the time.

00:26:35.110 --> 00:26:36.900
GL renderer string.

00:26:36.900 --> 00:26:38.900
Don't use that to check
for functionality.

00:26:38.900 --> 00:26:43.660
We see people saying, "Oh, you know,
is this G46?" Because I know

00:26:43.780 --> 00:26:45.900
G46 has this particular feature.

00:26:46.000 --> 00:26:49.640
And then when they get to G48,
their code is suddenly saying, "Oh, wait,

00:26:49.690 --> 00:26:50.900
it's not G46.

00:26:50.900 --> 00:26:53.900
It doesn't have that feature."
And they fall back to some old code.

00:26:53.930 --> 00:26:54.700
That's not the way to do things.

00:26:54.700 --> 00:26:58.700
If you absolutely have to
check for a particular card,

00:26:58.700 --> 00:27:00.700
use the render ID.

00:27:00.700 --> 00:27:03.700
That's not going to change
over time or driver to driver.

00:27:03.910 --> 00:27:06.680
But the recommended thing to do,
check for extensions.

00:27:06.740 --> 00:27:08.660
Look at the extension string.

00:27:08.760 --> 00:27:10.700
That's really going to tell
you what you need to know.

00:27:10.700 --> 00:27:12.590
So learn to rely on that.

00:27:12.700 --> 00:27:15.800
And lastly, if you're writing a game,
this is pretty obvious,

00:27:15.800 --> 00:27:16.700
but use full screen.

00:27:16.700 --> 00:27:18.700
At least as the default thing.

00:27:18.700 --> 00:27:21.080
Full screen is a lot more efficient
because you're going to be the only

00:27:21.080 --> 00:27:22.650
context on the system probably.

00:27:22.720 --> 00:27:23.500
You're not going to be fighting
with the Windows Server,

00:27:23.550 --> 00:27:25.500
or any other applications for resources.

00:27:25.500 --> 00:27:27.470
So it's going to run faster.

00:27:27.530 --> 00:27:31.500
And then, of course, full screen,
we're actually going to be using flipping

00:27:31.500 --> 00:27:33.500
with the frame buffer and not blitting.

00:27:33.500 --> 00:27:35.500
And so that's kind of like the
difference between changing

00:27:35.500 --> 00:27:37.490
pointers and copying a whole array.

00:27:37.500 --> 00:27:39.500
Much more efficient.

00:27:39.500 --> 00:27:41.500
All right, that's it for optimizations.

00:27:41.880 --> 00:27:43.180
Now, bottleneck identification.

00:27:43.420 --> 00:27:46.540
These are the techniques that
we're actually using internally.

00:27:46.540 --> 00:27:50.000
So I'm not going to go really
in-depth on the basic methodology.

00:27:50.000 --> 00:27:51.840
This is really well covered elsewhere.

00:27:51.900 --> 00:27:53.280
But this is just kind
of a high-level view,

00:27:53.280 --> 00:27:54.790
the first things to look at.

00:27:54.880 --> 00:27:56.710
You know, open up Activity Monitor.

00:27:56.870 --> 00:27:58.040
See what Activity Monitor tells you.

00:27:58.040 --> 00:28:00.660
If your CPU seems to
not be doing very much,

00:28:00.730 --> 00:28:02.660
then there's a lot of things it could be.

00:28:02.660 --> 00:28:04.900
You could be GPU-bound,
you could be bus-bound,

00:28:04.900 --> 00:28:06.870
you could be memory system-bound.

00:28:07.120 --> 00:28:10.480
Next thing to open up at that
point is OpenGL Driver Monitor and

00:28:10.480 --> 00:28:12.260
look at the activity on the GPU.

00:28:12.310 --> 00:28:16.500
If the GPU is also not using, you know,
very high utilization,

00:28:16.540 --> 00:28:18.540
you're probably bus or memory-bound.

00:28:18.570 --> 00:28:23.540
But either way, at this point,
you move on to fine

00:28:23.540 --> 00:28:25.220
bottleneck identification.

00:28:25.250 --> 00:28:31.150
The fine bottleneck identification can
seem pretty blunt force in some ways.

00:28:31.200 --> 00:28:34.120
The reason I say that is because you're
basically turning things on and off,

00:28:34.480 --> 00:28:37.950
scaling things up and down,
and seeing when your performance changes.

00:28:38.130 --> 00:28:40.190
So, for example, simplify your shaders.

00:28:40.200 --> 00:28:43.030
You may have some really fancy shader
that does all sorts of complex math.

00:28:43.180 --> 00:28:45.000
Well, do something really simple.

00:28:45.000 --> 00:28:46.420
Make it output red.

00:28:46.480 --> 00:28:50.010
You know, whatever it is,
dumb it down and see if

00:28:50.010 --> 00:28:51.220
your performance changes.

00:28:51.240 --> 00:28:54.170
If suddenly your frame rate jumps way
up when you dumbed your shader down,

00:28:54.180 --> 00:28:55.780
well, your shader limited.

00:28:55.820 --> 00:28:57.660
Alter your geometry complexity.

00:28:57.660 --> 00:28:59.670
If you're using some
sort of model that's got,

00:28:59.670 --> 00:29:02.210
you know, 10 million vertices,
drop it down to a much

00:29:02.210 --> 00:29:04.800
lower level of detail,
you know, maybe 1,000 vertices.

00:29:04.930 --> 00:29:06.020
See if your frame rate goes up.

00:29:06.020 --> 00:29:08.200
If it does, you're geometry-bound.

00:29:08.210 --> 00:29:10.100
Modern hardware,
it's very hard to get geometry.

00:29:10.100 --> 00:29:13.940
You can't get geometry-bound,
but it's possible.

00:29:13.940 --> 00:29:17.540
What's much more likely is
that you're fragment-bound.

00:29:17.610 --> 00:29:19.000
So alter your resolution.

00:29:19.000 --> 00:29:23.890
If you're running at 1920x1080,
scale back to 640x480.

00:29:24.040 --> 00:29:25.920
That's where a lot of
things you're going to see,

00:29:25.920 --> 00:29:27.740
you're suddenly going
to get much better perf.

00:29:27.830 --> 00:29:30.280
That means probably that you
need to change your pixel shader.

00:29:30.280 --> 00:29:32.820
You need to change textures you're using.

00:29:32.820 --> 00:29:33.820
You get the idea.

00:29:33.820 --> 00:29:36.580
There's a lot of things that you
can change and tweak within your

00:29:36.580 --> 00:29:40.000
system to get better perf or to
figure out where your bottleneck is.

00:29:40.000 --> 00:29:42.000
I'm not going to go into
a lot more detail on this,

00:29:42.000 --> 00:29:45.150
but see the "NVIDIA Practical
Performance Analysis Guide." We've

00:29:45.150 --> 00:29:48.800
got a really good tutorial on how to
go through and find your bottlenecks

00:29:48.800 --> 00:29:51.390
using this sort of methodology.

00:29:52.130 --> 00:29:55.410
So when it comes down to
actually profiling on the system,

00:29:55.410 --> 00:29:58.170
with OS X, there are certain things
you need to keep in mind.

00:29:58.180 --> 00:30:00.820
And these kind of hold true
for any operating system,

00:30:01.020 --> 00:30:03.930
but these things are
what we look at first.

00:30:03.980 --> 00:30:06.880
First of all, any periodic tasks that
you've got in the OS system,

00:30:06.880 --> 00:30:10.060
in the OS,
dial this back as much as possible.

00:30:10.060 --> 00:30:13.220
Power management, screen saver,
software update,

00:30:13.220 --> 00:30:16.640
any applications you've got
running in the background,

00:30:16.640 --> 00:30:17.890
turn these things off.

00:30:18.120 --> 00:30:18.950
Dial them down.

00:30:18.960 --> 00:30:21.550
I'm not saying turn these off forever,
just while you're profiling.

00:30:21.560 --> 00:30:23.360
Now, obviously,
you want these things on in general.

00:30:23.360 --> 00:30:26.830
And also, keep in mind that your user is
going to have these things on.

00:30:26.840 --> 00:30:30.680
So it's no good if your app runs really
great with power management turned off,

00:30:30.780 --> 00:30:32.770
because your users are going
to have that turned on.

00:30:32.780 --> 00:30:34.750
But for profiling, it's useful.

00:30:34.760 --> 00:30:40.100
Also, if you have the luxury of running
in full screen for profiling,

00:30:40.100 --> 00:30:40.780
do it.

00:30:40.850 --> 00:30:42.290
That eliminates a lot of noise.

00:30:42.300 --> 00:30:44.360
You're not going to be competing
with the Windows server.

00:30:44.360 --> 00:30:47.100
You're not going to be competing
with any other OpenGL apps.

00:30:47.100 --> 00:30:50.230
You're going to be the only app
on the system graphics-wise.

00:30:51.160 --> 00:30:52.620
And that's going to
help you with profiling.

00:30:52.620 --> 00:30:55.140
If you're not a full screen app,
if you can't do that,

00:30:55.220 --> 00:30:57.260
here's an NVIDIA-specific
trick you can do.

00:30:57.360 --> 00:31:03.060
If you look in system library extensions,
there's a file called gforcega.plugin.

00:31:03.060 --> 00:31:05.420
That basically,
the presence of that turns on

00:31:05.460 --> 00:31:07.090
Windows server acceleration.

00:31:07.240 --> 00:31:11.620
That does a bunch of other things,
but if you rename that just temporarily

00:31:12.080 --> 00:31:16.090
and reboot or restart the Windows server,
your app will be the only thing

00:31:16.090 --> 00:31:17.960
using OpenGL on the system.

00:31:17.960 --> 00:31:20.500
You'll be the only graphics context,
and that'll help you isolate.

00:31:20.850 --> 00:31:24.540
Obviously, when you're done,
you want to rename that back.

00:31:24.790 --> 00:31:26.940
The last thing to mention
is power management.

00:31:26.970 --> 00:31:30.160
There's a periodic, well not periodic,
there's a continual background

00:31:30.240 --> 00:31:34.700
process in the OS that looks
at the busyness of the GPU.

00:31:34.700 --> 00:31:37.700
It looks at how much activity
is going on in the GPU and

00:31:37.710 --> 00:31:40.140
if the GPU isn't very busy,
it throttles it back.

00:31:40.220 --> 00:31:44.180
The reason I mention that
is because you can see weird

00:31:44.180 --> 00:31:46.610
kind of spiky perf over time.

00:31:46.610 --> 00:31:51.460
One run will show 130 frames a second,
the next run will show 110.

00:31:51.580 --> 00:31:55.180
And it'll be really hard to figure
out why if you don't keep in

00:31:55.180 --> 00:31:57.460
mind that this could be an issue.

00:31:57.470 --> 00:31:59.390
It's not usually a big issue.

00:31:59.680 --> 00:32:03.160
The main time it can be an issue
is if your app doesn't always

00:32:03.160 --> 00:32:04.980
use the GPU to its fullest.

00:32:04.990 --> 00:32:08.320
For example, if you're CPU bound,
this could be raising its head,

00:32:08.320 --> 00:32:10.200
so it's something to keep in mind.

00:32:10.960 --> 00:32:13.760
All right, OpenGL Driver Monitor.

00:32:13.910 --> 00:32:15.220
This is a very, very valuable tool.

00:32:15.330 --> 00:32:20.330
This is one of your best ways to get an
idea of what's going on inside the GPU.

00:32:20.580 --> 00:32:22.570
It doesn't tell you
what the GPU is doing,

00:32:22.640 --> 00:32:23.300
however.

00:32:23.460 --> 00:32:26.620
It only tells you how hard the
GPU is doing whatever it's doing.

00:32:26.740 --> 00:32:30.300
That can still be very useful, though,
to identify whether you're CPU-bound

00:32:30.300 --> 00:32:33.340
or GPU-bound and a lot of other things.

00:32:33.460 --> 00:32:35.840
OpenGL Driver Monitor also you
can access through Instruments,

00:32:35.840 --> 00:32:39.310
so if you like Instruments,
it's available there.

00:32:39.540 --> 00:32:43.780
These are kind of just a quick list of
the things that I find most useful when

00:32:43.780 --> 00:32:45.780
I need to go in and profile something.

00:32:45.810 --> 00:32:50.880
The top three that I've listed here are
ones that are actually NVIDIA-specific.

00:32:50.880 --> 00:32:53.060
They're in the snow leopard seed,
if you have that,

00:32:53.070 --> 00:32:57.100
and they'll be in drivers that are
going to be coming out in the future.

00:32:57.120 --> 00:33:00.440
These three basically give you
core utilization on the GPU.

00:33:00.440 --> 00:33:02.830
This is the core number that
you want to look at that says,

00:33:02.930 --> 00:33:04.200
how busy is the GPU?

00:33:04.200 --> 00:33:05.680
It's a percentage.

00:33:05.680 --> 00:33:07.170
Next down is memory utilization.

00:33:07.180 --> 00:33:10.580
This is basically how busy is
the memory system on the GPU?

00:33:10.700 --> 00:33:13.220
You know,
how much VRAM activity is going on?

00:33:13.220 --> 00:33:15.400
And then finally,
video engine utilization.

00:33:15.400 --> 00:33:16.740
You know,
if you're working on a video app

00:33:16.830 --> 00:33:21.200
that's using QuickTime or anything
that's using the GPU's video engines,

00:33:21.200 --> 00:33:24.580
like VP1, VP3, anything like that,
this will give you an idea of

00:33:24.580 --> 00:33:27.600
how hard that's working and can
help you figure out bottlenecks

00:33:27.730 --> 00:33:29.190
for underutilization there.

00:33:29.220 --> 00:33:32.360
A couple other quick things, textures,
surfaces,

00:33:32.370 --> 00:33:34.350
you can get counts of all of that.

00:33:34.420 --> 00:33:37.180
Here's where you can find out
how much paging you're doing.

00:33:37.340 --> 00:33:40.040
You can look at page on,
page off for textures and surfaces.

00:33:40.320 --> 00:33:41.620
That'll give you a very good idea.

00:33:41.620 --> 00:33:45.300
If you see that number really high, well,
you've probably fallen

00:33:45.300 --> 00:33:47.910
off a minor perf cliff,
or potentially a very big perf cliff,

00:33:48.000 --> 00:33:50.800
depending on what your usage pattern is.

00:33:50.800 --> 00:33:53.610
You can see how much AGP memory,
which really translates in

00:33:53.620 --> 00:33:57.580
this case to system memory,
is mapped into the GPU.

00:33:57.580 --> 00:34:00.780
That'll help figure out if
you're using a lot of that,

00:34:00.780 --> 00:34:03.640
and that could also be a
mapping and unmapping issue.

00:34:03.640 --> 00:34:05.410
There's a lot of things
I would really just strongly

00:34:05.420 --> 00:34:06.700
encourage you to play with this.

00:34:06.700 --> 00:34:06.700
This is a very simple thing.

00:34:07.180 --> 00:34:08.760
This is a very powerful tool.

00:34:08.760 --> 00:34:11.580
And as time goes by,
we'll be adding more statistics,

00:34:11.580 --> 00:34:15.290
and so it'll be even
more powerful over time.

00:34:16.120 --> 00:34:17.890
OpenGL Driver Monitor Example.

00:34:17.890 --> 00:34:19.990
The main reason I include this,
most of you are probably

00:34:19.990 --> 00:34:21.000
familiar with it.

00:34:21.000 --> 00:34:23.530
In the lower right-hand corner,
you'll notice a little

00:34:23.530 --> 00:34:24.840
button that says Parameters.

00:34:24.840 --> 00:34:31.960
If I've been away from this for
four or five months and I come back,

00:34:32.210 --> 00:34:33.910
I always forget how to
open the tray on the right.

00:34:33.910 --> 00:34:33.910
I'm like, "Oh man,
how do I get that thing

00:34:33.910 --> 00:34:33.910
open?" Click that button.

00:34:34.910 --> 00:34:37.890
Sorry, it's, yeah.

00:34:38.390 --> 00:34:39.130
All right, Shark.

00:34:39.410 --> 00:34:41.300
If you're CPU bound,
if you're trying to figure out

00:34:41.300 --> 00:34:45.190
what's going on in the CPU,
Shark is the very best tool you have.

00:34:45.330 --> 00:34:47.550
Shark is amazingly awesome.

00:34:47.650 --> 00:34:50.730
Go kiss the Shark team when you see them.

00:34:50.770 --> 00:34:53.060
However,
there are a couple things in Shark that

00:34:53.200 --> 00:34:56.500
are maybe not standard for most
developers that I want to recommend.

00:34:56.530 --> 00:35:01.740
If you're profiling OpenGL stuff,
the standard time profile is cool.

00:35:01.800 --> 00:35:02.820
That will help a lot.

00:35:02.860 --> 00:35:05.860
But all thread states is awesome.

00:35:05.890 --> 00:35:09.540
All thread states, basically,
the difference between that and normal

00:35:09.810 --> 00:35:13.710
time profile is normal time profile

00:35:15.900 --> 00:35:17.900
and the rest of the team.

00:35:45.910 --> 00:35:49.320
It's a very complex and powerful tool,
so I'm not going to get into it here.

00:35:49.340 --> 00:35:51.440
Mostly I want you to know that it exists.

00:35:51.460 --> 00:35:53.760
And if you're curious, go explore.

00:35:53.880 --> 00:35:56.120
Window Time Facility is also useful.

00:35:56.140 --> 00:35:57.960
Again,
I'm not going to go into a lot of detail.

00:35:57.960 --> 00:36:00.670
I mostly want you to
know that this exists.

00:36:00.760 --> 00:36:03.240
To use these modes,
you actually have to do a lot more

00:36:03.240 --> 00:36:06.860
data mining to make use of it than
with just standard time profile,

00:36:06.860 --> 00:36:09.140
but the payoff is huge.

00:36:09.140 --> 00:36:12.180
It's something that if
you have a spare hour,

00:36:12.180 --> 00:36:12.920
go do it.

00:36:12.920 --> 00:36:14.550
If you've got a spare day, even better.

00:36:14.820 --> 00:36:15.900
Get very familiar with it.

00:36:15.900 --> 00:36:18.820
I'm going to go ahead and do this because
the more familiar you are with this,

00:36:18.820 --> 00:36:20.920
the easier your profiling will get.

00:36:21.460 --> 00:36:22.700
and Data Mining.

00:36:22.700 --> 00:36:26.640
I just wanted to show the Data Mining
tab over on the side here.

00:36:27.060 --> 00:36:31.900
The Data Mining is absolutely
essential for all thread states.

00:36:31.900 --> 00:36:35.080
So experiment with the
Data Mining in particular.

00:36:35.370 --> 00:36:36.700
There are a lot of things that I turn on.

00:36:36.700 --> 00:36:38.700
One of my favorite things is
actually color by library,

00:36:38.700 --> 00:36:43.480
so I can just tell really quickly at a
glance which library is causing me pain.

00:36:43.620 --> 00:36:45.840
Show all branches is also very powerful.

00:36:46.210 --> 00:36:49.900
Again, I can't cover everything,
but experiment.

00:36:50.760 --> 00:36:53.350
All right, finishing up,
most important things

00:36:53.380 --> 00:36:54.730
I want you to take home.

00:36:54.850 --> 00:36:58.330
Shaders, textures and contexts
are very heavyweight.

00:36:58.460 --> 00:37:01.700
Set these up in the beginning,
leave them alone as much as you can.

00:37:01.700 --> 00:37:07.700
Every time you have to touch these,
you're hurting your performance.

00:37:07.810 --> 00:37:08.180
Reuse.

00:37:08.640 --> 00:37:12.680
Anything you can do to reuse these
are going to be huge for you.

00:37:12.770 --> 00:37:17.700
Some apps, I can guarantee you will see a
10-time improvement just by reuse.

00:37:17.700 --> 00:37:18.320
Not every app.

00:37:18.320 --> 00:37:20.700
I mean, a lot of games already use
things very efficiently,

00:37:20.700 --> 00:37:22.680
but look at your own situation and see.

00:37:22.700 --> 00:37:24.690
You might be able to help.

00:37:24.750 --> 00:37:26.550
And finally, keeping data on the GPU.

00:37:26.840 --> 00:37:29.640
You know,
the last talk we talked about transform

00:37:29.640 --> 00:37:31.700
feedback and geometry shaders.

00:37:31.700 --> 00:37:34.700
Those are great ways to
dynamically generate data.

00:37:34.700 --> 00:37:37.970
The more you can keep it on the GPU,
the better you're going to

00:37:37.970 --> 00:37:39.650
be in terms of performance.

00:37:40.250 --> 00:37:42.950
A couple resources that you
might want to look at later.

00:37:42.970 --> 00:37:46.690
I talked a little bit about the Practical
Performance Analysis Guide from NVIDIA,

00:37:46.690 --> 00:37:48.100
also the GPU Programming Guide.

00:37:48.450 --> 00:37:50.200
Those are very useful.

00:37:50.200 --> 00:37:54.450
Apple has a lot of documentation
up online for optimizing OpenGL and

00:37:54.450 --> 00:37:57.200
the tools that are Apple-specific.

00:37:57.200 --> 00:38:00.190
Very helpful documents,
so I suggest you go look.

00:38:00.200 --> 00:38:03.620
All right,
I'm going to hand back to Chris.

00:38:09.990 --> 00:38:10.900
Thanks, Eric.

00:38:10.900 --> 00:38:15.200
So that was a lot of great
information that helps both with

00:38:15.240 --> 00:38:16.720
NVIDIA as well as everything else.

00:38:16.720 --> 00:38:21.370
But that's a lot of great
info for tuning your apps.

00:38:21.380 --> 00:38:25.800
So we already went over bottlenecks,
but I'm going to go a

00:38:25.800 --> 00:38:27.890
little bit more over it.

00:38:28.100 --> 00:38:34.780
The major bottlenecks tend to be the CPU,
the bus bandwidth, traffic back and forth

00:38:34.900 --> 00:38:36.820
talking to the GPU.

00:38:37.540 --> 00:38:39.780
And then there's also
pipeline and data stalls,

00:38:39.780 --> 00:38:44.300
basically,
where you can have bubbles in one of

00:38:44.300 --> 00:38:46.220
your threads or on the GPU and the CPU.

00:38:46.220 --> 00:38:51.520
And then also, as Eric already went over,
the GPU has vertex processing

00:38:51.530 --> 00:38:53.340
and then the fill rate.

00:38:53.460 --> 00:38:59.820
And you can basically see
if you're one of those two.

00:38:59.820 --> 00:39:02.170
You want to experiment to
see if you're one of those,

00:39:02.420 --> 00:39:03.560
bound by one of those two.

00:39:03.560 --> 00:39:07.220
And then also, Srinivas,
who works on the Intel graphics.

00:39:07.540 --> 00:39:10.770
He's going to give a lot
more hints on fill rate.

00:39:10.800 --> 00:39:15.260
So for CPU,
I just wanted to give some hints in

00:39:15.400 --> 00:39:18.080
addition to what's already been said.

00:39:18.080 --> 00:39:22.210
Other than using Shark,
what you find out, you attack with Shark,

00:39:22.270 --> 00:39:25.220
if you see that you're CPU bound,
there's some other helpful hints here.

00:39:25.220 --> 00:39:27.860
And so one thing is using
a 64-bit application,

00:39:27.860 --> 00:39:30.710
actually compiling your
application to 64-bit.

00:39:30.900 --> 00:39:32.580
So why build 64-bit?

00:39:32.580 --> 00:39:33.880
What's it going to do to speed you up?

00:39:33.940 --> 00:39:36.140
Well, obviously,
there's the fact that you can

00:39:36.140 --> 00:39:37.480
use much bigger data sets.

00:39:37.550 --> 00:39:44.060
So if you are using a large data set
that's more than the 2 gigs or 4 gigs

00:39:44.060 --> 00:39:48.550
that you're able to fit into RAM,
you can use a 64-bit and

00:39:48.550 --> 00:39:52.380
it will actually help,
you know, you won't have to be doing

00:39:52.380 --> 00:39:53.470
any paging at that point.

00:39:53.500 --> 00:39:56.920
And then also,
something that's a little bit

00:39:56.920 --> 00:40:01.200
less known is that it actually,
when you're using x86-64,

00:40:01.360 --> 00:40:05.650
the Intel chip has more optimal
instructions for larger data,

00:40:05.650 --> 00:40:07.520
you know, 64-bit.

00:40:07.520 --> 00:40:10.550
And also, in addition to that,
it has more registers

00:40:10.550 --> 00:40:12.020
available on the CPU.

00:40:12.020 --> 00:40:15.050
So basically,
code goes a little bit faster

00:40:15.150 --> 00:40:17.620
just by compiling in 64-bit.

00:40:17.620 --> 00:40:21.220
And in addition to your
application being 64-bit,

00:40:21.220 --> 00:40:26.160
the OpenGL engine and also the graphics
drivers below that are also going to

00:40:26.160 --> 00:40:30.440
be running on the 64-bit versions,
which in hand have the exact

00:40:30.490 --> 00:40:32.480
same performance benefits.

00:40:34.800 --> 00:41:20.900
[Transcript missing]

00:41:21.100 --> 00:41:54.000
[Transcript missing]

00:41:56.400 --> 00:44:34.600
[Transcript missing]

00:44:34.870 --> 00:44:38.660
I'm going to go over in a second,
basically, avoiding stalls with data

00:44:38.660 --> 00:44:41.800
synchronization and basically
by double buffering objects.

00:44:41.910 --> 00:44:44.230
And I just wanted to reiterate
that this is sort of,

00:44:44.570 --> 00:44:51.180
you know, it's a balancing act,
trying to make sure that

00:44:51.600 --> 00:44:53.740
the CPU and the GPU,
they're both very capable things,

00:44:53.740 --> 00:44:53.740
so you want to be using
them as much as possible.

00:44:53.860 --> 00:44:56.630
Not causing stalls on one or the other.

00:44:56.650 --> 00:45:02.870
So here we have an example of a
texture object that we're modifying

00:45:03.050 --> 00:45:09.320
a texture on the CPU and then using
that texture to draw with on the GPU.

00:45:09.320 --> 00:45:13.750
And we see here that we're actually
getting some bubbles in the pipeline.

00:45:13.750 --> 00:45:17.260
So the CPU doesn't have
anything to do while the GPU is

00:45:17.630 --> 00:45:19.300
drawing with that texture.

00:45:19.590 --> 00:45:23.860
And meanwhile, when we get that texture,
when we're able to write

00:45:23.860 --> 00:45:27.370
into that texture again,
the GPU is then waiting for us

00:45:27.370 --> 00:45:29.280
to upload that second texture.

00:45:29.300 --> 00:45:32.070
So a trick to do -- you know,
this is what -- basically

00:45:32.070 --> 00:45:35.260
what double buffering is,
is you can add a second object in

00:45:35.300 --> 00:45:38.300
here to fill in those pipeline stalls.

00:45:38.300 --> 00:45:42.440
And so what you're doing here is it's --
while the GPU is working on one texture,

00:45:42.440 --> 00:45:44.510
the CPU gets to work
on the other texture.

00:45:44.520 --> 00:45:47.740
And you basically flip-flop
the two between each other.

00:45:47.910 --> 00:45:51.720
And doing this allows you to much
more easily -- more efficiently

00:45:52.440 --> 00:45:56.270
basically get rid of those pipeline
stalls that are existing for,

00:45:56.270 --> 00:46:00.310
you know, texture objects,
even vertex objects,

00:46:00.310 --> 00:46:03.680
vertex buffer objects,
that sort of thing.

00:46:05.430 --> 00:46:08.510
And so bandwidth-wise,
I wanted to reiterate

00:46:08.600 --> 00:46:10.840
what's been said a lot,
you know, in every single

00:46:10.840 --> 00:46:12.090
OpenGL session that we've had.

00:46:12.090 --> 00:46:15.900
And that is do not use immediate
mode vertex submission.

00:46:15.900 --> 00:46:21.270
Geo begin, geo end is basically,
it's a very inefficient way to do things.

00:46:21.270 --> 00:46:25.400
And what it's doing is basically
every single time you call geo vertex,

00:46:25.560 --> 00:46:29.020
we're sending this call,
we're sending the data associated

00:46:29.070 --> 00:46:32.670
with that vertex over the bus
to the vertex processing unit,

00:46:32.670 --> 00:46:36.610
where then it's going to be using those,
that data to process.

00:46:36.630 --> 00:46:41.240
And that's just not an efficient
way to get the data to the GPU.

00:46:41.450 --> 00:46:45.930
So instead, we're obviously recommending
vertex buffer objects for

00:46:45.970 --> 00:46:47.340
pretty much everything.

00:46:47.350 --> 00:46:51.310
So here we see in the VRAM on the GPU,

00:46:51.480 --> 00:46:53.470
In the video memory,
we have a buffer object

00:46:53.470 --> 00:46:56.680
that we've created or buffer
objects that we've created.

00:46:56.680 --> 00:47:00.200
And so similar to like a texture,
we have this buffer object

00:47:00.350 --> 00:47:01.880
with vertex data in it.

00:47:02.070 --> 00:47:06.010
And so we can just literally,
it will just put it over the

00:47:06.010 --> 00:47:08.760
extremely fast bus that's on the GPU.

00:47:09.140 --> 00:47:12.890
There's no bus traffic between the
CPU and the GPU being used here.

00:47:12.990 --> 00:47:17.160
And the vertex processor
is able to basically,

00:47:17.160 --> 00:47:18.660
you know,
get that data as fast as possible.

00:47:21.730 --> 00:47:30.320
And so also with dynamic vertex data,
you can create vertex buffer objects

00:47:30.320 --> 00:47:31.530
that are dynamic or streaming.

00:47:31.530 --> 00:47:35.840
And so what happens in these situations
is that you have your CPU copy,

00:47:35.990 --> 00:47:41.310
but only when you update things,
it's able to actually blip the entire,

00:47:41.410 --> 00:47:47.450
it's able to copy all of your vertex
data at once into the GPU's video memory,

00:47:47.450 --> 00:47:49.920
as opposed to with the media
mode where we're putting one

00:47:49.920 --> 00:47:51.250
vertex on the GPU at a time.

00:47:51.750 --> 00:47:56.410
This basically does a mem
copy straight onto the GPU.

00:47:59.310 --> 00:48:01.890
And then I wanted to talk a little
bit about flush buffer range,

00:48:01.930 --> 00:48:03.780
how that works.

00:48:03.920 --> 00:48:07.940
So in general, so when you're trying
to get your vertex data,

00:48:08.040 --> 00:48:11.200
when you're going to modify it,
if it's dirty on the video card,

00:48:11.240 --> 00:48:14.210
it's going to be read back
to the CPU at that point.

00:48:14.390 --> 00:48:17.400
But after this happens,
I have the objects.

00:48:17.460 --> 00:48:22.330
And say I want to,
without Apple flush buffer range,

00:48:22.330 --> 00:48:25.980
say I want to modify one of my objects.

00:48:25.980 --> 00:48:27.290
So I'll modify that object.

00:48:27.290 --> 00:48:27.290
And

00:48:27.720 --> 00:48:31.330
After I'm done modifying that object,
it then copies the entire

00:48:31.490 --> 00:48:33.490
buffer object back up there.

00:48:33.610 --> 00:48:37.260
But I was only modifying
a small amount of it.

00:48:37.260 --> 00:48:37.260
So,

00:48:37.610 --> 00:48:39.750
What Apple Flush Buffer
Range allows me to do is I'm

00:48:39.760 --> 00:48:42.340
modifying two small parts here,
for instance,

00:48:42.360 --> 00:48:47.780
and I call flush mapped buffer range on
both of those sub ranges of that object,

00:48:47.860 --> 00:48:52.830
un-map my object, and then at that point,
only those two small sub ranges

00:48:52.830 --> 00:48:55.010
would have been modified.

00:48:55.120 --> 00:49:00.460
So it's a much more efficient way to,
if you are only modifying small

00:49:00.460 --> 00:49:04.560
sub ranges of your buffer objects,
you can just use this extension

00:49:04.740 --> 00:49:07.480
to easily speed that up.

00:49:08.500 --> 00:49:20.500
[Transcript missing]

00:49:26.370 --> 00:49:27.600
Hi, everybody.

00:49:27.600 --> 00:49:29.140
My name is Srinivas Dasari.

00:49:29.140 --> 00:49:33.970
I work in the GPU software team at Apple.

00:49:34.420 --> 00:49:38.630
Today I want to go through some tips
for getting better performance on X3100.

00:49:38.700 --> 00:49:43.640
This is the integrated graphics from
Intel that is used in MacBook and

00:49:43.640 --> 00:49:45.820
MacBook Air product lines.

00:49:45.900 --> 00:49:50.740
Today I want to give you a brief
overview of X3100 and its architecture.

00:49:50.860 --> 00:49:55.810
I want to go through state management
and why it is actually crucial

00:49:55.960 --> 00:49:59.640
for getting performance on X3100.

00:50:00.430 --> 00:50:03.170
Eric Klein from NVIDIA already
gave you a lot of details on

00:50:03.170 --> 00:50:08.700
state management and how state
changes can affect GPU performance.

00:50:08.740 --> 00:50:11.330
I'm going to reiterate
those points some more,

00:50:11.330 --> 00:50:14.860
but within the context of
X3100 and its architecture.

00:50:14.980 --> 00:50:19.040
This hardware is especially
tend to be fill rate limited.

00:50:19.040 --> 00:50:22.510
So I'm going to go through some
tips for getting better fill rates.

00:50:22.620 --> 00:50:27.730
Also, we support some API features that
can help you with performance.

00:50:27.800 --> 00:50:29.780
So I'm going to go
through those features.

00:50:30.260 --> 00:50:34.360
And then finally,
I'm going to cover some general hints

00:50:34.450 --> 00:50:39.080
for do's and don'ts that help you with
performance in general on this hardware.

00:50:41.120 --> 00:50:45.140
So X3100 is what is known as
unified memory architecture.

00:50:45.140 --> 00:50:50.410
There is no dedicated video memory
like it exists for other GPUs.

00:50:50.490 --> 00:50:53.600
A portion of the system
memory is allocated as video

00:50:53.600 --> 00:50:56.100
memory for graphics purposes.

00:50:56.500 --> 00:51:54.200
[Transcript missing]

00:51:55.210 --> 00:51:56.370
So, state management.

00:51:56.400 --> 00:52:00.350
So, because the driver has to generate
and compile these kernel programs

00:52:00.580 --> 00:52:03.980
for each stage of the pipeline,
state management becomes very crucial

00:52:04.090 --> 00:52:05.660
for performance on this hardware.

00:52:05.660 --> 00:52:08.760
So, it's very important to
avoid state thrashing.

00:52:08.800 --> 00:52:11.660
By thrashing,
I mean toggling state back and forth.

00:52:11.680 --> 00:52:14.590
Because transitions are very
expensive on this hardware,

00:52:14.590 --> 00:52:17.360
they can force kernel program
recompiles on the driver,

00:52:17.360 --> 00:52:19.250
which is an expensive operation.

00:52:19.260 --> 00:52:24.340
But the driver does have a number
of optimizations to cache the

00:52:24.340 --> 00:52:28.800
kernel programs and the state to
avoid and reduce the recompiles.

00:52:28.880 --> 00:52:33.980
But the amount of checking the driver has
to do to make sure if a particular kernel

00:52:33.980 --> 00:52:39.010
program needs to be compiled or not can
really add up and become a bottleneck.

00:52:39.140 --> 00:52:42.120
And also, there is a limit to the
amount of caching we can do.

00:52:42.120 --> 00:52:46.910
And also, too many state transitions can
result in too many state vectors.

00:52:46.940 --> 00:52:51.210
So, hardware requires the driver to
maintain a state vector heap.

00:52:51.530 --> 00:52:54.280
Basically,
the state heap contains all the

00:52:54.280 --> 00:52:58.120
required state as well as kernel
programs that are required to

00:52:58.120 --> 00:52:59.900
finish a particular draw operation.

00:52:59.900 --> 00:53:02.590
So,
if there are too many state transitions,

00:53:02.620 --> 00:53:04.290
it can result in too many state vectors.

00:53:04.370 --> 00:53:07.720
That means we may have to grow
the state heap at some point.

00:53:07.760 --> 00:53:11.570
And we have to, at some point,
we run out of state heaps.

00:53:11.720 --> 00:53:13.270
So, we have to reallocate heaps.

00:53:13.440 --> 00:53:16.420
So, that will result in full
pipeline flushes in the hardware.

00:53:16.420 --> 00:53:16.920
Which are very important.

00:53:16.920 --> 00:53:16.920
So, we have to reallocate heaps.

00:53:16.920 --> 00:53:16.920
So, that will result in full
pipeline flushes in the hardware.

00:53:16.920 --> 00:53:18.220
And these are very expensive.

00:53:18.270 --> 00:53:21.100
So, it's very important to be
efficient in doing state

00:53:21.170 --> 00:53:23.360
transitions and state management.

00:53:23.360 --> 00:53:26.140
If you can sort your state
to reduce transitions,

00:53:26.140 --> 00:53:29.810
that is actually a great win for
performance on this hardware.

00:53:30.670 --> 00:53:33.600
This hardware, especially because of
its hybrid architecture,

00:53:33.600 --> 00:53:35.520
tend to be field rate limited.

00:53:35.520 --> 00:53:38.000
There are some obvious things you can do.

00:53:38.000 --> 00:53:42.370
Minimize the resolution of the textures,
reducing the size of your render targets.

00:53:42.480 --> 00:53:44.960
That way you are filling
up fewer number of pixels.

00:53:44.960 --> 00:53:45.980
That helps.

00:53:46.100 --> 00:53:49.750
Also,
if you can get away with 16-bit bits

00:53:49.870 --> 00:53:54.460
per pixel as opposed to 24- and 32-bit,
that helps with memory bandwidth.

00:53:54.460 --> 00:53:56.740
So are the compressed textures,
which are currently

00:53:56.820 --> 00:53:58.180
supported on this hardware.

00:53:59.250 --> 00:54:02.770
You can do other things like
using the LOD bias controls,

00:54:02.910 --> 00:54:03.340
for example.

00:54:03.340 --> 00:54:04.980
Choose a smaller size MIP map.

00:54:05.020 --> 00:54:07.760
This helps you with the
better texture cache reuse.

00:54:07.820 --> 00:54:11.390
Of course,
if you are using a smaller size MIP map,

00:54:11.540 --> 00:54:13.800
then you are actually increasing
the blurring in your scene.

00:54:13.800 --> 00:54:15.790
So if you can get away
with some blurring,

00:54:15.790 --> 00:54:18.030
maybe you can go for a
smaller size MIP map.

00:54:18.360 --> 00:54:19.110
That helps.

00:54:19.200 --> 00:54:23.950
Another important thing is
to simplify the shaders.

00:54:23.960 --> 00:54:26.320
The simpler the shaders,
the better it is,

00:54:26.500 --> 00:54:28.360
especially on this hardware.

00:54:28.840 --> 00:54:32.300
Because it's going to keep your
compute time within reason.

00:54:32.460 --> 00:54:35.290
And also it is going to free up
the cores for other threads to run.

00:54:35.400 --> 00:54:36.260
So it helps.

00:54:36.400 --> 00:54:41.200
In particular, if possible,
if you can avoid these complex math

00:54:41.200 --> 00:54:44.150
instructions that I just listed here,
that is actually very

00:54:44.150 --> 00:54:45.600
helpful on this hardware.

00:54:45.600 --> 00:54:49.400
Because there is only one
math box unit that is there

00:54:49.470 --> 00:54:52.220
to do these math instructions.

00:54:52.220 --> 00:54:55.550
And that math box unit is
actually shared by all cores.

00:54:55.700 --> 00:54:58.450
And also almost all these
instructions take multiple rounds.

00:54:58.470 --> 00:55:00.330
So you need to compute multiple rounds
to the math box unit to compute.

00:55:00.460 --> 00:55:04.460
So the more of these
instructions you use,

00:55:04.460 --> 00:55:06.340
the more likelihood
of introducing stalls.

00:55:06.460 --> 00:55:11.970
So this is something to keep in mind when
you are programming to this hardware.

00:55:12.870 --> 00:55:16.820
Also, this hardware supports what
is called the early-Z feature.

00:55:17.060 --> 00:55:20.070
That is,
the hardware is capable of rejecting

00:55:20.120 --> 00:55:25.260
pixels that fail the depth test
before running a frame rate shader.

00:55:25.460 --> 00:55:30.140
This can actually give you
substantial gain in performance,

00:55:30.290 --> 00:55:34.130
especially if depth complexity
in your scene is high.

00:55:34.630 --> 00:55:37.460
Usually, I mean,
this feature automatically

00:55:37.550 --> 00:55:42.030
kicks in whenever possible,
but there are certain OpenGL states that

00:55:42.030 --> 00:55:44.800
can actually disable this LDZ testing.

00:55:44.800 --> 00:55:49.120
For example, one such case is if the
fragment shader manipulates Z.

00:55:49.120 --> 00:55:53.460
Basically, what that means is instead of
using the interpolated depth,

00:55:53.560 --> 00:55:56.940
you are actually calculating your
own depth in the fragment shader.

00:55:56.940 --> 00:55:59.570
That is, you are doing your own Z testing
in the fragment shader.

00:55:59.760 --> 00:56:01.810
Then, obviously,
the hardware doesn't know,

00:56:01.810 --> 00:56:05.270
have access to the source depth,
so it can't do the early Z test

00:56:05.270 --> 00:56:07.220
before the fragment shader is run.

00:56:07.220 --> 00:56:09.690
So,
it has to disable the early Z testing.

00:56:09.700 --> 00:56:15.610
Another condition is if you have stencil
writes enabled and also your stencil

00:56:15.610 --> 00:56:20.250
G fail operation is not set to GL keep,
meaning that whenever a

00:56:20.250 --> 00:56:25.070
pixel fails the depth test,
you want to update the stencil buffer.

00:56:25.120 --> 00:56:28.190
Now, the hardware is actually
capable of doing that.

00:56:28.390 --> 00:56:32.030
That is, as soon as a pixel
fails the early Z test,

00:56:32.030 --> 00:56:33.980
it can update the stencil buffer.

00:56:33.980 --> 00:56:38.570
But if you have alpha testing enabled,
or if you are killing pixels

00:56:38.640 --> 00:56:40.450
in the fragment shader,

00:56:40.710 --> 00:56:43.560
So in these conditions,
even though the pixel

00:56:43.650 --> 00:56:47.090
fails the early-Z test,
the hardware can't immediately update the

00:56:47.090 --> 00:56:50.690
stencil buffer because it doesn't know
if the pixel is going to get killed by

00:56:50.690 --> 00:56:52.540
the alpha test or in the fragment shader.

00:56:52.660 --> 00:56:55.400
So it has to run the fragment
shader and go through the pipeline.

00:56:55.700 --> 00:56:58.840
So you won't get benefit out
of this hardware feature.

00:56:59.070 --> 00:57:03.020
So if you can avoid these two conditions,
actually you can take advantage

00:57:03.020 --> 00:57:04.980
of this early-Z hardware.

00:57:05.820 --> 00:57:08.580
Also, there are some common ways in
which actually you can take

00:57:08.630 --> 00:57:09.720
advantage of early-Z hardware.

00:57:09.720 --> 00:57:12.770
One is to draw the scene front to back.

00:57:12.850 --> 00:57:17.840
So if you can sort your scene and draw
the objects that are on the front first,

00:57:17.840 --> 00:57:21.360
that will help you initialize
the depth buffer with the

00:57:21.360 --> 00:57:23.580
Z values of all visible pixels.

00:57:23.580 --> 00:57:25.740
And then you draw the
objects that are in the back,

00:57:25.740 --> 00:57:29.310
then they get early rejected because
they're going to fail the early-Z test.

00:57:29.430 --> 00:57:31.480
For example, I have a case here.

00:57:31.480 --> 00:57:33.790
The red triangle is in the front,
the blue is in the back,

00:57:33.790 --> 00:57:35.060
and it's occluded by the red.

00:57:35.060 --> 00:57:39.380
So if I draw the red first,
it's going to update the depth buffer

00:57:39.530 --> 00:57:42.000
with the Z values of the red triangle.

00:57:42.000 --> 00:57:44.330
And then I go draw the
blue triangle next,

00:57:44.330 --> 00:57:48.780
it's going to get early rejected because
it's going to fail the early-Z test.

00:57:48.810 --> 00:57:50.870
So this is one way to
take advantage of it.

00:57:50.960 --> 00:57:54.630
There's another common way is
to do a multi-pass approach.

00:57:54.630 --> 00:57:58.680
Do a depth-only pass first,
and then follow by the color pass.

00:57:59.320 --> 00:58:01.890
So with the depth pass,
you disable the color rights.

00:58:01.890 --> 00:58:03.440
You just draw the whole scene.

00:58:03.440 --> 00:58:06.260
That way you are populating
the depth buffer with the

00:58:06.380 --> 00:58:08.420
Z values of all visible pixels.

00:58:08.420 --> 00:58:12.770
And then you could do a color pass,
then all the pixels that are occluded,

00:58:12.770 --> 00:58:14.520
they get early rejected.

00:58:14.520 --> 00:58:19.170
So this technique can bring the depth
complexity in your scene to almost one.

00:58:19.270 --> 00:58:22.380
So it can give you substantial
gain in fill rates.

00:58:22.400 --> 00:58:25.280
But how much gain you actually
get out of these techniques,

00:58:25.280 --> 00:58:29.000
it depends on what kind of overhead
is involved in doing these techniques.

00:58:29.080 --> 00:58:29.300
And what kind of overhead is
involved in doing these techniques.

00:58:29.300 --> 00:58:31.640
And what kind of performance
you get out of early-Z hardware.

00:58:31.640 --> 00:58:35.120
For example,
if your fragment share is simple,

00:58:35.120 --> 00:58:38.860
then you may not get any benefit or
much benefit out of early-Z hardware.

00:58:38.860 --> 00:58:41.020
In those cases,
if you do these techniques,

00:58:41.020 --> 00:58:43.520
then the overhead itself
can become a bottleneck.

00:58:43.620 --> 00:58:46.770
So you need to balance the overhead
with the kind of performance

00:58:46.860 --> 00:58:48.540
you get with early-Z hardware.

00:58:50.920 --> 00:58:53.410
We currently support occlusion queries.

00:58:53.450 --> 00:58:56.140
This is one good way extension to use.

00:58:56.140 --> 00:58:59.900
You can follow the normal bounding
box techniques to only draw those

00:58:59.900 --> 00:59:01.960
portions of the scene that are visible.

00:59:01.960 --> 00:59:05.110
This definitely helps you with frame
rates because you are not drawing certain

00:59:05.310 --> 00:59:07.620
parts of the scene that are not visible,
which is good.

00:59:08.320 --> 00:59:09.480
Also, there's one tidbit.

00:59:09.590 --> 00:59:13.520
If you can combine the color depth
stencil clears into one GL clear call,

00:59:13.520 --> 00:59:17.560
that helps because the driver can
just do all of these in one operation.

00:59:17.670 --> 00:59:20.080
If you separate them out,
then it results in three different

00:59:20.090 --> 00:59:21.120
operations in the driver.

00:59:21.680 --> 00:59:22.580
Something to keep in mind.

00:59:24.400 --> 01:00:32.100
[Transcript missing]

01:00:32.300 --> 01:04:14.300
[Transcript missing]

01:04:14.780 --> 01:04:18.450
So finally, whatever I explained so
far is pretty general.

01:04:18.760 --> 01:04:22.320
So most of it applies to any GPU.

01:04:22.370 --> 01:04:25.880
But it's even more helpful on
this particular hardware because

01:04:25.880 --> 01:04:28.190
of its unique architecture.

01:04:28.400 --> 01:04:28.840
Thank you.

01:04:28.860 --> 01:04:30.630
Thank you for listening.

01:04:31.400 --> 01:04:33.400
I'm back with Chris, I guess.

01:04:33.400 --> 01:04:36.670
Thank you.

01:04:36.740 --> 01:04:37.700
So that's great, Srinivas.

01:04:37.700 --> 01:04:40.230
So...

01:04:40.840 --> 01:04:41.260
Let's see.

01:04:41.260 --> 01:04:45.660
So we've talked a lot about
general optimizations and even got

01:04:45.660 --> 01:04:47.140
NVIDIA and Intel-specific hints.

01:04:47.140 --> 01:04:49.280
They're great to use in general.

01:04:49.280 --> 01:04:54.310
So for any more information,
Alan Schaefer is our evangelist

01:04:54.310 --> 01:04:56.720
for graphics technology.

01:04:56.720 --> 01:04:59.290
His email is here,
aschaefer at apple.com.

01:05:00.520 --> 01:05:03.460
And also, documentation.

01:05:03.460 --> 01:05:08.520
We've got a lot of documentation
at developer.apple.com/opengl.

01:05:08.520 --> 01:05:10.740
And so I recommend that
everyone takes a look there,

01:05:10.810 --> 01:05:18.170
especially like at the
MacÂ OSÂ X OpenGL Programming Guide,

01:05:19.350 --> 01:05:19.350
especially if you're new to MacÂ OSÂ X.

01:05:19.670 --> 01:05:20.770
So some related sessions.

01:05:20.850 --> 01:05:23.720
There aren't really-- this
is the last OpenGL session.

01:05:23.720 --> 01:05:25.780
Hopefully you saw the
earlier two OpenGL sessions.

01:05:25.860 --> 01:05:29.020
But tomorrow,
there's introducing OpenCL and

01:05:29.020 --> 01:05:34.280
Advanced OpenCL both in
Russian Hill at 9:00 and 10:15 AM.

01:05:34.350 --> 01:05:38.930
So if you are interested in doing
computation-type stuff on the

01:05:38.930 --> 01:05:43.120
GPU and seeing potentially how to
also integrate that with OpenGL,

01:05:43.340 --> 01:05:46.380
those should be shown at
those sessions tomorrow.

01:05:46.480 --> 01:05:50.860
And then we have a lab tomorrow
as well for the OpenGL on the Mac.

01:05:51.060 --> 01:05:56.620
And that is at the same time, I think,
as an OpenCL lab as well

01:05:56.620 --> 01:05:57.800
that's across from it.

01:05:57.830 --> 01:05:59.280
I'm not exactly sure
where it is right now.

01:05:59.390 --> 01:06:04.490
But it's at the same time,
2:00 to like 6:15, something like that.

01:06:04.540 --> 01:06:08.430
And if you have a question
that's too complex or not enough

01:06:08.550 --> 01:06:11.560
time to get the question today,
you can always meet us tomorrow then.