WEBVTT

00:00:22.240 --> 00:00:26.200
So thank you, and welcome to Graphics and
Media State of the Union.

00:00:26.440 --> 00:00:30.480
And thanks for staying around
for the last session of the day.

00:00:32.580 --> 00:00:42.730
So past WWCs have been all
about Mac OS the platform.

00:00:42.730 --> 00:00:42.730
And this year is really exciting
because we have a new platform.

00:00:43.230 --> 00:00:46.240
The iPhone OS platform.

00:00:46.240 --> 00:00:50.030
And many of the sessions you're going
to be going to this week will be

00:00:50.330 --> 00:00:53.400
talking about both of these platforms.

00:00:55.190 --> 00:01:00.090
And for this session,
the theme that we're going to use,

00:01:00.150 --> 00:01:06.230
one of the themes we're going to use,
is we're going to emphasize

00:01:06.230 --> 00:01:06.230
the importance of scalability.

00:01:07.210 --> 00:01:12.050
And a great example of
scalability is display sizes.

00:01:12.190 --> 00:01:16.680
You want your graphics to look good
on everything from the iPhone all the

00:01:16.800 --> 00:01:19.460
way up to this huge display behind us.

00:01:19.520 --> 00:01:25.020
So we're going to be talking
about that as a theme of the

00:01:25.020 --> 00:01:28.980
technologies that we are going to be
delivering in the iPhone and Mac OS.

00:01:30.050 --> 00:01:32.660
So there's other important variables.

00:01:32.660 --> 00:01:37.050
CPU differences, GPU differences,
they vary in power, performance,

00:01:37.110 --> 00:01:39.220
storage size, memory.

00:01:39.220 --> 00:01:40.850
You have to be efficient with all these.

00:01:40.850 --> 00:01:46.290
And with mobile users becoming more
and more part of the product line

00:01:46.360 --> 00:01:51.260
and what we're selling to people,
we want your applications to be as

00:01:51.260 --> 00:01:55.820
efficient and give your users the
best mobile experience possible.

00:01:55.820 --> 00:01:58.680
So you want to be
efficient with batteries.

00:02:01.890 --> 00:02:07.640
So Apple has a wealth of technologies.

00:02:07.640 --> 00:02:09.490
And today,
we're going to focus in on a few

00:02:09.490 --> 00:02:12.350
key graphics and media technologies.

00:02:13.910 --> 00:02:15.900
And importantly,
we're going to talk about how Apple has

00:02:15.900 --> 00:02:20.460
taken these technologies and scaled them
across the iPhone OS and the Mac OS.

00:02:20.740 --> 00:02:23.740
Many of them are common,
and then there's a few that

00:02:23.760 --> 00:02:24.600
are going to be different.

00:02:24.690 --> 00:02:28.580
And we're going to talk about those
and focus on these key technologies.

00:02:29.390 --> 00:02:32.210
So we're going to talk about graphics,
we're going to talk about media,

00:02:32.310 --> 00:02:35.500
and then we're going to talk about
getting access to that great graphics

00:02:35.500 --> 00:02:37.740
and media technology through the web.

00:02:39.780 --> 00:02:42.800
So, let's start with graphics.

00:02:42.800 --> 00:02:46.100
At the heart of graphics is the GPU.

00:02:46.180 --> 00:02:50.600
And GPUs have been getting
incredibly fast over the years.

00:02:50.600 --> 00:02:55.900
As many of you saw in Bertrand's session,
this chart, GPUs have been growing

00:02:55.900 --> 00:03:00.090
in power and performance,
and they're just an incredible

00:03:00.840 --> 00:03:03.570
asset to use for graphics and media.

00:03:03.580 --> 00:03:08.040
But an interesting trend that
has been happening along that

00:03:08.390 --> 00:03:10.700
time has been their features.

00:03:10.830 --> 00:03:16.840
Back in 2000, 2002,
GPUs were largely fixed function devices.

00:03:16.920 --> 00:03:29.010
And the way I look at that is that they
were largely designed for a specific API,

00:03:29.010 --> 00:03:29.550
meaning they provided the features
necessary to accelerate and rasterize

00:03:30.330 --> 00:03:33.140
for a particular API.

00:03:33.140 --> 00:03:35.780
And then came along shaders,
the ability to write programs

00:03:35.780 --> 00:03:37.970
and to upload them onto the GPU.

00:03:37.980 --> 00:03:42.950
And this enabled a whole new array of
possibilities of what you could do.

00:03:42.980 --> 00:03:49.270
And we started seeing all
kinds of new technologies

00:03:49.270 --> 00:03:49.270
and new imaging applications,
what you could accelerate.

00:03:50.100 --> 00:03:53.500
But recently,
GPUs started taking on some new features.

00:03:53.610 --> 00:03:59.530
And we look at those as compute features,
features that started making the

00:03:59.540 --> 00:04:02.600
GPU look more and more like the CPU.

00:04:03.400 --> 00:04:06.340
So what do we mean by compute features?

00:04:06.350 --> 00:04:08.640
The first thing is precision.

00:04:08.910 --> 00:04:14.090
IEEE floating-point mathematics,
the ability to accelerate high-precision,

00:04:14.140 --> 00:04:16.940
IEEE-compliant mathematics on the GPU.

00:04:16.970 --> 00:04:23.710
And this is incredibly important
for many types of algorithms you're

00:04:23.710 --> 00:04:23.710
going to want to run if you're
going to target it for the GPU.

00:04:24.410 --> 00:04:26.730
The second being flow control.

00:04:26.880 --> 00:04:31.650
And what I mean by flow control is the
ability to manage tasks on the GPU to

00:04:31.650 --> 00:04:36.130
be able to control their execution.

00:04:37.440 --> 00:04:39.540
And third, memory access.

00:04:39.680 --> 00:04:44.720
Have a better, more flexible ability to
read and write to memory.

00:04:45.460 --> 00:04:49.140
And together, these three things,
these three groups of features,

00:04:49.270 --> 00:04:53.000
we call compute capabilities
that GPUs are taking on.

00:04:53.200 --> 00:04:56.740
And with that, as you've seen,
we introduced a new

00:04:56.740 --> 00:04:59.050
technology called OpenCL.

00:04:59.170 --> 00:05:03.040
And OpenCL stands for
Open Compute Library.

00:05:03.040 --> 00:05:08.330
So, let's talk a little bit about that.

00:05:09.620 --> 00:05:14.240
So OpenCL is designed to leverage
the compute features of the GPU.

00:05:14.270 --> 00:05:15.340
But it's not just for the GPU.

00:05:15.340 --> 00:05:17.910
It's for the CPU and the GPU.

00:05:17.950 --> 00:05:20.260
It's optimized for both.

00:05:20.290 --> 00:05:21.570
It has an easy programming model.

00:05:21.730 --> 00:05:23.820
That was really,
really important when we designed it.

00:05:23.850 --> 00:05:26.520
We wanted it to be as simple as possible.

00:05:26.680 --> 00:05:34.660
We made it integrated with OpenGL such
that they played well together.

00:05:34.660 --> 00:05:34.660
They complement each other.

00:05:36.010 --> 00:05:42.680
So let's talk about how we have made it
leverage the compute features of the GPU.

00:05:42.910 --> 00:05:47.170
Traditional shader languages allowed
you to read from multiple locations

00:05:47.710 --> 00:05:50.470
and then write to a single location.

00:05:50.920 --> 00:05:53.680
With OpenCL,
the language allows you to read

00:05:53.680 --> 00:05:57.490
from multiple locations and
write to multiple locations.

00:05:57.490 --> 00:06:01.140
And this is what I meant by
more flexible memory access.

00:06:01.280 --> 00:06:05.440
And this is what will enable
you to have greater flexibility,

00:06:05.440 --> 00:06:08.990
what kind of problems,
what kind of algorithms you

00:06:08.990 --> 00:06:11.140
can accelerate on the GPU.

00:06:11.140 --> 00:06:13.260
This is a key feature.

00:06:14.700 --> 00:06:19.080
Another feature is what
we call atomic operations.

00:06:19.100 --> 00:06:22.530
And what that means is the ability
to go and increment or decrement a

00:06:22.530 --> 00:06:26.400
value in memory in a way that you're
guaranteed to get the right result.

00:06:26.990 --> 00:06:30.320
Because you have many tasks running,
many work queues trying

00:06:30.860 --> 00:06:34.870
to access that memory,
and you need to be able to synchronize

00:06:34.870 --> 00:06:39.770
and to change memory and guarantee
that that increment or decrementing

00:06:39.790 --> 00:06:42.560
of that value is going to be correct.

00:06:42.650 --> 00:06:45.560
So this is important to
a series of algorithms,

00:06:45.560 --> 00:06:51.780
and we found that as we write OpenSeal
algorithms that we use this quite a bit.

00:06:53.480 --> 00:06:54.300
So flow control.

00:06:54.300 --> 00:06:56.060
I mentioned that a little bit.

00:06:56.210 --> 00:07:00.200
So we offer a feature in OpenSeal,
the language, called barriers.

00:07:00.200 --> 00:07:03.880
And what barriers means is that
all your tasks will proceed

00:07:03.880 --> 00:07:05.830
to a certain point and stop.

00:07:05.910 --> 00:07:08.720
They will all synchronize,
like cars coming up to a stoplight.

00:07:08.840 --> 00:07:09.330
And they will stop.

00:07:09.380 --> 00:07:12.280
Once they all get there,
then they'll be allowed to continue.

00:07:12.280 --> 00:07:15.900
So this gives you some control
over the execution of the tasks

00:07:15.900 --> 00:07:17.780
that are running on the GPU.

00:07:20.650 --> 00:07:25.270
So let's talk about how we
optimize it for the CPU and GPU.

00:07:27.480 --> 00:07:29.870
First, I want to look a little
bit at kind of what,

00:07:30.070 --> 00:07:32.480
how we integrate this
into your application.

00:07:32.480 --> 00:07:36.820
So the first thing you have to do when
you integrate this into your application,

00:07:36.820 --> 00:07:41.160
you have to find the compute-intensive
chunk of code in your application.

00:07:41.190 --> 00:07:49.090
And you take that and you
write it into an OpenCL kernel.

00:07:49.090 --> 00:07:49.090
You take that along with the data,

00:07:49.730 --> 00:07:52.470
and you send it to the OpenCL framework.

00:07:52.470 --> 00:07:55.630
And the OpenCL framework
will take that kernel,

00:07:55.630 --> 00:07:58.890
runtime compile it,
and then send that data down to

00:07:58.960 --> 00:08:03.600
the compute device with the kernel
that has been runtime compiled.

00:08:03.740 --> 00:08:08.600
Now,
the compute device can be CPUs and GPUs.

00:08:08.960 --> 00:08:11.920
and the complexities of what
a compute device can look like

00:08:11.920 --> 00:08:13.740
is actually quite complex.

00:08:13.880 --> 00:08:15.990
It can have a hierarchy of memory.

00:08:16.190 --> 00:08:19.400
It literally can have
hundreds of compute units.

00:08:19.730 --> 00:08:22.080
But OpenCL,

00:08:22.650 --> 00:08:26.300
gives you a programming model for talking
to this hardware that makes it easy.

00:08:26.300 --> 00:08:33.280
It abstracts that complexity
away so that you can get at

00:08:33.280 --> 00:08:33.280
that computational horsepower.

00:08:35.020 --> 00:08:37.360
So, let's look at a demo.

00:08:37.410 --> 00:08:41.360
Now, this demo was one that you

00:08:41.750 --> 00:08:47.110
have seen in Bertrand's session,
but I thought it was so good,

00:08:47.110 --> 00:08:49.720
I had to show it again for
those who may not have seen it.

00:08:51.600 --> 00:08:59.840
Now, what this demo shows is taking a
complex problem like a gravitational

00:08:59.840 --> 00:09:05.310
simulation where you have 16,000 stars,
each one feeling the gravitational

00:09:05.420 --> 00:09:06.900
effects of the other.

00:09:07.000 --> 00:09:08.270
So it's an N-squared problem.

00:09:08.280 --> 00:09:14.610
And what we're doing right now is we
have taken that code and we've just

00:09:14.610 --> 00:09:18.190
compiled it like you normally would,
and we're running it on the CPU.

00:09:18.370 --> 00:09:21.510
So a single core, and we're running it,
and it's getting two

00:09:21.510 --> 00:09:23.360
gigaflops of compute power.

00:09:23.500 --> 00:09:28.230
So gigaflops stands for billions of
floating-point operations per second.

00:09:28.380 --> 00:09:38.090
Now, what we do,
as I just showed in the diagram,

00:09:38.090 --> 00:09:38.090
is we take that code and we
move it to OpenSeal as a kernel.

00:09:38.330 --> 00:09:42.460
and OpenSeal runtime compiles it
and optimizes it for the compute

00:09:42.460 --> 00:09:44.980
device that you're targeting.

00:09:45.320 --> 00:09:48.370
Now, OpenCL,
with the language that it enables

00:09:48.370 --> 00:09:52.310
you to write the kernel language in,
is it targets the vector

00:09:52.390 --> 00:09:54.340
instructions of the CPU.

00:09:54.340 --> 00:09:57.050
And by doing that,
that's how we've gone from

00:09:57.110 --> 00:09:59.480
2 gigaflops to 11 gigaflops.

00:09:59.580 --> 00:10:03.240
Now, OpenCL is built on top of
Grand Central Dispatch.

00:10:03.240 --> 00:10:07.680
And what that allows us to do, then,
is very easily tell OpenCL to run

00:10:07.680 --> 00:10:09.940
this across all the CPU cores.

00:10:11.440 --> 00:10:16.300
So by doing that,
now we've gone from 2 gigaflops to 67.

00:10:16.960 --> 00:10:19.720
So now we're running across
all eight cores of the system,

00:10:19.720 --> 00:10:24.450
and we're running with the
SSE instruction set native to these CPUs.

00:10:25.570 --> 00:10:28.110
So OpenSeal runs across CPUs and GPUs.

00:10:28.420 --> 00:10:32.200
I can take that same piece of code
now and have it execute on the GPU.

00:10:32.450 --> 00:10:36.760
And by doing that,
we go to 105 gigaflops.

00:10:36.890 --> 00:10:39.790
So that's a pretty
incredible performance boost.

00:10:40.130 --> 00:10:42.600
And further,
what we can do is we can have

00:10:42.830 --> 00:10:44.920
it run across CPUs and GPUs.

00:10:44.940 --> 00:10:48.630
So I can have it run across both.

00:10:49.610 --> 00:10:53.120
And that takes us up to
almost about 240 gigaflops.

00:10:53.500 --> 00:10:56.140
And remember,
we started off at 2 gigaflops.

00:10:56.280 --> 00:10:59.100
Now we're up at 240.

00:10:59.220 --> 00:11:01.950
And we did this by not
writing any assembly,

00:11:02.250 --> 00:11:05.060
by writing still C code.

00:11:05.200 --> 00:11:08.550
So here's the demo I've shown,
which is the collision,

00:11:08.660 --> 00:11:11.700
simulating the collision between the
Andromeda and the Milky Way galaxy.

00:11:11.990 --> 00:11:14.440
This is actually real data that we got.

00:11:14.540 --> 00:11:17.590
And this is simulating Earth,
the blue dot.

00:11:18.770 --> 00:11:22.540
And I'll let it run a little
longer so you can see that

00:11:23.270 --> 00:11:30.530
things don't go well for Earth.

00:11:30.530 --> 00:11:30.530
So let's go back to slides.

00:11:35.730 --> 00:11:38.600
Okay, so easy programming model.

00:11:38.620 --> 00:11:41.360
What do I mean by that?

00:11:41.550 --> 00:11:45.190
So the kernel language
in OpenCL is just C.

00:11:45.750 --> 00:11:51.100
Based off of C99, plain vanilla C,
so that's really easy.

00:11:51.890 --> 00:11:53.960
So I mentioned it's runtime
compiled and optimized.

00:11:53.960 --> 00:11:57.500
We have real compiler technology
underneath OpenCL that

00:11:57.500 --> 00:11:59.220
gives you optimal code.

00:11:59.230 --> 00:12:03.190
And that's optimal for whether
you're targeting the CPUs or GPUs.

00:12:04.410 --> 00:12:07.320
So we took C99 and we
added some data types.

00:12:07.470 --> 00:12:10.880
We added vectors for getting
access to the vector instructions

00:12:10.970 --> 00:12:14.280
of the compute device,
whether it be a CPU or GPU.

00:12:14.310 --> 00:12:17.570
We added image data types,
making it easy to use

00:12:17.720 --> 00:12:19.640
for imaging or graphics.

00:12:19.690 --> 00:12:23.650
And we added address qualifiers,
giving you some access,

00:12:23.650 --> 00:12:27.400
some control over the memory
hierarchy of a device.

00:12:28.320 --> 00:12:32.790
We also provide a full math lib,
so the same math functions you're used

00:12:32.820 --> 00:12:36.000
to when you're programming C normally.

00:12:36.370 --> 00:12:40.660
The same IEEE compliant math.h.

00:12:40.660 --> 00:12:42.840
So let's look at what a
compute kernel looks like.

00:12:42.890 --> 00:12:44.740
It just looks like C.

00:12:44.750 --> 00:12:48.800
I've highlighted the things that
are not traditional C in orange.

00:12:48.800 --> 00:12:52.260
Let me zoom in a little bit
so we can get a look at that.

00:12:52.260 --> 00:12:57.090
For the most part, it just looks like C.

00:12:57.090 --> 00:12:57.090
And this is basically what I was
just showing you in the demo.

00:12:59.100 --> 00:13:05.140
Okay, so as I said,
it's fully integrated with OpenGL.

00:13:05.690 --> 00:13:09.090
And let's look at that
a little bit closer.

00:13:09.090 --> 00:13:13.570
So traditionally,
OpenGL takes two types of inputs.

00:13:13.670 --> 00:13:16.360
It takes textures and it takes geometry.

00:13:16.360 --> 00:13:19.840
So your application traditionally
will be taking static textures

00:13:19.840 --> 00:13:22.980
and static geometry and passing
it to the OpenGL framework,

00:13:23.080 --> 00:13:26.240
and then OpenGL will be using
that to render using the GPU.

00:13:26.240 --> 00:13:32.400
Now, what OpenCL allows you to do
is you can take that and have a

00:13:32.590 --> 00:13:37.360
compute kernel with your data,
and you can use that to feed

00:13:37.430 --> 00:13:42.880
OpenCL and have OpenCL dynamically
generate texture and vertex data.

00:13:42.880 --> 00:13:47.740
So you can have a scene that is
dynamic and interactive by using

00:13:48.270 --> 00:13:53.500
OpenCL as the front end for OpenGL,
and it can all be accelerated

00:13:53.560 --> 00:13:55.680
either on CPU or GPU.

00:13:55.680 --> 00:13:59.230
So I'm gonna show you
a demo of doing that.

00:14:04.360 --> 00:14:12.030
So, what I have here is I have a bunny,
and he's sitting in a

00:14:12.030 --> 00:14:13.440
nicely rendered room.

00:14:13.450 --> 00:14:16.900
And traditionally,
OpenGL has been good at rendering, right?

00:14:16.900 --> 00:14:18.890
So this looks like something
you could do with OpenGL.

00:14:18.900 --> 00:14:24.080
But what is really interesting about
this is that I'm using OpenCL to

00:14:24.080 --> 00:14:27.160
generate this fluid-like looking bunny.

00:14:27.160 --> 00:14:31.590
And I can actually prove that
he's fluid because I can melt

00:14:31.590 --> 00:14:34.170
him into a puddle on the floor.

00:14:34.300 --> 00:14:40.620
So what we're doing is we're
actually using OpenCL to simulate

00:14:40.620 --> 00:14:44.200
fluid and make it interactive,
make it an interactive

00:14:44.200 --> 00:14:45.400
part of this environment.

00:14:45.550 --> 00:14:49.350
So what I can do now is I can
actually interact with this fluid.

00:14:49.700 --> 00:14:53.560
So this is a fluid simulation
running on the GPU.

00:14:53.860 --> 00:14:56.580
So that bunny was actually a liquid
that we held in a little container,

00:14:56.580 --> 00:14:59.390
and we released the container,
and he flowed into this puddle.

00:14:59.510 --> 00:15:03.650
So this shows you how you can use
OpenCL to simulate real physical effects

00:15:04.050 --> 00:15:06.590
and accelerate all of that on the GPU.

00:15:06.710 --> 00:15:11.550
So let's go back to slides.

00:15:15.370 --> 00:15:21.590
So OpenCL runs on all
Snow Leopard platforms on the CPU.

00:15:22.230 --> 00:15:26.570
And it runs on a select set of models,
GPU accelerated,

00:15:26.630 --> 00:15:32.330
and that is the select MacBook Pro, iMac,
and Mac Pro models.

00:15:33.600 --> 00:15:36.940
So we talked a little bit
about the details of OpenCL.

00:15:36.960 --> 00:15:37.810
What else can it do?

00:15:37.960 --> 00:15:41.190
Well, just to go over some things,
it's really good for

00:15:41.190 --> 00:15:42.680
graphics and imaging.

00:15:42.700 --> 00:15:47.830
It's good for scientific visualization,
physics, you name it.

00:15:47.880 --> 00:15:53.400
Really, any data-intensive algorithm,
you can use OpenCL to

00:15:53.400 --> 00:15:53.400
accelerate and to optimize.

00:15:53.710 --> 00:15:59.800
So we think it's going to be really
good for getting access to all that

00:15:59.800 --> 00:15:59.800
computing horsepower on the system.

00:16:00.640 --> 00:16:05.610
Now,
OpenCL is an Apple-developed technology

00:16:07.270 --> 00:16:13.290
and Apple worked in conjunction
with industry leaders to define

00:16:13.870 --> 00:16:14.170
the OpenCL specification.

00:16:16.860 --> 00:16:20.650
And we're taking that specification,
Apple is taking that specification as

00:16:20.650 --> 00:16:23.340
a proposed open standard to Kronos.

00:16:23.470 --> 00:16:28.760
So we think that making OpenCL an
industry standard is going to be great.

00:16:29.010 --> 00:16:31.860
We think it's going to
be fantastic for you,

00:16:32.170 --> 00:16:35.020
developers, to be able to access this
across all the platforms.

00:16:44.180 --> 00:16:45.200
So that's OpenCL.

00:16:45.210 --> 00:16:48.900
Leverages the GPU,
optimized for the CPU and GPU,

00:16:48.940 --> 00:16:51.400
easy programming model so
you can make use of it,

00:16:51.580 --> 00:16:55.290
not a lot of work,
fully integrated with OpenGL.

00:16:56.860 --> 00:17:02.490
and it's new in Snow Leopard and on the
disc that you can get Snow Leopard Seed.

00:17:05.000 --> 00:17:15.800
[Transcript missing]

00:17:16.100 --> 00:17:22.390
It is, it enables this by
making animations easy.

00:17:24.110 --> 00:17:29.240
So core animation is at the heart
of the iPhone user experience.

00:17:29.320 --> 00:17:33.000
It is what drives the
iPhone interactivity.

00:17:33.070 --> 00:17:37.500
The UI in the iPhone is built
directly on top of the core

00:17:37.510 --> 00:17:40.510
animation that is on the iPhone.

00:17:40.840 --> 00:17:42.900
So let's look at some examples.

00:17:43.020 --> 00:17:44.030
So CoverFlow.

00:17:44.330 --> 00:17:46.700
CoverFlow is built with Core Automation.

00:17:46.700 --> 00:17:52.700
It's a good example of an immersive,
interactive user experience.

00:17:52.780 --> 00:17:56.690
You can use it for heads-up displays
over media and other content.

00:17:59.230 --> 00:18:06.650
So what I want to show is a demo
that we showed a couple years ago.

00:18:08.000 --> 00:18:13.720
at WWC when we introduced
coordination for Snow Leopard.

00:18:25.530 --> 00:18:34.030
So what we have here is we have a
core animation application where every

00:18:34.180 --> 00:18:34.230
tile here is a core animation layer.

00:18:34.550 --> 00:18:40.450
And these layers can be animated
and animated in 3D space.

00:18:42.170 --> 00:18:46.760
The animation is being automatically
controlled by core animation.

00:18:46.800 --> 00:18:51.020
It's what is making these things
move smoothly through space.

00:18:51.070 --> 00:18:54.110
You just set the
beginning and end states,

00:18:54.190 --> 00:18:58.160
and it animates through all
the positions that you need to

00:18:58.250 --> 00:19:00.590
to get the smooth animation.

00:19:07.510 --> 00:19:12.920
So one of the things that we are
showing here is really pushing

00:19:12.920 --> 00:19:15.420
the limits of core animation.

00:19:15.430 --> 00:19:18.080
This is over 300 layers.

00:19:18.450 --> 00:19:20.510
And this is very similar to the
demo we showed two years ago.

00:19:20.520 --> 00:19:24.060
And what we want to show here is that
all the power that we've been giving

00:19:24.060 --> 00:19:29.630
you through Core Animation on the
desktop is available on the phone.

00:19:29.690 --> 00:19:32.350
So you can make great animations.

00:19:42.780 --> 00:19:48.450
So Core Animation is also on the desktop,
Mac OS.

00:19:48.470 --> 00:19:52.450
And new for Snow Leopard,
we've added a particle systems engine,

00:19:52.580 --> 00:19:56.750
transform layers and gradient layers,
so some new ways to make

00:19:57.330 --> 00:20:00.610
new layer behaviors.

00:20:03.090 --> 00:20:05.280
So that's Core Automation,
and we think Core Automation is a

00:20:05.280 --> 00:20:09.840
really key technology for building
immersive user experiences.

00:20:12.080 --> 00:20:13.740
So let's talk about OpenGL.

00:20:13.740 --> 00:20:17.880
OpenGL was traditionally
a desktop technology.

00:20:19.210 --> 00:20:26.760
And recently,
a smaller version of it has come

00:20:26.760 --> 00:20:29.460
into existence called OpenGL ES,
and that's what we have on the iPhone.

00:20:33.080 --> 00:20:36.240
So let's talk a little
bit more about OpenGL ES.

00:20:36.450 --> 00:20:40.950
So OpenGL ES is a scaled
version of its big brother.

00:20:41.130 --> 00:20:43.620
It's a simplified API.

00:20:44.940 --> 00:20:50.210
But it's an industry standard,
just like the desktop version of OpenGL.

00:20:51.850 --> 00:20:56.000
And on the iPhone,
we deliver OpenGL ES 1.1.

00:20:56.010 --> 00:20:58.600
It's GPU accelerated with
a lightning-fast GPU,

00:20:58.600 --> 00:21:00.940
as you saw in the games in the keynote.

00:21:01.090 --> 00:21:05.900
This thing is going to be great
for building really great graphics.

00:21:06.230 --> 00:21:12.600
So, Core Animation is the layers
that OpenGL ES renders into.

00:21:12.690 --> 00:21:15.460
So what that means is that when
you render with OpenGL ES into

00:21:15.460 --> 00:21:18.070
a Core Animation layer,
you can use that to do all

00:21:18.070 --> 00:21:21.340
the great things that we were
showing with Core Animation with

00:21:21.340 --> 00:21:23.490
OpenGL ES rendered into that layer.

00:21:23.610 --> 00:21:28.810
So it's integrated into the heart
of the display system on the iPhone.

00:21:30.750 --> 00:21:34.830
So let's do a little comparison
between OpenGL ES on iPhone

00:21:35.120 --> 00:21:37.400
and OpenGL on the desktop.

00:21:37.480 --> 00:21:41.060
First, we have all the great
optimized paths of OpenGL,

00:21:41.060 --> 00:21:42.780
vertex arrays, multi-texturing.

00:21:42.780 --> 00:21:46.400
The simplified API part of
that is that we've removed the

00:21:46.400 --> 00:21:50.150
APIs that are less efficient,
like immediate mode paths for

00:21:50.450 --> 00:21:52.830
passing geometry into OpenGL ES.

00:21:52.830 --> 00:21:55.870
It has depth buffers, stencil buffers,
and multi-sampling,

00:21:55.920 --> 00:21:58.920
the same types of buffers
you're used to on the desktop.

00:21:58.920 --> 00:22:01.020
It does not have shaders.

00:22:01.020 --> 00:22:11.810
It's a fixed function API.

00:22:11.850 --> 00:22:11.850
So let's look at a
demo of this in action.

00:22:23.340 --> 00:22:25.450
So this is a demo that some of
the engineers at Apple wrote

00:22:25.620 --> 00:22:29.450
to kind of test and to really
push the limits of the iPhone.

00:22:29.460 --> 00:22:36.540
This is a little game,
which I'm traditionally pretty bad at.

00:23:07.630 --> 00:23:11.440
Okay, so OpenGL ES is really
great on the phone.

00:23:11.660 --> 00:23:17.070
It's going to enable all kinds of great
immersive high-performance graphics.

00:23:18.560 --> 00:23:21.890
So, let's talk about
optimizing for the iPhone.

00:23:21.910 --> 00:23:24.670
Memory is going to be limited.

00:23:24.810 --> 00:23:30.270
On the iPhone,
you have 24 megabytes of memory for

00:23:30.270 --> 00:23:30.270
use for textures and for surfaces.

00:23:30.700 --> 00:23:35.080
To help optimize for that,
we've enabled compressed textures.

00:23:35.270 --> 00:23:37.930
We highly encourage you to
compress all your texture data.

00:23:38.100 --> 00:23:41.900
That'll give you a large savings
in how much texture space

00:23:41.900 --> 00:23:44.290
you're using with your content.

00:23:45.610 --> 00:23:48.950
And the OpenGL ES is enabled
in the iPhone simulator,

00:23:48.950 --> 00:23:52.960
letting you write all the same
OpenGL code on the simulator and

00:23:52.960 --> 00:23:57.250
test it and run it on the simulator
before you upload it on the device

00:23:57.250 --> 00:23:59.810
for really seeing how it performs.

00:23:59.980 --> 00:24:02.710
Now, when you upload it on the iPhone,

00:24:02.990 --> 00:24:04.080
We have instruments.

00:24:04.160 --> 00:24:12.700
Instruments give you real-time tools
for profiling and optimizing for iPhone.

00:24:12.710 --> 00:24:15.510
It's the same types of tools that
you're used to on our desktop,

00:24:15.760 --> 00:24:17.560
such as the OpenGL driver monitor.

00:24:17.630 --> 00:24:22.880
Same types of great tools are
built right into instruments.

00:24:22.900 --> 00:24:27.660
So that's OpenGL and OpenGL ES.

00:24:29.630 --> 00:24:31.660
Now let's talk about color.

00:24:31.770 --> 00:24:37.750
So Apple has been a leader in color
management and color technology.

00:24:37.860 --> 00:24:41.290
And I want to talk a little bit
about what we're doing to make

00:24:41.390 --> 00:24:44.770
that even better on Mac OS X.

00:24:45.790 --> 00:24:48.020
So display gamma.

00:24:48.110 --> 00:24:51.390
So when Mac OS was first introduced,

00:24:51.780 --> 00:24:54.800
Display Gamma of 1.8 was chosen.

00:24:54.840 --> 00:24:59.320
And since then,
the web has come along and has chosen

00:24:59.610 --> 00:25:04.180
a display default gamma of 2.2.

00:25:04.180 --> 00:25:07.500
Media has chosen a gamma of 2.2.

00:25:07.500 --> 00:25:12.490
So we've decided that it's time
to switch Mac OS to gamma 2.2.

00:25:16.900 --> 00:25:23.640
So we're going to be doing
that in Snow Leopard.

00:25:23.640 --> 00:25:23.640
And in fact, the seed you have,
we've already switched it.

00:25:25.170 --> 00:25:27.320
So now the question is, what do you do?

00:25:27.350 --> 00:25:30.120
What does that mean for you?

00:25:30.120 --> 00:25:32.210
Well, it means nothing.

00:25:32.360 --> 00:25:34.310
You don't have to do anything.

00:25:34.860 --> 00:25:39.270
If, with some caveats,
you're already using modern

00:25:39.270 --> 00:25:44.920
APIs and your application is
tagging your media and graphics.

00:25:45.070 --> 00:25:52.260
So if you're not doing that,
we encourage you to move on to modern

00:25:52.260 --> 00:25:55.660
APIs and tag all your content because
we want Mac OS X to be a color-managed

00:25:55.660 --> 00:25:55.660
system from the top to the bottom.

00:25:58.020 --> 00:26:00.660
So now let's talk about
what's new for Snow Leopard.

00:26:00.680 --> 00:26:03.900
What are we adding to
our color management?

00:26:03.970 --> 00:26:09.350
First, we're adding the ability to tag
windows with a color sync profile.

00:26:10.110 --> 00:26:15.300
Second, we're adding 64-bit and
128-bit window depth.

00:26:15.570 --> 00:26:20.170
So 64 and 128 bits per pixel

00:26:21.270 --> 00:26:23.300
You'll be able to get
that into a window now.

00:26:23.320 --> 00:26:26.490
And what this means is we're
driving color management and

00:26:26.550 --> 00:26:31.200
deeper pixels deeper into Mac OS X,
making it an even better

00:26:31.200 --> 00:26:33.290
platform for color.

00:26:36.910 --> 00:26:40.640
So that's ColorSync.

00:26:40.690 --> 00:26:44.740
So we've talked about OpenCL,
we've talked about core animation,

00:26:44.780 --> 00:26:47.420
talked about OpenGL,
and we've talked about color.

00:26:48.220 --> 00:26:51.780
And that's the graphics that
we want to talk about today.

00:26:51.910 --> 00:26:53.510
So now let's talk about media.

00:26:53.590 --> 00:26:59.100
And to do that, I'm going to invite
Tim Bienz up to cover media.

00:27:07.650 --> 00:27:08.440
Hi, John.

00:27:08.440 --> 00:27:10.440
Good afternoon, everyone.

00:27:10.440 --> 00:27:11.140
I'm Tim.

00:27:11.280 --> 00:27:14.800
As you heard John talk about
iPhone and desktop Mac OS and

00:27:14.800 --> 00:27:18.360
scaling technologies between them,
most of the scaling you heard

00:27:18.360 --> 00:27:22.200
about was bringing technologies
from the desktop down to iPhone.

00:27:22.200 --> 00:27:26.080
However, it's also possible for
technologies to scale the other

00:27:26.080 --> 00:27:28.030
way from iPhone back to Mac OS.

00:27:28.030 --> 00:27:32.660
We'd like to take a look at today at
Quick Time and Core Audio which provide

00:27:32.700 --> 00:27:35.450
examples of scaling in both directions.

00:27:35.450 --> 00:27:37.960
Let's start with Quick Time.

00:27:37.960 --> 00:27:40.280
To do that,
let's go back two years ago to

00:27:40.300 --> 00:27:44.600
the graphics and media state
of the union here at WWDC.

00:27:44.700 --> 00:27:46.960
At that time, we told you the following.

00:27:46.960 --> 00:27:48.680
Look at the first point
on the slide here.

00:27:48.820 --> 00:27:51.510
Using our high-level Cocoa APIs is
the best way to ensure

00:27:51.510 --> 00:27:53.430
compatibility with the future.

00:27:53.430 --> 00:27:56.250
Secondly,
we were undertaking a bunch of work in

00:27:56.250 --> 00:27:59.750
our low-level engine to modernize it.

00:27:59.960 --> 00:28:06.130
And although we couldn't tell you
at the time what the reason was,

00:28:06.130 --> 00:28:06.130
there was a reason,
and the reason was iPhone.

00:28:06.290 --> 00:28:09.000
The desktop code base we
had was not really suitable

00:28:09.000 --> 00:28:11.840
for scaling down to iPhone,
and so we had to undertake development

00:28:11.920 --> 00:28:13.640
of a new code base for use on iPhone.

00:28:13.640 --> 00:28:17.100
In doing so,
we had three guiding principles.

00:28:17.100 --> 00:28:20.470
First of all,
whatever we did needed to be portable.

00:28:20.480 --> 00:28:22.990
We knew it had to run
on the iPhone processor.

00:28:23.100 --> 00:28:26.120
In addition, we knew it had to run on the
Intel processors in the desktop.

00:28:26.260 --> 00:28:29.800
Secondly,
whatever we did had to be modular.

00:28:29.800 --> 00:28:33.360
We knew we needed a system where we
could pick and choose pieces and features

00:28:33.360 --> 00:28:34.870
to deploy on individual products.

00:28:35.060 --> 00:28:38.640
We couldn't have a system where
we're sort of all or nothing.

00:28:38.700 --> 00:28:42.600
Third, whatever we did had to be
efficient and performant.

00:28:42.630 --> 00:28:45.430
And this means a lot of different
things in a lot of different contexts.

00:28:45.540 --> 00:28:54.170
But for battery-powered systems,
which as you know are becoming

00:28:54.180 --> 00:28:54.470
more and more important,
one of the extremely important attributes

00:28:54.470 --> 00:28:54.470
of efficiency is battery lifetime.

00:28:55.200 --> 00:28:58.520
So, we implemented based on these three
principles and hopefully you've all

00:28:58.520 --> 00:29:02.070
had a chance to enjoy the really
great video quality we have on iPhone,

00:29:02.070 --> 00:29:05.980
be it displaying content from the web,
or from the iTunes store,

00:29:05.980 --> 00:29:07.640
or from any other source.

00:29:07.690 --> 00:29:11.380
We're really happy with the way the
video work on the iPhone turned out.

00:29:11.570 --> 00:29:14.770
As you heard Bertrand
talking about earlier today,

00:29:14.770 --> 00:29:19.830
we're bringing what we learned from that
work back to the desktop in Snow Leopard

00:29:19.830 --> 00:29:22.580
as the beginning of QuickTime 10.

00:29:23.240 --> 00:29:26.970
Now, QuickTime 10 is a really exciting
and important announcement

00:29:27.110 --> 00:29:29.340
for us here at WWDC this year.

00:29:29.620 --> 00:29:33.890
It represents a significant ongoing
technology investment by Apple to

00:29:33.920 --> 00:29:36.720
provide a modern foundation for media.

00:29:36.950 --> 00:29:40.880
Let's take a look at three
areas of focus for QuickTime 10.

00:29:41.290 --> 00:29:44.680
First of all,
seamless Mac OS X integration.

00:29:45.040 --> 00:29:51.800
Secondly, a focus on modern codecs.

00:29:51.800 --> 00:29:51.800
And third, high-level APIs.

00:29:52.200 --> 00:29:55.940
Let's begin by looking at
seamless Mac OS X integration.

00:29:55.960 --> 00:29:58.720
And several examples of this are 64-bit.

00:29:58.900 --> 00:30:03.200
The code base for Mac OS X is
fully 64-bit native.

00:30:03.460 --> 00:30:05.850
Secondly, color sync.

00:30:05.940 --> 00:30:11.170
Whatever we do in QuickTime 10 is fully
color managed throughout by color sync.

00:30:11.590 --> 00:30:13.600
Third, core animation.

00:30:13.650 --> 00:30:16.370
You heard John talking about the
importance of core animation on

00:30:16.420 --> 00:30:19.680
the desktop and the centrality
of core animation on the iPhone.

00:30:19.680 --> 00:30:23.700
We've recently done a lot of work
in the rendering pipeline of QtKit,

00:30:23.860 --> 00:30:28.000
our Objective-C layer,
to better integrate with core animation.

00:30:28.050 --> 00:30:30.070
And in fact,
you can really do some things easily

00:30:30.120 --> 00:30:31.800
now that used to be really hard to do.

00:30:31.800 --> 00:30:37.090
So, let's talk about another
side of integration.

00:30:37.270 --> 00:30:40.000
Sometimes for integration,
it's better just to let other parts

00:30:40.000 --> 00:30:41.730
of the system do what they do best.

00:30:41.730 --> 00:30:44.560
First example is still image support.

00:30:44.560 --> 00:30:48.330
Mac OS X has a robust framework
for doing still image support,

00:30:48.330 --> 00:30:50.000
and that's Image I.O.

00:30:50.000 --> 00:30:53.700
So rather than doing image
support in QuickTime 10,

00:30:53.700 --> 00:30:55.880
you should use core Image I.O.

00:30:55.920 --> 00:30:58.140
for your still image support.

00:30:58.140 --> 00:31:01.140
Secondly, let's talk about interactivity.

00:31:01.800 --> 00:31:05.490
Apple has been working
over the past years on web

00:31:05.490 --> 00:31:07.350
technologies for interactivity.

00:31:07.520 --> 00:31:09.390
And as you heard in
the keynote last year,

00:31:09.500 --> 00:31:12.830
the graphics and media keynote,
and you'll hear a little bit more

00:31:12.830 --> 00:31:16.330
in the section in this keynote,
State of the Union Following Mine,

00:31:16.620 --> 00:31:20.210
You can really use web technologies
to do some really great interactivity.

00:31:20.210 --> 00:31:23.990
And so we believe that interactivity
does not belong within the media system.

00:31:24.290 --> 00:31:31.150
Instead, you should be using web
technologies such as HTML and

00:31:31.150 --> 00:31:31.150
JavaScript to do interactivity.

00:31:33.050 --> 00:31:36.000
talk about modern codecs.

00:31:36.000 --> 00:31:39.010
And as you know, Apple is in the business
of selling content.

00:31:39.100 --> 00:31:41.340
This has three interesting implications.

00:31:41.450 --> 00:31:47.790
First of all,
it means that we really need

00:31:47.790 --> 00:31:49.570
high-quality video and audio
codecs in order to provide the kind

00:31:49.570 --> 00:31:49.570
of content that we need to sell.

00:31:49.600 --> 00:31:55.000
[Transcript missing]

00:31:56.550 --> 00:31:59.760
Secondly, it means that we work with
our content providers in movie

00:31:59.880 --> 00:32:03.340
studios and music labels,
and that has the effect that we

00:32:03.380 --> 00:32:07.180
get a lot of feedback from them
as to the quality of the content,

00:32:07.180 --> 00:32:10.850
and so we are able to improve the quality
of the codex significantly from that.

00:32:10.880 --> 00:32:13.290
In addition,
we receive an awfully broad range of

00:32:13.290 --> 00:32:16.440
content from our content providers,
and that also feeds back into

00:32:16.520 --> 00:32:18.360
improving the quality of our codex.

00:32:19.070 --> 00:32:21.270
Third, it means that we have an
interest in having codex

00:32:21.270 --> 00:32:22.630
that can last for many years.

00:32:23.030 --> 00:32:25.270
Neither we nor you are interested
in having to re-encode your

00:32:25.390 --> 00:32:28.300
content periodically just to
update to the latest standards.

00:32:28.300 --> 00:32:31.380
Another thing that's true, as you know,
is that Apple has a very

00:32:31.380 --> 00:32:34.760
broad hardware product line,
all the way from iPods and iPhones

00:32:34.760 --> 00:32:36.700
up to high-end desktop machines.

00:32:36.700 --> 00:32:39.220
We need a single audio and
video codex that can span

00:32:39.220 --> 00:32:40.900
this entire range of products.

00:32:41.000 --> 00:32:45.440
The answer to this is standards,
and standards are central to media.

00:32:45.440 --> 00:32:47.280
In particular,
there are a few standards that

00:32:47.280 --> 00:32:48.780
are of critical importance to us.

00:32:48.780 --> 00:32:52.070
First is the MPEG-4 file format,
which is based on the

00:32:52.070 --> 00:32:53.610
QuickTime file format.

00:32:53.610 --> 00:32:55.430
Secondly is AAC audio codex.

00:32:55.430 --> 00:32:57.740
Third, H.264 video codex.

00:32:57.740 --> 00:33:01.800
In addition, there are other standards,
such as closed captions,

00:33:01.800 --> 00:33:03.790
that are quite important to us.

00:33:04.230 --> 00:33:06.300
Let's take a look at audio for a moment.

00:33:06.310 --> 00:33:08.440
AAC does not,
as many people seem to believe,

00:33:08.440 --> 00:33:09.880
stand for Apple Audio Codec.

00:33:09.930 --> 00:33:12.160
It really stands for
Advanced Audio Coding,

00:33:12.160 --> 00:33:15.590
and it is the premier audio
codec in the MPEG-4 standards.

00:33:15.590 --> 00:33:18.580
It's a variable bit rate codec,
which means it is very efficient and

00:33:18.580 --> 00:33:22.010
only uses the minimum number of bits
necessary to encode the complexity of the

00:33:22.020 --> 00:33:24.060
local region of audio you're encoding.

00:33:24.480 --> 00:33:27.480
There are many uses for AAC,
all the way from iTunes Plus,

00:33:27.480 --> 00:33:30.860
which is the approximately 256
kilobit per second audio we

00:33:30.860 --> 00:33:32.780
sell through the iTunes Store.

00:33:32.780 --> 00:33:36.880
We've had really positive feedback on the
quality of the content in iTunes Plus.

00:33:36.890 --> 00:33:39.210
In addition,
there's a low delay mode for AAC,

00:33:39.210 --> 00:33:42.010
which is very useful for
real-time communications.

00:33:42.050 --> 00:33:45.120
Another example is multi-channel audio.

00:33:45.150 --> 00:33:50.270
AAC supports multi-channel audio
to allow you to do surround sound.

00:33:51.120 --> 00:33:54.330
On the video side,
H.264 goes by many names.

00:33:54.430 --> 00:34:00.100
In addition to H.264,
it's also known as MPEG-4 Part 10, AVC,

00:34:00.100 --> 00:34:01.000
and JVT.

00:34:01.060 --> 00:34:02.760
The reason for this is
primarily historical.

00:34:02.800 --> 00:34:08.680
The initial work on H.264
started in a number of places,

00:34:08.680 --> 00:34:13.280
none of which seem to have
been able to afford to buy a

00:34:13.280 --> 00:34:13.910
vowel from what I can tell,
and was later unified to

00:34:13.910 --> 00:34:13.910
produce the final standard.

00:34:14.170 --> 00:34:17.840
H.264 is an extremely
robust and rich standard.

00:34:18.070 --> 00:34:20.700
And to understand what this means,
it's useful to go back and look

00:34:20.700 --> 00:34:23.370
at a somewhat earlier standard
that was less rich but still

00:34:23.430 --> 00:34:25.980
a moderately rich standard,
and that's MPEG-2.

00:34:25.980 --> 00:34:28.940
If you look at what happened
over the history of MPEG-2,

00:34:28.940 --> 00:34:31.710
as implementations took more
and more advantage of the

00:34:31.710 --> 00:34:35.160
full breadth of the standard,
it was possible to encode video

00:34:35.160 --> 00:34:38.840
of the same quality at lower and
lower bit rates as time went on.

00:34:39.520 --> 00:34:42.560
We've seen the same thing
happening with H.264 already.

00:34:42.560 --> 00:34:45.940
We expect it to continue happening,
and I expect it to happen to a

00:34:45.940 --> 00:34:49.280
degree even more than it did in
MPEG-2 because of the extreme

00:34:49.280 --> 00:34:51.790
richness of the H.264 standard.

00:34:52.080 --> 00:34:56.260
In addition, H.264 can be used across a
wide range of display sizes,

00:34:56.260 --> 00:35:00.370
all the way from small QSIF 176x144
sizes appropriate for edge

00:35:00.370 --> 00:35:03.410
networks on mobile devices,
all the way up to full

00:35:03.410 --> 00:35:05.240
HD sizes useful on desktop.

00:35:05.240 --> 00:35:10.380
With the introduction today of the iPhone
3G and the already existing edge support,

00:35:10.380 --> 00:35:12.930
it's useful to focus on this and
just take a look at examples of

00:35:12.930 --> 00:35:15.580
a couple pieces of content and
what they look like on the phone,

00:35:15.580 --> 00:35:16.590
so let's go do that.

00:35:16.740 --> 00:35:20.260
So as you can see, H.264 is usable down
to very low bit rates.

00:35:20.260 --> 00:35:22.310
However, if you're able to
allocate additional bits,

00:35:22.310 --> 00:35:24.170
for example, for a 3G network,
you'll be able to get

00:35:24.170 --> 00:35:25.560
significantly better quality.

00:35:25.560 --> 00:35:27.970
So, let's...

00:35:32.920 --> 00:35:35.980
Talk about high-level APIs.

00:35:36.020 --> 00:35:39.720
And for us, primarily,
this means Cocoa APIs and

00:35:39.770 --> 00:35:42.080
specifically QtKit.

00:35:42.390 --> 00:35:45.230
In QuickTime 10,
what we're doing in Snow Leopard

00:35:45.590 --> 00:35:50.810
is having QtKit actually bridge
across QuickTime 10 and QuickTime 7.

00:35:50.820 --> 00:35:54.120
Bertrand talked about this a little
in his talk earlier this afternoon.

00:35:54.150 --> 00:35:57.360
What this means for you is that
you can use the same APIs you're

00:35:57.360 --> 00:36:00.190
already using for playing back
content using QuickTime 7 and

00:36:00.190 --> 00:36:03.340
use them to take advantage of the
additional efficiencies and color

00:36:03.340 --> 00:36:07.700
correction and other modern features
we're introducing in QuickTime 10.

00:36:07.730 --> 00:36:09.600
In order to do this,
you do need to opt into

00:36:09.600 --> 00:36:10.960
the QuickTime 10 code path.

00:36:11.130 --> 00:36:13.290
It's actually really easy to
do that in your application.

00:36:13.500 --> 00:36:15.850
We strongly encourage you to
do that in order that you take

00:36:15.870 --> 00:36:18.520
advantage of all the modern features
we're adding in QuickTime 10,

00:36:18.520 --> 00:36:22.340
as well as the ongoing tuning we're
going to be doing in that code path.

00:36:22.380 --> 00:36:27.270
Along with our focus on Objective-C APIs,
we are deprecating

00:36:27.270 --> 00:36:29.750
QtJava in Snow Leopard.

00:36:33.020 --> 00:36:38.790
So QuickTime 10, three areas of focus--
seamless Mac OS X integration,

00:36:38.790 --> 00:36:42.690
modern codecs,
and a focus on high-level APIs.

00:36:43.610 --> 00:36:48.840
QuickTime 10, shipping the beginnings of
QuickTime 10 in Snow Leopard.

00:36:48.880 --> 00:36:53.880
That includes support for
playback of H.264 and AAC content.

00:36:53.880 --> 00:36:54.820
Why playback?

00:36:55.060 --> 00:36:57.090
Because it's what most
of your applications and

00:36:57.090 --> 00:36:58.150
most of our customers do.

00:36:58.380 --> 00:37:00.420
Why H.264 and AAC?

00:37:00.460 --> 00:37:03.840
Because it's the codex that
plays back across the entire

00:37:03.840 --> 00:37:07.610
range of products we have,
and it's what we're focusing on.

00:37:07.610 --> 00:37:10.520
Let's turn our attention
to audio for a moment,

00:37:10.520 --> 00:37:11.350
core audio.

00:37:11.350 --> 00:37:12.610
Let's again look at iPhone.

00:37:12.790 --> 00:37:15.770
iPhone has an extremely
complex audio environment.

00:37:15.900 --> 00:37:18.450
In addition to a number of
audio sources on iPhone,

00:37:18.600 --> 00:37:21.250
there are a number of places, headphones,
Bluetooth, so on,

00:37:21.410 --> 00:37:22.620
where content can be played out.

00:37:22.800 --> 00:37:26.110
We needed technologies that
could support the very complex

00:37:26.110 --> 00:37:28.050
audio environment on iPhone.

00:37:28.150 --> 00:37:31.300
It turns out we already
had them on the desktop.

00:37:31.420 --> 00:37:37.330
Core Audio and Open AL were just
what we needed to support the iPhone.

00:37:37.330 --> 00:37:37.330
Let's take a look.

00:37:38.210 --> 00:37:40.330
On Mac OS, on the desktop,
we support OpenAL,

00:37:40.440 --> 00:37:43.570
technologies you heard earlier
in Bertrand's talk for rendering

00:37:43.570 --> 00:37:46.580
sound in three dimensions,
shares a coordinate space with OpenGL.

00:37:46.580 --> 00:37:49.760
In addition, we have system sounds,
which support key clicks and

00:37:49.760 --> 00:37:51.270
very simple system sounds.

00:37:51.280 --> 00:37:54.240
Audio file and audio cue,
very useful for doing audio

00:37:54.340 --> 00:37:55.900
playback and recording.

00:37:55.900 --> 00:37:58.370
And finally, audio units,
which allow you to get at

00:37:58.370 --> 00:38:01.220
low-level things such as
mixing and other attributes.

00:38:01.220 --> 00:38:04.530
On the phone,
we've brought all of these things across.

00:38:05.120 --> 00:38:08.360
In addition, we've implemented a new API,
Audio Session,

00:38:08.360 --> 00:38:11.000
used for managing the complex
audio environment on the phone.

00:38:11.000 --> 00:38:13.500
And this allows you,
in your applications,

00:38:13.500 --> 00:38:16.510
to provide the same kind of
seamless audio experience that we

00:38:16.510 --> 00:38:17.900
provide in our own applications.

00:38:17.900 --> 00:38:21.330
One feature I should mention that's
shared between the phone and desktop,

00:38:21.530 --> 00:38:24.970
because it's been very much requested,
is the phone does support the

00:38:24.970 --> 00:38:28.220
ability to do full duplex audio,
both inputting and outputting

00:38:28.220 --> 00:38:30.230
audio simultaneously,
which is really useful for

00:38:30.360 --> 00:38:31.530
real-time communications.

00:38:33.950 --> 00:38:36.720
So that's Core Audio.

00:38:36.770 --> 00:38:39.360
Putting everything together,
as you just heard,

00:38:39.400 --> 00:38:42.300
the way we've scaled from the
desktop to iPhone on the audio

00:38:42.430 --> 00:38:45.930
side is to bring the Core Audio and
Open AL technologies down to iPhone

00:38:45.930 --> 00:38:49.440
so that you can use your knowledge
and leverage that that you already

00:38:49.440 --> 00:38:53.480
have on the desktop in implementing
great applications on the iPhone.

00:38:53.480 --> 00:38:56.860
QuickTime 10,
a really important and extremely

00:38:57.070 --> 00:38:58.880
exciting announcement for us here.

00:38:59.360 --> 00:39:02.840
QuickTime 10 represents a significant
ongoing investment from us to

00:39:03.100 --> 00:39:05.420
implement a modern framework for media.

00:39:05.420 --> 00:39:08.040
With that,
I'd like to turn it over to Gilles Drieu,

00:39:08.100 --> 00:39:12.510
who will be talking about how to
use graphics and media on the web.

00:39:12.520 --> 00:39:12.940
Gilles?

00:39:12.960 --> 00:39:14.210
Thank you.

00:39:19.970 --> 00:39:23.900
Thank you, Tim.

00:39:23.990 --> 00:39:25.200
Good afternoon, everyone.

00:39:25.260 --> 00:39:25.990
All right.

00:39:26.100 --> 00:39:30.480
So you just heard from Tim and
John about our latest and greatest

00:39:30.630 --> 00:39:33.300
graphics and media technologies.

00:39:33.610 --> 00:39:41.400
I'm here today to tell you why
they are so essential on the Web.

00:39:41.400 --> 00:39:41.400
Today,

00:39:42.410 --> 00:39:47.660
We'll see how web standards
help shape graphics and media,

00:39:47.660 --> 00:39:52.800
and how these same graphics and
media can be leveraged on iPhone.

00:39:52.950 --> 00:39:55.860
First, web standards.

00:39:57.080 --> 00:40:05.540
Over time, graphics content has become as
commonly used as text on the web.

00:40:05.790 --> 00:40:10.600
But really today, it is not just about
standalone graphics anymore.

00:40:10.660 --> 00:40:16.390
It is about integrating them in
rich and dynamic experiences.

00:40:22.170 --> 00:40:28.020
And that means defining a rich
presentation for your content.

00:40:28.140 --> 00:40:31.410
And you guys,
as web designers and developers,

00:40:31.470 --> 00:40:34.220
are very familiar with that concept.

00:40:34.260 --> 00:40:39.890
With CSS, you know how to style
your HTML web pages.

00:40:40.990 --> 00:40:45.890
CSS stands for Cascading Style Sheet.

00:40:45.890 --> 00:40:50.560
And CSS was standardized
over 10 years ago by the W3C.

00:40:51.340 --> 00:40:56.220
And it has become a very powerful tool.

00:40:56.360 --> 00:40:59.700
And it's supported in all major browsers.

00:40:59.850 --> 00:41:03.440
But we think that more can be done.

00:41:03.610 --> 00:41:09.560
Apple has been working with the
W3C on a brand new set of rich,

00:41:09.570 --> 00:41:17.110
compelling features for graphics: CSS,
Visual Effects.

00:41:19.630 --> 00:41:27.910
CSS Visual Effects,
such as the ones you can

00:41:28.310 --> 00:41:33.030
see on the screen here,
have been designed to take

00:41:33.030 --> 00:41:33.030
full advantage of our graphics
stacks on modern platforms.

00:41:33.890 --> 00:41:41.410
Now, you can polish your design with
masks or gradients or reflections,

00:41:41.410 --> 00:41:47.490
and you can add life to your
content with transforms,

00:41:47.490 --> 00:41:47.490
transitions, or animations.

00:41:48.500 --> 00:41:54.090
And I'll show you what it really can do
for you in a demo in a couple of minutes.

00:41:54.970 --> 00:41:58.150
Now, that's about graphics as standards.

00:41:58.260 --> 00:42:01.220
What about media content?

00:42:01.290 --> 00:42:07.050
As you all know, audio and video are
everywhere on the web today.

00:42:07.520 --> 00:42:11.080
And traditionally,
we've been using plug-in to

00:42:11.080 --> 00:42:13.280
handle that type of media.

00:42:13.350 --> 00:42:18.940
But a natural evolution would be to
integrate our media within these rich

00:42:19.080 --> 00:42:22.000
experiences in a very seamless way.

00:42:22.070 --> 00:42:25.800
As seamlessly as you integrate images,
for instance.

00:42:25.900 --> 00:42:29.790
Well, for images, we have an image tag.

00:42:30.230 --> 00:42:35.530
So we believe it is time to
make audio and video first-class

00:42:35.530 --> 00:42:38.980
citizens in your web pages.

00:42:39.140 --> 00:42:42.960
How about an audio and a video tag?

00:42:48.850 --> 00:42:53.770
Apple has been very actively
working with the W3C and the Watt

00:42:53.770 --> 00:43:01.110
Working Group on a new set of
media elements for audio and video.

00:43:02.880 --> 00:43:10.350
And it is now part of the HTML5
specification draft for you.

00:43:12.950 --> 00:43:16.120
OK, so audio and video tags.

00:43:16.570 --> 00:43:18.940
Well, they are page elements.

00:43:18.980 --> 00:43:24.700
As such, they are styleable with CSS and
scriptable with JavaScript,

00:43:24.700 --> 00:43:26.770
like any other element.

00:43:27.120 --> 00:43:41.560
They work beautifully with H.264 and ASE,
our state-of-the-art video and audio

00:43:41.560 --> 00:43:41.910
codecs that Tim mentioned earlier,
but they also offer a very

00:43:41.910 --> 00:43:41.910
elegant fallback mechanism.

00:43:44.150 --> 00:43:48.540
In the current shipping
version of Safari 3.1,

00:43:48.560 --> 00:43:54.440
we implemented the audio and video tag
on top of the QuickTime technology.

00:43:54.500 --> 00:43:59.270
We also implemented the CSS visual
effects and specifically

00:43:59.790 --> 00:44:02.400
transforms and transitions.

00:44:04.310 --> 00:44:16.420
Because Safari is built on top
of our graphics and media stacks,

00:44:16.420 --> 00:44:19.780
respectively Quartz and QuickTime,
you get the absolutely best

00:44:19.780 --> 00:44:19.780
performance and quality.

00:44:20.010 --> 00:44:23.650
That was about web standards
and graphics and media.

00:44:23.750 --> 00:44:26.420
Now you know what you can do with them.

00:44:26.520 --> 00:44:31.700
Now we're going to talk about
some of the innovations we've

00:44:31.700 --> 00:44:33.660
been working on on iPhone.

00:44:37.040 --> 00:44:42.110
As you know, less than a year ago,
we introduced iPhone, and with it,

00:44:42.250 --> 00:44:45.460
a full-fledged web experience.

00:44:45.460 --> 00:44:50.560
And as you heard,
it's been an incredible success.

00:44:51.370 --> 00:44:54.500
And you guys have been awesome.

00:44:54.560 --> 00:44:59.990
Like really, in less than a year,
you implemented over 1,700

00:44:59.990 --> 00:45:02.740
web applications for iPhone,
for Safari on iPhone.

00:45:04.240 --> 00:45:07.030
and your applications are awesome too.

00:45:07.080 --> 00:45:11.750
Like, they are dynamic and interactive
and they take advantage of

00:45:11.770 --> 00:45:13.600
the full large touchscreen.

00:45:13.650 --> 00:45:22.240
We love them and we believe we can
help you do even better with more

00:45:22.240 --> 00:45:22.240
access to graphics and media features.

00:45:23.610 --> 00:45:30.990
OK, so as you heard from John and team,
our graphics and media features are

00:45:30.990 --> 00:45:34.670
scalable and at the core of iPhone.

00:45:34.890 --> 00:45:40.820
So we thought about it,
and we decided to integrate

00:45:40.870 --> 00:45:50.670
Safari with the same graphics and
media stacks that are currently used

00:45:50.670 --> 00:45:50.670
and leveraged by native applications.

00:45:52.480 --> 00:45:57.560
First, we implemented CSS visual effects.

00:45:57.580 --> 00:46:00.960
And specifically,
we focused on transforms, transitions,

00:46:00.960 --> 00:46:05.260
and animations,
because we know that these are the

00:46:05.260 --> 00:46:10.300
ones you need to build your next
generation rich user interfaces.

00:46:10.330 --> 00:46:13.240
And as you heard in a previous session,
in Dash Code,

00:46:13.250 --> 00:46:18.380
you can leverage very easily in
the tool the same technologies.

00:46:20.750 --> 00:46:25.940
As you heard from John, though,
we also have a beautiful

00:46:25.950 --> 00:46:31.770
compositing system on iPhone,
and it's called Core Animation.

00:46:33.690 --> 00:46:39.320
We took the same technology beyond
core animation and we built it

00:46:39.320 --> 00:46:41.840
right inside Safari on iPhone.

00:46:42.000 --> 00:46:45.860
That gives us access to the
full power of GPU acceleration,

00:46:46.220 --> 00:46:51.520
which opens the doors for 3D transforms,
for instance, which you can control over

00:46:51.520 --> 00:46:55.480
the same CSS transformations
we talked about earlier.

00:46:55.480 --> 00:46:59.570
You still have 2D transformations,
which also are GPU accelerated,

00:46:59.590 --> 00:47:02.380
and you also have now 3D transformations.

00:47:04.700 --> 00:47:06.840
So let me show you what
it really means for you.

00:47:07.040 --> 00:47:11.840
What you see on the screen is an example
of an animated scene of falling leaves.

00:47:11.930 --> 00:47:17.600
And this has been implemented with
traditional JavaScript techniques.

00:47:17.660 --> 00:47:19.800
And as you can see, it looks pretty good.

00:47:19.850 --> 00:47:22.780
Now, side by side.

00:47:22.890 --> 00:47:26.290
On the right side,
you see the same animated scene

00:47:26.980 --> 00:47:30.700
leveraging the GPU acceleration
and CSS visual effects.

00:47:30.720 --> 00:47:33.550
As you can see,
there's a pretty substantial

00:47:34.000 --> 00:47:36.390
performance improvement here.

00:47:36.390 --> 00:47:39.820
As a matter of fact,
almost ten times faster.

00:47:39.820 --> 00:47:43.080
Not only that,
but it took us 100 lines of

00:47:43.080 --> 00:47:48.270
JavaScript for the first version,
and now it takes us ten lines of

00:47:48.270 --> 00:47:51.840
CSS for the exact same animated scene.

00:47:51.840 --> 00:47:54.360
What does it really mean for you
web developers and designers?

00:47:54.360 --> 00:47:57.560
Well,
it means that you can not only benefit

00:47:57.560 --> 00:48:04.670
from the maximum performance on a device,
but also gain very,

00:48:04.670 --> 00:48:07.660
very much in productivity.

00:48:07.660 --> 00:48:13.460
That's what it means for you.

00:48:13.460 --> 00:48:13.460
Okay.

00:48:13.460 --> 00:48:13.460
So that's --

00:48:18.680 --> 00:48:22.100
So we talked about the new graphics
features on Safari for iPhone.

00:48:22.140 --> 00:48:28.230
Now, on iPhone, we have a really seamless
playback system here.

00:48:28.320 --> 00:48:31.840
It's very easy to embed your content,
as you know.

00:48:32.030 --> 00:48:35.870
It leverages beautifully H.264 and ASE.

00:48:36.360 --> 00:48:39.300
It's high performance, built right in.

00:48:39.370 --> 00:48:42.300
You guys told us you love it.

00:48:42.300 --> 00:48:45.700
But as usual, you want more.

00:48:45.740 --> 00:48:48.820
And you want more
control over your media.

00:48:48.880 --> 00:48:50.620
And we listen to you.

00:48:50.620 --> 00:48:56.980
And for this reason,
we implemented the JavaScript methods

00:48:57.640 --> 00:48:59.650
and DOM events that will help you
control your media within the playback.

00:48:59.940 --> 00:49:08.280
These APIs are compatible with the same
APIs that have been used for many years

00:49:08.570 --> 00:49:11.640
on QuickTime plugin on desktop browsers.

00:49:11.700 --> 00:49:12.560
That's right.

00:49:12.640 --> 00:49:21.140
That means that all the content you've
been working on for the past 10 years,

00:49:21.220 --> 00:49:23.410
you can leverage on iPhone
today the exact same content.

00:49:23.410 --> 00:49:23.410
It's compatible.

00:49:24.630 --> 00:49:26.340
But we didn't stop there.

00:49:26.420 --> 00:49:31.910
There's also a need to trigger
the full screen playback from

00:49:32.270 --> 00:49:35.390
your custom web applications.

00:49:35.760 --> 00:49:42.520
And so we implemented also APIs that
help you trigger the playback

00:49:42.780 --> 00:49:46.380
from your custom UIs as well.

00:49:46.380 --> 00:49:46.380
All right.

00:49:46.380 --> 00:49:46.380
So,

00:49:49.430 --> 00:49:56.500
There are two things I'd
like you to remember today.

00:49:56.500 --> 00:50:03.550
First, web standards are the
backbone of the web.

00:50:03.550 --> 00:50:10.540
And we at Apple are very committed
to evolving further in particular

00:50:10.540 --> 00:50:10.540
when it comes to graphics and media.

00:50:10.540 --> 00:50:10.540
Second,

00:50:11.280 --> 00:50:20.220
On OS X, we have great graphics
and media technologies.

00:50:20.220 --> 00:50:20.220
And as you heard,
they scale beautifully onto iPhone.

00:50:22.840 --> 00:50:28.550
And we expose them for
you in Safari on iPhone.

00:50:28.900 --> 00:50:33.360
That means your web graphics
become fast and dynamic,

00:50:33.360 --> 00:50:38.390
and your web video is
simple and very immersive.

00:50:39.520 --> 00:50:44.380
So check them out this week, you know,
and start tuning up your web apps.

00:50:44.520 --> 00:50:45.500
I'm still waiting for you.

00:50:45.500 --> 00:50:47.930
I would love to show you these
demos because that's a bit

00:50:47.930 --> 00:50:49.540
hard to visualize without them.

00:50:49.560 --> 00:50:53.560
Okay.

00:50:53.560 --> 00:50:56.360
Okay.

00:50:56.360 --> 00:50:58.330
All right.

00:50:58.330 --> 00:51:00.130
No demos.

00:51:01.730 --> 00:51:05.910
As you can tell,
I'm really happy right now.

00:51:05.910 --> 00:51:08.710
Because I was really excited
to show you these demos.

00:51:08.710 --> 00:51:12.030
So that's really unfortunate here.

00:51:12.130 --> 00:51:17.460
Okay.

00:51:17.460 --> 00:51:19.460
So that was about web.

00:51:19.460 --> 00:51:22.490
And now I'd like to turn it back to John.

00:51:29.550 --> 00:51:30.890
Thank you, Gilles.

00:51:31.030 --> 00:51:37.220
So just before the show,
some of my engineers came to me.

00:51:37.260 --> 00:51:39.440
They had this really fun demo.

00:51:39.810 --> 00:51:43.380
And we decided that

00:51:43.800 --> 00:51:48.200
It shows the ability of OpenSeal
to do some really fun stuff.

00:51:48.360 --> 00:51:50.000
And we decided we had to show it.

00:51:50.190 --> 00:51:53.560
So to do that,
I'm going to invite Jeff Stahl

00:51:53.560 --> 00:51:56.640
on stage and Nick Burns,
and we're going to take

00:51:56.640 --> 00:51:58.160
a look at this demo.

00:51:58.740 --> 00:52:00.980
So this demo will take a few
minutes to look at something that

00:52:01.440 --> 00:52:03.980
we can do with OpenCL on the GPU.

00:52:03.980 --> 00:52:07.330
And if we switch to the demo machine,
please.

00:52:08.130 --> 00:52:09.800
There we go.

00:52:09.800 --> 00:52:11.430
Okay.

00:52:11.460 --> 00:52:12.900
Now you've been waiting for this.

00:52:12.940 --> 00:52:16.830
Let's show you what we can
do with OpenCL on the GPU.

00:52:19.000 --> 00:52:25.990
What you have here is an instruction
level emulation of an Apple II 6502

00:52:25.990 --> 00:52:28.720
processor running on OpenCL.

00:52:32.190 --> 00:52:37.980
And of course, with an Apple II,
you get full AppleSoft basic support.

00:52:41.440 --> 00:52:52.020
So, but... We're graphics folks,
so we thought we'd do something

00:52:52.020 --> 00:52:52.020
a little bit more immersive,
3D graphics circa 1982.

00:53:06.230 --> 00:53:10.960
standing 4-bit graphics.

00:53:11.000 --> 00:53:16.460
So -- Obviously,
one of the most recognized

00:53:16.460 --> 00:53:20.600
games of the Apple II era,
but it is interesting to take a second

00:53:20.710 --> 00:53:23.300
to talk about exactly how this was done.

00:53:23.300 --> 00:53:26.680
So this is an OpenCL kernel,
the emulators -- an instruction-level

00:53:26.680 --> 00:53:30.800
emulator running completely in OpenCL,
about 2,300 lines of code.

00:53:30.800 --> 00:53:34.960
This is then -- the data stream
input is the processor state,

00:53:34.960 --> 00:53:40.120
the memory, and the disk representation,
and this OpenCL kernel iterates on that,

00:53:40.120 --> 00:53:42.600
obviously, to produce the frames.

00:53:42.600 --> 00:53:47.830
We then take a back-end,
custom-written OpenGL fragment shader

00:53:48.130 --> 00:53:54.220
to take the exciting 4-bit graphics and
convert them for the big screen here.

00:53:54.220 --> 00:53:57.810
And we'll see what luck
Nick has with the princess.

00:53:59.230 --> 00:54:00.500
I don't think this is
going to go very well.

00:54:00.500 --> 00:54:03.640
Oh, that was not good.

00:54:03.700 --> 00:54:08.370
In any case, you know,
when you have one Apple II, that's great,

00:54:08.370 --> 00:54:11.800
but how about having maybe 64 Apple IIs?

00:54:17.400 --> 00:54:20.960
So this is 64 Apple IIs running
on top of OpenCL on the GPU.

00:54:21.290 --> 00:54:22.900
Thank you very much.

00:54:32.380 --> 00:54:35.420
So we've talked about graphics,
and we've talked about media,

00:54:35.420 --> 00:54:38.250
and then we've talked about how
to get access to all that great

00:54:38.250 --> 00:54:39.970
technology through the web.

00:54:43.300 --> 00:54:45.460
was our demo.

00:54:45.460 --> 00:54:49.920
Okay,
so Apple has spent a lot of time taking

00:54:49.920 --> 00:54:59.470
all these great technologies and scaling
them across both iPhone OS and Mac OS,

00:54:59.470 --> 00:55:01.210
and we've optimized them for those
platforms so that you can build great

00:55:01.210 --> 00:55:01.210
applications on top of this technology.

00:55:02.700 --> 00:55:05.170
and Apple has a wealth of other
technologies that are going to

00:55:05.210 --> 00:55:07.390
be covered this week at WWC.

00:55:07.800 --> 00:55:11.340
We encourage you to go and see
all of them and learn about

00:55:11.350 --> 00:55:16.480
all the great technologies
on both iPhone OS and Mac OS.

00:55:16.940 --> 00:55:19.400
We have labs downstairs.

00:55:19.410 --> 00:55:23.100
We have the Graphics and Media Lab with
engineers there all week that will

00:55:23.100 --> 00:55:26.620
answer all the details that you
want about these technologies.

00:55:26.650 --> 00:55:31.230
And we have an iPhone Lab downstairs
with engineers there all week

00:55:31.310 --> 00:55:33.640
long to answer any questions.

00:55:33.710 --> 00:55:37.820
So thank you for staying,
and welcome to WWC.