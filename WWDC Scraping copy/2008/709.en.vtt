WEBVTT

00:00:20.200 --> 00:00:25.540
The great thing about these
filters is that the user can

00:00:26.110 --> 00:00:28.160
select one of the parameters,
in this case the exposure,

00:00:28.190 --> 00:00:30.050
and do adjustments on it.

00:00:30.560 --> 00:00:36.770
Those adjustments are then
fed back into the RAW filter,

00:00:36.770 --> 00:00:36.770
and as you can see,

00:00:37.180 --> 00:00:42.410
The resulting image is the result of
the exposure being dropped is dimmed.

00:00:42.890 --> 00:00:46.390
This can all happen real time because
we're using Core Image filters to

00:00:46.390 --> 00:00:49.390
implement all of these parameters.

00:00:51.590 --> 00:00:53.720
So that's hopefully just a
good introduction on what you

00:00:53.720 --> 00:00:55.000
can do with the CI RAW filter.

00:00:55.000 --> 00:00:57.220
Let me just show you how
easy it is to do in code.

00:00:57.390 --> 00:01:00.480
Again, unlike normal CI filters,
you do not locate them by name.

00:01:00.500 --> 00:01:04.100
You just call CI filter,
filter with image URL.

00:01:04.260 --> 00:01:05.850
You specify the URL.

00:01:05.930 --> 00:01:08.200
And in this case,
the options dictionary is nil.

00:01:08.260 --> 00:01:11.100
You can specify other parameters,
potentially.

00:01:11.140 --> 00:01:14.230
The next thing we want to do in this
particular example is to show you

00:01:14.370 --> 00:01:17.830
what code is needed to dim the image.

00:01:17.930 --> 00:01:22.200
In this case, we're creating a double,
which is the value minus one,

00:01:22.250 --> 00:01:26.420
and we're setting that to
be the input EV adjustment.

00:01:26.570 --> 00:01:28.440
Now,
this kind of seems like a boring example,

00:01:28.440 --> 00:01:31.310
adjusting the EV on an image,
but in fact, this is one of the great

00:01:31.330 --> 00:01:33.510
things about RAW files,
is with RAW files,

00:01:33.570 --> 00:01:38.030
there's extra content in an image
beyond the normal clipped range.

00:01:38.240 --> 00:01:40.340
And by adjusting the
exposure down in a RAW file,

00:01:40.340 --> 00:01:43.070
you can actually reveal all
sorts of content in the image

00:01:43.140 --> 00:01:48.010
that may have been not visible,
like detail in clouds, for example.

00:01:48.200 --> 00:01:51.430
Last but not least,
we take the image and get the

00:01:51.430 --> 00:01:55.600
output image from that filter,
which we can then display on the screen.

00:01:55.700 --> 00:01:56.640
So that's a brief introduction.

00:01:56.640 --> 00:02:03.980
I hope I've whet your appetite on how
to use RAW processing using Core Image.

00:02:04.130 --> 00:02:06.760
Next, I'd like to bring up Ralph Brunner,
who will talk in some more detail

00:02:06.760 --> 00:02:09.530
about how to write your own kernels.

00:02:15.610 --> 00:02:18.800
Good morning.

00:02:18.800 --> 00:02:22.100
I'm going to talk about how
to make your own image unit.

00:02:22.130 --> 00:02:25.980
And first I'd like to point out the
image unit tutorial which you'll find

00:02:25.980 --> 00:02:29.490
on your Leopard and your Snow Leopard
disc is a document that kind of

00:02:29.490 --> 00:02:33.090
goes into all the details about
which entry goes into which P-list,

00:02:33.090 --> 00:02:36.500
how to make the project, you know,
all the administrative part

00:02:36.640 --> 00:02:38.070
of making an image unit.

00:02:38.220 --> 00:02:40.720
So I'm not going to
talk a lot about that,

00:02:40.720 --> 00:02:43.310
just that's the document to read and,
you know, follow the steps there.

00:02:43.620 --> 00:02:47.010
Fundamentally, to make your own filter,
there are two ingredients.

00:02:47.130 --> 00:02:51.290
One is the actual kernel,
or more than one kernel,

00:02:51.470 --> 00:02:53.810
that does the per-pixel processing.

00:02:53.920 --> 00:02:56.570
And that is written in
the CI kernel language,

00:02:56.570 --> 00:02:59.620
which is essentially the
OpenGL shading language.

00:02:59.720 --> 00:03:03.370
And if you're not familiar with that,
think of it as C with a

00:03:03.370 --> 00:03:05.510
vector data type added to it.

00:03:06.390 --> 00:03:10.160
The second part that you need is
the Objective-C code that wraps

00:03:10.490 --> 00:03:13.700
the kernels into the full filter.

00:03:13.700 --> 00:03:18.930
This is the code that knows how to call
the kernels and it contains additional

00:03:19.090 --> 00:03:24.400
data like what kind of inputs need to
be exposed and these kind of things.

00:03:24.600 --> 00:03:27.150
You then package those
two pieces together,

00:03:27.200 --> 00:03:30.360
either in a custom filter that
you compile into your app,

00:03:30.430 --> 00:03:34.360
or you make an image unit,
which is a plug-in so that all other apps

00:03:34.450 --> 00:03:37.620
that support image units can host them.

00:03:37.620 --> 00:03:39.950
And it's a great way for
debugging your filters,

00:03:39.950 --> 00:03:43.760
because when you make an image unit,
it will show up in Core Image Funhouse,

00:03:43.760 --> 00:03:46.850
it will show up in Quartz Composer,
and it's very easy to

00:03:46.850 --> 00:03:48.800
try it out and find bugs.

00:03:48.900 --> 00:03:54.050
Okay, so the example I'm going to talk
about today is Image Straighten.

00:03:54.180 --> 00:03:58.490
So imagine you're making an
app that deals with photos,

00:03:58.490 --> 00:04:02.130
and every now and then you
get a photo like the one here,

00:04:02.130 --> 00:04:03.680
which is kind of an exaggerated case.

00:04:03.820 --> 00:04:05.570
So your horizon isn't straight.

00:04:05.610 --> 00:04:07.280
How do you make the horizon straight?

00:04:07.280 --> 00:04:11.010
Well, you rotate the image until
the horizon is straight,

00:04:11.010 --> 00:04:14.420
and because now it's no
longer a rectilinear image,

00:04:14.420 --> 00:04:19.420
you find some cropped rectangle inside,
and you crop the image to the new bounds,

00:04:19.560 --> 00:04:21.840
and you have a slightly better image.

00:04:24.870 --> 00:04:26.110
So cropping is easy.

00:04:26.120 --> 00:04:27.340
Rotating is easy, too.

00:04:27.340 --> 00:04:30.110
It's these two lines of code here.

00:04:30.260 --> 00:04:32.990
Essentially what you do,
you create a CG-affined transform

00:04:32.990 --> 00:04:38.270
with the rotation angle and you
call image by applying transform

00:04:38.320 --> 00:04:40.690
and you get a new image out which
has the appropriate rotation.

00:04:40.720 --> 00:04:43.790
However, that's too easy for what I'm
going to talk about today,

00:04:43.860 --> 00:04:46.010
so we're going to aim
a little bit higher.

00:04:46.020 --> 00:04:51.040
The reason is, if you're doing this,
you get the default interpolation method,

00:04:51.040 --> 00:04:53.260
which is linear interpolation.

00:04:53.280 --> 00:04:55.700
And if, let's say,
you're making an app that is

00:04:55.700 --> 00:04:58.650
geared towards pro photographers,
you might want to do a

00:04:58.650 --> 00:05:00.060
high-quality rotation.

00:05:00.230 --> 00:05:02.760
Instead of just using
linear interpolation.

00:05:02.760 --> 00:05:07.310
Oops, that was too fast.

00:05:10.190 --> 00:05:14.860
The Cialanco Scale Transform that's
built into the system does

00:05:14.870 --> 00:05:16.590
a high quality image scale.

00:05:16.590 --> 00:05:19.780
However, there is no high quality
rotation filter in the system.

00:05:19.870 --> 00:05:24.120
And the next 10 minutes I'm
going to essentially implement

00:05:24.120 --> 00:05:26.340
one and show you how to do this.

00:05:26.510 --> 00:05:29.220
If you would like to learn
more about image resampling,

00:05:29.220 --> 00:05:34.100
I would recommend this book,
Digital Image Warping by George Wilberg.

00:05:34.160 --> 00:05:39.050
It goes into great detail how all these
sampling methods work and why I'm,

00:05:39.050 --> 00:05:41.870
what the things I'm going to talk
about in the next few minutes

00:05:41.990 --> 00:05:43.010
and why this is a good idea.

00:05:43.020 --> 00:05:47.280
So, it's my favorite book on the topic,
so go get it.

00:05:48.130 --> 00:05:52.420
You're going to use a result from 1986,
kind of the golden years

00:05:52.490 --> 00:05:57.240
of computer graphics,
which says you can decompose a

00:05:57.240 --> 00:06:00.220
rotation into three shear transforms.

00:06:01.060 --> 00:06:06.190
And so how that works is you take the
image and you shift each scan line

00:06:06.190 --> 00:06:08.010
to the right by a certain amount.

00:06:08.010 --> 00:06:12.720
Then you take that result and you shift
each scan row by a certain amount.

00:06:12.950 --> 00:06:16.440
And then the last step,
you shift each scan line again,

00:06:16.440 --> 00:06:18.520
and that gives you a rotation.

00:06:18.600 --> 00:06:19.880
And so why would you do it that way?

00:06:19.880 --> 00:06:23.000
Well, for one, it saves computation.

00:06:23.000 --> 00:06:27.450
Doing the filter call we're looking
at would be 64 vector multiplies per

00:06:27.450 --> 00:06:30.000
pixel if you do it in a single pass.

00:06:30.000 --> 00:06:33.520
However, it's 24 total if you
do it in three passes.

00:06:33.560 --> 00:06:35.640
And secondly,
the implementation is much simpler

00:06:35.640 --> 00:06:40.930
because each filter step you're really
just moving individual scan lines around.

00:06:42.960 --> 00:06:46.620
Okay, yeah,
so this is the filter will take the

00:06:46.690 --> 00:06:48.600
image and produce the rotated image.

00:06:48.600 --> 00:06:52.880
So the immediate phases will not be
visible to the client of your filter.

00:06:53.640 --> 00:06:55.340
So how do you do this?

00:06:55.340 --> 00:06:58.360
We're going to use the
four-lobed Lancash interpolator.

00:06:58.360 --> 00:07:02.880
And again, Wilbur's book talks about in
great detail how that works.

00:07:02.950 --> 00:07:05.860
So you have your scan
line full of pixels.

00:07:05.890 --> 00:07:10.900
And how do you shift a scan of pixel
by a fractional amount to the right?

00:07:11.180 --> 00:07:15.460
Well, it all comes down to,
can I compute a value in

00:07:15.460 --> 00:07:17.720
between two sample points?

00:07:18.110 --> 00:07:19.020
So how do you do this?

00:07:19.020 --> 00:07:22.150
Well, fundamentally,
you're looking at a local neighborhood.

00:07:22.170 --> 00:07:23.990
In our case,
we're going to take four pixels to

00:07:23.990 --> 00:07:28.950
the left and four pixels to the right
to the point we want to reconstruct.

00:07:29.530 --> 00:07:32.900
And then we take our Lankos kernel
and align it so that its zero

00:07:33.020 --> 00:07:35.950
point aligns to the point where
we want to reconstruct our data,

00:07:36.000 --> 00:07:38.420
the green point down there.

00:07:38.420 --> 00:07:41.560
And then for each of the
neighboring sample points where

00:07:41.560 --> 00:07:44.290
we actually have the data,
we're going to evaluate that

00:07:44.290 --> 00:07:46.040
kernel and this gives us a weight.

00:07:46.040 --> 00:07:48.790
So in the end,
we're reading eight pixels,

00:07:48.940 --> 00:07:51.850
we multiply each of these
RGB values by some weight

00:07:51.960 --> 00:07:55.190
which comes from this function,
and then add them all up.

00:07:56.270 --> 00:07:59.560
Okay, so how do you implement this?

00:07:59.650 --> 00:08:02.970
So, first of all, we're kind of lazy,
so we're writing only a single

00:08:02.970 --> 00:08:06.950
kernel for the shared transform,
and essentially we use the

00:08:07.180 --> 00:08:11.450
different parameters to do the
horizontal and the vertical shifts.

00:08:11.620 --> 00:08:14.330
The Lancashire function itself,
we're going to put that

00:08:14.330 --> 00:08:16.860
into a lookup table,
because it's quite a few trigonometric

00:08:16.910 --> 00:08:21.220
operations to evaluate it,
and we don't want to do that per pixel.

00:08:22.310 --> 00:08:24.840
Now, as I mentioned before,
to reconstruct one pixel,

00:08:24.840 --> 00:08:27.720
you need eight neighbors,
and therefore you need eight

00:08:27.720 --> 00:08:29.380
coefficients for each location.

00:08:29.380 --> 00:08:34.510
You could put these eight values
into kind of a linear table and

00:08:34.510 --> 00:08:38.760
read eight pixels and also read
eight values from that lookup table,

00:08:38.760 --> 00:08:42.790
but because we are working with images,
so we actually have four

00:08:42.790 --> 00:08:44.480
values in a single pixel.

00:08:44.580 --> 00:08:45.820
We have red, green, blue, and alpha.

00:08:46.590 --> 00:08:50.740
So we kind of can save a little
bit here by packing this data

00:08:50.740 --> 00:08:54.970
into an RGBA floating point image,
and therefore a single pixel read

00:08:54.970 --> 00:08:57.860
gives us RGBA or four arbitrary values.

00:08:57.880 --> 00:09:00.400
So to get our eight coefficients,
we do two lookups.

00:09:00.480 --> 00:09:03.780
We get the first four from one pixel
and the other four from the other pixel,

00:09:03.780 --> 00:09:07.680
so we save quite a bit
of texture reads here.

00:09:12.620 --> 00:09:15.530
So the lookup table is kind of
laid out in memory as I have

00:09:15.530 --> 00:09:17.500
a little diagram down there.

00:09:17.560 --> 00:09:23.580
So there's, it's 250, sorry,
512 pixels wide and 2 pixels high,

00:09:23.580 --> 00:09:28.690
and the 2 pixels high are the total
of 8 coefficients that you need.

00:09:29.710 --> 00:09:31.360
Okay, so how does that look in code?

00:09:31.360 --> 00:09:33.600
This is the kernel that
does the shear transform.

00:09:33.600 --> 00:09:35.710
Let me start here.

00:09:36.220 --> 00:09:38.840
The kernel returns a vec4 value.

00:09:38.840 --> 00:09:45.600
This is the RGBA value that gets
returned for a single pixel location.

00:09:45.600 --> 00:09:47.600
And it takes four parameters.

00:09:47.600 --> 00:09:51.600
The first two are a
sampler for the source.

00:09:51.600 --> 00:09:53.480
That's the image we're
going to do the rotate on.

00:09:53.600 --> 00:09:57.600
And the second one is
the LanCOS lookup table.

00:09:57.600 --> 00:10:00.600
You notice there is this keyword,
underscore, underscore, table.

00:10:00.600 --> 00:10:03.010
And what that does,
it prevents Core Image from

00:10:03.010 --> 00:10:06.600
inlining any world transform
into its sampler transform,

00:10:06.600 --> 00:10:08.700
which for a lookup table
doesn't make much sense,

00:10:08.700 --> 00:10:10.040
so that's why that's there.

00:10:11.030 --> 00:10:14.140
The other two parameters are
two two-dimensional vectors,

00:10:14.140 --> 00:10:16.580
a direction vector and a shear vector.

00:10:16.580 --> 00:10:20.960
The direction vector is either 1, 0 or 0,
1, depending on which

00:10:20.960 --> 00:10:24.180
direction you're working on,
horizontal or vertical path.

00:10:24.240 --> 00:10:27.050
And the shear vector
contains the shift value,

00:10:27.100 --> 00:10:32.910
how much you shift a scan line relative
to its neighboring scan line or scan row.

00:10:34.470 --> 00:10:37.760
Fundamentally,
the kernel has three blocks.

00:10:37.870 --> 00:10:40.810
The first one is we take our
destination coordinate and

00:10:40.810 --> 00:10:42.540
compute the source location.

00:10:42.540 --> 00:10:44.900
Where do we need to read the pixel from?

00:10:45.190 --> 00:10:53.960
And you see this little floor instruction
there to kind of round to the pixel

00:10:53.960 --> 00:10:55.960
location that is the neighboring sample
point that we actually have in memory.

00:10:56.280 --> 00:11:00.890
The second block is then compute
the index into the lookup table

00:11:00.930 --> 00:11:04.640
and then do these two lookups,
Z0 and Z1,

00:11:04.640 --> 00:11:07.780
to get our total of eight coefficients.

00:11:10.120 --> 00:11:16.240
And the last piece is we're doing
eight reads from the source image,

00:11:16.240 --> 00:11:20.450
which are the four pixels to the
left and four pixels to the right.

00:11:21.400 --> 00:11:25.360
You will notice I'm using F is
that coordinate that we used

00:11:25.360 --> 00:11:27.040
the floor operator before.

00:11:27.100 --> 00:11:31.500
And I use that direction vector
to get our values to the neighbor.

00:11:31.500 --> 00:11:33.900
So at that point,
we're reading either to the

00:11:33.900 --> 00:11:39.600
left or to the right or north
or south of the pixel location.

00:11:40.060 --> 00:11:42.640
And yeah, then we multiply those
with all the coefficients,

00:11:42.640 --> 00:11:44.460
add them all up, and we're done.

00:11:44.480 --> 00:11:47.390
So, how do you apply the kernel?

00:11:47.520 --> 00:11:53.190
This is now in the Objective-C part,
excerpt from the output image method.

00:11:53.200 --> 00:11:56.770
And what you're essentially seeing,
apply is called three times.

00:11:56.940 --> 00:11:59.510
These are the three passes we need to do.

00:12:00.350 --> 00:12:03.550
In each pass,
we pass in a different set of parameters,

00:12:03.670 --> 00:12:06.650
the horizontal, the vertical,
and then again the horizontal

00:12:06.730 --> 00:12:08.680
pass with the shift values.

00:12:10.020 --> 00:12:12.140
There is also this
interesting little piece,

00:12:12.150 --> 00:12:14.770
Apply Option User Info.

00:12:14.770 --> 00:12:18.180
And that's essentially a context
information that you can provide.

00:12:18.180 --> 00:12:21.590
It can be pointed to arbitrary data.

00:12:21.780 --> 00:12:24.740
And at a later point, you will get,
for the region of interest function,

00:12:24.740 --> 00:12:25.730
a callback.

00:12:25.820 --> 00:12:29.280
And that's the value you
get back at that point.

00:12:29.460 --> 00:12:31.900
So we'll talk about that
in a couple minutes.

00:12:32.010 --> 00:12:36.680
So just keep in mind that each of these
passes pass in additional information

00:12:36.880 --> 00:12:38.820
that you can use at render time.

00:12:39.160 --> 00:12:44.640
And the last point I would like to point
out here is the apply option definition.

00:12:44.640 --> 00:12:48.820
So you define--get--at that point,
specify the domain of definition

00:12:48.910 --> 00:12:50.380
for your output image.

00:12:50.450 --> 00:12:54.520
And let me explain what the
domain of definition is.

00:12:54.930 --> 00:12:58.670
The domain of definition is just like,
you know, in math.

00:12:58.830 --> 00:13:02.010
It's the area of your
function that is not zero.

00:13:02.120 --> 00:13:04.480
And in this case, it's a shape.

00:13:04.640 --> 00:13:08.040
It's the area of your
image that outside of it,

00:13:08.180 --> 00:13:12.840
all, your kernel will evaluate
to zero outside this area.

00:13:12.900 --> 00:13:16.480
And this allows the Core Image runtime
to do optimizations.

00:13:16.480 --> 00:13:20.170
Now, keep in mind,
DOD that you specify is an upper bound.

00:13:20.170 --> 00:13:22.930
So you can, for example,
you could just use a

00:13:22.930 --> 00:13:24.110
bounding box if you wish.

00:13:26.370 --> 00:13:28.960
So for our shear transformation,
this looks like this.

00:13:29.170 --> 00:13:31.580
So this is our first path.

00:13:31.580 --> 00:13:32.950
And the domain of definition is a shape.

00:13:33.130 --> 00:13:34.660
So this is how the shapes look like.

00:13:34.800 --> 00:13:39.240
So to take the source shape,
you have to return a destination shape

00:13:39.400 --> 00:13:42.490
that has essentially a slanted rectangle.

00:13:44.020 --> 00:13:46.740
And in code,
you ask the source for its definition,

00:13:46.740 --> 00:13:50.220
which is a CI filter shape,
and then we transform it

00:13:50.240 --> 00:13:53.400
by a CG-affine transform,
and that affine transform I'm making

00:13:53.400 --> 00:13:57.570
is essentially the shear transform,
and that's how you get

00:13:57.570 --> 00:13:59.760
your domain of definition.

00:14:00.820 --> 00:14:03.530
If you don't specify a
domain of definition,

00:14:03.600 --> 00:14:04.640
that is okay.

00:14:04.640 --> 00:14:09.100
It just means that whenever a
piece of the image is drawn,

00:14:09.400 --> 00:14:11.090
Core Image has to call your kernel.

00:14:11.370 --> 00:14:14.140
And you can imagine if you
have a lot of zeros out there,

00:14:14.140 --> 00:14:17.200
there's optimization
opportunities that you miss.

00:14:17.200 --> 00:14:19.700
For kernels that don't do
anything with geometry,

00:14:19.700 --> 00:14:24.500
typically the domain of definition
of the output is the same as the

00:14:24.500 --> 00:14:26.200
domain of definition of the input.

00:14:26.200 --> 00:14:28.690
So you just ask source domain
of definition and then pass

00:14:28.690 --> 00:14:30.200
that back and you call apply.

00:14:30.200 --> 00:14:33.160
Like a U transform doesn't
change the shape of the image,

00:14:33.210 --> 00:14:35.200
so there's no need to do
anything special there.

00:14:35.200 --> 00:14:40.180
And domain of definition can
sometimes be rather nasty to code.

00:14:40.310 --> 00:14:44.610
It is okay to make the domain
of definition a bit bigger than

00:14:44.610 --> 00:14:47.200
what would be theoretically pure.

00:14:47.200 --> 00:14:50.190
As long as it's not too big,
it's slightly less

00:14:50.190 --> 00:14:52.200
efficient but not tragic.

00:14:54.540 --> 00:14:58.600
Kind of the conceptual opposite
to the domain of definition is

00:14:58.600 --> 00:15:00.800
the region of interest function.

00:15:00.850 --> 00:15:03.980
And that's that callback
I was talking about before.

00:15:04.400 --> 00:15:09.200
Essentially this is the runtime
asks your filter question,

00:15:09.200 --> 00:15:09.950
which is,

00:15:10.300 --> 00:15:15.320
If I want to compute this
area in the destination,

00:15:15.320 --> 00:15:17.840
which part of the source do I need?

00:15:17.960 --> 00:15:21.580
And this allows things like tiling
and efficient use of resources

00:15:21.640 --> 00:15:24.340
if that is implemented correctly.

00:15:24.920 --> 00:15:28.640
Well, in our case, it is a parallelogram.

00:15:28.650 --> 00:15:31.260
And the region of interest function
actually doesn't return a shape,

00:15:31.260 --> 00:15:33.300
it just returns a CG rectangle.

00:15:33.360 --> 00:15:37.210
So you'll return a
bounding box of the area.

00:15:37.400 --> 00:15:40.540
So let me repeat that because
that's a really good source for

00:15:40.540 --> 00:15:42.280
bugs when you get that wrong.

00:15:42.350 --> 00:15:47.070
The question you have to
answer is to render a certain

00:15:47.070 --> 00:15:49.870
rectangle in the destination,
which part of the source is

00:15:49.870 --> 00:15:55.020
needed to perform that operation,
so that we can upload the proper part

00:15:55.020 --> 00:15:58.350
of the textures onto the graphics
card and these kind of things.

00:16:00.070 --> 00:16:04.740
Okay, so here is the ROI function
for our little rotate filter.

00:16:04.810 --> 00:16:06.930
You get called back,
it's called region off,

00:16:07.080 --> 00:16:10.070
and you get called
back with a sampler ID.

00:16:10.230 --> 00:16:13.640
That's the number of the sampler that
you have in your kernel function.

00:16:13.640 --> 00:16:20.530
So in our case,
sampler ID 0 is the image we

00:16:20.530 --> 00:16:21.050
rotate and sampler ID 1 is
the Lancashire lookup table.

00:16:21.280 --> 00:16:24.240
Destination Rect,
this is the rectangle you want to render.

00:16:24.320 --> 00:16:28.560
And UserInfo is that pointer that we
specified back when we called Apply.

00:16:28.640 --> 00:16:32.460
In our case, that was this
two-dimensional shear vector.

00:16:33.250 --> 00:16:36.780
What this function does is,
if the sampler ID is 1,

00:16:36.910 --> 00:16:41.700
you simply return the 512 by 2 pixels
full rectangle for the lookup table.

00:16:41.700 --> 00:16:45.890
So, to compute every pixel,
we need the entire

00:16:45.970 --> 00:16:48.430
lookup table available.

00:16:49.080 --> 00:16:53.120
For the actual image that we're
doing the shear transform on,

00:16:53.140 --> 00:16:57.520
we again create a CG-affined
transform with the shear vector we

00:16:57.520 --> 00:17:02.470
passed in from the user info data,
and then apply that to a rectangle,

00:17:02.590 --> 00:17:04.800
and we get a new rectangle back.

00:17:05.760 --> 00:17:09.720
One important piece at the very end,
we take this rectangle and we

00:17:09.960 --> 00:17:12.580
enlarge it either in the horizontal
or the vertical direction,

00:17:12.580 --> 00:17:14.960
depending on which path we're working on,
by four pixels.

00:17:14.960 --> 00:17:17.140
And so that's an interesting detail.

00:17:17.140 --> 00:17:19.760
Remember,
we're not just doing a shear transform,

00:17:19.880 --> 00:17:22.320
which turns a rectangle
into a parallelogram.

00:17:22.320 --> 00:17:25.940
We're also using neighboring pixels,
up to four pixels to the left,

00:17:26.030 --> 00:17:27.530
four pixels to the right.

00:17:27.670 --> 00:17:31.250
That's why we expand this rectangle
here by another four pixels

00:17:31.340 --> 00:17:33.640
in the appropriate direction,
to make sure that all

00:17:34.010 --> 00:17:36.220
the data that we needed,
that we need slightly

00:17:36.220 --> 00:17:39.930
outside our working area,
that is going to be read by the kernel.

00:17:39.940 --> 00:17:45.010
And if you ever forget stuff like that,
what you will see if your image gets big,

00:17:45.010 --> 00:17:47.830
you will see little,
typically black lines

00:17:47.830 --> 00:17:49.720
around tile boundaries.

00:17:49.720 --> 00:17:54.070
Because Core Image loaded a tile for you,
which I thought was the right size,

00:17:54.070 --> 00:17:56.460
but you're reading slightly outside.

00:17:56.740 --> 00:18:00.010
You're getting zeros back,
and then you get grayish or black

00:18:00.030 --> 00:18:01.940
lines around tile boundaries.

00:18:04.160 --> 00:18:08.430
OK, so is it all worth it?

00:18:09.040 --> 00:18:12.900
Well, it turns out it's actually pretty
hard to show if you're like

00:18:12.900 --> 00:18:14.860
30 feet away from the screen.

00:18:15.120 --> 00:18:19.860
So I'm doing something here to
kind of exaggerate how this looks.

00:18:19.960 --> 00:18:23.850
I'm taking this image and I'm
rotating it by five degrees and

00:18:23.850 --> 00:18:27.340
then another by five degrees,
and again and again, nine times.

00:18:27.360 --> 00:18:30.790
And what you end up with is an
image which is kind of blurry.

00:18:31.050 --> 00:18:34.130
So I'm exaggerating by using
the fact that I could accumulate

00:18:34.320 --> 00:18:37.160
errors to make this really visible.

00:18:37.160 --> 00:18:41.020
The first step was just
using linear interpolation.

00:18:41.060 --> 00:18:43.560
And now I'm using the
Lancos interpolator,

00:18:43.630 --> 00:18:46.320
doing the same thing,
five degrees each time,

00:18:46.380 --> 00:18:48.780
and you get an image which
is substantially sharper.

00:18:48.800 --> 00:18:53.300
So if you look at zoomed-in version,
the eye is a blurry mess in the

00:18:53.380 --> 00:18:55.040
case of linear interpolation.

00:18:55.130 --> 00:18:57.860
And in the Lancos case,
it is actually pretty nice that

00:18:57.860 --> 00:19:02.090
the scales are still there,
the wrinkles around the eye and so on,

00:19:02.160 --> 00:19:04.960
so quite a bit of detail and
a bit of detail got preserved.

00:19:06.200 --> 00:19:10.390
Every now and then we get asked why does
Core Image doesn't support a bicubic

00:19:10.500 --> 00:19:15.200
interpolator because it's really popular
in a bunch of image processing programs.

00:19:15.200 --> 00:19:18.910
And, well,
the nice thing about the implementation

00:19:18.910 --> 00:19:22.200
we're having here is it takes
the kernel as a lookup table.

00:19:22.200 --> 00:19:24.200
So we don't have to use
the Lancus function.

00:19:24.200 --> 00:19:25.190
You can use anything.

00:19:25.200 --> 00:19:28.140
Just, in fact,
when you look at the sample code,

00:19:28.300 --> 00:19:32.070
there's a piece of code that is commented
out which does the bicubic interpolation

00:19:32.260 --> 00:19:35.200
and fills in the table appropriately.

00:19:35.200 --> 00:19:38.710
So if you do that the same way,

00:19:39.860 --> 00:19:43.500
What you're seeing here is that the
result of the bicubing interpolation

00:19:43.500 --> 00:19:45.170
is kind of over sharpened,
you know,

00:19:45.170 --> 00:19:46.940
local contrast kind of went wacky.

00:19:47.270 --> 00:19:49.810
And the reason is the...

00:19:49.930 --> 00:19:52.620
The actual kernel has kind
of exaggerated side lobes,

00:19:52.790 --> 00:19:54.910
which causes a bit of
a sharpening effect,

00:19:54.960 --> 00:19:58.040
and if I do that enough,
you can exaggerate that way.

00:19:58.040 --> 00:20:01.160
So there's nothing wrong with, you know,
making images sharp.

00:20:01.340 --> 00:20:03.220
However,
I would argue this shouldn't be a

00:20:03.220 --> 00:20:05.000
side effect of the rotate filter.

00:20:05.080 --> 00:20:07.040
If you want sharpness,
you should use a sharpen filter,

00:20:07.040 --> 00:20:09.260
therefore you can control
where it happens and how

00:20:09.260 --> 00:20:12.230
much sharpness you introduce,
and it's not a side effect

00:20:12.230 --> 00:20:14.180
of a geometry operation.

00:20:15.490 --> 00:20:18.180
So the last thing
I would like to show is,

00:20:18.180 --> 00:20:22.270
well, doing this rotation nine times is
really just for illustration purposes,

00:20:22.270 --> 00:20:25.640
and you should never do this because
clearly there are losses and there is,

00:20:25.660 --> 00:20:27.560
you know, performance impact and
that kind of stuff.

00:20:27.560 --> 00:20:31.370
So if I'd used the Lancashire Rotate
Filter and do it in a single pass,

00:20:31.370 --> 00:20:32.710
how does it look like?

00:20:32.790 --> 00:20:36.510
And people in the rows closer to
the screen will see a difference

00:20:36.640 --> 00:20:40.220
that doing a single iteration
is still of higher quality than

00:20:40.350 --> 00:20:42.510
doing the nine iteration step.

00:20:42.890 --> 00:20:47.120
But the difference is now pretty subtle,
so it shows that there are losses,

00:20:47.120 --> 00:20:49.890
but they are not that
tragic at this point.

00:20:51.360 --> 00:20:54.630
Okay, so there's another example
I would like to talk about.

00:20:54.740 --> 00:21:02.200
Frank was saying that Core Image does its
work in the linear working color space.

00:21:02.220 --> 00:21:04.830
And you might think for something
simple like rotating an image,

00:21:04.830 --> 00:21:06.200
that doesn't really matter.

00:21:06.200 --> 00:21:10.200
Couldn't you just work in whichever
color space you are and you're done?

00:21:10.590 --> 00:21:15.190
There is a difference,
which I'm trying to illustrate here.

00:21:15.200 --> 00:21:21.330
I'm taking the really boring image on
the left side with green and magenta,

00:21:21.330 --> 00:21:23.200
and I rotate it by 10 degrees.

00:21:23.200 --> 00:21:26.120
The middle one rotates it in
the nonlinear working space,

00:21:26.200 --> 00:21:28.200
so it's essentially in device space.

00:21:28.200 --> 00:21:31.310
And on the right side we're using
what every Core Image is doing by

00:21:31.310 --> 00:21:34.200
converting it to a linear color space,
rotate it,

00:21:34.200 --> 00:21:36.200
and convert it to the target color space.

00:21:36.200 --> 00:21:42.200
So you'll see that there are a
bunch of dark pixels in the middle.

00:21:42.200 --> 00:21:46.390
And the reason for that is
In a nonlinear color space,

00:21:46.390 --> 00:21:49.110
say gamma 2.2 or 1.8,

00:21:49.670 --> 00:21:53.870
A blend between green and magenta,
or pretty much any colors that

00:21:53.970 --> 00:21:57.530
are sufficiently far away from
each other in the color cube,

00:21:57.660 --> 00:22:01.600
results in a color which is darker
than either of those colors.

00:22:01.600 --> 00:22:04.800
And that's why you get these kind
of slight aliasing artifacts,

00:22:04.860 --> 00:22:07.360
because it didn't work
in a linear color space.

00:22:07.360 --> 00:22:11.970
So keep that in mind if you're
doing high quality image processing,

00:22:11.970 --> 00:22:15.050
you know,
how working in a linear color space

00:22:15.050 --> 00:22:16.600
matters even for really simple
things like rotating an image.

00:22:17.630 --> 00:22:20.660
Okay, and with that,
I would like to ask Frank back

00:22:20.880 --> 00:22:24.600
up to put it all together.

00:22:30.410 --> 00:22:32.300
Thank you, Ralph.

00:22:32.360 --> 00:22:35.880
So now for this year again,
we have a new sample code that

00:22:35.880 --> 00:22:39.020
we would like to give you,
and it's a Core Image Editor that

00:22:39.020 --> 00:22:42.710
kind of ties our presentation
together a little bit.

00:22:43.340 --> 00:22:46.310
So what do we do in the CI Image Editor?

00:22:46.440 --> 00:22:48.660
First,
we use the CI RAW filter that David was

00:22:48.750 --> 00:22:53.530
talking about to do RAW image processing,
so better photo quality

00:22:53.690 --> 00:22:55.740
that we get out of it.

00:22:55.950 --> 00:22:59.070
Second, we want to use Core Animation,
the new kid on the block,

00:22:59.090 --> 00:23:03.600
and to do a little bit nicer UI and
show you how to integrate those two.

00:23:03.960 --> 00:23:06.880
And third, of course,
it showcases also the new rotation

00:23:06.880 --> 00:23:10.000
filter that Ralph was just talking
about to straighten out an image.

00:23:10.000 --> 00:23:13.230
So with that, I would like to give you
a demo of the application.

00:23:17.870 --> 00:23:21.340
So since we are still actually
in our old application,

00:23:21.340 --> 00:23:23.170
let me show you actually-- oops.

00:23:26.800 --> 00:23:36.000
Let me show you why this
RAW part is so important.

00:23:36.000 --> 00:23:38.950
This is back to the original image.

00:23:41.040 --> 00:23:46.380
What I want to adjust actually
here is now the exposure on it.

00:23:46.520 --> 00:23:50.590
So I need to find the exposure.

00:23:53.600 --> 00:23:56.640
So now with this exposure address,
so this is a JPEG file.

00:23:56.820 --> 00:23:58.500
So it's an 8-bit data source.

00:23:58.580 --> 00:24:02.890
And what I'm trying to do now is
you see how quickly-- it's like

00:24:02.940 --> 00:24:04.600
there's not much more detail in here.

00:24:04.600 --> 00:24:08.080
And if I go bright, it's like, boom,
it washes out immediately to white.

00:24:08.120 --> 00:24:10.460
That's because this is a JPEG file.

00:24:10.500 --> 00:24:14.560
Now with our new sample code that you
find actually attached to the session,

00:24:14.560 --> 00:24:16.540
it's available on the ADC website.

00:24:16.540 --> 00:24:18.160
This should look a little bit different.

00:24:18.160 --> 00:24:19.580
So we use a different image.

00:24:19.840 --> 00:24:21.910
We use a RAW file.

00:24:22.700 --> 00:24:24.140
Open this up here.

00:24:24.140 --> 00:24:26.790
And you see this photo has a problem.

00:24:26.830 --> 00:24:28.600
So we used a contractor
to get this image,

00:24:28.600 --> 00:24:29.820
and he did a mistake.

00:24:29.820 --> 00:24:33.660
It's easy to blame those people.

00:24:33.690 --> 00:24:37.610
So now I'm using actually
the exposure adjust again.

00:24:37.800 --> 00:25:00.100
[Transcript missing]

00:25:03.290 --> 00:25:06.270
Now, as I promised,
we can straighten the image.

00:25:06.390 --> 00:25:10.100
And this, I just grab it here and
straighten it out so that,

00:25:10.100 --> 00:25:12.200
yeah, now it's a nice realigned.

00:25:12.200 --> 00:25:15.480
And all these kind of things,
like you see this little glow and so on,

00:25:15.480 --> 00:25:17.330
that is all done in Core Animation.

00:25:19.680 --> 00:25:22.400
One of the other things that I can do
nicely with the RAW file is actually,

00:25:22.400 --> 00:25:27.190
for instance, look at the real color
temperature setting of it.

00:25:27.230 --> 00:25:29.810
And so we should just show off here, OK,
these are the different ones.

00:25:29.840 --> 00:25:32.800
I just created some
scenes for doing this.

00:25:32.800 --> 00:25:35.640
And say, OK, well,
this is actually how I want this

00:25:35.640 --> 00:25:40.000
picture to look like if I didn't set the
white balance correctly on my camera.

00:25:40.080 --> 00:25:42.830
And of course, we can use some effects.

00:25:43.980 --> 00:25:47.650
And now I can make this look like
a photo from my grandparents,

00:25:47.730 --> 00:25:50.100
kind of like from the 60s.

00:25:50.130 --> 00:25:52.440
And since this is all
done in Core Animation,

00:25:52.490 --> 00:25:55.040
it's also very easy for me to go like,
boom, full screen.

00:25:55.070 --> 00:25:59.030
It nicely animates everything,
showing back, like, for instance,

00:25:59.060 --> 00:26:00.160
this kind of stuff.

00:26:00.210 --> 00:26:02.930
This is all happening in Core Animation.

00:26:02.940 --> 00:26:05.730
Going back, it scales nicely.

00:26:05.780 --> 00:26:08.280
I said I would like to
go back to the slides.

00:26:11.900 --> 00:26:15.990
Thank you.

00:26:16.970 --> 00:26:20.010
So let me walk you through some of
the high level aspects of the code.

00:26:20.210 --> 00:26:22.430
So first of all, as I said,
we're using core animation.

00:26:22.530 --> 00:26:25.690
And we're using a so
called CA tiled layer,

00:26:25.690 --> 00:26:26.700
since we have a really large image.

00:26:26.800 --> 00:26:31.700
This was a 12 megapixel file that
I was using in this demonstration.

00:26:31.710 --> 00:26:34.040
And you notice that there was
little blocks basically showing up.

00:26:34.160 --> 00:26:36.090
This is because we draw
it in little tiles.

00:26:36.290 --> 00:26:39.240
Well,
core animation draws in little tiles.

00:26:39.240 --> 00:26:43.980
And this allows us, first of all,
that this image gets scaled down.

00:26:44.060 --> 00:26:46.940
So we only see basically a
representation on the screen.

00:26:46.940 --> 00:26:49.440
It's, of course,
much smaller than the original size.

00:26:49.440 --> 00:26:53.610
And that has a scale factor that we
can actually use from core animation

00:26:53.610 --> 00:26:57.340
and pass this on to the CI raw filter,
which then is smart enough not

00:26:57.400 --> 00:26:58.900
to process all the data it needs.

00:26:58.900 --> 00:27:02.820
It actually scales it down and only
samples the points that are needed.

00:27:02.820 --> 00:27:06.000
This gives us the nice performance
that we are looking for.

00:27:06.000 --> 00:27:09.120
And the moment basically
I step into full screen,

00:27:09.120 --> 00:27:11.320
I'm sure if this was really
visible here on the projector,

00:27:11.320 --> 00:27:14.100
but you will notice that the
details all of a sudden pop up,

00:27:14.130 --> 00:27:18.150
because now we are using a different
scale factor of the image and we'll draw

00:27:18.150 --> 00:27:20.440
in the background with higher details.

00:27:20.490 --> 00:27:23.460
So the user can already interact
with the image and you can,

00:27:23.600 --> 00:27:27.030
and all the stuff is happening
nicely in the background.

00:27:28.260 --> 00:27:29.790
Now,
how do you get the context when you want

00:27:29.800 --> 00:27:31.290
to draw with a Core Animation layer?

00:27:31.310 --> 00:27:34.040
That might not be as
obvious in the first place,

00:27:34.070 --> 00:27:37.000
but Core Animation provides you, again,
a CG context.

00:27:37.130 --> 00:27:39.120
And as I showed in the beginning,
from that,

00:27:39.120 --> 00:27:42.230
we simply can create our CI context.

00:27:42.570 --> 00:27:44.570
In the moment,
there is still some work that we need

00:27:44.570 --> 00:27:46.200
to do to make it a little bit faster.

00:27:46.200 --> 00:27:48.210
As you noticed,
it was not quite as performing

00:27:48.210 --> 00:27:49.290
as we would like it to see.

00:27:49.610 --> 00:27:53.100
But in Snow Leopard, we are making this,
the Quas-GL integration on this one,

00:27:53.160 --> 00:27:54.500
even a little bit better.

00:27:54.520 --> 00:27:56.610
Now, I can't explain everything
about Core Animation,

00:27:56.680 --> 00:27:58.900
so please check out the
Core Animation sessions.

00:27:58.900 --> 00:28:00.250
There's one also later on today.

00:28:00.260 --> 00:28:04.670
Or definitely look also on the online
documentation of Core Animation.

00:28:07.880 --> 00:28:23.720
How does the drawing code look like?

00:28:23.720 --> 00:28:23.790
First, as I mentioned,
we get the CI context from the

00:28:23.790 --> 00:28:23.790
CG context that gets passed in.

00:28:23.790 --> 00:28:23.790
It's important that you
don't cache this one because

00:28:23.790 --> 00:28:23.790
Core Animation might decide for you,
well, I need to switch the

00:28:23.790 --> 00:28:23.790
context for each drawing.

00:28:24.680 --> 00:28:28.450
Now I'm getting the current
transformation matrix from the context,

00:28:28.450 --> 00:28:31.890
and that allows me to use
the scale factor from it.

00:28:32.580 --> 00:28:35.260
Now you notice that I put
in the synchronization step.

00:28:35.320 --> 00:28:37.760
As I mentioned, all this drawing is
happening asynchronously.

00:28:37.760 --> 00:28:39.330
It's happening on multiple threads.

00:28:39.440 --> 00:28:44.140
So you have to make sure that your code
for the drawing part is thread safe.

00:28:45.040 --> 00:28:48.900
Here I use the scale factor,
and you will see in the real code

00:28:48.900 --> 00:28:51.520
what that does to the CIRAW filter.

00:28:51.930 --> 00:28:57.010
Taking from the CTM value
and passing it down,

00:28:57.010 --> 00:29:01.730
and therefore the CIRAW filter only has
to process certain parts of the data.

00:29:01.960 --> 00:29:05.220
and then I simply draw into our context.

00:29:05.250 --> 00:29:08.180
That is as simple as it
is for the drawing part.

00:29:08.200 --> 00:29:10.160
Now when you would use
something like GDB,

00:29:10.160 --> 00:29:13.660
you would notice, for instance, well,
I get asked like eight times for

00:29:13.660 --> 00:29:15.170
each tile to draw this whole image.

00:29:15.170 --> 00:29:18.900
And you don't see, like, well,
what rectangle do I have to draw?

00:29:18.920 --> 00:29:21.670
You don't have to care about this
because Core Animation actually sets

00:29:21.670 --> 00:29:25.640
up in that CG context a clipping
rectangle which Core Image simply

00:29:25.640 --> 00:29:29.860
honors and will only take basically
that tile of the image to draw.

00:29:29.970 --> 00:29:31.240
It's that simple.

00:29:31.270 --> 00:29:32.210
Let's work for you.

00:29:34.620 --> 00:29:36.820
Now, how did I do these effects?

00:29:36.820 --> 00:29:40.150
And you see here in the screenshot,
I actually used the

00:29:40.230 --> 00:29:42.770
Image UI demo application,
from which I can actually

00:29:42.830 --> 00:29:44.610
export my chain of filters.

00:29:44.700 --> 00:29:47.500
So I created these effects for
like the Ansel Adams effect

00:29:47.500 --> 00:29:52.440
or the old photo style,
and simply export them as

00:29:52.540 --> 00:29:54.380
the CF filter generator.

00:29:54.400 --> 00:29:57.560
And then they act as a single
filter that I simply imported

00:29:57.580 --> 00:29:59.680
now into my application.

00:30:02.310 --> 00:30:05.870
Now, there always comes a time when
we have to debug a problem.

00:30:05.900 --> 00:30:07.950
We all hate it, but it happens.

00:30:08.050 --> 00:30:10.260
It's the nature of the beast.

00:30:11.450 --> 00:30:13.120
Now, what do you do?

00:30:13.210 --> 00:30:15.340
Of course,
everybody knows to work with GDB,

00:30:15.340 --> 00:30:17.460
and there's, like,
for those who want to do a little more of

00:30:17.460 --> 00:30:21.360
the low-level stuff with the OpenGL code,
can use OpenGL Profiler and so on.

00:30:21.400 --> 00:30:24.340
But there's one tool that I would like
to point out today that might not be

00:30:24.470 --> 00:30:27.030
as obvious in working with Core Image,
and that is Dtrace.

00:30:27.170 --> 00:30:30.780
And internally, we started using it for
debugging some of our stuff,

00:30:30.780 --> 00:30:32.900
and had really great results with it.

00:30:32.980 --> 00:30:35.550
Now, Dtrace on its own is a
little bit more complex,

00:30:35.670 --> 00:30:39.210
so I can't give you a full overview here,
but there's plenty of sessions

00:30:39.270 --> 00:30:41.050
on Dtrace that explain all that.

00:30:41.240 --> 00:30:45.020
So what is Dtrace good for
in this particular scenario?

00:30:45.340 --> 00:30:47.870
With Core Image, the nice part is,
first of all, with Dtrace,

00:30:47.890 --> 00:30:49.920
I can do this on any
kind of client machine.

00:30:49.920 --> 00:30:52.920
I don't need to have any kind
of special debug environment.

00:30:52.920 --> 00:30:56.520
If I want to analyze the performance of,
like, who's getting,

00:30:56.520 --> 00:31:00.920
actually calling my drawing code and
which context and so on I get created,

00:31:00.920 --> 00:31:02.660
I mean, yeah, old school style.

00:31:02.660 --> 00:31:05.540
You would put a lot of printfs in there,
and you have to recompile it and try

00:31:05.550 --> 00:31:08.220
it on the client's machine and say,
"Ah, this is actually what the

00:31:08.220 --> 00:31:10.920
problem is." With Dtrace,
you don't have to do that.

00:31:11.070 --> 00:31:12.730
You can simply run on
your client machine,

00:31:12.810 --> 00:31:15.260
and it will, with probes,
actually show you, "Okay,

00:31:15.410 --> 00:31:18.090
that's the one who called it,
and this is actually how

00:31:18.100 --> 00:31:21.180
often you got called,
and this is very useful information,

00:31:21.180 --> 00:31:24.170
particularly for performance debugging,
or even, like, in general, even, like,

00:31:24.300 --> 00:31:27.680
finding out what problems
might occur in my code."

00:31:28.860 --> 00:31:30.900
Now,
you need to know what probes do we have.

00:31:30.980 --> 00:31:33.870
So Core Image has a few of its
custom probes that actually are

00:31:33.880 --> 00:31:36.000
specific to Core Image problems.

00:31:36.200 --> 00:31:40.030
And since it's an Objective-C language
that we use for the API,

00:31:40.030 --> 00:31:45.260
you can actually know all the probes
that you need to know in terms

00:31:45.260 --> 00:31:49.020
of figuring out who's creating
a filter or who's rendering.

00:31:49.020 --> 00:31:52.460
If you don't know them
because you're new to this,

00:31:52.460 --> 00:31:55.570
you can simply use DTrace and query,
okay, give me all the probes

00:31:55.570 --> 00:31:59.380
available in this process on a
CI context or on a CI filter,

00:31:59.400 --> 00:32:03.110
and I can find out what probes
I have and set basically a DTrace

00:32:03.130 --> 00:32:07.090
script that gets triggered whenever
these functions get called.

00:32:07.660 --> 00:32:10.240
So this is just a little
appetizer for DTrace.

00:32:10.240 --> 00:32:14.250
And yeah, just close to your heart,
this is a good debugging tool,

00:32:14.250 --> 00:32:16.620
particularly for performance part.

00:32:18.410 --> 00:32:20.390
So this was a lot today,
hopefully for you.

00:32:20.460 --> 00:32:24.060
And now you want to know, OK,
what can I do next?

00:32:24.130 --> 00:32:25.790
First of all,
we have a bunch of sample code.

00:32:25.880 --> 00:32:29.590
It's already on your disks
in the developer examples.

00:32:29.750 --> 00:32:31.170
Find them in the Quartz and Core Image.

00:32:31.200 --> 00:32:36.270
In addition, we have on the ADC website,
this was often requested from last year,

00:32:36.270 --> 00:32:39.600
our sample code that does
some CI color tracking.

00:32:39.600 --> 00:32:42.820
It's also mentioned in the
NVIDIA book GPU Gems 3.

00:32:42.820 --> 00:32:46.180
There's a whole article about it,
so you can learn more about something

00:32:46.180 --> 00:32:48.000
interesting to do with Core Image.

00:32:48.300 --> 00:32:49.330
Okay.

00:32:49.550 --> 00:32:52.010
I would recommend playing
around with the sample apps,

00:32:52.010 --> 00:32:54.460
concatenate filters,
create interesting effects,

00:32:54.510 --> 00:32:56.930
don't see them as a single
instance that you want to use,

00:32:56.940 --> 00:32:58.850
and don't just use
them for image editing,

00:32:58.850 --> 00:33:01.360
which is the one part,
but also use them like, you know,

00:33:01.360 --> 00:33:03.490
as we've shown,
like these little glow effects

00:33:03.490 --> 00:33:06.520
in the UI to make your UI a
little bit more interesting.

00:33:06.520 --> 00:33:09.490
And if you're in the business
of doing like 2D graphics,

00:33:09.530 --> 00:33:13.080
like using quartz drawing,
we've seen some samples of people who

00:33:13.080 --> 00:33:17.750
do like very nice stuff and actually
creating just a drawing application

00:33:17.780 --> 00:33:21.270
and use actually these CI filters
to give a little bit more real life

00:33:21.310 --> 00:33:26.810
scenarios by creating shadows or
blurriness to give you a depth of field.

00:33:29.200 --> 00:33:31.120
And that's part of,
if there are more questions,

00:33:31.120 --> 00:33:33.470
Alan Schaefer,
who is our contact for you,

00:33:33.480 --> 00:33:35.800
you have his email right here.

00:33:35.800 --> 00:33:38.080
You find the documentation
on our website.

00:33:38.080 --> 00:33:41.640
And with that, I would also like to
point you out to our lab,

00:33:41.700 --> 00:33:43.960
which is shortly after
the session downstairs,

00:33:43.960 --> 00:33:46.750
so you can come and ask
any questions for us.

00:33:46.970 --> 00:33:49.420
Your kernel will evaluate
to zero outside this area,

00:33:49.420 --> 00:33:52.280
and this allows the Core Image Runtime
to do optimizations.

00:33:52.300 --> 00:33:56.740
Now, keep in mind,
DOD that you specify is an upper bound.

00:33:57.320 --> 00:34:01.290
So you can, for example,
just use a bounding box if you wish.

00:34:03.630 --> 00:34:06.240
So for our shear transformation,
this looks like this.

00:34:06.430 --> 00:34:08.820
So this is our first path.

00:34:08.820 --> 00:34:10.200
And the domain of definition is a shape.

00:34:10.370 --> 00:34:11.910
So this is how the shapes look like.

00:34:12.020 --> 00:34:16.510
So to take the source shape,
you have to return a destination shape

00:34:16.660 --> 00:34:19.690
that has essentially a slanted rectangle.

00:34:21.250 --> 00:34:23.960
And in code,
you ask the source for its definition,

00:34:23.960 --> 00:34:26.020
which is a CI filter shape.

00:34:26.100 --> 00:34:28.950
And then we transform it
by a CG-affine transform.

00:34:28.950 --> 00:34:33.190
And the affine transform I'm making
is essentially the shear transform.

00:34:33.380 --> 00:34:36.990
And that's how you get
your domain of definition.

00:34:38.050 --> 00:34:40.750
If you don't specify a
domain of definition,

00:34:40.840 --> 00:34:41.900
that is okay.

00:34:41.970 --> 00:34:46.560
It just means that whenever a
piece of the image is drawn,

00:34:46.620 --> 00:34:48.430
Core Image has to call your kernel.

00:34:48.600 --> 00:34:51.410
And you can imagine if you
have a lot of zeros out there,

00:34:51.460 --> 00:34:54.500
there's optimization
opportunities that you miss.

00:34:54.510 --> 00:34:57.000
For kernels that don't do
anything with geometry,

00:34:57.000 --> 00:35:01.690
typically the domain of definition
of the output is the same as the

00:35:01.690 --> 00:35:03.500
domain of definition of the input.

00:35:03.500 --> 00:35:05.920
So you just ask source domain
of definition and then pass

00:35:06.030 --> 00:35:07.500
that back and you call apply.

00:35:07.500 --> 00:35:10.490
Like a U transform doesn't
change the shape of the image,

00:35:10.500 --> 00:35:12.490
so there's no need to do
anything special there.

00:35:12.500 --> 00:35:17.400
And domain of definition can
sometimes be rather nasty to code.

00:35:17.540 --> 00:35:21.250
It is okay to make the domain
of definition a bit bigger than

00:35:21.250 --> 00:35:24.500
what would be theoretically pure.

00:35:24.540 --> 00:35:27.420
As long as it's not too big,
it's slightly less

00:35:27.490 --> 00:35:29.500
efficient but not tragic.

00:35:31.720 --> 00:35:35.810
Kind of the conceptual opposite
to the domain of definition is

00:35:35.970 --> 00:35:38.080
the region of interest function.

00:35:38.080 --> 00:35:41.170
And that's that callback
I was talking about before.

00:35:41.590 --> 00:35:47.080
Essentially this is the runtime
asks your filter question,

00:35:47.080 --> 00:35:47.080
which is,

00:35:47.490 --> 00:35:52.520
If I want to compute this
area in the destination,

00:35:52.520 --> 00:35:55.000
which part of the source do I need?

00:35:55.150 --> 00:35:59.090
And this allows things like tiling
and efficient use of resources

00:35:59.090 --> 00:36:01.470
if that is implemented correctly.

00:36:02.110 --> 00:36:06.060
Well, in our case, it is a parallelogram.

00:36:06.110 --> 00:36:08.340
And the region of interest function
actually doesn't return a shape,

00:36:08.440 --> 00:36:10.400
it just returns a CG rectangle.

00:36:10.400 --> 00:36:12.810
So you'll return a
bounding box of the area.

00:36:13.000 --> 00:36:17.510
So let me repeat that because
that's a really good source for

00:36:17.770 --> 00:36:20.000
bugs when you get that wrong.

00:36:20.000 --> 00:36:23.650
The question you have to
answer is to render a certain

00:36:23.650 --> 00:36:27.510
rectangle in the destination,
which part of the source is

00:36:27.510 --> 00:36:30.000
needed to perform that operation?

00:36:30.000 --> 00:36:33.770
So that we can upload the proper part
of the textures onto the graphics

00:36:33.770 --> 00:36:35.660
card and these kind of things.

00:36:37.250 --> 00:36:41.940
Okay, so here is the ROI function
for our little rotate filter.

00:36:42.000 --> 00:36:44.120
You get called back,
it's called region off,

00:36:44.260 --> 00:36:47.200
and you get called
back with a sampler ID.

00:36:47.200 --> 00:36:50.840
That's the number of the sampler that
you have in your kernel function.

00:36:50.840 --> 00:36:57.730
So in our case,
sampler ID 0 is the image we

00:36:57.730 --> 00:36:58.190
rotate and sampler ID 1 is
the Lancashire lookup table.

00:36:58.530 --> 00:37:01.500
Destination Rect,
this is the rectangle you want to render.

00:37:01.570 --> 00:37:05.900
And UserInfo is that pointer that we
specified back when we called Apply.

00:37:05.900 --> 00:37:09.590
In our case, that was this
two-dimensional shear vector.

00:37:10.570 --> 00:37:13.730
What this function does is,
if the sampler ID is 1,

00:37:13.730 --> 00:37:18.890
you simply return the 512 by 2 pixels
full rectangle for the lookup table.

00:37:18.910 --> 00:37:23.110
So, to compute every pixel,
we need the entire

00:37:23.110 --> 00:37:25.600
lookup table available.

00:37:26.330 --> 00:37:30.340
For the actual image that we're
doing the shear transform on,

00:37:30.390 --> 00:37:34.840
we again create a CG-affined
transform with the shear vector we

00:37:35.050 --> 00:37:39.720
passed in from the user info data,
and then apply that to a rectangle

00:37:39.840 --> 00:37:42.000
and we get a new rectangle back.

00:37:43.010 --> 00:37:46.880
One important piece at the very end,
we take this rectangle and we

00:37:46.880 --> 00:37:49.940
enlarge it either in the horizontal
or the vertical direction,

00:37:49.940 --> 00:37:52.220
depending on which path we're working on,
by four pixels.

00:37:52.220 --> 00:37:54.380
And so that's an interesting detail.

00:37:54.380 --> 00:37:57.020
Remember,
we're not just doing a shear transform,

00:37:57.020 --> 00:37:59.560
which turns a rectangle
into a parallelogram.

00:37:59.560 --> 00:38:03.200
We're also using neighboring pixels,
up to four pixels to the left,

00:38:03.200 --> 00:38:04.780
four pixels to the right.

00:38:04.920 --> 00:38:08.440
That's why we expand this rectangle
here by another four pixels

00:38:08.440 --> 00:38:10.850
in the appropriate direction,
to make sure that all

00:38:10.850 --> 00:38:13.300
the data that we need,
if we need slightly

00:38:13.300 --> 00:38:17.180
outside our working area,
that is going to be read by the kernel.

00:38:17.180 --> 00:38:21.590
And if you ever forget stuff like that,
what you will see,

00:38:21.590 --> 00:38:24.200
if your image gets big,
you will see little,

00:38:24.200 --> 00:38:26.980
typically black lines
around tile boundaries,

00:38:26.980 --> 00:38:31.800
because Core Image loaded a tile for you,
which I thought was the right size,

00:38:31.800 --> 00:38:34.660
but you're reading slightly outside,
you're getting zeros,

00:38:34.800 --> 00:38:39.190
and then you get grayish or black
lines around tile boundaries.

00:38:39.240 --> 00:38:42.230
Okay, so...

00:38:44.520 --> 00:38:46.220
Is it all worth it?

00:38:46.320 --> 00:38:49.750
Well, it turns out it's actually pretty
hard to show if you're like

00:38:49.860 --> 00:38:52.400
30 feet away from the screen.

00:38:52.400 --> 00:38:57.400
So I'm doing something here to
kind of exaggerate how this looks.

00:38:57.400 --> 00:39:01.740
I'm taking this image and I'm rotating
it by five degrees and then another

00:39:01.740 --> 00:39:04.400
by five degrees and again and again,
nine times.

00:39:04.640 --> 00:39:08.400
And what you end up with is an
image which is kind of blurry.

00:39:08.400 --> 00:39:10.670
So I'm exaggerating,
kind of using the fact that

00:39:10.720 --> 00:39:13.400
I can accumulate errors to
make this really visible.

00:39:13.400 --> 00:39:17.570
If I then, the first step that was just
using linear interpolation.

00:39:17.630 --> 00:39:20.500
And now I'm using the
Lancos interpolator,

00:39:20.500 --> 00:39:23.510
doing the same thing,
five degrees each time,

00:39:23.660 --> 00:39:26.400
and you get an image which
is substantially sharper.

00:39:26.400 --> 00:39:30.330
So if you look at the zoomed in version,
the eye is a blurry mess in the

00:39:30.460 --> 00:39:32.400
case of linear interpolation.

00:39:32.410 --> 00:39:35.570
And in the Lancos case,
it is actually pretty nice that

00:39:35.670 --> 00:39:39.370
the scales are still there,
the wrinkles around the eye and so on.

00:39:39.440 --> 00:39:42.310
So quite a bit of detail got preserved.

00:39:43.520 --> 00:39:47.610
Every now and then we get asked why does
Core Image doesn't support a bicubic

00:39:47.720 --> 00:39:52.500
interpolator because it's really popular
in a bunch of image processing programs.

00:39:52.500 --> 00:39:56.190
And, well,
the nice thing about the implementation

00:39:56.260 --> 00:39:59.500
we're having here is it takes
the kernel as a lookup table.

00:39:59.500 --> 00:40:01.500
So we don't have to use
the Lankos function.

00:40:01.500 --> 00:40:02.420
You can use anything.

00:40:02.500 --> 00:40:05.600
Just, in fact,
when you look at the sample code,

00:40:05.600 --> 00:40:09.500
there's a piece of code that is commented
out which does the bicubic interpolation

00:40:09.500 --> 00:40:12.500
and fills in the table appropriately.

00:40:12.500 --> 00:40:15.750
So if you do that the same way,

00:40:17.090 --> 00:40:20.780
What you're seeing here is that the
result of the bicubing interpolation

00:40:20.830 --> 00:40:22.240
is kind of over sharpened,
you know,

00:40:22.240 --> 00:40:24.780
local contrast kind of went wacky.

00:40:24.880 --> 00:40:26.910
And the reason is the

00:40:27.150 --> 00:40:29.990
The actual kernel has kind
of exaggerated side lobes,

00:40:30.010 --> 00:40:32.200
which causes a bit of
a sharpening effect,

00:40:32.200 --> 00:40:35.330
and if I do that enough,
you can exaggerate that way.

00:40:35.450 --> 00:40:38.430
So there's nothing wrong with, you know,
making images sharp.

00:40:38.570 --> 00:40:40.430
However,
I would argue this shouldn't be a

00:40:40.430 --> 00:40:42.140
side effect of the rotate filter.

00:40:42.140 --> 00:40:44.140
If you want sharpness,
you should use a sharpen filter,

00:40:44.140 --> 00:40:46.360
therefore you can control
where it happens and how

00:40:46.360 --> 00:40:49.500
much sharpness you introduce,
and it's not a side effect

00:40:49.500 --> 00:40:51.470
of a geometry operation.

00:40:52.710 --> 00:40:55.240
So the last thing
I would like to show is,

00:40:55.280 --> 00:40:59.470
well, doing this rotation nine times is
really just for illustration purposes,

00:40:59.470 --> 00:41:02.880
and you should never do this because
clearly there are losses and there is,

00:41:02.910 --> 00:41:04.810
you know, performance impact and
that kind of stuff.

00:41:04.820 --> 00:41:08.470
So if I'd used the Lancashire Rotate
Filter and do it in a single pass,

00:41:08.470 --> 00:41:09.960
how does it look like?

00:41:10.040 --> 00:41:13.760
And people in the rows closer to
the screen will see a difference

00:41:13.890 --> 00:41:17.470
that doing a single iteration
is still of higher quality than

00:41:17.600 --> 00:41:19.760
doing the nine iteration step.

00:41:20.140 --> 00:41:24.380
But the difference is now pretty subtle,
so it shows that there are losses,

00:41:24.380 --> 00:41:26.080
but they are not that
tragic at this point.

00:41:28.580 --> 00:41:31.870
Okay, so there's another example
I would like to talk about.

00:41:31.970 --> 00:41:38.520
Frank was saying that Core Image does its
work in the linear working color space.

00:41:38.520 --> 00:41:41.880
And you might think for something
simple like rotating an image,

00:41:41.880 --> 00:41:43.550
that doesn't really matter.

00:41:43.550 --> 00:41:46.970
Couldn't you just work in whichever
color space you are and you're done?

00:41:46.980 --> 00:41:51.400
There is a difference,
which I'm trying to illustrate here.

00:41:52.400 --> 00:41:58.910
I'm taking the really boring image on
the left side with green and magenta,

00:41:59.070 --> 00:42:00.360
and I rotate it by 10 degrees.

00:42:00.400 --> 00:42:03.340
The middle one rotates it in
the nonlinear working space,

00:42:03.420 --> 00:42:05.400
so it's essentially in device space.

00:42:05.400 --> 00:42:09.450
And on the right side we're using
whatever Core Image is doing by

00:42:09.450 --> 00:42:11.730
converting it to a linear color space,
rotate it and convert it

00:42:11.730 --> 00:42:13.400
to the target color space.

00:42:13.400 --> 00:42:19.400
So you'll see that there are a
bunch of dark pixels in the middle.

00:42:19.400 --> 00:42:26.410
And the reason for that is, color space,
say gamma 2.2 or 1.8.

00:42:26.950 --> 00:42:31.350
A blend between green and magenta,
or pretty much any colors that

00:42:31.350 --> 00:42:35.590
are sufficiently far away from
each other in the color cube,

00:42:35.630 --> 00:42:38.880
results in a color which is darker
than either of those colors.

00:42:38.950 --> 00:42:42.000
And that's why you get these kind
of slight aliasing artifacts,

00:42:42.000 --> 00:42:44.540
because you didn't work
in a linear color space.

00:42:44.560 --> 00:42:49.540
So keep that in mind if you're
doing high quality image processing.

00:42:49.640 --> 00:42:53.900
Working in a linear color space
matters even for really simple

00:42:53.900 --> 00:42:53.900
things like rotating an image.

00:42:54.850 --> 00:42:57.880
Okay, and with that,
I would like to ask Frank back

00:42:58.100 --> 00:43:01.960
up to put it all together.

00:43:07.640 --> 00:43:09.230
Thank you, Ralph.

00:43:09.580 --> 00:43:13.220
So now for this year again,
we have a new sample code that

00:43:13.220 --> 00:43:14.100
we would like to give you.

00:43:14.100 --> 00:43:18.120
And it's a Core Image Editor that
kind of ties our presentation

00:43:18.120 --> 00:43:19.880
together a little bit.

00:43:20.530 --> 00:43:23.520
So what do we do in the CI Image Editor?

00:43:23.620 --> 00:43:25.840
First,
we use the CI Raw filter that David was

00:43:25.840 --> 00:43:30.570
talking about to do raw image processing,
so better photo quality

00:43:30.570 --> 00:43:32.870
that we get out of it.

00:43:33.170 --> 00:43:36.340
Second, we want to use Core Animation,
the new kid on the block,

00:43:36.340 --> 00:43:40.770
to do a little bit nicer UI and
show you how to integrate those two.

00:43:41.210 --> 00:43:44.140
And third, of course,
it showcases also the new rotation

00:43:44.140 --> 00:43:47.260
filter that Ralph was just talking
about to straighten out an image.

00:43:47.260 --> 00:43:50.470
So with that, I would like to give you
a demo of the application.

00:43:55.120 --> 00:43:58.440
So since we are still actually
in our old application,

00:43:58.440 --> 00:44:00.430
let me show you actually-- oops.

00:44:04.200 --> 00:44:13.240
Let me show you why this
RAW part is so important.

00:44:13.260 --> 00:44:16.230
This is back to the original image.

00:44:18.270 --> 00:44:23.630
What I want to adjust actually
here is now the exposure on it.

00:44:23.770 --> 00:44:27.790
So I need to find the exposure.

00:44:30.850 --> 00:44:34.000
So now with this exposure address,
so this is a JPEG file.

00:44:34.050 --> 00:44:35.820
So it's an 8-bit data source.

00:44:35.820 --> 00:44:40.450
And what I'm trying to do now
is you see how quickly-- there's

00:44:40.480 --> 00:44:41.860
not much more detail in here.

00:44:41.860 --> 00:44:45.320
And if I go bright, it's like, boom,
it washes out immediately to white.

00:44:45.350 --> 00:44:47.720
That's because this is a JPEG file.

00:44:47.720 --> 00:44:51.710
Now with our new sample code that you
find actually attached to the session,

00:44:51.720 --> 00:44:53.800
it's available on the ADC website.

00:44:53.800 --> 00:44:55.220
This should look a little bit different.

00:44:55.360 --> 00:44:56.800
So we use a different image.

00:44:57.070 --> 00:44:59.080
We use a RAW file.

00:44:59.900 --> 00:45:01.360
Open this up here.

00:45:01.370 --> 00:45:04.010
And you see this photo has a problem.

00:45:04.080 --> 00:45:06.890
So we used a contractor to get
this image and he did a mistake.

00:45:06.890 --> 00:45:10.900
It's easy to blame those people.

00:45:10.940 --> 00:45:14.900
So now I'm using actually
the exposure adjust again.

00:45:14.900 --> 00:45:18.760
And what you see now is like
how nicely actually the face

00:45:18.780 --> 00:45:22.900
comes out of the rock part,
in this case in Yosemite,

00:45:22.900 --> 00:45:24.840
El Capitan that we see here.

00:45:24.920 --> 00:45:29.000
And this is just because now
when I go a little bit higher,

00:45:29.000 --> 00:45:32.300
you see now how the shadows
come out of the trees.

00:45:32.300 --> 00:45:35.370
I can see more of the details
there because the RAW file has

00:45:35.370 --> 00:45:37.330
so much more data available.

00:45:40.530 --> 00:45:43.620
Now, as I promised,
we can straighten the image.

00:45:43.620 --> 00:45:47.240
And this, I just grab it here and
straighten it out so that,

00:45:47.240 --> 00:45:50.070
yeah, now it's nice and aligned.

00:45:50.100 --> 00:45:53.060
And all these kind of things,
like you see this little glow and so on,

00:45:53.060 --> 00:45:55.790
that is all done in Core Animation.

00:45:56.940 --> 00:46:00.110
One of the other things that I can do
nicely with the RAW file is actually,

00:46:00.110 --> 00:46:04.310
for instance, look at the real color
temperature setting of it.

00:46:04.310 --> 00:46:07.060
And so we should just show off here, OK,
these are the different ones.

00:46:07.100 --> 00:46:09.950
I just created some
scenes for doing this.

00:46:10.040 --> 00:46:15.080
And say, OK, well,
this is actually how I want this

00:46:15.080 --> 00:46:20.150
picture to look like if I didn't set the
white balance correctly on my camera.

00:46:20.150 --> 00:46:20.150
And of course, we can use some effects.

00:46:21.230 --> 00:46:24.910
And now I can make this look like
a photo from my grandparents,

00:46:24.980 --> 00:46:27.170
kind of like from the 60s.

00:46:27.380 --> 00:46:29.640
And since this is all
done in Core Animation,

00:46:29.640 --> 00:46:31.940
it's also very easy for me to go like,
boom, full screen.

00:46:31.940 --> 00:46:35.720
It nicely animates everything,
showing back, like, for instance,

00:46:35.720 --> 00:46:36.950
this kind of stuff.

00:46:36.950 --> 00:46:39.730
This is all happening in Core Animation.

00:46:39.780 --> 00:46:42.440
Going back, it scales nicely.

00:46:42.440 --> 00:46:44.280
Instead,
I would like to go back to the slides.

00:46:49.100 --> 00:46:53.160
Thank you.

00:46:54.160 --> 00:46:57.170
So let me walk you through some of
the high level aspects of the code.

00:46:57.400 --> 00:46:59.740
So first of all, as I said,
we're using core animation.

00:46:59.740 --> 00:47:02.890
And we're using a so
called CA tiled layer,

00:47:02.890 --> 00:47:03.890
since we have a really large image.

00:47:03.990 --> 00:47:08.900
This was a 12 megapixel file that
I was using in this demonstration.

00:47:08.900 --> 00:47:11.230
And you notice that there was
little blocks basically showing up.

00:47:11.350 --> 00:47:13.270
This is because we draw
it in little tiles.

00:47:13.480 --> 00:47:16.440
Well,
core animation draws in little tiles.

00:47:16.440 --> 00:47:21.180
And this allows us, first of all,
that this image gets scaled down.

00:47:21.240 --> 00:47:24.140
So we only see basically a
representation on the screen.

00:47:24.140 --> 00:47:26.640
It's, of course,
much smaller than the original size.

00:47:26.640 --> 00:47:30.820
And that has a scale factor that we
can actually use from core animation

00:47:30.820 --> 00:47:34.590
and pass this on to the CI raw filter,
which then is smart enough not

00:47:34.600 --> 00:47:36.100
to process all the data it needs.

00:47:36.100 --> 00:47:40.020
It actually scales it down and only
samples the points that are needed.

00:47:40.020 --> 00:47:43.200
This gives us the nice performance
that we are looking for.

00:47:43.200 --> 00:47:46.300
And the moment basically
I stepped into full screen,

00:47:46.300 --> 00:47:48.520
I'm not sure if this was really
visible here on the projector,

00:47:48.520 --> 00:47:52.180
but you will notice that the details
all of a sudden pop up because now

00:47:52.180 --> 00:47:55.380
we are using a different scale factor
of the image and we'll draw in the

00:47:55.380 --> 00:47:57.620
background with higher details.

00:47:57.680 --> 00:48:00.780
So the user can already interact
with the image and you can,

00:48:00.790 --> 00:48:04.170
and all the stuff is happening
nicely in the background.

00:48:05.510 --> 00:48:07.020
Now,
how do you get the context when you want

00:48:07.020 --> 00:48:08.600
to draw with the Core Animation layer?

00:48:08.600 --> 00:48:10.990
That might not be as
obvious in the first place,

00:48:11.320 --> 00:48:14.250
but Core Animation provides you, again,
a CG context.

00:48:14.380 --> 00:48:16.380
And as I showed in the beginning,
from that,

00:48:16.440 --> 00:48:19.140
we simply can create our CI context.

00:48:19.140 --> 00:48:21.530
In the moment,
there is still some work that we need

00:48:21.530 --> 00:48:23.250
to do to make it a little bit faster.

00:48:23.340 --> 00:48:25.290
As you noticed,
it was not quite as performing

00:48:25.370 --> 00:48:26.520
as we would like it to see.

00:48:26.520 --> 00:48:28.960
But in Snow Leopard,
we are making the quasi-geo integration

00:48:28.960 --> 00:48:30.620
on this one even a little bit better.

00:48:31.770 --> 00:48:33.720
Now, I can't explain everything
about Core Animation,

00:48:33.720 --> 00:48:35.760
so please check out the
Core Animation sessions.

00:48:35.760 --> 00:48:38.900
There's one also later on today,
or definitely look also on the online

00:48:38.910 --> 00:48:40.520
documentation of Core Animation.

00:48:45.100 --> 00:48:48.860
How does the drawing code look like?

00:48:48.870 --> 00:48:51.780
First, as I mentioned,
we get the CI context from the

00:48:51.780 --> 00:48:53.670
CG context that gets passed in.

00:48:53.760 --> 00:48:56.260
It's important that you
don't cache this one because

00:48:56.310 --> 00:48:59.380
Core Animation might decide for you,
well, I need to switch the

00:48:59.420 --> 00:49:01.030
context for each drawing.

00:49:01.930 --> 00:49:05.720
Now I'm getting the current
transformation matrix from the context,

00:49:05.720 --> 00:49:09.220
and that allows me to use
the scale factor from it.

00:49:09.770 --> 00:49:12.460
Now you notice that I put
in the synchronization step.

00:49:12.510 --> 00:49:14.960
As I mentioned, all this drawing is
happening asynchronously.

00:49:14.960 --> 00:49:16.510
It's happening on multiple threads.

00:49:16.630 --> 00:49:20.160
So you have to make sure that your code
for the drawing part is thread safe.

00:49:22.260 --> 00:49:25.190
See here I use now the
scale factor that I'm,

00:49:25.340 --> 00:49:29.590
and you will see in the real code
what that does to the CIRAW filter.

00:49:29.830 --> 00:49:34.240
Taking from the CTM,
simply a value and passing that down

00:49:34.240 --> 00:49:38.900
and therefore the CIRAW filter only has
to process certain parts of the data.

00:49:39.210 --> 00:49:42.440
and then I simply draw into our context.

00:49:42.500 --> 00:49:45.440
That is as simple as it
is for the drawing part.

00:49:45.450 --> 00:49:47.380
Now when you would use
something like GDB,

00:49:47.390 --> 00:49:50.350
you would notice, for instance, well,
I get asked like eight times for

00:49:50.350 --> 00:49:54.070
each tile to draw this whole image,
and you don't see like, well,

00:49:54.070 --> 00:49:56.140
what rectangle do I have to draw?

00:49:56.180 --> 00:49:59.100
You don't have to care about this
because core animation actually sets up

00:49:59.110 --> 00:50:03.160
in that CG context a clipping rectangle,
which core image simply honors,

00:50:03.160 --> 00:50:07.140
and will only take basically
that tile of the image to draw.

00:50:07.230 --> 00:50:09.310
It's that simple, so let's work for you.

00:50:11.870 --> 00:50:14.020
Now, how did I do these effects?

00:50:14.070 --> 00:50:18.050
And you see here in the screenshot,
I actually used the Image UI demo

00:50:18.050 --> 00:50:21.860
application from which I can
actually export my chain of filters.

00:50:21.960 --> 00:50:26.340
So I created these effects for like
either the Ansel Adams effect or the

00:50:26.430 --> 00:50:31.220
old photo style and simply export
them as the CF filter generator.

00:50:31.650 --> 00:50:36.880
And then they act as a single
filter that I simply imported

00:50:36.880 --> 00:50:36.880
now into my application.

00:50:39.550 --> 00:50:43.100
Now there always comes a time
when we have to debug a problem.

00:50:43.120 --> 00:50:45.500
We all hate it, but it happens.

00:50:45.500 --> 00:50:47.490
It's the nature of the beast.

00:50:48.700 --> 00:50:50.370
Now what do you do?

00:50:50.470 --> 00:50:53.480
Of course everybody knows to work
with GDB and there's like for those

00:50:53.480 --> 00:50:56.500
who want to do a little more of the
low level stuff with the OpenGL code

00:50:56.500 --> 00:50:58.160
can use OpenGL Profiler and so on.

00:50:58.200 --> 00:51:00.950
But there's one tool that I would
like to point out today that might

00:51:00.950 --> 00:51:03.860
not be as obvious in working with
Square Image and that is D-Trace.

00:51:03.860 --> 00:51:07.370
And internally we started using it
for debugging some of our stuff and

00:51:07.370 --> 00:51:09.300
had really great results with it.

00:51:10.210 --> 00:51:12.970
Now D-Trace on its own is a little
bit more complex so I can't give

00:51:12.970 --> 00:51:15.580
you a full overview here but
there's plenty of sessions on

00:51:15.670 --> 00:51:17.350
D-Trace that explain all that.

00:51:17.360 --> 00:51:22.180
So what is D-Trace good for
in this particular scenario?

00:51:22.180 --> 00:51:25.260
With Square Image the nice part is
first of all with D-Trace I can do

00:51:25.320 --> 00:51:27.150
this on any kind of client machine.

00:51:27.150 --> 00:51:29.630
I don't need to have any kind
of special debug environment.

00:51:29.640 --> 00:51:33.920
If I want to analyze the performance
of like who's getting actually

00:51:33.920 --> 00:51:38.320
calling my drawing code and which
context and so on I get created.

00:51:38.320 --> 00:51:39.860
I mean yeah old school style.

00:51:39.860 --> 00:51:40.020
You would have to do that.

00:51:40.020 --> 00:51:42.720
Put a lot of printfs in there and
you have to recompile it and try it

00:51:42.720 --> 00:51:45.850
on the client's machine and see ah
this is actually what the problem is.

00:51:45.940 --> 00:51:47.910
With D-Trace you don't have to do that.

00:51:47.910 --> 00:51:51.160
You can simply run on your client
machine and it will with probes

00:51:51.170 --> 00:51:54.220
actually show you okay that's
the one who called it and this is

00:51:54.220 --> 00:51:56.240
actually how often you got called in.

00:51:56.240 --> 00:52:00.250
This is very useful information
particularly for performance debugging

00:52:00.250 --> 00:52:04.880
or even like in general even like finding
out what problems might occur in my code.

00:52:06.100 --> 00:52:08.540
You need to know what probes do we have.

00:52:08.540 --> 00:52:13.670
Core Image has a few of its custom probes
that are specific to Core Image problems.

00:52:13.670 --> 00:52:17.470
Since it's an Objective-C language
that we use for the API,

00:52:17.520 --> 00:52:21.140
you can find out all the probes
that you need to know in terms

00:52:21.140 --> 00:52:25.450
of figuring out who's creating
a filter or who's rendering.

00:52:25.600 --> 00:52:31.650
If you don't know them,
you can simply use DTrace and query,

00:52:31.650 --> 00:52:34.470
"Okay, give me all the probes
available in this process on a

00:52:34.470 --> 00:52:39.160
CI context or on a CI filter,
and I can find out what probes I have and

00:52:39.160 --> 00:52:44.390
set a DTrace script that gets triggered
whenever these functions get called."

00:52:44.910 --> 00:52:47.710
So this is just a little
appetizer for DTrace and,

00:52:47.710 --> 00:52:51.100
yeah, just close to your heart,
this is a good debugging tool

00:52:51.120 --> 00:52:52.670
particularly for performance part.

00:52:55.690 --> 00:52:57.620
So this was a lot today,
hopefully for you.

00:52:57.680 --> 00:53:01.300
And now you want to know, OK,
what can I do next?

00:53:01.350 --> 00:53:03.010
First of all,
we have a bunch of sample code.

00:53:03.100 --> 00:53:04.790
It's already on your disks.

00:53:04.850 --> 00:53:09.300
And the developer examples find
it in the Quartz and Core Image.

00:53:09.340 --> 00:53:13.860
In addition, we have on the ADC website,
this was often requested from last year,

00:53:13.860 --> 00:53:16.820
our sample code that does
some CI color tracking.

00:53:16.820 --> 00:53:20.100
That's also mentioned in the NVIDIA book,
GPU Gems 3.

00:53:20.190 --> 00:53:24.720
So you can learn more about something
interesting to do with Core Image.

00:53:26.240 --> 00:53:28.230
I would recommend play
around with the sample apps,

00:53:28.380 --> 00:53:30.390
concatenate filters,
create interesting effects,

00:53:30.500 --> 00:53:32.790
don't see them as a single
instance that you want to use.

00:53:32.800 --> 00:53:35.720
And don't just use them
for this image editing,

00:53:35.720 --> 00:53:38.320
which is the one part,
but also use them like, you know,

00:53:38.320 --> 00:53:40.660
as we've shown,
like these little glow effects in the UI,

00:53:40.660 --> 00:53:43.280
so to make your UI a little
bit more interesting.

00:53:43.280 --> 00:53:46.220
And if you're in the business
of doing like 2D graphics,

00:53:46.220 --> 00:53:49.720
like using quartz drawing,
we've seen some samples of people who

00:53:49.720 --> 00:53:54.500
do like very nice stuff and actually
creating just a drawing application

00:53:54.530 --> 00:53:58.150
and use actually these CI filters
to give a little bit more real life

00:53:58.150 --> 00:54:02.370
scenarios by creating shadows or
blurriness to give you a depth of field.

00:54:05.940 --> 00:54:07.910
And that's part of,
if there are more questions,

00:54:07.920 --> 00:54:10.190
Alan Schaffer,
who is our contact for you.

00:54:10.210 --> 00:54:12.590
You have his email right here.

00:54:12.730 --> 00:54:14.820
You find the documentation
on our website.

00:54:14.820 --> 00:54:18.130
And with that, I would also like to
point you out to our lab,

00:54:18.130 --> 00:54:20.820
which is shortly after
the session downstairs,

00:54:20.880 --> 00:54:23.210
so you can come and ask any questions.