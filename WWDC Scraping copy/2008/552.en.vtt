WEBVTT

00:00:20.350 --> 00:00:23.040
My name is Steve Parker.

00:00:23.040 --> 00:00:30.000
I am the lead of a fairly new team,
the server performance

00:00:30.040 --> 00:00:33.040
team inside 10 Server.

00:00:33.040 --> 00:00:39.120
And I am here to share with you
some of the great stuff that's

00:00:39.180 --> 00:00:42.430
new in Leopard and Snow Leopard.

00:00:42.570 --> 00:00:45.760
I'm not sure I'm going to be able
to compete with the entertainment

00:00:45.810 --> 00:00:47.640
level at the bash last night.

00:00:47.680 --> 00:00:50.080
I assume some of you enjoyed that.

00:00:50.300 --> 00:00:51.200
Thank you.

00:00:51.200 --> 00:00:51.930
Yeah?

00:00:51.930 --> 00:00:53.100
All right.

00:00:53.100 --> 00:00:55.760
So my entertainment is going
to be a much geekier sort.

00:00:55.770 --> 00:00:59.810
It's going to be about systems
and making them fast and scalable.

00:00:59.820 --> 00:01:01.480
So here we go.

00:01:01.570 --> 00:01:04.960
Can I get the – there we go.

00:01:07.000 --> 00:01:10.650
Basically, the talk today,
I'm going to begin by talking about

00:01:10.650 --> 00:01:13.270
software-specific performance gains.

00:01:13.400 --> 00:01:18.960
I'm going to talk a little bit
about how the hardware has improved

00:01:19.080 --> 00:01:20.800
over even just the last year.

00:01:20.800 --> 00:01:26.600
And then I'm going to talk about how
to approach setting up a Leopard server

00:01:26.760 --> 00:01:29.880
system and getting the most out of it.

00:01:29.880 --> 00:01:33.150
And then finally,
I'm going to go through – and this

00:01:33.150 --> 00:01:36.800
is the bulk of the talk – is actually
going to be about diagnosing –

00:01:36.800 --> 00:01:44.980
performance problems and what you can
do on OS X to work out those things.

00:01:45.420 --> 00:01:49.140
So first of all,
I'm going to begin by running through

00:01:49.140 --> 00:01:55.940
a couple of the key performance
gains that stand out in Leopard.

00:01:55.970 --> 00:02:00.860
The first one I wanted to talk about,
this is 10 gigabit ethernet.

00:02:00.860 --> 00:02:05.180
This is based on 1,500 byte MTU packets,
so actually challenging the

00:02:05.180 --> 00:02:07.750
OS with lots of little packets.

00:02:07.810 --> 00:02:13.070
This is over 1.4 times better in Leopard.

00:02:14.670 --> 00:02:18.240
AFP file sharing is over 2x.

00:02:18.260 --> 00:02:21.700
This is almost entirely
SMP scalability improvements,

00:02:21.700 --> 00:02:26.690
so it's putting all of those
cores in new systems to work.

00:02:27.420 --> 00:02:33.740
And this is a model that we have that
simulates a corporate support site,

00:02:33.740 --> 00:02:35.720
sort of like support Applecom.

00:02:35.720 --> 00:02:39.300
So this is based on using
Apache on our system,

00:02:39.400 --> 00:02:44.120
simulating a site with CGI that
actually consults a back-end

00:02:44.120 --> 00:02:47.400
database that presents images,
downloads,

00:02:47.780 --> 00:02:50.130
all that kind of stuff over 3X.

00:02:50.130 --> 00:02:52.020
So how's that?

00:02:56.260 --> 00:03:01.230
So you might be asking,
how do you do that?

00:03:01.270 --> 00:03:03.280
That's an awfully big game.

00:03:03.280 --> 00:03:09.340
So one of the things that Tiger had
was a thing called the funnel lock.

00:03:09.550 --> 00:03:13.460
The funnel lock, unfortunately,
was across about 80

00:03:13.460 --> 00:03:15.310
different system calls.

00:03:15.310 --> 00:03:22.360
And this is an example of a timeline
of a hypothetical mail server,

00:03:22.360 --> 00:03:24.580
web server, and pop client.

00:03:24.580 --> 00:03:28.610
And you notice what there
are is a lot of gap in there.

00:03:28.610 --> 00:03:32.770
And that gap was because this
was a single global lock,

00:03:32.770 --> 00:03:38.510
and you couldn't be in any one of those
system calls on more than one core.

00:03:38.520 --> 00:03:44.610
And this was probably the biggest single
difficulty for server performance.

00:03:44.610 --> 00:03:49.290
Select was one of those system calls,
and as many of you know,

00:03:49.330 --> 00:03:52.740
that's key in many server applications.

00:03:52.960 --> 00:03:54.750
Leopard, gone.

00:03:54.750 --> 00:04:00.770
So all of these system calls
now proceed in parallel.

00:04:01.370 --> 00:04:07.500
And the result is a significant
part of those gains that you see in,

00:04:07.500 --> 00:04:10.090
for example, web performance.

00:04:11.190 --> 00:04:15.700
Something else that wasn't very good
in Tiger was the way the networking

00:04:15.700 --> 00:04:20.560
stack worked for multi-core,
and in particular, the mBuffs,

00:04:20.640 --> 00:04:22.640
which are used for network buffering.

00:04:22.640 --> 00:04:28.000
So those are a global pool,
and that global pool meant

00:04:28.170 --> 00:04:33.250
that as you were processing,
any time you needed to get or

00:04:33.340 --> 00:04:38.570
return an mBuff from the pool,
you were stuck behind a global lock.

00:04:39.550 --> 00:04:44.850
And so only one of those CPUs could
actually be getting work done.

00:04:44.860 --> 00:04:48.080
And if you failed to get that lock,
you'd get rescheduled.

00:04:48.120 --> 00:04:52.960
So that meant your cache gets dumped,
something else tries to start running,

00:04:52.960 --> 00:04:54.970
and if you're unlucky,
that something else also

00:04:54.970 --> 00:04:56.450
tries to go after that lock.

00:04:56.560 --> 00:04:57.680
That's bad.

00:04:59.380 --> 00:05:05.720
In Leopard, a new architecture
that we call the MCache

00:05:05.900 --> 00:05:12.030
has been implemented and although it
still has a global lock across the

00:05:12.030 --> 00:05:19.840
original mBuff pool at the bottom edge,
it has a set of depots which is broken

00:05:19.920 --> 00:05:22.800
up by different sizes of mBuffs.

00:05:23.050 --> 00:05:30.420
So when you go to allocate,
several allocations can

00:05:30.420 --> 00:05:32.290
in fact go on at once.

00:05:32.490 --> 00:05:35.170
That's great,
but there's yet one more change,

00:05:35.230 --> 00:05:39.720
which is allocations from
those depots can be in groups.

00:05:39.720 --> 00:05:44.080
So, for example, if the TCP stack has a
megabyte of data thrown at it,

00:05:44.170 --> 00:05:50.260
it can reach down to the depot and
grab all of the mBufs that it's going

00:05:50.260 --> 00:05:53.580
to need for that in a single call.

00:05:54.020 --> 00:05:58.290
And then once this group of
mBuffs has moved up and is

00:05:58.290 --> 00:06:02.420
in use by a particular core,
there is a per CPU magazine

00:06:03.060 --> 00:06:06.000
and it will use it,
return it to the magazine,

00:06:06.000 --> 00:06:10.030
and if shortly thereafter
there's need for mBuffs again,

00:06:10.030 --> 00:06:13.200
it will simply grab it
out of the magazine.

00:06:13.220 --> 00:06:17.400
And that doesn't entail a
global lock that proceeds in

00:06:17.400 --> 00:06:20.220
parallel across all of the CPUs.

00:06:21.830 --> 00:06:26.380
So this is the next biggest
element of those really

00:06:26.420 --> 00:06:29.000
substantial performance gains.

00:06:29.470 --> 00:06:34.620
Finally, something else in TIGER,
TCP input processing was

00:06:34.690 --> 00:06:37.420
restricted to a single CPU.

00:06:37.870 --> 00:06:41.560
So that meant that no matter how
many networks you stacked up,

00:06:41.560 --> 00:06:44.580
it was all going to get
shuttled across to one core.

00:06:44.620 --> 00:06:49.260
That core would do the processing,
and it would have to migrate back

00:06:49.260 --> 00:06:51.820
out to the individual applications.

00:06:52.010 --> 00:06:55.780
No more in Leopard.

00:06:56.250 --> 00:07:02.660
Network interface is assigned a
separate CPU to do the TCP input

00:07:02.800 --> 00:07:06.940
processing so that all of those
networks proceed in parallel.

00:07:07.010 --> 00:07:12.980
And those web performance results
you see are based on using many NICs,

00:07:13.370 --> 00:07:15.060
not just one.

00:07:15.150 --> 00:07:19.220
So, all right, well that's Leopard,
but Leopard's kind of yesterday.

00:07:19.490 --> 00:07:22.560
So Snow Leopard is the future now.

00:07:23.210 --> 00:07:29.690
And why don't we take a look at what
the web performance in Snow Leopard is.

00:07:30.040 --> 00:07:34.120
Well,
we're up to 4.34 times the performance

00:07:34.150 --> 00:07:39.810
of Tiger and a huge jump against Leopard.

00:07:40.710 --> 00:07:42.410
So how did you do that?

00:07:42.510 --> 00:07:43.480
Right?

00:07:43.480 --> 00:07:47.170
First it's three times faster,
now it's 4.34.

00:07:47.290 --> 00:07:51.600
Well, first of all,
still in Leopard was a

00:07:51.600 --> 00:07:53.880
global lock for IP routes.

00:07:53.990 --> 00:07:58.880
So that meant that at the IP layer,
everything was having to

00:07:58.880 --> 00:08:01.460
contend across a single lock.

00:08:01.460 --> 00:08:05.230
They weren't necessarily
using the same information,

00:08:05.230 --> 00:08:07.480
but the lock had too wide a scope.

00:08:09.160 --> 00:08:13.430
So this is now broken up in Leopard.

00:08:14.570 --> 00:08:23.300
That is in addition to adding
TCP segment offloading support.

00:08:23.300 --> 00:08:27.060
So NIC drivers are now able,
if the hardware is capable,

00:08:27.200 --> 00:08:30.600
of volunteering and saying,
you can send me megabytes of

00:08:30.760 --> 00:08:34.530
data and I'll just break it up
and compute the TCP headers,

00:08:34.640 --> 00:08:38.580
checksums, all that kind of stuff
taken care of for you.

00:08:38.640 --> 00:08:43.520
That gains back a bunch of additional
CPU that you can do web processing with.

00:08:45.600 --> 00:10:36.700
[Transcript missing]

00:10:38.310 --> 00:10:40.890
So there are some other gains
in Snow Leopard that I think

00:10:40.890 --> 00:10:42.280
are really outstanding.

00:10:42.280 --> 00:10:49.760
One of them is that although late
in Tiger we introduced 64-bit user

00:10:49.760 --> 00:10:54.500
processes and you could have far more
than 4 gigabytes of memory in a map,

00:10:54.610 --> 00:10:59.460
each individual map was
limited to 4 gigabyte in size.

00:10:59.460 --> 00:11:02.000
That limitation has been removed.

00:11:02.580 --> 00:11:07.810
In addition, although M-Advise had always
been one of the system calls,

00:11:07.810 --> 00:11:11.550
the virtual memory system
didn't actually use it.

00:11:11.850 --> 00:11:16.640
So M-Advise and Snow Leopard now
allows you a lot of creative and

00:11:16.640 --> 00:11:22.600
interesting ways to work with the
VM system to get better performance.

00:11:23.800 --> 00:11:29.320
An example of that is that you can
M-Map a private memory region to

00:11:29.320 --> 00:11:31.620
create a large chunk of memory.

00:11:32.630 --> 00:11:35.240
You can reach a point in your
program where you decide,

00:11:35.250 --> 00:11:39.950
I'm done with it,
but I might want to use it later.

00:11:39.950 --> 00:11:42.920
And this was a 4-gigabyte segment.

00:11:42.920 --> 00:11:45.730
I spent a lot of time
getting that set up,

00:11:45.730 --> 00:11:50.420
but I can tell the OS,
those pages have nothing valid in them,

00:11:50.480 --> 00:11:53.350
but I don't want to tear down the map.

00:11:57.420 --> 00:11:59.760
You get to keep all that
expensive virtual memory

00:11:59.760 --> 00:12:04.230
mapping work that's been done,
but if you go touch those pages,

00:12:04.230 --> 00:12:08.270
they'll be filled in with zero-based
pages if the VM system ended up

00:12:08.600 --> 00:12:14.640
taking those pages from your process
later on to help another process.

00:12:16.220 --> 00:12:24.600
In addition, as disks grow in size,
you want to do I/Os in fairly big chunks.

00:12:24.640 --> 00:12:27.860
The cluster I/O size within
the kernel has been increased

00:12:27.860 --> 00:12:32.110
from 1 megabyte to 16 megabyte,
provides some substantial increases in

00:12:32.110 --> 00:12:34.880
performance where you're streaming data.

00:12:35.650 --> 00:12:39.470
Besides the VM page queue lock,
there are a bunch of other

00:12:39.950 --> 00:12:42.400
changes that I can't go into.

00:12:42.400 --> 00:12:48.360
There are too many and too complicated
to explain in the amount of time I have.

00:12:48.470 --> 00:12:52.370
I would be happy to discuss that
more in our lab this afternoon,

00:12:52.440 --> 00:12:53.300
however.

00:12:53.300 --> 00:12:58.600
But they remove a number
of additional global locks,

00:12:58.770 --> 00:13:03.090
reduce the amount of time under locks,
and generally improve the parallel

00:13:03.750 --> 00:13:06.090
execution on Snow Leopard.

00:13:06.100 --> 00:13:12.170
And finally,
there are two other interrelated things

00:13:12.170 --> 00:13:18.860
that you won't enjoy the benefits from
unless you go out of your way to do

00:13:18.910 --> 00:13:23.900
so in the Snow Leopard seed build,
but will be in the general release,

00:13:23.900 --> 00:13:27.410
which are a range of
higher resource limits,

00:13:27.420 --> 00:13:31.150
including things like the
maximum number of... the number

00:13:31.150 --> 00:13:35.150
of files you can have open,
as well as the maximum

00:13:35.160 --> 00:13:36.970
number of processes.

00:13:37.290 --> 00:13:41.220
and the 64-bit kernel.

00:13:41.240 --> 00:13:44.230
How many of you went to the K64 talk?

00:13:44.710 --> 00:13:45.540
Not too many.

00:13:45.640 --> 00:13:46.150
Okay.

00:13:46.150 --> 00:13:49.890
Well, so in the server world,
one of the key bits of news

00:13:49.890 --> 00:13:54.010
is that the kernel now has
its own 64-bit address space.

00:13:54.010 --> 00:13:58.990
Server applications benefit a lot
because the file system metadata

00:13:59.100 --> 00:14:03.980
cache and other internal structures
can grow to appropriate sizes

00:14:04.060 --> 00:14:06.880
for really substantial workloads.

00:14:10.290 --> 00:14:13.120
Okay, so is Snow Leopard better?

00:14:13.120 --> 00:14:16.910
Well, first I guess I want
to talk a little bit,

00:14:17.070 --> 00:14:22.540
one of the things that Apple has been
involved with is the updating of specSFS.

00:14:22.900 --> 00:14:31.230
Spec.org is one of the outstanding
industry organizations for auditable,

00:14:31.280 --> 00:14:36.790
verifiable benchmarks,
and we are particularly proud

00:14:36.800 --> 00:14:39.520
to have been involved with this
update of what had originally

00:14:39.520 --> 00:14:45.710
been an NFS-only benchmark,
and it now supports both NFS and Samba.

00:14:46.240 --> 00:14:48.900
And it is extremely rigorous.

00:14:48.900 --> 00:14:52.280
In particular,
it's careful to make sure that

00:14:52.280 --> 00:14:54.620
it watches its own behavior.

00:14:54.620 --> 00:14:57.110
So it doesn't just issue an op.

00:14:57.180 --> 00:15:02.250
It looks at the clock and says, okay,
I issued it now, and it's done now,

00:15:02.410 --> 00:15:04.650
and I'm doing ops at this rate.

00:15:04.650 --> 00:15:07.950
The latency is this much on average.

00:15:07.950 --> 00:15:09.520
The standard deviation is this much.

00:15:09.520 --> 00:15:11.780
And it reports all that information back.

00:15:11.780 --> 00:15:18.620
Makes it an extremely hard benchmark
to do anything that isn't extremely

00:15:19.040 --> 00:15:21.470
clear and obvious what you've done.

00:15:21.470 --> 00:15:24.490
So there's no tricking this benchmark.

00:15:24.790 --> 00:15:31.170
So we released the first commercial
posting of spec SFS with the release

00:15:31.200 --> 00:15:36.740
of the benchmark against Leopard,
8,000 ops per second.

00:15:36.760 --> 00:15:40.750
One thing to notice is that
the overall response time

00:15:40.970 --> 00:15:43.540
on that is 1.4 milliseconds.

00:15:43.570 --> 00:15:46.690
The disk drives on it
have a far longer latency.

00:15:46.750 --> 00:15:54.580
One of the things that means is that
you're not bottlenecked on the disks.

00:15:55.170 --> 00:15:58.740
Yesterday we posted this
new Snow Leopard result.

00:15:58.830 --> 00:16:04.940
This is 18,500 ops per second and
a substantially higher latency.

00:16:04.940 --> 00:16:09.330
It's at least a 50% increase in latency
because we are finally reaching the point

00:16:10.140 --> 00:16:16.680
where we have utilized all of that XServe
and our bottlenecked on the disk drives.

00:16:16.780 --> 00:16:21.680
SpecSFS is a benchmark that
normally you would expect to be

00:16:21.920 --> 00:16:24.660
limited by the disk throughput.

00:16:25.150 --> 00:16:29.350
So I wanted to dive down a
little bit into these results and

00:16:29.470 --> 00:16:31.220
talk about the CPU utilization.

00:16:31.280 --> 00:16:36.910
So notice that on Leopard,
we were basically not able to put

00:16:36.980 --> 00:16:38.910
all eight of those cores to work.

00:16:39.020 --> 00:16:43.200
On Snow Leopard,
we are able to get extremely close

00:16:43.200 --> 00:16:50.250
to putting all eight cores 100%
on the job to service that NFS.

00:16:50.420 --> 00:16:52.750
But notice something else.

00:16:52.920 --> 00:16:54.800
Notice that...

00:16:55.000 --> 00:18:10.600
[Transcript missing]

00:18:10.970 --> 00:18:12.650
That just underscores the gain here.

00:18:12.800 --> 00:18:19.040
So what used to be adequate 48,
15 case hash drives is now

00:18:19.040 --> 00:18:21.740
not adequate in Snow Leopard.

00:18:22.230 --> 00:18:24.640
And then,
just as a sort of a geeky footnote,

00:18:24.760 --> 00:18:30.160
to put this in perspective,
one of the really demanding moments

00:18:30.270 --> 00:18:32.860
of the benchmark is actually
where it creates the file set.

00:18:33.090 --> 00:18:38.300
So the file set is 0.6
terabytes to run this test.

00:18:38.300 --> 00:18:42.940
It creates it at 540
megabytes a second sustained.

00:18:43.720 --> 00:18:46.050
And this is not IO zone
against a raw disk.

00:18:46.250 --> 00:18:53.340
This is file system activity creating
a directory tree with real file names

00:18:53.410 --> 00:18:56.900
just like it would be used in practice.

00:18:57.020 --> 00:19:00.830
So we are extremely
happy with these results,

00:19:01.220 --> 00:19:05.440
and we look forward to even
more gains in the future.

00:19:08.710 --> 00:19:14.300
So, so far I've talked strictly
about the software.

00:19:14.340 --> 00:19:17.300
So that's not the only story here.

00:19:18.750 --> 00:19:23.420
Since the transition to Intel,
we have two XSERVs that have shipped,

00:19:23.450 --> 00:19:29.890
both a four core Woodcrest based system
and an eight core Penryn based system.

00:19:30.720 --> 00:19:40.000
The spec CPU numbers,
so the basic integer SMP score is 2.17x.

00:19:41.010 --> 00:19:42.020
with SpecJBB.

00:19:42.040 --> 00:19:46.540
Now,
SpecJBB is a user-bound process that uses

00:19:46.900 --> 00:19:54.180
Java to simulate an order entry system,
order entry and inventory system, 2.2x.

00:19:55.510 --> 00:19:59.020
And finally,
just memory bandwidth using the

00:19:59.020 --> 00:20:04.100
stream performance benchmark 1.6x.

00:20:05.340 --> 00:20:11.940
So add those both together and you
get a stunningly faster system.

00:20:13.260 --> 00:20:18.190
So now I want to move to talking
about what it is that you can

00:20:18.190 --> 00:20:23.020
do to ensure that you get the
most out of that server system.

00:20:24.270 --> 00:20:26.210
So...

00:20:26.470 --> 00:20:29.240
Keep in mind,
if nothing else from this talk,

00:20:29.330 --> 00:20:33.080
this is an era where the server
is a big brain that's connected

00:20:33.290 --> 00:20:34.930
by a lot of little pipes.

00:20:34.940 --> 00:20:40.000
So to put this in perspective,
that NFS result is based

00:20:40.000 --> 00:20:46.620
on six gigabit subnets,
4.6 gigabits of aggregate traffic,

00:20:46.710 --> 00:20:54.040
four gigabit fiber channel links
to that big array of disk drives.

00:20:55.010 --> 00:20:58.240
So one of the key parts of the
problem of getting the most

00:20:58.690 --> 00:21:02.500
out of server performance is
balancing those different pipes,

00:21:02.500 --> 00:21:05.340
making sure that you
actually put them to use,

00:21:05.430 --> 00:21:08.290
because if you don't,
the power of that server in the

00:21:08.290 --> 00:21:10.470
middle may not be a benefit to you.

00:21:12.890 --> 00:21:18.380
So now I want to start talking about
some very particular bits of planning.

00:21:18.470 --> 00:21:23.030
First of all,
remember I mentioned that each NIC gets

00:21:23.030 --> 00:21:26.620
a specific CPU for its input processing.

00:21:26.660 --> 00:21:28.890
So this diagram

00:21:30.410 --> 00:21:34.620
is a reminder that if you choose
to bond several of your NICs

00:21:34.820 --> 00:21:39.910
into the switch with 802.3ad,
you will in fact be ensuring

00:21:40.150 --> 00:21:44.920
that the input side processing
is bound to a single CPU.

00:21:44.920 --> 00:21:51.590
So if you have a choice between bonding
or multiple subnets with multiple NICs,

00:21:51.680 --> 00:21:56.210
I would recommend that you
go with multiple subnets.

00:21:56.330 --> 00:21:59.960
If you don't,
the next question is whether

00:21:59.960 --> 00:22:02.990
or not you will have a heavy
degree of input traffic.

00:22:03.110 --> 00:22:06.160
If it does have a heavy
degree of input traffic,

00:22:06.160 --> 00:22:08.120
this could become a bottleneck.

00:22:09.550 --> 00:22:11.700
So let's

00:22:13.070 --> 00:22:16.960
If we talk about other
aspects of network planning,

00:22:17.000 --> 00:22:21.040
if you have a substantial number
of clients that are across a

00:22:21.100 --> 00:22:28.540
significant network latency,
so far across the country, the world,

00:22:28.540 --> 00:22:34.080
so if you're talking to iPhones
as they wander around the world,

00:22:34.080 --> 00:22:40.140
one of the things you may find is
that the default network buffer pools

00:22:40.310 --> 00:22:46.280
are not necessarily large enough
to service that load in Leopard.

00:22:48.280 --> 00:22:52.760
And in particular,
you can use this series of tunings,

00:22:52.950 --> 00:22:56.330
first of all running NVRAM boot
args to determine what the

00:22:56.460 --> 00:22:58.130
current system boot arguments are.

00:22:58.160 --> 00:23:08.100
Then adding an NCL equal value and then
rebooting allows you to modify that pool.

00:23:08.100 --> 00:23:12.250
And I'll talk later on about
how to decide when that pool

00:23:12.250 --> 00:23:16.700
needs to be increased in size
and how to choose that size.

00:23:18.130 --> 00:23:23.070
So those were a couple of recommendations
I wanted to make about networking.

00:23:23.570 --> 00:23:26.210
Now let's talk about storage.

00:23:26.580 --> 00:23:33.540
So this is just the supported
list for the Intel XServe.

00:23:33.540 --> 00:23:38.420
So the key takeaway here is there are a
lot of different choices in your storage.

00:23:38.470 --> 00:23:43.130
And I've put details in the
slides about those tradeoffs.

00:23:43.220 --> 00:23:44.400
I'm not going to go over them here.

00:23:44.400 --> 00:23:49.610
But you should think carefully about
what use you will put your server to and

00:23:50.130 --> 00:23:53.480
make sure that you've chosen a storage
pool that's appropriate for your storage.

00:23:53.500 --> 00:23:58.350
So for example, with the NFS benchmark,
it was very clear that if

00:23:58.420 --> 00:24:03.410
I was going to get the maximum,
I needed a very fast storage pool.

00:24:03.590 --> 00:24:07.900
And unless I mention otherwise,
that's probably the storage

00:24:08.420 --> 00:24:11.200
subsystem I'm using in this talk.

00:24:12.880 --> 00:24:18.060
So once you've chosen what you're
going to actually store it on,

00:24:18.070 --> 00:24:19.860
you need to decide how
it's going to be organized.

00:24:19.860 --> 00:24:22.420
So we have several
different choices here.

00:24:22.420 --> 00:24:23.940
One is XAN.

00:24:23.940 --> 00:24:29.960
This is especially good choice when
you need scalable IO bandwidth,

00:24:29.960 --> 00:24:34.760
when you want to be able to
incrementally increase the amount

00:24:35.100 --> 00:24:41.490
of traffic to a file system,
and especially if it's a large data set.

00:24:41.580 --> 00:24:46.720
And so you are not going to want to
reformat it or move it in any way.

00:24:46.720 --> 00:24:50.750
So XAN is an excellent choice for that.

00:24:51.660 --> 00:24:57.250
If the utilization of the files is
strictly local to each system or if

00:24:57.460 --> 00:25:03.280
you're intending to reshare it via NFS,
AFP, or SMB,

00:25:03.280 --> 00:25:07.790
you should choose HFS Plus today.

00:25:08.120 --> 00:25:14.700
That does have one drawback,
which is HFS+ has a single B-tree,

00:25:14.810 --> 00:25:16.230
single catalog file.

00:25:16.370 --> 00:25:20.440
That's a serializing point when
there is a substantial rate of

00:25:20.440 --> 00:25:23.200
change on the file system metadata.

00:25:23.320 --> 00:25:28.380
So adding new files, removing files,
appending to files.

00:25:28.640 --> 00:25:34.300
Those operations have a limited
scalability on systems today.

00:25:34.910 --> 00:25:39.160
So in that case,
you may wish to consider how many file

00:25:39.190 --> 00:25:42.280
systems that you need to break that into.

00:25:42.770 --> 00:25:48.140
And finally, as we announced at the 10
Server State of the Union,

00:25:48.140 --> 00:25:54.790
ZFS is going to be supported.

00:25:57.120 --> 00:26:01.460
So we are very excited about that,
and that does remove many of those

00:26:01.660 --> 00:26:05.120
scalability limits that HFS+ has.

00:26:05.140 --> 00:26:11.070
We look forward to that as
something moving forward.

00:26:11.320 --> 00:26:14.010
Finally,
here's a collection of a bunch of the

00:26:14.010 --> 00:26:15.770
services that come with 10 Server.

00:26:15.800 --> 00:26:20.410
So in particular, those four at the top,

00:26:20.600 --> 00:26:24.340
When you are planning a
multi-machine deployment,

00:26:24.340 --> 00:26:29.800
one of the things that you should not
do is divide it up in that kind of way.

00:26:29.800 --> 00:26:36.180
All of those services at the top are
what I call multi-process services.

00:26:36.180 --> 00:26:39.640
So they are starting multiple
processes to do their work.

00:26:39.700 --> 00:26:43.910
So for example, for SMB,
there is a daemon present for every

00:26:44.050 --> 00:26:46.510
SMB connection on that server.

00:26:46.520 --> 00:26:50.480
There is a 2500 process
link to the server.

00:26:50.500 --> 00:26:53.920
There is a limit in Leopard,
and that limit can very quickly

00:26:54.100 --> 00:26:56.200
become a constraining factor.

00:26:56.200 --> 00:27:00.290
So instead,
a far better approach is to begin by

00:27:00.380 --> 00:27:06.250
thinking about those multi-process
services and choosing to divide

00:27:06.330 --> 00:27:10.400
those up across different systems,
and then,

00:27:10.400 --> 00:27:16.790
based on what capacity is left over,
choose to assign different services

00:27:16.790 --> 00:27:20.480
to the various servers that you have.

00:27:20.500 --> 00:27:20.990
have.

00:27:22.970 --> 00:27:26.980
So those are the choices to keep
in mind as you plan 10 server

00:27:27.180 --> 00:27:29.710
installations for performance.

00:27:29.740 --> 00:27:34.910
There's one other thing that I wanted
to just mention more so you would be

00:27:34.910 --> 00:27:39.830
aware and for troubleshooting purposes,
which is somewhere late in Tiger,

00:27:39.830 --> 00:27:44.560
a file called etsyrc.server
slipped into the release.

00:27:44.680 --> 00:27:48.880
That file is our sort
of tuning master pilot.

00:27:50.070 --> 00:27:52.570
And what it does is it makes
a variety of adjustments to

00:27:52.570 --> 00:27:54.100
the behavior of the system.

00:27:54.100 --> 00:27:57.660
So in particular,
if you're in a situation

00:27:58.340 --> 00:28:02.680
where you have an OS X system,
desktop system, and a server,

00:28:02.680 --> 00:28:07.120
and one of them acts differently,
if it's a performance-related tuning,

00:28:07.120 --> 00:28:09.260
this is probably where it is.

00:28:09.360 --> 00:28:11.330
This is probably where
the difference comes from.

00:28:11.340 --> 00:28:15.560
In particular,
we set TCP behavior to be more

00:28:15.560 --> 00:28:19.720
friendly to Windows TCP implementation.

00:28:19.900 --> 00:28:24.100
And most of the other ones
are all memory-dependent.

00:28:24.160 --> 00:28:27.360
They are things like the file
system metadata cache and the

00:28:27.360 --> 00:28:29.340
maximum number of processes.

00:28:29.460 --> 00:28:32.480
Normally,
there's not a reason to change it,

00:28:32.480 --> 00:28:34.770
but I wanted you to be aware of it.

00:28:34.880 --> 00:28:37.670
Accompanying this talk
is a KBase article,

00:28:37.670 --> 00:28:40.060
which will be available shortly.

00:28:40.060 --> 00:28:45.890
That KBase article will go into
more detail on what each of those

00:28:46.320 --> 00:28:49.800
parameters tunes and when it's used.

00:28:49.960 --> 00:28:52.350
And it would be appropriate
for you to make adjustments

00:28:52.490 --> 00:28:54.130
if you have a special case.

00:28:54.140 --> 00:28:56.140
We hope you don't have special cases.

00:28:56.140 --> 00:28:58.510
We do our best to eliminate that.

00:28:59.360 --> 00:29:00.800
All right.

00:29:00.840 --> 00:29:05.340
So you've done those
things to plan your server.

00:29:05.360 --> 00:29:10.060
You've built out the servers,
installed everything.

00:29:10.090 --> 00:29:11.770
Now it's running.

00:29:11.890 --> 00:29:12.690
How good is it?

00:29:12.880 --> 00:29:14.840
How do you tell?

00:29:14.870 --> 00:29:20.140
Also associated with that KBase article,
we are releasing a script which

00:29:20.140 --> 00:29:22.400
we use a lot called Top Guide.

00:29:22.450 --> 00:29:26.240
Now, don't get out your binoculars.

00:29:26.240 --> 00:29:31.190
We're not going to ask you to
read the slide at that level.

00:29:31.190 --> 00:29:31.190
But Top

00:29:31.870 --> 00:29:35.520
I'm going to take the output that
it produces and break it down.

00:29:35.810 --> 00:29:41.280
This is basically harvesting top minus
D output and summarizing it over time.

00:29:41.280 --> 00:29:44.610
It can save it into a log file
and some other cute little things.

00:29:44.610 --> 00:29:48.480
But this is what we use as our
top level as we investigate

00:29:48.480 --> 00:29:50.680
how a system is performing.

00:29:50.680 --> 00:29:54.170
So for example,
the CPU section breaks down

00:29:54.230 --> 00:29:59.110
the percentage CPU utilization
across user system idle as well

00:29:59.190 --> 00:30:01.340
as keeping a running average.

00:30:01.840 --> 00:30:07.770
Now, obviously, if that had said,
you know, I've got 100% utilization,

00:30:07.850 --> 00:30:11.840
well, that's an easy performance problem,
right?

00:30:11.840 --> 00:30:15.920
We know that that means an
application is soaking up more

00:30:15.920 --> 00:30:18.470
CPU perhaps than we would like.

00:30:18.610 --> 00:30:20.580
I'm not actually going
to talk about that case.

00:30:20.580 --> 00:30:22.860
I think there's lots of
other developer resources.

00:30:22.860 --> 00:30:26.270
What I'd actually like to talk about,
though,

00:30:26.270 --> 00:30:31.710
and what I think is often a problem
in the server space is identifying the

00:30:31.820 --> 00:30:34.460
when you have an underutilized CPU.

00:30:34.760 --> 00:30:38.480
So you push load at your
server more and more,

00:30:38.510 --> 00:30:42.200
but there's some point at which it
just stops getting more work done.

00:30:42.240 --> 00:30:44.560
There's lots of CPU left.

00:30:44.810 --> 00:30:52.820
And if there is not a network or
disk storage bandwidth problem,

00:30:52.820 --> 00:30:58.390
one of the key places to look
would be Pthread mutexes.

00:30:58.760 --> 00:31:04.970
So you can trace this sum with SHARP,
but it's also very easy to use

00:31:04.970 --> 00:31:07.500
the new D-trace-based tool,
PLockstat.

00:31:07.500 --> 00:31:11.780
And in particular,
I definitely recommend that you

00:31:11.880 --> 00:31:14.430
use the minus C option there.

00:31:14.440 --> 00:31:20.520
And this gives you a very quick
way to bore in on occasions

00:31:20.520 --> 00:31:24.440
where the PSTAT locking has
caused you performance grief,

00:31:24.550 --> 00:31:30.020
in particular where it has put
threads to sleep perhaps needlessly.

00:31:30.270 --> 00:31:35.400
They break down into mutex block,
reader-writer block for reader,

00:31:35.400 --> 00:31:38.700
and reader-writer block
for writer events.

00:31:38.700 --> 00:31:44.100
And in particular,
you can hone in on how often these

00:31:44.100 --> 00:31:51.760
things are happening and how long
the total amount of sleep time,

00:31:51.760 --> 00:31:55.160
so the total amount of time
threads weren't executing,

00:31:55.190 --> 00:31:56.560
is very easily.

00:31:56.560 --> 00:32:00.560
And in fact, even in some cases I find
without source code,

00:32:00.560 --> 00:32:05.140
it's very easy to look back through
clues from the symbols and get some

00:32:05.370 --> 00:32:07.410
idea of what might be going on.

00:32:07.440 --> 00:32:11.160
So for example, in this case,
I would in fact be quite concerned.

00:32:11.160 --> 00:32:15.090
That one particular lock
that's shown in mutex blocks is

00:32:15.690 --> 00:32:17.510
happening thousands of times.

00:32:17.570 --> 00:32:23.390
If this is, say, a one-second sample,
that's 3,600 reschedules per second.

00:32:23.390 --> 00:32:25.470
This does not sound like efficiency.

00:32:26.140 --> 00:32:30.260
So this would be an indication
of underutilized CPU,

00:32:30.260 --> 00:32:34.880
and it would be time to go
investigate that application.

00:32:36.800 --> 00:32:37.590
All right.

00:32:37.720 --> 00:32:43.130
So sometimes, however,
you get an underutilized CPU where it's

00:32:43.130 --> 00:32:46.290
not necessarily at the application layer.

00:32:46.450 --> 00:32:53.900
One of the possibilities is that you
have an application which is pushing on

00:32:53.900 --> 00:32:59.670
the kernel in ways that are aggravating
a lock on resources inside the OS.

00:32:59.900 --> 00:33:03.620
So you can get a handle
on that from top-minus-D,

00:33:03.630 --> 00:33:06.770
which tells you about
the context switch rate.

00:33:07.200 --> 00:33:11.890
In general, if it's under 100,
a smallish number like that,

00:33:11.890 --> 00:33:14.270
it's almost certainly not a problem.

00:33:14.270 --> 00:33:17.500
A certain amount of context
switching is normal.

00:33:17.500 --> 00:33:22.810
I tend to use a sort of a rule of
thumb on current server systems,

00:33:22.920 --> 00:33:27.720
so a current Mac Pro or
Intel XServe of 250 a second

00:33:27.720 --> 00:33:30.580
or so might get my attention.

00:33:30.580 --> 00:33:33.250
Certainly thousands per
second get my attention.

00:33:33.280 --> 00:33:37.080
Now, it's not guaranteed that
that's actually a problem.

00:33:37.100 --> 00:33:41.770
Some workloads have a need to
very quickly switch between

00:33:42.010 --> 00:33:45.330
many different threads,
but in general,

00:33:45.610 --> 00:33:51.820
that would be a case where I would be
interested in investigating further.

00:33:53.800 --> 00:33:59.030
Finally, I wanted to show you
a couple of key bits.

00:33:59.030 --> 00:34:03.620
On D-Trace, there is a facility called
the lock stat provider.

00:34:03.620 --> 00:34:08.510
The lock stat provider allows
you to look into kernel locking

00:34:08.510 --> 00:34:11.380
primitives and their behavior.

00:34:12.100 --> 00:34:15.780
Now, unfortunately,
there's a lot of that activity.

00:34:15.790 --> 00:34:20.010
In fact, a normal system has hundreds
of thousands or millions of

00:34:20.010 --> 00:34:22.330
lock operations every second.

00:34:22.330 --> 00:34:23.560
That's not uncommon.

00:34:23.560 --> 00:34:29.190
So very key is to restrict lock
stat provider operations to

00:34:29.700 --> 00:34:35.470
using adaptive block if you want
to follow the P-thread mutex,

00:34:35.510 --> 00:34:41.220
sorry, the mutex,
kernel mutex blocking activity.

00:34:41.220 --> 00:34:45.370
And the same applies
for reader-writer locks.

00:34:45.480 --> 00:34:55.160
So trace strictly those block activities,
and that ensures that you don't insert

00:34:55.160 --> 00:35:00.810
D-Trace overhead anywhere except in an
instance where you're getting actual

00:35:00.860 --> 00:35:02.900
data about a performance problem.

00:35:02.900 --> 00:35:04.820
So those are very helpful.

00:35:04.820 --> 00:35:09.390
I'll show a sample output of one
of those scripts a little later on.

00:35:11.220 --> 00:35:12.210
So let's roll back up.

00:35:12.320 --> 00:35:15.680
So we've investigated
the CPU side of things.

00:35:15.680 --> 00:35:19.500
Now let's go and look at disk I/O.

00:35:19.630 --> 00:35:23.820
So top guide brings together
two pairs of columns.

00:35:23.910 --> 00:35:26.610
On the left, the read operations.

00:35:26.690 --> 00:35:29.280
On the right, write operations.

00:35:29.420 --> 00:35:34.300
And then within each,
the number of unique I/O operations and

00:35:34.380 --> 00:35:37.850
the data write in k bytes per second.

00:35:38.190 --> 00:35:44.400
So this gives me a way to look
at aggregate level on my server,

00:35:44.520 --> 00:35:48.100
how much am I pushing
through the disk subsystem.

00:35:48.100 --> 00:35:52.600
And note that this is in
particular what's passing into

00:35:52.670 --> 00:35:54.070
and out of the disk drive.

00:35:54.110 --> 00:35:58.100
So there may be more file
system activity than this,

00:35:58.100 --> 00:36:01.040
but this is what I'm actually
presenting as load to the disk.

00:36:01.100 --> 00:36:03.010
And for example,
one of the things that I might

00:36:03.010 --> 00:36:05.100
take away from this sample of data,
that through the disk,

00:36:05.100 --> 00:36:05.100
I'm actually pushing through the disk.

00:36:05.100 --> 00:36:05.610
So this gives me a way to look
at aggregate level on my server,

00:36:05.610 --> 00:36:06.100
how much am I pushing
through the disk subsystem.

00:36:06.100 --> 00:36:06.100
And note that this is in
particular what's passing into

00:36:06.100 --> 00:36:06.100
and out of the disk drive.

00:36:06.100 --> 00:36:06.100
So there may be more file
system activity than this,

00:36:06.100 --> 00:36:06.100
but this is what I'm actually
presenting as load to the disk.

00:36:06.100 --> 00:36:06.610
And for example,
one of the things that I might

00:36:06.610 --> 00:36:07.100
take away from this sample of data,
that through the disk,

00:36:07.100 --> 00:36:07.100
I'm actually pushing through the disk.

00:36:07.100 --> 00:36:11.370
That third line, if I look at both read
and write together,

00:36:11.430 --> 00:36:15.500
that's over 230 unique IOs a second.

00:36:15.500 --> 00:36:19.060
If I had an XSERV with
a single SATA drive,

00:36:19.060 --> 00:36:21.220
I would be concerned.

00:36:21.220 --> 00:36:24.850
That's actually pretty high for
a single SATA drive in terms of

00:36:24.900 --> 00:36:26.750
the number of IOs per second.

00:36:26.760 --> 00:36:33.540
So that actually might be an indication
that it is not always up to the task.

00:36:35.850 --> 00:36:40.700
So I mentioned the HFS+ journal.

00:36:40.810 --> 00:36:43.100
So it turns out there's a cute
little trick that I wanted to

00:36:43.190 --> 00:36:48.240
share with that mutex lock script.

00:36:48.280 --> 00:36:51.590
to actually assess journal impact.

00:36:51.630 --> 00:36:57.550
So this is the output of that script
and it shows you exactly how many

00:36:57.700 --> 00:37:04.180
times per second that something went
to update into a particular HFS plus

00:37:04.250 --> 00:37:07.510
file systems journal and blocked.

00:37:07.510 --> 00:37:12.670
So that particular stack
trace is unique to that event.

00:37:12.670 --> 00:37:19.290
Up at the top it's printing out the
kernel address for that particular file

00:37:19.350 --> 00:37:24.290
systems lock and that bottom number
giving you the blocks per second.

00:37:24.520 --> 00:37:28.790
So in that case that is probably
indicating that the journal

00:37:28.890 --> 00:37:32.150
performance is possibly limiting here.

00:37:32.160 --> 00:37:38.800
179 times a second to stop because
you can't get into the journal to

00:37:39.040 --> 00:37:45.020
update the file system is pretty
high for most disk subsystems and

00:37:45.190 --> 00:37:47.790
it would be huge for a single drive.

00:37:50.670 --> 00:37:55.700
Another way that you can go at assessing
whether or not HFS+ journal performance

00:37:55.820 --> 00:38:00.700
may be at issue is to use FS Usage.

00:38:00.700 --> 00:38:03.120
And I'm also not going to dive into that.

00:38:03.240 --> 00:38:10.370
That's a well-established tool
with ADC articles available on it.

00:38:10.600 --> 00:38:14.650
But one quick thing
I thought I would point out,

00:38:14.680 --> 00:38:18.600
that little W as well
as the number beside it,

00:38:18.600 --> 00:38:21.770
that's telling you both
whether there was an IO wait,

00:38:21.770 --> 00:38:25.480
as in the thread was put to sleep,
and how long that lasted.

00:38:25.660 --> 00:38:32.060
So that select took 1.3 milliseconds
and actually put that process to sleep.

00:38:34.510 --> 00:38:39.460
So in addition,
there is another DTrace script

00:38:39.480 --> 00:38:43.800
which gives you a sort of load
average for disks called I/O pending.

00:38:43.800 --> 00:38:46.170
I also wanted to mention that

00:38:46.340 --> 00:38:51.790
Io pending takes a slightly different
argument form than it does on Solaris.

00:38:51.790 --> 00:38:55.970
So the minus M option,
which allows you to focus on a volume,

00:38:55.970 --> 00:38:58.150
is taking the volume name.

00:38:58.210 --> 00:39:01.540
But if you provide that,
you get a breakdown of a

00:39:01.540 --> 00:39:04.120
particular volume's IO activity.

00:39:04.120 --> 00:39:08.300
And in particular, in this case,
we see that the majority of

00:39:08.370 --> 00:39:10.490
the distribution is at zero.

00:39:10.490 --> 00:39:13.700
So in fact,
the disk is not very overloaded.

00:39:13.700 --> 00:39:16.110
It's got a couple of things.

00:39:16.380 --> 00:39:19.960
It's pending once in a while,
but not too bad.

00:39:20.020 --> 00:39:20.770
So that's a good tool.

00:39:22.970 --> 00:39:30.380
So I wanted to go back up and
dive down into networking.

00:39:30.650 --> 00:39:36.030
Networking is certainly an area that
I could spend hours talking about

00:39:36.110 --> 00:39:42.830
diagnosing network performance problems,
and there are many, many aspects to it.

00:39:42.940 --> 00:39:47.540
But what I do find useful out
of TopGuide is this ability to

00:39:47.540 --> 00:39:53.060
get that high-level idea of in
aggregate what the system is doing,

00:39:53.060 --> 00:39:57.420
and especially in an implied
deployment kind of situation.

00:39:57.780 --> 00:40:00.400
As you get to know the
workload of your server,

00:40:00.400 --> 00:40:03.690
you'll have a fairly good idea
of exactly what to expect.

00:40:05.660 --> 00:40:09.620
But in particular,
as a result of knowing the

00:40:09.710 --> 00:40:13.680
capacity of my setup and my server,
I'm able to look quickly at this

00:40:13.720 --> 00:40:17.560
and work out whether or not I'm
getting close to the network limit.

00:40:18.990 --> 00:40:23.280
Now,
I also mentioned that NCLEqual parameter.

00:40:23.410 --> 00:40:28.070
There are occasions where if
you run out of network buffers,

00:40:28.300 --> 00:40:32.310
the behavior of the system is
that it appears to simply freeze.

00:40:32.310 --> 00:40:35.860
And this is because its
buffers are all committed.

00:40:35.860 --> 00:40:37.890
You send it new traffic.

00:40:37.890 --> 00:40:39.370
It has to throw it away.

00:40:39.370 --> 00:40:42.470
It doesn't even have a
buffer to respond to a ping.

00:40:42.900 --> 00:40:47.020
So, eventually,
if its TCP connections time out,

00:40:47.020 --> 00:40:50.500
it may recover, but that is kind of ugly.

00:40:50.500 --> 00:40:55.440
What you can do to anticipate and
tune for that is to look at net stat

00:40:55.440 --> 00:41:00.750
minus M on your system and follow
those sets of highlighted numbers.

00:41:00.800 --> 00:41:05.160
So, if the left and right hand
of either pair get close,

00:41:05.160 --> 00:41:08.660
as in the top line,
so those are within a couple

00:41:08.660 --> 00:41:14.210
hundred of each other,
less than 10%, that would make me

00:41:14.210 --> 00:41:18.700
concerned that this system is at
risk for having network freezes

00:41:18.700 --> 00:41:22.900
and that you should consider
increasing the cluster size.

00:41:23.070 --> 00:41:27.210
So, in this case, looking at that,
for example,

00:41:27.270 --> 00:41:34.560
I might set an NCLEqual to perhaps 16K,
push up that substantially so

00:41:34.600 --> 00:41:39.980
that there is enough buffer
pool to keep the network moving.

00:41:40.230 --> 00:41:41.860
So that's a key one.

00:41:41.910 --> 00:41:46.280
The KBASE article will have some
additional details about the exact

00:41:46.380 --> 00:41:47.640
numbers to choose and so forth.

00:41:50.420 --> 00:41:58.170
Finally, Spotlight is enabled by
default on all of our systems.

00:41:58.290 --> 00:42:01.360
and it indexes your file systems.

00:42:01.450 --> 00:42:05.520
It provides delightful value
when you're searching for a file,

00:42:05.660 --> 00:42:07.990
but it does come at a cost.

00:42:08.810 --> 00:42:17.210
Under particularly heavy write loads,
it has to evaluate and

00:42:17.210 --> 00:42:17.210
index all of those files.

00:42:17.860 --> 00:42:21.620
So there are several
techniques you can use.

00:42:21.750 --> 00:42:25.980
One is simply to look for
MDS and MDS worker processes,

00:42:26.010 --> 00:42:29.700
which will indicate
the indexing activity.

00:42:30.320 --> 00:42:36.120
You can also choose to selectively
disable indexing on individual files

00:42:36.620 --> 00:42:43.510
by creating a zero length dot no index
file beside either a file or directory.

00:42:43.690 --> 00:42:48.240
In addition,
if you have particular file sets

00:42:48.330 --> 00:42:52.920
that are not of interest to index,
an example might be a MySQL database.

00:42:52.920 --> 00:42:57.440
That's probably not very
interesting to have a MyISAM file

00:42:57.540 --> 00:43:02.330
pop up in a Spotlight search,
and it probably changes a lot.

00:43:02.390 --> 00:43:08.040
So you can organize all of those
files onto a separate file system.

00:43:09.380 --> 00:43:20.080
In addition,
if you would like to keep Spotlight's

00:43:20.140 --> 00:43:32.040
indexing available at all times,
but reverse the...

00:43:33.590 --> 00:43:39.890
put a lower priority on the I/O that
supports spotlight indexing.

00:43:40.630 --> 00:43:43.860
Finally, if you want,
you can also just throw

00:43:43.860 --> 00:43:45.400
the big red switch.

00:43:45.450 --> 00:43:49.500
And that is also, I find,
particularly useful,

00:43:49.540 --> 00:43:52.000
because it's a very quick
and easy way to just say,

00:43:52.060 --> 00:43:54.470
do I care about spotlight
indexing overhead?

00:43:54.490 --> 00:43:56.390
You turn it off, and you watch.

00:43:56.440 --> 00:44:00.300
And a few seconds later,
if you can see something on top guide,

00:44:00.330 --> 00:44:04.510
then you know you have a
performance issue that big

00:44:05.170 --> 00:44:08.460
with the spotlight indexing.

00:44:08.810 --> 00:44:09.690
All right.

00:44:10.070 --> 00:44:17.600
So that was kind of the survey
of the tools and techniques that

00:44:17.600 --> 00:44:23.250
we use as our primary triage
for these particular performance

00:44:23.250 --> 00:44:26.520
problems for server performance.

00:44:26.650 --> 00:44:31.230
I now wanted to talk about
a real example of this.

00:44:31.230 --> 00:44:37.410
So I had a customer that had a
one terabyte production database.

00:44:37.430 --> 00:44:43.730
It was extremely critical resource
and it was just not doing much.

00:44:43.730 --> 00:44:46.480
It was a tiny amount of CPU.

00:44:46.480 --> 00:44:49.870
It was and it didn't
matter what they did.

00:44:49.870 --> 00:44:52.390
It just didn't seem to go fast.

00:44:52.480 --> 00:44:57.910
So I was working with them
to help examine this problem.

00:44:57.990 --> 00:45:01.030
So beginning with top guide,

00:45:01.240 --> 00:45:07.200
I ended up being able to very quickly
identify their entire database was

00:45:07.210 --> 00:45:13.760
striped with software RAID across
two 750 gigabyte SATA drives.

00:45:13.910 --> 00:45:18.530
And the number of IOs per second
that they were throwing at it was

00:45:18.530 --> 00:45:23.320
absolutely as much as you could
get out of that class of drive.

00:45:23.350 --> 00:45:24.830
So they were IO bound.

00:45:24.830 --> 00:45:33.010
By moving them onto SAS drives
for that database was an

00:45:33.350 --> 00:45:37.350
immediate 3x gain in performance.

00:45:38.100 --> 00:45:43.050
But that 3x gain was a hard cap also.

00:45:43.290 --> 00:45:46.630
In particular,
we still found that although we had

00:45:46.670 --> 00:45:52.660
lots more I/O capacity now than was
actually being done and the network

00:45:52.820 --> 00:45:57.690
traffic to the MySQL database was tiny,
still it wouldn't go any faster.

00:45:57.790 --> 00:46:01.010
You could push more load at it,
no faster.

00:46:01.190 --> 00:46:04.190
So we ran PLockstat-C.

00:46:04.330 --> 00:46:07.150
So with PLockstep-C,
we were able to see that indeed

00:46:07.530 --> 00:46:12.130
there was a ton of Pthread
lock thrashing inside MySQL.

00:46:12.240 --> 00:46:21.240
So investigation led us to discover that
with MyISAM indexed tables on MySQL,

00:46:21.240 --> 00:46:24.240
there is a global key cache by default.

00:46:24.280 --> 00:46:30.000
So every single table was
sharing a process-wide,

00:46:30.030 --> 00:46:35.490
MySQL server-wide global
lock and everybody wanted in.

00:46:35.540 --> 00:46:42.890
So this was seeing in fact on the
order of 4,000 reschedules a second

00:46:42.890 --> 00:46:49.120
and it was unable to get above about
10% CPU utilization because of that.

00:46:49.380 --> 00:46:50.940
So, what now?

00:46:51.230 --> 00:46:57.670
Well, we moved a few of the key tables
out to a separate key cache.

00:46:57.720 --> 00:47:00.200
There's some
MySQL configuration for that.

00:47:00.280 --> 00:47:02.700
But it didn't actually go much faster.

00:47:02.770 --> 00:47:09.700
So, all right, the next thing was to dig
in deeper with Dtrace.

00:47:09.720 --> 00:47:14.620
And what we did with Dtrace was to
couple gathering information from

00:47:14.620 --> 00:47:21.200
function calls within MySQL to work
out what table was actually involved.

00:47:21.250 --> 00:47:27.700
And having identified the table,
it turns out there was a merge table,

00:47:27.700 --> 00:47:32.590
so a table that's a view
across four other tables.

00:47:32.820 --> 00:47:35.650
And the light went on.

00:47:35.670 --> 00:47:38.300
As soon as I mentioned that
to the database administrator,

00:47:38.300 --> 00:47:39.380
he was like, ooh.

00:47:39.380 --> 00:47:43.340
So that was a query that
was being done as a,

00:47:43.340 --> 00:47:47.520
oh, you know,
this might be an easy check and

00:47:47.520 --> 00:47:50.860
this might save us work later on.

00:47:50.860 --> 00:47:51.800
Let's just do this check.

00:47:52.690 --> 00:47:57.050
Well, this check was, in fact,
completely pounding on the

00:47:57.050 --> 00:47:59.680
key cache lock for that table.

00:47:59.680 --> 00:48:04.940
There was pretty much no way out of that.

00:48:04.980 --> 00:48:08.350
However, it turns out that that
check was speculative.

00:48:08.450 --> 00:48:10.490
The application didn't need it.

00:48:10.490 --> 00:48:11.390
We removed it.

00:48:11.540 --> 00:48:15.750
And at this point,
the customer can only tell me that he

00:48:15.750 --> 00:48:18.720
doesn't know how much faster it is.

00:48:18.720 --> 00:48:22.220
He hasn't been able to get the load
cranked up high enough to find it.

00:48:22.320 --> 00:48:23.890
find the limit.

00:48:24.690 --> 00:48:29.250
So I wanted to give you that
story as kind of a way to tie in.

00:48:29.260 --> 00:48:34.000
I know I've gone across the top
of a lot of different techniques,

00:48:34.000 --> 00:48:40.680
but I wanted to give you that sort of
idea of how in real life these tools

00:48:40.680 --> 00:48:46.990
apply and can become a way to get
at and solve performance problems.

00:48:47.730 --> 00:48:49.360
All right.

00:48:49.500 --> 00:48:53.340
So in summary,
we're in an era with big brains,

00:48:53.610 --> 00:48:59.080
small pipes, and you've got to spend time
to get those things balanced.

00:48:59.130 --> 00:49:02.720
I hope I've given you some tips
and techniques that will help

00:49:03.130 --> 00:49:05.740
you in your setup and diagnosis.

00:49:05.790 --> 00:49:09.460
And in particular,
pointed out some of the newer

00:49:09.460 --> 00:49:14.510
detrace facilities in Leopard
that will help you to do that.

00:49:15.140 --> 00:49:20.920
So, with that,
I guess the other thing I wanted to

00:49:20.920 --> 00:49:29.240
mention is we have a lab coming up this
afternoon and myself and one of my other,

00:49:29.240 --> 00:49:31.750
actually a couple of my other
team members will be there.

00:49:31.750 --> 00:49:36.340
I hope you will come by and we
would love to take your questions.

00:49:36.340 --> 00:49:41.280
We will demonstrate some spec SFS and
spec web performance runs for you.

00:49:41.330 --> 00:49:43.740
So, thank you.