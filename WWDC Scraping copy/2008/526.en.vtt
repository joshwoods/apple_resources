WEBVTT

00:00:20.280 --> 00:00:22.750
My name is Kim Silverman.

00:00:22.840 --> 00:00:26.040
I manage the spoken
language technologies.

00:00:26.100 --> 00:00:27.330
We do speech synthesis.

00:00:27.550 --> 00:00:29.100
We did the Alex voice in Leopard.

00:00:29.100 --> 00:00:31.330
Who has heard Alex?

00:00:32.500 --> 00:00:33.620
Thank you.

00:00:33.620 --> 00:00:36.040
We do other cool stuff.

00:00:36.260 --> 00:00:37.940
We do speech recognition.

00:00:38.040 --> 00:00:43.360
Most relevantly for us today,
we do latent semantic analysis,

00:00:43.550 --> 00:00:47.020
figuring out what text documents mean.

00:00:47.150 --> 00:00:49.060
Have you ever looked at a
document and said to yourself,

00:00:49.150 --> 00:00:52.260
"What the heck does this mean?" Well,
latent semantic analysis

00:00:52.260 --> 00:00:54.840
figures that out,
and that's quite useful.

00:00:54.900 --> 00:00:58.260
We use it quite successfully
for the junk mail filter.

00:00:58.340 --> 00:01:00.490
We released the API to you folk.

00:01:00.620 --> 00:01:05.900
And in Leopard, we have released new
features that do clustering.

00:01:06.670 --> 00:01:09.820
You know,
any sufficiently advanced technology

00:01:10.390 --> 00:01:13.300
is indistinguishable from magic.

00:01:13.390 --> 00:01:21.010
So to tell you about this magic,
I'd like to introduce the senior

00:01:21.520 --> 00:01:23.810
software engineer who implemented the
Latent Semantic Mapping Framework,

00:01:23.810 --> 00:01:23.810
Dr.

00:01:23.810 --> 00:01:23.810
Matthias Neeracher.

00:01:28.900 --> 00:01:30.550
Good afternoon, everybody.

00:01:30.570 --> 00:01:32.320
And I probably have to correct Kim.

00:01:32.320 --> 00:01:33.600
It's not really magic.

00:01:33.660 --> 00:01:36.530
It's at best,
it's a little protective hex or so.

00:01:36.550 --> 00:01:38.940
You can think of that.

00:01:39.880 --> 00:01:43.300
So, today we're talking about
Latent Semantic Mapping,

00:01:43.300 --> 00:01:48.310
what it is, how it works,
how you can use the API,

00:01:48.310 --> 00:01:51.440
and how you can avoid using the API.

00:01:51.460 --> 00:01:57.680
We're going to discuss how
we used it in Mac OS X,

00:01:57.780 --> 00:02:00.790
and then move on to what's
more important to you,

00:02:00.790 --> 00:02:00.790
how you can use it in your application.

00:02:01.830 --> 00:02:03.650
So what is latent semantic mapping?

00:02:03.780 --> 00:02:07.950
In its most general terms,
latent semantic mapping is a

00:02:08.010 --> 00:02:14.100
technology to analyze text or
analyze other data in fact,

00:02:14.120 --> 00:02:17.560
and classify it into one
of a number of categories.

00:02:17.560 --> 00:02:20.380
Now this is awfully abstract,
so let me demonstrate.

00:02:20.550 --> 00:02:25.020
If you look at /usr/bin,
there are not just binaries in there.

00:02:25.050 --> 00:02:30.960
There are more and more Perl scripts,
Python scripts, Ruby scripts in there.

00:02:31.810 --> 00:02:34.050
And...

00:02:35.140 --> 00:02:39.640
So let's try to use Latent Semantic
Mapping to train up a classifier that

00:02:39.640 --> 00:02:43.440
can tell these types of scripts apart.

00:02:45.080 --> 00:02:47.540
So first of all, we need training data.

00:02:47.570 --> 00:02:50.260
And it turns out we have plenty of that.

00:02:50.370 --> 00:02:52.740
We have lots of libraries installed.

00:02:52.780 --> 00:02:55.780
If you look at it,
you have something like a

00:02:55.780 --> 00:02:58.890
good five megabytes of source
code for these libraries in

00:02:58.890 --> 00:03:00.670
all three languages combined.

00:03:00.730 --> 00:03:08.240
That's more than enough to train
up a recognizer or a classifier.

00:03:08.240 --> 00:03:08.670
So let's train up a Latent
Semantic Mapping classifier.

00:03:09.610 --> 00:03:14.250
And that we can do with a command line
tool that is actually also in /usr/bin.

00:03:14.350 --> 00:03:19.610
It's called lsm for
Latent Semantic Mapping.

00:03:20.300 --> 00:03:29.000
[Transcript missing]

00:03:30.290 --> 00:03:35.250
And we use these source code
libraries as training data.

00:03:35.340 --> 00:03:37.420
Now, that's a quite complex task.

00:03:37.500 --> 00:03:39.800
You read in five megabytes of data.

00:03:39.810 --> 00:03:44.540
You do complex number of numerical
processing that somebody's

00:03:44.620 --> 00:03:46.160
going to talk about later.

00:03:46.220 --> 00:03:50.800
So that's going to take some time,
about a second.

00:03:52.190 --> 00:03:54.500
Now we have our map.

00:03:54.550 --> 00:03:58.260
The five megabytes of training
data is now represented by

00:03:58.260 --> 00:04:01.100
about a megabyte or so of a map.

00:04:01.200 --> 00:04:07.250
We can use that map to evaluate files
to see what category they fall into.

00:04:07.430 --> 00:04:08.530
So we have three categories.

00:04:08.610 --> 00:04:12.820
We have category one is Perl,
category two is Python,

00:04:12.820 --> 00:04:14.940
category three is Ruby.

00:04:15.030 --> 00:04:19.550
So we're going to look at three
particular scripts in Userbin

00:04:19.800 --> 00:04:24.930
and see what door Latent semantic
mapping things they are behind.

00:04:25.840 --> 00:04:29.460
So we see that acLocal,
our guess is that this is going

00:04:29.460 --> 00:04:35.470
to be Perl because category one
has by far the highest score.

00:04:35.680 --> 00:04:40.870
PyDoc, LateN Semantic Mapping makes this
astute guess that this might be Python.

00:04:40.990 --> 00:04:44.850
And GenerateBridgeMetadata,
our guess is that this

00:04:44.920 --> 00:04:46.620
is going to be Ruby.

00:04:46.660 --> 00:04:50.050
And now we're going to cheat
and actually use a method

00:04:50.490 --> 00:04:52.730
We just look at the first
line of these scripts,

00:04:52.730 --> 00:04:57.930
and we find out that, lo and behold,
acLocal is a Perl script,

00:04:58.050 --> 00:05:01.580
Pydoc is a Python script,
and GenerateBridgeMetadata

00:05:01.900 --> 00:05:03.370
is a Ruby script.

00:05:03.480 --> 00:05:07.290
So, in this case, we had 100% success,
although you should not expect

00:05:07.440 --> 00:05:09.290
that to happen every time around.

00:05:09.500 --> 00:05:11.400
That would be truly magic.

00:05:11.400 --> 00:05:15.420
Can we go back to the slides?

00:05:17.870 --> 00:05:20.890
So we use Latent Semantic Mapping.

00:05:21.060 --> 00:05:25.230
The best known example in Mac OS X is
we use it for the junk mail filter

00:05:25.620 --> 00:05:30.020
to assess whether a mail message
is legitimate mail or junk mail.

00:05:30.460 --> 00:05:33.490
Now in Leopard,
we also use it somewhat similarly in

00:05:33.490 --> 00:05:41.080
parental controls to filter out the
evil web pages from the good web pages.

00:05:41.280 --> 00:05:46.430
We also use it in the Japanese input
method in our kana to kanji conversion,

00:05:46.530 --> 00:05:50.800
because if there are multiple
characters with the same reading,

00:05:50.850 --> 00:05:54.610
we can use Latent Semantic Mapping as
one of many methods to disambiguate

00:05:54.610 --> 00:05:57.430
between the ambiguous readings.

00:05:57.530 --> 00:06:01.790
And we use it internally for
localization to use the underlying

00:06:01.820 --> 00:06:07.160
topic of discourse to disambiguate
words that can be translated

00:06:07.160 --> 00:06:09.800
differently in different contexts.

00:06:10.550 --> 00:06:12.820
So you've seen what we do with it.

00:06:12.860 --> 00:06:14.300
How does it work?

00:06:14.350 --> 00:06:16.420
For that,
I would like to bring up a colleague.

00:06:16.430 --> 00:06:18.440
There's going to be some math,
but don't worry,

00:06:18.530 --> 00:06:19.780
it's not going to be on the test.

00:06:20.050 --> 00:06:27.840
Please welcome the scientist,
distinguished scientist who

00:06:27.840 --> 00:06:27.840
brought this technology to Apple,
Dr.

00:06:27.840 --> 00:06:27.840
Jerome Bellegarda.

00:06:32.230 --> 00:06:34.110
Thank you, Matthias.

00:06:34.270 --> 00:06:35.730
So I'm Jerome Bellegarda.

00:06:35.740 --> 00:06:41.300
And what I'd like to do is give you
a little flavor of how LSM works.

00:06:41.300 --> 00:06:44.550
And in some sense,
this is relatively easy,

00:06:45.020 --> 00:06:46.700
because it's all in the name.

00:06:46.700 --> 00:06:50.280
Latent semantic mapping
has three aspects to it.

00:06:50.280 --> 00:06:51.530
Well, it's mapping.

00:06:51.540 --> 00:06:52.520
And it's semantic.

00:06:52.520 --> 00:06:53.140
And it's latent.

00:06:53.260 --> 00:06:54.080
So let's go through it.

00:06:54.080 --> 00:06:57.560
First of all, it's a mapping.

00:06:57.560 --> 00:07:01.660
The concept originated
from information retriever.

00:07:01.730 --> 00:07:06.170
And it deals with entities
such as words and documents.

00:07:06.280 --> 00:07:09.070
And what it does is it
maps those entities,

00:07:09.070 --> 00:07:14.070
which are discrete in nature,
into a continuous space,

00:07:14.070 --> 00:07:16.880
which we'll talk about.

00:07:16.990 --> 00:07:18.740
So second, it's semantic.

00:07:18.930 --> 00:07:23.700
That means it has something to do with
the overall content and the meaning

00:07:23.710 --> 00:07:26.850
which is inside those documents.

00:07:27.240 --> 00:07:28.860
And it's also latent.

00:07:29.000 --> 00:07:31.880
Latent means hidden in the general sense.

00:07:32.100 --> 00:07:36.280
In this particular context,
it means that we're going to leverage

00:07:36.400 --> 00:07:41.980
the co-occurrences between words in order
to infer some of their hidden meaning.

00:07:42.090 --> 00:07:45.800
And that will enable us to
handle things like synonyms and,

00:07:45.800 --> 00:07:47.690
also, multiple senses of the words.

00:07:47.850 --> 00:07:52.730
So for example, when it's well-trained,
the framework knows that car

00:07:52.810 --> 00:07:55.510
and automobile are synonyms.

00:07:55.700 --> 00:08:00.420
Similarly, it knows that bank has to do
with financial institution,

00:08:00.420 --> 00:08:01.470
most likely.

00:08:01.590 --> 00:08:07.000
But also, it's clever enough that if bank
co-occurs with rate in the same document,

00:08:07.000 --> 00:08:11.360
it can infer that the topic of the
document most likely is about finance.

00:08:11.470 --> 00:08:16.660
Whereas if the same bank
co-occurs with a word like river,

00:08:17.020 --> 00:08:20.590
then it's most likely an
article about fishing.

00:08:20.840 --> 00:08:25.200
So what I'd like to do now
is walk you through those

00:08:25.200 --> 00:08:32.040
three aspects of LSM in turn,
starting with mapping.

00:08:32.040 --> 00:08:38.080
So as I mentioned before,
what we have is we sort of gather

00:08:38.080 --> 00:08:39.650
a whole bunch of documents.

00:08:39.880 --> 00:08:41.740
That's called the training corpus.

00:08:41.740 --> 00:08:44.060
And what we're going to do
with those documents is try

00:08:44.060 --> 00:08:48.020
to map them onto a space.

00:08:48.020 --> 00:08:50.890
And in this particular case,
I use a three-dimensional example

00:08:50.890 --> 00:08:52.610
because it's easier to visualize.

00:08:52.650 --> 00:08:55.430
But in general,
it could be fairly complex.

00:08:55.530 --> 00:08:59.080
It's a complex space
with a lot of dimensions.

00:08:59.090 --> 00:09:04.390
And so the point of the exercise is to
take each of the documents that we have

00:09:04.390 --> 00:09:07.030
and map them onto points in that space.

00:09:07.180 --> 00:09:11.220
So in this particular case,
the triangles,

00:09:11.220 --> 00:09:14.480
the red triangles that you see,
are just representation of the

00:09:14.480 --> 00:09:16.830
original documents in that space.

00:09:16.840 --> 00:09:19.320
This is called the training phase.

00:09:19.330 --> 00:09:23.950
And so we do that with all the
documents that appear in the training,

00:09:23.960 --> 00:09:27.970
and so pretty soon,
what we see is that we see regions of the

00:09:27.970 --> 00:09:33.210
space that characterize certain topics,
such as finance and

00:09:33.500 --> 00:09:35.300
computer science and so on.

00:09:35.350 --> 00:09:39.000
Then during a phase
called classification,

00:09:39.060 --> 00:09:43.580
what happens is that we take a new
document-- might be a web page,

00:09:43.670 --> 00:09:46.240
for example,
something like that-- and we're trying

00:09:46.320 --> 00:09:48.360
to see where it fits in the space.

00:09:48.510 --> 00:09:52.150
And so what we do is we map it
in the space using the framework,

00:09:52.350 --> 00:09:55.440
and lo and behold,
it falls somewhere in there.

00:09:55.540 --> 00:10:01.290
And we sort of look at which
cluster it falls within,

00:10:01.430 --> 00:10:03.470
and we can deduce that
in this particular case,

00:10:03.620 --> 00:10:07.100
for example,
the web page that we had is most

00:10:07.150 --> 00:10:09.180
likely about computer science.

00:10:09.360 --> 00:10:10.880
That's the mapping part.

00:10:11.010 --> 00:10:15.310
Let's go into the semantic aspect of it.

00:10:15.390 --> 00:10:18.710
And I'd like to take the example
of parental controls because my

00:10:19.140 --> 00:10:23.630
colleague Giovanni is going to go
through a case study of that later,

00:10:23.630 --> 00:10:27.170
but very briefly,
and I'm going to give you a little

00:10:27.290 --> 00:10:32.200
bit of a summary of what the subject
here is to assess whether a web page

00:10:32.200 --> 00:10:36.240
is free of objectionable material
or whether it contains words that

00:10:36.240 --> 00:10:38.740
are not suitable for children.

00:10:38.740 --> 00:10:43.240
And so in the LSM strategy,
what we're going to do is we're

00:10:43.240 --> 00:10:49.290
going to try to encapsulate what
exactly characterizes an objectionable

00:10:49.290 --> 00:10:53.700
material versus what exactly
characterizes legitimate material.

00:10:53.700 --> 00:10:55.400
And so for that,
we have two natural categories,

00:10:55.400 --> 00:10:58.400
one having objectionable material,
or so-called explicit material,

00:10:58.430 --> 00:11:01.240
and one for the legitimate material.

00:11:01.590 --> 00:11:06.450
And so the implementation is that
we're going to construct an LSM space.

00:11:06.540 --> 00:11:09.060
In this particular case,
since we have only two categories,

00:11:09.060 --> 00:11:10.660
it's going to be two-dimensional.

00:11:10.700 --> 00:11:14.610
And then we're going to define what's
called semantic anchors in that space.

00:11:14.620 --> 00:11:20.740
Those will be the points that most
characterizes the objectionableness,

00:11:20.800 --> 00:11:25.370
if you will, of the material versus the
legitimacy of the material.

00:11:25.570 --> 00:11:29.560
And then every time we have a web page,
we're going to evaluate it

00:11:29.560 --> 00:11:34.590
against those two anchors and
then figure out what it is.

00:11:34.910 --> 00:11:36.600
So let me illustrate.

00:11:36.710 --> 00:11:39.950
So here, again,
we have the two-dimensional space.

00:11:40.090 --> 00:11:41.870
And we have those two anchors.

00:11:42.010 --> 00:11:46.320
So the legitimate anchor might
be this green square here.

00:11:46.320 --> 00:11:51.180
You can think of it as the centroid
of all the legitimate web page that

00:11:51.180 --> 00:11:53.020
we've seen in the training data.

00:11:53.170 --> 00:11:57.090
And similarly,
we have the-- objectionable material,

00:11:57.090 --> 00:11:59.960
the anchor of objectionable
material that might fall in there.

00:11:59.960 --> 00:12:03.960
And again,
you can think of it as the centroid of

00:12:03.960 --> 00:12:08.960
all the pornographic web pages and so
on that we've seen in the training data.

00:12:09.020 --> 00:12:11.170
And then a new web page comes in.

00:12:11.240 --> 00:12:13.070
We map it in the space.

00:12:13.160 --> 00:12:16.720
We then compute the distance
between that representation,

00:12:16.720 --> 00:12:19.370
that point, and the two anchors.

00:12:19.510 --> 00:12:23.970
And we see that in this particular case,
it is closer to the anchor

00:12:23.970 --> 00:12:25.340
of explicit material.

00:12:25.340 --> 00:12:28.480
In which case,
we deduce that it's probably a page that

00:12:28.480 --> 00:12:31.350
you wouldn't want your children to see.

00:12:31.740 --> 00:12:37.580
So let's move on and now talk
about the latent aspect of things.

00:12:37.690 --> 00:12:41.210
And for this I'd like to go
through a little case study,

00:12:41.210 --> 00:12:44.440
a little artificial construction here.

00:12:44.930 --> 00:12:48.300
Imagine a four feature calendar
management system where you

00:12:48.300 --> 00:12:50.130
can have only four queries.

00:12:50.170 --> 00:12:52.350
You can ask about the time,
about the day,

00:12:52.350 --> 00:12:54.140
about the time of the meeting.

00:12:54.140 --> 00:12:57.720
You can also cancel the meeting
and that's all you can do.

00:12:57.720 --> 00:13:02.770
Very contrived example but it will
I think illustrate some important points.

00:13:02.780 --> 00:13:06.590
So the LSM strategy here is we
have four natural categories which

00:13:06.650 --> 00:13:11.050
means that we're going to construct
four semantic anchors in the space.

00:13:11.180 --> 00:13:14.930
And then of course as
we evaluate the input,

00:13:14.930 --> 00:13:19.790
any input to that system that
may not be necessarily in the

00:13:19.790 --> 00:13:24.130
same words as what's expected,
we're going to... ... ... ... ... ...

00:13:24.140 --> 00:13:29.510
...we're going to map this input into
the space and figure out which query,

00:13:29.510 --> 00:13:32.140
which category it is closest to.

00:13:32.240 --> 00:13:36.310
So again, because,
well I'd like to first before we go

00:13:36.320 --> 00:13:41.140
through the actual latent space for that,
why did I choose this

00:13:41.140 --> 00:13:43.720
admittedly contrived example?

00:13:44.010 --> 00:13:48.930
Well, those categories,
those queries have been chosen

00:13:48.930 --> 00:13:53.870
because they illustrate a
couple of different things.

00:13:53.960 --> 00:13:56.870
First of all,
the predictive power of the words

00:13:56.870 --> 00:14:00.730
that appear in those queries are very,
is very different.

00:14:00.860 --> 00:14:05.170
For example, the, you'll notice,
appear in all four queries,

00:14:05.310 --> 00:14:11.060
meaning that if you see the,
that gives you absolutely no information

00:14:11.060 --> 00:14:15.220
whatsoever about which query it is about,
meaning its predictive

00:14:15.330 --> 00:14:17.060
power is essentially zero.

00:14:17.130 --> 00:14:20.420
Whereas they, or cancel for example,
they each appear in one

00:14:20.420 --> 00:14:24.430
particular query and nowhere else,
meaning that if you see... ...the,

00:14:24.460 --> 00:14:27.640
you know that I'm talking about
category number two in that case.

00:14:27.660 --> 00:14:30.130
So the predictive power is different.

00:14:30.270 --> 00:14:32.810
Also, we have all kinds of occurrences.

00:14:32.890 --> 00:14:34.040
We have overlaps.

00:14:34.130 --> 00:14:37.700
We have meeting, appearing in,
in two of the queries.

00:14:37.700 --> 00:14:40.650
We have ambiguities
and so on and so forth.

00:14:40.660 --> 00:14:43.490
So that's kind of an
interesting case study.

00:14:43.490 --> 00:14:46.770
Now let's assume that a user
has been using this system

00:14:46.770 --> 00:14:50.820
and was successful with it,
and then he goes, you know, goes in,

00:14:50.820 --> 00:14:54.980
takes a little break,
goes... ...somewhere, comes back,

00:14:54.980 --> 00:14:57.180
doesn't quite remember
how to query the system.

00:14:57.180 --> 00:15:00.870
So he says something like,
"When is the meeting?" instead of,

00:15:00.870 --> 00:15:03.660
"What time is the meeting?"
And you'll notice that in that case,

00:15:03.730 --> 00:15:05.920
"When" has never been seen by the system.

00:15:05.920 --> 00:15:09.920
And so the question is,
what will LSM do with that?

00:15:09.920 --> 00:15:13.180
So let's go through,
that's the actual illustration.

00:15:13.180 --> 00:15:16.120
You can actually construct this,
this example in,

00:15:16.120 --> 00:15:19.400
in using the LSM framework and see what,
what happens.

00:15:19.420 --> 00:15:23.110
This is the two-dimensional
rendition of this example.

00:15:23.190 --> 00:15:27.440
And here I've mapped the words.

00:15:27.670 --> 00:15:29.140
So those are all the words.

00:15:29.180 --> 00:15:35.180
"The" you recall had no predictive power,
so it just happens to be at the origin.

00:15:35.180 --> 00:15:41.180
"They" and "consul" you recall each
predicted one query particularly well.

00:15:41.180 --> 00:15:46.180
And so they tend to score high on
one dimension and low on the other.

00:15:46.380 --> 00:15:48.930
And the other words fall
somewhere in the middle,

00:15:49.010 --> 00:15:52.810
and you notice that "what" and "is"
happen to co-occur all the time,

00:15:52.890 --> 00:15:56.940
meaning that they fall on top
of each other in this space.

00:15:56.940 --> 00:15:59.870
Now about the, the query themselves.

00:15:59.940 --> 00:16:00.940
Here they are.

00:16:00.940 --> 00:16:03.670
Not surprisingly,
"what is the day?" falls

00:16:03.700 --> 00:16:06.940
very close to "day," which is
the word that predicts best.

00:16:06.940 --> 00:16:11.450
And similarly with "consul the
meeting." And the other two fall

00:16:11.660 --> 00:16:15.940
similarly fairly close to the,
their constituent words.

00:16:16.030 --> 00:16:18.910
The question is,
what happened with the new input?

00:16:18.960 --> 00:16:23.910
Remember, it was "when is the meeting?"
And so you do the computation,

00:16:23.910 --> 00:16:25.680
and lo and behold, that's where it falls.

00:16:25.700 --> 00:16:29.550
And you see that the query that
is the closest to it is this one.

00:16:29.700 --> 00:16:33.700
So that would be the query
that's predicted by the system.

00:16:33.980 --> 00:16:39.880
And so what we've seen is that in
a very sort of data-driven way,

00:16:39.880 --> 00:16:44.880
the system has essentially figured
out that "when" is a synonym for

00:16:44.880 --> 00:16:48.210
"what time." Isn't that great?

00:16:53.370 --> 00:16:56.630
Okay, so that seems like magic.

00:16:56.630 --> 00:16:57.850
It's not all magic.

00:16:57.960 --> 00:17:02.650
And now I'm going to walk you
through some of the tedious details

00:17:03.010 --> 00:17:05.270
of the math that's behind it.

00:17:05.460 --> 00:17:09.700
I'm going to keep it short and simple,
hopefully.

00:17:09.700 --> 00:17:14.030
The two pieces of information that
we leverage here is how often does

00:17:14.030 --> 00:17:18.630
each word appear in each document,
and compared to how often does each

00:17:18.630 --> 00:17:21.460
word appear in the entire training data.

00:17:21.460 --> 00:17:27.780
And what we do is we form a
matrix of words by documents.

00:17:27.780 --> 00:17:32.700
It is not a Christmas gift,
despite the appearance.

00:17:32.700 --> 00:17:37.940
This is simply a two-dimensional
array of numbers.

00:17:37.940 --> 00:17:40.600
Each entry in this matrix
is a weighted count,

00:17:40.600 --> 00:17:43.920
weighted appropriately,
of essentially how many

00:17:43.920 --> 00:17:47.220
times that particular word,
the green word,

00:17:47.220 --> 00:17:51.420
appear in this particular document,
the red document.

00:17:51.420 --> 00:17:55.910
And in order to make -- so this defines,
as it turns out,

00:17:55.910 --> 00:18:00.960
this appropriate vector representation
for the words in the documents.

00:18:00.960 --> 00:18:04.280
But then it turns out they're
not completely practical.

00:18:04.410 --> 00:18:07.670
So we go through an additional step,
which is called singular

00:18:07.670 --> 00:18:10.490
value decomposition,
or SVD for short,

00:18:10.490 --> 00:18:14.950
that takes this matrix W and
massage it a little bit,

00:18:14.950 --> 00:18:20.820
sort of decompose it into three different
matrices that are easier to deal with.

00:18:20.820 --> 00:18:23.970
And this gives us the
appropriate representation,

00:18:23.970 --> 00:18:27.480
the points in the space
that we were looking for.

00:18:27.480 --> 00:18:32.440
And those -- the set of those points are
essentially what the space looks like,

00:18:32.520 --> 00:18:34.990
the latent semantic space.

00:18:35.520 --> 00:18:41.960
So coming back to my
example from the beginning,

00:18:42.300 --> 00:18:45.420
we then have a set of documents,
a bag of documents,

00:18:45.420 --> 00:18:48.680
and we map it into the space,
just as we did in the beginning.

00:18:48.690 --> 00:18:53.330
Then when we have a new document,
we classify it and find out

00:18:53.330 --> 00:18:55.100
its position in the space.

00:18:55.120 --> 00:18:58.460
We also-- we've seen in the
case study that I presented

00:18:58.580 --> 00:19:02.120
before that from the document,
of course, we can infer the words,

00:19:02.160 --> 00:19:05.500
and we can map those words
equally in the space.

00:19:05.630 --> 00:19:11.660
So we are left with a framework that
allows us to respond to two questions.

00:19:11.660 --> 00:19:14.820
Given this blue triangle,
which is the new input,

00:19:14.820 --> 00:19:20.260
this web page that I want to classify,
we can ask,

00:19:20.590 --> 00:19:25.500
what is the closest document
in my training corpus that,

00:19:25.500 --> 00:19:28.690
you know, the document that's closest
to this particular input?

00:19:28.770 --> 00:19:31.090
And that would be given
by the red triangle.

00:19:31.100 --> 00:19:36.100
And this is the kind of stuff that we do,
the kind of question we answer

00:19:36.100 --> 00:19:40.510
when we do junk mail filtering
and also parental controls,

00:19:40.510 --> 00:19:41.670
as you will see.

00:19:41.780 --> 00:19:46.460
But we can also ask,
given this blue triangle,

00:19:46.460 --> 00:19:53.350
given this new input, what word best
characterize that document?

00:19:53.540 --> 00:19:56.550
And that would be the green square there.

00:19:56.660 --> 00:19:59.950
And this is the kind of
question we answer when we

00:19:59.950 --> 00:20:03.180
do a Kanata-Kanji conversion,
for example.

00:20:03.310 --> 00:20:07.730
Try to figure out which word
best characterizes the document.

00:20:07.970 --> 00:20:13.310
And so we will either figure out
which document is closest or which

00:20:13.350 --> 00:20:16.600
word is closest in that LSM space.

00:20:17.010 --> 00:20:18.800
Now, a couple of caveats.

00:20:18.970 --> 00:20:20.390
You know, lsm is powerful.

00:20:20.390 --> 00:20:21.540
It's no panacea.

00:20:21.590 --> 00:20:26.690
It only works within the constraints
of the particular paradigm.

00:20:27.210 --> 00:20:31.610
And in particular,
it has three limitations.

00:20:31.730 --> 00:20:36.250
One has to do with a fairly
shallow sense of semantic.

00:20:36.330 --> 00:20:40.070
We're not talking about semantics as
is described in a typical artificial

00:20:40.230 --> 00:20:42.130
intelligence literature here.

00:20:42.520 --> 00:20:47.620
The semantic aspect of lsm
is completely tied to word

00:20:47.770 --> 00:20:51.300
co-occurrences as they appear in
that matrix that I was talking about.

00:20:51.300 --> 00:20:52.640
So it's fairly shallow.

00:20:52.640 --> 00:20:53.740
Still powerful.

00:20:53.900 --> 00:20:57.950
The second aspect is that
the word order is ignored.

00:20:57.970 --> 00:21:02.480
In other words,
we take the document as a bag of words.

00:21:02.630 --> 00:21:09.250
Hence the little
pictograph of a bag here.

00:21:09.300 --> 00:28:03.900
[Transcript missing]

00:28:08.200 --> 00:28:10.760
So how do we use the API?

00:28:10.760 --> 00:28:14.110
The first thing to notice
is the demo I just gave you

00:28:14.580 --> 00:28:16.240
does not use the API at all.

00:28:16.300 --> 00:28:18.430
It just uses the command line tool.

00:28:18.540 --> 00:28:21.530
And in fact,
in a large percentage of applications

00:28:21.530 --> 00:28:27.010
of Latent Semantic Mapping,
the command line tool is perfectly

00:28:27.700 --> 00:28:33.280
adequate to do the prototyping,
to possibly even pre-train a map,

00:28:33.280 --> 00:28:33.280
to do a lot of your testing.

00:28:33.560 --> 00:28:37.280
So you can decide whether it's
actually working out for your

00:28:37.280 --> 00:28:41.590
application before you write the
first line of C code using the API.

00:28:41.610 --> 00:28:44.400
Once you do want to
write that first line,

00:28:44.440 --> 00:28:46.920
the API is core foundation based.

00:28:47.180 --> 00:28:52.620
That means all the types in the Latent
Semantic Mapping API can be retained,

00:28:52.620 --> 00:28:53.460
released.

00:28:53.460 --> 00:28:56.530
You can put them into NSArrays.

00:28:56.560 --> 00:28:59.970
You can do unspeakable things with them.

00:29:00.160 --> 00:29:08.690
So we have-- Latent Semantic Mapping
framework is based around three types.

00:29:08.890 --> 00:29:12.690
The LSM map,
which is the data structure we use

00:29:12.700 --> 00:29:19.000
to store the transformed training
data and to evaluate things against.

00:29:19.080 --> 00:29:22.210
The LSM text,
which is where you would put in

00:29:22.210 --> 00:29:26.660
text or your other data that you
want to use for training or for

00:29:26.660 --> 00:29:30.010
evaluation while you're building it up.

00:29:30.100 --> 00:29:34.390
And as a result of the evaluation,
you get back an LSM result.

00:29:35.200 --> 00:29:38.660
To dig a bit further into
an LSM map operations,

00:29:38.790 --> 00:29:43.440
there are LSM map create to create a map.

00:29:43.470 --> 00:29:47.770
Then you start training it by
creating a text by first creating

00:29:48.080 --> 00:29:50.880
categories with LSM map add category.

00:29:50.940 --> 00:29:55.840
And then you keep creating texts
and calling LSM map add text to

00:29:55.840 --> 00:29:58.350
add data to those categories.

00:29:59.650 --> 00:30:04.360
Once you're done with your training data,
you call LSM map compile to put

00:30:04.360 --> 00:30:07.210
the map into a compiled state.

00:30:07.300 --> 00:30:10.180
Now, occasionally you may want to
go back and add more data.

00:30:10.180 --> 00:30:14.380
For instance, in junk mail filtering,
whenever the user hits the

00:30:14.510 --> 00:30:17.700
junk mail or not junk button,
we go back,

00:30:17.720 --> 00:30:22.130
put the map back into training state,
add the mail as further training data,

00:30:22.160 --> 00:30:23.970
and compile it again.

00:30:24.070 --> 00:30:27.850
That putting back is done
with LSM map start training.

00:30:27.950 --> 00:30:33.520
In evaluation state, To evaluate a text,
you call LSM result create

00:30:33.660 --> 00:30:37.470
because according to core
foundation naming rules,

00:30:37.470 --> 00:30:39.180
what you really get
back is an LSM result.

00:30:39.180 --> 00:30:43.830
So that's what the call is named after.

00:30:44.310 --> 00:30:47.990
And to store a map to disk
and to load it back in,

00:30:48.090 --> 00:30:53.000
you have lsmmap write to
URL and lsmmap create from URL.

00:30:53.020 --> 00:30:56.380
And finally,
the calls that we didn't talk about

00:30:56.710 --> 00:31:02.480
last time that are new for Leopard
is lsmmap create clusters to discover

00:31:02.570 --> 00:31:05.860
the clusters present in a dataset.

00:31:05.910 --> 00:31:07.480
And then if you decide
that they are good,

00:31:07.610 --> 00:31:10.780
that you want to use them,
you call lsmmap apply clusters,

00:31:10.780 --> 00:31:15.850
which reorganizes the map around
those clusters that you've discovered.

00:31:17.930 --> 00:31:21.400
So moving on to an LSM text.

00:31:21.460 --> 00:31:25.170
The name might suggest that an
LSM text is a sequence of words.

00:31:25.180 --> 00:31:28.560
And that's, in fact, what it often is.

00:31:28.650 --> 00:31:32.620
But it can be more than
that or less than that,

00:31:32.670 --> 00:31:34.220
depending on how you view it.

00:31:34.270 --> 00:31:36.960
There are three ways of
adding data to a text.

00:31:37.010 --> 00:31:39.700
The simplest way,
and the way that is supported

00:31:39.780 --> 00:31:44.290
by the command line tool,
is you just take a long string and let

00:31:44.350 --> 00:31:48.640
latent semantic mapping break that up
into words and add those to the text.

00:31:48.760 --> 00:31:51.970
That's done with LSM text add words.

00:31:52.700 --> 00:31:56.060
This default parser does not
work in all circumstances.

00:31:56.060 --> 00:31:58.760
For instance,
our parser discards numbers,

00:31:58.790 --> 00:32:03.080
because in many contexts,
the numbers just clutter up the space

00:32:03.080 --> 00:32:05.900
and don't really add any information.

00:32:05.930 --> 00:32:08.050
But in some cases,
it's crucially important

00:32:08.050 --> 00:32:10.830
to preserve numbers,
in which case you want

00:32:10.830 --> 00:32:12.360
to write your own parser.

00:32:12.370 --> 00:32:14.990
Also, we might not parse all
languages correctly.

00:32:15.000 --> 00:32:18.720
So for some languages,
you might want to write your own parser,

00:32:18.840 --> 00:32:23.230
in which case you just write your parser,
and whenever you found a word,

00:32:23.380 --> 00:32:29.060
you call lsm.text.addWord in the
singular to add that to the text.

00:32:29.060 --> 00:32:34.230
And the third option is you don't
necessarily have to use words,

00:32:34.230 --> 00:32:39.890
because despite all the semantic stuff,
latent semantic mapping is fundamentally

00:32:39.940 --> 00:32:43.280
agnostic of what's in your tokens.

00:32:43.580 --> 00:32:44.530
It doesn't have to be a word.

00:32:44.530 --> 00:32:46.390
It can be in any language.

00:32:46.410 --> 00:32:52.680
And in fact,
it can't just be binary data.

00:32:52.700 --> 00:32:58.980
So if you want to use binary data,
if you want to use a CFData instead of

00:32:58.980 --> 00:32:58.980
a CFString as your fundamental unit,
you just call lsm_text_add_token.

00:33:04.890 --> 00:33:07.310
Now you have your text and
you want to evaluate it.

00:33:07.420 --> 00:33:13.100
You do that by calling lsm_result create,
specifying a number of categories

00:33:13.160 --> 00:33:14.790
that you're interested in.

00:33:14.890 --> 00:33:17.920
Sometimes you have this kind of
winner-takes-it-all evaluation,

00:33:17.920 --> 00:33:21.520
in which case you only want one category,
the top one.

00:33:21.570 --> 00:33:25.020
In some cases you want to do
some kind of an n-best thing,

00:33:25.070 --> 00:33:28.470
in which case you would have
a number greater than one.

00:33:28.920 --> 00:33:32.310
For this number of categories,
you can inquire what

00:33:32.310 --> 00:33:34.080
the category number is.

00:33:34.100 --> 00:33:39.190
For instance, as we saw in the example,
one for Perl, two for Python,

00:33:39.290 --> 00:33:40.600
three for Ruby.

00:33:40.600 --> 00:33:43.680
That would be lsm_result.get_category.

00:33:43.930 --> 00:33:47.300
You may want to know what the score is.

00:33:47.320 --> 00:33:51.150
We have the scores of the categories
adding up to one conceptually,

00:33:51.150 --> 00:33:53.000
so it's like a probability.

00:33:53.120 --> 00:33:57.760
You want to get the score to find out
what your confidence in the result is,

00:33:57.950 --> 00:34:00.880
and you do that with
lsm_result_get_score.

00:34:00.930 --> 00:34:04.500
If you do a word-based mapping,
where you want to get back

00:34:04.500 --> 00:34:07.800
the best matching words,
then the category number

00:34:07.800 --> 00:34:08.990
doesn't tell you a whole lot.

00:34:09.100 --> 00:34:12.560
That's just the index within
the overall list of words.

00:34:12.630 --> 00:34:17.310
So you would rather prefer to have
lsm_result_copy_word to get back the

00:34:17.470 --> 00:34:20.940
CFString of the words that you put in.

00:34:20.970 --> 00:34:25.360
In a clustered map, you may need
lsm_result_copy_word_cluster,

00:34:25.370 --> 00:34:29.020
so you get a CFArray of CFStrings.

00:34:29.160 --> 00:34:32.800
And similarly,
if you have a map using binary

00:34:32.800 --> 00:34:37.270
tokens instead of strings,
you get lsm_result_copy_token

00:34:37.440 --> 00:34:41.320
or copy_token_cluster,
which just returns CFData or CFArray.

00:34:41.320 --> 00:34:41.320
So you would rather prefer to have
lsm_result_copy_word to get back the

00:34:41.320 --> 00:34:41.320
CFString of the words that you put in.

00:34:41.320 --> 00:34:41.320
In a clustered map, you may need
lsm_result_copy_word_cluster,

00:34:41.320 --> 00:34:41.320
so you get a CFArray of CFStrings.

00:34:41.320 --> 00:34:44.590
with a CFArray of CFData.

00:34:47.320 --> 00:34:48.590
That's how we used the API.

00:34:48.730 --> 00:34:50.050
So how did we use it?

00:34:50.160 --> 00:34:53.620
Our first usage, I said,
was chunk mail filtering.

00:34:53.620 --> 00:34:56.180
In a way,
that's a pretty simple application.

00:34:56.180 --> 00:34:58.840
You have the good guys here,
the bad guys there,

00:34:58.840 --> 00:35:03.270
no ambiguity whatsoever,
but there are some refinements needed.

00:35:03.270 --> 00:35:07.020
First of all,
we don't want to have equal error rates.

00:35:07.060 --> 00:35:11.550
As aggravating as it is to have a
chunk mail delivered to your inbox,

00:35:11.940 --> 00:35:15.720
it's much worse to have a legitimate
mail drop out of sight in your

00:35:15.740 --> 00:35:20.140
chunk mailbox and not to be
discovered until several days later.

00:35:20.140 --> 00:35:25.850
So we err a little bit on the side
of classifying a mail as legitimate.

00:35:25.850 --> 00:35:31.000
We do that by not just testing the top
category against the chunk mail category,

00:35:31.000 --> 00:35:36.830
but by also testing that the score we
got for that top category is greater

00:35:36.830 --> 00:35:41.280
than a threshold which we defined to
be somewhat greater than 50 percent.

00:35:41.280 --> 00:35:45.500
So you might may want 55% certainty.

00:35:45.750 --> 00:35:49.750
The second problem is that
the people who send junk mail,

00:35:49.850 --> 00:35:52.540
they are evil but they are
not necessarily stupid.

00:35:52.670 --> 00:35:55.960
So they know that they're
parsing their mail,

00:35:56.070 --> 00:35:58.620
so they're making their
mail difficult to parse.

00:35:58.740 --> 00:36:03.010
And they do that, for instance,
by inserting gratidious punctuation or

00:36:03.340 --> 00:36:08.940
doing the heavy metal thing and inserting
gratidious umlauts and other diacritics.

00:36:09.060 --> 00:36:13.650
So we need to counteract that,
so we have a specialized parser that

00:36:13.650 --> 00:36:19.680
is just used for parsing junk which we
activate with a flag to LSM text AdWords.

00:36:19.800 --> 00:36:23.310
Our third problem is that if
you look at the map generated by

00:36:23.310 --> 00:36:26.810
training up a junk mail filter,
and you dump that out of the

00:36:26.870 --> 00:36:31.840
console with strings or with cat,
you would see all sorts of offensive

00:36:31.900 --> 00:36:33.420
words and we don't really want that.

00:36:33.420 --> 00:36:37.700
You don't want your children to use cat
on that map and see a word like mortgage.

00:36:37.700 --> 00:36:41.480
So to counteract that,
we added a little bit

00:36:41.480 --> 00:36:43.760
of a hashing function.

00:36:43.760 --> 00:36:46.760
It's not military-grade
cryptography by any means,

00:36:46.760 --> 00:36:50.750
but it's just enough that you would
not really be able to read anything

00:36:50.750 --> 00:36:52.260
useful with a text-based tool.

00:36:52.260 --> 00:36:55.040
And that might be useful
in other contexts as well.

00:36:55.040 --> 00:37:00.590
So you can specify this flag,
lsm_map_hash_text when creating a map.

00:37:00.770 --> 00:37:04.500
And one final and important
point is LateN Semantic Mapping

00:37:04.500 --> 00:37:08.040
is not used in isolation here.

00:37:08.040 --> 00:37:10.300
It's used as a last line of defense.

00:37:10.340 --> 00:37:14.390
If you think about the path
that a mail message takes,

00:37:14.610 --> 00:37:18.380
first goes to your internet service
provider and your internet service

00:37:18.500 --> 00:37:23.880
provider probably is going to throw
away about 85 to 95 percent of incoming

00:37:23.880 --> 00:37:29.320
mail and if it does its job properly
because much of it is so obviously spam

00:37:29.460 --> 00:37:35.220
you don't you never want to even deliver
that to your end-user machine once it

00:37:35.230 --> 00:37:40.540
is delivered to your inbox you apply the
handwritten rules that you have in mail

00:37:40.540 --> 00:37:47.000
dot app if you to sort mail early that's
usually only used to define a mail early

00:37:47.020 --> 00:37:52.410
as good mail not to throw it away but you
could also write rules to throw it away

00:37:52.410 --> 00:37:58.360
then what you do next is you look up the
sender of the mail in your address book

00:37:58.540 --> 00:38:02.710
because that's another case where we err
on the side of caution if you know the

00:38:02.820 --> 00:38:07.060
person who pretends to have sent you this
mail we rather present you the mail and

00:38:07.060 --> 00:38:10.520
let you decide whether it's a desirable
mail so add a mail to your inbox and

00:38:10.520 --> 00:38:12.550
you can send it to your email address
book and address book is also used

00:38:12.760 --> 00:38:18.900
to preserve a mail and only if all those
filters don't give a conclusive response

00:38:18.900 --> 00:38:21.690
do we use latent semantic mapping

00:38:21.800 --> 00:38:27.770
To decide whether a mail is to be
discarded or whether it's to be kept.

00:38:29.890 --> 00:38:31.900
So this is kind of the simple case.

00:38:32.070 --> 00:38:35.210
For a more complex case,
I would like to bring up my colleague,

00:38:35.210 --> 00:38:38.880
Giovanni Donelli,
who implemented the Web Content Filter.

00:38:45.890 --> 00:38:49.400
and I'm a software engineer,
member of the team that designed

00:38:49.400 --> 00:38:52.000
the Leopard Web Content Filter.

00:38:52.690 --> 00:38:55.900
With my presentation today,
I would like to show you what is

00:38:55.900 --> 00:38:59.960
it like to use Latent Semantic
Mapping to solve quite a complex

00:38:59.960 --> 00:39:02.400
problem such as web filtering.

00:39:02.440 --> 00:39:05.550
But before I delve more into
the details on how we use LSM,

00:39:05.660 --> 00:39:08.600
let me show you where you
can find the web filter.

00:39:08.730 --> 00:39:11.990
So as some of you may notice,
Leopard introduces a brand new set

00:39:12.010 --> 00:39:14.400
of parental control functionalities.

00:39:14.530 --> 00:39:17.830
It allows you to impose several
restrictions on the use of the

00:39:17.910 --> 00:39:20.100
computer and of its applications.

00:39:20.190 --> 00:39:23.400
One main area of concern nowadays,
obviously, the internet,

00:39:23.410 --> 00:39:25.100
especially for parents.

00:39:25.200 --> 00:39:29.190
And I think we all agree that the
web can be considered a potentially

00:39:29.190 --> 00:39:31.870
harmful place for younger minds.

00:39:32.030 --> 00:39:35.040
So the objective of the web
content filter is to validate the

00:39:35.210 --> 00:39:39.020
material coming from the internet,
making sure no kid gets

00:39:39.020 --> 00:39:41.490
exposed to explicit material.

00:39:47.200 --> 00:39:49.670
So the filter is based
on a two categories map,

00:39:49.670 --> 00:39:53.980
which has been trained to recognize
explicit and legitimate material.

00:39:54.010 --> 00:39:57.010
Our training data is made by
approximately 7,000 pages,

00:39:57.040 --> 00:40:03.090
which have been collected primarily
manually in an effort to approximate the

00:40:03.090 --> 00:40:03.090
variety of the distribution of the web.

00:40:05.650 --> 00:40:07.000
This is just a text-based filter.

00:40:07.000 --> 00:40:11.200
We're not doing any fancy image analysis
or skin recognition of any sort.

00:40:11.200 --> 00:40:15.990
We're taking the HTML page source and
converting that into simple text by

00:40:15.990 --> 00:40:18.980
removing all the layout information,
all the tags that would add

00:40:19.100 --> 00:40:22.290
clatter and noise to the LSM map.

00:40:22.500 --> 00:40:24.760
In this process,
we're obviously trying to retain

00:40:24.770 --> 00:40:29.110
as much information as possible,
such as meta tags or image descriptions.

00:40:30.790 --> 00:40:34.830
As you've heard from Matthias,
LSM is currently ignoring numbers,

00:40:34.970 --> 00:40:38.210
but numbers could be very
relevant to our classification.

00:40:38.400 --> 00:40:40.190
You see here a really good example.

00:40:40.260 --> 00:40:44.320
The USC 2257 identifies a law
that regulates the handling of

00:40:44.320 --> 00:40:46.500
adult material on the Internet.

00:40:46.500 --> 00:40:50.500
So obviously the presence of this string
can highly identify explicit material,

00:40:50.670 --> 00:40:55.800
and we convert numbers into tokens
that you see here in the example,

00:40:55.900 --> 00:41:00.960
so that LSM can learn to distinguish
specific words or specific flags

00:41:00.960 --> 00:41:04.100
that are potentially explicit.

00:41:07.200 --> 00:41:17.640
The structural feature of a web page
can also give us some hint on the type

00:41:17.640 --> 00:41:18.710
of material displayed by a web page.

00:41:18.710 --> 00:41:18.710
As you probably can imagine,
explicit pages tend to have a

00:41:18.710 --> 00:41:18.710
lot of images and little text.

00:41:18.800 --> 00:41:20.660
So we are converting a
structure of features,

00:41:20.660 --> 00:41:23.580
such as the number of
images or number of words,

00:41:23.840 --> 00:41:27.530
into tokens, into just fake words that
we insert in the text.

00:41:27.620 --> 00:41:31.210
And we just let LSM learn what
features are to be considered

00:41:31.330 --> 00:41:33.930
potentially explicit or legitimate.

00:41:36.520 --> 00:41:44.580
To test how well the
filter works on our scale,

00:41:44.590 --> 00:41:48.680
we need to verify the accuracy
of the web filter over a set of

00:41:48.680 --> 00:41:48.680
pages which have never been seen
in the training phase before.

00:41:49.050 --> 00:41:53.900
For the purpose of collecting test data,
we are using the Open Directory project.

00:41:54.000 --> 00:41:57.280
This is an open source
effort to classify the web.

00:41:57.740 --> 00:42:01.940
Users on Demos have already
classified thousands of

00:42:01.940 --> 00:42:03.970
legitimate and explicit pages.

00:42:04.060 --> 00:42:08.420
We're taking approximately
100,000 of these documents,

00:42:08.420 --> 00:42:11.270
and we're making the filter
evaluate every single one.

00:42:11.590 --> 00:42:16.460
And the filter associates a score
between 0 and 1 to each single page.

00:42:16.520 --> 00:42:19.770
Then we aggregate this
information in this graph.

00:42:20.520 --> 00:42:22.900
In the vertical axis,
we have the page score.

00:42:23.050 --> 00:42:25.480
The higher the score,
the higher the probability

00:42:25.480 --> 00:42:26.990
for a page to be explicit.

00:42:28.730 --> 00:42:32.040
On the horizontal axis,
we have the page score.

00:42:32.140 --> 00:42:36.910
On the vertical axis,
we have the proportion

00:42:36.910 --> 00:42:36.910
of pages with that score.

00:42:37.310 --> 00:42:41.970
So let's see how our data
distributed over its core.

00:42:42.270 --> 00:42:44.680
These are the legitimate pages.

00:42:45.190 --> 00:42:47.750
These are the explicit ones.

00:42:47.830 --> 00:42:50.630
So the shape of these two
curves tell us that the explicit

00:42:50.710 --> 00:42:52.630
pages are all very similar.

00:42:52.660 --> 00:42:58.210
In fact, they are primarily classified
within a very narrow score range.

00:42:58.290 --> 00:43:00.980
Legitimate pages, instead,
are much more diverse.

00:43:01.000 --> 00:43:03.700
They cover a wider variety of topics.

00:43:03.800 --> 00:43:08.350
That's why the curve is much
more evenly distributed in the

00:43:08.350 --> 00:43:11.190
first half of the core spectrum.

00:43:12.720 --> 00:43:17.800
Somewhere where those two lines overlap,
we can identify the equal error rate.

00:43:17.800 --> 00:43:20.750
And at this point,
the filter makes equal mistakes

00:43:20.760 --> 00:43:23.590
in classifying explicit
material and legitimate.

00:43:23.720 --> 00:43:29.910
The equal error rate is a really good
metric for us of the filter accuracy.

00:43:30.200 --> 00:43:33.920
And as we evolve the filter,
our goal is to minimize

00:43:33.920 --> 00:43:35.730
the equal error rate.

00:43:36.390 --> 00:43:40.990
By looking at this graph,
we can also understand where we should

00:43:41.060 --> 00:43:45.190
put our fifth threshold and the risks
that are involved with this decision.

00:43:48.310 --> 00:43:55.860
So automatic testing is really
great to understand how our

00:43:56.450 --> 00:43:56.510
filter works on the Internet.

00:43:56.760 --> 00:44:00.000
And it's extremely helpful to
keep track of the filter progress

00:44:00.000 --> 00:44:06.100
over time as we change it and
see if there are any regression.

00:44:06.610 --> 00:44:08.790
However,
it can only be as accurate as long

00:44:08.800 --> 00:44:13.730
as the test data that we're using
is a good representation of the web.

00:44:14.230 --> 00:44:17.400
There are also some disadvantages
of automatic testing.

00:44:17.400 --> 00:44:21.100
Primarily, it has a quite high initial
cost to set up all this system

00:44:21.100 --> 00:44:22.900
to gather all this test data.

00:44:23.000 --> 00:44:26.570
It might not really be suitable
in a prototyping phase.

00:44:26.880 --> 00:44:30.110
And most importantly,
Automatic Testing is not really telling

00:44:30.110 --> 00:44:32.430
you what's going wrong with your LSM map.

00:44:32.510 --> 00:44:35.510
It's not allowing you to easily
understand what you need to

00:44:35.570 --> 00:44:38.700
change in order to improve
your classification system.

00:44:39.120 --> 00:44:42.780
So what we found extremely helpful,
especially at the beginning of

00:44:42.780 --> 00:44:46.140
the development of the web filter,
was to analyze what LSM will

00:44:46.290 --> 00:44:48.160
learn in the training phase.

00:44:48.320 --> 00:44:49.650
You can do that from terminal.

00:44:49.730 --> 00:44:55.500
I use the LSM dump command,
and you pass it as input the map file.

00:44:56.390 --> 00:45:00.520
All of a sudden,
we print out all the data gathered

00:45:00.920 --> 00:45:05.000
during the training phase,
and let's analyze it more closely.

00:45:05.000 --> 00:45:05.000
Starting from the last column,

00:45:05.210 --> 00:45:07.560
So in here,
we read all the words that LSM has

00:45:07.560 --> 00:45:09.920
seen in the training documents.

00:45:10.270 --> 00:45:14.350
These make the dictionary of the LSM map.

00:45:14.490 --> 00:45:18.850
These are all the words that LSM is able
to recognize and assign a meaning to.

00:45:20.860 --> 00:45:25.340
Then we have as many columns as the
number of categories that are in our map,

00:45:25.350 --> 00:45:29.010
which is, in the case of the web filter,
just two.

00:45:29.630 --> 00:45:34.340
And here we read the number of
times a given word was observed

00:45:34.760 --> 00:45:38.770
in the training documents provided
for each specific category.

00:45:39.430 --> 00:45:42.190
So by looking at the values
on these two columns,

00:45:42.190 --> 00:45:45.880
we can have an idea on what
LSM thinks about specific words.

00:45:45.990 --> 00:45:47.870
So for example,

00:45:48.090 --> 00:45:55.130
The word advertising was found five times
more in the training document provided

00:45:55.140 --> 00:45:57.010
to train the legitimate category.

00:45:57.110 --> 00:46:01.560
And therefore, LSM is thinking that
this word is legitimate.

00:46:02.020 --> 00:46:07.260
The word "storings" then was found
almost equally in both categories.

00:46:07.370 --> 00:46:10.600
Therefore, the semantic meaning of
this word is very low.

00:46:10.710 --> 00:46:15.210
And LSM would probably ignore this
word as it's classifying a document.

00:46:15.680 --> 00:46:18.620
So the idea here is that we can go
through all this list and verify

00:46:18.720 --> 00:46:22.440
whether LSM has really learned
to recognize what words are to be

00:46:22.600 --> 00:46:25.000
considered explicit or legitimate.

00:46:25.060 --> 00:46:27.020
The problem here is that
the number is pretty big.

00:46:27.080 --> 00:46:31.080
In our web filter,
we have over 100,000 unique words.

00:46:31.210 --> 00:46:33.400
So this is not something
that you can do manually.

00:46:33.440 --> 00:46:36.360
You want to write a script that
identifies the most significant

00:46:36.360 --> 00:46:42.220
words that are being used to
classify a specific category.

00:46:42.370 --> 00:46:46.850
So for the sake of the example here,
let's say we want to identify

00:46:46.890 --> 00:46:49.860
the most representative,
the most significant words that have been

00:46:49.860 --> 00:46:53.030
used to classify the specific category.

00:46:53.480 --> 00:46:58.400
Well, we first need to select those words
that have very high word count.

00:46:58.400 --> 00:47:02.610
These are words that appear in
almost every single document that

00:47:02.610 --> 00:47:05.110
is provided in the training phase.

00:47:06.050 --> 00:47:09.110
And then out of this world,
we need to select only those that

00:47:09.200 --> 00:47:13.290
appear significantly more in one
category versus the other ones.

00:47:14.000 --> 00:47:17.130
And we call a word with this
feature an indexing word,

00:47:17.290 --> 00:47:21.020
because its presence in an unknown--
and porn is an indexing word for

00:47:21.250 --> 00:47:30.210
the specific category-- because its
presence in an unknown document highly

00:47:30.210 --> 00:47:30.210
shifts the classification of this
document towards the specific category.

00:47:32.720 --> 00:47:37.380
So one of the very first thing that we
wanted to verify when we were developing

00:47:37.380 --> 00:47:42.330
the web filter was to see whether the top
indexing word of this specific category

00:47:42.400 --> 00:47:45.280
were actually related to adult material.

00:47:45.390 --> 00:47:47.440
And this is what we obtained.

00:47:48.440 --> 00:47:54.760
So without doing a very complex analysis,
we could see very well what

00:47:54.760 --> 00:47:54.760
the problems were here.

00:47:55.250 --> 00:47:58.520
The filter is considering explicit
words that are just frequently

00:47:58.540 --> 00:48:02.700
used in English or that are just
part of the Internet vocabulary.

00:48:02.740 --> 00:48:07.450
It was pretty obvious that
in the first prototype,

00:48:07.450 --> 00:48:10.460
the training data that we were
using was very imbalanced.

00:48:10.500 --> 00:48:13.730
It did not really approximate
well the distribution of the

00:48:13.760 --> 00:48:15.420
content of the whole web.

00:48:15.670 --> 00:48:19.240
We also realized that finding a
good representation of the web was

00:48:19.240 --> 00:48:21.260
a quite hard task to accomplish.

00:48:21.390 --> 00:48:24.060
So in addition to finding
better training data,

00:48:24.130 --> 00:48:28.260
we should also exclude from the
classification words that don't really

00:48:28.260 --> 00:48:30.760
have any semantic meaning associated.

00:48:30.870 --> 00:48:34.990
And we called the words that I excluded
from the classification "stop words."

00:48:36.370 --> 00:48:40.800
And this graph shows you the distribution
of the training pages over their score.

00:48:40.860 --> 00:48:44.900
The blue dot are pages that
we know are legitimate.

00:48:44.950 --> 00:48:48.390
The red dot are pages
that we know are explicit.

00:48:48.460 --> 00:48:50.160
On the vertical axis,
we have the page score.

00:48:50.210 --> 00:48:53.770
And once again, the higher the score,
the higher the probability

00:48:53.770 --> 00:48:55.330
for a page to be explicit.

00:48:55.410 --> 00:48:58.040
So if our filter was perfect,
all those red dots would

00:48:58.040 --> 00:49:00.500
be at the top of the graph,
and all those blue dots

00:49:00.500 --> 00:49:01.800
would be at the bottom.

00:49:01.850 --> 00:49:04.000
Now, without going too much
into the details here,

00:49:04.000 --> 00:49:06.710
we see that by increasing
the number of stop words,

00:49:06.760 --> 00:49:11.300
the two group of pages start to be
clustered at the edge of the graph.

00:49:12.430 --> 00:49:15.180
And this means we are making a
better classification and fewer

00:49:15.180 --> 00:49:20.490
error in classifying explicit
and legitimate documents.

00:49:23.270 --> 00:49:25.710
Another frequent problem that you're
going to face while working with

00:49:25.740 --> 00:49:29.290
LSM is to understand the reason
behind a document classification,

00:49:29.320 --> 00:49:33.240
or most importantly,
a document misclassification.

00:49:33.400 --> 00:49:35.500
And you see here a really good example.

00:49:35.700 --> 00:49:39.020
In one of the first
iterations of our web filter,

00:49:39.020 --> 00:49:43.100
the Wikipedia page about
Barbie was being restricted.

00:49:45.830 --> 00:49:51.800
So to figure out what are the
reasons behind a nice classification,

00:49:51.820 --> 00:49:55.320
you can use, once again, from Terminal,
the lsmdump command.

00:49:55.550 --> 00:50:02.180
You pass as input the map file,
and the text documented is the

00:50:02.180 --> 00:50:02.180
subject of your investigation.

00:50:04.070 --> 00:50:07.620
In LSM, we print out all the data or
part of the data that has been

00:50:07.620 --> 00:50:09.780
used to evaluate this document.

00:50:09.880 --> 00:50:11.880
So let's analyze it once again.

00:50:12.100 --> 00:50:15.220
In the last column,
we read the words that have been

00:50:15.220 --> 00:50:16.960
used to evaluate this document.

00:50:16.980 --> 00:50:20.000
These are words that are part
of the document and that are

00:50:20.000 --> 00:50:22.360
also part of the LSM map.

00:50:23.490 --> 00:50:26.000
Then once again,
we have the word frequency.

00:50:26.000 --> 00:50:29.780
These are the number of times a given
word was observed in the training

00:50:29.790 --> 00:50:32.100
document for each specific category.

00:50:32.230 --> 00:50:38.820
These are the exact same word counts that
you will find in the simple map dump.

00:50:40.000 --> 00:50:43.880
And then in the very first column,
we read the percentage value

00:50:43.880 --> 00:50:46.870
relative to the number of times,
or...

00:50:47.360 --> 00:50:50.410
Yeah, a percentage value relative to
the number of times a given word

00:50:50.410 --> 00:50:53.300
is repeated in this document.

00:50:53.450 --> 00:50:56.140
So, for example,
in this specific Wikipedia page,

00:50:56.140 --> 00:51:04.960
the word "Barbie" is repeated
almost ten times -- or,

00:51:04.960 --> 00:51:04.960
sorry, every ten words in the document.

00:51:07.580 --> 00:51:09.000
So let's go back to our initial question.

00:51:09.000 --> 00:51:13.190
Why is this Wikipedia page
being blocked by our filter?

00:51:13.210 --> 00:51:16.460
What we can see here on top,
that the word "doll" and "dolls"

00:51:16.640 --> 00:51:19.880
were found significantly more
in this specific category.

00:51:19.890 --> 00:51:22.040
And therefore,
these two words are driving

00:51:22.390 --> 00:51:25.440
the classification towards
this specific category,

00:51:25.440 --> 00:51:28.550
and the filter is restricting
the Wikipedia page.

00:51:28.650 --> 00:51:34.390
But to fix this problem,
we simply needed to add more training

00:51:34.710 --> 00:51:38.380
documents related to legitimate toys.

00:51:38.440 --> 00:51:41.480
And that was enough to
fix this specific issue.

00:51:44.890 --> 00:51:49.730
So it is now 5:50,
and you can relax knowing that your

00:51:50.150 --> 00:51:55.240
children are safely surfing the web
thanks to Latent Semantic Mapping.

00:51:55.240 --> 00:52:00.580
Thank you.

00:52:03.200 --> 00:52:07.560
So you've seen how we use latent
semantic mapping for our purposes.

00:52:07.560 --> 00:52:12.500
How can you make it work for you,
yourself, for your applications?

00:52:12.580 --> 00:52:16.960
You have to think about what you could
categorize with latent semantic mapping.

00:52:16.960 --> 00:52:20.250
You could use it to categorize
your bookmarks in your browser.

00:52:20.330 --> 00:52:24.040
You could use it to categorize
RSS feeds by content.

00:52:24.040 --> 00:52:29.380
You could categorize your books or other
media library by going and fetching

00:52:29.380 --> 00:52:34.560
reviews or abstracts and using those
to put those media into categories.

00:52:34.560 --> 00:52:37.980
You could categorize your wine cellar.

00:52:37.980 --> 00:52:43.460
You could go wild and do math
science and categorize DNA sequences.

00:52:43.460 --> 00:52:44.670
It's really up to you.

00:52:44.680 --> 00:52:49.570
But there are a few things you should
know before you consider using LSM.

00:52:51.420 --> 00:52:57.100
First of all, LSM handles tasks that
are semantic in nature.

00:52:57.100 --> 00:53:06.690
If a problem is syntactic in nature,
like identifying dates, times,

00:53:06.690 --> 00:53:06.690
or addresses in text,
that's not an area where

00:53:06.690 --> 00:53:06.690
LSM is going to do well.

00:53:07.100 --> 00:53:08.830
A problem needs to be semantic in nature.

00:53:08.840 --> 00:53:14.010
That is, for instance,
categorizing documents by topic.

00:53:16.060 --> 00:53:20.750
Secondly, the categories you pick
need to be distinct enough.

00:53:20.880 --> 00:53:25.380
If you have something like an
economy page of a newspaper

00:53:25.380 --> 00:53:29.810
versus a business page,
then Latent Semantic Mapping is

00:53:29.810 --> 00:53:33.330
not going to be able to tell you
what page an article belongs on,

00:53:33.360 --> 00:53:34.300
probably.

00:53:34.320 --> 00:53:38.580
If it's the economy section
versus entertainment section,

00:53:38.580 --> 00:53:43.590
although there still are overlaps,
Latent Semantic Mapping is likely

00:53:43.590 --> 00:53:45.690
to be able to tell those apart.

00:53:47.570 --> 00:53:50.550
You also need good training data.

00:53:50.920 --> 00:53:52.940
You need a good quality
of your training data.

00:53:52.940 --> 00:53:56.840
It needs to be representative of
the full breadth of your domain.

00:53:57.060 --> 00:54:01.210
For instance, as Giovanni said,
if you don't train with toys,

00:54:01.300 --> 00:54:09.360
you might mischaracterize whether
dolls are an adult or a child concept.

00:54:09.610 --> 00:54:13.050
Your data needs to be reasonably clean
for the purpose of classification.

00:54:13.050 --> 00:54:16.090
That is,
if you're not interested in HTML tags,

00:54:16.200 --> 00:54:20.990
you should not present the
HTML tags to the training.

00:54:21.020 --> 00:54:26.530
You should try to fix the typos
in your training material.

00:54:26.870 --> 00:54:30.780
And very important,
your training data needs to be as

00:54:30.780 --> 00:54:35.430
balanced as possible in each category.

00:54:35.430 --> 00:54:35.430
If you have vastly more

00:54:35.610 --> 00:54:39.410
Material in one category than in another,
that's also going to

00:54:39.410 --> 00:54:42.420
skew evaluation results.

00:54:43.190 --> 00:54:45.600
That also leads us into the other point.

00:54:45.680 --> 00:54:47.480
You need enough training data.

00:54:47.640 --> 00:54:51.880
You need enough data to cover
the variability in your material.

00:54:52.050 --> 00:54:55.560
As a rule of thumb,
if you use a large vocabulary application

00:54:55.560 --> 00:55:00.060
that is general English text rather
than very domain restricted text,

00:55:00.060 --> 00:55:03.760
you need more than 30,000 unique words.

00:55:03.880 --> 00:55:09.230
And the more categories you have,
the more training data you need.

00:55:09.460 --> 00:55:14.850
And if you have something like you
categorize stuff that comes in from

00:55:14.850 --> 00:55:18.840
a news feed or something like that,
if your data changes over time,

00:55:19.040 --> 00:55:20.900
you need more initial training data.

00:55:21.000 --> 00:55:24.540
Or, of course,
you can also go back and retrain later,

00:55:24.540 --> 00:55:26.810
adding more material.

00:55:28.800 --> 00:55:32.580
So how do you test the
accuracy of your results?

00:55:32.920 --> 00:55:38.430
One method which is kind of tried and
proven in research and in practical

00:55:38.570 --> 00:55:42.920
application is to partition your
training data into a number of chunks.

00:55:42.980 --> 00:55:46.390
You use all but one of
them to train up your map.

00:55:46.520 --> 00:55:49.680
And the last one that you held out,
you use for testing.

00:55:49.720 --> 00:55:52.280
It's important that you don't
use testing data that is already

00:55:52.280 --> 00:55:56.350
present in the training of the map,
because that's completely going

00:55:56.350 --> 00:55:58.660
to invalidate your results.

00:55:58.660 --> 00:56:00.700
Then you run your test.

00:56:00.720 --> 00:56:05.610
You rotate things around by holding
out another part of your input data,

00:56:05.610 --> 00:56:08.500
and then average out the results.

00:56:09.110 --> 00:56:12.760
So what if your results are not as
good as you would like them to be?

00:56:12.820 --> 00:56:16.740
First thing you could try
is what Giovanni also did,

00:56:16.750 --> 00:56:18.150
is to use a list of stop words.

00:56:18.220 --> 00:56:22.660
You saw in his diagrams that this
was a simple and very effective

00:56:22.720 --> 00:56:26.270
means of improving results.

00:56:27.170 --> 00:56:32.870
That is, holding out words that appear in
all categories roughly equally.

00:56:32.990 --> 00:56:37.210
Secondly, you can try experimenting
with the number of dimensions.

00:56:37.390 --> 00:56:40.160
By default, our number of dimensions is
the number of categories.

00:56:40.240 --> 00:56:43.490
But if you have a problem
where you use 1,000 categories,

00:56:43.610 --> 00:56:48.470
there is no point in doing your
math with 1,000 dimensions.

00:56:48.550 --> 00:56:51.410
For a natural language problem,
you should restrict things to

00:56:51.410 --> 00:56:55.540
about 100 to 300 dimensions.

00:56:55.550 --> 00:56:58.680
And if that still doesn't work,
you can also try adding some

00:56:58.680 --> 00:57:03.880
frequently used word pairs or words
triplets by doing a custom parser.

00:57:03.880 --> 00:57:08.840
And if you have something
like 18 USC 2257,

00:57:08.960 --> 00:57:13.840
that might be a useful to
use and to add to your map.

00:57:16.900 --> 00:57:20.180
As we have seen, for instance,
in junk mail filtering,

00:57:20.220 --> 00:57:24.110
it's often useful to combine Latent
Semantic Mapping with other sources

00:57:24.240 --> 00:57:27.770
of information and knowledge
because Latent Semantic Mapping

00:57:27.770 --> 00:57:31.390
does well where other techniques
don't do so well and vice versa,

00:57:31.390 --> 00:57:34.880
other techniques complement
Latent Semantic Mapping.

00:57:34.900 --> 00:57:39.340
We've used that in a junk mail filter
where we have handwritten rules,

00:57:39.530 --> 00:57:40.940
server-side rules.

00:57:41.040 --> 00:57:45.450
We use it in Kanato Kanji conversion
where we apply a whole bunch of

00:57:45.500 --> 00:57:50.620
heuristics and use Latent Semantic
Mapping as one method among many.

00:57:50.850 --> 00:57:52.500
That's all there is to know.

00:57:52.570 --> 00:57:55.970
Now go forth, map some text,
map some other data,

00:57:56.000 --> 00:57:58.600
and tell us about your results.

00:57:58.790 --> 00:58:02.840
For more information,
you can go to the WWDC website.

00:58:02.850 --> 00:58:06.240
You can also contact our evangelist,
Matt Brands.

00:58:06.260 --> 00:58:09.800
We have a public mailing list that
you're welcome to subscribe to.

00:58:09.850 --> 00:58:15.830
It's fairly low traffic,
so it's not going to burden

00:58:15.830 --> 00:58:21.220
your inbox with more spam in
the interest of spam reduction.

00:58:21.220 --> 00:58:21.220
And you can also go look
up our documentation.