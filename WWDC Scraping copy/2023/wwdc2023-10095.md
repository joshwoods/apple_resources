# Wwdc2023 10095

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Explore rendering for spatial computingFind out how you can take control of RealityKit rendering to improve the look and feel of your apps and games on visionOS. Discover how you can customize lighting, add grounding shadows, and control tone mapping for your content. We'll also go over best practices for two key treatments on the platform: rasterization rate maps and dynamic content scaling.Chapters0:00 -Introduction1:15 -Lighting and shadows5:05 -Materials10:09 -Rasterization rate maps13:13 -Dynamic content scaling16:01 -Wrap-upResourcesRendering at Different Rasterization RatesHD VideoSD VideoRelated VideosWWDC23Enhance your spatial computing app with RealityKitExplore materials in Reality Composer ProOptimize app power and performance for spatial computing

Find out how you can take control of RealityKit rendering to improve the look and feel of your apps and games on visionOS. Discover how you can customize lighting, add grounding shadows, and control tone mapping for your content. We'll also go over best practices for two key treatments on the platform: rasterization rate maps and dynamic content scaling.

0:00 -Introduction

1:15 -Lighting and shadows

5:05 -Materials

10:09 -Rasterization rate maps

13:13 -Dynamic content scaling

16:01 -Wrap-up

Rendering at Different Rasterization Rates

HD VideoSD Video

HD Video

SD Video

Enhance your spatial computing app with RealityKit

Explore materials in Reality Composer Pro

Optimize app power and performance for spatial computing

Search this video…♪ Mellow instrumental hip-hop ♪♪Hello! I'm Ivan, and I'm an engineer on the RealityKit team.Welcome to my session,"Explore rendering for spatial computing."RealityKit is a framework for rendering, animating,and simulating 3D models.One of the strongest suits of RealityKitis applying realistic rendering for your content.In order to help you make the most of the rendering abilitiesof RealityKit and enhance the look of your content,I wanted to share some rendering considerations to keep in mindwhile developing your app for spatial computing.We'll start with lighting and shadows for your 3D content.Then we'll learn what's new with RealityKit materials.Next, I will introduce rasterization rate mapswhich greatly improves system performance.I will share recommendations on how to adjust your contentto make it work well with this optimization.Finally, I will introduce a techniquecalled dynamic content scaling,which ensures that the UI is always sharp.Let's start with lighting and shadows.If you are familiar with RealityKit on iOS and macOS,you will find that most of that knowledgealso applies to building spatial experiences.We introduced image-based lighting in RealityKitto make your content look realistic.Image-based lighting, or IBL, uses textures,like the one on the right to produce realistic reflections.Shadows help us understand how objects are positionedwith respect to each other.Before we look at the new features,let's quickly go over the componentsof image-based lighting.There are two main components to an IBL:an Environment probe texture that is provided by ARKitand is specific to the physical space in the roomand the system IBL texture which is packaged with the OS.The system IBL texture adds extra highlightsto ensure that your content looks great in any environment.The two components are added togetherto produce the combined IBL texture.If you have an active environment,it would also have an effect on the combined IBL texture.This year RealityKit adds ability to overridethe system IBL texture in order to customize lighting.Let's take a look at an example.This is the "Hello World" experiencethat offers a view of the solar system.By default RealityKit would light it using the system IBL.However, if you assign a new IBLto the new image-based light component,it would replace the system IBL and light those objectsusing the surrounding immersive environment.Let me show you how that's done.Here we first load our 3D content.In this case, it's the satellite model.Then we load an environment resource called Sunlight.It contains an image of the Sun and stars surrounding the Earth.We need both the model and the environment resourceto set up IBL, so let's make sureboth loading operations have finished.Next, we add the ImageBasedLightComponent.It references the Environment resource that we've just loaded.Finally we add ImageBasedLightReceiverComponentto the satellite entity.You can add these receiver componentseven to other entities in order to light themusing the same IBL.And that's how easy it is to customize lightingin RealityKit.Next, let's take a look at how to add shadowsto your application.Let's consider a simple example where you place a 3D objectlike this vase on top of a floating plane.Without any shadows turned on, it might be hard to understandthe relative position of the vase and the plane.But by simply adding RealityKit's grounding shadow,it becomes a lot clearer that the vaseis above the center of the plane.Let's see how to do this in code.We start by loading the vase model.Here, flower_tulip is the name of our 3D modelin our project.Next, we add the grounding shadow component.Make sure to set castsShadow flag set to true.And that's it!The vase entity will now cast grounding shadows.Simple, isn't it?Grounding shadows appear on top of 3D modelsas well as objects in the physical environment.Using a custom IBL for lighting your sceneand including grounding shadows can make your contentlook a lot better, but you could also directly workon the look of your objects by tweaking materials.Most of the RealityKit materials that are availableon macOS and iOS can also be used on xrOS.Let's quickly review them.The most commonly used material is PhysicallyBasedMaterial.PhysicallyBasedMaterial in RealityKitreacts to lighting and can be used to represent a varietyof real-world materials, such as plastics or metals.SimpleMaterial also reacts to lighting,but uses a smaller subset of parameters.It is especially good for quick experiments.UnlitMaterial doesn't react to lighting.In other words, it maintains a constant lookunder changing lighting conditions.VideoMaterial is a variation of unlit materialthat can map a movie file onto the surface of an entity.In addition to these materials, RealityKit introducesa new type of material called ShaderGraphMaterial.You can author the new ShaderGraphMaterialin Reality Composer Pro or load it from a MaterialX file.You can learn more about ShaderGraphMaterialin the session"Explore Materials in Reality Composer Pro."The color output of all of these materialsgoes through a special step called tone mapping.Tone mapping is a transformation that RealityKit appliesby default to the color output of a material.It enables more natural perceived colorsusing a variety of techniques.One such technique is remapping values above oneinto the visible range.Let me demonstrate this with an example.Here's a 3D render of a TV with tone mapping disabled.I assigned a texture with very bright values to the display.Now, if I enable tone mapping, you can see more detailsin the bright regions,like these flower petals.Tone mapping works great in generaland renders beautiful visuals; but for some use cases,you may want to display the exact colors of the object,for which you will have to opt out of tone mapping.Let's look at an example.Here's a simple application that shows a traffic lightand three buttons with labels "Stop," "Wait," and "Go."The traffic light itself is a 3D model,and the three buttons were added using SwiftUI.In order to precisely match the color of the lampto the color of the button, we could use an unlit materialfor the lamps, since unlit materialsmaintain the same constant look of the object,independent of the lighting conditions.However, the output of unlit material is still affectedby tone mapping which is on by defaultfor all of RealityKit materials.So, even if the same color is assigned to the SwiftUI buttonand the material of the lamp, they may appearslightly different from each other.The screenshot you see was taken with tone mapping enabled;let me show you what it looks likewhen tone mapping is disabled for the lamp material.You will notice that the colors of lamps and buttonsaccurately match.Let's toggle tone mapping for lamp material one more time.This is with tone mapping enabledand this is with tone mapping disabled.Let's take a look at the code samplethat shows how tone mapping can be toggled in code.We start by loading the traffic light model.Here, traffic_light is the name of our 3D modelin our project.Next, we find the entity named red_light.This entity corresponds to the top lamp of the traffic light.Once we have the entity, we access its model component.Next, we create a new unlit material.We pass both our desired color and a new Boolean parametercalled applyPostProcessToneMap.This Boolean parameter is set to false in order to disabletone mapping transformation for this material.Finally, we replace material on the model componentand assign the model component back to the entity.This is done for each of the three lamps.Now the color of button and color of lampsshould match closely.applyPostProcessToneMap flag is useful in caseswhen you want to show an exact representationof the colors in your scene.This can come in handy when using RealityKitto build something like a menu or a heads-up display.This new property is also exposed in the material editorof Reality Composer Pro.Now, let's take a look at some quality considerations.We'll start with the rasterization rate mapsfor spatial computing.The displays used in the headset have a high resolution,and the OS needs to update these displaysmany times a second.Let me explain this with a visual.As you may know already, the headset has the abilityto detect exactly where a person's eyes are looking.Here's a simulated scenario where a personmoves their eyes to the right and then back to the center.The yellow circle represents the center pointof the person's focus.The area that is surrounding that pointis highlighted with a glow, and the periphery is darkened.Rasterization rate map makes it so that fewer calculationsare performed in the areas that are darkened.You can see that at any given momentthe highlighted region is small in comparison to the periphery.This allows the system to achieve significant memoryand performance savings.In RealityKit,this optimization is automatically enabled for you.While it greatly improves the system performance,in some situations you may have to adjust your contentto make it work well with this optimization at play.For example, here's a palm leaf asset,When placed in the center of the screen,it looks sharp and detailed.But when I move the object to the leftand apply the eye movement simulation again,you can observe flickering on the palm leaf.The flickering is especially strongwhen the yellow circle representing the eye directionis close to the right edge of the screen.The flickering happens because the rasterization rate mapenables higher detail around the pointwhere the person is looking, and the pixelsaround the palm leaf are rendered at a lower detailas the eyes move away from it.Now, you can reduce the flickeringby simply adjusting a few parameters of your content.Let's take a look at this.Here's a representation of the same palm leaf assetwith a red wireframe overlay on top.You can see that there are a lot of small triangles here.These small triangles were the reason of flickeringin the periphery.We can reduce the flickering by simply makingthe triangles larger and storing the fine detailsin an opacity texture.Here's how the simulation looks after adjusting the asset.This 3D model looks better after adjustment,because RealityKit automatically generateslower-resolution versions of the opacity mapwhen the asset is loaded.Those lower-resolution versions of the textureare called mipmaps and automatically used by the GPUto improve the look in the lower-detail region.For more details on rasterization rate maps,please refer to the article"Rendering at Different Rasterization Rates."Similar to rasterization rate maps,there is another technique called "dynamic content scaling"that automatically improves the look of contentthat was authored using SwiftUI.Let's take a look.Here's an application that displays a list of monthsarranged in a grid.Each month is represented with a text label.When the eyes look at the month of June,the system rasterizes the text in that areaat the highest level of detail.The area marked in blue surrounding "June"will be rasterized at a slightly reduced level of detail,but still maintains a high quality overall.The area marked in purple, however,is rasterized at a much lower level of detailsince human vision system perceives fewer detailsin the periphery and it wouldn't be as noticeable.This kind of rasterization at variable levels of detailbased on what the eyes are looking atis called "dynamic content scaling."The system relies on dynamic content scalingto draw UI content at the right scaleand ensures that it's always sharp.Dynamic content scaling affects the relative sizein memory for the rasterized content.In other words, our text labels are scaledto different sizes depending on how close they areto the point where the eyes are looking at.For example, you can see that the label that says "June"is the largest --it has the most resolution and detail.Then there is a group of eight months --January, February, March, and so onthat have slightly less detail.Finally, there is a group of three months --April, August, December -- that are farthest awayfrom eye look-at direction.That last group would be represented with smaller imagesin memory.Now, let's understand how to enable dynamic content scaling.If you are using UIKit and SwiftUI,your application will automatically benefitfrom this technique.If you are relying on the Core Animation frameworkto build your UI, there is a new APIto enable dynamic content scaling.Let's take a look at this API.Dynamic content scaling can be enabled by settingthe property of CALayer wantsDynamicContentScalingto true.Note that this technique relies on rasterizingat higher resolutions, so it is not recommendedto use with primarily bitmap-based content.You can find the full list of recommendationsregarding dynamic content scaling on developer.apple.com.Let me summarize everything we've learned.We started by looking at how to add image-based lightsand grounding shadows to RealityKit applications.Then we reviewed materials that are availablefor spatial experiences,including the new ShaderGraphMaterial.And we've also learned how to control tone mappingfor unlit material.Next we learned how rasterization rate mapsare used for spatial computing, including an examplehow to adjust 3D model to reduce flickering in the periphery.Finally, we learned how dynamic content scaling workson the system and how you can make use of it.We're very excited about this year's releaseand can't wait to see the beautiful spatial experiencesyou build on xrOS.Thank you.♪

♪ Mellow instrumental hip-hop ♪♪Hello! I'm Ivan, and I'm an engineer on the RealityKit team.

Welcome to my session,"Explore rendering for spatial computing."RealityKit is a framework for rendering, animating,and simulating 3D models.

One of the strongest suits of RealityKitis applying realistic rendering for your content.

In order to help you make the most of the rendering abilitiesof RealityKit and enhance the look of your content,I wanted to share some rendering considerations to keep in mindwhile developing your app for spatial computing.

We'll start with lighting and shadows for your 3D content.

Then we'll learn what's new with RealityKit materials.

Next, I will introduce rasterization rate mapswhich greatly improves system performance.

I will share recommendations on how to adjust your contentto make it work well with this optimization.

Finally, I will introduce a techniquecalled dynamic content scaling,which ensures that the UI is always sharp.

Let's start with lighting and shadows.

If you are familiar with RealityKit on iOS and macOS,you will find that most of that knowledgealso applies to building spatial experiences.

We introduced image-based lighting in RealityKitto make your content look realistic.

Image-based lighting, or IBL, uses textures,like the one on the right to produce realistic reflections.

Shadows help us understand how objects are positionedwith respect to each other.

Before we look at the new features,let's quickly go over the componentsof image-based lighting.

There are two main components to an IBL:an Environment probe texture that is provided by ARKitand is specific to the physical space in the roomand the system IBL texture which is packaged with the OS.

The system IBL texture adds extra highlightsto ensure that your content looks great in any environment.

The two components are added togetherto produce the combined IBL texture.

If you have an active environment,it would also have an effect on the combined IBL texture.

This year RealityKit adds ability to overridethe system IBL texture in order to customize lighting.

Let's take a look at an example.

This is the "Hello World" experiencethat offers a view of the solar system.

By default RealityKit would light it using the system IBL.

However, if you assign a new IBLto the new image-based light component,it would replace the system IBL and light those objectsusing the surrounding immersive environment.

Let me show you how that's done.

Here we first load our 3D content.

In this case, it's the satellite model.

Then we load an environment resource called Sunlight.

It contains an image of the Sun and stars surrounding the Earth.

We need both the model and the environment resourceto set up IBL, so let's make sureboth loading operations have finished.

Next, we add the ImageBasedLightComponent.

It references the Environment resource that we've just loaded.

Finally we add ImageBasedLightReceiverComponentto the satellite entity.

You can add these receiver componentseven to other entities in order to light themusing the same IBL.

And that's how easy it is to customize lightingin RealityKit.

Next, let's take a look at how to add shadowsto your application.

Let's consider a simple example where you place a 3D objectlike this vase on top of a floating plane.

Without any shadows turned on, it might be hard to understandthe relative position of the vase and the plane.

But by simply adding RealityKit's grounding shadow,it becomes a lot clearer that the vaseis above the center of the plane.

Let's see how to do this in code.

We start by loading the vase model.

Here, flower_tulip is the name of our 3D modelin our project.

Next, we add the grounding shadow component.

Make sure to set castsShadow flag set to true.

And that's it!The vase entity will now cast grounding shadows.

Simple, isn't it?Grounding shadows appear on top of 3D modelsas well as objects in the physical environment.

Using a custom IBL for lighting your sceneand including grounding shadows can make your contentlook a lot better, but you could also directly workon the look of your objects by tweaking materials.

Most of the RealityKit materials that are availableon macOS and iOS can also be used on xrOS.

Let's quickly review them.

The most commonly used material is PhysicallyBasedMaterial.

PhysicallyBasedMaterial in RealityKitreacts to lighting and can be used to represent a varietyof real-world materials, such as plastics or metals.

SimpleMaterial also reacts to lighting,but uses a smaller subset of parameters.

It is especially good for quick experiments.

UnlitMaterial doesn't react to lighting.

In other words, it maintains a constant lookunder changing lighting conditions.

VideoMaterial is a variation of unlit materialthat can map a movie file onto the surface of an entity.

In addition to these materials, RealityKit introducesa new type of material called ShaderGraphMaterial.

You can author the new ShaderGraphMaterialin Reality Composer Pro or load it from a MaterialX file.

You can learn more about ShaderGraphMaterialin the session"Explore Materials in Reality Composer Pro."The color output of all of these materialsgoes through a special step called tone mapping.

Tone mapping is a transformation that RealityKit appliesby default to the color output of a material.

It enables more natural perceived colorsusing a variety of techniques.

One such technique is remapping values above oneinto the visible range.

Let me demonstrate this with an example.

Here's a 3D render of a TV with tone mapping disabled.

I assigned a texture with very bright values to the display.

Now, if I enable tone mapping, you can see more detailsin the bright regions,like these flower petals.

Tone mapping works great in generaland renders beautiful visuals; but for some use cases,you may want to display the exact colors of the object,for which you will have to opt out of tone mapping.

Let's look at an example.

Here's a simple application that shows a traffic lightand three buttons with labels "Stop," "Wait," and "Go."The traffic light itself is a 3D model,and the three buttons were added using SwiftUI.

In order to precisely match the color of the lampto the color of the button, we could use an unlit materialfor the lamps, since unlit materialsmaintain the same constant look of the object,independent of the lighting conditions.

However, the output of unlit material is still affectedby tone mapping which is on by defaultfor all of RealityKit materials.

So, even if the same color is assigned to the SwiftUI buttonand the material of the lamp, they may appearslightly different from each other.

The screenshot you see was taken with tone mapping enabled;let me show you what it looks likewhen tone mapping is disabled for the lamp material.

You will notice that the colors of lamps and buttonsaccurately match.

Let's toggle tone mapping for lamp material one more time.

This is with tone mapping enabledand this is with tone mapping disabled.

Let's take a look at the code samplethat shows how tone mapping can be toggled in code.

We start by loading the traffic light model.

Here, traffic_light is the name of our 3D modelin our project.

Next, we find the entity named red_light.

This entity corresponds to the top lamp of the traffic light.

Once we have the entity, we access its model component.

Next, we create a new unlit material.

We pass both our desired color and a new Boolean parametercalled applyPostProcessToneMap.

This Boolean parameter is set to false in order to disabletone mapping transformation for this material.

Finally, we replace material on the model componentand assign the model component back to the entity.

This is done for each of the three lamps.

Now the color of button and color of lampsshould match closely.

applyPostProcessToneMap flag is useful in caseswhen you want to show an exact representationof the colors in your scene.

This can come in handy when using RealityKitto build something like a menu or a heads-up display.

This new property is also exposed in the material editorof Reality Composer Pro.

Now, let's take a look at some quality considerations.

We'll start with the rasterization rate mapsfor spatial computing.

The displays used in the headset have a high resolution,and the OS needs to update these displaysmany times a second.

Let me explain this with a visual.

As you may know already, the headset has the abilityto detect exactly where a person's eyes are looking.

Here's a simulated scenario where a personmoves their eyes to the right and then back to the center.

The yellow circle represents the center pointof the person's focus.

The area that is surrounding that pointis highlighted with a glow, and the periphery is darkened.

Rasterization rate map makes it so that fewer calculationsare performed in the areas that are darkened.

You can see that at any given momentthe highlighted region is small in comparison to the periphery.

This allows the system to achieve significant memoryand performance savings.

In RealityKit,this optimization is automatically enabled for you.

While it greatly improves the system performance,in some situations you may have to adjust your contentto make it work well with this optimization at play.

For example, here's a palm leaf asset,When placed in the center of the screen,it looks sharp and detailed.

But when I move the object to the leftand apply the eye movement simulation again,you can observe flickering on the palm leaf.

The flickering is especially strongwhen the yellow circle representing the eye directionis close to the right edge of the screen.

The flickering happens because the rasterization rate mapenables higher detail around the pointwhere the person is looking, and the pixelsaround the palm leaf are rendered at a lower detailas the eyes move away from it.

Now, you can reduce the flickeringby simply adjusting a few parameters of your content.

Let's take a look at this.

Here's a representation of the same palm leaf assetwith a red wireframe overlay on top.

You can see that there are a lot of small triangles here.

These small triangles were the reason of flickeringin the periphery.

We can reduce the flickering by simply makingthe triangles larger and storing the fine detailsin an opacity texture.

Here's how the simulation looks after adjusting the asset.

This 3D model looks better after adjustment,because RealityKit automatically generateslower-resolution versions of the opacity mapwhen the asset is loaded.

Those lower-resolution versions of the textureare called mipmaps and automatically used by the GPUto improve the look in the lower-detail region.

For more details on rasterization rate maps,please refer to the article"Rendering at Different Rasterization Rates."Similar to rasterization rate maps,there is another technique called "dynamic content scaling"that automatically improves the look of contentthat was authored using SwiftUI.

Let's take a look.

Here's an application that displays a list of monthsarranged in a grid.

Each month is represented with a text label.

When the eyes look at the month of June,the system rasterizes the text in that areaat the highest level of detail.

The area marked in blue surrounding "June"will be rasterized at a slightly reduced level of detail,but still maintains a high quality overall.

The area marked in purple, however,is rasterized at a much lower level of detailsince human vision system perceives fewer detailsin the periphery and it wouldn't be as noticeable.

This kind of rasterization at variable levels of detailbased on what the eyes are looking atis called "dynamic content scaling."The system relies on dynamic content scalingto draw UI content at the right scaleand ensures that it's always sharp.

Dynamic content scaling affects the relative sizein memory for the rasterized content.

In other words, our text labels are scaledto different sizes depending on how close they areto the point where the eyes are looking at.

For example, you can see that the label that says "June"is the largest --it has the most resolution and detail.

Then there is a group of eight months --January, February, March, and so onthat have slightly less detail.

Finally, there is a group of three months --April, August, December -- that are farthest awayfrom eye look-at direction.

That last group would be represented with smaller imagesin memory.

Now, let's understand how to enable dynamic content scaling.

If you are using UIKit and SwiftUI,your application will automatically benefitfrom this technique.

If you are relying on the Core Animation frameworkto build your UI, there is a new APIto enable dynamic content scaling.

Let's take a look at this API.

Dynamic content scaling can be enabled by settingthe property of CALayer wantsDynamicContentScalingto true.

Note that this technique relies on rasterizingat higher resolutions, so it is not recommendedto use with primarily bitmap-based content.

You can find the full list of recommendationsregarding dynamic content scaling on developer.apple.com.

Let me summarize everything we've learned.

We started by looking at how to add image-based lightsand grounding shadows to RealityKit applications.

Then we reviewed materials that are availablefor spatial experiences,including the new ShaderGraphMaterial.

And we've also learned how to control tone mappingfor unlit material.

Next we learned how rasterization rate mapsare used for spatial computing, including an examplehow to adjust 3D model to reduce flickering in the periphery.

Finally, we learned how dynamic content scaling workson the system and how you can make use of it.

We're very excited about this year's releaseand can't wait to see the beautiful spatial experiencesyou build on xrOS.

Thank you.

♪

3:05 -Image based lighting

4:28 -Grounding shadows

8:48 -Disable tone mapping

15:34 -Dynamic content scaling

## Code Samples

```swift
RealityView
 { content 
in

    
async
 
let
 satellite 
=
 
Entity
(named: 
"Satellite"
, in: worldAssetsBundle)
    
async
 
let
 environment 
=
 
EnvironmentResource
(named: 
"Sunlight"
)

    
if
 
let
 satellite 
=
 
try?
 
await
 satellite, 
let
 environment 
=
 
try?
 
await
 environment {
        content.add(satellite)

        satellite.components.set(
ImageBasedLightComponent
(
           source: .single(environment)))

        satellite.components.set(
ImageBasedLightReceiverComponent
(
           imageBasedLight: satellite))
   }
}
```

```swift
RealityView
 { content 
in

    
if
 
let
 vase 
=
 
try?
 
await
 
Entity
(named: 
"flower_tulip"
) {
        content.add(vase)

        vase.components.set(
GroundingShadowComponent
(castsShadow: 
true
))
    }
}
```

```swift
RealityView
 { content 
in

    
if
 
let
 trafficLight 
=
 
try?
 
await
 
Entity
(named: 
"traffic_light"
) {
        content.add(trafficLight)

        
if
 
let
 lamp 
=
 trafficLight.findEntity(named: 
"red_light"
) {
            
if
 
var
 model 
=
 lamp.components[
ModelComponent
.
self
] {
                
let
 material 
=
 
UnlitMaterial
(color: .
init
(color), 
                                             applyPostProcessToneMap: 
false
)

                model.materials 
=
 [material]

                lamp.components[
ModelComponent
.
self
] 
=
 model
            }
        }
    }
}
```

```swift
// Enable dynamic content scaling on CALayer with:



var
 wantsDynamicContentScaling: 
Bool
 { 
get
 
set
 }
```

