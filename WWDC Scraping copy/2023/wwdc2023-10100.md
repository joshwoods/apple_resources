# Wwdc2023 10100

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Optimize app power and performance for spatial computingLearn how you can create powerful apps and games for visionOS by optimizing for performance and efficiency. We'll cover the unique power characteristics of the platform, explore building a performance plan, and share some of the tools and strategies to test and optimize your apps.Chapters0:38 -Explore performance with spatial computing1:45 -Profile your app6:19 -Explore render performance8:13 -Optimize SwiftUI and UIKit content for render performance10:50 -Optimize RealityKit content for render performance16:55 -Optimize Metal apps for render performance18:57 -Learn about user input performance20:14 -Optimize ARKit usage22:09 -Explore audio and video playback performance24:12 -Bring great performance to SharePlay experiences25:20 -Avoid terminations from thermal and memory pressureResourcesAnalyzing the performance of your visionOS appCreating a performance plan for your visionOS appHD VideoSD VideoRelated VideosWWDC23Create 3D models for Quick Look spatial experiencesCreate a great spatial playback experienceExplore materials in Reality Composer ProExplore rendering for spatial computingMeet ARKit for spatial computingMeet RealityKit TraceWWDC22Profile and optimize your game's memoryWWDC21Detect and diagnose memory issuesUltimate application performance survival guideWWDC20Optimize Metal apps and games with GPU countersWWDC19Delivering Optimized Metal Apps and GamesDesigning for Adverse Network and Temperature ConditionsWWDC18iOS Memory Deep DiveMetal Game Performance Optimization

Learn how you can create powerful apps and games for visionOS by optimizing for performance and efficiency. We'll cover the unique power characteristics of the platform, explore building a performance plan, and share some of the tools and strategies to test and optimize your apps.

0:38 -Explore performance with spatial computing

1:45 -Profile your app

6:19 -Explore render performance

8:13 -Optimize SwiftUI and UIKit content for render performance

10:50 -Optimize RealityKit content for render performance

16:55 -Optimize Metal apps for render performance

18:57 -Learn about user input performance

20:14 -Optimize ARKit usage

22:09 -Explore audio and video playback performance

24:12 -Bring great performance to SharePlay experiences

25:20 -Avoid terminations from thermal and memory pressure

Analyzing the performance of your visionOS app

Creating a performance plan for your visionOS app

HD VideoSD Video

HD Video

SD Video

Create 3D models for Quick Look spatial experiences

Create a great spatial playback experience

Explore materials in Reality Composer Pro

Explore rendering for spatial computing

Meet ARKit for spatial computing

Meet RealityKit Trace

Profile and optimize your game's memory

Detect and diagnose memory issues

Ultimate application performance survival guide

Optimize Metal apps and games with GPU counters

Delivering Optimized Metal Apps and Games

Designing for Adverse Network and Temperature Conditions

iOS Memory Deep Dive

Metal Game Performance Optimization

Search this video…♪ Mellow instrumental hip-hop ♪♪Hi, my name's Roy,and I'm an engineer on the Performance team.Today, we'll learn how you can optimizeyour app for spatial computing.We'll first look at the unique aspectsof this new platform for performance and power.We'll then go over building a performance plan,starting with profiling your app.And finally, we'll take a tour of the best waysto optimize performance issues for this platform.So what makes spatial computing differentfor power and performance?For one, the content on the displayis always being updated, regardless of app updates.Whenever people move their body, hands, or eyes,content needs to be updated.This means the system is always renderingevery frame at all times.The platform is also always running spatial algorithmsto create visuals and interactions across every app,and can run multiple apps at the same time.People will use your app with other apps.To handle multitasking and the additional system work,optimize your own app's resource usage as much as you can.To deliver a great user experience,performance in your app is essential.People want apps to be immediately responsive to inputand to provide smooth visual updatesfor a sense of immersion and comfort.Let's talk about how to profile and analyze your appfor performance issues.You may already be familiar with performance metricsfrom other Apple platforms.On any platform, people want apps that launch quickly,avoid disk wear, and don't use too much battery.They also want apps that avoid terminationsfrom inefficient memory use.With spatial computing, some of these metricstake on new meaning.Take power.Users want apps optimized for power,not for battery life, but because of thermal pressure.To sustain great performance,apps need to be optimized for system power use,to reduce the likelihood of encountering thermal pressure.Hangs are another example.They occur when an app's main thread is stalledon doing work for a period of time.But on this platform, even small, momentary stallsare disruptive to responsiveness.Now consider rendering.On other platforms, you may be optimizingfor render performance primarily to providesmooth UI and 3D animations.But here, render performance is essentialfor static content as well, since the system is always rendering.All Apple platforms provide tools to profile these metrics.Today, we'll cover finding performance issuesspecifically for spatial computing apps.But to learn more about optimizing for these metricson any Apple platform, check out the "Ultimate ApplicationPerformance Survival Guide" session.To optimize your app, profile during developmentusing tools like Instruments and Xcode Gauges.Once your app is released, gather more data from the fieldto help you further optimize your app.Let's talk more about profiling during development.RealityKit Trace is a brand-new template in Instrumentsto help profile any spatial computing appfor performance and power.It is an incredible tool that can help identifywhen your app has poor rendering performanceor when it is causing high system power use.There are many more instrument templates you can use as well.To learn more and explore this new template in action,watch the session "Meet RealityKit Trace."Your app's performance and power depends onhow someone interacts with it.The simulator doesn't perform the same work as a real device,so its performance data might not be accurate.Profile in the device.Profile using various interactions in your appwhen playing audio or video,or when using technologies like FaceTime and Personas.Make sure to check for good performance and low system powerover minutes of use.Lastly, try profiling while other apps are also runningand using resources.If you are bringing over compatible iPad and iPhone apps,make sure to profile them on deviceto identify further optimizations needed.After development, people may run your appin a wide variety of conditions.Data from the field is a great way to find issuesthat people are actually running into.When your app is in beta or publicly released,use MetricKit to get diagnostic reports from users.Xcode Organizer provides aggregated performance datafrom consenting users' devices,including energy diagnostics to help find any power issues.All of this data you collect helps you find bottlenecksand prioritize performance work for your app.Now, let's talk about optimizing your spatial computing app.Performance issues can arise from many areas.Today, we'll cover strategies for optimizingseveral core areas: rendering, user input, ARKit,audio and video playback, SharePlay,and app terminations from system pressure.Great rendering performance is one of the top prioritiesfor a great user experience.Let's dive in.In this platform, the rendering pipeline starts with your app,which is responsible for updating your app's content.Like all Apple platforms, your app's interface is updatedon the main thread and must provide updates promptly.Since your app is rendered in a 3D space alongside other apps,its updates get sent to the system render server.The render server is continuously runningto process updates from apps, users' inputs,and from their space and surroundings.It renders a new frame with all these updatesand sends it to the compositor.The compositor is always rendering.It supplies new frames to the displayat a rate matching the display's refresh rate.This helps provide a comfortable experience.This rate is usually 90 frames a second, but can be higher.While the compositor updates the display consistently,a great user experience still needs fast visual updatesfrom your app.If your app has content or updates that taketoo long to render, the render server can missits rendering deadline for optimal rendering latency.This means the app visuals could have made itto the compositor on frame Y,but made it on frame Y+1 instead.This delays the visual updates the people see on displayand makes your app feel less responsive.Especially severe rendering stalls can even causeyour app to be terminated.Whether your app is built on SwiftUI, UIKit,RealityKit, or Metal, you want to optimize its contentand updates to reduce frame dropsand work done in the render server.Let's start with optimizing SwiftUI and UIKit usage.On this platform, the system does render workfor static UI content, even with no app updates.This rendering work can increase from overdraw.Overdraw occurs when you have translucent contentin front of other virtual content.The GPU has to do work to render both content,but if that translucent content was fully opaque,the GPU wouldn't need to render any UI behind it.If you have any overlapping UI views with Z offsets,avoid adding translucency to them.Also, the more pixels on the displaythat your app's UI takes up,the more work is done to render the window.Consider reducing their default sizes.UI redraws in the render server are usually triggeredby app updates, but on this platform,they are also triggered by dynamic content scalingof core animation layers.With this behavior, the resolution of text,or vector-based UI content changes based onwhere the user is looking to allow for sharper visuals.This can also lead to more frequent redrawing of UI contentat potentially higher scales, even with no app updates.SwiftUI and UIKit enable this behavior by default,but apps doing custom Core Animationor Core Graphics rendering can opt in to this behavior.To learn more about its visual benefits and trade-offs,watch the session"Explore rendering for spatial computing."The cost of these redraws is heavily impactedby offscreen render passes.This can be caused by visual effectslike shadows, blur, and masking.Reduce these effects to make your appeasier for the system to render.To minimize re-draws in your app,avoid unnecessary view updates whenever possible.For example, with SwiftUI, use @Observable.@Observable provides more granular change trackingand reduces unneeded layout updates.Next, let's talk about optimizing 3D renderingwith RealityKit.SwiftUI has added RealityView this yearfor spatial computing.It can natively display RealityKit 3D sceneswithin a SwiftUI hierarchy.Your app should be a good citizen on the platformby optimizing your 3D scenesfor all of these RealityKit features.In these 3D scenes,the complexity of the assets they containcan greatly increase the amountof render server work done each frame.So let's start by optimizing these assets.Reality Composer Pro helps you createRealityKit scenes from assets.From mesh rendering, particles, animations,physics, and audio work, this tool provides statisticsabout the entire scene that can help youunderstand its performance impact.When examining these statistics, lower numbers usually meanless work, which can improve render performance.Watch the session"Create 3D models for Quick Look spatial experiences"to learn more around best practicesfor visuals and power use of 3D assets.Mesh rendering in particular is a core part of 3D rendering.Complex meshes and materials can quickly becomeperformance bottlenecks.Optimize the geometry of your mesh assets.Reduce the amount of separate mesh partsby combining parts that share a material.Mesh geometries with high triangle and vertex countscan also be costly.Use assets with smaller counts as needed.Minimize the impact of overdraw with your 3D meshes.To do this, use transparency sparinglyjust like with UI content.The “Physically Based” material in Reality Composer Prohas environment lighting, is well optimized,and works best for meshes with minimal transparency.But for translucent or very large content,consider using a Custom material with an unlit surface,Use baked lighting textures or other cheaper visuals.This helps avoid potential bottleneckswith more expensive lighting calculations.For further guidance on building and using materialsin RealityKit, watch these two sessions.Having optimized content for runtime renderingis a great start.But there's even more you can doto optimize your app with RealityKit.When your app updates its RealityKit content,updates get sent to the render server,which applies and renders them.But too many updates in a short period of timecan become a bottleneck for the render server.For example, your app may be rapidly creating and destroyingRealityKit entities.It may have too many complex animations,be updating too many SwiftUI views,or it may be loading many assets in a single frame.Create entities in advance, and hide or show them as needed.You could remove and add them to the scene hierarchy,or use the isEnabled flag.Minimize the amount of entities that are updatedby flattening your mesh entity hierarchies.For code-based animations, consider lower update ratesor reducing the number of entities the animations update.And when updating RealityKit entities,avoid triggering excessive SwiftUI redrawing accidentally.When using attachments, make sure to optimizetheir rendering in the same wayyou optimize for all SwiftUI content.Loading complex assets can also triggerexpensive render updates.Complex assets can also contributeto high app launch and content loading times.Use asynchronous loading APIs at runtimeto avoid blocking the main threadand load assets well before they are needed.Entities that use the same assetscan also share that asset and only load it once.Use exported files from Reality Composer Proas these files are optimized for loading timesand memory costs.You also get texture compression for free.Reducing asset sizes usually speeds up loading,but remember that texture compression already happenswith Reality Composer Pro files,so you may not need to do it yourself.Finally, let's talk about immersive experienceswith RealityKit.When your app requests to move to a dedicated full space,it becomes the only foreground experience running.When using a portal or moving to a fully immersive experience,the system also hidespart or all of the person's surroundings.Your app can create an environmentwith RealityKit content to fill their space.Your fully immersive content needs to be renderedto a lot more pixels on the displaythan scenes in a shared space or a full space.This means that more work can be done on the GPUto render that content.Optimize this type of content for GPU power use.Start with a “Custom” material with an unlit surfacein Reality Composer Pro for optimal power use.Consider adding baked lighting texturesor using time-based animationsto get a feel of dynamic lighting instead.Profile your material for system power and render performance.You can also create fully immersive experienceswith Metal.For those of you building 3D engines or experiencesusing Metal, let's talk about some things to optimize.You can use Metal with the CompositorServices frameworkto bypass the render server and send a rendered surfacedirectly to the compositor.Watch the session "Discover Metal for immersive apps"to learn how to do this properly.When using CompositorServices,pace your Metal frame submissions so the compositorreceives a new frame on each of its updates.Make sure to query a new foviation mapand post prediction each frame.And query this input data at the last momentbefore you start using it to encode GPU work.Doing all three of these things helps ensureresponsive virtual contentrelative to user motion and input.If the app takes too long to submit a new frame,the system terminates it.Avoid any long frame stalls.Make sure to profile GPU performanceusing the Metal System Trace Instruments templatewhile running your app.Long-running fragment and vertex shader executionsfrom your Metal app or from custom materialswith Reality Composer Procan impact system rendering times heavily.To reduce fragment and vertex times,start by reducing ALU instructionsand texture accesses by shaders.For Metal, use compute shaders instead wherever possible.Review these talks to learn moreabout optimizing your GPU performance.Remember, optimizing your app for UI and 3D renderingperformance benefits the overall user experience.Let's now move on to input performance.People can use their eyes, hands, voice,and hardware inputs on this platform.App updates to inputs are processed on the main thread.If these take too long,it makes your app feel slow and unresponsive.Input updates on the main thread need to completewithin certain deadlines based on the display refresh rate.Hardware for this platformusually has a refresh rate of 90 hertz or higher.For 90 hertz refresh rates, keep input updatesbelow eight milliseconds for optimal latency.When interacting with spatial content,the system does hit testing work to checkwhich UI or 3D objects the user is trying to interact with.For RealityKit content, you will add physics collidersto interact with them.When adding these colliders, use static collidersover dynamic colliders whenever possible,as static ones are cheaper.To reduce redundant hit testing work in your app,minimize overlapping any interactive content.Now, let's move on to ARKit.On this platform, ARKit algorithmsare always running to create visuals and interactionsacross every app.Your app can impact system power and visual smoothnessbased on how it uses ARKit data and anchors virtual content.For example, your app can use ARKit or RealityKitto place an anchor content in the user's surroundings,head, or hands.Every anchor adds additional work for the system.When anchoring content, consider whether the anchorsneed to be tracked continuously in a user's space.When using AnchorComponent in RealityKit,use the “once” tracking mode to avoid continuous tracking costs.Minimize the total amount of persistentand transient anchors from your app.For persistent anchors especially,every app can add them,so try not to add too many from your own app.There's even more optimizations you can dowhile using ARKit data.If you apply ARKit data that is too old to app content,app visuals can look out of sync with input.Query ARKit data right before it needs to be usedand apply it to updates promptly.Post predictions are expensive to compute.Generally, only custom Metal rendering enginesneed this data.If you just want to place app content in the scene,RealityKit is a great choice instead.Generating collision data for scene understanding meshesis also expensive.If you do use this data, turn it offwhen your app doesn't need it anymore.Now, let's talk about optimizing audio and video playbackfor spatial computing.Spatial audio is used by default on this platform.The system processes information in real timeabout the user's position, their surroundings,and audio sources to output audio.If your app causes too much spatial audio work,it can cause problems with system power useor lead to delays in audio output.If you see these issues,there are three main things to look atfor reducing spatial audio work:concurrently playing audio sources,the number of moving audio sources,and the size of the soundstage.All of these are variables that can increasethe computational work.Now, let's consider video.In a shared space, people can play multiple videos at once.For each video, the system needs to decode itand render it in the render server.Each new rendered video frameneeds to make it to the display at consistent intervalsfor a great video watching experience.To give the render server as much power and timeto meet its rendering deadlines,your app should minimize updates to UI or 3D contentduring video playback.The video frame rate also impacts the work done.Consider using 24 or 30 hertz videosfor optimal performance and power.Finally, reduce the number of concurrent videosthat need to be played and rendered on the devicefrom your app at any given time.When choosing between video presentation methods,consider how you would like to optimizefor different features and performance.Watch the session"Create a great spatial playback experience" to learn more.Now, let's talk about SharePlay.This platform opens up a whole new set of experiencesto collaborate and connect with people.To create a truly great SharePlay group experience,you'll want to ensure your app can sustain great performanceover long periods of time.And great spatial computing performance with SharePlaystarts with the basics.Profile and optimize your app for local performance first.Then examine your app's performance during SharePlayto avoid expensive render updatesbeing synced across devices.Profile your app for power to ensure system power needsdoesn't create thermal pressure,which can prevent your app from sustainingits great performance.To help with this, carefully considerwhat work and features in your appare essential for your app's SharePlay experience,and turn off anything it doesn't need.Lastly, let's look at app terminationsfrom thermal or memory pressure.People may use this device in a warm place.Like all Apple platforms, the system managescomputational resources available under thermal pressurein order to keep the device cool and comfortable when in use.Having lower computational resourcescan impact your app's performance.The system may even terminate your appdue to critical thermal pressure,or because render deadlines were no longer being met.When under thermal pressure, do less work in your appto maintain good performance and to keep thermal pressurefrom increasing further.Do this by subscribing to thethermalStateDidChange Notification.When the pressure gets higher,adapt your app's content and updates in response to it.To see how your app performs under a thermal pressure,use thermal inducers in Xcode to simulatehigher thermal states for your device.To learn even more about thermal pressure,check out the session"Designing for Adverse Network and Temperature Conditions."Next, let's talk about memory pressure.Devices have a limited amount of memorythat is shared between the system and all apps running.When the device gets close to this limit,the system begins to terminate apps,starting with apps that are not being actively used.A single app using too much memorycan also get terminated, even if it is being used.You don't want this to happen for your app.You can avoid this by reducing your app's memory usageas much as possible.On this platform, apps are more likelyto have large amounts of memory allocatedfor UI and 3D rendering, and audio and video playback.If your app has UI content, reduce renderingmemory allocations by minimizing offscreen render passes,the total amount of windows, and media content.For 3D memory with RealityKit, the resolutionof your textures and geometry sizers for meshes and particlescan contribute significantly to memory use.Reduce them wherever you can.When playing audio and video, evaluate the total memory loadfrom all audio and video files in your app.When changing resolutions, bitrates, file formats,and durations, consider the trade-offsfor the user experience and performanceagainst any memory savings.Review these talks to learn more tips for reducingyour memory footprint across all Apple platforms.Remember, performance is essentialfor a great user experience on this platform.To get started, profile your appsactively during developmentto find performance and power issues.Build a performance plan around important metricsfor spatial computing.And optimize your app for rendering, power,and all of the other areas we covered today.And finally, collect performance field datawith tools like MetricKit and Xcode Organizer.I can't wait to see all the great apps and experiencesyou come up with on this platform.Thanks for watching.♪

♪ Mellow instrumental hip-hop ♪♪Hi, my name's Roy,and I'm an engineer on the Performance team.Today, we'll learn how you can optimizeyour app for spatial computing.We'll first look at the unique aspectsof this new platform for performance and power.We'll then go over building a performance plan,starting with profiling your app.And finally, we'll take a tour of the best waysto optimize performance issues for this platform.So what makes spatial computing differentfor power and performance?For one, the content on the displayis always being updated, regardless of app updates.Whenever people move their body, hands, or eyes,content needs to be updated.This means the system is always renderingevery frame at all times.The platform is also always running spatial algorithmsto create visuals and interactions across every app,and can run multiple apps at the same time.People will use your app with other apps.To handle multitasking and the additional system work,optimize your own app's resource usage as much as you can.To deliver a great user experience,performance in your app is essential.People want apps to be immediately responsive to inputand to provide smooth visual updatesfor a sense of immersion and comfort.Let's talk about how to profile and analyze your appfor performance issues.You may already be familiar with performance metricsfrom other Apple platforms.On any platform, people want apps that launch quickly,avoid disk wear, and don't use too much battery.They also want apps that avoid terminationsfrom inefficient memory use.With spatial computing, some of these metricstake on new meaning.Take power.Users want apps optimized for power,not for battery life, but because of thermal pressure.To sustain great performance,apps need to be optimized for system power use,to reduce the likelihood of encountering thermal pressure.Hangs are another example.They occur when an app's main thread is stalledon doing work for a period of time.But on this platform, even small, momentary stallsare disruptive to responsiveness.Now consider rendering.On other platforms, you may be optimizingfor render performance primarily to providesmooth UI and 3D animations.But here, render performance is essentialfor static content as well, since the system is always rendering.All Apple platforms provide tools to profile these metrics.Today, we'll cover finding performance issuesspecifically for spatial computing apps.But to learn more about optimizing for these metricson any Apple platform, check out the "Ultimate ApplicationPerformance Survival Guide" session.To optimize your app, profile during developmentusing tools like Instruments and Xcode Gauges.Once your app is released, gather more data from the fieldto help you further optimize your app.Let's talk more about profiling during development.RealityKit Trace is a brand-new template in Instrumentsto help profile any spatial computing appfor performance and power.It is an incredible tool that can help identifywhen your app has poor rendering performanceor when it is causing high system power use.There are many more instrument templates you can use as well.To learn more and explore this new template in action,watch the session "Meet RealityKit Trace."Your app's performance and power depends onhow someone interacts with it.The simulator doesn't perform the same work as a real device,so its performance data might not be accurate.Profile in the device.Profile using various interactions in your appwhen playing audio or video,or when using technologies like FaceTime and Personas.Make sure to check for good performance and low system powerover minutes of use.Lastly, try profiling while other apps are also runningand using resources.If you are bringing over compatible iPad and iPhone apps,make sure to profile them on deviceto identify further optimizations needed.

After development, people may run your appin a wide variety of conditions.Data from the field is a great way to find issuesthat people are actually running into.When your app is in beta or publicly released,use MetricKit to get diagnostic reports from users.Xcode Organizer provides aggregated performance datafrom consenting users' devices,including energy diagnostics to help find any power issues.All of this data you collect helps you find bottlenecksand prioritize performance work for your app.Now, let's talk about optimizing your spatial computing app.Performance issues can arise from many areas.Today, we'll cover strategies for optimizingseveral core areas: rendering, user input, ARKit,audio and video playback, SharePlay,and app terminations from system pressure.Great rendering performance is one of the top prioritiesfor a great user experience.Let's dive in.In this platform, the rendering pipeline starts with your app,which is responsible for updating your app's content.Like all Apple platforms, your app's interface is updatedon the main thread and must provide updates promptly.Since your app is rendered in a 3D space alongside other apps,its updates get sent to the system render server.The render server is continuously runningto process updates from apps, users' inputs,and from their space and surroundings.It renders a new frame with all these updatesand sends it to the compositor.The compositor is always rendering.It supplies new frames to the displayat a rate matching the display's refresh rate.This helps provide a comfortable experience.This rate is usually 90 frames a second, but can be higher.While the compositor updates the display consistently,a great user experience still needs fast visual updatesfrom your app.If your app has content or updates that taketoo long to render, the render server can missits rendering deadline for optimal rendering latency.This means the app visuals could have made itto the compositor on frame Y,but made it on frame Y+1 instead.This delays the visual updates the people see on displayand makes your app feel less responsive.Especially severe rendering stalls can even causeyour app to be terminated.Whether your app is built on SwiftUI, UIKit,RealityKit, or Metal, you want to optimize its contentand updates to reduce frame dropsand work done in the render server.Let's start with optimizing SwiftUI and UIKit usage.On this platform, the system does render workfor static UI content, even with no app updates.This rendering work can increase from overdraw.Overdraw occurs when you have translucent contentin front of other virtual content.The GPU has to do work to render both content,but if that translucent content was fully opaque,the GPU wouldn't need to render any UI behind it.If you have any overlapping UI views with Z offsets,avoid adding translucency to them.Also, the more pixels on the displaythat your app's UI takes up,the more work is done to render the window.Consider reducing their default sizes.UI redraws in the render server are usually triggeredby app updates, but on this platform,they are also triggered by dynamic content scalingof core animation layers.With this behavior, the resolution of text,or vector-based UI content changes based onwhere the user is looking to allow for sharper visuals.This can also lead to more frequent redrawing of UI contentat potentially higher scales, even with no app updates.SwiftUI and UIKit enable this behavior by default,but apps doing custom Core Animationor Core Graphics rendering can opt in to this behavior.To learn more about its visual benefits and trade-offs,watch the session"Explore rendering for spatial computing."The cost of these redraws is heavily impactedby offscreen render passes.This can be caused by visual effectslike shadows, blur, and masking.Reduce these effects to make your appeasier for the system to render.To minimize re-draws in your app,avoid unnecessary view updates whenever possible.For example, with SwiftUI, use @Observable.@Observable provides more granular change trackingand reduces unneeded layout updates.Next, let's talk about optimizing 3D renderingwith RealityKit.SwiftUI has added RealityView this yearfor spatial computing.It can natively display RealityKit 3D sceneswithin a SwiftUI hierarchy.Your app should be a good citizen on the platformby optimizing your 3D scenesfor all of these RealityKit features.In these 3D scenes,the complexity of the assets they containcan greatly increase the amountof render server work done each frame.So let's start by optimizing these assets.Reality Composer Pro helps you createRealityKit scenes from assets.From mesh rendering, particles, animations,physics, and audio work, this tool provides statisticsabout the entire scene that can help youunderstand its performance impact.When examining these statistics, lower numbers usually meanless work, which can improve render performance.Watch the session"Create 3D models for Quick Look spatial experiences"to learn more around best practicesfor visuals and power use of 3D assets.Mesh rendering in particular is a core part of 3D rendering.Complex meshes and materials can quickly becomeperformance bottlenecks.Optimize the geometry of your mesh assets.Reduce the amount of separate mesh partsby combining parts that share a material.Mesh geometries with high triangle and vertex countscan also be costly.Use assets with smaller counts as needed.Minimize the impact of overdraw with your 3D meshes.To do this, use transparency sparinglyjust like with UI content.The “Physically Based” material in Reality Composer Prohas environment lighting, is well optimized,and works best for meshes with minimal transparency.But for translucent or very large content,consider using a Custom material with an unlit surface,Use baked lighting textures or other cheaper visuals.This helps avoid potential bottleneckswith more expensive lighting calculations.For further guidance on building and using materialsin RealityKit, watch these two sessions.Having optimized content for runtime renderingis a great start.But there's even more you can doto optimize your app with RealityKit.When your app updates its RealityKit content,updates get sent to the render server,which applies and renders them.But too many updates in a short period of timecan become a bottleneck for the render server.For example, your app may be rapidly creating and destroyingRealityKit entities.It may have too many complex animations,be updating too many SwiftUI views,or it may be loading many assets in a single frame.Create entities in advance, and hide or show them as needed.You could remove and add them to the scene hierarchy,or use the isEnabled flag.Minimize the amount of entities that are updatedby flattening your mesh entity hierarchies.For code-based animations, consider lower update ratesor reducing the number of entities the animations update.And when updating RealityKit entities,avoid triggering excessive SwiftUI redrawing accidentally.When using attachments, make sure to optimizetheir rendering in the same wayyou optimize for all SwiftUI content.Loading complex assets can also triggerexpensive render updates.Complex assets can also contributeto high app launch and content loading times.Use asynchronous loading APIs at runtimeto avoid blocking the main threadand load assets well before they are needed.Entities that use the same assetscan also share that asset and only load it once.Use exported files from Reality Composer Proas these files are optimized for loading timesand memory costs.You also get texture compression for free.Reducing asset sizes usually speeds up loading,but remember that texture compression already happenswith Reality Composer Pro files,so you may not need to do it yourself.Finally, let's talk about immersive experienceswith RealityKit.When your app requests to move to a dedicated full space,it becomes the only foreground experience running.When using a portal or moving to a fully immersive experience,the system also hidespart or all of the person's surroundings.Your app can create an environmentwith RealityKit content to fill their space.Your fully immersive content needs to be renderedto a lot more pixels on the displaythan scenes in a shared space or a full space.This means that more work can be done on the GPUto render that content.Optimize this type of content for GPU power use.Start with a “Custom” material with an unlit surfacein Reality Composer Pro for optimal power use.Consider adding baked lighting texturesor using time-based animationsto get a feel of dynamic lighting instead.Profile your material for system power and render performance.You can also create fully immersive experienceswith Metal.For those of you building 3D engines or experiencesusing Metal, let's talk about some things to optimize.You can use Metal with the CompositorServices frameworkto bypass the render server and send a rendered surfacedirectly to the compositor.Watch the session "Discover Metal for immersive apps"to learn how to do this properly.When using CompositorServices,pace your Metal frame submissions so the compositorreceives a new frame on each of its updates.Make sure to query a new foviation mapand post prediction each frame.And query this input data at the last momentbefore you start using it to encode GPU work.Doing all three of these things helps ensureresponsive virtual contentrelative to user motion and input.If the app takes too long to submit a new frame,the system terminates it.Avoid any long frame stalls.Make sure to profile GPU performanceusing the Metal System Trace Instruments templatewhile running your app.Long-running fragment and vertex shader executionsfrom your Metal app or from custom materialswith Reality Composer Procan impact system rendering times heavily.To reduce fragment and vertex times,start by reducing ALU instructionsand texture accesses by shaders.For Metal, use compute shaders instead wherever possible.Review these talks to learn moreabout optimizing your GPU performance.Remember, optimizing your app for UI and 3D renderingperformance benefits the overall user experience.Let's now move on to input performance.People can use their eyes, hands, voice,and hardware inputs on this platform.App updates to inputs are processed on the main thread.If these take too long,it makes your app feel slow and unresponsive.Input updates on the main thread need to completewithin certain deadlines based on the display refresh rate.Hardware for this platformusually has a refresh rate of 90 hertz or higher.For 90 hertz refresh rates, keep input updatesbelow eight milliseconds for optimal latency.When interacting with spatial content,the system does hit testing work to checkwhich UI or 3D objects the user is trying to interact with.For RealityKit content, you will add physics collidersto interact with them.When adding these colliders, use static collidersover dynamic colliders whenever possible,as static ones are cheaper.To reduce redundant hit testing work in your app,minimize overlapping any interactive content.Now, let's move on to ARKit.On this platform, ARKit algorithmsare always running to create visuals and interactionsacross every app.Your app can impact system power and visual smoothnessbased on how it uses ARKit data and anchors virtual content.For example, your app can use ARKit or RealityKitto place an anchor content in the user's surroundings,head, or hands.Every anchor adds additional work for the system.When anchoring content, consider whether the anchorsneed to be tracked continuously in a user's space.When using AnchorComponent in RealityKit,use the “once” tracking mode to avoid continuous tracking costs.Minimize the total amount of persistentand transient anchors from your app.For persistent anchors especially,every app can add them,so try not to add too many from your own app.There's even more optimizations you can dowhile using ARKit data.If you apply ARKit data that is too old to app content,app visuals can look out of sync with input.Query ARKit data right before it needs to be usedand apply it to updates promptly.Post predictions are expensive to compute.Generally, only custom Metal rendering enginesneed this data.If you just want to place app content in the scene,RealityKit is a great choice instead.Generating collision data for scene understanding meshesis also expensive.If you do use this data, turn it offwhen your app doesn't need it anymore.Now, let's talk about optimizing audio and video playbackfor spatial computing.Spatial audio is used by default on this platform.The system processes information in real timeabout the user's position, their surroundings,and audio sources to output audio.If your app causes too much spatial audio work,it can cause problems with system power useor lead to delays in audio output.If you see these issues,there are three main things to look atfor reducing spatial audio work:concurrently playing audio sources,the number of moving audio sources,and the size of the soundstage.All of these are variables that can increasethe computational work.Now, let's consider video.In a shared space, people can play multiple videos at once.For each video, the system needs to decode itand render it in the render server.Each new rendered video frameneeds to make it to the display at consistent intervalsfor a great video watching experience.To give the render server as much power and timeto meet its rendering deadlines,your app should minimize updates to UI or 3D contentduring video playback.The video frame rate also impacts the work done.Consider using 24 or 30 hertz videosfor optimal performance and power.Finally, reduce the number of concurrent videosthat need to be played and rendered on the devicefrom your app at any given time.When choosing between video presentation methods,consider how you would like to optimizefor different features and performance.Watch the session"Create a great spatial playback experience" to learn more.Now, let's talk about SharePlay.This platform opens up a whole new set of experiencesto collaborate and connect with people.To create a truly great SharePlay group experience,you'll want to ensure your app can sustain great performanceover long periods of time.And great spatial computing performance with SharePlaystarts with the basics.Profile and optimize your app for local performance first.Then examine your app's performance during SharePlayto avoid expensive render updatesbeing synced across devices.Profile your app for power to ensure system power needsdoesn't create thermal pressure,which can prevent your app from sustainingits great performance.To help with this, carefully considerwhat work and features in your appare essential for your app's SharePlay experience,and turn off anything it doesn't need.Lastly, let's look at app terminationsfrom thermal or memory pressure.People may use this device in a warm place.Like all Apple platforms, the system managescomputational resources available under thermal pressurein order to keep the device cool and comfortable when in use.Having lower computational resourcescan impact your app's performance.The system may even terminate your appdue to critical thermal pressure,or because render deadlines were no longer being met.When under thermal pressure, do less work in your appto maintain good performance and to keep thermal pressurefrom increasing further.Do this by subscribing to thethermalStateDidChange Notification.When the pressure gets higher,adapt your app's content and updates in response to it.To see how your app performs under a thermal pressure,use thermal inducers in Xcode to simulatehigher thermal states for your device.To learn even more about thermal pressure,check out the session"Designing for Adverse Network and Temperature Conditions."Next, let's talk about memory pressure.Devices have a limited amount of memorythat is shared between the system and all apps running.When the device gets close to this limit,the system begins to terminate apps,starting with apps that are not being actively used.A single app using too much memorycan also get terminated, even if it is being used.You don't want this to happen for your app.You can avoid this by reducing your app's memory usageas much as possible.On this platform, apps are more likelyto have large amounts of memory allocatedfor UI and 3D rendering, and audio and video playback.If your app has UI content, reduce renderingmemory allocations by minimizing offscreen render passes,the total amount of windows, and media content.For 3D memory with RealityKit, the resolutionof your textures and geometry sizers for meshes and particlescan contribute significantly to memory use.Reduce them wherever you can.When playing audio and video, evaluate the total memory loadfrom all audio and video files in your app.When changing resolutions, bitrates, file formats,and durations, consider the trade-offsfor the user experience and performanceagainst any memory savings.Review these talks to learn more tips for reducingyour memory footprint across all Apple platforms.Remember, performance is essentialfor a great user experience on this platform.To get started, profile your appsactively during developmentto find performance and power issues.Build a performance plan around important metricsfor spatial computing.And optimize your app for rendering, power,and all of the other areas we covered today.And finally, collect performance field datawith tools like MetricKit and Xcode Organizer.I can't wait to see all the great apps and experiencesyou come up with on this platform.Thanks for watching.♪

## Code Samples

