# Wwdc2023 10080

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Build spatial experiences with RealityKitDiscover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We'll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we'll explore combining RealityKit with spatial input, animation, and spatial audio.Chapters0:00 -Introduction2:50 -RealityKit and SwiftUI9:36 -Entities and components12:20 -RealityView15:37 -Input, animation and audio23:00 -Custom systems26:15 -Wrap-upResourcesHello WorldHD VideoSD VideoRelated VideosWWDC23Develop your first immersive appEnhance your spatial computing app with RealityKitEvolve your ARKit app for spatial experiencesExplore the USD ecosystemGet started with building apps for spatial computingGo beyond the window with SwiftUIMeet ARKit for spatial computingMeet Reality Composer ProMeet SwiftUI for spatial computingMeet UIKit for spatial computingTake SwiftUI to the next dimensionWork with Reality Composer Pro content in Xcode

Discover how RealityKit can bring your apps into a new dimension. Get started with RealityKit entities, components, and systems, and learn how you can add 3D models and effects to your app on visionOS. We'll also take you through the RealityView API and demonstrate how to add 3D objects to windows, volumes, and spaces to make your apps more immersive. And we'll explore combining RealityKit with spatial input, animation, and spatial audio.

0:00 -Introduction

2:50 -RealityKit and SwiftUI

9:36 -Entities and components

12:20 -RealityView

15:37 -Input, animation and audio

23:00 -Custom systems

26:15 -Wrap-up

Hello World

HD VideoSD Video

HD Video

SD Video

Develop your first immersive app

Enhance your spatial computing app with RealityKit

Evolve your ARKit app for spatial experiences

Explore the USD ecosystem

Get started with building apps for spatial computing

Go beyond the window with SwiftUI

Meet ARKit for spatial computing

Meet Reality Composer Pro

Meet SwiftUI for spatial computing

Meet UIKit for spatial computing

Take SwiftUI to the next dimension

Work with Reality Composer Pro content in Xcode

Search this video…♪ Mellow instrumental hip-hop ♪♪Hello. I'm John, and I'm an engineeron the RealityKit team.Today, I'm delighted to introduce youto the new RealityKit for creating spatial experiences.RealityKit is a framework for realistically rendering,animating, and simulating 3D models and effects.We introduced RealityKit in 2019and have added a lot of new features since then.If you've already used RealityKitfor building apps on other devices,you'll find that there's a lot in common.With RealityKit, you can augment your app's 2D windowswith 3D content, bring 3D content front and centerin a separate window, or bring yourself and your environmentinto an immersive experience.RealityKit is a core 3D framework on Apple platforms.And especially on xrOS, it offers a lot of features.In this presentation, I'll focus on some key features,like entities, components, and RealityView,which will introduce you to RealityKitand show you how to use it.I'll also mention sessions that cover other conceptsor go into more detail.Let's get started.I'll use the Hello World experience to explainthe concepts in this presentation.But before I get to those concepts,let me take you through the three different modulesthat are a part of this experience.The first module, Planet Earth,presents a 3D globe in its own windowthat you can interact with from any angle.The second module, Objects in Orbit,immerses you in a model of the Earth, the Moon,and a satellite, demonstrating animations,Spatial Audio, and custom behaviors,like the trace which follows the satellite.The third module, the Solar System,contains a fully immersive experience,which you can learn more about in other sessions.I'm going to show you how to build the 3D elementsof this Hello World experience using SwiftUI, RealityKit,and Reality Composer Pro.Let's dive in.I'll get started by talking about how you can use RealityKittogether with SwiftUI to bring your appinto the next dimension.Next, I'll examine the building blocks of RealityKit,entities like the Earth model and the componentswhich implement its behaviors.You'll learn about the features of RealityView,which is a new SwiftUI view for 3D models and effects.Then I'll explain how you can handle inputand bring your app to life with animation and Spatial Audio.Finally, I'll talk about unlocking the potentialof RealityKit with custom components and systems.Let's begin by exploring how RealityKitand SwiftUI work together.SwiftUI is how you define your views and windows,and RealityKit lets you add 3D elements.For example, the World app uses SwiftUI to displaya standard 2D window with a few buttons.Tapping the Planet Earth button on the leftnavigates to a detail view,which shows a 2D illustration of the Earth.But what if I want to replace that 2D image with a 3D globe?Adding 3D content to a 2D window is easyusing the model 3D view in RealityKit.Let's go over the code.Here's the SwiftUI view, which displays that globe image.I'll change it to display a 3D globe by importing RealityKitand changing the image to a model 3D view,referencing a USD file in my project called Globe.We can customize the loaded model before displaying itby adding two pieces of code:a content closure for the model that is returnedand a placeholder view builder to specify a viewthat's displayed while the model is loading.In the content closure,I'll add resizable and scaledToFit modifiersto make sure that the model fits into the available spacein my UI.And because Model 3D loads its model asynchronously,there is a placeholder view builder,which you can use to customize the viewthat's displayed during the loading process.In this case, I'm just using the built-in ProgressViewto display a spinner.Finally, I need to add the globe 3D model as a resourceto the app or Swift package.And now the model appears in line in the appwith the same appearance that it has in Quick Lookor Reality Composer Pro.Placing 3D content in a 2D window is great,but I want my 3D model to be front and center.To accomplish that,I'm going to put the globe in a separate window.I'll add a button to the app's detail viewto open that new window.And instead of using a regular window,which displays its contents against a 2D background,I'll use a new window stylewhich places its contents in a volume.This is called a volumetric window,and it's great for viewing 3D content.Unlike a 2D window,a volumetric window is meant to be used from any angle,so it's ideal for 3D models.A volumetric window also keeps a fixed sizethat is true to life.You can scale a model in a volumetric windowto be one meter across,and it will always be displayed at exactly that size.I think that's a great fit for the globe in Hello World.Let's go through the process of adding a volumetric window.First, I'll add a window group to my app.Window groups act as a template that an app can useto open new windows.I'll give the new window an identifier to distinguish itfrom this app's main window.Next, I'll add a windowStyle volumetric modifierto the window group.I'll also add a defaultSize modifierto give this window a size in meters.Finally, I'll add a button to the detail view.To make the button open the window I've just added,I'll add a property that gives me accessto the open window action from the SwiftUI environment.Then I'll call that action from my button.Let's run this app in the simulator.When I press the View Globe button,a volumetric window appears.Now I can interact with the globe from multiple angles,not just the front.But sometimes, the key to unlocking the experienceyou want to create is immersion.In the Objects in Orbit module of the World app,you're immersed in an animated model of the Earthand its satellites that demonstrates their orbits.This uses an immersive space, a new scene typewhich allows your app to place 3D elements anywhere in space.When you open an Immersive Space,your app can go beyond the bounds of a windowand provide a magical experience.Adding an Immersive Spaceis similar to adding a window group.It's a new scene in the body of my app.Here I'm using RealityView,which will give me more control over the scene than Model 3D.I'll go over RealityView in more detail in a few minutes.Like before, I'll add a button to the app's detail view.I'll get the openImmersiveSpace action from the environmentand call it with the identifier of the scene I've defined.Note that the openImmersiveSpace action is asynchronous.It completes once the space has finished opening.When I press the View Orbits button,an Immersive Space appears.This is already stunning,but you can make it more engagingby adding interactivity, animation,and audio with RealityKit.Whether you're working with 2D windows containing 3D content,or volumetric windows that emphasize your 3D models,I encourage you to check out these SwiftUI sessionsif you haven't already.The "Meet SwiftUI for spatial computing" sessionis an overview of what's new with SwiftUI on this platform.The "Take SwiftUI to the next dimension" sessiondemonstrates how to get the most out of 3D content in a window.There are also multiple styles of immersion.The solar system module of Hello Worlduses a fully immersive space that hides passthroughand displays its own backdrop.The "Go beyond the window with SwiftUI" sessiongoes into detail about all styles of Immersive Spaces.If you're thinking about creatingan immersive experience, I highly recommend this talk.You've encountered two ways to use RealityKitin your SwiftUI views,the easy-to-use Model 3D and RealityView.RealityView is what I'll use for the rest of this sessionbecause it allows you to compose your 3D contentusing RealityKit entities.So what is a RealityKit entity?An entity is a container object.If you create an empty entity from code,it won't do anything.To make an entity render or give a behavior,it must have components.Each component enables some specific behavior for an entity.Here are some examples.The Earth entity in this app is implemented with two components:a model component, which gives the entity a mesh and materials,and a transform component,which places the entity in 3D space.The same is true of the satellite entity.The model component renders a meshand applies materials to it.These Earth and satellite modelswere created in a digital content creation tool,exported to a USDZ file, and loaded into RealityKit.These meshes have a physically-based materialapplied to them to give them their final appearance.A material uses a set of textures and shadersto describe how the surface of a mesh responds to light.To learn more about materials,I recommend watching Niels' session,"Explore materials in Reality Composer Pro."In addition to a model,these entities have a transform component.The transform component places an entity in 3D space.You can control an entity's position, orientation,and scale by setting properties on its transform component,as well as by setting the entity's parent.RealityKit uses the same 3D coordinate conventions as ARKitand many other 3D engines.The origin is at the center of the RealityView.The y-axis points upward, the z-axis points towards you,and the x-axis points to your right.One unit is one meter.Note that these conventions are differentfrom SwiftUI's conventions.There are functions on RealityView's content instancethat make it easy to convert back and forthbetween the RealityKit and SwiftUI coordinate spaces.Every entity has a transform,but not every entity has a model.Sometimes an entity is assembled out of multiple child entities,each with their own set of components.This gives you more programmatic control.For example, you could play individual animationson the transforms of child entities.RealityKit contains a variety of componentsdepending on what you want to do.I'll talk about some specific components today,collision, input target, and hover effectjust to name a few.I'll also demonstrate how to create your own components.Now that we've got a sense of how entitiesand components work, let's use RealityViewto place those entities in your app.RealityView is a SwiftUI viewthat contains any number of entities.Entities need to be added to a RealityViewin order to be rendered, animated, and simulated.So, how does a RealityView work?RealityView provides a content instancewhich lets you add entities to the view.This is an easy way to get startedif you have already loaded an entityor if you want to create an entity programmatically.But this closure is asynchronous,so it's simple to load an entity from a fileand display it in your view.Here I asynchronously load an Earth model from a USD fileand add it to the content instanceonce the load has completed.You can also load more than one modeland place both of them in your RealityView.Instead of being laid out next to each other,these models will coincide in space.If that's not what you want,you can change the position of the entities added to the view.This example positions the moon entityhalf a meter to the right.Once you've set up your RealityView,you may want to connect state in your app to propertiesstored on RealityKit components.RealityView lets you express the connectionsbetween SwiftUI managed state and the entitiesin a RealityView with an update closure.This makes it easy to drive the behavior of 3D modelswith a source of truth from your app's data model.This view loads a model and applies a rotationcontrolled by whoever uses the view.Note that the code in the update section only runswhen the values that it depends on change.If you're building a UI with a combination of 2Dand 3D elements, you'll sometimes need to convertcoordinates between views and entities.RealityView provides coordinate conversion functionsbetween SwiftUI view coordinate spacesand RealityKit entity coordinate spaces.The RealityView's content instanceprovides a convert function that converts points,bounding boxes, and transforms from a SwiftUI coordinate spaceto an entity's local space or vice versa.Here, I get the minimum length of any of the view's dimensionsand scale the loaded entity to fit in the available space.RealityView also provides a mechanismfor subscribing to events published by entitiesand components.In this example, I play an animationauthored in the loaded USD file after the load completes.The content instance has a subscribe to: function,which adds an event handler.This example runs some code when an animation completes.There are RealityKit events publishedfor all kinds of things, from animation to physics to audio.You can also attach SwiftUI views to entities.The attachments feature of RealityView makes it easyto position views in 3D space.Check out Yujin’s session,"Enhance your spatial computing app with RealityKit,"to learn more.There's a lot you can do with RealityView.But let's get back to our celestial bodiesand bring them to life.First, I'll show you how to add a drag gestureso that you can reposition the Earth entity.And then I'll explain animations and Spatial Audio.Here's an example RealityView containing three entities.You can add a gesture to a RealityView,like any other SwiftUI view,and it will hit test against entities in that view.To receive input, the entity must have bothan input target component and a collision component.When a touch event is handled by RealityView,it will ignore any entities that don't have both collisionand an input target.Only this last entity has both components,so gestures added to this RealityViewwill only react to input directed at this entity.To make the Earth entity draggable,I'll give it an input target componentand a collision component, and add a drag gestureto the RealityView.To add the components, I'll use Reality Composer Pro.Reality Composer Pro is a new developer toolthat lets you compose, edit, and preview 3D content.I'll just use it to add a few components to an entity.To learn more about what you can do with Reality Composer Pro,check out Eric's session, "Meet Reality Composer Pro."The World app already has a World Assets package set upcontaining the USD files that this experience uses.I'll open that package in Reality Composer Pro.The Earth model is in a USDZ archive,which is self-contained and not meant to be modified.Instead of modifying that asset, I'll create a new USD scene fileand reference the Earth asset.USD files can reference other USDs and modify them in placewithout actually changing the referenced file.Nondestructive editing like this is really handywhen you need to make small changes to a USD filethat someone else is working on.I'll create a new scene named DraggableGlobeand drag in the globe file to create a reference to it.Now I can add components to it.I'll add an input target componentand also a collision component.The default shape for the collision componentis a cube.I'll change it to a sphere so it better matches the model.It's important for the collision shape to bea reasonable approximation of the visual model.The closer the match,the more intuitive interactions with the model will be.I want to be able to move the Earth model around,so I'll add a drag gesture to the RealityView.A standard SwiftUI drag gesture will work,but I can enable the gesture to manipulate specific entitiesrather than the entire viewby adding a targetedToEntity modifier on the gesture.When the gesture's value changes,I'll change the entity's position to match.There's one critical detail though.The gesture's value is in SwiftUI's coordinate space,so I have to convert it to RealityKit's coordinate spacein order to change the entity's position.All the pieces are now in place.So in the Objects in Orbit module,I can now pinch and drag to move the Earth around.Great, our app is now interactive.But I'd like my Earth entityto indicate that it's interactive.There's a RealityKit component we can use for this,the HoverEffectComponent.Hover effects provided by SwiftUI and RealityKitare the only way to make your app reactto where you're looking.This effect is applied outside of your app's processin a privacy-preserving manner.I'll add a hover effect component to the Earth entitywhen it's added to the RealityView.Now, the Earth model lights up when the pointer is over itto indicate that I am able to interact with it.Next, let's move on to animations.RealityKit has a number of built-in animation types,such as from-to-by animations,which animate a property from an initial value to a final value,orbit animations that cause an entity to revolvearound its parent, and time-sampled animationsthat progress frame by frame through a series of values.I'll set up an orbit animation on the Moon.The Moon will take 30 seconds to complete a full orbitand the orbital axis will be the y-axis.And I'll make sure that the orbit startsfrom the Moon's current position.Once I've defined the properties of this orbit animation,I'll generate an animation resource for itand play that animation on the Moon entity.And now the Moon orbits the Earth.To me, this is the magical moment.With an animation in place, the scene feels alive.But while animation helps bring your 3D content to life,Spatial Audio makes your model feel like it's really there.There are three types of audio in RealityKit:spatial, ambient, and channel.Let's look at each one of them in more detail.RealityKit sounds are spatial by default,so audio sources sound like they actually existin your surroundings.Spatial Audio Component lets you customize how your objectsemit sound into your space to make them even more realisticor more artistic.Use directivity to emit sounds in all directionsor project sound in a specific direction.Ambient Audio Component is great for multichannel files,which capture the sound of an environment.No additional reverb is added to ambient sources.Each channel of the ambience is played from a fixed direction.And finally, Channel Audio Componentsends the audio files channels directly to the speakerswithout any spatial effects.This is ideal for background musicwhich is not connected to any visual element.You can add audio to your scene in Reality Composer Proand interface with it using RealityKit.Or you can hook up audio in code.Let's take a look.I'll add a bit of looping audio to an orbiting satellite.First, I'll add a Spatial Audio Component to an empty entitythat will act as the audio source.A directivity of 0.75 creates a tight beam of soundin a particular direction.I'll rotate that audio source entity around its y-axisso that the audio is projected in the direction I want.I'll then load a looping audio clip from a resourceand play it on the audioSource entity by calling playAudio.Let's see this in action.Since the Spatial Audio source is configuredwith a tightly focused directivity,the audio can be heard clearly on my side of the Earth,but it is quieter when the satellite is on the other side.That was input, animation, and audio.You can build more functionality in RealityKit by combiningits existing functionality in different ways.There are two primary tools you can use for this purpose,defining your own components and defining your own systems.A component contains the data controlling one aspectof a 3D experience.Components are grouped into entities.Without components, an entity does nothing.Each component supplies a single elementof an entity's implementation.You've learned that a transform componentpositions an entity and that a model componentrenders a 3D model.In addition to the predefined componentsthat RealityKit provides,you can define your own components.Here's an example custom componentthat contains a traceMesh objectthat my coworker Paul has created.The trace component typeconforms to the component protocol,so you can get and set this componenton any entity at runtime.You can also adopt a data-driven workflowby defining a component in a Swift packageand conforming it to the Codable protocol.Codable components will appearin the Reality Composer Pro interfaceand can be directly added to entities at design time.You can learn more about custom components in the talk"Work with Reality Composer Pro content in Xcode."I already went through entities earlier in this talk,and I just covered components.Next, let's talk about systems.Systems contain code that act on entities and components.Taken together, entities, components, and systems, or ECS,are a tool for modeling the appearanceand behavior of your 3D experience.Systems are a way to structure the codethat implement your app's behaviors.Code in a system runs at a regular interval,acting upon your component's current state.For example, this TraceSystem updates a line meshthat's traced behind the satellite entityas it orbits the earth.Each update, it adds the entity's current positionto the trace.Once a system is registered,it automatically applies everywhere in your appthat you use RealityKit.Registering the trace system in my app's initializercauses it to update for all relevant entities.But what entities are relevant, and when does the system update?This system only wants to update entities with a trace component,so I create an entity query that filters to entitieswhich have a trace component.In the update function, the system passes inthe entity query and also specifiesthat it wants to update entities when rendering.The rendering condition means that this system will updateat an appropriate rate for smooth animations.Here's the trace system in action,adding the entity's position to the line meshin order to produce a fluid custom animation.Systems are a really effective way to implementa variety of effects and behaviors.RealityKit has a lot of features that make it easyto build 3D apps.You can use RealityKit and RealityView to add 3D elementsto views, windows, and immersive spaces defined with SwiftUI.You can load USD files, handle gestures, and play animationand Spatial Audio, all using RealityKit.RealityKit provides many predefined components,but you can also define custom components and systemsfor your app's specific needs.With that, I've covered the concepts you needto get started with RealityKit.Yujin’s session,"Enhance Your spatial computing app with RealityKit"will take you through more features of RealityKit,like portals, particle emitters, attachments, and more.And Amanda's session"Work with Reality Composer Pro content in Xcode"takes you through the process of building an immersive appusing Reality Composer Pro, RealityKit,Xcode previews, and the simulator.There are a lot of exciting features in RealityKitthat you can use in your app.I'm really excited to see the wonderful experiencesyou'll create.Thanks for watching.♪

♪ Mellow instrumental hip-hop ♪♪Hello. I'm John, and I'm an engineeron the RealityKit team.Today, I'm delighted to introduce youto the new RealityKit for creating spatial experiences.RealityKit is a framework for realistically rendering,animating, and simulating 3D models and effects.We introduced RealityKit in 2019and have added a lot of new features since then.If you've already used RealityKitfor building apps on other devices,you'll find that there's a lot in common.With RealityKit, you can augment your app's 2D windowswith 3D content, bring 3D content front and centerin a separate window, or bring yourself and your environmentinto an immersive experience.RealityKit is a core 3D framework on Apple platforms.And especially on xrOS, it offers a lot of features.In this presentation, I'll focus on some key features,like entities, components, and RealityView,which will introduce you to RealityKitand show you how to use it.I'll also mention sessions that cover other conceptsor go into more detail.Let's get started.I'll use the Hello World experience to explainthe concepts in this presentation.But before I get to those concepts,let me take you through the three different modulesthat are a part of this experience.The first module, Planet Earth,presents a 3D globe in its own windowthat you can interact with from any angle.The second module, Objects in Orbit,immerses you in a model of the Earth, the Moon,and a satellite, demonstrating animations,Spatial Audio, and custom behaviors,like the trace which follows the satellite.The third module, the Solar System,contains a fully immersive experience,which you can learn more about in other sessions.I'm going to show you how to build the 3D elementsof this Hello World experience using SwiftUI, RealityKit,and Reality Composer Pro.Let's dive in.I'll get started by talking about how you can use RealityKittogether with SwiftUI to bring your appinto the next dimension.Next, I'll examine the building blocks of RealityKit,entities like the Earth model and the componentswhich implement its behaviors.You'll learn about the features of RealityView,which is a new SwiftUI view for 3D models and effects.Then I'll explain how you can handle inputand bring your app to life with animation and Spatial Audio.Finally, I'll talk about unlocking the potentialof RealityKit with custom components and systems.Let's begin by exploring how RealityKitand SwiftUI work together.SwiftUI is how you define your views and windows,and RealityKit lets you add 3D elements.For example, the World app uses SwiftUI to displaya standard 2D window with a few buttons.Tapping the Planet Earth button on the leftnavigates to a detail view,which shows a 2D illustration of the Earth.But what if I want to replace that 2D image with a 3D globe?Adding 3D content to a 2D window is easyusing the model 3D view in RealityKit.Let's go over the code.Here's the SwiftUI view, which displays that globe image.I'll change it to display a 3D globe by importing RealityKitand changing the image to a model 3D view,referencing a USD file in my project called Globe.We can customize the loaded model before displaying itby adding two pieces of code:a content closure for the model that is returnedand a placeholder view builder to specify a viewthat's displayed while the model is loading.In the content closure,I'll add resizable and scaledToFit modifiersto make sure that the model fits into the available spacein my UI.And because Model 3D loads its model asynchronously,there is a placeholder view builder,which you can use to customize the viewthat's displayed during the loading process.In this case, I'm just using the built-in ProgressViewto display a spinner.Finally, I need to add the globe 3D model as a resourceto the app or Swift package.

And now the model appears in line in the appwith the same appearance that it has in Quick Lookor Reality Composer Pro.Placing 3D content in a 2D window is great,but I want my 3D model to be front and center.To accomplish that,I'm going to put the globe in a separate window.I'll add a button to the app's detail viewto open that new window.And instead of using a regular window,which displays its contents against a 2D background,I'll use a new window stylewhich places its contents in a volume.This is called a volumetric window,and it's great for viewing 3D content.Unlike a 2D window,a volumetric window is meant to be used from any angle,so it's ideal for 3D models.A volumetric window also keeps a fixed sizethat is true to life.You can scale a model in a volumetric windowto be one meter across,and it will always be displayed at exactly that size.I think that's a great fit for the globe in Hello World.Let's go through the process of adding a volumetric window.First, I'll add a window group to my app.Window groups act as a template that an app can useto open new windows.I'll give the new window an identifier to distinguish itfrom this app's main window.Next, I'll add a windowStyle volumetric modifierto the window group.I'll also add a defaultSize modifierto give this window a size in meters.Finally, I'll add a button to the detail view.To make the button open the window I've just added,I'll add a property that gives me accessto the open window action from the SwiftUI environment.

Then I'll call that action from my button.

Let's run this app in the simulator.When I press the View Globe button,a volumetric window appears.Now I can interact with the globe from multiple angles,not just the front.

But sometimes, the key to unlocking the experienceyou want to create is immersion.In the Objects in Orbit module of the World app,you're immersed in an animated model of the Earthand its satellites that demonstrates their orbits.This uses an immersive space, a new scene typewhich allows your app to place 3D elements anywhere in space.When you open an Immersive Space,your app can go beyond the bounds of a windowand provide a magical experience.Adding an Immersive Spaceis similar to adding a window group.It's a new scene in the body of my app.Here I'm using RealityView,which will give me more control over the scene than Model 3D.I'll go over RealityView in more detail in a few minutes.Like before, I'll add a button to the app's detail view.I'll get the openImmersiveSpace action from the environmentand call it with the identifier of the scene I've defined.

Note that the openImmersiveSpace action is asynchronous.It completes once the space has finished opening.When I press the View Orbits button,an Immersive Space appears.This is already stunning,but you can make it more engagingby adding interactivity, animation,and audio with RealityKit.Whether you're working with 2D windows containing 3D content,or volumetric windows that emphasize your 3D models,I encourage you to check out these SwiftUI sessionsif you haven't already.The "Meet SwiftUI for spatial computing" sessionis an overview of what's new with SwiftUI on this platform.The "Take SwiftUI to the next dimension" sessiondemonstrates how to get the most out of 3D content in a window.There are also multiple styles of immersion.The solar system module of Hello Worlduses a fully immersive space that hides passthroughand displays its own backdrop.The "Go beyond the window with SwiftUI" sessiongoes into detail about all styles of Immersive Spaces.If you're thinking about creatingan immersive experience, I highly recommend this talk.You've encountered two ways to use RealityKitin your SwiftUI views,the easy-to-use Model 3D and RealityView.RealityView is what I'll use for the rest of this sessionbecause it allows you to compose your 3D contentusing RealityKit entities.So what is a RealityKit entity?An entity is a container object.If you create an empty entity from code,it won't do anything.To make an entity render or give a behavior,it must have components.Each component enables some specific behavior for an entity.Here are some examples.The Earth entity in this app is implemented with two components:a model component, which gives the entity a mesh and materials,and a transform component,which places the entity in 3D space.The same is true of the satellite entity.The model component renders a meshand applies materials to it.These Earth and satellite modelswere created in a digital content creation tool,exported to a USDZ file, and loaded into RealityKit.These meshes have a physically-based materialapplied to them to give them their final appearance.A material uses a set of textures and shadersto describe how the surface of a mesh responds to light.To learn more about materials,I recommend watching Niels' session,"Explore materials in Reality Composer Pro."In addition to a model,these entities have a transform component.The transform component places an entity in 3D space.You can control an entity's position, orientation,and scale by setting properties on its transform component,as well as by setting the entity's parent.RealityKit uses the same 3D coordinate conventions as ARKitand many other 3D engines.The origin is at the center of the RealityView.The y-axis points upward, the z-axis points towards you,and the x-axis points to your right.One unit is one meter.Note that these conventions are differentfrom SwiftUI's conventions.There are functions on RealityView's content instancethat make it easy to convert back and forthbetween the RealityKit and SwiftUI coordinate spaces.Every entity has a transform,but not every entity has a model.Sometimes an entity is assembled out of multiple child entities,each with their own set of components.This gives you more programmatic control.For example, you could play individual animationson the transforms of child entities.RealityKit contains a variety of componentsdepending on what you want to do.I'll talk about some specific components today,collision, input target, and hover effectjust to name a few.I'll also demonstrate how to create your own components.Now that we've got a sense of how entitiesand components work, let's use RealityViewto place those entities in your app.RealityView is a SwiftUI viewthat contains any number of entities.Entities need to be added to a RealityViewin order to be rendered, animated, and simulated.So, how does a RealityView work?RealityView provides a content instancewhich lets you add entities to the view.This is an easy way to get startedif you have already loaded an entityor if you want to create an entity programmatically.But this closure is asynchronous,so it's simple to load an entity from a fileand display it in your view.Here I asynchronously load an Earth model from a USD fileand add it to the content instanceonce the load has completed.You can also load more than one modeland place both of them in your RealityView.Instead of being laid out next to each other,these models will coincide in space.If that's not what you want,you can change the position of the entities added to the view.This example positions the moon entityhalf a meter to the right.Once you've set up your RealityView,you may want to connect state in your app to propertiesstored on RealityKit components.RealityView lets you express the connectionsbetween SwiftUI managed state and the entitiesin a RealityView with an update closure.This makes it easy to drive the behavior of 3D modelswith a source of truth from your app's data model.This view loads a model and applies a rotationcontrolled by whoever uses the view.Note that the code in the update section only runswhen the values that it depends on change.If you're building a UI with a combination of 2Dand 3D elements, you'll sometimes need to convertcoordinates between views and entities.RealityView provides coordinate conversion functionsbetween SwiftUI view coordinate spacesand RealityKit entity coordinate spaces.The RealityView's content instanceprovides a convert function that converts points,bounding boxes, and transforms from a SwiftUI coordinate spaceto an entity's local space or vice versa.Here, I get the minimum length of any of the view's dimensionsand scale the loaded entity to fit in the available space.RealityView also provides a mechanismfor subscribing to events published by entitiesand components.In this example, I play an animationauthored in the loaded USD file after the load completes.The content instance has a subscribe to: function,which adds an event handler.This example runs some code when an animation completes.There are RealityKit events publishedfor all kinds of things, from animation to physics to audio.You can also attach SwiftUI views to entities.The attachments feature of RealityView makes it easyto position views in 3D space.Check out Yujin’s session,"Enhance your spatial computing app with RealityKit,"to learn more.There's a lot you can do with RealityView.But let's get back to our celestial bodiesand bring them to life.First, I'll show you how to add a drag gestureso that you can reposition the Earth entity.And then I'll explain animations and Spatial Audio.Here's an example RealityView containing three entities.You can add a gesture to a RealityView,like any other SwiftUI view,and it will hit test against entities in that view.To receive input, the entity must have bothan input target component and a collision component.When a touch event is handled by RealityView,it will ignore any entities that don't have both collisionand an input target.Only this last entity has both components,so gestures added to this RealityViewwill only react to input directed at this entity.To make the Earth entity draggable,I'll give it an input target componentand a collision component, and add a drag gestureto the RealityView.To add the components, I'll use Reality Composer Pro.Reality Composer Pro is a new developer toolthat lets you compose, edit, and preview 3D content.I'll just use it to add a few components to an entity.To learn more about what you can do with Reality Composer Pro,check out Eric's session, "Meet Reality Composer Pro."The World app already has a World Assets package set upcontaining the USD files that this experience uses.I'll open that package in Reality Composer Pro.

The Earth model is in a USDZ archive,which is self-contained and not meant to be modified.Instead of modifying that asset, I'll create a new USD scene fileand reference the Earth asset.USD files can reference other USDs and modify them in placewithout actually changing the referenced file.Nondestructive editing like this is really handywhen you need to make small changes to a USD filethat someone else is working on.I'll create a new scene named DraggableGlobeand drag in the globe file to create a reference to it.

Now I can add components to it.I'll add an input target componentand also a collision component.The default shape for the collision componentis a cube.I'll change it to a sphere so it better matches the model.It's important for the collision shape to bea reasonable approximation of the visual model.The closer the match,the more intuitive interactions with the model will be.I want to be able to move the Earth model around,so I'll add a drag gesture to the RealityView.A standard SwiftUI drag gesture will work,but I can enable the gesture to manipulate specific entitiesrather than the entire viewby adding a targetedToEntity modifier on the gesture.When the gesture's value changes,I'll change the entity's position to match.There's one critical detail though.The gesture's value is in SwiftUI's coordinate space,so I have to convert it to RealityKit's coordinate spacein order to change the entity's position.All the pieces are now in place.So in the Objects in Orbit module,I can now pinch and drag to move the Earth around.Great, our app is now interactive.But I'd like my Earth entityto indicate that it's interactive.There's a RealityKit component we can use for this,the HoverEffectComponent.Hover effects provided by SwiftUI and RealityKitare the only way to make your app reactto where you're looking.This effect is applied outside of your app's processin a privacy-preserving manner.I'll add a hover effect component to the Earth entitywhen it's added to the RealityView.Now, the Earth model lights up when the pointer is over itto indicate that I am able to interact with it.Next, let's move on to animations.RealityKit has a number of built-in animation types,such as from-to-by animations,which animate a property from an initial value to a final value,orbit animations that cause an entity to revolvearound its parent, and time-sampled animationsthat progress frame by frame through a series of values.I'll set up an orbit animation on the Moon.The Moon will take 30 seconds to complete a full orbitand the orbital axis will be the y-axis.And I'll make sure that the orbit startsfrom the Moon's current position.Once I've defined the properties of this orbit animation,I'll generate an animation resource for itand play that animation on the Moon entity.And now the Moon orbits the Earth.To me, this is the magical moment.With an animation in place, the scene feels alive.But while animation helps bring your 3D content to life,Spatial Audio makes your model feel like it's really there.There are three types of audio in RealityKit:spatial, ambient, and channel.Let's look at each one of them in more detail.RealityKit sounds are spatial by default,so audio sources sound like they actually existin your surroundings.Spatial Audio Component lets you customize how your objectsemit sound into your space to make them even more realisticor more artistic.Use directivity to emit sounds in all directionsor project sound in a specific direction.Ambient Audio Component is great for multichannel files,which capture the sound of an environment.No additional reverb is added to ambient sources.Each channel of the ambience is played from a fixed direction.And finally, Channel Audio Componentsends the audio files channels directly to the speakerswithout any spatial effects.This is ideal for background musicwhich is not connected to any visual element.You can add audio to your scene in Reality Composer Proand interface with it using RealityKit.Or you can hook up audio in code.Let's take a look.I'll add a bit of looping audio to an orbiting satellite.First, I'll add a Spatial Audio Component to an empty entitythat will act as the audio source.A directivity of 0.75 creates a tight beam of soundin a particular direction.I'll rotate that audio source entity around its y-axisso that the audio is projected in the direction I want.I'll then load a looping audio clip from a resourceand play it on the audioSource entity by calling playAudio.Let's see this in action.Since the Spatial Audio source is configuredwith a tightly focused directivity,the audio can be heard clearly on my side of the Earth,but it is quieter when the satellite is on the other side.That was input, animation, and audio.You can build more functionality in RealityKit by combiningits existing functionality in different ways.There are two primary tools you can use for this purpose,defining your own components and defining your own systems.A component contains the data controlling one aspectof a 3D experience.Components are grouped into entities.Without components, an entity does nothing.Each component supplies a single elementof an entity's implementation.You've learned that a transform componentpositions an entity and that a model componentrenders a 3D model.In addition to the predefined componentsthat RealityKit provides,you can define your own components.Here's an example custom componentthat contains a traceMesh objectthat my coworker Paul has created.The trace component typeconforms to the component protocol,so you can get and set this componenton any entity at runtime.You can also adopt a data-driven workflowby defining a component in a Swift packageand conforming it to the Codable protocol.Codable components will appearin the Reality Composer Pro interfaceand can be directly added to entities at design time.You can learn more about custom components in the talk"Work with Reality Composer Pro content in Xcode."I already went through entities earlier in this talk,and I just covered components.Next, let's talk about systems.Systems contain code that act on entities and components.Taken together, entities, components, and systems, or ECS,are a tool for modeling the appearanceand behavior of your 3D experience.Systems are a way to structure the codethat implement your app's behaviors.Code in a system runs at a regular interval,acting upon your component's current state.For example, this TraceSystem updates a line meshthat's traced behind the satellite entityas it orbits the earth.Each update, it adds the entity's current positionto the trace.Once a system is registered,it automatically applies everywhere in your appthat you use RealityKit.Registering the trace system in my app's initializercauses it to update for all relevant entities.But what entities are relevant, and when does the system update?This system only wants to update entities with a trace component,so I create an entity query that filters to entitieswhich have a trace component.In the update function, the system passes inthe entity query and also specifiesthat it wants to update entities when rendering.The rendering condition means that this system will updateat an appropriate rate for smooth animations.Here's the trace system in action,adding the entity's position to the line meshin order to produce a fluid custom animation.Systems are a really effective way to implementa variety of effects and behaviors.RealityKit has a lot of features that make it easyto build 3D apps.You can use RealityKit and RealityView to add 3D elementsto views, windows, and immersive spaces defined with SwiftUI.You can load USD files, handle gestures, and play animationand Spatial Audio, all using RealityKit.RealityKit provides many predefined components,but you can also define custom components and systemsfor your app's specific needs.With that, I've covered the concepts you needto get started with RealityKit.Yujin’s session,"Enhance Your spatial computing app with RealityKit"will take you through more features of RealityKit,like portals, particle emitters, attachments, and more.And Amanda's session"Work with Reality Composer Pro content in Xcode"takes you through the process of building an immersive appusing Reality Composer Pro, RealityKit,Xcode previews, and the simulator.There are a lot of exciting features in RealityKitthat you can use in your app.I'm really excited to see the wonderful experiencesyou'll create.Thanks for watching.♪

3:40 -Model3D

5:52 -Volumetric window

7:31 -ImmersiveSpace

12:40 -RealityView

12:54 -RealityView asynchronous loading and entity positioning

13:54 -Earth rotation

14:27 -Converting co-ordinate spaces

14:56 -Play an animation

18:31 -Adding a drag gesture

20:20 -Playing a transform animation

22:12 -Adding audio

23:47 -Defining a custom component

24:51 -Defining a system

## Code Samples

```swift
import
 SwiftUI

import
 RealityKit


struct
 
GlobeModule
: 
View
 {
    
var
 body: 
some
 
View
 {
        
Model3D
(named: 
"Globe"
) { model 
in

            model
                .resizable()
                .scaledToFit()
        } placeholder: {
          	
ProgressView
()
        }
    }
}
```

```swift
import
 SwiftUI

import
 RealityKit


// Define a volumetric window.


struct
 
WorldApp
: 
App
 {
    
var
 body: 
some
 
SwiftUI
.
Scene
 {
        
// ...


        
WindowGroup
(id: 
"planet-earth"
) {
            
Model3D
(named: 
"Globe"
)
        }
        .windowStyle(.volumetric)
        .defaultSize(width: 
0.8
, height: 
0.8
, depth: 
0.8
, in: .meters)
    }
}
```

```swift
import
 SwiftUI

import
 RealityKit


// Define a immersive space.


struct
 
WorldApp
: 
App
 {
    
var
 body: 
some
 
SwiftUI
.
Scene
 {
        
// ...


        
ImmersiveSpace
(id: 
"objects-in-orbit"
) {
            
RealityView
 { content 
in

                
// ...

            }
        }
    }
}
```

```swift
import
 SwiftUI

import
 RealityKit


struct
 
Orbit
: 
View
 {
    
let
 earth: 
Entity


    
var
 body: 
some
 
View
 {
        
RealityView
 { content 
in

            content.add(earth)
        }
    }
}
```

```swift
import
 SwiftUI

import
 RealityKit


struct
 
Orbit
: 
View
 {
    
var
 body: 
some
 
View
 {
        
RealityView
 { content 
in

            
async
 
let
 earth 
=
 
ModelEntity
(named: 
"Earth"
)
            
async
 
let
 moon 
=
 
ModelEntity
(named: 
"Moon"
)

            
if
 
let
 earth 
=
 
try?
 
await
 earth, 
let
 moon 
=
 
try?
 
await
 moon {
                content.add(earth)
                content.add(moon)
                moon.position 
=
 [
0.5
, 
0
, 
0
]
            }
        }
    }
}
```

```swift
import
 SwiftUI

import
 RealityKit


struct
 
RotatedModel
: 
View
 {
    
var
 entity: 
Entity

    
var
 rotation: 
Rotation3D


    
var
 body: 
some
 
View
 {
        
RealityView
 { content 
in

            content.add(entity)
        } update: { content 
in

            entity.orientation 
=
 .
init
(rotation)
        }
   }
}
```

```swift
import
 SwiftUI

import
 RealityKit


struct
 
ResizableModel
: 
View
 {
    
var
 body: 
some
 
View
 {
        
GeometryReader3D
 { geometry 
in

            
RealityView
 { content 
in

                
if
 
let
 earth 
=
 
try?
 
await
 
ModelEntity
(named: 
"Earth"
) {
                    
let
 bounds 
=
 content.convert(geometry.frame(in: .local),
                                                 from: .local, to: content)
                    
let
 minExtent 
=
 bounds.extents.min()
                    earth.scale 
=
 [minExtent, minExtent, minExtent]
                }
            }
        }
    }
}
```

```swift
import
 SwiftUI

import
 RealityKit


struct
 
AnimatedModel
: 
View
 {
    
@State
 
var
 subscription: 
EventSubscription
? 

    
var
 body: 
some
 
View
 {
        
RealityView
 { content 
in

            
if
 
let
 moon 
=
 
try?
 
await
 
Entity
(named: 
"Moon"
),
               
let
 animation 
=
 moon.availableAnimations.first {
                moon.playAnimation(animation)
                content.add(moon)
            }
            subscription 
=
 content.subscribe(to: 
AnimationEvents
.
PlaybackCompleted
.
self
) {
                
// ...

            }
       }
   }
}
```

```swift
import
 SwiftUI

import
 RealityKit


struct
 
DraggableModel
: 
View
 {
    
var
 earth: 
Entity


    
var
 body: 
some
 
View
 {
        
RealityView
 { content 
in

            content.add(earth)
        }
        .gesture(
DragGesture
()
            .targetedToEntity(earth)
            .onChanged { value 
in

                earth.position 
=
 value.convert(value.location3D,
                                               from: .local, to: earth.parent
!
)
            })
    }
}
```

```swift
// Playing a transform animation


let
 orbit 
=
 
OrbitAnimation
(name: 
"Orbit"
,
                           duration: 
30
,
                           axis: [
0
, 
1
, 
0
],
                           startTransform: moon.transform,
                           bindTarget: .transform,
                           repeatMode: .repeat)


if
 
let
 animation 
=
 
try?
 
AnimationResource
.generate(with: orbit) {
    moon.playAnimation(animation)
}
```

```swift
// Create an empty entity to act as an audio source.


let
 audioSource 
=
 
Entity
()


// Configure the audio source to project sound out in a tight beam.

audioSource.spatialAudio 
=
 
SpatialAudioComponent
(directivity: .beam(focus: 
0.75
))


// Change the orientation of the audio source (rotate 180º around the Y axis).

audioSource.orientation 
=
 .
init
(angle: .pi, axis: [
0
, 
1
, 
0
])


// Add the audio source to a parent entity, and play a looping sound on it.


if
 
let
 audio 
=
 
try?
 
await
 
AudioFileResource
(named: 
"SatelliteLoop"
,
                                            configuration: .
init
(shouldLoop: 
true
)) {
    satellite.addChild(audioSource)
    audioSource.playAudio(audio)
}
```

```swift
import
 RealityKit


// Components are data attached to an Entity.


struct
 
TraceComponent
: 
Component
 {
    
var
 mesh 
=
 
TraceMesh
()
}


// Entities contain components, identified by the component’s type.


func
 
updateTrace
(
for
 
entity
: 
Entity
) {
    
var
 component 
=
 entity.components[
TraceComponent
.
self
] 
??
 
TraceComponent
()
    component.update()
    entity.components[
TraceComponent
.
self
] 
=
 component
}


// Codable components can be added to entities in Reality Composer Pro.


struct
 
PointOfInterestComponent
: 
Component
, 
Codable
 {
    
var
 name 
=
 
""

}
```

```swift
import
 SwiftUI

import
 RealityKit


// Systems supply logic and behavior.


struct
 
TraceSystem
: 
System
 {
    
static
 
let
 query 
=
 
EntityQuery
(where: .has(
TraceComponent
.
self
))
    
    
init
(
scene
: 
Scene
) {
        
// ...

    }

    
func
 
update
(
context
: 
SceneUpdateContext
) {
         
// Systems often act on all entities matching certain conditions.

        
for
 entity 
in
 context.entities(
Self
.query, updatingSystemWhen: .rendering) {
            addCurrentPositionToTrace(entity)
        }
    }
}


// Systems run on all RealityKit content in your app once registered.


struct
 
MyApp
: 
App
 {
    
init
() {
        
TraceSystem
.registerSystem()
    }
}
```

