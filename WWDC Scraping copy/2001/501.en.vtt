WEBVTT

00:00:03.120 --> 00:00:06.420
Good morning.

00:00:06.480 --> 00:00:08.920
I was thinking about just sitting
in the audience and starting

00:00:08.920 --> 00:00:14.290
this talk because to some extent
the Java Virtual Machine is

00:00:14.820 --> 00:00:16.440
an invisible thing,
right?

00:00:16.440 --> 00:00:18.740
It like sits there and does your stuff.

00:00:18.830 --> 00:00:21.330
When you're programming in
Swing or when you're running

00:00:21.330 --> 00:00:24.350
your application and things,
the Virtual Machine is like just,

00:00:24.350 --> 00:00:25.340
it's just there.

00:00:25.340 --> 00:00:26.750
It's just the utility.

00:00:26.750 --> 00:00:30.200
It's just the thing that makes
your Java happen and hopefully

00:00:30.200 --> 00:00:34.240
if my group does this job right,
that's, you know, you won't hardly even

00:00:34.240 --> 00:00:36.090
have to know about it,
right?

00:00:36.170 --> 00:00:37.480
Well, that's our goal.

00:00:37.760 --> 00:00:40.680
We want you to just
enjoy the benefits of it,

00:00:40.680 --> 00:00:44.600
but in fact,
it's an incredible piece of technology.

00:00:44.600 --> 00:00:51.160
I don't know whether you have heard
of the game or have played the game,

00:00:51.160 --> 00:00:55.040
the Incredible Machine or have
kids who have played that game,

00:00:55.040 --> 00:00:59.190
but the Incredible Machine is this
great little app on the Mac that

00:00:59.190 --> 00:01:02.960
lets you build and put together
really fun virtual machines.

00:01:02.960 --> 00:01:06.440
It's just one little stuff and I kind
of think of the Virtual Machine,

00:01:06.440 --> 00:01:09.860
the Java Virtual Machine,
as an incredible machine.

00:01:10.190 --> 00:01:15.330
So anyway, in this talk we're going to
talk about what we're going to,

00:01:15.330 --> 00:01:19.870
I'm going to get up on stage as if
I were still sitting in the audience

00:01:19.870 --> 00:01:22.860
saying all this and tell you about it.

00:01:23.140 --> 00:01:27.570
So first of all, if you just came from
Steve Neroff's talk,

00:01:27.580 --> 00:01:31.710
you heard Larry Abrahams get up there
and talk about how hotspot is this

00:01:31.860 --> 00:01:34.460
next generation virtual machine.

00:01:34.460 --> 00:01:35.560
So it's true.

00:01:35.560 --> 00:01:38.540
It is a fabulous piece of technology.

00:01:38.540 --> 00:01:42.600
So we're going to talk about what
hotspot's about and why it's so good and

00:01:42.600 --> 00:01:46.180
why some of the things we like about it.

00:01:46.180 --> 00:01:50.420
Beyond that, we're going to talk about
what Apple does beyond that.

00:01:50.420 --> 00:01:54.670
What Apple does to add value
to the virtual machine as

00:01:54.670 --> 00:01:56.790
we get it from the sun.

00:01:57.200 --> 00:02:01.990
We will talk a little bit about what
is in the Java developer preview

00:02:02.060 --> 00:02:05.600
that we are going to be releasing,
I guess, later this week or any day

00:02:05.600 --> 00:02:09.360
now or by the end of the week,
whenever we get it out on the website.

00:02:09.360 --> 00:02:15.400
And finally,
we'll have some time for some Q&A.

00:02:15.780 --> 00:02:17.590
Java Virtual Machine Basics.

00:02:17.820 --> 00:02:19.980
What does a Java Virtual Machine do?

00:02:19.980 --> 00:02:22.850
So if I say JVM,
by now I hope you know that I'm,

00:02:22.850 --> 00:02:25.870
it's the acronym for the
Java Virtual Machine.

00:02:25.930 --> 00:02:30.630
The Virtual Machine is responsible
for managing the threads of execution.

00:02:30.980 --> 00:02:34.850
Your code is written in Java and
it executes on various threads.

00:02:34.850 --> 00:02:38.180
So the Virtual Machine makes
those threads happen.

00:02:38.250 --> 00:02:42.670
It's pretty easy for us because we
have Mach and threads underneath us,

00:02:42.680 --> 00:02:45.580
but we keep track of what's going on.

00:02:45.600 --> 00:02:49.430
There, we, the machine,
execute your bytecodes.

00:02:49.510 --> 00:02:52.910
It is an operating system
in a lot of respects.

00:02:53.100 --> 00:02:55.400
And having managed
operating systems before,

00:02:55.410 --> 00:02:58.740
let me assure you, it is an operating
system in many respects.

00:02:58.770 --> 00:03:02.300
The machine collects your garbage.

00:03:02.380 --> 00:03:05.450
Your garbage is your unused objects.

00:03:05.540 --> 00:03:09.050
These eat up memory and as fast,
and one of the virtues of the

00:03:09.220 --> 00:03:13.300
Java programming model is you don't
have to worry about getting rid of

00:03:13.370 --> 00:03:15.580
your memory when you're not using it.

00:03:15.600 --> 00:03:20.460
It helps us if you null
out your references when

00:03:20.460 --> 00:03:22.470
you're not using it anymore.

00:03:22.470 --> 00:03:25.120
It helps you also,
but it lets the machine

00:03:25.120 --> 00:03:26.860
take care of that stuff.

00:03:28.430 --> 00:03:34.660
The machine helps shift control back
and forth between your bytecodes

00:03:34.870 --> 00:03:37.310
and native code underneath.

00:03:38.400 --> 00:03:40.560
"Byte codes are great.

00:03:40.670 --> 00:03:47.370
So are native libraries that do
great things like speech recognition,

00:03:47.420 --> 00:03:51.730
speech synthesis, QuickTime, you know,
GUI drawing, all that kinds of stuff.

00:03:51.840 --> 00:03:54.930
So there's so much you can get done
in byte code and some stuff you

00:03:54.940 --> 00:03:56.800
have to get done in native code.

00:03:56.800 --> 00:04:01.300
And so the machine also handles
the transition to and fro.

00:04:01.300 --> 00:04:06.470
"Library Java Home" is where we put,
you know, the standard properties

00:04:06.470 --> 00:04:08.300
and things like that.

00:04:08.300 --> 00:04:10.300
And that's something
that you get to extend.

00:04:10.300 --> 00:04:15.350
"Cocoa Java," if you wander around
with Java browser or something,

00:04:15.350 --> 00:04:18.300
is located in a couple other places.

00:04:18.300 --> 00:04:22.180
It's under "System Library Java."
So if you poke around and find

00:04:22.300 --> 00:04:26.060
strange things in strange places,
this is meant to help tell you

00:04:26.460 --> 00:04:28.300
where some of our stuff belongs.

00:04:28.900 --> 00:04:31.300
The next slide.

00:04:31.300 --> 00:04:38.250
"Java Home" is about what we do
or what we think of as your place.

00:04:38.390 --> 00:04:43.060
So in our system,
Java Home is "Library Java Home."

00:04:43.290 --> 00:04:46.300
And the things in there that
you extend with your code,

00:04:46.340 --> 00:04:49.300
with your applications, are the bin area.

00:04:49.300 --> 00:04:53.220
Sometimes you've got little
helper utilities and stuff.

00:04:53.370 --> 00:04:56.300
"Java Home Bin" is a
great place to drop those.

00:04:56.300 --> 00:04:58.890
If you have jar files
that need to be part of,

00:04:59.040 --> 00:05:01.300
you know, the standard extensions,
you can put them in there.

00:05:01.440 --> 00:05:03.300
That's what the extensions
directory is all about.

00:05:03.300 --> 00:05:07.300
You put stuff in there and you don't have
to fool around with class paths anymore.

00:05:07.300 --> 00:05:09.180
That is great.

00:05:09.410 --> 00:05:13.190
Class paths are not such a great idea.

00:05:13.300 --> 00:05:18.230
Obviously, the other stuff there, fonts,
images, you put your properties there,

00:05:18.230 --> 00:05:21.330
security data, you know,
it's the general kind of

00:05:21.330 --> 00:05:24.540
dumping ground for all stuff,
all sort of support

00:05:24.540 --> 00:05:26.300
data for Java programs.

00:05:26.300 --> 00:05:30.300
"Cocoa" and "Mac OS X" has different
bundling mechanisms that let you...

00:05:30.330 --> 00:05:34.230
package some of that stuff before,
but if you're coming to

00:05:34.230 --> 00:05:37.300
us from another platform,
don't want to rethink that part.

00:05:37.300 --> 00:05:39.290
You know, Java Home is where you
already put your stuff.

00:05:39.550 --> 00:05:42.300
This is the part of Java Home that
we want you to extend.

00:05:42.300 --> 00:05:45.670
And of course, in applications,
when you write stuff,

00:05:45.670 --> 00:05:48.300
you put your resulting product up there.

00:05:48.300 --> 00:05:50.130
So that's it with the basics.

00:05:50.300 --> 00:05:52.260
I want to talk a little
bit about Hotspot.

00:05:52.300 --> 00:05:57.610
So what is Hotspot?

00:06:00.810 --> 00:06:08.240
We take HotSpot from Sun and we put it
and and and and port it to Mac OS X.

00:06:08.280 --> 00:06:12.410
So it's

00:06:13.470 --> 00:06:16.310
Not hard compared to
what it was on Mac OS 9.

00:06:16.570 --> 00:06:21.300
On Mac OS 9, we had to do things like
invent a threading model.

00:06:21.300 --> 00:06:24.470
We had to do things like, well, anyway,
I don't want to go into it.

00:06:24.560 --> 00:06:29.370
So the adopt to Darwin phase
is pretty easy because there's

00:06:29.370 --> 00:06:35.060
natural threads underneath,
there's a natural file system model,

00:06:35.060 --> 00:06:38.600
so IO just happens and stuff like that.

00:06:38.670 --> 00:06:40.200
So it's a porting job.

00:06:40.610 --> 00:06:49.520
The main thing where we add value at
this stage is we write the interpreter.

00:06:49.970 --> 00:06:52.900
This, you might think, well,
the interpreter is just a C file, right?

00:06:52.900 --> 00:06:54.300
And you just kind of compile it.

00:06:54.320 --> 00:06:55.960
Well, that's not quite the way it is.

00:06:55.960 --> 00:06:57.720
So I'll talk about that
a little bit later.

00:06:57.720 --> 00:06:59.700
But we get the interpreter
up and running.

00:06:59.700 --> 00:07:04.560
And so now you can run HotSpot
in an interpreted mode.

00:07:04.560 --> 00:07:07.860
And then, of course,
in order to make it run fast,

00:07:07.860 --> 00:07:09.940
we have to write a compiler.

00:07:09.940 --> 00:07:13.740
We have to write a runtime,
a Jitsi compiler that compiles your

00:07:13.740 --> 00:07:18.120
bytecodes dynamically into machine code,
folds it into your program,

00:07:18.120 --> 00:07:19.400
and makes it run.

00:07:19.900 --> 00:07:23.130
So that's the basics for
what we do with HotSpot,

00:07:23.230 --> 00:07:23.690
right?

00:07:23.920 --> 00:07:26.900
And then the point comes where
we want to make it better.

00:07:26.900 --> 00:07:29.640
And I'm going to talk a lot
about how we make it better.

00:07:29.640 --> 00:07:33.180
But let's just step back to HotSpot.

00:07:33.220 --> 00:07:38.040
HotSpot, this next generation technology,
what is that really all about?

00:07:38.040 --> 00:07:41.110
Well, first of all, it's 700 files.

00:07:41.210 --> 00:07:44.230
I have four people in my
group who work on HotSpot,

00:07:44.320 --> 00:07:46.060
as well as other things.

00:07:46.180 --> 00:07:48.050
So 700 files.

00:07:48.080 --> 00:07:49.880
That's 200.

00:07:49.910 --> 00:07:51.430
200,000 lines of code.

00:07:51.440 --> 00:07:58.490
It's actually 714 files,
220,000 lines of C++ code.

00:08:02.360 --> 00:08:05.490
I don't know whether any of you
just started out programming six

00:08:05.520 --> 00:08:10.110
years ago and have only known Java,
but C++ code can be intricately

00:08:10.220 --> 00:08:12.080
complex if it's not done well.

00:08:12.590 --> 00:08:15.180
Luckily for us,
HotSpot is done very well,

00:08:15.180 --> 00:08:18.220
but it is still an enormous
undertaking just getting that part up.

00:08:18.640 --> 00:08:20.890
So let me talk about that
interpreter for a minute.

00:08:20.920 --> 00:08:26.700
The interpreter is actually combined,
assembled if you were,

00:08:26.950 --> 00:08:30.030
out of code templates
every time you launch.

00:08:30.030 --> 00:08:33.920
So there is no interpreter.c file.

00:08:33.920 --> 00:08:36.080
There are templates for the interpreter.

00:08:36.080 --> 00:08:41.100
Now why would you jam together an
interpreter every time you launch the VM?

00:08:41.100 --> 00:08:43.040
Well, let me tell you.

00:08:43.040 --> 00:08:44.830
There's two reasons.

00:08:45.110 --> 00:08:47.100
One is, we don't quite make
use of this right now,

00:08:47.100 --> 00:08:48.620
but if you're on a job,
you're going to have to have a VM.

00:08:48.650 --> 00:08:51.670
If you're on a G4,
we might be able to have a faster

00:08:51.770 --> 00:08:55.620
little loop that could take
advantage of a G4 processor.

00:08:55.620 --> 00:08:58.890
So if we had just one version of it,
it would have to be tuned

00:08:58.890 --> 00:09:00.690
for either a G3 or a G4.

00:09:00.700 --> 00:09:03.350
Another one, though,
which we do make use of,

00:09:03.480 --> 00:09:06.990
is if you're debugging,
every time you execute a bytecode,

00:09:06.990 --> 00:09:08.380
you often have to ask.

00:09:08.380 --> 00:09:11.010
You have to say,
am I supposed to stop here?

00:09:11.010 --> 00:09:12.540
Is this a breakpoint?

00:09:12.540 --> 00:09:14.030
Am I supposed to do something else?

00:09:14.070 --> 00:09:16.850
And so there's at least an
if debugging check that you

00:09:16.850 --> 00:09:18.540
have to do on every bytecode.

00:09:18.680 --> 00:09:24.330
Well, not if you assemble the
interpreter on the fly.

00:09:24.330 --> 00:09:29.040
So we check, and we look, and we say,
are we running this in a debug mode?

00:09:29.120 --> 00:09:33.440
And if not, we assemble the interpreter
without that little if check.

00:09:33.470 --> 00:09:36.290
So the instructions just go flat out.

00:09:36.290 --> 00:09:39.200
The interpreter instructions just
go flat out as fast as they can.

00:09:39.200 --> 00:09:44.680
And it's really important to have a very
fast interpreter because compilation,

00:09:44.680 --> 00:09:48.580
just-in-time compilation,
takes cycles away from the interpreter.

00:09:48.610 --> 00:09:50.880
And you should only do
it when you have to,

00:09:50.940 --> 00:09:54.060
when it's going to be to
your program's advantage.

00:09:54.090 --> 00:09:56.800
So having a very fast
interpreter is very important.

00:09:56.940 --> 00:09:59.230
And so that's why that
part of the technology is

00:09:59.230 --> 00:10:01.000
actually pretty sophisticated.

00:10:01.160 --> 00:10:04.190
I could tell you more about how,
when you're about ready

00:10:04.190 --> 00:10:07.370
to do garbage collection,
you actually swap out the whole

00:10:07.370 --> 00:10:10.620
interpreter with a little jump
table such that you jump into

00:10:10.620 --> 00:10:14.280
and start synchronizing with
the garbage collector thread.

00:10:14.280 --> 00:10:16.890
But, I mean, it is a bunch of very
sophisticated technology.

00:10:16.890 --> 00:10:17.820
It's really cool.

00:10:19.470 --> 00:10:25.020
But if you're not going to be
spending your life in the interpreter,

00:10:25.020 --> 00:10:27.150
what you want to do is
have a fast compiler.

00:10:27.160 --> 00:10:30.840
You want a compiler that
compiles fast because it's,

00:10:30.840 --> 00:10:33.960
again, taking cycles away from the
running time of your program.

00:10:34.210 --> 00:10:39.100
And you need it to build good
code when it does spend that time.

00:10:39.290 --> 00:10:44.810
So our compiler is a fast compiler
and compiles into pretty good code.

00:10:44.960 --> 00:10:50.910
We are anxiously awaiting the next
generation technology from Sun,

00:10:50.910 --> 00:10:54.170
the 1.4 train,
because it actually has a better

00:10:54.480 --> 00:10:57.960
technology for generating better code.

00:10:58.270 --> 00:11:03.750
So we're looking at that because,
as Steve Naroff said,

00:11:03.800 --> 00:11:06.480
the pendulum is swinging
back to the compiler part.

00:11:06.550 --> 00:11:11.170
So we generate pretty good code,
and we're looking to make that

00:11:11.170 --> 00:11:13.090
code a little bit better for you.

00:11:14.010 --> 00:11:19.240
Finally, HotSpot has a patented,
I believe, implementation of Synchronize.

00:11:19.600 --> 00:11:24.460
Now, Synchronize is an interesting notion
from the Java language viewpoint.

00:11:24.460 --> 00:11:28.080
When you go to access a vector object,
for example,

00:11:28.080 --> 00:11:29.860
its methods are synchronized, right?

00:11:29.860 --> 00:11:33.540
And what that means is that
they're safe if several threads

00:11:33.670 --> 00:11:38.460
are trying to do operations on
that object at the same time.

00:11:38.580 --> 00:11:41.390
Well,
the reality is that most of the time,

00:11:41.390 --> 00:11:45.590
when you use a vector, only one thread's
operating on it at a time.

00:11:45.590 --> 00:11:48.080
In fact, maybe only one thread
will ever operate on that.

00:11:48.130 --> 00:11:52.590
So the idea with the Synchronize
operation is that to get a

00:11:52.590 --> 00:11:56.780
hold of and acquire the lock
for that object is a very,

00:11:56.780 --> 00:12:03.360
very fast, hand-tuned, assembled,
you know, compare and swap operation.

00:12:03.380 --> 00:12:06.300
And basically,
it says that the data structure

00:12:06.350 --> 00:12:08.380
for that is built on the stack.

00:12:08.540 --> 00:12:11.530
So you can see that the data structure
is built on the stack of the caller,

00:12:11.550 --> 00:12:11.650
and basically, it's very, very cheap.

00:12:11.780 --> 00:12:17.970
There's no extra data allocated for that.

00:12:18.100 --> 00:12:21.600
Only if a second thread
comes in and says,

00:12:21.700 --> 00:12:26.170
"I need to operate on this object also,"
do we build a heavier weight operation,

00:12:26.180 --> 00:12:29.420
a heavier weight locking operation,
and actually go to the

00:12:29.560 --> 00:12:30.100
operating system to say,
"Block that thread.

00:12:30.100 --> 00:12:31.330
We don't want them to spin.

00:12:31.330 --> 00:12:34.720
We want to put them to sleep until this
other guy is done." So a very fast,

00:12:34.720 --> 00:12:37.880
synchronized implementation
is a trademark on a HotSpot.

00:12:37.900 --> 00:12:37.900
Thank you.

00:12:38.540 --> 00:12:39.200
It's a patent.

00:12:39.200 --> 00:12:43.540
It's one of the really
cool things about HotSpot.

00:12:43.590 --> 00:12:47.410
A fabulous thing about HotSpot
is that garbage collector.

00:12:47.550 --> 00:12:50.040
I mean, when I grew up,
I never thought I'd be extolling

00:12:50.040 --> 00:12:54.120
the virtues of garbage collectors,
but garbage collection is actually

00:12:54.310 --> 00:12:58.030
a fabulous technology that
lets you program a lot easier.

00:12:58.090 --> 00:13:01.930
And so I'm going to talk a bit
about garbage collection right now.

00:13:02.430 --> 00:13:04.200
Well, not quite yet, sorry.

00:13:04.200 --> 00:13:05.780
What are the benefits?

00:13:05.950 --> 00:13:09.580
I want to talk a bit about what
does all this fabulous technology

00:13:09.640 --> 00:13:12.370
do for you in combination.

00:13:12.400 --> 00:13:17.170
So, one of the people who works for me
put together a little tiny benchmark.

00:13:17.280 --> 00:13:19.200
We call it the allocation
micro benchmark.

00:13:19.200 --> 00:13:23.680
It's from one to 16 threads or
something like that it goes.

00:13:23.800 --> 00:13:25.110
Let me tell you about it.

00:13:25.210 --> 00:13:28.820
It's several threads running
in this allocate and objects,

00:13:28.820 --> 00:13:29.590
free them.

00:13:29.810 --> 00:13:31.380
Allocate and objects, free them.

00:13:31.560 --> 00:13:32.180
How many threads?

00:13:32.200 --> 00:13:34.330
Can you get going at this?

00:13:34.330 --> 00:13:38.000
And he measures the
peak rate of allocation.

00:13:38.000 --> 00:13:41.780
So, the fun thing about it is he
wrote it about four times.

00:13:41.780 --> 00:13:43.500
He wrote the code in Java.

00:13:43.500 --> 00:13:44.980
He wrote the code in C.

00:13:44.980 --> 00:13:46.880
He wrote the code in C++.

00:13:46.880 --> 00:13:52.000
And he wrote the code in Objective-C,
which is what Cocoa is based on.

00:13:52.040 --> 00:13:54.560
So, then, of course,
you run it on a multiple processor

00:13:54.620 --> 00:13:57.240
machine to make sure you've
got two threads actually trying

00:13:57.340 --> 00:14:00.150
to do the same thing at the
hardware level at the same time.

00:14:00.180 --> 00:14:05.370
So, I have to warn you,
micro benchmarks should be

00:14:05.370 --> 00:14:08.540
taken with a grain of salt,
a lot of water,

00:14:08.540 --> 00:14:11.120
and don't think about them too much.

00:14:11.510 --> 00:14:17.390
or don't trust them to predict your
performance because they often focus

00:14:17.410 --> 00:14:20.460
on one very atypical usage pattern.

00:14:20.460 --> 00:14:23.520
I mean you might use it a little
bit but you don't use it a lot.

00:14:23.520 --> 00:14:26.940
And so anything you see from a micro
benchmark about a particular little

00:14:26.940 --> 00:14:32.060
usage pattern it's really hard,
impossible really to extrapolate from

00:14:32.060 --> 00:14:37.350
that to your program to any kind of
a extrapolated win for your program.

00:14:37.430 --> 00:14:42.100
So to emphasize the point,
your mileage will vary obviously,

00:14:42.100 --> 00:14:44.630
it will be much less.

00:14:45.520 --> 00:14:46.880
So let's talk about the results.

00:14:46.940 --> 00:14:52.040
So with C code,
this allocation benchmark gives us about

00:14:52.520 --> 00:14:55.640
two hundred objects per millisecond.

00:14:57.300 --> 00:15:17.400
[Transcript missing]

00:15:18.160 --> 00:15:23.650
allocates faster than compiled C++ code.

00:15:23.760 --> 00:15:24.360
Not bad.

00:15:24.770 --> 00:15:28.100
When the compiler has run
and is running those threads,

00:15:28.160 --> 00:15:31.980
the allocations are eight times faster.

00:15:32.270 --> 00:15:34.080
That is pretty phenomenal.

00:15:34.080 --> 00:15:37.240
This is two threads trying
to go after objects,

00:15:37.240 --> 00:15:41.960
and they get them eight times
faster when you're writing in Java.

00:15:42.040 --> 00:15:46.130
For a point of reference,
in MRJ on Mac OS 9,

00:15:46.460 --> 00:15:48.440
compiled as fast as it could go.

00:15:48.510 --> 00:15:53.350
Well, it's still faster than C or C++,
but it's just a little bit

00:15:53.760 --> 00:15:56.900
faster than HotSpot interpreted.

00:15:57.850 --> 00:16:00.800
So let me talk about
garbage collection again.

00:16:00.800 --> 00:16:04.190
Garbage collection is 41 years old.

00:16:04.740 --> 00:16:08.410
First paper on garbage collection
was John McCarthy in 1960,

00:16:08.410 --> 00:16:10.600
where he talks about mark and sweep.

00:16:10.660 --> 00:16:14.690
Mark and sweep is the idea that you
got your object laid out in memory,

00:16:14.690 --> 00:16:16.720
and you go and you mark
every one that's still alive.

00:16:16.720 --> 00:16:20.710
And then you get to reclaim
the stuff between the objects.

00:16:20.830 --> 00:16:22.240
So that's pretty cool.

00:16:22.240 --> 00:16:24.200
It was used, obviously, on a LISP system.

00:16:24.520 --> 00:16:29.960
Three years later, Marvin Minsky,
of other fame, came along and provided an

00:16:30.120 --> 00:16:34.730
interesting paper on a copying
and hence compacting collector,

00:16:34.730 --> 00:16:38.600
where not only do you mark all
the objects that are alive by

00:16:38.940 --> 00:16:44.030
descending through their roots,
but you copy them into a new space.

00:16:44.030 --> 00:16:45.840
And so that compacts your memory.

00:16:45.840 --> 00:16:50.970
And so you don't have
fragmentation issues that plague

00:16:50.970 --> 00:16:53.820
C programmers all the time.

00:16:54.420 --> 00:16:58.700
Because your objects can be packed into
the smallest memory they need to survive.

00:16:58.770 --> 00:17:03.070
And so this hugely extends the
running lifetime of a program.

00:17:03.260 --> 00:17:08.700
It was a long time before the next major
advance in garbage collection came along,

00:17:08.780 --> 00:17:11.050
and that was in 1984.

00:17:11.120 --> 00:17:16.070
Dave Unger put out a paper
about generational collecting.

00:17:16.100 --> 00:17:20.970
And since then, well,
over the course of these 41 years,

00:17:21.210 --> 00:17:24.240
there have been over a thousand
papers written on garbage collection.

00:17:24.240 --> 00:17:26.240
It's a great topic.

00:17:26.330 --> 00:17:29.810
Java is the first system where it really
comes in the mainstream for folks,

00:17:29.810 --> 00:17:30.130
though.

00:17:30.240 --> 00:17:34.240
I got my data for this great
book called Garbage Collection.

00:17:34.360 --> 00:17:40.240
And if any of this talk interests
you or intrigues you a little bit,

00:17:40.240 --> 00:17:42.200
I highly recommend you
go and buy this book.

00:17:42.240 --> 00:17:46.230
It reviews all the algorithms in a very,
very great way.

00:17:46.240 --> 00:17:48.210
Let's talk about generational collecting.

00:17:48.310 --> 00:17:50.240
What's the idea with
generational collecting?

00:17:50.410 --> 00:17:52.240
Most objects die young.

00:17:52.240 --> 00:17:54.100
Right?

00:17:54.100 --> 00:17:57.230
If you use an object just a little bit,
it's dead.

00:17:58.300 --> 00:18:03.670
So the idea is you split memory
into generations such that

00:18:04.280 --> 00:18:08.600
You can minimize the number of
CPU cycles allocating a new object,

00:18:08.600 --> 00:18:12.030
and you can minimize the number
of CPU cycles to remember and

00:18:12.240 --> 00:18:13.450
keep track of the old ones.

00:18:13.580 --> 00:18:18.010
So the idea is that old objects actually
often don't change that much in terms

00:18:18.070 --> 00:18:19.990
of what objects they hang on to.

00:18:20.040 --> 00:18:22.150
So if you can never
worry about an object,

00:18:22.150 --> 00:18:24.990
if it never changes,
then you don't have to spend cycles

00:18:25.010 --> 00:18:27.260
even remembering that it's still alive.

00:18:27.880 --> 00:18:31.410
So in order to make this really happen,
the compiler and the

00:18:31.410 --> 00:18:34.920
interpreter implement what's
known as a write barrier,

00:18:34.920 --> 00:18:38.310
such that if an object in one
generation gets stored into an

00:18:38.350 --> 00:18:42.300
object in another generation,
we keep track of that to say, hey,

00:18:42.300 --> 00:18:45.420
you better go look at these objects
over here because they might,

00:18:45.420 --> 00:18:47.750
you know,
we might have had an intergenerational

00:18:47.750 --> 00:18:51.270
reference here so that we can keep
track of which objects are alive.

00:18:51.280 --> 00:18:54.670
So that's sort of the basic
background technology.

00:18:54.740 --> 00:18:57.680
So what I want to talk about is
how is that employed in HotSpot?

00:18:57.880 --> 00:19:01.240
HotSpot has four
generations running at once.

00:19:01.240 --> 00:19:05.280
The first generation, the Eden,
is where you allocate objects.

00:19:05.280 --> 00:19:09.870
And basically it's as simple as you've
got a pointer to the top of memory,

00:19:10.030 --> 00:19:12.750
you add the size to it, and you're done.

00:19:12.780 --> 00:19:14.520
You have an allocation.

00:19:14.520 --> 00:19:18.580
The only complication here is that
the assignment for the memory,

00:19:18.580 --> 00:19:22.060
the mem plus equal size,
is an atomic compare because you've got

00:19:22.310 --> 00:19:25.210
multiple threads that may be having to
go after that and you might have missed,

00:19:25.220 --> 00:19:27.860
so there's actually a little loop to
make sure that you stored what you want.

00:19:27.880 --> 00:19:30.730
And so you have to loop back up
and see whether or not you have

00:19:30.730 --> 00:19:31.880
to re-add from the top of stack.

00:19:31.880 --> 00:19:33.800
It's very, very fast.

00:19:33.880 --> 00:19:37.120
The so-called new generation,

00:19:37.310 --> 00:19:41.190
It's where objects that survive,
that survive the first run.

00:19:41.230 --> 00:19:43.720
I mean, that's the only thing you can
do with objects in the new

00:19:43.720 --> 00:19:45.410
generation is you allocate them.

00:19:45.460 --> 00:19:49.120
You never worry about them again
because if they ever stay alive,

00:19:49.120 --> 00:19:52.500
the only way they stay alive is if
they got stored in an older object.

00:19:52.600 --> 00:19:54.120
Other than that, they're dead.

00:19:54.160 --> 00:19:57.800
So you just assume that everything
that's in the Eden space is dead

00:19:57.800 --> 00:20:00.100
because you actually track it.

00:20:00.180 --> 00:20:03.980
You actually keep track of what objects
stay alive in the other generations.

00:20:04.450 --> 00:20:06.590
So in the new space,
the new space is a two-space

00:20:06.600 --> 00:20:08.420
copying and collecting,
you know,

00:20:08.420 --> 00:20:12.340
Marvin Minsky kind of technology
from 1963 where objects that are

00:20:12.340 --> 00:20:15.990
in this space just get copied
over to another one and compacted.

00:20:16.240 --> 00:20:19.360
And if they survive this kind
of back-and-forth space a while,

00:20:19.360 --> 00:20:21.060
then we say, ah,
they're no longer a child,

00:20:21.060 --> 00:20:21.900
they're an adult.

00:20:21.900 --> 00:20:26.390
We push them into what's known
as the tenured generation,

00:20:26.400 --> 00:20:30.590
and they stay there from
adulthood until death.

00:20:31.030 --> 00:20:34.080
Actually, they can die at any stage,
but their adult objects go there.

00:20:34.420 --> 00:20:37.370
Hotspot actually has two
different algorithms for using to

00:20:37.380 --> 00:20:39.330
maintain the tenured generation.

00:20:39.390 --> 00:20:42.700
The one we ship with is a pretty
classical mark-and-sweep algorithm.

00:20:42.700 --> 00:20:45.660
There's another one called
the train collector,

00:20:45.780 --> 00:20:48.880
which you can get to with dash X, Inc.

00:20:48.880 --> 00:20:50.740
GC, I believe it is.

00:20:50.740 --> 00:20:54.730
We haven't done much experimenting
or much qualification on that.

00:20:54.800 --> 00:20:58.350
We intend to, though,
because the virtue of the train

00:20:58.350 --> 00:21:03.440
generation is it spends more cycles
keeping track of your objects,

00:21:03.660 --> 00:21:08.150
but you have less pause times when it
goes to do and find some dead memory.

00:21:08.180 --> 00:21:12.180
So pause time is actually kind
of important for GUI-based apps,

00:21:12.270 --> 00:21:13.010
isn't it?

00:21:13.080 --> 00:21:15.780
So we're going to work on the
train collector and see if we can

00:21:15.790 --> 00:21:17.590
get it into shape to ship with.

00:21:17.700 --> 00:21:19.410
You're invited to go
play with it yourself.

00:21:19.420 --> 00:21:21.170
Maybe it works just fine for you today.

00:21:21.180 --> 00:21:27.880
There's another generation, however,
which is used for support objects.

00:21:28.020 --> 00:21:34.800
Those 200,000 lines of C++ code are
possible because... those objects are,

00:21:34.900 --> 00:21:36.640
for the most part, garbage collected.

00:21:36.700 --> 00:21:39.640
They're garbage collected with
the same collector that is used

00:21:39.790 --> 00:21:41.440
for the rest of your Java objects.

00:21:41.440 --> 00:21:44.700
So Hotspot eats its own dog foods.

00:21:44.700 --> 00:21:47.150
It collects its own... it
implements its own collector and

00:21:47.150 --> 00:21:48.640
uses it for its own purposes.

00:21:48.660 --> 00:21:55.180
So the permanent generation is where the
support objects for the program are used.

00:21:55.180 --> 00:21:57.520
And other implementations,
those usually just come

00:21:57.520 --> 00:21:58.330
out of the mallet keep.

00:21:58.340 --> 00:22:01.260
But in Hotspot's case,
they come out of the so-called

00:22:01.260 --> 00:22:02.280
permanent generation.

00:22:02.280 --> 00:22:03.560
And that uses a mark-and-sweep.

00:22:03.660 --> 00:22:06.020
Objects there rarely die.

00:22:06.020 --> 00:22:11.460
So it's rare that we actually
worry about those too much.

00:22:11.500 --> 00:22:15.630
Let me shift gears a bit and talk
about the things we do... the

00:22:16.440 --> 00:22:23.980
things we do to make it better,
to make Java better.

00:22:25.300 --> 00:22:29.770
First of all, from the VM perspective,
one of the things we do is

00:22:29.770 --> 00:22:33.000
provide better integration.

00:22:33.630 --> 00:22:39.570
Better language integration lets you see
more APIs to use to write your programs.

00:22:40.130 --> 00:22:42.370
We like to provide better performance.

00:22:42.500 --> 00:22:47.750
Performance is critical
to how your program looks,

00:22:47.950 --> 00:22:51.500
how it behaves, and we really believe
in better performance.

00:22:51.640 --> 00:22:53.500
There's general observations
about performance.

00:22:53.560 --> 00:22:56.000
There's all different ways
to think about performance.

00:22:56.150 --> 00:23:00.960
In general,
you want to do more with less memory.

00:23:00.960 --> 00:23:05.480
One of the things that HotSpot does is,
in other implementations,

00:23:05.480 --> 00:23:09.830
they had an extra word per object
just to keep track of that lock,

00:23:09.830 --> 00:23:13.940
just to keep track of whether or
not a lock was around for an object.

00:23:14.000 --> 00:23:17.050
And they had another data structure,
the handle, to keep track of where

00:23:17.150 --> 00:23:19.990
it really ought to be,
so you stored handles and everything.

00:23:19.990 --> 00:23:22.000
And so all that pays off.

00:23:22.000 --> 00:23:26.000
So HotSpot runs about
10% in smaller memory.

00:23:26.000 --> 00:23:31.640
Simply because it doesn't use handles,
and it doesn't have extra data space for

00:23:31.970 --> 00:23:36.000
that rarely used monitor on every object.

00:23:36.000 --> 00:23:40.920
For the client, Steve Naroff talked about

00:23:41.100 --> 00:27:41.300
[Transcript missing]

00:27:41.720 --> 00:27:42.840
You all can see this.

00:27:42.840 --> 00:27:44.100
Not too bad.

00:27:44.170 --> 00:27:46.500
This is the JDirect3 example.

00:27:46.510 --> 00:27:49.930
I just pulled this pretty
much straight off the web at

00:27:50.080 --> 00:27:55.990
developer.apple.com/java and as you see,

00:27:56.600 --> 00:28:02.000
The first line of code,
public static linkage,

00:28:03.570 --> 00:28:08.080
needs to be done typically
in a static initializer.

00:28:08.500 --> 00:28:11.380
For some reason,
why didn't that show up here?

00:28:11.410 --> 00:28:17.890
The new linker part is the part that you
should do in your static initializer and

00:28:18.140 --> 00:28:22.530
and the rest of the team have
been working on the HotSpot

00:28:22.650 --> 00:28:24.730
Client Virtual Machine.

00:28:49.050 --> 00:28:50.000
So, from that, that's it.

00:28:50.000 --> 00:28:57.900
From that point on,
you can now do prime dot compute prime,

00:28:57.900 --> 00:29:02.200
send it a short, and it'll return a long,
long, and you're in business.

00:29:02.200 --> 00:29:05.600
You're writing in Java,
and you're using this C-based

00:29:05.600 --> 00:29:07.800
library underneath you.

00:29:07.800 --> 00:29:13.010
The counterpart for Cocoa,
Cocoa's a pretty rich framework.

00:29:13.440 --> 00:29:17.860
Steve Naroff says he's been working
like obvi with Steve Jaroff.

00:29:17.900 --> 00:29:17.980
Steve Naroff: Yeah.

00:29:17.980 --> 00:29:20.090
I've been working with Jobs for 15 years.

00:29:20.090 --> 00:29:21.610
My tenure isn't quite that long.

00:29:21.610 --> 00:29:23.190
It's only about 11.

00:29:23.310 --> 00:29:26.880
But I had something to do with
some of the Cocoa APIs in a role

00:29:26.880 --> 00:29:30.180
previous to the one I have now,
and I wanted to pull up just a little

00:29:30.180 --> 00:29:31.990
bit of something I did a long time ago.

00:29:31.990 --> 00:29:33.790
I can get to it from Java.

00:29:33.790 --> 00:29:35.940
There's a date formatter there.

00:29:36.150 --> 00:29:39.610
The date formatter takes a
string and turns it into a date.

00:29:39.660 --> 00:29:42.380
And more than that,
it can take a date and turn

00:29:42.510 --> 00:29:44.210
it into a formatted string.

00:29:44.210 --> 00:29:46.310
So this is an example that does that.

00:29:46.310 --> 00:29:48.760
So the key is to have a string element.

00:29:48.760 --> 00:29:53.480
The key element here is the -- I'm going
to go back to the -- I'm going to go

00:29:54.000 --> 00:29:54.680
Let's see where to go.

00:29:54.720 --> 00:29:56.840
The next Tuesday at dinner.

00:29:56.840 --> 00:29:58.520
That's a pretty simple
little English string.

00:29:58.520 --> 00:30:00.240
It was a weekend's worth of hacking.

00:30:00.240 --> 00:30:01.290
It's kind of fun.

00:30:01.300 --> 00:30:03.810
But that actually turns into a real date.

00:30:03.830 --> 00:30:07.470
So you can actually get to Cocoa from
your Java and make use of it without

00:30:07.580 --> 00:30:11.700
having to wade through Objective-C,
without having to wade through JNI.

00:30:11.700 --> 00:30:16.060
And I invite you to take a
look at the Cocoa examples that

00:30:16.060 --> 00:30:21.160
are shipped under Developer,
Examples, Java, AppKit.

00:30:21.160 --> 00:30:23.950
There's actually two or three
programs completely written in Java.

00:30:24.000 --> 00:30:27.940
There's a game called Blast App.

00:30:27.940 --> 00:30:31.620
There's the Sketch program,
which is a simple Mac draw

00:30:31.620 --> 00:30:33.520
kind of a game or a program.

00:30:33.650 --> 00:30:35.820
And there's a text editor in there.

00:30:36.060 --> 00:30:37.480
So go play with Cocoa.

00:30:37.600 --> 00:30:38.860
It's kind of fun.

00:30:39.780 --> 00:30:44.040
Let me talk now about better performance.

00:30:44.040 --> 00:30:45.900
I said we tried to innovate in two areas.

00:30:46.050 --> 00:30:49.550
One was better language integration.

00:30:50.780 --> 00:30:53.500
The next one is better performance.

00:30:53.570 --> 00:30:56.070
Better performance, we all want it,
right?

00:30:56.300 --> 00:30:58.570
Question is, of course, how?

00:30:58.890 --> 00:31:02.640
I mean, it's not like you just
walk up to your program,

00:31:02.700 --> 00:31:05.240
unless you have optimized it, and say,
how do I make it faster?

00:31:05.350 --> 00:31:06.710
And it's obvious.

00:31:06.780 --> 00:31:08.560
With optimized it, it actually is.

00:31:08.620 --> 00:31:10.600
In our case,

00:31:12.230 --> 00:31:14.680
We had to scratch our heads a little bit,
right?

00:31:14.950 --> 00:31:20.130
We said, "What are the basic principles
of performance?" Well,

00:31:20.130 --> 00:31:22.210
if you remember, if you think,
if you've ever done

00:31:22.210 --> 00:31:26.930
performance work before,
you should know that memory is evil.

00:31:27.320 --> 00:31:31.320
If you are wasting memory,
you're going to spend more

00:31:31.700 --> 00:31:34.020
time taking it away from a
system that might not have it.

00:31:34.040 --> 00:31:36.480
You might have to bring it in from disk.

00:31:36.500 --> 00:31:40.240
You might have to... I mean,
just memory is evil.

00:31:40.240 --> 00:31:42.660
If you can use less memory
to get your job done,

00:31:42.740 --> 00:31:44.800
your system's going to run faster.

00:31:44.840 --> 00:31:50.150
Cycles are moving... The rate of
increase of CPU cycles to memory

00:31:50.200 --> 00:31:55.370
bandwidth is just continuing to...
The disparity just keeps growing,

00:31:55.370 --> 00:31:57.940
keeps getting larger and larger,
and to ameliorate that,

00:31:57.940 --> 00:32:01.270
we keep putting more and more
caches onto the chip because memory

00:32:01.270 --> 00:32:03.770
has to be really close to the CPU.

00:32:03.860 --> 00:32:06.460
So, just think, memory is evil.

00:32:06.580 --> 00:32:10.880
If you remember that, the next thing,
is that, of course,

00:32:10.880 --> 00:32:12.490
you should steal good ideas.

00:32:12.720 --> 00:32:16.540
I mean, why invent totally new stuff
if there's already some good

00:32:16.540 --> 00:32:17.750
ideas out there already?

00:32:17.810 --> 00:32:20.190
So, if we think about memory and
we think about good ideas,

00:32:20.320 --> 00:32:20.950
what do we come to?

00:32:20.950 --> 00:32:24.390
When you talk about C technology,

00:32:24.810 --> 00:32:28.380
Long time ago, they put shared libraries
into the system.

00:32:28.430 --> 00:32:33.530
Shared libraries are a
mechanism for C libraries for

00:32:34.800 --> 00:33:39.600
[Transcript missing]

00:33:39.690 --> 00:33:42.090
The tenured generation,
remember that's the one where

00:33:42.090 --> 00:33:43.940
your objects live in adulthood.

00:33:43.940 --> 00:33:45.750
And then there's that
permanent generation,

00:33:45.750 --> 00:33:49.660
that sort of you don't know about it,
but it actually costs you kind of place,

00:33:49.660 --> 00:33:50.180
right?

00:33:50.180 --> 00:33:54.260
When you get running,
that whole space gets dwarfed.

00:33:54.260 --> 00:33:59.690
The HotSpot keeps the ratios of Eden to
new and the total of that to tenured,

00:33:59.690 --> 00:34:02.440
and they keep the ratios the same.

00:34:02.440 --> 00:34:06.160
But in a 25, or in this case,
a 35 megabyte application,

00:34:06.280 --> 00:34:09.370
the tenured space is where
most of your stuff lives.

00:34:09.410 --> 00:34:11.940
But doggone it,
that permanent generation,

00:34:11.940 --> 00:34:15.450
the place where we keep things
like your bytecodes and stuff,

00:34:15.450 --> 00:34:17.500
takes up a fair amount of space.

00:34:17.500 --> 00:34:20.520
Now, wait a minute, bytecodes,
wait a minute,

00:34:20.610 --> 00:34:23.930
what about all the bytecodes
for things like Swing?

00:34:23.930 --> 00:34:26.630
Things like JavaLang String?

00:34:26.640 --> 00:34:29.710
I mean, does your program have a
different version of the

00:34:29.970 --> 00:34:31.880
bytecodes for JavaLang String?

00:34:31.880 --> 00:34:32.420
Of course not.

00:34:32.420 --> 00:34:33.850
It's the same bytecodes.

00:34:33.980 --> 00:34:37.740
Well, why does your program in memory
have a different copy of it?

00:34:37.790 --> 00:34:39.550
No good reason whatsoever.

00:34:39.700 --> 00:34:42.970
So when we took a look
at what we could share,

00:34:42.970 --> 00:34:47.490
we figured out that it's
that space for the bytecodes.

00:34:47.560 --> 00:34:53.060
It's that space for the metadata for
your program that comes out of the

00:34:53.060 --> 00:34:56.010
standard shipping system libraries.

00:34:56.100 --> 00:35:00.290
So what we did was,
so imagine that red space.

00:35:00.720 --> 00:35:02.400
That red space gets split up.

00:35:02.400 --> 00:35:05.200
And then we split it
up into three sections.

00:35:05.240 --> 00:35:07.640
There's a section that
is completely shareable,

00:35:07.700 --> 00:35:09.500
the completely read-only part.

00:35:09.620 --> 00:35:11.340
There's a section that is mostly shared.

00:35:11.340 --> 00:35:13.640
It can be touched on,
but it's mostly shareable.

00:35:13.720 --> 00:35:17.310
And then there's still your classes,
the bytecodes for your classes that

00:35:17.520 --> 00:35:19.640
aren't really shareable to anybody.

00:35:19.770 --> 00:35:23.310
So this is a review slide.

00:35:23.400 --> 00:35:28.320
What we did was we
added a new generation.

00:35:28.380 --> 00:35:30.950
We call it the shared generation.

00:35:32.160 --> 00:35:38.690
It has no CPU cost to maintain
because it's there to start out with.

00:35:39.410 --> 00:35:42.310
It doesn't die,
because these objects are immortal.

00:35:42.500 --> 00:35:44.640
So, that's pretty cool.

00:35:44.730 --> 00:35:47.890
If we don't even have
to build these objects,

00:35:47.890 --> 00:35:52.530
and we don't have to even maintain them,
that offers us a CPU savings as well.

00:35:52.530 --> 00:35:56.880
So in addition to reducing memory,
we get to reduce the CPU cycles to

00:35:56.970 --> 00:36:00.900
get to this initial configuration
and to maintain it during the

00:36:00.900 --> 00:36:02.620
running time of your program.

00:36:02.640 --> 00:36:05.580
So let me talk a bit about
the shared generation.

00:36:05.720 --> 00:36:10.480
It's based on the observation that some
objects never change and never die.

00:36:10.480 --> 00:36:13.130
So those are the objects
we want to share.

00:36:13.150 --> 00:36:16.680
Those are the objects we maintain
on your behalf for the byte codes,

00:36:16.680 --> 00:36:21.630
for the strings and
stuff in your jar files,

00:36:21.630 --> 00:36:23.950
or in the system jar files at least.

00:36:23.960 --> 00:36:28.460
What we do is we process
those standard jar files once.

00:36:28.460 --> 00:36:35.110
We take a a a a we have
a list of the of the,

00:36:35.110 --> 00:36:38.110
an ordered list of the
classes that typically get

00:36:38.110 --> 00:36:40.000
used in a swing application.

00:36:40.090 --> 00:36:43.960
We load them into the
VM using a special option,

00:36:43.960 --> 00:36:46.340
which I'm not going to tell you about.

00:36:46.410 --> 00:36:51.940
We, uh, a key point here is that we
don't execute any byte codes.

00:36:51.940 --> 00:36:54.540
Typically when you load
classes into HotSpot,

00:36:54.540 --> 00:36:57.240
you of course, you know,
run the static initializers.

00:36:57.240 --> 00:36:59.440
Well,
the static initializers can do things

00:36:59.440 --> 00:37:01.140
like look at your command line arguments.

00:37:01.230 --> 00:37:04.230
They can, you know, go look at,
look at you know, uh,

00:37:04.230 --> 00:37:05.040
go look at disk memory.

00:37:05.040 --> 00:37:06.650
They can do arbitrary code, right?

00:37:06.690 --> 00:37:10.480
And so that would change the, you know,
change the state of the program.

00:37:10.570 --> 00:37:14.830
So the idea here is that we want
to just preserve the jar file.

00:37:14.900 --> 00:37:18.500
We just want to have an in-memory
version of the jar file.

00:37:18.500 --> 00:37:22.610
The, the useful, the running,
the useful part of the jar file is

00:37:22.610 --> 00:37:24.500
the part we want to save and share.

00:37:24.500 --> 00:37:26.500
And so we don't execute any byte codes.

00:37:26.500 --> 00:37:30.600
And then we use that fabulous
garbage collector technology.

00:37:30.600 --> 00:37:34.100
There's a little part of it that just
says iterate every object in this

00:37:34.100 --> 00:37:36.090
generation and do something to it.

00:37:36.100 --> 00:37:39.500
You know, something like a closure,
only it's written in C++.

00:37:39.730 --> 00:37:41.870
But anyway,
we reapply that garbage collecting

00:37:41.930 --> 00:37:46.530
technology to pack all the objects
that ever got created and pack

00:37:46.530 --> 00:37:49.600
them into these two spaces,
the shared read-only space

00:37:49.600 --> 00:37:51.600
and the shared rewrite space.

00:37:51.710 --> 00:37:53.590
And then of course,
we write that space to disk.

00:37:53.600 --> 00:37:57.600
And the next time you start up HotSpot,
you just map that into memory,

00:37:57.600 --> 00:38:00.490
do a little bit of fix up,
and you're running, right?

00:38:00.580 --> 00:38:01.440
Piece of cake.

00:38:01.720 --> 00:38:02.540
Simple.

00:38:02.690 --> 00:38:03.580
This is called pickling.

00:38:03.580 --> 00:38:06.580
Um, swizzling, no, not swizzling,
it's not pickling.

00:38:06.580 --> 00:38:10.580
Um, map and go, I can't remember what,
there's a, I don't know,

00:38:10.580 --> 00:38:11.580
there's a term for that.

00:38:11.580 --> 00:38:14.580
Um, map and go,
maybe that's the right term.

00:38:14.750 --> 00:38:18.570
The shared generation benefits,
I think I hit on some of those already.

00:38:18.580 --> 00:38:22.580
There are virtually no CPU cycles
used for the shared generation.

00:38:22.580 --> 00:38:24.580
That's what the asterisk is about.

00:38:24.580 --> 00:38:26.450
The read-only part, that's true.

00:38:26.670 --> 00:38:30.560
The read-write part,
we do spend some cycles and actually,

00:38:30.700 --> 00:38:35.270
few more than we need to
it's almost totally free

00:38:36.690 --> 00:38:39.770
We rarely read the standard JARs.

00:38:39.930 --> 00:38:43.060
Classes.jar, UI.jar,
we don't even read them

00:38:43.060 --> 00:38:45.110
to get you started.

00:38:45.110 --> 00:38:48.460
That saves cycles to process them.

00:38:48.750 --> 00:38:52.030
It saves you memory to, you know,
read map the index to

00:38:52.170 --> 00:38:53.870
the JAR file and to,
you know,

00:38:53.960 --> 00:38:58.520
read part to map it in and to wander
through it and copy the stuff out to make

00:38:58.520 --> 00:39:01.260
our versions of it and stuff like that.

00:39:01.330 --> 00:39:02.890
And obviously the disk I.O.

00:39:02.970 --> 00:39:04.670
to get those things off the disk.

00:39:05.000 --> 00:39:08.960
So if you never have to read them in,
that they're not sitting

00:39:08.960 --> 00:39:09.810
in your disk cache.

00:39:10.050 --> 00:39:12.990
So that helps with the rest of
your system's performance as well.

00:39:13.180 --> 00:39:16.890
So one of the benefits from
that is that a hot start,

00:39:16.890 --> 00:39:20.430
you know,
the second start of any Java program

00:39:20.460 --> 00:39:25.530
is always faster because we save
all those cycles to begin with.

00:39:28.660 --> 00:39:35.600
A secondary benefit of this technology is
that we can be smarter about how we lay

00:39:35.600 --> 00:39:38.040
those runtime data objects out in memory.

00:39:38.060 --> 00:39:43.510
So, for example, there's linkage strings
that keep your class,

00:39:43.690 --> 00:39:45.660
that whenever you
reference another object,

00:39:45.660 --> 00:39:47.910
there's a little linkage
string that goes in that says,

00:39:47.910 --> 00:39:50.120
you know, Java lang,
da-da-da-da-da-da-da,

00:39:50.120 --> 00:39:53.380
or a reference to your classes.

00:39:53.570 --> 00:39:56.230
That's actually laid
down in the metadata,

00:39:56.230 --> 00:39:58.570
and those strings are rarely used.

00:39:58.600 --> 00:40:02.400
But if your bytecodes are sandwiched
between those rarely used strings,

00:40:02.440 --> 00:40:05.770
what we do by pulling the strings
out and putting them in their own

00:40:05.770 --> 00:40:09.700
space that's hardly ever used,
and keeping your bytecodes hotter,

00:40:09.700 --> 00:40:14.760
then we never even pull those
pages in off of disk that reference

00:40:14.890 --> 00:40:17.350
the data that you never use.

00:40:17.360 --> 00:40:23.160
And so your working set actually gets
smaller because we've done packing.

00:40:23.500 --> 00:40:24.880
So,
what we're trying to do is we're trying

00:40:25.020 --> 00:40:27.820
to put the hot data into the memory pages
that you're actually pulling off of disk.

00:40:27.900 --> 00:40:32.390
So, those disk I/Os pack more punch
because they bring in more usable

00:40:32.870 --> 00:40:35.150
data due to this packing benefit.

00:40:35.940 --> 00:40:38.780
This sharing benefit was
the one I started out with.

00:40:38.780 --> 00:40:40.730
It's the last one I want to talk about.

00:40:40.780 --> 00:40:44.160
Steve showed you how, altogether,
the combined benefits were 20

00:40:44.160 --> 00:40:45.740
megabytes for two applications.

00:40:45.800 --> 00:40:50.740
You know, the benefits for three and
four and five are the same.

00:40:51.010 --> 00:40:55.800
So sharing saves, we've measured three
to six megabytes alone.

00:40:55.800 --> 00:40:59.800
The other processing adds up
to some of that other data.

00:40:59.800 --> 00:41:03.800
The other reductions in the working set
add up to some of those other benefits.

00:41:03.900 --> 00:41:06.800
So if you're writing a swing app,
and most of you are,

00:41:07.080 --> 00:41:12.590
you're going to be saving and
getting that for free using our

00:41:12.870 --> 00:41:14.800
shared generation technology.

00:41:15.140 --> 00:41:16.660
There are just a few caveats.

00:41:16.750 --> 00:41:21.780
We don't yet know how to
share your application jars.

00:41:21.800 --> 00:41:26.680
Well, your application jars actually
aren't all that often shared,

00:41:26.680 --> 00:41:29.800
but getting that runtime/launchtime
benefit would be pretty cool.

00:41:29.800 --> 00:41:33.510
So we're going to at least try to
figure out how to map and go your stuff

00:41:33.510 --> 00:41:35.800
so that your stuff launches faster.

00:41:35.910 --> 00:41:40.770
The first start of a Java application
is actually a little slower.

00:41:40.790 --> 00:41:45.260
And that is because we actually
have to do some processing

00:41:45.270 --> 00:41:47.650
for all those swing classes.

00:41:47.800 --> 00:41:52.410
We have to do some processing all
up front that we typically meter

00:41:52.450 --> 00:41:54.800
out as you load them on demand.

00:41:54.800 --> 00:41:58.790
And we're working on ways
to not have to do that.

00:41:58.840 --> 00:41:59.800
The other benefit is that we're not
going to have to do that all the time.

00:41:59.800 --> 00:41:59.800
We're going to have to
do it in a few weeks.

00:41:59.800 --> 00:42:02.290
The interpreter,
those bytecodes that you execute

00:42:02.300 --> 00:42:03.700
have to be slightly slower.

00:42:03.800 --> 00:42:07.690
But since in Hotspot you spend
90% of your time in compiled code,

00:42:07.800 --> 00:42:13.800
slowing down the 10% you spend in
interpreted by 1 or 2% isn't a big deal.

00:42:13.800 --> 00:42:15.800
But I just want to be truthful.

00:42:15.800 --> 00:42:23.380
A caveat here is that what we share are
the classes on your boot class path.

00:42:24.110 --> 00:42:27.910
Now, for some programs that
alter your boot class path,

00:42:27.910 --> 00:42:32.080
HotSpot takes a look at that and says,
uh-oh, we don't know what they're doing.

00:42:32.080 --> 00:42:36.330
So in JBuilder's case, for example,
what they've done is they've

00:42:36.420 --> 00:42:41.180
provided their own implementation of
certain AWT classes so that they can

00:42:41.180 --> 00:42:43.730
use them in their great designer.

00:42:43.730 --> 00:42:45.200
Their designer is a great tool.

00:42:45.200 --> 00:42:50.190
So if you're using JBuilder for
designing swing applications,

00:42:50.190 --> 00:42:51.420
here's a tip.

00:42:51.700 --> 00:42:55.550
You can get sharing for JBuilder
by configuring JBuilder 5,

00:42:55.730 --> 00:42:59.270
which just got pre-pronounced
and it's in your bags,

00:42:59.330 --> 00:43:05.250
by adding a line called add skip
path dot dot slash lawt.jar.

00:43:05.530 --> 00:43:11.300
That lawt.jar is their jar file
for giving them a better AWT.

00:43:12.960 --> 00:43:16.740
and that's a configure that that
line goes in a file I called it

00:43:16.740 --> 00:43:20.550
JSA you can call anything you
want the magic is .config in the

00:43:20.550 --> 00:43:23.450
open tools area of JBuilder 5.

00:43:23.870 --> 00:43:28.180
So, directions for our sharing work.

00:43:28.270 --> 00:43:31.020
First of all,
we know how to and we can improve the

00:43:31.170 --> 00:43:34.710
HotStart launch time even further.

00:43:34.870 --> 00:43:39.080
We can and know how to eliminate,
for the most part,

00:43:39.080 --> 00:43:42.620
we know how to eliminate
that first start penalty.

00:43:42.620 --> 00:43:47.600
We know how to extend the HotStart

00:43:48.390 --> 00:43:56.120
or we want to extend this fast start
launching behavior to all the files,

00:43:56.120 --> 00:44:00.090
or at least the ones we're told to,
all the jar files that exist

00:44:00.180 --> 00:44:02.950
in that extensions directory.

00:44:03.240 --> 00:44:11.200
We're really pleased with that
second-order benefit of packing data.

00:44:11.200 --> 00:44:14.800
So what we would like to do
is rather than gather all the

00:44:14.810 --> 00:44:18.930
data for a class and jam it,
we want to make the observation that

00:44:19.460 --> 00:44:22.200
some methods are never used in a class.

00:44:22.200 --> 00:44:25.820
So the bytecodes for some
methods shouldn't be on some of

00:44:25.820 --> 00:44:28.200
those pages that get brought in.

00:44:28.250 --> 00:44:32.080
So we want to start packing based on
the methods that are used and not just

00:44:32.110 --> 00:44:34.180
based on the classes that are used.

00:44:34.200 --> 00:44:38.970
This may well double the benefit
of our sharing already by reducing

00:44:38.970 --> 00:44:41.070
your working set even more.

00:44:41.200 --> 00:44:49.200
We of course have to finish the GC work
on the read/write share generation.

00:44:49.200 --> 00:44:52.200
And we of course could
figure out how to do that.

00:44:52.200 --> 00:44:54.920
We've got to share more runtime
data structures that live in

00:44:54.920 --> 00:44:59.890
that permanent generation.

00:45:03.040 --> 00:45:06.740
There's a few things we're
not trying to do right now.

00:45:06.870 --> 00:45:08.180
The non-directions.

00:45:08.180 --> 00:45:10.380
It's important when you're setting
out to build something to know

00:45:10.380 --> 00:45:14.250
what your goals are and if you can,
to identify the goals that you're

00:45:14.250 --> 00:45:15.720
not going to try to worry about.

00:45:15.830 --> 00:45:20.000
So the biggest one for us is
we're not going to share the

00:45:20.000 --> 00:45:23.170
machine code that gets compiled

00:45:23.430 --> 00:45:24.760
for your bytecodes.

00:45:24.790 --> 00:45:28.030
I mean that is the first thing
that other shared libraries,

00:45:28.040 --> 00:45:30.080
that the traditional C library share.

00:45:30.120 --> 00:45:32.510
But in HotSpot's cases,
you've got to remember

00:45:32.510 --> 00:45:33.740
what HotSpot's about.

00:45:33.850 --> 00:45:40.260
HotSpot is about compiling the
methods that you're actually using.

00:45:40.320 --> 00:45:44.030
Not only combining them,
but inlining methods that they use.

00:45:44.070 --> 00:45:49.320
So you get one long pile of code
that is really hot because it has

00:45:49.530 --> 00:45:52.300
everything it needs to get its job done.

00:45:52.360 --> 00:46:00.500
So that highly tight code
is really good for you.

00:46:00.600 --> 00:46:04.480
So when we've measured how
much code do we compile,

00:46:04.480 --> 00:46:07.620
it never has exceeded two megabytes.

00:46:07.630 --> 00:46:12.680
When you're running with HotSpot,
applications like JBuilder and stuff,

00:46:12.680 --> 00:46:16.360
we never end up compiling more
than about two megabytes of code.

00:46:16.390 --> 00:46:19.220
That code is not worth sharing.

00:46:19.260 --> 00:46:23.300
That code is the stuff that's
hot that is for your run time.

00:46:23.300 --> 00:46:26.950
Because every time you run an app,
of course, you get different HotSpots,

00:46:27.000 --> 00:46:27.200
right?

00:46:27.200 --> 00:46:30.270
You shift into this area,
and it needs to do that,

00:46:30.330 --> 00:46:31.360
and then you shift into another app.

00:46:31.480 --> 00:46:35.060
It's all based on the work program.

00:46:35.060 --> 00:46:37.500
So the idea with HotSpot is
it's going to optimize what

00:46:37.500 --> 00:46:39.780
your program is doing right now.

00:46:39.780 --> 00:46:42.730
And so if we tried to share that,
we wouldn't do as good of a job.

00:46:42.760 --> 00:46:48.640
So we're not going to share
the compiled machine code that

00:46:48.640 --> 00:46:50.140
we've built on your behalf.

00:46:50.140 --> 00:46:52.980
So the other reason is it's kind of hard,
right?

00:46:52.980 --> 00:46:55.700
Because if you do try to share that,
then it has to have

00:46:55.700 --> 00:46:57.140
relocation data in it.

00:46:57.140 --> 00:47:01.240
And so rather than folding in
a branch to a direct address,

00:47:01.240 --> 00:47:02.710
we have to fold in an indirect.

00:47:02.770 --> 00:47:04.120
It just gets messy.

00:47:04.120 --> 00:47:05.700
It's not very good.

00:47:05.700 --> 00:47:11.110
There's only one place where sharing

00:47:13.990 --> 00:47:16.760
compiled bytecodes
might make a difference.

00:47:16.780 --> 00:47:23.740
And that might be for, say,
the static initializers or the code that

00:47:23.740 --> 00:47:27.010
you actually run to get up and running.

00:47:27.100 --> 00:47:33.950
If the interpreter-- if that's a dominant
cost to getting a program up and running,

00:47:34.060 --> 00:47:39.080
it might be better to have a precompiled,
but not so good, but compiled-- compiled,

00:47:39.080 --> 00:47:42.530
not as good as Hotspot would do normally,
but compiled better than the

00:47:42.630 --> 00:47:46.690
interpreter-- might be better
to have compiled code start out.

00:47:46.710 --> 00:47:49.610
But that's sort of precompiled stuff,
and I wouldn't even

00:47:49.880 --> 00:47:51.160
characterize it in the same way.

00:47:51.160 --> 00:47:53.130
So we might look at that.

00:47:54.260 --> 00:47:57.960
Another thing we just decided
at the outset was we are

00:47:57.960 --> 00:48:01.910
not going to try to share,
have any kind of shared buffer,

00:48:01.950 --> 00:48:05.700
shared read/write buffer of
loaded class information,

00:48:05.700 --> 00:48:09.000
a shared read/write buffer
of compiled code information,

00:48:09.000 --> 00:48:12.460
a shared read/write buffer of anything,
because you know what happens

00:48:12.460 --> 00:48:15.330
when you have a shared
read/write buffer of something?

00:48:15.430 --> 00:48:17.860
Some other app can make you crash.

00:48:17.930 --> 00:48:19.330
We do not want that to happen.

00:48:19.480 --> 00:48:22.700
So that's just not a design
point we're going to provide.

00:48:24.830 --> 00:48:27.440
The status of the shared generation.

00:48:27.450 --> 00:48:29.800
This code that I'm talking
about is in Mac OS X.

00:48:29.800 --> 00:48:31.700
We shipped it on March 24th.

00:48:31.700 --> 00:48:34.140
You're getting it already
if you're using Java.

00:48:34.140 --> 00:48:37.210
The Merlin, we've asked,
we've talked to some,

00:48:37.260 --> 00:48:39.990
we talked to some about
a year ago and said,

00:48:40.190 --> 00:48:43.450
you guys really ought to do something
about sharing because that's what

00:48:43.450 --> 00:48:45.290
scalability means for the client.

00:48:45.300 --> 00:48:49.120
And so they said,
well the way you do this

00:48:49.120 --> 00:48:54.900
is you file a little,
oh God, I can't remember the, not JSR.

00:48:55.550 --> 00:48:57.580
You file a little,
you put a feature request

00:48:57.960 --> 00:49:01.080
into Merlin through the open
community process and stuff.

00:49:01.160 --> 00:49:05.100
So we sponsored one of those guys
and it's a feature request in Merlin,

00:49:05.100 --> 00:49:08.440
which is their code name for JDK 1.4.

00:49:08.440 --> 00:49:12.050
And more than that,
we talked with these folks.

00:49:12.140 --> 00:49:13.780
The VM teams know each other.

00:49:13.780 --> 00:49:17.400
And we talked with them and said,
have you guys thought about doing this?

00:49:17.400 --> 00:49:18.490
And what about that?

00:49:18.490 --> 00:49:19.600
And stuff like that.

00:49:19.720 --> 00:49:23.010
But anyway,
so we've worked with them testing

00:49:23.010 --> 00:49:25.450
our designs out with them.

00:49:25.560 --> 00:49:28.930
And as we develop this thing,
and we've provided this code,

00:49:28.930 --> 00:49:33.110
we've provided it back to Sun so that
they can use it for their implementation

00:49:33.270 --> 00:49:35.490
of this little feature request.

00:49:35.490 --> 00:49:39.340
So current status,
we have talked to Larry about

00:49:39.370 --> 00:49:41.700
the current status of that.

00:49:41.850 --> 00:49:47.480
So we've had very positive
interactions with Sun on this work.

00:49:47.850 --> 00:49:50.570
This comes about in two ways.

00:49:50.570 --> 00:49:54.020
With WebObjects, for example,
with WebObjects stress testing,

00:49:54.020 --> 00:49:55.480
they run a lot of tests.

00:49:55.480 --> 00:49:58.700
And we ran into some bugs and
we kind of chased them down.

00:49:58.700 --> 00:50:05.690
We go, hmm, this is bugging what we
call the portable code.

00:50:05.690 --> 00:50:14.570
So we call up our friends
across the street and say,

00:50:14.570 --> 00:50:18.910
do you know about this?

00:50:18.910 --> 00:50:25.460
And they go, hmm, no, we didn't.

00:50:25.460 --> 00:50:25.460
So we're actually feeding bug
fixes through the indirect channels

00:50:25.460 --> 00:50:25.460
and making Hotspot as shipped
by Sun better for everybody.

00:50:25.460 --> 00:50:25.460
And of course,
they've given us some feedback

00:50:25.460 --> 00:50:25.460
on approaches to take when
we run into some problems.

00:50:25.460 --> 00:50:29.190
and stuff,
so the feedback goes both ways.

00:50:29.650 --> 00:50:31.970
I'd like to spend the last,
not the last section,

00:50:31.990 --> 00:50:33.720
but the last section before Q&A.

00:50:33.790 --> 00:50:36.700
The last section of this talk,
I'd like to talk about what's

00:50:36.700 --> 00:50:38.570
in Developer Preview 1,
which you're going to

00:50:38.630 --> 00:50:42.200
be getting either today,
tomorrow, or the next day, before Friday.

00:50:42.800 --> 00:50:46.530
The JVM in Java DP1,
it's basically got about two fixes

00:50:46.590 --> 00:50:48.710
since we shipped it in Mac OS X.

00:50:48.710 --> 00:50:51.230
I just talked about them, actually.

00:50:51.230 --> 00:50:55.670
The WebObject stress testing gave us,
showed us two things once

00:50:55.670 --> 00:50:57.580
they started kicking off.

00:50:57.620 --> 00:51:01.670
And so we've upped our mean time
to failure to at least days.

00:51:01.670 --> 00:51:05.110
I'm not sure,
we don't know of failure right now.

00:51:05.110 --> 00:51:08.110
But it was running in
terms of hours and about,

00:51:08.230 --> 00:51:12.400
you know, after about 24 hours, no,
24 hours.

00:51:12.700 --> 00:51:16.920
48 hours of continuous hammering,
a bug would show up.

00:51:16.920 --> 00:51:21.680
And that's the bug I alluded to
that we figured out with Sun's help.

00:51:21.680 --> 00:51:27.060
The other thing, though,
that was not quite right

00:51:27.190 --> 00:51:32.680
in Mac OS X GM was that
debugging was really slow.

00:51:33.200 --> 00:51:34.770
"Painfully slow.

00:51:35.060 --> 00:51:37.910
And profiling didn't work.

00:51:37.910 --> 00:51:40.200
So that's kind of bad.

00:51:40.370 --> 00:51:45.270
So in DP1 what we've done
is we fixed both problems.

00:51:45.270 --> 00:51:51.020
We fixed profiling and we
fixed the speed of debugging.

00:51:51.020 --> 00:51:53.700
And the way we did that was

00:51:55.350 --> 00:52:02.600
We took HotSpot 2.0 from the 1.3.1
technology train and packaged it as an

00:52:02.600 --> 00:52:06.580
extra VM sitting somewhere in that little
implementation space I told you about.

00:52:06.750 --> 00:52:09.900
So there's actually two HotSpots in DP1.

00:52:09.900 --> 00:52:14.210
The one that's configured for normal use
and the one that is secretly utilized

00:52:14.210 --> 00:52:16.920
whenever you do debugging or profiling.

00:52:17.100 --> 00:52:18.470
So, now why would we do that?

00:52:18.520 --> 00:52:20.270
I mean, where do we get that VM from?

00:52:20.270 --> 00:52:23.320
Well, obviously we're working on 1.3.1,
right?

00:52:23.540 --> 00:52:26.900
So we wanted to get 1.3.1
out to you in some ways,

00:52:26.900 --> 00:52:30.350
especially for debugging and profiling,
because we think that's really important.

00:52:30.360 --> 00:52:35.470
The benefits from HotSpot 2.0 is, again,
it's the client compiler

00:52:35.470 --> 00:52:37.010
technology from Sun.

00:52:37.120 --> 00:52:39.700
They also have a server compiler.

00:52:39.700 --> 00:52:45.220
The debugging, as I said, now works fast.

00:52:45.300 --> 00:52:46.870
Profiling works fast.

00:52:47.010 --> 00:52:47.080
Profiling works fast.

00:52:47.080 --> 00:52:47.540
It works.

00:52:47.540 --> 00:52:49.300
It didn't work at all.

00:52:49.360 --> 00:52:53.530
1.3.1 is actually,
HotSpot 2.0 is actually, you know,

00:52:53.660 --> 00:52:56.470
a next generation of the
next generation stuff.

00:52:56.520 --> 00:53:00.440
And they have a register
allocator technology in there

00:53:00.460 --> 00:53:02.560
that we can use right away.

00:53:02.560 --> 00:53:04.780
And we do use that,
so we get better register

00:53:04.780 --> 00:53:06.660
allocation when we're compiling.

00:53:06.660 --> 00:53:12.840
And it foreshadows the compiler
that they're working on for 1.4,

00:53:12.840 --> 00:53:15.930
which does even better code gen.

00:53:15.940 --> 00:53:16.930
So we're perfect.

00:53:17.100 --> 00:53:20.560
And we're prepping ourselves for
getting on board with the 1.4 work.

00:53:20.660 --> 00:53:23.060
But we didn't stop there.

00:53:23.060 --> 00:53:24.620
I mean, this is Apple, right?

00:53:24.620 --> 00:53:27.950
I want you guys to come to expect
more from us than just what you

00:53:27.950 --> 00:53:29.900
can read on the web pages at Sun.

00:53:30.090 --> 00:53:35.250
So what we've done since then,
or since we shipped GM, or Mac was 10 GM,

00:53:35.250 --> 00:53:39.680
was we put some smarts in to
recognize when you're on a G4.

00:53:39.680 --> 00:53:43.180
Now,
what could you do differently on a G4?

00:53:43.180 --> 00:53:46.880
Well, a G4 comes with this
thing called a velocity.

00:53:46.900 --> 00:53:48.900
And it's a velocity engine.

00:53:48.900 --> 00:53:51.100
Now, what's a velocity engine, right?

00:53:51.100 --> 00:53:53.260
You're supposed to do graphics with that,
right?

00:53:53.310 --> 00:53:55.890
Well,
it's a special processing unit for doing

00:53:55.890 --> 00:53:58.500
highly fast pipeline graphics operations.

00:53:58.500 --> 00:54:02.700
To do graphic or pipeline graphics
operations in a high speed way,

00:54:02.700 --> 00:54:06.700
you've got to read memory
like mad off the bus.

00:54:06.700 --> 00:54:08.830
Well, if you can read memory
like mad off the bus,

00:54:08.910 --> 00:54:11.280
you can use it for simple
things like copying memory,

00:54:11.320 --> 00:54:11.900
can't you?

00:54:11.900 --> 00:54:16.740
So we put a copy memory implementation
in there that went on G4s,

00:54:16.740 --> 00:54:19.290
uses the AlteVec,
and it is dramatically faster than

00:54:19.290 --> 00:54:23.740
just any kind of C loop or assembly
loop you can write in PowerPC yourself.

00:54:23.740 --> 00:54:30.550
So we have that,
and it's in our 131 version of Hotspot,

00:54:30.660 --> 00:54:32.940
Hotspot 2.0.

00:54:32.940 --> 00:54:36.140
We put in an optimized instance of.

00:54:36.140 --> 00:54:38.520
I mean,
this is just an example of lots of

00:54:38.520 --> 00:54:41.740
little things we do for you that
you guys will never hear about.

00:54:41.740 --> 00:54:44.450
All you're ever going to see it
is it improves your run time.

00:54:44.540 --> 00:54:47.870
But when you do instance of,
you typically think, well,

00:54:47.870 --> 00:54:48.700
how would you do it?

00:54:48.780 --> 00:54:51.640
Well, if it's not this class,
I got to look at the parent class,

00:54:51.740 --> 00:54:52.580
got to look at parent class.

00:54:52.620 --> 00:54:54.700
Well,
we put a table in there such that it's

00:54:54.790 --> 00:54:56.980
always it's a constant speed operation.

00:54:57.030 --> 00:54:58.850
Instance of works.

00:54:59.070 --> 00:55:01.210
So it's fast.

00:55:01.590 --> 00:55:06.140
We put in even better register
allocation than what came from 131.

00:55:06.140 --> 00:55:09.950
131 still doesn't deal with
floating point registers very well,

00:55:09.950 --> 00:55:14.400
so now we have a better floating point
register allocation method for when

00:55:14.490 --> 00:55:18.130
you're doing those graphics operations.

00:55:18.380 --> 00:55:27.500
Sharing is not in this little package
for profiling and debugging use only VM.

00:55:27.500 --> 00:55:30.300
We know, actually,
how to make startup times even faster,

00:55:30.300 --> 00:55:33.290
but since that's part of sharing,
it's also not in that thing yet.

00:55:33.460 --> 00:55:40.870
And 131 also has a technology known
as per-thread allocation pools.

00:55:40.870 --> 00:55:46.650
So remember that very fastest
Eden technology that I talked

00:55:46.660 --> 00:55:52.570
about where you bump the pointer,
but that reassigned to the memory was

00:55:52.570 --> 00:55:53.970
that compare and swap instruction?

00:55:53.990 --> 00:55:58.670
Well, with a per-thread allocation pool,
you don't need the compare and swap even.

00:55:58.680 --> 00:56:02.450
So it really is just about three
instructions to allocate memory.

00:56:03.050 --> 00:56:06.600
Instead of a "stall the processor and
check with the other CPUs maybe next

00:56:06.600 --> 00:56:10.380
to you and make sure they're not using
this memory" kind of instruction.

00:56:10.550 --> 00:56:16.790
So it actually is going to be really,
really fast.

00:56:17.520 --> 00:56:23.820
I put this up here because we're starting
this kind of beta train thing with DP1.

00:56:23.860 --> 00:56:25.140
I want you guys to play with it.

00:56:25.160 --> 00:56:32.820
So if you want to use it for casual use,
use it via the command line like this.

00:56:32.840 --> 00:56:38.020
You say java-hs1-3-1.

00:56:39.320 --> 00:56:44.550
java-hs1-3-1 will run this new version of
HotSpot on any program you throw at it.

00:56:44.650 --> 00:56:48.760
If you really like it,
try using it all the time.

00:56:50.300 --> 00:56:53.360
There's a link, a sim link,
I'll let you go explore,

00:56:53.520 --> 00:56:57.310
but there's a sim link under
Java VM framework that points

00:56:57.500 --> 00:57:00.100
to the version of HotSpot
that actually gets used.

00:57:00.100 --> 00:57:03.090
It's the libjvm-dilib sim link.

00:57:03.200 --> 00:57:04.980
Slam it to point to that thing.

00:57:04.980 --> 00:57:10.040
You'll find an hs-131.dilib somewhere.

00:57:10.040 --> 00:57:13.600
If you slam the jvm sim
link to point to it,

00:57:13.600 --> 00:57:17.560
you'll get HotSpot 131 all the time.

00:57:18.930 --> 00:57:20.590
Tell us about it.

00:57:20.820 --> 00:57:23.160
So,
when is this thing going to be available?

00:57:23.160 --> 00:57:24.220
I wish I knew.

00:57:24.340 --> 00:57:24.500
No.

00:57:24.500 --> 00:57:28.660
It's going to be coming,
it's real soon now.

00:57:28.700 --> 00:57:31.980
So to get to it,
you sign up at developer.apple.com.

00:57:31.980 --> 00:57:35.790
You go to the connect.app,
after you sign up as a developer,

00:57:35.880 --> 00:57:38.890
you're all developers, you're here,
right?

00:57:38.900 --> 00:57:39.120
Okay.

00:57:39.130 --> 00:57:41.900
You go to connect.apple.com
and you download it.

00:57:43.050 --> 00:57:45.520
When you download it, what does it do?

00:57:45.520 --> 00:57:49.530
It preserves your existing
1.3 implementation.

00:57:49.800 --> 00:57:52.460
1.3 is a subdirectory
under Java Framework,

00:57:52.460 --> 00:57:55.670
so it pushes that aside in case
you don't like what you got.

00:57:55.900 --> 00:58:02.000
It preserves what we find under
Java Home that we think you've augmented,

00:58:02.480 --> 00:58:08.140
specifically the stuff that's in Lib,
including your extensions.

00:58:08.140 --> 00:58:11.470
Any other third party,
even QuickTime is in there, right?

00:58:11.530 --> 00:58:12.190
Stuff we ship.

00:58:12.260 --> 00:58:14.020
It's packaged up in extensions.

00:58:14.020 --> 00:58:16.220
So we preserve everything
that's in extensions,

00:58:16.300 --> 00:58:18.490
because we actually put
some other stuff in there,

00:58:18.590 --> 00:58:23.010
and we preserve everything
we find in Java Lib Home bin.

00:58:23.020 --> 00:58:28.400
So that's the main motivation for that
first set of slides that tell you the

00:58:28.400 --> 00:58:34.400
stuff that we consider our implementation
and the stuff we think you should extend,

00:58:34.400 --> 00:58:38.270
because we do need to upgrade,
you want us to upgrade,

00:58:38.280 --> 00:58:41.510
and we've got to agree on some rules.

00:58:41.800 --> 00:58:45.760
The stuff we can upgrade and the
stuff that we shouldn't upgrade.

00:58:47.200 --> 00:58:52.090
So, there is a mailing list, JavaDev,
that you can get to.

00:58:52.240 --> 00:58:55.540
Go to, as I said,
that page where I pulled the JNI example,

00:58:55.540 --> 00:59:00.540
or yeah, the JDIRECT example off,
developer.apple.com/java.

00:59:00.570 --> 00:59:04.240
There's a section on there that
talks about the JavaDev mailing list,

00:59:04.300 --> 00:59:06.560
and sign up.

00:59:06.960 --> 00:59:09.380
Members of the extended
Java team read that,

00:59:09.380 --> 00:59:10.240
respond to it.

00:59:10.360 --> 00:59:12.870
We found it very useful,
and we appreciate your

00:59:12.870 --> 00:59:13.980
comments from that.

00:59:14.100 --> 00:59:16.410
So, a quick roadmap.

00:59:17.050 --> 00:59:20.160
The first one,
wrapping Mac OS APIs and Beans.

00:59:20.180 --> 00:59:23.760
If you went to Steve Naroff's one,
you saw Steve Llewellyn.

00:59:23.800 --> 00:59:26.590
Steve Llewellyn is

00:59:27.560 --> 00:59:28.640
is a great guy.

00:59:28.720 --> 00:59:33.860
I've empowered him to go do great
stuff making more Java happen at Apple.

00:59:33.860 --> 00:59:35.560
He came up with some great APIs.

00:59:35.940 --> 00:59:37.690
The stuff you saw there are APIs.

00:59:37.730 --> 00:59:38.650
They're beans.

00:59:38.720 --> 00:59:43.070
You can use them inside JBuilder to add
that kind of technology to your apps.

00:59:43.070 --> 00:59:46.300
Find out all about it by
going to the session 502.

00:59:46.300 --> 00:59:48.460
That's today at 5 o'clock.

00:59:48.540 --> 00:59:51.350
Java Development Tools,
Steve Naroff talked about.

00:59:51.350 --> 00:59:53.350
That's tomorrow at 10:30.

00:59:53.950 --> 00:59:55.470
Java Performance.

00:59:55.580 --> 01:00:00.390
Performance is critical to us.

01:00:00.390 --> 01:00:00.390
So we have a whole session on how

01:00:00.700 --> 01:00:03.600
is going to talk about how you can
add performance to your programs,

01:00:03.610 --> 01:00:06.600
how you can discover it, things to avoid,
things to do.

01:00:06.670 --> 01:00:12.750
Part of the Java Development Tools talk
is the Optimize It demonstration,

01:00:12.750 --> 01:00:18.600
and JBuilder debugging,
and project builder debugging.

01:00:18.810 --> 01:00:24.530
And if that's not enough,
if you really... I put the

01:00:24.530 --> 01:00:27.470
JBuilder reference up here as well,
because JBuilder is just an awesome

01:00:27.620 --> 01:00:29.600
tool for building your job applications.

01:00:29.600 --> 01:00:34.020
That's about it.

01:00:36.490 --> 01:00:38.000
Ah, how about that?

01:00:38.040 --> 01:00:41.380
There is the feedback forum
as well on Friday at 10:30.

01:00:41.380 --> 01:00:43.390
That should have been on the first one.

01:00:43.390 --> 01:00:46.400
So please come tell us what you like,
what you don't like,

01:00:46.400 --> 01:00:49.400
and give us suggestions as to what
you'd like to see even better.

01:00:49.400 --> 01:00:51.320
Alan Samuel is the contact.

01:00:51.320 --> 01:00:54.400
He was the guy that
introduced Steve Naroff.

01:00:54.400 --> 01:00:58.530
Find him as Blucher1@apple.com.