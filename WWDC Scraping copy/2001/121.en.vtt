WEBVTT

00:00:05.640 --> 00:00:09.840
Welcome to session 121.

00:00:09.840 --> 00:00:13.500
You know, performance is an important
consideration for all of us.

00:00:13.500 --> 00:00:15.500
And at Apple,
we're certainly doing our part,

00:00:15.500 --> 00:00:20.500
working hard to improve the performance
characteristics of Mac OS X.

00:00:20.920 --> 00:00:24.500
Many developers have told me that

00:00:25.380 --> 00:00:28.150
They've seen measurable
performance boosts in their

00:00:28.150 --> 00:00:30.940
Carbon apps running on 10,
but we know there's always

00:00:31.030 --> 00:00:32.650
room for improvement.

00:00:35.860 --> 00:00:42.080
And so it's my pleasure to introduce the
manager of the Advanced Mac Toolbox team,

00:00:42.080 --> 00:00:45.440
John Iaroci,
to tell you about how you can improve

00:00:45.440 --> 00:00:48.360
your performance running on Mac OS X.

00:00:48.400 --> 00:00:50.030
Welcome, John.

00:00:55.160 --> 00:00:59.500
Good afternoon.

00:00:59.540 --> 00:01:02.100
Perhaps you've noticed there's been
a little bit of an undercurrent,

00:01:02.150 --> 00:01:07.100
a theme here throughout the
conference on performance.

00:01:07.160 --> 00:01:12.500
And basically,
a lot of that revolves around

00:01:13.830 --> 00:01:17.770
A realization at some point,
you've carbonized your app,

00:01:17.930 --> 00:01:21.470
you've taken advantage of
some of these latest features,

00:01:21.470 --> 00:01:25.010
and you're comparing
your app on 9 and 10.

00:01:25.270 --> 00:01:28.780
And you realize, gee,
this part of my app is slow.

00:01:28.810 --> 00:01:30.750
Why is it slow?

00:01:30.960 --> 00:01:37.880
And there's been other talks that
have kind of gone over the high

00:01:37.880 --> 00:01:40.170
level description of why it's slow.

00:01:40.390 --> 00:01:42.550
But basically,
we've seen time and time again,

00:01:42.610 --> 00:01:46.890
as more and more people
bring Carbon apps to 10,

00:01:47.010 --> 00:01:49.940
that there's this basic
assumption that certain code,

00:01:50.020 --> 00:01:55.760
certain code paths, certain calls,
will have the same compatibility

00:01:55.760 --> 00:01:59.080
on OS X as they do on 9.

00:01:59.960 --> 00:02:04.740
We looked at all of the
APIs going into Carbon.

00:02:04.790 --> 00:02:07.270
We studied them carefully.

00:02:07.280 --> 00:02:13.460
We knew right up front that there were
several APIs that just would not be--

00:02:14.200 --> 00:02:48.500
[Transcript missing]

00:02:49.170 --> 00:02:52.760
Before I actually get into some
of the specifics in this session,

00:02:52.760 --> 00:02:59.530
I just want to mention that this session
is coming ahead of the tools talk,

00:02:59.650 --> 00:03:03.450
7:05, which is later on,
5:00 this afternoon.

00:03:03.610 --> 00:03:06.890
And this session is going
to refer to tools that are

00:03:06.940 --> 00:03:09.210
described in depth in that talk.

00:03:09.450 --> 00:03:13.860
Ideally, we would have actually been
able to schedule the sessions,

00:03:14.200 --> 00:03:29.700
[Transcript missing]

00:03:30.300 --> 00:03:34.090
And finally,
there's no one answer for performance,

00:03:34.100 --> 00:03:36.280
and there's going to be all
sorts of different performance

00:03:36.360 --> 00:03:37.870
problems with your apps.

00:03:38.010 --> 00:03:42.880
So look to other sessions as well,
some of which have already happened,

00:03:43.010 --> 00:03:47.090
for tips on performance in your app.

00:03:48.390 --> 00:03:53.240
Okay, so these are the topics that
we're going to go through today.

00:03:53.370 --> 00:03:57.190
And they're pretty
much ranked in terms of

00:03:57.270 --> 00:03:59.740
The way I would prioritize them for you.

00:03:59.800 --> 00:04:03.110
If you're only going to do one thing
with your app regarding performance,

00:04:03.150 --> 00:04:06.540
I would definitely look
into application launch.

00:04:06.600 --> 00:04:10.390
I'd highly recommend the first three,
going through launching,

00:04:10.420 --> 00:04:13.200
file system usage, and CPU usage.

00:04:13.410 --> 00:04:15.870
That's where you're really
going to get a lot of payback

00:04:15.920 --> 00:04:17.530
in terms of the time you put in.

00:04:17.650 --> 00:04:21.490
But all of them have interesting
performance benefits,

00:04:21.630 --> 00:04:24.760
and I really would encourage
you to really try to get

00:04:24.930 --> 00:04:28.260
performance into your planning,
into your scheduling,

00:04:28.260 --> 00:04:30.900
and into the way you develop your app.

00:04:31.030 --> 00:04:33.800
So let's start with application launch.

00:04:34.960 --> 00:04:40.970
Perhaps some of you are
familiar with the bouncing icon.

00:04:41.740 --> 00:04:46.140
The interesting thing is that
sometimes it bounces quite a lot.

00:04:46.290 --> 00:04:48.600
Sometimes it doesn't stop bouncing.

00:04:49.000 --> 00:04:51.630
There are pretty good reasons for that.

00:04:51.990 --> 00:04:53.980
First of all,
the bouncing is there as visual

00:04:53.980 --> 00:04:56.760
feedback to the user that
something is actually happening,

00:04:56.760 --> 00:04:58.550
that a launch is occurring, right?

00:04:58.830 --> 00:05:06.520
Some very legitimate reasons why the app
may take a long time to launch is perhaps

00:05:06.540 --> 00:05:10.800
the app is actually off on some network
volume and the network is sluggish.

00:05:10.800 --> 00:05:14.790
Perhaps it's on a disk that is spun down.

00:05:14.790 --> 00:05:17.800
It may be on a CD drive.

00:05:17.800 --> 00:05:21.800
There's real legitimate answers to some
of these launching performance problems.

00:05:21.800 --> 00:05:28.800
But those aren't really interesting and
they're not really under your control.

00:05:28.800 --> 00:05:28.800
They're kind of environmental.

00:05:29.000 --> 00:05:32.240
The ones that we really want to
talk about today are the things

00:05:32.240 --> 00:05:34.380
that you can do something about.

00:05:36.940 --> 00:05:40.910
So when talking about app launching,
I like to refer to two

00:05:40.910 --> 00:05:45.190
different kind of launches,
two different environments

00:05:45.260 --> 00:05:47.900
in which you launch your app.

00:05:47.900 --> 00:05:52.790
The first one being a cold launch,
and the second one being a warm launch.

00:05:53.190 --> 00:05:59.600
Cold Launch is your app
launching on a bad day.

00:05:59.610 --> 00:06:02.100
Everything is going against your app.

00:06:02.100 --> 00:06:06.480
All the files that it has are not readily
available or cached in the system.

00:06:06.480 --> 00:06:10.160
All the memory that it needs has
to fight for some of that memory

00:06:10.160 --> 00:06:12.480
if some other app is using it.

00:06:12.480 --> 00:06:16.260
This is kind of a worst case scenario.

00:06:16.790 --> 00:06:20.830
And it's actually-- it's an extreme
that you're not really likely to hit

00:06:20.970 --> 00:06:24.230
as the system is actually being used.

00:06:24.480 --> 00:06:27.890
But what we do is we mimic this.

00:06:28.050 --> 00:06:30.800
A simple way to do it is to
basically write a tool that

00:06:30.840 --> 00:06:33.500
allocates all of physical memory,
then touch that memory,

00:06:33.500 --> 00:06:36.190
and that will flush out all the
memory that's in the system,

00:06:36.310 --> 00:06:40.490
and then see how your
app launches after that.

00:06:40.590 --> 00:06:43.240
That doesn't quite cover all of
it because there are cases where,

00:06:43.390 --> 00:06:46.720
even though the memory
is no longer cached,

00:06:46.830 --> 00:06:49.540
you actually potentially have
files that have been cached in

00:06:49.630 --> 00:06:53.960
the file system and other kernel
objects that affect the performance.

00:06:54.070 --> 00:06:59.480
So it's actually hard to get to
your real worst case scenario.

00:06:59.780 --> 00:07:05.290
Warm Launch, on the other hand,
is basically things are

00:07:05.310 --> 00:07:07.800
going well for the app.

00:07:07.960 --> 00:07:10.470
The libraries that you
depend on are all loaded.

00:07:10.540 --> 00:07:12.420
They've already been instantiated.

00:07:12.510 --> 00:07:16.640
The best case is basically it's an
app very much like yours or another

00:07:16.640 --> 00:07:19.460
instance of your app has just launched.

00:07:19.520 --> 00:07:25.150
And the reason I distinguish between
the two is because they're really

00:07:25.300 --> 00:07:28.810
different in terms of how you optimize.

00:07:29.370 --> 00:07:36.320
And the biggest point is the
cold launch is predominated by

00:07:36.440 --> 00:07:40.170
what I would call low-level I/O,
and I'll explain that in a little bit.

00:07:40.380 --> 00:07:45.360
So my challenge to you is to get your
warm launches for your typical app,

00:07:45.360 --> 00:07:48.600
and this will vary depending on the
memory and disk and configuration,

00:07:48.770 --> 00:07:51.050
to launch in one bounce.

00:07:51.560 --> 00:07:56.180
There are apps on OS X that launch
in one bounce in this situation,

00:07:56.180 --> 00:07:59.670
and there's plenty of improvement
for even the apps that we've

00:07:59.670 --> 00:08:02.590
shipped in the first release of X.

00:08:03.650 --> 00:08:07.140
The other thing I would encourage
is two measurement techniques

00:08:07.220 --> 00:08:12.800
that help constrain or help give
you boundaries as to how fast

00:08:12.910 --> 00:08:16.140
or how slow your app can launch.

00:08:16.250 --> 00:08:20.710
The first one,
what I refer to as the Do Nothing app, is

00:08:20.900 --> 00:08:24.890
Take your application,
and the very first thing you should do,

00:08:24.890 --> 00:08:29.500
right after, in your main entry point,
is just put in exit to shell.

00:08:30.180 --> 00:08:32.980
Leave everything else the same.

00:08:33.010 --> 00:08:35.850
Exit will work as well.

00:08:36.070 --> 00:08:39.860
What you're trying to do here is launch
an app that basically does nothing.

00:08:39.870 --> 00:08:42.600
But not just any app, your app,
with all of the libraries

00:08:42.710 --> 00:08:43.650
that it depends on.

00:08:43.930 --> 00:08:44.970
Everything else is the same.

00:08:44.990 --> 00:08:48.150
It's just you're not executing
any coded initialization.

00:08:48.220 --> 00:08:51.600
I think you'll be surprised when
you actually measure that with

00:08:51.600 --> 00:08:55.540
either a stopwatch or any of the
tools that we have on the system.

00:08:55.610 --> 00:09:00.020
I usually use, for this case,
I usually use the time

00:09:00.170 --> 00:09:03.000
command at the command line.

00:09:03.120 --> 00:09:07.160
It's an interesting data
point because it's--

00:09:07.700 --> 00:09:10.760
When you first look at it,
that's your best case, right?

00:09:10.760 --> 00:09:13.930
And a warm launch when you just
do absolutely nothing at main,

00:09:13.990 --> 00:09:16.270
that's as fast as you're going to get.

00:09:16.370 --> 00:09:19.640
Well, actually that's not quite true.

00:09:19.750 --> 00:09:25.010
Because before main is run,
there is other code that runs that

00:09:25.010 --> 00:09:27.480
you actually have some control over.

00:09:27.590 --> 00:09:33.010
Particularly, there's the init routines
of your libraries that you

00:09:33.010 --> 00:09:35.070
pull in that execute code.

00:09:35.230 --> 00:09:41.140
There's the init routine of your
app itself that executes code.

00:09:41.190 --> 00:09:45.670
And the third major category is,

00:09:45.880 --> 00:09:47.780
Static Initializers for C++.

00:09:47.780 --> 00:09:52.170
These three areas are things you
definitely have to look at because they

00:09:52.170 --> 00:09:54.800
contribute to your best case scenario.

00:09:54.800 --> 00:09:57.160
You haven't run any
code in the app at all.

00:09:57.240 --> 00:10:00.900
So you may be doing things in your
static initializers that you just

00:10:00.900 --> 00:10:03.550
don't even remember you put there,
right?

00:10:03.610 --> 00:10:06.080
So make sure you take a look at those.

00:10:06.760 --> 00:10:10.940
So that's the do nothing app approach,
and that's a good data point to capture.

00:10:10.950 --> 00:10:15.660
The other one is more like the best case,
just to kind of get an idea

00:10:15.660 --> 00:10:18.100
of how good things could be.

00:10:18.100 --> 00:10:22.640
And there I would just recommend that you
basically have a very high end system,

00:10:22.640 --> 00:10:26.140
as much memory as you can put in it.

00:10:26.150 --> 00:10:28.550
Make sure that absolutely
nothing else is running.

00:10:28.790 --> 00:10:31.970
Take it off the net.

00:10:33.290 --> 00:10:36.240
Launch the app once, launch it again,
measure it.

00:10:36.300 --> 00:10:39.210
Those are two boundaries that
you should keep in mind as you do

00:10:39.260 --> 00:10:41.710
performance analysis of your app.

00:10:42.090 --> 00:10:47.070
And what you should be doing
as you improve your application

00:10:47.080 --> 00:10:50.790
launch performance is see how you
can get those two to converge,

00:10:50.790 --> 00:10:52.360
essentially.

00:10:53.750 --> 00:10:56.580
I'm not actually bringing up
or talking at length about some

00:10:56.580 --> 00:11:01.010
more conventional techniques that
you are already familiar with.

00:11:01.300 --> 00:11:04.520
The whole area of perceived
performance is something that

00:11:04.520 --> 00:11:06.470
you might also want to look into.

00:11:06.500 --> 00:11:09.290
I'm talking about real-time performance.

00:11:09.290 --> 00:11:11.700
I'm talking about clock time.

00:11:11.940 --> 00:11:18.100
There's still definitely advantages to,
for example, putting a splash screen up.

00:11:18.100 --> 00:11:22.500
Ideally, you'd want to put your first
window up as fast as possible,

00:11:22.500 --> 00:11:27.060
and if you can't get that to be
a second kind of granularity,

00:11:27.180 --> 00:11:29.460
maybe a splash screen is in order.

00:11:29.650 --> 00:11:31.450
Some feedback.

00:11:32.580 --> 00:11:35.710
Oh, the other thing I forgot to
mention on the bouncing icon.

00:11:35.960 --> 00:11:40.740
The bouncing icon starts when
you double click on your app.

00:11:40.790 --> 00:11:44.780
It stops when your application
is handling events.

00:11:46.010 --> 00:11:49.900
So if you're doing a whole bunch of
other stuff before handling events,

00:11:49.910 --> 00:11:54.870
you're not able to respond to events,
that's going to tie into this.

00:11:54.940 --> 00:11:57.900
It's going to tie into how it's
perceived that your application launches.

00:11:57.900 --> 00:12:02.920
It also is going to tie into how when the
user can actually use your application.

00:12:04.040 --> 00:12:06.310
And then there was one other
thing on the bouncing app,

00:12:06.310 --> 00:12:09.710
is it will time out
after some absurd time.

00:12:10.090 --> 00:12:14.440
And then at that point,
the user isn't quite sure if the

00:12:14.440 --> 00:12:16.820
app is actually launched or not.

00:12:17.880 --> 00:12:22.090
Okay,
so in looking at launch performance,

00:12:22.090 --> 00:12:25.560
I was able to profile
two word processing apps.

00:12:26.120 --> 00:12:29.880
This is a typical profile
of an untuned app.

00:12:30.000 --> 00:12:34.140
You can see the time is
dominated by low level I/O.

00:12:34.140 --> 00:12:40.400
By that I mean the virtual memory system,
paging, the dynamic loader,

00:12:40.540 --> 00:12:42.550
doing library loading,
initializing libraries

00:12:42.600 --> 00:12:43.520
for the first time.

00:12:43.590 --> 00:12:45.690
This is largely completely
out of your control.

00:12:45.700 --> 00:12:49.090
This is something the OS takes care of.

00:12:49.400 --> 00:12:52.990
But the other two sections
are really interesting.

00:12:53.100 --> 00:13:00.490
That being the file I/O and
the CPU time during launch.

00:13:01.300 --> 00:13:05.440
By file I/O, a typical example of file
I/O is when you're actually

00:13:05.440 --> 00:13:10.340
going and reading preferences,
maybe you're enumerating plug-ins.

00:13:10.520 --> 00:13:13.100
That's the kind of file I/O I mean.

00:13:13.860 --> 00:13:18.000
On the CPU side of things,
it could be as simple as determining,

00:13:18.000 --> 00:13:20.300
you know,
maybe you've read your preferences in

00:13:20.300 --> 00:13:24.360
and now you're sanity checking them.

00:13:24.490 --> 00:13:27.680
Anything that's typically compute bound.

00:13:29.550 --> 00:13:31.820
Now,
what's interesting here is those two,

00:13:31.870 --> 00:13:37.020
file I/O and CPU time,
compete with the lower level I/O.

00:13:37.620 --> 00:13:40.260
The ideal case,
we minimize the file I/O and

00:13:40.260 --> 00:13:45.300
CPU time and we can make a much
better use of low level I/O.

00:13:45.730 --> 00:13:53.530
The other thing that sometimes shows
up in untuned applications is pauses.

00:13:53.730 --> 00:13:59.210
By that I mean either an explicit call
to a call like delay or a sleep call,

00:14:00.090 --> 00:14:04.060
left in accidentally,
left in to work around some bug.

00:14:04.110 --> 00:14:05.630
Those are kind of hard to detect.

00:14:05.760 --> 00:14:08.440
Usually you have to see that
basically the app is running,

00:14:08.440 --> 00:14:12.710
but it's not doing anything compute
intensive and it's not doing I/O.

00:14:12.820 --> 00:14:18.040
There's a couple tools that I'll
get into a little bit later that'll

00:14:18.720 --> 00:14:21.240
helped find these kind of problems.

00:14:21.270 --> 00:14:25.910
The other anomaly we see sometimes
is writing during launches.

00:14:26.050 --> 00:14:29.520
There's really no good reason that
your application has to write to

00:14:29.520 --> 00:14:32.190
the file system during a launch.

00:14:32.490 --> 00:14:35.310
Now I'm not talking the first
time your app ever launches

00:14:35.590 --> 00:14:37.690
on that system for that user.

00:14:37.730 --> 00:14:41.130
It's perfectly okay to go ahead and write
out your preferences for the first time,

00:14:41.130 --> 00:14:44.940
but statistically speaking,
your typical launch should not

00:14:44.940 --> 00:14:47.370
have any file system rights.

00:14:47.730 --> 00:14:52.210
The reason for that is first,
writes are much more

00:14:52.220 --> 00:14:53.600
expensive than reads.

00:14:53.650 --> 00:14:57.920
And the whole launch facilities,
the low level I/O has

00:14:57.920 --> 00:15:00.130
optimizations for reads.

00:15:00.260 --> 00:15:02.100
It's basically geared at reads.

00:15:02.280 --> 00:15:08.370
And a write right in the middle of that
will interrupt it and will essentially

00:15:08.370 --> 00:15:08.370
discard some of the optimizations.

00:15:09.450 --> 00:15:14.030
Here's the profile of a tuned app.

00:15:14.340 --> 00:15:21.700
Now both of these are what I refer to,
what I explained before as a cold launch.

00:15:22.060 --> 00:15:27.060
This one you can see has a lot
more low level I/O and that's good

00:15:27.110 --> 00:15:29.150
because that's the best case for us.

00:15:29.270 --> 00:15:33.950
We can optimize that into the largest
chunks of I/O that we can do and we

00:15:33.950 --> 00:15:37.010
can do them as efficiently as possible.

00:15:37.770 --> 00:15:41.140
And of course,
the file I/O and the CPU are

00:15:41.260 --> 00:15:42.940
minimized in this case.

00:15:43.060 --> 00:15:47.830
If this were a worm launch,
all that low-level I/O would go away.

00:15:48.490 --> 00:15:53.310
You might see some more compute cycles,
but the profile is quite

00:15:53.310 --> 00:15:55.630
different for a warm launch.

00:15:57.770 --> 00:15:59.320
Okay, so what does that mean?

00:15:59.420 --> 00:16:02.020
For both cold and warm launches,
you should concentrate on

00:16:02.070 --> 00:16:05.120
CPU usage and file system usage.

00:16:05.220 --> 00:16:11.450
That's the areas that'll
pay back the most.

00:16:12.400 --> 00:16:18.760
The best way of doing that is
first do only what you need to do.

00:16:18.950 --> 00:16:23.950
Look at what you're doing in
the launch of your applications.

00:16:24.780 --> 00:16:27.730
If it's the typical app,
you're probably initializing a whole

00:16:27.730 --> 00:16:33.490
bunch of stuff that you may or may
not use during the life of that app.

00:16:33.570 --> 00:16:37.450
Look at deferring some
of that initialization.

00:16:37.470 --> 00:16:42.200
This might be a very good use of
setting up a Carbon event timer to

00:16:42.380 --> 00:16:47.400
send yourself a one-shot timer to
defer some of this initialization.

00:16:47.480 --> 00:16:50.540
Or don't even do it when the
app is up and running events.

00:16:50.710 --> 00:16:55.180
Do it when the user first uses
that feature of your application.

00:16:55.270 --> 00:17:00.490
Particularly if the feature in question
is a somewhat optional feature.

00:17:00.540 --> 00:17:02.340
I'm not saying it's a
bad feature or anything.

00:17:02.340 --> 00:17:05.990
I'm just saying if your typical user
base isn't going to use that feature,

00:17:06.020 --> 00:17:07.770
why pay for it?

00:17:07.840 --> 00:17:11.220
Why pay for it up front
in your initialization?

00:17:14.220 --> 00:17:20.200
Then the second speed-up tip I would
have for you is eliminating some of

00:17:20.200 --> 00:17:22.100
these things that you see during launch.

00:17:22.400 --> 00:17:24.100
Just outright eliminating.

00:17:24.100 --> 00:17:28.080
Writing and pausing of some sort,
that's a good example of that.

00:17:28.560 --> 00:17:30.100
Dead code.

00:17:30.100 --> 00:17:34.100
Make sure your tools are
working for you in this regard.

00:17:34.100 --> 00:17:36.390
I'm talking about dead code that,
you know,

00:17:36.390 --> 00:17:39.850
may be in there for debug reasons,
may be in there for

00:17:39.850 --> 00:17:44.100
whatever reasons you have,
for tracing, profiling, things like that.

00:17:44.100 --> 00:17:48.100
Make sure that that doesn't
end up in your final product.

00:17:48.130 --> 00:17:52.100
Just a little bit of code sprinkled
around means it affects your locality,

00:17:52.100 --> 00:17:56.210
means that code that would
not be on the same page.

00:17:56.690 --> 00:17:58.740
Code that should be on the
same page would potentially

00:17:58.740 --> 00:18:02.800
be split up across two pages,
and that can make a difference.

00:18:03.620 --> 00:18:06.760
Then there's another kind of dead code
that I would encourage you to go after.

00:18:06.850 --> 00:18:12.200
That's the dead code that
you've inherited over time.

00:18:12.510 --> 00:18:15.260
Now is the time to get rid of that
kind of code that's checking to

00:18:15.260 --> 00:18:18.340
see if Quickdraw supports color.

00:18:18.380 --> 00:18:20.900
No need for that anymore.

00:18:21.530 --> 00:18:23.320
You probably still have
the check in your code.

00:18:23.400 --> 00:18:26.640
You probably still have the code
base that supports that check.

00:18:26.790 --> 00:18:30.480
At least,
pound to find that out of your app.

00:18:32.090 --> 00:18:34.740
And then of course, redundant I/O.

00:18:34.740 --> 00:18:35.910
And that shouldn't be understated.

00:18:35.980 --> 00:18:38.460
Redundant I/O is where you
can actually get a lot of

00:18:38.460 --> 00:18:41.590
time back from your launches.

00:18:42.460 --> 00:18:46.820
And now I'd like to
bring up Nitin Ganatra,

00:18:46.840 --> 00:18:52.090
who's going to go through some of the
details of file system performance

00:18:52.200 --> 00:18:55.610
and help with that redundant I/O.

00:19:11.700 --> 00:19:13.410
OK, it's on now.

00:19:13.430 --> 00:19:16.120
Good afternoon.

00:19:16.200 --> 00:19:23.000
So as John mentioned, redundant I/O,
and in fact, any kind of file I/O,

00:19:23.000 --> 00:19:29.360
is a big burden on clock
time of your application.

00:19:29.640 --> 00:19:34.120
Doing anything to get rid of
this file I/O or minimize it at

00:19:34.120 --> 00:19:36.740
launch will pay off immediately.

00:19:36.740 --> 00:19:41.270
And it can either pay off at least
minimally in reducing system call

00:19:41.270 --> 00:19:46.170
overhead in the best case scenario
where you've got buffer caches that have

00:19:46.270 --> 00:19:52.350
got your data and they're already hot,
all the way to if you're reading

00:19:52.350 --> 00:19:55.480
something off of a network disk and
you solve because it's on a network.

00:19:56.920 --> 00:20:00.380
So here are the areas
that I'd like to cover.

00:20:00.430 --> 00:20:04.880
First is file iteration, metadata,
volume iteration.

00:20:04.880 --> 00:20:05.800
Well, actually, no.

00:20:05.800 --> 00:20:06.980
You can read those.

00:20:06.980 --> 00:20:08.990
Let's just get right into it.

00:20:09.590 --> 00:20:13.100
First one, the venerable pbgetcatinfo.

00:20:13.440 --> 00:20:16.220
You're all familiar with this call,
I'm sure.

00:20:16.260 --> 00:20:21.660
And when we were creating the Carbon API,
it was pretty much no question.

00:20:21.810 --> 00:20:24.260
We couldn't get rid of pbgetcatinfo.

00:20:24.260 --> 00:20:28.620
It would have just caused a huge upheaval
in people's source bases everywhere,

00:20:28.620 --> 00:20:29.700
ours included.

00:20:29.750 --> 00:20:32.640
And so there was just no choice.

00:20:32.780 --> 00:20:33.550
We had to provide it.

00:20:33.620 --> 00:20:35.100
It had to be compatible.

00:20:35.130 --> 00:20:38.160
Unfortunately, we couldn't make it
performance compatible,

00:20:38.180 --> 00:20:40.840
but that was a secondary concern
in the interest of getting

00:20:40.840 --> 00:20:43.610
your apps onto 10 quickly.

00:20:44.190 --> 00:20:50.180
The bad news is that PBGetCADinfo
is non-optimal on any file system.

00:20:50.180 --> 00:20:54.150
That goes for 9 and for 10,
if you have file sharing on 9,

00:20:54.150 --> 00:20:54.860
for example.

00:20:54.860 --> 00:20:59.300
And for the most part,
it's overkill for all clients.

00:20:59.300 --> 00:21:03.560
PBGetCADinfo just returns
a huge amount of data,

00:21:03.560 --> 00:21:08.200
and the developer code out
there that uses PBGetCADinfo

00:21:08.730 --> 00:21:10.860
ranges from using none of it,
in other words,

00:21:10.860 --> 00:21:14.480
just checking an error code,
to maybe one field from this

00:21:14.870 --> 00:21:17.260
enormous data structure.

00:21:17.260 --> 00:21:20.250
Let's take a look at that data structure.

00:21:20.890 --> 00:21:25.270
In fact, I couldn't even fit everything
that GetCatInfo returns to you.

00:21:25.540 --> 00:21:27.430
It's just an enormous amount of stuff.

00:21:27.550 --> 00:21:33.170
And, you know, when it came time to,
or back when PBGetCatInfo was first

00:21:33.560 --> 00:21:37.950
created and exported as a system call,
it made perfect sense because

00:21:37.950 --> 00:21:41.720
it was a great reflection of
the underlying volume format,

00:21:41.770 --> 00:21:42.450
right?

00:21:42.660 --> 00:21:46.460
On HFS disks,
the catalog information is stored

00:21:46.510 --> 00:21:48.960
in one section of the disk.

00:21:48.960 --> 00:21:53.690
It tends to be hot in the caches because
everyone is using the catalog files.

00:21:53.690 --> 00:21:56.470
So PBGetCatInfo tends to be free.

00:21:56.600 --> 00:21:59.460
And, well,
while you've paid the trap overhead,

00:21:59.460 --> 00:22:03.530
you know, on a classic Mac OS system,
while you've paid the trap overhead

00:22:03.600 --> 00:22:07.450
of making the call and getting into
the file system and what have you,

00:22:07.490 --> 00:22:10.010
let's just return back
everything that we possibly can.

00:22:10.020 --> 00:22:10.980
And guess what?

00:22:11.230 --> 00:22:12.460
We did.

00:22:12.510 --> 00:22:15.620
Of course, and everyone uses this call.

00:22:15.720 --> 00:22:17.320
It's plenty fast on 9.

00:22:17.370 --> 00:22:19.390
There aren't any real problems with it.

00:22:19.540 --> 00:22:23.600
Problems slowly started creeping
in with file sharing again,

00:22:23.800 --> 00:22:26.390
and things got much worse with 10.

00:22:26.970 --> 00:22:31.280
Sort of as a graphical example
of how pbGitCatInfo works,

00:22:31.300 --> 00:22:34.140
this is an optimal case right here.

00:22:34.180 --> 00:22:35.960
This is with file sharing turned off.

00:22:35.990 --> 00:22:39.180
This is on an HFS or an AFP disk.

00:22:39.440 --> 00:22:42.600
In other words,
all the data that's given to you

00:22:42.890 --> 00:22:47.220
in one pbGitCatInfo call is in
one contiguous part of the disk.

00:22:47.260 --> 00:22:51.090
And lo and behold,
it fills in the param block in one shot.

00:22:52.060 --> 00:22:54.060
Again, this is optimal.

00:22:54.070 --> 00:22:57.760
Let's look at what happens with
pbgetcatinfo on other file systems.

00:22:57.910 --> 00:23:00.400
With Mac OS X now,
we have the opportunity to

00:23:00.400 --> 00:23:04.860
support plenty of other file
systems than we ever did before,

00:23:05.030 --> 00:23:08.920
and it turns out that pbgetcatinfo
is just not a good reflection

00:23:08.920 --> 00:23:11.140
of the underlying volume format.

00:23:11.460 --> 00:23:14.760
In order to get some data,
we have to go to parts of the disk,

00:23:14.890 --> 00:23:16.200
different parts of the disk.

00:23:16.320 --> 00:23:18.800
And in fact,
a lot of those different parts of

00:23:18.890 --> 00:23:23.420
the disk are completely disjoint,
which means you make one pbgetcatinfo

00:23:23.420 --> 00:23:27.960
call on one of these file systems,
you're doing numerous I/O operations.

00:23:28.070 --> 00:23:30.590
And I don't think I have
to say that that's bad,

00:23:30.720 --> 00:23:33.460
potentially if this is
a network-based disk.

00:23:33.570 --> 00:23:36.500
And as we move forward,
more of them will be.

00:23:37.900 --> 00:24:37.100
[Transcript missing]

00:24:37.390 --> 00:24:41.350
A good way to see exactly
what's going on as,

00:24:41.350 --> 00:24:44.790
you know, when you make a request,
an FS Get Catalog Info call

00:24:44.790 --> 00:24:48.940
to see what's going on under
the covers is to use FS Usage.

00:24:48.940 --> 00:24:53.170
This is a tool that's on your
systems and it will be covered

00:24:53.170 --> 00:24:55.470
in the Performance Tools talk.

00:24:55.550 --> 00:24:58.340
I believe it's session 705
that John talked about earlier.

00:24:58.340 --> 00:25:01.910
It's great to actually just
write a simple little app,

00:25:01.910 --> 00:25:06.370
call FS Get Catalog Info with the
various bits that you are interested

00:25:06.390 --> 00:25:07.900
in and just see what's happening.

00:25:08.350 --> 00:25:12.140
Particularly on these other file systems,
you know,

00:25:12.140 --> 00:25:15.840
something that's not HFS or AFP,
NFS or UFS.

00:25:15.840 --> 00:25:19.020
UFS is probably the
most readily available.

00:25:19.600 --> 00:25:23.180
So here's a quick little sample.

00:25:23.240 --> 00:25:27.680
Given an FS ref,
tell me if this item is a folder.

00:25:27.690 --> 00:25:32.730
Notice that the only bit that's
passed to the FS get catalog info

00:25:32.880 --> 00:25:36.400
call is the FS cat info node flags,
because that's the only bit

00:25:36.450 --> 00:25:37.870
that we're really interested in.

00:25:37.970 --> 00:25:42.020
So on an NFS or a UFS file system,
that's all we have to worry about.

00:25:42.020 --> 00:25:44.680
And we can do that in
one system call at most.

00:25:44.760 --> 00:25:48.360
In fact, in a lot of cases,
we can do it in zero system calls.

00:25:48.790 --> 00:25:53.880
And then, of course,
the field is anded and returned.

00:25:53.930 --> 00:25:56.690
The next topic is volume iteration.

00:25:57.050 --> 00:26:01.390
So when it came time to
create the Carbon API,

00:26:01.390 --> 00:26:04.430
we were going through and pruning
out a lot of areas that we just

00:26:04.450 --> 00:26:07.960
couldn't support in Carbon on OS X.

00:26:08.320 --> 00:26:13.110
One of them was the low mem
to get at the VCB pointer.

00:26:13.220 --> 00:26:16.080
A lot of Carbon apps,
or a lot of Mac OS apps,

00:26:16.320 --> 00:26:19.400
saw this as a free way to
get access to all volumes,

00:26:19.400 --> 00:26:22.860
to enumerate all volumes, with zero I/O.

00:26:22.950 --> 00:26:26.620
And, you know, I don't have to tell you,
just in-memory copies are very fast,

00:26:26.660 --> 00:26:27.650
very efficient.

00:26:27.930 --> 00:26:32.360
However, when we created the Carbon API,
it was pretty clear that we

00:26:32.470 --> 00:26:34.360
couldn't support direct VCB access.

00:26:34.430 --> 00:26:37.830
And our recommendation was,
and continues to be,

00:26:37.830 --> 00:26:40.990
to use one of the get
volume info type calls.

00:26:41.100 --> 00:26:44.660
Specifically in the documentation,
we mentioned hgetvinfo.

00:26:44.780 --> 00:26:49.980
However, the problems that we have
with pbgetcatinfo are the same

00:26:49.980 --> 00:26:52.860
problems we have with pbhgetvinfo.

00:26:53.040 --> 00:26:54.860
And it tends to be very expensive.

00:26:54.860 --> 00:26:56.660
It returns a large parameter block.

00:26:56.920 --> 00:26:59.160
For most uses,
you probably just don't care

00:26:59.300 --> 00:27:00.970
about a lot of that information.

00:27:01.310 --> 00:27:05.520
And exactly analogous
to fsgetcataloginfo,

00:27:05.870 --> 00:27:08.060
there is an fsgetvoluminfo call.

00:27:08.180 --> 00:27:11.690
Again, pass in the minimal
bitmap that you require,

00:27:11.800 --> 00:27:14.030
and we will do the minimal I/O.

00:27:14.110 --> 00:27:17.500
In a lot of cases,
it will just be an in-memory copy for us,

00:27:17.630 --> 00:27:21.500
out to your param block,
and you do zero I/O.

00:27:21.980 --> 00:27:31.040
The FSRef APIs are the primary APIs and
the preferred APIs in Carbon on OS X.

00:27:31.190 --> 00:27:35.700
In fact, all of the major clients of
the file manager on OS X today,

00:27:35.700 --> 00:27:42.090
the file manager, navigation services,
and Cocoa OpenSave,

00:27:42.090 --> 00:27:48.730
all use the FSRef API and have actually
seen huge performance gains in doing so.

00:27:48.740 --> 00:27:55.740
We've seen performance gains not just
on NFS and network-based file systems,

00:27:55.740 --> 00:27:58.330
but in fact we've seen them
even on local HFS disks.

00:27:58.330 --> 00:28:02.920
So it's definitely something
worth investigating.

00:28:07.100 --> 00:28:09.340
So on to file I/O.

00:28:09.390 --> 00:28:13.980
First thing I'd like to plug here is
what some of you probably recognize

00:28:13.980 --> 00:28:16.310
as being a relatively old tech note.

00:28:16.400 --> 00:28:20.040
I think it was put out in '93 or '92,
I'm not really sure.

00:28:20.040 --> 00:28:22.160
File Manager Performance and Caching.

00:28:22.210 --> 00:28:26.460
Turns out a lot of the lessons
that are taught in that tech

00:28:26.460 --> 00:28:29.850
note are relevant today,
and I highly recommend that

00:28:29.850 --> 00:28:31.930
you go back and read that.

00:28:32.430 --> 00:28:37.310
Some of the biggest points in it,
of course, are to use large page-aligned

00:28:37.310 --> 00:28:38.500
I/O wherever you can.

00:28:38.500 --> 00:28:42.800
If you're picking through
little bits of data in a file,

00:28:43.210 --> 00:28:47.800
don't push that down to the file manager
or the file system and don't pay the

00:28:47.800 --> 00:28:51.380
system call overhead just because
you're doing little bitty writes.

00:28:51.460 --> 00:28:55.050
Do larger page-aligned I/O into
preferably page-aligned buffers

00:28:55.060 --> 00:28:58.440
and you'll get the maximum
throughput from the file system,

00:28:58.440 --> 00:29:02.910
a lot of times without even having to
do copies from the kernel buffer if you

00:29:02.910 --> 00:29:06.760
pass those page-aligned buffers as well.

00:29:07.360 --> 00:29:10.070
Again,
let me put in another plug for FS Usage.

00:29:10.180 --> 00:29:13.570
This is a great place to look,
and you can actually see exactly

00:29:13.570 --> 00:29:16.700
where reads are coming through,
writes are going through,

00:29:16.790 --> 00:29:20.540
and how much data is actually
being read per read or write.

00:29:20.690 --> 00:29:26.880
This will help you identify quickly
where you're spending a lot of your

00:29:26.900 --> 00:29:29.570
time doing a lot of small I/Os.

00:29:30.290 --> 00:29:33.640
The next point is don't
pollute the cache.

00:29:33.640 --> 00:29:36.320
This is covered in the
Performance Tech Note,

00:29:36.320 --> 00:29:40.790
and it's something that a
lot of clients overlook,

00:29:40.790 --> 00:29:46.770
and it really shouldn't be because
it tends to pay off in big wins.

00:29:51.280 --> 00:29:55.760
What I mean by not polluting the
cache is you as the app developers

00:29:56.770 --> 00:30:00.480
know exactly what your usage
pattern is going to be for any bit

00:30:00.480 --> 00:30:03.480
of data or large chunks of data.

00:30:03.800 --> 00:30:07.790
you know that if you're streaming in,
if you're importing a file that you're

00:30:07.790 --> 00:30:11.710
just not going to look at again,
say you're importing from some

00:30:11.710 --> 00:30:15.500
foreign file format into your
own internal representation,

00:30:15.500 --> 00:30:19.090
you're just not going to go back
to that file again to do the read.

00:30:19.120 --> 00:30:21.620
And if you're talking
about a multi-megabyte or,

00:30:21.620 --> 00:30:25.330
you know,
it doesn't even have to be that big,

00:30:25.400 --> 00:30:29.500
multiple hundreds of K file,
if you just do reads without

00:30:29.500 --> 00:30:34.850
passing the no-cache mask,
what you're actually doing is filling

00:30:34.850 --> 00:30:38.340
the buffer cache with data that you
know that you're never going to read.

00:30:38.380 --> 00:30:41.570
Turns out that by passing
the no-cache mask,

00:30:41.840 --> 00:30:45.800
you're not actually hurting yourself,
you're not hurting your throughput by

00:30:45.800 --> 00:30:50.390
doing those fresh reads from these files,
but by...

00:31:21.600 --> 00:31:26.830
bit to these writes you're not going
to pollute the users buffer cache and

00:31:26.840 --> 00:31:30.780
in fact you're not going to pay any
performance penalty by passing the no

00:31:30.780 --> 00:31:34.920
cache bit you're just going to make it
an overall better experience I think a

00:31:34.920 --> 00:31:40.010
big reason why this isn't used so often
is because it doesn't look like it's

00:31:40.080 --> 00:31:44.930
a performance game in other words when
you go and change your code it's really

00:31:44.930 --> 00:31:48.480
hard to see the benefit of this the
reads that you're doing are just as fast

00:31:48.480 --> 00:31:52.540
the rights that you were doing are just
as fast and if you're not if you haven't

00:31:52.600 --> 00:31:57.230
evicted pages from the buffer cache
that you really cared about you're just

00:31:57.230 --> 00:32:02.380
not going to notice but it is still very
important and I strongly encourage you to

00:32:02.430 --> 00:32:07.440
to look at to look hard at where you're
doing IO and what kind of IO you're

00:32:07.440 --> 00:32:13.460
doing and pass the no cache mask where
you can internally just a couple examples

00:32:13.460 --> 00:32:18.660
of where we use it are when we're doing
finder copies the finder is doing a

00:32:18.660 --> 00:32:18.660
copy of the no cache but it's not going
to be able to see the no cache but it's

00:32:18.660 --> 00:32:18.660
not going to be able to see the no cache
but it's not going to be able to see

00:32:18.660 --> 00:32:22.710
the no cache of a folder from A to B it
knows the finder itself knows it's never

00:32:22.710 --> 00:32:25.890
gonna or it's very likely that it's
not going to look at that data again

00:32:25.890 --> 00:32:30.510
unless the user requests it so there's
no reason to flood the entire buffer

00:32:30.530 --> 00:32:36.630
cache with these copied blocks instead
the users data can stay intact and the

00:32:36.990 --> 00:32:42.800
finder copy can execute just as quickly
as it did before the other area is in

00:32:42.940 --> 00:32:50.640
iTunes when it's encoding a file or
ripping a file from CD and writing out to

00:32:50.680 --> 00:32:55.730
disk iTunes itself knows that the chances
are very slim that it's going to actually

00:32:55.730 --> 00:33:00.810
go back and read those pages again so
it passes the no cache mask and it turns

00:33:00.980 --> 00:33:06.000
out that because of that the use the user
experience on 10 is a little bit better

00:33:06.000 --> 00:33:10.820
even though it's kind of hard to really
quantify that and look at it you kind

00:33:10.930 --> 00:33:16.110
of just have to know that it's better and
know that you're doing the right thing

00:33:20.120 --> 00:33:22.860
Okay, writing large files.

00:33:22.860 --> 00:33:27.800
One common technique that has sort of
been passed down from generation to

00:33:27.810 --> 00:33:32.860
generation is when you're writing a large
file to first do a set EOF or an FSSet

00:33:32.860 --> 00:33:38.450
fork size to the final length of the file
that you're actually writing and then

00:33:38.450 --> 00:33:41.470
back up and start filling in the data.

00:33:42.940 --> 00:33:46.720
This has a couple of advantages and
this is why it's been done over time.

00:33:46.720 --> 00:33:50.040
First of all,
it is a good pre-flight to allow you

00:33:50.040 --> 00:33:55.040
to know whether or not you have space
on the disk to actually do the IO.

00:33:55.040 --> 00:33:59.450
And then second, it's also a good way to
reserve a portion of the disk,

00:33:59.450 --> 00:34:02.250
a hopefully contiguous
portion of the disk,

00:34:02.370 --> 00:34:06.440
so that when you go back and
you're actually doing your writes,

00:34:06.440 --> 00:34:09.590
you know that you're writing
to contiguous parts of the disk

00:34:09.590 --> 00:34:12.900
and subsequent reads of that
document or that data offer.

00:34:13.030 --> 00:34:15.550
for the disk will be fast.

00:34:15.960 --> 00:34:19.740
The problem is on OS X,
for security purposes,

00:34:19.760 --> 00:34:25.300
when you extend a file,
what we do is we zero fill the entire

00:34:25.300 --> 00:34:29.800
file from the current EOF out to
the very end where you extend it.

00:34:29.800 --> 00:34:32.780
And the reason we do that, of course,
is security.

00:34:32.810 --> 00:34:37.800
We don't want some malicious
program to run on your disk,

00:34:38.060 --> 00:34:40.800
reserve as much space as possible,
and then potentially sniff through

00:34:40.800 --> 00:34:44.800
looking for social security numbers or
credit card numbers or what have you.

00:34:44.800 --> 00:34:47.800
So this is why we do the zero fill.

00:34:47.800 --> 00:34:51.160
Of course,
it has the downside of producing

00:34:51.160 --> 00:34:55.800
double I/Os in this very common
usage of the file manager.

00:34:56.510 --> 00:35:01.120
The double I/Os come from first when we
do the zero fill of that extended area,

00:35:01.160 --> 00:35:04.280
and then later on when you
actually do your write.

00:35:04.420 --> 00:35:07.830
If you write a little
app on OS X right now,

00:35:07.830 --> 00:35:11.330
that all it does is just
create and open a file and then

00:35:11.740 --> 00:35:13.760
just do a set EOF of a gig.

00:35:13.820 --> 00:35:16.250
You'll notice that before
that set EOF returns,

00:35:16.250 --> 00:35:20.980
your disk will be buzzing away,
and when you go and do a subsequent read,

00:35:20.980 --> 00:35:23.320
you'll see that it is all zero filled,
and that's exactly

00:35:23.380 --> 00:35:24.750
what I'm talking about.

00:35:25.210 --> 00:35:28.210
We're looking at ways to
fix this in the near future,

00:35:28.210 --> 00:35:30.130
but the truth of it is
we've shipped this way.

00:35:30.280 --> 00:35:32.980
This is already on customers' disks,
so it's something that you

00:35:32.980 --> 00:35:33.990
should probably address now.

00:35:34.100 --> 00:35:36.480
And fortunately,
there are a couple of ways

00:35:36.580 --> 00:35:37.960
that you can address it.

00:35:37.960 --> 00:35:40.380
You can use the PBAllocate call.

00:35:40.770 --> 00:35:42.570
This does not have the
zero-filling behavior.

00:35:42.830 --> 00:35:48.840
However, it does allow you to reserve
a portion of the disk for a

00:35:49.010 --> 00:35:51.910
contiguous file on the disk.

00:35:52.120 --> 00:35:55.460
Or the other thing you
can do is just write.

00:35:55.570 --> 00:35:56.800
Just start writing.

00:35:56.850 --> 00:35:58.750
If you're not doing,
as long as you're not doing

00:35:58.770 --> 00:36:02.370
set EOFs followed by a write,
you won't get this double I/O.

00:36:02.410 --> 00:36:05.180
If you're just doing writes
past the end of the file,

00:36:05.390 --> 00:36:09.420
then that's enough of a trigger to
the file system that any subsequent

00:36:09.420 --> 00:36:12.390
reads are just going to pick
up that data that was written,

00:36:12.390 --> 00:36:14.840
so we don't need to zero fill,
and we don't.

00:36:19.150 --> 00:36:28.570
Finally, file assumptions.

00:36:29.440 --> 00:36:29.460
I couldn't think of a
better topic for this,

00:36:29.460 --> 00:36:29.460
or heading for this slide,
so I just put this.

00:36:30.460 --> 00:36:34.900
Since the beginning
of personal computers,

00:36:34.900 --> 00:36:39.680
we've been able to make some
assumptions about the layout of

00:36:39.680 --> 00:36:44.520
disks and the layout of hardware and
usage patterns and things like that.

00:36:44.520 --> 00:36:48.930
And as we move forward,
more and more of those assumptions

00:36:49.630 --> 00:36:55.200
will prove to be false or can prove
to be false under certain situations.

00:36:55.200 --> 00:36:59.100
One of these assumptions, of course,
is that your disks or the user disk

00:36:59.490 --> 00:37:03.520
is locally attached to the machine,
that all user data is

00:37:03.520 --> 00:37:06.730
coming off of a local disk,
all preferences are coming

00:37:06.730 --> 00:37:08.530
off of a local disk,
and in fact,

00:37:08.530 --> 00:37:11.840
document directories and things
like that are on local disks.

00:37:11.900 --> 00:37:16.030
Well,
networks are getting faster all the time.

00:37:16.280 --> 00:37:17.850
Pretty much right now,
they're fast enough

00:37:17.980 --> 00:37:23.120
that in some situations,
you can actually create an environment

00:37:23.200 --> 00:37:27.000
on the disk where user preferences,
user documents,

00:37:27.020 --> 00:37:31.300
and various other bits of data are
actually stored on a network-backed disk,

00:37:31.330 --> 00:37:33.940
and it provides lots of benefits.

00:37:33.940 --> 00:37:36.830
In fact, we have this all set
up at Apple right now,

00:37:36.840 --> 00:37:40.100
where users can log into their machines.

00:37:40.120 --> 00:37:43.620
You log in in one workstation,
let's just call it.

00:37:43.650 --> 00:37:47.240
And you log in with your
username and your password.

00:37:47.270 --> 00:37:49.240
All of your preferences
come up on that one machine.

00:37:49.240 --> 00:37:55.340
You can use your documents just
as you were maybe in your office,

00:37:55.340 --> 00:37:57.280
or do whatever you want to.

00:37:57.280 --> 00:37:59.240
You get all your same preferences.

00:37:59.240 --> 00:38:02.800
You go back to your office,
all of your preferences are updated,

00:38:02.850 --> 00:38:04.310
because everything is on the network.

00:38:04.320 --> 00:38:06.740
It's a beautiful thing, this sharing.

00:38:06.790 --> 00:38:09.780
And as we move forward,
it's going to be one of those

00:38:09.780 --> 00:38:13.620
things that a lot more users
are going to be exposed to.

00:38:13.620 --> 00:38:14.620
Thank you.

00:38:15.270 --> 00:38:20.700
But it does mean some serious
considerations for your applications.

00:38:20.700 --> 00:38:23.810
In other words,
preferences and documents and

00:38:23.810 --> 00:38:27.690
things like that are no longer
going to be backed by local disk.

00:38:27.960 --> 00:38:31.630
And this can have impacts on
your code base that you're

00:38:31.630 --> 00:38:33.880
probably not even aware of.

00:38:33.880 --> 00:38:37.790
Just because when you're coding or
designing with some assumptions in mind,

00:38:37.790 --> 00:38:40.700
a lot of times you're not even aware
you're making those assumptions.

00:38:40.700 --> 00:38:44.310
And you'll tend to do things like,
let's say, "Oh,

00:38:44.310 --> 00:38:48.290
I know that I'm bringing this
data down off the network and

00:38:48.290 --> 00:38:50.700
I need to cache it somewhere.

00:38:50.700 --> 00:38:51.900
Let me cache it in the
preferences directory." Or,

00:38:51.900 --> 00:38:55.160
"Let me cache it to a temp file
in the documents directory." Well,

00:38:55.310 --> 00:38:58.700
if those directories are
backed by a network volume,

00:38:58.700 --> 00:39:01.970
you're really not buying much
by caching something off the

00:39:01.970 --> 00:39:04.220
network to another network volume.

00:39:04.490 --> 00:39:08.830
Or, this is a lot more common scenario,
when you launch your app,

00:39:08.830 --> 00:39:11.320
you're doing tiny little
I/Os to the preferences file,

00:39:11.320 --> 00:39:13.340
and this has never been a problem
because it's a local disk.

00:39:13.390 --> 00:39:14.990
It's very fast.

00:39:15.090 --> 00:39:20.130
Well, if it's a network disk,
that's a big window that you can stall

00:39:20.130 --> 00:39:23.480
in and your users will definitely notice.

00:39:23.620 --> 00:39:27.130
Trust me, we've noticed at Apple,
and we've been working with developers

00:39:27.130 --> 00:39:32.300
where we can to point out what's going
on and help them work through it.

00:39:32.370 --> 00:39:36.420
But the best thing that you can
do is try to set up one of these

00:39:36.710 --> 00:39:41.590
hostile test environments in your
own offices and see for yourself.

00:39:41.680 --> 00:39:48.900
One of the best examples of this is to
set up an NFS-based user directory and

00:39:49.060 --> 00:39:52.600
log into that user and just double-click
your app and see what happens.

00:39:52.700 --> 00:39:57.300
Or double-click your app with FS usage
running alongside and see what happens.

00:39:57.370 --> 00:40:02.200
You'll notice that if you're logged in as
either a local user or as a network user,

00:40:02.200 --> 00:40:08.700
a lot of times you'll notice a great
variation in the performance of your app,

00:40:08.700 --> 00:40:12.190
and a lot of that can be attributed
to some of these design decisions.

00:40:12.200 --> 00:40:15.920
The good news is that anything
that you fix for the network case

00:40:15.920 --> 00:40:18.200
will also benefit the local case.

00:40:18.200 --> 00:40:21.240
So if you're working off
of maybe slower media,

00:40:21.240 --> 00:40:24.080
or maybe not, say you're just working
off of fast media,

00:40:24.280 --> 00:40:27.290
you can reduce the number of system
calls that you're making and speed

00:40:27.290 --> 00:40:29.200
things up even in your local scenario.

00:40:29.200 --> 00:40:32.100
So it's definitely a good thing to do.

00:40:32.470 --> 00:40:35.850
Look into doing and
check the Mac OS X server

00:40:35.850 --> 00:40:42.100
documentation for more details.

00:40:42.100 --> 00:40:46.100
And with that,
I'll bring John back up on stage.

00:40:58.960 --> 00:41:02.730
Talk about watching the
application bounce a lot.

00:41:02.730 --> 00:41:08.170
Those network users, when you have your
system set up that way.

00:41:08.220 --> 00:41:11.440
We typically see two or three
times the number of bounces

00:41:11.440 --> 00:41:12.850
we do in a local directory.

00:41:12.900 --> 00:41:14.040
It's really something I advise.

00:41:14.100 --> 00:41:16.660
Take Nitin's advice on that one.

00:41:16.710 --> 00:41:21.030
Okay, you've learned all of the details
about what you can do to help

00:41:21.030 --> 00:41:23.540
with your file system performance.

00:41:23.640 --> 00:41:28.500
I'm going to talk a little
bit now about your CPU usage.

00:41:28.550 --> 00:41:31.850
The first thing I'd like to say is

00:41:32.320 --> 00:41:36.440
You're running on a preemptive
multitasking system,

00:41:36.440 --> 00:41:38.690
but it's not magic.

00:41:38.750 --> 00:41:43.280
It doesn't give you more than 100%
of the CPU on a single CPU system.

00:41:43.410 --> 00:41:45.990
It can't give you free cycles.

00:41:46.070 --> 00:41:48.930
Matter of fact,
basically the gain is that one

00:41:48.930 --> 00:41:52.480
single thread on that system is not
going to take over the whole system.

00:41:52.480 --> 00:41:55.810
It's not going to bring
the system to its knees.

00:41:56.910 --> 00:41:59.970
So if you have a hundred
threads that all need to run,

00:41:59.970 --> 00:42:03.170
they're all sitting there,
have something to do,

00:42:03.170 --> 00:42:06.570
even if it's very little,
the scheduler has to

00:42:06.570 --> 00:42:08.480
take them into account.

00:42:08.700 --> 00:42:12.360
That's why we talk about making
sure that your threads are blocked.

00:42:12.460 --> 00:42:15.700
That CPU is still a limited resource.

00:42:16.970 --> 00:42:22.380
So make sure when you're
using threads or timers,

00:42:22.450 --> 00:42:26.290
cooperative threads,
that you're taking this into account.

00:42:26.410 --> 00:42:29.560
The best tools on the system
to really look at this are

00:42:29.560 --> 00:42:32.110
a top time and CPU monitor.

00:42:32.200 --> 00:42:35.060
CPU monitor you've probably
seen in some of the demos.

00:42:35.100 --> 00:42:38.620
I would advise just keep that thing
running as you're doing development.

00:42:38.720 --> 00:42:41.820
Just keep it off,
maybe on a second monitor.

00:42:42.000 --> 00:42:45.150
It'll show you very easily when
there's a little bit of a CPU peak

00:42:45.390 --> 00:42:49.870
and you can go in and see,
is that your problem or not?

00:42:50.180 --> 00:42:58.530
Typically, that is a great indicator for
when you have CPU bound problems.

00:43:00.770 --> 00:43:05.990
Top is another one that you could
run because it shows you a little

00:43:05.990 --> 00:43:07.700
bit more than just CPU usage.

00:43:07.970 --> 00:43:10.490
Both of those I would encourage
as you're just doing your

00:43:10.490 --> 00:43:13.230
ongoing development on your app.

00:43:13.290 --> 00:43:17.480
Keep them running in some window
as clues to the possibility

00:43:17.480 --> 00:43:19.570
of a performance problem.

00:43:22.670 --> 00:43:24.600
So, responsiveness.

00:43:24.600 --> 00:43:30.050
This is the next area after launching
file system and CPU usage that

00:43:30.070 --> 00:43:32.060
I would encourage you to look into.

00:43:32.080 --> 00:43:35.020
Mostly things to do with responsiveness.

00:43:35.060 --> 00:43:38.830
You should be able to fix up fairly
quickly by just taking a quick

00:43:38.830 --> 00:43:40.900
look at what your app is doing.

00:43:41.000 --> 00:43:46.100
[Transcript missing]

00:43:46.580 --> 00:43:49.300
The biggest indicator that you're
not doing event handling right is

00:43:49.440 --> 00:43:52.400
probably that you're pegging the CPU.

00:43:52.470 --> 00:43:55.840
You've seen this in some demos.

00:43:55.900 --> 00:44:00.130
The best and simplest workaround
for that is maybe look around.

00:44:00.210 --> 00:44:11.180
If your app is showing this behavior,
if it's CPU bound, during tracking,

00:44:11.180 --> 00:44:11.840
during interaction with your UI.

00:44:12.960 --> 00:44:14.130
Take a look.

00:44:14.430 --> 00:44:16.880
Use Sampler,
which is a tool that lets you

00:44:16.880 --> 00:44:20.640
actually pinpoint where in
your code the problem lies.

00:44:21.310 --> 00:44:21.900
Search your code.

00:44:22.080 --> 00:44:24.980
Search your code for
still down and button.

00:44:25.040 --> 00:44:28.100
And look at how you're using -- how
you're calling these older calls that

00:44:28.100 --> 00:44:31.260
we really would rather you get off of.

00:44:31.320 --> 00:44:32.950
Track mouse location is your friend.

00:44:33.090 --> 00:44:34.520
That's what you want to be using.

00:44:34.580 --> 00:44:38.270
That's the basic primitive for
letting you do all sorts of tracking

00:44:38.270 --> 00:44:41.530
in the UI that blocks intelligently.

00:44:43.690 --> 00:44:48.370
So after event handling-- oh,
in addition to those tools,

00:44:48.370 --> 00:44:50.600
I would encourage you to
look on a developer CD.

00:44:50.680 --> 00:44:53.310
There's an application
called Appearance Sample,

00:44:53.340 --> 00:44:57.120
which has almost every
widget the toolbox supports,

00:44:57.120 --> 00:44:58.840
every control you've ever seen.

00:44:58.850 --> 00:44:59.920
Go and play with that app.

00:44:59.920 --> 00:45:01.860
Run CPU Monitor.

00:45:01.860 --> 00:45:05.450
You'll see all of those
controls block well.

00:45:05.540 --> 00:45:07.720
That's what your app should do.

00:45:07.720 --> 00:45:09.640
If you're seeing different
behavior in your app,

00:45:09.640 --> 00:45:14.150
it's either a problem in that you've
done your own kind of handling,

00:45:14.150 --> 00:45:16.720
your own custom control,
or potentially in the way

00:45:16.720 --> 00:45:18.130
that you're using the toolbox.

00:45:21.490 --> 00:45:24.850
The next area that contributes
to your app's responsiveness,

00:45:24.850 --> 00:45:27.290
you know,
maybe it feels a little sluggish.

00:45:27.370 --> 00:45:28.790
Maybe everything else is looking good.

00:45:28.830 --> 00:45:31.000
Your file system performance
in your launch is good,

00:45:31.160 --> 00:45:35.650
but when you activate Windows,
things don't appear as snappy as they do,

00:45:35.650 --> 00:45:36.800
say, online.

00:45:36.910 --> 00:45:40.400
That's probably an indication
that you have a drawing problem.

00:45:40.400 --> 00:45:43.370
The best tool for that is Quartz Debug.

00:45:43.400 --> 00:45:45.400
You've probably seen it in
some of the other sessions.

00:45:45.400 --> 00:45:48.550
It should be in the
Performance Tool session as well.

00:45:48.590 --> 00:45:51.390
Because it'll let you see when
you're doing redundant drawing,

00:45:51.390 --> 00:45:54.930
when you're drawing the
same things over and over.

00:45:55.800 --> 00:46:02.560
The other typical pitfall that
we've seen is people back buffering,

00:46:02.560 --> 00:46:07.480
doing their own double buffering
for their drawing when the system

00:46:07.480 --> 00:46:09.200
is already doing that for them.

00:46:09.280 --> 00:46:14.770
So make sure you check the port using QD,
is port buffered, and if it is,

00:46:14.770 --> 00:46:16.870
then you don't have to do
that buffering yourself.

00:46:17.020 --> 00:46:19.120
That's being done for you.

00:46:21.410 --> 00:46:26.180
The next area on responsiveness
has to do with flushing.

00:46:26.270 --> 00:46:29.500
Because you have a back buffer,
it means there has to be a time

00:46:29.500 --> 00:46:34.030
when you actually get those bits
in a back buffer to the screen.

00:46:34.530 --> 00:46:37.750
Generally,
you should try to avoid flushing.

00:46:37.830 --> 00:46:41.730
The system will do flushing for
you basically on event boundaries.

00:46:41.810 --> 00:46:45.130
It'll try to do that as
intelligently as possible.

00:46:45.140 --> 00:46:47.190
So you shouldn't have to flush.

00:46:47.300 --> 00:46:52.590
The two examples of exceptions are when
you're doing some kind of animation,

00:46:52.600 --> 00:46:55.900
you want that to get to
the screen right now,

00:46:55.900 --> 00:46:59.120
or when you're not really
involved with events at all,

00:46:59.190 --> 00:47:00.880
the splash screen case.

00:47:00.900 --> 00:47:03.620
Those are good uses of explicit flushing.

00:47:03.760 --> 00:47:07.260
Otherwise, let the system do it for you.

00:47:08.540 --> 00:47:14.570
Another common performance problem area
is with regards to window resizing.

00:47:14.820 --> 00:47:18.540
This also has to do with the
back buffer and the design

00:47:18.540 --> 00:47:20.700
of the window system on OS X.

00:47:20.940 --> 00:47:23.650
Basically,
our advice there is to try to do this all

00:47:23.760 --> 00:47:28.130
in one fell swoop with set window bounds,
instead of trying to use size window

00:47:28.130 --> 00:47:30.560
and move window in combination.

00:47:30.750 --> 00:47:34.560
That's what that call exists for,
to optimize those cases.

00:47:34.690 --> 00:47:39.060
Also, the other thing that we've seen
with regard to Windows is pervasive

00:47:39.060 --> 00:47:42.280
or heavy use of invisible Windows.

00:47:42.310 --> 00:47:45.820
Windows are generally
more expensive on OS X.

00:47:45.850 --> 00:47:48.040
The back buffer,
in addition the overhead,

00:47:48.040 --> 00:47:51.460
the interaction with the core
graphics system in the Windows Server.

00:47:51.600 --> 00:47:53.410
You may have invisible Windows.

00:47:53.640 --> 00:47:55.450
That doesn't mean that
they don't cost anything.

00:47:55.460 --> 00:47:59.650
That manipulating invisible
Windows doesn't come for free.

00:47:59.660 --> 00:48:02.550
As a matter of fact,
I would look into why you're

00:48:02.550 --> 00:48:04.160
using invisible Windows.

00:48:04.160 --> 00:48:07.370
It is often the case that
you can ditch that window,

00:48:07.410 --> 00:48:12.060
dispose it, create a new one,
and redraw faster than you can by

00:48:12.200 --> 00:48:14.660
twiddling that invisible window.

00:48:15.900 --> 00:48:19.730
The last one I wasn't going
to put on here at all,

00:48:19.730 --> 00:48:22.400
but I figured I would try
some of the tools and look at

00:48:22.470 --> 00:48:24.980
various apps a couple days ago.

00:48:25.090 --> 00:48:30.360
And I just happened to notice that one
of the apps that I use every day was

00:48:30.360 --> 00:48:33.590
doing file I/O when I activated a window.

00:48:33.830 --> 00:48:36.540
And I'm sitting here scratching my head,
trying to figure this out.

00:48:36.730 --> 00:48:38.200
And it's just a bug.

00:48:38.200 --> 00:48:40.610
But this is one of those things
that you probably wouldn't notice

00:48:40.610 --> 00:48:43.400
unless you're running a tool that
tells you that that's happening.

00:48:43.450 --> 00:48:45.520
FS Usage is perfect for that.

00:48:45.610 --> 00:48:49.220
FS Usage lets you basically see
the file I/O that's going on in the

00:48:49.220 --> 00:48:53.490
whole system and a particular app.

00:48:53.570 --> 00:48:55.770
You can filter things out.

00:48:56.370 --> 00:48:59.270
Another use if you're
really going after file,

00:48:59.270 --> 00:49:04.730
anything in particular, is Sampler,
which lets you tie the usage

00:49:04.820 --> 00:49:06.980
pattern back to your code.

00:49:08.130 --> 00:49:10.090
Okay, pulling versus blocking.

00:49:10.090 --> 00:49:13.820
I'm sure you've heard this
a lot in various talks.

00:49:14.850 --> 00:49:20.360
I'm going to talk a little bit about some
of the more atypical situations in which

00:49:20.360 --> 00:49:24.390
you find polling affecting performance.

00:49:25.340 --> 00:49:27.840
WaitNext Event is
actually pretty typical,

00:49:27.840 --> 00:49:34.860
but the fallout of using WaitNext Event 0
is where we sometimes see some problems.

00:49:34.950 --> 00:49:36.850
So just to make sure we're
all on the same page here,

00:49:36.970 --> 00:49:40.110
you really shouldn't be
using WaitNext Event 0.

00:49:40.300 --> 00:49:43.880
The very simple way to get rid of the
WaitNext Event 0 is if you have something

00:49:43.880 --> 00:49:48.090
that you want to do periodically,
set a Carbon event timer to do

00:49:48.220 --> 00:49:52.760
it with the frequency that you
need and use WaitNext Event.

00:49:52.800 --> 00:49:54.910
Very long time now.

00:49:56.680 --> 00:50:00.690
Time and tick count.

00:50:00.690 --> 00:50:04.330
It's something that
surprised a few of us,

00:50:04.360 --> 00:50:08.750
basically, that we did some performance
profiling and various apps show

00:50:08.910 --> 00:50:13.640
up that tick count is taking up
a significant amount of time.

00:50:13.700 --> 00:50:19.440
And one of the reasons is that tick
count costs more than Adonis on OS 9.

00:50:19.920 --> 00:50:25.480
But it's also used all over the
place in a lot of UI in places where

00:50:25.500 --> 00:50:27.370
it really doesn't have to be used.

00:50:27.510 --> 00:50:29.100
First of all,
we're talking about something

00:50:29.100 --> 00:50:30.600
that's fairly coarse-grained,
right?

00:50:30.850 --> 00:50:32.880
Ticks, 60ths of a second.

00:50:32.960 --> 00:50:38.670
Calling it more often than 60 times
a second doesn't make a lot of sense.

00:50:42.040 --> 00:50:46.870
So the best advice I have for you here
is to try to use the event system.

00:50:47.110 --> 00:50:51.170
Try to use the timestamps that are in
events and look at events like that.

00:50:51.180 --> 00:50:55.690
There's often comparisons
made to the time now.

00:50:56.110 --> 00:51:00.270
That can get you out of polling
essentially for tick count and have it

00:51:00.270 --> 00:51:03.030
show up in being a performance problem.

00:51:03.530 --> 00:51:10.610
Another often asked for bit of
information is the volume list.

00:51:10.620 --> 00:51:15.180
Nitin went through earlier how to
do that as efficiently as possible.

00:51:15.190 --> 00:51:20.020
But I think it's a pretty rare case
where you actually need the volume list.

00:51:20.050 --> 00:51:24.610
I would suggest you just get
rid of that code altogether or

00:51:25.270 --> 00:51:26.340
figure out what you really need.

00:51:26.340 --> 00:51:28.740
If you're trying to find out
about new volumes or if you're

00:51:28.740 --> 00:51:32.430
trying to find out about volumes
that have just been unmounted,

00:51:32.870 --> 00:51:36.500
register yourself for a Carbon event
for volume mount and unmount.

00:51:36.550 --> 00:51:39.550
Ask the system to tell you about it
instead of periodically going out

00:51:39.590 --> 00:51:44.390
and looking at all the volumes and
trying to figure out what happened.

00:51:45.440 --> 00:51:48.350
Same kind of thing goes for
preference change notifications.

00:51:48.460 --> 00:51:50.610
There's a theme change app event.

00:51:50.820 --> 00:51:55.900
There's various new Carbon events
that let you know about things.

00:51:56.010 --> 00:51:58.580
Actually, up on the volume slider,
I should probably also have

00:51:58.610 --> 00:52:00.020
another bullet for processes.

00:52:00.060 --> 00:52:03.800
If you're trying to find out what process
just got launched or what process died,

00:52:03.860 --> 00:52:06.390
there's a Carbon event for that as well.

00:52:06.690 --> 00:52:08.940
Generally,
we've been really looking at the

00:52:08.940 --> 00:52:12.550
system to try to find out if there's
any legitimate need to do polling.

00:52:12.560 --> 00:52:14.220
The answer should be no.

00:52:14.270 --> 00:52:19.160
We're trying to notify you of everything
that you might find of interest.

00:52:19.160 --> 00:52:21.640
It's a much better solution on OS X.

00:52:21.840 --> 00:52:24.770
So if you guys see things that you
still think you have to poll for,

00:52:24.780 --> 00:52:25.740
let us know about it.

00:52:25.770 --> 00:52:28.160
We'll figure out a better way to do it.

00:52:28.330 --> 00:52:31.150
And on this final note,
maybe some of you have heard this

00:52:31.310 --> 00:52:38.730
bit in the application packaging and
document binding presentation yesterday.

00:52:38.820 --> 00:52:43.040
We need notification too,
particularly in the parts of the system

00:52:43.040 --> 00:52:47.360
that present the file system visually.

00:52:47.480 --> 00:52:52.480
So in the finder, in nav services,
in the open save panel,

00:52:52.510 --> 00:52:55.050
those are showing you
the file system objects.

00:52:55.160 --> 00:52:56.410
They're not polling.

00:52:56.510 --> 00:52:57.710
We don't poll.

00:52:57.820 --> 00:53:01.400
So we need you guys to,
if you participate in this kind of thing,

00:53:01.400 --> 00:53:04.400
if you're an installer or if
you're copying files to a place

00:53:04.400 --> 00:53:08.860
that is likely to be visible,
to use the FN notify call.

00:53:08.950 --> 00:53:11.810
FN notify is a 10 only API.

00:53:11.810 --> 00:53:13.210
It's in files.h.

00:53:13.320 --> 00:53:17.920
Basically says something happened,
something changed in this directory.

00:53:17.980 --> 00:53:19.620
It takes an FS ref.

00:53:19.720 --> 00:53:23.570
It lets us know that something
changed and we should refresh

00:53:23.890 --> 00:53:25.060
the contents of that directory.

00:53:25.140 --> 00:53:28.670
in any UI elements that care.

00:53:28.920 --> 00:53:30.420
Do this intelligently.

00:53:30.510 --> 00:53:34.890
If you're copying a whole bunch
of files to a single directory,

00:53:35.030 --> 00:53:37.140
let us know when you're done
with that copy operation,

00:53:37.140 --> 00:53:39.290
not at every file.

00:53:41.530 --> 00:53:43.400
Okay, resource manager use.

00:53:43.400 --> 00:53:46.700
The resource manager is very
tied to the file manager.

00:53:46.750 --> 00:53:51.490
So in essence,
I could just repeat what Nitin said

00:53:51.710 --> 00:53:54.770
earlier about the file manager.

00:53:54.770 --> 00:53:54.770
But, um,

00:53:55.670 --> 00:54:00.490
It's actually worse in that the
resource file format was designed

00:54:00.560 --> 00:54:06.800
way before VM systems were really
commercial like they are now.

00:54:06.910 --> 00:54:12.960
And really the file format is not
designed for a VM system in that

00:54:13.420 --> 00:54:17.460
there's a resource map in one
part of the file and resource data

00:54:17.460 --> 00:54:18.600
in the other part of the file.

00:54:18.600 --> 00:54:23.370
And there's no way around going to
both places every time you need data.

00:54:23.870 --> 00:54:25.120
You're asking for a resource.

00:54:25.240 --> 00:54:29.440
You have to go look up where the resource
is in the file in the resource map.

00:54:29.580 --> 00:54:32.960
That's at least one I/O.

00:54:33.090 --> 00:54:36.200
Then you've got to go to where
it told you the resource was.

00:54:36.200 --> 00:54:38.320
That's a second I/O.

00:54:38.570 --> 00:54:40.160
Okay, that's bad enough.

00:54:40.180 --> 00:54:42.500
Then you look at what's in a
typical resource file and you

00:54:42.500 --> 00:54:45.920
see lots of little resources.

00:54:46.200 --> 00:55:00.700
[Transcript missing]

00:55:01.280 --> 00:55:02.760
Coalescing of your resources.

00:55:02.760 --> 00:55:06.540
If you have resources that, for example,
stir resources that could

00:55:06.680 --> 00:55:09.590
be combined in a stir pound,
it's a much better use

00:55:09.600 --> 00:55:11.000
of the Resource Manager.

00:55:11.030 --> 00:55:15.220
Going and reading eight bytes out of
the Resource Manager is about one of the

00:55:15.320 --> 00:55:17.770
most expensive kinds of I/O you can do.

00:55:18.550 --> 00:55:21.500
The other thing that we see
with regards to resources,

00:55:21.590 --> 00:55:25.090
particularly in the use of plug-ins,
is enumerating your plug-ins,

00:55:25.200 --> 00:55:29.060
opening up their resource files
to find out something about them.

00:55:29.110 --> 00:55:34.020
Opening and closing the same files
is a pattern that we've seen and

00:55:34.020 --> 00:55:36.790
we'd really like you to avoid that.

00:55:37.320 --> 00:55:39.310
Perhaps what you can do
is cache that and open,

00:55:39.310 --> 00:55:44.090
you know, cache the results in
one file and open that.

00:55:45.210 --> 00:55:47.340
Minimally,
make sure that you just do that

00:55:47.550 --> 00:55:51.370
scan once when you actually have
to find out about your plugins.

00:55:52.790 --> 00:55:56.460
And then for historical reasons,
just lots of calls to update res file,

00:55:56.460 --> 00:56:01.910
which writes out the map and the
data for your resource forks.

00:56:02.270 --> 00:56:03.760
Just kind of call it willy-nilly.

00:56:03.760 --> 00:56:06.310
It's more like a flush
from people's minds,

00:56:06.340 --> 00:56:08.490
and that causes I/O.

00:56:09.310 --> 00:56:14.370
Okay, the last bullet item on here is
something that we added to OS X,

00:56:14.560 --> 00:56:18.590
basically a feature in the
Resource Manager to kind of help

00:56:18.860 --> 00:56:22.890
out with these sets of problems.

00:56:23.590 --> 00:56:31.740
What we did is add a new key to your
Info.plist called CSResourceFileMapped.

00:56:31.770 --> 00:56:35.550
And if you set this, it's a Boolean key,
if you set this to true,

00:56:35.550 --> 00:56:38.850
it'll change the behavior of the
resource manager with respect

00:56:39.320 --> 00:56:41.140
to your application's resources.

00:56:41.220 --> 00:56:46.200
What it'll do is it'll open them up,
read only, okay, you can't write to them,

00:56:46.260 --> 00:56:48.140
and it'll file map them.

00:56:48.180 --> 00:56:52.170
And then there's some support
in the memory manager.

00:56:52.300 --> 00:56:57.000
to support file mapping so that
we don't have to allocate for the

00:56:57.000 --> 00:57:01.680
data that's in your resource fork,
which saves on your memory footprint.

00:57:01.680 --> 00:57:04.620
And because it's all file mapped now,
we get a lot better

00:57:04.700 --> 00:57:09.100
characteristics of I/O because,
yes, we're still hitting that resource

00:57:09.100 --> 00:57:13.380
map and we're still hitting the data,
but there's some locality there.

00:57:13.380 --> 00:57:15.660
When we go to the resource
map the second time,

00:57:15.660 --> 00:57:18.380
it's likely to be on the same page.

00:57:18.380 --> 00:57:20.770
And when we go for data,
if you're going through

00:57:20.770 --> 00:57:23.360
data of a certain type,
this will depend on the

00:57:23.440 --> 00:57:26.060
organization of the data,
it's likely that we're going

00:57:26.110 --> 00:57:27.750
to get some good win there.

00:57:28.090 --> 00:57:30.250
The only caveat to this,
and the reason why we didn't

00:57:30.250 --> 00:57:35.870
turn this behavior on by default,
is that it'll break some of your code.

00:57:36.070 --> 00:57:42.640
At the point where you say, "Yes,
turn this on," then all of the

00:57:42.640 --> 00:57:47.770
resource handles that you get back,
essentially the pointers in them,

00:57:47.770 --> 00:57:50.000
point to read-only memory.

00:57:50.080 --> 00:57:54.810
If you try to modify that,
your application is going to crash.

00:57:55.990 --> 00:57:59.500
So there's plenty of folks who
have just turned this on and

00:57:59.500 --> 00:58:01.690
don't write back to the resources,
right?

00:58:01.840 --> 00:58:04.380
I mean, in general, particularly the
application resource file,

00:58:04.390 --> 00:58:08.140
you probably don't want to write to
because it might be living on a CD,

00:58:08.140 --> 00:58:11.300
it might be reading on a network
volume that other people are using.

00:58:11.390 --> 00:58:13.160
In general, it's bad practice.

00:58:13.220 --> 00:58:15.960
But let's say you were writing
things to the resource but not

00:58:15.960 --> 00:58:18.100
actually flushing them out to file.

00:58:18.220 --> 00:58:20.340
You can still do that.

00:58:20.540 --> 00:58:24.230
By detaching the resource,
thereby getting an in-memory copy,

00:58:24.230 --> 00:58:26.030
mess with the copy,

00:58:26.230 --> 00:58:28.740
and everything else
still works correctly.

00:58:28.820 --> 00:58:31.900
So this is something that you have
to turn on yourself and it's fairly

00:58:31.900 --> 00:58:37.040
straightforward to debug because
it basically leads to crashes.

00:58:37.200 --> 00:58:41.130
And if you have any questions about
exactly what the Info P-List is,

00:58:41.130 --> 00:58:45.220
I would recommend looking
at Tech Note 2013.

00:58:47.200 --> 00:58:51.000
Okay, the next section is memory usage.

00:58:51.070 --> 00:58:55.930
This can be a real big problem on 10,
largely because of the big

00:58:56.350 --> 00:59:01.260
difference between the memory models,
in that you just have a very

00:59:01.260 --> 00:59:03.590
large and sparse address space.

00:59:03.710 --> 00:59:07.460
For example, just right off the bat,
you could accidentally allocate,

00:59:07.460 --> 00:59:10.090
you know,
order magnitude off what you intended

00:59:10.090 --> 00:59:11.600
to allocate and not even know it.

00:59:11.600 --> 00:59:13.200
The system will give it to you.

00:59:13.330 --> 00:59:17.240
Memful errors are relatively
rare on this system.

00:59:17.410 --> 00:59:20.090
And that could be a problem.

00:59:20.170 --> 00:59:23.140
So in order to keep on top of this,
I really would recommend getting

00:59:23.220 --> 00:59:28.090
familiar with both the leaks
and the malloc debug tools.

00:59:28.140 --> 00:59:31.130
Leaks in particular you
want to keep an eye on.

00:59:31.260 --> 00:59:36.570
You may not notice the performance
necessarily so much in your app.

00:59:36.670 --> 00:59:43.580
It may be that a slow leak over time,
but it really does affect what's going

00:59:43.580 --> 00:59:46.180
on underneath the covers in that,
you know, you don't get reuse of

00:59:46.180 --> 00:59:47.290
the same memory blocks.

00:59:47.290 --> 00:59:49.300
It'll lead to paging.

00:59:49.300 --> 00:59:51.300
It'll lead to general
bad characterizations.

00:59:51.300 --> 00:59:57.300
It'll lead to your app
generally feeling sluggish.

00:59:57.380 --> 00:59:59.960
Aside from leaks,
I would really recommend that

01:00:00.050 --> 01:00:04.300
you get a good handle on the
size of your application.

01:00:04.330 --> 01:00:07.060
Particularly,
make sure your tools are doing

01:00:07.080 --> 01:00:09.300
the work that they should for you.

01:00:09.300 --> 01:00:13.280
Make sure that

01:00:13.520 --> 01:00:17.800
Things that are actually constant in your
application end up in the right section

01:00:17.800 --> 01:00:22.640
so that they don't get-- so that the
OS takes the maximum advantage of that.

01:00:22.700 --> 01:00:25.780
We went through a lot of the
Carbon frameworks early on and

01:00:26.000 --> 01:00:27.880
got a lot of gains by doing this.

01:00:27.940 --> 01:00:31.990
Basically marking strings and other
constant sections as constant so

01:00:31.990 --> 01:00:37.120
that they show up in a text section
that gets shared across the system.

01:00:37.220 --> 01:00:39.380
Same thing goes for your app.

01:00:40.440 --> 01:00:44.930
The third thing on memory usage
is there's really been a reversal

01:00:45.520 --> 01:00:49.800
in terms of handles and pointers.

01:00:50.230 --> 01:00:54.600
On OS 9, the handle was really
the first class citizen.

01:00:54.600 --> 01:00:59.840
It was designed to work with that
limited application partition,

01:00:59.840 --> 01:01:02.650
that heap,
and it was designed to be reused

01:01:02.650 --> 01:01:04.740
inside that limited space.

01:01:04.870 --> 01:01:07.350
On 10, the reverse is the case.

01:01:07.500 --> 01:01:09.510
Pointers are really the
first class citizens and

01:01:09.510 --> 01:01:12.240
there's some cost to handles.

01:01:12.340 --> 01:01:17.310
So in performance critical code,
look at rewriting to use

01:01:17.470 --> 01:01:23.120
pointers instead of handles.

01:01:23.120 --> 01:01:23.120
We found one case where

01:01:23.370 --> 01:01:28.400
Just removal of HLock and HUnlock
in this code path made a big

01:01:28.400 --> 01:01:30.500
difference in terms of performance.

01:01:30.500 --> 01:01:34.490
The reason there was that

01:01:36.910 --> 01:01:43.660
The locking costs are sufficiently
higher on 10 than they are on 9.

01:01:43.660 --> 01:01:48.970
And what work had to be done
was really impacted by that.

01:01:48.980 --> 01:01:52.120
And this is something that you
should do kind of carefully.

01:01:52.140 --> 01:01:54.350
The OS itself-- I mean,
if you're looking into this

01:01:54.450 --> 01:01:58.640
kind of an optimization,
the OS itself doesn't rely or

01:01:58.660 --> 01:02:03.180
doesn't go and purge and move
handles out from under you.

01:02:03.180 --> 01:02:05.540
That's really under your control on 10.

01:02:05.540 --> 01:02:08.810
And so if you know that
you're not resizing the handle

01:02:08.820 --> 01:02:12.380
somewhere else in your code,
if you know that you're not looking

01:02:12.380 --> 01:02:16.920
at the handle to see if it's locked,
then you're likely able to make

01:02:16.920 --> 01:02:19.260
this kind of an optimization.

01:02:22.160 --> 01:02:26.000
Then lastly, I hope it's pretty obvious,
is there's really no purging.

01:02:26.000 --> 01:02:27.760
The calls are still there.

01:02:27.880 --> 01:02:31.000
They're largely there so you can
run the same app on both 9 and 10.

01:02:31.000 --> 01:02:33.820
But your purge procs are
not going to get called.

01:02:33.820 --> 01:02:37.000
The application heap is
not going to fill up.

01:02:37.000 --> 01:02:39.300
And if you're relying
on basically allocating,

01:02:39.340 --> 01:02:42.440
allocating, allocating until you get
called in your purge proc,

01:02:42.440 --> 01:02:44.000
that's not going to happen.

01:02:44.000 --> 01:02:47.000
That's the biggest
leak you can ever have.

01:02:47.180 --> 01:02:53.740
So take a look at that if you're
in that kind of a category.

01:02:54.250 --> 01:02:57.800
Okay, code loading.

01:02:57.820 --> 01:03:02.880
This is something that kind of referred
to earlier on in launching a bit in

01:03:03.090 --> 01:03:06.730
that I said something to the effect
of defer some of the things that

01:03:06.730 --> 01:03:08.570
you do at launch time to later on.

01:03:08.680 --> 01:03:13.050
And one of the ways in which you
can do this is to factor your app.

01:03:13.200 --> 01:03:21.790
Most application code bases start
off and are organized basically by

01:03:21.790 --> 01:03:25.200
the people that work on them first.

01:03:25.200 --> 01:03:34.430
So you get Kelly's feature and Mary's
feature and John's feature and they go

01:03:34.500 --> 01:03:37.200
off and do those different pieces of it.

01:03:37.200 --> 01:03:40.200
And then Nitin comes along and
he has a new feature to add.

01:03:40.200 --> 01:03:43.200
And pretty soon you've got one
little piece of code that you

01:03:43.200 --> 01:03:43.200
can add to your application.

01:03:43.200 --> 01:03:46.090
And then you add the rest of the app,
whether it's a shared

01:03:46.090 --> 01:03:49.090
library or a plug-in,
for each person that's working on it.

01:03:49.200 --> 01:03:51.600
And soon those features grow
up and there's a whole team

01:03:51.660 --> 01:03:53.200
around each of those features.

01:03:53.200 --> 01:03:55.820
And before you know it,
the organization of your app

01:03:55.950 --> 01:03:59.570
looks a little bit like the
organization -- your organization,

01:03:59.570 --> 01:04:00.200
right?

01:04:01.820 --> 01:04:05.800
And that's rarely the best
organization in terms of performance.

01:04:05.800 --> 01:04:09.940
You really want to look at the features
in terms of what the app really needs.

01:04:10.000 --> 01:04:12.790
Probably want to look at
layering and dependencies.

01:04:12.870 --> 01:04:16.070
So factoring in your app in
terms of performance is something

01:04:16.070 --> 01:04:17.710
that I would advise you to do.

01:04:17.800 --> 01:04:21.560
It's usually not something
that you would do quickly.

01:04:21.590 --> 01:04:24.580
It's something you probably
converge on over time.

01:04:25.350 --> 01:04:30.090
Look at plugins for things
that are truly optional.

01:04:30.510 --> 01:04:35.170
Again, I don't mean this is optional in
the sense no one would use it.

01:04:35.200 --> 01:04:41.180
An example of this in the RealLive
OS is nav services and printing.

01:04:41.180 --> 01:04:47.380
Those are both good categories from the
OS's point of view of services that are

01:04:47.390 --> 01:04:53.340
purely optional in that the application,
your application, can run fine,

01:04:53.340 --> 01:04:56.080
do lots of good work,
and never interact with

01:04:56.080 --> 01:04:57.140
nav services or printing.

01:04:57.140 --> 01:05:00.710
So why should they pay the cost up front?

01:05:01.100 --> 01:05:02.800
The answer is that it shouldn't.

01:05:02.880 --> 01:05:05.350
So look for those kind of
opportunities in your app.

01:05:05.440 --> 01:05:09.260
Maybe there's a plug-in that
has all the bells and whistles

01:05:09.330 --> 01:05:13.500
that you could ever want,
but you only use it once in a blue moon.

01:05:13.560 --> 01:05:16.370
Factor that out so you don't
pay any costs for that.

01:05:16.530 --> 01:05:23.390
Don't give that plug-in
an initial load and say,

01:05:23.390 --> 01:05:23.390
are you happy with things?

01:05:23.390 --> 01:05:23.390
That'll cost.

01:05:23.510 --> 01:05:27.260
Then finally, look at your libraries,
look at the number of

01:05:27.260 --> 01:05:29.380
libraries that you're using.

01:05:29.620 --> 01:05:32.600
Libraries, when backed by files,
are costs.

01:05:32.810 --> 01:05:34.730
They're costs all the
way down to kernels.

01:05:34.810 --> 01:05:37.040
The kernel has a fixed cost.

01:05:37.200 --> 01:05:41.080
There's a per process cost.

01:05:41.250 --> 01:05:45.190
If your tools support it,
take libraries and combine them together.

01:05:45.200 --> 01:05:49.200
Merge your PEF libraries
together into one big file.

01:05:49.200 --> 01:05:51.740
That's infinitely better
from a performance and

01:05:51.740 --> 01:05:53.350
resource use point of view.

01:05:55.620 --> 01:06:00.750
Okay, in the async I/O space,
we've seen some problems that

01:06:00.750 --> 01:06:05.090
are kind of interesting in the
combination of async I/O and threading.

01:06:05.350 --> 01:06:08.610
Asynchronous I/O on 10.

01:06:08.980 --> 01:06:14.030
By that I mean deferred task,
file manager, time manager.

01:06:14.030 --> 01:06:24.170
Those are all implemented based
on running the operation in

01:06:24.210 --> 01:06:30.080
question synchronously on a thread
that the OS creates for you.

01:06:31.560 --> 01:06:35.230
Particularly when used with cooperative
threads or were used combined,

01:06:35.290 --> 01:06:37.660
there's additional costs there.

01:06:37.690 --> 01:06:41.840
In general, this is not performing as
well as the equivalent on 9.

01:06:41.860 --> 01:06:45.270
This is a case where I would recommend
continuing to do async I/O and

01:06:45.310 --> 01:06:48.480
chain completion routines on 9,
factoring your app and

01:06:48.480 --> 01:06:50.760
dynamically checking,
and doing something

01:06:50.760 --> 01:06:52.300
entirely different on 10.

01:06:52.320 --> 01:06:56.480
The simplest workaround or the simplest
solution on 10 is really just to use

01:06:56.620 --> 01:06:59.400
threading in a synchronous I/O model.

01:07:00.420 --> 01:07:03.960
And then just a data point we ran
with one of-- there was an app or

01:07:03.960 --> 01:07:06.890
two that we've seen that implement
threaded packages-- threading

01:07:06.890 --> 01:07:09.530
packages on top of the Time Manager.

01:07:09.790 --> 01:07:13.540
The Time Manager is itself
implemented as a thread.

01:07:13.820 --> 01:07:17.510
Which means you're threading on top of
a thread that's scheduled by the kernel,

01:07:17.510 --> 01:07:20.810
which is you're trying to run threads
on top of something that's already

01:07:21.020 --> 01:07:22.800
being managed by something else.

01:07:22.940 --> 01:07:25.950
Not a good performance solution.

01:07:30.740 --> 01:07:34.760
In the context of cooperative threads,
there's one basic flaw

01:07:34.860 --> 01:07:36.730
with cooperative threads.

01:07:36.730 --> 01:07:40.340
And that is that in order for
cooperative threads to get scheduled,

01:07:40.380 --> 01:07:43.400
you have to yield,
and there's no blocking going on.

01:07:43.550 --> 01:07:49.890
So by their very nature,
cooperative threads are compute bound.

01:07:50.760 --> 01:07:51.730
That's the biggest problem.

01:07:51.730 --> 01:07:54.200
They're still there because we know
you have code that depends on it.

01:07:54.300 --> 01:07:56.970
I would really look at not
using cooperative threads

01:07:57.030 --> 01:08:01.640
or potentially using timers,
Carbon event timers instead,

01:08:01.810 --> 01:08:05.480
or moving your code off to MP threads.

01:08:07.270 --> 01:08:14.870
Often there's a performance problem with
regards to messaging between threads.

01:08:15.230 --> 01:08:19.670
This usually has to do with
messaging as opposed to,

01:08:20.260 --> 01:08:26.150
or polling to see if some message-based
thing is complete versus true messaging.

01:08:26.270 --> 01:08:28.240
And there I would just encourage,
if you're doing things

01:08:28.240 --> 01:08:30.910
with multiple threads,
even across processes,

01:08:30.910 --> 01:08:34.920
make sure that you're not getting
in a situation where both of

01:08:34.920 --> 01:08:37.590
the threads are competing.

01:08:37.880 --> 01:08:43.370
The case in the data point that
I have was basically one thread

01:08:43.440 --> 01:08:48.470
was doing a lot of file I/O and
was reading and writing to a file.

01:08:48.530 --> 01:08:52.140
The first thread was basically
looking to see if it was done.

01:08:52.180 --> 01:08:55.300
And the cleaner solution to that and the
better performing solution is basically

01:08:55.300 --> 01:09:00.740
have the second thread just block and
when the file I/O thread is completed,

01:09:00.940 --> 01:09:05.520
just send it a Carbon event to
get that whole thing to work well.

01:09:05.600 --> 01:09:08.530
And then finally,
seeing situations where basically

01:09:08.530 --> 01:09:10.260
people just go thread happy.

01:09:10.290 --> 01:09:13.820
They have just way too many threads
for no real apparent reason.

01:09:13.860 --> 01:09:18.450
And just bear in mind that each one
of those threads has a real cost.

01:09:18.520 --> 01:09:24.210
There's a wired memory cost in
the kernel and they're not free.

01:09:24.250 --> 01:09:27.710
So use them diligently.

01:09:32.190 --> 01:09:36.200
And then finally,
threading in general can be used to

01:09:36.200 --> 01:09:39.260
really help out with performance.

01:09:39.950 --> 01:09:42.390
I would say look,
particularly look for things like

01:09:42.500 --> 01:09:46.170
when you're trying to do a safe
save or a fast save kind of feature.

01:09:46.580 --> 01:09:48.390
That's a very good use of a thread.

01:09:48.440 --> 01:09:52.160
You can create the thread,
do the work on it, and dispose it.

01:09:52.220 --> 01:09:55.090
A network listener is another
model that works really well

01:09:55.100 --> 01:09:59.460
where the thread is just basically
listening for incoming activity.

01:09:59.580 --> 01:10:04.760
And occasionally there's good use
for threading when you're doing low

01:10:04.760 --> 01:10:07.950
priority idle kinds of computation.

01:10:08.120 --> 01:10:10.530
Maybe you're indexing
something in the background,

01:10:10.560 --> 01:10:12.340
something like that.

01:10:14.160 --> 01:10:18.290
Okay, so we're finally at the summary.

01:10:18.440 --> 01:10:22.100
Really want to encourage you to
factor performance into your planning.

01:10:22.100 --> 01:10:25.190
Try to really make it be a
feature of your application.

01:10:25.200 --> 01:10:29.390
We want that killer app to be that
much better by performing well.

01:10:30.550 --> 01:10:33.730
Performance isn't a one-shot deal.

01:10:33.750 --> 01:10:36.200
You really have to keep
it in your workflow.

01:10:36.200 --> 01:10:41.500
You've got to keep on top of it.

01:10:41.780 --> 01:10:44.720
Ideally, you would, you know,
with different builds of your app,

01:10:44.900 --> 01:10:48.330
try to capture data about that,
about how it performs and see

01:10:48.330 --> 01:10:51.810
and pinpoint where performance
problems were introduced.

01:10:52.550 --> 01:10:55.040
And then I really encourage
you to get into the tools.

01:10:55.090 --> 01:10:57.590
The tools talk is later
on this afternoon.

01:10:57.590 --> 01:10:59.640
And all those tools are on the system.

01:10:59.720 --> 01:11:01.740
You should just become experts at them.

01:11:01.890 --> 01:11:05.700
Those tools allow you to look
at your app in various different

01:11:05.700 --> 01:11:10.190
ways and they're really helpful
in pinpointing these problems.

01:11:10.490 --> 01:11:14.290
And lastly,
just go after those performance problems.

01:11:14.330 --> 01:11:17.500
All right, so now,

01:11:18.050 --> 01:11:18.920
Let's see.

01:11:19.040 --> 01:11:20.280
Oh yeah, one last thing.

01:11:20.360 --> 01:11:23.170
So the first one,
the Carbon Developer Documentation,

01:11:23.180 --> 01:11:24.490
you should just generally know.

01:11:24.540 --> 01:11:29.120
The second one, if you're not ready to do
anything with performance at all,

01:11:29.140 --> 01:11:32.190
you're stuck behind a whole bunch of,
you know, couple months worth of

01:11:32.280 --> 01:11:34.290
features on your app,
you're still carbonizing,

01:11:34.290 --> 01:11:37.790
anything like that, at the very least,
remember this second URL up here,

01:11:37.960 --> 01:11:43.300
that performance PDF file has a
lot of information on performance.

01:11:43.330 --> 01:11:47.240
A lot of what I've gone over and
what we'll be going over in other

01:11:47.260 --> 01:11:50.310
sessions is in that one document.

01:11:50.530 --> 01:11:54.890
Okay, I'd like to bring
Mark up and then we can,

01:11:54.950 --> 01:11:58.520
he'll do the road map and
then we'll head off to Q&A.

01:12:01.500 --> 01:12:03.430
Thank you, John.

01:12:03.430 --> 01:12:07.000
There we go.

01:12:07.000 --> 01:12:08.500
That one worked.

01:12:08.750 --> 01:12:10.380
Okay.

01:12:10.380 --> 01:12:12.860
So as John mentioned,
we'd like you all to attend the

01:12:12.860 --> 01:12:15.860
Performance Tools session at
5:00 today if you possibly can.

01:12:15.860 --> 01:12:21.660
We're going to talk about the various
tools that he introduced you to.

01:12:21.660 --> 01:12:25.380
And also, because we don't have a lot of
time right now to take questions,

01:12:25.380 --> 01:12:28.900
I'd ask you to take your
questions to that session,

01:12:28.910 --> 01:12:32.340
and we'll have some of the same
people there to answer them.

01:12:32.440 --> 01:12:37.400
But we'll just take a couple right now,
so if we can bring up our Q&A panel,

01:12:37.400 --> 01:12:40.600
we can do maybe two or three questions.

01:12:44.550 --> 01:12:47.270
Oh, by the way, this is me.

01:12:47.290 --> 01:12:51.470
If during or after the conference
you have any questions or comments

01:12:51.630 --> 01:12:56.760
about Carbon or Carbon Performance,
send them to me at this address.