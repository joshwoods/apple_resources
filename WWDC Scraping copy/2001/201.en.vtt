WEBVTT

00:00:04.270 --> 00:00:06.400
Good morning.

00:00:06.430 --> 00:00:09.480
Welcome to session 201,
How Threading Can Benefit

00:00:09.480 --> 00:00:10.800
Your Application on Mac OS X.

00:00:10.800 --> 00:00:12.020
My name is Mark Tozer-Vilchez.

00:00:12.050 --> 00:00:16.230
I'm the Desktop Technology Manager in
Developer Relations.

00:00:18.270 --> 00:00:22.110
So today what I'd like to do is start
the conversation with-- actually,

00:00:22.210 --> 00:00:24.780
first of all,
I've gotten kind of feedback from the

00:00:24.780 --> 00:00:29.160
fact that our session title is the
longest one at the conference this year.

00:00:29.280 --> 00:00:32.020
So I've been asked to take
some input at the end of the

00:00:32.110 --> 00:00:34.180
session for title suggestions.

00:00:34.300 --> 00:00:36.620
So make sure you give me some input.

00:00:36.620 --> 00:00:40.910
I need to shorten it here
is what I'm being told.

00:00:41.900 --> 00:00:44.210
What I'd like to do is kind of
go over some of the ways that

00:00:44.310 --> 00:00:48.680
Apple Computer has been working
to optimize system performance.

00:00:48.730 --> 00:00:51.500
And some of the ways today
we'll talk about how you can

00:00:51.560 --> 00:00:55.680
optimize system performance
through hardware and software.

00:00:56.310 --> 00:01:02.390
So what I'd like to do is kind of take a
look at how we introduce systems at these

00:01:02.580 --> 00:01:04.600
keynote shows like Macworld and so forth.

00:01:04.910 --> 00:01:08.510
And aside from the features
of new functionality,

00:01:08.510 --> 00:01:12.480
design, performance is one of the
key customer messages that

00:01:12.480 --> 00:01:14.760
we deliver to our customers.

00:01:14.760 --> 00:01:16.920
Customers want to be able to
say that if they're going to

00:01:17.050 --> 00:01:19.610
buy this new piece of hardware,
their applications are going

00:01:19.610 --> 00:01:20.720
to be able to run faster.

00:01:20.720 --> 00:01:24.090
So performance is a key message here.

00:01:24.400 --> 00:01:28.460
How does Apple address performance
aside from increasing the megahertz?

00:01:28.520 --> 00:01:31.660
Well,
there are different ways we can do that.

00:01:31.870 --> 00:01:35.650
We can use the processor technology,
the G4, that we've migrated

00:01:35.650 --> 00:01:37.610
throughout our product line.

00:01:37.640 --> 00:01:41.340
So the most recent addition has
been the Titanium PowerBook G4.

00:01:41.340 --> 00:01:44.760
Other ways we've done that is
last year at Macworld New York,

00:01:44.760 --> 00:01:47.290
we introduced dual processor systems.

00:01:47.300 --> 00:01:51.300
So the ability to now have
two G4 processors with two G4

00:01:51.420 --> 00:01:54.010
velocity engine available to you.

00:01:54.240 --> 00:01:55.620
as well.

00:01:56.120 --> 00:02:00.150
Other ways is the unified chip
architecture for I/O on the

00:02:00.150 --> 00:02:01.790
bus has also been improved.

00:02:01.940 --> 00:02:06.070
So information can be passed along
the bus much more efficiently.

00:02:07.890 --> 00:02:09.660
So what are the ways that
you as a developer can take

00:02:09.700 --> 00:02:11.180
advantage of these technologies?

00:02:11.180 --> 00:02:13.790
Well,
there are APIs that we put out there.

00:02:13.930 --> 00:02:17.160
So the MP API has been out for
at least three or four years.

00:02:17.400 --> 00:02:19.600
Velocity Engine API has
also been out there.

00:02:19.700 --> 00:02:23.370
So those are ways that you can optimize
your code to take advantage of some

00:02:23.370 --> 00:02:25.370
of these hardware technologies.

00:02:25.400 --> 00:02:29.050
Multitasking and multithreaded are
also ways that you can increase

00:02:29.130 --> 00:02:32.490
performance just through the
application and not have to worry

00:02:32.570 --> 00:02:34.650
about the processor being faster.

00:02:35.610 --> 00:02:37.600
At the root of all of
this is obviously OS X.

00:02:37.600 --> 00:02:39.440
And this is what you're going
to learn throughout the whole

00:02:39.440 --> 00:02:43.550
week of how OS X provides all the
functionality and abilities for you

00:02:43.820 --> 00:02:46.870
to optimize your code without having
to worry about when is Apple going

00:02:46.870 --> 00:02:48.470
to deliver a gigahertz processor.

00:02:48.570 --> 00:02:51.680
Well, today, what you should be really
asking yourself is,

00:02:51.730 --> 00:02:55.340
when are you going to optimize for the
APIs that we have today and increase

00:02:55.350 --> 00:02:57.350
performance on today's processors?

00:02:59.680 --> 00:03:04.350
One of the areas also that I want
to kind of clarify are some of the

00:03:04.350 --> 00:03:07.340
definitions that we use in this type
of presentation and conversation

00:03:07.430 --> 00:03:09.100
about optimizing for hardware.

00:03:09.100 --> 00:03:13.150
Multitasking is the ability to handle
several different tasks at the same time.

00:03:13.180 --> 00:03:16.890
Multiprocessing is the ability of
the OS to actually utilize more

00:03:16.890 --> 00:03:19.170
than one processor at the same time.

00:03:19.960 --> 00:03:23.590
SMP, or Symmetrical Multiprocessing,
is the ability of the OS to actually

00:03:23.590 --> 00:03:27.930
be a little bit intelligent of how
to schedule the actual functions and

00:03:27.930 --> 00:03:32.000
execution of code across multiple
processors to actually balance the load,

00:03:32.000 --> 00:03:32.590
so to speak.

00:03:32.780 --> 00:03:34.810
Can we go to Demo 3 machine?

00:03:34.820 --> 00:03:37.310
To give you an example
of what that looks like,

00:03:37.370 --> 00:03:41.130
here's QuickTime running
three different movies.

00:03:41.140 --> 00:03:44.080
And if you can notice,
the system is actually

00:03:44.080 --> 00:03:48.500
utilizing both processors,
and they're pretty well balanced.

00:03:48.600 --> 00:03:50.070
QuickTime itself is... Mr.

00:03:50.110 --> 00:03:51.900
Schaffer,
would you go to Window or Aisle?

00:03:52.000 --> 00:03:52.930
...is actually threaded.

00:03:52.940 --> 00:03:56.330
So because of SMP,
the OS basically knows how to hand

00:03:56.330 --> 00:04:00.690
off to each processor the task
of pushing pixels to the screen.

00:04:00.700 --> 00:04:03.890
So if we had -- if
QuickTime itself was not threaded,

00:04:03.890 --> 00:04:07.500
if it was a single threaded
application or technology,

00:04:07.500 --> 00:04:11.410
you would see one processor being
overloaded and the second processor

00:04:11.500 --> 00:04:15.450
kind of getting some time when
the operating system actually

00:04:15.510 --> 00:04:17.670
divvied up some of the tasks.

00:04:20.430 --> 00:04:25.060
Can we go to slides, please?

00:04:25.120 --> 00:04:27.800
So what I'd like to do
is introduce Matt Watson,

00:04:27.860 --> 00:04:31.890
Core OS engineer who will actually
deliver today's presentation

00:04:32.280 --> 00:04:37.360
on why you should be threading
your application for Mac OS X.

00:04:42.300 --> 00:04:44.600
Thanks, Mark.

00:04:44.730 --> 00:04:49.160
So I work in the CoreOS group at Apple,
and we're responsible for most of

00:04:49.160 --> 00:04:51.860
the lower level Darwin source code.

00:04:51.900 --> 00:04:58.100
And I specifically work on the user
level implementation of Darwin.

00:04:59.130 --> 00:05:02.330
So, why do you want to use
threads in your application?

00:05:02.340 --> 00:05:07.520
What Mark alluded to earlier was
the user perception of the marketing

00:05:07.690 --> 00:05:11.190
message we've been sending out for
Mac OS X is it's fully preemptive,

00:05:11.190 --> 00:05:14.840
supports symmetric multiprocessing,
so customers are going to expect

00:05:14.840 --> 00:05:18.550
that their applications are going
to run more efficiently and scale

00:05:18.550 --> 00:05:21.500
better on multiprocessor machines.

00:05:21.560 --> 00:05:25.390
So, to take advantage of that,
if your application can perform

00:05:25.520 --> 00:05:29.240
tasks simultaneously and you're
running on a multiprocessor,

00:05:29.300 --> 00:05:32.440
the customers are going to expect
that added benefit of performance.

00:05:32.440 --> 00:05:38.330
Since Mac OS X is fully preemptive,
you'll notice that all the applications

00:05:38.360 --> 00:05:42.010
are getting time-sliced simultaneously,
and if your application

00:05:42.010 --> 00:05:45.300
has multiple threads,
it's going to get more than another

00:05:45.810 --> 00:05:47.610
application's share of that time.

00:05:47.620 --> 00:05:50.740
So, you're actually going to see the
benefit directly in your application.

00:05:52.250 --> 00:05:56.490
In some applications,
you might notice that synchronous

00:05:56.620 --> 00:05:58.010
requests would block the UI.

00:05:58.140 --> 00:05:59.350
So we want to avoid that.

00:05:59.360 --> 00:06:02.560
We want to make sure that if
you're coding and you're using

00:06:02.560 --> 00:06:05.580
an API that could block for an
indeterminate amount of time,

00:06:05.580 --> 00:06:10.130
an extra thread in your application
could help prevent the UI from blocking

00:06:10.130 --> 00:06:12.640
and let that other request complete.

00:06:13.960 --> 00:06:16.790
Also,
polling is considered bad on Mac OS X.

00:06:16.800 --> 00:06:20.640
We don't want applications to
constantly check for state.

00:06:20.640 --> 00:06:24.480
And one way you can do that is through
some of the synchronization mechanisms

00:06:24.490 --> 00:06:28.410
that I'll discuss in a little bit
where you can have a thread that's

00:06:28.410 --> 00:06:32.360
waiting for an event to occur in the
background and it will only continue

00:06:32.360 --> 00:06:34.620
after that event has actually fired.

00:06:37.290 --> 00:06:40.600
So, most cases,
your application may not need to be

00:06:40.600 --> 00:06:42.900
multi-threaded in a lot of instances.

00:06:42.900 --> 00:06:47.390
There are some times when the added
complexity of a thread may change

00:06:47.390 --> 00:06:49.130
the logic of your application.

00:06:49.140 --> 00:06:51.650
If it was written originally
to be single-threaded and

00:06:51.650 --> 00:06:55.940
you have lots of global data,
your locking mechanism may not be as

00:06:55.940 --> 00:06:59.460
robust as you have originally designed.

00:06:59.460 --> 00:07:02.550
There's a little bit of added
overhead for an extra thread

00:07:02.550 --> 00:07:04.420
to come into your application.

00:07:04.990 --> 00:07:07.500
There's some kernel resources
that are associated with that.

00:07:07.750 --> 00:07:12.220
And you basically need to decide
when you're designing your app which

00:07:12.220 --> 00:07:15.830
portions of your application make
more sense to be multi-threaded.

00:07:15.840 --> 00:07:18.620
There may also be other
options that make sense.

00:07:18.620 --> 00:07:21.510
In a GUI application,
you always have a run loop

00:07:21.510 --> 00:07:23.760
going that's polling for events.

00:07:23.760 --> 00:07:29.240
And if you can use a timer
for a short-lived task,

00:07:29.350 --> 00:07:31.150
that might be a better
option in certain cases.

00:07:33.620 --> 00:07:36.470
Some of the overhead I was
talking about in a preemptive

00:07:36.630 --> 00:07:40.860
multitasking operating system,
a context switch is what occurs when the

00:07:40.860 --> 00:07:44.450
kernel decides to go between different
threads that are running on the system.

00:07:44.460 --> 00:07:48.080
And there's data associated
with every thread.

00:07:48.080 --> 00:07:51.990
Basically, the register state that each
thread takes up needs to be saved

00:07:51.990 --> 00:07:53.820
and restored between threads.

00:07:53.860 --> 00:07:57.310
There may also be extra register
state depending on if that

00:07:57.310 --> 00:08:01.100
thread has used floating point
or even the velocity engine.

00:08:01.680 --> 00:08:05.520
And that amount of data is obviously
a little bit more expensive when

00:08:05.520 --> 00:08:07.980
you're switching extra threads
throughout your application.

00:08:08.000 --> 00:08:12.960
The thread memory footprint is also
something that might be significant.

00:08:12.960 --> 00:08:18.770
In Mac OS X, every thread gets a virtual
half a megabyte of stack space,

00:08:18.770 --> 00:08:22.900
for instance, which is controllable when
you create the thread.

00:08:22.900 --> 00:08:24.520
But you have to be aware of that.

00:08:24.540 --> 00:08:27.320
So if you're creating a thread
that only calls one function,

00:08:27.320 --> 00:08:29.260
you may want to reduce the stack space.

00:08:29.290 --> 00:08:31.610
And I'll discuss APIs to do that.

00:08:31.680 --> 00:08:33.680
I'll talk about that
here a little bit later.

00:08:33.680 --> 00:08:39.140
Thread creation in and of itself is a
little bit of overhead that you need to

00:08:39.360 --> 00:08:45.220
worry about because the act of creating a
thread introduces those kernel resources.

00:08:45.510 --> 00:08:51.190
There's a set of Mach APIs that is used
under the covers to create threads.

00:08:51.220 --> 00:08:57.080
And the calls that you use to create
the stack and the actual thread itself

00:08:57.580 --> 00:09:00.600
take up a little bit of overhead.

00:09:01.240 --> 00:09:05.140
Throughout the APIs that
Mac OS X provides for multithreading,

00:09:05.140 --> 00:09:06.440
there are some common concepts.

00:09:06.440 --> 00:09:11.850
All these APIs let you create a
thread and let the thread exit itself.

00:09:11.900 --> 00:09:16.680
There are synchronization primitives
that let you coordinate the events that

00:09:16.680 --> 00:09:19.050
are occurring between multiple threads.

00:09:19.060 --> 00:09:23.500
And every API will have a
set of thread-safe services.

00:09:23.500 --> 00:09:26.650
The documentation describes
things that you can and can't

00:09:26.730 --> 00:09:28.200
do for multiple threads.

00:09:28.580 --> 00:09:31.510
We're working toward making it a
lot easier so that you don't have to

00:09:31.520 --> 00:09:34.730
worry about which APIs are thread-safe
by making sure that everything

00:09:34.730 --> 00:09:38.140
that you call will be thread-safe,
but that's not quite there yet.

00:09:40.530 --> 00:09:43.480
In Mac OS X,
threads are the scheduling primitive.

00:09:43.480 --> 00:09:48.520
It's the unit that the kernel uses
when divvying up the work that needs

00:09:48.520 --> 00:09:50.140
to be done at every time slice.

00:09:50.140 --> 00:09:54.820
Our threads are fully preemptive,
so the kernel will interrupt a thread

00:09:54.940 --> 00:09:57.040
that's running to start the next thread.

00:09:57.040 --> 00:10:02.070
There are some exceptions to that where
we have some scheduling models where

00:10:02.070 --> 00:10:07.020
a real-time-like API can be used to
specify somewhat of a deadline schedule,

00:10:07.020 --> 00:10:09.010
where you can say,
I want my thread to run this long.

00:10:09.020 --> 00:10:11.520
But in most cases,
the default threads that get

00:10:11.670 --> 00:10:13.470
created are normally preempted.

00:10:13.510 --> 00:10:16.560
We use a priority-based scheduling model.

00:10:16.560 --> 00:10:19.600
So by default,
all threads get the same priority.

00:10:19.600 --> 00:10:22.950
When you create threads or after
the thread has been created,

00:10:22.950 --> 00:10:25.300
you can change or modify that priority.

00:10:25.300 --> 00:10:28.830
So if you have a thread that needs to
be more important than other threads,

00:10:28.860 --> 00:10:30.830
either in your application
or system-wide,

00:10:30.830 --> 00:10:31.860
you can change that.

00:10:32.090 --> 00:10:35.800
You can also depress the priority
of a thread if you want that thread

00:10:35.800 --> 00:10:39.260
to be in the background more,
or if it's just doing some

00:10:39.260 --> 00:10:43.110
low-level work that doesn't
need to be in the user's face.

00:10:43.310 --> 00:10:46.740
We use a one-to-one threading model,
which means that as the

00:10:47.110 --> 00:10:50.770
APIs I describe are calling into
the low-level kernel threads,

00:10:50.770 --> 00:10:55.510
we use a single kernel thread
per high-level thread concept.

00:10:55.620 --> 00:10:59.030
So as I discuss these APIs,
keep that in mind.

00:10:59.040 --> 00:11:02.850
There are other implementations out
there where you have multiplexing of

00:11:03.130 --> 00:11:07.120
threads in user space per kernel thread,
but the added complexity of that

00:11:07.440 --> 00:11:11.080
and scalability on MP machines
makes it a little bit more

00:11:11.080 --> 00:11:13.180
difficult to justify on OS X.

00:11:13.200 --> 00:11:38.260
Mark Tozer-Vilchez, Matt Watson,
Robert Bowdidge,

00:11:38.260 --> 00:11:45.750
Ivan Posva If you manage a thread's
priority through the Mach API and

00:11:45.910 --> 00:11:48.890
not through the API you're using,
that API may not notice it.

00:11:48.920 --> 00:11:54.600
So later on, your thread scheduling
might behave unexpectedly.

00:11:56.840 --> 00:12:01.770
So this is a slide we've shown before,
and what it's trying to show is

00:12:01.930 --> 00:12:06.480
an example of what happens if
you take an application and run

00:12:06.480 --> 00:12:09.420
it on a multiprocessor system
with more than one thread.

00:12:09.420 --> 00:12:13.730
And the numbers along the edge of the
bars there are the multiplier factors

00:12:14.140 --> 00:12:16.580
for the improvement in performance.

00:12:16.580 --> 00:12:21.160
So you can see the first, third,
and fourth numbers are all under two,

00:12:21.160 --> 00:12:25.020
but that second number is above two,
which is kind of interesting.

00:12:25.200 --> 00:12:28.740
And it's an exceptional case where
you might wonder how I could get

00:12:28.740 --> 00:12:33.010
more than 2x performance improvement
on a multithreaded application.

00:12:33.050 --> 00:12:35.360
Well,
if you have two processors in the system,

00:12:35.360 --> 00:12:37.300
you also happen to have two caches.

00:12:37.300 --> 00:12:40.620
So if your data set fit
in the primary cache,

00:12:40.770 --> 00:12:45.520
you wouldn't see more than
2x performance improvement.

00:12:45.520 --> 00:12:48.310
But what happened in this case
was the data set was able to

00:12:48.400 --> 00:12:51.990
be split up across two caches,
and you actually got a little bit better

00:12:52.110 --> 00:12:54.200
than a 2x performance improvement.

00:12:54.200 --> 00:12:55.200
So you may be surprised.

00:12:55.200 --> 00:12:57.960
In your application,
depending on the size of the

00:12:57.960 --> 00:13:01.210
data that you're manipulating,
how good your performance

00:13:01.300 --> 00:13:02.400
can actually be.

00:13:04.410 --> 00:13:07.610
In the Mach implementation,
it was designed from the ground up

00:13:07.690 --> 00:13:09.650
to be full symmetric multiprocessing.

00:13:09.840 --> 00:13:13.770
So we don't have any special
case code for a single processor,

00:13:13.770 --> 00:13:15.100
dual processor.

00:13:15.100 --> 00:13:20.400
Everything on the system is designed
to be run on a multiprocessor machine.

00:13:20.440 --> 00:13:23.450
The velocity context I mentioned
earlier is something that has to be

00:13:23.500 --> 00:13:26.840
saved and restored across processors,
and that context that gets

00:13:26.900 --> 00:13:28.800
saved is a little bit expensive.

00:13:28.800 --> 00:13:33.580
That's what I was mentioning about the
overhead you might need to worry about.

00:13:33.930 --> 00:13:38.580
On OS X, we use the same kernel binary
for either a single processor

00:13:38.580 --> 00:13:39.780
or a multiprocessor system.

00:13:39.780 --> 00:13:43.930
We don't have a special install
for a UP or an MP system.

00:13:43.940 --> 00:13:49.520
This basically makes our own
development a little bit easier.

00:13:49.520 --> 00:13:52.420
We don't have to QA two
different kernels on the system,

00:13:52.420 --> 00:13:56.980
and it's a little bit easier for
us to do the install as far as

00:13:57.020 --> 00:14:00.580
making sure that customers all have
the same bits on their machines.

00:14:03.330 --> 00:14:06.280
The Mach scheduler was
inherited from the OSF,

00:14:06.320 --> 00:14:07.700
the Open Software Foundation.

00:14:07.700 --> 00:14:12.830
We use a scheduling
framework that they designed,

00:14:12.830 --> 00:14:16.010
but we've modified it
heavily for our own use.

00:14:16.160 --> 00:14:19.010
It has a global run queue,
meaning that all the tasks

00:14:19.090 --> 00:14:23.970
on the system get switched
through on every contact switch.

00:14:24.100 --> 00:14:26.940
The tasks that are runnable,
I should say.

00:14:27.310 --> 00:14:30.240
The system notices that if you're
on a multiprocessor system,

00:14:30.240 --> 00:14:33.680
you have an idle processor,
so it will go and schedule a thread to be

00:14:33.830 --> 00:14:36.020
on the most idle processor at the time.

00:14:36.080 --> 00:14:38.880
So we don't really have a
notion of thread affinity.

00:14:38.880 --> 00:14:42.600
It might be a term you've heard of before
where you can have a thread running

00:14:42.600 --> 00:14:44.610
on a single processor for a long time.

00:14:44.620 --> 00:14:48.960
The kernel will basically balance the
resources of the system as best it can.

00:14:48.960 --> 00:14:52.420
And as I've said before,
preemption is key here.

00:14:52.420 --> 00:14:56.060
Every thread gets preempted as
it goes through the run queue.

00:14:58.240 --> 00:15:02.700
The user frameworks that you'll see
when writing a multithreaded application

00:15:02.700 --> 00:15:06.010
are probably just the same frameworks
you're using for your application.

00:15:06.020 --> 00:15:07.100
There's nothing really special.

00:15:07.100 --> 00:15:10.020
Most of the frameworks that we
have have an API for threading.

00:15:10.060 --> 00:15:16.180
In Carbon, it's the MP or MPTask API that
has been out for a few years.

00:15:16.260 --> 00:15:21.220
In Cocoa, there's NSThreads,
which are used both in the

00:15:21.220 --> 00:15:24.030
non-GUI and GUI frameworks.

00:15:24.930 --> 00:15:27.840
And in Java, we have JavaThreads,
which is just a special

00:15:27.880 --> 00:15:31.920
implementation that is using the
underlying primitives in Darwin.

00:15:31.920 --> 00:15:37.880
All of those three APIs depend on the
Darwin Pthreads or POSIXThreads APIs.

00:15:37.880 --> 00:15:41.740
And since I work in the CoreOS group,
that's actually the API set

00:15:41.860 --> 00:15:45.710
that I'm most familiar with,
and I'll talk about that later.

00:15:45.850 --> 00:15:47.390
in a second.

00:15:47.800 --> 00:15:50.950
Pthreads, as I said,
is the basis for all threading models.

00:15:51.090 --> 00:15:54.720
Every API that I described goes
through the Pthreads layer.

00:15:54.920 --> 00:15:58.590
So when we make changes and
enhancements to the Pthreads layer,

00:15:58.680 --> 00:16:02.050
all of those API sets
take advantage of that.

00:16:02.340 --> 00:16:04.530
I put in quotes there,
it's a light implementation.

00:16:04.530 --> 00:16:09.160
The history behind that is when
we were trying to decide on an

00:16:09.280 --> 00:16:13.760
API that we could use to implement
those higher level threading models,

00:16:13.980 --> 00:16:17.580
we chose Pthreads and the
implementation decisions were

00:16:17.740 --> 00:16:20.300
driven by those higher level APIs.

00:16:20.300 --> 00:16:23.370
So if you look in the header
file in our documentation,

00:16:23.370 --> 00:16:27.690
you might see that there are some
API calls missing and in general we're

00:16:27.690 --> 00:16:32.370
working toward flushing out that API,
but the design goal was to help

00:16:32.610 --> 00:16:38.300
ensure that the higher level Carbon,
Cocoa, and Java APIs could do their job.

00:16:38.300 --> 00:16:41.890
We use a one-to-one Mach to
Pthread implementation,

00:16:42.140 --> 00:16:47.090
as I said, that reduces the complexity of
our user level code and helps the

00:16:47.090 --> 00:16:49.530
scaling on an MP system better.

00:16:49.830 --> 00:16:53.320
In Pthreads, there are some common
API uses and misuses.

00:16:53.320 --> 00:16:57.070
If you haven't done threading before,
Pthreads is a fairly

00:16:57.070 --> 00:16:58.130
well-defined standard.

00:16:58.130 --> 00:17:00.800
You can go to your local
bookstore and get a book on it.

00:17:00.800 --> 00:17:07.970
I'll talk about some of the ways
that you'll need to be careful when

00:17:07.970 --> 00:17:07.970
using Pthreads on our implementation.

00:17:08.210 --> 00:17:10.800
For instance, one case,
we don't have any system-wide types.

00:17:10.800 --> 00:17:14.390
So in Pthreads,
there's a specification that provides

00:17:14.750 --> 00:17:18.660
global shared memory-based mutexes
and condition variables for signaling.

00:17:18.660 --> 00:17:22.090
Those can be implemented
in your own application,

00:17:22.180 --> 00:17:25.090
but we don't provide
those APIs right now.

00:17:27.750 --> 00:17:30.580
One thing that you might need
to remember is synchronization

00:17:30.580 --> 00:17:32.090
is not cheap in Pthreads.

00:17:32.410 --> 00:17:37.180
The model that Pthreads uses
has a mutex lock associated

00:17:37.180 --> 00:17:38.700
with a condition variable.

00:17:38.770 --> 00:17:43.120
And for those to be properly
used in an atomic fashion,

00:17:43.120 --> 00:17:46.970
we have to use some kernel resources
to do the signaling when you're

00:17:47.010 --> 00:17:49.580
synchronizing between threads.

00:17:50.230 --> 00:17:54.550
The default behavior for a Pthread
as specified by POSIX is that

00:17:54.700 --> 00:17:57.600
threads are what's called joinable,
which means that when

00:17:57.600 --> 00:18:00.250
you create a thread,
the operating system will hang around

00:18:00.250 --> 00:18:01.990
and wait for that thread to finish.

00:18:02.090 --> 00:18:05.430
If you want your thread to go
away and do its job and you don't

00:18:05.430 --> 00:18:09.200
want to worry about it anymore,
there's an API to detach that thread,

00:18:09.200 --> 00:18:12.200
which just means let it do its job,
I don't want to hear about it,

00:18:12.230 --> 00:18:14.610
let it finish on its own.

00:18:15.640 --> 00:18:18.610
As I mentioned earlier,
the stack space for a thread

00:18:18.640 --> 00:18:20.760
is by default half a megabyte.

00:18:20.780 --> 00:18:23.560
Now, it sounds like a lot,
but it's all virtual memory

00:18:23.900 --> 00:18:25.420
that is used on demand.

00:18:25.420 --> 00:18:29.490
So if you look at process listing,
you might see your application

00:18:29.580 --> 00:18:33.190
using a lot of virtual memory,
but unless it's actually been touched,

00:18:33.360 --> 00:18:36.210
the system hasn't allocated
that for your application yet.

00:18:36.270 --> 00:18:38.650
So it won't cost you as
much as you might think.

00:18:38.690 --> 00:18:41.190
But even given that,
if you have a lot of threads

00:18:41.190 --> 00:18:44.680
running in your application,
you may want to create them

00:18:44.680 --> 00:18:47.320
with an attribute saying,
I want my thread stack

00:18:47.630 --> 00:18:49.100
size to be smaller.

00:18:49.100 --> 00:18:52.680
And if you do that,
then you can limit the visible virtual

00:18:52.680 --> 00:18:55.010
memory used by your application.

00:18:56.630 --> 00:19:00.400
In the POSIX specification for
condition variables and signaling,

00:19:00.400 --> 00:19:04.130
there's the notion of a predicate,
which is when you want to signal

00:19:04.130 --> 00:19:07.780
that something has happened,
there's a mutex and a condition

00:19:07.780 --> 00:19:11.230
variable associated with that,
but there's also some external

00:19:11.290 --> 00:19:13.520
condition that needs to be checked for.

00:19:13.520 --> 00:19:16.560
So you can have a global,
volatile variable that says,

00:19:16.560 --> 00:19:20.380
"This thing happened." Well,
if you just use the condition and

00:19:20.380 --> 00:19:25.100
mutexes without having a global variable,
the API won't work properly.

00:19:25.100 --> 00:19:30.200
And this is discussed in a lot of
POSIX thread specification texts.

00:19:30.200 --> 00:19:31.320
You can just look this up.

00:19:31.480 --> 00:19:34.690
The most common error that
people use is they try and do

00:19:34.690 --> 00:19:36.940
signaling without a predicate.

00:19:37.310 --> 00:19:42.520
Our implementation of PthreadCancel,
which when you start using threads or

00:19:42.520 --> 00:19:48.000
if you've used threads in other systems,
you might want to try to cancel or

00:19:48.220 --> 00:19:50.970
kill a thread that's currently running.

00:19:50.980 --> 00:19:53.110
And this is dangerous for a few reasons.

00:19:53.120 --> 00:19:56.130
One is if you're using asynchronous
cancellation where you're

00:19:56.130 --> 00:19:59.060
basically telling the system,
I don't care what the thread's doing,

00:19:59.060 --> 00:20:00.040
I just want it to go away.

00:20:00.040 --> 00:20:03.200
That's dangerous in the sense that
there could be kernel resources

00:20:03.200 --> 00:20:06.410
associated with that thread that
may not be properly cleaned up.

00:20:07.020 --> 00:20:11.360
There may be some other data associated
with that thread in some other task

00:20:11.360 --> 00:20:15.060
that is not getting cleaned up,
like a file descriptor that's open or a

00:20:15.060 --> 00:20:16.950
file that's taking up space on the disk.

00:20:17.010 --> 00:20:21.920
So we recommend using the PthreadCancel
in its deferred or synchronous model

00:20:22.320 --> 00:20:27.910
where you basically make a request to the
system that I'd like this thread to quit.

00:20:27.920 --> 00:20:30.870
And in our API,
we have a PthreadTestCancel

00:20:30.880 --> 00:20:34.980
call where if you're in a
long-running compute-bound loop,

00:20:34.980 --> 00:20:39.330
you can check to see if, for example,
a thread has a request to cancel,

00:20:39.380 --> 00:20:42.890
and if so, that thread will exit at
the PthreadTestCancel point.

00:20:42.960 --> 00:20:48.260
The POSIX specification also provides
for system-defined cancellation

00:20:48.260 --> 00:20:50.720
points like most system calls.

00:20:50.740 --> 00:20:53.330
And if you look in the
Darwin source base,

00:20:53.350 --> 00:20:58.100
you'll see that we're busily working on
implementing those because it's actually

00:20:58.160 --> 00:20:59.900
a better way of doing the cancellation.

00:20:59.900 --> 00:21:03.500
If I'm in an open or a read system
call and I tell that thread to cancel,

00:21:03.650 --> 00:21:06.660
it should just break out of
that open or read system call.

00:21:06.780 --> 00:21:10.830
if I had interrupted that system call.

00:21:11.910 --> 00:21:15.480
The Pthreads documentation right now
is a little sparse on our system.

00:21:15.500 --> 00:21:20.130
I usually point people to the
Open Group site because they

00:21:20.130 --> 00:21:24.980
happen to have a pretty extensive
documentation on both the UNIX 98

00:21:25.400 --> 00:21:27.180
standard and Pthreads specifically.

00:21:27.180 --> 00:21:31.780
In general, we use that as our model for
doing our implementation.

00:21:31.780 --> 00:21:36.290
We will be providing more Pthreads
documentation on the system

00:21:36.300 --> 00:21:38.540
at some point in the future.

00:21:42.890 --> 00:21:49.280
So in the Carbon APIs, as I said,
the MPTask spec is what you'd probably

00:21:49.280 --> 00:21:52.100
look at for your multithreading needs.

00:21:52.100 --> 00:21:55.320
MPTasks, just a quick overview.

00:21:55.320 --> 00:22:01.220
In Mac OS X,
there's the notion of tasks and MPTasks.

00:22:01.270 --> 00:22:03.830
So tasks have classically
been the process notion where

00:22:03.890 --> 00:22:07.680
you have an application,
its address space, all of its threads.

00:22:07.720 --> 00:22:12.300
In MPTasks, those are threads within
a Carbon application.

00:22:13.240 --> 00:22:16.860
And as you know, in Mac OS X,
all applications are in

00:22:16.860 --> 00:22:18.040
a separate address space.

00:22:18.040 --> 00:22:23.210
So some of the APIs that you may
have used in classic Mac OS 9 are

00:22:23.240 --> 00:22:25.140
not going to work the same way.

00:22:25.140 --> 00:22:28.070
You can't do signaling
between applications right

00:22:28.070 --> 00:22:29.720
now using the MPTask API.

00:22:32.970 --> 00:22:35.030
The API here is pretty rich.

00:22:35.200 --> 00:22:39.730
There are a lot of mechanisms to do
synchronization between MP tasks.

00:22:39.830 --> 00:22:42.360
There's a semaphore model.

00:22:42.480 --> 00:22:45.790
There are message
queues and event groups.

00:22:45.830 --> 00:22:48.030
All three of these can
be used in different ways

00:22:48.080 --> 00:22:49.620
depending on your application.

00:22:49.660 --> 00:22:55.460
If you have some client server model,
if you have a worker thread model,

00:22:55.460 --> 00:22:58.750
you can decide which
one works best for you.

00:22:59.360 --> 00:23:02.860
The other API that's a little bit
unique here is the Critical Region API.

00:23:02.860 --> 00:23:06.830
This basically lets you
do mutual exclusion,

00:23:07.220 --> 00:23:12.440
and it also allows for recursive
entry to those regions.

00:23:13.140 --> 00:23:17.080
There are atomic operations that are
present in this API that are kind of

00:23:17.080 --> 00:23:21.660
handy for atomic increment and decrement
and test and set type instructions.

00:23:21.660 --> 00:23:26.580
These are all done very efficiently,
and they're probably very close to the

00:23:26.700 --> 00:23:29.010
same implementation as on Mac OS 9.

00:23:30.770 --> 00:23:35.390
Some of the APIs that exist
on Mac OS X that use MP Tasks

00:23:35.600 --> 00:23:39.450
under the covers are the
Synchronous File Manager APIs and

00:23:39.450 --> 00:23:41.060
the Open Transport APIs.

00:23:41.060 --> 00:23:47.470
If you'd like to see an example of
some of these APIs and the tech note

00:23:47.470 --> 00:23:53.880
that we usually refer to is 1104,
the URL is kind of hard to read there.

00:23:54.360 --> 00:23:57.460
But in general,
that will give you a background on what

00:23:57.460 --> 00:24:02.970
we're doing with the MP Task APIs and
some examples of the thread-safe

00:24:02.970 --> 00:24:05.780
services that you can use in Carbon.

00:24:08.490 --> 00:24:13.400
The documentation specifically for the
multiprocessing services is on developer,

00:24:13.400 --> 00:24:17.690
apple.com, techpubs, mpservices.

00:24:17.690 --> 00:24:22.500
And all these documents are
being evolved to reflect what

00:24:22.500 --> 00:24:24.910
the current Carbon API is.

00:24:25.810 --> 00:24:28.170
The second framework
I'll talk about is Cocoa.

00:24:28.330 --> 00:24:34.460
It's the high-level GUI framework
that Apple has presented as an

00:24:34.460 --> 00:24:39.200
object-oriented environment for
doing application development.

00:24:39.330 --> 00:24:41.200
NSThreads API is very simple to use.

00:24:41.250 --> 00:24:43.820
There aren't very many
entry points to it.

00:24:43.880 --> 00:24:45.700
Basically, you can create a thread.

00:24:45.750 --> 00:24:50.690
You can get the thread's
state at any time.

00:24:50.800 --> 00:24:53.770
The preemptive nature of
the thread isn't unique.

00:24:53.860 --> 00:24:58.080
All the threads in the thread models
I've described are preemptive.

00:24:58.150 --> 00:25:01.240
There's an exit notification
for NSThreads where,

00:25:01.280 --> 00:25:04.630
even though the thread is detached,
meaning that it can go away

00:25:04.730 --> 00:25:07.090
and you can forget about it,
you could also register

00:25:07.090 --> 00:25:09.910
for a notification saying,
I'd like to know when this thread

00:25:09.920 --> 00:25:12.960
goes away to clean up resources.

00:25:13.510 --> 00:25:18.020
Common to most thread APIs is
the notion of a per-thread data.

00:25:18.080 --> 00:25:21.400
And when you extend that into
an object-oriented environment,

00:25:21.550 --> 00:25:24.460
the per-thread data becomes
a per-thread NSDictionary.

00:25:24.460 --> 00:25:29.380
So you can have keys and values
that are associated with your thread

00:25:29.540 --> 00:25:32.710
using the nice high-level Cocoa APIs.

00:25:34.110 --> 00:25:36.440
In NSThread, there's an AppKit extension.

00:25:36.460 --> 00:25:39.820
So even though NSThread is
defined in the foundation classes,

00:25:39.820 --> 00:25:43.860
if you look in the
AppKit or Cocoa framework,

00:25:43.860 --> 00:25:48.990
you'll notice that there's a method in
there that says detach drawing thread.

00:25:49.000 --> 00:25:51.510
And what that lets you do is
give a hint to the system that

00:25:51.510 --> 00:25:54.070
I'm going to be creating a
thread here that might be doing

00:25:54.070 --> 00:25:57.000
interaction with the window manager.

00:25:57.000 --> 00:26:01.390
And the AppKit will set up special state
to make sure that all its interactions

00:26:01.390 --> 00:26:04.000
with the window manager are thread safe.

00:26:04.000 --> 00:26:07.350
Now if you're writing a Quartz,
pure Quartz application,

00:26:07.350 --> 00:26:10.000
that interaction is already thread safe.

00:26:10.000 --> 00:26:13.030
In fact,
the way that you can write a Quartz

00:26:13.030 --> 00:26:19.000
application without using any of the
Cocoa frameworks is to use one thread.

00:26:19.000 --> 00:26:22.000
So you have one connection
to Quartz per thread.

00:26:22.000 --> 00:26:24.000
And that provides all the
synchronization you need.

00:26:24.000 --> 00:26:28.240
You still have to protect your global
data if you have multiple threads that

00:26:28.240 --> 00:26:32.000
are running that are all trying to
communicate with the same connection.

00:26:32.000 --> 00:26:34.880
You need to use the
synchronization mechanism that

00:26:34.890 --> 00:26:37.000
I've described to make that work.

00:26:37.000 --> 00:26:39.490
But in general,
the AppKit extension lets you

00:26:39.630 --> 00:26:42.640
do all you need to do for a
Cocoa thread to let it know that

00:26:42.760 --> 00:26:44.940
you're going to be doing drawing.

00:26:45.000 --> 00:26:48.990
NSThreads are self-aware,
meaning there's no global notion.

00:26:49.000 --> 00:26:50.990
You're not going to be doing
the distribution of all the

00:26:51.050 --> 00:26:54.480
NSThreads on the system,
or you're not really going to

00:26:54.620 --> 00:26:58.000
be handing NSThreads off to
other objects in the system.

00:26:58.000 --> 00:27:01.140
All these APIs I've described,
since they're layered

00:27:01.420 --> 00:27:04.980
on top of POSIX threads,
can ask for their POSIX thread.

00:27:05.050 --> 00:27:07.830
And then once they've done that,
they can perform any of

00:27:07.830 --> 00:27:11.000
the POSIX thread APIs,
like changing their priority

00:27:11.000 --> 00:27:13.990
or finding out what the
stack size is for the thread.

00:27:14.000 --> 00:27:18.000
But in general, NSThreads kind of stay
in their own realm.

00:27:18.000 --> 00:27:20.000
They have a separate run loop.

00:27:20.000 --> 00:27:23.000
So usually when you're
creating an NSThread,

00:27:23.000 --> 00:27:26.000
since you're already in a
GUI application if you're using Cocoa,

00:27:26.160 --> 00:27:29.810
there's a main run loop that's
associated with the first thread that's

00:27:29.810 --> 00:27:32.000
been created on behalf of the system.

00:27:32.110 --> 00:27:35.000
But new threads that get created are
going to have their own run loop,

00:27:35.080 --> 00:27:40.870
because those threads will probably
have a different signaling mechanism

00:27:41.130 --> 00:27:44.590
and different events that are
occurring that need to signal back

00:27:44.590 --> 00:27:47.000
and forth between other threads.

00:27:47.000 --> 00:27:51.000
So other Cocoa APIs that have to do with
run loops are timers and notifications.

00:27:51.000 --> 00:27:56.000
And you can send those between threads
with a little bit of synchronization.

00:27:56.000 --> 00:27:59.260
There's a concept of an
auto-release pool that,

00:27:59.330 --> 00:28:01.000
if you haven't done any
Cocoa programming yet,

00:28:01.000 --> 00:28:08.000
this is a wrapper for objects which get
created and destroyed kind of on the fly.

00:28:08.000 --> 00:28:11.950
So you call a method,
it returns you an object,

00:28:11.990 --> 00:28:16.000
and one notion that Cocoa tries to
help out with is the memory method.

00:28:16.000 --> 00:28:18.990
So if you don't actually
explicitly create an object,

00:28:19.000 --> 00:28:24.000
it just comes back from a call,
it gets what's called auto-released.

00:28:24.000 --> 00:28:28.000
And the way the auto-release pool
works is on a per-thread basis.

00:28:28.000 --> 00:28:30.000
So the main run loop has
an auto-release pool.

00:28:30.000 --> 00:28:33.920
Every time through the event loop,
it releases all these objects

00:28:33.920 --> 00:28:38.000
that may have been created on
behalf of another method call.

00:28:38.000 --> 00:28:41.010
And in a separate thread,
you need to make sure that

00:28:41.010 --> 00:28:45.000
you're maintaining the
auto-release pool as well,

00:28:45.000 --> 00:28:48.320
because all the messages that get
sent on that separate thread will

00:28:48.320 --> 00:28:53.000
need to be auto-released if they're
returning objects eventually.

00:28:54.420 --> 00:28:59.440
The documentation for NSThread is also on
developer.apple.com in a very long URL.

00:28:59.440 --> 00:29:04.220
Actually, the Cocoa documentation
is very well done.

00:29:04.220 --> 00:29:07.150
And there's, I believe,
an O'Reilly book out

00:29:07.150 --> 00:29:08.820
that you can go get now.

00:29:08.840 --> 00:29:15.300
For future developments, basically,
if you follow Darwin,

00:29:15.300 --> 00:29:19.540
since I'm involved in the CoreOS group,
we basically get,

00:29:19.540 --> 00:29:23.670
we have the ability to put all
of our work that we're working on

00:29:23.670 --> 00:29:26.240
daily in the public CVS repository.

00:29:26.240 --> 00:29:30.360
So if you want to just go
to the Darwin webpages,

00:29:30.360 --> 00:29:34.700
that will let you know how to go ahead
and check out any of the CVS repositories

00:29:34.700 --> 00:29:37.040
for all the work that we're doing.

00:29:37.040 --> 00:29:40.890
Specifically, the LibC project is where
the Pthreads code lives,

00:29:40.890 --> 00:29:44.420
and the XNU project is where
the Mach kernel is and where

00:29:44.420 --> 00:29:46.760
the Mach threading model lives.

00:29:48.120 --> 00:29:52.660
Some of the things we're working on,
and we're also getting help, actually,

00:29:52.660 --> 00:29:56.260
the Darwin community is very interested
in our threading implementation.

00:29:56.260 --> 00:30:02.080
Priority inheritance is an issue
where if you have multiple threads and

00:30:02.080 --> 00:30:07.120
you're finding your lock contention
becomes a problem where a higher

00:30:07.360 --> 00:30:11.410
priority thread is blocked waiting
for a lower priority thread to run,

00:30:11.420 --> 00:30:15.050
there are some solutions that
you can use in your application

00:30:15.310 --> 00:30:17.240
to work around this problem.

00:30:18.000 --> 00:30:22.310
In general, the system should help out by
temporarily raising the priority of

00:30:22.320 --> 00:30:26.520
the thread that needs to run for the
higher priority thread to continue.

00:30:26.540 --> 00:30:30.510
So that concept hasn't
been implemented yet,

00:30:30.830 --> 00:30:32.540
but we're working on that.

00:30:32.930 --> 00:30:39.150
The general API expansion issues of
the Pthread spec that we've provided,

00:30:39.150 --> 00:30:44.040
we've gotten a lot of requests for
specific functionality that's missing.

00:30:44.040 --> 00:30:47.060
We know about that,
and we're working on it.

00:30:47.330 --> 00:30:49.560
The other thing that we've been
focusing on is performance.

00:30:49.560 --> 00:30:54.640
Like I said in the first couple slides,
when you're deciding whether you

00:30:54.640 --> 00:30:58.970
should use multiple threads in your
application or how you should use them,

00:30:58.980 --> 00:31:00.580
we don't want to be an impediment there.

00:31:00.580 --> 00:31:04.160
We don't want the choice to use
more than one thread in your

00:31:04.160 --> 00:31:08.710
application to have to be made
because there's a performance issue.

00:31:08.720 --> 00:31:11.900
In general,
you should use multiple threads

00:31:11.900 --> 00:31:16.500
if your application has a data
model that works well with that.

00:31:16.520 --> 00:31:20.960
If you have lots of data that can be
parallelized in its functionality where

00:31:21.250 --> 00:31:25.560
you're splitting up chunks of data in
a graphical application that's doing

00:31:25.560 --> 00:31:30.800
tiling or the best example we've used is
Photoshop a lot for some of its filters.

00:31:30.800 --> 00:31:34.290
Those things lend themselves
very well to multithreading.

00:31:34.300 --> 00:31:38.700
And we don't want you as a developer
to have to worry about whether you're

00:31:38.700 --> 00:31:40.520
even on a multiprocessor system.

00:31:40.540 --> 00:31:44.150
In fact,
if your application is written properly,

00:31:44.150 --> 00:31:47.430
you should just automatically take
advantage of that second processor and

00:31:47.430 --> 00:31:51.610
your customers will be happy because they
paid the money for the multiprocessor

00:31:51.610 --> 00:31:56.310
box and they're actually getting the
performance that they would expect.

00:31:56.520 --> 00:31:59.480
We're working on providing
more thread-safe services.

00:31:59.490 --> 00:32:03.340
As I've mentioned,
in the Carbon APIs and even in

00:32:03.340 --> 00:32:06.910
the lower level Darwin APIs,
we've been working pretty hard on

00:32:06.910 --> 00:32:10.490
making sure that you can call the
APIs that you want without having

00:32:10.490 --> 00:32:14.700
to worry about creating your own
locking mechanisms around the parts

00:32:14.840 --> 00:32:17.830
of the API that are not thread-safe.

00:32:19.380 --> 00:32:21.950
So right now we have a couple demos.

00:32:22.200 --> 00:32:24.550
First I'd like to bring
up Robert Bowdidge,

00:32:24.550 --> 00:32:26.900
who's going to show an example
of some of the developer

00:32:26.960 --> 00:32:29.790
tools that we're working on.

00:32:29.800 --> 00:32:31.580
Thanks, Matt.

00:32:37.980 --> 00:32:42.680
So what Matt has done is explain
to us what the APIs are for using

00:32:42.830 --> 00:32:45.540
threads and a little about the
reasons about why we might use them.

00:32:45.550 --> 00:32:48.690
What I'd like to do is give us some
case studies and explain how some

00:32:48.690 --> 00:32:50.960
of Apple's own tools use threading.

00:32:50.970 --> 00:32:54.150
Now, the interesting problem--

00:32:54.360 --> 00:32:56.000
So let's start this up.

00:32:56.010 --> 00:32:59.100
Is that this is going to be
a somewhat unauthorized talk.

00:32:59.200 --> 00:33:00.420
I've talked with the groups a bit.

00:33:00.440 --> 00:33:02.310
But in general,
what we're going to do is we're going to

00:33:02.310 --> 00:33:06.540
reverse engineer on the fly these apps
and try to understand what's going on.

00:33:06.570 --> 00:33:12.270
The way I'm going to do it is with a
handy dandy little performance tool.

00:33:12.300 --> 00:33:13.680
This is a pet project.

00:33:13.790 --> 00:33:15.360
It's not yet on the developer CD.

00:33:15.380 --> 00:33:18.360
That tries to visualize
how threading goes on.

00:33:18.360 --> 00:33:23.970
Now, the first app I'm going
to look at is the Finder.

00:33:24.090 --> 00:33:24.390
OK.

00:33:24.500 --> 00:33:29.300
Let's get some action here.

00:33:31.720 --> 00:33:36.390
and what we're seeing here is a
timeline view in Thread Viewer.

00:33:36.400 --> 00:33:39.230
So each of the little blocks there
represents about a 50 millisecond

00:33:39.230 --> 00:33:42.790
interval and each of the bars represents

00:33:43.760 --> 00:33:47.330
Each thread.

00:33:47.330 --> 00:33:52.620
And so the idea here is that
you can see that there's three

00:33:52.620 --> 00:33:52.620
threads currently in the finder.

00:33:52.620 --> 00:33:52.620
Click around.

00:33:58.420 --> 00:34:00.240
and the colors change
according to what's going on.

00:34:00.310 --> 00:34:02.160
So for example,
the green represents that there's

00:34:02.160 --> 00:34:03.660
currently execution on that thread.

00:34:03.820 --> 00:34:07.180
The yellow represents that execution
occurred but is not currently occurring.

00:34:07.240 --> 00:34:09.820
So there was some execution
during the last sample.

00:34:09.900 --> 00:34:13.480
The green, as in here,
represents that the program

00:34:13.480 --> 00:34:14.860
was waiting in the run loop.

00:34:14.890 --> 00:34:17.720
The red represents that the
thread was waiting on the lock.

00:34:17.730 --> 00:34:21.060
Now the first thing I'll show you is
that you can see that there's basically

00:34:21.070 --> 00:34:22.820
one thread that does most of the action.

00:34:22.840 --> 00:34:23.680
That is the main thread.

00:34:23.680 --> 00:34:25.330
And that's how most applications run.

00:34:25.480 --> 00:34:29.140
So most of the drawing,
most of the UI logic is going on there.

00:34:29.140 --> 00:34:33.400
The second thread from the bottom,
the one that's locked,

00:34:33.400 --> 00:34:38.020
represents what the Finder
people call a sync thread.

00:34:38.060 --> 00:34:41.480
So the idea is that they cache
a lot of the information about

00:34:41.620 --> 00:34:43.440
what's going on in each folder.

00:34:43.440 --> 00:34:46.180
However, when you enter a folder
that you've already seen,

00:34:46.180 --> 00:34:48.430
you need something that will
go and make sure that nothing

00:34:48.490 --> 00:34:49.720
is changed in that folder.

00:34:49.720 --> 00:34:51.330
And that's what the sync thread does.

00:34:51.380 --> 00:34:53.340
So the idea is it quickly
goes and it looks in that

00:34:53.340 --> 00:34:55.700
directory in a separate thread.

00:34:55.700 --> 00:34:57.300
Notice that it's always existing.

00:34:57.310 --> 00:34:59.750
It's always locked,
so it can be started up quickly.

00:34:59.800 --> 00:35:03.840
And by having it on a separate thread,
you not only have the ability to

00:35:03.840 --> 00:35:07.290
basically have scalability and do
things in a multiprocessing way

00:35:07.300 --> 00:35:09.440
so that you get quick response,
but also,

00:35:09.500 --> 00:35:12.530
since you're accessing the disk,
you know that if that blocks-- because

00:35:12.660 --> 00:35:15.560
let's say it's an iDisk-- you're
going to be able to go and access

00:35:15.640 --> 00:35:19.720
that and wait for the response without
actually stopping the UI thread.

00:35:19.720 --> 00:35:23.710
And so that improves the user experience,
as Matt was telling us.

00:35:25.420 --> 00:35:27.060
Let's start Finder up again.

00:35:27.080 --> 00:35:31.810
The other thing that you'll
find as we click around

00:35:33.010 --> 00:35:37.460
is that each time that
we enter a new folder,

00:35:37.460 --> 00:35:40.000
we can see that new threads get started.

00:35:40.000 --> 00:35:42.440
So there was the remnants of one here,
and then we have a thread here.

00:35:42.440 --> 00:35:46.680
And that thread only stays around for a
small instance and then goes away again.

00:35:46.680 --> 00:35:49.200
And what's happening
there is that once again,

00:35:49.200 --> 00:35:51.400
the finder guys don't
want the UI to block.

00:35:51.600 --> 00:35:55.070
The finder would look miserable if every
time that you went into a new folder

00:35:55.070 --> 00:35:58.240
and it went out to touch the disk,
if the entire finder locked up.

00:35:58.240 --> 00:36:00.020
It's a horrible user experience.

00:36:00.070 --> 00:36:02.490
And so to avoid that,
as many of you probably will

00:36:02.570 --> 00:36:05.130
want to do in your own apps,
what they do is they have the disk

00:36:05.200 --> 00:36:07.320
accesses going on in a separate thread.

00:36:07.500 --> 00:36:10.120
When they enter the new folder, they go,
they catalog it,

00:36:10.200 --> 00:36:13.120
they do that on a separate thread,
and that way they know that the

00:36:13.120 --> 00:36:16.640
finder is not going to block
while they collect that data.

00:36:20.690 --> 00:36:24.200
A third example is if we do a copy.

00:36:24.270 --> 00:36:30.450
So let's go to the home directory,
and let's duplicate an application.

00:36:30.640 --> 00:36:35.830
And what we find is, again, up here,

00:36:37.230 --> 00:36:39.000
We've created a new thread.

00:36:39.000 --> 00:36:41.660
The idea is that the copy is something
that's going to be a long-running

00:36:41.660 --> 00:36:43.800
app or a long-running thread.

00:36:43.800 --> 00:36:46.040
It's something that's going
to be touching the disk,

00:36:46.120 --> 00:36:48.280
and so it's going to be blocking,
so you don't want it

00:36:48.280 --> 00:36:49.300
on the normal thread.

00:36:49.300 --> 00:36:51.960
And it's something that should be
running in the background because

00:36:52.120 --> 00:36:54.760
it's probably something that the
user doesn't have a huge amount,

00:36:54.760 --> 00:36:57.050
or doesn't really care that it
completes immediately and wants

00:36:57.300 --> 00:36:58.780
to be able to do other activities.

00:36:58.780 --> 00:37:02.050
And so the idea of being able to
split off this background task or

00:37:02.300 --> 00:37:04.460
background process is an important idea.

00:37:05.160 --> 00:37:08.730
So what you've seen here is that
the finder is using threading

00:37:08.730 --> 00:37:11.240
to avoid blocking on I/O,
in case they're accessing

00:37:11.320 --> 00:37:13.010
disks that are remote,
for example.

00:37:13.160 --> 00:37:16.490
You've seen trying to improve the user
experience by making sure that blocking

00:37:16.490 --> 00:37:19.930
stuff happens on separate threads,
and you've seen the idea of using

00:37:19.930 --> 00:37:22.160
the threads for background actions.

00:37:22.160 --> 00:37:29.080
Okay, the second example I'd
like to show is iTunes.

00:37:29.160 --> 00:37:35.160
So let's go back to Thread Viewer.

00:37:35.160 --> 00:37:36.220
Amen.

00:37:41.700 --> 00:37:43.660
We'll see there's a few
more threads in this.

00:37:43.730 --> 00:37:47.770
So let's start out by
getting some music playing.

00:37:53.400 --> 00:37:54.640
Okay, so we know it's actually playing.

00:37:54.640 --> 00:37:55.990
You know that this isn't canned.

00:37:56.230 --> 00:37:59.280
And what you see here is the
activity going on in the threads.

00:37:59.300 --> 00:38:01.270
The thread at the bottom, again,
is the main thread.

00:38:01.390 --> 00:38:03.860
So it's sitting there and
it's doing all the UI work.

00:38:03.950 --> 00:38:06.890
And if we actually had the
visualization part of iTunes going,

00:38:06.960 --> 00:38:08.630
you'd see that thread
basically pegging out,

00:38:08.630 --> 00:38:10.610
constantly running.

00:38:11.150 --> 00:38:14.930
The next thread up represents
basically data collect,

00:38:14.930 --> 00:38:17.500
or is the data decompression,
which is actually running as a

00:38:17.500 --> 00:38:21.460
deferred task as a Carbon thread.

00:38:21.740 --> 00:38:25.180
What you also will see is
occasionally on this third thread,

00:38:25.180 --> 00:38:26.790
there'll be some green blocks that go by.

00:38:26.800 --> 00:38:30.310
And what's happening there is that
there's actually a separate thread

00:38:30.320 --> 00:38:32.330
that's being used for accessing the disk.

00:38:32.360 --> 00:38:34.420
And so the idea is that
this thread goes off,

00:38:34.420 --> 00:38:36.480
and every now and then
when it needs data,

00:38:36.480 --> 00:38:39.800
it grabs as much data as it can,
stores it in a buffer.

00:38:39.800 --> 00:38:42.340
Then there's a separate thread that
actually does the decompression.

00:38:42.340 --> 00:38:46.050
And then the thread at the very
top where you see all the activity

00:38:46.050 --> 00:38:49.770
is actually the thread that sends
data off to the audio device.

00:38:50.540 --> 00:38:52.680
On the disk,
we want to do large accesses.

00:38:52.740 --> 00:38:57.140
We want to grab a huge amount of
data and then do the decompression.

00:38:57.140 --> 00:38:59.360
With the audio device,
we want to minimize latency.

00:38:59.380 --> 00:39:01.630
And so the idea is we want to
throw a few little bytes at a

00:39:01.630 --> 00:39:03.080
time out to that audio device.

00:39:03.080 --> 00:39:04.890
And so by having that
on a separate thread,

00:39:04.890 --> 00:39:07.410
that means that we can easily
send the data that's needed and

00:39:07.480 --> 00:39:10.810
do it in as timely a manner as
possible so we have no dropouts.

00:39:10.880 --> 00:39:14.250
In actuality,
the three threads that you see there,

00:39:14.250 --> 00:39:18.720
the decompression, the disk reads,
and the audio playback,

00:39:18.720 --> 00:39:20.520
are actually all controlled
by the sound system.

00:39:20.520 --> 00:39:21.740
And so the sound manager.

00:39:21.880 --> 00:39:24.970
So they're actually not threads
that iTunes actually went to

00:39:24.970 --> 00:39:26.850
any trouble to actually create.

00:39:27.320 --> 00:39:30.380
But once again,
you're seeing cases of iTunes using

00:39:30.390 --> 00:39:33.960
threading to avoid blocking on disk I/O.

00:39:34.030 --> 00:39:37.120
You see it trying to take the
tasks that are time critical and

00:39:37.230 --> 00:39:38.700
put them on separate threads.

00:39:38.800 --> 00:39:40.980
And you're seeing the idea of
trying to make sure that you can

00:39:41.090 --> 00:39:44.700
parallelize the code by breaking the
major parts of sort of this pipe and

00:39:44.700 --> 00:39:48.120
filter model into separate threads.

00:39:48.920 --> 00:39:52.100
Okay, these were just two examples about
how Apple is actually using threading.

00:39:52.130 --> 00:39:54.560
Hopefully the people who are
available for Q&A can give you

00:39:54.560 --> 00:39:57.460
some more ideas about when to
use threading and when not to.

00:39:57.460 --> 00:39:59.740
Thank you.

00:40:05.430 --> 00:40:06.440
Thanks, Robert.

00:40:06.510 --> 00:40:13.360
So the second demo we have is Ivan Posva,
who works on the Java Virtual Machine.

00:40:13.720 --> 00:40:16.740
And as I said earlier,
there are definitely cases

00:40:16.740 --> 00:40:21.560
where your application is more
inclined to be multithreaded,

00:40:21.560 --> 00:40:24.640
especially if you have lots of data
that can be operated on in parallel.

00:40:24.940 --> 00:40:28.410
So he's going to give us an example
of an application where this is

00:40:28.630 --> 00:40:31.600
the case and helps out a lot.

00:40:32.230 --> 00:40:34.540
Okay, good morning.

00:40:34.540 --> 00:40:39.240
What I have is basically a digital
elevation model from Switzerland,

00:40:39.240 --> 00:40:43.680
and I wrote a swing app that basically
renders scenes within Switzerland.

00:40:43.680 --> 00:40:47.060
So I have a UI element down here, swing.

00:40:47.060 --> 00:40:51.820
It says one, so I'll spawn this
rendering in one thread.

00:40:52.900 --> 00:40:57.870
So it goes off,
it tiles the image into small pieces,

00:40:57.970 --> 00:41:00.520
and does that on a thread.

00:41:00.520 --> 00:41:04.250
You see in the task manager,
one CPU is usually used,

00:41:04.250 --> 00:41:10.100
and the other CPU is Java UI making use
of the spare processing power to display.

00:41:10.100 --> 00:41:15.300
So we saw that it took 15.7
seconds to display this image.

00:41:15.320 --> 00:41:19.460
If I go to two or even three
threads on this machine,

00:41:19.570 --> 00:41:22.300
when I restart this image,
we see that it's not going

00:41:22.300 --> 00:41:22.880
to display the image.

00:41:22.880 --> 00:41:26.760
So we can see that the
UI updates much quicker.

00:41:26.890 --> 00:41:30.680
It's pegging both the CPUs, calculating.

00:41:30.680 --> 00:41:32.680
So what else do I have?

00:41:32.680 --> 00:41:36.680
I can do the same thing
with the satellite image,

00:41:36.770 --> 00:41:39.140
just taking the...

00:41:41.090 --> 00:41:48.290
Mark Tozer-Vilchez, Matt Watson,
Robert Bowdidge, Ivan Posva

00:41:50.010 --> 00:41:54.340
still use the UI while
it's calculating the stuff.

00:41:54.440 --> 00:42:00.970
So Java itself has built in support
for threading in the language.

00:42:01.420 --> 00:42:07.550
It's rather easy to use threading,
rather easy for us to update the UI at

00:42:07.560 --> 00:42:09.010
the same time as you do calculation.

00:42:09.010 --> 00:42:12.410
That's about it.

00:42:12.440 --> 00:42:16.900
So what was the performance benefit you
saw with your multi-threaded example?

00:42:18.140 --> 00:42:21.840
For this calculation,
it was about 1.8 scale factor,

00:42:21.930 --> 00:42:23.550
so that's pretty good.

00:42:23.670 --> 00:42:28.940
If you consider that part of the update
is happening while you're calculating,

00:42:28.940 --> 00:42:32.210
it's pretty using the
processors at max speed.

00:42:32.220 --> 00:42:36.520
So it's also a feature of the swing
implementation that the developer

00:42:36.770 --> 00:42:40.560
doesn't have to worry about the
locking for drawing to the UI,

00:42:40.560 --> 00:42:42.600
that just happens for them?

00:42:42.600 --> 00:42:45.900
That happens behind the
scenes for the user.

00:42:45.900 --> 00:42:47.640
You just say, repaint this area.

00:42:48.100 --> 00:42:49.780
Here's your new image.

00:42:49.850 --> 00:42:50.230
That's it.

00:42:50.240 --> 00:42:50.910
Great.

00:42:51.340 --> 00:42:52.200
Thanks, Ivan.

00:43:02.640 --> 00:43:06.280
So I'll bring up Mark to finish
off the information about this

00:43:06.280 --> 00:43:08.570
session and other sessions.

00:43:12.300 --> 00:43:17.100
What I wanted to do is bring up related
sessions that you might be interested

00:43:17.210 --> 00:43:21.600
in furthering your knowledge about
tuning and specific areas of how

00:43:21.640 --> 00:43:24.390
to get hardware advancements here.

00:43:24.520 --> 00:43:28.160
So session 121 with
Carbon Performance Tuning,

00:43:28.400 --> 00:43:32.980
which Robert will be at,
advanced Cocoa topics for session 123,

00:43:33.110 --> 00:43:36.260
the Darwin Kernel, and session 140.

00:43:36.260 --> 00:43:41.430
I also want to add that there will be
a Birds of a Feathers session at the

00:43:41.600 --> 00:43:44.450
end of the evening today at 6 p.m.

00:43:44.450 --> 00:43:48.860
here in Hall C, I believe it is,
with Velocity Engine.

00:43:48.860 --> 00:43:52.640
So we will actually discuss with
the updates on Velocity Engine.

00:43:52.640 --> 00:43:55.750
We wanted to kind of separate both
of these topics and allocate as

00:43:55.750 --> 00:43:57.680
much time as we could to threading.

00:43:57.700 --> 00:44:01.570
One of the things that last
year I was up here on stage

00:44:01.570 --> 00:44:05.080
promoting to you developers,
and at that time we didn't

00:44:05.200 --> 00:44:06.190
have dual-processor.

00:44:06.280 --> 00:44:09.540
I was promoting the fact that you
should thread your application,

00:44:09.650 --> 00:44:12.960
kind of not being able to tell you that,
hey, we're coming out with

00:44:12.960 --> 00:44:14.540
multi-processor systems.

00:44:14.560 --> 00:44:17.520
But if you thread today,
as OS X matures and was

00:44:17.550 --> 00:44:21.780
actually going to be released,
your application will run faster

00:44:21.780 --> 00:44:25.530
simply because the threading
model within OS X is a lot more

00:44:25.530 --> 00:44:28.040
efficient than what is in OS 9.

00:44:28.040 --> 00:44:31.880
So today with multi-processor systems,
you can see now why there's even

00:44:31.880 --> 00:44:35.300
more of a reason why you want
to optimize your applications.

00:44:35.300 --> 00:44:36.230
So taking that into account.

00:44:36.240 --> 00:44:38.920
So if you're doing a
single-threaded application,

00:44:38.920 --> 00:44:42.450
bringing it over to Mac OS X,
the customer experience is going to be,

00:44:42.450 --> 00:44:45.270
well, there might be some
performance enhancement,

00:44:45.270 --> 00:44:48.070
but really it's more perceptual
because OS X is actually

00:44:48.340 --> 00:44:49.880
doing all the work for you.

00:44:49.920 --> 00:44:54.350
If you multi-thread your application,
you get additional benefits

00:44:54.350 --> 00:44:58.380
because OS X now says,
okay, great, I can move things around a

00:44:58.390 --> 00:45:02.580
lot quicker and use the thread
model within the Mach kernel.

00:45:02.580 --> 00:45:06.160
Now, the next step is really
optimizing your application.

00:45:06.260 --> 00:45:09.340
So what we're doing is optimizing for
MP because just providing threads is

00:45:09.470 --> 00:45:12.580
not going to give you the efficiency
of using that second processor.

00:45:12.580 --> 00:45:14.610
That's where SMP comes into play.

00:45:14.660 --> 00:45:18.330
So actually paralyzing your code
and seeing where it makes sense to

00:45:18.460 --> 00:45:22.390
actually have your thread go off to
the second processor is what factoring

00:45:22.660 --> 00:45:24.750
or paralyzing your code involves.

00:45:24.800 --> 00:45:28.120
And that's what we term as
optimization for MP hardware.

00:45:28.120 --> 00:45:31.690
And that's what you kind of saw in
the example with QuickTime itself,

00:45:31.690 --> 00:45:36.100
actually balancing the pegging of each
processor so that SMP itself can...

00:45:36.260 --> 00:45:38.180
take care of the housekeeping there.