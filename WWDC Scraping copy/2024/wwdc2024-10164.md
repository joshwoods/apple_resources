# Wwdc2024 10164

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

What’s new in DockKitDiscover how intelligent tracking in DockKit allows for smoother transitions between subjects. We will cover what intelligent tracking is, how it uses an ML model to select and track subjects, and how you can use it in your app.Chapters0:00 -Introduction2:49 -Introduction to Intelligent Tracking4:07 -How it works7:08 -Custom control in your app9:52 -Button controls for DocKit14:03 -New camera modes14:46 -Monitor accessory batteryResourcesForum: Photos & CameraHD VideoSD VideoRelated VideosWWDC23Integrate with motorized iPhone stands using DockKit

Discover how intelligent tracking in DockKit allows for smoother transitions between subjects. We will cover what intelligent tracking is, how it uses an ML model to select and track subjects, and how you can use it in your app.

0:00 -Introduction

2:49 -Introduction to Intelligent Tracking

4:07 -How it works

7:08 -Custom control in your app

9:52 -Button controls for DocKit

14:03 -New camera modes

14:46 -Monitor accessory battery

Forum: Photos & Camera

HD VideoSD Video

HD Video

SD Video

Integrate with motorized iPhone stands using DockKit

Search this video…Hello everyone.My name is Dhruv Samant,an engineer on the DockKit team, and today,I'm thrilled to share the exciting updates and innovationswe've been working on for DockKit.Last year, we introduced DockKit, a groundbreaking frameworkthat elevates the iPhone content creationand video calling experiences to new heights.I have great news, the first DockKit-powered standsare now available for purchase at Apple Stores.Let us take a quick look at how you can set upand start using your DockKit stand.To get started, tap to pair your iPhone with your DockKit device.A pairing card will providestep-by-step instructions to complete the pairing process.Once paired, simply dock your iPhone.And there you have it. Your DockKit device is ready to go.Now, I can launch the iOS camera app,and the dock will automatically keep me in the frame.I can move around, and the dock follows me seamlessly.DockKit tracking also works in FaceTime.In fact, any app that uses Camera will now track youand keep you in the frame.With a DockKit device,and our user-friendly APIs, you can now designpersonalized and extraordinary experiences ranging from video capture,video conferencing to education and healthcare.With these devices, our customers can now focus on their contentwithout worrying about being in frame.This year we have an exciting update to DockKit,Intelligent Subject Tracking.Intelligent tracking uses Machine Learningto enhance the DockKit tracking experience.In this session we will talk about what Intelligent Tracking is,how it works and how you can use it in your applications.Next, we'll shift our focus to button controlsand unveil a new category of DockKit accessories.Then, we'll introduce new camera modes that now support DockKit functionality.Finally, we will look at how you can easily monitorthe battery of your DockKit accessory.Great! Let's dive into it.So, what is Intelligent Subject Tracking?Intelligent Subject Tracking aims to addressthe age-old question of who to focus on in a video scene.Imagine a scenario where some subjects are interacting with each other,or interacting with the camera, while others are in the background.It can be extremely challenging to determinethe most relevant individuals to track and maintain focus on.For instance, in this simple scene,as a cameraperson you will likely want to focus on the 2 subjects in the frontinteracting with each other and ignore the person in the back.As the scene gets more complex,we need more sophisticated ways to make these decisions.This is where Intelligent Subject Tracking comes into picture.Using advanced algorithms and Machine Learning,Intelligent Subject Tracking analyzes a scene in real-time.It identifies the main subjects, such as individual faces or objects,and then determines the most relevant person to trackbased on various factors like movement, speech, and proximity to the camera.This tracking is smooth and seamless,allowing you to focus on creating content without any manual intervention.Now lets look at the underlying algorithms,and frameworks that make this possible.Building upon the multi-person tracker in iOS 17,which used iPhone's image intelligence to estimate trajectoriesof multiple subjects in a scene,we've developed a brand new Intelligent Tracking Pipeline in iOS 18.This pipeline takes the datafrom the multi-person tracker and processes itthrough an advanced Subject Selection Machine Learning Model.This model analyzes various attributes like body pose,face pose, attention, and speaking confidence, to determinethe most relevant subject to focus on in a scene.We then have a subject framing modulethat takes the chosen subjects as input and, using advanced algorithms,determines the most visually appealing way to frame them.Once we have a final computed scene,we use the motor positional and velocity feedback to achievethe final actuator commands to send to the DockKit accessory.While our Intelligent Tracking system can handle many scenarios remarkably well,we acknowledge the expertise of a human cameraman.Consequently, we've introduced Watch Control for all DockKit devicesWith Watch Control, users can exert more precise controlover tracking and framing in the iOS Camera App.They can also manually control the DockKit accessoryto further refine their shot.Now, instead of just talking about it, let's see it in action!I have a DockKit stand and my iPhone herewith our new Intelligent Tracking Pipeline running.Since I am the only person in the frame, its an easy decision to track me.Now, I would like to invite my friend Steveto come and share the stage with me.Hey, Steve.Steve is now also a person of interestand Intelligent Tracking will select and track both of us.I can now simply use my Apple Watch to tap on Steve's face,and DockKit will now only track Steve.Steve, can you take a couple of steps in that direction?As you can see DockKit is now only tracking Steve.Steve is a good friend of mine but I would like to nowcontinue with the demonstration by unselecting him.To do this, I can just swipe on my watchto manually move my DockKit accessoryand tap on my face to start tracking me again.These are some great changes we brought to DockKit system tracking,without you having to add any additional code to your app.However, we want to give you even more control.To that end, we are providing accessto our Machine Learning signals in your app.This will enable you to create innovative and distinctive featuresthat your customers will love.If your application is using DockKit intelligent tracking,you can get a summary of tracked subjects with important attributes.We can query the tracking summary using the tracking states async sequence.The tracking state includes a time which is the time when the state was capturedand a list of tracked subjects.A tracked subject can either be a person or an object.A tracked subject will have an identifier, face rectangle, and saliency rank.If the subject is a person, we also providethe speaking confidence and looking at the camera confidence.The saliency rank represents our assessmentof the most important subject in the scene.Rank starts from 1 and increases monotonically.A lower rank indicates higher importance for that particular subject.For instance, Rank 1 is more salient than rank 2.The speaking confidence is the likelihood score of the person speaking.A confidence score of 0 indicates that the person is not speakingand a confidence score of 1 indicates that the person is speaking.Similarly, lookingAtCameraConfidenceis the likelihood score of the person looking directly at the camera.Now let us see how you can use these parametersin your app to create customized tracking features.Say now I am writing an app to always track the active speakers.First, I query tracking state as an async sequenceand save it in my variable trackingState.I update this variable whenever DockKit provides me with an update.Now to track the active speakers, I have a functionthat first gets the list of all tracked subjects that are personsand then filters them to get all persons speaking with a confidencegreater than 80%.I can then pass this list to the selectSubjects APIand just like that DockKit will now track all active speakers in the scene.This is great because it allows you to utilize our Machine Learning signalsto determine what is most important for your usersand design innovative and distinctive features effortlessly.So this is how you can benefit from intelligent tracking in your app.We are also adding button support for DockKit accessories.Let’s dive into how buttons workfor first party and third party applications.For Camera and FaceTime,DockKit supports three types of accessory events out of the box:Shutter, flip, and zoom.With the shutter event, users can quickly capture a photo or video.The flip event allows users to switch betweenthe front and back cameras seamlessly.The zoom event enables users to zoom in or out of the scene.We also deliver these events to your app, allowing youto implement custom behaviors that will enhance your users experience.Camera shutter and flip events are toggle eventsthat do not have any value associated with them.Camera zoom event has a relative factor.For example, a value of 2.0 should double the size of an imageand halve the field of view.You can handle the factor as you please.The accessory can also send a custom button event, including an IDto identify the button and a boolean value indicating whether it was pressed or not.This provides greater flexibility,enabling you to design custom behaviors that your customers will truly appreciate.Building on this, we're introducing a new class of DockKit accessoriesthat will greatly benefit from button support: Gimbals.Gimbals are a game-changer for action-packed sports and photography.They allow you to lock onto the athlete,eliminating the need for manual panning and tilting.These new DockKit gimbals will help stabilize camera movementto create smooth, and professional-looking videos.Let us see gimbals in action!I happen to have a dockKit gimbal with me.I have already paired it with my iPhone.I can simply dock my phone, and it magically connects to the gimbal.Now I can open the camera app, and the gimbal tracks me beautifully.I can now do cool new things with this gimbal.I can hold it in my hand, and it still tracks me.I can press the flip button on the gimbal to switch to the back cameraand show you my beautiful room.Look who we have here. Its Steve again, it’s nice to see you, Steve.I can now hit record to start recording a videoand use the scroll wheel to zoom into Steve.With gimbals, DockKit powers dynamic hand-held experiences.These new buttons help enable these experiences.Let us explore how you can take advantage of button controls in your app.Say I am writing a camera app to take panoramas.I have a DockKit gimbal with a custom button with ID 5and I want to take advantage of the buttonto start and stop rotating my gimbal to take a panorama.First I write 2 functions, one to start my Panorama rotation, and one to stop it.Then I subscribe to accessory events.When the user triggers the button 5 event on the dock,the event is communicated to my app.If button 5 is pressed, I start rotating the DockKit accessorywith a constant velocity.I stop rotating when the button is unpressed.With just a few lines of code I can now designbeautiful camera experiences with my DockKit accessory.Leveraging on our work in intelligent subject tracking, and remote controlI am excited to announce that in iOS 18 we have expanded DockKit supportto new camera modes in the iOS camera app - photo, panorama and cinematic mode.We can now track subjects in the Camera app for photo mode.You can use your Apple Watch or DockKit gimbalsto capture subjects and sceneries.In Pano mode, just one button press allows you to take beautiful panoramasto capture expansive representation of objectsand environments autonomously.In Cinematic mode, you can now track the person in focus cinematically.In iOS 18, we've also added a feature that allows you to monitorthe battery of your DockKit accessory within your app.You can utilize this data to implement custom behaviorsand display relevant status messages to your users.You can subscribe to the async sequence battery states.A dock can report charging states for multiple batteries.A battery is identified by a name,and it reports the current battery percentage and charging state.For instance, a Dock connected to powermight report battery level as 50% and charge state as charging.We introduced Intelligent Tracking which acts as an AI cameramanto select and track subjects in a scene autonomously.You can also manually control the cameramanusing an Apple Watch or direct the cameraman using APIs.We also introduced DockKit gimbals to support fast-paced sports photography.With these new APIs and accessories,I hope to unlock new exciting use-cases for DockKit.The innovation potential with DockKit is enormous,and I'm excited to see where this journey takes us!

Hello everyone.My name is Dhruv Samant,an engineer on the DockKit team, and today,I'm thrilled to share the exciting updates and innovationswe've been working on for DockKit.Last year, we introduced DockKit, a groundbreaking frameworkthat elevates the iPhone content creationand video calling experiences to new heights.I have great news, the first DockKit-powered standsare now available for purchase at Apple Stores.Let us take a quick look at how you can set upand start using your DockKit stand.

To get started, tap to pair your iPhone with your DockKit device.

A pairing card will providestep-by-step instructions to complete the pairing process.

Once paired, simply dock your iPhone.

And there you have it. Your DockKit device is ready to go.Now, I can launch the iOS camera app,and the dock will automatically keep me in the frame.

I can move around, and the dock follows me seamlessly.

DockKit tracking also works in FaceTime.In fact, any app that uses Camera will now track youand keep you in the frame.With a DockKit device,and our user-friendly APIs, you can now designpersonalized and extraordinary experiences ranging from video capture,video conferencing to education and healthcare.With these devices, our customers can now focus on their contentwithout worrying about being in frame.This year we have an exciting update to DockKit,Intelligent Subject Tracking.Intelligent tracking uses Machine Learningto enhance the DockKit tracking experience.In this session we will talk about what Intelligent Tracking is,how it works and how you can use it in your applications.Next, we'll shift our focus to button controlsand unveil a new category of DockKit accessories.Then, we'll introduce new camera modes that now support DockKit functionality.Finally, we will look at how you can easily monitorthe battery of your DockKit accessory.Great! Let's dive into it.So, what is Intelligent Subject Tracking?Intelligent Subject Tracking aims to addressthe age-old question of who to focus on in a video scene.Imagine a scenario where some subjects are interacting with each other,or interacting with the camera, while others are in the background.It can be extremely challenging to determinethe most relevant individuals to track and maintain focus on.For instance, in this simple scene,as a cameraperson you will likely want to focus on the 2 subjects in the frontinteracting with each other and ignore the person in the back.As the scene gets more complex,we need more sophisticated ways to make these decisions.This is where Intelligent Subject Tracking comes into picture.

Using advanced algorithms and Machine Learning,Intelligent Subject Tracking analyzes a scene in real-time.It identifies the main subjects, such as individual faces or objects,and then determines the most relevant person to trackbased on various factors like movement, speech, and proximity to the camera.This tracking is smooth and seamless,allowing you to focus on creating content without any manual intervention.Now lets look at the underlying algorithms,and frameworks that make this possible.Building upon the multi-person tracker in iOS 17,which used iPhone's image intelligence to estimate trajectoriesof multiple subjects in a scene,we've developed a brand new Intelligent Tracking Pipeline in iOS 18.This pipeline takes the datafrom the multi-person tracker and processes itthrough an advanced Subject Selection Machine Learning Model.This model analyzes various attributes like body pose,face pose, attention, and speaking confidence, to determinethe most relevant subject to focus on in a scene.

We then have a subject framing modulethat takes the chosen subjects as input and, using advanced algorithms,determines the most visually appealing way to frame them.

Once we have a final computed scene,we use the motor positional and velocity feedback to achievethe final actuator commands to send to the DockKit accessory.

While our Intelligent Tracking system can handle many scenarios remarkably well,we acknowledge the expertise of a human cameraman.Consequently, we've introduced Watch Control for all DockKit devicesWith Watch Control, users can exert more precise controlover tracking and framing in the iOS Camera App.They can also manually control the DockKit accessoryto further refine their shot.Now, instead of just talking about it, let's see it in action!I have a DockKit stand and my iPhone herewith our new Intelligent Tracking Pipeline running.

Since I am the only person in the frame, its an easy decision to track me.Now, I would like to invite my friend Steveto come and share the stage with me.Hey, Steve.

Steve is now also a person of interestand Intelligent Tracking will select and track both of us.I can now simply use my Apple Watch to tap on Steve's face,and DockKit will now only track Steve.

Steve, can you take a couple of steps in that direction?As you can see DockKit is now only tracking Steve.Steve is a good friend of mine but I would like to nowcontinue with the demonstration by unselecting him.To do this, I can just swipe on my watchto manually move my DockKit accessoryand tap on my face to start tracking me again.

These are some great changes we brought to DockKit system tracking,without you having to add any additional code to your app.However, we want to give you even more control.To that end, we are providing accessto our Machine Learning signals in your app.This will enable you to create innovative and distinctive featuresthat your customers will love.If your application is using DockKit intelligent tracking,you can get a summary of tracked subjects with important attributes.

We can query the tracking summary using the tracking states async sequence.The tracking state includes a time which is the time when the state was capturedand a list of tracked subjects.A tracked subject can either be a person or an object.

A tracked subject will have an identifier, face rectangle, and saliency rank.If the subject is a person, we also providethe speaking confidence and looking at the camera confidence.

The saliency rank represents our assessmentof the most important subject in the scene.Rank starts from 1 and increases monotonically.A lower rank indicates higher importance for that particular subject.For instance, Rank 1 is more salient than rank 2.The speaking confidence is the likelihood score of the person speaking.A confidence score of 0 indicates that the person is not speakingand a confidence score of 1 indicates that the person is speaking.Similarly, lookingAtCameraConfidenceis the likelihood score of the person looking directly at the camera.Now let us see how you can use these parametersin your app to create customized tracking features.Say now I am writing an app to always track the active speakers.First, I query tracking state as an async sequenceand save it in my variable trackingState.I update this variable whenever DockKit provides me with an update.Now to track the active speakers, I have a functionthat first gets the list of all tracked subjects that are personsand then filters them to get all persons speaking with a confidencegreater than 80%.I can then pass this list to the selectSubjects APIand just like that DockKit will now track all active speakers in the scene.This is great because it allows you to utilize our Machine Learning signalsto determine what is most important for your usersand design innovative and distinctive features effortlessly.So this is how you can benefit from intelligent tracking in your app.We are also adding button support for DockKit accessories.Let’s dive into how buttons workfor first party and third party applications.For Camera and FaceTime,DockKit supports three types of accessory events out of the box:Shutter, flip, and zoom.With the shutter event, users can quickly capture a photo or video.The flip event allows users to switch betweenthe front and back cameras seamlessly.The zoom event enables users to zoom in or out of the scene.We also deliver these events to your app, allowing youto implement custom behaviors that will enhance your users experience.Camera shutter and flip events are toggle eventsthat do not have any value associated with them.Camera zoom event has a relative factor.For example, a value of 2.0 should double the size of an imageand halve the field of view.You can handle the factor as you please.The accessory can also send a custom button event, including an IDto identify the button and a boolean value indicating whether it was pressed or not.

This provides greater flexibility,enabling you to design custom behaviors that your customers will truly appreciate.Building on this, we're introducing a new class of DockKit accessoriesthat will greatly benefit from button support: Gimbals.Gimbals are a game-changer for action-packed sports and photography.They allow you to lock onto the athlete,eliminating the need for manual panning and tilting.These new DockKit gimbals will help stabilize camera movementto create smooth, and professional-looking videos.Let us see gimbals in action!I happen to have a dockKit gimbal with me.

I have already paired it with my iPhone.I can simply dock my phone, and it magically connects to the gimbal.

Now I can open the camera app, and the gimbal tracks me beautifully.

I can now do cool new things with this gimbal.I can hold it in my hand, and it still tracks me.

I can press the flip button on the gimbal to switch to the back cameraand show you my beautiful room.

Look who we have here. Its Steve again, it’s nice to see you, Steve.I can now hit record to start recording a videoand use the scroll wheel to zoom into Steve.With gimbals, DockKit powers dynamic hand-held experiences.These new buttons help enable these experiences.Let us explore how you can take advantage of button controls in your app.Say I am writing a camera app to take panoramas.I have a DockKit gimbal with a custom button with ID 5and I want to take advantage of the buttonto start and stop rotating my gimbal to take a panorama.First I write 2 functions, one to start my Panorama rotation, and one to stop it.Then I subscribe to accessory events.When the user triggers the button 5 event on the dock,the event is communicated to my app.If button 5 is pressed, I start rotating the DockKit accessorywith a constant velocity.I stop rotating when the button is unpressed.With just a few lines of code I can now designbeautiful camera experiences with my DockKit accessory.Leveraging on our work in intelligent subject tracking, and remote controlI am excited to announce that in iOS 18 we have expanded DockKit supportto new camera modes in the iOS camera app - photo, panorama and cinematic mode.We can now track subjects in the Camera app for photo mode.You can use your Apple Watch or DockKit gimbalsto capture subjects and sceneries.In Pano mode, just one button press allows you to take beautiful panoramasto capture expansive representation of objectsand environments autonomously.In Cinematic mode, you can now track the person in focus cinematically.In iOS 18, we've also added a feature that allows you to monitorthe battery of your DockKit accessory within your app.You can utilize this data to implement custom behaviorsand display relevant status messages to your users.You can subscribe to the async sequence battery states.A dock can report charging states for multiple batteries.A battery is identified by a name,and it reports the current battery percentage and charging state.For instance, a Dock connected to powermight report battery level as 50% and charge state as charging.

We introduced Intelligent Tracking which acts as an AI cameramanto select and track subjects in a scene autonomously.You can also manually control the cameramanusing an Apple Watch or direct the cameraman using APIs.We also introduced DockKit gimbals to support fast-paced sports photography.With these new APIs and accessories,I hope to unlock new exciting use-cases for DockKit.The innovation potential with DockKit is enormous,and I'm excited to see where this journey takes us!

## Code Samples

