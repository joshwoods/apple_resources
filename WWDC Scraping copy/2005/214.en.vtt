WEBVTT

00:00:04.000 --> 00:00:08.800
Welcome to the Maximizing
OpenGL Performance session.

00:00:09.120 --> 00:00:10.130
My name's John Stauffer.

00:00:10.220 --> 00:00:13.240
I manage the OpenGL Engineering group.

00:00:14.500 --> 00:00:17.090
So, let's talk a little bit about
what we want to learn today.

00:00:17.090 --> 00:00:18.740
So what this session is,
it's a little bit

00:00:18.870 --> 00:00:21.600
different than last year,
if anybody's gone to that session.

00:00:21.600 --> 00:00:24.400
We tried to provide a little
bit different content here.

00:00:24.400 --> 00:00:29.580
What this session is about is to
give you a hands-on session about

00:00:29.650 --> 00:00:32.750
how to optimize your application.

00:00:32.750 --> 00:00:36.340
So we're going to talk,
let's go down the subjects here.

00:00:36.340 --> 00:00:38.710
We're going to introduce a
seed and tell you how to get

00:00:38.790 --> 00:00:40.460
involved in the seeding program.

00:00:41.300 --> 00:00:43.780
We're going to go over some key concepts,
some just high-level key

00:00:43.780 --> 00:00:46.070
concepts that we're going to
want people to keep in mind.

00:00:46.100 --> 00:00:48.810
Basic tips, and they are fairly basic.

00:00:48.820 --> 00:00:51.110
Then we're going to get into
more detail about texture

00:00:51.110 --> 00:00:52.800
uploading and vertex throughput.

00:00:52.800 --> 00:00:57.230
So, the two main types of data
bandwidth primitives that

00:00:57.250 --> 00:01:02.140
are going through the system,
being pixels and vertices.

00:01:02.140 --> 00:01:05.400
We'll talk about how to
optimize that data throughput.

00:01:05.400 --> 00:01:07.680
So, the OpenGL seed.

00:01:08.200 --> 00:01:10.760
So, for some of you that
haven't seen this already,

00:01:10.760 --> 00:01:14.880
we have an OpenGL seeding program
that we have announced for developers.

00:01:14.880 --> 00:01:18.750
What this allows developers to
do is get early access to the

00:01:18.760 --> 00:01:21.040
OpenGL framework and drivers.

00:01:21.040 --> 00:01:25.490
And the benefit that brings to you is
it gives you early access to features,

00:01:25.700 --> 00:01:28.470
bug fixes that you may have
that you're looking for,

00:01:28.470 --> 00:01:32.340
profiling and tuning,
enhancements that may be coming.

00:01:32.340 --> 00:01:36.110
But it gives you early access and
it gets you started developing

00:01:36.110 --> 00:01:38.180
with the technology advanced.

00:01:38.180 --> 00:01:39.880
So, we're going to talk about
the software updates and the

00:01:39.960 --> 00:01:41.100
improvements we're making earlier.

00:01:41.220 --> 00:01:43.120
You don't have to wait for a software
update before getting your hands

00:01:43.120 --> 00:01:44.190
on it and then giving us feedback.

00:01:44.200 --> 00:01:47.190
We want the feedback before
we release it the first time.

00:01:47.410 --> 00:01:53.630
So the email address to get access
to that is openglseed@apple.com.

00:01:53.630 --> 00:01:56.120
And what you'll want to do if you
want to become part of this program

00:01:56.120 --> 00:02:01.380
is send an email to that address,
list who you are, why you want to become

00:02:01.390 --> 00:02:06.270
active member of this seed,
and then that email will go to Apple.

00:02:06.300 --> 00:02:09.570
And we'll sit down and see if we
can make you part of that program.

00:02:11.650 --> 00:02:13.870
So, key concepts.

00:02:14.140 --> 00:02:17.370
So this is kind of kicking off what
we're going to be doing in this session.

00:02:17.380 --> 00:02:22.840
What we try to do when we analyze
problems at Apple is you kind of put

00:02:22.840 --> 00:02:24.660
yourself in the mind of a detective,
right?

00:02:24.660 --> 00:02:27.460
You've got to sit down,
you've got to gather clues,

00:02:27.460 --> 00:02:31.260
you've got to try to come to a problem
with an open mind and make sure that

00:02:31.260 --> 00:02:35.340
you are basing your decisions on facts,
clues that you're gathering.

00:02:35.340 --> 00:02:38.870
So what we're going to try to do in
this session is give you the tools,

00:02:38.870 --> 00:02:41.460
the ability to gather clues as to
where your performance is going to be.

00:02:41.500 --> 00:02:43.700
So I'll be going through
some demonstrations of

00:02:43.770 --> 00:02:47.150
going through the tools,
using the tools, analyzing some problems,

00:02:47.160 --> 00:02:49.620
and seeing if we can
figure out what's going on.

00:02:49.660 --> 00:02:52.120
So, what tools do we want to use?

00:02:52.150 --> 00:02:55.440
So, for OpenGL applications,
clearly the OpenGL tools are an

00:02:55.440 --> 00:02:57.280
important part of that process.

00:02:57.280 --> 00:03:00.540
The OpenGL Profiler,
the OpenGL Driver Monitor,

00:03:00.600 --> 00:03:01.680
but also Shark.

00:03:01.740 --> 00:03:05.410
Shark is a very powerful tool and a
very important part of any attempt

00:03:05.410 --> 00:03:07.270
to optimize your application.

00:03:07.280 --> 00:03:11.460
So, some of the things that we
will do in this session.

00:03:11.500 --> 00:03:13.860
So, one of the things that we will do
in this session then is start using

00:03:13.860 --> 00:03:17.450
some OpenGL extensions to optimize
some of the problems we're finding.

00:03:17.460 --> 00:03:20.510
And we'll go a little bit more in detail
about what extensions we're going to use,

00:03:20.510 --> 00:03:22.560
but we're only going to
touch on a couple of them.

00:03:22.560 --> 00:03:23.730
There's lots of extensions out there.

00:03:23.740 --> 00:03:25.280
We'll touch on a couple.

00:03:26.900 --> 00:03:28.400
So some basic tips.

00:03:28.410 --> 00:03:31.930
I like to repeat these every year to make
sure that everyone is aware of these.

00:03:31.930 --> 00:03:35.380
So calling GL flush is
something you rarely want to do.

00:03:35.380 --> 00:03:37.780
You have to have a
good reason to call it.

00:03:37.840 --> 00:03:41.080
There are a few cases out
there you'll want to call it,

00:03:41.080 --> 00:03:43.060
but most people don't need it.

00:03:43.230 --> 00:03:46.290
So if your application calls GL flush,
remove it.

00:03:46.420 --> 00:03:50.200
If you call GL finish,
there's no reason to ever call GL finish.

00:03:50.540 --> 00:03:51.340
Remove that.

00:03:51.340 --> 00:03:53.950
Those are the first things you
want to do to an application.

00:03:56.660 --> 00:03:57.660
So some OpenGL extensions.

00:03:57.660 --> 00:04:01.330
We're going to be looking at
today our vertex buffer object,

00:04:01.350 --> 00:04:04.600
and that's an extension for moving
vertex data through the system.

00:04:04.600 --> 00:04:08.910
There's Apple Texture
Range and Apple Client Storage.

00:04:08.910 --> 00:04:12.480
Those are extensions used for
optimizing texture upload.

00:04:12.480 --> 00:04:15.140
So we'll be looking at those
for optimizing our data flow

00:04:15.270 --> 00:04:16.800
in our applications today.

00:04:17.440 --> 00:04:21.140
So the other important basic tip then
is to minimize your state changes.

00:04:21.150 --> 00:04:23.560
State changes in OpenGL can be expensive.

00:04:23.560 --> 00:04:27.040
And in fact, if you change state a lot,
you can be bottlenecked

00:04:27.090 --> 00:04:29.720
simply by your state changes,
not by your data movement,

00:04:29.760 --> 00:04:31.950
but by how you are managing your state.

00:04:32.140 --> 00:04:35.680
If you're doing a lot of state
changes and little geometry,

00:04:35.680 --> 00:04:40.800
little in the way of moving data,
then it's your state changes that

00:04:40.800 --> 00:04:42.950
will be your predominant bottleneck.

00:04:43.820 --> 00:04:46.840
Okay, so let's get into a demo here.

00:04:46.970 --> 00:04:49.550
Switch to Demo Machine 1, please.

00:04:54.150 --> 00:05:02.160
So what I've got here,
let me just run it and we'll take a look.

00:05:02.180 --> 00:05:08.240
I've got a basic demo here showing
a mesh that's been texture mapped.

00:05:08.270 --> 00:05:11.080
And I want to analyze
the performance of this.

00:05:11.130 --> 00:05:16.000
So what we're going to do is
we're going to launch a few tools,

00:05:16.000 --> 00:05:19.680
and we're going to see
what this shows us.

00:05:19.710 --> 00:05:19.910
So the first tool I'm
going to launch is Shark.

00:05:20.030 --> 00:05:21.500
Sharks fairly easy to use.

00:05:21.560 --> 00:05:23.160
We're just going to launch it.

00:05:23.180 --> 00:05:26.500
We're going to hit start to take
a sample for about five seconds.

00:05:26.520 --> 00:05:28.540
We'll hit stop.

00:05:28.670 --> 00:05:31.000
Let it generate the report.

00:05:32.500 --> 00:05:36.840
So, looking at the top items here,
the first one we see is

00:05:36.840 --> 00:05:38.500
it's often an interrupt.

00:05:38.500 --> 00:05:39.240
Okay.

00:05:39.700 --> 00:05:41.940
Well, that doesn't look good, right?

00:05:42.010 --> 00:05:45.810
Down at the bottom here,
if people can see, we can see that we're

00:05:45.810 --> 00:05:47.500
using about 39% of the CPU.

00:05:47.500 --> 00:05:51.500
Well, let's say that this application,
I want to use 100% of the CPU.

00:05:51.500 --> 00:05:53.500
I want it to be maximum performance.

00:05:53.500 --> 00:05:56.000
So, why am I only using 30% of the CPU?

00:05:56.000 --> 00:05:59.660
Why am I spending 30% of my application
time up here in an interrupt?

00:05:59.820 --> 00:06:01.290
So, those are things I'll want to solve.

00:06:01.500 --> 00:06:02.510
Thank you.

00:06:02.940 --> 00:06:05.160
Looking down here,
I'm spending about 30% of

00:06:05.160 --> 00:06:07.200
my time calculating a wave.

00:06:07.200 --> 00:06:10.740
So let's launch some more tools to see
what other information we can gather.

00:06:10.790 --> 00:06:14.890
So I'm going to launch
the OpenGL Profiler.

00:06:15.730 --> 00:06:19.120
For those of you that
have never seen this tool,

00:06:19.120 --> 00:06:21.270
there's a variety of ways to use it.

00:06:21.300 --> 00:06:22.770
We'll get into a little
more detail later,

00:06:22.920 --> 00:06:27.880
but right now I'm just going to attach
to this application while it's running.

00:06:28.120 --> 00:06:31.200
Scroll down, find my demo app there.

00:06:31.230 --> 00:06:33.820
I'm going to attach this tool to it.

00:06:34.400 --> 00:06:38.800
Now,
once I'm attached to the OpenGL Profiler,

00:06:38.820 --> 00:06:43.060
I can go up here and I can
pull down a statistics view.

00:06:43.080 --> 00:06:46.900
I like to clear it,
just to make sure my stats are current.

00:06:48.350 --> 00:06:50.820
Let me shrink it a little bit,
not to use too much screen space.

00:06:50.950 --> 00:06:54.540
So, and I'll sort the times
based on percent time OpenGL.

00:06:54.660 --> 00:06:58.020
So, looking at this,
there's a variety of information

00:06:58.120 --> 00:06:59.760
we can pull out of this.

00:06:59.800 --> 00:07:03.560
One is I can see that the top
OpenGL call that's consuming time in

00:07:03.660 --> 00:07:05.450
this application is draw elements.

00:07:06.110 --> 00:07:11.910
Using 97% of the GL time,
or looking at this column,

00:07:12.400 --> 00:07:28.700
[Transcript missing]

00:07:29.120 --> 00:07:32.980
And what the OpenGL Driver Monitor does,
it queries values directly out

00:07:33.240 --> 00:07:36.070
of the kernel graphics driver.

00:07:37.780 --> 00:07:44.480
And the parameter I have preset here
is a parameter called CPU Wait for GPU.

00:07:44.500 --> 00:07:48.900
And what that means is that's the
amount of time the CPU is waiting for

00:07:48.900 --> 00:07:52.250
the graphics processor to complete.

00:07:54.050 --> 00:08:01.000
So, what we can see here,
let me set this to linear scale here,

00:08:01.170 --> 00:08:04.500
and I'm using the percent numbers
on the right-hand side of the scale.

00:08:04.550 --> 00:08:09.260
So what I can see is I'm spending
about 35% of my CPU time waiting

00:08:09.260 --> 00:08:10.590
for the graphics processors.

00:08:10.660 --> 00:08:13.770
So my CPU is just spin
looping in the driver,

00:08:14.280 --> 00:08:18.510
waiting for something to happen
in the graphics processor.

00:08:18.510 --> 00:08:18.510
Now,

00:08:18.740 --> 00:08:21.200
That's approximately
correlating with Shark.

00:08:21.410 --> 00:08:24.260
Shark is telling me that
something is spending about

00:08:24.430 --> 00:08:27.220
30% of the time spin looping.

00:08:27.300 --> 00:08:30.630
So I'm finding that these two tools
are showing me something here.

00:08:30.920 --> 00:08:33.920
So now the trick is to find
out what's causing that.

00:08:33.990 --> 00:08:36.740
So what you can do in the
Driver Monitor is you can

00:08:36.740 --> 00:08:39.930
open this parameters window,
okay, and there's a variety of parameters

00:08:39.930 --> 00:08:45.380
you can investigate that will give you
more resolution into these problems.

00:08:46.200 --> 00:08:49.100
Anything here that starts with a,
that has the word "wait" in it is

00:08:49.100 --> 00:08:52.500
something that's going to monitor
blocking points in the driver,

00:08:52.570 --> 00:08:55.940
points at which the CPU is
waiting for the GPU.

00:08:56.100 --> 00:09:00.100
The CPU wait for GPU is
the total of all of those.

00:09:00.100 --> 00:09:01.100
So I'm looking at the total.

00:09:01.100 --> 00:09:04.240
So now what I want to do is go
in and find the individual item

00:09:04.240 --> 00:09:06.080
that's contributing to that.

00:09:06.100 --> 00:09:08.570
Well it turns out,
since I set this up in advance,

00:09:08.630 --> 00:09:09.890
I already know what it is.

00:09:09.890 --> 00:09:13.100
It's CPU wait for free
OpenGL command buffers.

00:09:13.100 --> 00:09:15.070
It's this command here.

00:09:15.160 --> 00:09:18.120
So if I select that,
I can see the red line and the green

00:09:18.120 --> 00:09:20.460
line are fairly close to each other.

00:09:20.870 --> 00:09:24.380
So now the question is,
what's causing that?

00:09:24.380 --> 00:09:26.240
Well,
that's where it gets a little tricky.

00:09:26.240 --> 00:09:31.700
So let's look at the code and see if
we can analyze a little bit more detail

00:09:31.700 --> 00:09:33.400
as to what could be causing that.

00:09:33.580 --> 00:09:41.620
So let's quit this application and
let's open up my actual source code.

00:09:41.620 --> 00:09:41.620
And

00:09:42.000 --> 00:09:46.130
I'm going to... Someone was fortunate
enough to put comments in here labeling

00:09:46.130 --> 00:09:48.590
everything that was bad in here.

00:09:49.740 --> 00:09:54.000
So, one piece of information actually
that I forgot to mention was that

00:09:54.040 --> 00:09:57.010
what's interesting about this
application is that it seems to be

00:09:57.010 --> 00:09:59.140
locked in at 60 frames a second.

00:09:59.230 --> 00:10:02.390
That's actually a pretty good clue to me
because I know that the refresh rate of

00:10:02.390 --> 00:10:04.340
these monitors are 60 frames a second.

00:10:04.400 --> 00:10:08.980
So, somehow what it tells me is that
it's likely that my refresh rate

00:10:09.020 --> 00:10:14.360
in my demo is somehow locked to
the refresh rate of the display.

00:10:14.640 --> 00:10:17.810
The one thing I know that can
do that is a CGL set parameter

00:10:17.810 --> 00:10:20.650
setting the swap interval to 1.

00:10:20.660 --> 00:10:23.020
And what that does is that
tells OpenGL to be tear-free.

00:10:23.220 --> 00:10:26.200
Okay, so my OpenGL presentation
is going to be tear-free,

00:10:26.390 --> 00:10:28.440
which is good in some cases,
but in this case I want

00:10:28.440 --> 00:10:29.560
maximum performance.

00:10:29.650 --> 00:10:31.880
I'm not looking for
tear-free presentation.

00:10:31.940 --> 00:10:35.000
Okay,
so let's go ahead and comment that out,

00:10:35.050 --> 00:10:38.880
because I'm just looking
to get maximum throughput.

00:10:39.240 --> 00:10:41.860
So we commented out
the CGL set parameter.

00:10:41.890 --> 00:10:42.800
We're going to close that window.

00:10:42.800 --> 00:10:46.200
Now we're going to launch it again.

00:10:48.800 --> 00:10:50.300
I'll let it compile.

00:10:50.300 --> 00:10:54.680
OK, so we went from 60
frames a second to 118,

00:10:54.680 --> 00:10:55.580
115.

00:10:56.700 --> 00:11:00.000
Let's go ahead and take
another shark sample.

00:11:00.110 --> 00:11:02.480
Take a look and see what that looks like.

00:11:08.260 --> 00:11:10.840
Okay, so we can see that, in fact,
that was it, right?

00:11:10.880 --> 00:11:15.960
So the top item, which was blocking spin
looping down in the kernel,

00:11:15.970 --> 00:11:19.500
is now gone, and now we're spending,
instead of approximately 30% of

00:11:19.500 --> 00:11:21.800
our CPU time calculating the wave,
we're spending 44.

00:11:21.800 --> 00:11:24.760
Our performance got about twice as fast.

00:11:27.040 --> 00:11:32.300
So, okay, so let's,
so we did what we needed to do there.

00:11:32.300 --> 00:11:36.110
Now looking over at the driver monitor,
we can see that our CPU time

00:11:36.480 --> 00:11:39.000
waiting for the GPU has dropped,
right?

00:11:39.000 --> 00:11:42.890
It went from 30 plus
percent down to zero.

00:11:43.140 --> 00:11:48.480
Okay, so now we believe that we are not
artificially blocking ourselves

00:11:48.480 --> 00:11:50.330
against a graphics processor.

00:11:53.220 --> 00:11:54.810
So let's back up a little bit now.

00:11:54.930 --> 00:11:57.500
Let's go and review the tools.

00:11:57.530 --> 00:12:00.080
I just gave you a quick example,
but let's go over the tools

00:12:00.080 --> 00:12:01.480
in a little more detail.

00:12:02.760 --> 00:12:08.670
So the OpenGL Driver Monitor is
a powerful tool that has

00:12:08.670 --> 00:12:09.500
a number of features.

00:12:09.570 --> 00:12:12.850
So the first screen you see in
the OpenGL Driver Monitor is

00:12:12.850 --> 00:12:14.500
this screen right in the center.

00:12:14.510 --> 00:12:17.380
And this screen gives you the
ability to launch or attach

00:12:17.380 --> 00:12:18.950
to an OpenGL application.

00:12:19.390 --> 00:12:22.760
So if I wanted to,
I could launch an application

00:12:22.790 --> 00:12:26.320
simply by clicking the Add button,
adding an application to that list,

00:12:26.320 --> 00:12:29.190
adding it, and then it'll show up here.

00:12:29.200 --> 00:12:33.210
Now, the basic difference between adding
an application and attaching is

00:12:33.210 --> 00:12:36.870
that if you launch an application,
I'm sorry, from launching an application

00:12:36.870 --> 00:12:39.180
and attaching to an application,
is that when you launch it,

00:12:39.180 --> 00:12:42.750
you can actually vary some of the startup
characteristics of the application.

00:12:42.760 --> 00:12:47.660
So, for instance, I could vary the pixel
format that's used.

00:12:48.900 --> 00:12:51.260
For those that program OpenGL,
you know that to create

00:12:51.340 --> 00:12:53.790
an OpenGL context,
you have to create,

00:12:54.370 --> 00:12:58.540
define a list of attributes for how
you want that context to be created.

00:12:58.540 --> 00:13:02.120
So if you wanted to, in real time,
without recompiling your application,

00:13:02.120 --> 00:13:05.370
you could come in here and vary
that pixel format attribute list.

00:13:05.420 --> 00:13:08.230
So an example of that would be,
let's say I wanted to

00:13:08.230 --> 00:13:09.620
change my depth size.

00:13:09.620 --> 00:13:14.270
Let's say I wanted to make it a 16-bit
depth instead of a 32-bit depth,

00:13:14.320 --> 00:13:15.360
for example.

00:13:15.360 --> 00:13:18.880
Okay, so we're not going to use that,
but good to know.

00:13:18.900 --> 00:13:23.700
Another item that is useful
for people is the ability to

00:13:23.740 --> 00:13:28.780
emulate different hardware,
and the emulation is simply on the

00:13:28.780 --> 00:13:30.570
return values OpenGL will give you.

00:13:30.580 --> 00:13:33.580
In other words, if your application is
querying into OpenGL,

00:13:33.580 --> 00:13:37.110
this will vary the return values
that OpenGL gives your application.

00:13:37.120 --> 00:13:39.990
It will not actually vary the
behavior of a graphics driver.

00:13:40.000 --> 00:13:43.540
So let's say that this
graphics device I have here,

00:13:43.570 --> 00:13:46.640
I want it to behave like a RAGE 128.

00:13:48.500 --> 00:13:51.560
If you look at what that does,
is it will vary these

00:13:51.560 --> 00:13:53.620
return values from OpenGL.

00:13:53.620 --> 00:14:00.160
Okay, so we have a list of extensions
that will simulate a RAGE 128.

00:14:00.160 --> 00:14:02.880
We have a list of return parameters
that simulate a RAGE 128.

00:14:02.880 --> 00:14:07.170
This is useful for developers who
are looking to try to test certain

00:14:07.180 --> 00:14:10.820
behaviors of their application,
how their application responds

00:14:10.820 --> 00:14:14.020
to different graphics devices
with different feature sets.

00:14:14.020 --> 00:14:17.170
Okay, and we're not going to
use that right now either.

00:14:19.550 --> 00:14:22.110
So let's go ahead and launch
the application we were

00:14:22.120 --> 00:14:24.740
just looking at previously,
but launch it through

00:14:24.740 --> 00:14:27.010
the OpenGL Profiler.

00:14:27.260 --> 00:14:29.060
So there it is.

00:14:29.630 --> 00:14:32.430
Now let's go look at some of the
other features of the Profiler.

00:14:32.620 --> 00:14:35.830
So one of the features
is called the trace.

00:14:35.980 --> 00:14:40.190
I'm going to suspend it here because
I don't want it to go too far.

00:14:40.190 --> 00:14:43.910
The trace gives you a trace
view of all the OpenGL calls.

00:14:43.910 --> 00:14:48.500
It gives you a time for each OpenGL call
and how long it took to execute.

00:14:48.590 --> 00:14:51.050
And it'll also give you a call stack.

00:14:51.050 --> 00:14:54.940
Now, to get the call stack,
I actually have to enable it.

00:14:54.940 --> 00:14:56.090
Let me clear it.

00:14:56.150 --> 00:15:01.420
Let's resume the application and suspend
it again just to get a small snapshot.

00:15:01.420 --> 00:15:05.630
So what we see here then is
we see the same basic list.

00:15:05.900 --> 00:15:08.700
And over in this window,
if I select the function,

00:15:08.700 --> 00:15:10.400
I can see I get a call stack.

00:15:10.450 --> 00:15:14.780
So every call that you make into
OpenGL will be tagged with time,

00:15:15.260 --> 00:15:18.830
call stack, and the parameters it
used to call into OpenGL.

00:15:18.890 --> 00:15:23.230
So this is useful for debugging,
getting you some feedback as

00:15:23.230 --> 00:15:24.720
to how you're driving OpenGL.

00:15:24.870 --> 00:15:29.860
One of the other features that this
allows is to post-process that data.

00:15:29.890 --> 00:15:31.800
So what you can do is
you can run a script.

00:15:31.920 --> 00:15:35.300
I've made a pre-made script
here called Condense.

00:15:35.900 --> 00:15:38.660
I've loaded this condensed
as the current script.

00:15:38.660 --> 00:15:41.690
Now I'm going to click the Filter button.

00:15:41.690 --> 00:15:44.820
It's going to ask me for a--

00:15:46.870 --> 00:15:50.600
- For a name for the file,
the Save It As, it goes off,

00:15:50.750 --> 00:15:53.560
post-processes that data.

00:15:53.560 --> 00:15:57.930
Now let me hide the profiler and we'll
hide Xcode so I can get to the file.

00:15:58.940 --> 00:16:01.190
So opening that up,
what I did is I wrote a script

00:16:01.300 --> 00:16:03.730
that generated a report.

00:16:03.900 --> 00:16:07.370
This report tells me how-- a
summary of how I'm driving OpenGL.

00:16:07.480 --> 00:16:09.510
So you can see that what it's
telling me is that you're

00:16:09.510 --> 00:16:13.990
starting your frame with GL clear,
you're calling draw elements 239 times,

00:16:14.100 --> 00:16:18.480
calling GL finish,
and then GL flush drawable.

00:16:18.560 --> 00:16:22.950
So obviously,
one thing that pops out at me is,

00:16:22.950 --> 00:16:24.270
didn't I just get done telling
people not to call GL finish?

00:16:24.530 --> 00:16:27.790
So we're going to go
fix that in a minute.

00:16:27.890 --> 00:16:30.940
So let's make OpenGL Profiler
the top application again.

00:16:31.060 --> 00:16:33.880
So that's the trace window.

00:16:34.070 --> 00:16:36.340
Let's look at some other windows here.

00:16:36.390 --> 00:16:39.290
We saw the statistics window.

00:16:39.350 --> 00:16:41.290
Let's resume.

00:16:42.560 --> 00:16:44.940
Okay,
so here's what the new statistics looks

00:16:44.990 --> 00:16:48.550
like after we removed the wait for VBL.

00:16:48.920 --> 00:16:53.490
So we still see that draw elements
is the main time consumer.

00:16:53.620 --> 00:16:59.510
Though we noticed the time spent in the
application has dropped from 70% down

00:16:59.510 --> 00:17:04.440
to about 50%. So we've removed about 30,
or I'm sorry,

00:17:04.440 --> 00:17:11.040
about 20% of the time that OpenGL is
consuming out of the application's time.

00:17:11.040 --> 00:17:11.040
And

00:17:12.090 --> 00:17:14.500
But draw elements remains the top item.

00:17:14.570 --> 00:17:19.110
So one important number I'm
going to highlight again here is

00:17:19.110 --> 00:17:20.720
this number down at the bottom.

00:17:20.780 --> 00:17:24.320
This number here tells
you what percentage

00:17:25.920 --> 00:17:30.900
OpenGL is taking out of your
application's process time.

00:17:31.010 --> 00:17:33.120
So it's a good way to get
an idea of whether OpenGL is

00:17:33.120 --> 00:17:34.900
your main performance culprit.

00:17:35.030 --> 00:17:37.170
So if OpenGL is consuming
10% of your time,

00:17:37.370 --> 00:17:39.920
you probably want to look
elsewhere for how to improve the

00:17:39.970 --> 00:17:41.590
performance of your application.

00:17:41.850 --> 00:17:46.290
If it's taking 20, 30, 40,
50% of your time,

00:17:46.290 --> 00:17:49.070
it's something worth investigating.

00:17:49.070 --> 00:17:53.400
So that's a good place to look
right away for an indicator of what

00:17:53.400 --> 00:17:54.020
tools you ought to be going to.

00:17:55.080 --> 00:17:57.450
Let's go down the list a little bit.

00:17:57.560 --> 00:18:00.060
So let's open up a breakpoint window.

00:18:00.160 --> 00:18:04.170
So what breakpoints do is allow us to
stop at any function call in OpenGL.

00:18:04.280 --> 00:18:05.800
So let's pick the flush drawable call.

00:18:05.800 --> 00:18:08.150
So we stop there.

00:18:08.460 --> 00:18:09.880
You can see the application is paused.

00:18:09.880 --> 00:18:13.580
It gives you a backtrace
where you stopped it.

00:18:13.830 --> 00:18:20.550
If you click on this tab here,
it gives you the current OpenGL state.

00:18:20.560 --> 00:18:23.910
So what you're able to do with
this is you are able to examine

00:18:23.910 --> 00:18:24.980
your entire OpenGL state.

00:18:25.000 --> 00:18:43.130
So what you're able to do with
this is you are able to examine

00:18:43.190 --> 00:18:51.930
your entire OpenGL state.

00:18:52.120 --> 00:18:52.150
So what you're able to do with
this is you are able to examine

00:18:52.150 --> 00:18:52.150
your entire OpenGL state.

00:18:52.310 --> 00:18:55.060
So let's, well, actually,
while we're at a breakpoint,

00:18:55.060 --> 00:18:57.440
let's pull up the resource view here.

00:18:57.460 --> 00:19:00.930
Now the resource view lets you
examine some of the resources

00:19:00.930 --> 00:19:02.340
that OpenGL may have loaded.

00:19:02.390 --> 00:19:06.960
For instance, we know we have the
OS 10 logo loaded here.

00:19:06.970 --> 00:19:11.680
And we can see from the list
here that it's under an ID of 20.

00:19:11.970 --> 00:19:16.990
We can see it's a rectangle
texture type RGBA,

00:19:16.990 --> 00:19:18.700
size of 768 by 768.

00:19:18.790 --> 00:19:21.680
So it'll give you a
list of your textures.

00:19:21.690 --> 00:19:23.430
It'll also give you a
list of your programs.

00:19:23.470 --> 00:19:27.580
So if you're using fragment programs,
vertex programs, you can also view those.

00:19:27.580 --> 00:19:31.110
This demo doesn't actually have any,
so the list is empty.

00:19:33.720 --> 00:19:35.880
So let's look at what else we have here.

00:19:35.910 --> 00:19:39.930
So one other important item here
that's valuable is to check for errors.

00:19:39.930 --> 00:19:42.410
If your application is
having some trouble,

00:19:42.560 --> 00:19:45.670
sometimes what happens is that
your application is causing

00:19:45.670 --> 00:19:47.100
OpenGL to throw an error.

00:19:47.190 --> 00:19:50.250
And when OpenGL throws an error,
it ignores the function

00:19:50.290 --> 00:19:51.590
that threw the error.

00:19:51.590 --> 00:19:53.090
So it will not take effect.

00:19:53.140 --> 00:19:57.710
The state change that it was supposed
to do to execute will not take effect.

00:19:57.920 --> 00:20:01.320
So you can simply say break on error,
hit continue,

00:20:01.370 --> 00:20:05.340
and the OpenGL Profiler will
watch for any errors in which your

00:20:05.340 --> 00:20:08.400
application is throwing within OpenGL.

00:20:08.400 --> 00:20:14.390
Another important feature here
is break on thread conflict.

00:20:14.460 --> 00:20:16.800
What this does is OpenGL has
certain rules as far as how

00:20:16.880 --> 00:20:18.220
threading should behave.

00:20:18.220 --> 00:20:21.220
This will watch for any
violations of those rules.

00:20:21.220 --> 00:20:24.640
When people use threading in OpenGL,
sometimes they get it wrong,

00:20:24.640 --> 00:20:27.470
and that can cause a variety
of unpredictable results.

00:20:28.110 --> 00:20:33.020
So this will watch for threading
conflicts and help you debug any

00:20:33.150 --> 00:20:35.960
threading problems you may have.

00:20:36.000 --> 00:20:40.430
We also have another item down
here called break on VAR error.

00:20:40.430 --> 00:20:43.120
VAR,
standing for vertex array range error,

00:20:43.120 --> 00:20:47.660
and that will watch for any time
you're trying to draw your geometry

00:20:47.660 --> 00:20:51.960
and it happens to span outside of your
currently enabled vertex array range.

00:20:51.980 --> 00:20:55.780
And the net effect of doing that when
you try to draw outside of your currently

00:20:55.910 --> 00:20:57.900
defined vertex array range is that you're
not going to be able to see the error.

00:20:57.900 --> 00:20:57.900
So this will watch for threading
conflicts and help you debug any

00:20:57.900 --> 00:20:57.900
threading problems you may have.

00:20:57.900 --> 00:21:00.460
You actually fall off the fast
path you're trying to enable,

00:21:00.460 --> 00:21:02.360
and it falls onto the
immediate mode path.

00:21:02.460 --> 00:21:05.260
The extension effectively gets disabled.

00:21:05.260 --> 00:21:07.500
So it's good to know if
you're running into that case.

00:21:09.910 --> 00:21:13.800
So, I'm going to leave that up,
and we're going to go look and

00:21:13.830 --> 00:21:15.300
see what else we have here.

00:21:15.350 --> 00:21:16.710
So, pixel formats.

00:21:16.840 --> 00:21:20.860
A pixel format window tells you
what pixel format attributes

00:21:20.860 --> 00:21:24.810
you passed into OpenGL at the
time you created the context.

00:21:24.810 --> 00:21:26.600
Useful for reference.

00:21:29.840 --> 00:21:31.800
So, let's talk about scripts.

00:21:31.800 --> 00:21:34.800
OpenGL allows you to execute scripts.

00:21:34.800 --> 00:21:41.800
You can basically add a script, write it,
let me call one, say, clear color,

00:21:42.030 --> 00:21:49.650
and then I can go over here and say,
"GEO clear color." Let's say

00:21:49.660 --> 00:21:50.470
I want the background to be red.

00:21:53.620 --> 00:21:54.250
Okay.

00:21:54.420 --> 00:21:58.440
Now, let's see here.

00:21:58.440 --> 00:22:01.010
I got to get to a breakpoint
to actually execute scripts.

00:22:01.140 --> 00:22:03.200
They will only be
executed at breakpoints.

00:22:03.240 --> 00:22:04.850
Okay, so now we're at a breakpoint.

00:22:05.000 --> 00:22:08.200
I'm going to say execute that script,
and I'm going to tell it to go

00:22:08.250 --> 00:22:09.900
again here and see what happens.

00:22:10.170 --> 00:22:12.980
So you can see that I overwrote
some of the OpenGL state.

00:22:12.980 --> 00:22:16.320
And you can also see in the state
window that it told me I did that.

00:22:16.330 --> 00:22:19.840
So anytime you modify state
from breakpoint to breakpoint,

00:22:19.840 --> 00:22:23.730
the state window will
highlight in red the class,

00:22:23.730 --> 00:22:26.640
the state that actually was modified.

00:22:26.690 --> 00:22:30.560
So I can open it up and I can see that
I modified that clear color value.

00:22:30.590 --> 00:22:32.650
So it will highlight state
changes between breakpoints.

00:22:32.700 --> 00:22:38.610
Okay, so let's set it back to black
because red is kind of annoying.

00:22:40.620 --> 00:22:41.400
Close that window.

00:22:41.400 --> 00:22:43.680
Let's tell it continue.

00:22:43.680 --> 00:22:45.100
Oops, I said to white.

00:22:45.180 --> 00:22:46.780
We'll leave it white for now.

00:22:46.910 --> 00:22:49.140
So what else do we want to look at?

00:22:49.220 --> 00:22:50.640
Buffer views.

00:22:50.700 --> 00:22:54.690
Another thing you can do at a
breakpoint is you can come up

00:22:54.690 --> 00:23:02.130
and look at the back buffer,
the alpha buffer or the depth

00:23:02.130 --> 00:23:02.130
buffer of your application.

00:23:02.330 --> 00:23:08.020
So what this allows you to do is to
incrementally view the buffer contents.

00:23:09.100 --> 00:23:11.050
So for instance,
if I wanted to incrementally

00:23:11.060 --> 00:23:14.530
look at my back color buffer,
let's choose something

00:23:14.750 --> 00:23:16.760
other than flush drawable.

00:23:16.770 --> 00:23:18.980
Let's choose--

00:23:19.100 --> 00:23:45.300
[Transcript missing]

00:23:46.620 --> 00:23:47.340
Get to that.

00:23:47.390 --> 00:23:51.120
Now, on the depth buffer view,
you can see the slider at the top.

00:23:51.120 --> 00:23:54.800
What the slider does is helps you
analyze how many significant bits

00:23:54.970 --> 00:23:57.040
you're using out of the depth buffer.

00:23:57.120 --> 00:23:59.920
So what you do is you click
this magnifying glass.

00:23:59.920 --> 00:24:03.450
The sliders will zoom in on the
number of significant bits out of

00:24:03.450 --> 00:24:06.920
the total number of bits available
in the depth buffer and tell you

00:24:06.920 --> 00:24:09.250
how many of those bits you're using.

00:24:09.250 --> 00:24:12.540
So I can see that I'm only
using about 10 to 15% of the

00:24:12.700 --> 00:24:14.420
precision of the depth buffer.

00:24:14.420 --> 00:24:16.560
It's not very efficient.

00:24:16.660 --> 00:24:21.920
I should be using more because I've
allocated that memory and I'm wasting it,

00:24:21.920 --> 00:24:22.610
basically.

00:24:22.610 --> 00:24:26.720
So let's go and do
some debugging on that.

00:24:27.350 --> 00:24:30.300
Let's continue.

00:24:30.300 --> 00:24:32.340
Let's quit the application.

00:24:32.360 --> 00:24:43.570
I'm going to debug that problem of
not using all of the depth buffer.

00:24:49.330 --> 00:24:52.470
Okay, so we, there's the GL finish.

00:24:52.540 --> 00:24:55.590
While we're here,
why don't we comment out the GL finish.

00:24:56.640 --> 00:25:01.540
And before this session,
I played around with a few values here.

00:25:01.550 --> 00:25:06.590
And the call that actually sets
up your frustrum for determining

00:25:06.590 --> 00:25:11.040
what your near and far clipping
plane is the GL frustrum call.

00:25:11.040 --> 00:25:13.870
GL frustrum is also called
from a GLU perspective,

00:25:13.870 --> 00:25:18.290
which is a utility function for setting
up your viewing projection matrix.

00:25:18.340 --> 00:25:22.670
So I'm going to comment in
the one that I had set up.

00:25:22.750 --> 00:25:25.720
And what that does is it changes this 10.

00:25:26.650 --> 00:25:28.500
to a 1.2.

00:25:28.500 --> 00:25:33.160
And what that does is moves
my near clipping plane out,

00:25:33.270 --> 00:25:37.070
thus moving it nearer the object,
giving me a tighter range

00:25:37.080 --> 00:25:40.280
of values around the actual
geometry that I'm drawing.

00:25:40.390 --> 00:25:42.420
So let's save that.

00:25:42.490 --> 00:25:45.710
Let's run the application.

00:25:46.670 --> 00:25:49.100
So there's the application again.

00:25:49.100 --> 00:25:50.780
Let's select flush drawable.

00:25:50.780 --> 00:25:55.490
Oops, sorry,
I've got to attach to the application.

00:25:57.850 --> 00:26:00.960
So let's attach this time.

00:26:00.980 --> 00:26:04.200
Scroll down, find the application,
attach to it.

00:26:04.210 --> 00:26:04.780
And there we are.

00:26:04.780 --> 00:26:08.080
We stopped at this breakpoint.

00:26:08.080 --> 00:26:10.210
So let's see here.

00:26:12.600 --> 00:26:20.630
I stopped at a point that it's
not going to be available.

00:26:20.630 --> 00:26:22.640
Let's do this.

00:26:25.500 --> 00:26:30.800
I'm actually going to
change the way I did that.

00:26:30.820 --> 00:26:34.200
So let's do that again.

00:26:34.200 --> 00:26:37.270
Okay,
now let's go look at the depth buffer.

00:26:38.540 --> 00:26:40.450
Okay, so now we can see from
the previous settings,

00:26:40.530 --> 00:26:40.960
it's all red.

00:26:41.040 --> 00:26:46.390
Red telling me that the current range
of this slider is outside the bounds

00:26:46.450 --> 00:26:47.830
for which defines the entire region.

00:26:47.900 --> 00:26:49.640
So let's click on the magnifying glass.

00:26:49.740 --> 00:26:53.480
So now we can see that we're using about
90% of the precision of the depth buffer.

00:26:53.490 --> 00:26:58.480
So this is just a simple tool to help
people analyze how effectively you're

00:26:58.480 --> 00:27:01.500
using the precision of the depth buffer.

00:27:01.600 --> 00:27:03.580
So let's move on.

00:27:05.900 --> 00:27:08.300
Now, we saw a little bit
with the Driver Monitor.

00:27:08.300 --> 00:27:11.250
I'm going to explain a little
bit more about the parameters

00:27:11.250 --> 00:27:12.580
of the Driver Monitor.

00:27:13.720 --> 00:27:16.810
So the Driver Monitor, again,
is querying values directly out

00:27:16.810 --> 00:27:18.880
of the graphics kernel driver.

00:27:19.010 --> 00:27:21.980
So these values get
exported up to this tool,

00:27:21.990 --> 00:27:26.950
and they allow you to monitor a
variety of parameters from the driver.

00:27:26.960 --> 00:27:30.730
So to talk a little bit about some
of the parameters you can look at,

00:27:30.790 --> 00:27:34.390
you can look at things like
current free video memory.

00:27:34.400 --> 00:27:37.020
So if I want to look
current free video memory,

00:27:37.020 --> 00:27:39.690
I select that item,
I drag it down into the list,

00:27:39.730 --> 00:27:42.170
and now I can see what the values are.

00:27:42.380 --> 00:27:46.540
So let me change the color on this to,
let's say, blue.

00:27:46.540 --> 00:27:47.830
So I can see what the values are.

00:27:48.150 --> 00:27:50.080
So I can see that on
this graphics device,

00:27:50.080 --> 00:27:55.580
I have something over 200 megabytes
available of video memory at this moment.

00:27:56.060 --> 00:28:00.460
Other things I can examine
are data throughput.

00:28:00.720 --> 00:28:05.470
So, for example, I can look at...

00:28:07.230 --> 00:28:09.200
Let's scroll down.

00:28:09.200 --> 00:28:11.200
Optical context.

00:28:11.400 --> 00:28:15.200
So, yeah, so you can look at command
buffer data for DVD.

00:28:15.200 --> 00:28:18.130
You can look at OpenGL command data.

00:28:18.210 --> 00:28:20.170
And command data is any data that
goes through the command buffers.

00:28:20.240 --> 00:28:22.340
There's several different
ways of transporting data up

00:28:22.340 --> 00:28:24.190
to the graphics processor.

00:28:24.200 --> 00:28:27.200
One is command buffers,
another is data buffers.

00:28:27.200 --> 00:28:30.530
So let's look at data buffers,
because we tend to try to sneak a

00:28:30.530 --> 00:28:31.200
lot of things into data buffers.

00:28:31.200 --> 00:28:35.200
But let's just see how
they're being used right now.

00:28:35.200 --> 00:28:40.090
Let's change that color to yellow.

00:28:41.390 --> 00:28:44.640
So we don't see a lot there, do we?

00:28:44.640 --> 00:28:47.500
Let's deselect a few
of these others here.

00:28:48.730 --> 00:28:50.600
Okay,
so let's look at OpenGL command data

00:28:50.600 --> 00:28:53.260
and see if the data that we're sending
through here right now is going

00:28:53.260 --> 00:28:54.520
through the command data channel.

00:28:54.520 --> 00:28:55.710
And there, sure enough, there it is.

00:28:55.740 --> 00:28:58.880
So what we're seeing,
looking at the green line there,

00:28:58.880 --> 00:29:03.270
we're seeing something over a half a
gigabyte a second of data going through

00:29:03.350 --> 00:29:05.720
the command buffer channel in OpenGL.

00:29:05.720 --> 00:29:07.600
So that's where the bulk
of our data is going.

00:29:20.480 --> 00:29:20.480
So, I need a case.

00:29:20.480 --> 00:29:20.480
You can look at these
different parameters.

00:29:20.480 --> 00:29:20.480
If you mouse over them,
they will give you a description.

00:29:22.280 --> 00:29:23.200
Okay.

00:29:23.200 --> 00:29:26.220
And let you analyze
OpenGL in a variety of ways.

00:29:26.340 --> 00:29:29.560
So let's hide that application.

00:29:29.560 --> 00:29:33.180
Okay.

00:29:33.180 --> 00:29:35.600
So let's -- I think
we've done enough there.

00:29:35.600 --> 00:29:37.870
Let's switch back to the slides.

00:29:42.560 --> 00:29:45.240
Okay, let's talk a little bit about
what we were just seeing there

00:29:45.240 --> 00:29:48.410
and how we're going to further
improve that application.

00:29:49.050 --> 00:29:51.460
So when we look a little bit about,
look a little bit at the

00:29:51.460 --> 00:29:54.340
OpenGL pipeline when we're
talking about vertex throughput,

00:29:54.340 --> 00:29:57.980
the OpenGL pipeline can make copies
of the data at various stages.

00:29:57.980 --> 00:30:00.770
When you're using a media mode,
what you'll see is that the

00:30:00.770 --> 00:30:03.560
application hands the data in,
we have to copy it off into a

00:30:03.560 --> 00:30:06.530
current vertex data structure,
and then we copy it out of the current

00:30:06.910 --> 00:30:09.300
vertex structure into the command buffer.

00:30:09.300 --> 00:30:16.240
So you end up with your copy of the data,
and then OpenGL will make two copies.

00:30:16.240 --> 00:30:19.870
So a better way of doing
it is use vertex arrays.

00:30:19.880 --> 00:30:24.240
Vertex arrays optimizes around
the current vertex state,

00:30:24.240 --> 00:30:24.850
right?

00:30:24.900 --> 00:30:26.880
So we don't have to
maintain that in OpenGL.

00:30:26.880 --> 00:30:29.670
And what happens is you
hand us an array of data,

00:30:29.670 --> 00:30:31.450
we take the data directly
out of that array,

00:30:31.490 --> 00:30:33.930
and we copy it directly into
a command buffer to transport

00:30:33.930 --> 00:30:34.860
across to the graphics device.

00:30:34.910 --> 00:30:37.690
So this is a fairly decent optimization,
and this is actually

00:30:37.790 --> 00:30:38.870
what my demo is using.

00:30:38.870 --> 00:30:44.870
It's using draw elements,
which is a vertex array data path.

00:30:45.810 --> 00:30:47.840
So let's talk about
some basics here then.

00:30:47.840 --> 00:30:50.860
So what you want to do when you're
optimizing data throughput is you

00:30:50.870 --> 00:30:53.160
want to eliminate data conversions.

00:30:53.160 --> 00:30:56.490
Some data types you can pass into
OpenGL are not necessarily natively

00:30:56.490 --> 00:30:57.930
supported by the graphics device.

00:30:57.940 --> 00:31:02.220
So some basic data types you probably
want to stick to are GL float,

00:31:02.220 --> 00:31:03.990
GL short, and unsigned byte.

00:31:04.190 --> 00:31:06.610
Those tend to be reasonably
well-supported across

00:31:06.610 --> 00:31:07.500
the different products.

00:31:07.500 --> 00:31:09.860
You want to minimize your
function call overhead,

00:31:09.860 --> 00:31:11.120
and there's several ways to do that.

00:31:11.120 --> 00:31:12.310
One is to use draw arrays.

00:31:13.280 --> 00:31:15.580
Obviously,
what you want to do is to minimize the

00:31:15.580 --> 00:31:18.380
number of times you're calling to OpenGL,
so you're going to want to maximize

00:31:18.450 --> 00:31:20.820
the size of the array that you're
passing to OpenGL at each call.

00:31:20.820 --> 00:31:23.610
The more data you pass us,
the less time we're going to be

00:31:23.610 --> 00:31:24.910
spending handshaking with you.

00:31:26.230 --> 00:31:28.810
You can also use the CGL macros.

00:31:28.890 --> 00:31:32.100
The macros is a way to reduce
the per-function call overhead.

00:31:32.100 --> 00:31:34.030
I'm not going to get
into it too much here,

00:31:34.130 --> 00:31:37.780
but one thing you ought to keep in mind,
if you're making a lot of OpenGL calls,

00:31:37.780 --> 00:31:41.190
you can reduce that function call
overhead by using the CGL macros.

00:31:42.890 --> 00:31:45.560
And another thing to keep in mind
is that the graphics processors

00:31:45.560 --> 00:31:46.560
are becoming programmable.

00:31:46.560 --> 00:31:49.020
So what that allows you to
do is to consider offloading

00:31:49.160 --> 00:31:52.150
some of the computational
work onto the graphics device.

00:31:52.150 --> 00:31:55.340
So for instance, in previous years,
this exact demo in fact,

00:31:55.340 --> 00:31:59.180
I wrote a vertex program that offloaded
the work onto the graphics processor

00:31:59.180 --> 00:32:01.080
for actually calculating the wave.

00:32:01.300 --> 00:32:03.150
Now it depends on what
you want to achieve,

00:32:03.240 --> 00:32:06.180
what effect you're doing,
or what performance profile

00:32:06.270 --> 00:32:07.620
you're trying to optimize for.

00:32:07.620 --> 00:32:09.960
But in some cases,
offloading the computational

00:32:09.960 --> 00:32:13.130
work to the graphics processor
can give you quite a benefit.

00:32:15.240 --> 00:32:18.690
So, talked a little bit about
the extensions already,

00:32:18.770 --> 00:32:22.410
but for vertex data, again,
our vertex buffer object is a

00:32:22.480 --> 00:32:25.000
useful extension for you to look at.

00:32:25.030 --> 00:32:29.600
It is primarily designed to give you
a high bandwidth path for uploading

00:32:29.600 --> 00:32:32.060
data into the graphics processor.

00:32:32.060 --> 00:32:34.650
Static data,
you'll want to treat slightly

00:32:34.650 --> 00:32:37.860
differently as far as where
you want the data to live.

00:32:37.930 --> 00:32:41.470
Dynaptic data, you probably want the data
to reside in system memory

00:32:41.510 --> 00:32:43.060
where the CPU can talk to it.

00:32:43.500 --> 00:32:46.570
For static data,
it's ideal to tell OpenGL that

00:32:46.660 --> 00:32:49.070
it's static and that we can
pick it up and move it in video

00:32:49.070 --> 00:32:51.330
memory and leave it there,
thereby using the internal memory

00:32:51.330 --> 00:32:54.180
bandwidth of the graphics device,
not having then to transport

00:32:54.180 --> 00:32:55.900
it across the bus every frame.

00:32:55.900 --> 00:32:59.000
There's two ways to get
static data into video memory.

00:32:59.000 --> 00:33:03.460
One is using the static type
qualifier for a vertex buffer object,

00:33:03.540 --> 00:33:08.430
or you can just give the data to us in a
display list and we try to post-process

00:33:08.510 --> 00:33:11.820
the data and store it up in video memory
without any direct interaction by you.

00:33:11.820 --> 00:33:16.590
Other than just wrapping your
calls with the display list.

00:33:20.410 --> 00:33:23.450
So with that,
now let's go back to the demo one

00:33:23.450 --> 00:33:29.000
machine and see if we can use that
extension to optimize our performance.

00:33:30.250 --> 00:33:36.690
So here's the application as we left it.

00:33:36.960 --> 00:33:39.810
For comparison's sake,
we see we're running

00:33:39.850 --> 00:33:41.400
at 120 frames a second.

00:33:41.430 --> 00:33:43.410
We can see down here at the
bottom the CPU is working

00:33:43.420 --> 00:33:45.000
really hard to make that happen.

00:33:45.000 --> 00:33:47.670
We're consuming about 100% of
one of the CPUs at this point.

00:33:47.710 --> 00:33:51.440
If we take a shark profile and
take a look at what it's doing,

00:33:51.490 --> 00:33:56.230
again, we're spending about 45% of
the time calculating the wave.

00:33:56.280 --> 00:34:01.540
We're spending then a bunch
of time down here in OpenGL.

00:34:01.540 --> 00:34:03.890
We see two items down
here in OpenGL taking

00:34:03.890 --> 00:34:06.200
approximately 30% of the time.

00:34:07.770 --> 00:34:10.180
You know,
about 30-35% of the time spending

00:34:10.180 --> 00:34:11.830
in these top items in OpenGL.

00:34:11.920 --> 00:34:15.790
So, let's see what we can do to
reduce OpenGL's overhead.

00:34:19.370 --> 00:34:23.620
So, let me quit this app here.

00:34:23.630 --> 00:34:32.930
Now what I've done is coded up the use of
the arb vertex buffer object extension.

00:34:35.630 --> 00:34:40.240
So moving over from straight vertex
arrays to our vertex buffer object is

00:34:40.240 --> 00:34:42.700
actually relatively straightforward.

00:34:42.940 --> 00:34:44.260
So I've got two pieces of code here.

00:34:44.260 --> 00:34:48.470
The first one is going to represent
the items I have to turn on,

00:34:48.470 --> 00:34:50.660
and this is the items
I'm going to turn off.

00:34:50.660 --> 00:34:53.740
So there's various places I'm going
to comment code out and a couple

00:34:53.740 --> 00:34:55.280
places I'm going to comment code in.

00:34:55.330 --> 00:34:59.220
So the first thing I need to do is
I need to bind to a vertex buffer object.

00:34:59.220 --> 00:35:01.270
It's an object semantic,
just like a texture.

00:35:01.470 --> 00:35:03.640
So you need to create an object,
and you create an object

00:35:03.640 --> 00:35:05.220
by binding to a new object.

00:35:05.430 --> 00:35:07.580
So I'm going to bind to an
object that gives it a name and

00:35:07.580 --> 00:35:11.180
something I can switch to when
I want to draw from that object.

00:35:11.190 --> 00:35:16.670
Now, the remaining two calls,
when you use a vertex buffer object,

00:35:16.670 --> 00:35:18.840
the meaning of vertex pointer changes.

00:35:18.860 --> 00:35:22.540
It changes from being a
memory address to an offset.

00:35:22.560 --> 00:35:25.410
That's important to remember,
because you may already

00:35:25.410 --> 00:35:27.700
be using vertex arrays,
and if you don't modify the

00:35:27.810 --> 00:35:30.090
parameters to vertex arrays,
you'll find that things

00:35:30.090 --> 00:35:32.120
don't work as expected.

00:35:32.140 --> 00:35:35.680
And the reason that it's done this
way is that the memory is contained

00:35:35.680 --> 00:35:36.920
within the vertex buffer object.

00:35:36.920 --> 00:35:39.720
You're no longer going to
be passing arrays to OpenGL.

00:35:39.740 --> 00:35:42.690
You're just telling OpenGL the
offset into your object at which

00:35:42.750 --> 00:35:44.380
you want to pull the data from.

00:35:44.380 --> 00:35:45.140
OK?

00:35:45.230 --> 00:35:47.490
So I'm going to comment
those two lines in,

00:35:47.830 --> 00:35:52.220
and I'm going to comment out
the two old lines that are no

00:35:52.220 --> 00:35:55.980
longer using the correct syntax.

00:35:57.340 --> 00:35:58.160
So let's go down.

00:35:58.180 --> 00:36:04.200
Now, I've created the object right
up here with the bind buffer.

00:36:04.200 --> 00:36:08.060
I've set the offsets of where the
data's going to live in the object.

00:36:08.060 --> 00:36:10.900
And now down here,
once I've loaded the data-- see here,

00:36:10.900 --> 00:36:17.580
I'm calculating the initial wave
values-- the initial values.

00:36:17.580 --> 00:36:20.880
And now I'm ready to
give this data to OpenGL.

00:36:20.880 --> 00:36:25.280
And the way you can initially give data
to OpenGL is called GL Buffer data.

00:36:25.280 --> 00:36:28.290
And GL Buffer data then will
take the pointers you give it and

00:36:28.290 --> 00:36:29.660
copy the data into the object.

00:36:29.660 --> 00:36:31.630
So it's not going to retain
a pointer to that memory.

00:36:31.820 --> 00:36:34.930
It's going to copy the data
into the buffer object.

00:36:36.100 --> 00:36:37.630
Let's see what else we have to do.

00:36:37.670 --> 00:36:38.100
OK.

00:36:38.460 --> 00:36:41.690
So now when we calculate
the way of every frame,

00:36:42.010 --> 00:36:45.400
What we need to do is we need to bind
to the object because we're going to

00:36:45.430 --> 00:36:47.620
have to modify the data in the object.

00:36:47.620 --> 00:36:50.210
So I want to make that object current.

00:36:50.290 --> 00:36:52.440
Now,
since the data lives in the object now,

00:36:52.440 --> 00:36:53.590
it doesn't live in my space.

00:36:53.630 --> 00:36:56.530
The object, the data actually is
part of OpenGL's state,

00:36:56.590 --> 00:36:59.140
and it lives in OpenGL's memory space.

00:36:59.140 --> 00:37:01.920
I'm going to have to
retrieve that memory,

00:37:01.920 --> 00:37:04.540
so I do that by calling mapBufferArb.

00:37:04.600 --> 00:37:07.640
What that does, it tells OpenGL,
go give me a pointer

00:37:07.640 --> 00:37:11.530
to your object memory,
and I need to modify it.

00:37:11.700 --> 00:37:18.590
So I call mapBufferArb,
and it returns the pointer.

00:37:18.620 --> 00:37:21.200
So now I've got to comment out
my old code I had here that set

00:37:21.240 --> 00:37:23.950
the pointer to something else,
because that's no longer valid.

00:37:23.950 --> 00:37:25.580
I'm no longer in charge of the memory.

00:37:27.500 --> 00:37:30.900
Now, anytime you call map buffer,
you need to un-map it.

00:37:30.900 --> 00:37:36.060
OpenGL R buffer objects require you
to bound your access to the data.

00:37:36.150 --> 00:37:39.510
Before you access it, you call map,
and when you're done accessing the data,

00:37:39.590 --> 00:37:40.520
you call un-map.

00:37:40.620 --> 00:37:44.750
So, here I am calculating the wave,
and I've got various alt-evec commands

00:37:44.750 --> 00:37:46.410
in there to try to do it fast.

00:37:47.340 --> 00:37:49.780
So down at the bottom
of this whole thing,

00:37:49.780 --> 00:37:51.380
I've got the UNMAP.

00:37:51.480 --> 00:37:53.550
So now that I've filled
in my wave calculation,

00:37:53.550 --> 00:37:57.800
which I will be executing every frame,
I need to call UNMAP to tell

00:37:57.800 --> 00:38:00.460
OpenGL that I'm done accessing the data.

00:38:00.540 --> 00:38:04.690
So now I've done the initialization,
I've done the bounding of the

00:38:04.690 --> 00:38:06.260
dynamically modifying the data.

00:38:06.280 --> 00:38:09.360
Now I gotta go modify,
have to go modify the data,

00:38:09.390 --> 00:38:11.880
how I'm going to draw the data.

00:38:11.970 --> 00:38:16.500
So here in the wave display function,
I have the, again,

00:38:16.500 --> 00:38:17.740
the bind to the object.

00:38:17.820 --> 00:38:21.420
I want to make sure the object's
current before I draw to it.

00:38:21.440 --> 00:38:23.180
And that's it.

00:38:23.470 --> 00:38:24.420
Everything else is the same.

00:38:24.420 --> 00:38:28.380
I'm going to issue the draw
elements command as I did before.

00:38:28.410 --> 00:38:30.420
And everything should just work.

00:38:30.470 --> 00:38:32.080
So let's close this
window and give it a try.

00:38:32.080 --> 00:38:35.040
So remember before we were using
a hundred percent of the CPU,

00:38:35.060 --> 00:38:37.180
we were at a hundred and
twenty frames a second.

00:38:37.230 --> 00:38:39.770
So let's see what difference this makes.

00:38:41.120 --> 00:38:43.860
So we're at 140 frames a second.

00:38:43.910 --> 00:38:48.100
And it turns out that I actually
throttled this at 140 frames a second.

00:38:48.130 --> 00:38:51.580
And the CPU behavior,
I'm not quite using 100% of the CPU.

00:38:51.600 --> 00:38:56.680
I'm using something that looks like
maybe 80%. So let's take a shark trace

00:38:56.710 --> 00:38:58.720
of that and see what it looks like.

00:39:04.120 --> 00:39:08.620
So the wave calculation's
still up there pretty high.

00:39:08.620 --> 00:39:10.080
But the other items of
OpenGL have changed.

00:39:10.080 --> 00:39:15.400
Now all of a sudden I'm seeing
this 15% spent in an idle loop,

00:39:15.590 --> 00:39:16.500
just like I had before.

00:39:16.500 --> 00:39:19.150
Whereas before I was seeing
about 30%, but now all of a

00:39:19.150 --> 00:39:20.680
sudden this is showing back up.

00:39:20.740 --> 00:39:24.780
So I'm going to talk a little bit
more about this in detail later,

00:39:24.780 --> 00:39:29.320
but what happens is that when you are
sharing data with a graphics processor,

00:39:29.320 --> 00:39:34.280
which vertex array range,
R buffer object, texture range do,

00:39:34.280 --> 00:39:36.840
they are talking to the same
memory region that the graphics

00:39:36.930 --> 00:39:38.520
processor is accessing.

00:39:38.520 --> 00:39:40.980
You are synchronizing with
the graphics processor,

00:39:40.980 --> 00:39:43.010
and you have to be
careful how you do that.

00:39:43.160 --> 00:39:45.380
So what this is,
is this is telling me that I'm

00:39:45.380 --> 00:39:48.570
potentially hitting a blocking
spot where the CPU is waiting

00:39:48.570 --> 00:39:50.280
for the graphics processor.

00:39:50.320 --> 00:39:53.760
So let's go see if that is true.

00:39:53.760 --> 00:39:59.280
Let's open up the Driver Monitor,
which is the ideal tool for analyzing.

00:39:59.320 --> 00:40:04.210
And let's again look at
the CPU wait for GPU time.

00:40:04.320 --> 00:40:06.910
And sure enough,
it looks like I'm spending

00:40:06.910 --> 00:40:09.850
about 15% of my CPU time waiting
for the graphics processor,

00:40:09.860 --> 00:40:10.770
just like Shark told me.

00:40:10.840 --> 00:40:14.010
So this tool's confirmed it,
so let's go dig in deeper and find

00:40:14.010 --> 00:40:15.950
out where that time's being spent.

00:40:16.040 --> 00:40:18.370
Well, just like before,
I figured it out before,

00:40:18.420 --> 00:40:22.020
so we're not going to waste that time,
but I'm spending time in

00:40:22.020 --> 00:40:23.700
CPU wait for user code.

00:40:23.700 --> 00:40:29.260
And that's a pretty interesting
parameter to be moving around in.

00:40:29.260 --> 00:40:31.230
I'm going to go ahead and do
a little bit of monitoring,

00:40:31.280 --> 00:40:34.740
because that parameter tells me
that a blocking point that the

00:40:34.780 --> 00:40:39.220
developer has put in their code is
what's blocking OpenGL's execution.

00:40:39.220 --> 00:40:45.010
And that can happen from a
fence command or a map command.

00:40:45.020 --> 00:40:49.100
Now remember, we call glmapbufferr before
we go modify the data.

00:40:49.100 --> 00:40:55.610
So this actually is where the time
will show up in the Driver Monitor if

00:40:55.610 --> 00:40:59.100
I'm spending time in any routine.

00:40:59.300 --> 00:41:02.200
That is a fencing type
routine in the OpenGL API.

00:41:02.260 --> 00:41:06.360
And again, those are going to be
the glmapbuffer calls,

00:41:06.360 --> 00:41:08.260
or they're going to be the fence calls.

00:41:08.260 --> 00:41:12.260
Those are the two calls that will start
attributing time to this parameter.

00:41:12.260 --> 00:41:16.170
So what this is telling me is
that the graphics processor

00:41:16.190 --> 00:41:19.260
is slowing down the CPU some.

00:41:19.260 --> 00:41:22.260
In other words, I'm ready to go off and
start modifying the data,

00:41:22.260 --> 00:41:24.260
but the graphics processor hasn't
quite gotten done displaying it.

00:41:24.260 --> 00:41:27.450
So I'm stalling the CPU a little bit,
waiting for the graphics

00:41:27.530 --> 00:41:30.230
processor to consume the data,
before I can go and

00:41:30.480 --> 00:41:32.190
touch it with the CPU.

00:41:32.200 --> 00:41:36.630
So we'll talk a little bit more later,
but keep that in mind.

00:41:39.190 --> 00:41:44.060
Now, as a last little experiment here,
let's just again open the Profiler

00:41:44.090 --> 00:41:46.770
and let's pull up the statistics.

00:41:49.020 --> 00:41:51.900
And we have to attach
to this application.

00:41:52.010 --> 00:41:58.150
And let me clear the
stats to get a fresh view.

00:42:00.010 --> 00:42:02.900
So what's interesting is that now
the top call is the map buffer.

00:42:03.010 --> 00:42:07.680
And that's also consistent with what
we saw in Shark and the Driver Monitor,

00:42:07.730 --> 00:42:11.140
where we believe that map
buffer is a stalling routine.

00:42:11.140 --> 00:42:14.900
It's stalling,
waiting for the graphics processor.

00:42:15.040 --> 00:42:18.480
So all those pieces of
information are consistent.

00:42:18.570 --> 00:42:25.140
And again, we'll talk about that
more in a little bit.

00:42:25.140 --> 00:42:26.900
So I'm going to clean up here a little.

00:42:31.000 --> 00:42:42.200
[Transcript missing]

00:42:46.800 --> 00:42:48.900
Slides on the screen, please.

00:42:48.900 --> 00:42:53.280
There we go.

00:42:55.480 --> 00:42:57.820
Okay, so let's review a little bit.

00:42:57.830 --> 00:43:01.930
So we were using vertex arrays,
then we wanted to go off and start

00:43:01.930 --> 00:43:04.060
using some OpenGL extensions.

00:43:04.060 --> 00:43:07.670
And what we did is we used our
vertex buffer object to try to

00:43:08.030 --> 00:43:09.840
optimize the data throughput.

00:43:09.860 --> 00:43:12.290
We saw that we got some performance.

00:43:12.290 --> 00:43:14.120
We started using less CPU.

00:43:14.120 --> 00:43:16.640
So optimize both CPU and performance.

00:43:16.830 --> 00:43:20.320
And what it looks like when we
start using that extension is

00:43:20.520 --> 00:43:25.380
that the data gets pulled directly
from the application's memory.

00:43:25.400 --> 00:43:27.140
So we have a space directly to the CPU.

00:43:27.140 --> 00:43:29.460
There's no copies being
made of the data by the CPU.

00:43:29.460 --> 00:43:32.270
The data is being pulled directly
by the graphics processor.

00:43:32.380 --> 00:43:34.660
CPU is not spending time
doing copying of data.

00:43:36.140 --> 00:43:38.400
Okay, so let's look at the code,
summary of the code here.

00:43:38.400 --> 00:43:42.040
So, as we showed before,
we always have to do a bind

00:43:42.190 --> 00:43:46.240
before we are going to access
or operate on a buffer object.

00:43:46.310 --> 00:43:49.540
We enable the vertex array state,
we set up the pointers,

00:43:49.540 --> 00:43:52.600
the vertex array pointer,
but we set it up as an offset,

00:43:52.670 --> 00:43:53.860
not as a pointer.

00:43:53.860 --> 00:43:57.130
We call the buffer data to
initialize the object with some data,

00:43:57.130 --> 00:44:00.440
and then we call map buffer if
we're going to modify the data.

00:44:00.440 --> 00:44:03.180
So we call map buffer,
we get the data pointer back,

00:44:03.180 --> 00:44:05.350
we fill in the data, and then we unmap.

00:44:06.000 --> 00:44:08.630
Just like we did in the code.

00:44:09.020 --> 00:44:12.790
So again, static data,
you want to tell OpenGL if it's static.

00:44:12.800 --> 00:44:15.060
Now, static, you're not going to want to
be modifying it every frame,

00:44:15.060 --> 00:44:16.560
but if you modify it once in a while,
it's okay,

00:44:16.560 --> 00:44:19.370
but it primarily needs to be static data.

00:44:19.380 --> 00:44:22.300
So if you're only modifying
it every fifth or tenth frame,

00:44:22.300 --> 00:44:24.890
put it up in video memory,
let the graphics processor

00:44:24.960 --> 00:44:27.310
use its internal bus instead
of transferring it across the

00:44:27.820 --> 00:44:29.820
graphics device bus every time.

00:44:29.820 --> 00:44:33.080
And again, displayless,
you can get static data and put

00:44:33.130 --> 00:44:36.920
it into video memory by wrapping
it with a displayless calls.

00:44:37.500 --> 00:44:41.100
You can put that data in begin, end,
and we'll parse through the data,

00:44:41.100 --> 00:44:42.870
pull it out,
and put it up into video memory.

00:44:45.710 --> 00:44:50.970
So I want to show you one more thing
on the Vertex Performance Demo.

00:44:57.550 --> 00:45:01.680
So let's see here.

00:45:01.860 --> 00:45:03.770
What are we going to do?

00:45:07.700 --> 00:45:12.450
So one thing I want to
show you was what happens.

00:45:12.460 --> 00:45:16.360
We can see that we're
using about 80% of the CPU.

00:45:16.360 --> 00:45:24.160
And we saw that we were consuming
or stalling about 15% of the time.

00:45:26.040 --> 00:45:27.800
And Shark was showing that as well.

00:45:27.960 --> 00:45:31.320
So let's modify this
application one more time.

00:45:31.320 --> 00:45:35.490
And let's take out the throttling
of the 140 frames a second.

00:45:35.500 --> 00:45:39.310
Let's see what these profiles
show us once we do that.

00:45:42.880 --> 00:45:47.040
So, what I'm going to do, oops,
wrong file here.

00:45:47.100 --> 00:45:50.540
So what I'm going to do is I'm going
to go down to the timer that I have.

00:45:50.570 --> 00:45:53.340
I'm going to increase this
from 140 frames a second.

00:45:53.550 --> 00:45:57.180
Let's increase it to 180 and let's see
what this looks like in the profiles.

00:45:57.180 --> 00:46:01.550
Because right now I'm kind of
artificially limiting the performance.

00:46:02.400 --> 00:46:04.590
First off, let's see if it can keep up.

00:46:04.780 --> 00:46:07.930
So it turns out that it
doesn't get a whole lot faster.

00:46:09.760 --> 00:46:15.380
So we're pretty much hitting
the limit of this system here.

00:46:15.420 --> 00:46:18.290
We can look at the blocking behavior.

00:46:18.400 --> 00:46:20.320
As we were looking at before,
we were spending about

00:46:20.380 --> 00:46:23.060
15% of the time blocked,
but now we're spending over

00:46:23.060 --> 00:46:25.550
20% of the time blocked,
the CPU being blocked against

00:46:25.550 --> 00:46:26.740
the graphics processor.

00:46:26.760 --> 00:46:29.130
So what I'm doing is I'm
driving the system harder,

00:46:29.210 --> 00:46:32.510
but it didn't get all that much faster,
but I'm spending approximately

00:46:32.610 --> 00:46:35.460
7% more time blocked against
the graphics processor.

00:46:35.480 --> 00:46:37.500
So I'm driving it harder,
but I'm not getting that much faster.

00:46:38.680 --> 00:46:43.640
So this is kind of the point here is
that you have to make your architecture

00:46:43.670 --> 00:46:48.680
behave in a way that it's asynchronous
with the graphics processor.

00:46:48.680 --> 00:46:51.130
If you drive the system in such a
way that you're running synchronous,

00:46:51.130 --> 00:46:53.500
you can drive it as hard as you want,
and all you're going to do is block

00:46:53.500 --> 00:46:55.230
harder against the graphics processor.

00:46:55.250 --> 00:46:58.630
So let's also look at Shark,
and let's see if Shark is

00:46:58.630 --> 00:47:03.520
consistent with that data that the
OpenGL Driver Monitor is giving us.

00:47:07.780 --> 00:47:12.400
It's telling us about 15%,
which looks a little low,

00:47:12.400 --> 00:47:18.860
but not all that different than what
the Driver Monitor is telling us.

00:47:18.930 --> 00:47:22.180
So, okay,
let's switch back slides and we'll

00:47:22.510 --> 00:47:26.190
get into more about asynchronous
behavior here in a minute.

00:47:26.650 --> 00:47:30.270
So texture uploads,
let's talk about that for a while.

00:47:30.290 --> 00:47:32.770
So just like vertices,
texture uploads have the

00:47:32.770 --> 00:47:35.650
same kind of behavior,
where the OpenGL framework will

00:47:35.650 --> 00:47:42.500
make copies of the data through the
various parts of the OpenGL pipeline.

00:47:42.760 --> 00:47:44.520
One copy could be in
the OpenGL framework,

00:47:44.520 --> 00:47:46.520
one could be in the driver,
and another copy could be

00:47:46.520 --> 00:47:47.840
resided up in video memory.

00:47:47.850 --> 00:47:51.040
Now these copies, obviously,
to make a copy, to save a memory copy

00:47:51.040 --> 00:47:53.970
somewhere in the pipeline,
there is a copy of the

00:47:53.970 --> 00:47:55.580
data being performed,
either by the CPU or

00:47:55.580 --> 00:47:57.950
the graphics processor,
physically copying the data

00:47:57.950 --> 00:47:59.460
and depositing it somewhere.

00:47:59.540 --> 00:48:03.340
So everywhere we see an arrow,
basically the data is being moved.

00:48:03.340 --> 00:48:06.490
Everywhere we see a cylinder there,
the data is being deposited.

00:48:06.500 --> 00:48:08.770
So there's memory being consumed.

00:48:09.670 --> 00:48:11.550
So let's go to another demo
that I'm going to show you

00:48:11.550 --> 00:48:15.040
about texture performance.

00:48:15.140 --> 00:48:16.660
Switch back to demo one, please.

00:48:16.730 --> 00:48:17.200
Thank you.

00:48:17.200 --> 00:48:23.990
OK, so we're going to run a
completely different demo here.

00:48:27.470 --> 00:48:28.530
So let me just run it as it is.

00:48:28.700 --> 00:48:38.150
So the first thing you'll see here is
you'll see my boss's head popping off.

00:48:40.210 --> 00:48:45.790
He's in the audience,
so this may be my last day.

00:48:46.590 --> 00:48:49.610
But let's say we have a bad
prank we're doing at work and

00:48:49.610 --> 00:48:54.170
we want it to run really well.

00:48:56.800 --> 00:48:57.420
Sorry.

00:48:57.420 --> 00:49:01.380
What I'm seeing here is that
I'm using a lot of CPU time.

00:49:01.380 --> 00:49:04.660
I'm getting about 46 frames per second.

00:49:05.130 --> 00:49:07.860
My application's actually trying
to get 60 frames a second.

00:49:08.130 --> 00:49:13.420
So I know that somehow I'm being limited
by the performance of my application,

00:49:13.460 --> 00:49:15.620
and I'd like it to run smoother.

00:49:15.680 --> 00:49:20.440
So we're going to run through the
same basic steps we did before.

00:49:20.460 --> 00:49:23.870
And what we're going to do
is we're going to run Shark.

00:49:23.870 --> 00:49:23.870
We're going to take a trace.

00:49:26.280 --> 00:49:29.130
So we take a trace for
about five seconds.

00:49:29.130 --> 00:49:32.540
And we look and we see the top item,
65% of the time is

00:49:32.660 --> 00:49:34.300
being spent in memcopy.

00:49:34.380 --> 00:49:36.720
So we know we're copying
a lot of data around,

00:49:36.760 --> 00:49:39.310
and that's something
we would like to avoid.

00:49:40.210 --> 00:49:47.870
So let's also look at
the OpenGL Profiler,

00:49:47.870 --> 00:49:49.440
and let's attach to this application

00:49:52.680 --> 00:49:57.000
Okay, so let's attach to it and
let's open up the stats view.

00:49:57.150 --> 00:50:00.160
Hit clear to get a nice
fresh trace of this.

00:50:00.390 --> 00:50:03.990
So the OpenGL Profiler is telling me that

00:50:04.610 --> 00:50:11.200
98% of the application's time is
being spent in GL text SUBMG2D.

00:50:11.200 --> 00:50:15.630
And the shark is telling me that
65% of the application time is

00:50:15.630 --> 00:50:20.320
being spent just doing mem copy,
probably happening underneath

00:50:20.320 --> 00:50:22.730
the text image SUBMG2D call.

00:50:22.740 --> 00:50:26.420
So we know that we're moving a lot of
data and it's happening in that call.

00:50:26.420 --> 00:50:32.260
So let's go back to the slides and let's
talk about some extensions we can use to

00:50:32.400 --> 00:50:37.070
try to to eliminate copies of the texture
data as it goes through the pipeline.

00:50:37.300 --> 00:50:38.900
So, first some basics.

00:50:38.950 --> 00:50:40.880
So, the goal, again,
is to eliminate CPU copies

00:50:40.880 --> 00:50:41.800
and conversions.

00:50:41.800 --> 00:50:46.290
The way you do this is
you use the right formats.

00:50:46.340 --> 00:50:48.830
The right formats are going to be
key because what you want is you

00:50:48.830 --> 00:50:51.840
want a pixel format that is natively
supported by the graphics device.

00:50:51.840 --> 00:50:54.090
If it's not natively supported
by the graphics device,

00:50:54.100 --> 00:50:57.280
we're going to have to convert it to
a format that is natively supported.

00:50:57.740 --> 00:51:00.750
So, here's some formats that
are common on our platform,

00:51:00.750 --> 00:51:02.500
supported by all of our chips.

00:51:02.500 --> 00:51:04.620
There's other formats that are out there.

00:51:04.620 --> 00:51:07.240
You'll have to experiment
to see which ones work best,

00:51:07.310 --> 00:51:10.440
or you can email us and ask whether
a format is optimal for the system

00:51:10.440 --> 00:51:12.540
or the graphics device you're using.

00:51:14.970 --> 00:51:16.390
So, texture extensions.

00:51:16.390 --> 00:51:21.460
So, to optimize the texture throughput,
some extensions you want to keep in

00:51:21.460 --> 00:51:23.180
mind are the Apple Client Storage.

00:51:23.180 --> 00:51:27.650
The Client Storage extension,
what it does is it retains a

00:51:27.650 --> 00:51:29.960
pointer to the texture data.

00:51:30.010 --> 00:51:32.230
It does not make a copy of it.

00:51:32.310 --> 00:51:35.410
So, what OpenGL does is it hangs
onto a pointer of the data,

00:51:35.410 --> 00:51:39.960
and now the application's responsible for
making sure that the data is retained.

00:51:39.960 --> 00:51:40.610
It stays around.

00:51:40.610 --> 00:51:43.640
You can't throw it away while
OpenGL has a pointer to it.

00:51:44.060 --> 00:51:47.690
So, that extension has the benefit that
the framework will not make a copy of

00:51:47.750 --> 00:51:49.730
that data anymore once you use that.

00:51:49.730 --> 00:51:51.840
Apple Texture Range.

00:51:52.170 --> 00:51:55.830
It has the benefit of the
Texture Range is it will bypass

00:51:55.830 --> 00:51:57.980
the copy made by the driver.

00:51:57.980 --> 00:52:00.190
It has two modes, shared and cached.

00:52:00.190 --> 00:52:03.310
Shared and cached are similar
to static and dynamic.

00:52:03.310 --> 00:52:06.360
Cached is static,
meaning cached up video memory.

00:52:06.360 --> 00:52:09.940
Shared, meaning put it down as system
memory because I'm going

00:52:09.940 --> 00:52:11.840
to share it with the GPU.

00:52:13.220 --> 00:52:14.480
And EXT Texture Range.

00:52:14.480 --> 00:52:17.030
Texture Range can be an
important extension because

00:52:17.120 --> 00:52:20.560
some hardware will require that
extension for doing direct DMA.

00:52:20.560 --> 00:52:26.300
It has a more compatible format with
the data as it resides in system memory.

00:52:26.300 --> 00:52:31.180
So, the Texture Range extension is
useful to ensure optimal performance.

00:52:31.180 --> 00:52:34.500
So, let's look at what each one
of these does in this diagram.

00:52:34.500 --> 00:52:39.500
So, before I showed cylinders,
now we have the images of my boss.

00:52:42.380 --> 00:52:44.840
So, the Texture Range extension
gives an image to OpenGL.

00:52:44.860 --> 00:52:47.450
Now, if I use Client Storage,
I'm bypassing the framework's

00:52:47.450 --> 00:52:49.100
copy going directly to the driver.

00:52:49.100 --> 00:52:51.600
So, I've eliminated one copy of the data.

00:52:51.600 --> 00:52:53.840
And then,
if I'm using the data as cached,

00:52:53.840 --> 00:52:56.160
it's going to be cached up video memory.

00:52:56.160 --> 00:52:58.680
The data gets copied up video
memory and used from there.

00:52:58.830 --> 00:53:01.580
So,
I've eliminated one copy down to three.

00:53:02.990 --> 00:53:06.400
So what does the client
storage app look like?

00:53:06.490 --> 00:53:07.000
It's one line.

00:53:07.130 --> 00:53:09.840
It's the PixelStore Eye Unpacked
Client Storage Apple.

00:53:09.840 --> 00:53:13.610
Just setting that to true when
you bind to your texture object

00:53:13.670 --> 00:53:15.620
will enable this extension.

00:53:15.620 --> 00:53:17.200
Just one line of code.

00:53:20.810 --> 00:53:24.080
So, texture range and rectangle texture,
what does that do?

00:53:24.190 --> 00:53:26.940
So those bypass the
copy that the framework,

00:53:26.980 --> 00:53:29.230
I'm sorry, that the driver is making.

00:53:29.420 --> 00:53:31.840
So now I've bypassed the graphics
driver's copy of the data.

00:53:31.860 --> 00:53:34.200
So now it's pulling directly
from the OpenGL framework,

00:53:34.230 --> 00:53:36.700
directly DMAing it into video memory.

00:53:36.770 --> 00:53:39.450
So now I've bypassed the driver's copy.

00:53:40.950 --> 00:53:42.020
And what does that look like?

00:53:42.050 --> 00:53:43.800
Also, one line of code.

00:53:43.830 --> 00:53:49.470
You just call GL_TEXT_PARAM_I rectangle
texture target type.

00:53:49.820 --> 00:53:53.660
And in this case,
I'm calling the texture storage hint,

00:53:53.850 --> 00:53:56.180
which is the extension parameter.

00:53:56.500 --> 00:53:58.100
And I'm calling storage cache.

00:53:58.140 --> 00:54:00.990
So I'm going to cache
it up in video memory.

00:54:02.030 --> 00:54:05.970
So combining these extensions,
the behavior I get is that the pixel

00:54:05.990 --> 00:54:09.760
data that is stored up in the application
will be DMHed directly into video memory.

00:54:09.760 --> 00:54:11.760
No copies made by OpenGL.

00:54:11.830 --> 00:54:13.960
Zero CPU copies.

00:54:16.490 --> 00:54:18.780
And putting all that code together then,
what it looks like is you

00:54:18.860 --> 00:54:22.330
bind to the texture object,
you call the texture param i

00:54:22.410 --> 00:54:24.390
to set up the client storage.

00:54:24.600 --> 00:54:26.840
Actually, in this case,
you call the rectangle

00:54:26.840 --> 00:54:28.250
texture extension first.

00:54:28.320 --> 00:54:30.840
Then you call the pixel storei,
which is the client storage.

00:54:30.840 --> 00:54:34.100
Those are the two lines you add
to enable these two extensions.

00:54:34.100 --> 00:54:35.660
And then you load your texture.

00:54:35.660 --> 00:54:39.190
You call your GL text image
2D call to load the image.

00:54:40.120 --> 00:54:42.570
So let's talk a little bit
about the blocking behavior

00:54:42.570 --> 00:54:43.980
I was pointing out before.

00:54:43.980 --> 00:54:46.430
When you are using some
of these extensions,

00:54:46.430 --> 00:54:49.790
again, you are sharing data with
the graphics processor.

00:54:49.790 --> 00:54:52.940
The application and the graphics
processor are pointing to the

00:54:52.940 --> 00:54:54.650
same data out in system memory.

00:54:54.660 --> 00:54:57.690
So when you do that,
there is synchronization involved.

00:54:57.690 --> 00:55:01.530
You have two asynchronous devices
trying to talk to one region of memory.

00:55:01.530 --> 00:55:03.300
They need to be synchronized.

00:55:03.370 --> 00:55:05.760
And you need to make sure when you're
synchronizing those that you do it in a

00:55:05.760 --> 00:55:07.240
way that you're not blocking each other.

00:55:07.440 --> 00:55:10.390
So for instance,
if I was to only use one object,

00:55:10.400 --> 00:55:14.310
one vertex buffer object, for say,
or in the case of textures,

00:55:14.330 --> 00:55:17.870
one texture range,
and every time I went to talk to the CPU,

00:55:17.950 --> 00:55:21.470
I would call a fence to block
before I access the data.

00:55:21.480 --> 00:55:24.470
And what would happen is the
CPU would block until the graphics

00:55:24.470 --> 00:55:26.190
processor is completed using it.

00:55:26.220 --> 00:55:27.610
The CPU would operate on it.

00:55:27.780 --> 00:55:29.980
And then the graphics
CPU would operate on it.

00:55:30.080 --> 00:55:32.350
And then I would draw with it,
and the GPU would pull it up.

00:55:32.500 --> 00:55:34.040
So this is what this
block diagram looks like,

00:55:34.080 --> 00:55:34.450
right?

00:55:34.540 --> 00:55:35.290
The CPU operates.

00:55:35.290 --> 00:55:37.150
I flush, get it.

00:55:37.440 --> 00:55:39.820
It's processed up to
the graphics processor.

00:55:39.990 --> 00:55:42.190
Graphics processor
completes its processing,

00:55:42.250 --> 00:55:43.180
lets the CPU go.

00:55:43.230 --> 00:55:45.480
And they're basically
operating in serial,

00:55:45.480 --> 00:55:46.020
right?

00:55:46.020 --> 00:55:49.010
But if I double buffer my data,
I can have a copy that the graphics

00:55:49.010 --> 00:55:52.600
processor is operating on and the
CPU you're operating on in parallel.

00:55:52.600 --> 00:55:56.070
So it's important to double buffer
your data when you're using these

00:55:56.070 --> 00:55:59.360
types of extensions to make sure
that the graphics processor and

00:55:59.360 --> 00:56:02.110
the CPU are operating in parallel,
not serial.

00:56:02.120 --> 00:56:05.830
That's a key aspect of when you're
using these optimal extensions,

00:56:05.830 --> 00:56:07.420
because you're sharing.

00:56:07.440 --> 00:56:09.890
data with a graphic processor.

00:56:12.380 --> 00:56:16.260
So, texture range synchronization,
I mentioned a little bit.

00:56:16.450 --> 00:56:19.080
For texture range,
the synchronization extension

00:56:19.080 --> 00:56:20.890
is the Apple Fence extension.

00:56:20.900 --> 00:56:25.510
You'll need to use that any time you
want to go and access the data which

00:56:25.560 --> 00:56:28.360
the graphics processor is pointing to.

00:56:30.500 --> 00:56:32.080
So let's look at what that means.

00:56:32.150 --> 00:56:34.770
So just like with our
vertex buffer object,

00:56:34.770 --> 00:56:36.040
we had to call a map.

00:56:36.210 --> 00:56:39.030
The map was a synchronization
point for the vertex extension.

00:56:39.050 --> 00:56:43.710
The finish object with a GL texture
type is the synchronization call

00:56:43.710 --> 00:56:48.010
that you'll need to call before
accessing vertex array range,

00:56:48.040 --> 00:56:50.500
or a texture range data, okay?

00:56:50.500 --> 00:56:53.260
You call that before you
access the texture data,

00:56:53.340 --> 00:56:57.800
and that will make sure that the CPU does
not access the data before the graphics

00:56:57.800 --> 00:57:00.200
processor is completed accessing it.

00:57:03.810 --> 00:57:07.610
Okay, so let's go back and take some
of these extensions now and apply

00:57:07.610 --> 00:57:11.900
them to this demo and see what
performance improvement that does.

00:57:11.960 --> 00:57:15.990
So the first things to note are
that the CPU is at about 100%,

00:57:16.260 --> 00:57:22.240
the performance of our demo is
at about 742 megabytes a second,

00:57:22.410 --> 00:57:24.600
42 frames a second.

00:57:24.640 --> 00:57:28.910
Just note those so that when we change
things we can compare those back.

00:57:29.860 --> 00:57:33.160
Okay,
so let's open up my source code here.

00:57:33.450 --> 00:57:35.680
Now I'm going to scroll down
to where I load my textures,

00:57:35.680 --> 00:57:37.540
down at the bottom.

00:57:37.960 --> 00:57:41.440
And like I said in the slides,
there's two lines of code.

00:57:41.470 --> 00:57:43.120
There's line one and line two.

00:57:43.210 --> 00:57:46.100
I'm just going to add those two
lines of code and see what behavior

00:57:46.100 --> 00:57:47.850
change that gives my application.

00:57:47.920 --> 00:57:53.460
So the text param i, I added that line,
and the GL pixel store i.

00:57:53.460 --> 00:57:54.110
OK.

00:57:54.910 --> 00:57:57.030
So let's run it.

00:58:01.100 --> 00:58:05.420
So now you can see I'm
achieving my 60 frames a second.

00:58:05.450 --> 00:58:09.500
You can also see that my CPU burden
has gone down substantially.

00:58:09.710 --> 00:58:14.910
So not only am I achieving frame rate,
but I'm freeing up

00:58:14.910 --> 00:58:16.320
quite a bit of the CPU.

00:58:16.320 --> 00:58:18.680
I'm consuming less power for portables.

00:58:18.710 --> 00:58:24.260
I'm freeing up CPU for doing
other types of processing.

00:58:24.480 --> 00:58:27.300
And I'm achieving higher performance.

00:58:31.460 --> 00:58:35.010
So let's go through and
take our samples again,

00:58:35.010 --> 00:58:38.180
just to take a look at
what Shark looks like now.

00:58:42.860 --> 00:58:48.390
So,
we're spending 37% of our time blocking.

00:58:48.700 --> 00:58:50.530
That's pretty interesting.

00:58:50.640 --> 00:58:54.150
It's interesting because
this is actually on a timer,

00:58:54.150 --> 00:58:57.160
and the timer is firing
at 60 frames a second.

00:58:57.160 --> 00:59:00.360
The rest of the time,
my application is just blocked.

00:59:00.360 --> 00:59:05.030
So if I was to modify my application
to fire at a much higher rate,

00:59:05.030 --> 00:59:08.410
the time that would be
blocked would go down.

00:59:08.760 --> 00:59:11.430
But this is actually,
if you learn to recognize

00:59:11.490 --> 00:59:14.660
what Shark is telling you,
this is actually a really

00:59:14.660 --> 00:59:19.670
important symbol to recognize
the ML set interrupts enabled,

00:59:19.690 --> 00:59:22.240
simply because that tells me
that somewhere I'm blocking,

00:59:22.240 --> 00:59:26.050
and then it becomes a process
of analyzing where that blocking

00:59:26.050 --> 00:59:27.820
behavior is coming from.

00:59:27.820 --> 00:59:32.170
So now, in the OpenGL Profiler,
let's go ahead and once again

00:59:32.330 --> 00:59:35.070
attach to this application...

00:59:37.490 --> 00:59:41.000
Look at my stats again just
to see how I'm looking.

00:59:41.050 --> 00:59:44.330
So,
what I see is that I used to be spending

00:59:44.330 --> 00:59:48.200
97% of my time in GL text sub-image 2D.

00:59:48.240 --> 00:59:52.320
That has dropped down to
0.04% of the application time.

00:59:52.360 --> 00:59:59.210
So I'm hardly spending any time there.

00:59:59.210 --> 01:00:01.330
And GL flush drawable
has become the top item.

01:00:01.980 --> 01:00:02.700
Not a bad place to be.

01:00:02.700 --> 01:00:06.840
I've gone down from 97% of
the application time being

01:00:06.840 --> 01:00:09.700
spent in OpenGL down to 30%.

01:00:13.780 --> 01:00:18.710
So let's go back to slides.

01:00:18.750 --> 01:00:21.920
OK, so that's basically all
I had to talk about.

01:00:21.990 --> 01:00:27.180
For more information,
there are these sample code

01:00:27.180 --> 01:00:30.980
up on the WWDC 2005 website.

01:00:31.010 --> 01:00:36.640
And TechPubs has a number of documents
up there that have been updated

01:00:36.640 --> 01:00:41.070
for Tiger for you to review that
give good information about OpenGL.

01:00:41.080 --> 01:00:44.230
So I encourage you to go up there
and look at that website for any of

01:00:44.240 --> 01:00:48.250
the follow-on information you may
be looking for after these sessions.

01:00:48.560 --> 01:00:51.340
I also encourage you to look
at the OpenGL org website.

01:00:51.440 --> 01:00:56.240
It's the website maintained
for the OpenGL organization.

01:00:56.640 --> 01:01:00.110
It has a number of links
and interesting articles,

01:01:00.110 --> 01:01:06.220
documents,
and developer events that are happening.

01:01:07.300 --> 01:01:08.510
Events after this session.

01:01:08.520 --> 01:01:10.490
An important one is we're
going to be in a lab,

01:01:10.490 --> 01:01:12.680
in the Tiger Lab,
right after this session.

01:01:12.680 --> 01:01:15.010
So anybody that has a question
about anything we've talked

01:01:15.020 --> 01:01:17.420
about or about your application,
they can come there.

01:01:17.420 --> 01:01:21.160
Myself and a number of OpenGL engineers
will be there to answer your questions.

01:01:21.160 --> 01:01:29.910
And tomorrow at 9 o'clock,
we're having also a drop-in lab where you

01:01:29.910 --> 01:01:29.910
can come by and talk to OpenGL engineers.

01:01:31.730 --> 01:01:33.980
So, who to contact?

01:01:34.010 --> 01:01:38.520
If you need to contact somebody at Apple,
you can contact myself,

01:01:38.690 --> 01:01:41.170
Stauffer@apple.com, or Travis Brown.

01:01:41.540 --> 01:01:48.660
Travis is very helpful for going
out and a good person to contact.

01:01:48.660 --> 01:01:50.810
So, we're going to go into
questions and answers right now.