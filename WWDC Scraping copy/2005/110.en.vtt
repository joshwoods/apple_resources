WEBVTT

00:00:02.150 --> 00:00:06.540
What you'll learn in this session is
what the Accelerate framework is about.

00:00:06.540 --> 00:00:09.840
Some of you already are using it,
but for people who are not using it,

00:00:09.840 --> 00:00:11.790
this would be a good introduction.

00:00:12.000 --> 00:00:13.460
How to use the Accelerate framework?

00:00:13.560 --> 00:00:15.220
That would be Eric's section.

00:00:15.470 --> 00:00:18.000
And how to translate Altivec to SSC?

00:00:18.000 --> 00:00:21.300
We have a small section
for hardware overview.

00:00:21.740 --> 00:00:27.310
We have the instruction overview of the
SSC and the translation techniques of

00:00:27.310 --> 00:00:30.350
how to translate your Altivec to SSC.

00:00:30.690 --> 00:00:34.960
First of all,
I think the best thing to do for

00:00:34.960 --> 00:00:39.230
performance on Mac OS X on any platform
for people who are hungry for that sort

00:00:39.230 --> 00:00:43.580
of thing for computational performance
is to use the Accelerate framework.

00:00:43.600 --> 00:00:45.600
And what is inside the
Accelerate framework?

00:00:45.600 --> 00:00:47.600
We have a state-of-the-art
image processing library.

00:00:47.600 --> 00:00:51.600
We have vector mathematics,
which is vForce and vMathlib.

00:00:51.600 --> 00:00:55.130
We also have a state-of-the-art
signal processing library.

00:00:55.130 --> 00:00:57.770
Some of you might be
using our FFTs already.

00:00:57.960 --> 00:01:04.590
And our in-house technologies
use also the FFT quite a bit.

00:01:04.600 --> 00:01:06.970
Then we also have the
entire LA-PACK and the BLAS,

00:01:06.970 --> 00:01:09.600
which is the basic linear
algebra subroutines.

00:01:09.600 --> 00:01:13.790
We also have large number computations.

00:01:14.540 --> 00:01:19.000
I'd like to go over some of these
briefly to tell you what these are about.

00:01:19.040 --> 00:01:23.670
The level 1, 2, 3 BLAS,
the basic linear algebra subroutines,

00:01:23.740 --> 00:01:26.320
are vector-vector,
vector-vector matrix and

00:01:26.320 --> 00:01:28.180
matrix-matrix computations.

00:01:28.200 --> 00:01:31.820
And if you're doing that sort of work,
this is industry standard,

00:01:31.820 --> 00:01:35.900
it can be found on all sorts of
platforms and all sorts of OSs.

00:01:35.930 --> 00:01:38.360
The APIs are exactly the same.

00:01:38.610 --> 00:01:42.320
LAPACK, the linear algebra
package for eigensolvers,

00:01:42.520 --> 00:01:44.790
system solvers and things like that.

00:01:45.020 --> 00:01:48.030
If you're doing linear algebra
work of any sort in speech

00:01:48.420 --> 00:01:51.800
or in signal processing,
this would be the sort of

00:01:51.810 --> 00:01:52.960
library that you like to use.

00:01:55.130 --> 00:02:00.200
Now a little bit in detail about
what these libraries are all about.

00:02:00.200 --> 00:02:03.430
vDSP, the signal processing
library that we have,

00:02:03.600 --> 00:02:08.710
it has Fourier transforms, 1D and 2D,
real and complex,

00:02:08.840 --> 00:02:10.000
single and double precision.

00:02:10.000 --> 00:02:13.470
It has fast array math,
convolutions and correlations,

00:02:13.470 --> 00:02:18.000
all the regular things that you can
find in a signal processing library.

00:02:18.000 --> 00:02:21.500
vMathlib and vForce,
we set out to produce exactly the same

00:02:21.500 --> 00:02:26.000
thing that we have on the scalar domain,
which is the LibM, on the vector domain.

00:02:26.090 --> 00:02:31.000
So if you are sitting in vector code,
be it SSC or Altivec,

00:02:31.000 --> 00:02:34.160
and you are dealing with 128-bit vectors,
hardware vectors here,

00:02:34.160 --> 00:02:36.640
not mathematical vectors
that you point to,

00:02:36.640 --> 00:02:40.120
pointers, then you would like to have
the same facilities that

00:02:40.120 --> 00:02:43.800
you have inside your scalar,
like if you like to take the cosine of

00:02:43.800 --> 00:02:45.900
that vector or sine or things like that.

00:02:46.020 --> 00:02:51.000
vMathlib is... vForce is
that sort of facility.

00:02:51.000 --> 00:02:52.910
It will give you,
it will allow you to stay

00:02:52.910 --> 00:02:54.950
on the vector domain,
it will give you the answers

00:02:54.950 --> 00:02:56.000
back in the vector domain.

00:02:56.040 --> 00:02:58.810
So this is for people who are
actually vectorizing their code,

00:02:58.810 --> 00:03:00.000
writing vector code.

00:03:00.010 --> 00:03:04.110
A lot of people who would like to
benefit from vector computation in

00:03:04.190 --> 00:03:09.000
single precision on Altivec and single
precision and double precision on SSC,

00:03:09.050 --> 00:03:12.360
would like to have this sort of facility,
but they like to stay away

00:03:12.590 --> 00:03:14.000
from vector arithmetic.

00:03:14.000 --> 00:03:16.000
vForce is for them.

00:03:16.000 --> 00:03:18.000
It turns out vForce has higher
performance than the other libraries.

00:03:18.050 --> 00:03:20.010
vForce has higher
performance than vMathlib,

00:03:20.010 --> 00:03:22.960
and the reason is that vForce
operates on very large arrays.

00:03:23.020 --> 00:03:28.000
You can give it an array of
1024 elements or 1024k elements,

00:03:28.010 --> 00:03:30.950
lots of elements, and this allows the
pipes to be saturated,

00:03:31.020 --> 00:03:34.000
so it will give you
much better performance.

00:03:34.070 --> 00:03:40.000
Using vForce does not make you
use the vector engine directly,

00:03:40.000 --> 00:03:44.000
but underneath it decides to do it,
and it will do that for you.

00:03:44.000 --> 00:03:46.000
So you don't have to be any
vector programming to use vForce.

00:03:46.000 --> 00:03:46.990
Very, very capable of doing that.

00:03:47.000 --> 00:03:48.890
Very, very capable little library.

00:03:49.000 --> 00:03:50.000
We introduced that.

00:03:50.000 --> 00:03:54.000
This is the first
incarnation of it for Tiger.

00:03:54.000 --> 00:03:56.850
As we go along,
before I go through this here,

00:03:57.140 --> 00:04:01.250
is that our aim is that vMathlib
and vForce will mimic more and

00:04:01.250 --> 00:04:05.000
more the functionality of the Libem
that we have on the scalar domain.

00:04:05.000 --> 00:04:09.100
So many of the functions which
you may find not there will

00:04:09.100 --> 00:04:12.230
eventually show up there,
so that we'll have parity

00:04:12.320 --> 00:04:15.000
pretty much between Libem,
vForce, and vMathlib.

00:04:15.010 --> 00:04:17.970
So that's what we're planning on doing.

00:04:18.000 --> 00:04:21.000
The other two libraries
are vBasicOps and vBignum.

00:04:21.000 --> 00:04:24.450
As you know,
the hardware on SSC and Altevec allow

00:04:24.450 --> 00:04:29.890
you a certain amount of facilities
to a certain amount of data types.

00:04:30.000 --> 00:04:31.920
On Altevec,
you have things up to 32 bits,

00:04:32.020 --> 00:04:34.000
but if you wanted to
have higher than that,

00:04:34.000 --> 00:04:37.120
if you wanted to operate
on 64 bits or 128 bits,

00:04:37.120 --> 00:04:41.000
let's say adds, multiplies, or shifts,
or things like that,

00:04:41.000 --> 00:04:43.980
then the vBasicOps will do that for you.

00:04:44.000 --> 00:04:49.410
vBignum is essentially the same thing,
but it takes it from 128 bit

00:04:49.410 --> 00:04:55.000
to 1024 and allows you to do
multi-precision arithmetic on that.

00:04:55.000 --> 00:04:59.000
The last thing in here is vImage.

00:04:59.000 --> 00:05:01.640
vImage is our, as I said,
state-of-the-art image

00:05:01.790 --> 00:05:02.950
processing library.

00:05:03.040 --> 00:05:07.950
It is used in all sorts of
technologies within Apple and outside.

00:05:08.000 --> 00:05:09.700
It's very fast.

00:05:10.150 --> 00:05:12.830
We introduced this two OSs ago.

00:05:13.150 --> 00:05:18.000
It has the regular things,
the convolutions, the morphologies,

00:05:18.000 --> 00:05:24.000
geometry, transforms,
and things of that nature.

00:05:24.000 --> 00:05:26.970
What I would like to do is I just
gave you a small overview of

00:05:27.110 --> 00:05:28.980
what the Accelerate framework is.

00:05:29.030 --> 00:05:33.000
I'd like to pass this on to my colleague,
Eric Pospischel,

00:05:33.000 --> 00:05:37.450
who is going to talk to you in depth
about how to use the Accelerate framework

00:05:37.450 --> 00:05:39.950
by one example and go over one example.

00:05:40.020 --> 00:05:41.000
Eric.

00:05:41.000 --> 00:05:42.000
Thank you.

00:05:42.000 --> 00:05:42.930
Good morning.

00:05:43.000 --> 00:05:47.000
Well, I just told you some of
what's in Accelerate.

00:05:47.000 --> 00:05:53.000
I'm going to tell you
why to use it and how.

00:05:53.000 --> 00:05:58.000
This slide shows the performance of
one of our FFT routines on a G5 system.

00:05:58.000 --> 00:05:59.950
FFT stands for Fast Fourier Transform.

00:06:00.010 --> 00:06:02.850
We don't need to go into much
detail about what it does,

00:06:02.850 --> 00:06:06.250
although coincidentally somebody
just asked me before the talk

00:06:06.250 --> 00:06:08.000
about starting to use this.

00:06:08.000 --> 00:06:11.000
It is a quite popular
routine in signal processing.

00:06:11.110 --> 00:06:15.350
It's a famous routine and it provides
a good mix of both calculation in the

00:06:15.370 --> 00:06:18.000
processor and motion of data in memory.

00:06:18.000 --> 00:06:21.000
So it's a challenging
routine to optimize.

00:06:21.000 --> 00:06:25.930
The first table shows how long it
takes to execute a single-position

00:06:26.070 --> 00:06:30.000
FFT on 1,024 complex elements on a G5.

00:06:30.170 --> 00:06:34.320
If you open up Numerical
Recipes and type in the 4-1

00:06:34.330 --> 00:06:37.990
FFT routine there and run that,
it's going to take about

00:06:37.990 --> 00:06:40.000
130,000 CPU cycles to finish.

00:06:40.000 --> 00:06:45.940
If you're familiar with the FFT,
you might have heard of FFTW,

00:06:46.050 --> 00:06:50.000
which stands for Fastest
Fourier Transform in the West.

00:06:50.000 --> 00:06:54.500
And it's a highly optimized and
self-tuning FFT developed at MIT by

00:06:54.500 --> 00:06:57.000
Matteo Frigo and Steven Johnson.

00:06:57.000 --> 00:07:00.400
And it certainly runs faster
than Numerical Recipes in

00:07:00.400 --> 00:07:03.000
about 32,300 CPU cycles.

00:07:03.000 --> 00:07:08.750
But it doesn't take full advantage
of Altavec's capabilities.

00:07:09.000 --> 00:07:12.000
FFT does take advantage of vector
processing to great effect.

00:07:12.000 --> 00:07:15.610
And as you can see,
it runs a little faster than

00:07:15.610 --> 00:07:17.960
the fastest FFT in the West.

00:07:18.040 --> 00:07:22.930
It runs about three times
faster in 11,200 CPU cycles.

00:07:23.160 --> 00:07:28.410
So we got an advantage here out
of using the Altivec capabilities.

00:07:28.510 --> 00:07:33.000
Double precision is harder because
the PowerPC doesn't provide vector

00:07:33.000 --> 00:07:34.600
processing for double precision.

00:07:34.700 --> 00:07:38.360
And in spite of that,
we still managed to beat FFTW quite

00:07:38.490 --> 00:07:44.960
handily from 40,000 CPU cycles
for FFTW to 27,000 for ours.

00:07:45.040 --> 00:07:45.750
So that's a clear win.

00:07:45.760 --> 00:07:50.870
That should motivate you pretty strongly
to want to use the Accelerate framework.

00:07:52.690 --> 00:07:54.930
And next, here is how to use it.

00:07:54.990 --> 00:07:57.560
I'm going to go through this quickly,
and then I'm going to look at

00:07:57.560 --> 00:08:00.470
a little bit of example code.

00:08:00.820 --> 00:08:08.460
So, in the source code,
you need to include the Xcelerate header.

00:08:08.460 --> 00:08:09.180
Simple enough.

00:08:09.220 --> 00:08:11.570
And when you build the application,
you need to tell the linker that

00:08:11.570 --> 00:08:13.460
you're using the Xcelerate framework.

00:08:13.630 --> 00:08:16.800
And if you're using Xcode,
as probably most of you are,

00:08:16.800 --> 00:08:19.430
certainly after Monday,
I think a lot of you are,

00:08:19.430 --> 00:08:22.860
you do that just by adding the
Xcelerate framework to your project.

00:08:22.960 --> 00:08:25.280
And once you do that,
Xcode knows how to pass the

00:08:25.280 --> 00:08:26.650
framework to the linker.

00:08:26.650 --> 00:08:29.340
If you're using make or
link commands directly,

00:08:29.340 --> 00:08:32.260
you just add the GCC switch,
dash framework Xcelerate

00:08:32.450 --> 00:08:33.380
to the link command.

00:08:35.120 --> 00:08:37.430
So those are the declarations you need.

00:08:37.500 --> 00:08:41.230
And here's some sample code.

00:08:41.500 --> 00:08:44.090
One reason we chose the FFT is
it's a little more complicated to

00:08:44.090 --> 00:08:45.500
use than most xcelerate routines.

00:08:45.500 --> 00:08:48.500
A lot of routines,
you can just call and do the work.

00:08:48.500 --> 00:08:53.990
The FFT as an alternative
requires some setup.

00:08:54.000 --> 00:08:56.490
In spite of that,
it's still fairly straightforward to use.

00:08:56.500 --> 00:08:59.500
So this summarizes the code to do that.

00:08:59.500 --> 00:09:04.870
To do the setup, you call this routine,
vdsp create FFT setup at the--you call

00:09:04.870 --> 00:09:08.570
it once at the start of your application,
and it gets the memory it needs,

00:09:08.610 --> 00:09:12.000
and it does some calculations to
prepare some constants for later FFTs,

00:09:12.000 --> 00:09:16.990
and it returns a value to you
that is a handle to that data.

00:09:17.000 --> 00:09:22.000
You do need to check that handle to
see if allocation of memory failed.

00:09:22.180 --> 00:09:25.510
If it didn't fail,
then you can use the FFTs as many times

00:09:25.510 --> 00:09:29.220
as you want later in your application
without having to check the data

00:09:29.220 --> 00:09:31.960
anymore-- check the setup anymore.

00:09:32.080 --> 00:09:36.000
So once you've got the setup,
you can go ahead and call vdsp fft zip.

00:09:36.150 --> 00:09:39.000
And you can call this as
many times as you want.

00:09:39.000 --> 00:09:40.960
This is a high-performance routine.

00:09:41.030 --> 00:09:41.930
The setup is not.

00:09:42.000 --> 00:09:43.000
You call the setup only once.

00:09:43.070 --> 00:09:46.400
You call the FFT as many times as you
want while you're doing your image

00:09:46.400 --> 00:09:49.300
processing or system processing,
whatever.

00:09:49.760 --> 00:09:51.900
And at the end of your application,
you release the memory.

00:09:51.900 --> 00:09:55.840
You call vDSP destroy
FFT setup to do that.

00:09:56.940 --> 00:09:58.900
Could I have demo one on screen now?

00:09:58.900 --> 00:10:01.900
We'll take a look at
the demonstration code.

00:10:01.900 --> 00:10:05.560
This is actual running code.

00:10:05.560 --> 00:10:08.220
It doesn't do too much
because all the data is zero.

00:10:08.220 --> 00:10:09.270
You have to supply your own data.

00:10:09.280 --> 00:10:10.180
We just give you the routine.

00:10:10.180 --> 00:10:14.340
We'll take a look at some pieces of this.

00:10:14.340 --> 00:10:16.980
Obviously the include
of the headers here.

00:10:16.980 --> 00:10:22.920
Another thing to look at
here is we allocate the data,

00:10:22.920 --> 00:10:25.680
we allocate, excuse me,
we allocate space for the data.

00:10:26.470 --> 00:10:31.210
Malik is a common way to allocate large
amounts of space and it has additional

00:10:31.420 --> 00:10:34.580
benefit of returning addresses that
are aligned well for high performance.

00:10:34.580 --> 00:10:40.960
The AltaVec capability,
the AltaVec processor wants its vectors

00:10:40.960 --> 00:10:44.900
to be aligned to multiples of 16
bytes and Malik will do that for you.

00:10:44.900 --> 00:10:49.280
If instead you allocate space
by declaring arrays in C,

00:10:49.280 --> 00:10:54.110
they might not be aligned
well and you won't get as good

00:10:54.160 --> 00:10:57.850
performance and that will,
there will be some effect

00:10:57.910 --> 00:10:59.370
of that as well on SSE.

00:10:59.380 --> 00:11:03.160
It doesn't require alignment in the
same ways that AltaVec does but it

00:11:03.270 --> 00:11:05.100
still benefits from it in situations.

00:11:05.100 --> 00:11:10.840
So we do recommend using Malik
to allocate the space you need.

00:11:10.840 --> 00:11:16.920
And then for complex data,
we package the,

00:11:17.140 --> 00:11:19.840
We package the pointers to the
real imaginary parts into a

00:11:19.850 --> 00:11:23.620
data structure here so they can
be passed around as one unit.

00:11:24.240 --> 00:11:25.200
I just set the data to zero.

00:11:25.200 --> 00:11:28.600
As I said, you have to supply your own.

00:11:28.840 --> 00:11:39.430
We call the setup routine here and
check its result and call the FFT.

00:11:42.520 --> 00:11:46.230
When we call the FFT,
that first parameter is that data

00:11:46.430 --> 00:11:47.520
that got returned by the setup.

00:11:47.650 --> 00:11:52.600
The second parameter is the structure
that contains the pointers to your data,

00:11:52.600 --> 00:11:54.300
the signal data.

00:11:54.380 --> 00:11:57.340
The third parameter here
isn't the length of the data.

00:11:57.340 --> 00:12:01.340
It's going to be the base-2
logarithm of the length.

00:12:01.600 --> 00:12:05.320
So that would be 10 to
represent 1,024 elements.

00:12:05.360 --> 00:12:09.150
2 to the 10 is 1,024.

00:12:10.050 --> 00:12:13.200
And,
the final parameter is the direction,

00:12:13.320 --> 00:12:18.820
which is forward for forward FFT and
FFT_inverse for a reverse FFT.

00:12:18.820 --> 00:12:22.750
And, there's no result here,
we don't have anything to test

00:12:22.750 --> 00:12:25.840
because we know it's going to work.

00:12:25.840 --> 00:12:27.660
This sample code does only
show one call to the FFT,

00:12:27.660 --> 00:12:32.060
but typically this is going to be in some
sort of processing loop and release our

00:12:32.080 --> 00:12:35.000
space and destroy everything at the end.

00:12:35.000 --> 00:12:38.540
So, it's really pretty simple to use
a lot of the accelerate routines.

00:12:38.540 --> 00:12:43.110
you can just insert them into your
application pretty quickly on that.

00:12:44.020 --> 00:12:45.800
Now I'm going to give the
floor to my colleague,

00:12:45.820 --> 00:12:49.280
Ian Ollmann,
who will show you many things that

00:12:49.330 --> 00:12:52.800
you must do to optimize an application
for high performance if you choose

00:12:52.800 --> 00:12:57.400
not to use our Accelerate framework
or can't use it for some way.

00:13:07.100 --> 00:13:10.460
So the reason we presented the
Accelerate framework first is we

00:13:10.460 --> 00:13:14.940
really want you to investigate that
first and save yourself a lot of time.

00:13:14.940 --> 00:13:18.180
You can write your own AlteVac code,
and a number of you have,

00:13:18.410 --> 00:13:20.320
and that's great.

00:13:20.350 --> 00:13:22.360
There are a lot of functions
that we just can't provide in the

00:13:22.450 --> 00:13:25.660
Accelerate framework because they're
very specialized to your app.

00:13:25.660 --> 00:13:29.820
We'd like to build it as we go along and
bring in more and more functionality.

00:13:29.840 --> 00:13:31.300
But if you've got something
really wild and crazy,

00:13:31.300 --> 00:13:33.700
you might have to write your own code.

00:13:33.700 --> 00:13:36.880
So this is always going to be something
people will be looking at doing.

00:13:36.880 --> 00:13:40.940
And now that we have the Intel platform,
for the same reasons you vectorized,

00:13:40.940 --> 00:13:43.100
you're probably going to
want to write SSE code.

00:13:43.100 --> 00:13:46.420
It's a definite strong win over Scalar.

00:13:46.420 --> 00:13:50.560
So we encourage you to
consider doing that.

00:13:50.660 --> 00:13:53.760
So for the rest of this talk,
I'll be talking about SSE.

00:13:53.760 --> 00:13:58.500
What I'm really talking about is SSE,
SSE2, SSE3, and any future incarnations.

00:13:58.500 --> 00:14:02.040
It just gets to be taxing
to say that all the time.

00:14:02.140 --> 00:14:05.910
So the good news about translating
AlteVac to SSE is that they're

00:14:05.920 --> 00:14:06.720
actually quite similar.

00:14:06.760 --> 00:14:11.800
They have the same vector size
as 128-bit wide for the register.

00:14:11.800 --> 00:14:14.220
There's pretty good instruction homology.

00:14:14.220 --> 00:14:17.370
You'll generally find that the
AlteVac series of instructions are

00:14:17.370 --> 00:14:20.260
larger than SSE in terms of numbers.

00:14:20.350 --> 00:14:24.040
So there'll be a few things that are
used in AlteVac that aren't there,

00:14:24.040 --> 00:14:26.030
and you'll have to find ways around it.

00:14:26.220 --> 00:14:28.400
In our experience,
and we've ported a bunch

00:14:28.470 --> 00:14:30.940
of the Accelerate framework
over to the SSE unit,

00:14:31.120 --> 00:14:34.460
most of the work that we actually
had to do when writing the Altivec

00:14:34.580 --> 00:14:41.390
code was the parallelization,
the DAO layout,

00:14:41.390 --> 00:14:41.390
planning and handling misalignment.

00:14:41.580 --> 00:14:44.610
The good news is you've already done
that work if you have Altivec code,

00:14:44.610 --> 00:14:46.840
and you don't really
have to redo it for SSC.

00:14:46.840 --> 00:14:48.540
The data's already
there where you put it.

00:14:48.540 --> 00:14:50.790
It's already aligned.

00:14:50.840 --> 00:14:54.840
It may already be padded out
to multiples of 128 bits.

00:14:54.840 --> 00:14:58.840
So in our experience,
and we hope that it carries over to you,

00:14:58.840 --> 00:15:02.260
you can expect the translation
of Altivec to SSC to take a small

00:15:02.260 --> 00:15:07.070
fraction of the time that it took to
write the Altivec in the first place,

00:15:07.070 --> 00:15:08.760
in most cases.

00:15:10.000 --> 00:15:13.240
So as a overview of what you learned,
we'll have a brief

00:15:13.240 --> 00:15:14.080
discussion of hardware.

00:15:14.080 --> 00:15:17.840
Now, Apple hasn't actually said what the
specific chip is that's going to go out,

00:15:17.840 --> 00:15:20.040
so I'm just going to kind of gloss
over it and show you what's on

00:15:20.040 --> 00:15:23.360
the developer transition system,
but don't expect that that's necessarily

00:15:23.360 --> 00:15:26.620
going to apply to what customers get.

00:15:26.620 --> 00:15:27.900
There's a C programming model.

00:15:27.900 --> 00:15:30.340
You don't have to write an assembly.

00:15:30.340 --> 00:15:32.460
As its on-site of data
types and intrinsics.

00:15:32.480 --> 00:15:35.680
And finally, I'll talk about difference
in instructions,

00:15:35.680 --> 00:15:38.840
like how to map from ultimate
to SSE and some of the tougher

00:15:38.840 --> 00:15:42.140
cases and what to watch out for.

00:15:42.780 --> 00:15:44.830
So as far as the hardware overview,
as I mentioned earlier,

00:15:44.830 --> 00:15:49.380
there's eight 128-bit XMM registers.

00:15:49.400 --> 00:15:53.150
If we, on the 64-bit architecture
looking way out into the future,

00:15:53.150 --> 00:15:56.180
or if you're programming for Linux now,
you'll find that you

00:15:56.180 --> 00:15:58.300
actually get 16 of them.

00:15:58.300 --> 00:16:00.490
The register file is flat like Altivec.

00:16:00.490 --> 00:16:03.880
It's not stack-based
like the FPU on the X87.

00:16:03.880 --> 00:16:10.720
There's no special purpose registers,
so you can use all that space.

00:16:10.720 --> 00:16:14.950
The instructions generally take no more
than two register operations-- operands.

00:16:14.950 --> 00:16:17.690
So you might be used to
from Altivec being able to

00:16:17.810 --> 00:16:21.340
provide up to four operators,
so you'll only get two here.

00:16:21.420 --> 00:16:24.040
And the instructions are
typically destructive.

00:16:24.040 --> 00:16:28.330
That is, one of the inputs is destroyed
and replaced with result data.

00:16:29.180 --> 00:16:32.190
On the Pentium IV core,
I just want to give you a

00:16:32.240 --> 00:16:35.630
sense that there's really a
lot going on behind the scenes.

00:16:35.640 --> 00:16:42.100
You've got eight different units
providing the vector support.

00:16:42.100 --> 00:16:45.160
So it's not very simple in the back end,
but on the dispatch,

00:16:45.160 --> 00:16:47.100
everything goes through port ones.

00:16:47.100 --> 00:16:51.300
You kind of get this throughput of
one vector instruction per cycle.

00:16:51.770 --> 00:16:55.020
As far as the data types
that are supported,

00:16:55.160 --> 00:16:58.980
they support the same
sorts of types as Altivec.

00:16:58.980 --> 00:17:02.820
You can get 8-bit, 16-bit, 32-bit ints,
32-bit floats as well.

00:17:02.820 --> 00:17:06.710
In addition,
there is support for 64-bit types,

00:17:06.720 --> 00:17:12.200
which means 64-bit ints and
double precision floating point.

00:17:12.200 --> 00:17:14.820
The hardware provides aligned
and misaligned loads and stores,

00:17:14.830 --> 00:17:17.960
so that will probably be
welcome to a number of you.

00:17:17.960 --> 00:17:21.620
There is a limited permute
capability on board.

00:17:21.620 --> 00:17:24.590
It's you can do predicated
operation just like Altivec.

00:17:24.640 --> 00:17:27.290
It has some saturated arithmetic support.

00:17:27.340 --> 00:17:29.770
It has this normal set of
integer operations that

00:17:29.850 --> 00:17:33.510
you'd expect from Altivec,
sort of multiply, add, subtracts, min,

00:17:33.570 --> 00:17:33.880
max.

00:17:33.880 --> 00:17:38.460
It also provides a sum of
absolute differences instructions

00:17:38.460 --> 00:17:40.760
useful for video encoding.

00:17:40.780 --> 00:17:42.540
It does the various Boolean operations.

00:17:42.540 --> 00:17:46.340
Same thing for floating point, multiply,
add, subtract, et cetera.

00:17:46.340 --> 00:17:48.100
In addition,
there's hardware divide and square root,

00:17:48.110 --> 00:17:50.440
so that will save you a little
time if you're tired of programming

00:17:50.440 --> 00:17:51.520
Newton graphs and opt-in.

00:17:51.630 --> 00:17:58.900
The C programming model for SSE,
there's an Intel C programming interface

00:17:58.910 --> 00:18:05.120
supported by the Intel C compiler and
also various other Intel-based compilers.

00:18:05.120 --> 00:18:07.860
And it's a lot like the Altivec
C programming interface.

00:18:07.860 --> 00:18:11.500
So to give you an idea,
they provide a series of types.

00:18:11.500 --> 00:18:14.960
The Intel types,
there's a double underbar M128I,

00:18:15.000 --> 00:18:17.620
which will stand for any packed integer.

00:18:17.620 --> 00:18:21.350
You can also use double
underbar 128 for floats.

00:18:21.470 --> 00:18:22.690
And the other type of type is the D.

00:18:22.690 --> 00:18:25.050
In Accelerate framework,
we provide a whole series of types to

00:18:25.050 --> 00:18:29.000
better differentiate the various integer
types you might put in a register.

00:18:29.000 --> 00:18:31.880
We actually suggest you use these
things because it gives GDB more

00:18:31.880 --> 00:18:34.120
information on how to show the data.

00:18:34.120 --> 00:18:37.680
So you can actually view your data
as a vector full of 8-bit types.

00:18:37.680 --> 00:18:42.120
So if you include accelerate.h,
you'll be able to use the sort of VSNT8,

00:18:42.280 --> 00:18:44.240
for example, as shown here.

00:18:44.240 --> 00:18:46.600
And you can view your
stuff as a series of cares.

00:18:48.490 --> 00:18:52.480
As for the intrinsics,
Altivec would have a vecadd,

00:18:52.670 --> 00:18:57.000
SSC will have a mmaddepi8.

00:18:57.000 --> 00:18:59.550
The convention here is they
put the type of the data on

00:18:59.550 --> 00:19:01.350
the end of the instruction.

00:19:01.360 --> 00:19:04.160
E stands for extended,
which means 128-bit register.

00:19:04.160 --> 00:19:05.330
It's not MMX.

00:19:05.490 --> 00:19:08.400
P for packed, I for signed integer.

00:19:08.400 --> 00:19:10.390
If you have an unsigned integer,
it'll be EPU.

00:19:10.390 --> 00:19:13.390
8 is the size of the element type.

00:19:13.500 --> 00:19:16.970
Where Altivec uses vecadd over and
over again for different data types,

00:19:17.010 --> 00:19:20.500
you'll see that SSC changes
the function name or the

00:19:20.500 --> 00:19:22.220
intrinsic name as you go along.

00:19:22.350 --> 00:19:28.180
PES stands for packed float,
packed single precision float.

00:19:28.310 --> 00:19:32.110
And in addition,
the SSC unit supports 64-bit INS,

00:19:32.110 --> 00:19:34.000
which is the EPI64.

00:19:34.000 --> 00:19:35.990
You can do packed double precision.

00:19:36.000 --> 00:19:40.510
And also for the floating point stuff,
it has a series of scalar operations that

00:19:40.510 --> 00:19:42.990
operate only one element in the vector.

00:19:46.330 --> 00:19:48.340
So here's the sample function.

00:19:48.440 --> 00:19:51.150
This is what you might do in Altivec
to calculate the distance from

00:19:51.150 --> 00:19:52.910
the origin to a point in 2D space.

00:19:52.990 --> 00:19:57.710
It's a simple square root
of x squared plus y squared.

00:19:58.370 --> 00:20:00.260
Here's the same thing in SSE.

00:20:00.260 --> 00:20:03.720
And you'll notice as I flip back and
forth that very little has changed here.

00:20:03.820 --> 00:20:04.960
You have to include an extra header.

00:20:04.960 --> 00:20:10.140
There's an xmm and trin.h,
which on GCC will pull in everything.

00:20:10.270 --> 00:20:14.450
On Intel you might want to pull in
one of the later headers like emm or

00:20:14.450 --> 00:20:17.140
pmm for the Prescott new instructions.

00:20:17.610 --> 00:20:21.800
And there's a standard
multiplier you're used to,

00:20:21.800 --> 00:20:22.740
mmolps.

00:20:22.740 --> 00:20:24.320
Altivec has a multiply add fuse.

00:20:24.380 --> 00:20:28.360
There is no multiply add fuse on SSEs,
so what we do is we split it apart into

00:20:28.360 --> 00:20:30.500
add and multiply on the second line.

00:20:30.610 --> 00:20:38.080
And then finally, for the square root,
we just call into Accelerate framework,

00:20:38.100 --> 00:20:40.210
which is present on both platforms,
and you can call it with either

00:20:40.210 --> 00:20:40.210
Altivec vectors or SSE vectors.

00:20:40.670 --> 00:20:46.860
If you're clever,
you can sometimes write one piece of

00:20:46.860 --> 00:20:49.500
code that works on both platforms.

00:20:49.500 --> 00:20:53.100
So in the Universal Binary
Programming Guide,

00:20:53.100 --> 00:20:56.090
you'll find an example of a matrix
multiplication that's written

00:20:56.090 --> 00:21:01.100
using a shared set of code and some
defines up at front that map it to

00:21:01.100 --> 00:21:04.140
either instruction set architecture.

00:21:04.140 --> 00:21:08.570
C provides a sort of leading edge
support for standard operators

00:21:08.580 --> 00:21:11.890
with vectors like this example,
which would work on both.

00:21:11.980 --> 00:21:19.960
But that would tie you to GCC,
so take caution before going that way.

00:21:20.040 --> 00:21:22.470
As far as what parts of the vector
unit are guaranteed to be there,

00:21:22.470 --> 00:21:26.920
the hardware and the ABI supports MMX,
SSC, SSC2 guaranteed.

00:21:26.960 --> 00:21:31.230
To detect SSC3,
you go through the same sysketl by name

00:21:31.330 --> 00:21:35.980
interface that you use for Altivec,
except you change the string that you

00:21:35.980 --> 00:21:37.920
use to test for SSC3 in particular.

00:21:37.920 --> 00:21:39.440
particular.

00:21:41.280 --> 00:21:45.140
For Floating Point,
you'll find that as far as the ISA goes,

00:21:45.140 --> 00:21:46.440
there's a very good matchup in general.

00:21:46.440 --> 00:21:49.520
Both are strongly influenced by IEEE 754.

00:21:49.720 --> 00:21:53.180
SSC is a lot like Altivec,
except that you also get

00:21:53.180 --> 00:21:56.440
double precision operations,
you get scalar operations, you know,

00:21:56.440 --> 00:21:59.750
the divide and square root in hardware,
and it's a fully IEEE 754

00:21:59.820 --> 00:22:02.040
compliant machine,
which means you can actually

00:22:02.050 --> 00:22:05.380
get exceptions and set flags
and set rounding modes.

00:22:05.440 --> 00:22:08.540
You don't get the multi-add fuse unit,
and you aren't going to

00:22:08.560 --> 00:22:09.510
get vector compare bounds.

00:22:09.530 --> 00:22:11.900
I doubt any of you have used
the vector compare bounds.

00:22:11.920 --> 00:22:14.840
And there's a log 2 to
the x estimate on Altivec,

00:22:14.840 --> 00:22:19.270
which isn't there either,
but you probably didn't use that either.

00:22:19.600 --> 00:22:23.580
As for the Transcendentals,
as mentioned earlier,

00:22:23.580 --> 00:22:27.330
just include Accelerate, accelerate.h.

00:22:27.350 --> 00:22:29.710
It's sort of like your
vector math library.

00:22:29.710 --> 00:22:32.940
It will give you all of the
vectors functions that you've

00:22:33.000 --> 00:22:34.340
come to expect from libm.

00:22:34.540 --> 00:22:36.500
And you get the rounding modes.

00:22:36.500 --> 00:22:41.480
If you want to change the rounding
modes or exceptions or flag bits,

00:22:41.490 --> 00:22:44.500
they provide intrinsics mm_get_scr.

00:22:44.500 --> 00:22:50.300
You can read it in and you can
use mm_set_scr at the bottom of

00:22:50.310 --> 00:22:52.500
this slide for changing things.

00:22:52.530 --> 00:22:55.620
There's one additional hazard under
SSC that you'll have to watch out for

00:22:55.700 --> 00:22:57.500
if you're doing floating point work.

00:22:57.500 --> 00:23:00.500
They take a trap under normal.

00:23:00.500 --> 00:23:01.470
Altivec does too.

00:23:01.530 --> 00:23:04.500
The big difference is that
by default on a gValue,

00:23:04.500 --> 00:23:04.500
you can't do that.

00:23:04.590 --> 00:23:08.450
So if you're running a Mac OS X,
the denormal handling is turned off.

00:23:08.510 --> 00:23:10.500
You can turn it on if you want
and you'll get a kernel trap.

00:23:10.500 --> 00:23:14.500
And that takes 1,100 cycles
if you hit a denormal.

00:23:14.500 --> 00:23:18.430
On Intel, it's handled in hardware,
but the denorms are on by default

00:23:18.530 --> 00:23:20.900
because we're doing most of
the scalar arithmetic in your

00:23:20.900 --> 00:23:23.300
application using the vector unit.

00:23:23.510 --> 00:23:27.380
And if you hit a denormal,
it's a 1,500 cycle stall.

00:23:27.380 --> 00:23:29.500
So you may want to take special steps.

00:23:29.500 --> 00:23:32.090
You can do things like, for example,
check with the integer comparers

00:23:32.140 --> 00:23:34.500
to see if you're actually a
denormal and then handle it.

00:23:34.500 --> 00:23:37.200
handle those differently so you don't
actually hit the denormal in the floating

00:23:37.200 --> 00:23:39.490
point segment of the vector unit.

00:23:39.820 --> 00:23:46.280
If you want to turn denormals off,
which might be advisable

00:23:46.290 --> 00:23:53.020
for real-time code,
you can do that by using double underbar

00:23:53.020 --> 00:24:00.300
mmgetScr to load in the status and
control register or in the appropriate

00:24:00.300 --> 00:24:00.300
bits to turn off the denormal support
and then slam it back into the MxScr.

00:24:00.520 --> 00:24:03.600
As for integer,
you'll find the instructions

00:24:03.600 --> 00:24:06.340
are very similar to MMX,
if you've ever done that for SSE2,

00:24:06.360 --> 00:24:10.620
except they're sort of stamped
out twice in the register.

00:24:10.620 --> 00:24:12.630
You can do standard add and subtract.

00:24:12.660 --> 00:24:16.160
They provide 8, 16, 32 and 64 bits.

00:24:16.260 --> 00:24:19.630
For saturated ads,
the support is more limited.

00:24:19.640 --> 00:24:22.960
You only get 8 and 16-bit saturated ads.

00:24:22.960 --> 00:24:26.640
You can do min and max operations
with signed and unsigned,

00:24:26.640 --> 00:24:29.660
but only 8 and 16-bit integers.

00:24:29.670 --> 00:24:31.480
There's 5 multiplication operators.

00:24:31.660 --> 00:24:33.760
Almost none of them look
very much like Altevec,

00:24:33.760 --> 00:24:36.660
so if you're doing multiplication,
you typically have to

00:24:36.660 --> 00:24:40.340
rewrite those segments,
take advantage of these things.

00:24:40.340 --> 00:24:46.160
They do the low and high work 16-bit
part of a 16 times 16-bit multiply.

00:24:46.160 --> 00:24:50.680
There's another one that will do two
16-bit multiplies to get a 32-bit

00:24:50.680 --> 00:24:54.330
products and add them together
and give you a 32-bit result.

00:24:54.340 --> 00:24:54.980
That's a little bit like that.

00:24:55.000 --> 00:24:56.240
I can't sum.

00:24:56.240 --> 00:25:01.000
And there's some support for 32
by 32 gives you a 64-bit result.

00:25:01.910 --> 00:25:04.060
There are various compare operations.

00:25:04.060 --> 00:25:06.580
They operate just like AlteVec.

00:25:06.580 --> 00:25:09.090
You can -- when you use them,
they return minus one,

00:25:09.090 --> 00:25:13.820
where the compare returns true,
and zero in the mask where it's false.

00:25:13.860 --> 00:25:17.500
But they don't set the condition
register or any equivalent

00:25:17.510 --> 00:25:22.170
thereof on the x86 architecture,
so what you -- you'll have to do that

00:25:22.170 --> 00:25:27.800
a different way if you want to branch
directly based on what those things do.

00:25:27.800 --> 00:25:30.520
They provide a whole series of compares,
actually a larger set than

00:25:30.520 --> 00:25:33.930
you'll get in AlteVec,
and they're available in floating point

00:25:33.930 --> 00:25:36.140
in both scalar and pack varieties.

00:25:36.140 --> 00:25:39.500
So the AlteVec set are here in blue,
but you also get not equal to and

00:25:39.500 --> 00:25:43.320
unordered and ordered compares,
which are occasionally useful

00:25:43.320 --> 00:25:48.860
for doing the right thing when
NANDs come through your code.

00:25:48.860 --> 00:25:51.120
For integer compares,
there are only signed compares.

00:25:51.120 --> 00:25:54.540
There are no unsigned integer compares,
so that involves some

00:25:54.540 --> 00:25:58.690
dancing to get around,
and there's no 64-bit integer compare.

00:25:59.100 --> 00:26:02.230
For predication,
if you actually want to branch based on

00:26:02.230 --> 00:26:04.950
the result of one of these compare tests,
they have a move mask,

00:26:05.080 --> 00:26:08.460
a series of move mask
instructions that you can use.

00:26:08.490 --> 00:26:12.910
I forgot to mention earlier that
SSE is kind of designed with some

00:26:12.980 --> 00:26:14.650
segmentation between the data types.

00:26:14.710 --> 00:26:17.640
The integer, single precision and double
precision are different,

00:26:17.720 --> 00:26:22.260
so oftentimes you'll find instructions
that do substantially the same thing.

00:26:22.260 --> 00:26:23.960
For example, the loads,
which actually have

00:26:23.960 --> 00:26:25.140
three different variants.

00:26:25.140 --> 00:26:29.140
It's encouraged that you use the
right load with the right data type.

00:26:29.150 --> 00:26:32.090
And here we have three
different move masks.

00:26:32.140 --> 00:26:37.600
So we have one for integers,
one for double and one for float.

00:26:37.720 --> 00:26:43.210
So anyway, in this example,
if you want to do a

00:26:43.320 --> 00:26:47.640
SSC version of vec any equals,
which will branch if any value

00:26:47.640 --> 00:26:51.960
between A and B is equal to its
counterpart in the other one,

00:26:52.070 --> 00:26:54.180
what you can do is do
the regular compare,

00:26:54.180 --> 00:26:56.960
which provides you with the
zero or negative one mask.

00:26:56.980 --> 00:26:59.750
Move the mask bits,
it copies the high bit from

00:26:59.750 --> 00:27:05.300
each packed single into the
integer register directly.

00:27:05.330 --> 00:27:08.560
And then you can test that against zero.

00:27:09.660 --> 00:27:13.600
More commonly in vector you'll use
something like a select instruction

00:27:13.600 --> 00:27:18.190
to trace through both sides of a
conditional and then select between the

00:27:18.190 --> 00:27:20.380
two results based on the value of a test.

00:27:20.440 --> 00:27:22.990
There's no select instruction.

00:27:23.080 --> 00:27:30.810
So what you have to do is the and not
and and then or the results together,

00:27:30.900 --> 00:27:33.020
which you might have been
doing in scalar code.

00:27:33.020 --> 00:27:33.020
It's the same sort of thing.

00:27:34.030 --> 00:27:37.580
For type conversions,
you can do float to int conversions,

00:27:37.590 --> 00:27:40.040
but it only does signed ints,
no unsigned support.

00:27:40.040 --> 00:27:41.880
In addition, it saturates differently.

00:27:41.900 --> 00:27:44.490
If you have a very large floating
point value that's outside the

00:27:44.490 --> 00:27:48.900
range of a standard signed int,
it'll saturate to a very negative number.

00:27:48.900 --> 00:27:51.190
So if you want to preserve
the Altivec behavior,

00:27:51.190 --> 00:27:53.900
there's a three instruction
sequence you can do that.

00:27:53.900 --> 00:27:56.900
You first test against 2 to the
31 to see if it's an overflow

00:27:56.900 --> 00:27:57.890
and you get a mask back.

00:27:57.900 --> 00:28:02.970
Then you do the conversion and then
finally you XOR the result with the

00:28:02.980 --> 00:28:07.900
mask to flip all of those overflows,
which are giving a very negative number,

00:28:08.090 --> 00:28:12.490
back up to a positive saturated value.

00:28:14.030 --> 00:28:15.700
There are various int conversions.

00:28:15.700 --> 00:28:19.900
Mostly these things boil down to
kinds of permute or pack operations.

00:28:19.900 --> 00:28:22.900
In Altivec,
it's the same sort of thing on SSC.

00:28:23.090 --> 00:28:26.590
There are a couple of
conversions which are not there,

00:28:26.590 --> 00:28:30.460
such as the int to unsigned
short saturated pack.

00:28:30.460 --> 00:28:34.550
I don't particularly use
that one myself very much,

00:28:34.550 --> 00:28:37.450
so I don't miss it, but you might.

00:28:38.560 --> 00:28:41.480
There is no unsaturated packing.

00:28:41.610 --> 00:28:46.890
That's just a permute operation,
but if you need it and the permute

00:28:46.960 --> 00:28:50.540
doesn't quite do what you want,
then one thing you can do is sort of

00:28:50.690 --> 00:28:55.920
shift left and then shift back right
algebraically to chop off the high

00:28:55.920 --> 00:28:57.910
bits and then do the saturated pack.

00:28:58.000 --> 00:29:01.630
That will keep the saturating
pack from saturating.

00:29:03.040 --> 00:29:06.460
From the small int to large int,
usually you just use the unpack.

00:29:06.560 --> 00:29:09.140
They're a lot like the
Altivec merge instructions.

00:29:09.140 --> 00:29:13.400
So you merge it with zero
to go from a small unsigned

00:29:13.400 --> 00:29:16.010
to a larger unsigned value.

00:29:18.300 --> 00:29:23.260
For the Permute unit-- oh, I'm sorry.

00:29:23.260 --> 00:29:24.540
This is-- I'm sorry.

00:29:24.540 --> 00:29:28.540
It says unpack,
but this is really how to do a transpose.

00:29:28.550 --> 00:29:30.660
The merges are there,
so you can just-- previously in

00:29:30.660 --> 00:29:35.290
Altivec you'd use merge to do-- eight
merges to do a transpose operation.

00:29:35.300 --> 00:29:37.250
You can do the same
thing with unpack things.

00:29:37.310 --> 00:29:40.590
The only difference is that because the--

00:29:40.750 --> 00:29:44.600
the data appears in the register,
you swap low for high,

00:29:44.760 --> 00:29:47.600
which can be a little confusing.

00:29:47.600 --> 00:29:53.860
As for the permute shifts-- the shifts,
there are shift supports for

00:29:53.910 --> 00:29:57.360
a variety of different types,
but there isn't shift

00:29:57.360 --> 00:29:58.600
support for 8-bit integers.

00:29:58.600 --> 00:30:01.550
So if you're working on 8-bit
ints and you need to shift them,

00:30:01.650 --> 00:30:04.180
you'll probably have to
promote them to 16-bit ints,

00:30:04.180 --> 00:30:06.600
shift them, and put them back.

00:30:06.600 --> 00:30:10.600
They do have shifts for 64-bit types,
which is handy.

00:30:10.930 --> 00:30:15.600
There's a 128-bit shift like Altevec,
but it'll only move in

00:30:15.680 --> 00:30:16.580
multiples of 8 bits.

00:30:16.620 --> 00:30:19.600
It's a little bit like vec slo or sro.

00:30:19.600 --> 00:30:23.590
And it's a shift by immediate only,
so if you want to shift like

00:30:23.600 --> 00:30:25.600
we might have done in the
permute unit for misalignment,

00:30:25.600 --> 00:30:27.600
there's no way to do that.

00:30:30.360 --> 00:30:35.520
Finally, there's a series of shuffle
commands which do some basic

00:30:35.520 --> 00:30:37.640
sort of arbitrary permutes.

00:30:37.640 --> 00:30:40.290
I wouldn't say that it doesn't
cover all of the kinds of permutes

00:30:40.290 --> 00:30:43.030
you'd want to do with Altivec or
that you could do with Altivec.

00:30:43.080 --> 00:30:46.180
Altivec will allow you to
move any bytes anywhere.

00:30:46.300 --> 00:30:50.300
The permute unit is a little
bit more limited here.

00:30:50.300 --> 00:30:52.300
So for floating point,
there is a floating point shuffle

00:30:52.300 --> 00:30:57.530
that will allow you to copy two floats
from vector A and put them in the

00:30:57.530 --> 00:30:58.300
high two positions on the result.

00:30:58.300 --> 00:31:02.260
And then two floats from vector
B and put them into the low

00:31:02.260 --> 00:31:04.300
two positions on the result.

00:31:04.300 --> 00:31:08.350
There's an integer permute which
operates on 32-bit ints which

00:31:08.350 --> 00:31:12.300
will allow you to just randomly
shuffle around within one vector.

00:31:12.370 --> 00:31:17.100
And then there's a 16-bit thing
which does the same thing except you

00:31:17.100 --> 00:31:22.300
randomly shuffle them around within
the high or low 64 bits of the vector.

00:31:22.350 --> 00:31:24.210
And there's no way to do 8-bit stuff.

00:31:24.310 --> 00:31:26.300
The only thing there is is
16-bit shifts left and right.

00:31:26.410 --> 00:31:30.300
Or you can do 8-bit merges.

00:31:33.090 --> 00:31:34.910
So as I mentioned earlier,
there's a lot of things that

00:31:34.970 --> 00:31:36.460
can't be done with the permute.

00:31:36.520 --> 00:31:42.550
It's sometimes difficult to move data
between the low and high 64-bit segments.

00:31:42.680 --> 00:31:48.390
The minimum permute level is the word,
which is 16-bits on the x86 platform,

00:31:48.390 --> 00:31:49.200
not a byte.

00:31:49.200 --> 00:31:50.840
So if you want to do
something like a byte swap,

00:31:50.840 --> 00:31:55.400
you're going to have to shift left,
shift right, or the results together.

00:31:55.630 --> 00:31:58.830
There is the byteways on the pack.

00:31:58.910 --> 00:32:01.240
But there's no good way to do
data-dependent data movements.

00:32:01.240 --> 00:32:04.640
So if you are writing a matrix
inverse and you need to find a pivot

00:32:04.640 --> 00:32:08.150
element and you want to rotate data
around based on the pivot element,

00:32:08.150 --> 00:32:09.830
you don't know where
it is at compile time,

00:32:09.830 --> 00:32:15.490
you might have to start
out and use a scalar unit.

00:32:18.770 --> 00:32:22.340
As to loads and stores,
the scalar loads and stores

00:32:22.340 --> 00:32:25.940
always load into one end of
the vector in a fixed position,

00:32:26.110 --> 00:32:27.200
which may be welcome.

00:32:27.200 --> 00:32:30.420
It's a little bit of a game to figure
out where your data went on AltaVec if

00:32:30.420 --> 00:32:32.850
you're doing scalar loads and stores.

00:32:32.960 --> 00:32:35.380
And there's a whole series of
instructions that can do that.

00:32:35.380 --> 00:32:38.560
There's move_ss,
move_sd for single and double precision,

00:32:38.560 --> 00:32:40.820
and move_d for integers.

00:32:40.820 --> 00:32:44.620
Move_d will also move
directly to the integer unit,

00:32:44.650 --> 00:32:48.100
so that's kind of handy in some cases.

00:32:48.110 --> 00:32:51.740
So that doesn't really
translate directly very well.

00:32:51.740 --> 00:32:53.960
And then--

00:32:54.220 --> 00:32:58.090
The vector loads and stores on SSC,
they have the align flavor like Altivec.

00:32:58.090 --> 00:32:58.960
It's very fast.

00:32:59.310 --> 00:33:02.000
However, if your pointer is misaligned,
Altivec would just return

00:33:02.000 --> 00:33:03.200
you the aligned vector.

00:33:03.350 --> 00:33:08.880
SSC will return an access exception,
so it's suggested you don't do that.

00:33:08.940 --> 00:33:11.030
As for misaligned loads and stores,
those are handled in hardware.

00:33:11.030 --> 00:33:14.220
There's a separate instruction for those,
which is convenient.

00:33:14.260 --> 00:33:17.640
It's one and a half to two
times slower in many cases.

00:33:17.640 --> 00:33:20.220
But misaligned stores
are particularly costly,

00:33:20.220 --> 00:33:21.430
so I suggest you don't do that.

00:33:21.450 --> 00:33:25.760
You might want to iterate in scalar code
up to the first the line boundary and

00:33:25.860 --> 00:33:28.950
then go forward with vector after that.

00:33:29.540 --> 00:33:32.720
So in summary,
the misaligned access is handled

00:33:32.720 --> 00:33:35.240
almost completely differently.

00:33:35.240 --> 00:33:36.870
It's almost orthogonal to Altivec.

00:33:36.940 --> 00:33:40.320
You can write some Altivec which does
the same thing as SSC but is not a

00:33:40.320 --> 00:33:42.400
particularly fast implementation.

00:33:42.400 --> 00:33:47.330
It's suggested you always align
your stores and be careful

00:33:47.330 --> 00:33:49.400
of those crashing problems.

00:33:49.400 --> 00:33:53.550
And there's one more thing when you
load and store data from memory.

00:33:53.550 --> 00:33:55.400
It's little endian,
so it gets bytes swapped.

00:33:55.400 --> 00:33:58.400
The full 16 bytes,
the entire vector is bytes swapped.

00:33:58.400 --> 00:34:01.940
And the end result of that is that
the elements which should appear on

00:34:01.940 --> 00:34:05.400
the left side of the vector are now
on the right side of the vector.

00:34:05.480 --> 00:34:09.380
So you're going to have to keep that
in mind while you're programming

00:34:09.390 --> 00:34:12.090
because those shift lefts or shift
rights are actually going the

00:34:12.090 --> 00:34:13.400
other way from what you think.

00:34:13.400 --> 00:34:18.990
And so there it is in the graphic.

00:34:19.160 --> 00:34:23.970
Unrolling for performance in
PowerPC you'd frequently do

00:34:24.010 --> 00:34:27.340
several things in parallel to
try to keep the pipelines busy.

00:34:27.340 --> 00:34:31.240
PowerPC is especially deep
pipelines compared to x86.

00:34:31.240 --> 00:34:33.100
So this was often
required for performance.

00:34:33.100 --> 00:34:37.100
It's a bad idea on SSC in many cases.

00:34:37.100 --> 00:34:41.360
There aren't enough registers to hold
that kind of parallelism and everything

00:34:41.380 --> 00:34:47.100
is reordered quite successfully and
quite efficiently in the back end.

00:34:47.100 --> 00:34:50.970
So you're actually better off
with some serially unrolled code

00:34:50.970 --> 00:34:55.070
that just reuses the same small
set of registers over and over.

00:34:55.100 --> 00:34:59.100
That'll save you some
spills out onto the stack.

00:34:59.100 --> 00:35:02.100
And it all gets reordered for parallelism
back in the back of the machine.

00:35:02.100 --> 00:35:04.100
So the machine stays full.

00:35:04.100 --> 00:35:07.100
You just don't have to write this
massive body of parallel code.

00:35:07.100 --> 00:35:10.360
You just write the little loop.

00:35:11.930 --> 00:35:13.890
So other performance tips.

00:35:13.900 --> 00:35:15.900
Overall,
I would suggest you try to reduce

00:35:15.900 --> 00:35:17.490
or eliminate your need for the unit.

00:35:17.600 --> 00:35:20.130
There are many cases where
people go to town with that thing

00:35:20.130 --> 00:35:21.560
and work to create an Altivec.

00:35:21.560 --> 00:35:24.680
It's not going to port very well.

00:35:24.770 --> 00:35:28.440
You may have to change data layouts.

00:35:28.440 --> 00:35:29.690
It's very -- it suggested
you align your data.

00:35:29.700 --> 00:35:34.100
That was always a good idea for Altivec,
but it's a good idea here, too.

00:35:34.130 --> 00:35:37.000
Do not enroll as much for parallelism,
as I mentioned earlier.

00:35:37.000 --> 00:35:40.000
And one other thing -- I mean,
it's often a fun game in Altivec to

00:35:40.000 --> 00:35:44.480
synthesize your constants and code
rather than looking them up from memory.

00:35:44.560 --> 00:35:46.300
It doesn't really get you much here.

00:35:46.300 --> 00:35:48.880
There's no VEX splat to begin with,
so it's hard to make them.

00:35:49.090 --> 00:35:51.650
And then the problem is that
there's eight registers,

00:35:51.690 --> 00:35:54.010
so they'll just spill
out to the stack anyway,

00:35:54.040 --> 00:35:57.230
so you'll have to load them in again.

00:35:57.500 --> 00:36:00.070
So if this is starting to
sound like a bit of work,

00:36:00.070 --> 00:36:03.670
I will encourage you once again
to use the Accelerate framework.

00:36:04.580 --> 00:36:09.520
In summary,
I'll say that the platform that you'll

00:36:09.520 --> 00:36:11.660
be porting to has fewer registers.

00:36:11.660 --> 00:36:15.480
It has a 64-bit ALU in the back end,
so things are moving through in

00:36:15.480 --> 00:36:20.500
successive pipeline stages rather than
one instruction per pipeline stage.

00:36:20.500 --> 00:36:24.390
And the pipelines are a lot shorter,
so you have to enroll a lot less,

00:36:24.390 --> 00:36:28.310
or sometimes not at all,
or preferentially serially in parallel.

00:36:28.500 --> 00:36:32.460
Nearly all the vector instructions
dispatch through a single port,

00:36:32.460 --> 00:36:34.500
except loads and moves and stores.

00:36:34.500 --> 00:36:38.320
So there's not as much advantage
to hand-scheduling stuff,

00:36:38.320 --> 00:36:42.330
so you get permuted against ALU activity,
that kind of thing.

00:36:42.550 --> 00:36:44.500
The Seq program model is there.

00:36:44.500 --> 00:36:46.930
The data types,
you can use Accelerate types

00:36:46.930 --> 00:36:48.500
for both Altivec and SSC.

00:36:48.500 --> 00:36:49.500
They work interchangeably.

00:36:49.500 --> 00:36:54.470
And for intrinsics,
you can include xmm.h to get them.

00:36:54.700 --> 00:36:57.500
And so we found in our case that
some codes are not as good as others.

00:36:57.500 --> 00:36:59.440
In the case that some code
can port over fairly cleanly,

00:36:59.510 --> 00:37:03.390
especially floating point code,
if you're heavily dependent on permute

00:37:03.500 --> 00:37:08.390
or have difficult misalignment problems,
then those could be more of a challenge.

00:37:08.530 --> 00:37:11.860
Remember that the element
order is backwards in register

00:37:11.860 --> 00:37:13.500
from what you're used to.

00:37:13.500 --> 00:37:16.810
And I'll suggest again that you
use the Accelerate framework

00:37:16.840 --> 00:37:18.500
to avoid porting worries.

00:37:20.110 --> 00:37:27.230
So for more information,
you can go to the standard WWDC website.

00:37:27.500 --> 00:37:30.630
And you can also go to
various reference pages.

00:37:30.680 --> 00:37:34.510
Velocity Engine web page currently
doesn't say too much about Intel,

00:37:34.510 --> 00:37:35.780
but it will.

00:37:35.930 --> 00:37:37.890
Intel reference documents are available.

00:37:37.890 --> 00:37:41.030
You can downline the,
what are essentially the equivalents

00:37:41.030 --> 00:37:43.040
of the PIM and PEM from Intel.

00:37:43.040 --> 00:37:44.700
Here's the link to it.

00:37:44.800 --> 00:37:48.130
And the universal binary program
guidelines will get you started.

00:37:48.220 --> 00:37:51.730
And it's a rather long URL,
so we've given you a

00:37:51.730 --> 00:37:54.210
tiny one to go with it.

00:37:57.930 --> 00:38:03.230
And here's some contact slides if
you need to get in touch with us.