WEBVTT

00:00:07.830 --> 00:00:08.460
Well, good afternoon.

00:00:08.460 --> 00:00:09.840
My name is JD Mankovsky.

00:00:09.860 --> 00:00:13.360
I run Apple's
Enterprise Professional Services group

00:00:13.980 --> 00:00:14.630
for the U.S.

00:00:14.640 --> 00:00:18.380
And we're here to talk about advanced
backup architectures for Mac OS X.

00:00:18.380 --> 00:00:21.690
Only two more sessions to go,
and then you're free to go home.

00:00:21.690 --> 00:00:23.050
Isn't that exciting?

00:00:23.060 --> 00:00:28.200
What I wanted to do first is
quickly talk about some backup

00:00:28.200 --> 00:00:32.050
terminologies to make sure everyone
is up to speed on some of those.

00:00:32.060 --> 00:00:37.000
Talk about some basic building blocks
around different backup architectures.

00:00:37.660 --> 00:00:41.660
And then what we'll do is we'll talk
about some advanced backup architectures

00:00:41.660 --> 00:00:48.120
and bring on stage three success stories
of customers like Dark Horse Comics,

00:00:48.120 --> 00:00:52.310
Kansas City, Life Insurance,
and the Simran Group who have been using

00:00:52.310 --> 00:00:57.080
some of the third-party solutions that
are available today that run on Mac OS X.

00:00:57.080 --> 00:01:02.120
And actually server solutions that you
can use to actually back up your data.

00:01:04.190 --> 00:01:07.190
So, you know, some quick backup concepts.

00:01:07.300 --> 00:01:09.850
Fiber channel, you know,
SAN type deployments.

00:01:09.920 --> 00:01:11.610
When I, you know,
when I'm going to talk about

00:01:11.610 --> 00:01:15.700
SAN deployments in this solution,
it's really true clustered

00:01:15.710 --> 00:01:18.610
file system backup solutions.

00:01:18.630 --> 00:01:20.770
SAN means a lot of things
to a lot of people,

00:01:20.780 --> 00:01:22.640
including like, LUN masking.

00:01:22.640 --> 00:01:25.290
And so I just want to make sure
that when we talk about SAN,

00:01:25.330 --> 00:01:28.330
it's really, you know,
a clustered file system like

00:01:28.330 --> 00:01:30.000
an XSAN type deployment.

00:01:30.010 --> 00:01:33.580
NAS, Mark Attached Storage,
disk-to-disks-to-tape.

00:01:33.580 --> 00:01:37.630
We'll spend quite a bit of time on
that because that's definitely where

00:01:37.630 --> 00:01:43.330
most of you are headed in terms of your
backup and to meet your backup windows.

00:01:43.360 --> 00:01:46.320
And disaster recovery,
replication mirroring,

00:01:46.320 --> 00:01:47.660
we saw a great example.

00:01:47.660 --> 00:01:52.280
How many of you were in the large
XServe RAID deployment session?

00:01:52.400 --> 00:01:52.940
A few of you.

00:01:52.940 --> 00:01:56.580
So actually there's some great
third-party products that are available

00:01:56.580 --> 00:01:59.140
now to do this and snapshots as well.

00:02:01.720 --> 00:02:04.910
So first let's talk about some
basic backup architectures

00:02:04.970 --> 00:02:06.700
and review some of those.

00:02:06.800 --> 00:02:12.900
And then we'll finish by some more
advanced deployments around Xsan Backup.

00:02:12.930 --> 00:02:17.740
The first one I wanted to talk about
is just a simple basic backup server.

00:02:17.810 --> 00:02:20.940
And that's something that most
of you probably use today.

00:02:20.940 --> 00:02:23.200
I mean,
how many in this room-- just curious--

00:02:23.200 --> 00:02:28.350
how many of this room actually
backup more than 5 terabytes of data?

00:02:29.260 --> 00:02:31.700
Okay, how about 10?

00:02:32.010 --> 00:02:34.200
How about 20?

00:02:34.370 --> 00:02:37.500
Okay, how about 500 gigs of data?

00:02:37.510 --> 00:02:38.200
Okay.

00:02:38.210 --> 00:02:42.190
How many people backed up their laptop
before they came to the conference?

00:02:42.330 --> 00:02:45.340
Wow, that's impressive.

00:02:45.370 --> 00:02:46.800
That's impressive.

00:02:46.900 --> 00:02:50.500
So this is a really basic concept.

00:02:50.500 --> 00:02:52.230
You've got a bunch of Xserve RAIDs.

00:02:52.270 --> 00:02:53.830
You have your tape backup system.

00:02:53.830 --> 00:02:58.390
And you need to basically backup
the storage onto the tape library.

00:02:58.400 --> 00:03:02.750
That's just regular server-based
backup with the software loaded

00:03:02.750 --> 00:03:04.600
on the Xserve in this case.

00:03:04.600 --> 00:03:09.600
And you've got everything attached
through the fiber channel switch.

00:03:10.950 --> 00:03:13.410
You know, one of the great things about
this is it's really simple

00:03:13.410 --> 00:03:14.570
usually to administrate.

00:03:14.640 --> 00:03:18.480
You know, it's a one-to-one relationship
between the tape device and

00:03:18.480 --> 00:03:20.460
the server and the storage.

00:03:20.480 --> 00:03:23.430
And, you know, it's fine.

00:03:23.480 --> 00:03:27.020
Some of the issues around that is
that from a scalability perspective,

00:03:27.020 --> 00:03:32.050
from an IT management,
it's much more complicated to manage.

00:03:32.450 --> 00:03:35.440
Especially when you have,
when you then grow to more than

00:03:35.440 --> 00:03:39.550
one server and one or two RAIDs,
it becomes quickly unmanageable.

00:03:39.560 --> 00:03:42.380
You know, you have to swap the tapes.

00:03:42.380 --> 00:03:43.550
You have to do a whole bunch of things.

00:03:43.550 --> 00:03:46.510
And it doesn't scale very well.

00:03:47.140 --> 00:03:51.960
What a lot of you are probably
putting together or have today

00:03:51.960 --> 00:03:53.760
is network-based backups.

00:03:53.840 --> 00:03:57.560
And that's through using
backup client agents.

00:03:57.560 --> 00:03:58.880
How many people are in this case?

00:03:58.880 --> 00:04:00.200
Yeah.

00:04:00.200 --> 00:04:05.340
And usually in this case,
we have a backup server in the middle,

00:04:05.340 --> 00:04:07.240
and that's running your software.

00:04:07.240 --> 00:04:09.480
And you load an agent
on the backup client.

00:04:09.480 --> 00:04:13.360
In this case,
we have an Xserve on the left side,

00:04:13.370 --> 00:04:16.920
and we have a Windows PC on
the right side.

00:04:16.920 --> 00:04:20.070
And those have different agents running,
you know,

00:04:20.070 --> 00:04:22.850
they could be running database backups.

00:04:22.910 --> 00:04:25.500
They could be running file data backup.

00:04:25.500 --> 00:04:27.270
It doesn't really matter, even mail.

00:04:27.280 --> 00:04:30.060
The great thing about some
of those solutions is,

00:04:30.060 --> 00:04:33.600
again, they fit very well in a
heterogeneous environment,

00:04:33.600 --> 00:04:36.160
which a lot of our customers are in.

00:04:36.160 --> 00:04:38.240
You know,
they definitely have a mixed environment,

00:04:38.300 --> 00:04:39.140
and that's great.

00:04:39.140 --> 00:04:45.940
It does use your LAN most of the time,
unless you kind of separate that off.

00:04:46.460 --> 00:04:50.190
So it does require some good
networking on the back end.

00:04:50.220 --> 00:04:56.000
I've definitely seen, I've seen customers
who back up their data,

00:04:56.000 --> 00:05:00.050
and they put that on 100BaseT,
and when a problem happens

00:05:00.060 --> 00:05:04.290
and they need to restore,
it takes them 24 hours.

00:05:04.300 --> 00:05:07.100
So just be real careful to make
sure you've got a good pipe,

00:05:07.100 --> 00:05:10.080
good fat pipe on the back end when
you need to restore that data.

00:05:10.080 --> 00:05:11.900
A lot of people do backup.

00:05:11.900 --> 00:05:13.880
They never try to actually do a restore.

00:05:13.880 --> 00:05:15.690
That gets really scary.

00:05:15.880 --> 00:05:17.260
When time comes.

00:05:17.260 --> 00:05:21.340
So, you know, again,
the restores are a lot slower

00:05:21.400 --> 00:05:23.680
when you need to restore it.

00:05:23.820 --> 00:05:29.050
Again, it's much more CPU intensive
on the servers.

00:05:29.060 --> 00:05:31.900
And, again,
it uses more of your LAN bandwidth.

00:05:31.900 --> 00:05:34.870
So people are trying to move
off of that if they can.

00:05:34.880 --> 00:05:38.080
Again, because their backup
windows are getting just,

00:05:38.100 --> 00:05:40.120
you know, shorter and shorter.

00:05:40.120 --> 00:05:46.460
So what most people are headed into is a,
is a disk-to-disk-to-tape

00:05:46.470 --> 00:05:47.530
type architecture.

00:05:47.540 --> 00:05:51.150
And in this case, you see,
we've got a similar

00:05:51.150 --> 00:05:54.380
diagram where we have,
you know, the backup server.

00:05:54.380 --> 00:05:56.080
We've got our backup clients.

00:05:56.080 --> 00:05:58.960
And what we're doing is we're
migrating the user data,

00:05:58.960 --> 00:06:01.280
which is that XSERV rate
at the bottom here.

00:06:01.280 --> 00:06:08.330
And the workflow is basically that the
first stage is you're backing up your

00:06:08.690 --> 00:06:11.790
data over to a second set of disks.

00:06:11.840 --> 00:06:15.220
And the reason why most people
are actually putting this,

00:06:15.290 --> 00:06:17.730
together is just the sheer cost of disks.

00:06:17.920 --> 00:06:21.070
If you look at XSERV rate,
you're talking $2 per gigabyte.

00:06:21.120 --> 00:06:24.450
So it's becoming really affordable
for people to actually deploy

00:06:24.450 --> 00:06:25.740
those disk-to-disk backups.

00:06:25.780 --> 00:06:28.140
And it also improves reliability.

00:06:28.180 --> 00:06:32.360
You know, how many people have had
tapes that have failed?

00:06:32.400 --> 00:06:33.510
Yes.

00:06:33.680 --> 00:06:35.180
We're all in the same boat.

00:06:35.250 --> 00:06:36.220
That definitely happens.

00:06:36.240 --> 00:06:39.400
You know, people forget to rotate tapes
or they don't buy enough tapes

00:06:39.460 --> 00:06:40.260
because they're expensive.

00:06:40.260 --> 00:06:41.730
And they try to cut corners.

00:06:41.780 --> 00:06:45.190
And then when you need to restore,
you get into some problems.

00:06:45.220 --> 00:06:48.780
So in this,
the first case is you back up the disks.

00:06:49.140 --> 00:06:53.070
It gives you,
it allows you to back up very

00:06:53.070 --> 00:06:54.850
quickly because you're talking some,
you know,

00:06:54.880 --> 00:06:56.280
you have some really nice throughputs.

00:06:56.360 --> 00:06:59.810
In the case of XSERV rate,
you're talking, you know, easily,

00:06:59.820 --> 00:07:01.780
you know, 100 megabytes per controller.

00:07:01.780 --> 00:07:02.830
You've got two controllers.

00:07:02.920 --> 00:07:04.970
So you're getting some really
nice throughput on that.

00:07:05.020 --> 00:07:08.970
And then finally,
once you've backed up the disks,

00:07:08.970 --> 00:07:11.180
you can take all the time in the world,
you know,

00:07:11.260 --> 00:07:15.140
to then do your incrementals or do your
full backup over to your tape library.

00:07:15.140 --> 00:07:19.700
And that allows people to really
stay within their five to six,

00:07:19.740 --> 00:07:23.130
five to six hour window
that they usually,

00:07:23.250 --> 00:07:28.720
you know, give us when we need to,
you know, implement a backup strategy.

00:07:31.110 --> 00:07:33.260
So again, it's great, you know,
it's easy.

00:07:33.350 --> 00:07:36.750
The central administration
is much easier in this case.

00:07:36.750 --> 00:07:38.980
And again,
it's a little bit more complex to set up,

00:07:39.040 --> 00:07:42.310
but nowadays it's almost a necessity.

00:07:42.310 --> 00:07:45.850
And we'll talk about some
of the different compliance,

00:07:45.850 --> 00:07:49.640
Sarbanes-Oxley and other issues
that you probably deal with

00:07:49.640 --> 00:07:51.760
on a regular basis nowadays.

00:07:53.060 --> 00:08:14.570
And again, the reliability and the
restore is essential.

00:08:15.410 --> 00:08:15.410
I mean, reliability,
now you have two copies,

00:08:15.410 --> 00:08:15.410
you have a copy on disk,
your restore is much faster.

00:08:15.410 --> 00:08:15.410
You can take those tapes,
you can rotate them,

00:08:15.410 --> 00:08:15.410
you take those tapes, you load them into,
you send them to like

00:08:15.410 --> 00:08:15.410
Iron Mountain or some area to
store them in a safe location.

00:08:15.410 --> 00:08:15.410
And that usually, you know,
is a lot easier.

00:08:15.590 --> 00:08:18.190
will help in terms of a
catastrophic failure if your

00:08:18.200 --> 00:08:20.260
building burns down or something.

00:08:20.260 --> 00:08:24.450
You have a safe location where
those tapes are stored into.

00:08:24.940 --> 00:08:27.780
Then, you know, when you go into,
if you don't want to use

00:08:27.780 --> 00:08:30.060
any of the networking,
you want to go into pure kind of

00:08:30.190 --> 00:08:32.440
fiber channel tape backup solution.

00:08:32.440 --> 00:08:35.640
Now you're talking deploying
a Xsan architecture.

00:08:35.640 --> 00:08:38.570
And in this case,
this is really a direct Xsan

00:08:38.710 --> 00:08:41.500
to tape backup solution.

00:08:41.500 --> 00:08:43.280
That's the first one we'll talk about.

00:08:43.300 --> 00:08:47.320
And again, in this case,
we're back to your backup window and

00:08:47.690 --> 00:08:53.130
making sure that we're not stepping on
the Xsan throughput that you might be

00:08:53.360 --> 00:08:56.990
needing if the workstations are like,
you know,

00:08:57.010 --> 00:08:59.120
Final Cut video editing workstations.

00:08:59.180 --> 00:09:00.990
So again,
you need to be careful that you've

00:09:01.090 --> 00:09:05.160
got the adequate amount of throughput
available from your tape on the

00:09:05.190 --> 00:09:09.860
backend to be able to meet the amount
of storage that you need to backup.

00:09:10.190 --> 00:09:12.940
In this case, we've got eight terabytes.

00:09:12.940 --> 00:09:14.760
We've got two XServe RAIDs.

00:09:14.770 --> 00:09:16.740
There are, you know,
about four terabytes per RAID.

00:09:16.740 --> 00:09:19.000
So you have about eight
terabytes to backup,

00:09:19.000 --> 00:09:20.840
and that's a pretty large window.

00:09:21.100 --> 00:09:26.270
But the advantage, again, here,
is because it's a Xsan environment,

00:09:26.550 --> 00:09:30.020
each of the servers, the Xsan client one,
the two, and the three,

00:09:30.050 --> 00:09:33.180
have the same data mounted on all three.

00:09:33.230 --> 00:09:37.840
So again,
from a backup and restore capability,

00:09:38.120 --> 00:09:40.820
it makes it easy to load
on one of the clients,

00:09:40.870 --> 00:09:42.740
the backup server software.

00:09:42.750 --> 00:09:45.780
You won't have to load any
agents on the other machines,

00:09:45.800 --> 00:09:50.650
and you can pretty much dedicate
one machine to do your backup.

00:09:51.020 --> 00:09:53.100
So again,
this is kind of how the flow is,

00:09:53.100 --> 00:09:57.180
how the data goes from the disks
over to the through-fiber channel,

00:09:57.180 --> 00:10:00.090
pure-fiber channel, and over to tape.

00:10:00.100 --> 00:10:02.820
So again, what's great,
you've got a dedicated server.

00:10:02.820 --> 00:10:06.480
You're not using any of the LAN,
any of your water network

00:10:06.490 --> 00:10:07.980
or your LAN network.

00:10:08.020 --> 00:10:11.950
And again,
it gets a little bit more complex.

00:10:11.960 --> 00:10:17.180
And again, you're really dependent on the
throughput of your tape backup mechanism.

00:10:17.820 --> 00:10:23.200
And you need to look at LTO2, LTO3, AIT,
and really calculate how

00:10:23.200 --> 00:10:25.380
much throughput you can get.

00:10:25.420 --> 00:10:27.590
And you can scale that.

00:10:27.600 --> 00:10:29.540
I mean,
if you've been to our data center,

00:10:29.690 --> 00:10:32.480
how many people here went to
the data center downstairs?

00:10:32.480 --> 00:10:33.980
Okay, pretty much all of you.

00:10:33.980 --> 00:10:39.840
I mean, you saw Exabyte,
they've got different types of hardware.

00:10:39.840 --> 00:10:44.620
And if you look at a Magnum,
it can have up to eight LTO2

00:10:44.620 --> 00:10:47.250
tape mechanisms in there.

00:10:47.360 --> 00:10:51.370
So you could pretty much
sustain almost a terabyte an

00:10:51.370 --> 00:10:53.990
hour with one of those devices.

00:10:54.000 --> 00:10:56.920
And, you know,
if you haven't looked at those, you know,

00:10:56.920 --> 00:10:58.610
people are pretty blown away.

00:10:58.620 --> 00:11:00.970
I mean,
you're talking $25,000 for something

00:11:01.480 --> 00:11:05.730
that has like 140 cartridges and
that can back up up to 30 terabytes.

00:11:05.740 --> 00:11:11.070
So $25,000 for 30 terabytes
is not a bad deal for tape.

00:11:11.080 --> 00:11:14.940
And so you should definitely, you know,
check it out.

00:11:17.720 --> 00:11:21.840
So most people will deploy
Xsan and disk-to-disk,

00:11:21.840 --> 00:11:25.310
and that's really the combination
that I think is the most appealing

00:11:25.710 --> 00:11:26.800
in any type of deployment.

00:11:26.800 --> 00:11:31.940
And you've got your user
data on this volume.

00:11:31.940 --> 00:11:33.460
Again, we've got 8 terabytes here.

00:11:33.460 --> 00:11:36.350
You've got your disk-to-disk backup,
and that allows you to

00:11:36.350 --> 00:11:37.920
backup your incremental.

00:11:37.920 --> 00:11:41.670
So you could have many days,
depending on how much data

00:11:41.680 --> 00:11:43.660
rotates on a daily basis.

00:11:43.660 --> 00:11:46.560
In this case,
we've got 8 terabytes of disk-to-disk.

00:11:46.720 --> 00:11:50.360
So if you have only 10% of your
data changing on a regular basis,

00:11:50.360 --> 00:11:54.090
you could pretty much have almost
8 or 10 days of disk-to-disk

00:11:54.480 --> 00:11:57.330
information stored on that RAID.

00:11:57.340 --> 00:12:04.320
And then once you've done your backup,
you then backup the tape.

00:12:04.380 --> 00:12:07.440
And you can take however
much time you need,

00:12:07.470 --> 00:12:12.710
do your incrementals every day,
and then do your fulls over the weekend.

00:12:12.720 --> 00:12:16.440
So that's kind of the flow
we're looking at in this case.

00:12:18.500 --> 00:12:22.240
So again, it's really easy,
much easier to manage, and again,

00:12:22.240 --> 00:12:23.440
it's much more reliable.

00:12:23.440 --> 00:12:25.800
But again, it gets more complex.

00:12:25.800 --> 00:12:27.560
It adds another level of complexity.

00:12:27.560 --> 00:12:34.490
But it's just great for off-site,
long-term compliance and just

00:12:34.490 --> 00:12:37.020
safekeeping of your data.

00:12:39.620 --> 00:12:43.560
So I wanted to quickly talk about some
of the advanced backup architectures.

00:12:43.610 --> 00:12:47.500
And the first thing,
when we come in as the consulting team,

00:12:47.500 --> 00:12:50.660
and really that's probably one of
the first questions that we ask

00:12:50.660 --> 00:12:54.170
a customer if they deploy a Xsan,
is like, what is your backup strategy?

00:12:54.270 --> 00:12:58.060
Because you can have RAID 5 drives,
you could have hot spares.

00:12:58.110 --> 00:13:00.230
You know what,
if you don't have a tape backup

00:13:00.330 --> 00:13:02.220
or some solution like that,
or a disk-to-disk,

00:13:02.220 --> 00:13:05.160
at least a disk-to-disk type solution,

00:13:05.560 --> 00:13:09.530
There is a huge risk that
something is going to happen and

00:13:09.530 --> 00:13:10.660
your data is going to go away.

00:13:10.680 --> 00:13:14.310
And we're very adamant to make
sure that the customer has

00:13:14.310 --> 00:13:16.520
a backup-type architecture.

00:13:16.540 --> 00:13:22.730
If they don't, on our statement of work,
we'll put, the customer has denied any

00:13:22.750 --> 00:13:23.840
type of backup solution.

00:13:23.840 --> 00:13:27.420
And if they call us a few months
later and the data is gone,

00:13:27.420 --> 00:13:29.230
we can't guarantee that.

00:13:29.240 --> 00:13:31.040
They have to be in charge of that.

00:13:31.890 --> 00:13:36.200
So, you know, when we talk about disaster
recovery plans with a customer,

00:13:36.260 --> 00:13:37.940
those are definitely
questions that we ask.

00:13:37.970 --> 00:13:40.020
You know,
what is your business continuity plan?

00:13:40.020 --> 00:13:42.970
Or what's your, you know,
business process continuity plan?

00:13:42.980 --> 00:13:46.090
You know, BCP or BPCP.

00:13:46.100 --> 00:13:50.550
And then, of course, you know,
we all hear about Sarbanes-Oxley.

00:13:50.560 --> 00:13:53.180
How many people here in this room
have to deal with Sarbanes-Oxley?

00:13:54.680 --> 00:13:58.340
Not as many as I would expect,
and maybe some of you don't know

00:13:58.340 --> 00:14:00.830
that you will have to deal with
Sarbanes-Oxley very shortly.

00:14:00.840 --> 00:14:06.920
There's about 40 laws around the
Sarbanes-Oxley compliancy today.

00:14:06.920 --> 00:14:09.120
There's another 200
that are in the works.

00:14:09.120 --> 00:14:13.760
So you should definitely start looking
at those because it's probably going

00:14:13.800 --> 00:14:18.450
to affect most of you in the room if
you have to deal with enterprise-type

00:14:18.450 --> 00:14:23.770
data that is required to be,
where you're running an enterprise

00:14:23.930 --> 00:14:28.600
and financial-type information,
you will have to comply with those.

00:14:28.600 --> 00:14:30.010
HIPAA is another one.

00:14:30.010 --> 00:14:34.210
The European Data Protection Act is
also something that the

00:14:34.210 --> 00:14:36.540
European guys have to deal with.

00:14:36.660 --> 00:14:43.400
And really it's all about policies
and process management and really

00:14:43.470 --> 00:14:49.380
understanding the process of your
company's process and the data,

00:14:49.380 --> 00:14:51.320
the flow of the data throughout.

00:14:51.340 --> 00:14:53.600
throughout the corporation.

00:14:53.890 --> 00:14:56.670
Interesting enough,
if you look at Gartner report,

00:14:56.690 --> 00:15:01.960
the latest number for storage
management solutions which include that,

00:15:02.110 --> 00:15:06.470
the number was 5.6 billion in 2004,
and it's going to be in

00:15:06.470 --> 00:15:08.540
the 6.3 billion in 2006.

00:15:08.540 --> 00:15:14.030
It's a huge number in terms of just
sheer storage management software

00:15:14.030 --> 00:15:19.910
to be able to be in compliance with
some of those regulatory pressures.

00:15:21.160 --> 00:15:22.820
So, you know, quickly, you know,
bare-metal restore.

00:15:22.820 --> 00:15:24.800
If you haven't heard what
a bare-metal restore is,

00:15:24.840 --> 00:15:27.780
it's really you reload the OS,
and then from there on,

00:15:27.780 --> 00:15:30.740
you have a way to restore the
data that was on that server.

00:15:30.740 --> 00:15:35.390
And just wanted to quickly touch on
that and make sure that people were up

00:15:35.390 --> 00:15:37.450
to par on what a bare-metal restore is.

00:15:37.480 --> 00:15:40.290
Pre-OS recovery, basically.

00:15:40.300 --> 00:15:42.510
Replication and mirroring.

00:15:42.540 --> 00:15:47.020
So, you know, we definitely talk a lot to
customers about replication.

00:15:47.020 --> 00:15:50.790
You know, we hear customers want off-site
disaster recovery-type solutions.

00:15:51.100 --> 00:15:54.740
And really, you know,
it really depends on, you know,

00:15:54.740 --> 00:15:57.530
what kind of transfer do you want?

00:15:57.550 --> 00:16:00.630
What kind of pipe do you have
between the two locations?

00:16:00.640 --> 00:16:06.370
Do you have a huge, you know,
fiber channel, dark fiber-type deployment

00:16:06.790 --> 00:16:10.080
between the two sites,
which would allow you to pretty much do,

00:16:10.240 --> 00:16:11.400
you know, real-time mirroring?

00:16:11.440 --> 00:16:14.770
Or would you have,
are you going to use more of a

00:16:14.770 --> 00:16:20.060
synchronous-type method where you'll
back up your data every other,

00:16:20.060 --> 00:16:24.520
you know, every few hours or every
day or every 12 hours?

00:16:24.600 --> 00:16:28.790
So it's going to really depend on your
bandwidth that's available between the

00:16:28.840 --> 00:16:32.550
different sites that require backup
and your disaster recovery sites.

00:16:32.660 --> 00:16:35.400
And then, of course, you know,
there's file-based replications.

00:16:35.400 --> 00:16:38.070
There's volume-based replications.

00:16:38.170 --> 00:16:40.660
You know,
the snapshotting portion of that,

00:16:40.740 --> 00:16:41.260
of course.

00:16:41.300 --> 00:16:44.100
And if you were at the other session,
you saw that we, you know,

00:16:44.100 --> 00:16:47.160
there's some new technologies
that are coming around mirroring

00:16:47.200 --> 00:16:51.100
and around snapshotting that
are actually in the switch.

00:16:51.210 --> 00:16:52.500
In the fiber channel switch.

00:16:52.600 --> 00:16:56.940
And that's really exciting because
it moves you away from having

00:16:56.950 --> 00:17:01.100
software-based replication,
and it brings it down to the layer three,

00:17:01.100 --> 00:17:03.040
right into the fiber channel switch.

00:17:03.100 --> 00:17:07.100
And that was discussed in the
other session around a Miranti.

00:17:07.100 --> 00:17:10.890
Miranti is a new company that
has this type of replication and

00:17:10.910 --> 00:17:16.900
snapshotting across WANs over fiber
channel and IP and allows you to

00:17:16.960 --> 00:17:20.070
accomplish those kinds of solutions.

00:17:22.860 --> 00:17:26.150
So let's talk about
example of deployments.

00:17:26.160 --> 00:17:27.380
There's a few here.

00:17:27.420 --> 00:17:32.840
This is an example of a deployment
that we would do around either

00:17:33.140 --> 00:17:38.040
network home directories or QTSS,
QuickTime streaming, web serving,

00:17:38.090 --> 00:17:39.140
and file serving.

00:17:39.140 --> 00:17:43.020
So in this case, what you have is this is
a typical Xsan deployment.

00:17:43.060 --> 00:17:44.940
And you've got your DNS, DHCP.

00:17:44.940 --> 00:17:46.960
You've got your LDAP,
or your Active Directory,

00:17:47.050 --> 00:17:48.290
for authentication.

00:17:48.460 --> 00:17:49.770
And those are the two top servers.

00:17:49.830 --> 00:17:52.500
We always have two, again,
for redundancy.

00:17:52.660 --> 00:17:55.010
Then you have your metadata servers.

00:17:55.020 --> 00:17:56.350
And those are running Xsan.

00:17:56.360 --> 00:18:01.800
And this is what manages the file
locking on the metadata servers.

00:18:01.870 --> 00:18:03.280
And you've got a failover server.

00:18:03.280 --> 00:18:05.420
And you notice on the
failover metadata server,

00:18:05.420 --> 00:18:07.160
I've got two red disks.

00:18:07.170 --> 00:18:10.120
And what we did here is,
because the XServe has some

00:18:10.210 --> 00:18:14.100
pretty nice 400 gig drives,
you've got about 800 gigabytes

00:18:14.100 --> 00:18:16.010
available for disk-to-disk.

00:18:16.180 --> 00:18:22.150
And so what we're doing is we're doing
disk-to-disk on that second XServe.

00:18:22.590 --> 00:18:26.120
And we're going to do the math in
terms of the amount of space we have

00:18:26.150 --> 00:18:28.320
on those RAIDs at the bottom here.

00:18:28.320 --> 00:18:31.980
You're probably at six
or seven terabytes.

00:18:31.980 --> 00:18:35.780
So if you think that-- in this case,
this customer,

00:18:35.780 --> 00:18:38.730
they had only about 10% of their
data that changes on a daily basis.

00:18:38.740 --> 00:18:42.680
So that gives us the opportunity
to do disk-to-disk during the day,

00:18:42.680 --> 00:18:45.790
and then at night,
do the incremental over

00:18:45.790 --> 00:18:48.320
to the tape backup system.

00:18:48.360 --> 00:18:50.790
So typical type Xsan
deployment with disk-to-disk.

00:18:50.900 --> 00:18:51.860
So that's the first thing.

00:18:53.590 --> 00:18:55.090
This is another example.

00:18:55.090 --> 00:18:57.490
And in this case, this is a CNN.

00:18:57.490 --> 00:18:59.320
This is actually CNN in Washington, D.C.

00:18:59.320 --> 00:19:03.190
It took us about two weeks
to do this deployment.

00:19:03.200 --> 00:19:06.300
But you've got about 18 Xserves.

00:19:06.300 --> 00:19:08.430
You've got a whole bunch of Power Macs.

00:19:08.450 --> 00:19:11.540
And you've got a full Xsan
deployment with like two Qlogic.

00:19:11.540 --> 00:19:14.980
We didn't put both of those
switches on the slide here.

00:19:14.980 --> 00:19:18.780
In this case, the customer really wanted,
they didn't want any tape.

00:19:18.880 --> 00:19:23.420
So what we did is we built two
12-terabyte RAID deployments,

00:19:23.420 --> 00:19:28.670
Xserve RAID deployments,
and we're replicating the data

00:19:28.680 --> 00:19:35.800
on a daily basis between the two
Xsan volumes over fiber channel.

00:19:36.960 --> 00:19:41.140
So just two examples of
different ways and different

00:19:41.140 --> 00:19:43.870
architectures to backup your data.

00:19:44.090 --> 00:19:48.390
So what I wanted to do now is
kind of switch over to some of the

00:19:48.400 --> 00:19:52.180
customer success stories that we've
had around some of the third-party

00:19:52.200 --> 00:19:56.670
solutions that you might have
seen in the data center around,

00:19:56.740 --> 00:20:01.050
you know, a tempo, you know, backbone,
and retrospect.

00:20:01.150 --> 00:20:06.050
And the first person that
I wanted to invite is Chris Irvine

00:20:06.070 --> 00:20:08.300
from Dark Horse Comics.

00:20:08.350 --> 00:20:10.810
Chris?

00:21:09.900 --> 00:21:12.800
We've missed the opportunity to
do some high def with QuickTime 7.

00:21:12.800 --> 00:21:14.950
We've been having a lot of fun with that.

00:21:15.500 --> 00:21:21.740
That shows you a little bit of the titles
that we're using with Dark Horse Comics.

00:21:21.740 --> 00:21:25.590
Mike Richardson actually
formed Dark Horse in 1986.

00:21:25.590 --> 00:21:28.840
He had been running comic book
shops and decided he could

00:21:28.990 --> 00:21:31.430
compete with the big players,
DC and Marvel,

00:21:31.430 --> 00:21:34.660
and started his own publication company.

00:21:34.660 --> 00:21:37.570
We've been able to attract a lot
of top talent for publications

00:21:37.580 --> 00:21:42.950
and then we've also done a lot of
licensed comic book properties.

00:21:42.970 --> 00:21:47.030
We're the biggest licensed
publisher of comic materials.

00:21:47.120 --> 00:21:50.800
We do like Star Wars, Buffy,
and recently The Incredibles,

00:21:50.800 --> 00:21:53.200
so we get to do a lot
of those fun projects.

00:21:53.340 --> 00:21:57.530
We also have a company we started
in '92 that our department supports

00:21:57.530 --> 00:22:00.500
at Star Horse Entertainment.

00:22:00.690 --> 00:22:04.760
And so we are,
that company's producing movies

00:22:05.300 --> 00:22:06.260
Let's see, what do we have?

00:22:06.270 --> 00:22:08.260
We started out with the
mask with Jim Carrey,

00:22:08.270 --> 00:22:09.440
which was a big hit.

00:22:09.440 --> 00:22:12.800
And then also recently
we worked on Hellboy,

00:22:12.800 --> 00:22:14.860
which has worked out really well for us.

00:22:14.860 --> 00:22:17.210
And then the comic book
shops that Mike started with

00:22:17.220 --> 00:22:18.760
are still doing quite well.

00:22:18.760 --> 00:22:20.800
They've expanded into pop culture stuff.

00:22:20.810 --> 00:22:23.500
So we have actually retail
stores in Oregon and California.

00:22:23.540 --> 00:22:25.920
And we actually have one right
in town across the street,

00:22:25.920 --> 00:22:26.880
so check that out.

00:22:28.040 --> 00:22:30.470
As far as how we're
doing IT at Dark Horse,

00:22:30.470 --> 00:22:32.900
it's fairly typical structure here.

00:22:32.900 --> 00:22:37.400
I'm just going to skip over some
of this so we can save some time.

00:22:37.600 --> 00:22:39.930
We have about 80% of our
servers are running OS X,

00:22:39.940 --> 00:22:43.070
and then we have a mix of Windows,
Solaris, OpenBSD,

00:22:43.070 --> 00:22:45.600
so we have some heterogeneous
server requirements.

00:22:45.620 --> 00:22:48.590
Lucky for us,
most of our desktops are running OS X,

00:22:48.600 --> 00:22:52.600
so about 95% of our users
have OS X workstations.

00:22:52.600 --> 00:22:54.920
And then one of the other
things we're doing is we're

00:22:54.930 --> 00:22:56.600
using remote home directories.

00:22:56.600 --> 00:22:59.110
As far as backup goes,
that's great for us because we

00:22:59.110 --> 00:23:02.740
can centralize all the data on
the server and gives us a central

00:23:02.740 --> 00:23:06.970
point of backup for all of our,
at least for our desktop machines.

00:23:07.480 --> 00:23:10.600
And then one of the other things
we love is Netboot and things

00:23:10.600 --> 00:23:11.720
like the Disk Image Framework.

00:23:11.720 --> 00:23:16.580
So getting those machines back up
sort of the bare metal situation at

00:23:16.580 --> 00:23:19.820
the desktops is pretty easy because
it just takes us a few minutes to

00:23:19.890 --> 00:23:23.680
get Netbooted and our image restored
and users can be back online.

00:23:23.680 --> 00:23:27.090
As long as we have redundant storage
behind those home directories

00:23:27.100 --> 00:23:32.480
and those critical servers,
uptime is actually quite good on that.

00:23:33.950 --> 00:23:37.570
As far as the data that we're
backing up on a regular basis,

00:23:37.640 --> 00:23:43.030
we've got about one terabyte of data
that we backup on a regular basis.

00:23:43.040 --> 00:23:45.300
That would be our key
production and media files.

00:23:45.340 --> 00:23:50.240
We've got about four terabytes of
archives that we've run over the last,

00:23:50.240 --> 00:23:53.580
you know, digital publications we've
done over the last 13 years.

00:23:53.580 --> 00:23:57.330
And then we've got about another
terabyte for all the other supporting

00:23:57.330 --> 00:24:00.220
data for just operating a business,
so your marketing

00:24:00.220 --> 00:24:02.740
operations and accounting,
all that sort of thing.

00:24:03.940 --> 00:24:06.300
I already mentioned that our user
data is centralized on the server,

00:24:06.300 --> 00:24:09.060
so we don't have any user data
that we have to worry about backing

00:24:09.060 --> 00:24:10.760
up on the end-user workstations.

00:24:10.760 --> 00:24:13.440
And we do have a little bit
to deal with on laptops,

00:24:13.440 --> 00:24:17.480
but we're looking forward to moving those
to Tiger with portable home directories.

00:24:21.070 --> 00:24:23.240
As far as the data that moves
around inside of our company,

00:24:23.240 --> 00:24:26.480
our core business is publishing.

00:24:26.480 --> 00:24:31.220
Data comes into the pipeline,
that's often scanned or FTP.

00:24:31.220 --> 00:24:34.270
During the production process,
there's hundreds of phases probably,

00:24:34.270 --> 00:24:37.540
but those might be like color
corrections and proofing.

00:24:37.540 --> 00:24:40.940
And then the final product comes out,
usually as a PDF,

00:24:41.040 --> 00:24:47.000
often that's FTPed straight to the
printer where it's ready to be printed.

00:24:47.000 --> 00:24:50.400
And all that data for us,
we've made a decision that we want to

00:24:50.400 --> 00:24:56.440
retain nightly backups of that production
pipeline for at least 12 weeks.

00:24:56.440 --> 00:24:59.990
Also important to us and anybody else
who does publications is archiving.

00:25:00.000 --> 00:25:03.860
You know, a good chunk of our revenue
comes from reprinting material or

00:25:03.910 --> 00:25:06.600
licensing it to be printed overseas.

00:25:06.600 --> 00:25:11.100
So whenever a publication is shipped,
the data is all collected and archived.

00:25:11.100 --> 00:25:14.240
Over the years, you know, way back,
people started just throwing that

00:25:14.260 --> 00:25:16.820
stuff onto a DAT or a DLT or whatever.

00:25:16.920 --> 00:25:22.320
It's grown into things like DVD carousels
and things like that more recently.

00:25:22.320 --> 00:25:25.790
And then even though we've got a
library of information that production

00:25:25.790 --> 00:25:31.550
users are backing up archiving,
the IT department also takes on the

00:25:31.550 --> 00:25:37.950
responsibility of running extra media
and platform diverse copies of those

00:25:38.380 --> 00:25:42.270
publications that we can vault and,
you know, safeguard

00:25:42.300 --> 00:25:55.800
[Transcript missing]

00:25:56.690 --> 00:25:59.330
So towards the end of last year,
we sort of recognized a

00:25:59.330 --> 00:26:01.930
lot of deficiencies in the
way we were doing backups.

00:26:02.020 --> 00:26:07.380
One of the big things for us
was just the risk of downtime.

00:26:07.380 --> 00:26:10.960
We were looking at our platform
and how long it would take us

00:26:10.960 --> 00:26:15.840
to restore our critical data in
some sort of worst-case scenario.

00:26:15.840 --> 00:26:19.860
Heaven forbid an Xserve RAID ever
ends up with corrupted data on it,

00:26:19.990 --> 00:26:22.950
but you have to look at
situations of how long would it

00:26:23.270 --> 00:26:26.610
take me to get that back online,
and that's actually probably

00:26:26.890 --> 00:26:30.620
our strongest argument to pitch
the project of making changes.

00:26:30.620 --> 00:26:33.430
It was just sort of,
can we live with being down for

00:26:33.430 --> 00:26:35.450
X number of hours sort of thing.

00:26:37.200 --> 00:26:40.340
Also, we were faced with media that had
really hit the end of the line.

00:26:40.340 --> 00:26:43.180
We were using Mammoth 2,
and there is no Mammoth 3,

00:26:43.180 --> 00:26:47.370
so we were looking at
changing directions there.

00:26:47.380 --> 00:26:50.210
Just like our restores
were taking a long time,

00:26:50.280 --> 00:26:52.990
our backups also were taking a long time.

00:26:53.000 --> 00:26:55.780
We had to split those
across multiple days,

00:26:55.950 --> 00:26:59.620
multiple weekends in order to
fit into our backup window.

00:27:00.430 --> 00:27:04.450
We were really facing a major
administrative overhead.

00:27:04.450 --> 00:27:07.260
In order to accomplish the
requirements that we had,

00:27:07.260 --> 00:27:10.700
we had set up like 20
different tape pools,

00:27:10.700 --> 00:27:15.340
and we were pretty much manually
tracking hundreds of pieces of media.

00:27:15.340 --> 00:27:18.200
So we wanted to do that in
a more efficient manner.

00:27:18.200 --> 00:27:22.120
And then those archives that we
looked at weren't very uniform

00:27:22.120 --> 00:27:25.960
and had a lot of problems,
so we wanted to fix those problems too.

00:27:25.960 --> 00:27:30.160
We started out by comparing our
media options that were out there.

00:27:30.180 --> 00:27:31.680
We were using Mammoth 2.

00:27:31.680 --> 00:27:35.520
It was costing us about a dollar and
a half per gigabyte for tape media.

00:27:35.520 --> 00:27:38.110
And there was obviously
a speed problem there.

00:27:38.120 --> 00:27:42.440
So we started out by just comparing
the platforms that were available.

00:27:42.440 --> 00:27:44.720
These numbers were from late last year.

00:27:44.720 --> 00:27:49.500
The big players, Quantum, LTO, and Sony,
all have very competitive

00:27:49.600 --> 00:27:51.830
media in the market right now.

00:27:51.840 --> 00:27:55.300
Those are pennies per gigabyte,
which is great.

00:27:55.300 --> 00:27:58.260
One thing that stood out to
us there was the throughput of

00:27:58.320 --> 00:28:00.160
Ultrium 2 was a notch better.

00:28:00.160 --> 00:28:02.780
And so that was attractive to us.

00:28:02.780 --> 00:28:06.630
And I should mention that all
these vendors have started shipping

00:28:06.630 --> 00:28:10.530
their next generation equipment
that's going to hold twice as much,

00:28:10.530 --> 00:28:11.500
run twice as fast.

00:28:11.680 --> 00:28:15.680
As soon as the volume of those
shipping units starts to go up,

00:28:15.680 --> 00:28:19.470
we'll see the cost per gigabyte of those
becoming just as competitive as this.

00:28:19.680 --> 00:28:22.670
And then we also wanted
to keep disk in mind.

00:28:22.680 --> 00:28:27.600
Apple XRV RAID has become very
competitive in the storage market.

00:28:27.680 --> 00:28:29.680
I don't work for Apple,
so my number is a lot more competitive.

00:28:30.290 --> 00:28:35.610
But we looked at the actual usable
redundant space on a RAID and

00:28:35.620 --> 00:28:40.220
saw that around $3 a gigabyte,
which is actually quite good.

00:28:40.260 --> 00:28:46.260
And we're easily seeing benchmarks 63 or
higher depending on your attached host,

00:28:46.340 --> 00:28:49.180
just even from one side of an XRV RAID.

00:28:49.260 --> 00:28:51.260
Ultimately, we went with the Ultrium 2.

00:28:51.260 --> 00:28:56.810
And we did that with Overland
Storage Power Loader.

00:28:59.400 --> 00:29:03.230
When we looked at our archive system,
we really wanted to solve

00:29:03.250 --> 00:29:06.890
this problem with the DATs and
DLTs and DVDs and everything

00:29:06.990 --> 00:29:09.460
coming from different directions.

00:29:09.460 --> 00:29:13.070
And we looked at HSM products
and nearline products and really

00:29:13.440 --> 00:29:18.180
for the size of our organization,
cost performance wasn't adding up.

00:29:18.180 --> 00:29:21.340
So we went back and looked at disk again
and that's what we ended up going with.

00:29:21.340 --> 00:29:24.120
We've decided to just do
all of our archives online.

00:29:24.120 --> 00:29:28.520
We're going to restore all of our
old tapes and quit messing with that.

00:29:28.540 --> 00:29:31.250
And so when we run our archives,
we'll just move data from

00:29:31.620 --> 00:29:35.360
the production systems onto
these archive storage volumes,

00:29:35.550 --> 00:29:38.160
lock them,
and then run off archival copies that

00:29:38.160 --> 00:29:40.260
we can protect in case of a disaster.

00:29:44.000 --> 00:29:48.040
Looking at the software,
we wanted to make sure we were using

00:29:48.130 --> 00:29:50.070
the best software as we moved forward.

00:29:50.080 --> 00:29:54.480
The big priorities for us,
one of those was scalability.

00:29:54.480 --> 00:29:57.440
We obviously wanted software
that could handle multiple jobs,

00:29:57.500 --> 00:30:01.130
multiple administrators,
multiple tape drives.

00:30:01.200 --> 00:30:04.450
We sort of saw those as things
that we really had to have.

00:30:04.480 --> 00:30:06.640
Price is a factor.

00:30:06.640 --> 00:30:09.330
I don't look at any project
really without making sure

00:30:09.550 --> 00:30:11.460
it's competitive in the market.

00:30:13.230 --> 00:30:16.040
A big thing for us was Macintosh
Enterprise support because

00:30:16.130 --> 00:30:17.860
we're so heavily running OS X.

00:30:17.860 --> 00:30:23.380
We wanted a company that was going to be
100% both behind Macintosh clients and

00:30:23.380 --> 00:30:26.660
Macintosh servers for the backup end.

00:30:26.660 --> 00:30:29.230
And we wanted a company that would
be responsive to us when we say,

00:30:29.260 --> 00:30:31.780
"Well,
we've got this problem or whatever." And,

00:30:31.780 --> 00:30:35.940
yeah, we're running OS X and they should
respond that that's no problem too.

00:30:35.940 --> 00:30:37.730
It's a great Unix platform.

00:30:37.740 --> 00:30:39.520
And performance should be good.

00:30:39.520 --> 00:30:42.850
We don't want to consume any more
resources than we need to on our,

00:30:43.030 --> 00:30:46.380
especially our backup clients when
we're running a backup or restore.

00:30:46.380 --> 00:30:49.610
When we compared all these and
a few other issues as well,

00:30:49.610 --> 00:30:54.480
we ended up going with the
NetVault software from Backbone.

00:30:54.530 --> 00:30:57.020
And it met all these quite well.

00:30:57.020 --> 00:31:01.430
As far as the way we've deployed, we've

00:31:01.740 --> 00:31:04.560
The NetVault software,
we're using a single backup server and

00:31:04.600 --> 00:31:09.770
sort of that network backups server
configuration like JD talked about,

00:31:09.800 --> 00:31:13.840
where we have the server sitting
between the tape mechanism and the LAN.

00:31:13.840 --> 00:31:18.700
At the moment,
that machine's actually just a dual 800,

00:31:18.720 --> 00:31:21.690
which is enough to... Whoops.

00:31:22.070 --> 00:31:24.050
Thank you for joining us.

00:31:24.150 --> 00:31:28.510
We're going to talk about
our back-up architecture,

00:31:28.510 --> 00:31:31.230
which is the core of our system.

00:31:31.230 --> 00:31:34.580
We're going to start with a full backup.

00:31:34.720 --> 00:31:38.690
The full backup is a backup
to the Mac OS Xserver.

00:31:38.690 --> 00:31:44.420
We're going to run it every six months
for auditing and then our full and

00:31:44.420 --> 00:31:47.980
incremental backups are the core.

00:31:47.980 --> 00:31:49.660
The fulls are running every two
weeks on the weekends and then

00:31:49.770 --> 00:31:51.830
incremental backups are running
every three weeks on the weekends.

00:31:51.900 --> 00:32:00.450
The full backups are running every
two weeks on the weekends and then

00:32:00.450 --> 00:32:09.320
incremental backups are running
every three weeks on the weekends.

00:32:09.760 --> 00:32:11.940
Performance we've been
really pleased with.

00:32:11.940 --> 00:32:15.670
This is an example of one of our clients.

00:32:15.700 --> 00:32:20.010
This is a 1.4 and we're backing up
about a terabyte during the night.

00:32:20.040 --> 00:32:26.540
It's pretty easily saturating the Ultram
drive at around 36 megabytes a second.

00:32:26.540 --> 00:32:31.680
And we were pretty happy with
the load average sitting at about

00:32:31.820 --> 00:32:33.760
.6 through the entire operation.

00:32:33.760 --> 00:32:38.860
And at that sort of throughput,
we felt like that was a pretty good fit.

00:32:40.390 --> 00:32:45.350
So just to wrap up really quick,
the problems we looked at, the downtime,

00:32:45.540 --> 00:32:50.090
the media that we hit end of life,
all those issues.

00:32:50.310 --> 00:32:53.310
The changing the media platform,
moving to Ultrium 2 really helped

00:32:53.320 --> 00:32:57.400
us to break through the barriers
with the throughput problems and

00:32:57.400 --> 00:33:00.590
helped us to have the ability to cut
down our backup and restore times.

00:33:00.680 --> 00:33:05.570
Moving to Xserve RAIDs gave us the
option to sort of re-approach how we do

00:33:05.570 --> 00:33:08.510
archives by just storing data online.

00:33:08.520 --> 00:33:13.170
And then using NetVault,
we can sort of manage all this

00:33:13.420 --> 00:33:19.530
stuff and manage how our media is
handled and the jobs as they run.

00:33:20.110 --> 00:33:22.040
And we're really happy
with how this is going.

00:33:22.040 --> 00:33:25.420
So far, our estimation is we're probably
going to cut the administration

00:33:25.460 --> 00:33:28.670
time that we were spending in
managing our backups about in half.

00:33:30.290 --> 00:33:34.880
So just to close, we're happy to be here.

00:33:34.880 --> 00:33:40.040
And I've been able to actually offer you
guys a 20% discount if you're interested.

00:33:40.040 --> 00:33:42.420
Right across the street on the
second floor of the Metreon,

00:33:42.420 --> 00:33:45.380
if you just show your badge at our
Things from Another World store,

00:33:45.380 --> 00:33:46.980
we'll hook you up.

00:33:46.980 --> 00:33:48.500
Thanks.

00:33:54.800 --> 00:33:58.500
So I'd like to invite John Welsh from
Kansas City Life Insurance.

00:33:59.080 --> 00:34:00.490
John?

00:34:01.990 --> 00:34:06.250
Okay, so my name is John Welch.

00:34:06.400 --> 00:34:07.840
I work for Kansas City Life Insurance.

00:34:07.840 --> 00:34:12.070
I'm probably best described as, well,
my semi-official title is Unix

00:34:12.140 --> 00:34:14.100
slash Open Systems Administrator.

00:34:14.100 --> 00:34:17.170
That really translates out to
I don't work on mainframes and

00:34:17.180 --> 00:34:18.830
I do stuff besides Windows.

00:34:20.960 --> 00:34:23.930
We're a publicly traded
financial services company based,

00:34:23.930 --> 00:34:26.680
obviously, Kansas City, Missouri,
not Kansas.

00:34:26.680 --> 00:34:29.840
We've been in business for 110 years.

00:34:29.840 --> 00:34:34.380
We've been run by the
same family for 110 years.

00:34:34.380 --> 00:34:36.880
4.6 billion in assets, you can read that.

00:34:36.910 --> 00:34:40.680
We've got 600 employees,
about 800 computers.

00:34:40.740 --> 00:34:43.550
20 of those are Macs,
the rest are Windows.

00:34:43.620 --> 00:34:47.450
This is probably pretty typical
of a financial services group.

00:34:47.510 --> 00:34:50.290
Insurance is a Windows world still.

00:34:50.300 --> 00:34:50.940
I'm trying to get that right.

00:34:50.960 --> 00:34:53.310
I'm trying,
but luckily one of those Macs sits

00:34:53.370 --> 00:34:56.660
in a corner office run by one of
the brothers who runs the company,

00:34:56.660 --> 00:34:58.110
so that's kind of handy.

00:34:58.120 --> 00:35:02.010
In our case, data preservation is not
only a business decision,

00:35:02.010 --> 00:35:03.590
but it's mandated by law.

00:35:03.690 --> 00:35:05.060
HIPAA, GLB, SOX.

00:35:05.060 --> 00:35:09.020
I think probably if there's a
government regulation that affects

00:35:09.020 --> 00:35:12.800
data preservation or data handling,
we get it three ways.

00:35:12.800 --> 00:35:13.890
We live with auditors.

00:35:13.890 --> 00:35:15.830
I think we should just give them offices.

00:35:15.940 --> 00:35:18.260
It's not quite as bad
as the guys from Japan,

00:35:18.270 --> 00:35:20.920
but honestly,
I would not want to be the guy.

00:35:20.960 --> 00:35:23.430
I would want to be the guy who
would put a company that's been in

00:35:23.430 --> 00:35:27.590
business across three centuries out of
business because I messed up a backup.

00:35:28.210 --> 00:35:31.720
We traditionally, like a lot of people,
only backed up our servers.

00:35:31.750 --> 00:35:34.130
This was pretty much how it worked.

00:35:34.200 --> 00:35:36.680
The Windows servers were
backed up automatically.

00:35:36.730 --> 00:35:40.220
Everybody else, whether they ran Macs,
even my Xserve,

00:35:40.230 --> 00:35:43.880
or if they ran Windows workstations,
you just dragged that

00:35:43.880 --> 00:35:45.690
stuff up to the network.

00:35:45.700 --> 00:35:49.760
The Windows people had their
U drive or whatever drive it was.

00:35:49.920 --> 00:35:53.490
The Macs had, we have a share called
literally Mac Share.

00:35:53.700 --> 00:35:56.410
More recently, they have their home
directories also mounted,

00:35:56.410 --> 00:35:57.850
but you got to do it on your own.

00:35:58.800 --> 00:36:00.390
Yeah.

00:36:00.580 --> 00:36:02.610
The problem is backup really
isn't just for servers anymore.

00:36:02.750 --> 00:36:05.900
I mean, you know, clients at this point,
we call them anything

00:36:05.900 --> 00:36:06.990
not in a server room.

00:36:07.000 --> 00:36:10.220
This includes everything from
the security desk up to the

00:36:10.280 --> 00:36:11.980
president of the company.

00:36:12.110 --> 00:36:14.230
Now,
we use a Windows-based product to backup

00:36:14.230 --> 00:36:16.380
our Windows servers to AIT2 jukeboxes.

00:36:16.530 --> 00:36:20.140
And again, as I said,
the clients are all backed up manually.

00:36:20.140 --> 00:36:21.290
Fairly common.

00:36:21.870 --> 00:36:23.700
There's problems with this.

00:36:23.740 --> 00:36:26.390
I mean, there's one thing you want to say
when a crash happens and someone says,

00:36:26.420 --> 00:36:28.870
"Well, I hadn't dragged a bunch of stuff
over to the network." You want to say,

00:36:28.870 --> 00:36:33.160
"Well, that'll learn you." However,
when the person who crashed

00:36:33.220 --> 00:36:35.700
is in a corner office,
up on a high floor with

00:36:35.700 --> 00:36:38.340
a real pretty view,
and they have certain last names,

00:36:38.340 --> 00:36:39.680
you're not going to do this.

00:36:40.010 --> 00:36:41.290
That's not an option.

00:36:41.460 --> 00:36:46.370
And we had a couple of high-profile
crashes that showed there's a

00:36:46.370 --> 00:36:46.370
weakness in this philosophy.

00:36:46.550 --> 00:36:49.780
And when it came to the Macs,
although our backup system is excellent,

00:36:49.780 --> 00:36:51.120
it's really great for Windows.

00:36:51.120 --> 00:36:52.530
The Mac client has some issues.

00:36:52.550 --> 00:36:54.630
For one thing, security.

00:36:54.640 --> 00:36:59.780
It required an admin-level password and
an unencrypted text file and slash Etsy.

00:36:59.780 --> 00:37:00.920
No.

00:37:00.920 --> 00:37:03.150
As soon as I realized that,
the answer was no.

00:37:03.150 --> 00:37:06.290
I did some speed tests anyways,
but it was still going to be no.

00:37:06.860 --> 00:37:09.060
The client pulls a server.

00:37:09.090 --> 00:37:10.490
In a desktop situation, great.

00:37:10.580 --> 00:37:11.410
We have laptops.

00:37:11.490 --> 00:37:14.470
You know, I don't want my client sitting
out there in an airport on an

00:37:14.470 --> 00:37:17.350
unsecured wireless network going,
can you back me up?

00:37:17.370 --> 00:37:18.200
Can you back me up?

00:37:18.340 --> 00:37:20.020
Because eventually someone's going to go,
sure.

00:37:20.110 --> 00:37:21.650
I can do that.

00:37:21.650 --> 00:37:22.800
Thanks.

00:37:22.800 --> 00:37:24.990
And honestly, speed,
we couldn't even saturate

00:37:25.150 --> 00:37:29.600
802.11b connection,
much less 100 meg Ethernet, 802.11g,

00:37:29.600 --> 00:37:31.190
anything with any kind of speed.

00:37:31.190 --> 00:37:33.400
It just was not going
to happen with this.

00:37:35.470 --> 00:37:37.560
Backup window is an issue.

00:37:37.590 --> 00:37:40.100
Even just our Windows servers,
our backup window,

00:37:40.100 --> 00:37:42.270
we're shaving that real close.

00:37:42.590 --> 00:37:44.280
Restores, we dread them.

00:37:44.640 --> 00:37:49.000
The only thing that saves us is
99% of our people are in the office

00:37:49.000 --> 00:37:52.400
from exactly 8 in the morning
until exactly 4:15 at night.

00:37:52.400 --> 00:37:54.390
We can predict that really well.

00:37:54.390 --> 00:37:55.380
We have bells.

00:37:55.380 --> 00:37:58.390
Again, 110-year-old company.

00:37:58.500 --> 00:38:02.570
If we start adding in these really slow
Macs because the Windows client for

00:38:02.650 --> 00:38:06.400
this product didn't speed along nicely,
it just blows it up.

00:38:06.400 --> 00:38:07.400
I mean, we tried it.

00:38:07.400 --> 00:38:09.330
There was just no way
it was going to happen.

00:38:09.400 --> 00:38:13.520
The Windows backup guy said,
"No way," once he looked at the speed.

00:38:13.530 --> 00:38:15.140
And we tried everything.

00:38:15.140 --> 00:38:17.400
We just could not get that speed up.

00:38:17.410 --> 00:38:21.840
We also realized that we wanted to start
backing up PC laptops because we didn't

00:38:22.010 --> 00:38:26.230
want to just do a redirecting of my
documents to the network because then

00:38:26.230 --> 00:38:28.790
if they're off the network for a while,
their virus definitions

00:38:28.790 --> 00:38:30.390
don't get updated on time.

00:38:30.390 --> 00:38:31.400
These are Windows boxes.

00:38:31.400 --> 00:38:35.270
You know, we didn't want to backup
viruses to our backup server.

00:38:35.610 --> 00:38:39.400
That could be, I believe the technical
term would be bad.

00:38:40.210 --> 00:38:42.850
So we had to go with a separate
system with its own server

00:38:42.850 --> 00:38:44.010
and its own tape drives.

00:38:44.100 --> 00:38:46.130
And there was also a philosophical issue.

00:38:46.210 --> 00:38:50.060
I kind of get off the bus with the
people who say client data doesn't count.

00:38:50.060 --> 00:38:52.510
It does because all our
data is created by clients.

00:38:52.510 --> 00:38:55.420
And it's not always backed up, you know,
reliably or sometimes

00:38:55.420 --> 00:38:57.150
they're offline for a while.

00:38:57.160 --> 00:39:01.070
And I don't really like punishing people
because they're not running on a server,

00:39:01.070 --> 00:39:02.430
they're running on a laptop.

00:39:02.430 --> 00:39:06.530
And that's kind of what I view that
whole server-only backup thing as.

00:39:07.630 --> 00:39:10.760
So this is going to be
the new toy in town.

00:39:10.780 --> 00:39:13.480
It's got to have solid
Mac and Windows support,

00:39:13.480 --> 00:39:14.300
obviously.

00:39:14.310 --> 00:39:16.740
It's got to have good support
for laptop and mobile backups

00:39:16.800 --> 00:39:19.190
because along with the Macs,
its primary reason for being

00:39:19.190 --> 00:39:20.600
here is to backup our laptops.

00:39:20.680 --> 00:39:23.600
It's got to be reasonably secure.

00:39:23.600 --> 00:39:26.310
Now, reasonably secure means
not plain text files.

00:39:26.350 --> 00:39:29.500
It doesn't have to be kerberized
with six layers of encryption.

00:39:29.500 --> 00:39:34.300
It just has to be hard for the
script kiddies to get into.

00:39:35.160 --> 00:39:38.370
It has to be able to run well on an
XServe without needing a SCSI card that

00:39:38.390 --> 00:39:40.110
we didn't have the slot for anyways.

00:39:40.110 --> 00:39:42.710
It's got to be pretty
much fire and forget.

00:39:42.710 --> 00:39:44.600
I do not like writing servers.

00:39:44.600 --> 00:39:47.940
You know, the perfect server is
the one I forget I have.

00:39:47.940 --> 00:39:52.400
It's got to be pretty much zero effort
for restore and very little effort for,

00:39:52.400 --> 00:39:56.400
or almost zero effort for backup
and very little effort for restore.

00:39:56.400 --> 00:39:59.420
By very little effort,
I mean they email me and call me

00:39:59.420 --> 00:40:01.740
and say I need this file restored.

00:40:01.740 --> 00:40:04.170
That's really all I want
the user to have to do.

00:40:04.720 --> 00:40:07.550
they should not even know it's happening.

00:40:08.030 --> 00:40:11.340
The solution, as it turned out,
was Retrospect 6 from EMC Dance.

00:40:11.340 --> 00:40:13.420
Understand we have modest needs.

00:40:13.420 --> 00:40:16.400
At some day, again,
we only have 600 people,

00:40:16.400 --> 00:40:20.720
some day we might have a whole hundred
clients with just their home directories

00:40:20.800 --> 00:40:23.670
backed up to a small tape library,
and not everything in that.

00:40:23.680 --> 00:40:28.720
We chose the Exabyte VXA2
1U FireWire 800 library.

00:40:28.800 --> 00:40:29.950
It's brilliant.

00:40:29.960 --> 00:40:33.100
Suitable speed and
capacities for our needs.

00:40:33.100 --> 00:40:34.450
It was easily racked.

00:40:34.560 --> 00:40:36.700
It's actually smaller than
the XServe by a good bit.

00:40:37.600 --> 00:40:40.780
Fastest client connection we have
on our network is 100 meg Ethernet.

00:40:40.790 --> 00:40:44.910
So FireWire 800 speed, tape speeds,
that's never going to be the bottleneck.

00:40:44.960 --> 00:40:46.900
It's going to be the cable coming
out of the back of the client.

00:40:46.900 --> 00:40:50.180
It's a 10-tape library.

00:40:50.180 --> 00:40:51.400
We do an incremental every day.

00:40:51.400 --> 00:40:52.700
We don't do fulls on the weekend.

00:40:52.700 --> 00:40:55.080
Again, most of the laptops are
gone on the weekend.

00:40:55.080 --> 00:40:57.940
We really, when I say we never have
people working on the weekend,

00:40:57.940 --> 00:40:59.200
I'm very serious about that.

00:40:59.220 --> 00:41:01.320
You know, if you're not underground
with the mainframe,

00:41:01.320 --> 00:41:02.560
you're not working on the weekend.

00:41:05.480 --> 00:41:07.340
So that's what it looks like now.

00:41:07.370 --> 00:41:09.900
We have a dual processor Xserve G4.

00:41:10.150 --> 00:41:13.990
We've got the FireWire 800
stuff to the tape drive.

00:41:14.030 --> 00:41:18.800
And it just talks to--it backs up a few
things on the Xserve that I care about.

00:41:18.970 --> 00:41:21.990
It backs up home directories
on Windows laptops.

00:41:22.310 --> 00:41:24.060
It backs up home directories on the Macs.

00:41:24.060 --> 00:41:26.600
It backs up some stuff in slash library.

00:41:26.740 --> 00:41:28.620
But I leave systems alone.

00:41:28.630 --> 00:41:30.660
I can always reimage those.

00:41:30.660 --> 00:41:33.040
I don't need to worry about the
system files or anything like that.

00:41:33.320 --> 00:41:36.980
The tape library itself is a 10-tape
single-drive library for under $3,000.

00:41:37.000 --> 00:41:38.810
It's small.

00:41:38.880 --> 00:41:40.200
It's dead simple to set up.

00:41:40.250 --> 00:41:43.620
I mean, like, plug it in, turn it on,
you're 90% done.

00:41:43.660 --> 00:41:46.600
It's got a couple of command
line utilities for management,

00:41:46.600 --> 00:41:50.350
which lets me update firmware on the
library and on the drive separately.

00:41:50.400 --> 00:41:52.870
The front console,
I think I read the instructions

00:41:52.870 --> 00:41:55.760
once just to see if it was
different than what I'd found.

00:41:55.760 --> 00:41:59.700
It really wasn't,
so it wasn't really needed.

00:41:59.700 --> 00:42:00.820
It's got a barcode reader.

00:42:00.820 --> 00:42:02.030
Barcodes are good always.

00:42:02.030 --> 00:42:05.180
And it's really been a fantastic
bit of hardware for us.

00:42:05.180 --> 00:42:06.740
I mean,
if any of the Exabyte guys are here,

00:42:06.740 --> 00:42:07.440
I love you all.

00:42:07.460 --> 00:42:08.600
It's been brilliant.

00:42:08.600 --> 00:42:12.440
We're actually looking at some of their
other stuff now because this little

00:42:12.440 --> 00:42:14.390
piece of hardware has been so good.

00:42:16.330 --> 00:42:19.730
Those speeds at 280 megaminute
versus 20 megaminute,

00:42:19.940 --> 00:42:23.030
that was during the middle of the day,
and I happened to be using remote

00:42:23.030 --> 00:42:25.710
desktop to make sure that the
designer who was getting backed up,

00:42:26.110 --> 00:42:34.150
she was running Photoshop on a dual
800-ish G4 without a whole lot of RAM.

00:42:34.160 --> 00:42:35.740
So we're not running really hot hardware.

00:42:35.740 --> 00:42:38.980
She's on the same 100 megabit connection.

00:42:38.980 --> 00:42:41.920
I was getting 280 megaminute
versus 20 megaminute.

00:42:41.920 --> 00:42:43.740
I can live with that speed increase.

00:42:44.840 --> 00:42:47.780
The selectors allow for
really fine-grained selection,

00:42:47.780 --> 00:42:49.600
so I'm not backing up video files.

00:42:49.600 --> 00:42:52.540
I'm not backing up audio files,
and that means on either platform,

00:42:52.600 --> 00:42:58.210
whether it's WMA, MPEG-4, QuickTime, MP3,
AAC, whatever, I'm not backing it up.

00:42:58.220 --> 00:43:00.880
Once I got the president's
brother to buy in on that,

00:43:00.880 --> 00:43:03.250
that his music library
wouldn't be backed up,

00:43:03.250 --> 00:43:06.870
that kind of gave me really good
political capital for everybody else,

00:43:06.910 --> 00:43:10.140
because I could say, he's fine with it,
what's your excuse?

00:43:12.210 --> 00:43:17.330
The only dances mailing list has
been all the support I've needed for

00:43:17.370 --> 00:43:19.540
almost 10 years of using the product.

00:43:19.600 --> 00:43:21.980
I definitely tend to
plan a little bit more,

00:43:21.980 --> 00:43:26.100
but I've never really had a problem
that the mailing list couldn't solve.

00:43:26.280 --> 00:43:28.910
The other nice thing with
the fine-grained selection,

00:43:28.940 --> 00:43:31.220
although,
is that although people in corner

00:43:31.300 --> 00:43:34.590
offices are willing to play by the rules,
sometimes they want their

00:43:34.710 --> 00:43:36.610
rules to be a little different.

00:43:36.860 --> 00:43:40.480
So I was able to create different
selectors for the corner

00:43:40.480 --> 00:43:42.140
offices than for everybody else.

00:43:42.190 --> 00:43:47.400
The only issues was the firmware
on the tape unit and the

00:43:47.400 --> 00:43:49.340
Windows client version issues,
and both of those were

00:43:49.340 --> 00:43:50.500
solved in about a day.

00:43:50.500 --> 00:43:52.580
Literally,
I think it was about three hours.

00:43:52.580 --> 00:43:54.980
You know, once I updated the
firmware on the tape drive,

00:43:54.980 --> 00:43:58.990
updated the firmware on the library,
made sure my Windows client

00:43:58.990 --> 00:44:02.010
numbers were right,
it's just been working.

00:44:02.720 --> 00:44:04.600
It's excellent laptop support.

00:44:04.610 --> 00:44:05.790
The server pulls the clients.

00:44:05.800 --> 00:44:09.100
If the client's not on the network,
it just doesn't get backed up.

00:44:09.100 --> 00:44:11.560
And that's really been great when
I'm explaining how this works to

00:44:11.560 --> 00:44:12.650
people because that's what they ask.

00:44:12.720 --> 00:44:14.340
What happens if I'm not on the network?

00:44:14.340 --> 00:44:14.970
You don't get backed up.

00:44:15.050 --> 00:44:16.230
When do I get backed up?

00:44:16.490 --> 00:44:18.710
As soon as you're back on the network,
you get backed up.

00:44:18.730 --> 00:44:19.950
So I don't have to do anything?

00:44:19.990 --> 00:44:20.560
No, you don't.

00:44:20.640 --> 00:44:21.280
Oh, cool.

00:44:22.750 --> 00:44:24.790
The backups are transparent.

00:44:24.880 --> 00:44:27.240
They don't know.

00:44:27.270 --> 00:44:29.870
I did tell them that when it's
first starting the incrementals,

00:44:29.870 --> 00:44:31.380
you're going to hear a lot
of hard drive activity.

00:44:31.380 --> 00:44:32.000
That's fine.

00:44:32.040 --> 00:44:33.540
They can live with that.

00:44:33.540 --> 00:44:36.790
Once it gets done,
the incremental data changes, again,

00:44:36.790 --> 00:44:38.620
insurance company, not a lot.

00:44:38.670 --> 00:44:41.440
Even the designers don't
change stuff that much.

00:44:41.440 --> 00:44:43.700
We reuse stuff over and
over and over again.

00:44:45.020 --> 00:44:48.520
The Mac servers client support
fits our needs perfectly.

00:44:48.520 --> 00:44:52.650
We don't have a lot of, we don't have any
Linux clients at the moment.

00:44:52.790 --> 00:44:56.050
We might, but it's all Macs and PCs,
and Retrospect backs

00:44:56.100 --> 00:44:57.520
those up really well.

00:44:57.560 --> 00:44:58.950
And we're a small company.

00:44:58.950 --> 00:45:01.040
This is a small, part of a small company.

00:45:01.040 --> 00:45:03.060
We don't need the ultimate backup tool.

00:45:03.060 --> 00:45:05.140
We don't need something
that will back up,

00:45:05.140 --> 00:45:07.560
you know, 16 petabytes overnight.

00:45:07.560 --> 00:45:10.740
We just need small,
and Retrospect is handling this,

00:45:10.820 --> 00:45:12.670
you know, really perfectly.

00:45:12.680 --> 00:45:14.540
It does the job.

00:45:14.540 --> 00:45:16.860
It's been running six months.

00:45:16.900 --> 00:45:17.820
I don't mess with it much.

00:45:17.820 --> 00:45:20.920
I check on it occasionally,
a little remote desktop.

00:45:20.980 --> 00:45:22.340
Oh, okay, I don't need tapes yet.

00:45:22.520 --> 00:45:22.660
Cool.

00:45:22.660 --> 00:45:24.250
That's pretty much what it is.

00:45:24.300 --> 00:45:25.640
Oh, still don't need tapes.

00:45:25.650 --> 00:45:25.960
Fine.

00:45:26.050 --> 00:45:26.920
Oh, need tapes.

00:45:28.480 --> 00:45:30.060
We've got about 25 clients at the moment.

00:45:30.060 --> 00:45:31.230
We're adding about four a month.

00:45:31.230 --> 00:45:35.710
I am adding them small and sanely
because that way if something goes wrong,

00:45:35.730 --> 00:45:38.440
I know right away,
not after adding 50 clients at

00:45:38.440 --> 00:45:41.970
once and then wondering why things
suddenly went straight to heck.

00:45:42.680 --> 00:45:44.840
It's also been a PR bonanza for us.

00:45:44.840 --> 00:45:47.880
There is nothing like
having your party planner,

00:45:47.880 --> 00:45:51.980
the vice chairman of the board,
the VP of operations, the VP of IS,

00:45:51.980 --> 00:45:56.190
you know, all those kind of people with
those titles suddenly really

00:45:56.190 --> 00:45:58.400
happy with your department.

00:45:58.400 --> 00:46:01.550
That's great political capital
because then you can go in and say,

00:46:01.550 --> 00:46:03.540
you know, we could use a budget increase.

00:46:03.620 --> 00:46:05.170
We're really happy with you.

00:46:05.210 --> 00:46:08.080
We may not be that happy with you,
but we're really happy with you.

00:46:08.100 --> 00:46:12.430
It's also the most boring server I have.

00:46:12.680 --> 00:46:16.120
Boring in the sense of
I don't have to mess with it.

00:46:16.210 --> 00:46:17.630
It lets me go home on time.

00:46:17.630 --> 00:46:20.870
This makes two people very happy, my son,
my girlfriend.

00:46:20.880 --> 00:46:25.230
Well, it makes my bosses happy too,
but I care less about them.

00:46:25.230 --> 00:46:30.420
So that's,
we're not as cool as Dark Horse.

00:46:30.420 --> 00:46:31.750
Thank you.

00:46:39.040 --> 00:46:39.540
Thank you.

00:46:39.560 --> 00:46:41.630
And now I'd like to invite
Mark Miranda on stage

00:46:41.670 --> 00:46:42.520
with the Cimarron Group.

00:46:42.540 --> 00:46:43.100
Mark.

00:46:43.100 --> 00:46:44.590
Thank you.

00:46:44.770 --> 00:46:50.220
Good afternoon.

00:46:50.220 --> 00:46:53.470
My name is Mark Miranda,
and I am the IT Director for a company

00:46:53.540 --> 00:46:55.740
called the Cimarron Group in Hollywood,
California.

00:46:58.100 --> 00:47:01.140
Cimarron Group was established in 1979.

00:47:01.140 --> 00:47:05.110
We are one of the largest advertising
agencies for the motion picture industry.

00:47:05.350 --> 00:47:06.440
We run the gambit.

00:47:06.500 --> 00:47:12.010
We do movie trailers, movie TV spots,
one-sheets, movie posters that you

00:47:12.010 --> 00:47:14.340
see in the theaters,
DVD box design,

00:47:14.340 --> 00:47:18.940
and even now DVD menu animations when
you stick a DVD in your DVD player.

00:47:19.700 --> 00:47:22.440
We also do celebrity and
feature film websites.

00:47:22.440 --> 00:47:24.710
As you can see,
we have quite a few rather

00:47:24.710 --> 00:47:28.420
important clients up there,
and we like to keep them happy.

00:47:30.280 --> 00:47:32.630
So you probably haven't
heard of the Cimarron Group,

00:47:32.630 --> 00:47:34.140
but I know you've seen some of our work.

00:47:34.140 --> 00:47:38.320
On the top row,
we have all our theatrical audiovisual

00:47:38.320 --> 00:47:40.100
campaigns that we've worked on.

00:47:40.120 --> 00:47:43.400
Troy, Collateral, War of the Worlds,
which is coming this summer,

00:47:43.400 --> 00:47:46.480
and the critically acclaimed
Million Dollar Baby.

00:47:47.770 --> 00:47:52.790
On the bottom row,
we do all of the Star Wars DVD packaging,

00:47:52.800 --> 00:47:55.000
which as you probably
have seen over the years,

00:47:55.010 --> 00:47:58.970
they tend to come out once or twice,
three, four, five, six times.

00:47:58.980 --> 00:48:00.990
And now that we have
Episode 3 coming out,

00:48:00.990 --> 00:48:02.760
we know there's more coming there.

00:48:02.760 --> 00:48:07.240
We were also just recently awarded,
we are the official advertising

00:48:07.290 --> 00:48:10.840
agency for Lotus Cars,
so that's exciting for us.

00:48:10.840 --> 00:48:14.700
And we also do political cartoons,
or not cartoons, commercials.

00:48:22.000 --> 00:48:24.880
Arnold Schwarzenegger was one of our
celebrity clients and he's also become

00:48:24.880 --> 00:48:28.450
one of our political advertising clients,
so that's also fun to work with.

00:48:28.480 --> 00:48:30.770
And we do all the print
and video advertising for

00:48:30.810 --> 00:48:34.160
Universal Studios Hollywood,
so hopefully you've seen them.

00:48:35.720 --> 00:48:37.860
You like them.

00:48:37.860 --> 00:48:39.200
Our architecture.

00:48:39.460 --> 00:48:42.220
One thing I just want to say,
we do all kinds of things

00:48:42.220 --> 00:48:43.800
in terms of print and video.

00:48:43.800 --> 00:48:47.250
For the focuses of this,
I want to focus on our theatrical

00:48:47.260 --> 00:48:50.720
audio-visual side because that
presents the biggest challenge

00:48:50.790 --> 00:48:52.620
in terms of backup and restore.

00:48:53.100 --> 00:48:55.940
So we are a 24/7 facility,
which means we don't have a

00:48:55.940 --> 00:48:58.600
lot of maintenance window,
don't have a lot of downtime.

00:48:58.600 --> 00:49:00.530
It makes things difficult for us.

00:49:00.600 --> 00:49:05.460
We exclusively use
Apple Final Cut Pro for our edit bays,

00:49:05.470 --> 00:49:07.600
which is really cool.

00:49:07.600 --> 00:49:11.680
Back right around the first of the year,
actually the day after Christmas,

00:49:11.680 --> 00:49:13.600
I remember that very well because
we were all stuck at work.

00:49:13.600 --> 00:49:19.660
We converted everything over from
Final Cut 3 OS 9 to Final Cut 4 5

00:49:19.810 --> 00:49:22.600
OS 10 with Xsan running as our backup.

00:49:22.600 --> 00:49:24.580
We had to do a lot of work
to get our file system,

00:49:24.580 --> 00:49:26.580
so that presented a
few challenges for us.

00:49:26.600 --> 00:49:29.290
Anyway,
we have 25 compressed DV edit bays

00:49:29.290 --> 00:49:31.180
for offline rough cut editing.

00:49:31.180 --> 00:49:35.020
And then we have two uncompressed
finishing bays that take the rough

00:49:35.020 --> 00:49:37.600
cuts and make them ready for broadcast.

00:49:37.600 --> 00:49:39.640
And all of our stations share media.

00:49:39.640 --> 00:49:42.600
And this is really key,
which is why we needed Xsan.

00:49:42.600 --> 00:49:46.900
It's not uncommon at all for an
editor during the day to be working

00:49:46.990 --> 00:49:52.550
on multiple campaigns or even within a
single campaign that you're working on.

00:49:52.600 --> 00:49:55.910
There may be four separate editors
during the day creating different

00:49:55.910 --> 00:49:59.590
creative TV spots because you never
know what the studio is going to like.

00:49:59.600 --> 00:50:03.360
And then on a more basic level,
we share our media because we

00:50:03.400 --> 00:50:07.600
need access to a centralized
music and sound effects library.

00:50:07.600 --> 00:50:10.020
So that way we just
maintain one master library.

00:50:10.020 --> 00:50:11.560
It makes work easier for us.

00:50:12.910 --> 00:50:16.000
So here's a simple diagram of
basically how everything's hooked up.

00:50:16.000 --> 00:50:21.200
We use a SAN strategy
called SAN to the Desktop.

00:50:21.310 --> 00:50:25.770
So all 27 of our G5 edit bays have
a direct fiber optic connection

00:50:25.850 --> 00:50:28.910
to a fiber channel switch,
as do our metadata

00:50:28.920 --> 00:50:31.760
controllers that run the SAN,
and then of course the backup server.

00:50:32.430 --> 00:50:34.530
One thing I want to point
out on the backup server,

00:50:34.550 --> 00:50:36.870
you'll see there's actually
two connections to the

00:50:36.870 --> 00:50:41.140
fiber channel switch there,
and we use multi-pathing for that.

00:50:41.160 --> 00:50:43.970
Multi-pathing basically
allows you to achieve,

00:50:43.970 --> 00:50:46.770
in theory,
up to twice the throughput with Xsan,

00:50:46.770 --> 00:50:50.010
as well as the benefit of if you
lose one of those fiber optic

00:50:50.110 --> 00:50:53.900
connections for some reason,
your backup will keep running.

00:50:55.210 --> 00:50:58.120
And then of course there's our
LTO3 tape library attached to that,

00:50:58.130 --> 00:51:01.120
which hopefully will soon
be Fibre Channel itself.

00:51:02.370 --> 00:51:03.540
So there it is.

00:51:03.540 --> 00:51:07.700
That's our Xsan system,
seven Xserve RAIDs, switch at the top,

00:51:07.840 --> 00:51:10.540
and two controllers,
modest little system.

00:51:10.540 --> 00:51:14.440
We have three volumes
set up on those drives,

00:51:14.440 --> 00:51:19.640
16 terabyte only because
that's the maximum for Panther,

00:51:19.640 --> 00:51:20.760
which we can now change.

00:51:20.760 --> 00:51:22.910
But that's our offline video volume.

00:51:22.910 --> 00:51:25.500
We have an online video
volume that's four terabytes,

00:51:25.500 --> 00:51:30.000
and another music and sound effects
library that's four terabytes as well.

00:51:30.830 --> 00:51:33.180
Now you might be thinking,
that's an awful lot of RAIDs,

00:51:33.180 --> 00:51:35.800
and that's a lot of storage,
but it's not that much storage.

00:51:35.840 --> 00:51:40.080
Well, all of these RAIDs are configured
with only six hot drives on each side,

00:51:40.090 --> 00:51:43.980
so there is a hot spare on each
drive just to minimize our downtime

00:51:43.980 --> 00:51:47.090
if an array becomes degraded.

00:51:49.420 --> 00:51:50.640
So our challenge.

00:51:50.640 --> 00:51:54.600
Our challenge was we needed to
back up 24 terabytes of data.

00:51:54.600 --> 00:51:57.120
The RAID 5 protection and
having the spare drive,

00:51:57.130 --> 00:51:57.830
still not enough.

00:51:57.900 --> 00:51:58.900
You never know what's going to happen.

00:51:58.900 --> 00:52:02.380
And we wanted to implement
it in a very specific way.

00:52:02.380 --> 00:52:05.070
We needed to be able to do full
backups on the weekends when

00:52:05.150 --> 00:52:08.900
not all the editors were there,
but some of them inevitably are there.

00:52:08.900 --> 00:52:10.890
And then incrementals on the weeknights,
again,

00:52:10.930 --> 00:52:14.060
when not all of the editors are there,
but some of the editors are there.

00:52:14.790 --> 00:52:17.920
And then it's got to have
minimal impact on their workflow.

00:52:17.920 --> 00:52:21.780
If they start dropping
frames while editing video,

00:52:21.780 --> 00:52:23.540
that's not going to reflect good on us.

00:52:23.540 --> 00:52:26.100
And then we have a separate
need to archive our data.

00:52:26.100 --> 00:52:31.250
24 terabytes may seem like a lot,
but we ingest feature films all the time,

00:52:31.250 --> 00:52:35.210
getting new footage from the studios,
so we're constantly having to

00:52:35.220 --> 00:52:36.660
take things on and off the SAN.

00:52:36.660 --> 00:52:39.150
And when we do that,
we like to generate two copies,

00:52:39.150 --> 00:52:41.510
one that we keep on site
for immediate retrieval,

00:52:41.570 --> 00:52:44.280
and one that we send off
site for disaster recovery.

00:52:46.570 --> 00:52:48.440
So the pains of evaluation.

00:52:48.440 --> 00:52:51.720
As I said, we made this jump back
at the first of the year,

00:52:51.730 --> 00:52:55.140
and so we needed to immediately start
evaluating some enterprise-level

00:52:55.140 --> 00:52:58.900
backup programs that would work for us.

00:52:58.900 --> 00:53:01.700
And we ran into quite a few challenges.

00:53:01.700 --> 00:53:05.410
First and foremost,
that's not even on this list, is, yeah,

00:53:05.590 --> 00:53:08.160
you can test backups and
backup a few folders,

00:53:08.160 --> 00:53:11.220
but when you're backing up an
actual production system with 24

00:53:11.220 --> 00:53:14.530
terabytes and something goes wrong,
your window is shot.

00:53:14.640 --> 00:53:17.860
You have to wait until the following
weekend to actually run another test and

00:53:17.980 --> 00:53:19.850
see if you've fixed whatever is wrong.

00:53:19.860 --> 00:53:23.270
But in addition to that,
we ran into maximum file size

00:53:23.290 --> 00:53:27.660
and volume size limitations with
some of the programs we tested.

00:53:27.660 --> 00:53:32.560
Little or no Xsan support,
no LTO3 tape library support,

00:53:32.560 --> 00:53:38.750
which we had recently acquired, again,
for performance and capacity.

00:53:38.760 --> 00:53:40.490
LTO3 seemed the right way to go.

00:53:40.500 --> 00:53:42.870
No simultaneous stream support.

00:53:42.880 --> 00:53:47.030
And by that, I mean... Backing up from
multiple sources onto multiple

00:53:47.040 --> 00:53:48.390
drives at the same time.

00:53:48.400 --> 00:53:49.510
Not everybody does that.

00:53:49.520 --> 00:53:51.270
No parallel streaming.

00:53:51.280 --> 00:53:55.540
Parallel streaming allows us to take a
single data source and make two copies at

00:53:55.550 --> 00:53:59.910
the same time on two different devices,
which we use for our archiving.

00:53:59.920 --> 00:54:03.190
And then I'm sure none of you
have run into the experience

00:54:03.190 --> 00:54:06.190
of calling tech support and not
getting answers that you like.

00:54:06.320 --> 00:54:08.990
When you're evaluating software,
it's even harder.

00:54:09.040 --> 00:54:12.500
But a lot of them we
found had bad support.

00:54:13.210 --> 00:54:16.330
And then poor backup
and restore performance.

00:54:16.660 --> 00:54:22.360
The backup and restore performance
is critical for us because we have a

00:54:22.360 --> 00:54:23.980
lot of data to backup in that window.

00:54:23.980 --> 00:54:28.380
And if your performance is subpar,
we know we can't make our window.

00:54:28.600 --> 00:54:29.870
So what was the solution?

00:54:29.980 --> 00:54:34.410
Well, a temple came to us a few months
back and showed us this product

00:54:34.420 --> 00:54:36.500
that they had called Time Navigator.

00:54:36.500 --> 00:54:39.070
And I have to say we
were skeptical at first.

00:54:39.100 --> 00:54:41.940
We had already evaluated quite a few
products and been really disappointed.

00:54:42.920 --> 00:54:46.470
But a few of the features that
we liked right out of the box,

00:54:46.470 --> 00:54:51.470
Xsan support, it's a plus,
LTO3 tape library support, another plus.

00:54:51.470 --> 00:54:56.470
They had a professional service team that
was able to come down to our facility,

00:54:56.480 --> 00:54:59.920
help us set it up,
go over our general backup strategy,

00:54:59.920 --> 00:55:00.840
which is key.

00:55:00.840 --> 00:55:03.440
You always need to have a
plan before starting a backup.

00:55:03.440 --> 00:55:06.970
And really able to tune and tweak
both our setup and their software

00:55:06.980 --> 00:55:10.350
to make sure that we got the
fastest performance possible.

00:55:12.100 --> 00:55:34.140
And the most impressive thing
out of it all is we had it

00:55:34.140 --> 00:55:34.140
all up and running in one day.

00:55:34.140 --> 00:55:34.140
We were doing test backups,
doing performance benchmarks,

00:55:34.140 --> 00:55:34.140
everything on the very first day.

00:55:34.140 --> 00:55:34.140
Extremely, extremely fast.

00:55:34.140 --> 00:55:34.140
In fact,
so fast that it is the only product that

00:55:34.140 --> 00:55:34.140
we tested that when we gave it the full
24 terabytes to backup over a weekend,

00:55:34.140 --> 00:55:34.140
we were able to meet the
very first weekend we ran it.

00:55:34.870 --> 00:55:37.190
Even more,
couldn't fit it all in one slide.

00:55:37.200 --> 00:55:40.000
There were some bonus
features that we really liked.

00:55:40.000 --> 00:55:44.200
The object-oriented approach
of the GUI is really fantastic.

00:55:44.200 --> 00:55:47.320
It takes a little getting used to,
but you can get an overall view

00:55:47.320 --> 00:55:49.240
of what's going on really easily.

00:55:49.240 --> 00:55:52.980
Everything's drag and drop,
moving slots around, all drag and drop,

00:55:52.990 --> 00:55:54.120
very, very nice.

00:55:57.050 --> 00:56:02.480
The Time Slice Approach So, time slicing,
the way they work it is you can

00:56:02.480 --> 00:56:07.000
create a virtual file system on your
screen at any given point in time.

00:56:07.000 --> 00:56:08.500
You say, "Well,
I want to see what the disk

00:56:08.570 --> 00:56:11.650
looked like two weeks ago at
3 o'clock." And sure enough,

00:56:11.650 --> 00:56:14.870
it'll pull up exactly what it
thinks was on the file system

00:56:14.870 --> 00:56:16.870
at 3 o'clock two weeks ago.

00:56:17.000 --> 00:56:18.960
And then you click on a file
that you want to look at,

00:56:18.960 --> 00:56:21.040
click Instances,
it shows you every version of

00:56:21.040 --> 00:56:23.500
that file that was ever backed up.

00:56:23.500 --> 00:56:26.340
If that's not the file you want or
you don't see what you're looking for,

00:56:26.340 --> 00:56:28.320
you can just scrub forwards
and backwards in time until you

00:56:28.320 --> 00:56:29.620
find what you are looking for.

00:56:29.860 --> 00:56:32.740
Extremely, extremely handy when you're
not quite sure what it is

00:56:32.910 --> 00:56:36.040
you're looking for off the bat.

00:56:36.100 --> 00:56:38.740
Synthetic backups,
we love synthetic backups.

00:56:38.740 --> 00:56:42.700
Again, I've said before, you know,
things will go wrong.

00:56:42.730 --> 00:56:45.740
It's inevitable you're going to
have SCSI problems or a tape jam

00:56:45.840 --> 00:56:49.940
at some point and your backup
window is shot if that happens.

00:56:49.940 --> 00:56:53.570
So, a Tempo has kind of a unique
solution to that problem.

00:56:53.570 --> 00:56:55.680
They can go back to your
previous full backup,

00:56:55.680 --> 00:56:57.130
they can go back to your
previous incremental backup,

00:56:57.160 --> 00:56:59.290
your previous incremental
backups and generate a new

00:56:59.290 --> 00:57:03.480
full set if for some reason you
can't complete your full backup.

00:57:03.480 --> 00:57:05.510
So, that's a fantastic feature.

00:57:05.710 --> 00:57:07.980
And then the parallel
streams I mentioned before,

00:57:07.980 --> 00:57:11.140
we can then take our archives,
archive on to two separate tapes,

00:57:11.140 --> 00:57:14.810
keep one on-site, send one off-site,
all works really beautifully.

00:57:16.580 --> 00:57:21.480
So, we like the product so much that now,
going into phase two,

00:57:21.480 --> 00:57:25.110
we are going to implement
it across the board.

00:57:25.140 --> 00:57:28.340
We are going to run it on
our Mac OS X server with a

00:57:28.340 --> 00:57:30.920
centralized unified interface.

00:57:30.920 --> 00:57:34.550
We are going to use it to backup
all of our Mac OS X file servers,

00:57:34.550 --> 00:57:37.550
our Windows servers,
and even our application servers

00:57:37.600 --> 00:57:40.460
like our Exchange servers and
our Microsoft SQL servers.

00:57:40.460 --> 00:57:42.860
And all utilizing our existing equipment.

00:57:42.860 --> 00:57:46.930
We have a Spectralogic AIT4 tape
library as well as an older Mammoth

00:57:46.930 --> 00:57:48.980
2 that we use for archiving.

00:57:48.980 --> 00:57:50.680
So, that's about it.

00:57:50.680 --> 00:57:52.830
I hope you take the time
to evaluate the product.

00:57:52.840 --> 00:57:55.180
We think it's really great
and we hope you will too.

00:57:55.180 --> 00:57:56.200
Thank you very much.

00:58:04.400 --> 00:58:09.400
Great, so I just wanted to quickly
summarize the backup solutions

00:58:09.400 --> 00:58:11.050
that we have available for X.

00:58:11.540 --> 00:58:13.530
For those of you who have
been around quite a while,

00:58:13.530 --> 00:58:16.200
if you remember the
early days of Mac OS X,

00:58:16.200 --> 00:58:19.740
there wasn't a lot of them at the time,
and we definitely have a

00:58:19.740 --> 00:58:24.690
lot of new vendors on board,
thanks to the Unix underpinnings.

00:58:24.720 --> 00:58:27.920
So we've got all those
vendors on the platform,

00:58:28.000 --> 00:58:33.400
and we have a grid as well that we've
put together in terms of Tiger support,

00:58:33.520 --> 00:58:39.750
Xsan support, and of course server
availability on our platform.