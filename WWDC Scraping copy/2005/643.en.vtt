WEBVTT

00:00:11.000 --> 00:00:14.860
Welcome and congratulations for
making it to the last session on

00:00:14.860 --> 00:00:19.280
the last hour of the last day.

00:00:20.290 --> 00:00:23.530
will be trying to top off your
tank this afternoon and send

00:00:23.540 --> 00:00:26.900
you home brimming with tips,
tools, and techniques for parallel

00:00:26.900 --> 00:00:28.930
debugging on HPC systems.

00:00:28.970 --> 00:00:32.380
I'm Steve Peters,
I'm a senior software scientist in the

00:00:32.380 --> 00:00:36.620
Mac OS Platform Performance Engineering
group.

00:00:37.280 --> 00:00:40.610
And this afternoon,

00:00:41.810 --> 00:00:44.100
I'm going to give you
a bit of a personal,

00:00:44.230 --> 00:00:48.410
perhaps idiosyncratic perspective
on the kinds of cluster debugging

00:00:48.410 --> 00:00:50.240
problems across my desk.

00:00:50.830 --> 00:00:53.980
A colleague of mine will
tell you about Shark,

00:00:54.150 --> 00:01:02.830
some recipes for debugging using
old menus and some new features.

00:01:05.630 --> 00:01:10.400
A long-time partner
on the Apple platform,

00:01:10.480 --> 00:01:13.260
nearly two decades running, I think,
getting close.

00:01:13.260 --> 00:01:15.560
Absoft has some interesting
and exciting new technology

00:01:15.600 --> 00:01:19.890
they're going to tell us about,
and a new partner coming to Mac OS X,

00:01:20.010 --> 00:01:23.000
Etnus, will tell us about their
TotalView Debuggers,

00:01:23.000 --> 00:01:26.290
something you may know from other places.

00:01:28.500 --> 00:01:32.900
So I'm a software guy,
interested mainly in performance

00:01:32.900 --> 00:01:36.590
of math and science codes.

00:01:37.350 --> 00:01:39.100
I did some work with
the Virginia Tech crew

00:01:39.100 --> 00:01:44.960
bringing up the System 10,
both in its G5 PowerMark incarnation

00:01:44.960 --> 00:01:48.460
and in the final G5 XServe setup.

00:01:48.540 --> 00:01:54.640
I helped with some of the tuning of the
benchmarks on the Kulso Mach 5 system.

00:01:54.680 --> 00:01:59.360
I meet with HPC developers in
one-on-one performance kitchens.

00:01:59.360 --> 00:02:04.880
If you haven't had an opportunity
or feel you have a problem that's

00:02:05.020 --> 00:02:08.960
Important to work out,
check with Skip and maybe we can get

00:02:08.960 --> 00:02:12.310
you into Performance Kitchen where
the results have been,

00:02:12.320 --> 00:02:15.040
I think, uniformly good.

00:02:15.250 --> 00:02:19.950
and I occasionally do some consulting
internally on contracts and projects.

00:02:20.020 --> 00:02:22.510
So maybe some reasons you
might want to listen to me.

00:02:22.780 --> 00:02:28.690
I'm going to talk a bit about what
I see are kind of the two classes of

00:02:28.810 --> 00:02:30.640
problems that come across my desk.

00:02:30.690 --> 00:02:33.100
First, new HPC codes.

00:02:33.150 --> 00:02:34.720
I'll have a bit to say about that.

00:02:34.720 --> 00:02:37.940
I think some of the following
presentations will have really specific

00:02:38.040 --> 00:02:40.550
tools to help you work out those issues.

00:02:40.570 --> 00:02:46.640
I'll try to give down a brief rundown of
best practices implementation performance

00:02:46.650 --> 00:02:49.690
and pointers to some debugging aids.

00:02:50.010 --> 00:02:55.000
But for the most part,
what I get to see are existing HPC codes,

00:02:55.080 --> 00:02:59.500
people bringing from Linux, Iris,
Solaris, elsewhere,

00:02:59.500 --> 00:03:02.000
bringing that code to Mac OS X.

00:03:02.000 --> 00:03:05.440
And their debugging usually means,
"How come this isn't working

00:03:05.440 --> 00:03:10.000
as fast as I hoped it would?"
And that's where I get involved.

00:03:10.000 --> 00:03:15.000
I like to point out where the
Mac OS X performance high ground is,

00:03:15.000 --> 00:03:19.500
and perhaps leave a few signposts
to how to get there quickly.

00:03:19.600 --> 00:03:23.770
I'd like to leave you with some rules of
thumb and some cautions about bring-up,

00:03:23.820 --> 00:03:26.310
particularly of big clusters.

00:03:27.990 --> 00:03:31.400
So what's to say for
implementing new code?

00:03:31.520 --> 00:03:33.440
Why debug when you don't have to?

00:03:33.620 --> 00:03:37.670
Please consider Apple's
tested and tuned libraries.

00:03:37.750 --> 00:03:41.720
We offer in our Accelerate
framework industry standard BLAS,

00:03:41.750 --> 00:03:43.880
linear algebra, and LAPAC.

00:03:43.950 --> 00:03:47.800
LAPAC is the gold standard
for numerical linear algebra.

00:03:48.000 --> 00:03:52.710
We offer VMathLibed single precision,
four at a time,

00:03:52.760 --> 00:03:55.420
elementary math functions.

00:03:55.780 --> 00:04:01.200
Vforce single and double precision
arrays of memory operands for

00:04:01.200 --> 00:04:06.700
the elementary math functions,
much like the mass library on IBM.

00:04:07.590 --> 00:04:11.830
VDSP single and double
digital signal processing,

00:04:11.870 --> 00:04:14.790
particularly good on FFTs.

00:04:15.190 --> 00:04:18.620
We now think,
at least for certain radices,

00:04:18.620 --> 00:04:22.790
we handily beat FFTW.

00:04:23.970 --> 00:04:30.120
and Vimage, an image processing library,
many pixel formats,

00:04:30.180 --> 00:04:32.960
highly optimized for the platform.

00:04:33.060 --> 00:04:38.070
One of the advantages of using these
codes is Apple takes care to insulate

00:04:38.090 --> 00:04:41.350
you from changes in the underlying
instruction set architecture.

00:04:41.360 --> 00:04:46.060
So folks who code to the
Fast Fourier transforms in the

00:04:46.060 --> 00:04:53.210
VDSP library don't need to worry about
changes to the underlying processor.

00:04:56.010 --> 00:04:58.290
Consider some auto vectorization tools.

00:04:58.380 --> 00:05:00.990
All the current processors and
all the ones we contemplate

00:05:01.050 --> 00:05:05.330
will have SIMD engines,
and you can get big performance

00:05:05.330 --> 00:05:11.240
gains and correct code
quickly from automatic tools.

00:05:11.350 --> 00:05:17.720
Absoft has offered VAST,
a wonderful tool in that domain.

00:05:17.720 --> 00:05:17.720
There are some features

00:05:17.980 --> 00:05:20.340
and David Koehn,
and I'll be joined by David Koehn,

00:05:20.340 --> 00:05:24.010
who will be presenting some of the most
recent features in GCC4 that you might

00:05:24.030 --> 00:05:26.510
want to check out that do similar,
but I don't think is

00:05:26.520 --> 00:05:28.200
ambitious approaches best.

00:05:31.910 --> 00:05:34.260
Follow some cautious bring-up discipline.

00:05:34.280 --> 00:05:38.580
A lot of stuff can be worked
out on a dual processor,

00:05:38.630 --> 00:05:41.560
single mode of G5,
either a Power Mac or a single

00:05:41.560 --> 00:05:44.560
head node in your server rack.

00:05:44.590 --> 00:05:47.570
And I'll say a little bit more
about expanding that upwards

00:05:47.580 --> 00:05:49.780
a little later in the talk.

00:05:50.580 --> 00:05:54.800
And consider TotalView for your high-end
debugging needs as you move up to

00:05:54.800 --> 00:05:57.430
larger and larger number of systems.

00:05:59.600 --> 00:06:02.340
And finally,
for performance issues in new code,

00:06:02.340 --> 00:06:05.570
understanding where to spend your time,

00:06:06.130 --> 00:06:07.860
Please, please use Shark.

00:06:07.860 --> 00:06:13.090
It's one of the best things I've ever
seen in my career of doing this business.

00:06:13.100 --> 00:06:15.950
It's a wonderful, wonderful tool.

00:06:21.000 --> 00:06:30.980
Ported codes, the bulk of what I see,
ranging from dusty decks to last

00:06:30.980 --> 00:06:37.890
year's implementation or version of
BLAST or the BLAS or scalable BLAS.

00:06:38.610 --> 00:06:40.010
This is existing code.

00:06:40.120 --> 00:06:43.480
It already builds and
runs on some cluster,

00:06:43.480 --> 00:06:45.440
maybe yours, maybe a colleague's.

00:06:45.440 --> 00:06:47.750
You want to port to Mac OS X.

00:06:49.680 --> 00:06:52.140
Often, stuff just works.

00:06:52.260 --> 00:06:55.040
But,
and this is where I often get called in,

00:06:55.180 --> 00:06:56.750
performance has been left on the table.

00:06:56.870 --> 00:06:59.850
We're just not seeing the
kind of gains people have

00:06:59.860 --> 00:07:01.600
laid down their hard cash for.

00:07:01.600 --> 00:07:04.120
What can we do?

00:07:05.450 --> 00:07:07.340
I usually start right from the beginning.

00:07:07.410 --> 00:07:10.280
Let's check the config scripts,
the make files,

00:07:10.400 --> 00:07:15.120
and just see that we're not being
defaulted out of the performance world.

00:07:15.440 --> 00:07:19.880
We want to make sure that the config
script is aware of the platform,

00:07:19.880 --> 00:07:22.510
that it either knows
about Mac OS X or Darwin,

00:07:22.640 --> 00:07:25.040
that it knows about the particular
processor we're targeting,

00:07:25.060 --> 00:07:29.200
G5, not just a generic Apple processor.

00:07:29.220 --> 00:07:33.550
Most auto-config scripts nowadays
are understanding Darwin,

00:07:33.690 --> 00:07:38.040
often by updating to the
latest version of that stuff,

00:07:38.040 --> 00:07:41.540
the latest config script,
you'll find Darwin has been included.

00:07:41.540 --> 00:07:44.180
Much of the, you see the stuff on Fink,
for example,

00:07:44.180 --> 00:07:49.310
which is an open source repository
of tools ported to Mac OS X,

00:07:49.310 --> 00:07:53.280
are all of that character.

00:07:54.480 --> 00:07:57.990
Has any tuning been done
for the platform at all?

00:07:58.010 --> 00:08:00.800
Is the code aware of the SIMD unit?

00:08:00.800 --> 00:08:03.880
Is the code aware of any
additional double precision

00:08:03.880 --> 00:08:05.680
floating point resources?

00:08:05.720 --> 00:08:10.230
Are there machine-dependent
implementations in subdirectories?

00:08:10.320 --> 00:08:14.880
Would it be important to replace
the generic loops with ones that

00:08:14.880 --> 00:08:20.310
are a little bit closer tied to the
capabilities of the Mac OS X platform?

00:08:22.130 --> 00:08:24.880
There are compiler issues,
as you might well imagine.

00:08:25.160 --> 00:08:27.130
Are you using a performance compiler?

00:08:27.140 --> 00:08:30.030
G77, I'm sorry, doesn't count.

00:08:30.200 --> 00:08:31.140
But there are other options.

00:08:31.140 --> 00:08:34.990
Absoft has a wonderful compiler suite.

00:08:38.940 --> 00:08:41.890
Are you using the right
performance options?

00:08:41.940 --> 00:08:45.660
C flags need to be set perhaps
a little bit differently,

00:08:45.660 --> 00:08:50.300
and it's worth checking that, again,
you don't default into debug settings,

00:08:50.300 --> 00:08:53.590
for example,
or storage conserving settings that you

00:08:53.940 --> 00:09:00.330
really don't need and you would benefit
by optimizing at level three or beyond.

00:09:02.680 --> 00:09:12.190
Library Issues.

00:09:12.190 --> 00:09:12.190
Again,
I'm going to return to my mantra of try

00:09:12.190 --> 00:09:12.190
to use Apple's Accelerate framework.

00:09:13.350 --> 00:09:17.300
For all those good reasons of
isolation from processor differences,

00:09:17.300 --> 00:09:21.250
highly tuned by the folks at Apple,
good strong industry

00:09:21.250 --> 00:09:23.690
standard tested routines.

00:09:25.930 --> 00:09:29.000
You want to choose an appropriate MPI,
perhaps one that your vendor,

00:09:29.000 --> 00:09:30.700
the vendor of your
interconnect recommends.

00:09:30.740 --> 00:09:34.330
There are many out there today.

00:09:38.900 --> 00:09:45.520
And on occasion I've seen places
where codes will fall back to

00:09:45.520 --> 00:09:51.240
slow reference implementations of,
for example, linear algebra loops,

00:09:51.350 --> 00:09:55.460
based on some if-def on the code,
where if it doesn't discover your Irix,

00:09:55.460 --> 00:09:59.230
Solaris, or Linux,
you end up in the slow path.

00:09:59.320 --> 00:10:05.260
It's worth scanning through the code,
perhaps even after a hint by Shark that,

00:10:05.260 --> 00:10:08.160
"Hey, this loop is just really
sucking up a lot of time,

00:10:08.160 --> 00:10:12.490
and you might do well to improve it."
A good place to look first is to see if

00:10:12.490 --> 00:10:16.610
the code already knows how to improve it,
and you've just been boxed

00:10:16.610 --> 00:10:18.410
out by an if-def setting.

00:10:23.010 --> 00:10:26.600
So I mentioned bring up plans,
how to bring up a very large

00:10:26.680 --> 00:10:28.860
or a very large cluster.

00:10:28.940 --> 00:10:33.340
This is experience mostly
that I gleaned on the 1100

00:10:33.340 --> 00:10:35.520
node cluster at Virginia Tech.

00:10:35.690 --> 00:10:38.630
Start small and work the size up.

00:10:38.800 --> 00:10:54.400
[Transcript missing]

00:10:55.590 --> 00:11:00.500
Verify, first of all,
that the communication fabric is solid.

00:11:00.520 --> 00:11:04.300
There are usually vendor
performance tools and communication

00:11:04.300 --> 00:11:05.840
tools and diagnostic tools.

00:11:05.900 --> 00:11:08.900
It's well worth spending some
time making sure you're not

00:11:08.900 --> 00:11:13.600
dropping bits on the floor,
that you're not overrunning buffers and

00:11:13.990 --> 00:11:17.770
causing large numbers of retransmits.

00:11:18.600 --> 00:11:23.800
[Transcript missing]

00:11:26.160 --> 00:11:32.200
It seems that we live in a binary
world and the problems in communication

00:11:32.210 --> 00:11:36.840
and messaging arise binarily,
I guess.

00:11:36.970 --> 00:11:42.080
So expect issues to arise as power of two
boundaries are crossed on your bring up.

00:11:42.120 --> 00:11:45.230
Expect issues to arise as
physical boundaries are crossed,

00:11:45.250 --> 00:11:52.230
as communication occurs off a rack,
across a router, across a big switch from

00:11:52.230 --> 00:11:54.100
one aisle to another.

00:11:54.100 --> 00:11:58.860
Anybody building machines
in multiple buildings?

00:11:58.860 --> 00:11:58.860
I don't know.

00:11:59.220 --> 00:12:03.100
But those are places to expect to spend
a little bit more time and do a little

00:12:03.100 --> 00:12:09.580
more sniffing around to make sure that
the bring-up is going as expected.

00:12:09.750 --> 00:12:12.890
You need to investigate all
scaling anomalies early on.

00:12:12.940 --> 00:12:17.700
These things tend to multiply
as your performance drops and

00:12:17.700 --> 00:12:20.540
your sort of sadness increases.

00:12:20.540 --> 00:12:24.330
It's really important to sort
of stay on the line you're

00:12:24.330 --> 00:12:26.610
expecting for the scale-up.

00:12:28.340 --> 00:12:34.570
And finally, do some A/B comparisons on
symmetric subsets of the cluster.

00:12:35.200 --> 00:12:43.200
[Transcript missing]

00:12:46.470 --> 00:12:51.530
I was asked, I guess Skip hinted at a
special topic that I do here,

00:12:51.550 --> 00:12:53.900
an HPC-friendly memory allocation.

00:12:53.920 --> 00:12:56.660
This derives from work
done at Virginia Tech.

00:12:56.770 --> 00:13:00.390
This was undertaken by
our very own Quinn in DTS,

00:13:00.470 --> 00:13:07.190
and we're grateful to have
this contribution today,

00:13:07.190 --> 00:13:07.190
and happy to be able
to pass along to you.

00:13:08.050 --> 00:13:12.550
So the story is something like this:
Mac OS X, as we ship it on new machines

00:13:12.560 --> 00:13:18.200
and on the DVDs that you buy,
has a memory allocation scheme in the

00:13:18.200 --> 00:13:21.790
user land that's tuned for the desktop.

00:13:21.890 --> 00:13:25.680
This is Libsys, Malik,
or I believe it's the same stuff that

00:13:25.680 --> 00:13:28.790
underlies the Fortran dynamic allocation.

00:13:28.940 --> 00:13:32.220
It favors small, short-lived allocations.

00:13:32.270 --> 00:13:37.520
I think our studies show
that the most often allocated

00:13:37.600 --> 00:13:39.900
block is about 40 bytes long.

00:13:39.900 --> 00:13:43.900
We make it very fast to
get those to recycle them.

00:13:44.170 --> 00:13:47.900
Bigger allocations are
aggressively released.

00:13:47.900 --> 00:13:50.980
When the application is done with them,
you call free,

00:13:51.160 --> 00:13:54.780
they're aggressively released
back to the OS to reduce pressure

00:13:54.780 --> 00:13:57.890
on the real pages in the system.

00:13:59.780 --> 00:14:03.200
And this scheme really doesn't
pay much attention to any

00:14:03.550 --> 00:14:05.730
particular access pattern.

00:14:05.840 --> 00:14:07.180
And that's different than HPC.

00:14:07.300 --> 00:14:12.250
HPC is going to prefer large,
long-lived allocations,

00:14:12.250 --> 00:14:13.900
your big data arrays.

00:14:14.700 --> 00:14:17.460
Sequential access.

00:14:17.470 --> 00:14:22.270
And it's going to be essential
that the memory cache

00:14:22.310 --> 00:14:24.680
hierarchy be used effectively.

00:14:25.590 --> 00:14:30.360
So behind all this is the notion that
we want to ensure that a contiguous

00:14:31.070 --> 00:14:35.920
virtual address range and array is
backed by contiguous physical storage.

00:14:35.970 --> 00:14:38.810
This is kind of the best
situation for the machine.

00:14:40.150 --> 00:14:42.840
We get the full benefit of the L2 cache.

00:14:42.920 --> 00:14:48.420
It turns out the most
salient feature for Mr.

00:14:48.420 --> 00:14:51.520
Goto's BLAS to run
effectively on the platform,

00:14:51.690 --> 00:14:54.260
and often the communication
layers like this too,

00:14:54.260 --> 00:14:57.380
because the pages can be
wired in sequence and sent

00:14:57.380 --> 00:14:59.830
out in just one big hurry.

00:15:00.600 --> 00:15:04.620
So here's a sample
code called HPC memory.

00:15:04.700 --> 00:15:07.600
If you need to get a hold of this,
contact Skip.

00:15:07.850 --> 00:15:09.640
It really comes in two parts.

00:15:09.690 --> 00:15:12.540
There's a kernel extension that
loads when the machine boots.

00:15:12.990 --> 00:15:15.840
It grabs a contiguous extent
of physical memory that you

00:15:15.840 --> 00:15:19.200
can specify using a plist.

00:15:19.430 --> 00:15:23.790
And then there's a user land library
that basically offers five simple

00:15:23.790 --> 00:15:28.970
calls to connect to the KEXT,
get an allocation, free it,

00:15:28.970 --> 00:15:32.530
and check that it's really contiguous.

00:15:32.530 --> 00:15:32.530
So we have

00:15:33.080 --> 00:15:37.030
HBC MemOpen gets us a file
descriptor-like object

00:15:37.130 --> 00:15:38.770
used for accounting.

00:15:38.830 --> 00:15:42.680
We'll close it at the end and then
we'll allocate and free from that.

00:15:42.740 --> 00:15:45.940
Pages obtained this way are contiguous.

00:15:45.940 --> 00:15:50.820
You can double check
using HPC MemCheck config.

00:15:50.890 --> 00:15:54.810
And they should enjoy a
little bit better performance.

00:15:54.860 --> 00:16:01.850
We're seeing single digit
percentages in big numerical codes.

00:16:02.590 --> 00:16:06.420
Okay, so that was the piece
I wanted to talk about,

00:16:06.420 --> 00:16:09.560
and now my esteemed colleague,
Yusuf Abdulghani,

00:16:09.560 --> 00:16:12.350
will come up and tell us about SHARC.

00:16:18.100 --> 00:16:19.440
Hello.

00:16:19.440 --> 00:16:22.070
Steve talked about Shark quite
a bit in his presentation,

00:16:22.070 --> 00:16:24.160
so I'm going to tell you about Shark.

00:16:24.350 --> 00:16:29.590
So, what I would like to do is
start off introducing Shark to

00:16:29.590 --> 00:16:31.800
those who do not know about it.

00:16:31.870 --> 00:16:34.460
And for those who already
know and love Shark,

00:16:34.460 --> 00:16:40.840
we'll be talking about some features that
you can find in the version 4.2 of Shark.

00:16:40.900 --> 00:16:43.550
And then we'll show you how to
get started quickly with Shark.

00:16:43.620 --> 00:16:45.220
It's a very easy to use tool.

00:16:45.540 --> 00:16:48.610
And after that,
I will show you how you can use Shark in

00:16:48.610 --> 00:16:52.580
your HPC or cluster environment,
where you want to profile a

00:16:52.580 --> 00:16:55.790
computer or a node for which
you do not have direct access.

00:16:55.820 --> 00:16:58.650
There is no monitor,
and it's a headless node

00:16:58.650 --> 00:17:00.900
somewhere sitting in a cluster.

00:17:00.960 --> 00:17:02.550
So, what is Shark?

00:17:02.820 --> 00:17:06.780
Well,
Shark is a simple and a fast profiling

00:17:06.850 --> 00:17:09.140
tool that is available on Mac OS X.

00:17:09.320 --> 00:17:12.920
It runs on Tiger as well as on Panther.

00:17:12.980 --> 00:17:15.750
It works with the language
and compilers of your choice.

00:17:15.860 --> 00:17:19.640
So, if you have an application
which is written in C,

00:17:19.640 --> 00:17:24.310
C++, Objective-C, Java, or even Fortran,
you can profile that

00:17:24.310 --> 00:17:27.950
application with Shark,
and it will give you the source

00:17:27.950 --> 00:17:30.060
view for that application.

00:17:30.140 --> 00:17:34.320
And any application compiled
with GCC or Code Warrior or XLC,

00:17:34.390 --> 00:17:39.160
XLF, or even Appsoft, Fortran,
can be profiled using Shark.

00:17:39.210 --> 00:17:42.840
It recognizes both the Mac OS as
well as CFM binary formats,

00:17:42.920 --> 00:17:43.940
Thank you.

00:17:44.220 --> 00:17:47.000
There is a GUI shark available
as well as a command line

00:17:47.000 --> 00:17:49.920
shark for scripting purposes.

00:17:50.620 --> 00:17:54.140
As I said,
it is available with CHAT 4.2 preview.

00:17:54.140 --> 00:17:57.180
You can download it from
developer.apple.com,

00:17:57.180 --> 00:17:59.580
and it is available for free.

00:17:59.840 --> 00:18:02.660
So how do you profile
your application in Shark?

00:18:02.770 --> 00:18:05.840
There are several workflows,
starting from time

00:18:05.840 --> 00:18:10.340
profile to mallet tracing,
Java profiling, counter spreadsheet.

00:18:10.340 --> 00:18:15.340
These are some of, some of these are new
features in Shark 4.2,

00:18:15.370 --> 00:18:18.180
like custom configuration,
counter spreadsheet,

00:18:18.210 --> 00:18:20.560
and network profiling.

00:18:21.430 --> 00:18:23.300
So let's talk about time profile.

00:18:23.330 --> 00:18:27.720
Time profile actually is the most common
workflow that you will use in order to

00:18:27.880 --> 00:18:30.300
profile and optimize your application.

00:18:30.300 --> 00:18:34.120
It exactly shows you where
you're spending most of the time.

00:18:34.120 --> 00:18:41.300
It focuses your attention directly to the
function where most of the time is spent,

00:18:41.300 --> 00:18:44.520
so that you can look at that
function and start optimizing and

00:18:44.520 --> 00:18:46.300
get the best benefit out of it.

00:18:46.300 --> 00:18:49.300
So how does time profile work?

00:18:49.300 --> 00:18:52.300
Well, when you start time
profiling your application,

00:18:52.430 --> 00:18:58.630
Shark stops the system at regular
intervals and records the backtrace,

00:18:58.630 --> 00:19:01.490
the process,
and the thread that's currently running,

00:19:01.490 --> 00:19:04.300
and records it into the profile.

00:19:04.320 --> 00:19:10.260
It has got very low overhead,
and it captures everything from drivers,

00:19:10.260 --> 00:19:12.940
kernels, and application.

00:19:14.020 --> 00:19:20.290
Another new feature in
Shark is malloc tracing.

00:19:20.580 --> 00:19:24.130
This tool actually monitors
allocations and deallocations

00:19:24.130 --> 00:19:26.010
of memory in your application.

00:19:26.100 --> 00:19:30.400
It helps you to understand your memory
usage pattern in the application,

00:19:30.470 --> 00:19:35.900
and it also helps you to visualize
complex applications and see

00:19:35.900 --> 00:19:39.020
where you're spending time,
whether your memory allocations

00:19:39.020 --> 00:19:45.840
are done in how you're allocating
and deallocating memory.

00:19:46.690 --> 00:19:53.600
So, if you have a Java application,
that also can be profiled using Shark.

00:19:53.600 --> 00:19:56.990
And there are three
configurations that you can use,

00:19:56.990 --> 00:20:00.440
including time profiling, ALEC tracing,
and function tracing.

00:20:00.450 --> 00:20:03.950
And you can also view your
Java applications in the code

00:20:03.980 --> 00:20:06.630
browser window for Shark.

00:20:09.200 --> 00:21:01.100
[Transcript missing]

00:21:01.620 --> 00:21:04.270
You can design your own metrics,
for example, these counters,

00:21:04.270 --> 00:21:09.360
and write your own equations to come up
with metrics and see how these metrics

00:21:09.430 --> 00:21:12.120
are behaving in your application.

00:21:13.310 --> 00:21:17.350
This is one of the most requested
features from developers that they

00:21:17.850 --> 00:21:23.810
wanted a very easy way to configure,
to create configurations,

00:21:23.810 --> 00:21:29.260
an easy way to find the performance
monitor counters on all the platforms,

00:21:29.470 --> 00:21:32.100
on all the processors that we have.

00:21:32.140 --> 00:21:37.640
So here, if you just type the word cache
in this particular search window,

00:21:37.670 --> 00:21:42.360
it lists all the events that
are related to cache and shows

00:21:42.360 --> 00:21:46.790
you up in the table view.

00:21:46.880 --> 00:21:50.360
You don't have to specify which
processor you are running it on.

00:21:50.390 --> 00:21:53.280
It automatically detects the
processor that it's running on

00:21:53.540 --> 00:21:57.050
and finds out the events that are
relevant to that processor and

00:21:57.050 --> 00:22:00.490
shows up in this table view for you.

00:22:01.180 --> 00:22:05.530
If you want to get more advanced
features in the profiling,

00:22:05.530 --> 00:22:09.080
you can control each and every
aspect of it by clicking on the

00:22:09.130 --> 00:22:12.550
advanced drop-down menu at the bottom.

00:22:13.490 --> 00:22:18.610
So, let's see how you can use
Shark and get started quickly.

00:22:19.140 --> 00:22:21.770
But before that,
let's try and revisit some of the

00:22:21.770 --> 00:22:23.960
basics of performance analysis.

00:22:24.100 --> 00:22:27.160
So you're using Shark to
analyze your code.

00:22:27.210 --> 00:22:30.250
So the first step is to
establish a baseline.

00:22:30.290 --> 00:22:35.440
It is very important that you come up
with an appropriate workload so that

00:22:35.790 --> 00:22:40.800
the workload is representative and it's
reflective of what you're measuring.

00:22:40.810 --> 00:22:44.000
Then come up with also
a meaningful metric.

00:22:44.150 --> 00:22:48.580
So once you have established a baseline,
then you can go to the second step,

00:22:48.620 --> 00:22:55.780
which is profile optimized deployment
code with debug symbols enabled.

00:22:55.930 --> 00:22:57.250
This is very important.

00:22:57.320 --> 00:23:01.300
If the debug symbols are not enabled,
then...

00:23:01.450 --> 00:23:05.850
We will not be able to actually
get and relate the source code

00:23:05.880 --> 00:23:07.910
in the Shark code browser.

00:23:08.100 --> 00:23:11.500
Secondly, profile your optimized code,
because if you're not

00:23:11.580 --> 00:23:15.500
profiling the optimized code,
you're profiling your debug code.

00:23:15.620 --> 00:23:20.450
You can have two very different profiles
and it might be very misleading.

00:23:20.680 --> 00:23:24.600
So make sure that profile your
optimized and the deployment code.

00:23:24.730 --> 00:23:29.040
And the third step, of course,
is to Shark your application.

00:23:29.180 --> 00:23:32.610
When you start Shark,
it comes up with a very

00:23:32.640 --> 00:23:34.810
simple window like this one.

00:23:34.930 --> 00:23:38.360
There's a one button click,
which is used to start

00:23:38.430 --> 00:23:41.060
and stop your application,
start your profiling,

00:23:41.130 --> 00:23:43.340
and you're on the way.

00:23:44.260 --> 00:23:47.580
By default,
Shark has several configurations.

00:23:47.610 --> 00:23:49.740
Time profile is selected by default.

00:23:49.750 --> 00:23:52.500
The other configurations
include system trace,

00:23:52.500 --> 00:23:54.230
malloc trace, and so on.

00:23:54.310 --> 00:23:57.540
So select what configuration
you want to profile,

00:23:57.580 --> 00:24:00.890
or what you want to use,
and click on the start and stop button.

00:24:00.960 --> 00:24:04.980
We recommend that from
the target dropdown menu,

00:24:05.010 --> 00:24:07.950
you select the system profile.

00:24:08.350 --> 00:24:12.900
We want you to use system profile most
of the time so that it gives you an

00:24:13.050 --> 00:24:17.320
idea of how your application is behaving
with respect to the entire system.

00:24:17.360 --> 00:24:20.590
However, in some cases,
you might not be able to

00:24:20.640 --> 00:24:22.040
use the system profile.

00:24:22.330 --> 00:24:24.590
As an example here,
if you are trying to trace

00:24:24.590 --> 00:24:27.390
your memory allocations,
you might want to just use

00:24:27.390 --> 00:24:31.060
one particular process to look
at your memory allocations.

00:24:31.180 --> 00:24:34.110
The other example is when you
want to do a static analysis

00:24:34.140 --> 00:24:35.940
of your file or a process.

00:24:35.940 --> 00:24:38.040
That's when you would
probably select a file,

00:24:38.040 --> 00:24:41.670
an application,
and do static analysis on that one.

00:24:42.910 --> 00:24:46.990
The SHARC shows up the profile,
the data that is collected

00:24:47.070 --> 00:24:48.400
in this session window.

00:24:48.410 --> 00:24:50.980
By default it shows the heavy view.

00:24:51.310 --> 00:24:55.810
Heavy view actually takes your
code and points you where you're

00:24:56.130 --> 00:24:57.720
spending most of the time.

00:24:57.720 --> 00:25:01.580
In this case about 80% of the time
is spent in this particular function

00:25:01.960 --> 00:25:03.610
called a Cycle True Brain Scaler.

00:25:03.620 --> 00:25:07.430
So it focuses and draws your
attention to the function where

00:25:07.830 --> 00:25:10.080
you're spending most of the time.

00:25:10.080 --> 00:25:14.830
The other view that SHARC also allows you
to look at your code is the Tree View.

00:25:15.010 --> 00:25:18.500
This gives you an idea of your hot paths.

00:25:18.700 --> 00:25:21.000
How did I get to this
particular hot function?

00:25:21.020 --> 00:25:24.270
And then if you want to
look at both the views,

00:25:24.270 --> 00:25:27.410
which function is hot
and how did I get there,

00:25:27.730 --> 00:25:31.690
there's a heavy and a tree view
that you can select at the bottom.

00:25:32.770 --> 00:25:36.370
Once you double-click on a function
which is spending most of the time,

00:25:36.370 --> 00:25:38.100
it opens up the code browser.

00:25:38.140 --> 00:25:43.040
The code browser highlights the
lines of the code with yellow.

00:25:43.180 --> 00:25:45.680
And brighter the yellow,
hotter the code is.

00:25:45.780 --> 00:25:49.200
There's a special gutter on the
right side that you can see,

00:25:49.200 --> 00:25:50.700
which is color-coded.

00:25:50.700 --> 00:25:57.700
So there are horizontal yellow bars which
points to you where is the hot code,

00:25:57.700 --> 00:26:01.700
so that you can easily
navigate to the hot code.

00:26:01.980 --> 00:26:05.700
Once you have identified the hot code,
you might want to edit it.

00:26:05.700 --> 00:26:09.900
So when you can click on the edit button,
as soon as you click on the edit button,

00:26:09.980 --> 00:26:15.700
it opens up Xcode and opens
up your source code in Xcode

00:26:15.700 --> 00:26:18.630
and takes you directly to the
application that you want,

00:26:18.850 --> 00:26:21.570
directly to the line
that you are looking at.

00:26:21.700 --> 00:26:26.280
So this way,
Shark is very well integrated

00:26:26.280 --> 00:26:30.700
with the Xcode IDE and helps
you to reduce the profile.

00:26:30.970 --> 00:26:34.290
profile change, turnaround cycle, a lot.

00:26:36.050 --> 00:26:42.080
So that is Shark in a nutshell,
how to use it and how easy it is to use.

00:26:42.140 --> 00:26:43.060
But what do you do?

00:26:43.060 --> 00:26:47.760
How can you use Shark in an
environment where systems are

00:26:47.820 --> 00:26:49.490
connected over the network?

00:26:49.610 --> 00:26:51.260
So let's look at that.

00:26:51.360 --> 00:26:54.740
Shark actually is your
camera on the cluster.

00:26:54.800 --> 00:26:58.910
You can share your computer for
network profiling using either the

00:26:59.090 --> 00:27:01.300
GUI Shark or the command line Shark.

00:27:01.660 --> 00:27:05.720
You can discover and control the
shared computers using Bonjour,

00:27:05.720 --> 00:27:10.750
that is automatic detection,
or you can add specific IP addresses.

00:27:10.870 --> 00:27:13.620
You can simultaneously
profile multiple machines,

00:27:13.620 --> 00:27:18.230
and you can retrieve profiling session
either automatically or on demand.

00:27:18.390 --> 00:27:19.510
So how do we do that?

00:27:19.820 --> 00:27:22.450
Well,
the first thing that you would do is to

00:27:22.460 --> 00:27:24.860
set up a computer for network profiling.

00:27:25.020 --> 00:27:26.210
There are two ways to do it.

00:27:26.380 --> 00:27:29.370
One way is through the GUI,
and the second way is through

00:27:29.480 --> 00:27:30.760
the command line shark.

00:27:31.030 --> 00:27:36.350
In the network profiling tab,
you would click on the

00:27:36.360 --> 00:27:39.770
radio button which says,
"Share this computer for network

00:27:39.770 --> 00:27:40.950
profiling," and that's it.

00:27:41.090 --> 00:27:48.760
So that particular computer now becomes
ready to be profiled by another computer.

00:27:48.970 --> 00:27:52.800
On the command line you would
probably just say "shark -n"

00:27:52.840 --> 00:27:55.900
and then that computer becomes
ready for network profiling.

00:27:55.980 --> 00:28:01.820
If you look at the profile set,
we are profiling time profile here,

00:28:01.820 --> 00:28:08.900
but you can select whatever profile
you want to and you can set that up.

00:28:09.080 --> 00:28:11.670
Once the computer is set
for network profiling,

00:28:11.670 --> 00:28:16.060
the second step is to actually connect
to that computer and do the profiling,

00:28:16.060 --> 00:28:19.900
either from your laptop or
from your desktop machine.

00:28:20.050 --> 00:28:23.820
The way you do that is click on
the "Control Network Profiling of

00:28:23.820 --> 00:28:25.900
Shared Computers" radio button.

00:28:25.900 --> 00:28:29.020
As soon as you click on that,
all the machines that are

00:28:29.020 --> 00:28:32.900
automatically discovered by
Bonjura show up in the table view.

00:28:32.900 --> 00:28:36.430
You can also add machines by
computer name or IP addresses,

00:28:36.430 --> 00:28:38.900
and they also show up in the table view.

00:28:38.940 --> 00:28:43.010
You can select one or multiple
machines using the check boxes,

00:28:43.010 --> 00:28:46.900
and then from the target drop-down menu,
you can select whether you want

00:28:46.900 --> 00:28:50.900
to target the entire system or
a particular process and so on.

00:28:50.900 --> 00:28:55.520
Once this is all set,
you just click on the "Start" button.

00:28:55.670 --> 00:28:58.950
and StartButton is going
to start profiling,

00:28:59.010 --> 00:29:02.160
start the collection of the
profiles across these multiple

00:29:02.160 --> 00:29:04.280
machines across the network.

00:29:04.350 --> 00:29:08.700
And then all these profiles
come back to your laptop one

00:29:08.700 --> 00:29:11.630
at a time and you can see them.

00:29:11.720 --> 00:29:17.060
Each of these profiling window is
uniquely identified by the IP addresses

00:29:17.280 --> 00:29:21.210
from where you're getting the profile and
the type of profile that you collected.

00:29:21.290 --> 00:29:25.300
You can save these profiles
and analyze them or whatever

00:29:25.300 --> 00:29:26.500
you want to do with this.

00:29:26.640 --> 00:29:31.320
So this is how you will use Shark in
a network or a cluster environment

00:29:31.630 --> 00:29:36.430
in order to gather information about
what's going on on a particular system.

00:29:36.840 --> 00:29:41.800
So in summary,
Shark is very easy for beginners

00:29:41.800 --> 00:29:43.600
and powerful enough for experts.

00:29:43.660 --> 00:29:47.340
It is great for high-level and
low-level performance analysis,

00:29:47.340 --> 00:29:50.550
and it is compatible with
all major Mac OS X compilers.

00:29:50.700 --> 00:29:54.650
It is available for free
from developer.apple.com,

00:29:54.650 --> 00:29:56.700
and it is available today.

00:29:56.700 --> 00:29:59.650
So you can go ahead and try it out
and see how it works out for you.

00:29:59.700 --> 00:30:03.700
One thing that I want to mention about
Shark is that it is a universal binary,

00:30:03.700 --> 00:30:08.190
so if you have got a developer system,
you can give it a shot at that system

00:30:08.200 --> 00:30:10.570
as well and see how you can use it.

00:30:10.700 --> 00:30:14.620
Sessions saved on the developer
system can easily be taken to

00:30:14.730 --> 00:30:18.510
your Power Mac or PowerBook,
and you can view the sessions and

00:30:18.550 --> 00:30:20.700
do the analysis over there as well.

00:30:20.700 --> 00:30:23.940
So that is Shark,
and now I would like to invite

00:30:24.310 --> 00:30:28.700
Rodney Mark from AppSoft to
talk about the FXP technology.

00:30:28.700 --> 00:30:28.700
Thank you.

00:30:37.600 --> 00:30:39.080
From Absoft.

00:30:39.210 --> 00:30:44.500
So our FXP technology is built
on our FX2 serial debugger.

00:30:44.580 --> 00:30:47.740
It debugs Fortran, C and C++.

00:30:47.740 --> 00:30:52.120
We had a lot of customers that
were requesting a low-end beginning

00:30:52.330 --> 00:30:56.850
MPI debugger that would let them
debug their MPI code without having

00:30:56.860 --> 00:30:59.020
to resort to printf-style debugging.

00:30:59.810 --> 00:31:04.800
So we came up with our basic
entry-level MPI debugger.

00:31:04.970 --> 00:31:09.850
It supports debugging 64 and
32-bit codes and serial as well.

00:31:10.100 --> 00:31:14.230
It has the same interface
as our FX2 debugger,

00:31:14.230 --> 00:31:19.930
an aqua-looking interface.

00:31:19.930 --> 00:31:19.930
It has support for Fortran, C, C++,
and Assembler.

00:31:20.240 --> 00:31:22.300
It supports all the major
compiler vendors and

00:31:22.390 --> 00:31:25.960
MPI implementations in one package.

00:31:25.990 --> 00:31:29.500
As an easy to use graphical interface,
you can basically get started without

00:31:29.500 --> 00:31:30.960
even having to read the documentation.

00:31:30.960 --> 00:31:33.580
It's very intuitive.

00:31:33.810 --> 00:31:39.290
You don't have to spend a
lot of time trying to learn

00:31:39.300 --> 00:31:40.960
the MPI debugging paradigm.

00:31:40.960 --> 00:31:42.350
If you're already familiar
with serial debugging,

00:31:42.360 --> 00:31:44.400
it'll translate quite well.

00:31:44.450 --> 00:31:48.550
As I mentioned before,
it builds on our FX2 serial debugger.

00:31:48.920 --> 00:31:52.310
Some of the features we have is
automatically attached to MPI processes.

00:31:52.430 --> 00:31:57.580
So if you're using LAMMPI or MPish,
you'll be able to automatically attach

00:31:57.700 --> 00:32:01.500
to all processes that you've started up,
so you don't have to manually know

00:32:01.500 --> 00:32:04.800
the PIDs or figure out what hosts
you're on or anything like that.

00:32:04.900 --> 00:32:07.280
It lets you view local
and global variables,

00:32:07.280 --> 00:32:10.220
stack traces, registers,
the message queue across

00:32:10.240 --> 00:32:11.800
all your MPI processes.

00:32:11.920 --> 00:32:14.700
It has some visual elements
that let you see the state of

00:32:14.700 --> 00:32:16.800
processes running on your cluster.

00:32:16.800 --> 00:32:19.780
You'll have like green
is everything's good,

00:32:19.800 --> 00:32:20.670
red stops.

00:32:20.800 --> 00:32:25.450
It's very intuitive state mechanisms
that let you see it in an instant

00:32:25.450 --> 00:32:27.780
what's going on with your code.

00:32:27.900 --> 00:32:29.800
It is a basic MPI debugger.

00:32:29.800 --> 00:32:31.730
Like I said,
if you're doing hybrid codes,

00:32:31.730 --> 00:32:34.900
you're using OpenMP,
doing some other things,

00:32:34.910 --> 00:32:37.950
then TotalView is also available.

00:32:38.680 --> 00:32:41.260
So this is a screenshot of FXP.

00:32:41.260 --> 00:32:43.590
It's kind of hard to read,
but it has two windows.

00:32:43.600 --> 00:32:45.900
This is a Fortran code, Hello World.

00:32:46.030 --> 00:32:48.840
You can see in the
left-hand corner there,

00:32:48.840 --> 00:32:53.780
the variables rank and size are shown
across all the nodes in the cluster.

00:32:53.780 --> 00:32:57.830
You can use named groups to
select which variables from which

00:32:57.830 --> 00:33:00.820
nodes you would like to see,
or which ranks.

00:33:00.820 --> 00:33:05.870
It also has-- you can control
which nodes you want to stop,

00:33:05.880 --> 00:33:08.480
which ones you'd like to step through.

00:33:09.450 --> 00:33:10.580
This is showing the name groups.

00:33:10.600 --> 00:33:12.360
You can give them any name you want.

00:33:12.360 --> 00:33:15.560
Whether you have a group,
maybe you want to have ranks one, two,

00:33:15.560 --> 00:33:19.150
and five called like the batch mechanism.

00:33:19.400 --> 00:33:21.400
And you can have whatever
intuitive name you like.

00:33:21.400 --> 00:33:24.670
It has a history mechanism so you
can go back through and easily select

00:33:24.670 --> 00:33:26.800
different groups that you've looked at.

00:33:28.920 --> 00:33:32.140
Some other, if you're,
right now we're in beta,

00:33:32.140 --> 00:33:34.320
so if you'd like to
beta test this for us,

00:33:34.420 --> 00:33:39.240
just contact me or Woodlots,
this is our contact information.

00:33:39.240 --> 00:33:44.570
We'll scale from small number of nodes,
we're targeting 32 nodes,

00:33:44.570 --> 00:33:47.300
so if you have a really
extremely large cluster,

00:33:47.300 --> 00:33:50.140
like a thousand plus nodes,
then we do recommend TotalView.

00:33:50.140 --> 00:33:53.790
So, thank you for your time,
and I think we'll introduce Etnus now.

00:34:05.130 --> 00:34:07.100
Hello.

00:34:07.100 --> 00:34:09.070
I'm Chris Gottbrath from Etnus.

00:34:09.550 --> 00:34:12.230
And I'd like to-- there's a
little bit of a deviation from

00:34:12.230 --> 00:34:13.100
the normal procedure here.

00:34:13.100 --> 00:34:14.900
I really-- I think
it's a very cool thing.

00:34:15.090 --> 00:34:16.410
Apple set this up and
you don't have to take,

00:34:16.470 --> 00:34:18.180
you know, bags of stuff home with you.

00:34:18.420 --> 00:34:22.880
But my sales people sent me
here with like 50 of these.

00:34:23.090 --> 00:34:25.060
So they're back lined up
right near the entrance there.

00:34:25.060 --> 00:34:28.120
So if you're interested in learning
a little bit about TotalView,

00:34:28.120 --> 00:34:29.540
or maybe you aren't going
to use the debugger,

00:34:29.540 --> 00:34:31.170
but you know someone who would,
this would be a great thing to take

00:34:31.240 --> 00:34:32.780
home and just drop on their desk and,
you know,

00:34:32.780 --> 00:34:34.050
you can forget about it after that.

00:34:34.160 --> 00:34:36.060
But this is a nice little
packet of information.

00:34:36.060 --> 00:34:38.060
We have like a quick start guide,
which is a little mini manual.

00:34:38.060 --> 00:34:40.060
Our real manuals are pretty thick.

00:34:40.060 --> 00:34:45.220
And some other information detailing
TotalView in different ways.

00:34:45.220 --> 00:34:45.220
So.

00:34:45.240 --> 00:34:46.760
I apologize for the
plug for the literature,

00:34:46.760 --> 00:34:48.110
but it's back there and
I don't want to carry it home.

00:34:48.200 --> 00:34:51.200
So, okay.

00:34:51.200 --> 00:34:54.200
So, as it says there,
I'm an engineer at Etnus.

00:34:54.210 --> 00:34:59.650
I'm one of the developers of TotalView,
and we're very proud to

00:34:59.650 --> 00:35:03.200
be bringing TotalView,
which has a very long heritage

00:35:03.200 --> 00:35:07.200
of being a parallel debugger,
a debugger for complex code in general,

00:35:07.200 --> 00:35:10.060
on Unix platforms of other varieties.

00:35:10.430 --> 00:35:16.200
We were very excited when Mac OS was
moved over into the Unix world

00:35:16.200 --> 00:35:17.200
when they saw the Unix Lite,
I guess,

00:35:17.200 --> 00:35:21.990
and we were able to take the opportunity
to move TotalView as well and bring

00:35:21.990 --> 00:35:26.070
all of you guys into the-- into,
I guess, our world of debugging.

00:35:26.200 --> 00:35:29.200
So this is--I guess I'll
apologize a little bit in advance.

00:35:29.200 --> 00:35:32.200
This is not--this is an X11 application.

00:35:32.200 --> 00:35:35.200
So we've taken advantage
of the fact that Apple has,

00:35:35.250 --> 00:35:39.390
I think, very wisely allowed people to
bring applications over and

00:35:39.700 --> 00:35:43.920
use the X11 graphics engine as,
you know-- obviously the

00:35:43.920 --> 00:35:47.520
Quartz engine is great,
but this is a way that allows us to bring

00:35:47.520 --> 00:35:50.150
our application very easily over to OS X.

00:35:50.200 --> 00:35:55.200
So it'll look a little bit motif-y,
which, you know, I've had some people

00:35:55.200 --> 00:35:57.320
raise their hand and say,
"Is it always gonna be

00:35:57.320 --> 00:36:00.200
so ugly?" And I was like,
"Well, you know,

00:36:00.260 --> 00:36:04.170
it allowed us to bring the debugger
over," which I think is a nice thing.

00:36:04.200 --> 00:36:06.200
Okay, so what is TotalView?

00:36:06.200 --> 00:36:08.200
I know some people may
be familiar with it,

00:36:08.200 --> 00:36:11.200
but for those who aren't,
TotalView is a source code debugger,

00:36:11.200 --> 00:36:12.200
and it's an application development tool.

00:36:12.200 --> 00:36:14.200
This is not a kernel debugger.

00:36:14.200 --> 00:36:17.200
It's a source code debugger for both
serial and parallel applications.

00:36:17.200 --> 00:36:19.200
I'm mostly focusing here
on parallel applications,

00:36:19.200 --> 00:36:23.200
but some of the complexities that
TotalView can help you out with,

00:36:23.200 --> 00:36:27.140
which are detailed in the little flyer,
you know, are equally appropriate

00:36:27.340 --> 00:36:28.050
for serial debugging.

00:36:28.210 --> 00:36:31.980
For example, threads-- some of the same
concurrency issues that come

00:36:31.980 --> 00:36:35.200
up with parallel debugging of
having lots of things running.

00:36:35.200 --> 00:36:37.200
TotalView's very comfortable
with dealing with that,

00:36:37.240 --> 00:36:39.860
and it'll be very easy to see how
you can transfer what I'm talking

00:36:39.860 --> 00:36:41.190
about into the threads world.

00:36:41.290 --> 00:36:44.710
We handle C, C++, Fortran,
and Fortran 90-- basically

00:36:44.710 --> 00:36:46.170
all the compiled languages.

00:36:46.200 --> 00:36:48.080
Actually,
one of the things that I'm interested

00:36:48.080 --> 00:36:51.200
in for this audience-- I've heard
a lot about Objective-C here,

00:36:51.200 --> 00:36:53.200
and coming from the Unix
world and not the Apple world,

00:36:53.230 --> 00:36:55.150
that's kind of, you know,
that's kind of new for me.

00:36:55.230 --> 00:36:58.740
How many people--is it a ding
against TotalView or a reason

00:36:58.740 --> 00:37:02.160
you wouldn't be able to use it if
it doesn't work with Objective-C?

00:37:02.200 --> 00:37:04.640
How many people is that an
absolute requirement that you need

00:37:04.680 --> 00:37:07.200
to be able to do GUI debugging
for this to be interesting?

00:37:07.200 --> 00:37:10.150
Okay, so a couple of hands,
but not an overwhelming majority.

00:37:10.210 --> 00:37:13.200
Okay, that's really good information
for me to take back.

00:37:13.240 --> 00:37:15.200
We're looking at Objective-C.

00:37:15.220 --> 00:37:17.200
My opinion,
having just barely looked at it,

00:37:17.200 --> 00:37:19.200
looks like it shouldn't
be a problem to support,

00:37:19.200 --> 00:37:21.190
but we don't currently.

00:37:21.200 --> 00:37:25.480
Wide compiler and platform support--
so we've been historically on

00:37:25.480 --> 00:37:31.120
Linux and the Unixes of the world,
the SGIs, the ERIXs, the Crays.

00:37:31.270 --> 00:37:35.150
So one of the nice things for you
if you are bringing applications--

00:37:35.210 --> 00:37:38.050
one of the things that was mentioned
earlier was this idea that if

00:37:38.050 --> 00:37:40.200
you're doing HPC with Apple,
it's likely,

00:37:40.200 --> 00:37:42.260
if you already have the application,
it was already working on

00:37:42.260 --> 00:37:43.200
one of those other platforms.

00:37:43.200 --> 00:37:46.200
If you're doing the porting process,
hopefully it will all just work.

00:37:46.230 --> 00:37:49.350
Maybe they're just performance issues,
but if it doesn't,

00:37:49.350 --> 00:37:52.200
if it crashes due to some idiosyncrasy,
TotalView may be useful.

00:37:52.200 --> 00:37:54.690
You may be able to bring up
TotalView on the Apple and also

00:37:54.690 --> 00:37:58.200
on the previous platform and do
some sort of comparison debugging,

00:37:58.200 --> 00:38:02.200
and you'll have almost exactly the
same feature set in both cases,

00:38:02.200 --> 00:38:03.200
and we think that's a
really important advantage.

00:38:03.200 --> 00:38:07.520
And of course, multi-threaded debugging,
one of the features that makes

00:38:07.520 --> 00:38:10.200
TotalView different is that we
handle multi-threaded debugging,

00:38:10.200 --> 00:38:12.020
even if it's within the context of MPI.

00:38:12.340 --> 00:38:15.850
So especially in the future,
given the fact that Apple is

00:38:15.850 --> 00:38:18.230
moving towards Intel,
and if you look way down

00:38:18.230 --> 00:38:21.200
the road map in Intel,
you see lots of discussion of dual cores

00:38:21.200 --> 00:38:23.200
and hyper-threading and things like that.

00:38:23.200 --> 00:38:27.180
You may want to start taking advantage
of the ability to use threads

00:38:27.200 --> 00:38:27.200
even within an MPI application.

00:38:27.270 --> 00:38:31.200
So TotalView will be there for you
and can handle all that comfortably.

00:38:31.200 --> 00:38:33.800
Distributed debugging, obviously,
is the main thing I'm going to

00:38:33.800 --> 00:38:37.200
be talking about here today,
and cluster architecture.

00:38:37.200 --> 00:38:40.200
And I guess I already mentioned
the idea that we have an X11 GUI.

00:38:40.200 --> 00:38:44.190
We also have a command line interface,
which can allow you to do scripting.

00:38:44.200 --> 00:38:48.200
If you have something that takes,
you know, a scenario to debug, you know,

00:38:48.200 --> 00:38:50.200
one of these sort of hairy
situations that takes,

00:38:50.200 --> 00:38:53.680
you know, 53 steps and three weeks
of run time to set up,

00:38:53.800 --> 00:38:55.200
you know,
hopefully you don't have that situation,

00:38:55.200 --> 00:38:57.200
but if you do, you don't want to be
clicking all the buttons.

00:38:57.210 --> 00:38:59.190
You want to be able to
write a script for it.

00:38:59.220 --> 00:39:02.200
We also use it internally for testing.

00:39:02.200 --> 00:39:06.200
So this is the sort of road map of
things I'm going to talk about today.

00:39:06.200 --> 00:39:10.200
So I've already sort of-- I'll talk
about TotalView as a parallel debugger.

00:39:10.200 --> 00:39:12.200
I've already sort of
introduced it a little bit.

00:39:12.200 --> 00:39:15.010
I'll talk about TotalView's architecture,
which I think is very

00:39:15.010 --> 00:39:16.200
unique and very neat.

00:39:16.200 --> 00:39:18.200
Then I'll do a little live demo,
and in the live demo,

00:39:18.200 --> 00:39:20.200
I'll try and cover automatic
process acquisition,

00:39:20.410 --> 00:39:23.180
parallel debugging features,
and the message queue debugging.

00:39:23.200 --> 00:39:26.200
Finally,
I'll talk a little bit about scalability,

00:39:26.200 --> 00:39:28.710
and then I'll talk a little
bit about our road map bringing

00:39:29.070 --> 00:39:31.020
TotalView to the OS X platform.

00:39:31.200 --> 00:39:35.200
So you can just see a sort of
screenshot over the right of TotalView,

00:39:35.200 --> 00:39:37.200
and I'll be doing a
live demo in a moment,

00:39:37.200 --> 00:39:39.070
so I don't want to
dwell on that too much.

00:39:39.310 --> 00:39:43.200
Okay, so the architecture of TotalView,
we think it's really neat.

00:39:43.250 --> 00:39:46.200
TotalView basically--so
in a cluster situation,

00:39:46.230 --> 00:39:48.200
you're going to have some
number of compute nodes,

00:39:48.200 --> 00:39:51.190
and your job is going to be running
one or more instance of your

00:39:51.190 --> 00:39:54.290
MPI job out on the compute node,
and those are represented by

00:39:54.330 --> 00:39:55.200
the little red boxes there.

00:39:55.200 --> 00:39:59.190
There may or may not be a job
running on the local system

00:39:59.280 --> 00:40:01.200
where you're--the interface node.

00:40:01.200 --> 00:40:04.200
The user is going to start up
TotalView on the front-end node,

00:40:04.370 --> 00:40:07.200
and that's where we're actually
going to do a lot of the analysis,

00:40:07.200 --> 00:40:09.200
the code analysis of the application.

00:40:09.200 --> 00:40:11.700
And then we're going to
start up-- basically,

00:40:11.700 --> 00:40:14.380
you can think of them as debug agents,
little lightweight units of

00:40:14.380 --> 00:40:18.610
TotalView stuff out in the cluster,
and we're going to communicate with that

00:40:18.940 --> 00:40:23.140
separately from the MPI communication,
and those little debug unit--

00:40:23.230 --> 00:40:25.150
sort of agents are going
to live out in the cluster,

00:40:25.200 --> 00:40:28.150
and those are what actually
handle debugging those tasks.

00:40:28.240 --> 00:40:30.200
But all the information is
channeled not through the MPI,

00:40:30.200 --> 00:40:33.200
so we're not messing with
any of the MPI communication,

00:40:33.280 --> 00:40:35.520
through a separate channel back
up to the front end version of

00:40:35.570 --> 00:40:37.900
TotalView that's running in the front.

00:40:38.100 --> 00:40:39.490
So there's sort of two elements.

00:40:39.500 --> 00:40:42.200
There's a main debugger,
the debugger server,

00:40:42.210 --> 00:40:45.260
and they can allow you to debug
even multiple instances of a

00:40:45.260 --> 00:40:48.000
process on each one of the nodes.

00:40:48.190 --> 00:40:51.000
And TotalView starts and
handles those separately.

00:40:51.000 --> 00:40:53.910
What are some of the advantages of
that architecture that make this

00:40:53.910 --> 00:40:58.000
a really neat way of doing things
is that it's very lightweight.

00:40:58.000 --> 00:41:00.000
It's a widely applicable model.

00:41:00.000 --> 00:41:04.000
Almost every cluster is going to have
something where this idea will work.

00:41:04.000 --> 00:41:05.910
Because we stay out
of the way of the MPI,

00:41:05.910 --> 00:41:08.000
we're not going to be messing with that.

00:41:08.000 --> 00:41:10.000
And the debugger
processes run as the user,

00:41:10.000 --> 00:41:11.000
so there's no privilege.

00:41:11.000 --> 00:41:12.430
You don't need to worry
about running these things as

00:41:12.430 --> 00:41:12.980
root or anything like that.

00:41:13.160 --> 00:41:15.750
So this is a robust, scalable mechanism.

00:41:16.100 --> 00:41:18.000
Okay, now enough talking about
it in the abstract.

00:41:18.000 --> 00:41:19.910
Let's show you what this looks like.

00:41:20.070 --> 00:41:24.010
So if we can switch the
screen input to the demo.

00:41:27.300 --> 00:41:34.400
This is TotalView running on G5 here.

00:41:34.540 --> 00:41:37.940
It's just reading the
data off of my PowerBook.

00:41:38.010 --> 00:41:40.400
We're just going to start up.

00:41:40.400 --> 00:41:43.080
I'm going to do the
simplest possible situation.

00:41:43.140 --> 00:41:46.100
I'm not going to try and give a debugging
tutorial here or anything like that.

00:41:46.100 --> 00:41:49.280
I'm just going to give you guys a
chance to see the debugger and to

00:41:49.280 --> 00:41:51.140
see how the user interacts with it.

00:41:51.230 --> 00:41:55.070
If you've been using MPI before,
I apologize, this font here is small,

00:41:55.200 --> 00:41:57.650
but the TotalView font
will be a little bigger.

00:41:57.750 --> 00:42:00.140
I'm actually going to just
do the CPI application.

00:42:00.200 --> 00:42:02.640
It comes included in
MPI-CH as an example.

00:42:02.720 --> 00:42:04.200
I think it's probably even in the LAM.

00:42:04.200 --> 00:42:06.700
It's a very simple,
very standard application.

00:42:06.700 --> 00:42:09.700
Just to show that it can run,
I'm doing an MPI run.

00:42:09.700 --> 00:42:11.360
The way you would run
this in the command line,

00:42:11.400 --> 00:42:14.810
at least, is you'd run an MPI run,
the number of processors argument,

00:42:14.810 --> 00:42:15.910
and then the application.

00:42:16.000 --> 00:42:18.530
Just to show that it runs,
that's the CPI.

00:42:18.700 --> 00:42:22.190
In order to get TotalView into the mix,
you're going to have to use a little

00:42:22.190 --> 00:42:23.140
bit of a different syntax here.

00:42:23.230 --> 00:42:25.200
This is an MPI-specific thing.

00:42:25.200 --> 00:42:25.200
I'm having to be using MPI-CH.

00:42:25.200 --> 00:42:27.540
With LAM, it may be a little bit
different if you're using

00:42:27.540 --> 00:42:28.200
some other MPI in the future.

00:42:28.200 --> 00:42:30.180
There may be a slightly
different invocation syntax here,

00:42:30.240 --> 00:42:34.480
but the idea is it's a very
small tweak on what you would do

00:42:34.480 --> 00:42:35.200
normally to start the application.

00:42:35.200 --> 00:42:38.400
In this case, I just added a "-tv" flag.

00:42:38.420 --> 00:42:41.190
That has to do with the
architecture of MPI-CH.

00:42:41.200 --> 00:42:44.190
The MPI has to actually start us.

00:42:44.200 --> 00:42:48.200
We throw in the "-tv" flag,
and then you get the TotalView windows.

00:42:48.200 --> 00:42:50.200
TotalView starts two windows.

00:42:50.230 --> 00:42:51.200
This has to do with the fact
that we're running a total view.

00:42:51.270 --> 00:42:54.200
The total view is really designed
to handle multiple processes.

00:42:54.200 --> 00:42:57.330
This left window here,
as we get into the demo, you'll see,

00:42:57.330 --> 00:42:59.180
serves as a navigation point.

00:42:59.210 --> 00:43:03.200
There's going to be one item in
this left window here per process.

00:43:03.200 --> 00:43:05.100
You'll be able to see feedback.

00:43:05.200 --> 00:43:09.110
The right window, on the other hand,
is your focus on one process.

00:43:09.200 --> 00:43:14.160
In the usage model I'll do here,
we'll be able to refocus

00:43:14.220 --> 00:43:16.200
this right window very easily
from different processes.

00:43:16.200 --> 00:43:19.250
It gives you the idea that
you're debugging a process,

00:43:19.270 --> 00:43:21.660
and that process may have other friends,
which may do some of the same things

00:43:21.660 --> 00:43:23.200
or not do some of the same things.

00:43:23.200 --> 00:43:25.200
You can see what's going
on with the root window,

00:43:25.200 --> 00:43:27.520
but you're controlling everything
through a very familiar one

00:43:27.520 --> 00:43:30.200
process debugging window.

00:43:30.200 --> 00:43:32.200
This has all the features
you'd expect to see,

00:43:32.200 --> 00:43:33.140
a go button, a halt button.

00:43:33.200 --> 00:43:36.190
Once I get into things,
there's going to be stack trace

00:43:36.190 --> 00:43:37.190
and source code down here.

00:43:37.200 --> 00:43:39.200
Let me switch this to processes.

00:43:39.200 --> 00:43:42.430
In order to get things started,
what are some of the challenges the

00:43:42.480 --> 00:43:46.200
debugger has to handle to really
make debugging on MPI comfortable?

00:43:46.200 --> 00:43:49.200
One of the things is that an MPI program
is not just a single process.

00:43:49.200 --> 00:43:53.200
It's a bunch of processes running
on a distributed set of processors,

00:43:53.220 --> 00:43:55.140
a distributed set of computers.

00:43:55.200 --> 00:43:58.410
One of the things that could be
potentially very painful would be finding

00:43:58.410 --> 00:44:01.190
out where all those processes are,
attaching debuggers to them,

00:44:01.200 --> 00:44:03.080
and dealing with the feedback.

00:44:03.200 --> 00:44:05.170
What TotalView does is it makes
that all very transparent.

00:44:05.200 --> 00:44:07.200
You just start the MPI process.

00:44:07.200 --> 00:44:10.500
We'll get some notification here
that TotalView recognized the thing

00:44:10.590 --> 00:44:12.110
that was starting is a parallel job.

00:44:12.200 --> 00:44:16.110
Then we have an interaction with the
MPI where we get some information

00:44:16.200 --> 00:44:18.200
about where that job is running.

00:44:18.210 --> 00:44:21.200
The question here is really asking,
do you want to stop the job now?

00:44:21.200 --> 00:44:23.200
The reason it's asking that is
you may want to set breakpoints.

00:44:23.200 --> 00:44:26.310
Remember that the application I'm running
on right now is a little demo app,

00:44:26.310 --> 00:44:28.200
and it will exit almost immediately.

00:44:28.200 --> 00:44:29.800
If I said no,
we would just run to completion before

00:44:29.800 --> 00:44:31.180
I had a chance to click anything else.

00:44:31.200 --> 00:44:33.200
I want to say yes.

00:44:33.200 --> 00:44:36.200
That startup question
there is configurable.

00:44:36.200 --> 00:44:38.190
You may actually want a
little bit more control.

00:44:38.200 --> 00:44:41.190
You may want to debug a subset
of a larger application.

00:44:41.200 --> 00:44:44.150
That's the basic behavior.

00:44:44.200 --> 00:44:47.200
I can go into the preferences and
change things so that when it launches,

00:44:47.200 --> 00:44:50.060
I get a list of all the processes,
and I can choose which

00:44:50.120 --> 00:44:51.200
ones I want to attach to.

00:44:51.200 --> 00:44:53.160
The nice thing is that's
not a final decision.

00:44:53.240 --> 00:44:55.200
I can start off just debugging
a couple of processes.

00:44:55.200 --> 00:44:57.460
Then I can run the application
for a little while and look

00:44:57.460 --> 00:44:59.200
at the communication and see
what the problems may be,

00:44:59.200 --> 00:45:01.200
and then attach to
other processes as I go.

00:45:01.240 --> 00:45:05.210
That's one behavior there,
but there are lots of wrinkles

00:45:05.210 --> 00:45:07.200
and other possibilities.

00:45:07.200 --> 00:45:10.080
Now I've run into the
application a little bit.

00:45:10.300 --> 00:45:13.810
What's happened here behind the
scenes is that the application

00:45:13.810 --> 00:45:16.190
launched three other processes.

00:45:16.200 --> 00:45:18.070
In this case, locally, but they could be.

00:45:18.210 --> 00:45:21.200
This would have been
equally easy in a cluster.

00:45:21.200 --> 00:45:24.800
In this case, this says host local,
but in a cluster,

00:45:24.800 --> 00:45:26.200
this would just have the list of hosts.

00:45:26.200 --> 00:45:28.200
You'd have all the processes
that were part of this job.

00:45:28.200 --> 00:45:31.200
You'd be attached to them
wherever they are in the cluster.

00:45:31.200 --> 00:45:32.190
They each have their rank.

00:45:32.220 --> 00:45:36.180
This comes from the MPI rank
that's associated with the process,

00:45:36.250 --> 00:45:38.050
and then the debugger assigns
a separate ID to each one.

00:45:38.320 --> 00:45:40.200
What I've done here is
I've branched out this.

00:45:40.330 --> 00:45:43.140
TotalView, I mentioned earlier,
handles threads as well,

00:45:43.200 --> 00:45:45.200
and particularly it handles
threads along with MPI.

00:45:45.200 --> 00:45:48.200
You could easily imagine
writing an application,

00:45:48.210 --> 00:45:52.200
or even your MPI implementation might do
some stuff with threads to handle I/O.

00:45:52.200 --> 00:45:55.240
You can imagine that your
application might be made up of

00:45:55.280 --> 00:45:58.080
a number of different processes,
each of which has multiple threads.

00:45:58.460 --> 00:46:02.750
TotalView would handle that by having
one process item here and then all

00:46:02.900 --> 00:46:06.170
the threads that are part of it
under this tree structure here.

00:46:06.200 --> 00:46:08.700
In this case,
I'm just showing that this is an

00:46:08.700 --> 00:46:13.270
application that has four processes,
and they're each made up of one thread.

00:46:13.600 --> 00:46:17.730
Um, okay, in this case-- let me just
show you a little-- uh,

00:46:17.740 --> 00:46:19.500
read for you here the statuses.

00:46:19.500 --> 00:46:21.500
This is saying that the first
process is at a breakpoint.

00:46:21.500 --> 00:46:24.180
These other processes have a
status of "T," which means--which

00:46:24.180 --> 00:46:25.500
comes from debugger terminology.

00:46:25.500 --> 00:46:28.360
It's the word--it stands for
"traced." They're stopped,

00:46:28.410 --> 00:46:31.280
but they're not stopped at
a particular breakpoint.

00:46:31.520 --> 00:46:33.500
You'll also see a green "R"
here when they're running,

00:46:33.500 --> 00:46:35.500
uh, and you'll see, you know,
they'll switch to breakpoints.

00:46:35.740 --> 00:46:38.520
Once we get to user set breakpoints,
they'll have breakpoint

00:46:38.530 --> 00:46:39.500
numbers and things.

00:46:39.500 --> 00:46:41.450
So this, again,
is the sort of navigation point

00:46:41.600 --> 00:46:44.080
that you'll see in the back place
where you'll see what's going on

00:46:44.080 --> 00:46:45.500
with the processes in the cluster.

00:46:45.500 --> 00:46:47.500
Over here we have the process window.

00:46:47.500 --> 00:46:49.430
It's focused on one of the processes.

00:46:49.580 --> 00:46:51.500
In this case,
the first process gives us a stack trace.

00:46:51.500 --> 00:46:53.480
All these, uh,
things are configurable here.

00:46:53.620 --> 00:46:55.460
You can see the stack trace.

00:46:55.530 --> 00:46:57.500
We can click back to main.

00:46:57.500 --> 00:47:01.500
You can see all the local variables, um,
and in this case, we're--we've currently

00:47:01.500 --> 00:47:03.500
stopped at the end of MPI-NIT.

00:47:03.500 --> 00:47:05.500
Remember,
the program had to run a little bit,

00:47:05.570 --> 00:47:07.500
create the parallel job.

00:47:07.500 --> 00:47:12.690
That's what it's completed doing,
or it's in the middle of doing, Thanks.

00:47:12.930 --> 00:47:15.800
This interaction should be very familiar
with you if you've used other debuggers.

00:47:15.800 --> 00:47:18.630
You know,
we don't think our-- what we're trying to

00:47:18.660 --> 00:47:22.800
do is actually give a nice interaction,
a very familiar interaction that handles

00:47:22.800 --> 00:47:24.710
all the complexities of parallelism here.

00:47:24.810 --> 00:47:26.800
But, you know,
the basic paradigms are very--

00:47:26.860 --> 00:47:28.780
should be very familiar.

00:47:28.850 --> 00:47:30.800
So I've set two breakpoints.

00:47:30.850 --> 00:47:32.800
Now, in a serial debugger,
setting those two breakpoints

00:47:32.820 --> 00:47:34.800
has a very unambiguous meaning.

00:47:35.010 --> 00:47:36.730
Program runs.

00:47:36.810 --> 00:47:38.800
When the program gets to the breakpoint,
the program stops.

00:47:38.840 --> 00:47:41.800
In a parallel application,
what is it that you want to have happen?

00:47:41.800 --> 00:47:44.800
'Cause remember, the parallel application
is four processes,

00:47:44.800 --> 00:47:46.800
each of which is running separately.

00:47:46.800 --> 00:47:48.800
Any one of those could
hit that breakpoint.

00:47:48.800 --> 00:47:50.100
And what do you--how do you--

00:47:52.130 --> 00:47:58.580
Mike Cutout, oh, it's back.

00:47:58.580 --> 00:47:59.900
What do you want to have happen
in that case when any one of those

00:47:59.900 --> 00:47:59.900
processes hits that breakpoint?

00:47:59.900 --> 00:47:59.900
Do you want it to--

00:48:00.000 --> 00:48:03.240
You want it to stop that individual
process on its own and leave the

00:48:03.240 --> 00:48:06.490
rest of the simulation running,
or the application running,

00:48:06.500 --> 00:48:08.000
or do you want it to stop
the entire application?

00:48:08.000 --> 00:48:13.210
And those are two very rational choices,
and you may, in the debugging session,

00:48:13.230 --> 00:48:14.980
you may want both at
different points in time.

00:48:15.010 --> 00:48:18.000
By default, TotalView,
this actually is a change recently,

00:48:18.000 --> 00:48:20.000
by default, TotalView stops just
the individual process.

00:48:20.000 --> 00:48:21.970
That's almost always what you want.

00:48:21.970 --> 00:48:24.000
The meaning there is you'll
have everything will line up.

00:48:24.000 --> 00:48:28.080
If you set the breakpoint in a line
that all the processes go through,

00:48:28.080 --> 00:48:29.000
obviously if you set it
off in an if statement,

00:48:29.000 --> 00:48:33.100
it won't work, but if all the processes
do reach this breakpoint,

00:48:33.100 --> 00:48:34.880
they will all line up at that breakpoint.

00:48:35.040 --> 00:48:36.960
So it allows you to sort of synchronize.

00:48:37.070 --> 00:48:39.000
Often we've found what people want to do.

00:48:39.000 --> 00:48:42.000
They want to sort of synchronously
move their application through

00:48:42.000 --> 00:48:44.940
so they can have a clear idea of
what the application is doing.

00:48:45.170 --> 00:48:46.930
They imagine that that's what
happens when they run it,

00:48:47.000 --> 00:48:50.000
and for the most part they
may or may not be right,

00:48:50.000 --> 00:48:52.000
but when they're debugging,
that at least gives you a clear state.

00:48:52.000 --> 00:48:55.110
So you'll maybe want to bring the whole
application to a particular point,

00:48:55.240 --> 00:48:58.000
and then you might want to take one
process and run it ahead or something.

00:48:58.020 --> 00:49:01.420
So setting the breakpoint by default,
we're going to just

00:49:01.540 --> 00:49:02.990
stop that one process.

00:49:03.000 --> 00:49:05.400
But if you wanted to
do something different,

00:49:05.400 --> 00:49:06.990
you have that capability.

00:49:07.000 --> 00:49:10.060
So what I did was I brought
up the sort of properties

00:49:10.060 --> 00:49:13.940
dialogue for that breakpoint,
and I have the first choice it gives

00:49:13.950 --> 00:49:17.000
me here is what do I want to have
stop when the breakpoint gets hit.

00:49:17.000 --> 00:49:19.390
I could choose the group,
choose the process,

00:49:19.400 --> 00:49:20.990
or I could choose the thread.

00:49:21.000 --> 00:49:24.000
So in this case,
process is almost always what you want,

00:49:24.000 --> 00:49:27.000
and you can say, "Okay,
so let me now let the

00:49:27.000 --> 00:49:29.580
application"-- Okay,
so just like setting the breakpoint

00:49:29.580 --> 00:49:33.160
has a degree of freedom that's
new in parallel debugging that's

00:49:33.180 --> 00:49:35.290
not there in serial debugging,
also the basic commands,

00:49:35.320 --> 00:49:38.280
the go and the halt and the step,
those have a degree

00:49:38.280 --> 00:49:40.000
of freedom that's new.

00:49:40.000 --> 00:49:41.680
And the question is,
when I click go here,

00:49:41.680 --> 00:49:42.970
what do I want to have happen?

00:49:43.000 --> 00:49:48.000
I'm focused right now on the rank zero,
this first process here.

00:49:48.000 --> 00:49:51.130
Do I want to have just that one process
run and leave the other ones stopped,

00:49:51.130 --> 00:49:53.000
or do I want to launch them all?

00:49:53.000 --> 00:49:56.000
And the way you control that is
there's a scope selector here.

00:49:56.260 --> 00:49:59.000
Which has a couple of different options.

00:49:59.110 --> 00:50:00.860
It's got the process you're looking at.

00:50:01.080 --> 00:50:03.990
It's got the thread that we're focused on
a particular thread within the process.

00:50:04.000 --> 00:50:07.050
In this case, the thread and the process
obviously have the same meaning,

00:50:07.060 --> 00:50:09.000
but in a multi-threaded application,
that wouldn't be true.

00:50:09.020 --> 00:50:10.940
And then there's several
different groups.

00:50:11.040 --> 00:50:13.000
For this application,
they all sort of have the same meaning.

00:50:13.050 --> 00:50:15.000
So group control means all the processes.

00:50:15.100 --> 00:50:16.980
So if I hit go,
they should all start running.

00:50:17.000 --> 00:50:19.480
What you should look for is you
should see the statuses over here

00:50:19.480 --> 00:50:22.000
all changed to green R's as they run.

00:50:22.000 --> 00:50:23.190
And then they should all,
at their own time,

00:50:23.190 --> 00:50:24.970
they should get around to getting
to the breakpoint and stop.

00:50:25.060 --> 00:50:29.000
You'll also see the feedback occurs
down here in the process list.

00:50:29.150 --> 00:50:32.000
So hit go.

00:50:32.000 --> 00:50:34.000
They all ran.

00:50:34.000 --> 00:50:35.000
It was too fast to see.

00:50:35.000 --> 00:50:37.000
You didn't see the little green R's,
but they were there for a moment

00:50:37.000 --> 00:50:39.760
if it updated in that time.

00:50:40.110 --> 00:50:42.000
And they all ran to the breakpoint.

00:50:42.000 --> 00:50:44.000
And so you can see the
nice thing is the feedback.

00:50:44.000 --> 00:50:45.950
You can all probably read this already.

00:50:46.000 --> 00:50:47.960
These are all sitting
at the same breakpoint.

00:50:48.000 --> 00:50:50.000
You maybe don't know
which breakpoint two is,

00:50:50.000 --> 00:50:50.000
but you know they're all at the same one.

00:50:50.000 --> 00:50:53.000
And you can see which one it
is here with the little arrow.

00:50:53.000 --> 00:50:54.000
And if I bring up this, you know,
there's a couple different things here.

00:50:54.000 --> 00:50:57.000
There's a couple different things
that this bottom pane can display.

00:50:57.000 --> 00:50:57.930
And one of them is action points.

00:50:58.010 --> 00:51:00.000
It gives you the number, the line number.

00:51:00.000 --> 00:51:04.250
And you can zoom to these if these
happen to be over in other code

00:51:04.250 --> 00:51:07.000
segments and control them from here.

00:51:07.200 --> 00:51:09.000
Okay, so I've run all my processes.

00:51:09.000 --> 00:51:10.980
What I've done here is I've synchronized
now my parallel application.

00:51:11.000 --> 00:51:14.180
It was no harder than just running
a normal serial application

00:51:14.270 --> 00:51:15.960
to a particular breakpoint.

00:51:16.000 --> 00:51:20.000
But, you know, there was a lot more going
on under the covers here.

00:51:20.000 --> 00:51:22.000
We see a stack trace that makes sense.

00:51:22.000 --> 00:51:22.960
We're in main.

00:51:23.080 --> 00:51:25.000
We've got variables that make sense.

00:51:25.000 --> 00:51:27.380
If you're an MPI programmer,
one of the things that you

00:51:27.380 --> 00:51:29.000
expect to see here is my ID.

00:51:29.000 --> 00:51:32.090
If I were to dive on that,
that's the term we use in

00:51:32.090 --> 00:51:35.000
our documentation for get
more information about.

00:51:35.000 --> 00:51:38.740
We'd see that the ID for the
first process is indeed zero.

00:51:39.000 --> 00:51:40.980
If you want to,
one of the things you can do that's kind

00:51:40.980 --> 00:51:45.990
of neat in TotalView is when you have a
multi-- we have a variable which exists.

00:51:46.040 --> 00:51:48.000
A lot of MPI applications
are what's called SIMD,

00:51:48.000 --> 00:51:50.000
single instruction multiple data.

00:51:50.000 --> 00:51:52.000
A lot of times you have code like
this where everybody has an ID.

00:51:52.000 --> 00:51:54.000
And you're kind of--you might
sometimes be interested in

00:51:54.010 --> 00:51:54.990
what are all the different IDs.

00:51:55.000 --> 00:51:58.270
One thing you could do
is you can get--basically

00:51:58.270 --> 00:51:58.920
make an array out of these.

00:51:59.010 --> 00:52:04.060
So this now constructs an array where
the values of the array are the IDs in

00:52:04.110 --> 00:52:06.000
each one of the different processes.

00:52:07.460 --> 00:52:10.560
Another way you could have done
that is you could actually go here.

00:52:10.560 --> 00:52:13.720
We could actually navigate to
the next process if we want to,

00:52:13.740 --> 00:52:15.770
and look at the separately on ID.

00:52:16.180 --> 00:52:17.640
We could also go here.

00:52:17.640 --> 00:52:19.960
This is one of these things
where there's gonna be several

00:52:19.960 --> 00:52:22.710
ways to do it in the interface,
but they all have the same meaning.

00:52:22.720 --> 00:52:24.270
We've switched which
process we're focused on.

00:52:24.280 --> 00:52:26.980
Now we're focused on rank three,
this one down here.

00:52:26.980 --> 00:52:30.220
And again,
if we were to look at the ID here,

00:52:30.260 --> 00:52:31.150
that'll have a value of three.

00:52:31.200 --> 00:52:33.520
I don't even need to dive,
I can just read it right there.

00:52:33.810 --> 00:52:36.390
So the kind of point I'm trying to
get across here is that the interface

00:52:36.440 --> 00:52:39.210
is really not that hard to use,
but that it's doing a

00:52:39.210 --> 00:52:41.440
lot behind the scenes,
doing the important stuff for you here.

00:52:41.440 --> 00:52:42.840
In this case it's just four processes.

00:52:42.840 --> 00:52:44.860
You probably could launch
four different debuggers here.

00:52:44.900 --> 00:52:46.630
But imagine if you had 16 or 32.

00:52:46.630 --> 00:52:51.140
You want an interface like this that
brings everything down into one window.

00:52:51.410 --> 00:52:52.900
Actually, it doesn't have to bring
it down into one window.

00:52:52.900 --> 00:52:54.440
You might want to actually
do comparison debugging.

00:52:54.440 --> 00:52:57.400
If you do,
let me get the right window here,

00:52:57.420 --> 00:53:00.090
you can actually bring up two of these.

00:53:00.210 --> 00:53:01.760
We don't think you probably
ever want more than two,

00:53:01.760 --> 00:53:04.140
but you might want to compare what's
going on in two different processes.

00:53:04.160 --> 00:53:06.140
And TotalView is perfectly
happy to let you do that.

00:53:06.140 --> 00:53:08.240
So what I did there was
I chose a different rank,

00:53:08.240 --> 00:53:11.140
and I asked TotalView to bring
up a new window focused on that.

00:53:11.140 --> 00:53:12.790
Again,
with TotalView the underlying engine is

00:53:12.790 --> 00:53:15.330
attached to all of them all the time,
but you may or may not

00:53:15.330 --> 00:53:17.140
want more than one window.

00:53:17.140 --> 00:53:18.130
Okay.

00:53:18.130 --> 00:53:20.640
That's the basic
functionality process control.

00:53:20.640 --> 00:53:24.630
I talked about wanting to sometimes
control an individual process.

00:53:24.630 --> 00:53:25.640
Let me just demonstrate that.

00:53:25.640 --> 00:53:27.640
I think everyone sort of understands
what's going to happen here.

00:53:27.730 --> 00:53:29.640
If I run this one process,
it's going to run.

00:53:29.640 --> 00:53:31.640
The other ones are not.

00:53:31.640 --> 00:53:34.540
So that one,
I saw it flicker for a moment to green,

00:53:34.630 --> 00:53:36.140
and it's now sitting at
breakpoint number three.

00:53:36.140 --> 00:53:37.640
That's this one here.

00:53:37.640 --> 00:53:40.630
We were again,
the rank ID is reported there,

00:53:40.840 --> 00:53:41.640
rank three.

00:53:41.640 --> 00:53:43.570
So rank three was the one
that we were focused on,

00:53:43.740 --> 00:53:44.630
and it ran ahead.

00:53:44.640 --> 00:53:46.100
So it's now at breakpoint number three.

00:53:46.220 --> 00:53:47.500
It's a little bit further down.

00:53:47.640 --> 00:53:49.800
I can now,
another thing you might want to do,

00:53:49.800 --> 00:53:53.000
just sort of going through things
that you might reasonably want

00:53:53.000 --> 00:53:53.640
to do in a debugging session.

00:53:53.640 --> 00:53:55.530
I'm now holding this process.

00:53:55.640 --> 00:53:57.140
So it says held.

00:53:57.140 --> 00:53:59.020
I went to the process
menu here and said hold.

00:53:59.220 --> 00:54:02.130
And now this process,
it also is reflected over here,

00:54:02.210 --> 00:54:04.630
is not going to go if
I tell the other ones to go.

00:54:04.640 --> 00:54:08.030
So now I can issue a command
to the entire group and say go.

00:54:08.140 --> 00:54:09.140
This one will not move.

00:54:09.140 --> 00:54:11.130
The other ones will all
catch up to where it is.

00:54:11.140 --> 00:54:13.120
So now they're all caught up.

00:54:13.150 --> 00:54:15.140
I've resynchronized
my group of processes.

00:54:15.140 --> 00:54:19.650
So what this is giving,
so the debugger is still going

00:54:19.650 --> 00:54:22.140
to be used in the same way
that you use a debug normally.

00:54:22.140 --> 00:54:24.450
It's just that there are lots
more degrees of freedom to what

00:54:24.740 --> 00:54:27.130
you might want to do when you
have a parallel application.

00:54:27.140 --> 00:54:28.620
And you want a debugger that
makes that really fairly easy.

00:54:28.640 --> 00:54:30.040
Okay.

00:54:30.100 --> 00:54:33.640
So what I've talked about now,
up till now,

00:54:33.640 --> 00:54:35.630
are mostly process acquisition.

00:54:35.640 --> 00:54:38.640
You know, basically it's no big
deal with TotalView.

00:54:38.640 --> 00:54:41.640
And basic debugging functionality
that everyone sort of expects to see.

00:54:41.640 --> 00:54:43.130
They want to see if they
can set breakpoints.

00:54:43.150 --> 00:54:45.130
They want to see if they
can control their process.

00:54:45.140 --> 00:54:47.140
They want to see if they
can look at variables.

00:54:47.140 --> 00:54:48.640
So I've tried to cover those bases.

00:54:48.710 --> 00:54:50.140
If anybody has any
questions about any details,

00:54:50.140 --> 00:54:51.140
I probably shouldn't handle them now.

00:54:51.140 --> 00:54:52.900
Maybe you can come up afterwards
and I can walk you through the

00:54:52.900 --> 00:54:56.140
demo and you can tell me to push
buttons and see if it crashes.

00:54:56.140 --> 00:54:58.140
What I want to talk about now
is something that's really,

00:54:58.140 --> 00:54:59.640
kind of specific to MPI.

00:54:59.640 --> 00:55:02.640
Sort of a failure mode that can
occur in a serial application.

00:55:02.660 --> 00:55:05.080
And that is a communication
pattern mismatch.

00:55:05.260 --> 00:55:08.140
So, you know, without doing a little
mini lecture on MPI,

00:55:08.140 --> 00:55:12.140
in MPI one of the things you can do is
you can pass a message from a process,

00:55:12.140 --> 00:55:17.500
a rank, it's called in MPI parlance,
to another rank with a particular ID.

00:55:17.640 --> 00:55:19.640
And, you know,
there's some built-in constructs

00:55:19.640 --> 00:55:21.140
like send to everybody.

00:55:21.140 --> 00:55:22.640
And you use those a lot of times.

00:55:22.640 --> 00:55:24.140
But sometimes,
especially as you're tuning,

00:55:24.140 --> 00:55:27.410
you get to the point where you want
to have really fine-grained control

00:55:27.410 --> 00:55:27.640
of where you're passing the messages.

00:55:27.640 --> 00:55:30.690
And anytime the user
has that kind of power,

00:55:30.690 --> 00:55:31.640
they have the ability to screw it up.

00:55:31.640 --> 00:55:32.620
Right?

00:55:32.640 --> 00:55:36.640
So, you can get in this failure mode
where your program is running,

00:55:36.640 --> 00:55:39.640
all the processes have done the
work that they were given to do,

00:55:39.640 --> 00:55:41.640
but they've passed messages
to the wrong place.

00:55:41.640 --> 00:55:43.640
Or a message didn't arrive
or something like that.

00:55:43.660 --> 00:55:46.070
And the thing is that MPI is designed
to be very forgiving of that.

00:55:46.150 --> 00:55:48.140
Because there's all these big
latencies and things like that.

00:55:48.140 --> 00:55:51.290
So the program, there won't be any, like,
segmentation fault that

00:55:51.290 --> 00:55:52.130
occurs because of that.

00:55:52.190 --> 00:55:55.770
Everything will, you know,
the wrong receiving process will accept

00:55:55.890 --> 00:55:57.140
the message and stick it in its pocket.

00:55:57.160 --> 00:55:59.140
And it just won't ever look at it.

00:55:59.280 --> 00:56:03.140
And so, because there's no segfault,
there's no sort of obvious failure,

00:56:03.140 --> 00:56:05.070
the program just sort
of grinds to a halt.

00:56:05.610 --> 00:56:08.140
Everybody is waiting for
something from somebody.

00:56:08.140 --> 00:56:10.910
In that case, it's very,
very difficult to debug without a

00:56:10.910 --> 00:56:14.140
little bit of help from the debugger.

00:56:14.140 --> 00:56:16.140
So I'm going to show how that works.

00:56:16.140 --> 00:56:18.140
And I'm actually going to simulate it
in this application by just holding it.

00:56:18.290 --> 00:56:20.070
That one that I held earlier,
I'm just going to leave it held.

00:56:20.140 --> 00:56:21.990
So it's never going to
run beyond this point.

00:56:22.150 --> 00:56:23.140
That's the thing.

00:56:23.140 --> 00:56:26.640
I'm just sort of sticking my thumb on
this process and not allowing it to go.

00:56:26.640 --> 00:56:29.640
And I'm going to now tell
the rest of the group to run.

00:56:29.660 --> 00:56:31.640
And actually,
let me disable this breakpoint here.

00:56:31.640 --> 00:56:33.640
They're going to run down
here into this MPIReduce,

00:56:33.640 --> 00:56:34.640
which is a collective operation.

00:56:34.640 --> 00:56:37.640
They're all supposed to exchange
information back and forth.

00:56:37.640 --> 00:56:40.610
And I'm going to use that to
show you how this is a deadlock,

00:56:40.660 --> 00:56:41.610
just like what I described.

00:56:41.640 --> 00:56:44.020
In this case, I've done it by
simulating it by sticking,

00:56:44.110 --> 00:56:46.640
you know, sticking my thumb on one of
the processes so it won't run.

00:56:46.640 --> 00:56:48.370
And telling all the others
to do a collective where

00:56:48.370 --> 00:56:49.640
everybody has to participate.

00:56:49.720 --> 00:56:52.630
So since one of the guys isn't playing,
he isn't participating,

00:56:52.630 --> 00:56:53.640
it actually deadlocks.

00:56:53.640 --> 00:56:55.640
So these are all running.

00:56:55.640 --> 00:56:58.400
They would continue to run
all night if I left it.

00:56:58.470 --> 00:57:00.510
But what I'd like to do is actually

00:57:01.100 --> 00:58:31.900
[Transcript missing]

00:58:32.290 --> 00:58:37.550
0, meanwhile, was expecting a message
from 2 with a tag of 11,

00:58:37.970 --> 00:58:42.250
and 2 was expecting a message
from 3 with a tag of 11.

00:58:42.280 --> 00:58:46.470
So whose fault is this is
actually really easy to work out.

00:58:46.480 --> 00:58:49.740
You just sort of walk back the arrows
in the case of a receive queue,

00:58:49.740 --> 00:58:53.260
and even if I didn't know what
I had just done to cause this,

00:58:53.360 --> 00:58:56.350
I would be able to read this and say,
I'm pretty sure that what I need

00:58:56.350 --> 00:58:59.280
to look at is why 3 hasn't
gotten around to delivering to 2,

00:58:59.280 --> 00:59:01.100
because then probably
2 would deliver to 0,

00:59:01.100 --> 00:59:03.120
and 0 would deliver to 1,
and I'd be done.

00:59:03.160 --> 00:59:08.430
So this gives you a graphical way to get
at this sort of new sort of error state,

00:59:08.450 --> 00:59:10.060
which is possible in an MPI application.

00:59:10.060 --> 00:59:13.800
We think that's really kind
of nifty and handy and cool.

00:59:13.800 --> 00:59:17.080
And obviously,
this scales up quite a bit.

00:59:17.080 --> 00:59:20.540
I mean, I'm only doing 4 here,
but you can imagine 32 or 64,

00:59:20.540 --> 00:59:23.140
you'd still be able to, you know,
and you can actually

00:59:23.140 --> 00:59:25.620
move these guys around,
you could still sort of unwind,

00:59:25.650 --> 00:59:27.100
and the nice thing is you
can do it sort of graphically

00:59:27.100 --> 00:59:28.020
right there in front of you.

00:59:28.540 --> 00:59:29.860
Unwind these things,
and you'll get something

00:59:29.860 --> 00:59:30.640
that looks like a tree.

00:59:30.640 --> 00:59:32.340
Somebody's responsible,
and everybody else is waiting,

00:59:32.340 --> 00:59:34.770
or something that looks like a circle,
and that tells you that

00:59:34.770 --> 00:59:36.780
you've got a deadlock where
everybody's waiting on somebody,

00:59:36.780 --> 00:59:37.530
but no one's going to start.

00:59:37.710 --> 00:59:40.760
So this is, I think,
a really neat and very powerful

00:59:40.760 --> 00:59:44.860
sort of graphical way of debugging
this sort of new class of error that

00:59:44.880 --> 00:59:46.880
can occur with parallel debugging,
or parallel programming.

00:59:48.430 --> 00:59:51.580
And of course I would resolve that
in this case by just unholding that

00:59:51.590 --> 00:59:55.340
process and allowing everybody to run,
which I can do.

00:59:55.340 --> 00:59:59.170
But in general you'd probably
have to go in and edit code.

00:59:59.300 --> 01:00:29.600
[Transcript missing]

01:00:35.800 --> 01:00:36.960
Can I switch back to the slides?

01:00:37.000 --> 01:00:37.640
Okay, thanks.

01:00:37.640 --> 01:00:40.660
Okay,
so these couple slides were actually

01:00:40.660 --> 01:00:43.680
my insurance policy in case the demo
didn't come off for some reason.

01:00:43.680 --> 01:00:45.420
They couldn't sync with
the screen or something.

01:00:45.420 --> 01:00:47.880
So these slides actually kind of cover
the stuff I've just talked about.

01:00:47.940 --> 01:00:51.310
It talks about process acquisition,
some of the capabilities,

01:00:51.320 --> 01:00:55.140
parallel debugging features,
talks a little bit about, you know,

01:00:55.140 --> 01:00:57.810
the point I was trying to emphasize
is that it's really a nice,

01:00:57.810 --> 01:01:00.970
clean GUI which gives you the power
to deal with this extra complexity.

01:01:00.980 --> 01:01:03.260
And then the message queue graph.

01:01:03.470 --> 01:01:05.220
This is just a different
message queue graph.

01:01:05.380 --> 01:01:06.280
I thought I updated that slide.

01:01:06.300 --> 01:01:06.800
Okay.

01:01:06.800 --> 01:01:11.760
That was supposed to be
an Apple boundary there.

01:01:11.760 --> 01:01:15.780
You saw, like,
some sort of Linux desktop.

01:01:15.800 --> 01:01:16.750
I apologize.

01:01:16.760 --> 01:01:18.370
Same functionality,
but you already saw it.

01:01:18.640 --> 01:01:19.940
Okay, scalability.

01:01:19.940 --> 01:01:22.430
This is something I can't really talk
about from the little demo of four

01:01:22.430 --> 01:01:23.910
processes running on the same machine.

01:01:23.920 --> 01:01:26.080
TotalView has been
around and in the market,

01:01:26.080 --> 01:01:29.410
in the high-performance computing market,
for over 15 years.

01:01:29.430 --> 01:01:31.260
I think it's actually now up to 17 years.

01:01:31.300 --> 01:01:34.000
We originally started with BBM Butterfly,
which was actually one of the

01:01:34.030 --> 01:01:36.720
first actual implementations
-- kind of a buggy one,

01:01:36.720 --> 01:01:39.180
as I understand it -- but one of
the first actual implementations

01:01:39.260 --> 01:01:42.480
of a distributed parallel computer.

01:01:42.500 --> 01:01:44.410
So we've been doing this for a long time.

01:01:44.420 --> 01:01:47.580
And what that means for you
guys is that this code base,

01:01:47.630 --> 01:01:49.080
which has been around
for this period of time,

01:01:49.080 --> 01:01:51.820
has been stress-tested by lots
of other people ahead of you.

01:01:51.820 --> 01:01:55.570
So we've had people kicking
the tires for a long time.

01:01:55.580 --> 01:02:00.850
And little internal things like how
do you handle displaying -- I didn't

01:02:00.880 --> 01:02:04.430
even talk about displaying an array,
but TotalView has the ability to give

01:02:04.430 --> 01:02:04.740
you a nice little bit of information.

01:02:04.760 --> 01:02:05.930
It gives you a nice view of an array.

01:02:05.980 --> 01:02:08.250
If you have a million
elements in your array,

01:02:08.260 --> 01:02:09.910
but you just want to kind of
look at the first couple things,

01:02:09.910 --> 01:02:13.080
the first -- the easiest thing that a
debugger developer probably would do

01:02:13.080 --> 01:02:15.340
is they would go get all that data,
put it in a buffer,

01:02:15.340 --> 01:02:16.430
and then they draw the window.

01:02:16.650 --> 01:02:20.880
Well, when that involves a thousand
processes distributed over a network

01:02:20.880 --> 01:02:23.310
and a million elements which might
be on various different processes,

01:02:23.320 --> 01:02:24.720
that's going to be a slow operation.

01:02:24.740 --> 01:02:26.560
So we don't do that.

01:02:26.660 --> 01:02:30.340
You know, somebody else has already beat
us up over the head about that.

01:02:30.350 --> 01:02:33.230
And we have very efficient mechanisms
for little things like that.

01:02:33.240 --> 01:02:34.610
So you're going to find that
TotalView is a very efficient system.

01:02:34.620 --> 01:02:34.680
So you're going to find that
TotalView is a very efficient system.

01:02:34.720 --> 01:02:40.620
TotalView scales out very comfortably in
terms of performance and responsiveness,

01:02:40.620 --> 01:02:42.900
in terms of memory usage,
if your application is likely to

01:02:42.900 --> 01:02:45.370
be very huge if you're buying,
you know, some sort of large cluster.

01:02:45.380 --> 01:02:49.070
TotalView is going to very efficiently
build up the data structures it

01:02:49.080 --> 01:02:52.560
needs to hold the information about
your debugger or about your process.

01:02:52.560 --> 01:02:55.040
Status and data representation,
all these things have already

01:02:55.040 --> 01:02:56.760
been stressed out by other people.

01:02:56.760 --> 01:03:00.880
Now, that's not to say that there aren't
challenges that we're working on in

01:03:00.880 --> 01:03:05.800
that area and we're continuing to
innovate and change and grow the product.

01:03:05.930 --> 01:03:08.770
But, you know,
you shouldn't have something that

01:03:08.840 --> 01:03:12.450
sort of doesn't scale past 64,
doesn't scale past 32.

01:03:12.500 --> 01:03:15.350
Practical scalability,
you should have no problem

01:03:15.440 --> 01:03:18.320
with tens to 100 processes,
pretty much trivially.

01:03:18.320 --> 01:03:20.900
It's not going to be
any kind of major lag.

01:03:21.320 --> 01:03:23.890
Thousands of processors,
you do have to wait a little

01:03:23.900 --> 01:03:25.910
while while we gather the
information over the network.

01:03:26.100 --> 01:03:30.510
So we do have customers who are
using TotalView on 2,000 processes,

01:03:30.510 --> 01:03:32.060
3,000 processes.

01:03:32.060 --> 01:03:34.440
And they give us a hard time
about how long it takes to do it.

01:03:34.440 --> 01:03:37.180
You know, a synchronized step or
something like that.

01:03:37.200 --> 01:03:38.990
But, you know,
there are other people who are doing

01:03:38.990 --> 01:03:40.270
that and we're responding to them.

01:03:40.310 --> 01:03:43.100
So you shouldn't have
a problem at 50 or 100.

01:03:43.100 --> 01:03:46.260
And it's an ongoing concern of ours.

01:03:46.260 --> 01:03:50.270
Just to talk about, you know,
other architectures,

01:03:50.360 --> 01:03:52.780
we're actually on the Blue Gene machine,
which has targets of

01:03:52.780 --> 01:03:54.160
10,000s of processes.

01:03:54.160 --> 01:03:57.660
And so, you know,
I don't want to talk about that here

01:03:57.660 --> 01:03:58.460
because it's not really relevant.

01:03:58.460 --> 01:04:00.990
But, you know, that is an architecture
we have to support.

01:04:01.060 --> 01:04:03.700
Okay, so Atmos TotalView releases.

01:04:04.340 --> 01:04:06.640
We're actually a fairly small company.

01:04:06.640 --> 01:04:11.940
And we have a fairly ambitious sort
of roadmap for each given year.

01:04:11.940 --> 01:04:15.380
We have two major releases and
then also four minor releases.

01:04:15.500 --> 01:04:16.200
And why is that?

01:04:16.200 --> 01:04:18.040
I actually had some of the
Apple guys giving me a hard time

01:04:18.040 --> 01:04:19.420
about that at a lunch the other day.

01:04:19.460 --> 01:04:22.450
And the real reason is because we
have a bunch of different platforms.

01:04:22.460 --> 01:04:24.620
People are releasing compilers.

01:04:24.620 --> 01:04:26.400
We handle a huge number of compilers.

01:04:26.420 --> 01:04:28.670
We're releasing new compilers,
new operating system

01:04:28.670 --> 01:04:29.740
versions all the time.

01:04:29.740 --> 01:04:33.440
And we really need to spin a new
version often to those things.

01:04:34.370 --> 01:04:39.290
In terms of major features coming in,
we really have the two main releases.

01:04:39.300 --> 01:04:42.510
So TotalView 7 is the one that
we're about ready to release.

01:04:42.610 --> 01:04:43.670
We're in a beta period right now.

01:04:43.680 --> 01:04:46.720
And then TotalView 7 something,
I'm not sure what the name will be,

01:04:46.720 --> 01:04:49.670
will be out about supercomputing
time at the end of third quarter,

01:04:50.130 --> 01:04:51.330
beginning of fourth.

01:04:53.060 --> 01:04:56.560
Okay, that's the overall roadmap,
where we're at in versions

01:04:56.560 --> 01:04:57.340
and what we're doing.

01:04:57.340 --> 01:05:00.280
The Mac OS is what you guys care about.

01:05:00.320 --> 01:05:01.260
We're currently in the beta.

01:05:01.260 --> 01:05:06.100
We're really excited to have some
people testing TotalView on the Apple.

01:05:06.100 --> 01:05:08.670
We're actually,
I think that if anyone was

01:05:08.670 --> 01:05:11.340
really excited out of this group,
I can probably still squeeze you in.

01:05:11.340 --> 01:05:13.990
We only have a couple of weeks left,
but certainly feel free to come up

01:05:13.990 --> 01:05:16.830
and talk to me afterwards if you'd
really like to go and kick the tires

01:05:16.830 --> 01:05:18.090
of this even before we do release.

01:05:18.100 --> 01:05:19.710
But the release will be
within a couple of weeks,

01:05:19.720 --> 01:05:21.210
probably before the end of this month.

01:05:22.700 --> 01:05:25.820
Support will be for
both Tiger and Panther.

01:05:25.820 --> 01:05:31.080
We will be supporting...
We don't support Xcode,

01:05:31.080 --> 01:05:33.080
as you can tell from the GUI.

01:05:33.190 --> 01:05:35.130
We're not an Xcode plug-in
or anything like that.

01:05:35.400 --> 01:05:38.280
But I said here we support Xcode
because we support the compilers

01:05:38.280 --> 01:05:39.360
that you can use with Xcode.

01:05:39.360 --> 01:05:42.510
So you can still build with an Xcode,
but then you take the application and

01:05:42.510 --> 01:05:43.620
you run TotalView on the application.

01:05:43.620 --> 01:05:47.530
So we support the Apple GCC builds,
the AppSoft compilers,

01:05:47.600 --> 01:05:51.640
and the IBM Excel compilers,
both for Fortran and C.

01:05:52.320 --> 01:05:56.040
And we support Xgrid, again,
the same sort of idea because

01:05:56.040 --> 01:05:59.450
we support the underlying MPIs,
which Xgrid is built on, which is,

01:05:59.450 --> 01:06:01.430
I understand, MPI-CH and LAN.

01:06:01.440 --> 01:06:03.890
So we've been working with both
those MPI vendors for a long time.

01:06:03.900 --> 01:06:06.680
Heap memory debugging,
I actually didn't sort of talk about,

01:06:06.690 --> 01:06:08.870
but in your flyers or in
the little folders you'll

01:06:08.910 --> 01:06:10.060
see the really neat feature.

01:06:10.060 --> 01:06:12.440
We're really excited about
it for our other platforms.

01:06:12.440 --> 01:06:14.940
And it's something we'd
love to bring to Apple.

01:06:14.940 --> 01:06:18.720
And if it's something that you guys need,
if you need a heap debugger,

01:06:18.720 --> 01:06:21.940
a memory debugger for Apple,
that sort of feedback is great,

01:06:22.030 --> 01:06:23.420
because I can take that back
to our product management.

01:06:23.420 --> 01:06:26.620
But it's something we're currently
sort of analyzing to see whether

01:06:26.620 --> 01:06:29.230
the architecture we have on the
other Unix platforms is going to be

01:06:29.230 --> 01:06:30.300
able to be ported over to Darwin.

01:06:30.300 --> 01:06:31.520
I think it will be.

01:06:31.520 --> 01:06:32.200
I'm pretty confident.

01:06:32.200 --> 01:06:34.660
And hearing from you guys that
it's something you need will help

01:06:34.660 --> 01:06:36.160
me accelerate that time scale.

01:06:36.160 --> 01:06:40.660
And obviously,
Intel Darwin was a surprise to me

01:06:40.660 --> 01:06:41.980
as much as it was to everyone else.

01:06:42.020 --> 01:06:44.060
So I don't have a really strong story.

01:06:44.060 --> 01:06:46.270
I know we're talking to Apple,
we're talking to Skip,

01:06:46.280 --> 01:06:49.570
and we're going to watch and see how
well this release does to see whether

01:06:49.590 --> 01:06:51.190
we'll be able to support Intel Darwin.

01:06:51.670 --> 01:06:54.710
I'm pretty confident that it'll happen,
because I'm enthusiastic and hopeful

01:06:54.800 --> 01:06:58.380
that lots of people will be wanting
to go out and get TotalView for

01:06:58.540 --> 01:07:00.350
their power Darwin as well.

01:07:00.360 --> 01:07:05.940
So finally, do feel free to take home
those folders back there.

01:07:05.940 --> 01:07:10.230
And we're currently in the beta,
so if you go to Etnis' website,

01:07:10.310 --> 01:07:11.980
you won't see a whole lot
of discussion about Apple.

01:07:11.980 --> 01:07:14.130
Contact me if you want
to get in right now.

01:07:14.140 --> 01:07:16.690
We will have a release
before the end of the month,

01:07:16.770 --> 01:07:18.100
which is 7.0.

01:07:18.100 --> 01:07:19.320
That's going to have support for Apple.

01:07:19.320 --> 01:07:21.290
And at that point,
you'll be able to go to the website

01:07:21.300 --> 01:07:24.220
and get a 15-day free trial,
fully featured version of TotalView.

01:07:24.220 --> 01:07:26.640
The only thing is you can't
run it on a 64-node machine.

01:07:26.640 --> 01:07:28.060
It's limited to eight processors.

01:07:28.060 --> 01:07:29.460
But that's the only limitation.

01:07:29.570 --> 01:07:30.460
All the other features are there.

01:07:30.460 --> 01:07:34.160
You can kick the tires, send us feedback,
let us know,

01:07:34.160 --> 01:07:35.160
and then hopefully send us a check.

01:07:35.200 --> 01:07:38.250
Contact sales at etnis.com
for that last operation.

01:07:38.320 --> 01:07:40.040
If you have any technical support,
feedback,

01:07:40.040 --> 01:07:44.610
you need to tell us that X11 isn't
good enough and we really need to move

01:07:44.610 --> 01:07:47.990
over to the Apple interface standards,
that's great feedback.

01:07:48.050 --> 01:07:51.030
Send that to support at
etnis.com or to me individually.

01:07:51.380 --> 01:07:52.730
So I'd love to hear that feedback.

01:07:52.740 --> 01:07:53.940
So that's it.

01:07:53.950 --> 01:07:57.780
I want to allow my co-presenters up here
on the stand so we can take questions,

01:07:57.780 --> 01:07:58.300
and I'm done.

01:07:58.300 --> 01:07:59.240
Thanks a lot for your attention.

01:07:59.240 --> 01:07:59.340
Thank you.