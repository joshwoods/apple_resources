# Wwdc2022 10127

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Create parametric 3D room scans with RoomPlanRoomPlan can help your app quickly create simplified parametric 3D scans of a room. Learn how you can use this API to easily add a room scanning experience. We'll show you how to adopt this API, explore the 3D parametric output, and share best practices to help your app get great results with every scan.ResourcesCreate a 3D model of an interior room by guiding the user through an AR experienceRoomPlanHD VideoSD VideoRelated VideosWWDC23Explore enhancements to RoomPlanTech TalksWhat's new for enterprise developersWWDC22Explore USD tools and renderingQualities of great AR experiencesWWDC22 Day 2 recap

RoomPlan can help your app quickly create simplified parametric 3D scans of a room. Learn how you can use this API to easily add a room scanning experience. We'll show you how to adopt this API, explore the 3D parametric output, and share best practices to help your app get great results with every scan.

Create a 3D model of an interior room by guiding the user through an AR experience

RoomPlan

HD VideoSD Video

HD Video

SD Video

Explore enhancements to RoomPlan

What's new for enterprise developers

Explore USD tools and rendering

Qualities of great AR experiences

WWDC22 Day 2 recap

Search this video…♪ (Mellow instrumental hip-hop music) ♪♪Praveen Sharma: Hi. My name is Praveen,and I'm from the Prototyping team here at Apple.Kai Kang: Hi. My name is Kaiand I'm from the Video Engineering team.Praveen: Over the past few years Apple has enabledpowerful new ways for people to bring the world into their apps.Last year, we introduced Object Capture,which takes in photos of real-world objects,and using the Photogrammetry API in RealityKit,turns them into a 3D model ready for use in your app.Previous to Object Capture,we released the Scene Reconstruction APIwhich gives you a coarse understandingof the geometric structure of your spaceand enables brand-new augmented reality use casesin your apps.This year, we are very excited to announcea brand-new framework called RoomPlan.RoomPlan allows you to scan your roomusing your LiDAR-enabled iPhone or iPad.It generates a parametric 3D model of the roomand its room-defining objects which you can use in your app.Let's take a look at what a RoomPlan scanning experiencelooks like.RoomPlan uses sophisticated machine learning algorithmspowered by ARKit to detect walls, windows, openings,and doors, as well as room-defining objectslike fireplaces, couches, tables, and cabinets.With our RoomCaptureView API,which uses RealityKit to render scanning progress in real time,you can easily integrate a scanning experienceinto your app.And when you are finished scanning,RoomCaptureView presents the final post-processed resultsfor you to use however best fits your use case.For the first time, without the complexities of implementingmachine learning and computer vision algorithms,people can now interact with their room in brand new ways.For example, interior design apps can previewwall color changes and accurately calculatethe amount of paint required to repaint a room.Architecture apps can now easily allow someone to previewand edit changes to their room's layout in real time.Real estate apps can now seamlessly enable agentsto capture floor plans and 3D models of a listing.And e-commerce apps can engage customersthrough product visualization in their physical spaces.These are just a few examples of applications RoomPlan enables,and you'll be surprised to see how simple it isto integrate RoomPlan into your app.Let's take a look.There are two main ways you can use RoomPlan.The first is our out-of-the-box scanning experiencewhich allows you to seamlessly integrate RoomPlaninto your app.The second is our data API which enables your appto use the live parametric data from a scanhowever best suits your use case.With both of these APIs, we recommend some best practicesto help you achieve the best possible scan results,which we'll go over in the last section of this presentation.First, let's talk about the scanning experiencethat you can bring into your appusing our new RoomCaptureView API.RoomCaptureView is a UIView subclassthat you can easily place in your app.It handles the presentation of world space scanning feedback,real-time room model generation,as well as coaching and user guidance.Let's take a closer look at the design elementspresented during a RoomCaptureView-based scan.During an active RoomCaptureView session,animated lines outline detected walls, windows, openings,doors, and room-defining objects in real time.The interactive 3D model generated in real timeat the bottom of the RoomCaptureView,gives you an overview of your scanning progress at a glance.Finally, text coaching guides youto the best possible scanning results.Let's take a look at how you can start using RoomCaptureViewin just four easy steps.First, we create a RoomCaptureView referencein our ViewController.Second, we create a referenceto our RoomCaptureSession configuration object.Third, we start our scan session,passing in our configurationto the capture session's run function.And finally, our application tells the capture sessionto stop scanning.Optionally, your app can adhere to our RoomCaptureViewDelegateprotocol and opt out of post-processed resultsand their presentationor handle the post-processed scan resultsonce they have been presented.For example, you can export a USDZ of the resultsby calling the export function availableon the provided CapturedRoom data struct.And that's how simple it is to integrate RoomPlaninto your app.We are so excited to see what you make with this API.Now my colleague Kai will talk about RoomCaptureSessionand RoomPlan's Data API.Kai: Thanks, Praveen.In this section, we will walk you through the Data APIsthat provide you the access to the underlying data structuresduring scanning and can help you build a custom visualizationof the scanning experience from ground up.The basic workflow consists of three parts:scan, process, and export.For scanning, we will cover the basics of how to set upand start the capture session,as well as display and monitor the capture process.Then we'll look at how your scanned data is processedand the final model is received for presentation.Finally, we'll discuss how you can generate and exportthe output USD file which can also be usedin your USD workflows.Now, let's look into the Scan step in detail.We will use the RoomCaptureSession APIto set up the session and display the progressas we continue scanning.Let me show you in code.Here's a simple RealityKit app as an example.To start, simply import RoomPlan into your Swift project.In the ViewController of your app,you can have a custom type to visualize the resultsand to initiate a RoomCaptureSession instance.Additionally, RoomCaptureSession provides a handleto the underlying AR session so that your apps can draw planesand object bounding boxes in the AR view.RoomCaptureSession adopts the delegate pattern.In your ViewController class,you can assign the ViewController itselfas the captureSession's delegate.This would allow the ViewControllerto get real-time updates from the RoomCaptureSession.Theses updates include 3D models and instructionsin order to guide people during the capture.To get these updates, your ViewControllerneeds to conform to the RoomCaptureSessionDelegateprotocol and implement two methods.The first one iscaptureSession(_ session: didUpdate room:) methodin order to get the real-time CapturedRoom data structure.Your visualizer can use it to update AR view of the 3D model,which provides real-time feedback to peopleon the progress.We will dive into the CapturedRoom structuremore in a later part of the talk.This method will be called when we detect updatesto the captured room.The second method iscaptureSession(_ session: didProvide instruction:).This method provides you with an instruction structurewhich contains real-time feedback.Your visualizer can use the instructionto guide people during the scan.Let's go through the instructionsthat this API provides.These instructions include distance to the objects,scanning speed, lighting adjustment to the room,as well as focusing on specific areas of the roomthat have more textures.These instructions will be provided during the scanin order to guide people with real-time feedback.Next, we will move on to the process part.In this section, we will use the RoomBuilder classto process the scanned data and generate the final 3D models.To process the captured data, the first step is to initiatea RoomBuilder instance in your ViewController class.Next, in order to receive the sensor dataafter the capture process, your app needs to implementthe captureSession(_ session: didEndWith data: error:) method.When the RoomCaptureSession is stopped, by callingthe stop() function in your app, or due to an error,this function will be called to return a CaptureRoomData objectand an optional error.Finally, to process the captured data,we call the roomBuilder's async roomModel(from:) methodwith the await keyword.The method runs asynchronously to process the scanned dataand build the final 3D model.It utilizes the Swift async/await functionthat we introduced in last year's WWDC.Within just a few seconds, the model will be availablefor the final presentation in your app.Now, let's dive into the detailsof the CapturedRoom data structureand how you can export it to use in your app.At the top level, there is CapturedRoomwhich consists of Surfaces and Objects.Surface contains unique attributes to represent curvessuch as radius; starting and ending angles;four different edges of the surface;and architecture categories of wall, opening, window, door.Object contains furniture categoriessuch as table, bed, sofa, etc.Surface and Object share some common attributessuch as dimensions;confidence, which gives you three levels of confidencefor the scanned surface or object;the 3D transform matrix; as well as a unique identifier.Let's see how they are represented in code.The CapturedRoom structure is a fully parametric representationof the elements in the room.It contains five properties including walls, openings,doors, windows, and objects in the room.For the first four elements,they are represented as the Surface structurewhich represents 2D planar architectural structures.On the right, you can see the various propertiesof Surface we covered earlier.The last property is an array of 3D objects in the room,and they are represented as cuboids.On the right, you can see the various properties of Object.Here is the list of object types we support in RoomPlan.These include a variety of common furniture typessuch as sofa, table, chair, bed, and many more.Finally, the export function allows you to exportthis CapturedRoom into a USD or USDZ datafor your existing workflows.Here is an example to show how you can directly openthe USD output in Cinema 4Dto browse and edit the hierarchical data structureof the room, as well as the dimensions and locationof each room element or object.You can also leverage your existing USD and USDZ workflowsto add renders of the captured roominto a variety of applications such as real estate, e-commerce,utilities, and interior design.So far, we covered the scanning experienceand underlying RoomPlan APIs.We'll now go through some best practicesto help you get good results with RoomPlan.We will cover the recommended conditionsthat allow for a good scan,room features to look out for while selecting a room,as well as a few scanning and thermal considerationsto keep in mind.RoomPlan API supports most common architectural structuresand objects in a typical household.It works best for a single residential roomwith a maximum room size of 30 feet by 30 feetor around 9 by 9 meters.Lighting is also important for the APIto get a clear video stream and good AR tracking performance.A minimum 50 lux or higher is recommended for using the API,which is typical for a family living room at night.For the hardware, RoomPlan API is supported on allLiDAR-enabled iPhone and iPad Pro models.There are some special conditionsthat can present a challenge for the API.For example, full-height mirrors and glass pose a challengefor the LiDAR sensor to produce the expected output.Even high ceilings could exceed the limit of the scanning rangeof the LiDAR sensor.Also, very dark surfaces could be hard for the device to scan.There are some considerations to get better scanning results.First, for applications that have high accuracy requirements,preparing the room before scanningcan enhance the quality of the scan.For example, opening the curtainscan let more natural light in and reduce window occlusions,which works best for daytime scans.Closing the doors can reduce the chanceof scanning unnecessary area outside of the room.Following a good scanning motion is also very importantto achieving good scanning results with the API.And that is why we provide the user instruction delegate methodin order to provide feedback on textures, distance, speed,and lighting conditions to people during the scans.Another thing to keep in mindis battery and thermals of the device.We have done many optimizations on RoomPlan APIto ensure a good scanning experience.Nevertheless, it's best to avoid repeated scansor single long scans over 5 minutes.These could not only cause fatiguebut also drain out the battery and create thermal issueswhich might in turn impact the user experience of your app.There is a lot that we covered today.We introduced a brand-new API, RoomPlan.It provides an intuitive scanning experienceto capture your rooms,powerful machine learning models to understand the environment,as well as a fully parametric USD output formatfor easy integration in your apps.For guidance on how to better design and implementyour new RoomPlan experience,please check out the related talks below.Praveen: It's time for you to try RoomPlan in your app.We can't wait to see what you can create with this new API.Kai: Thanks for watching!♪

♪ (Mellow instrumental hip-hop music) ♪♪Praveen Sharma: Hi. My name is Praveen,and I'm from the Prototyping team here at Apple.

Kai Kang: Hi. My name is Kaiand I'm from the Video Engineering team.

Praveen: Over the past few years Apple has enabledpowerful new ways for people to bring the world into their apps.

Last year, we introduced Object Capture,which takes in photos of real-world objects,and using the Photogrammetry API in RealityKit,turns them into a 3D model ready for use in your app.

Previous to Object Capture,we released the Scene Reconstruction APIwhich gives you a coarse understandingof the geometric structure of your spaceand enables brand-new augmented reality use casesin your apps.

This year, we are very excited to announcea brand-new framework called RoomPlan.

RoomPlan allows you to scan your roomusing your LiDAR-enabled iPhone or iPad.

It generates a parametric 3D model of the roomand its room-defining objects which you can use in your app.

Let's take a look at what a RoomPlan scanning experiencelooks like.

RoomPlan uses sophisticated machine learning algorithmspowered by ARKit to detect walls, windows, openings,and doors, as well as room-defining objectslike fireplaces, couches, tables, and cabinets.

With our RoomCaptureView API,which uses RealityKit to render scanning progress in real time,you can easily integrate a scanning experienceinto your app.

And when you are finished scanning,RoomCaptureView presents the final post-processed resultsfor you to use however best fits your use case.

For the first time, without the complexities of implementingmachine learning and computer vision algorithms,people can now interact with their room in brand new ways.

For example, interior design apps can previewwall color changes and accurately calculatethe amount of paint required to repaint a room.

Architecture apps can now easily allow someone to previewand edit changes to their room's layout in real time.

Real estate apps can now seamlessly enable agentsto capture floor plans and 3D models of a listing.

And e-commerce apps can engage customersthrough product visualization in their physical spaces.

These are just a few examples of applications RoomPlan enables,and you'll be surprised to see how simple it isto integrate RoomPlan into your app.

Let's take a look.

There are two main ways you can use RoomPlan.

The first is our out-of-the-box scanning experiencewhich allows you to seamlessly integrate RoomPlaninto your app.

The second is our data API which enables your appto use the live parametric data from a scanhowever best suits your use case.

With both of these APIs, we recommend some best practicesto help you achieve the best possible scan results,which we'll go over in the last section of this presentation.

First, let's talk about the scanning experiencethat you can bring into your appusing our new RoomCaptureView API.

RoomCaptureView is a UIView subclassthat you can easily place in your app.

It handles the presentation of world space scanning feedback,real-time room model generation,as well as coaching and user guidance.

Let's take a closer look at the design elementspresented during a RoomCaptureView-based scan.

During an active RoomCaptureView session,animated lines outline detected walls, windows, openings,doors, and room-defining objects in real time.

The interactive 3D model generated in real timeat the bottom of the RoomCaptureView,gives you an overview of your scanning progress at a glance.

Finally, text coaching guides youto the best possible scanning results.

Let's take a look at how you can start using RoomCaptureViewin just four easy steps.

First, we create a RoomCaptureView referencein our ViewController.

Second, we create a referenceto our RoomCaptureSession configuration object.

Third, we start our scan session,passing in our configurationto the capture session's run function.

And finally, our application tells the capture sessionto stop scanning.

Optionally, your app can adhere to our RoomCaptureViewDelegateprotocol and opt out of post-processed resultsand their presentationor handle the post-processed scan resultsonce they have been presented.

For example, you can export a USDZ of the resultsby calling the export function availableon the provided CapturedRoom data struct.

And that's how simple it is to integrate RoomPlaninto your app.

We are so excited to see what you make with this API.

Now my colleague Kai will talk about RoomCaptureSessionand RoomPlan's Data API.

Kai: Thanks, Praveen.

In this section, we will walk you through the Data APIsthat provide you the access to the underlying data structuresduring scanning and can help you build a custom visualizationof the scanning experience from ground up.

The basic workflow consists of three parts:scan, process, and export.

For scanning, we will cover the basics of how to set upand start the capture session,as well as display and monitor the capture process.

Then we'll look at how your scanned data is processedand the final model is received for presentation.

Finally, we'll discuss how you can generate and exportthe output USD file which can also be usedin your USD workflows.

Now, let's look into the Scan step in detail.

We will use the RoomCaptureSession APIto set up the session and display the progressas we continue scanning.

Let me show you in code.

Here's a simple RealityKit app as an example.

To start, simply import RoomPlan into your Swift project.

In the ViewController of your app,you can have a custom type to visualize the resultsand to initiate a RoomCaptureSession instance.

Additionally, RoomCaptureSession provides a handleto the underlying AR session so that your apps can draw planesand object bounding boxes in the AR view.

RoomCaptureSession adopts the delegate pattern.

In your ViewController class,you can assign the ViewController itselfas the captureSession's delegate.

This would allow the ViewControllerto get real-time updates from the RoomCaptureSession.

Theses updates include 3D models and instructionsin order to guide people during the capture.

To get these updates, your ViewControllerneeds to conform to the RoomCaptureSessionDelegateprotocol and implement two methods.

The first one iscaptureSession(_ session: didUpdate room:) methodin order to get the real-time CapturedRoom data structure.

Your visualizer can use it to update AR view of the 3D model,which provides real-time feedback to peopleon the progress.

We will dive into the CapturedRoom structuremore in a later part of the talk.

This method will be called when we detect updatesto the captured room.

The second method iscaptureSession(_ session: didProvide instruction:).

This method provides you with an instruction structurewhich contains real-time feedback.

Your visualizer can use the instructionto guide people during the scan.

Let's go through the instructionsthat this API provides.

These instructions include distance to the objects,scanning speed, lighting adjustment to the room,as well as focusing on specific areas of the roomthat have more textures.

These instructions will be provided during the scanin order to guide people with real-time feedback.

Next, we will move on to the process part.

In this section, we will use the RoomBuilder classto process the scanned data and generate the final 3D models.

To process the captured data, the first step is to initiatea RoomBuilder instance in your ViewController class.

Next, in order to receive the sensor dataafter the capture process, your app needs to implementthe captureSession(_ session: didEndWith data: error:) method.

When the RoomCaptureSession is stopped, by callingthe stop() function in your app, or due to an error,this function will be called to return a CaptureRoomData objectand an optional error.

Finally, to process the captured data,we call the roomBuilder's async roomModel(from:) methodwith the await keyword.

The method runs asynchronously to process the scanned dataand build the final 3D model.

It utilizes the Swift async/await functionthat we introduced in last year's WWDC.

Within just a few seconds, the model will be availablefor the final presentation in your app.

Now, let's dive into the detailsof the CapturedRoom data structureand how you can export it to use in your app.

At the top level, there is CapturedRoomwhich consists of Surfaces and Objects.

Surface contains unique attributes to represent curvessuch as radius; starting and ending angles;four different edges of the surface;and architecture categories of wall, opening, window, door.

Object contains furniture categoriessuch as table, bed, sofa, etc.

Surface and Object share some common attributessuch as dimensions;confidence, which gives you three levels of confidencefor the scanned surface or object;the 3D transform matrix; as well as a unique identifier.

Let's see how they are represented in code.

The CapturedRoom structure is a fully parametric representationof the elements in the room.

It contains five properties including walls, openings,doors, windows, and objects in the room.

For the first four elements,they are represented as the Surface structurewhich represents 2D planar architectural structures.

On the right, you can see the various propertiesof Surface we covered earlier.

The last property is an array of 3D objects in the room,and they are represented as cuboids.

On the right, you can see the various properties of Object.

Here is the list of object types we support in RoomPlan.

These include a variety of common furniture typessuch as sofa, table, chair, bed, and many more.

Finally, the export function allows you to exportthis CapturedRoom into a USD or USDZ datafor your existing workflows.

Here is an example to show how you can directly openthe USD output in Cinema 4Dto browse and edit the hierarchical data structureof the room, as well as the dimensions and locationof each room element or object.

You can also leverage your existing USD and USDZ workflowsto add renders of the captured roominto a variety of applications such as real estate, e-commerce,utilities, and interior design.

So far, we covered the scanning experienceand underlying RoomPlan APIs.

We'll now go through some best practicesto help you get good results with RoomPlan.

We will cover the recommended conditionsthat allow for a good scan,room features to look out for while selecting a room,as well as a few scanning and thermal considerationsto keep in mind.

RoomPlan API supports most common architectural structuresand objects in a typical household.

It works best for a single residential roomwith a maximum room size of 30 feet by 30 feetor around 9 by 9 meters.

Lighting is also important for the APIto get a clear video stream and good AR tracking performance.

A minimum 50 lux or higher is recommended for using the API,which is typical for a family living room at night.

For the hardware, RoomPlan API is supported on allLiDAR-enabled iPhone and iPad Pro models.

There are some special conditionsthat can present a challenge for the API.

For example, full-height mirrors and glass pose a challengefor the LiDAR sensor to produce the expected output.

Even high ceilings could exceed the limit of the scanning rangeof the LiDAR sensor.

Also, very dark surfaces could be hard for the device to scan.

There are some considerations to get better scanning results.

First, for applications that have high accuracy requirements,preparing the room before scanningcan enhance the quality of the scan.

For example, opening the curtainscan let more natural light in and reduce window occlusions,which works best for daytime scans.

Closing the doors can reduce the chanceof scanning unnecessary area outside of the room.

Following a good scanning motion is also very importantto achieving good scanning results with the API.

And that is why we provide the user instruction delegate methodin order to provide feedback on textures, distance, speed,and lighting conditions to people during the scans.

Another thing to keep in mindis battery and thermals of the device.

We have done many optimizations on RoomPlan APIto ensure a good scanning experience.

Nevertheless, it's best to avoid repeated scansor single long scans over 5 minutes.

These could not only cause fatiguebut also drain out the battery and create thermal issueswhich might in turn impact the user experience of your app.

There is a lot that we covered today.

We introduced a brand-new API, RoomPlan.

It provides an intuitive scanning experienceto capture your rooms,powerful machine learning models to understand the environment,as well as a fully parametric USD output formatfor easy integration in your apps.

For guidance on how to better design and implementyour new RoomPlan experience,please check out the related talks below.

Praveen: It's time for you to try RoomPlan in your app.

We can't wait to see what you can create with this new API.

Kai: Thanks for watching!♪

4:36 -RoomCaptureView API - Scan & Process

5:00 -RoomCaptureView API - Export

6:50 -RoomCaptureSession - setup previewVisualizer

7:40 -RoomCaptureSession - live results and user instructions

9:12 -Setup RoomBuilder

9:30 -RoomBuilder - generate final 3D CapturedRoom

11:20 -CapturedRoom and export

## Code Samples

```swift
// RoomCaptureView API - Scan & Process



import
 UIKit

import
 RoomPlan


class
 
RoomCaptureViewController
: 
UIViewController
 {

    
var
 roomCaptureView: 
RoomCaptureView

    
var
 captureSessionConfig: 
RoomCaptureSession
.
Configuration


   
private
 
func
 
startSession
() {
        roomCaptureView
?
.captureSession.run(configuration: captureSessionConfig)
     }
    
    
private
 
func
 
stopSession
() {
        roomCaptureView
?
.captureSession.stop()
	}
}
```

```swift
// RoomCaptureView API - Export



import
 UIKit

import
 RoomPlan


class
 
RoomCaptureViewController
: 
UIViewController
 {
  
…

  
func
 
captureView
(
shouldPresent
 
roomDataForProcessing
: 
CapturedRoomData
, 
error
: 
Error
?) -> 
Bool
 {
    
// Optionally opt out of post processed scan results.

    
return
 
false

  }

  
func
 
captureView
(
didPresent
 
processedResult
: 
CapturedRoom
, 
error
: 
Error
?) {
    
// Handle final, post processed results and optional error.

    
// Export processedResults

    
…

    
try
 processedResult.export(to: destinationURL)
    
…

  }
}
```

```swift
import
 UIKit

import
 RealityKit

import
 RoomPlan

import
 ARKit


class
 
ViewController
: 
UIViewController
 {
    
@IBOutlet
 
weak
 
var
 arView: 
ARView
!
    
var
 previewVisualizer: 
Visualizer
!
    
lazy
 
var
 captureSession: 
RoomCaptureSession
 
=
 {
        
let
 captureSession 
=
 
RoomCaptureSession
()
        arView.session 
=
 captureSession.arSession
        
return
 captureSession
    }()
    
override
 
func
 
viewDidLoad
() {
        
super
.viewDidLoad()
        captureSession.delegate 
=
 
self

        
// set up previewVisualizer

    }
}
```

```swift
// Getting live results and user instructions



extension
 
ViewController
: 
RoomCaptureSessionDelegate
 {

    
func
 
captureSession
(
_
 
session
: 
RoomCaptureSession
,
                        
didUpdate
 
room
: 
CapturedRoom
) {
        previewVisualizer.update(model: room)
    }
    
    
func
 
captureSession
(
_
 
session
: 
RoomCaptureSession
,
                   
didProvide
 
instruction
: 
Instruction
) {
        previewVisualizer.provide(instruction)
    }
}
```

```swift
// RoomBuilder


import
 UIKit

import
 RealityKit

import
 RoomPlan

import
 ARKit


class
 
ViewController
: 
UIViewController
 {
    
    
@IBOutlet
 
weak
 
var
 arView: 
ARView
!
    
var
 previewVisualizer: 
Visualizer
!

    
// set up RoomBuilder

    
var
 roomBuilder 
=
 
RoomBuilder
(options: [.beautifyObjects])
}
```

```swift
// RoomBuilder with the latest CapturedRoomData to generate final 3D CapturedRoom



extension
 
ViewController
: 
RoomCaptureSessionDelegate

{
    
func
 
captureSession
(
_
 
session
: 
RoomCaptureSession
, 
                        
didEndWith
 
data
: 
CapturedRoomData
, 
error
: 
Error
?)
    {
        
if
 
let
 error 
=
 error {
            
print
(
"Error: 
\(error)
"
)
        }
        
Task
 {
            
let
 finalRoom 
=
 
try!
 
await
 roomBuilder.capturedRoom(from: data)
            previewVisualizer.update(model: finalRoom)
        }
    }
}
```

```swift
// CapturedRoom and export



public
 
struct
 
CapturedRoom
: 
Codable
, 
Sendable

{
    
public
 
let
 walls: [
Surface
]
    
public
 
let
 doors: [
Surface
]
    
public
 
let
 windows: [
Surface
]
    
public
 
let
 openings: [
Surface
]
    
public
 
let
 objects: [
Object
]

    
public
 
func
 
export
(
to
 
url
: 
URL
) 
throws


    
// Surface definitions ...

    
    
// Object definitions ...

}
```

