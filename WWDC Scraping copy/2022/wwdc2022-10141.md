# Wwdc2022 10141

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Explore USD tools and renderingDiscover the latest advancements in tooling to help you generate, inspect, and convert Universal Scene Description (USD) assets. We'll learn about updates to these tools and help you integrate them into your content creation pipeline. We'll also explore the power of USD Hydra rendering, and show how you can integrate it into your own apps.

For an introduction to USD, watch "Understand USD fundamentals" from WWDC22.ResourcesASWF USD Working GroupCreating a 3D application with Hydra renderingIntroduction to Universal Scene Description (USD)HD VideoSD VideoRelated VideosWWDC22Create parametric 3D room scans with RoomPlanUnderstand USD fundamentalsWWDC21Create 3D models with Object CaptureCreate 3D workflows with USDExplore advanced rendering with RealityKit 2WWDC20The artist’s AR toolkit

Discover the latest advancements in tooling to help you generate, inspect, and convert Universal Scene Description (USD) assets. We'll learn about updates to these tools and help you integrate them into your content creation pipeline. We'll also explore the power of USD Hydra rendering, and show how you can integrate it into your own apps.

For an introduction to USD, watch "Understand USD fundamentals" from WWDC22.

ASWF USD Working Group

Creating a 3D application with Hydra rendering

Introduction to Universal Scene Description (USD)

HD VideoSD Video

HD Video

SD Video

Create parametric 3D room scans with RoomPlan

Understand USD fundamentals

Create 3D models with Object Capture

Create 3D workflows with USD

Explore advanced rendering with RealityKit 2

The artist’s AR toolkit

Search this video…♪ instrumental hip hop music ♪Hi there. Welcome to this year's WWDC.My name is Stella.And I'm Alex.Stella and I work together on the many parts of USD at Apple.Today we'll explore with you updates to USD tools and rendering.Take it away, Stella!USD is a foundational technologythat, with the growing and deepening integration into content creation tools,is enabling more and more ways of creating assets and content,rendering for games, AR, film, and the web,all with USD at the center.Today, we will focus on two parts of the ecosystem: tools and rendering.Let's start with updates to our USD tools.We'll then show you how your assets look even betterwith new lighting in AR Quick Look,take a deep dive into USD rendering,and last but not least, show you how to integrate Hydra.Let's get started with USD Tools in the Apple ecosystem.We'll cover USDZ Tools, Reality Converter,and then follow up with additional tools and frameworksthat can help you create USDZ content.USDZ Tools is a packagethat contains essential command line USD Python toolsto help you generate, validate, and inspect USDZ files.The package also includes a converter called usdzconvertthat creates USDZ files from other major 3D file formats.The Python scripts give you powerful tools for automation and batch processing.Also, they are a great way for you to explore USD and learnhow to use the API.This year, we're bringing you Python 3 and Apple Silicon support.We've also upgraded the USD version to give you simple accessto new USD features and performance improvements.On top of that, we added great new features to usdzconvert.You can now convert OBJ files with materials to USDZwith the useObjMtl flag.We also added support for points and lines from GLTF files,and scene time for animations from FBX files.To display all usdzconvert options and ways to customize your conversion,just type "usdzconvert --help" on the terminal.This will show you all the options you can use with usdzconvert,such as adding copyright informationor providing the diffuseColor or normalMap for your 3D model,and much more.Alternatively, if you prefer a UI editor for your workflowover using the command line,we also have Reality Converter, which is built using the USDZ toolsand provides the same capabilities as usdzconvert,but in an editor window,making it easy to convert, view, and customize USD content on MacOS.Simply import common 3D file formats,such as OBJ, GLTF, and FBX,to view the converted USDZ result.This year, we've also improved the UI to streamline your workflow.You can select the texture to view more information...Customize material properties with your own textures...Add copyright or edit file metadata...And choose classic or new lighting, which we'll get into more detailslater in the session.You can even preview your USDZ objectunder a variety of lighting conditions with built-in optionsand adjust exposure accordinglyOn the asset side, we added a new featureto let you choose texture quality while exporting a USDZ file.By default, the textures are exported in their original, uncompressed size.But, if you prefer to reduce the size of your USDZ files, you now havethe option to compress textures to the JPEG format.In this example, we used object capture to scan this chess piecein high resolution.In order to reduce the file size without losing mesh detail,we used RealityConverter to export the model with compressed textures.The visual difference is hardly noticeable,and we got a whopping 80% reduction in the resulting file size!Here is more exciting news:RealityConverter can now fix issues with your USD assets automatically!It will correct mismatched attributes and connection types,fix a stage with multiple top-level prims and a missing default prim,update deprecated attributes, and add missing stage metadata.We've also added universal binary support so now it runs natively on Apple Silicon.Now, what if you want to create 3D models from scratch?Last year, we launched Object Capture as a RealityKit API on macOS,which provides an innovative way to create USDZ assets.You can then use Reality Composer to compose a scene with multiple assets.This year, we are bringing you RoomPlan API,which lets you create parametric 3D scans of your room.I highly recommend you to check out these 3 sessions.Together, these technologies make it easier than everfor anyone to create immersive AR experiences.All these tools we covered todayare available for you to download right nowon our AR Creation Tools page on the Apple developer website.Please check them out!Next, let's take a look+ at AR Quick Look's new lighting.AR Quick Look is the built-in, system-wide AR viewer on iOSwhich enables you to place 3D USDZ objects in your physical space,like on a table, a wall, or a floor,and interact with them with simple touch gestures.You can even make interactive scenes built with Reality Composerand save them to a USDZ filewhich you can share with others on iMessage, Mail, Notes, and more.We constantly strive to make AR Quick Lookrendering more realistic, and this year,we are introducing improved lighting in AR Quick Look,which is brighter, with enhanced contrast and improved shape definitionto make your assets look even better.Here is an example of AirPods Pro in object modewith classic and new lighting.The AirPods Pro look great in both lighting conditions,and you will notice the new lighting optionoffers brighter color,higher contrast, and more highlights.Now let's place the AirPods Max on the desk to view it in AR modewith new lighting!Stunning, isn't it?So how do you apply the new lighting to your assets?It's really simple.You just have to pick the lighting that works best for your contentby setting the new preferredIblVersion metadata in your USDZ file.Here we have set the value of the preferredIblVersion to 2,which will indicate AR Quick Look to use the new lighting system.Let's understand this in more detail.The preferredIBLVersion metadatacan hold values of 0,1, and 2.An asset with preferredIblVersion set to 0will use the system default lighting.If set to 1, it will continue to use the classic lighting.A value of 2 will give you the new lighting.This means you can easily update your current assets to the new lightingas well!We recommend that you make an explicit choice and set this metadatain all of your assets.To do that, you can either useusdzconvert with the flag preferrediblversion.For example, here is how to use the flag to convertthe fire hydrant OBJ file to USDZ with the new lighting.Or you can use Reality Converter,which will now use the new lighting by default.But if you want to use the classic lighting,there is a new option in the Property Panel.Here we preview the AirPods Max asset with both the classic and new lighting.This provides an easy way to compare the differences.By clicking the lighting icon, the applied lightingwill also be highlighted for your reference.Lastly, for assets without this metadata,AR Quick Look will determine the lighting version automaticallybased on the file's date-time stamp.If the asset was created after July 1st, 2022, it will use the new lighting.Older assets will continue to use the classic lightingso they don't change how they look.Now, I'll hand it over to Alex for USD rendering.Thanks, Stella.We've already seen a lot of rendered USD assets today.Now we'll explore what makes USD rendering and Hydra a great choicefor your 3D content creation pipelineand how you can integrate it in your own applications.First, let's take a step back and talk about rendering in general.A renderer takes a collection of 3D models, cameras, and lights as inputand uses them to generate an image.There are many different renderers, and each one of themis built for a specific purpose and optimized for a different use case.Some renderers are designed for real-time applicationslike rendering a character in a game or an AR scene.Others take much longer but produce a more photorealistic image,for example, producing visual effects for a Hollywood movie.All renderers make choices about their features and are unique.Different USD renderers for different use casesalso exist on Apple platforms.We're adding documentation about these different renderersto developer.apple.com.It will help you understand the differences between them,explain which USD features they support,and provide guidance on how to author USDs that work best for you.One of the renderers on Apple platforms is RealityKit,which features a photorealistic rendering system,optimized for interactive augmented reality experiences,and is used in AR Quick Look.It is the primary renderer of USDZ files.Another option for USD rendering on macOS is Pixar's open-source renderer, Storm.It is optimized for production-grade assetsand designed for real-time preview of large-scale scenes.It's a great technology for you to visualize and iterate on assetsas they flow through your content creation pipeline.Storm uses a technology called Hydra.Hydra is a core aspect of the USD open source project.So next, let's understand Hydra and its connection to Storm.We start with this diagram from earlier.Here, we use Storm as the renderer.The input is usually called "the scene graph,"and Storm produces a preview render of it.But what if you want to generate a photorealistic image of the same sceneusing a different renderer?That's exactly what Hydra is made for.Instead of tightly coupling the scene to the renderer,Hydra acts as an abstract layer in between themto transport data from scenes to renderers.This allows you to easily swap out your rendererbased on your needs at any time without any changes to your scene graph.For example, you might use Storm and Pixar's RenderMan.In your content creation pipeline, you can use Storm for fast rendersand quick iteration,and then switch to RenderManto produce the final image when you're ready.The same goes for the scene graph.Your input to Hydra can be a USD scene graph or a different one.This allows you to leverage the same renderer in multiple applicationseven if each one of them has their own, totally different scene graph.The interfaces which connect Hydra with scene graphs and renderersare called delegates.Scene graphs are connected to Hydra via Scene Delegates,and Renderers are connected to Hydra via Render Delegates.And that is Hydra for you!Foundry's Nuke 13 is already using Hydra to render the viewport,enabling Nuke artists on macOS to have better qualityand an interactive experience in Nuke's 3D system.This is achieved by using Hydra with a custom scene delegateand Metal-accelerated Storm.We are excited to share that we've worked with Pixar Animation Studiosto publicly release Metal accelerated Storm to open source.It is ready for you to use in USD 22.05.Now that we've seen the power of Hydra,let's go through a Hydra sample applicationwith the typical use case of a USD scene graphand Storm as renderer.It will get you started with using Hydra to build content creation toolsand 3D workflow applications.Our sample application, HydraPlayer, is very simple but powerful.It renders a USD file with Storm and lets us move the camera around it.And we're excited to make HydraPlayera public sample project to get you started right away!It is available in the session resources and comeswith full instructions in the readme.I encourage you to pause this video now,download the project, and then follow along as we walk through it.In your Xcode project, you will find 4 classes:The AppDelegate, Camera, Renderer, and View Controller.The AppDelegate is basically your root objectand manages interactions with the system.The camera class is a simple representationof the USD scene camerato make it easy to translate the user input.The renderer class will handle all our interactions with USD and Hydra.Last but not least, the ViewController handles our user input.Before we can build and launch HydraPlayer, there are three things to do:prepare the environment, use Rosetta on Apple Silicon Macs,and download and build USD & Hydra.So let's get started.First, we prepare our development environment.Make sure you have Xcode, Python, and CMake installed.Now let's open up a terminal for the other two steps.If you are on an Apple Silicon Mac, you need to run under Rosettawhile USD is transitioning to fully support arm64.To do this, use the arch command.Once your environment is ready, we have to download the USDand Hydra source code.Both live in the same GitHub repository at PixarAnimationStudios/USD.Now that we have the code, we can build it.USD comes with a convenient Python build script.We add the flags "generator Xcode" and "no-python"and specify where we want to install USD to.Let's put it next to the source code at "USDInstall."Once USD finished building, we are ready to build HydraPlayer!Let's go back to this diagram one more time and use it to identifykey parts of HydraPlayer to check out in detail.We'll look at how to load the 3D models, how to set up the camera,and set the scene light.Then we'll learn how to get our scene graph to Stormand finally, how to produce an image for the application window.So let's get started with loading our 3D models from USD.In viewDidAppear in our ViewController, we create a file pickerwith an NSOpenPanel when the view appears the first time.Once a file has been selected, the renderercan start setting up our scene and load the USD file.Loading the file is very simple with the USD API.We simply open the USD stage at the file path.That's it. We have our file loaded.Next, we set up our camera. In our code, this is straightforward.In setupCamera, we first create a new scene camera.Then we calculate the world size and center based on our scene.Next, move our camera at a good distance and then focus on the center.This way, our camera captures the whole scene.Great, now we have our camera set up.Next, lighting.We keep it easy and create one simple ambient lightand set its position to match the camera, and that's it.And with that, we have our full scene with 3D models, a camera and a light!We can now pass our scene to Storm.First, we need to initialize our render engine.Here, we create a new UsdImagingGLEngine, which is the class name of Storm.The most important parameter here is the rootPath.It points the engine to our USD stage with our 3D models.To learn more about the other parameters and UsdImagingGLEngine,please check out Pixar's USD API documentation.Next, we set our camera in our engineand set our lighting setup.And last but not least, we define how we want Storm to renderby setting render parameters.For example, we want to render a transparent backgroundso that the rendered image works nicely with our app color scheme.Important for scenes with animation,this is also where we specify the time code.Now we're ready to render an image!We've already done all the necessary setup,so the render command is just one line of code.We get the result and display it in our window, and there we are!We're rendering the USD toy plane!And actually, we're rendering not just one plane.HydraPlayer can easily render thousands of animated assetswith tens of millions of triangles.If you haven't already, check out the resources for this session,download the sample project, and have fun exploring it further.Together we explored updates to Apple's USD toolsthat make them more powerful and make your assets look even better.We learned about Hydra's featuresand went through the HydraPlayer sample projectto see how you can integrate it into your own applications.To find out more about important concepts of USD,check out the session "Understand USD fundamentals.Thank you.♪ ♪

♪ instrumental hip hop music ♪Hi there. Welcome to this year's WWDC.My name is Stella.And I'm Alex.Stella and I work together on the many parts of USD at Apple.Today we'll explore with you updates to USD tools and rendering.Take it away, Stella!USD is a foundational technologythat, with the growing and deepening integration into content creation tools,is enabling more and more ways of creating assets and content,rendering for games, AR, film, and the web,all with USD at the center.

Today, we will focus on two parts of the ecosystem: tools and rendering.

Let's start with updates to our USD tools.

We'll then show you how your assets look even betterwith new lighting in AR Quick Look,take a deep dive into USD rendering,and last but not least, show you how to integrate Hydra.

Let's get started with USD Tools in the Apple ecosystem.

We'll cover USDZ Tools, Reality Converter,and then follow up with additional tools and frameworksthat can help you create USDZ content.

USDZ Tools is a packagethat contains essential command line USD Python toolsto help you generate, validate, and inspect USDZ files.The package also includes a converter called usdzconvertthat creates USDZ files from other major 3D file formats.

The Python scripts give you powerful tools for automation and batch processing.Also, they are a great way for you to explore USD and learnhow to use the API.

This year, we're bringing you Python 3 and Apple Silicon support.We've also upgraded the USD version to give you simple accessto new USD features and performance improvements.

On top of that, we added great new features to usdzconvert.You can now convert OBJ files with materials to USDZwith the useObjMtl flag.We also added support for points and lines from GLTF files,and scene time for animations from FBX files.To display all usdzconvert options and ways to customize your conversion,just type "usdzconvert --help" on the terminal.

This will show you all the options you can use with usdzconvert,such as adding copyright informationor providing the diffuseColor or normalMap for your 3D model,and much more.Alternatively, if you prefer a UI editor for your workflowover using the command line,we also have Reality Converter, which is built using the USDZ toolsand provides the same capabilities as usdzconvert,but in an editor window,making it easy to convert, view, and customize USD content on MacOS.

Simply import common 3D file formats,such as OBJ, GLTF, and FBX,to view the converted USDZ result.This year, we've also improved the UI to streamline your workflow.You can select the texture to view more information...

Customize material properties with your own textures...

Add copyright or edit file metadata...

And choose classic or new lighting, which we'll get into more detailslater in the session.

You can even preview your USDZ objectunder a variety of lighting conditions with built-in optionsand adjust exposure accordinglyOn the asset side, we added a new featureto let you choose texture quality while exporting a USDZ file.By default, the textures are exported in their original, uncompressed size.But, if you prefer to reduce the size of your USDZ files, you now havethe option to compress textures to the JPEG format.

In this example, we used object capture to scan this chess piecein high resolution.In order to reduce the file size without losing mesh detail,we used RealityConverter to export the model with compressed textures.The visual difference is hardly noticeable,and we got a whopping 80% reduction in the resulting file size!Here is more exciting news:RealityConverter can now fix issues with your USD assets automatically!It will correct mismatched attributes and connection types,fix a stage with multiple top-level prims and a missing default prim,update deprecated attributes, and add missing stage metadata.We've also added universal binary support so now it runs natively on Apple Silicon.

Now, what if you want to create 3D models from scratch?Last year, we launched Object Capture as a RealityKit API on macOS,which provides an innovative way to create USDZ assets.You can then use Reality Composer to compose a scene with multiple assets.This year, we are bringing you RoomPlan API,which lets you create parametric 3D scans of your room.

I highly recommend you to check out these 3 sessions.Together, these technologies make it easier than everfor anyone to create immersive AR experiences.All these tools we covered todayare available for you to download right nowon our AR Creation Tools page on the Apple developer website.Please check them out!Next, let's take a look+ at AR Quick Look's new lighting.

AR Quick Look is the built-in, system-wide AR viewer on iOSwhich enables you to place 3D USDZ objects in your physical space,like on a table, a wall, or a floor,and interact with them with simple touch gestures.You can even make interactive scenes built with Reality Composerand save them to a USDZ filewhich you can share with others on iMessage, Mail, Notes, and more.We constantly strive to make AR Quick Lookrendering more realistic, and this year,we are introducing improved lighting in AR Quick Look,which is brighter, with enhanced contrast and improved shape definitionto make your assets look even better.

Here is an example of AirPods Pro in object modewith classic and new lighting.The AirPods Pro look great in both lighting conditions,and you will notice the new lighting optionoffers brighter color,higher contrast, and more highlights.

Now let's place the AirPods Max on the desk to view it in AR modewith new lighting!Stunning, isn't it?So how do you apply the new lighting to your assets?It's really simple.You just have to pick the lighting that works best for your contentby setting the new preferredIblVersion metadata in your USDZ file.

Here we have set the value of the preferredIblVersion to 2,which will indicate AR Quick Look to use the new lighting system.

Let's understand this in more detail.The preferredIBLVersion metadatacan hold values of 0,1, and 2.

An asset with preferredIblVersion set to 0will use the system default lighting.

If set to 1, it will continue to use the classic lighting.

A value of 2 will give you the new lighting.

This means you can easily update your current assets to the new lightingas well!We recommend that you make an explicit choice and set this metadatain all of your assets.To do that, you can either useusdzconvert with the flag preferrediblversion.For example, here is how to use the flag to convertthe fire hydrant OBJ file to USDZ with the new lighting.Or you can use Reality Converter,which will now use the new lighting by default.

But if you want to use the classic lighting,there is a new option in the Property Panel.

Here we preview the AirPods Max asset with both the classic and new lighting.

This provides an easy way to compare the differences.

By clicking the lighting icon, the applied lightingwill also be highlighted for your reference.

Lastly, for assets without this metadata,AR Quick Look will determine the lighting version automaticallybased on the file's date-time stamp.

If the asset was created after July 1st, 2022, it will use the new lighting.

Older assets will continue to use the classic lightingso they don't change how they look.

Now, I'll hand it over to Alex for USD rendering.Thanks, Stella.We've already seen a lot of rendered USD assets today.Now we'll explore what makes USD rendering and Hydra a great choicefor your 3D content creation pipelineand how you can integrate it in your own applications.

First, let's take a step back and talk about rendering in general.

A renderer takes a collection of 3D models, cameras, and lights as inputand uses them to generate an image.There are many different renderers, and each one of themis built for a specific purpose and optimized for a different use case.

Some renderers are designed for real-time applicationslike rendering a character in a game or an AR scene.

Others take much longer but produce a more photorealistic image,for example, producing visual effects for a Hollywood movie.

All renderers make choices about their features and are unique.

Different USD renderers for different use casesalso exist on Apple platforms.We're adding documentation about these different renderersto developer.apple.com.

It will help you understand the differences between them,explain which USD features they support,and provide guidance on how to author USDs that work best for you.

One of the renderers on Apple platforms is RealityKit,which features a photorealistic rendering system,optimized for interactive augmented reality experiences,and is used in AR Quick Look.It is the primary renderer of USDZ files.

Another option for USD rendering on macOS is Pixar's open-source renderer, Storm.It is optimized for production-grade assetsand designed for real-time preview of large-scale scenes.

It's a great technology for you to visualize and iterate on assetsas they flow through your content creation pipeline.

Storm uses a technology called Hydra.

Hydra is a core aspect of the USD open source project.So next, let's understand Hydra and its connection to Storm.We start with this diagram from earlier.Here, we use Storm as the renderer.

The input is usually called "the scene graph,"and Storm produces a preview render of it.

But what if you want to generate a photorealistic image of the same sceneusing a different renderer?That's exactly what Hydra is made for.Instead of tightly coupling the scene to the renderer,Hydra acts as an abstract layer in between themto transport data from scenes to renderers.

This allows you to easily swap out your rendererbased on your needs at any time without any changes to your scene graph.For example, you might use Storm and Pixar's RenderMan.

In your content creation pipeline, you can use Storm for fast rendersand quick iteration,and then switch to RenderManto produce the final image when you're ready.

The same goes for the scene graph.Your input to Hydra can be a USD scene graph or a different one.

This allows you to leverage the same renderer in multiple applicationseven if each one of them has their own, totally different scene graph.The interfaces which connect Hydra with scene graphs and renderersare called delegates.Scene graphs are connected to Hydra via Scene Delegates,and Renderers are connected to Hydra via Render Delegates.And that is Hydra for you!Foundry's Nuke 13 is already using Hydra to render the viewport,enabling Nuke artists on macOS to have better qualityand an interactive experience in Nuke's 3D system.

This is achieved by using Hydra with a custom scene delegateand Metal-accelerated Storm.

We are excited to share that we've worked with Pixar Animation Studiosto publicly release Metal accelerated Storm to open source.It is ready for you to use in USD 22.05.Now that we've seen the power of Hydra,let's go through a Hydra sample applicationwith the typical use case of a USD scene graphand Storm as renderer.It will get you started with using Hydra to build content creation toolsand 3D workflow applications.

Our sample application, HydraPlayer, is very simple but powerful.It renders a USD file with Storm and lets us move the camera around it.

And we're excited to make HydraPlayera public sample project to get you started right away!It is available in the session resources and comeswith full instructions in the readme.

I encourage you to pause this video now,download the project, and then follow along as we walk through it.

In your Xcode project, you will find 4 classes:The AppDelegate, Camera, Renderer, and View Controller.The AppDelegate is basically your root objectand manages interactions with the system.The camera class is a simple representationof the USD scene camerato make it easy to translate the user input.

The renderer class will handle all our interactions with USD and Hydra.

Last but not least, the ViewController handles our user input.

Before we can build and launch HydraPlayer, there are three things to do:prepare the environment, use Rosetta on Apple Silicon Macs,and download and build USD & Hydra.So let's get started.

First, we prepare our development environment.Make sure you have Xcode, Python, and CMake installed.

Now let's open up a terminal for the other two steps.

If you are on an Apple Silicon Mac, you need to run under Rosettawhile USD is transitioning to fully support arm64.To do this, use the arch command.

Once your environment is ready, we have to download the USDand Hydra source code.Both live in the same GitHub repository at PixarAnimationStudios/USD.

Now that we have the code, we can build it.USD comes with a convenient Python build script.We add the flags "generator Xcode" and "no-python"and specify where we want to install USD to.

Let's put it next to the source code at "USDInstall."Once USD finished building, we are ready to build HydraPlayer!Let's go back to this diagram one more time and use it to identifykey parts of HydraPlayer to check out in detail.

We'll look at how to load the 3D models, how to set up the camera,and set the scene light.Then we'll learn how to get our scene graph to Stormand finally, how to produce an image for the application window.

So let's get started with loading our 3D models from USD.In viewDidAppear in our ViewController, we create a file pickerwith an NSOpenPanel when the view appears the first time.

Once a file has been selected, the renderercan start setting up our scene and load the USD file.

Loading the file is very simple with the USD API.We simply open the USD stage at the file path.

That's it. We have our file loaded.

Next, we set up our camera. In our code, this is straightforward.In setupCamera, we first create a new scene camera.

Then we calculate the world size and center based on our scene.Next, move our camera at a good distance and then focus on the center.This way, our camera captures the whole scene.

Great, now we have our camera set up.Next, lighting.We keep it easy and create one simple ambient lightand set its position to match the camera, and that's it.And with that, we have our full scene with 3D models, a camera and a light!We can now pass our scene to Storm.First, we need to initialize our render engine.Here, we create a new UsdImagingGLEngine, which is the class name of Storm.The most important parameter here is the rootPath.It points the engine to our USD stage with our 3D models.To learn more about the other parameters and UsdImagingGLEngine,please check out Pixar's USD API documentation.

Next, we set our camera in our engineand set our lighting setup.And last but not least, we define how we want Storm to renderby setting render parameters.For example, we want to render a transparent backgroundso that the rendered image works nicely with our app color scheme.Important for scenes with animation,this is also where we specify the time code.

Now we're ready to render an image!We've already done all the necessary setup,so the render command is just one line of code.We get the result and display it in our window, and there we are!We're rendering the USD toy plane!And actually, we're rendering not just one plane.HydraPlayer can easily render thousands of animated assetswith tens of millions of triangles.

If you haven't already, check out the resources for this session,download the sample project, and have fun exploring it further.

Together we explored updates to Apple's USD toolsthat make them more powerful and make your assets look even better.We learned about Hydra's featuresand went through the HydraPlayer sample projectto see how you can integrate it into your own applications.

To find out more about important concepts of USD,check out the session "Understand USD fundamentals.

Thank you.♪ ♪

3:00 -Phyton usdconvert --help

9:00 -choosing lighting in usda metadata

17:50 -Build USD + Hydra

18:54 -Load USD ViewController

19:30 -Create Scene Camera

19:54 -Create Scene Light

20:17 -transport to storm

## Code Samples

```swift
% python usdzconvert --
help

usdzconvert 
0.66

usage: usdzconvert inputFile [outputFile]
                   [-h] [-version] [-f file] [-v]
                   [-path path[+path2[...]]]
                   [-url url]
                   [-copyright copyright]
                   [-copytextures]
                   [-metersPerUnit value]
                   // ...
                   [-diffuseColor           r,g,b]
                   [-diffuseColor           <file> fr,fg,fb]
                   [-normal                 x,y,z]
                   [-normal                 <file> fx,fy,fz]
                   // ...
```

```swift
// asset.usda


#usda 1.0

(
    customLayerData = {
        dictionary Apple = {
             
int
 preferredIblVersion = 
2

        }
    }
)
```

```swift
// Rosetta
% arch -x86_64 /
bin
/zsh

// Download source code
% git clone https://github.com/PixarAnimationStudios/USD.git 

// Build USD + Hydra
% python3 USD/build_scripts/build_usd.py --generator Xcode --no-python USDInstall
```

```swift
// AAPLViewController.mm


- (
void
)viewDidAppear
{   
    
NSOpenPanel
* panel = [
NSOpenPanel
 openPanel];
    panel.allowedContentTypes = @[UTTypeUSD, UTTypeUSDZ];
   
    [panel beginWithCompletionHandler:^(
NSModalResponse
 result) {
        
if
 (result == 
NSModalResponseOK
)
        {
            
NSURL
* url = panel.URLs[
0
];
            [
self
->_renderer setupScene:[url path]];
        }
    }];
}


// AAPLRenderer.mm


- (
bool
)loadStage:(
NSString
*)filePath
{
    _stage = UsdStage::Open([filePath UTF8String]);
    
// ...

}
```

```swift
// AAPLRenderer.mm


- (
void
)setupCamera
{
    _viewCamera = [[AAPLCamera alloc] initWithRenderer:
self
];
    
    [
self
 calculateWorldCenterAndSize];
    
    [_viewCamera setDistance:_worldSize];
    [_viewCamera setFocus:_worldCenter];

}
```

```swift
// AAPLRenderer.mm


GlfSimpleLight computeCameraLight(
const
 GfMatrix4d& cameraTransform)
{
    GlfSimpleLight light;
    light.SetPosition(GfVec4f(cameraPosition[
0
], cameraPosition[
1
], cameraPosition[
2
], 
1
));
    
    
return
 light;
}
```

```swift
// AAPLRenderer.mm


- (
void
)initializeEngine
{
    _engine.reset(new UsdImagingGLEngine(_stage->GetPseudoRoot().GetPath(),
                                         excludedPaths,
                                         SdfPathVector(),
                                         SdfPath::AbsoluteRootPath(),
                                         driver));
}


// AAPLRenderer.mm


- (HgiTextureHandle)drawWithHydraAt:(
double
)timeCode
                           viewSize:(
CGSize
)viewSize
{
      _engine->SetCameraState(modelViewMatrix, projMatrix);
      _engine->SetLightingState(lights, _material, _sceneAmbient);
  
      UsdImagingGLRenderParams params;
      params.clearColor = GfVec4f(
0.0
f, 
0.0
f, 
0.0
f, 
0.0
f);
      params.frame = timeCode;

      
// ... 

}
```

