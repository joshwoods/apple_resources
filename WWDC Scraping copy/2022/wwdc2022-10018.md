# Wwdc2022 10018

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Bring Continuity Camera to your macOS appDiscover how you can use iPhone as an external camera in any Mac app with Continuity Camera. Whether you're building video conferencing software or an experience that makes creative use of cameras, we'll show you how you can enhance your app with automatic camera switching. We'll also explore how to recognize user-preferred and system-preferred cameras, take you through APIs for high-resolution and high-quality photo capture from iPhone's video stream, and more.

To learn more about camera capture, watch "Discover advancements in iOS camera capture" from WWDC22.ResourcesCapture setupSupporting Continuity Camera in your macOS appHD VideoSD VideoRelated VideosWWDC23Discover Continuity Camera for tvOSWWDC22Discover advancements in iOS camera capture: Depth, focus, and multitaskingWWDC21Capture high-quality photos using video formatsWhat’s new in camera capture

Discover how you can use iPhone as an external camera in any Mac app with Continuity Camera. Whether you're building video conferencing software or an experience that makes creative use of cameras, we'll show you how you can enhance your app with automatic camera switching. We'll also explore how to recognize user-preferred and system-preferred cameras, take you through APIs for high-resolution and high-quality photo capture from iPhone's video stream, and more.

To learn more about camera capture, watch "Discover advancements in iOS camera capture" from WWDC22.

Capture setup

Supporting Continuity Camera in your macOS app

HD VideoSD Video

HD Video

SD Video

Discover Continuity Camera for tvOS

Discover advancements in iOS camera capture: Depth, focus, and multitasking

Capture high-quality photos using video formats

What’s new in camera capture

Search this video…♪ instrumental hip hop music ♪♪Hi, my name is Karen Xing.I'm an engineer in the Camera Software team.Welcome to "Bring Continuity Camera supportto your macOS app"To start this session I will talk about,what is Continuity Camera?Next, I will discuss how your applicationcan build an automatic camera selection experiencewith Continuity Camera.And finally, I will walk through the APIsthat are new in macOS 13 for Continuity Camera.With Continuity Camera,you can now use iPhone as your webcam.Setup is seamless;just bring your iPhone close to your Mac.And it works wirelessly so you can quickly join a call.Your iPhone will appear on your Macas an external camera and microphoneunder several conditions.First, you must be running macOS 13 and iOS 16.Both Mac and iPhone must be signed into the same Apple IDusing two-factor authentication.For wired connection,the phone needs to be connected to Mac over USB.Or for wireless connection,the two devices need to be in proximityand have both Bluetooth and Wi-Fi turned on.Rather than talking through it, let me show you right awayhow magical Continuity Camera looks on devices.Here I have a MacBook Pro and iPhone 13 Pro.Both devices are signed in to the same Apple ID.The phone is placed on a stand attached to my MacBook.I will be joining a video conferencing callwith my colleague Eric todayand show you how we can use Continuity Camera in Zoom.The app is launched using the built-in camera first,and then an onboarding dialogue shows updescribing what you can do with the new camera.The dialogue shows up one timeafter your Mac is upgraded to macOS 13when you open a camera application for the first timeand there's an iPhone eligible for Continuity Camera.Hi, Eric!Eric: Oh, Karen! Hi!Karen: After the onboarding dialogue is shown on the system,Continuity Camera and microphone deviceswill become available in all applications.Let's switch to use this camera and see how it looks.Continuity Camera uses the rear camera system on the iPhone,so you get the same great video qualitythat you expect from iPhone.And it works with all four orientations of the phone.The portrait orientation gives you a more zoomed infield of view compared to landscape orientation.Continuity Camera also lets you do thingsthat were never before possible with a webcam,including several new video effects.You're probably already familiarwith Center Stage and Portrait video effectsintroduced in iOS 14.5 and macOS 12.3.If not, I highly recommend watching the"What's new in Camera Capture" session from WWDC 2021to learn more about system video effectsand how to interact with them in applications.Let's go to Control Center and enable system video effectson Continuity Camera.Center Stage keeps you in frame as you move around in the scene.Portrait blurs the backgroundand naturally puts the focus on you.Portrait is only supported on Apple silicon Macs,but with Continuity Camera,it is now available on all Intel and Apple silicon Macs.Studio Light is a new system video effectavailable on macOS 13.It is supported by Continuity Camerawhen using iPhone 12 or newer.Enable this when you want to look your best on screen.It provides a stunning lighting effectthat dims the background and illuminates your face.Studio Light is perfect for tough lighting situations,like when you're in front of a window.Even though I'm showing you each video effect separatelyfor a clear comparison, all of them work well together.And any combination of the effectscan be applied at the same time.Here's another exciting feature I really want to show youfor Continuity Camera.When you want to work together and share what's on your desk,you can now use Desk View.The Desk View app comes with macOS 13and can be launched right here in Control Center.It works like an overhead camera setup,without needing all the complicated equipment.iPhone will split the Ultra Wide camera feed in two,showing off your desk and face both at the same time,so you can collaborate on a school projector teach a friend a knitting stitch.It leverages the extended vertical field of viewof our Ultra Wide angle camera,applies perspective distortion correction onto cropped frames,and then rotates the frames to create this Desk View.You can use the share window function availablein most video conferencing apps to share this Desk View feed,running in parallel with the main video camera feed.Desk View can also be used alonewithout streaming from the main camera at the same time.But when you do streamfrom both Desk View and the main camera,we recommend enabling Center Stage on the main camerafor a better framing to capture face and body there.The feature is supported when the phone is placedin either landscape or portrait orientation.The portrait orientation provides the most versatility,as there's a larger vertical field of view.There's also a Desk View camera APIto provide customized integrationsuitable for your application.I will talk about the API in a moment.During a video conferencing call on your Mac,we want you to focus on the sessionbut we also want to make sureyou are not missing anything important.When Continuity Camera is in use,all notifications on your phone will be silencedand important call notifications will be forwarded on your Mac.Bye, Eric!Eric: Bye, Karen!Karen: We've just talked aboutall the great experiences available to userswithout writing a single line of new code in your application.But with some adoption of new APIs,you can make the Continuity Camera experienceeven more magical and polished in your app.Now that most users will getat least two camera devices on the Mac,we've thought more on how cameras should be managed.Prior to macOS 13, when a device is either unpluggedor a better camera becomes available on the system,a manual selection stepis usually required in applications.We'd like to offer customers a magical experience byswitching cameras automatically in applications.We've added two new APIs in the AVFoundation frameworkto help you build this function in your app:the class properties userPreferredCameraand systemPreferredCamera on AVCaptureDevice.userPreferredCamera is a read/write property.You will need to set this propertywhenever a user picks a camera in the application.This allows the AVCaptureDevice classto learn users' preference, store a list of camerasfor each application across app launches and reboots,and use that information to suggest a camera.It also takes into account whether any camerabecomes connected or disconnected.This property is key-value observableand intelligently returns the best selectionbased on user preference.When the most recent preferred device becomes disconnected,it spontaneously changesto the next available camera in the list.Even when there's no user selection historyor none of the preferred devices are connected,the property will always try to returna camera device that's ready to useand prioritize cameras that have been previously streamed.It only returns nil when there's no camera availableon the system.systemPreferredCamera is a read-only property.It incorporates userPreferredCameraas well as a few other factorsto suggest the best choice of cameras present on the system.For example, this property will return a different valuethan userPreferredCamera when a Continuity Camera shows upsignaling that it should be automatically chosen.The property also tracks device suspensions internallyso it prioritizes unsuspended devices over suspended ones.This is helpful for building automatic switching behaviorto change to another camera if the built-in cameragets suspended from closing the MacBook lid.Continuity Camera signals itself to be automatically chosenwhen the phone is placed on a stationary standin landscape orientation, the screen is off,and either connected over USB to the Macor within a close range of the Mac.In this scenario, the user's intention is clearthat the device should be used as Continuity Camera.When adopting systemPreferredCamera API,you should always key-value observe this propertyand update your AVCaptureSession'svideo input device accordinglyto offer a magic camera selection experience.userPreferredCamera and systemPreferredCameraare already adopted by first-party applications.With more and more applications adopting these APIs,we will be able to provide customersa universal and consistent method of camera selectionon Apple devices.Let me show you a demo to illustratehow automatic switching with Continuity Cameralooks like in FaceTime.Here in FaceTime,I'm in the Automatic Camera Selection mode.For applications that want to offer bothmanual and automatic behavior, we recommend adding a new UIfor enabling and disabling auto mode.FaceTime is currently streaming from the built-in camera.When I pick up the phone from the deskand place it on a stand behind the MacBook......FaceTime switches to stream from the Continuity Cameraseamlessly.That is where the new class propertysystemPreferredCamera comes in:the property value changes to Continuity Camerawhen the phone is in a position ready to stream.You might want to build your application in a similar way.Here's my recipe for how to implementAutomatic Camera Selection and manual selection mode.When Automatic Camera Selection is on,start key-value observing the systemPreferredCamera property.Follow the systemPreferredCamera whenever it changesby updating your session's input device.In auto mode, we highly recommendstill providing optionsto let users pick a camera by themselves.When a different camera gets picked,set the userPreferredCamera to that device,which then gets reflectedin systemPreferredCamera property value.When Automatic Camera Selection is off,stop key-value observing the systemPreferredCamera property.Instead of following systemPreferredCamera,you will need to update session's input devicewith the user-picked camera in manual mode.But same as auto mode, you still need to setthe userPreferredCamera propertyevery time a user picks a different camera,so we maintain the user's history of preferred camerasand suggest the right camera when getting backto Automatic Camera Selection mode.For best practices on how to incorporate userPreferredCameraand systemPreferredCamera APIs, please check outthe new sample app, "Continuity Camera Sample."Besides bringing a magical webcam experience to the Mac,Continuity Camera also presents you with new opportunitiesto harness the power of iPhone-specific camera featuresin your Mac app.We've added a few AVCapture APIs on macOS 13to help applications better utilizeContinuity Camera devices.We're bringing the amazing quality of iPhone photo capturesto macOS, thanks to Continuity Camera.First off, we support capturing high-resolution photos.Previously, macOS has only supported photo capturesat video resolution.Starting with macOS 13, you will be able to captureup to 12 megapixel photos with Continuity Camera.This can be enabled by first settinghighResolutionCaptureEnabled to trueon AVCapturePhotoOutput object before startinga capture session, and then setting thehighResolutionPhotoEnabled property to trueon your photoSettings object for each capture.In addition to capturing high-res photos,Continuity Camera supports controlling how photo qualityshould be prioritized against speedby first setting the maximum photo quality prioritizationon the photoOutput object,then choosing the prioritization for each capture by settingphotoQualityPrioritization propertyon the AVCapturePhotoSettings object.To learn more about choosing the right prioritizationfor your application, please check out"Capture high-quality photos using video formats"in WWDC2021.Another photo-related feature is flash capture.You can now set flashMode on your photoSettings objectto control whether flash should be on, off,or automatically chosenbased on the scene and lighting conditions.We are also making AVCaptureMetadataOutputavailable on macOS to allow processing timed metadataproduced by a capture session.You can now stream face metadata objectsand human body metadata objects from iPhone.Let's go through how to setup a sessionto receive face metadata objects.After setting up the sessionwith proper video input and output,you will need to create an AVCaptureMetadataOutputand call addOutput to add it to the session.To receive face metadata in particular,set your object types array on the outputto include the face object type.Make sure the metadata types requested are supportedby checkingavailableMetadataObjectTypes property.Then setup the delegate to receive metadata callbacks.After the session starts running,you will get callbackswith face metadata objects produced in real time.Besides AVCapturePhotoOutput and AVCaptureMetadataOutputwe just talked about,Continuity Camera also supports video data output,movie file output, and AVCaptureVideoPreviewLayer.Here's a list of video formats supported by Continuity Camerathat you'll want to be aware ofwhen integrating this camera into your application.It supports three 16 by 9 formats --from 640 by 480 to 1080p --and one 4 by 3 format: 1920 by 1440.You can choose between formatssupporting up to 30 frames per secondor 60 frames per second, based on the need.Another major addition is Desk View device API.Desk View camera is exposed as a separate AVCaptureDevice.There are two ways you can find this device.First one is by looking upAVCaptureDeviceType DeskViewCamerain device discovery session.Alternatively, if you already knowthe AVCaptureDevice object of the main video camera,you can use the companionDeskViewCameraproperty on that device to access a Desk View device.This API will be helpful to pair main cameraand Desk View device when there aremultiple Continuity Camera devices around.Once you have the AVCaptureDevice objectof the desired Desk View camera,you can use it with an AVCapture video data output,movie file output,or video preview layer in the capture sessionjust as you can with other camera devices.Desk View device currently supports one streaming formatin 420v pixel format.The resolution of the format is 1920 by 1440,and the maximum frame rate supported is 30 fps.This is the end of the session.You learned about Continuity Camera,how to build a magical camera selection on macOS,and a handful of new APIs to integrate Continuity Camerain your Mac application.I'm excited to see you adopting all these APIs,and have a great rest of WWDC.♪

♪ instrumental hip hop music ♪♪Hi, my name is Karen Xing.I'm an engineer in the Camera Software team.Welcome to "Bring Continuity Camera supportto your macOS app"To start this session I will talk about,what is Continuity Camera?Next, I will discuss how your applicationcan build an automatic camera selection experiencewith Continuity Camera.And finally, I will walk through the APIsthat are new in macOS 13 for Continuity Camera.With Continuity Camera,you can now use iPhone as your webcam.Setup is seamless;just bring your iPhone close to your Mac.And it works wirelessly so you can quickly join a call.Your iPhone will appear on your Macas an external camera and microphoneunder several conditions.First, you must be running macOS 13 and iOS 16.Both Mac and iPhone must be signed into the same Apple IDusing two-factor authentication.For wired connection,the phone needs to be connected to Mac over USB.Or for wireless connection,the two devices need to be in proximityand have both Bluetooth and Wi-Fi turned on.Rather than talking through it, let me show you right awayhow magical Continuity Camera looks on devices.Here I have a MacBook Pro and iPhone 13 Pro.Both devices are signed in to the same Apple ID.

The phone is placed on a stand attached to my MacBook.I will be joining a video conferencing callwith my colleague Eric todayand show you how we can use Continuity Camera in Zoom.

The app is launched using the built-in camera first,and then an onboarding dialogue shows updescribing what you can do with the new camera.The dialogue shows up one timeafter your Mac is upgraded to macOS 13when you open a camera application for the first timeand there's an iPhone eligible for Continuity Camera.

Hi, Eric!Eric: Oh, Karen! Hi!Karen: After the onboarding dialogue is shown on the system,Continuity Camera and microphone deviceswill become available in all applications.

Let's switch to use this camera and see how it looks.

Continuity Camera uses the rear camera system on the iPhone,so you get the same great video qualitythat you expect from iPhone.And it works with all four orientations of the phone.

The portrait orientation gives you a more zoomed infield of view compared to landscape orientation.

Continuity Camera also lets you do thingsthat were never before possible with a webcam,including several new video effects.You're probably already familiarwith Center Stage and Portrait video effectsintroduced in iOS 14.5 and macOS 12.3.If not, I highly recommend watching the"What's new in Camera Capture" session from WWDC 2021to learn more about system video effectsand how to interact with them in applications.Let's go to Control Center and enable system video effectson Continuity Camera.

Center Stage keeps you in frame as you move around in the scene.

Portrait blurs the backgroundand naturally puts the focus on you.Portrait is only supported on Apple silicon Macs,but with Continuity Camera,it is now available on all Intel and Apple silicon Macs.

Studio Light is a new system video effectavailable on macOS 13.It is supported by Continuity Camerawhen using iPhone 12 or newer.Enable this when you want to look your best on screen.It provides a stunning lighting effectthat dims the background and illuminates your face.Studio Light is perfect for tough lighting situations,like when you're in front of a window.Even though I'm showing you each video effect separatelyfor a clear comparison, all of them work well together.

And any combination of the effectscan be applied at the same time.

Here's another exciting feature I really want to show youfor Continuity Camera.When you want to work together and share what's on your desk,you can now use Desk View.The Desk View app comes with macOS 13and can be launched right here in Control Center.

It works like an overhead camera setup,without needing all the complicated equipment.iPhone will split the Ultra Wide camera feed in two,showing off your desk and face both at the same time,so you can collaborate on a school projector teach a friend a knitting stitch.It leverages the extended vertical field of viewof our Ultra Wide angle camera,applies perspective distortion correction onto cropped frames,and then rotates the frames to create this Desk View.You can use the share window function availablein most video conferencing apps to share this Desk View feed,running in parallel with the main video camera feed.

Desk View can also be used alonewithout streaming from the main camera at the same time.But when you do streamfrom both Desk View and the main camera,we recommend enabling Center Stage on the main camerafor a better framing to capture face and body there.The feature is supported when the phone is placedin either landscape or portrait orientation.The portrait orientation provides the most versatility,as there's a larger vertical field of view.There's also a Desk View camera APIto provide customized integrationsuitable for your application.I will talk about the API in a moment.During a video conferencing call on your Mac,we want you to focus on the sessionbut we also want to make sureyou are not missing anything important.When Continuity Camera is in use,all notifications on your phone will be silencedand important call notifications will be forwarded on your Mac.Bye, Eric!Eric: Bye, Karen!Karen: We've just talked aboutall the great experiences available to userswithout writing a single line of new code in your application.But with some adoption of new APIs,you can make the Continuity Camera experienceeven more magical and polished in your app.Now that most users will getat least two camera devices on the Mac,we've thought more on how cameras should be managed.Prior to macOS 13, when a device is either unpluggedor a better camera becomes available on the system,a manual selection stepis usually required in applications.We'd like to offer customers a magical experience byswitching cameras automatically in applications.We've added two new APIs in the AVFoundation frameworkto help you build this function in your app:the class properties userPreferredCameraand systemPreferredCamera on AVCaptureDevice.userPreferredCamera is a read/write property.You will need to set this propertywhenever a user picks a camera in the application.This allows the AVCaptureDevice classto learn users' preference, store a list of camerasfor each application across app launches and reboots,and use that information to suggest a camera.It also takes into account whether any camerabecomes connected or disconnected.This property is key-value observableand intelligently returns the best selectionbased on user preference.When the most recent preferred device becomes disconnected,it spontaneously changesto the next available camera in the list.Even when there's no user selection historyor none of the preferred devices are connected,the property will always try to returna camera device that's ready to useand prioritize cameras that have been previously streamed.It only returns nil when there's no camera availableon the system.systemPreferredCamera is a read-only property.It incorporates userPreferredCameraas well as a few other factorsto suggest the best choice of cameras present on the system.For example, this property will return a different valuethan userPreferredCamera when a Continuity Camera shows upsignaling that it should be automatically chosen.The property also tracks device suspensions internallyso it prioritizes unsuspended devices over suspended ones.This is helpful for building automatic switching behaviorto change to another camera if the built-in cameragets suspended from closing the MacBook lid.Continuity Camera signals itself to be automatically chosenwhen the phone is placed on a stationary standin landscape orientation, the screen is off,and either connected over USB to the Macor within a close range of the Mac.In this scenario, the user's intention is clearthat the device should be used as Continuity Camera.

When adopting systemPreferredCamera API,you should always key-value observe this propertyand update your AVCaptureSession'svideo input device accordinglyto offer a magic camera selection experience.userPreferredCamera and systemPreferredCameraare already adopted by first-party applications.With more and more applications adopting these APIs,we will be able to provide customersa universal and consistent method of camera selectionon Apple devices.Let me show you a demo to illustratehow automatic switching with Continuity Cameralooks like in FaceTime.

Here in FaceTime,I'm in the Automatic Camera Selection mode.For applications that want to offer bothmanual and automatic behavior, we recommend adding a new UIfor enabling and disabling auto mode.

FaceTime is currently streaming from the built-in camera.When I pick up the phone from the deskand place it on a stand behind the MacBook...

...FaceTime switches to stream from the Continuity Cameraseamlessly.That is where the new class propertysystemPreferredCamera comes in:the property value changes to Continuity Camerawhen the phone is in a position ready to stream.You might want to build your application in a similar way.Here's my recipe for how to implementAutomatic Camera Selection and manual selection mode.When Automatic Camera Selection is on,start key-value observing the systemPreferredCamera property.Follow the systemPreferredCamera whenever it changesby updating your session's input device.In auto mode, we highly recommendstill providing optionsto let users pick a camera by themselves.When a different camera gets picked,set the userPreferredCamera to that device,which then gets reflectedin systemPreferredCamera property value.When Automatic Camera Selection is off,stop key-value observing the systemPreferredCamera property.Instead of following systemPreferredCamera,you will need to update session's input devicewith the user-picked camera in manual mode.But same as auto mode, you still need to setthe userPreferredCamera propertyevery time a user picks a different camera,so we maintain the user's history of preferred camerasand suggest the right camera when getting backto Automatic Camera Selection mode.For best practices on how to incorporate userPreferredCameraand systemPreferredCamera APIs, please check outthe new sample app, "Continuity Camera Sample."Besides bringing a magical webcam experience to the Mac,Continuity Camera also presents you with new opportunitiesto harness the power of iPhone-specific camera featuresin your Mac app.We've added a few AVCapture APIs on macOS 13to help applications better utilizeContinuity Camera devices.We're bringing the amazing quality of iPhone photo capturesto macOS, thanks to Continuity Camera.First off, we support capturing high-resolution photos.Previously, macOS has only supported photo capturesat video resolution.Starting with macOS 13, you will be able to captureup to 12 megapixel photos with Continuity Camera.This can be enabled by first settinghighResolutionCaptureEnabled to trueon AVCapturePhotoOutput object before startinga capture session, and then setting thehighResolutionPhotoEnabled property to trueon your photoSettings object for each capture.In addition to capturing high-res photos,Continuity Camera supports controlling how photo qualityshould be prioritized against speedby first setting the maximum photo quality prioritizationon the photoOutput object,then choosing the prioritization for each capture by settingphotoQualityPrioritization propertyon the AVCapturePhotoSettings object.To learn more about choosing the right prioritizationfor your application, please check out"Capture high-quality photos using video formats"in WWDC2021.Another photo-related feature is flash capture.You can now set flashMode on your photoSettings objectto control whether flash should be on, off,or automatically chosenbased on the scene and lighting conditions.We are also making AVCaptureMetadataOutputavailable on macOS to allow processing timed metadataproduced by a capture session.You can now stream face metadata objectsand human body metadata objects from iPhone.Let's go through how to setup a sessionto receive face metadata objects.After setting up the sessionwith proper video input and output,you will need to create an AVCaptureMetadataOutputand call addOutput to add it to the session.To receive face metadata in particular,set your object types array on the outputto include the face object type.Make sure the metadata types requested are supportedby checkingavailableMetadataObjectTypes property.Then setup the delegate to receive metadata callbacks.After the session starts running,you will get callbackswith face metadata objects produced in real time.Besides AVCapturePhotoOutput and AVCaptureMetadataOutputwe just talked about,Continuity Camera also supports video data output,movie file output, and AVCaptureVideoPreviewLayer.Here's a list of video formats supported by Continuity Camerathat you'll want to be aware ofwhen integrating this camera into your application.It supports three 16 by 9 formats --from 640 by 480 to 1080p --and one 4 by 3 format: 1920 by 1440.You can choose between formatssupporting up to 30 frames per secondor 60 frames per second, based on the need.Another major addition is Desk View device API.Desk View camera is exposed as a separate AVCaptureDevice.There are two ways you can find this device.First one is by looking upAVCaptureDeviceType DeskViewCamerain device discovery session.Alternatively, if you already knowthe AVCaptureDevice object of the main video camera,you can use the companionDeskViewCameraproperty on that device to access a Desk View device.This API will be helpful to pair main cameraand Desk View device when there aremultiple Continuity Camera devices around.Once you have the AVCaptureDevice objectof the desired Desk View camera,you can use it with an AVCapture video data output,movie file output,or video preview layer in the capture sessionjust as you can with other camera devices.Desk View device currently supports one streaming formatin 420v pixel format.The resolution of the format is 1920 by 1440,and the maximum frame rate supported is 30 fps.This is the end of the session.You learned about Continuity Camera,how to build a magical camera selection on macOS,and a handful of new APIs to integrate Continuity Camerain your Mac application.I'm excited to see you adopting all these APIs,and have a great rest of WWDC.♪

## Code Samples

