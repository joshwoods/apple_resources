# Wwdc2022 10078

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Reduce networking delays for a more responsive appFind out how network latency can affect your apps when trying to get full benefit out of modern network throughput rates. Learn about changes you can make in your app and on your server to boost responsiveness, and prepare your app for improvements coming to the Internet that will offer even lower end-to-end delays.ResourcesNetwork Quality test in GoNetwork Speedtest by OoklaResponsiveness Test Server configuration instructionsWaveform bufferbloat testHD VideoSD VideoRelated VideosWWDC23Reduce network delays with L4SWWDC22Enhance voice communication with Push to TalkWWDC21Accelerate networking with HTTP/3 and QUICReduce network delays for your app

Find out how network latency can affect your apps when trying to get full benefit out of modern network throughput rates. Learn about changes you can make in your app and on your server to boost responsiveness, and prepare your app for improvements coming to the Internet that will offer even lower end-to-end delays.

Network Quality test in Go

Network Speedtest by Ookla

Responsiveness Test Server configuration instructions

Waveform bufferbloat test

HD VideoSD Video

HD Video

SD Video

Reduce network delays with L4S

Enhance voice communication with Push to Talk

Accelerate networking with HTTP/3 and QUIC

Reduce network delays for your app

Search this video…♪ Mellow instrumental hip-hip music ♪♪Hi, I am Vidhi Goel, and in this video,I will talk about how to reduce networking delays in your appsand make them more responsive.First, I will explain why reducing latency is crucialin making your apps responsive.Next, I will go over a listof things that you can do in your appand on your server to get rid of unnecessary delays.Finally, I will show what you can do to reduce delaysin the network itself.Network latency is the time it takes for datato get from one endpoint to another.It determines how quickly content can be deliveredto your app.All apps that use networking can be affectedby slow network transactionsthat result in a poor app experience.For example, video calls can sometimes freezeor become laggy, which can interrupt meetings.To address this, people often call uptheir service provider to upgrade their bandwidth,and yet, the problem still exists.To get to the root cause of this problem,you need to understand how your app's packetstravel in a network.When your app or framework requests data from a server,packets are sent out by the networking stack.It is often assumed that the packets go directlyto the server with no delays in the network.But, in reality, the slowest link of the networkusually has a large queue of packets to process.So, the packet from your appactually waits behind this large queueuntil the packets ahead of it are processed.This queuing at the slowest link increases the durationof each round trip between your app and your server.This problem is aggravated when it takes multiple round tripsto get the first response for your app's request.For example, the time to get the first response packetwhen using TLS 1.2 over TCPis the duration of each round tripmultiplied by four trips.Given that each round-trip time is already inflatedby queuing in the network,the resulting total time is simply too long.There are two factors that multiply togetherto determine your app's responsiveness:the duration of each round trip and the number of round trips.Reducing these will lower your app's latency,and increase your app's responsiveness.There was a study examining the impactof increasing bandwidth versus decreasing latencyon page load time.In the first test, latency is kept fixedand bandwidth is increased incrementally from 1 to 10Mbps.At first, increasing the bandwidth from 1 to 2Mbpsreduces page load time by almost 40 percent,which is great.But after 4Mbps, each incremental increaseresults in almost no improvement in the page load time.This is why apps can be slow even after upgradingto Gigabit Internet.On the other hand, the results for the latency test showthat for every 20 millisecond decrease in latency,there is a linear improvement in page load time.And these results apply to all network activityin your apps.Now, I will go over a few simple actions you can taketo reduce latency and make your app more responsive.You can reduce your app's latency significantlyby adopting modern protocolssuch as IPv6, TLS 1.3 and HTTP/3.And all you need to do is use URLSessionand Network.framework APIs in your appand these protocols will be used automaticallyonce they are enabled on your server.Since its rollout, we have seen a constant increasein HTTP/3 usage, and within just a year,20 percent of web traffic already uses HTTP/3,and it continues to grow.Comparing Safari traffic for different HTTP versions,HTTP/3 is the fastest of them all.HTTP/3 requests take a little over half the timeas compared to HTTP/1,when looking at median request completion timeas a multiple of round-trip time.This means your app's requests will complete much faster.When a device moves from Wi-Fi to cellular,it takes time to reestablish new connectionsand that can make your application stall.Using connection migration eliminates those stalls.To opt in, set the multipathServiceType propertyto .handover on your URLSession configuration,or on your NWParameters.Enable this option and make sure it works with your app.If you design your own protocol that uses UDP directly,iOS 16 and macOS Ventura introduce a better wayto send datagrams.QUIC datagrams provide many benefits over plain UDP,the most important being that QUIC datagramsreact to congestion in the networkwhich keeps the round-trip time low and reduces packet loss.To opt in on the client,set isDatagram to true on your QUIC optionsand set the maximum datagram frame size you want to use.After creating the datagram flow,you can send and receive on it just like any other QUIC stream.Now you know what to do in your appto reduce latency.Next, I will explain how servers impactyour app's responsiveness.Despite often running on top-of-the-line hardware,it is possible that your server actually becomes the reasonfor slowness in your app.We introduced the network quality tool in macOS Monterey,and you can use this toolto measure buffer bloat in your service provider's networkas well as on your server.You need to configure your server to act as a destinationfor the network quality tool.Once you have done that, run the networkQuality tool,first against Apple's default serverand then against your own configured server.If the tool scores well using the default server,but not so well when talking to your own server,there may be room to improve the responsivenessof your server.Now, I will show you an example where we used this techniqueto improve something that all of you are doing right now --streaming video.You may have had the experiencewhere you skip ahead to a different place in a videoand you end up waiting a long time while it rebuffers.So, we investigated the reason for this slownessin random access.We used the network quality toolto test the behavior of a streaming serverand we found that the responsiveness score was poor.On the right side, I streamed a WWDC video.Then, I skipped ahead in the video.The screen didn't display anythingwhile the video rebuffered.After a few seconds, the video showed up.With the help of detailed outputfrom the network quality tool on macOS,we found that there was huge queuing at the server.So we took a look at the server configuration.Specifically we looked at TCP, TLS, and HTTP buffer sizes,which were configured to 4MB, 256KB, and 4MB, respectively.The buffers were huge because RAM is plentiful.But just because some buffering is good,doesn't always mean that more buffering is better.Our responsiveness measurements highlighted this exact issue --a newly generated packet was queued behind stale datain these large buffers,and this created a lot of additional delayin delivering the most recent packet.So, we reduced the buffer size to 256KB for HTTP,16KB for TLS, and 128KB for TCP.This is the config file for Apache Traffic Serverwhich shows the options that were configured.TCP not-sent low-water mark was set to 128KBalong with other options that were enabled to lower buffering.For TLS, we enabled dynamic record sizesand for HTTP/2, we reduced the low-water markand buffer block size.We recommend using these configurationsfor your Apache Traffic Server,and if you are using a different web server,look for its equivalent options.After making these changes,we ran the network quality tool again.And this time we got a high RPM score!On the right, I streamed the same video,but this time when I skipped ahead,the video resumed instantly.By getting rid of unnecessary queuing at the server,we made random access much more responsive.Regardless of how your app uses networking,these changes on your server can make your app more responsiveand deliver a better user experience.That's how to improve your app and update your server.There is a third factor that affects responsiveness greatly;the network itself.Apple introduced the network quality tool in iOS 15and macOS Monterey.Since then, others have used the same methodologyto develop network quality tests.Waveform has launched a Bufferbloat test.There's an open source implementationof the responsiveness test, written in Go.And Ookla has added a responsiveness measurementto their Speedtest app.Ookla's app shows round trip time in milliseconds,and if you divide 60,000 by that number,you get the number of round trips per minute, or RPM.You can use these tools to measurehow well your own network is performing.The best way to understand delays in a networkis with a delay-sensitive application.So, I will show you my screen sharing experienceto a remote machine.I set up network conditionsto mimic a representative access network,with traffic from other devices sharing that network.Here, I logged on to my remote machine using Screen Sharing.I clicked on different Finder menusbut the display of each menu was very sluggish.To check how much this interaction was delayed,I launched an app that displays time on my local machine,and I launched the same app on my remote machine.Even though time on these computers is synchronized,my remote screen didn't update regularlyand showed time delayed by a few seconds.The reason for this delayed updatewas the presence of a large queueat the slowest link of the networkand packets from the Screen Sharing appwere stuck in this large queue.To solve this queuing issue,Apple is working with the networking communityon a new technology called L4S.It is available as a beta in iOS 16 and macOS Ventura.L4S reduces queuing delay significantlyand also achieves zero congestion loss.To keep a consistently short queue,the network explicitly signals congestioninstead of dropping packets,and the sender adjusts its sending ratebased on the congestion feedback from the network.This makes it possible to keep very low queuing in the networkwithout any packet loss,and that will make your app highly responsive.Now, let's look at how L4S improved Screen Sharing.Here, I used the same machines and the same networkexcept this time, I enabled L4S.When I clicked on different Finder menus,they opened immediately.I launched the Time app on both the machines.And now, time on both the remote screenand the local machine is almost perfectly in sync.This technology is not just for screen sharing.L4S improves all of today's apps,and opens the door for future appsthat wouldn't even be possible today.This chart plots the observed average round trip timeof packets from the Screen Sharing appwhich was running concurrently with trafficfrom other devices sharing the same network.Comparing classic queuing versus L4Sshows that there is a massive reductionin round trip time with L4S.This is the primary reason for the dramatic improvementin my screen-sharing experience.Test your app that uses HTTP/3 or QUIC with L4S.You can enable L4S in iOS 16 inside Developer settingsor on macOS Ventura via a defaults write.To test using a Linux server,your QUIC implementation needs to support accurate ECNand a scalable congestion control algorithm.To ensure that you are readywhen L4S-capable networks are deployed,test your app for compatibility with L4S,and provide feedback with any issues you might encounter.Now you know that reducing latency is crucialto improve your app's responsiveness.So, adopt HTTP/3 and QUIC,to reduce the number of round tripsand for faster delivery of content to your app.Eliminate unnecessary queuing on your serverto provide a more responsive interaction.Test your app's compatibility with L4S by enabling itin Developer settings and provide feedback.And finally, talk to your server providerabout enabling L4S support.Thanks for watching!♪

♪ Mellow instrumental hip-hip music ♪♪Hi, I am Vidhi Goel, and in this video,I will talk about how to reduce networking delays in your appsand make them more responsive.First, I will explain why reducing latency is crucialin making your apps responsive.Next, I will go over a listof things that you can do in your appand on your server to get rid of unnecessary delays.Finally, I will show what you can do to reduce delaysin the network itself.Network latency is the time it takes for datato get from one endpoint to another.It determines how quickly content can be deliveredto your app.All apps that use networking can be affectedby slow network transactionsthat result in a poor app experience.For example, video calls can sometimes freezeor become laggy, which can interrupt meetings.To address this, people often call uptheir service provider to upgrade their bandwidth,and yet, the problem still exists.To get to the root cause of this problem,you need to understand how your app's packetstravel in a network.When your app or framework requests data from a server,packets are sent out by the networking stack.It is often assumed that the packets go directlyto the server with no delays in the network.But, in reality, the slowest link of the networkusually has a large queue of packets to process.So, the packet from your appactually waits behind this large queueuntil the packets ahead of it are processed.This queuing at the slowest link increases the durationof each round trip between your app and your server.This problem is aggravated when it takes multiple round tripsto get the first response for your app's request.For example, the time to get the first response packetwhen using TLS 1.2 over TCPis the duration of each round tripmultiplied by four trips.Given that each round-trip time is already inflatedby queuing in the network,the resulting total time is simply too long.There are two factors that multiply togetherto determine your app's responsiveness:the duration of each round trip and the number of round trips.Reducing these will lower your app's latency,and increase your app's responsiveness.There was a study examining the impactof increasing bandwidth versus decreasing latencyon page load time.In the first test, latency is kept fixedand bandwidth is increased incrementally from 1 to 10Mbps.At first, increasing the bandwidth from 1 to 2Mbpsreduces page load time by almost 40 percent,which is great.But after 4Mbps, each incremental increaseresults in almost no improvement in the page load time.This is why apps can be slow even after upgradingto Gigabit Internet.On the other hand, the results for the latency test showthat for every 20 millisecond decrease in latency,there is a linear improvement in page load time.And these results apply to all network activityin your apps.Now, I will go over a few simple actions you can taketo reduce latency and make your app more responsive.You can reduce your app's latency significantlyby adopting modern protocolssuch as IPv6, TLS 1.3 and HTTP/3.And all you need to do is use URLSessionand Network.framework APIs in your appand these protocols will be used automaticallyonce they are enabled on your server.Since its rollout, we have seen a constant increasein HTTP/3 usage, and within just a year,20 percent of web traffic already uses HTTP/3,and it continues to grow.Comparing Safari traffic for different HTTP versions,HTTP/3 is the fastest of them all.HTTP/3 requests take a little over half the timeas compared to HTTP/1,when looking at median request completion timeas a multiple of round-trip time.This means your app's requests will complete much faster.When a device moves from Wi-Fi to cellular,it takes time to reestablish new connectionsand that can make your application stall.Using connection migration eliminates those stalls.To opt in, set the multipathServiceType propertyto .handover on your URLSession configuration,or on your NWParameters.Enable this option and make sure it works with your app.If you design your own protocol that uses UDP directly,iOS 16 and macOS Ventura introduce a better wayto send datagrams.QUIC datagrams provide many benefits over plain UDP,the most important being that QUIC datagramsreact to congestion in the networkwhich keeps the round-trip time low and reduces packet loss.To opt in on the client,set isDatagram to true on your QUIC optionsand set the maximum datagram frame size you want to use.After creating the datagram flow,you can send and receive on it just like any other QUIC stream.Now you know what to do in your appto reduce latency.Next, I will explain how servers impactyour app's responsiveness.Despite often running on top-of-the-line hardware,it is possible that your server actually becomes the reasonfor slowness in your app.We introduced the network quality tool in macOS Monterey,and you can use this toolto measure buffer bloat in your service provider's networkas well as on your server.You need to configure your server to act as a destinationfor the network quality tool.Once you have done that, run the networkQuality tool,first against Apple's default serverand then against your own configured server.If the tool scores well using the default server,but not so well when talking to your own server,there may be room to improve the responsivenessof your server.Now, I will show you an example where we used this techniqueto improve something that all of you are doing right now --streaming video.

You may have had the experiencewhere you skip ahead to a different place in a videoand you end up waiting a long time while it rebuffers.So, we investigated the reason for this slownessin random access.We used the network quality toolto test the behavior of a streaming serverand we found that the responsiveness score was poor.On the right side, I streamed a WWDC video.Then, I skipped ahead in the video.The screen didn't display anythingwhile the video rebuffered.After a few seconds, the video showed up.With the help of detailed outputfrom the network quality tool on macOS,we found that there was huge queuing at the server.So we took a look at the server configuration.Specifically we looked at TCP, TLS, and HTTP buffer sizes,which were configured to 4MB, 256KB, and 4MB, respectively.The buffers were huge because RAM is plentiful.But just because some buffering is good,doesn't always mean that more buffering is better.Our responsiveness measurements highlighted this exact issue --a newly generated packet was queued behind stale datain these large buffers,and this created a lot of additional delayin delivering the most recent packet.So, we reduced the buffer size to 256KB for HTTP,16KB for TLS, and 128KB for TCP.

This is the config file for Apache Traffic Serverwhich shows the options that were configured.TCP not-sent low-water mark was set to 128KBalong with other options that were enabled to lower buffering.For TLS, we enabled dynamic record sizesand for HTTP/2, we reduced the low-water markand buffer block size.We recommend using these configurationsfor your Apache Traffic Server,and if you are using a different web server,look for its equivalent options.After making these changes,we ran the network quality tool again.And this time we got a high RPM score!On the right, I streamed the same video,but this time when I skipped ahead,the video resumed instantly.By getting rid of unnecessary queuing at the server,we made random access much more responsive.Regardless of how your app uses networking,these changes on your server can make your app more responsiveand deliver a better user experience.That's how to improve your app and update your server.There is a third factor that affects responsiveness greatly;the network itself.Apple introduced the network quality tool in iOS 15and macOS Monterey.Since then, others have used the same methodologyto develop network quality tests.Waveform has launched a Bufferbloat test.There's an open source implementationof the responsiveness test, written in Go.And Ookla has added a responsiveness measurementto their Speedtest app.Ookla's app shows round trip time in milliseconds,and if you divide 60,000 by that number,you get the number of round trips per minute, or RPM.You can use these tools to measurehow well your own network is performing.The best way to understand delays in a networkis with a delay-sensitive application.So, I will show you my screen sharing experienceto a remote machine.I set up network conditionsto mimic a representative access network,with traffic from other devices sharing that network.Here, I logged on to my remote machine using Screen Sharing.

I clicked on different Finder menusbut the display of each menu was very sluggish.To check how much this interaction was delayed,I launched an app that displays time on my local machine,and I launched the same app on my remote machine.Even though time on these computers is synchronized,my remote screen didn't update regularlyand showed time delayed by a few seconds.The reason for this delayed updatewas the presence of a large queueat the slowest link of the networkand packets from the Screen Sharing appwere stuck in this large queue.

To solve this queuing issue,Apple is working with the networking communityon a new technology called L4S.It is available as a beta in iOS 16 and macOS Ventura.L4S reduces queuing delay significantlyand also achieves zero congestion loss.To keep a consistently short queue,the network explicitly signals congestioninstead of dropping packets,and the sender adjusts its sending ratebased on the congestion feedback from the network.This makes it possible to keep very low queuing in the networkwithout any packet loss,and that will make your app highly responsive.Now, let's look at how L4S improved Screen Sharing.Here, I used the same machines and the same networkexcept this time, I enabled L4S.When I clicked on different Finder menus,they opened immediately.I launched the Time app on both the machines.And now, time on both the remote screenand the local machine is almost perfectly in sync.This technology is not just for screen sharing.L4S improves all of today's apps,and opens the door for future appsthat wouldn't even be possible today.This chart plots the observed average round trip timeof packets from the Screen Sharing appwhich was running concurrently with trafficfrom other devices sharing the same network.Comparing classic queuing versus L4Sshows that there is a massive reductionin round trip time with L4S.This is the primary reason for the dramatic improvementin my screen-sharing experience.Test your app that uses HTTP/3 or QUIC with L4S.You can enable L4S in iOS 16 inside Developer settingsor on macOS Ventura via a defaults write.To test using a Linux server,your QUIC implementation needs to support accurate ECNand a scalable congestion control algorithm.To ensure that you are readywhen L4S-capable networks are deployed,test your app for compatibility with L4S,and provide feedback with any issues you might encounter.Now you know that reducing latency is crucialto improve your app's responsiveness.So, adopt HTTP/3 and QUIC,to reduce the number of round tripsand for faster delivery of content to your app.Eliminate unnecessary queuing on your serverto provide a more responsive interaction.Test your app's compatibility with L4S by enabling itin Developer settings and provide feedback.And finally, talk to your server providerabout enabling L4S support.Thanks for watching!♪

6:21 -Enable connection migration on URLSessionConfiguration for HTTP/3

6:29 -Enable connection migration on NWParameters for QUIC

7:08 -Opt-in to QUIC datagrams

8:12 -Network quality tool in MacOS

10:59 -Recommended configuration for Apache Traffic Server

12:52 -Responsiveness tests

17:12 -Enable L4S for QUIC on Mac

## Code Samples

```swift
let
 configuration 
=
 
URLSessionConfiguration
.default
configuration.multipathServiceType 
=
 .handover
```

```swift
let
 parameters 
=
 
NWParameters
.quic(alpn: [
"myproto"
])
parameters.multipathServiceType 
=
 .handover
```

```swift
// Only one datagram flow can be created per connection


let
 options 
=
 
NWProtocolQUIC
.
Options
()
options.isDatagram 
=
 
true

options.maxDatagramFrameSize 
=
 
65535
```

```swift
networkQuality -s -C https://myserver.example.com/config
```

```swift
% cat /opt/ats/etc/trafficserver/records.config


# Set not-sent low-water mark trigger threshold to 128 kilobytes

CONFIG proxy.config.net.sock
_notsent_
lowat INT 131072


# Set Socket Options flag to the sum of the options we want


# TCP
_NODELAY(1) + TCP_
FASTOPEN(8) + TCP
_NOTSENT_
LOWAT(64) = 73

CONFIG proxy.config.net.sock
_option_
flag
_in INT 73

...

# Enable Dynamic TLS record sizes
CONFIG proxy.config.ssl.max_
record
_size INT -1

...

# Reduce low-water mark and buffer block size for HTTP/2
CONFIG proxy.config.http2.default_
buffer
_water_
mark INT  32768
CONFIG proxy.config.http2.write
_buffer_
block
_size   INT 262144
```

```swift
https://www.waveform.com/tools/bufferbloat
https://github.com/network-quality/goresponsiveness
https://www.speedtest.net/
```

```swift
defaults write -g network_enable_l4s -bool 
true
```

