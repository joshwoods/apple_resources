# Wwdc2022 110361

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Author fast and reliable tests for Xcode CloudDiscover how you can create effective testing plans for Xcode Cloud, Apple's continuous integration and continuous delivery service. We'll show you how testing can be an essential tool to consistently verify your code works correctly. Learn how you can author fast, reliable, and efficient tests for Xcode Cloud, avoid irrelevant failures, and verify your code changes quickly.ResourcesHD VideoSD VideoRelated VideosWWDC23Create practical workflows in Xcode CloudWWDC22Deep dive into Xcode Cloud for teamsGet the most out of Xcode CloudWhat's new in XcodeWWDC22 Day 4 recapWWDC21Customize your advanced Xcode Cloud workflowsDiagnose unreliable code with test repetitionsEmbrace Expected Failures in XCTestMeet Xcode CloudWWDC20Get your test results fasterWrite tests to failXCTSkip your testsWWDC19Testing in XcodeWWDC18Testing Tips & Tricks

Discover how you can create effective testing plans for Xcode Cloud, Apple's continuous integration and continuous delivery service. We'll show you how testing can be an essential tool to consistently verify your code works correctly. Learn how you can author fast, reliable, and efficient tests for Xcode Cloud, avoid irrelevant failures, and verify your code changes quickly.

HD VideoSD Video

HD Video

SD Video

Create practical workflows in Xcode Cloud

Deep dive into Xcode Cloud for teams

Get the most out of Xcode Cloud

What's new in Xcode

WWDC22 Day 4 recap

Customize your advanced Xcode Cloud workflows

Diagnose unreliable code with test repetitions

Embrace Expected Failures in XCTest

Meet Xcode Cloud

Get your test results faster

Write tests to fail

XCTSkip your tests

Testing in Xcode

Testing Tips & Tricks

Search this video…Suzy: Hello and welcome to "Author fast and reliable tests for Xcode Cloud."I'm Suzy, and I work on XCTest.In this session, I'm going to share the most effective waysto start testing for Xcode Cloud.Our teams designed Xcode Cloud to be a powerful tool for all developers.In fact, we use it to test Xcode itself, and I love it.One of my favorite features of Xcode Cloudis its ability to substantially broaden a given test suite.By configuring most tests to run in the cloud,you now have a practical way to run tests on multiple destinations,including those running differing operating system versionsto leverage diverse platforms such as an iPhone, iPad,Apple Watch, Apple TV, and Mac,and to run various test plan configurations,allowing for runtime analysis toolssuch as address and thread sanitizers.Once we have passed such a thorough test suite,we can be confident the code is ready to ship.Offloading tests to Xcode Cloud allows for running a broader set of testswithout impacting the developers’ desktop cycle of code, compile, and test.With this now expanded test suite,there is a potential for an increased number of unreliable tests.This situation can become unmanageable.As such, ensuring reliability is essential.In addition to reliability, such a large number of testsalso needs to run efficientlyso as to limit their impact on the continuous integration process.Let’s address reliability first.I will demonstrate how to author more reliable tests for Xcode Cloudusing Food Truck.Food Truck is an app that converts taps and swipes into delicious donuts.By running the test suite in Xcode Cloud,we are able to validate that all Apple platformssupport ordering my favorite donut, chocolate with sprinkles.Each improvement to the Xcode Cloud Workflowwill be identified and demonstrated.For more information about getting started with Xcode Cloud Workflows,watch "Meet Xcode Cloud.”The first step to author more reliable testsis to ensure each test’s setup and tear down is thorough.Tests run in Xcode Cloud make use of a fresh simulatorwhich may not meet developers’ original assumptions.Let’s identify a number of device configuration assumptionssometimes seen in test code.Certain tests may rely on specific dates and times.For example, a server may be running in a different time zone.Tests should avoid being time zone specific.Locale-based values, such as number formattingand language directionality, can lead to unexpected results.Avoid this problem by explicitly setting your simulator’s locale.Another problematic assumption is reliance on certain device permissionssuch as internet access.It’s best to mock device permissions in a unit testand use an alert handler in a UI Test.Finally, some tests depend on preloaded data.For example, a test may expect to have an empty documents directory.While explicitly configuring the simulator is sometimes the easiest choice,enhancing the test’s setup method is generally more robust.For example, the Food Truck depends on a menu file.As part of instantiating the truck object in the setup function,we generate a mock data file containing the donut menu items.Note that rather than relying on teardown methods to prepare for subsequent tests,we recommend establishing all state preparation in the setup method.In many cases, read-only files can be checked into the repositoryand later accessed by tests.However, when these files need to be constructed,Xcode Cloud supports running a custom build scriptwhere you can generate the file once for multiple tests to access.For more details on how to configure your script,watch "Customize your advanced Xcode Cloud workflow."That wraps up proper simulator setup.Now, let’s cover how to handle tests that fail to meet preconditions.XCTSkip is an error that instructs the XCTest Runnerto cease executing the current test and mark it as skipped.This may be used to bypass a yet-to-be supported OS version or device type.You could also leverage XCTSkip by setting an environment variableto skip tests specific to staging or production environments.Let’s go over how we can control test flow using an environment variable.Environment variables can provide parametersto both the XCTest test runner app on your deviceand the test host running xcodebuild.In Xcode Cloud, environment variables prefixed with TEST_RUNNER_get passed into the XCTest test runner.This prefix will be stripped prior tothe variable being made available to your code.So, for example, a variable in your test codenamed BASE_URL would be passed in as the environment variablenamed TEST_RUNNER_BASE_URL.Test plans require the same format as test code.Namely, we do not add the TEST_RUNNER_ prefix.Environment variables may be referenced anywhere in test code.For example, they could be used with XCTSkipto skip the test for actually ordering donutswhen we are in a production environment.Unless you are hungry, of course.It’s important to keep in mindthat redefining an environment variable in multiple places,such as both a test plan and the Xcode Cloud User Interface,can lead to unexpected results.In this particular case, Xcode Cloud’s Environment variableswill take precedence over what’s specified in your project’s test plans.Now that we are referencing our environment variable within our test code,we can set its value in the Xcode Cloud User Interface.To do this, navigate to your Cloud Reports,and control-click on Food Truck.To edit our environment variables within our Workflows,we will select "Manage Workflows" in the context menu.We are editing the integration workflow specifically,so we will double click on it.Now, in the sidebar, we can select "Environment,"and in the middle of the sheet, under “Environment Variables,"we can add the variable’s name and value.As an alternative to setting the environment variablein the Xcode Cloud Workflow,we could instead set it within the test plan.In this example, we don’t yet have a test plan.To enable test plans, open the scheme editor,select "Test" in the sidebar,and then click on “Convert to Use Test Plans."Okay, now we have a test plan I called "Food Truck."To add the environment variable,we need to click on the test plan to open its editor.Near the top, we can select between "Tests" and "Configurations."Let’s select "Configurations."Now, within the "Arguments" section,we will add the variable by clicking on "Environment Variables."A popup will appear where we can enter the variable’s name and value.Now our test will be skipped when in the production environment.To learn more about skipping tests,watch "XCTSkip your tests."Now that we covered utilizing environment variables to control XCTSkip,let’s talk about expectation timeouts.It is possible for a test to fail due to an unexpected timeout.For example, this could be the result of a slow serveror an overly anxious user interface test.One approach to resolve either issuewould be to increase the XCTestExpectation timeoutso the interaction would have enough time to finish.In this example, we increase the OrderDonut timeoutfrom 5 to 10 seconds to allow the server more time to respond.It is usually preferable to instead replace both the appand test code timeout handling with async/await.This approach allows the test to pauseuntil the await call finishes without any timeout.We have resolved time dependent tests,so let’s handle any test failures within the test suite.For example, we have a test that relies on a servicewithin the staging environment that is down for maintenance.We can use XCTExpectFailure instead of disabling or skipping this test.With XCTExpectFailure, your test executes normallyand the results are transformed as follows:a failure in a test will now be reported as an expected failure,while that failed test within its suite will be reported as a pass.This approach eliminates the noise generated by expected failures.For example, testOrderDonut is failing.I know that the service that provides ordering donutsis under maintenance right now,so I added a call here to XCTExpectFailure.To learn more about XCTExpectFailurewatch "Embrace Expected Failures in XCTest."Now that we've declared expected failures,let’s leverage test repetitions to substantiate codeand diagnose unreliable code.Test repetitions is a tool that runs the same test multiple timeswaiting for the following:the first failure, the first success, or a statistical result.For example, at our desk,we run our new code and test cases multiple timeswith repetitions to confirm initial app and test code reliabilitybefore checking in the code.We were able to detect that testOrderDonut had only an 80% success rate.Uh-oh!Knowing the failure exists, we now use the repeat-until-failure modeto locally diagnose the bug.This is another way of utilizing test repetitions.For tests that rely on an unreliable external service,you may want to leverage the retry-on-failure repetition policyto confirm a test can succeed.While retrying tests is a powerful approach,it’s preferable to instead mock external services when possible.Advantages of a mocked service include deterministic reliability and speed.To learn how to mock your dependencies,watch “Testing Tips & Tricks.”Let’s explore how test repetitions can be enabled.To enable test repetitions in your test plan,go back to the test plan editor and select "Configurations."Then, under the "Test Execution" section,there is a popup to select your test repetition mode.In this case, we will select "Retry on Failure,"which is used primarily to work around unreliable external services.Now we have our test repetition mode enabled.For more information on leveraging test repetitions,watch "Diagnose unreliable code with test repetition."So we have gone over a variety of toolsthat can be used to improve test reliability.For more information about writing quality tests,watch "Write tests to fail."Now that our tests are reliable, let’s make them run fast!A number of configuration options exist for achieving faster results.Let’s do what we can to reduce the time it takes to run the test suite.One technique we use to improve performanceis to split our tests into multiple test plans.Sometimes, two is enough.You can identify a reduced set of tests to verifyas part of each open or update to a pull request.For example, we could run the unit testsalong with just a key subset of user interface tests for a single platform.The full set of tests on all supported platforms can still be run,but now in the background, and not blocking pull requests.This approach allows us to add tests and new platformswhile keeping our continuous integration process timely.Let’s set up a workflow to run a select set of tests.In this example, we have already created a new test plancalled “Pull Requests," and have it open in the test plan editor.Near the top we can selectw between "Tests" and "Configurations."Let’s select "Tests."Here we have chosen a subset of tests to be verified for a pull request.Now to setup a Workflow to run our “Pull Requests” test plan,we will go back to Xcode Cloud Manage Workflowsjust like we did when we added an environment variable for skipping tests.To create a new workflow, we will click the "Add" buttonat the bottom left of the “Manage Workflow” sheet.For simplicity, let’s also name our workflow “Pull Requests”and choose a start condition.We want this workflow to prevent any check-ins with failing tests.In the sidebar, to the right of "Start Conditions,"we will click the "Add" button.A menu will appear showing the start condition options.In our case, we will select “Pull Request Changes."Now, we now have a pull request start condition.Running tests require that the Food Truck app first be built.To do this, we need to add a build action.Again in the sidebar, below the “Start Conditions,”let’s add an action.We will click the "Add" button next to “Actions,"and then select “Build” from the context menu.Now that we have an action that builds our app,we will add another to run our tests.Again we will click add action, but this time we will select "Test."Great, we have a test action.Let’s select the test plan to run.In the middle of the sheet, there is a drop down for test.Here we can select our “Pull Requests” test plan.Awesome!Now our Workflow is configured to run our test plan on pull request.To create a second workflow that will run your complete test suite on a schedule,you can follow a similar set of steps.However, this time, select the start conditionto be “On a Schedule for a Branch”and then set the workflow to run your full suite test plan.We have both Workflows configured in Xcode Cloudand running their associated test plans.To learn more about test plans, check out "Testing in Xcode."Now we have created pull request and scheduled workflow test sets.Another improvement we can make for speed is to run tests concurrently.By default, Xcode Cloud tests your platforms in parallel.In addition, you can enable Xcode to run tests in parallelon a target and test object class level.To enable parallel test execution in Xcode,we will again go to our test plan editor and select "Tests."Then, to the right of our “Food Truck Tests" test bundle,we click the “Options” button.One of the options allows us to “Execute in parallel” when possible.If the server has enough cores available,multiple targets and test object classes can be executed concurrently.So let’s enable this option to improve our test suite turnaround time.Now our tests are configured to run in parallel.Note that tests must be designed to run independentlyto take advantage of parallel execution.Proper setup and teardown are essential to reliable test case behavior.With our tests running in parallel,it’s time to turn our attention to runaway tests.Runaway tests are those tests that don’t end in a timely manner.Some examples include an infinite loopor waiting indefinitely for a failed server.We can halt these tests by setting an execution time allowance in our test plan.The execution time allowance specifies the number of seconds for a test to runbefore it fails with a timeout error.This prevents a test suite from getting stuck on an individual test.In this case, the fifth test got stuck for some reason.By setting the execution time allowance,this runaway test was eventually halted and marked as a failure.The XCTest Test Runner then continued running the next test in the suite.Let’s configure an execution time allowance for our test plan.To set an execution time allowance,we will go to our test plan editor and select “Configurations."Under the “Test Execution” category, we can enable “Test Timeouts”and specify the number of seconds to wait.Note that the default is 600 seconds.Having configured the maximum execution time allowance,a single runaway test will no longer disrupt our testing workflow.For example, an overnight test suite can now complete on timeand provide a full set of useful results.Yay! We finally stopped those runaway tests,so we are able to move on to the next improvement.As you may recall, we were able to leverage test repetitionsto increase reliability of tests that rely on external services.We configured our test plan to retry on failureand selected a sufficient repetition value.However, these repetitions can add to the time it takes to run the test suite.Unnecessary repetitions are wastefuland you may want to optimize test repetition value to a lower number.Furthermore, you may consider removing the problematic test altogetherfrom the pull request workflow.Let’s go over how we might do this.Let’s return to the test repetitions configuration in the test plan editor.Earlier we set the test repetition mode to “Retry on Failure."Now we can adjust the "Maximum Test Repetitions” value.For example, we may have chosen to allow up to 10 attemptsfor a test that relies on an external serverthat fails 5% of the time.Most of the time, we will succeed on the first attempt.However, if that same test has an unrelated bug,it will fail every time and use all 10 attempts.Maybe 3 attempts would be sufficient and a better choice.While we want to reduce retries to improve performance,note that earlier we recommended increasing retriesto improve reliability in some cases.As such, this minimally chosen value must continue be sufficientto run those tests reliably.That wraps up configuring for faster results.To go into more detail on getting faster test results,check out "Get your test results faster."To recap, we covered the most effective waysto begin testing for Xcode Cloud.We focused on configuring tests to be both reliable and fastso that you can avoid irrelevant failures and verify your code changes quickly.Thank you, and I hope you enjoy the rest of your WWDC!

Suzy: Hello and welcome to "Author fast and reliable tests for Xcode Cloud."I'm Suzy, and I work on XCTest.In this session, I'm going to share the most effective waysto start testing for Xcode Cloud.Our teams designed Xcode Cloud to be a powerful tool for all developers.In fact, we use it to test Xcode itself, and I love it.One of my favorite features of Xcode Cloudis its ability to substantially broaden a given test suite.

By configuring most tests to run in the cloud,you now have a practical way to run tests on multiple destinations,including those running differing operating system versionsto leverage diverse platforms such as an iPhone, iPad,Apple Watch, Apple TV, and Mac,and to run various test plan configurations,allowing for runtime analysis toolssuch as address and thread sanitizers.Once we have passed such a thorough test suite,we can be confident the code is ready to ship.Offloading tests to Xcode Cloud allows for running a broader set of testswithout impacting the developers’ desktop cycle of code, compile, and test.With this now expanded test suite,there is a potential for an increased number of unreliable tests.This situation can become unmanageable.As such, ensuring reliability is essential.In addition to reliability, such a large number of testsalso needs to run efficientlyso as to limit their impact on the continuous integration process.Let’s address reliability first.I will demonstrate how to author more reliable tests for Xcode Cloudusing Food Truck.Food Truck is an app that converts taps and swipes into delicious donuts.By running the test suite in Xcode Cloud,we are able to validate that all Apple platformssupport ordering my favorite donut, chocolate with sprinkles.Each improvement to the Xcode Cloud Workflowwill be identified and demonstrated.For more information about getting started with Xcode Cloud Workflows,watch "Meet Xcode Cloud.”The first step to author more reliable testsis to ensure each test’s setup and tear down is thorough.Tests run in Xcode Cloud make use of a fresh simulatorwhich may not meet developers’ original assumptions.Let’s identify a number of device configuration assumptionssometimes seen in test code.

Certain tests may rely on specific dates and times.For example, a server may be running in a different time zone.Tests should avoid being time zone specific.Locale-based values, such as number formattingand language directionality, can lead to unexpected results.Avoid this problem by explicitly setting your simulator’s locale.Another problematic assumption is reliance on certain device permissionssuch as internet access.It’s best to mock device permissions in a unit testand use an alert handler in a UI Test.Finally, some tests depend on preloaded data.For example, a test may expect to have an empty documents directory.While explicitly configuring the simulator is sometimes the easiest choice,enhancing the test’s setup method is generally more robust.For example, the Food Truck depends on a menu file.As part of instantiating the truck object in the setup function,we generate a mock data file containing the donut menu items.Note that rather than relying on teardown methods to prepare for subsequent tests,we recommend establishing all state preparation in the setup method.In many cases, read-only files can be checked into the repositoryand later accessed by tests.However, when these files need to be constructed,Xcode Cloud supports running a custom build scriptwhere you can generate the file once for multiple tests to access.For more details on how to configure your script,watch "Customize your advanced Xcode Cloud workflow."That wraps up proper simulator setup.Now, let’s cover how to handle tests that fail to meet preconditions.XCTSkip is an error that instructs the XCTest Runnerto cease executing the current test and mark it as skipped.This may be used to bypass a yet-to-be supported OS version or device type.You could also leverage XCTSkip by setting an environment variableto skip tests specific to staging or production environments.Let’s go over how we can control test flow using an environment variable.

Environment variables can provide parametersto both the XCTest test runner app on your deviceand the test host running xcodebuild.In Xcode Cloud, environment variables prefixed with TEST_RUNNER_get passed into the XCTest test runner.This prefix will be stripped prior tothe variable being made available to your code.So, for example, a variable in your test codenamed BASE_URL would be passed in as the environment variablenamed TEST_RUNNER_BASE_URL.Test plans require the same format as test code.Namely, we do not add the TEST_RUNNER_ prefix.Environment variables may be referenced anywhere in test code.For example, they could be used with XCTSkipto skip the test for actually ordering donutswhen we are in a production environment.Unless you are hungry, of course.It’s important to keep in mindthat redefining an environment variable in multiple places,such as both a test plan and the Xcode Cloud User Interface,can lead to unexpected results.In this particular case, Xcode Cloud’s Environment variableswill take precedence over what’s specified in your project’s test plans.Now that we are referencing our environment variable within our test code,we can set its value in the Xcode Cloud User Interface.

To do this, navigate to your Cloud Reports,and control-click on Food Truck.

To edit our environment variables within our Workflows,we will select "Manage Workflows" in the context menu.We are editing the integration workflow specifically,so we will double click on it.Now, in the sidebar, we can select "Environment,"and in the middle of the sheet, under “Environment Variables,"we can add the variable’s name and value.

As an alternative to setting the environment variablein the Xcode Cloud Workflow,we could instead set it within the test plan.

In this example, we don’t yet have a test plan.To enable test plans, open the scheme editor,select "Test" in the sidebar,and then click on “Convert to Use Test Plans."Okay, now we have a test plan I called "Food Truck."To add the environment variable,we need to click on the test plan to open its editor.

Near the top, we can select between "Tests" and "Configurations."Let’s select "Configurations."Now, within the "Arguments" section,we will add the variable by clicking on "Environment Variables."A popup will appear where we can enter the variable’s name and value.

Now our test will be skipped when in the production environment.To learn more about skipping tests,watch "XCTSkip your tests."Now that we covered utilizing environment variables to control XCTSkip,let’s talk about expectation timeouts.It is possible for a test to fail due to an unexpected timeout.For example, this could be the result of a slow serveror an overly anxious user interface test.One approach to resolve either issuewould be to increase the XCTestExpectation timeoutso the interaction would have enough time to finish.In this example, we increase the OrderDonut timeoutfrom 5 to 10 seconds to allow the server more time to respond.It is usually preferable to instead replace both the appand test code timeout handling with async/await.This approach allows the test to pauseuntil the await call finishes without any timeout.

We have resolved time dependent tests,so let’s handle any test failures within the test suite.For example, we have a test that relies on a servicewithin the staging environment that is down for maintenance.We can use XCTExpectFailure instead of disabling or skipping this test.With XCTExpectFailure, your test executes normallyand the results are transformed as follows:a failure in a test will now be reported as an expected failure,while that failed test within its suite will be reported as a pass.This approach eliminates the noise generated by expected failures.

For example, testOrderDonut is failing.I know that the service that provides ordering donutsis under maintenance right now,so I added a call here to XCTExpectFailure.To learn more about XCTExpectFailurewatch "Embrace Expected Failures in XCTest."Now that we've declared expected failures,let’s leverage test repetitions to substantiate codeand diagnose unreliable code.Test repetitions is a tool that runs the same test multiple timeswaiting for the following:the first failure, the first success, or a statistical result.For example, at our desk,we run our new code and test cases multiple timeswith repetitions to confirm initial app and test code reliabilitybefore checking in the code.We were able to detect that testOrderDonut had only an 80% success rate.Uh-oh!Knowing the failure exists, we now use the repeat-until-failure modeto locally diagnose the bug.This is another way of utilizing test repetitions.For tests that rely on an unreliable external service,you may want to leverage the retry-on-failure repetition policyto confirm a test can succeed.While retrying tests is a powerful approach,it’s preferable to instead mock external services when possible.Advantages of a mocked service include deterministic reliability and speed.To learn how to mock your dependencies,watch “Testing Tips & Tricks.”Let’s explore how test repetitions can be enabled.

To enable test repetitions in your test plan,go back to the test plan editor and select "Configurations."Then, under the "Test Execution" section,there is a popup to select your test repetition mode.

In this case, we will select "Retry on Failure,"which is used primarily to work around unreliable external services.Now we have our test repetition mode enabled.For more information on leveraging test repetitions,watch "Diagnose unreliable code with test repetition."So we have gone over a variety of toolsthat can be used to improve test reliability.For more information about writing quality tests,watch "Write tests to fail."Now that our tests are reliable, let’s make them run fast!A number of configuration options exist for achieving faster results.Let’s do what we can to reduce the time it takes to run the test suite.

One technique we use to improve performanceis to split our tests into multiple test plans.Sometimes, two is enough.You can identify a reduced set of tests to verifyas part of each open or update to a pull request.

For example, we could run the unit testsalong with just a key subset of user interface tests for a single platform.

The full set of tests on all supported platforms can still be run,but now in the background, and not blocking pull requests.

This approach allows us to add tests and new platformswhile keeping our continuous integration process timely.

Let’s set up a workflow to run a select set of tests.In this example, we have already created a new test plancalled “Pull Requests," and have it open in the test plan editor.Near the top we can selectw between "Tests" and "Configurations."Let’s select "Tests."Here we have chosen a subset of tests to be verified for a pull request.Now to setup a Workflow to run our “Pull Requests” test plan,we will go back to Xcode Cloud Manage Workflowsjust like we did when we added an environment variable for skipping tests.To create a new workflow, we will click the "Add" buttonat the bottom left of the “Manage Workflow” sheet.For simplicity, let’s also name our workflow “Pull Requests”and choose a start condition.We want this workflow to prevent any check-ins with failing tests.In the sidebar, to the right of "Start Conditions,"we will click the "Add" button.

A menu will appear showing the start condition options.In our case, we will select “Pull Request Changes."Now, we now have a pull request start condition.Running tests require that the Food Truck app first be built.To do this, we need to add a build action.Again in the sidebar, below the “Start Conditions,”let’s add an action.We will click the "Add" button next to “Actions,"and then select “Build” from the context menu.

Now that we have an action that builds our app,we will add another to run our tests.Again we will click add action, but this time we will select "Test."Great, we have a test action.Let’s select the test plan to run.In the middle of the sheet, there is a drop down for test.Here we can select our “Pull Requests” test plan.

Awesome!Now our Workflow is configured to run our test plan on pull request.To create a second workflow that will run your complete test suite on a schedule,you can follow a similar set of steps.However, this time, select the start conditionto be “On a Schedule for a Branch”and then set the workflow to run your full suite test plan.

We have both Workflows configured in Xcode Cloudand running their associated test plans.To learn more about test plans, check out "Testing in Xcode."Now we have created pull request and scheduled workflow test sets.Another improvement we can make for speed is to run tests concurrently.By default, Xcode Cloud tests your platforms in parallel.In addition, you can enable Xcode to run tests in parallelon a target and test object class level.

To enable parallel test execution in Xcode,we will again go to our test plan editor and select "Tests."Then, to the right of our “Food Truck Tests" test bundle,we click the “Options” button.

One of the options allows us to “Execute in parallel” when possible.If the server has enough cores available,multiple targets and test object classes can be executed concurrently.So let’s enable this option to improve our test suite turnaround time.

Now our tests are configured to run in parallel.Note that tests must be designed to run independentlyto take advantage of parallel execution.Proper setup and teardown are essential to reliable test case behavior.

With our tests running in parallel,it’s time to turn our attention to runaway tests.Runaway tests are those tests that don’t end in a timely manner.Some examples include an infinite loopor waiting indefinitely for a failed server.

We can halt these tests by setting an execution time allowance in our test plan.The execution time allowance specifies the number of seconds for a test to runbefore it fails with a timeout error.This prevents a test suite from getting stuck on an individual test.

In this case, the fifth test got stuck for some reason.By setting the execution time allowance,this runaway test was eventually halted and marked as a failure.The XCTest Test Runner then continued running the next test in the suite.Let’s configure an execution time allowance for our test plan.

To set an execution time allowance,we will go to our test plan editor and select “Configurations."Under the “Test Execution” category, we can enable “Test Timeouts”and specify the number of seconds to wait.Note that the default is 600 seconds.

Having configured the maximum execution time allowance,a single runaway test will no longer disrupt our testing workflow.For example, an overnight test suite can now complete on timeand provide a full set of useful results.Yay! We finally stopped those runaway tests,so we are able to move on to the next improvement.As you may recall, we were able to leverage test repetitionsto increase reliability of tests that rely on external services.We configured our test plan to retry on failureand selected a sufficient repetition value.However, these repetitions can add to the time it takes to run the test suite.

Unnecessary repetitions are wastefuland you may want to optimize test repetition value to a lower number.Furthermore, you may consider removing the problematic test altogetherfrom the pull request workflow.Let’s go over how we might do this.

Let’s return to the test repetitions configuration in the test plan editor.

Earlier we set the test repetition mode to “Retry on Failure."Now we can adjust the "Maximum Test Repetitions” value.For example, we may have chosen to allow up to 10 attemptsfor a test that relies on an external serverthat fails 5% of the time.Most of the time, we will succeed on the first attempt.However, if that same test has an unrelated bug,it will fail every time and use all 10 attempts.Maybe 3 attempts would be sufficient and a better choice.

While we want to reduce retries to improve performance,note that earlier we recommended increasing retriesto improve reliability in some cases.As such, this minimally chosen value must continue be sufficientto run those tests reliably.That wraps up configuring for faster results.To go into more detail on getting faster test results,check out "Get your test results faster."To recap, we covered the most effective waysto begin testing for Xcode Cloud.We focused on configuring tests to be both reliable and fastso that you can avoid irrelevant failures and verify your code changes quickly.Thank you, and I hope you enjoy the rest of your WWDC!

3:37 -setUp()

3:46 -setUp() example

5:55 -Environment variable example

6:00 -XCTSkip example

8:18 -XCTSkip example

8:48 -XCTestExpectation example

8:59 -Increase XCTestExpectation example

9:16 -Async/await example

10:02 -XCTExpectFailure example

10:06 -XCTExpectFailure example

## Code Samples

```swift
override
 
func
 
setUp
() 
async
 
throws
 {

}
```

```swift
var
 truck: 
Truck
!


override
 
func
 
setUp
() 
async
 
throws
 {
    
let
 directoryURL 
=
 
FileManager
.default.temporaryDirectory
    
let
 fileName 
=
 
UUID
().uuidString
    
let
 fileURL 
=
 directoryURL.appendingPathComponent(fileName, isDirectory: 
false
)
    
let
 data 
=
 
await
 mockDonutMenuData()
    
try
 data.write(to: fileURL)
    truck 
=
 
Truck
(menuURL: fileURL)
}
```

```swift
var
 truck: 
Truck
!


func
 
testOrderDonut
() 
throws
 {
    
let
 host 
=
 
ProcessInfo
.processInfo.environment[
"BASE_URL"
]

    
let
 expectation 
=
 
XCTestExpectation
(description: 
"Order donut"
)
    truck.order(with: .sprinkles, host: host) { error, donut 
in

        
XCTAssertTrue
(donut.hasSprinkles)
        expectation.fulfill()
    }       
    wait(for: [expectation], timeout: 
5
)
}
```

```swift
var
 truck: 
Truck
!


func
 
testOrderDonut
() 
throws
 {
    
let
 host 
=
 
ProcessInfo
.processInfo.environment[
"BASE_URL"
]
    
try
 
XCTSkipIf
(host 
==
 
"prod.example.com"
)

    
let
 expectation 
=
 
XCTestExpectation
(description: 
"Order donut"
)
    truck.order(with: .sprinkles, host: host) { error, donut 
in

        
XCTAssertTrue
(donut.hasSprinkles)
        expectation.fulfill()
    }       
    wait(for: [expectation], timeout: 
5
)
}
```

```swift
var
 truck: 
Truck
!


func
 
testOrderDonut
() 
throws
 {
    
let
 host 
=
 
ProcessInfo
.processInfo.environment[
"BASE_URL"
]
    
try
 
XCTSkipIf
(host 
==
 
"prod.example.com"
)

    
let
 expectation 
=
 
XCTestExpectation
(description: 
"Order donut"
)
    truck.order(with: .sprinkles, host: host) { error, donut 
in

        
XCTAssertTrue
(donut.hasSprinkles)
        expectation.fulfill()
    }       
    wait(for: [expectation], timeout: 
10
)
}
```

```swift
var
 truck: 
Truck
!


func
 
testOrderDonut
() 
async
 
throws
 {
    
let
 host 
=
 
ProcessInfo
.processInfo.environment[
"BASE_URL"
]
    
try
 
XCTSkipIf
(host 
==
 
"prod.example.com"
)

    
let
 donut 
=
 
try
 
await
 truck.orderDonut(with: .sprinkles, host: host)
    
XCTAssertTrue
(donut.hasSprinkles)
}
```

```swift
var
 truck: 
Truck
!


func
 
testOrderDonut
() 
async
 
throws
 {
    
let
 host 
=
 
ProcessInfo
.processInfo.environment[
"BASE_URL"
]
    
try
 
XCTSkipIf
(host 
==
 
"prod.example.com"
)

    
XCTExpectFailure
(
"<https://dev.myco.com/bug/98> Donut ordering service is down"
)
    
let
 donut 
=
 
try
 
await
 truck.orderDonut(with: .sprinkles, host: host)
    
XCTAssertTrue
(donut.hasSprinkles)
}
```

