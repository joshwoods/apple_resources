# Wwdc2021 102

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Platforms State of the UnionTake a deeper dive into the new tools, technologies, and advances across Apple platforms that will help you create even better apps.ResourcesHD VideoSD VideoRelated VideosWWDC21KeynoteKeynote (ASL)Monday@WWDC21Platforms State of the Union (ASL)

Take a deeper dive into the new tools, technologies, and advances across Apple platforms that will help you create even better apps.

HD VideoSD Video

HD Video

SD Video

Keynote

Keynote (ASL)

Monday@WWDC21

Platforms State of the Union (ASL)

Search this video…Welcome to the WWDC2021 platform state of the union.WWDC is a time when we come togetheras a developer community to look at what the near future holdsfor our platforms.I also want to reflect a bit on how the work you didhelped all of us to get through this past year.Your apps and your creativity have enabled peopleto find new ways to keep things movingunder extraordinary circumstances.There are so many great examplesof developers making a difference,and we know there's much more we can doto help you make the world better faster.So this year we're delivering tools, technologies, and APIsdesigned to help you accomplish more.And we'll be talking today about three big areaswhere we're making that happen.First, we'll talk about the thingsthat help you build great apps:Xcode and Xcode Cloud, Swift, and our UI frameworks.Then we'll look at how Apple technologies can help youbuild apps that make it possible with augmented realityand our graphics technologies for users to see the worldin new ways.Finally, with new features like Focus, the Screen Time API,Widgets, and Share Play,we'll see ways in which the apps you build can help usersbetter connect with each otherand prioritize what's most important to them.Let's start with developing apps.To tell you more, here are Alison, Rhonda, and Andrew.Developing an app todayis a pretty sophisticated processand you rely on your toolsto keep you focused and effective.The most essential part of the process is coding,but building a quality app today involves a numberof specialized steps and tools.You need to test your code across various configurations.Your team reviews your code,and you integrate changes into a shared repository.You deliver to beta testers.And based on their feedback, you constantly refine your app.All of these steps are importantand it’s important to get all of them right.You often have to jump between different apps,websites, and services to get everything done.All of this context switching disrupts your focusand pulls you away from your code.It’s time to do something about that,to remove the friction and bring everything together,so you and your team can focus on creating great experiences.That’s why we created Xcode Cloud:a new continuous integration and delivery servicebuilt right into Xcode and hosted in the cloud.It helps you manage every stage of your development process,and makes it easy to get the important things right.Xcode Cloud was designed and built from the ground upto support development for all Apple platforms.It’s deeply integrated into Xcode,saving you time by keeping you focused in one place.It leverages Apple’s cloud infrastructure to offloadyour builds, tests, and even code signing for distribution.It integrates with Apple services like Test Flightand App Store Connect, as well as every majorgit-based source control provider.It even has REST APIs to help connectto other aspects of your development process.And it’s built with advanced securityto protect you and your projects.This is the biggest investment we’ve madein our developer tools since the original release of Xcode,and all of it is inside the experience you already know.You create and manage Xcode Cloud workflowsin Xcode 13, letting you stay in your codewhile test suites, code signing,and TestFlight distribution are handled for you.And when Xcode Cloud finishes a build,your results are right inside Xcode.This is going to change the way you work.It’s already changing the way we work.Many teams at Apple have incorporated Xcode Cloudinto their development process,including the team behind Xcode itself.It's incredibly easy to get started with Xcode Cloud.It only takes four steps: selecting the product,confirming your workflow,granting access to your source code,and linking with App Store Connect.Let's walk through the process with Fruta,a SwiftUI sample app.Xcode Cloud automatically detectsthe products and platform for my project,so I'll click next.Then I'll review the suggested workflow,which tells Xcode Cloud what to do and when to do it.The default actions build every change I make,which is exactly what I want.Now, Xcode Cloud will securely connectto the hosted account for my source code.I've already granted access using my credentials,so I can just move on.Finally, Xcode Cloud recognizesthat Fruta already exists on the App Storeand asks me to confirm the information.If your app isn't registered yet,Xcode Cloud will do it for you.I'll click Complete and start my first build in the Cloud.When the build is finished,I'll be able to view the results in the report navigator.And just like that, I set up continuous integrationand delivery for my app in one minuteall from within Xcode.Let's take a closer look at how results are presented.Under the Cloud tab in the report navigator,builds that have been run for each workflowwill be grouped by branch or Pull Request.Selecting an individual build brings up its overviewwith information like how and when it was started,which Xcode and macOS versions were used,and the status of all the actions.You can even check out the sourceor initiate a rebuild.While the default workflow is great for getting started,Xcode Cloud gives you even more powerto accomplish goals like analyzing an appor deploying new releases to Test Flight or the App Store.My team wants to run our iOS tests on every new Pull Request,so let's set that workflow up now.I'll go back to the Xcode Cloud product menu,selecting Manage Workflows this time,and I'll click Plus to add a new one.I'll name the workflow Pull Requests,then edit its start conditions to run on every Pull Requestthat targets the main branch.I want our tests to runon the public beta versions of Xcode and macOS,so I'll set that here.Next, I'll look at the workflow's actions,where I'll add a test action,then select an existing iOS test planfrom the project.To get broad testing coverage for my app,Xcode Cloud recommends simulators for me to use.With just two clicks, I geta curated set of iPhones and iPads for my workflow.Now that's pretty neat.Our team also needs to be notifiedwhen a build succeeds or fails.So I'll add a Notify post actionand add our team's Slack channel.By clicking Save, our workflow has been added to our producton Xcode Cloud.Now, my team will have added confidencein the changes we're making.There's so much more you can do with workflows,including running custom build scripts,and using Xcode Cloud’s web hooks and APIs to integratewith other systems you and your team depend on.And the workflow management and build reports you just sawin Xcode are also available in App Store Connect on the web.This makes it easy for you or other membersof your team to use Xcode Cloud from anywhere.Now that you’ve seen the basics of workingwith Xcode Cloud, let’s see how it helps youin each specific area of your development cycle.Writing good tests and running them repeatedlyis critical to creating a quality application.With Xcode Cloud, you’ll be testing your codemore thoroughly, more consistently,and more efficiently.You can configure your Xcode Cloud workflowsto run multiple test plans across multiple platforms,device simulators, and OS versions all in parallel.You can also run your tests in Xcode Cloudon beta OS releases before you even downloadthe betas to your own machine.So Xcode Cloud will help you test moreand Xcode 13 will help you test better.Our app Fruta supports the Light and Dark appearance,portrait and landscape orientations,and localizes to two languages.I've been working on a suite of user experience teststhat exercise Fruta's most popular features.Here in my test code, I'll adopt this simple XC test APIto make these tests go even furtherby automatically running each test in each variation.Let's look at that test coverage in Xcode Cloudby selecting the most recent buildand the workflow test action I have configured.Results are displayedin the familiar Xcode test report.These tests ran across a set of recommended iPad simulatorsrunning iOS 15, once per configuration,capturing screenshots all along the way.Xcode 13 has a brilliant new way to review those results.From the editor options menu,I'll enable the new gallery view.The screenshots from my tests are displayedin every variationand images from each test presented together.I can zoom out even further to see all images,and when I find one I'm really interested in,I can see it at full resolution using quick look.The gallery view makes it effortlessto confirm our app is looking fantasticacross all conditions, languages, and layouts.Over in my unit tests, I have a test failurethat I'm sure you will relate to.Sometimes the test passes and sometimes it fails.We've all been here before.And Xcode 13 is here to help.I navigate to the test source,click on the test gem, and choose Run Test Repeatedly.Let's get a better sense of reliabilityby running it 100 times.If I wanted to do this before, I'd have to run the testmany, many times myself.Now, I can sit back as the tools do all of the work.As I suspected, Xcode is showing this test is very unreliable.There must be a problem in my code.But until I can fix it, I'll adopt the new Expected Fail APIand include a message about reliabilityfor the rest of my team to see.To make sure things are just as I expect,I'll make use of the Test Again feature,available from the product menu.Xcode remembers what it did last timeso it's really easy.My test is still raising assertions,but it's not failing anymore.And I have a gentle reminder to fix it down the road.That is exactly what I need.As you can see, Xcode 13 and Xcode Cloudhelp you find and address issues in your app,or your tests, faster than ever.Tests are one form of insight on your code.Another is input from your peersthrough code reviews and Pull Requests.To keep you focused on your code,Xcode 13 brings these discussionswith your teamdirectly into the editor.I've created a Pull Requestfrom the feature branch I've been working on.My feature allows usersto favorite the most delicious smoothies.In the navigator on the left,you can see the new source control changes tab.It shows all the files I've modified locally,my Pull Request,and the changes that are included.When I select the Pull Request,I get a full overview of all the activityand the conversation going on.And as I scroll, I see my descriptionand the interesting events and time,as well as any code feedback from my teamand new commits that I make.But we're using Xcode Cloud,and our Pull Request workflowis building and testing every commit that I make.At the top, I get a live status from all of my workflows.Rhonda has a few suggestions to make my code even better.When I navigate to the source code,I see comments from Rhonda in my editor.This code requires the user to be logged in.So it needs to be reworkedto allow signing in before favoriting a recipe.I'll reply to let Rhonda know that I'm working on a changeand also give her a heads-up:This might crash in the build if she doesn't sign in first.Beyond Pull Requests,Xcode 13 makes reviewing local changes really easy too.As I navigate to a file that I'm working on,Xcode automatically displays the diff of my changesagainst the latest revisionin this beautiful new in-line presentation.I can use the updated revision selectorsto compare my local changes against any branch or tagin history.Best of all, I can use code review in any editor,even when I'm using multiple editor splitsacross different files in my window.And now with two options--in-line comparison and side by side--I get to pick the perfect presentationfor what I'm working on.With one last code change and comment,it could not be easierto review and respond to insight from my team.Part of delivering a great experienceis getting your appinto the hands of your team and beta testers.Xcode Cloud makes that process effortless.Xcode 13 now uses the cloudto securely obtain and manage everything you needto code sign your apps.This means you no longer need to worryabout keeping your certificates and profiles up to dateon your Mac.The archive action in your Xcode Cloud workflowuses the same system to sign your app for distribution.And by adding a postaction to your Xcode Cloud workflow,you get automatic delivery of betasthrough Test Flight to all Apple platforms,including macOSwith the new Test Flight for Mac.Once you've delivered your latest build,you'll get even more insight from your beta testers.Xcode 13 includes major improvementsto better connect youwith the same diagnostics and feedbackfound in App Store Connect.Crash logs from Test Flight appsare now delivered directly to the Organizerwithin minutes.And the Organizer now shows the written feedbacka user attaches to a crash report.This gives you valuable context when analyzing the crashand a broader view into your app's usage.After Andrew's test passed,Xcode Cloud submitted the build directly to Test Flight.I just received a notification on my phonefor a new iOS build of Fruta,and there's the Mac version from Test Flight for Mac.Since Fruta is a multiplatform project,I'm getting this new build in both places at the same time.I'm really excited to install this buildand see how the new feature feels.So I'll do that now.I suspectthere are still a few rough edges.Maybe the app will crash if I try to favorite this smoothie.And sure enough, it does.I can use Test Flight's crash feedback UIto let Andrew know.I'll explain what I was doing when the app crashed,and he'll be able to fix the issueand add a test to ensure this is caught earlier next time.I've been lookingat our most recent app releases in the OrganizerWhen I filter to the last day,here's a crash Rhonda experiencedjust a moment ago,fully symbolicated and ready for investigation.The new Test Flight feedback inspector includes her comments,information on the app build, version, and her device.And I can even contact her to learn more about her experience.What's even better:Xcode knows where in my code this crash came from.So with one click, I can open it in my project.The debug navigator has the full back trace.My source editor highlights the assertionand my Pull Request conversation displays too.It's incredibly excitingto have what I need to fix this problemright here in Xcode.We've brought everything you needinto the tools you use every day--test results,comments from peers, and user feedback--all to give you greater insightand help you deliverthe next great version of your app.Xcode Cloud was builtwith your privacy and security in mind.Your data--including your source, access tokens,sign-in keys, and build artifacts--are handled securely.And we use the least amount of data possibleto run the service.This is a huge year for our developer tools.With Xcode 13 and Xcode Cloud,you'll be building and delivering quality appsacross all of Apple's platformsin less time and with less effort than ever.Xcode Cloud will initially be availableas a free, limited beta.Developer Program account holders can sign up right nowat developer.apple.com.We will gradually add more teamsas we work towards making this availableto all developers next year.We'll provide more detailson pricing and availability this fall.You can check your registration statusfrom inside Xcode 13or the Xcode Cloud tab in App Store Connect.In addition to everything you've seen here,we have a huge list of improvements and featuresin our developer toolsthat you can learn about in this year's sessions,including some terrific enhancementsto Swift support in Xcode.That's just the startof an exciting story for Swift this year.To tell you more, here are Josh, Holly, and Matt.Swift has become a critical languagefor developers across Apple's platformsand beyond.It's enabled our most modern technologies,serving as the foundationfor a new generation of frameworkslike SwiftUI, CreateML,and the new StoreKit 2.It provides a modern, type-safe languageto craft your most complex appswith powerful tools like Xcode Previewsand Swift Package Managerto accelerate your development.And it's friendly and approachable for newcomers,with engaging content and lessonsavailable in Swift Playgroundsto learn how to code.Now, a key part of ensuring that a technology is great for youis adopting it ourselves.High-profile apps like Music have been written in Swiftfor years now,and system-wide features like Widgets have been designedfrom the ground up with SwiftUI.Learning Swift and SwiftUI gives you a common,powerful set of tools and APIs to build fully native appsfor all of our platforms.And because Swift itself is open source,we've been able to work together with many of youto deliver tons of new features and capabilitiesover the last few years.Now, one of those capabilities,which is crucial to building any app,is support for concurrency.And here's Holly to tell you all about it.Whether you think about it or not,you are writing concurrent code today.Concurrency enables your appsto perform multiple tasks at the same time,which helps your apps stay responsive to user inputwhile doing work in the background,like a weather app fetching forecast datawhile the user selects a city.And it's essentialto taking advantage of multicore processorsto achieve high performance for heavy computation,like rendering complex visual effects in a video app.But without language support,writing concurrent code is really hard to get right.So we're bringing first-class support for concurrencyto Swift.Our approachto building concurrency into the languagefollows the same core principles of Swift itself,making it easier to write modern, safe, and fast codethat eliminates entire classes of programming mistakes.First, let's talk about how we've taken a modern approachto building concurrency into Swift.Today, we think of modern code as structuredand easy to express what you want to do.Unfortunately,most of today's asynchronous codeuses completion handlers that are unstructuredand hard to express.To make expressing asynchronous functions easier,we've built the modern async/await pattern into Swift.Now you can mark an asynchronous functionwith the async keyword.When the function is called, you use the await keywordto indicate that other work can be done while the caller waitsfor the result of the async function.To understand the improvements async/await bringsover completion handlers,let's walk through an example.When I'm not working on the Swift compiler,I like to dance.To prepare for a show,a dance company must first warm up,the crew will fetch the scenery and props from storage,and then the stage is set.Once all of that is done, the dancers can moveinto their opening positions.Here is an asynchronous implementationof "prepareForShow" that uses completion handlers.What this code is trying to accomplishis really simple, but the code is convoluted.It uses nested completion handlersthat make the flow of execution unnatural,so the code is really hard to read.Adopting async/await in this exampleleaves us with code that's now in a straight line.This code is so much easier to understand.The control flow goes from top to bottom,like any other function.You handle errors and return valuesin the same way as you're used to in Swift.You can use all of the normal control flow constructs, too.So it's easy to add conditional logic,so the function behaves differently during a rehearsal.Async/await makes writing asynchronous code easierby leveraging the tools you already know.It's also easier to introduce concurrency where you need itusing Structured Concurrency.Structured Concurrency is a way of organizingconcurrent tasks to make them easier to reason about.Let's introduce concurrency into prepareForShow.Right now, the function waitsuntil the dancers finish their warm-upbefore starting to fetch the scenery,but these tasks could be done in parallel.With Structured Concurrency,you can easily create concurrent child tasksusing async/await with local variables, like this.Now, the code uses 'async let' variablesto create child tasks that execute concurrentlywith the parent.So, the company warm up and fetching the scenerywill run concurrently with the rest of prepareForShow.When we need the results of those child tasks,we await the results.Because fetchStageScenery executes concurrently,it's possible that the result isn't ready yetwhen prepareForShow needs to use it,so accessing the result must be done asynchronously.Swift's concurrency model is also designed to be safe.Just like Swift eliminates null pointer mistakes with optionals,the compiler will now help eliminatecommon concurrency issues by ensuringthat access to shared state is safely coordinatedbetween concurrent tasks.A core part of this safe concurrency modelis built around actors.Actors are an industry-proven modelfor safe concurrent programming,and a powerful synchronization primitive.Conceptually, an actor is an object that protectsits own state by only providing mutually exclusive access.This completely eliminates concurrent accessand the low-level data races that come with it.This concept might sound familiar, because it's similarto a pattern that you might already usefor classes with a dispatch queue,which was itself inspired by actors.In this pattern, the instance propertiesin a class are carefully accessed usinga serial dispatch queue to maintain mutual exclusion.But this pattern is prone to mistakes.There's a lot of boilerplate, and it's too easyto forget to manually use the queue just onceand introduce a race condition into your code.To solve these issues, we went back to the core idea of actors,and built it into Swift as a first-class construct.Now, you can declare an actor type in Swiftwith a simple keyword.It has the same structure as the constructs you already know,and there's no need for manual synchronization.With actors built into the Swift language,synchronizing access to actor statecan be managed for you automatically.An actor can access its own properties directly,and interacting with an actor externally uses async/awaitto guarantee mutual exclusion.The actor concept is so powerful that it also solvesanother common source of concurrency problems,which is proper use of the main threadfor things like UI operations.Today, you have to manually dispatch to the main queueeach time you call an API that must be run on the main thread.Now, we're introducing a way to state that an APIis always run on the main thread using the main actor.Making sure that an API always runs on the main actoris as easy as annotating the declarationwith the MainActor attribute.Just like with other actors, calling a functionthat runs on the main actor is just an await away.Altogether, this means it's easier writesafe concurrent code that you don't have to manage yourself.As we build support for concurrencydirectly into the language,it gives us the opportunity to better optimizethe performance of your concurrent code.With async/await, the compiler understandsthe concurrency of your code,which allows for more effective optimizations.This includes reducing reference counts and inliningas well as addressing concurrency-specificperformance issues like excessive context switches.And of course, your concurrent code will geteven faster as the compiler gets smarter in the years ahead.There are tons of asynchronous APIsin the SDK that you already use in your apps.We've refined the SDK to enable async/awaitwith these asynchronous APIs, so you can immediatelyadopt async/await in your existing code.And we didn't stop there.We've added new purposely crafted APIsthat take advantage of async/awaitfor when you work with URLs,when you're doing asynchronous I/O,and we even added support for asynchronously iteratingline-by-line through a file.Async/await makes it natural to express asynchronous code,structured concurrency makes concurrent codeeasier to reason about,and actors help you safely modelshared state in a concurrent program.The Swift concurrency model brings togetherthese fundamental pieces to make you more efficient,give you more power, and allow you to havemore fun building concurrent apps.Of course, the language is just one piece of the puzzle.The frameworks built with Swift are just as important.Now, back to Josh.Swift is the foundationfor the next generation of APIs.With new features like Concurrency,we're evolving the language and frameworks together,so you'll see immediate benefits across the SDK,including with key technologies like SwiftUI.Two years ago, we began to reinvent UI developmenton our platforms.We started small, with a core APIthat allowed you to adopt SwiftUI incrementallyin your existing applications.Last year, we added API to describe your app's life cycle,enabling you to develop apps entirely in SwiftUIfrom your first line of code.And this year, SwiftUI is takinganother huge step forward,helping you deliver great experiencesto all your users across all Apple platforms.We focused on APIs that we know are critical to your apps,because we also needed them to build ours.And your feedback helped us enhance the most important APIs,while also refining the development experience.This year, we've started using SwiftUI in apps like Maps,Photos, and Shortcuts.And we've rebuilt iOS apps like Weather,system interfaces like the Apple Pay payment sheet,and brand new watchOS apps like Find My,entirely with SwiftUI.To see just a few of the enhancementsthat make this possible,let's take a look at some ways that we can improve Fruta.We'll start with List, the most ubiquitous componentacross all our platforms.We can now easily add a swipe actionto mark a smoothie as a favorite.Adding pull-to-refresh is just one more line.And Swift now makes it easy to limit a modifierto a single platform-- in this case, iOS.Adding a Search field is just one more line.Now, we could stop there,but let's add some search suggestions as well,which will be shown while we're typing.And let's test it right here in Xcode.We have a swipe action now,pull-to-refresh, and full search supportincluding suggestions,all in just a few lines of code.Next, let's refine Fruta's accessibility support.First, a new modifier which adds accessibility rotorscan make our app faster to navigate with VoiceOver.And second we'll improve the accessibilityof this custom stepper control.Custom controls are often a source of poor accessibility,but we can now simply inherit the full accessibilityimplementation from the standard Stepper.Most SwiftUI APIs are available across all platforms,but we're moving platforms forward individuallywhere appropriate as well.Let's add a multi-column table to our macOS app.I already added a new file for this,so we'll just add the new Table component here.And then within it, we'll just add three columns of data.Now let's run the macOS version of our app.We'll find a search field placed right where you expect itin the toolbar,and suggestions appear just below it while we type.We can switch to our new multi-column tablethat we added, and we'll see it's displayingthe search results as well.And of course, we can clear the search to get them all back.Now let's switch to recipes and turn on VoiceOver.With VoiceOver, we can easily access the rotorthat we added to quickly choose a smoothie from the list.And VoiceOver interaction with our custom steppernow behaves exactly like a standard stepper,making it easy to use for all of our users.We're building our apps using these new capabilities,so we know that you'll find them helpful in yours as well.And we've just scratched the surface of what's new.For example, you're going to loveSwiftUI's new material support.In the Fruta app, views like this are made more interestingby adding a background image,and they're kept legible by applyingone of the new material styles behind the content.Content responds dynamically to this background,so instead of the gray normally usedfor secondary content in an opaque context,SwiftUI will automatically apply vibrant rendering to text,symbols, and even standard UI like separators.So with just one line of code,you can get great-looking results like this,automatically.And there's so much more.With all of these improvements, SwiftUI is the best way to buildgreat experiences for all your users across all our platforms.And this year, we're bringing app developmentwith SwiftUI to iPad in Swift Playgrounds.It's so much fun, and Matt will show you all about how it works.You know Swift Playgrounds providesa great way to learn how to code,and it's been used by millions of peopleto expand their knowledge of Swift.And beyond being a great way to learn,we know a lot of you already use Swift Playgroundsto experiment, sketching out new ideasand playing with the latest features in the iPadOS SDK.This year, Swift Playgrounds 4 is taking a huge step forwardby allowing you to build apps,and even submit them to the App Storeright from your iPad.With the ability to create apps on iPad,you can be more productive in Swift Playgroundsthan ever before, allowing you to work on your ideaswherever you go, on whichever device you prefer.And with a new package-based project format,you can seamlessly bring your work betweenSwift Playgrounds and Xcode.Let's dive in and take a look.This is Swift Playgrounds 4.It's got all of the great Learn to Code contentthat's helped inspire new developers around the world,and now, you can create projects that let you build SwiftUI apps.Let's make a new one nowand see what we can build.I'll open the new project I created.In an app project in Swift Playgrounds,my code is on the left, and the result of my workis on the right, just like I'm used to.What's new is deeply integrated support for SwiftUI,with live interactive previews powered by the same technologyused in Xcode.My new project template comes with a Hello World placeholder,which I can easily replace with a text view of my own.I'll start typing Text and right away, I get helpful suggestionsfrom code completion, which, new in this release,appears right below my insertion point.I'll accept the completion and write my own hello message.While I'm typing, my app updates liveto show my changes with each keystroke.Now, let's have a little fun.I'm going to replace this static text with a button.I'll select my text view, and then add a buttonfrom the library.Here in the library, I can browse and searchthrough assets in my project,as well as the SwiftUI views, modifiers,colors, and SF Symbols provided by iPadOS.For now, I'll just add my button.I'm going to fill the action in with a simple print statement.For the body, I'll use a Label with a system image.The text will be "Say Hello."And the image will be the SF Symbol for Swift.I've now got an interactive button in my app.When I tap it, the print message I wroteappears as a message bubble at the bottom of my screen.If I open the console, I can see a history of print statementsthat have been executed since I opened this project,and it updates in real-time as I interact with my app.Now, this button is purple because that'smy app's accent color, which Swift Playgroundschose for me when I created my project.If I open the document sidebar,I can access all of my app's top-level settings,like its name, accent color, and icon.As much as I do love purple, I think this smiley facewill look big and bright in orange,so I'll change my accent color here,and both my app's icon and the tint colorof the button I just made will update to reflect the change.This has been really fun, but Swift Playgroundsisn't just for experimentation.I've got another app that I've been working on for a while.I use this app to track the amount of time I spendon my favorite hobbies, and I thinkothers might find it useful as well.I can get a feel for what the installed app would look likeby taking it full-screen.Now I can explore my app in its full-width two-,or three-column layout.I can jump out of full screenand return to my code whenever I like.This feels great, and I think my hard work isready to share with my friends and family with TestFlight.Anyone with a Developer Accountcan upload their apps from the App Settings areaonce they're ready for App Store Connect.When I tap the upload button, Swift Playgrounds builds,packages, and uploads my app.I can then hop over to the App Store Connect website,and make my app available via TestFlight,and when it's ready, submit it to the App Store,and share it with the world.And that's a quick look at Swift Playgrounds 4,with the ability to create apps using SwiftUIright on your iPad.Swift Playgrounds 4 will be available later this year.We know you're going to love having the freedom to developyour app ideas wherever you go, on whichever device you prefer.And now, I'll hand it back to Susan.So much of the way we experience the world isthrough visual communication,and that's a big part of using Apple devices.Our technologies for graphics, displays,and augmented reality are front and center,whether you're glancing at the Always on Displayon Apple Watch,enjoying ProMotion as you work with video tools on iPad Pro,playing a game on your iPhone,or creating immersive 3D content on your Mac.And now Myra and Eric are gonna take you through what's newthis year starting with augmented reality.AR is a powerful technologyand thousands of you are already using it in your appsto transform how we all work,play, and express ourselves.With over a billion AR enabled iPhones and iPadsaround the world today, there's never beena better time to start adding AR experiences to your appsor building entirely new ones.Historically, building great AR apps has requireddeep knowledge of 3D modeling and a masteryof sophisticated rendering engines.However, we want all of you to be ableto create amazing AR experiences.This is why we've released a suite of technologiesto make it easy for you to get started with AR.One of these is RealityKit, our 3D rendering, audio,animation, and physics engine built from the ground up for AR.RealityKit makes rendering immersiveAR experiences simple,featuring photorealistic rendering,and camera effects like noise and motion blur.RealityKit also takes advantage of our latest hardwarelike the LiDAR Scanner, which enables virtual objectsto behave just like they were really therewith people and object occlusion.And it's all written in Swift.Today, we're announcing RealityKit 2,a huge update that gives you more visual, audio,and animation controland tackles the most difficult part of making great AR apps--creating 3D models.If you've ever created one before,you know a single model can take hoursand thousands of dollars to make.Now, with Object Capture, you'll be able to make 3D modelsin minutes using your iPhoneto capture 2D images of an objectand the Object Capture API on Mac to turn these imagesinto lifelike 3D models, optimized for AR.This process is so simple.You start by taking a series of pictures with youriPhone or iPad to capture all angles of the object,including the bottom, because we supportflipping the objectand automatic foreground segmentation.You can use apps like Qlone, which provide excellent guidesto help streamline your workflow.Then, using the Object Capture API,it only takes a few lines of code to generate your 3D model.You start a new photogrammetry session in RealityKitthat points to the folder of your captured images.Then, call the process function to generatethe model at the desired level of detail.It's that easy!Object Capture enables you to generate USDZ filesoptimized for AR Quick Look,so users can view them in Messages, Mail, Safari,and other apps.You can also generate USD or OBJ asset bundlesfrom the Object Capture API that can be used for ray-tracingand other post-production workflows.Turning real world objects into 3D models has never been easier.You can get started using Object Capture todaywith our sample code, and we're working withsome of the leading 3D content creation toolsto bring this workflow into many of the pro apps you already uselike Unity Mars, Cinema 4D, and Qlone,available later this year.It's easy to bring Object Capture models into Xcodeand use the new RealityKit APIs to add effects.My team and I tested Object Capture by scanningour favorite food,and we built an AR App Clip to share our recipes,which include the AR preview of the dish.The chocolate croissant we captured using Qloneis actually a virtual replica of a croissantsomeone on my team baked,and I want to add it as another recipe to our App Clip.I'll start by dragging the 3D model of my croissantinto my ARApp project.Next, I'll anchor it to my App Clip Codeusing ARKit and initialize a ModelEntity for the asset.I can always fully examine the 3D model directlyin Xcode Quicklook at any time while building my project,before deploying my app clip.We've used the new RealityKit APIs in our App Clipto add effects to each AR dish to make it more realistic.Because RealityKit is a native rendering engine,we can fit multiple AR scenes or recipes into the App Clip.Let's check it out.When I scan the App Clip Code, it launches the App Clipand then anchors the chocolate croissant right on top.To make the croissant more realistic,we used the new RealityKit custom surface shaderto add emissive light and pull back on the ambient occlusion.Let's take a look at a few more dishes from the team,like seared steak.Here we added onto the custom surface shaderby creating a steam effect with the newProcedural Geometry API to layer in a flip-book shader.Because the steam is procedural, we can use the same effecton lots of recipes, like this pizza.Notice how the steam effect procedurally expandedwith size of the pizza.For this barbecue chicken dish,we've added a full screen post processing fire effectto indicate this dish is spicy.And finally, we dropped the flames and instead useda new compute shader and geometry modifierto add some celebratory confetti around the birthday cake.As you can see, we've opened up RealityKit renderingto more customizations, and we can't wait to seeyour creativity in how you use these new APIs.These are just some of the exciting new improvementswe have for AR that enable all developersto create 3D models to build more immersiveand lifelike AR experiences.One of the foundational aspects of what we doin ARKit and RealityKit is our graphics technologies.And Eric will give us an update on what's new.A core idea of how we build products at Appleis that we bring together the most amazinghardware and software,and our approach to graphics reflects that ideal.For years, we've delivered powerfulApple-designed GPUs for iPhone and iPad,paired with our Metal graphics and compute APIsto help you get the most out of our products.And now, with the M1 chip, not only are we are deliveringan unprecedented level of graphics performanceand power efficiency in our latest Macs and iPad Pro,but we have created a unified Apple graphics platformwith a common architecture based on Metal, the Apple GPU,and unified memory, that spans from iPhone, to iPad, to Mac.And this platform enables a fundamental shift.Graphics workloads that previously requiredhigh-end workstations or discrete GPU gaming computers,are now possible across our most popular products.For instance, the console-level performance of this unifiedplatform has enabled developers like Larian to bring theirAAA game, Divinity Original Sin 2,to Mac and now to iPad.And Deep Silver is using M1and Metal's modern shader pipelineto enable the high performance, immersive graphicsin their survival game Metro Exodus for Mac.But this graphics platform is not just for games.Metal compute APIs are now accelerating the next generationof professional GPU renderers,like the all-new Octane X from OTOYand Maxon's Redshift renderer in Cinema 4D,now running Metal-acceleratedon the Mac for the very first time.So to help you bring your graphics apps and games acrossall of Apple's powerful devices,we focused on two big areas this year:advanced graphics and gaming features,and powerful graphics developer tools.First, we focused on three key features essential to modernhigh end games and GPU rendering algorithmsIn order to accelerate complex mathematical operations,model the behavior of light,and represent realistic surfaces, modern GPU renderersneed to interleave Metal graphics and compute commandsin the same pipeline,which is why Metal can now call dynamic libraries,and Ray Query primitives,directly from your graphics shaders.And you can create even more photo-realistic renderingwith the new Stochastic Motion Blur functionin the Metal Ray Tracing API.For games to achieve higher frame rateswith lower latency and less judder,developers need more control over the display.To accomplish this and take advantage ofthe awesome graphics performance of the latest iPad Pro,your game can use the Metal presentation time APIand the ProMotion display to dynamically adaptyour app's frame rate based on your desired latencybetween rendering and input.And macOS Monterey adds support for Adaptive Sync Displays.This means you can now take advantage of theseultra low-latency and variable refresh rate displaysfor your Mac games as well.Now, high-end games with advanced graphicsare often designed around using game controllers as input.And adding game controller support is a powerfuland easy way to use a common input modelto bring your games to our unified graphics platform.Our Game Controller framework now supportsthe most popular controllers,Including support for the latestXbox Series X Wireless Controllerand the PlayStation 5 DualSense Controller,complete with haptics support.To make it even easier for you to bring yourcontroller-based games to iPhone, and iPad,we've added a new API so that you can enable an on-screenvirtual Game Controller, with just a few lines of code.and game controller support is more valuable than ever,because in macOS Montereyand iPadOS 15, players can find the gamestheir friends are playing,directly navigate to the app libraryto launch a game, and then hit the "Share" buttonto record their favorite game highlights,all without the controller ever leaving their hands.Now, along with these new advanced APIs and features,Xcode 13 adds powerful new graphics developer toolsfor you to optimize and debug your GPU code,each designed to bring your modern high-end gamesand graphics applications to the next level.First, when building advanced GPU renderers and games,GPU shaders can get really big.Debugging 10,000 lines of shader codeacross thousands of workgroupsall running in parallel can take a really long time.To help you streamline this process, Xcode 13 addsSelective Shader Debugging.Here, we're using Selective Shader Debuggingto choose exactly which functions to debug,within a much larger GPU shader.This can dramatically reduce the time it takes youto iterate and debug your largest shaders,which lets you develop faster, and focus on adding featuresand performance to your GPU code.Next, high end AAA games also require the latestin modern texture compression support,which is why we've updated our powerfulMetal Texture Converter Toolto give you direct control over the Texture Convertercompression pipeline,added all-new gamma-aware pixel transforms,and vastly expanded support for the latest ASTCand BC texture compression formats used by Mac, PC,and iOS games.This makes it even easier to optimizeyour game's texture assets for each of Apple's devices.Finally, to help you achieve peak performance with yourmost advanced rendering, Xcode 13 adds an all-newGPU Timeline view in the Metal Debugger.This powerful new view allows you to combine the bestof visually debugging your Metal commands,resources, and buffers, on the timeline of events,in addition to powerful performance countersand bottleneck analysis information.With Apple CPUs, GPUs, and Metal, we have createda unified graphics platform with over a billion devices,with the latest features and developers toolsto enable you to unleash all-new levels of capabilityand performance for your graphics, pro apps, and games.And now back to you, Susan.Your apps can help connect peoplewith ideas, services, tools,and most importantly, other people.Finding balance is just as important as connecting,so this year we're enabling you to help usersfocus on your app at the right moments,to manage devices of loved oneswhile respecting their privacy,and to make your app's contentthe center of new, shared, intimate experiencesbuilt across Apple platforms.We created a powerful new set of APIsthat'll help your app create those kinds of relationships.Let's start with Heena and Matt to tell us about Focus.iOS 15 introduces a powerful new set of toolsto help people focus.These tools help reduce distractions,so that people can be in the moment.And it starts with an entirely new approach to notifications.Here are some notifications that have piled upon my Lock screen.Their levels of urgency are clearly different.But they all behaved identically.They had the same look, the same haptic,the same apparent level of importance.Now, with the new Interruption Level API,there are more nuanced ways for apps to conveydifferent levels of urgency.Notifications can be assigned one of four interruption levels.Passive interruptions are silent and don't wake the device.People will see them the next time they pick up their phones.You might want to use these for notificationsthat aren't time-sensitive.Active interruptions will play a sound or hapticjust like notifications today.Time Sensitive interruptions are designed to visually stand outand hang out on the Lock screen a little longerif the user hasn't tapped on it.They'll also be announced by Siri if someoneis wearing AirPods.And you'll want to use this for notificationsthat require immediate attention.Critical alerts are the most urgent category.They'll play a sound even if the device is muted.These are reserved for only very serious healthand safety concerns, and require an approved entitlement.There's another category of notificationsthat deserves special attention:communications from people.If you have a communication app, it's important that you tellthe system about your message and call notifications.The system will then use this informationto tune your notifications' appearance and behaviors,which will help people better interpret them.Once implemented, your notificationswill go from the standard appearance to looking like this,featuring a prominent avatar with your app icon superimposed,and the same avatars will be used elsewhere in the system,like in the Share Sheet.I'm so excited to see those avatars!All right, so notifications are a really effective wayto get people's attention.But they can also be kind of ephemeral.If they're not well-timed, people can easily miss them.To help users engage on notifications on their own time,we're introducing the Notification Summary,which delivers notifications as a helpful bundleat times the user chooses,so they can quickly catch up when it's best for them.The summary bundles Passive and Activenotifications from user selected appsand presents them in a beautiful layout.It then sticks around on the Lock screenfor a while until it's seen.The summary is also personalized for each user.As you can see, there are two marquee slots at the top.What's featured there is based on a few factors:First, to provide variety, those two appsare sampled from inside the summary.From there, we do some additional weighting.A notification with a large thumbnailwill always be chosen over one without.And the notification with the highest relevance score--which is something that you determine--will be chosen over others from the same app.Okay, so you might be wondering, "How does my app end upin the summary at all?”Well, first, it's completely up to the userif they want to use the notification summary.And if they do, apps that send the mostnotifications will be suggested.Users can then customize which apps go in the summaryalong with the times they'll receive them.If your app is placed in the scheduled summary,there's still a way for you to reach the user in real time.That's where Time Sensitive notifications come in.Notifications that use this interruption levelwill be delivered immediately.Remember, you should only mark notificationsas Time Sensitive if they require the immediate attentionand are relevant in the moment.No feature eliminates distractionsmore than Do Not Disturb.But Do Not Disturb silences all notificationsand we wanted to give users more flexibility.With Focus, users can choose the appsand people that they need to receive notifications frombased on what they're currently doing.They can carve out their day for work or create a Focusfor an activity like gaming, reading, or fitness.While in a Focus, users can sharetheir status with others, so they know not to interrupt.But if it's truly urgent,a message can break through and notify anyway.Your communication app can also request accessto the user's Focus status.If granted, the system will inform your appwhen it changes, so your app can keep its statusin sync with the rest of the system.Your app can even provide users the abilityto break through for urgent communications.We're providing users with more control and flexibilitythan ever to manage their notifications.And to help make sure these tools are working for them,the system will periodically check in to see ifa specific adjustment to their settings might be helpful.It's based off of how users interact with your appand your notifications.So if a user is typically using an app while in a Focus,then the system might suggest allowing that app'snotifications during that Focus.Or if a user is interacting with an app'sTime Sensitive notifications, then the system might suggestreverting them back to active notifications.The same goes for when an app sends one notificationafter another and the user isn't engaging.The system might suggest muting all notificationsfrom that app or maybe just a single conversationfor a limited amount of time.So to make the most of these new features,there are a few key things that you need to do.You can help make sure the right contentis featured in the marquee slots at the top of the summaryby setting a relevance score on your notificationsand attaching the appropriate thumbnails.You should think carefully about which interruption levelsmake sense for your notifications.If you have a communication app, you should adoptthe new User Notifications API to tell the systemabout your message and call notifications.You should also reflect the user's Focus in your appby using the new Focus Status API.We think these tools, with your help,will go a long way in helping users reduce distractions.Next, Martin is gonna tell us about the new Screen Time API.Thanks, Matt.Okay, let's switch gears to talk about Screen Timeand parental controls.We recognize that parents need modern,innovative solutions to help their childrenbuild healthy digital lives,and they also deeply value their family's privacy.And we've seen an appetite from many of you to deliveron these user needs.So today, we are releasing Screen Time API,a set of tailor made parental control frameworksthat build upon our deep commitment to privacy.We had three key goals in mind with the Screen Time API.To offer you modern solutions for developingparental control apps.To empower you to build dynamic experiencesand innovate beyond what even Screen Time offers today.And to protect user privacy.To that end, we've added three new Swift frameworksto the iOS SDK that enable you to innovatein the world of parental controls:Managed Settings, Family Controls,and Device Activity.First, let's talk about Managed Settings.Fundamentally, your parental control appneeds a way to restrict what a child can doacross their devices, and ensure thatthose restrictions remain in placeuntil the parent says otherwise.With Managed Settings, your app can set a number of restrictionslike locking accounts in place, preventing a password change,filtering web traffic, and limiting accessto applications, much like Screen Time.customized with your app's branding and functionality.By leveraging this framework, your app will be ableto manage all of these restrictions.Beyond restrictions you'll be able to limit accessto apps and websites when appropriateand provide a set of actions unique to your use cases.And finally, we lock the app in placeso it can only be removed with the parent's explicit approval.Now, the Family Controls framework is at the heartof our privacy model and it serves two keyuser-facing experiences.First, it allows parents to authorize your appfor management with their iCloud credentials,ensuring that the device is for a child in that family.And it provides a personalized experience viaa system App & Website picker,which allows parents to choose which apps and sitesshould be restricted, all while protecting user privacy.We wanted to allow parents to manage and restrictthe apps and websites that their children use,but do so in a way that doesn't divulgetheir private application and web browsing details.So, rather than returning a selection of raw bundle IDsand URLs, the picker will return opaque tokens instead.These tokens allow your app to keep trackof which apps and websites a parent wants to manage,all while ensuring that parents are the only peoplewho can access this highly sensitive information.And these tokens enable functionality acrossall of these frameworks.Use a token to limit access to a specific app or websitewith Managed Settings,or gain insight into app and website activity,something that wasn't possible on iOS until today,with the Device Activity framework.With the tokens providedby the Activity Picker in Family Controls,you're ready to leverage the power of Device Activity.You can register unique time windowsfor different apps and activities,each emitting a warning like, "Five more minutes left,"and a completion event.Once your app receives these events, it can react accordinglyby changing restrictions,limiting access to relevant apps and websitesor...encouraging children to do their homework.Whatever experience you are trying to deliverfor your users.This concept of seeing device activity,not just browser activity,but across all apps on the deviceis totally new and is a unique opportunityfor you to innovate in the world of parental controls.With the Screen Time API, you could enablefamily-wide downtime, or even create incentivesto do something fun after something educational,like unlocking some gaming after doing some homework.We're super excited to see how you will build on these APIsto help parents and families manage the waythat they use our devices.And now over to Vi to tell us what's new with Widgets.Last year, we introduced Widgets on the Home screen.and people loved them.Widgets provide deep personalizationwith delightful and timely viewsof the most relevant content from your app.They're all about glanceability.People love how widgets presentthe most useful information from your app,in a single glance, at exactly the right time.A tap can deep link just to the right part of your app.Over the past year, you've created someamazing widget experiences that have truly inspired us.The best widgets are focused, dynamic,and provide unique views of the app throughout the day.Like this one, from Day One.That's me and my kids on a trip to Santa Cruz.Surfacing just the right piece of contentin the right context helps your users discoverthe magic of your apps.And we've seen that widgets encourage peopleto use your app even more.This year, we are taking the next stepin making your apps more usefuland more discoverable with widgets.And it starts with letting people place widgetsamong your apps on the iPad Home screen.To take advantage of the large screen,we're introducing a new extra-large size for widgets.This means a whole new set of opportunitiesfor entirely new types of widgets that work best on iPad.To make getting into widgets even easier,we're adding new default Home screen layoutswith widgets on iPhone and iPad.These include widgets from apps people use the most,arranged in Smart Stacks.Stacks let you save space by placing multiple widgetson top of each other.Smart Stacks use on-device intelligence to show the widgetthat's most relevant right now.Building on the foundation of last year'sTimelineRelevance API, we are going beyondsimply rotating the stack with on-device intelligence.Now we can give your widget more exposure by suggesting iteven if it was not already in the stack.And how do we do this?Enter widget suggestions.How people interact with your app, as well aswhat you can tell us, helps us suggest your widget in a stack.Let us see how this works with our Fruta example app.If the user orders a green juice every morning,on-device intelligence will learn to suggest it.To opt in, you'll need to adopt the intents frameworkand donate an Interaction.That's it!Now your widget can be automatically suggestedbased on how people use your app.When you want to provide new information to users,you can also donate using the Intents API.For instance, the Fruta app can adopt thisto offer a free birthday smoothie.Both past usage behavior, as well asnew relevant intent donationscan then help us suggest your widget in a stackat the right time.And if a user finds your widget useful,they can easily add it permanently with a long press.So that's our big update to widgets this year.More useful, and more discoverable than ever.Next up is some news on SharePlay.Over to Ryan and Juan.This year, we've all had to improviseto find new ways of connecting.And it has been striking to see many of you innovate,and build awesome new ways for people to feela sense of togetherness while at a distance.And with people relying on FaceTime and iMessagemore than ever to stay connected,it was only natural for us to build on those experiences,to help people feel more together when they're apart.Some of the most meaningful moments people have togetherare about more than just sharing a conversationthey're about sharing experiences.So to foster that sense of closeness,we needed to build something completely new.And we had an ambitious goal.We wanted FaceTime to feel like a portalwhich transported people into the same spaceas some of their closest friends and family.So we built SharePlay.And we've given you the tools you needto create magical SharePlay experienceswith the new GroupActivities framework.We bring the group, you bring the activities.And it all comes down to this concept of activities.When someone in a FaceTime call starts an activity,SharePlay will bring the group directly into your app,allowing for rich interactive experienceswhere users can communicate, just like they're used to.There are a lot of possibilities to explorewith the Group Activities framework.And what better activity to do in your virtual living roomthan watching your favorite showswith some of your closest friends.Hey, Juan, since your team just finished integratingSharePlay into the TV app,why don't you show us around?Sure thing! What do you want to watch?How about a little "Ted Lasso"?Sounds good.I press play, and the system asks meif I want to start shared playback,or play locally instead.This is where you come in.We're offering new APIs to start playbackthat are designed to fit right into your app'sexisting video experience.Now because I chose shared playback,the system is coordinating the video on my deviceand Ryan's at exactly the same time with Core Mediaand Group Activities doing the heavy lifting.That means when I hit pause,Juan's video pauses on the exact same moment.I can even jump to a favorite sceneand everyone comes with me,as if we were all in the same room.All right? I mean, hey,Higgins and I are having lunch today.I love this scene!The magic behind this playback coordinationmeans your media isn't retransmitted in any way.Everyone will get your full-fidelity videobecause it's playing in your app and streamingfrom your servers as it always does.Now, let's see how easy it is to adopt Group Activitiesin a simple media appand take full advantage of the framework.There are just a few steps to get your app readyfor shared playback.First, we need to define our Group Activity.We'll create a new type that conformsto the Group Activity protocol,and supply a URL for everyone in the group to load.If your app already supports deep-links to content,you can use those here.We'll also provide some basic metadatato the system to customize system UIlike confirmation dialogs and notices.Next, we need to hook up our play buttons.In our play() function, we'll create a new activity,and call .prepareForActivation() on it.This is when the system presents that confirmation dialogueyou saw earlier.You can call this without any extra conditionals.It'll return immediately if the user is not on a FaceTime call.Now let's turn our attention to handling incoming activities.The initiator joins the session just like other participants,so the code looks the same for everyone.Here, I'm using Swift concurrencyto create a new modelwith each session that's delivered.We'll then join the new session once the player appears.You can observe the session for other state changesto update our UI accordingly.Finally, let's make sure we synchronize our players.Step 1: Grab your AVPlayer, and call.playbackCoordinator.coordinate WithSessionpassing in your session.Step 2: There's no step 2.That's it!That's all you need to do to get frame-accurate AV syncwith Group Activities and AVPlayer.The system handles the rest.Now we've talked a lot about shared media experiences.But we wanted Group Activities to provide a foundationthat could power even the most ambitious experiencesthat you could dream up.So we started building on top of the fabricthat powers Group FaceTime today,providing your app with a fast and reliable data channel.By taking on the job as group leader,our servers orchestrate a centralized statefor the entire group.These servers don't see your users' data,because it's all end-to-end encryptedso that it stays private.And using this fast and secure data channel,you can create immersive experiences,from turning the page on a shared book,to seeing the strokes that someone has drawnon a shared whiteboard live.We want to really inspire you to take full advantageof our APIs and bring your users togetherlike never before.But before we show you a demo,we're gonna need to call in a little extra help with this one.Hey, everyone. Thanks for joining.We're gonna need your help with this one last demoto really demonstrate the power of Group Activities.All right, we have a whiteboard demo app to show youwhat can be done with Group Activities.Now, by opening a shared canvas,I'm starting a new activity with the group to draw together.Now we're all looking at the same canvas,and we can interact with each other in a whole new way.If I draw somewhere on the canvas,everyone can see what I'm drawing live.Now this app is using the same APIs that you saw previously,but instead of synchronizing media,it's using GroupSessionMessengerto send my strokes to everyone's device.And this isn't screen sharing.Because the app is running natively on everyone's iPad,I can draw on the canvas, too.Let's all give it a try.So we can gather around a shared canvasno matter how far apart we are.And it's bringing us together like never before.Thanks for the help, everyone.The best part is, everything you just saw--SharePlay activities, playback synchronization,and the fast, secure data channel--you get all of these benefits just by integrating your appwith GroupActivities framework.SharePlay is a great new way to elevate your app's contentand help you create a more immersive experiencefor your users.We're eager to see the new shared experiencesthat you'll come up with using Group Activities.Now, over to Susan to wrap things up.We believe the advances you've see todaywill help you continue to build appsthat make a difference.We're building tools that streamline your workflowand make it easier to build great apps faster.We've made it easier to build immersive content,games, and tools for professional creators.We've shown you how your apps can help users connectwhile still focusing on the things that matter most.What you've seen today is just the start.There's so much more to check out this weekthat we haven't even had a chance to touch on.We know you're gonna build something awesome,and we can't wait to see it.

Welcome to the WWDC2021 platform state of the union.WWDC is a time when we come togetheras a developer community to look at what the near future holdsfor our platforms.I also want to reflect a bit on how the work you didhelped all of us to get through this past year.Your apps and your creativity have enabled peopleto find new ways to keep things movingunder extraordinary circumstances.There are so many great examplesof developers making a difference,and we know there's much more we can doto help you make the world better faster.So this year we're delivering tools, technologies, and APIsdesigned to help you accomplish more.And we'll be talking today about three big areaswhere we're making that happen.First, we'll talk about the thingsthat help you build great apps:Xcode and Xcode Cloud, Swift, and our UI frameworks.Then we'll look at how Apple technologies can help youbuild apps that make it possible with augmented realityand our graphics technologies for users to see the worldin new ways.Finally, with new features like Focus, the Screen Time API,Widgets, and Share Play,we'll see ways in which the apps you build can help usersbetter connect with each otherand prioritize what's most important to them.Let's start with developing apps.To tell you more, here are Alison, Rhonda, and Andrew.

Developing an app todayis a pretty sophisticated processand you rely on your toolsto keep you focused and effective.The most essential part of the process is coding,but building a quality app today involves a numberof specialized steps and tools.You need to test your code across various configurations.Your team reviews your code,and you integrate changes into a shared repository.You deliver to beta testers.And based on their feedback, you constantly refine your app.All of these steps are importantand it’s important to get all of them right.You often have to jump between different apps,websites, and services to get everything done.All of this context switching disrupts your focusand pulls you away from your code.It’s time to do something about that,to remove the friction and bring everything together,so you and your team can focus on creating great experiences.That’s why we created Xcode Cloud:a new continuous integration and delivery servicebuilt right into Xcode and hosted in the cloud.It helps you manage every stage of your development process,and makes it easy to get the important things right.Xcode Cloud was designed and built from the ground upto support development for all Apple platforms.It’s deeply integrated into Xcode,saving you time by keeping you focused in one place.It leverages Apple’s cloud infrastructure to offloadyour builds, tests, and even code signing for distribution.It integrates with Apple services like Test Flightand App Store Connect, as well as every majorgit-based source control provider.It even has REST APIs to help connectto other aspects of your development process.And it’s built with advanced securityto protect you and your projects.This is the biggest investment we’ve madein our developer tools since the original release of Xcode,and all of it is inside the experience you already know.You create and manage Xcode Cloud workflowsin Xcode 13, letting you stay in your codewhile test suites, code signing,and TestFlight distribution are handled for you.And when Xcode Cloud finishes a build,your results are right inside Xcode.This is going to change the way you work.It’s already changing the way we work.Many teams at Apple have incorporated Xcode Cloudinto their development process,including the team behind Xcode itself.

It's incredibly easy to get started with Xcode Cloud.It only takes four steps: selecting the product,confirming your workflow,granting access to your source code,and linking with App Store Connect.Let's walk through the process with Fruta,a SwiftUI sample app.Xcode Cloud automatically detectsthe products and platform for my project,so I'll click next.Then I'll review the suggested workflow,which tells Xcode Cloud what to do and when to do it.The default actions build every change I make,which is exactly what I want.Now, Xcode Cloud will securely connectto the hosted account for my source code.I've already granted access using my credentials,so I can just move on.Finally, Xcode Cloud recognizesthat Fruta already exists on the App Storeand asks me to confirm the information.If your app isn't registered yet,Xcode Cloud will do it for you.I'll click Complete and start my first build in the Cloud.When the build is finished,I'll be able to view the results in the report navigator.And just like that, I set up continuous integrationand delivery for my app in one minuteall from within Xcode.Let's take a closer look at how results are presented.Under the Cloud tab in the report navigator,builds that have been run for each workflowwill be grouped by branch or Pull Request.Selecting an individual build brings up its overviewwith information like how and when it was started,which Xcode and macOS versions were used,and the status of all the actions.You can even check out the sourceor initiate a rebuild.While the default workflow is great for getting started,Xcode Cloud gives you even more powerto accomplish goals like analyzing an appor deploying new releases to Test Flight or the App Store.My team wants to run our iOS tests on every new Pull Request,so let's set that workflow up now.I'll go back to the Xcode Cloud product menu,selecting Manage Workflows this time,and I'll click Plus to add a new one.I'll name the workflow Pull Requests,then edit its start conditions to run on every Pull Requestthat targets the main branch.I want our tests to runon the public beta versions of Xcode and macOS,so I'll set that here.Next, I'll look at the workflow's actions,where I'll add a test action,then select an existing iOS test planfrom the project.To get broad testing coverage for my app,Xcode Cloud recommends simulators for me to use.With just two clicks, I geta curated set of iPhones and iPads for my workflow.Now that's pretty neat.Our team also needs to be notifiedwhen a build succeeds or fails.So I'll add a Notify post actionand add our team's Slack channel.By clicking Save, our workflow has been added to our producton Xcode Cloud.Now, my team will have added confidencein the changes we're making.There's so much more you can do with workflows,including running custom build scripts,and using Xcode Cloud’s web hooks and APIs to integratewith other systems you and your team depend on.And the workflow management and build reports you just sawin Xcode are also available in App Store Connect on the web.This makes it easy for you or other membersof your team to use Xcode Cloud from anywhere.Now that you’ve seen the basics of workingwith Xcode Cloud, let’s see how it helps youin each specific area of your development cycle.Writing good tests and running them repeatedlyis critical to creating a quality application.With Xcode Cloud, you’ll be testing your codemore thoroughly, more consistently,and more efficiently.You can configure your Xcode Cloud workflowsto run multiple test plans across multiple platforms,device simulators, and OS versions all in parallel.You can also run your tests in Xcode Cloudon beta OS releases before you even downloadthe betas to your own machine.So Xcode Cloud will help you test moreand Xcode 13 will help you test better.

Our app Fruta supports the Light and Dark appearance,portrait and landscape orientations,and localizes to two languages.I've been working on a suite of user experience teststhat exercise Fruta's most popular features.Here in my test code, I'll adopt this simple XC test APIto make these tests go even furtherby automatically running each test in each variation.Let's look at that test coverage in Xcode Cloudby selecting the most recent buildand the workflow test action I have configured.Results are displayedin the familiar Xcode test report.These tests ran across a set of recommended iPad simulatorsrunning iOS 15, once per configuration,capturing screenshots all along the way.Xcode 13 has a brilliant new way to review those results.From the editor options menu,I'll enable the new gallery view.The screenshots from my tests are displayedin every variationand images from each test presented together.I can zoom out even further to see all images,and when I find one I'm really interested in,I can see it at full resolution using quick look.The gallery view makes it effortlessto confirm our app is looking fantasticacross all conditions, languages, and layouts.Over in my unit tests, I have a test failurethat I'm sure you will relate to.Sometimes the test passes and sometimes it fails.We've all been here before.And Xcode 13 is here to help.I navigate to the test source,click on the test gem, and choose Run Test Repeatedly.Let's get a better sense of reliabilityby running it 100 times.If I wanted to do this before, I'd have to run the testmany, many times myself.Now, I can sit back as the tools do all of the work.As I suspected, Xcode is showing this test is very unreliable.There must be a problem in my code.But until I can fix it, I'll adopt the new Expected Fail APIand include a message about reliabilityfor the rest of my team to see.To make sure things are just as I expect,I'll make use of the Test Again feature,available from the product menu.Xcode remembers what it did last timeso it's really easy.My test is still raising assertions,but it's not failing anymore.And I have a gentle reminder to fix it down the road.That is exactly what I need.As you can see, Xcode 13 and Xcode Cloudhelp you find and address issues in your app,or your tests, faster than ever.Tests are one form of insight on your code.Another is input from your peersthrough code reviews and Pull Requests.To keep you focused on your code,Xcode 13 brings these discussionswith your teamdirectly into the editor.I've created a Pull Requestfrom the feature branch I've been working on.My feature allows usersto favorite the most delicious smoothies.In the navigator on the left,you can see the new source control changes tab.It shows all the files I've modified locally,my Pull Request,and the changes that are included.When I select the Pull Request,I get a full overview of all the activityand the conversation going on.And as I scroll, I see my descriptionand the interesting events and time,as well as any code feedback from my teamand new commits that I make.But we're using Xcode Cloud,and our Pull Request workflowis building and testing every commit that I make.At the top, I get a live status from all of my workflows.

Rhonda has a few suggestions to make my code even better.When I navigate to the source code,I see comments from Rhonda in my editor.This code requires the user to be logged in.So it needs to be reworkedto allow signing in before favoriting a recipe.I'll reply to let Rhonda know that I'm working on a changeand also give her a heads-up:This might crash in the build if she doesn't sign in first.

Beyond Pull Requests,Xcode 13 makes reviewing local changes really easy too.As I navigate to a file that I'm working on,Xcode automatically displays the diff of my changesagainst the latest revisionin this beautiful new in-line presentation.

I can use the updated revision selectorsto compare my local changes against any branch or tagin history.Best of all, I can use code review in any editor,even when I'm using multiple editor splitsacross different files in my window.And now with two options--in-line comparison and side by side--I get to pick the perfect presentationfor what I'm working on.With one last code change and comment,it could not be easierto review and respond to insight from my team.

Part of delivering a great experienceis getting your appinto the hands of your team and beta testers.Xcode Cloud makes that process effortless.Xcode 13 now uses the cloudto securely obtain and manage everything you needto code sign your apps.This means you no longer need to worryabout keeping your certificates and profiles up to dateon your Mac.The archive action in your Xcode Cloud workflowuses the same system to sign your app for distribution.And by adding a postaction to your Xcode Cloud workflow,you get automatic delivery of betasthrough Test Flight to all Apple platforms,including macOSwith the new Test Flight for Mac.Once you've delivered your latest build,you'll get even more insight from your beta testers.Xcode 13 includes major improvementsto better connect youwith the same diagnostics and feedbackfound in App Store Connect.Crash logs from Test Flight appsare now delivered directly to the Organizerwithin minutes.And the Organizer now shows the written feedbacka user attaches to a crash report.This gives you valuable context when analyzing the crashand a broader view into your app's usage.After Andrew's test passed,Xcode Cloud submitted the build directly to Test Flight.

I just received a notification on my phonefor a new iOS build of Fruta,and there's the Mac version from Test Flight for Mac.

Since Fruta is a multiplatform project,I'm getting this new build in both places at the same time.I'm really excited to install this buildand see how the new feature feels.So I'll do that now.I suspectthere are still a few rough edges.Maybe the app will crash if I try to favorite this smoothie.And sure enough, it does.I can use Test Flight's crash feedback UIto let Andrew know.I'll explain what I was doing when the app crashed,and he'll be able to fix the issueand add a test to ensure this is caught earlier next time.

I've been lookingat our most recent app releases in the OrganizerWhen I filter to the last day,here's a crash Rhonda experiencedjust a moment ago,fully symbolicated and ready for investigation.The new Test Flight feedback inspector includes her comments,information on the app build, version, and her device.And I can even contact her to learn more about her experience.What's even better:Xcode knows where in my code this crash came from.So with one click, I can open it in my project.The debug navigator has the full back trace.My source editor highlights the assertionand my Pull Request conversation displays too.It's incredibly excitingto have what I need to fix this problemright here in Xcode.

We've brought everything you needinto the tools you use every day--test results,comments from peers, and user feedback--all to give you greater insightand help you deliverthe next great version of your app.Xcode Cloud was builtwith your privacy and security in mind.Your data--including your source, access tokens,sign-in keys, and build artifacts--are handled securely.And we use the least amount of data possibleto run the service.This is a huge year for our developer tools.With Xcode 13 and Xcode Cloud,you'll be building and delivering quality appsacross all of Apple's platformsin less time and with less effort than ever.Xcode Cloud will initially be availableas a free, limited beta.Developer Program account holders can sign up right nowat developer.apple.com.We will gradually add more teamsas we work towards making this availableto all developers next year.We'll provide more detailson pricing and availability this fall.You can check your registration statusfrom inside Xcode 13or the Xcode Cloud tab in App Store Connect.

In addition to everything you've seen here,we have a huge list of improvements and featuresin our developer toolsthat you can learn about in this year's sessions,including some terrific enhancementsto Swift support in Xcode.

That's just the startof an exciting story for Swift this year.To tell you more, here are Josh, Holly, and Matt.

Swift has become a critical languagefor developers across Apple's platformsand beyond.It's enabled our most modern technologies,serving as the foundationfor a new generation of frameworkslike SwiftUI, CreateML,and the new StoreKit 2.It provides a modern, type-safe languageto craft your most complex appswith powerful tools like Xcode Previewsand Swift Package Managerto accelerate your development.And it's friendly and approachable for newcomers,with engaging content and lessonsavailable in Swift Playgroundsto learn how to code.Now, a key part of ensuring that a technology is great for youis adopting it ourselves.High-profile apps like Music have been written in Swiftfor years now,and system-wide features like Widgets have been designedfrom the ground up with SwiftUI.Learning Swift and SwiftUI gives you a common,powerful set of tools and APIs to build fully native appsfor all of our platforms.And because Swift itself is open source,we've been able to work together with many of youto deliver tons of new features and capabilitiesover the last few years.Now, one of those capabilities,which is crucial to building any app,is support for concurrency.And here's Holly to tell you all about it.

Whether you think about it or not,you are writing concurrent code today.Concurrency enables your appsto perform multiple tasks at the same time,which helps your apps stay responsive to user inputwhile doing work in the background,like a weather app fetching forecast datawhile the user selects a city.And it's essentialto taking advantage of multicore processorsto achieve high performance for heavy computation,like rendering complex visual effects in a video app.But without language support,writing concurrent code is really hard to get right.So we're bringing first-class support for concurrencyto Swift.Our approachto building concurrency into the languagefollows the same core principles of Swift itself,making it easier to write modern, safe, and fast codethat eliminates entire classes of programming mistakes.First, let's talk about how we've taken a modern approachto building concurrency into Swift.Today, we think of modern code as structuredand easy to express what you want to do.Unfortunately,most of today's asynchronous codeuses completion handlers that are unstructuredand hard to express.To make expressing asynchronous functions easier,we've built the modern async/await pattern into Swift.Now you can mark an asynchronous functionwith the async keyword.

When the function is called, you use the await keywordto indicate that other work can be done while the caller waitsfor the result of the async function.To understand the improvements async/await bringsover completion handlers,let's walk through an example.When I'm not working on the Swift compiler,I like to dance.To prepare for a show,a dance company must first warm up,the crew will fetch the scenery and props from storage,and then the stage is set.Once all of that is done, the dancers can moveinto their opening positions.Here is an asynchronous implementationof "prepareForShow" that uses completion handlers.What this code is trying to accomplishis really simple, but the code is convoluted.It uses nested completion handlersthat make the flow of execution unnatural,so the code is really hard to read.Adopting async/await in this exampleleaves us with code that's now in a straight line.This code is so much easier to understand.The control flow goes from top to bottom,like any other function.You handle errors and return valuesin the same way as you're used to in Swift.You can use all of the normal control flow constructs, too.So it's easy to add conditional logic,so the function behaves differently during a rehearsal.Async/await makes writing asynchronous code easierby leveraging the tools you already know.It's also easier to introduce concurrency where you need itusing Structured Concurrency.Structured Concurrency is a way of organizingconcurrent tasks to make them easier to reason about.Let's introduce concurrency into prepareForShow.Right now, the function waitsuntil the dancers finish their warm-upbefore starting to fetch the scenery,but these tasks could be done in parallel.With Structured Concurrency,you can easily create concurrent child tasksusing async/await with local variables, like this.Now, the code uses 'async let' variablesto create child tasks that execute concurrentlywith the parent.So, the company warm up and fetching the scenerywill run concurrently with the rest of prepareForShow.When we need the results of those child tasks,we await the results.Because fetchStageScenery executes concurrently,it's possible that the result isn't ready yetwhen prepareForShow needs to use it,so accessing the result must be done asynchronously.

Swift's concurrency model is also designed to be safe.Just like Swift eliminates null pointer mistakes with optionals,the compiler will now help eliminatecommon concurrency issues by ensuringthat access to shared state is safely coordinatedbetween concurrent tasks.A core part of this safe concurrency modelis built around actors.Actors are an industry-proven modelfor safe concurrent programming,and a powerful synchronization primitive.Conceptually, an actor is an object that protectsits own state by only providing mutually exclusive access.This completely eliminates concurrent accessand the low-level data races that come with it.This concept might sound familiar, because it's similarto a pattern that you might already usefor classes with a dispatch queue,which was itself inspired by actors.In this pattern, the instance propertiesin a class are carefully accessed usinga serial dispatch queue to maintain mutual exclusion.But this pattern is prone to mistakes.There's a lot of boilerplate, and it's too easyto forget to manually use the queue just onceand introduce a race condition into your code.To solve these issues, we went back to the core idea of actors,and built it into Swift as a first-class construct.Now, you can declare an actor type in Swiftwith a simple keyword.It has the same structure as the constructs you already know,and there's no need for manual synchronization.With actors built into the Swift language,synchronizing access to actor statecan be managed for you automatically.An actor can access its own properties directly,and interacting with an actor externally uses async/awaitto guarantee mutual exclusion.The actor concept is so powerful that it also solvesanother common source of concurrency problems,which is proper use of the main threadfor things like UI operations.Today, you have to manually dispatch to the main queueeach time you call an API that must be run on the main thread.Now, we're introducing a way to state that an APIis always run on the main thread using the main actor.Making sure that an API always runs on the main actoris as easy as annotating the declarationwith the MainActor attribute.Just like with other actors, calling a functionthat runs on the main actor is just an await away.Altogether, this means it's easier writesafe concurrent code that you don't have to manage yourself.As we build support for concurrencydirectly into the language,it gives us the opportunity to better optimizethe performance of your concurrent code.With async/await, the compiler understandsthe concurrency of your code,which allows for more effective optimizations.This includes reducing reference counts and inliningas well as addressing concurrency-specificperformance issues like excessive context switches.And of course, your concurrent code will geteven faster as the compiler gets smarter in the years ahead.There are tons of asynchronous APIsin the SDK that you already use in your apps.We've refined the SDK to enable async/awaitwith these asynchronous APIs, so you can immediatelyadopt async/await in your existing code.And we didn't stop there.We've added new purposely crafted APIsthat take advantage of async/awaitfor when you work with URLs,when you're doing asynchronous I/O,and we even added support for asynchronously iteratingline-by-line through a file.Async/await makes it natural to express asynchronous code,structured concurrency makes concurrent codeeasier to reason about,and actors help you safely modelshared state in a concurrent program.The Swift concurrency model brings togetherthese fundamental pieces to make you more efficient,give you more power, and allow you to havemore fun building concurrent apps.Of course, the language is just one piece of the puzzle.The frameworks built with Swift are just as important.Now, back to Josh.Swift is the foundationfor the next generation of APIs.With new features like Concurrency,we're evolving the language and frameworks together,so you'll see immediate benefits across the SDK,including with key technologies like SwiftUI.Two years ago, we began to reinvent UI developmenton our platforms.We started small, with a core APIthat allowed you to adopt SwiftUI incrementallyin your existing applications.Last year, we added API to describe your app's life cycle,enabling you to develop apps entirely in SwiftUIfrom your first line of code.And this year, SwiftUI is takinganother huge step forward,helping you deliver great experiencesto all your users across all Apple platforms.We focused on APIs that we know are critical to your apps,because we also needed them to build ours.And your feedback helped us enhance the most important APIs,while also refining the development experience.This year, we've started using SwiftUI in apps like Maps,Photos, and Shortcuts.And we've rebuilt iOS apps like Weather,system interfaces like the Apple Pay payment sheet,and brand new watchOS apps like Find My,entirely with SwiftUI.To see just a few of the enhancementsthat make this possible,let's take a look at some ways that we can improve Fruta.We'll start with List, the most ubiquitous componentacross all our platforms.We can now easily add a swipe actionto mark a smoothie as a favorite.Adding pull-to-refresh is just one more line.And Swift now makes it easy to limit a modifierto a single platform-- in this case, iOS.Adding a Search field is just one more line.Now, we could stop there,but let's add some search suggestions as well,which will be shown while we're typing.And let's test it right here in Xcode.We have a swipe action now,pull-to-refresh, and full search supportincluding suggestions,all in just a few lines of code.Next, let's refine Fruta's accessibility support.First, a new modifier which adds accessibility rotorscan make our app faster to navigate with VoiceOver.And second we'll improve the accessibilityof this custom stepper control.Custom controls are often a source of poor accessibility,but we can now simply inherit the full accessibilityimplementation from the standard Stepper.Most SwiftUI APIs are available across all platforms,but we're moving platforms forward individuallywhere appropriate as well.Let's add a multi-column table to our macOS app.I already added a new file for this,so we'll just add the new Table component here.And then within it, we'll just add three columns of data.Now let's run the macOS version of our app.We'll find a search field placed right where you expect itin the toolbar,and suggestions appear just below it while we type.We can switch to our new multi-column tablethat we added, and we'll see it's displayingthe search results as well.And of course, we can clear the search to get them all back.Now let's switch to recipes and turn on VoiceOver.With VoiceOver, we can easily access the rotorthat we added to quickly choose a smoothie from the list.And VoiceOver interaction with our custom steppernow behaves exactly like a standard stepper,making it easy to use for all of our users.We're building our apps using these new capabilities,so we know that you'll find them helpful in yours as well.And we've just scratched the surface of what's new.For example, you're going to loveSwiftUI's new material support.In the Fruta app, views like this are made more interestingby adding a background image,and they're kept legible by applyingone of the new material styles behind the content.Content responds dynamically to this background,so instead of the gray normally usedfor secondary content in an opaque context,SwiftUI will automatically apply vibrant rendering to text,symbols, and even standard UI like separators.So with just one line of code,you can get great-looking results like this,automatically.And there's so much more.With all of these improvements, SwiftUI is the best way to buildgreat experiences for all your users across all our platforms.And this year, we're bringing app developmentwith SwiftUI to iPad in Swift Playgrounds.It's so much fun, and Matt will show you all about how it works.

You know Swift Playgrounds providesa great way to learn how to code,and it's been used by millions of peopleto expand their knowledge of Swift.And beyond being a great way to learn,we know a lot of you already use Swift Playgroundsto experiment, sketching out new ideasand playing with the latest features in the iPadOS SDK.This year, Swift Playgrounds 4 is taking a huge step forwardby allowing you to build apps,and even submit them to the App Storeright from your iPad.With the ability to create apps on iPad,you can be more productive in Swift Playgroundsthan ever before, allowing you to work on your ideaswherever you go, on whichever device you prefer.And with a new package-based project format,you can seamlessly bring your work betweenSwift Playgrounds and Xcode.Let's dive in and take a look.This is Swift Playgrounds 4.It's got all of the great Learn to Code contentthat's helped inspire new developers around the world,and now, you can create projects that let you build SwiftUI apps.Let's make a new one nowand see what we can build.I'll open the new project I created.In an app project in Swift Playgrounds,my code is on the left, and the result of my workis on the right, just like I'm used to.What's new is deeply integrated support for SwiftUI,with live interactive previews powered by the same technologyused in Xcode.My new project template comes with a Hello World placeholder,which I can easily replace with a text view of my own.I'll start typing Text and right away, I get helpful suggestionsfrom code completion, which, new in this release,appears right below my insertion point.I'll accept the completion and write my own hello message.While I'm typing, my app updates liveto show my changes with each keystroke.Now, let's have a little fun.I'm going to replace this static text with a button.I'll select my text view, and then add a buttonfrom the library.Here in the library, I can browse and searchthrough assets in my project,as well as the SwiftUI views, modifiers,colors, and SF Symbols provided by iPadOS.For now, I'll just add my button.

I'm going to fill the action in with a simple print statement.

For the body, I'll use a Label with a system image.The text will be "Say Hello."And the image will be the SF Symbol for Swift.I've now got an interactive button in my app.When I tap it, the print message I wroteappears as a message bubble at the bottom of my screen.If I open the console, I can see a history of print statementsthat have been executed since I opened this project,and it updates in real-time as I interact with my app.Now, this button is purple because that'smy app's accent color, which Swift Playgroundschose for me when I created my project.If I open the document sidebar,I can access all of my app's top-level settings,like its name, accent color, and icon.As much as I do love purple, I think this smiley facewill look big and bright in orange,so I'll change my accent color here,and both my app's icon and the tint colorof the button I just made will update to reflect the change.This has been really fun, but Swift Playgroundsisn't just for experimentation.I've got another app that I've been working on for a while.I use this app to track the amount of time I spendon my favorite hobbies, and I thinkothers might find it useful as well.I can get a feel for what the installed app would look likeby taking it full-screen.Now I can explore my app in its full-width two-,or three-column layout.I can jump out of full screenand return to my code whenever I like.This feels great, and I think my hard work isready to share with my friends and family with TestFlight.Anyone with a Developer Accountcan upload their apps from the App Settings areaonce they're ready for App Store Connect.When I tap the upload button, Swift Playgrounds builds,packages, and uploads my app.I can then hop over to the App Store Connect website,and make my app available via TestFlight,and when it's ready, submit it to the App Store,and share it with the world.And that's a quick look at Swift Playgrounds 4,with the ability to create apps using SwiftUIright on your iPad.Swift Playgrounds 4 will be available later this year.We know you're going to love having the freedom to developyour app ideas wherever you go, on whichever device you prefer.And now, I'll hand it back to Susan.

So much of the way we experience the world isthrough visual communication,and that's a big part of using Apple devices.Our technologies for graphics, displays,and augmented reality are front and center,whether you're glancing at the Always on Displayon Apple Watch,enjoying ProMotion as you work with video tools on iPad Pro,playing a game on your iPhone,or creating immersive 3D content on your Mac.And now Myra and Eric are gonna take you through what's newthis year starting with augmented reality.

AR is a powerful technologyand thousands of you are already using it in your appsto transform how we all work,play, and express ourselves.With over a billion AR enabled iPhones and iPadsaround the world today, there's never beena better time to start adding AR experiences to your appsor building entirely new ones.Historically, building great AR apps has requireddeep knowledge of 3D modeling and a masteryof sophisticated rendering engines.However, we want all of you to be ableto create amazing AR experiences.This is why we've released a suite of technologiesto make it easy for you to get started with AR.One of these is RealityKit, our 3D rendering, audio,animation, and physics engine built from the ground up for AR.RealityKit makes rendering immersiveAR experiences simple,featuring photorealistic rendering,and camera effects like noise and motion blur.RealityKit also takes advantage of our latest hardwarelike the LiDAR Scanner, which enables virtual objectsto behave just like they were really therewith people and object occlusion.And it's all written in Swift.Today, we're announcing RealityKit 2,a huge update that gives you more visual, audio,and animation controland tackles the most difficult part of making great AR apps--creating 3D models.If you've ever created one before,you know a single model can take hoursand thousands of dollars to make.Now, with Object Capture, you'll be able to make 3D modelsin minutes using your iPhoneto capture 2D images of an objectand the Object Capture API on Mac to turn these imagesinto lifelike 3D models, optimized for AR.This process is so simple.You start by taking a series of pictures with youriPhone or iPad to capture all angles of the object,including the bottom, because we supportflipping the objectand automatic foreground segmentation.You can use apps like Qlone, which provide excellent guidesto help streamline your workflow.Then, using the Object Capture API,it only takes a few lines of code to generate your 3D model.You start a new photogrammetry session in RealityKitthat points to the folder of your captured images.Then, call the process function to generatethe model at the desired level of detail.It's that easy!Object Capture enables you to generate USDZ filesoptimized for AR Quick Look,so users can view them in Messages, Mail, Safari,and other apps.You can also generate USD or OBJ asset bundlesfrom the Object Capture API that can be used for ray-tracingand other post-production workflows.Turning real world objects into 3D models has never been easier.You can get started using Object Capture todaywith our sample code, and we're working withsome of the leading 3D content creation toolsto bring this workflow into many of the pro apps you already uselike Unity Mars, Cinema 4D, and Qlone,available later this year.It's easy to bring Object Capture models into Xcodeand use the new RealityKit APIs to add effects.My team and I tested Object Capture by scanningour favorite food,and we built an AR App Clip to share our recipes,which include the AR preview of the dish.The chocolate croissant we captured using Qloneis actually a virtual replica of a croissantsomeone on my team baked,and I want to add it as another recipe to our App Clip.

I'll start by dragging the 3D model of my croissantinto my ARApp project.Next, I'll anchor it to my App Clip Codeusing ARKit and initialize a ModelEntity for the asset.I can always fully examine the 3D model directlyin Xcode Quicklook at any time while building my project,before deploying my app clip.We've used the new RealityKit APIs in our App Clipto add effects to each AR dish to make it more realistic.Because RealityKit is a native rendering engine,we can fit multiple AR scenes or recipes into the App Clip.Let's check it out.

When I scan the App Clip Code, it launches the App Clipand then anchors the chocolate croissant right on top.To make the croissant more realistic,we used the new RealityKit custom surface shaderto add emissive light and pull back on the ambient occlusion.Let's take a look at a few more dishes from the team,like seared steak.Here we added onto the custom surface shaderby creating a steam effect with the newProcedural Geometry API to layer in a flip-book shader.Because the steam is procedural, we can use the same effecton lots of recipes, like this pizza.Notice how the steam effect procedurally expandedwith size of the pizza.For this barbecue chicken dish,we've added a full screen post processing fire effectto indicate this dish is spicy.And finally, we dropped the flames and instead useda new compute shader and geometry modifierto add some celebratory confetti around the birthday cake.As you can see, we've opened up RealityKit renderingto more customizations, and we can't wait to seeyour creativity in how you use these new APIs.These are just some of the exciting new improvementswe have for AR that enable all developersto create 3D models to build more immersiveand lifelike AR experiences.One of the foundational aspects of what we doin ARKit and RealityKit is our graphics technologies.And Eric will give us an update on what's new.A core idea of how we build products at Appleis that we bring together the most amazinghardware and software,and our approach to graphics reflects that ideal.For years, we've delivered powerfulApple-designed GPUs for iPhone and iPad,paired with our Metal graphics and compute APIsto help you get the most out of our products.And now, with the M1 chip, not only are we are deliveringan unprecedented level of graphics performanceand power efficiency in our latest Macs and iPad Pro,but we have created a unified Apple graphics platformwith a common architecture based on Metal, the Apple GPU,and unified memory, that spans from iPhone, to iPad, to Mac.And this platform enables a fundamental shift.Graphics workloads that previously requiredhigh-end workstations or discrete GPU gaming computers,are now possible across our most popular products.For instance, the console-level performance of this unifiedplatform has enabled developers like Larian to bring theirAAA game, Divinity Original Sin 2,to Mac and now to iPad.And Deep Silver is using M1and Metal's modern shader pipelineto enable the high performance, immersive graphicsin their survival game Metro Exodus for Mac.But this graphics platform is not just for games.Metal compute APIs are now accelerating the next generationof professional GPU renderers,like the all-new Octane X from OTOYand Maxon's Redshift renderer in Cinema 4D,now running Metal-acceleratedon the Mac for the very first time.So to help you bring your graphics apps and games acrossall of Apple's powerful devices,we focused on two big areas this year:advanced graphics and gaming features,and powerful graphics developer tools.First, we focused on three key features essential to modernhigh end games and GPU rendering algorithmsIn order to accelerate complex mathematical operations,model the behavior of light,and represent realistic surfaces, modern GPU renderersneed to interleave Metal graphics and compute commandsin the same pipeline,which is why Metal can now call dynamic libraries,and Ray Query primitives,directly from your graphics shaders.And you can create even more photo-realistic renderingwith the new Stochastic Motion Blur functionin the Metal Ray Tracing API.For games to achieve higher frame rateswith lower latency and less judder,developers need more control over the display.To accomplish this and take advantage ofthe awesome graphics performance of the latest iPad Pro,your game can use the Metal presentation time APIand the ProMotion display to dynamically adaptyour app's frame rate based on your desired latencybetween rendering and input.And macOS Monterey adds support for Adaptive Sync Displays.This means you can now take advantage of theseultra low-latency and variable refresh rate displaysfor your Mac games as well.Now, high-end games with advanced graphicsare often designed around using game controllers as input.And adding game controller support is a powerfuland easy way to use a common input modelto bring your games to our unified graphics platform.Our Game Controller framework now supportsthe most popular controllers,Including support for the latestXbox Series X Wireless Controllerand the PlayStation 5 DualSense Controller,complete with haptics support.To make it even easier for you to bring yourcontroller-based games to iPhone, and iPad,we've added a new API so that you can enable an on-screenvirtual Game Controller, with just a few lines of code.and game controller support is more valuable than ever,because in macOS Montereyand iPadOS 15, players can find the gamestheir friends are playing,directly navigate to the app libraryto launch a game, and then hit the "Share" buttonto record their favorite game highlights,all without the controller ever leaving their hands.Now, along with these new advanced APIs and features,Xcode 13 adds powerful new graphics developer toolsfor you to optimize and debug your GPU code,each designed to bring your modern high-end gamesand graphics applications to the next level.First, when building advanced GPU renderers and games,GPU shaders can get really big.Debugging 10,000 lines of shader codeacross thousands of workgroupsall running in parallel can take a really long time.To help you streamline this process, Xcode 13 addsSelective Shader Debugging.Here, we're using Selective Shader Debuggingto choose exactly which functions to debug,within a much larger GPU shader.This can dramatically reduce the time it takes youto iterate and debug your largest shaders,which lets you develop faster, and focus on adding featuresand performance to your GPU code.Next, high end AAA games also require the latestin modern texture compression support,which is why we've updated our powerfulMetal Texture Converter Toolto give you direct control over the Texture Convertercompression pipeline,added all-new gamma-aware pixel transforms,and vastly expanded support for the latest ASTCand BC texture compression formats used by Mac, PC,and iOS games.This makes it even easier to optimizeyour game's texture assets for each of Apple's devices.Finally, to help you achieve peak performance with yourmost advanced rendering, Xcode 13 adds an all-newGPU Timeline view in the Metal Debugger.This powerful new view allows you to combine the bestof visually debugging your Metal commands,resources, and buffers, on the timeline of events,in addition to powerful performance countersand bottleneck analysis information.With Apple CPUs, GPUs, and Metal, we have createda unified graphics platform with over a billion devices,with the latest features and developers toolsto enable you to unleash all-new levels of capabilityand performance for your graphics, pro apps, and games.And now back to you, Susan.

Your apps can help connect peoplewith ideas, services, tools,and most importantly, other people.Finding balance is just as important as connecting,so this year we're enabling you to help usersfocus on your app at the right moments,to manage devices of loved oneswhile respecting their privacy,and to make your app's contentthe center of new, shared, intimate experiencesbuilt across Apple platforms.We created a powerful new set of APIsthat'll help your app create those kinds of relationships.Let's start with Heena and Matt to tell us about Focus.iOS 15 introduces a powerful new set of toolsto help people focus.These tools help reduce distractions,so that people can be in the moment.And it starts with an entirely new approach to notifications.Here are some notifications that have piled upon my Lock screen.Their levels of urgency are clearly different.But they all behaved identically.They had the same look, the same haptic,the same apparent level of importance.Now, with the new Interruption Level API,there are more nuanced ways for apps to conveydifferent levels of urgency.Notifications can be assigned one of four interruption levels.Passive interruptions are silent and don't wake the device.People will see them the next time they pick up their phones.You might want to use these for notificationsthat aren't time-sensitive.Active interruptions will play a sound or hapticjust like notifications today.Time Sensitive interruptions are designed to visually stand outand hang out on the Lock screen a little longerif the user hasn't tapped on it.They'll also be announced by Siri if someoneis wearing AirPods.And you'll want to use this for notificationsthat require immediate attention.Critical alerts are the most urgent category.They'll play a sound even if the device is muted.These are reserved for only very serious healthand safety concerns, and require an approved entitlement.There's another category of notificationsthat deserves special attention:communications from people.If you have a communication app, it's important that you tellthe system about your message and call notifications.The system will then use this informationto tune your notifications' appearance and behaviors,which will help people better interpret them.Once implemented, your notificationswill go from the standard appearance to looking like this,featuring a prominent avatar with your app icon superimposed,and the same avatars will be used elsewhere in the system,like in the Share Sheet.I'm so excited to see those avatars!All right, so notifications are a really effective wayto get people's attention.But they can also be kind of ephemeral.If they're not well-timed, people can easily miss them.To help users engage on notifications on their own time,we're introducing the Notification Summary,which delivers notifications as a helpful bundleat times the user chooses,so they can quickly catch up when it's best for them.The summary bundles Passive and Activenotifications from user selected appsand presents them in a beautiful layout.It then sticks around on the Lock screenfor a while until it's seen.The summary is also personalized for each user.As you can see, there are two marquee slots at the top.What's featured there is based on a few factors:First, to provide variety, those two appsare sampled from inside the summary.From there, we do some additional weighting.A notification with a large thumbnailwill always be chosen over one without.And the notification with the highest relevance score--which is something that you determine--will be chosen over others from the same app.Okay, so you might be wondering, "How does my app end upin the summary at all?”Well, first, it's completely up to the userif they want to use the notification summary.And if they do, apps that send the mostnotifications will be suggested.Users can then customize which apps go in the summaryalong with the times they'll receive them.If your app is placed in the scheduled summary,there's still a way for you to reach the user in real time.That's where Time Sensitive notifications come in.Notifications that use this interruption levelwill be delivered immediately.Remember, you should only mark notificationsas Time Sensitive if they require the immediate attentionand are relevant in the moment.No feature eliminates distractionsmore than Do Not Disturb.But Do Not Disturb silences all notificationsand we wanted to give users more flexibility.With Focus, users can choose the appsand people that they need to receive notifications frombased on what they're currently doing.They can carve out their day for work or create a Focusfor an activity like gaming, reading, or fitness.While in a Focus, users can sharetheir status with others, so they know not to interrupt.But if it's truly urgent,a message can break through and notify anyway.Your communication app can also request accessto the user's Focus status.If granted, the system will inform your appwhen it changes, so your app can keep its statusin sync with the rest of the system.Your app can even provide users the abilityto break through for urgent communications.We're providing users with more control and flexibilitythan ever to manage their notifications.And to help make sure these tools are working for them,the system will periodically check in to see ifa specific adjustment to their settings might be helpful.It's based off of how users interact with your appand your notifications.So if a user is typically using an app while in a Focus,then the system might suggest allowing that app'snotifications during that Focus.Or if a user is interacting with an app'sTime Sensitive notifications, then the system might suggestreverting them back to active notifications.The same goes for when an app sends one notificationafter another and the user isn't engaging.The system might suggest muting all notificationsfrom that app or maybe just a single conversationfor a limited amount of time.So to make the most of these new features,there are a few key things that you need to do.You can help make sure the right contentis featured in the marquee slots at the top of the summaryby setting a relevance score on your notificationsand attaching the appropriate thumbnails.You should think carefully about which interruption levelsmake sense for your notifications.If you have a communication app, you should adoptthe new User Notifications API to tell the systemabout your message and call notifications.You should also reflect the user's Focus in your appby using the new Focus Status API.We think these tools, with your help,will go a long way in helping users reduce distractions.Next, Martin is gonna tell us about the new Screen Time API.Thanks, Matt.Okay, let's switch gears to talk about Screen Timeand parental controls.We recognize that parents need modern,innovative solutions to help their childrenbuild healthy digital lives,and they also deeply value their family's privacy.And we've seen an appetite from many of you to deliveron these user needs.So today, we are releasing Screen Time API,a set of tailor made parental control frameworksthat build upon our deep commitment to privacy.We had three key goals in mind with the Screen Time API.To offer you modern solutions for developingparental control apps.To empower you to build dynamic experiencesand innovate beyond what even Screen Time offers today.And to protect user privacy.To that end, we've added three new Swift frameworksto the iOS SDK that enable you to innovatein the world of parental controls:Managed Settings, Family Controls,and Device Activity.First, let's talk about Managed Settings.Fundamentally, your parental control appneeds a way to restrict what a child can doacross their devices, and ensure thatthose restrictions remain in placeuntil the parent says otherwise.With Managed Settings, your app can set a number of restrictionslike locking accounts in place, preventing a password change,filtering web traffic, and limiting accessto applications, much like Screen Time.customized with your app's branding and functionality.By leveraging this framework, your app will be ableto manage all of these restrictions.

Beyond restrictions you'll be able to limit accessto apps and websites when appropriateand provide a set of actions unique to your use cases.And finally, we lock the app in placeso it can only be removed with the parent's explicit approval.

Now, the Family Controls framework is at the heartof our privacy model and it serves two keyuser-facing experiences.First, it allows parents to authorize your appfor management with their iCloud credentials,ensuring that the device is for a child in that family.And it provides a personalized experience viaa system App & Website picker,which allows parents to choose which apps and sitesshould be restricted, all while protecting user privacy.We wanted to allow parents to manage and restrictthe apps and websites that their children use,but do so in a way that doesn't divulgetheir private application and web browsing details.So, rather than returning a selection of raw bundle IDsand URLs, the picker will return opaque tokens instead.These tokens allow your app to keep trackof which apps and websites a parent wants to manage,all while ensuring that parents are the only peoplewho can access this highly sensitive information.And these tokens enable functionality acrossall of these frameworks.Use a token to limit access to a specific app or websitewith Managed Settings,or gain insight into app and website activity,something that wasn't possible on iOS until today,with the Device Activity framework.With the tokens providedby the Activity Picker in Family Controls,you're ready to leverage the power of Device Activity.You can register unique time windowsfor different apps and activities,each emitting a warning like, "Five more minutes left,"and a completion event.Once your app receives these events, it can react accordinglyby changing restrictions,limiting access to relevant apps and websitesor...encouraging children to do their homework.Whatever experience you are trying to deliverfor your users.This concept of seeing device activity,not just browser activity,but across all apps on the deviceis totally new and is a unique opportunityfor you to innovate in the world of parental controls.With the Screen Time API, you could enablefamily-wide downtime, or even create incentivesto do something fun after something educational,like unlocking some gaming after doing some homework.We're super excited to see how you will build on these APIsto help parents and families manage the waythat they use our devices.And now over to Vi to tell us what's new with Widgets.Last year, we introduced Widgets on the Home screen.and people loved them.Widgets provide deep personalizationwith delightful and timely viewsof the most relevant content from your app.They're all about glanceability.People love how widgets presentthe most useful information from your app,in a single glance, at exactly the right time.A tap can deep link just to the right part of your app.Over the past year, you've created someamazing widget experiences that have truly inspired us.The best widgets are focused, dynamic,and provide unique views of the app throughout the day.Like this one, from Day One.That's me and my kids on a trip to Santa Cruz.Surfacing just the right piece of contentin the right context helps your users discoverthe magic of your apps.And we've seen that widgets encourage peopleto use your app even more.This year, we are taking the next stepin making your apps more usefuland more discoverable with widgets.And it starts with letting people place widgetsamong your apps on the iPad Home screen.To take advantage of the large screen,we're introducing a new extra-large size for widgets.This means a whole new set of opportunitiesfor entirely new types of widgets that work best on iPad.To make getting into widgets even easier,we're adding new default Home screen layoutswith widgets on iPhone and iPad.These include widgets from apps people use the most,arranged in Smart Stacks.Stacks let you save space by placing multiple widgetson top of each other.Smart Stacks use on-device intelligence to show the widgetthat's most relevant right now.Building on the foundation of last year'sTimelineRelevance API, we are going beyondsimply rotating the stack with on-device intelligence.Now we can give your widget more exposure by suggesting iteven if it was not already in the stack.And how do we do this?Enter widget suggestions.How people interact with your app, as well aswhat you can tell us, helps us suggest your widget in a stack.Let us see how this works with our Fruta example app.If the user orders a green juice every morning,on-device intelligence will learn to suggest it.To opt in, you'll need to adopt the intents frameworkand donate an Interaction.That's it!Now your widget can be automatically suggestedbased on how people use your app.When you want to provide new information to users,you can also donate using the Intents API.For instance, the Fruta app can adopt thisto offer a free birthday smoothie.Both past usage behavior, as well asnew relevant intent donationscan then help us suggest your widget in a stackat the right time.And if a user finds your widget useful,they can easily add it permanently with a long press.So that's our big update to widgets this year.More useful, and more discoverable than ever.Next up is some news on SharePlay.Over to Ryan and Juan.This year, we've all had to improviseto find new ways of connecting.And it has been striking to see many of you innovate,and build awesome new ways for people to feela sense of togetherness while at a distance.And with people relying on FaceTime and iMessagemore than ever to stay connected,it was only natural for us to build on those experiences,to help people feel more together when they're apart.Some of the most meaningful moments people have togetherare about more than just sharing a conversationthey're about sharing experiences.So to foster that sense of closeness,we needed to build something completely new.And we had an ambitious goal.We wanted FaceTime to feel like a portalwhich transported people into the same spaceas some of their closest friends and family.So we built SharePlay.And we've given you the tools you needto create magical SharePlay experienceswith the new GroupActivities framework.We bring the group, you bring the activities.And it all comes down to this concept of activities.When someone in a FaceTime call starts an activity,SharePlay will bring the group directly into your app,allowing for rich interactive experienceswhere users can communicate, just like they're used to.There are a lot of possibilities to explorewith the Group Activities framework.And what better activity to do in your virtual living roomthan watching your favorite showswith some of your closest friends.

Hey, Juan, since your team just finished integratingSharePlay into the TV app,why don't you show us around?Sure thing! What do you want to watch?How about a little "Ted Lasso"?Sounds good.I press play, and the system asks meif I want to start shared playback,or play locally instead.This is where you come in.We're offering new APIs to start playbackthat are designed to fit right into your app'sexisting video experience.Now because I chose shared playback,the system is coordinating the video on my deviceand Ryan's at exactly the same time with Core Mediaand Group Activities doing the heavy lifting.That means when I hit pause,Juan's video pauses on the exact same moment.I can even jump to a favorite sceneand everyone comes with me,as if we were all in the same room.All right? I mean, hey,Higgins and I are having lunch today.I love this scene!The magic behind this playback coordinationmeans your media isn't retransmitted in any way.Everyone will get your full-fidelity videobecause it's playing in your app and streamingfrom your servers as it always does.Now, let's see how easy it is to adopt Group Activitiesin a simple media appand take full advantage of the framework.There are just a few steps to get your app readyfor shared playback.First, we need to define our Group Activity.We'll create a new type that conformsto the Group Activity protocol,and supply a URL for everyone in the group to load.If your app already supports deep-links to content,you can use those here.We'll also provide some basic metadatato the system to customize system UIlike confirmation dialogs and notices.Next, we need to hook up our play buttons.In our play() function, we'll create a new activity,and call .prepareForActivation() on it.This is when the system presents that confirmation dialogueyou saw earlier.You can call this without any extra conditionals.It'll return immediately if the user is not on a FaceTime call.Now let's turn our attention to handling incoming activities.The initiator joins the session just like other participants,so the code looks the same for everyone.Here, I'm using Swift concurrencyto create a new modelwith each session that's delivered.We'll then join the new session once the player appears.

You can observe the session for other state changesto update our UI accordingly.Finally, let's make sure we synchronize our players.Step 1: Grab your AVPlayer, and call.playbackCoordinator.coordinate WithSessionpassing in your session.

Step 2: There's no step 2.That's it!That's all you need to do to get frame-accurate AV syncwith Group Activities and AVPlayer.The system handles the rest.Now we've talked a lot about shared media experiences.But we wanted Group Activities to provide a foundationthat could power even the most ambitious experiencesthat you could dream up.So we started building on top of the fabricthat powers Group FaceTime today,providing your app with a fast and reliable data channel.By taking on the job as group leader,our servers orchestrate a centralized statefor the entire group.These servers don't see your users' data,because it's all end-to-end encryptedso that it stays private.And using this fast and secure data channel,you can create immersive experiences,from turning the page on a shared book,to seeing the strokes that someone has drawnon a shared whiteboard live.We want to really inspire you to take full advantageof our APIs and bring your users togetherlike never before.But before we show you a demo,we're gonna need to call in a little extra help with this one.

Hey, everyone. Thanks for joining.We're gonna need your help with this one last demoto really demonstrate the power of Group Activities.All right, we have a whiteboard demo app to show youwhat can be done with Group Activities.Now, by opening a shared canvas,I'm starting a new activity with the group to draw together.Now we're all looking at the same canvas,and we can interact with each other in a whole new way.If I draw somewhere on the canvas,everyone can see what I'm drawing live.Now this app is using the same APIs that you saw previously,but instead of synchronizing media,it's using GroupSessionMessengerto send my strokes to everyone's device.And this isn't screen sharing.Because the app is running natively on everyone's iPad,I can draw on the canvas, too.

Let's all give it a try.

So we can gather around a shared canvasno matter how far apart we are.And it's bringing us together like never before.

Thanks for the help, everyone.The best part is, everything you just saw--SharePlay activities, playback synchronization,and the fast, secure data channel--you get all of these benefits just by integrating your appwith GroupActivities framework.SharePlay is a great new way to elevate your app's contentand help you create a more immersive experiencefor your users.We're eager to see the new shared experiencesthat you'll come up with using Group Activities.Now, over to Susan to wrap things up.

We believe the advances you've see todaywill help you continue to build appsthat make a difference.We're building tools that streamline your workflowand make it easier to build great apps faster.We've made it easier to build immersive content,games, and tools for professional creators.We've shown you how your apps can help users connectwhile still focusing on the things that matter most.What you've seen today is just the start.There's so much more to check out this weekthat we haven't even had a chance to touch on.We know you're gonna build something awesome,and we can't wait to see it.

## Code Samples

