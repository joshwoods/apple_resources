# Wwdc2021 10245

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Design for spatial interactionDiscover the principles for creating intuitive physical interactions between two or more devices, as demonstrated by Apple designers who worked on features for iPhone, HomePod mini, and AirTag. Explore how you can apply these patterns to your own app when designing features for Apple platforms, and help people using your app interact more directly with their surroundings.ResourcesHuman Interface Guidelines: Nearby interactionsNearby InteractionNearby Interactions with U1HD VideoSD VideoRelated VideosWWDC22What's new in Nearby InteractionWWDC21Explore Nearby Interaction with third-party accessoriesThursday@WWDC21WWDC20Meet Nearby Interaction

Discover the principles for creating intuitive physical interactions between two or more devices, as demonstrated by Apple designers who worked on features for iPhone, HomePod mini, and AirTag. Explore how you can apply these patterns to your own app when designing features for Apple platforms, and help people using your app interact more directly with their surroundings.

Human Interface Guidelines: Nearby interactions

Nearby Interaction

Nearby Interactions with U1

HD VideoSD Video

HD Video

SD Video

What's new in Nearby Interaction

Explore Nearby Interaction with third-party accessories

Thursday@WWDC21

Meet Nearby Interaction

Search this video…♪ Bass music playing ♪♪Peter Tsoi: Hello and welcometo "Design for spatial interaction."My name is Peter,and I'm a designer on the Apple Design team.Together with my colleagues Arian, Taylor, Linus, and Pedro,we're excited to share some of the considerationsthat guide how we approach designing spatial interactions.We'll share lessons learned while creating interactionsfor AirTag, HomePod mini, and iPhone,and also give you tips and tricks that will help youapply those principleswhile designing interactions of your own.Let's get started.As our devices have evolved,so too has the way that we interact with them.Early computers were operated only using a keyboardand interfaces were entirely text based.Users memorized abstract commandsand relied on arrow keys to move around the screenand express their intent.Nowadays, most people use their keyboards togetherwith graphical user interfaces and a mouse.These innovations removed a layer of abstractionand allowed people to use the mouseto point, click, and dragto more directly express their intent.Later, Multi-Touch brought the digital worldto people's fingertips,removing yet another layer of abstractionand allowing people to touch their music,their photos, and the mobile web.Today we want to talk about a class of interactionsthat go beyond the bounds of a single deviceand ways to use the capabilities of the latest Apple devicesto help users interact more directlywith their physical surroundings.Some of these interactions may already feel familiar,like how you can pay for a coffeeby holding your phone or watch close to a payment terminal.Or how you can quickly check the battery level on your AirPodsjust by flipping open the case when it's near your phone.These human-scale interactions --the ones that happen between devices nearby --have the ability to remove layers of abstractionand allow users to interact more directlywith their surroundings.And with the enhanced spatial awarenessenabled by the U1 chip in the latest Apple products,we've been able to deliver more capable and responsiveexperiences for AirTag, HomePod mini, and iPhone.And now, thanks to new APIs and the ability to interactwith third-party hardware that you build in iOS 15,you can now bring these kinds of experiencesto your own products.In designing these interactions, we learned thatit's important to consider distance and ability,provide continuous feedback, and embrace the physical action.Let's dive right in.In iOS 13, we made it even easier to share contentby bringing spatial awareness to the share sheet.Using information about who you are facingor physically close to, combined with on-device knowledgeabout the frequency and recency of your communications,allows your device to intelligently predictwho you are trying to share with.This is a great example of how existing features in your appscan be made more intelligent with spatial awareness.You don't have to build an entirely new experienceto take advantage of these new capabilities.When incorporating spatial awarenessinto existing features,be mindful that these capabilitiesare not available on all devices and your designshould accommodate varying levels of capabilities.With the share sheet, all devices are ableto look for others using Bluetooth and Wi-Fi.However, iPhones with the U1 spatial awareness chiptake this a step further by prioritizing othersthat you are facing or are very close to.Of course, spatial awareness can be usedto not just enhance existing experiences;it can help build entirely new ones.Next, Arian will share how these same conceptsapply to AirTag.Arian Behzadi: With AirTag, we will show youhow your design can adaptto accommodate different distances and abilities.In this example, imagine I've misplaced an item I care about.I retrace my steps and realize I'm not sure where it is.I use my iPhone and feel relievedthat I can see where it is on a map.Previously, I'd only be ableto get to the general vicinity of this item,but now my iPhone can guide meat a scale that is much more helpful.In fact, the same button that gave me directionswhen I was far away has now become a buttonthat will help me find it as I'm closer.Augmenting elements of the designwhen at the appropriate scale is a great way for peopleto discover and use these new abilities.As iPhone is locating my AirTag,I'm invited to move around and search my surroundings.Once connected, an arrow formsand points directly to where I need to go.As I align with the direction of my AirTag,the design lights up to reinforce this.We emphasize this facing directionand provide guidance when not facing this direction.In a subtle way,this distinction also scales based on distance.When further away, we found that it is really hardto remain facing a specific direction.To remedy this, we are actually more generouswith the angle that iPhone considers facing.As you get closer, this forgiveness becomes more narrowto become more and more specific.This happens without you noticingas you're gently guided to your AirTag.When you're finally within arm's reach of your AirTag,the arrow defers to a form of feedbackthat we find much more effective at this small scale.The design transforms to highlight haptic feedbackas you pass your iPhone overwhere your AirTag might be hiding.With this example, we've shown youhow your design can transform based on distance,whether you're very far away or within millimeters.Think about how your design can bestaccommodate varying abilities we all share as humans.Be forgiving with angles at a distance,and consider changing the dominant form of feedbackto one that works best at smaller scale.Next, I'd like to hand it over to Taylorto show you just how critical this continuous feedback iswhen designing these kinds of interactions.Taylor Carrigan: Thanks, Arian.We've gone to great lengths to make onscreen interactionsfluidly and dynamically respond to touch input,but this continuous feedback is even more criticalwhen interacting in the physical world where your devicebecomes a more literal extension of your body.The right type of feedback applied and choreographedat the right time throughout these interactionscan help make the feature you're designing discoverable,provides instruction,and can communicate success or failure.It also acknowledges that our movementscan start, stop, and be interrupted at any time.We're going to talk about how you can use feedbackyou can see,  hear, and feelto help connect your interaction to the physical world.Though dependent on the capabilitiesof the devices used,there are multiple types of feedbackworth considering and using together.These can include visual feedback --such as user interface changes,lights and hardware interactions,and visual feedback coordinated across both devices --audio feedback , and haptic feedback.We'll also talk about natural interruptionand cancellation and the importance these playin creating a successful interaction between two devices.Let's look first at how different types of feedbackhelp make the transfer of music to HomePod miniintuitive and satisfying.With HomePod mini,we use multiple types of feedback to establisha physical relationship with your iPhone,provide direction, and ultimately confirmthat your music has been successfully transferred.We achieved this by creating two discrete boundariesaround the HomePod,and respond to your movement across and between them.Feedback is provided when your iPhone reaches the first zone,between the first and second to instruct you to move closeror allow you to cancel the interaction,and finally when your iPhone reaches the second zone,to confirm and transfer music.Feedback is continuously providedfrom the moment iPhone reaches the first distance threshold.On screen, the banner position, scale, and modalitycreated by the background blurincrease fluidly and in direct responseto your distance from the HomePod.When designing visual feedback,look for opportunities for the onscreen elements to animatein a way that feels related to your physical movements --like how the movement of this banneris related to the linear movement of your handtowards or away from the HomePod.Haptic feedback complements this with a physical acknowledgementthat the two devices are aware of each other,and increases in strength to encourage youto continue moving closer.In addition to the feedback on iPhone,HomePod mini acknowledges the proximity of iPhonethrough the animations on the top of the speaker.Great spatial interactions use natural body movementsto not only confirm but also to cancel actions.When moving an iPhonenear a HomePod mini, clear and continuous feedbackthat tracks your distance from the HomePodmakes it clear that you can simply pull awayto cancel or interrupt the gesture.This allowed us to create an interaction that can be doneentirely without looking at the displayor requiring additional onscreen buttonsto cancel or confirm user intent.All of these aspects are driven by and respond tothe movement of your body as it brings iPhonecloser to or farther away from the HomePod.The directness of the relationshipbetween someone's movements in the physical worldand what they're seeing, hearing, and feelingon one or both devices are criticalwhen designing a spatial interaction.Next, Linus will talk about the unique constraintsof providing feedback while finding an AirTag.Linus Persson: HomePod mini is a good exampleof how to choreograph feedback across two devices,both capable of expressing rich feedback.For designs where this is not a possibility,you might have to rely more heavily on a single device.Since AirTag helps you find an item when it's lost,the experience is designed for scenarioswhen it's hidden from view.Let's revisit the finding experience we saw before,this time with an eye on how we provide continuous feedbackacross the senses using iPhone'srich haptic, visual, and acoustic capabilities.A spatial interaction feels great when it's responsiveand follows your motion.That means responding to movements that are bigas well as ones that are subtle.Even as iPhone is connecting to the AirTag,the interface gently rotates and responds as I turn,implying the nature of the interactionthat is about to follow.These dots also provide the building blocksfor a continuously adapting experience.Once connected, the distance between me and my AirTagalso appears.This distance responds incredibly preciselyas I walk in any direction.It instantly updates and tells meif I'm walking toward, or away, from where I want to go.As I walk around, the same dots smoothly form an arrowpointing me in the right direction.This moment is reinforced further using a delicate hapticand sound to mark its importance.It feels as though the arrowfloats in space as my iPhone moves around it.As you saw earlier,the interface reinforces moments when I am on the right path.When facing the direction of my lost AirTag,the screen boldly lights upand I also feel and hear the arrow snap into place.By responding to every step and subtle turn,the design feels tightly coupled with me and the space I'm in.When designing your spatial interaction,consider how people will connect their own movementwith what they experience on the device.Try to make a clear link between action and feedbackin a way that is mindful of the particular motion.Just ahead of the arrow,there's a dot that starts to pulse in my hand.The pace of this pulse picks up as I get closer,and the haptics become tighter and crisperalong with it.If I break away from this direction,the pulse stops and the interface guides me back.If I walk far enough away from my AirTag,the arrow disassembles to mark the loss of signal.Nuance in moments like thesealso provide important and very helpful guidance.Be mindful of how feedback can complement human motionsthat are varied and unpredictable,and build a design that is resilientand can adaptively change to accommodate the way we move.When within arm's reach, we visually zoom in on this dot,and the pulse changes to continuous haptic feedbackthat shifts with my movement.This haptic response changes in character as I move closerand further away.I can move my iPhone over where AirTag might beand sense through my hand more precisely where it's hiding.Note that we do not use sound for this part of the experience,as haptic feedback does a much more effective job.As with any continuous feedback,your design should be mindful of how haptics, sound,and visuals work together in concert across the senses.Similarly to the way we perceive what we see,hear and feel in the world as one holistic experience.When designing your interaction, it is important to considerthe different strengths of each form of feedbackand how they can be used together.Seek to provide a visual layer of continuous feedbacktied to physical motion and use additional feedbackto emphasize important moments in your interaction.Use haptics and sound judiciouslyand at the right levels,with a repeatable cause and effectso it is clear what is being communicated.In addition to working with feedback in this way,keep in mind that your design will complementa physical action.And to speak about this is my colleague Pedro.Pedro Mari: In the case of HomePods,we use spatial awareness to make the taskof selecting a speaker more natural.Oftentimes, I'll be listening to some music,and I'll want to move it from my iPhoneto a better speaker near me.Previously, if I wanted to play this songon a different speaker, I'd have to go into the AirPlay list.In this list, all of the other devices in my spaceare presented equally, whether they are near me or not.What I am really interested in, though,is this particular HomePod.With this new human-scale interaction,I can finally transfer a song to this HomePodwithout navigating an onscreen UI,or having to interact with the screen at all, for that matter.We provide visual feedback on the HomePod itselfto show that the music is about to be transferred.The light modulates preciselywith my movement, growing in intensity as I approach,and shrinking as I move away.And of course,the ultimate confirmation of the transferis the music playing from the speaker itself.By embracing the physical action,a previously intangible experiencenow feels completely tangible, visceral, and instinctive.Think of ways that your own interfacescan support a natural physical motion,rather than an abstracted list of options.Try to make your experiences and designsdefer to the physical task at hand.Also, consider how the concepts of "this" and "that"can be finally used to create a more natural experiencethat aligns with how we think.Make sure to provide instant and continuous feedbackon both devices.Specifically, be very clear on the target devicethat an action is happening,as this is where your attention will be naturally drawn to.Similarly, when finding a lost item,my attention is meant to be directed at the world around meand where it might be hiding.Playing sound from the AirTag gives me an immediate senseof its place in space,drawing my attention to my surroundings.When it comes to the visual feedback on iPhone itself,make sure it can be read when performing a taskthat extends beyond the bounds of the display.We often design our interfaces to work in this mannerwhen we anticipate it will be viewed in the periphery.For instance, when using turn-by-turn navigation,the typography of when and where I need to take my next turnis bigger and bolder than other notificationsthat might occupy the same space.The buttons and active area of TV Remote are extra largeand are designed for your eyes to be directed to the TV itself,rather than the control for it.The digits and operation buttons in Calculatorare large and bold, as we anticipateyou might be referencing numbers on a restaurant billto calculate a tip, for instance.As in the previous examples,the type size we use for the distancewhen finding an AirTag is set much largerthan in other parts of the system,and the entire UI revolves aroundthe central element of a giant arrow.Bold color changes can be read in my periphery.Sound reinforces key moments and states --I can actually feel the distance getting smaller as I walkwithout ever having to look at the screen.This ultimately supports a more natural pose as I use it.When in arm's reach,haptic feedback can guide me closereven if the screen is not in my periphery.These large and bold UI choicesenable those with varying abilitiesto access the experience as well.Make sure your design uses more than one mode of feedback,and that each one is salient enough to be clearly understood.Your design shouldn't demand too much attentionto communicate its informationor compete with the primary task.Lastly, try to reinforce good statesand celebrate positive progressalong the way to completing a spatial interaction.Always consider the physical actionyour experience is complementing.And now, back to Peter!Peter: We've covered a lot today.We've seen how new and existing experiencesbecome more intelligent and relevantwhen they consider the device's context and surroundings.You learned how responsive and continuous feedbackcan help users discover and use these new experiences.And finally, we took a look at techniquesthat allow your designto be effectively experienced peripherallywhile keeping attention on the physical surroundings.We hope that you are just as excited as we areabout how spatial awareness can simplifyand bring more directness to interactions between our devicesand our users' physical surroundings.For more information, be sure to visit developer.apple.comwhere you'll find the Human Interface Guidelinesfor spatial interactions, as well as technical informationabout how to implement these types of interactions.We can't wait to see what you'll build next.♪

♪ Bass music playing ♪♪Peter Tsoi: Hello and welcometo "Design for spatial interaction."My name is Peter,and I'm a designer on the Apple Design team.

Together with my colleagues Arian, Taylor, Linus, and Pedro,we're excited to share some of the considerationsthat guide how we approach designing spatial interactions.

We'll share lessons learned while creating interactionsfor AirTag, HomePod mini, and iPhone,and also give you tips and tricks that will help youapply those principleswhile designing interactions of your own.

Let's get started.

As our devices have evolved,so too has the way that we interact with them.

Early computers were operated only using a keyboardand interfaces were entirely text based.

Users memorized abstract commandsand relied on arrow keys to move around the screenand express their intent.

Nowadays, most people use their keyboards togetherwith graphical user interfaces and a mouse.

These innovations removed a layer of abstractionand allowed people to use the mouseto point, click, and dragto more directly express their intent.

Later, Multi-Touch brought the digital worldto people's fingertips,removing yet another layer of abstractionand allowing people to touch their music,their photos, and the mobile web.

Today we want to talk about a class of interactionsthat go beyond the bounds of a single deviceand ways to use the capabilities of the latest Apple devicesto help users interact more directlywith their physical surroundings.

Some of these interactions may already feel familiar,like how you can pay for a coffeeby holding your phone or watch close to a payment terminal.

Or how you can quickly check the battery level on your AirPodsjust by flipping open the case when it's near your phone.

These human-scale interactions --the ones that happen between devices nearby --have the ability to remove layers of abstractionand allow users to interact more directlywith their surroundings.

And with the enhanced spatial awarenessenabled by the U1 chip in the latest Apple products,we've been able to deliver more capable and responsiveexperiences for AirTag, HomePod mini, and iPhone.

And now, thanks to new APIs and the ability to interactwith third-party hardware that you build in iOS 15,you can now bring these kinds of experiencesto your own products.

In designing these interactions, we learned thatit's important to consider distance and ability,provide continuous feedback, and embrace the physical action.

Let's dive right in.

In iOS 13, we made it even easier to share contentby bringing spatial awareness to the share sheet.

Using information about who you are facingor physically close to, combined with on-device knowledgeabout the frequency and recency of your communications,allows your device to intelligently predictwho you are trying to share with.

This is a great example of how existing features in your appscan be made more intelligent with spatial awareness.

You don't have to build an entirely new experienceto take advantage of these new capabilities.

When incorporating spatial awarenessinto existing features,be mindful that these capabilitiesare not available on all devices and your designshould accommodate varying levels of capabilities.

With the share sheet, all devices are ableto look for others using Bluetooth and Wi-Fi.

However, iPhones with the U1 spatial awareness chiptake this a step further by prioritizing othersthat you are facing or are very close to.

Of course, spatial awareness can be usedto not just enhance existing experiences;it can help build entirely new ones.

Next, Arian will share how these same conceptsapply to AirTag.

Arian Behzadi: With AirTag, we will show youhow your design can adaptto accommodate different distances and abilities.

In this example, imagine I've misplaced an item I care about.

I retrace my steps and realize I'm not sure where it is.

I use my iPhone and feel relievedthat I can see where it is on a map.

Previously, I'd only be ableto get to the general vicinity of this item,but now my iPhone can guide meat a scale that is much more helpful.

In fact, the same button that gave me directionswhen I was far away has now become a buttonthat will help me find it as I'm closer.

Augmenting elements of the designwhen at the appropriate scale is a great way for peopleto discover and use these new abilities.

As iPhone is locating my AirTag,I'm invited to move around and search my surroundings.

Once connected, an arrow formsand points directly to where I need to go.As I align with the direction of my AirTag,the design lights up to reinforce this.

We emphasize this facing directionand provide guidance when not facing this direction.

In a subtle way,this distinction also scales based on distance.

When further away, we found that it is really hardto remain facing a specific direction.

To remedy this, we are actually more generouswith the angle that iPhone considers facing.

As you get closer, this forgiveness becomes more narrowto become more and more specific.

This happens without you noticingas you're gently guided to your AirTag.

When you're finally within arm's reach of your AirTag,the arrow defers to a form of feedbackthat we find much more effective at this small scale.The design transforms to highlight haptic feedbackas you pass your iPhone overwhere your AirTag might be hiding.

With this example, we've shown youhow your design can transform based on distance,whether you're very far away or within millimeters.

Think about how your design can bestaccommodate varying abilities we all share as humans.

Be forgiving with angles at a distance,and consider changing the dominant form of feedbackto one that works best at smaller scale.

Next, I'd like to hand it over to Taylorto show you just how critical this continuous feedback iswhen designing these kinds of interactions.

Taylor Carrigan: Thanks, Arian.

We've gone to great lengths to make onscreen interactionsfluidly and dynamically respond to touch input,but this continuous feedback is even more criticalwhen interacting in the physical world where your devicebecomes a more literal extension of your body.

The right type of feedback applied and choreographedat the right time throughout these interactionscan help make the feature you're designing discoverable,provides instruction,and can communicate success or failure.

It also acknowledges that our movementscan start, stop, and be interrupted at any time.

We're going to talk about how you can use feedbackyou can see,  hear, and feelto help connect your interaction to the physical world.

Though dependent on the capabilitiesof the devices used,there are multiple types of feedbackworth considering and using together.

These can include visual feedback --such as user interface changes,lights and hardware interactions,and visual feedback coordinated across both devices --audio feedback , and haptic feedback.

We'll also talk about natural interruptionand cancellation and the importance these playin creating a successful interaction between two devices.

Let's look first at how different types of feedbackhelp make the transfer of music to HomePod miniintuitive and satisfying.

With HomePod mini,we use multiple types of feedback to establisha physical relationship with your iPhone,provide direction, and ultimately confirmthat your music has been successfully transferred.

We achieved this by creating two discrete boundariesaround the HomePod,and respond to your movement across and between them.

Feedback is provided when your iPhone reaches the first zone,between the first and second to instruct you to move closeror allow you to cancel the interaction,and finally when your iPhone reaches the second zone,to confirm and transfer music.

Feedback is continuously providedfrom the moment iPhone reaches the first distance threshold.

On screen, the banner position, scale, and modalitycreated by the background blurincrease fluidly and in direct responseto your distance from the HomePod.

When designing visual feedback,look for opportunities for the onscreen elements to animatein a way that feels related to your physical movements --like how the movement of this banneris related to the linear movement of your handtowards or away from the HomePod.

Haptic feedback complements this with a physical acknowledgementthat the two devices are aware of each other,and increases in strength to encourage youto continue moving closer.

In addition to the feedback on iPhone,HomePod mini acknowledges the proximity of iPhonethrough the animations on the top of the speaker.

Great spatial interactions use natural body movementsto not only confirm but also to cancel actions.

When moving an iPhonenear a HomePod mini, clear and continuous feedbackthat tracks your distance from the HomePodmakes it clear that you can simply pull awayto cancel or interrupt the gesture.

This allowed us to create an interaction that can be doneentirely without looking at the displayor requiring additional onscreen buttonsto cancel or confirm user intent.

All of these aspects are driven by and respond tothe movement of your body as it brings iPhonecloser to or farther away from the HomePod.

The directness of the relationshipbetween someone's movements in the physical worldand what they're seeing, hearing, and feelingon one or both devices are criticalwhen designing a spatial interaction.

Next, Linus will talk about the unique constraintsof providing feedback while finding an AirTag.

Linus Persson: HomePod mini is a good exampleof how to choreograph feedback across two devices,both capable of expressing rich feedback.

For designs where this is not a possibility,you might have to rely more heavily on a single device.

Since AirTag helps you find an item when it's lost,the experience is designed for scenarioswhen it's hidden from view.

Let's revisit the finding experience we saw before,this time with an eye on how we provide continuous feedbackacross the senses using iPhone'srich haptic, visual, and acoustic capabilities.

A spatial interaction feels great when it's responsiveand follows your motion.

That means responding to movements that are bigas well as ones that are subtle.

Even as iPhone is connecting to the AirTag,the interface gently rotates and responds as I turn,implying the nature of the interactionthat is about to follow.

These dots also provide the building blocksfor a continuously adapting experience.

Once connected, the distance between me and my AirTagalso appears.

This distance responds incredibly preciselyas I walk in any direction.

It instantly updates and tells meif I'm walking toward, or away, from where I want to go.

As I walk around, the same dots smoothly form an arrowpointing me in the right direction.

This moment is reinforced further using a delicate hapticand sound to mark its importance.

It feels as though the arrowfloats in space as my iPhone moves around it.

As you saw earlier,the interface reinforces moments when I am on the right path.

When facing the direction of my lost AirTag,the screen boldly lights upand I also feel and hear the arrow snap into place.

By responding to every step and subtle turn,the design feels tightly coupled with me and the space I'm in.

When designing your spatial interaction,consider how people will connect their own movementwith what they experience on the device.

Try to make a clear link between action and feedbackin a way that is mindful of the particular motion.

Just ahead of the arrow,there's a dot that starts to pulse in my hand.

The pace of this pulse picks up as I get closer,and the haptics become tighter and crisperalong with it.

If I break away from this direction,the pulse stops and the interface guides me back.

If I walk far enough away from my AirTag,the arrow disassembles to mark the loss of signal.

Nuance in moments like thesealso provide important and very helpful guidance.

Be mindful of how feedback can complement human motionsthat are varied and unpredictable,and build a design that is resilientand can adaptively change to accommodate the way we move.

When within arm's reach, we visually zoom in on this dot,and the pulse changes to continuous haptic feedbackthat shifts with my movement.

This haptic response changes in character as I move closerand further away.

I can move my iPhone over where AirTag might beand sense through my hand more precisely where it's hiding.

Note that we do not use sound for this part of the experience,as haptic feedback does a much more effective job.

As with any continuous feedback,your design should be mindful of how haptics, sound,and visuals work together in concert across the senses.

Similarly to the way we perceive what we see,hear and feel in the world as one holistic experience.

When designing your interaction, it is important to considerthe different strengths of each form of feedbackand how they can be used together.

Seek to provide a visual layer of continuous feedbacktied to physical motion and use additional feedbackto emphasize important moments in your interaction.

Use haptics and sound judiciouslyand at the right levels,with a repeatable cause and effectso it is clear what is being communicated.

In addition to working with feedback in this way,keep in mind that your design will complementa physical action.

And to speak about this is my colleague Pedro.

Pedro Mari: In the case of HomePods,we use spatial awareness to make the taskof selecting a speaker more natural.

Oftentimes, I'll be listening to some music,and I'll want to move it from my iPhoneto a better speaker near me.

Previously, if I wanted to play this songon a different speaker, I'd have to go into the AirPlay list.

In this list, all of the other devices in my spaceare presented equally, whether they are near me or not.

What I am really interested in, though,is this particular HomePod.

With this new human-scale interaction,I can finally transfer a song to this HomePodwithout navigating an onscreen UI,or having to interact with the screen at all, for that matter.

We provide visual feedback on the HomePod itselfto show that the music is about to be transferred.

The light modulates preciselywith my movement, growing in intensity as I approach,and shrinking as I move away.

And of course,the ultimate confirmation of the transferis the music playing from the speaker itself.

By embracing the physical action,a previously intangible experiencenow feels completely tangible, visceral, and instinctive.

Think of ways that your own interfacescan support a natural physical motion,rather than an abstracted list of options.

Try to make your experiences and designsdefer to the physical task at hand.

Also, consider how the concepts of "this" and "that"can be finally used to create a more natural experiencethat aligns with how we think.

Make sure to provide instant and continuous feedbackon both devices.

Specifically, be very clear on the target devicethat an action is happening,as this is where your attention will be naturally drawn to.

Similarly, when finding a lost item,my attention is meant to be directed at the world around meand where it might be hiding.

Playing sound from the AirTag gives me an immediate senseof its place in space,drawing my attention to my surroundings.

When it comes to the visual feedback on iPhone itself,make sure it can be read when performing a taskthat extends beyond the bounds of the display.

We often design our interfaces to work in this mannerwhen we anticipate it will be viewed in the periphery.

For instance, when using turn-by-turn navigation,the typography of when and where I need to take my next turnis bigger and bolder than other notificationsthat might occupy the same space.

The buttons and active area of TV Remote are extra largeand are designed for your eyes to be directed to the TV itself,rather than the control for it.

The digits and operation buttons in Calculatorare large and bold, as we anticipateyou might be referencing numbers on a restaurant billto calculate a tip, for instance.

As in the previous examples,the type size we use for the distancewhen finding an AirTag is set much largerthan in other parts of the system,and the entire UI revolves aroundthe central element of a giant arrow.

Bold color changes can be read in my periphery.

Sound reinforces key moments and states --I can actually feel the distance getting smaller as I walkwithout ever having to look at the screen.

This ultimately supports a more natural pose as I use it.

When in arm's reach,haptic feedback can guide me closereven if the screen is not in my periphery.

These large and bold UI choicesenable those with varying abilitiesto access the experience as well.

Make sure your design uses more than one mode of feedback,and that each one is salient enough to be clearly understood.

Your design shouldn't demand too much attentionto communicate its informationor compete with the primary task.

Lastly, try to reinforce good statesand celebrate positive progressalong the way to completing a spatial interaction.

Always consider the physical actionyour experience is complementing.

And now, back to Peter!Peter: We've covered a lot today.

We've seen how new and existing experiencesbecome more intelligent and relevantwhen they consider the device's context and surroundings.

You learned how responsive and continuous feedbackcan help users discover and use these new experiences.

And finally, we took a look at techniquesthat allow your designto be effectively experienced peripherallywhile keeping attention on the physical surroundings.

We hope that you are just as excited as we areabout how spatial awareness can simplifyand bring more directness to interactions between our devicesand our users' physical surroundings.

For more information, be sure to visit developer.apple.comwhere you'll find the Human Interface Guidelinesfor spatial interactions, as well as technical informationabout how to implement these types of interactions.

We can't wait to see what you'll build next.

♪

## Code Samples

