# Wwdc2021 10265

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Immerse your app in Spatial AudioDiscover how spatial audio can help you provide a theater-like experience for media in your apps and on the web. We'll show you how you can easily bring immersive audio to those listening with compatible hardware, and how to automatically deliver different listening experiences depending on someone's bandwidth or connection — all with little to no change to your code. And gain recommendations on how you can tailor the experience in your app and use spatial audio to tell stories in new, exciting ways.ResourcesCore AudioHD VideoSD VideoRelated VideosWWDC23Enhance your app’s audio experience with AirPodsWWDC21Explore HLS variants in AVFoundationWhat’s new in AVFoundation

Discover how spatial audio can help you provide a theater-like experience for media in your apps and on the web. We'll show you how you can easily bring immersive audio to those listening with compatible hardware, and how to automatically deliver different listening experiences depending on someone's bandwidth or connection — all with little to no change to your code. And gain recommendations on how you can tailor the experience in your app and use spatial audio to tell stories in new, exciting ways.

Core Audio

HD VideoSD Video

HD Video

SD Video

Enhance your app’s audio experience with AirPods

Explore HLS variants in AVFoundation

What’s new in AVFoundation

Search this video…♪ Bass music playing ♪♪Simon Goldrei: Hello! In this session,we'll explore how to immerse your app in spatial audio.I'm Simon and I'm part of the streaming media teamhere at Apple.Do you want to offer your customers,and differentiate your service,with the experience of a movie theater?Would you like to offer immersive audiowith rendering of multipoint audio sourcesthat provides that sense of being there?Can we do all this from the convenienceof the mobile device in our customer's pocket?In this session, we're going to explore spatial audioand how to deliver it with the Core AVFoundation playback APIsand WebKit.We've got a full agenda.Together we'll cover what is spatial audioby contrasting it to existing technology we're familiar with.Then we'll enumerate the technologies and treatmentsthat the feature offers.In the second half, I'll introduce APIand highlight different treatments that are applied.Next up, we'll review the levels of supportfor spatial audio in prior releasesso that you can target features appropriately.I'll also reveal what's new this yearin our fall 2021 OS releases.Then to top it all off, we'll end with a demo.I'm excited to share that with you.You're in for a treat!To understand what is spatial audio,let's start by considering classic stereo.Be it headphonesor stereo speaker arrangements of yesteryear,the soundstage we perceive is rather limited.We don't hear sounds from behind us,directly in front, or above us.It's missing lifelike, positional reproduction.And in the case of headphones,the sound emanates from tiny speakers in, or on, our heads;we call this an in-head experience.As we naturally move our heads while watching a movie,those tiny speakers move with us.This is not a theater-like experience,but this is where spatial audio can help.Spatial audio offers a theater-like experience.It's a psychoacoustic technology that has the effectof producing a compelling virtual soundstage.It works best with multichannel contentbut it also offers a compelling experiencefor stereo content as well.Finally, spatial audio support is offered for audiovisualand audio-only media sources.Best of all, it works with a variety of Apple productsyour customers already have.We made it simple to bring the spatial audio experienceto your customers.As I just alluded to, the best way to enjoy spatial audioin your applications is to provide multichannel audio.That experience is most adaptive to the customer's environmentwhen providing HLS variantsthat reference multichannel audio alternates.In fact, you may already have in your content librarymultichannel audio source media.Simply publishing this will enable, by default,spatial audio in your application.There's absolutely no software change needed.Multichannel audio tracks in regular media files --and WebKit's MSE in the fall 2021 releases --also benefit from limited support that I'll detail later.Let me tell you about media experiencesyou can now expect to create.There's so many experiences you can now recreatewith spatial audio.You can deliver music that surrounds us,that feels like being at the concert.You can build full-motion video gameswith interactive scenes that take gamerson their own immersive adventures.But how does this technology work?When spatial audio is used, the virtual soundstage is static.The soundstage doesn't move with casual head movement,unlike we saw earlier with stereo.What we get is the same audible effect and feelingwe expect from the theater.This effect is possible both from the built-in speakersin many of our productsand now is also available in select headphone products.When spatial-capable headphones are used,measurements from inertial measurement unitsin the playback device are compared withsimilar measurements in the headphonesto determine the customer's head pose.This is used to dynamically alter the audio renderingto maintain that static soundstage effect.The result is a feeling like the audio is emanatingfrom the original placement around the camera,or listener, for an out-of-head experience.It even works on a turning bus or a banking airplane.We also offer a technique to up-mix stereo sourcesto reproduce a 5.1 channel experience.We provide this feature to offer spatial audioalong with your existing library of stereo content.For supported headphones, it is the defaultstereo treatment in our fall 2021 releases.We also use this treatment implicitly to make spatial audioeven more compelling for you to adopt and offer,because right about now, you're probably thinkingthat distributing multichannel audiomight impede the visual quality of your media.After all, multichannel audio is much higher bitratethan the stereo AAC renditions you offer today.How can you possibly fit both in a constrainednetwork bandwidth environment?This a real problem.We solved this by making the spatial audio experienceadaptive to your customer's bandwidth.When bandwidth is insufficient to delivera high-quality audiovisual experience,the audio seamlessly degrades to a stereo, up-mixed --but a still spatial -- treatment.Head-tracking, if offered before the transition,is maintained.Soon after, when bandwidth reliably recovers,the full multichannel spatial treatment is restored.With this adaptive spatial audio experience,it is ever more important to both normalizethe volume levels between stereo and multichannel renditions.In addition, please provide DRC --Dynamic Range Control --and dialnorm metadata in your media encodingsas is appropriate.This is described in more detailin the HLS Authoring Specificationavailable at developer.apple.com.Let's take a look now at the interfaces you can useto tailor the spatial audio experience.To customize the default spatial audio experiencein your application --be it via AVPlayerItem or now, AVSampleBufferAudioRenderer --you specify one of four AVAudioSpatializationFormats.These are to permit the spatializationof mono and stereo, multichannel,and the combination of the last two --that is mono, stereo,and multichannel source audio formats.You can also specify zero to inhibit audio spatialization.Do note that our platforms provide system-level controlsfor customers to tailor the experience further,depending on the type of audio route,through Control Center and Bluetooth settings.We take one of these four values and set it on theallowedAudioSpatialization Formats propertyon an AVPlayerItem and now, new in our fall 2021 releases,an AVSampleBufferAudioRenderer.Now, you may be wondering, how do you use AVFoundation APIsto discover if an audio route supports spatial audio?How do you know if you should deliver multichannel audio toyour AVSampleBufferAudioRenderer instance?Well, in the fall 2021 releases,we're introducing a property that indicates thison an AVAudioSessionPortDescription.In addition, on AVAudioSession, we're introducing a mechanismfor you to advertise to the systemthat your application is able to offer multichannel audio.This indication is shown if the customershaven't enabled the spatial audio treatmentin Control Center or Bluetooth preferences.Note that if your application uses AVPlayer,these indications are managed for you.The isSpatialAudioEnabled property indicates that the portis capable of both rendering spatial audioand that the customer permits it.You are encouraged to observe route change notificationsand to check isSpatialAudioEnabledat each event.Similarly, AVAudioSession will emita spatialPlaybackCapabilities ChangedNotificationwhen the customer alters the spatial preferencesin Control Center and Bluetooth settings.As a convenience, this notification carries informationabout the state of spatial audio enablement.Use the AVAudioSession SpatialAudioEnabledKeyto retrieve the state as it pertains to this notification.Finally, to indicate to the system that your softwareor service can provide multichannel content,you call the function setSupportsMultichannelContentwith your intent.This is used to relay to the customerthat a spatial experience is availableif network conditions permit and if the treatment is enabled.Let's now survey the feature supportacross the last three release years.In macOS Catalina, iOS and iPad OS 13,spatial audio is offered via built-in speakerswith AVPlayerItem and the WebKit video tagby specifying any URL with an http scheme.It is available to customers with 2018 and later year modelMacBook, iPhone, and iPad Pro product lines.The default is to offer spatialization by selectingmultichannel audio renditions where available.In macOS Big Sur, iOS and iPad OS 14,we introduced support for the AirPods Pro and AirPods Maxhead-track-capable headphones.Spatialization capabilities via these accessoriesis offered to 2016 and later iPhone- and iPad-paired devices.The default remains to offer spatializationby selecting multichannel audio renditions where available.That brings us to the all-new support in macOS Monterey,iOS, iPadOS, and now, tvOS 15.Here we offer support via AVPlayerItem,AVSampleBufferAudioRenderer, and limited WebKit supportfor W3C Media Source Extensions, MSE.The MSE path offers no interfaceto tailor the spatialization experience.However, there does exist an interface to detectthe availability of spatial audio supportvia the AudioConfiguration dictionarywithin the Media Capabilities API set.The default in these releasesis to offer audio spatialization by defaultfor all of mono, stereo, and multichannel sourceswhere available and conditions permit.For audio-only presentations,including all AVSampleBuffer AudioRenderer uses,only multichannel audio renditionsare offered the treatment by default.Now that we know what spatial audio isand how to use it, we've got something really speciallined up for you today.We're going to show you how you can use spatial audioin your software and servicesto help tell stories in new, creative ways.Let's have a listen!♪ Upbeat music playing ♪<Uh-oh. Let's try that again.Um... Uh...Cupertino? We have a problem.Offscreen voice: What is it this time?Simon:  I know. I know. Anything?Offscreen whisper: Sorry, Simon. Simon: No?Offscreen whisper: It's not going to work.Simon: Really? Offscreen whisper: I know...Simon:  Bugger it. All right. All right. All right.So we made this really great demoto demonstrate all the cool things you can dowith spatial audio but... you know...it seems like this isn't happening today.Look.We're going to try something.I can't show you this video but what if I could, um......describe it?OK. So I don't know where you are right now,but I want you to close your eyesand let's imagine we're in a WWDC hall.You know what that sounds like, right?What that feels like?Picture it in your mind.Picture the stage and the big screen.We're just about to dim the lightsand start playing this video.Oi! You! Dim the lights.We're high in the sky above San Francisco.Whooshing from the bay, down through the tall buildings.The wind is rushing all around us,and then we're zooming out of the cityand down the peninsula, all the way to Apple Park.We soar into the parkand you see somebody with amazing hairduck as we fly past.He shouts, "Slow down!"which has this really cool left-to-right Doppler effect.Slow down!And we're flying through the Apple orchard now.Feel the whoosh of the trees.We find ourselves at the pondfor a moment of peace and tranquility.Whispered voice: I'm honestly not sold on spatial audio.Simon: And then, we're on the move again,whooshing over the birds until we reachthe big glass doors of Caffè Macssliding across the smooth terrazzo flooruntil we find this woman.She's eating a pizza with her iPad propped up on the table,totally absorbed in this movie that's really, really tense.It's this teeming jungle at the earliest hours of dusk.The audio is literally -- no really!It's -- It's pulling us into the scene.Whispered voice: He's doing a great job describing this demo.I almost feel like I'm there. It's so vivid.Simon: ...and distant monkey calls.But suddenly it gets eerie......and all the creatures go quiet.All we can hear is the rustling of leaves.Then a c-c-c-crashas a tree falls.Something is coming! Something big!Thump. Thump. Thump.We can hear our heart beating, right in the chest.And then... silence.We're about to relax when...a dinosaur bursts through the trees right across from us!And we look up,straight into its gaping maw!Voice over PA: That's a wrap on 42...Simon: We pull back to reveal we're on a film set.Man: I'm not sure I love that lighting...Simon: The dinosaur has stopped movingand a crew of people have appeared to clear the set.Woman: Go for Kelly.Voice over radio: You got a 20 on actors?Woman: Yeah. They're in makeupwatching the launch. Going off comms.Woman: Are you coming?Simon: We follow two of them into a trailerto watch today's space launch --streaming, of course, in surround audio.The audience is holding their breathbut we move through them and into the TV.Woman: Go for launch. Man: Good across the board.Simon: And now we're inside the capsule.Woman: Let's put the pedal to the floor.Simon: The rocket ignites!Woman:  Here we go!Express service to the moon! Next stop, Tranquility.Man: All still good.Booster separation in three, two, one...Clean and smooth.Simon: The second stage of the rocket has dropped away,and we drop with it......and follow the stage as it falls back to Earth,getting faster and faster.We're dropping through the atmosphere now,back towards the ground.Towards something.A big jet plane.Getting bigger, and bigger, and --Woman on PA: Good morning, folks.This is your captain speaking from the flight deck....our descent towards our final destination today.Shouldn't be more...Simon:  It's beautiful!Well, so, uh... that was fun.Let's summarize what we saw and heard.We discovered how easy it isto offer our customers a spatial audio experience.In fact, you may not need to do anything to your applicationto take advantage of spatial audio.Just by offering multichannel audioin your HLS variant playlists is often sufficient.Remember, it is important to normalize volume levelsbetween stereo and multichannel renditions,and to include DRC metadata.Finally, we've seen how you can offer spatial audioto a wide customer base across the last three yearsof OS releases.In our related sessions, you can learn how to discoverif your HLS resources have multichannel audio.Learn all about thatas you explore HLS variants in AVFoundation.I hope you've enjoyed this sessionas much as the team here and I have.We hope you'll immerse yourself, and your app,in spatial audio and enjoy the rest of WWDC 2021.Thank you.♪

♪ Bass music playing ♪♪Simon Goldrei: Hello! In this session,we'll explore how to immerse your app in spatial audio.

I'm Simon and I'm part of the streaming media teamhere at Apple.

Do you want to offer your customers,and differentiate your service,with the experience of a movie theater?Would you like to offer immersive audiowith rendering of multipoint audio sourcesthat provides that sense of being there?Can we do all this from the convenienceof the mobile device in our customer's pocket?In this session, we're going to explore spatial audioand how to deliver it with the Core AVFoundation playback APIsand WebKit.

We've got a full agenda.

Together we'll cover what is spatial audioby contrasting it to existing technology we're familiar with.

Then we'll enumerate the technologies and treatmentsthat the feature offers.

In the second half, I'll introduce APIand highlight different treatments that are applied.

Next up, we'll review the levels of supportfor spatial audio in prior releasesso that you can target features appropriately.

I'll also reveal what's new this yearin our fall 2021 OS releases.

Then to top it all off, we'll end with a demo.

I'm excited to share that with you.

You're in for a treat!To understand what is spatial audio,let's start by considering classic stereo.

Be it headphonesor stereo speaker arrangements of yesteryear,the soundstage we perceive is rather limited.

We don't hear sounds from behind us,directly in front, or above us.

It's missing lifelike, positional reproduction.

And in the case of headphones,the sound emanates from tiny speakers in, or on, our heads;we call this an in-head experience.

As we naturally move our heads while watching a movie,those tiny speakers move with us.

This is not a theater-like experience,but this is where spatial audio can help.

Spatial audio offers a theater-like experience.

It's a psychoacoustic technology that has the effectof producing a compelling virtual soundstage.

It works best with multichannel contentbut it also offers a compelling experiencefor stereo content as well.

Finally, spatial audio support is offered for audiovisualand audio-only media sources.

Best of all, it works with a variety of Apple productsyour customers already have.

We made it simple to bring the spatial audio experienceto your customers.

As I just alluded to, the best way to enjoy spatial audioin your applications is to provide multichannel audio.

That experience is most adaptive to the customer's environmentwhen providing HLS variantsthat reference multichannel audio alternates.

In fact, you may already have in your content librarymultichannel audio source media.

Simply publishing this will enable, by default,spatial audio in your application.

There's absolutely no software change needed.

Multichannel audio tracks in regular media files --and WebKit's MSE in the fall 2021 releases --also benefit from limited support that I'll detail later.

Let me tell you about media experiencesyou can now expect to create.

There's so many experiences you can now recreatewith spatial audio.

You can deliver music that surrounds us,that feels like being at the concert.

You can build full-motion video gameswith interactive scenes that take gamerson their own immersive adventures.

But how does this technology work?When spatial audio is used, the virtual soundstage is static.

The soundstage doesn't move with casual head movement,unlike we saw earlier with stereo.

What we get is the same audible effect and feelingwe expect from the theater.

This effect is possible both from the built-in speakersin many of our productsand now is also available in select headphone products.

When spatial-capable headphones are used,measurements from inertial measurement unitsin the playback device are compared withsimilar measurements in the headphonesto determine the customer's head pose.

This is used to dynamically alter the audio renderingto maintain that static soundstage effect.

The result is a feeling like the audio is emanatingfrom the original placement around the camera,or listener, for an out-of-head experience.

It even works on a turning bus or a banking airplane.

We also offer a technique to up-mix stereo sourcesto reproduce a 5.1 channel experience.

We provide this feature to offer spatial audioalong with your existing library of stereo content.

For supported headphones, it is the defaultstereo treatment in our fall 2021 releases.

We also use this treatment implicitly to make spatial audioeven more compelling for you to adopt and offer,because right about now, you're probably thinkingthat distributing multichannel audiomight impede the visual quality of your media.

After all, multichannel audio is much higher bitratethan the stereo AAC renditions you offer today.

How can you possibly fit both in a constrainednetwork bandwidth environment?This a real problem.

We solved this by making the spatial audio experienceadaptive to your customer's bandwidth.

When bandwidth is insufficient to delivera high-quality audiovisual experience,the audio seamlessly degrades to a stereo, up-mixed --but a still spatial -- treatment.

Head-tracking, if offered before the transition,is maintained.

Soon after, when bandwidth reliably recovers,the full multichannel spatial treatment is restored.

With this adaptive spatial audio experience,it is ever more important to both normalizethe volume levels between stereo and multichannel renditions.

In addition, please provide DRC --Dynamic Range Control --and dialnorm metadata in your media encodingsas is appropriate.

This is described in more detailin the HLS Authoring Specificationavailable at developer.apple.com.

Let's take a look now at the interfaces you can useto tailor the spatial audio experience.

To customize the default spatial audio experiencein your application --be it via AVPlayerItem or now, AVSampleBufferAudioRenderer --you specify one of four AVAudioSpatializationFormats.

These are to permit the spatializationof mono and stereo, multichannel,and the combination of the last two --that is mono, stereo,and multichannel source audio formats.

You can also specify zero to inhibit audio spatialization.

Do note that our platforms provide system-level controlsfor customers to tailor the experience further,depending on the type of audio route,through Control Center and Bluetooth settings.

We take one of these four values and set it on theallowedAudioSpatialization Formats propertyon an AVPlayerItem and now, new in our fall 2021 releases,an AVSampleBufferAudioRenderer.

Now, you may be wondering, how do you use AVFoundation APIsto discover if an audio route supports spatial audio?How do you know if you should deliver multichannel audio toyour AVSampleBufferAudioRenderer instance?Well, in the fall 2021 releases,we're introducing a property that indicates thison an AVAudioSessionPortDescription.

In addition, on AVAudioSession, we're introducing a mechanismfor you to advertise to the systemthat your application is able to offer multichannel audio.

This indication is shown if the customershaven't enabled the spatial audio treatmentin Control Center or Bluetooth preferences.

Note that if your application uses AVPlayer,these indications are managed for you.

The isSpatialAudioEnabled property indicates that the portis capable of both rendering spatial audioand that the customer permits it.

You are encouraged to observe route change notificationsand to check isSpatialAudioEnabledat each event.

Similarly, AVAudioSession will emita spatialPlaybackCapabilities ChangedNotificationwhen the customer alters the spatial preferencesin Control Center and Bluetooth settings.

As a convenience, this notification carries informationabout the state of spatial audio enablement.

Use the AVAudioSession SpatialAudioEnabledKeyto retrieve the state as it pertains to this notification.

Finally, to indicate to the system that your softwareor service can provide multichannel content,you call the function setSupportsMultichannelContentwith your intent.

This is used to relay to the customerthat a spatial experience is availableif network conditions permit and if the treatment is enabled.

Let's now survey the feature supportacross the last three release years.

In macOS Catalina, iOS and iPad OS 13,spatial audio is offered via built-in speakerswith AVPlayerItem and the WebKit video tagby specifying any URL with an http scheme.

It is available to customers with 2018 and later year modelMacBook, iPhone, and iPad Pro product lines.

The default is to offer spatialization by selectingmultichannel audio renditions where available.

In macOS Big Sur, iOS and iPad OS 14,we introduced support for the AirPods Pro and AirPods Maxhead-track-capable headphones.

Spatialization capabilities via these accessoriesis offered to 2016 and later iPhone- and iPad-paired devices.

The default remains to offer spatializationby selecting multichannel audio renditions where available.

That brings us to the all-new support in macOS Monterey,iOS, iPadOS, and now, tvOS 15.

Here we offer support via AVPlayerItem,AVSampleBufferAudioRenderer, and limited WebKit supportfor W3C Media Source Extensions, MSE.

The MSE path offers no interfaceto tailor the spatialization experience.

However, there does exist an interface to detectthe availability of spatial audio supportvia the AudioConfiguration dictionarywithin the Media Capabilities API set.

The default in these releasesis to offer audio spatialization by defaultfor all of mono, stereo, and multichannel sourceswhere available and conditions permit.

For audio-only presentations,including all AVSampleBuffer AudioRenderer uses,only multichannel audio renditionsare offered the treatment by default.

Now that we know what spatial audio isand how to use it, we've got something really speciallined up for you today.

We're going to show you how you can use spatial audioin your software and servicesto help tell stories in new, creative ways.

Let's have a listen!♪ Upbeat music playing ♪<Uh-oh. Let's try that again.

Um... Uh...Cupertino? We have a problem.

Offscreen voice: What is it this time?Simon:  I know. I know. Anything?Offscreen whisper: Sorry, Simon. Simon: No?Offscreen whisper: It's not going to work.

Simon: Really? Offscreen whisper: I know...

Simon:  Bugger it. All right. All right. All right.

So we made this really great demoto demonstrate all the cool things you can dowith spatial audio but... you know...

it seems like this isn't happening today.

Look.

We're going to try something.

I can't show you this video but what if I could, um...

...describe it?OK. So I don't know where you are right now,but I want you to close your eyesand let's imagine we're in a WWDC hall.

You know what that sounds like, right?What that feels like?Picture it in your mind.

Picture the stage and the big screen.

We're just about to dim the lightsand start playing this video.

Oi! You! Dim the lights.

We're high in the sky above San Francisco.

Whooshing from the bay, down through the tall buildings.

The wind is rushing all around us,and then we're zooming out of the cityand down the peninsula, all the way to Apple Park.

We soar into the parkand you see somebody with amazing hairduck as we fly past.

He shouts, "Slow down!"which has this really cool left-to-right Doppler effect.

Slow down!And we're flying through the Apple orchard now.

Feel the whoosh of the trees.

We find ourselves at the pondfor a moment of peace and tranquility.

Whispered voice: I'm honestly not sold on spatial audio.

Simon: And then, we're on the move again,whooshing over the birds until we reachthe big glass doors of Caffè Macssliding across the smooth terrazzo flooruntil we find this woman.

She's eating a pizza with her iPad propped up on the table,totally absorbed in this movie that's really, really tense.

It's this teeming jungle at the earliest hours of dusk.

The audio is literally -- no really!It's -- It's pulling us into the scene.

Whispered voice: He's doing a great job describing this demo.

I almost feel like I'm there. It's so vivid.

Simon: ...and distant monkey calls.But suddenly it gets eerie......and all the creatures go quiet.

All we can hear is the rustling of leaves.

Then a c-c-c-crashas a tree falls.

Something is coming! Something big!Thump. Thump. Thump.

We can hear our heart beating, right in the chest.

And then... silence.

We're about to relax when...

a dinosaur bursts through the trees right across from us!And we look up,straight into its gaping maw!Voice over PA: That's a wrap on 42...

Simon: We pull back to reveal we're on a film set.

Man: I'm not sure I love that lighting...

Simon: The dinosaur has stopped movingand a crew of people have appeared to clear the set.

Woman: Go for Kelly.

Voice over radio: You got a 20 on actors?Woman: Yeah. They're in makeupwatching the launch. Going off comms.

Woman: Are you coming?Simon: We follow two of them into a trailerto watch today's space launch --streaming, of course, in surround audio.

The audience is holding their breathbut we move through them and into the TV.

Woman: Go for launch. Man: Good across the board.

Simon: And now we're inside the capsule.

Woman: Let's put the pedal to the floor.

Simon: The rocket ignites!Woman:  Here we go!Express service to the moon! Next stop, Tranquility.

Man: All still good.Booster separation in three, two, one...

Clean and smooth.Simon: The second stage of the rocket has dropped away,and we drop with it...

...and follow the stage as it falls back to Earth,getting faster and faster.We're dropping through the atmosphere now,back towards the ground.

Towards something.

A big jet plane.

Getting bigger, and bigger, and --Woman on PA: Good morning, folks.

This is your captain speaking from the flight deck.

...our descent towards our final destination today.

Shouldn't be more...

Simon:  It's beautiful!Well, so, uh... that was fun.

Let's summarize what we saw and heard.

We discovered how easy it isto offer our customers a spatial audio experience.

In fact, you may not need to do anything to your applicationto take advantage of spatial audio.

Just by offering multichannel audioin your HLS variant playlists is often sufficient.

Remember, it is important to normalize volume levelsbetween stereo and multichannel renditions,and to include DRC metadata.

Finally, we've seen how you can offer spatial audioto a wide customer base across the last three yearsof OS releases.

In our related sessions, you can learn how to discoverif your HLS resources have multichannel audio.

Learn all about thatas you explore HLS variants in AVFoundation.

I hope you've enjoyed this sessionas much as the team here and I have.

We hope you'll immerse yourself, and your app,in spatial audio and enjoy the rest of WWDC 2021.

Thank you.

♪

6:55 -Spatialization Formats

7:21 -AVPlayerItem and AVSampleBufferAudioRenderer

8:21 -Spatial audio availability

8:35 -Spatial audio availability

9:01 -Control center integration

## Code Samples

```swift
public
 
struct
 
AVAudioSpatializationFormats
 : 
OptionSet
 
{

    
public
 
init
(
rawValue
: 
UInt
)


    
    
public
 
static
 
var
 monoAndStereo: 
AVAudioSpatializationFormats
 { 
get
 }

    
public
 
static
 
var
 multichannel: 
AVAudioSpatializationFormats
 { 
get
 }

    
public
 
static
 
var
 monoStereoAndMultichannel: 
AVAudioSpatializationFormats
 { 
get
 }
}
```

```swift
@available
(
macOS
 
11.0
, 
*
)

var
 allowedAudioSpatializationFormats: 
Int32
```

```swift
@available
(
iOS
 
6.0
, 
*
)

class
 
AVAudioSessionPortDescription
 : 
NSObject
 
{

  
@available
(
iOS
 
15.0
, 
*
)
  
var
 isSpatialAudioEnabled: 
Bool
 { 
get
 }

 }
```

```swift
extension
 
AVAudioSession
 
{
  
@available
(
iOS
 
15.0
, 
*
)
  
class
 
let
 
spatialPlaybackCapabilitiesChangedNotification
: 
NSNotification
.
Name

}

@
available
(
iOS
 15.0, *)

let
 
AVAudioSessionSpatialAudioEnabledKey
: 
String
```

```swift
extension
 
AVAudioSession
 
{
  
@available
(
iOS
 
15.0
, 
*
)
  
func
 
setSupportsMultichannelContent
(
_
 
inValue
: 
Bool
)
 
throws

  
@available
(
iOS
 
15.0
, 
*
)
  
var
 supportsMultichannelContent: 
Bool
 { 
get
 }
}
```

