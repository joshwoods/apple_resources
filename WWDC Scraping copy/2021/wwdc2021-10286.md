# Wwdc2021 10286

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

Explore bindless rendering in MetalUnleash the full potential of your shaders and implement modern rendering techniques by adding Argument Buffers to adopt bindless rendering. Learn how to make your entire scene and resources available to the GPU to make the most out of raytracing and rasterization pipelines.ResourcesAccelerating ray tracing using MetalApplying realistic material and lighting effects to entitiesManaging groups of resources with argument buffersMetalMetal Feature Set TablesMetal Shading Language SpecificationRendering reflections in real time using ray tracingHD VideoSD VideoRelated VideosWWDC22Go bindless with Metal 3WWDC21Enhance your app with Metal ray tracingExplore hybrid rendering with Metal ray tracingOptimize high-end games for Apple GPUs

Unleash the full potential of your shaders and implement modern rendering techniques by adding Argument Buffers to adopt bindless rendering. Learn how to make your entire scene and resources available to the GPU to make the most out of raytracing and rasterization pipelines.

Accelerating ray tracing using Metal

Applying realistic material and lighting effects to entities

Managing groups of resources with argument buffers

Metal

Metal Feature Set Tables

Metal Shading Language Specification

Rendering reflections in real time using ray tracing

HD VideoSD Video

HD Video

SD Video

Go bindless with Metal 3

Enhance your app with Metal ray tracing

Explore hybrid rendering with Metal ray tracing

Optimize high-end games for Apple GPUs

Search this video…♪ Bass music playing ♪♪Alejandro Segovia Azapian: Welcome to WWDC!My name is Ale Segovia Azapian,and I'm a GPU software engineer at Apple.In this session,we're going to explore bindless rendering in Metal.Bindless is a modern resource binding modelthat allows making groups of resourcesavailable to the GPUto implement modern rendering techniques.First, we'll take a look at the needfor the concept behind bindless.Then, we will introduce the bindless modeland show how it provides the flexibility neededto solve the challenges of the traditional binding model.We will recap the mechanisms to encodeand make your scene resources available to Metalwith argument buffersand how to navigate your GPU structures from shaders.Let's get started!So bindless rendering allows making all our scene resourcesavailable to our shaders,bringing incredible flexibility to our graphics techniques.Let's take a look at an example.Let's imagine we have a ray tracing kernelfinding intersections against an acceleration structure.For some light effects, such as ray-traced shadows,the algorithm is very natural.We want to find any objectsbetween the intersection point and the light.All we need to trace the shadow ray is a positionand the direction toward the light.No object attributes or Metal resources are neededbeyond the world-space position of the intersection,which we can derive from the rayand the intersection's parameter.For other effects however, such as reflections,the situation gets more complicated.Let's take a look at a ray tracing reflection shaderin Metal Shading Language.In this new example,we've just found an intersection,and we're trying to paint the pixelwith the correct reflected color.If we just paint a solid color after we find an intersection,the reflection on the ground will not look accurate.To produce correct results, we need to determinethe attributes of each reflected point foundand calculate the correct shading for its pixel.This problem is also present for other ray-traced effectssuch as diffuse global illuminationand even ambient occlusion in some cases.The challenge is that when we ray trace,our rays may hit any object in the acceleration structure.This means that from our ray tracing shader,we potentially need access to any Metal resourcesin our scene, including vertex data --associated with the mesh intersected --and its material.It is just not possible to bind this amount of resourcesdirectly to our pipeline.This is where the bindless binding model comes in.The idea behind bindless is to aggregate our resourcesand link them together.This allows us to bind a single buffer to the pipelineand make all referenced resources availablevia navigation.In Metal, the construct that allows us to do thisis argument buffers.In particular, for bindless,argument buffers Tier 2 are required.These are available on the Apple6 and Mac2 GPU families.Argument buffers can be used from all shader types in Metal.This means that you can use them for both ray tracingand rasterization.As we saw, for certain ray tracing effects,using bindless is mandatoryin order to obtain good visual results.For rasterization, the use is optionalbut provides advantages over the direct binding model.In particular, it virtually removes the slot limitsfor the number of resources that can be boundfor any given draw call,and it also provides some nice optimization opportunitiesthat we'll explore later in this session.We introduced argument buffers with Metal 2 as a mechanismto allow you to bind constant data and resourcesall at once in a single call to the Metal API.Argument buffers are very flexibleand can even reference other buffers.The idea behind the bindless modelis to leverage this capabilityto link all of our scene resources together.This will allow making them available to the GPUat the same time.Let's look at an example of a wayto link our scene resources with argument buffers.Let's say we want to render a model such as this fire truck.The model is comprised of textures,vertex data, and index data.These are the typical resources you would bind one by onefor every draw call in the traditional binding model.In our case, however --because we want to make all textures, vertex data,and indices of the scene available at once --we need to aggregate these.Here's a potential way to do so.We can first create a meshes argument bufferto contain all our meshes or submeshes,depending on how our assets are organized.This argument buffer will allow referencingthe vertex and index arrays in our scene.Similarly, we can do the same and encode our materialsto an argument buffer.Each material can reference its texturesas well as contain inline constant data.OK, but now that we have all our meshes and materialsavailable to the GPU, how can we bring them together?Well, we can, for example, create an instance objectand also place it in an argument buffer.An instance can reference one meshand an associated material.This is also a great placeto store a model transformation matrixas inline constant data.But we don't have to stop there.Now that we can store one instance,we can take this furtherand encode all of our instances as an arrayinto this argument buffer.Let's simplify this diagramand add a few more truck instances,each one with its own material.As we can see, with this,we can now have our full scene and its resourcesencoded and linked with argument buffers.Later, when we want to reference any of these resourcesfrom our shaders,we just need a pointer to the instances buffer.We can pass it directlyand interpret this buffer as an array,or pass a pointer through another scene argument buffer.Now, it's important to note what happens with the residencyof indirectly accessed resources.Since we're only passing a pointer to the sceneinto the pipeline,Metal will know about this buffer reference,but not about resources accessed indirectly.The application is responsible for declaring residencyof all indirectly accessed resources.Making a resource resident means signaling to the driverto make its memory available to the GPU.This is necessary so we can reference them from our shaders.We can do this by calling the useResource:usage: APIfor compute encoders and useResource:usage:stages: APIfor render command encoders.Accessing a nonresident resource is a common causeof GPU restarts and command buffer failures.This is because its memory pages may not be presentif we forgot to call this API.So it's very important to declareevery indirectly accessed resource to Metal.Now, another option, for convenience,is that resources allocated from MTLHeapscan now be made resident with a single callby means of the useHeap API.This is a great option if you are already suballocatingor planning to suballocate resources from heaps.Now, heaps are a fantastic part of the Metal API,and we recommend you use themfor the best resource-creation performance,and memory-saving opportunities.There are, however, a few considerationsto use them effectively.The first thing to ask is,Are all our suballocated resources only read from?Examples of where we might need to write into a resourceinclude mesh skinning from a compute shaderand dynamic textures, amongst others.In these cases, if the GPU needs to write into any resources,they need to be declared resident individuallywith the write usage flag.Additionally, any resources that may have been modifiedthat we now intend to read fromwill still need their own useResource call.This is so that the Metal frameworkcan handle resource transitions for you, flushing GPU cachesand adjusting the internal memory layout.The second consideration is,Does the heap track suballocate resource dependencies?Again, this is especially importantif we're reading and writing into resourcescoming from the same heap.Metal is great at avoiding synchronization problemsthrough dependency tracking,and since Metal 2.3, heaps can be configuredto track hazards in the access to their resources.However, since heaps are a single resource to Metal,synchronization is handled at the heap levelnot the suballocation level.This may subject suballocated resourcesto the problem of false sharing.Let's take a look.Let's imagine we have two render passes --A and B --accessing resources from the same heap.Render pass A is rendering to a render textureallocated from a tracked heap.Render pass B is reading from an unrelated bufferthat is suballocated from the same heap.Depending on different conditions,render passes A and B may qualify to be executedin parallel by the GPU;however, due to the potential hazardof writing and reading from the same resource --the heap -- Metal has to serialize accessto ensure there are no race conditions.This can potentially increase the execution wall-clock timeof our workload by the GPU.In our case, however,if we know the individual resources are independent,this fence could be avoided.There are two ways to do this.One option is to suballocate resources that are updatablefrom heaps separate to the ones used for our static resources.The other option, if we desire to bundle everything together,is to make sure heaps are configurednot to track their suballocated resources.This is the default behavior in Metal,and it means we as programmers take on the responsibilityof synchronizing hazards ourselves.Now, in this diagram I simplified things a bitto illustrate the problem of false sharing.In practice, overlapping occurs at the shading stage level,not at the render pass level.As a consequence, Metal allows usto specify our fences at the stage granularity.This is great because it allows us to still runparts of our pipeline -- such as vertex stageand rasterizer -- concurrently,and only block later in the fragment stageif it happens to depend ona previous pass's fragment stage output.We recommend you always do this for maximum performance,if possible.Now, this is a lot to remember,so if you only get one thing from this list,please remember this: read-only data,such as static textures and meshes,are the easiest to handle.Determine the total allocation sizeand alignment requirements upfrontand place these resources in a heap when the app startsor during a loading section in your game.This way, you can later make it resident in a single call,with minimal overhead in your critical path.Now that we know about the bindless binding model,let's take a look at how we can encode our resourcesand put this in practiceand make our complete scene available to the GPUwith argument buffers.Let's say we want to encode our instances buffer.Remember, this buffer consists of an array of instances.As we saw, instances reference a mesh, a material,and contain an inline constant 4x4 matrixdescribing the transformation from local to world space.Encoding is performed via an argument buffer encoder,and there are two distinct ways to create one in Metal.You may be familiar with encoding via reflection.If the argument buffer is passed as a direct parameterto the shader function,we can ask the MTLFunction objectto create an encoder for us.This mechanism works great,but when we are encoding the entire sceneinto argument buffers, not all encoders can be reflected.In particular, the MTLFunction signaturedoes not know about the indirectly referenced buffers.There might also be other situationswhere creating an encoder from a MTLFunctionis not convenient;for example, if your engine architecturehandles argument-buffer creation and resource loadingseparate from pipeline state creation.Additionally, we cannot reflect an encoderwhen the function is expecting to be passed an array.So what can we do in these cases?For these cases,Metal provides a convenient second mechanismto create an encoder through a MTLArgumentDescriptor.MTLArgumentDescriptors allow describing the struct membersto Metal and subsequently creating an encoderwithout a MTLFunction.We must first create a descriptor for each member,specifying data type and binding index.Next, we take our descriptors,and pass them directly to the MTLDeviceto create our encoder.As a result, we obtain our encoder object back.So let's explore what this looks like in code.For each member,we needed to create a MTLArgumentDescriptor;we specify the binding index,corresponding to the ID attributefor the member in the struct;we specify the MTLDataType and potentially access;and finally, after we've declared all the members,we can create the encoder directly from the device,passing an array with all our descriptors.Once we have an encoder,it's straightforward to record our data into a buffer.We set the argument buffer on the encoder,pointing at the beginning of the buffer.Then, we simply set the data we want to store.Encoding an array is simple as well.All we have to dois offset the encoder's argument buffer recording pointby the encodedLength,which we can conveniently retrieve from the encoder.For the next instance, we add the encodedLengthto our offset a second time.In fact, the offset for each position we need to record inis going to be the index times the encodedLength.This mechanism makes it very easyto encode arrays of structs.Now, one important point worth mentioningis that no special treatment is needed from shader sideto index into these arrays.The shader does not need to knowthe length of the bufferand can freely index into any location in the array.It just works!OK, now that we have encoded our bindless scene,let's take a look at navigation.For the case of ray tracing, navigation is very natural.First, we bind the buffer that contains the rootof our bindless scene to our ray tracing pipeline.This is the argument bufferfrom where we can access all the others.Next, from our kernel,we proceed with the ray-traced intersection as usual.After we discovered an intersection,the intersection result object describes the navigation.We can query this object for instance_id,geometry_id, and primitive_id.These members are designed specificallyfor navigating our acceleration structures.It is, therefore, important to build our bindless scenewith a structure that mirrors our acceleration structures,such as the one shown earlier.Let's take a look at it again.Remember, this is just an exampleof how to organize the scene,so I'm going to navigate it according to how I organized it.The particular details for your scene may vary,according to how you decide to organizeyour own argument buffers.First, we need to find an intersection.Once we have it,because we strategically organized our bindless scene,given the instance_id we can now follow the pointerto the instances buffer and determine which one we hit.Next, as we saw, the instance knows its mesh and material.So we can simply use the geometry_idto determine which geometry we hitwithin the referenced buffer.Finally, if we prepared each meshto know its index buffer, we can use the primitive_idto determine the exact primitive that we hit.In the case of a triangle, for instance,we can pull the three indices from this arrayand use them to retrieve its vertex data.Here's what this navigation looks likein Metal Shading Language.From the intersection object, we retrieve the instance_idand use it to dynamically index into our instances arrayand retrieve the instance we hit.Next, having the instance, we use the geometry_idto determine which geometry or submesh was hit.Once we've determined the geometry,we can directly pull the indices from the index buffer.In the case of a triangle, we pull three indices,one after the other.We use these indices to access into the vertex data arrayand retrieve any attribute we need for our technique.For example, we can retrieve the normalscorresponding to each vertex.And finally, using the point's barycentric coordinates,we manually interpolate vertex normalsto arrive at the correct normal at the intersection point.With these changes in place,taking it back to our teapot example,now that we have a way to calculate the normalat the intersection point,we can correctly shade our reflection.We've updated the code to find the correct attributesat the intersection point,and now the results are visually correct.We can now continue building on this frameworkto calculate any other attribute we want,such as texture coordinates to apply a textureor tangent vectors to implement normal mapping.So here we saw how to navigate our bindless sceneto retrieve vertex data, manually interpolate it,and finally, apply it to correctly shadeall the intersection points discovered.To help you bring these concepts into your own engine,we're going to be releasing a companion code samplethat shows a concrete implementation of all of this.This is a hybrid rendering samplethat calculates ray-traced reflections for a sceneloaded using the Model I/O framework.The sample shows how you can encode a bindless scenethat matches the ray tracing acceleration structures,and it also shows how to find intersectionsand correctly shade their associated pixelsdirectly from your ray tracing shaders.As we can see here,the sample also allows directly visualizingthe output of the reflection ray tracing shaderjust at the points where the rays intersect the trucks.This is great for iteratively experimentingwith the reflection algorithm.Now, we've covered a lot of ground here,and so far we've been centering most of our discussionin the context of ray tracing.But as I mentioned earlier, we can apply the same principlesto properly shade our pixels in the context of rasterization.Physically based rendering is a great candidate for this.In PBR, our fragment shader needs informationcoming from several textures;for example, albedo, roughness, metallic, and ambient occlusion.In the direct binding model,we need to bind each slot individuallybefore issuing each one of our draw calls.The bindless model vastly simplifies this.Once we have encoded our argument buffers,we can directly bind the scene,navigate to the material corresponding to our draw call,and access all textures indirectly.In fact, since we now just need to bind a single buffer once,this architecture provides an excellent opportunityto optimize our engines furtherby reducing the number of draw callsand use instanced rendering instead.Just remember to make resident all textures we plan to access.Here's an example of a typical PBR shader.In the traditional model, each referenced textureneeds to be individually bound before this draw call.If the following draw callrequires a different set of textures,all these resources need to be bound one by one as well.When using a bindless model,we can now just pass our root argument bufferand retrieve our materialdirectly from its referenced structures, just like before.First we retrieve the instance --this may be determined in the vertex shading stage --then retrieve its material,and use its referenced textures and constant datato calculate the appropriate shading.Finally, we just return the color.All right!And that was a tour on how to effectively implementbindless rendering in Metal!To recap, we explored the Metal bindless modeland saw how extremely flexible it is,allowing you to represent your scene any way you desire.My recommendation is to design and build structuresthat ease the navigation for your given renderer.This way, navigation becomes very natural,and you can even use the same buffersfor both ray tracing and rasterization.Bindless completely changes the game,giving your GPU all the data you needto implement modern rendering techniques.You can even take it further and use this architectureto put the GPU in the driver seatand adopt indirect pipelines through indirect command buffersand GPU culling.We can't wait to see how you put this in practiceto deliver the next generationof graphical applications and games.Thank you and enjoy the rest of WWDC 2021!♪

♪ Bass music playing ♪♪Alejandro Segovia Azapian: Welcome to WWDC!My name is Ale Segovia Azapian,and I'm a GPU software engineer at Apple.

In this session,we're going to explore bindless rendering in Metal.

Bindless is a modern resource binding modelthat allows making groups of resourcesavailable to the GPUto implement modern rendering techniques.

First, we'll take a look at the needfor the concept behind bindless.

Then, we will introduce the bindless modeland show how it provides the flexibility neededto solve the challenges of the traditional binding model.

We will recap the mechanisms to encodeand make your scene resources available to Metalwith argument buffersand how to navigate your GPU structures from shaders.

Let's get started!So bindless rendering allows making all our scene resourcesavailable to our shaders,bringing incredible flexibility to our graphics techniques.

Let's take a look at an example.

Let's imagine we have a ray tracing kernelfinding intersections against an acceleration structure.

For some light effects, such as ray-traced shadows,the algorithm is very natural.

We want to find any objectsbetween the intersection point and the light.

All we need to trace the shadow ray is a positionand the direction toward the light.

No object attributes or Metal resources are neededbeyond the world-space position of the intersection,which we can derive from the rayand the intersection's parameter.

For other effects however, such as reflections,the situation gets more complicated.

Let's take a look at a ray tracing reflection shaderin Metal Shading Language.

In this new example,we've just found an intersection,and we're trying to paint the pixelwith the correct reflected color.

If we just paint a solid color after we find an intersection,the reflection on the ground will not look accurate.

To produce correct results, we need to determinethe attributes of each reflected point foundand calculate the correct shading for its pixel.

This problem is also present for other ray-traced effectssuch as diffuse global illuminationand even ambient occlusion in some cases.

The challenge is that when we ray trace,our rays may hit any object in the acceleration structure.

This means that from our ray tracing shader,we potentially need access to any Metal resourcesin our scene, including vertex data --associated with the mesh intersected --and its material.

It is just not possible to bind this amount of resourcesdirectly to our pipeline.

This is where the bindless binding model comes in.

The idea behind bindless is to aggregate our resourcesand link them together.

This allows us to bind a single buffer to the pipelineand make all referenced resources availablevia navigation.

In Metal, the construct that allows us to do thisis argument buffers.

In particular, for bindless,argument buffers Tier 2 are required.

These are available on the Apple6 and Mac2 GPU families.

Argument buffers can be used from all shader types in Metal.

This means that you can use them for both ray tracingand rasterization.

As we saw, for certain ray tracing effects,using bindless is mandatoryin order to obtain good visual results.

For rasterization, the use is optionalbut provides advantages over the direct binding model.

In particular, it virtually removes the slot limitsfor the number of resources that can be boundfor any given draw call,and it also provides some nice optimization opportunitiesthat we'll explore later in this session.

We introduced argument buffers with Metal 2 as a mechanismto allow you to bind constant data and resourcesall at once in a single call to the Metal API.

Argument buffers are very flexibleand can even reference other buffers.

The idea behind the bindless modelis to leverage this capabilityto link all of our scene resources together.

This will allow making them available to the GPUat the same time.

Let's look at an example of a wayto link our scene resources with argument buffers.

Let's say we want to render a model such as this fire truck.

The model is comprised of textures,vertex data, and index data.

These are the typical resources you would bind one by onefor every draw call in the traditional binding model.

In our case, however --because we want to make all textures, vertex data,and indices of the scene available at once --we need to aggregate these.

Here's a potential way to do so.

We can first create a meshes argument bufferto contain all our meshes or submeshes,depending on how our assets are organized.

This argument buffer will allow referencingthe vertex and index arrays in our scene.

Similarly, we can do the same and encode our materialsto an argument buffer.

Each material can reference its texturesas well as contain inline constant data.

OK, but now that we have all our meshes and materialsavailable to the GPU, how can we bring them together?Well, we can, for example, create an instance objectand also place it in an argument buffer.

An instance can reference one meshand an associated material.

This is also a great placeto store a model transformation matrixas inline constant data.

But we don't have to stop there.

Now that we can store one instance,we can take this furtherand encode all of our instances as an arrayinto this argument buffer.

Let's simplify this diagramand add a few more truck instances,each one with its own material.

As we can see, with this,we can now have our full scene and its resourcesencoded and linked with argument buffers.

Later, when we want to reference any of these resourcesfrom our shaders,we just need a pointer to the instances buffer.

We can pass it directlyand interpret this buffer as an array,or pass a pointer through another scene argument buffer.

Now, it's important to note what happens with the residencyof indirectly accessed resources.

Since we're only passing a pointer to the sceneinto the pipeline,Metal will know about this buffer reference,but not about resources accessed indirectly.

The application is responsible for declaring residencyof all indirectly accessed resources.

Making a resource resident means signaling to the driverto make its memory available to the GPU.

This is necessary so we can reference them from our shaders.

We can do this by calling the useResource:usage: APIfor compute encoders and useResource:usage:stages: APIfor render command encoders.

Accessing a nonresident resource is a common causeof GPU restarts and command buffer failures.

This is because its memory pages may not be presentif we forgot to call this API.

So it's very important to declareevery indirectly accessed resource to Metal.

Now, another option, for convenience,is that resources allocated from MTLHeapscan now be made resident with a single callby means of the useHeap API.

This is a great option if you are already suballocatingor planning to suballocate resources from heaps.

Now, heaps are a fantastic part of the Metal API,and we recommend you use themfor the best resource-creation performance,and memory-saving opportunities.

There are, however, a few considerationsto use them effectively.

The first thing to ask is,Are all our suballocated resources only read from?Examples of where we might need to write into a resourceinclude mesh skinning from a compute shaderand dynamic textures, amongst others.

In these cases, if the GPU needs to write into any resources,they need to be declared resident individuallywith the write usage flag.

Additionally, any resources that may have been modifiedthat we now intend to read fromwill still need their own useResource call.

This is so that the Metal frameworkcan handle resource transitions for you, flushing GPU cachesand adjusting the internal memory layout.

The second consideration is,Does the heap track suballocate resource dependencies?Again, this is especially importantif we're reading and writing into resourcescoming from the same heap.

Metal is great at avoiding synchronization problemsthrough dependency tracking,and since Metal 2.3, heaps can be configuredto track hazards in the access to their resources.

However, since heaps are a single resource to Metal,synchronization is handled at the heap levelnot the suballocation level.

This may subject suballocated resourcesto the problem of false sharing.

Let's take a look.

Let's imagine we have two render passes --A and B --accessing resources from the same heap.

Render pass A is rendering to a render textureallocated from a tracked heap.

Render pass B is reading from an unrelated bufferthat is suballocated from the same heap.

Depending on different conditions,render passes A and B may qualify to be executedin parallel by the GPU;however, due to the potential hazardof writing and reading from the same resource --the heap -- Metal has to serialize accessto ensure there are no race conditions.

This can potentially increase the execution wall-clock timeof our workload by the GPU.

In our case, however,if we know the individual resources are independent,this fence could be avoided.

There are two ways to do this.

One option is to suballocate resources that are updatablefrom heaps separate to the ones used for our static resources.

The other option, if we desire to bundle everything together,is to make sure heaps are configurednot to track their suballocated resources.

This is the default behavior in Metal,and it means we as programmers take on the responsibilityof synchronizing hazards ourselves.

Now, in this diagram I simplified things a bitto illustrate the problem of false sharing.

In practice, overlapping occurs at the shading stage level,not at the render pass level.

As a consequence, Metal allows usto specify our fences at the stage granularity.

This is great because it allows us to still runparts of our pipeline -- such as vertex stageand rasterizer -- concurrently,and only block later in the fragment stageif it happens to depend ona previous pass's fragment stage output.

We recommend you always do this for maximum performance,if possible.

Now, this is a lot to remember,so if you only get one thing from this list,please remember this: read-only data,such as static textures and meshes,are the easiest to handle.

Determine the total allocation sizeand alignment requirements upfrontand place these resources in a heap when the app startsor during a loading section in your game.

This way, you can later make it resident in a single call,with minimal overhead in your critical path.

Now that we know about the bindless binding model,let's take a look at how we can encode our resourcesand put this in practiceand make our complete scene available to the GPUwith argument buffers.

Let's say we want to encode our instances buffer.

Remember, this buffer consists of an array of instances.

As we saw, instances reference a mesh, a material,and contain an inline constant 4x4 matrixdescribing the transformation from local to world space.

Encoding is performed via an argument buffer encoder,and there are two distinct ways to create one in Metal.

You may be familiar with encoding via reflection.

If the argument buffer is passed as a direct parameterto the shader function,we can ask the MTLFunction objectto create an encoder for us.

This mechanism works great,but when we are encoding the entire sceneinto argument buffers, not all encoders can be reflected.

In particular, the MTLFunction signaturedoes not know about the indirectly referenced buffers.

There might also be other situationswhere creating an encoder from a MTLFunctionis not convenient;for example, if your engine architecturehandles argument-buffer creation and resource loadingseparate from pipeline state creation.

Additionally, we cannot reflect an encoderwhen the function is expecting to be passed an array.

So what can we do in these cases?For these cases,Metal provides a convenient second mechanismto create an encoder through a MTLArgumentDescriptor.

MTLArgumentDescriptors allow describing the struct membersto Metal and subsequently creating an encoderwithout a MTLFunction.

We must first create a descriptor for each member,specifying data type and binding index.

Next, we take our descriptors,and pass them directly to the MTLDeviceto create our encoder.

As a result, we obtain our encoder object back.

So let's explore what this looks like in code.

For each member,we needed to create a MTLArgumentDescriptor;we specify the binding index,corresponding to the ID attributefor the member in the struct;we specify the MTLDataType and potentially access;and finally, after we've declared all the members,we can create the encoder directly from the device,passing an array with all our descriptors.

Once we have an encoder,it's straightforward to record our data into a buffer.

We set the argument buffer on the encoder,pointing at the beginning of the buffer.

Then, we simply set the data we want to store.

Encoding an array is simple as well.

All we have to dois offset the encoder's argument buffer recording pointby the encodedLength,which we can conveniently retrieve from the encoder.

For the next instance, we add the encodedLengthto our offset a second time.

In fact, the offset for each position we need to record inis going to be the index times the encodedLength.

This mechanism makes it very easyto encode arrays of structs.

Now, one important point worth mentioningis that no special treatment is needed from shader sideto index into these arrays.

The shader does not need to knowthe length of the bufferand can freely index into any location in the array.

It just works!OK, now that we have encoded our bindless scene,let's take a look at navigation.

For the case of ray tracing, navigation is very natural.

First, we bind the buffer that contains the rootof our bindless scene to our ray tracing pipeline.

This is the argument bufferfrom where we can access all the others.

Next, from our kernel,we proceed with the ray-traced intersection as usual.

After we discovered an intersection,the intersection result object describes the navigation.

We can query this object for instance_id,geometry_id, and primitive_id.

These members are designed specificallyfor navigating our acceleration structures.

It is, therefore, important to build our bindless scenewith a structure that mirrors our acceleration structures,such as the one shown earlier.

Let's take a look at it again.

Remember, this is just an exampleof how to organize the scene,so I'm going to navigate it according to how I organized it.

The particular details for your scene may vary,according to how you decide to organizeyour own argument buffers.

First, we need to find an intersection.

Once we have it,because we strategically organized our bindless scene,given the instance_id we can now follow the pointerto the instances buffer and determine which one we hit.

Next, as we saw, the instance knows its mesh and material.

So we can simply use the geometry_idto determine which geometry we hitwithin the referenced buffer.

Finally, if we prepared each meshto know its index buffer, we can use the primitive_idto determine the exact primitive that we hit.

In the case of a triangle, for instance,we can pull the three indices from this arrayand use them to retrieve its vertex data.

Here's what this navigation looks likein Metal Shading Language.

From the intersection object, we retrieve the instance_idand use it to dynamically index into our instances arrayand retrieve the instance we hit.

Next, having the instance, we use the geometry_idto determine which geometry or submesh was hit.

Once we've determined the geometry,we can directly pull the indices from the index buffer.

In the case of a triangle, we pull three indices,one after the other.

We use these indices to access into the vertex data arrayand retrieve any attribute we need for our technique.

For example, we can retrieve the normalscorresponding to each vertex.

And finally, using the point's barycentric coordinates,we manually interpolate vertex normalsto arrive at the correct normal at the intersection point.

With these changes in place,taking it back to our teapot example,now that we have a way to calculate the normalat the intersection point,we can correctly shade our reflection.

We've updated the code to find the correct attributesat the intersection point,and now the results are visually correct.

We can now continue building on this frameworkto calculate any other attribute we want,such as texture coordinates to apply a textureor tangent vectors to implement normal mapping.

So here we saw how to navigate our bindless sceneto retrieve vertex data, manually interpolate it,and finally, apply it to correctly shadeall the intersection points discovered.

To help you bring these concepts into your own engine,we're going to be releasing a companion code samplethat shows a concrete implementation of all of this.

This is a hybrid rendering samplethat calculates ray-traced reflections for a sceneloaded using the Model I/O framework.

The sample shows how you can encode a bindless scenethat matches the ray tracing acceleration structures,and it also shows how to find intersectionsand correctly shade their associated pixelsdirectly from your ray tracing shaders.

As we can see here,the sample also allows directly visualizingthe output of the reflection ray tracing shaderjust at the points where the rays intersect the trucks.

This is great for iteratively experimentingwith the reflection algorithm.

Now, we've covered a lot of ground here,and so far we've been centering most of our discussionin the context of ray tracing.

But as I mentioned earlier, we can apply the same principlesto properly shade our pixels in the context of rasterization.

Physically based rendering is a great candidate for this.

In PBR, our fragment shader needs informationcoming from several textures;for example, albedo, roughness, metallic, and ambient occlusion.

In the direct binding model,we need to bind each slot individuallybefore issuing each one of our draw calls.

The bindless model vastly simplifies this.

Once we have encoded our argument buffers,we can directly bind the scene,navigate to the material corresponding to our draw call,and access all textures indirectly.

In fact, since we now just need to bind a single buffer once,this architecture provides an excellent opportunityto optimize our engines furtherby reducing the number of draw callsand use instanced rendering instead.

Just remember to make resident all textures we plan to access.

Here's an example of a typical PBR shader.

In the traditional model, each referenced textureneeds to be individually bound before this draw call.

If the following draw callrequires a different set of textures,all these resources need to be bound one by one as well.

When using a bindless model,we can now just pass our root argument bufferand retrieve our materialdirectly from its referenced structures, just like before.

First we retrieve the instance --this may be determined in the vertex shading stage --then retrieve its material,and use its referenced textures and constant datato calculate the appropriate shading.

Finally, we just return the color.

All right!And that was a tour on how to effectively implementbindless rendering in Metal!To recap, we explored the Metal bindless modeland saw how extremely flexible it is,allowing you to represent your scene any way you desire.

My recommendation is to design and build structuresthat ease the navigation for your given renderer.

This way, navigation becomes very natural,and you can even use the same buffersfor both ray tracing and rasterization.

Bindless completely changes the game,giving your GPU all the data you needto implement modern rendering techniques.

You can even take it further and use this architectureto put the GPU in the driver seatand adopt indirect pipelines through indirect command buffersand GPU culling.

We can't wait to see how you put this in practiceto deliver the next generationof graphical applications and games.

Thank you and enjoy the rest of WWDC 2021!♪

0:07 -Simple Intersection Kernel 2

0:08 -PBR fragment shading requires several textures

0:09 -Bindless makes all textures available via AB navigation

1:48 -Simple Intersection Kernel 1

11:33 -Encoder creation

11:50 -Encoder via reflection

13:08 -Argument Buffers referenced indirectly

16:10 -Navigation 1

16:43 -Navigation 2

17:15 -Simple Intersection Kernel

19:30 -PBR fragment shading requires several textures

19:48 -Bindless makes all textures available via AB navigation

## Code Samples

```swift
if
(i.type == intersection_type::triangle)
{
  constant Instance& inst     = get_instance(i);
  constant Mesh&     mesh     = get_mesh(inst, i);
  constant Material& material = get_material(inst, i);
  
  color = shade_pixel(mesh, material, i);
}   

outImage.write(color, tid);
```

```swift
fragment half4 pbrFragment(ColorInOut 
in
 [[stage_in]],
                           texture2d< 
float
 > albedo    [[texture(
0
)]],
                           texture2d< 
float
 > roughness [[texture(
1
)]],
                           texture2d< 
float
 > metallic  [[texture(
2
)]],
                           texture2d< 
float
 > occlusion [[texture(
3
)]])
{	
	half4 color = calculateShading(
in
, albedo, roughness, metallic, occlusion);
	
return
 color;
}
```

```swift
fragment half4 pbrFragmentBindless(ColorInOut 
in
 [[stage_in]], 
                                   device 
const
 Scene* pScene [[buffer(
0
)]])
{
	device 
const
 Instance& instance = pScene->instances[
in
.instance_id];
	device 
const
 Material& material = pScene->materials[instance.material_id];
	
	half4 color = calculateShading(
in
, material);
	
	
return
 color;
}
```

```swift
if
 (intersection.type == intersection_type::triangle) 
{
  
// solid blue triangle

  color = float4(
0.0
f, 
0.0
f, 
1.0
f, 
1.0
f);
}   

outImage.write(color, tid);
```

```swift
struct
 Instance
{
    constant Mesh*     pMesh            [[
id
(
0
)]];
    constant Material* pMaterial        [[
id
(
1
)]];
    constant float4x4  modelTransform   [[
id
(
2
)]];
};
```

```swift
// Shader code references scene

kernel 
void
 RTReflections( constant Scene* pScene [[buffer(
0
)]] );
```

```swift
MTLArgumentDescriptor
* meshArg 
= [
MTLArgumentDescriptor
 argumentDescriptor];

meshArg.index    = 
0
;
meshArg.dataType = 
MTLDataTypePointer
;
meshArg.access   = 
MTLArgumentAccessReadOnly
;


// Declare all other arguments (material and transform)

   

id
<
MTLArgumentEncoder
> instanceEncoder 
= [device newArgumentEncoderWithArguments:@[meshArg, 
                                            materialArg, 
                                            transformArg]];
```

```swift
// Instance and Mesh


constant Instance& instance = pScene->instances[intersection.instance_id];
constant Mesh&     mesh     = instance.mesh[intersection.geometry_id];


// Primitive indices


ushort3 indices; 
// assuming 16-bit indices, use uint3 for 32-bit


indices.x = mesh.indices[ intersection.primitive_id * 
3
 + 
0
 ];
indices.y = mesh.indices[ intersection.primitive_id * 
3
 + 
1
 ];
indices.z = mesh.indices[ intersection.primitive_id * 
3
 + 
2
 ];
```

```swift
// Vertex data


packed_float3 n0 = mesh.normals[ indices.x ];
packed_float3 n1 = mesh.normals[ indices.y ];
packed_float3 n2 = mesh.normals[ indices.z ];


// Interpolate attributes


float3 barycentrics = calculateBarycentrics(intersection);
float3 normal       = weightedSum(n0, n1, n2, barycentrics);
```

```swift
fragment half4 pbrFragment(ColorInOut 
in
 [[stage_in]],
                           texture2d< 
float
 > albedo    [[texture(
0
)]],
                           texture2d< 
float
 > roughness [[texture(
1
)]],
                           texture2d< 
float
 > metallic  [[texture(
2
)]],
                           texture2d< 
float
 > occlusion [[texture(
3
)]])
{	
	half4 color = calculateShading(
in
, albedo, roughness, metallic, occlusion);
	
  
return
 color;
}
```

