# Wwdc2021 10290

## Transcript

More Videos

Streaming is available in most browsers,and in the Developer app.

About

Transcript

Code

What's new in AVKitLearn about enhancements to Picture in Picture and full screen improvements on macOS. Explore the new content source API, and learn how AVPictureInPictureController supports AVSampleBufferDisplayLayer, as well as recommended steps for an app to provide a seamless full screen experience on macOS or in a Mac Catalyst app.ResourcesAVKitHD VideoSD VideoRelated VideosWWDC21Deliver a great playback experience on tvOSWhat’s new in AVFoundationWWDC19Delivering Intuitive Media Playback with AVKit

Learn about enhancements to Picture in Picture and full screen improvements on macOS. Explore the new content source API, and learn how AVPictureInPictureController supports AVSampleBufferDisplayLayer, as well as recommended steps for an app to provide a seamless full screen experience on macOS or in a Mac Catalyst app.

AVKit

HD VideoSD Video

HD Video

SD Video

Deliver a great playback experience on tvOS

What’s new in AVFoundation

Delivering Intuitive Media Playback with AVKit

Search this video…♪ Bass music playing ♪♪Marty Pye: Welcome to "What’s new in AVKit".My name is Marty Pye and I'm an engineer on the AVKit team.Today, I'd like to talk aboutsome of the enhancements we've madeto Picture in Picture -- or short, PiP --as well as to the full-screen experience on macOS.Let's start with Picture in Picture.With Picture in Picture,users can continue to enjoy their video contentwhile multitasking with their device.For example, if you're watching a video full screenand you receive a message,you can briefly reply to that messagewhile continuing to watch your content.The video will automatically enter PiP,and once you've finished replying,you can quickly resume full-screen playback.This makes for a really seamless viewing experience,and we think users will expect this behaviorwhenever they're watching videos.For more information on how to integrate PiPinto your own apps,I encourage you to watch this 2019 sessionon delivering intuitive media playback with AVKit.New this year, if your video is playing inline,you can optionally allow it to automatically enter PiPwhen a user swipes back to the Home screen.Enabling this behavior is achieved via thecanStartPictureInPicture AutomaticallyFromInlineproperty.This property is available both on AVPlayerViewControllerfor apps using our native controlsand on AVPictureInPictureControllerfor apps implementing their own custom UI.Make sure to only set this flag to truewhen the playing content is intendedto be the user's primary focus.If you're using AVPlayerViewControllerto present video content, PiP is handled for you.There's nothing you need to do.If you're not using AVPlayerViewController,you can still use AVPictureInPictureControllerto bring the native PiP experience to your app.First, you need to configureyour app's audio session category for playbackand enable the PiP background mode.Then, all you need to dois create a pictureInPictureController,passing in a reference to the playerLayer.Then, when a user attempts to toggle Picture in Pictureusing the button you provide,you just need to call start or stop PiPon the controller object.Up until now, our Picture in Picture experiencewas built around AVPlayer-based content.Today, I'm excited to announce the same level of supportfor AVSampleBufferDisplayLayer.Instead of creating the Picture in Picture controllerwith a player layer, you first create a ContentSource,which you set up with either an AVPlayerLayer or --as shown here -- with an AVSampleBufferDisplayLayer.For a user, the Picture in Picture experiencewill be identical.For you as a developer,there are some new responsibilitiesassociated with supporting PiP for AVSampleBufferDisplayLayer.Let's take a look at this playback delegate.We have to rely on playback state informationprovided via the newAVPictureInPictureSample BufferPlaybackDelegatein order to render the PiP UI,since media playback is not managed by an AVPlayer.When the user attempts to control media from the PiP UI,we forward those commands to the delegate to handle.Let's go through the five individual callbacks one by one.The setPlaying function is called when the user pressesthe Play/Pause button in the PiP window.The skipByInterval function is calledwhen the user presses one of the skip buttons.Use these callbacks to control your media accordingly.The timeRangeForPlayback function allows you to specifythe currently playable time range.This allows us to render the timelineand show where the playhead is currently.Time ranges with a finite durationshould always contain the current timeof the sample buffer display layer's timebase.Use a time range with an infinite durationto indicate live content.The didTransitionToRenderSize functionis called when the Picture in Picture windowchanges size, such as during pinch-to-zoom.Take this render size into accountwhen choosing media variantsin order to avoid unnecessary decoding overhead.The isPlaybackPaused function is called periodicallyand informs the Picture in Picture UIwhether to reflect a paused or playing state.This is conceptually the equivalentof timeControlStatus on AVPlayer.Next, let's take a look at some of the improvementswe've made to the full-screen experience on macOS.In Big Sur, when you take a video full screenin a Mac Catalyst app,the video would fill the entire windowbut not the entire screen.Now in macOS Monterey,the video will take up the entire screen.You end up with a true full-screen experiencefor both native macOS and Mac Catalyst apps.The playback controls look the same for both.All Mac Catalyst apps will get this new behavior automatically.Just like in any native macOS full-screen experience,the user can swipe back to the app window.A placeholder will be shown instead of the original video,indicating that the content is playing full screen.This is very similar to the placeholder shownwhen the video is playing in Picture in Picture.In a scenario where you present a player view controllerfull screen after a user selects some content,the view controller will still present in full window.However, new in macOS Monterey,users can detach to a true full-screen playback experienceby pressing the green full screen buttonin the top left of the window.The full screen life cycle can be explicitly managedto provide a better user experiencebased on your application's needs.Let's take a look at an example.As we've already shown, a user should be ableto take a video full screen and then swipe back to your appwhile playback continues.They should be able to navigate your app freely,even if that results in the player view controllerbeing removed from your view hierarchy.At any point in time, they should be able to either swipeor use Mission Control to navigate backto the full-screen video.So let's take a look at how to make that work.You are responsible forthe playerViewController's life cycle.In order to achieve an optimal experience,you need to make sure to keep the playerViewController aliveeven if it's not in your app's view hierarchy.Otherwise, when the user navigates away from the pagewith the video, full-screen playback will endas the playerViewController is released.All you need to do is keep a strong referenceto the playerViewController when you receive thewillBeginFullScreenPresentation callback.Then, once the user exits full screen, you'll receive thewillEndFullScreenPresentation callback.This is your opportunity to let go ofthe playerViewController you were keeping alive,assuming the user has navigated awayfrom the original view it was presented from.The same applies for native macOS.You can use the new playerViewDelegateto keep the playerView alive until you receivethe playerViewWillExitFullScreen callback.When a user exits full screen, you will also receivethis restoreUserInterface callback.This is an opportunity for your appto navigate back to the original page containing the video,assuming that's appropriate for your use case.This is very similar to the existing callback you receivewhen a user stops Picture in Picture.Make sure to return from this completionHandleras quickly as possible so as not to blockthe transition from full screen to inline.Returning false indicates that restoration failedor isn't possible, in which casethe content exits full screen without an animation.With that, I would like to wrap up today's session.We saw how to use the new content source APIto add Picture in Picture support to your appwhen using AVSampleBufferDisplayLayerinstead of AVPlayerLayer.For macOS and Mac Catalyst,we went over the enhanced full screen experience,and outlined the necessary stepsfor your code to integrate seamlessly.I hope you enjoyed today's sessionand I look forward to seeing some of these featuresintegrated into your apps.Enjoy the rest of the conference.♪

♪ Bass music playing ♪♪Marty Pye: Welcome to "What’s new in AVKit".

My name is Marty Pye and I'm an engineer on the AVKit team.

Today, I'd like to talk aboutsome of the enhancements we've madeto Picture in Picture -- or short, PiP --as well as to the full-screen experience on macOS.

Let's start with Picture in Picture.

With Picture in Picture,users can continue to enjoy their video contentwhile multitasking with their device.

For example, if you're watching a video full screenand you receive a message,you can briefly reply to that messagewhile continuing to watch your content.

The video will automatically enter PiP,and once you've finished replying,you can quickly resume full-screen playback.

This makes for a really seamless viewing experience,and we think users will expect this behaviorwhenever they're watching videos.

For more information on how to integrate PiPinto your own apps,I encourage you to watch this 2019 sessionon delivering intuitive media playback with AVKit.

New this year, if your video is playing inline,you can optionally allow it to automatically enter PiPwhen a user swipes back to the Home screen.

Enabling this behavior is achieved via thecanStartPictureInPicture AutomaticallyFromInlineproperty.

This property is available both on AVPlayerViewControllerfor apps using our native controlsand on AVPictureInPictureControllerfor apps implementing their own custom UI.

Make sure to only set this flag to truewhen the playing content is intendedto be the user's primary focus.

If you're using AVPlayerViewControllerto present video content, PiP is handled for you.

There's nothing you need to do.

If you're not using AVPlayerViewController,you can still use AVPictureInPictureControllerto bring the native PiP experience to your app.

First, you need to configureyour app's audio session category for playbackand enable the PiP background mode.

Then, all you need to dois create a pictureInPictureController,passing in a reference to the playerLayer.

Then, when a user attempts to toggle Picture in Pictureusing the button you provide,you just need to call start or stop PiPon the controller object.

Up until now, our Picture in Picture experiencewas built around AVPlayer-based content.

Today, I'm excited to announce the same level of supportfor AVSampleBufferDisplayLayer.

Instead of creating the Picture in Picture controllerwith a player layer, you first create a ContentSource,which you set up with either an AVPlayerLayer or --as shown here -- with an AVSampleBufferDisplayLayer.

For a user, the Picture in Picture experiencewill be identical.

For you as a developer,there are some new responsibilitiesassociated with supporting PiP for AVSampleBufferDisplayLayer.

Let's take a look at this playback delegate.

We have to rely on playback state informationprovided via the newAVPictureInPictureSample BufferPlaybackDelegatein order to render the PiP UI,since media playback is not managed by an AVPlayer.

When the user attempts to control media from the PiP UI,we forward those commands to the delegate to handle.

Let's go through the five individual callbacks one by one.

The setPlaying function is called when the user pressesthe Play/Pause button in the PiP window.

The skipByInterval function is calledwhen the user presses one of the skip buttons.

Use these callbacks to control your media accordingly.

The timeRangeForPlayback function allows you to specifythe currently playable time range.

This allows us to render the timelineand show where the playhead is currently.

Time ranges with a finite durationshould always contain the current timeof the sample buffer display layer's timebase.

Use a time range with an infinite durationto indicate live content.

The didTransitionToRenderSize functionis called when the Picture in Picture windowchanges size, such as during pinch-to-zoom.

Take this render size into accountwhen choosing media variantsin order to avoid unnecessary decoding overhead.

The isPlaybackPaused function is called periodicallyand informs the Picture in Picture UIwhether to reflect a paused or playing state.

This is conceptually the equivalentof timeControlStatus on AVPlayer.

Next, let's take a look at some of the improvementswe've made to the full-screen experience on macOS.

In Big Sur, when you take a video full screenin a Mac Catalyst app,the video would fill the entire windowbut not the entire screen.

Now in macOS Monterey,the video will take up the entire screen.

You end up with a true full-screen experiencefor both native macOS and Mac Catalyst apps.

The playback controls look the same for both.

All Mac Catalyst apps will get this new behavior automatically.

Just like in any native macOS full-screen experience,the user can swipe back to the app window.

A placeholder will be shown instead of the original video,indicating that the content is playing full screen.

This is very similar to the placeholder shownwhen the video is playing in Picture in Picture.

In a scenario where you present a player view controllerfull screen after a user selects some content,the view controller will still present in full window.

However, new in macOS Monterey,users can detach to a true full-screen playback experienceby pressing the green full screen buttonin the top left of the window.

The full screen life cycle can be explicitly managedto provide a better user experiencebased on your application's needs.

Let's take a look at an example.

As we've already shown, a user should be ableto take a video full screen and then swipe back to your appwhile playback continues.

They should be able to navigate your app freely,even if that results in the player view controllerbeing removed from your view hierarchy.

At any point in time, they should be able to either swipeor use Mission Control to navigate backto the full-screen video.

So let's take a look at how to make that work.

You are responsible forthe playerViewController's life cycle.

In order to achieve an optimal experience,you need to make sure to keep the playerViewController aliveeven if it's not in your app's view hierarchy.

Otherwise, when the user navigates away from the pagewith the video, full-screen playback will endas the playerViewController is released.

All you need to do is keep a strong referenceto the playerViewController when you receive thewillBeginFullScreenPresentation callback.

Then, once the user exits full screen, you'll receive thewillEndFullScreenPresentation callback.

This is your opportunity to let go ofthe playerViewController you were keeping alive,assuming the user has navigated awayfrom the original view it was presented from.

The same applies for native macOS.

You can use the new playerViewDelegateto keep the playerView alive until you receivethe playerViewWillExitFullScreen callback.

When a user exits full screen, you will also receivethis restoreUserInterface callback.

This is an opportunity for your appto navigate back to the original page containing the video,assuming that's appropriate for your use case.

This is very similar to the existing callback you receivewhen a user stops Picture in Picture.

Make sure to return from this completionHandleras quickly as possible so as not to blockthe transition from full screen to inline.

Returning false indicates that restoration failedor isn't possible, in which casethe content exits full screen without an animation.

With that, I would like to wrap up today's session.

We saw how to use the new content source APIto add Picture in Picture support to your appwhen using AVSampleBufferDisplayLayerinstead of AVPlayerLayer.

For macOS and Mac Catalyst,we went over the enhanced full screen experience,and outlined the necessary stepsfor your code to integrate seamlessly.

I hope you enjoyed today's sessionand I look forward to seeing some of these featuresintegrated into your apps.

Enjoy the rest of the conference.

♪

1:16 -New canStartPictureInPictureAutomaticallyFromInline property

1:40 -Setting up AVPictureInPictureController with an AVPlayerLayer

2:11 -Starting and stopping picture in picture

2:56 -AVPictureInPictureSampleBufferPlaybackDelegate

3:17 -Toggle playback of the video and seek back / ahead 15 seconds

3:31 -Provide elapsed time information

3:51 -Choose appropriate media variant for render size

4:06 -Update playback state

6:05 -iOS / MacCatalyst - Persist full screen playback

6:38 -iOS / MacCatalyst - Release the playerViewController

6:46 -Persist full screen playback on macOS

6:55 -Restoring UI when exiting full screen

## Code Samples

```swift
// New property on AVPlayerViewController / AVPictureInPictureController.


var
 canStartPictureInPictureAutomaticallyFromInline: 
Bool
 { 
get
 
set
 }
```

```swift
func
 
setupPictureInPicture
()
 {
    
// Ensure PiP is supported by current device.

    
if
 
AVPictureInPictureController
.isPictureInPictureSupported() {
        
// Create a new controller, passing the reference to the AVPlayerLayer.

        pictureInPictureController 
=
 
AVPictureInPictureController
(playerLayer: playerLayer)
        pictureInPictureController.delegate 
=
 
self

        
        
// Observe AVPictureInPictureController.isPictureInPicturePossible to update the PiP

        
// button’s enabled state.

    } 
else
 {
        
// PiP isn't supported by the current device. Disable the PiP button.

        pictureInPictureButton.isEnabled 
=
 
false

    }
}
```

```swift
@IBAction
 
func
 
togglePictureInPictureMode
(
_
 
sender
: 
UIButton
)
 {
    
if
 pictureInPictureController.isPictureInPictureActive {
        pictureInPictureController.stopPictureInPicture()
    } 
else
 {
        pictureInPictureController.startPictureInPicture()
    }
}
```

```swift
public
 
protocol
 
AVPictureInPictureSampleBufferPlaybackDelegate
: 
NSObjectProtocol
{

    
// Delegate is responsible for:

    
//

    
// - Supplying playback state information for PiP UI.

    
// - Responding to user input from PiP UI.


}
```

```swift
func
 
pictureInPictureController
(
_
 
pictureInPictureController
: 
AVPictureInPictureController
, 
setPlaying
 
playing
: 
Bool
)


func
 
pictureInPictureController
(
_
 
pictureInPictureController
: 
AVPictureInPictureController
, 
skipByInterval
 
skipInterval
: 
CMTime
, 
completion
 
completionHandler
: 
@escaping
 () 
-›
 
Void
)
```

```swift
func
 
pictureInPictureControllerTimeRangeForPlayback
(
_
 
pictureInPictureController
: 
AVPictureInPictureController
) -> 
CMTimeRange
```

```swift
func
 
pictureInPictureController
(
_
 
pictureInPictureController
: 
AVPictureInPictureController
, 
didTransitionToRenderSize
 
newRenderSize
: 
CMVideoDimensions
)
```

```swift
func
 
pictureInPictureControllerIsPlaybackPaused
(
pictureInPictureController
: 
AVPictureInPictureController
) -> 
Bool
```

```swift
func
 
playerViewController
(
_
 
playerViewController
: 
AVPlayerViewController
, 
willBeginFullScreenPresentationWithAnimationCoordinator
 
coordinator
: 
UIViewControllerTransitionCoordinator
) {
    coordinator.animate(alongsideTransition: 
nil
) { context 
in

        
// Keep a strong reference to the playerViewController while in full screen.

        
self
.detachedPlayerViewController 
=
 playerViewController
    }
}
```

```swift
func
 
playerViewController
(
_
 
playerViewController
: 
AVPlayerViewController
, 
willEndFullScreenPresentationWithAnimationCoordinator
 
coordinator
: 
UIViewControllerTransitionCoordinator
){
    coordinator.animate(alongsideTransition: 
nil
) { context 
in

        
// Stop keeping the playerViewController alive when transition completes,

        
self
.detachedPlayerViewController 
=
 
nil

    }
}
```

```swift
func
 
playerViewWillEnterFullScreen
(
_
 
playerView
: 
AVPlayerView
) {
    
// Start keeping the player view alive while it is not in the view hierarchy.

    
self
.detachedPlayerView 
=
 playerView
}


func
 
playerViewWillExitFullScreen
(
_
 
playerView
: 
AVPlayerView
) {
    
// Stop keeping the player view alive.

    
self
.detachedPlayerView 
=
 
nil

}
```

```swift
// Restoring UI when exiting full screen



// iOS / MacCatalyst


func
 
playerViewControllerRestoreUserInterfaceForFullScreenExit
(
_
 
playerViewController
: 
AVPlayerViewController
)
 
async
 -> 
Bool
 {
	
// Custom UI restoration logic

	
return
 
true

}


// macOS


func
 
playerViewRestoreUserInterfaceForFullScreenExit
(
_
 
playerView
: 
AVPlayerView
)
 
async
 -> 
Bool
 {
	
// custom UI restore logic here		

	
return
 
true

}
```

