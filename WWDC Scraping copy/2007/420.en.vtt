WEBVTT

00:00:17.420 --> 00:00:23.030
>>Good morning; this is the Tune Your OpenGL
Application session; my name is Kent Miller.

00:00:23.030 --> 00:00:32.189
I am the Manager of the Desktop OpenGL Software team
at Apple and I'm joined here with Dave and our idea

00:00:32.189 --> 00:00:37.019
for this session, we're going to loop back probably
over some of the topics that have been covered in some

00:00:37.020 --> 00:00:45.640
of the other OpenGL sessions but our take on this session
is to show you how we work so a lot of what we do is trying

00:00:45.640 --> 00:00:49.070
to help people get the best performance
out of their applications or you know,

00:00:49.070 --> 00:00:54.689
they'll come it with specific application performance
problem and we try to help them diagnose it and we're going

00:00:54.689 --> 00:01:03.329
to show you the tools that we develop and use; Shark
and Profiler are the two main ones we turn to first

00:01:03.329 --> 00:01:09.519
and we also have Driver Monitor and Shader Builder to
help us do some other specific things to the applications;

00:01:09.519 --> 00:01:16.709
so I'm going to introduce Dave Springer,
awesome graphics dude and he's going

00:01:16.709 --> 00:01:20.780
to take us over a little tour of Profiler.

00:01:20.780 --> 00:01:22.480
>>Thanks Kent.

00:01:22.480 --> 00:01:29.730
As Kent said these are tools that we've developed
that we use every day and they are shipped,

00:01:29.730 --> 00:01:37.740
you have them on your DVD; so I'm going to
just give you a quick tour of OpenGL Profiler.

00:01:37.739 --> 00:01:46.259
Profiler is an app that is made for debugging
and for profiling specifically GL app;

00:01:46.260 --> 00:01:52.290
so it hooks directly to the GL library
entry points really by themselves.

00:01:52.290 --> 00:02:01.990
I'm going to start with launching and app here,
cylinder, and what we're going to do here is take a look

00:02:01.989 --> 00:02:06.310
at some of the things that we can see
in the app using Profiler.

00:02:06.310 --> 00:02:13.710
So the first thing I'm going to do is set a
breakpoint by going to the breakpoints window

00:02:13.710 --> 00:02:21.879
and I'll set a breakpoint here on CGLFlushDrawable
and this is the kind of a knot hole function

00:02:21.879 --> 00:02:27.659
that if you're a Cocoa programmer you're used
to calling it NSOpenGLViews flush buffer

00:02:27.659 --> 00:02:31.689
or if you're a Carbon programmer it's AGL swap buffers;

00:02:31.689 --> 00:02:36.859
so both of those calls routines
come down into CGLFlushDrawable.

00:02:36.860 --> 00:02:44.630
This is actually the frame end marker, really, of your
OpenGL app so generally speaking what we do is we

00:02:44.629 --> 00:02:51.090
like to capture a single frame of information and
see what's going on in the app and this is

00:02:51.090 --> 00:02:58.319
where we usually break, that's why it's actually
set out in bold because make it easier to find.

00:02:58.319 --> 00:03:08.739
Okay, so here I can see that I've got a call stack of
where I am stopping and some simple stuff like that;

00:03:08.740 --> 00:03:16.480
then what I can also do is like I said I can capture a
frame and the way I'm going to do that right now is get

00:03:17.659 --> 00:03:30.409
up the trace view here and what I can do is go back
and continue; now what I've done is I've run one frame

00:03:30.409 --> 00:03:38.180
of the app and when I go back and look in the trace
view here what it's giving me is all the OpenGL calls

00:03:38.180 --> 00:03:43.629
that are made in that one frame and I
can just browse through that like this.

00:03:43.629 --> 00:03:52.810
You can see it makes about 3,000 calls to do that one frame
which sounds kind of like a lot just to make a few quads

00:03:52.810 --> 00:03:57.650
and some textures; so right away I've already gathered
some information about this app that tells me,

00:03:57.650 --> 00:04:04.280
"You know what, maybe just in looking at the
kind of graphic that I've got here on the screen

00:04:04.280 --> 00:04:11.419
that there's possibly some ways that I can optimize this
already to reduce my function call overhead or something

00:04:11.419 --> 00:04:16.219
like that" and that's just with, you know,
if you, operations within OpenGL Profiler.

00:04:16.220 --> 00:04:16.840
( Pause )

00:04:16.839 --> 00:04:23.159
Other things I can do in Profiler too
is I can look at the state changes.

00:04:23.160 --> 00:04:28.890
Now state changes, Kent is going over this a little
later on to talk a little more about state changes.

00:04:28.889 --> 00:04:33.000
Generally speaking you want to keep
your state changes at a minimum.

00:04:33.000 --> 00:04:44.629
There usually fairly expensive so what I can do here
again is I'll continue on another frame, and take a look

00:04:44.629 --> 00:04:58.529
at the state; so again I'm stopped at a breakpoint, at the
frame end breakpoint and this pane over here on the, well,

00:04:58.529 --> 00:05:04.399
I guess it's my left and your right, is
all the GL state that's in the engine.

00:05:04.399 --> 00:05:13.819
So every single GL get call you can possibly make is
listed in here and there's two ways you can look at this.

00:05:13.819 --> 00:05:20.139
When Profiler starts your application the first thing it
does is it goes and grabs all the default state that's there

00:05:20.139 --> 00:05:25.709
so as you run it's doing differences
from that state to where you're at;

00:05:25.709 --> 00:05:30.579
so this is going to tell you all the state you've
changed since the genesis of OpenGL in your app

00:05:30.579 --> 00:05:36.449
and it shows those in blue over here so you can
see that, for example, I've changed transfers.

00:05:36.449 --> 00:05:38.639
I mean there's quite a few things that have been changed.

00:05:38.639 --> 00:05:44.800
I've changed the transforms, the view port
of course is changed; you have to do that;

00:05:44.800 --> 00:05:51.520
projection matrix things like that, the model view matrix.

00:05:51.519 --> 00:05:59.659
Another thing that we can do with state is look at the
difference from my last breakpoint to another breakpoint.

00:05:59.660 --> 00:06:07.780
So I want to see, for example, how much state I'm changing
between when I end a frame and when I call my first GL begin

00:06:07.779 --> 00:06:15.229
because that's interesting to me; I want to know how
much and do I really have to make all these state changes

00:06:15.230 --> 00:06:20.379
so I'm going to find out how much state I really am
changing and the way I'm going to do that is by scrolling

00:06:20.379 --> 00:06:25.430
down in this list and you can see in this list
here by the way it has every single GL entry point;

00:06:25.430 --> 00:06:28.509
there's about 900 of them; there's quite a few.

00:06:28.509 --> 00:06:34.000
They're alphabetized so it's at least a little easier
to find them but, whoops I don't want to break there,

00:06:34.000 --> 00:06:43.720
I want to break on GL begin and then what
I'm going to do is hit continue and...

00:06:43.720 --> 00:06:44.770
( Pause )

00:06:44.769 --> 00:06:55.240
when I hit continue it says, "Oh, since the
start of the frame or the end of the last frame

00:06:55.240 --> 00:06:58.600
in GL begin I've changed some pieces of state.

00:06:58.600 --> 00:07:07.750
Here I've changed GL texture 0 and I've changed
the width and height of some textures and some things

00:07:07.750 --> 00:07:16.970
like that, and then I can combine the two and see that
where there's blue that's state I've changed from default;

00:07:16.970 --> 00:07:21.910
where there's red only it's state since last breakpoint and
where they're purple that's where both of them have changed;

00:07:21.910 --> 00:07:25.400
right because purple is the (inaudible)
red and blue; everybody knows that.

00:07:26.540 --> 00:07:34.150
Okay, what you want to do in here is try and get
everything to be blue because idea being that you change,

00:07:34.149 --> 00:07:44.599
you set up all your state once from default and then you run
your frames and keep your per frame state changes to a minimum.

00:07:44.600 --> 00:07:49.510
Okay another thing I can do with Profiler is gather stats,

00:07:49.509 --> 00:07:59.069
let me get rid of all these breakpoints here first...I
had GL begin and then I'm just going to double check,

00:07:59.069 --> 00:08:05.389
there's a...break after none and a break
before none so I've cleared all the breakpoints.

00:08:05.389 --> 00:08:11.259
I can also run if I want to I can ignore all breakpoints
which is handy if you have a bunch of breakpoints set

00:08:11.259 --> 00:08:13.360
and you just want to run a few loops of your app

00:08:13.360 --> 00:08:16.460
and then turn the breakpoints back
on you can do that with that checkbox.

00:08:16.459 --> 00:08:28.899
Now what I'm going to do here with this app,
whoops I should have of course got it running again, right.

00:08:28.899 --> 00:08:38.159
I'm going to go to the statistics window now
and watch what's happening with my GL calls;

00:08:38.159 --> 00:08:43.919
so here I'm sorting on the number of calls
being made and you can see there's quite a few;

00:08:43.919 --> 00:08:46.610
there's 2 million to GL vertex, 3F and color forward.

00:08:46.610 --> 00:08:52.560
I also noticed that GL began an ender being
called; again I set a breakpoint on it stop there

00:08:52.559 --> 00:08:57.039
so obviously it's being called and that means
this app is running in immediate mode;

00:08:57.039 --> 00:09:05.909
so another thing...a little orange flag there, take a
look at that; generally speaking immediate mode is great

00:09:05.909 --> 00:09:12.949
for certain, for getting started for prototyping and
actually good for certain apps but not all.

00:09:12.950 --> 00:09:19.070
In here you have things like percent of GL time which
means the amount of time that you're actually spending

00:09:19.070 --> 00:09:30.190
in the engine; so this CGLFlushDrawable relative to all
the rest of GL only is spending 88% of your engine time.

00:09:30.190 --> 00:09:36.360
Percent app time is the amount that this
GL call spends relative to the whole app

00:09:36.360 --> 00:09:40.440
so about half you time is spent in CGLFlushDrawable
in this particular application;

00:09:40.440 --> 00:09:46.200
then there's other stats you can gather down here; the
amount of time spent in GL of course if you add this

00:09:46.200 --> 00:09:51.950
and the app time together they should be
equal to about 100 which they do.

00:09:51.950 --> 00:09:57.340
Okay one last thing to take a look at here
quickly, I'm going to set another breakpoint.

00:09:57.340 --> 00:10:00.830
You see that breakpoints are pretty,
pretty important; you use them all the time.

00:10:00.830 --> 00:10:06.360
I'm going to stop again at the frame end and
what I want to do is take a look at some buffers;

00:10:06.360 --> 00:10:13.070
I actually use this feature myself just
last night to debug some threading issues.

00:10:13.070 --> 00:10:23.090
You can look at the back buffer and one of the
things that happens often is we get...developers

00:10:23.090 --> 00:10:30.710
that have the wrong pixel format and they think they have
double buffered but don't so there is no back buffer;

00:10:30.710 --> 00:10:32.690
well that'll cause flickering and all kinds of other issues.

00:10:32.690 --> 00:10:37.400
Well here you can say, "Well what is my
back buffer and is there a back buffer?"

00:10:37.399 --> 00:10:41.689
So this is a buffer that's about to be flushed forward.

00:10:41.690 --> 00:10:46.340
Another view that we can look at that's
actually really useful is the depth buffer

00:10:46.340 --> 00:10:52.190
and okay this looks not very interesting; in
fact it doesn't look like much of anything,

00:10:52.190 --> 00:10:54.950
right but notice this orange bar up here.

00:10:54.950 --> 00:11:01.080
This is actually the Z values, scaled Z values
that are in the Z buffer right now for this image

00:11:01.080 --> 00:11:06.009
and if you have an application that's doing a
lot of Z fighting which means that you have polygons

00:11:06.009 --> 00:11:11.189
that get close together and they start flickering on
top of each other; I'm sure you've all run into that.

00:11:11.190 --> 00:11:18.610
What's happening it that your precision in your Z buffer
is starting to get to low so the compares are not working.

00:11:18.610 --> 00:11:26.169
Well there is a way to fix that; if you click on this
magnifying glass what it's going to show you is a kind

00:11:26.169 --> 00:11:33.969
of Z min, Z max bound on Z buffer and so Profiler has
gone in here and picked on and says, "You know what,

00:11:33.970 --> 00:11:39.670
you're really just using this little
tiny squashed up area of the Z buffer;

00:11:39.669 --> 00:11:45.509
so to fix your Z fighting problems what you
can do is go back to your GL (inaudible) call

00:11:45.509 --> 00:11:49.990
or your GLU perspective call and change the
Z near and Z far clipping planes;

00:11:49.990 --> 00:11:58.029
the farther you...the closer you put those to your model
the closer together you can get those the better Z position

00:11:58.029 --> 00:12:00.129
you're going to end up having.

00:12:00.129 --> 00:12:06.610
So that's how you would use that tool and the idea of
course is to get this orange bar automatically to be

00:12:06.610 --> 00:12:13.000
as close together as you can by using that magnifying glass.

00:12:13.000 --> 00:12:22.389
Okay, so to sum up this, you want to use this tool to get in
and take a look at your app, don't guess at things.

00:12:22.389 --> 00:12:25.500
We get a lot of folks saying, "My
app does this or that because,

00:12:25.500 --> 00:12:28.289
you know, your graphics do so on and so forth."

00:12:28.289 --> 00:12:33.549
Well that's not always the case; so you definitely want to
get in there, take a look at what your graphics are doing

00:12:33.549 --> 00:12:36.889
with the library, make sure that
you're using the library correctly.

00:12:36.889 --> 00:12:43.559
You can use break on GL error, you can use break on
thread conflict and all kinds of other things in Profiler,

00:12:43.559 --> 00:12:49.579
all the stuff we're going to look at later and
really understand what your usage of the library is,

00:12:49.580 --> 00:12:57.370
of the GL engine, of the GL library before you make
decisions; it's just like using a good debugger

00:12:57.370 --> 00:13:04.889
and then you have a lot more information; so don't guess,
measure first and then make your app perform.

00:13:04.889 --> 00:13:13.699
With that we'll turn it back to Kent.

00:13:13.700 --> 00:13:13.980
( Pause and applause )

00:13:13.980 --> 00:13:18.590
>> Could we go back the slides please?

00:13:18.590 --> 00:13:19.560
( Pause )

00:13:19.559 --> 00:13:26.819
Okay so let's talk for a second about just the
basics and Dave showed you how to use Profiler

00:13:26.820 --> 00:13:33.140
to examine how your apps calling up in GL and
one of the first things that you ought to look at is

00:13:33.139 --> 00:13:36.220
to minimize the number of times you call up in GL.

00:13:36.220 --> 00:13:41.629
Immediate mode as you saw adds up fast, you know, it
doesn't take very many frames of that application to get you

00:13:41.629 --> 00:13:47.600
up in the millions of function calls and instead a
better strategy is to use the functions that allow you

00:13:47.600 --> 00:13:57.159
to move a lot of data at one time which means one
function call submits lots of things and vertex arrays,

00:13:57.159 --> 00:14:00.100
vertex buffer objects are a good way to do that.

00:14:00.100 --> 00:14:07.220
If you have, if you're using programs or Shaders there's
these two extensions that allow you to change the program

00:14:07.220 --> 00:14:12.440
parameters or uniforms all at one time so you
don't have to make multiple function calls to do that.

00:14:12.440 --> 00:14:20.770
Bindable uniforms is new for Leopard, for Shaders, the
other one we've had out for a while and Dave and I went

00:14:20.769 --> 00:14:28.100
out in preparation for this talk and ran Profiler
and gathered some statistics from several

00:14:28.100 --> 00:14:35.470
of you know the latest, popular games and I thought
that might be interesting to take a look at and we see

00:14:35.470 --> 00:14:43.160
that they spend, you know, anywhere from, you know,
35% to 60% of their time actually calling up OpenGL

00:14:43.159 --> 00:14:48.139
for different things and you know,
some of them for various reasons.

00:14:48.139 --> 00:14:54.600
You know, some of them call a lot of program
parameters to put inputs into their vertex programs.

00:14:54.600 --> 00:15:00.509
Some of them call matrix mode to change the change the
matrix a lot but they spend an awful lot of time calling

00:15:00.509 --> 00:15:08.090
up OpenGL but we also noticed that they don't call glGet
and they never call glBegin so that means that, you know,

00:15:08.090 --> 00:15:15.940
high performance applications aren't doing those things
and these applications spend the majority of their time

00:15:15.940 --> 00:15:24.570
in these routines as indicated by Profiler but really
what's going on here is when you call something

00:15:24.570 --> 00:15:30.100
that actually physically does drawing that's when
all the state changes that you've made in between,

00:15:30.100 --> 00:15:36.100
that's where they get resolved; so if you see
these calls show up it may not necessarily be

00:15:36.100 --> 00:15:42.490
that one call that's causing you the problem; it could
be the things that you did before that and that's

00:15:42.490 --> 00:15:44.740
where examining the trace comes in handy.

00:15:44.740 --> 00:15:50.169
So it's said a lot the OpenGL is a
state machine so what's a state machine.

00:15:50.169 --> 00:15:56.259
It's just a concept for something that
takes a fixed number of inputs; you know,

00:15:56.259 --> 00:15:59.620
does certain operations to them and
adds a fixed number of outputs.

00:15:59.620 --> 00:16:07.399
Well your graphics card only has one current state so when
you flip back and forth between states it gets expensive

00:16:07.399 --> 00:16:13.980
so a strategy is to group your similar drawing together
to minimize the number of times you change state.

00:16:13.980 --> 00:16:21.930
Another great thing that's easy to find with Profiler is to
watch the trace for times when you continue to set the state

00:16:21.929 --> 00:16:28.389
to the same thing over and over; we see that a lot and
it's just overhead and it doesn't really buy you anything;

00:16:29.529 --> 00:16:33.819
so instead a better strategy is to
use objects in encapsulate state,

00:16:33.820 --> 00:16:38.970
these can be switched between with one function
call and change a lot of things at one time.

00:16:38.970 --> 00:16:45.330
Vertex_array_object will do that for vertex array state;
framebuffer_object does that for drawable so instead

00:16:45.330 --> 00:16:51.520
of changing OpenGL context you get to
just set new drawable and continue to draw.

00:16:51.519 --> 00:16:52.829
It's lighter weight.

00:16:52.830 --> 00:16:53.540
( Pause )

00:16:53.539 --> 00:16:59.559
So, when you're programming try not to stall the engine.

00:16:59.559 --> 00:17:07.899
Stalling the engine, the best way to do it is to start
asking OpenGL what you told it to do so query the state;

00:17:07.900 --> 00:17:15.190
ask it what you set it to and in all these sessions we
talked about sync points so a sync point is somewhere

00:17:15.190 --> 00:17:23.430
where the execution of the graphics pipe has to
stop and reset itself or give back some information

00:17:23.430 --> 00:17:28.779
to figure some things out that you ask it to do and
these are all classic reasons to sync; you know,

00:17:28.779 --> 00:17:36.889
glGet and glReadPixels sync because ask sometimes,
sometimes glGets syncs for some things and they have

00:17:36.890 --> 00:17:44.650
to stop, you know, figure some things out maybe perhaps
rendering before it can give you the answer back

00:17:44.650 --> 00:17:48.310
and instead a better strategy is to
let it keep working as much as you can.

00:17:48.309 --> 00:17:56.539
So wait to get your results as much as you can and if you
are using fences and you know, delay the test of the fences

00:17:56.539 --> 00:18:04.629
as long as you can so you don't want to be either
pulling the fencing or blocking, waiting on it to finish.

00:18:04.630 --> 00:18:11.350
Occlusion queries are the same if you can wait until
as late as possible to get the result from that,

00:18:11.349 --> 00:18:17.059
that's going allow the graphics to keep going as
much as possible and if you need to use ReadPixels,

00:18:17.059 --> 00:18:24.169
if you use pixel buffer objects then you can start the ReadPixels,
do more work and then right up until the last second

00:18:24.170 --> 00:18:29.090
when you have to have the results of the pixels then
you call matte buffer and then you'll block

00:18:29.089 --> 00:18:32.529
until they come back but hopefully
they'll already be back by then.

00:18:33.759 --> 00:18:40.680
Okay so some techniques to optimize your state and you
inspect your trace, look to see if it makes sense

00:18:40.680 --> 00:18:46.269
and look out for redundant state setting
and I think a lot of people are surprised;

00:18:46.269 --> 00:18:53.759
I know I'm surprised when I write a program and open up with
Profiler and I go, "Oh, what did I do" and so, and you see,

00:18:53.759 --> 00:19:00.869
"Well gee, you know" it's really easy to see sometimes that
you're making some stupid mistakes as far as redundancy

00:19:00.869 --> 00:19:05.769
and when you look at your immediate mode program
you think, "Well boy do I have to set the matrix mode

00:19:05.769 --> 00:19:17.420
for every quad I draw" probably not and then also the state
inspector helps you...helps you find changes in state easily

00:19:17.420 --> 00:19:24.180
because of the color coding and that's also a good debugging
tool, by the way so if you get drawing results or not

00:19:24.180 --> 00:19:30.539
and not expecting or you know, "why isn't this drawing,
why isn't this drawing" you can look at the state to see,

00:19:30.539 --> 00:19:36.680
"Oh gee, I've got blending enabled;
okay, yeah, I didn't want that."

00:19:36.680 --> 00:19:40.810
Okay so let's talk for a minute about
glFlush; so we say don't call flush,

00:19:40.809 --> 00:19:43.619
don't call finish; so what does flush actually do?

00:19:43.619 --> 00:19:50.159
So when the graphics system is executing and it's
buffering up commands to send to the graphics card

00:19:50.160 --> 00:19:57.660
and its filling buffer 1 up as
you issue commands it fills up.

00:19:57.660 --> 00:20:05.920
When you call flush it sends that buffer on to the card
and GPU starts to chew on it and then you start filling

00:20:05.920 --> 00:20:10.050
up another buffer with the next command you call.

00:20:10.049 --> 00:20:16.399
So, what happens is if you call flush
a lot these queues are relatively big

00:20:16.400 --> 00:20:23.730
and if you flush you only fill them a tiny amount and then
when you submit it well first of all you didn't fill it,

00:20:23.730 --> 00:20:29.430
second of all you, each application only gets a
fixed number of them so if you do a few things flush,

00:20:29.430 --> 00:20:32.779
do a few things flush, do a few things
flush, eventually you're going to block;

00:20:32.779 --> 00:20:38.769
you're going to...the graphics card will not finish
working on the buffer before need a new one back;

00:20:38.769 --> 00:20:44.309
it doesn't have any free and so then you're
blocked on flush waiting to get a new buffer.

00:20:44.309 --> 00:20:49.059
So instead, you know, the strategy should
be aiming for is to fill the buffers.

00:20:49.059 --> 00:20:55.029
If you never call flush what happens is the buffer
gets full and when it's full it cements it to the card,

00:20:55.029 --> 00:20:59.349
the card starts working and you get started on a new
empty one and then you get to fill that completely.

00:20:59.349 --> 00:21:02.559
If you have too much flushing then
you're making inefficient use

00:21:02.559 --> 00:21:06.909
of that resources; you know, aim for full command buffers.

00:21:06.910 --> 00:21:10.550
There are some times you have to
use glFlush and these are two.

00:21:10.549 --> 00:21:17.069
If you're single buffered, for whatever reason you might
want to be you have to call glFlush to get your results

00:21:17.069 --> 00:21:23.009
to appear on the screen; otherwise they won't appear
until the command buffer fills up and you know

00:21:23.009 --> 00:21:27.569
that can give you kind of half arbitrary rendering
results; so if you're single buffered you're going to have

00:21:27.569 --> 00:21:38.529
to call glFlush to get the results you want and another
case is if you have shared OpenGL context then you have

00:21:38.529 --> 00:21:44.680
to use flush to make sure that some rendering is
finished before you can use up the other context.

00:21:44.680 --> 00:21:51.630
An example of this is if you are using pbuffers and
you're going to use that as a texture in another context,

00:21:51.630 --> 00:21:53.940
if you have to, you'll have to call glFlush

00:21:53.940 --> 00:22:00.730
on the first context before the resource is
guaranteed to be available in the second context.

00:22:00.730 --> 00:22:01.740
( Pause )

00:22:01.740 --> 00:22:11.660
So, Dave...a lot of times we have developers come in and I
think that you saw this just yesterday, someone that said,

00:22:11.660 --> 00:22:16.880
"Oh well I was working on my app and all of a
sudden I fell into software" and can you show us how

00:22:16.880 --> 00:22:21.310
to use the tools to work on some
of the common cases for that?

00:22:21.309 --> 00:22:27.409
>>Sure, if I can get the demo machine back, please.

00:22:27.410 --> 00:22:31.070
I did get this on the list just yesterday.

00:22:31.069 --> 00:22:37.619
A developer wrote in and said, "I have this
Shader and it's flying along in hardware."

00:22:37.619 --> 00:22:42.250
He added one line to his Shader and
it tanked and he opened up Profiler

00:22:42.250 --> 00:22:49.009
and found out that GL vertex was going a thousand times
slower all of a sudden; so this is one of these, you know,

00:22:49.009 --> 00:22:56.960
I'd fell off a cliff, what happened, kind
of scenarios; not a graceful decline at all.

00:22:56.960 --> 00:23:01.610
This is definitely pushed you over the edge.

00:23:01.609 --> 00:23:08.259
So that's usually a symptom of what we call Suffer
fallback which means that you were hardware accelerated

00:23:08.259 --> 00:23:15.559
and now you're not; so that's what
we want to take a look at.

00:23:15.559 --> 00:23:22.500
Okay, we have an app here, this spinner
app and I'm going to go ahead and launch that;

00:23:22.500 --> 00:23:30.359
now this is a grociated quad; it's
four vertices with this rainbow pattern

00:23:30.359 --> 00:23:33.389
on it; it's running at about 200 frames a second.

00:23:33.390 --> 00:23:42.600
Okay, I've got some really smoking hardware in here
and 200 frames a second for a quad really sucks;

00:23:42.599 --> 00:23:48.699
that's...I mean this thing should be going like about
4,000 and this should be a blur so you can't see it.

00:23:48.700 --> 00:23:52.360
Why is it only going 200 frames a second for a quad?

00:23:52.359 --> 00:23:53.979
It seems way too slow.

00:23:53.980 --> 00:24:00.220
So, here's what I'm going to do.

00:24:00.220 --> 00:24:07.769
I'm going to check and see if we are in fact are just
falling off the hardware and it's really easy to do

00:24:07.769 --> 00:24:14.900
in Profiler; I just say "break on software
fallback" and it stops and says, "Well, yeah, you did;

00:24:14.900 --> 00:24:24.460
you fell off the hardware" and you can see that up in
here it says the fragment processing is in fact GL_FALSE;

00:24:24.460 --> 00:24:29.880
so this is...if you were to make the calls I think in Jeff's
session if you're in that there's a CGL call you can make

00:24:29.880 --> 00:24:35.800
to get the fragment processing and also the
vertex processing; these are those same calls.

00:24:35.799 --> 00:24:39.159
Now I what OpenGL Profiler is basically
doing is it's making those calls

00:24:39.160 --> 00:24:45.890
for you every single time you issue a GL command;
so using this feature is not super speedy,

00:24:45.890 --> 00:24:53.730
but it will also definitely tell you if that's your
problem; if you in fact fell off the fast hardware path.

00:24:53.730 --> 00:25:01.670
So, okay let's take a look more at this problem, how
we're going to solve it namely and one of the things

00:25:01.670 --> 00:25:11.120
that we've noticed is typically one of the main
suspects in falling off hardware path are Shaders.

00:25:11.119 --> 00:25:16.949
There's other ways to fall of hardware path too
but usually those are subtler and harder to get.

00:25:16.950 --> 00:25:20.170
It's real easy to fall off hardware
when you're using Shaders.

00:25:20.170 --> 00:25:25.529
So, I'm going to take a look at the Shaders that
are in here; I'm sitting at a breakpoint so I'll go

00:25:25.529 --> 00:25:34.019
and look at the resources panel in Profiler and I want to
take a look at Shaders; so Profiler has gone and reached

00:25:34.019 --> 00:25:39.000
into the application and said,
"Well its got this vertex shader

00:25:39.000 --> 00:25:43.799
and this fragment shader and they're bound to this program."

00:25:43.799 --> 00:25:52.079
So, let me take a look at the vertex shader
here...so I've got that right up there

00:25:52.079 --> 00:25:59.980
and nothing really jumps out as causing any major problems.

00:25:59.980 --> 00:26:02.049
It's doing some pretty straightforward stuff.

00:26:02.049 --> 00:26:13.149
I have transform, it's building a color, reading
a...putting a value into a varying, pretty lightweight.

00:26:13.150 --> 00:26:17.410
Let's take a look at the fragment
shader and well here we are.

00:26:17.410 --> 00:26:22.220
There's the noise 3 function;
that's not implemented in hardware at all.

00:26:22.220 --> 00:26:31.610
So no hardware that we ship has noise 3 functions;
that is definitely software fallback, guaranteed.

00:26:31.609 --> 00:26:36.529
So I'm going to say, "Well okay what
if I just don't do that then, you know,

00:26:36.529 --> 00:26:39.039
doctor it hurts when I do this, well don't do that."

00:26:39.039 --> 00:26:46.930
So I'll take that out of the shader, say compile; now
what Profiler has done is taken that fragment shader

00:26:46.930 --> 00:26:51.039
and replaced the old one in the
app with this new one.

00:26:51.039 --> 00:27:03.680
Let me go down to my breakpoints here...and
continue and get on the app

00:27:03.680 --> 00:27:03.750
( Pause )

00:27:03.750 --> 00:27:05.480
Now what happened?

00:27:05.480 --> 00:27:16.120
I got it...excuse me, there we go and now you can see that
I'm in fact running about 5,000 frames a second...not bad.

00:27:16.119 --> 00:27:23.389
I left the break on software fallback...break...whoops,

00:27:23.390 --> 00:27:28.370
after that whole thing about how
Profiler is invasive I do it myself.

00:27:28.369 --> 00:27:30.829
You'd think I'd know, I wrote the program.

00:27:32.490 --> 00:27:33.190
So there you go.

00:27:33.190 --> 00:27:41.180
So now from this stage you can take that shader
code that you fixed in Profiler and paste it back

00:27:41.180 --> 00:27:48.090
into the original app and presto you're not perform...or at least
you know so you can decide and make better decisions;

00:27:48.089 --> 00:27:54.470
so this is a good way to use Profiler to
look into why you might be falling off

00:27:54.470 --> 00:27:58.789
of the fast hardware path and onto the slower software path.

00:27:58.789 --> 00:28:02.700
Okay, with that, back to you Kent.

00:28:02.700 --> 00:28:08.430
>>The newer hardware is much better about falling off
but you know a lot of the developer problems that come

00:28:08.430 --> 00:28:13.779
to us are people that are trying to make their
applications run on, you know, across the line

00:28:13.779 --> 00:28:21.579
and the lower end hardware is more
difficult to make your stuff fit in it.

00:28:21.579 --> 00:28:25.799
Okay so why are some reasons you fall off the hardware?

00:28:25.799 --> 00:28:32.839
So vertex processing on the older hardware some of the
fixed function features will make you fall off hardware

00:28:32.839 --> 00:28:39.319
and two-sided lighting is an example and shaders
that use too many resources, so they get to long

00:28:39.319 --> 00:28:45.019
or to many texture lookups or never or
I guess any texture lookups currently

00:28:45.019 --> 00:28:50.730
but for vertex processing some hardware is always in
software vertex processing until integrated that's

00:28:50.730 --> 00:29:00.640
in the MacBook and the Mac Mini are always in software
vertex processing and for fragment processing some hardware

00:29:00.640 --> 00:29:07.150
and some features of non power of 2 will make you fallback
into softer fragment processing and you know shaders

00:29:07.150 --> 00:29:13.830
that exceed the hardware limits or use features
without hardware support make you fallback

00:29:13.829 --> 00:29:18.819
and fragment fallback is much more
expensive than vertex fallback.

00:29:18.819 --> 00:29:23.009
I think that it would probably
relatively easy to be falling back

00:29:23.009 --> 00:29:27.150
with your vertex processing sometimes
and not be able to tell.

00:29:27.150 --> 00:29:33.630
Now fragment processing usually just, you know, you can tell
immediately if you do any kind of significant rendering;

00:29:33.630 --> 00:29:39.640
and even though the fragment fallback is much improved
in Leopard you still...it's relatively easy to tell.

00:29:39.640 --> 00:29:46.720
It's interesting that when we were coming up with the
contrived program and we were developing on our laptops

00:29:46.720 --> 00:29:53.779
that when we fell back it would be two frames per
second and the we'd get up here on the super,

00:29:53.779 --> 00:30:02.750
super demo machines then it's 200 frames per second fall
back that the lower end hardware it's really easy to tell.

00:30:02.750 --> 00:30:04.500
So how can you tell?

00:30:04.500 --> 00:30:09.210
Use the break on fallback feature like Dave
showed you and if you're using Shark you can look

00:30:09.210 --> 00:30:15.110
for the software render library to show up in
your Shark trace and it's called GLRendererFloat.

00:30:15.109 --> 00:30:25.419
Inside your program, as Dave mentioned, there's these calls
you can use and just like any GLGet they're expensive

00:30:25.420 --> 00:30:33.279
and these actually alter the flow of your, of the system
when you make them so it's a complete and total sync

00:30:33.279 --> 00:30:36.980
when you call these so it's something
you want to call every time you render;

00:30:36.980 --> 00:30:43.769
it should be used more like a development feature or you
want to run your program one time on one fragment to see

00:30:43.769 --> 00:30:51.289
if it worked in hardware; that would be another time you
could get loaded up and check but not every time you draw

00:30:51.289 --> 00:31:01.200
and there's an application on the disk already in developer
example OpenGL called GSL Editor Sample that allows you

00:31:01.200 --> 00:31:07.360
to simply develop shaders and it shows you if
you're in software or hardware vertex processing

00:31:07.359 --> 00:31:12.979
as you edit the shaders so you can be editing shader
or you add something that makes you fallback, whoops,

00:31:12.980 --> 00:31:17.910
it turns red, you see it fell back and you can do
something different and the new shader builder also has

00:31:17.910 --> 00:31:22.009
that feature along with a ton of others and
that's going to be available in Leopard.

00:31:22.009 --> 00:31:32.750
Okay so Dave this brings us up to multithreading and I
had this application the other day that I was debugging for Leopard,

00:31:32.750 --> 00:31:39.890
it came up and it had 37 threats and I was like, "Oh
my gosh;" so these apps are really starting

00:31:39.890 --> 00:31:47.170
to use multithreading and it's a great way, every
machine we ship has multiple processors, multiple cores,

00:31:47.170 --> 00:31:52.050
and it's a great way to get some performance but can be
difficult so why don't you show us the features of the tools

00:31:52.049 --> 00:31:58.069
that allow you to more easily develop
multithreaded applications.

00:31:58.069 --> 00:32:02.849
>>Okay, first I want to say that we feel your pain.

00:32:02.849 --> 00:32:10.699
multithreaded programming is just hard and there's no
way around it, especially when you've got multiple cores

00:32:10.700 --> 00:32:15.539
and the threads really are assigned to run on
different processors; so if you're not really careful

00:32:15.539 --> 00:32:26.509
with your locking and things like that then your thread
competition problems and bugs are compounded a lot.

00:32:26.509 --> 00:32:33.450
So, we've endeavored to come up with some ways and
some tools and actually added things to Profiler

00:32:33.450 --> 00:32:38.309
to make the GL-specific stuff in
multithreaded programming easier.

00:32:38.309 --> 00:32:47.909
I want to, I have to give my usual lecture,
right, which is when you are going multithreaded

00:32:47.910 --> 00:32:55.820
in OpenGL generally speaking you want to
think of one thread per drawing context;

00:32:55.819 --> 00:33:01.109
so if you've got a OpenGL context,
CGL context with this drawing you want

00:33:01.109 --> 00:33:05.229
to have just one thread that's talking to it.

00:33:05.230 --> 00:33:10.279
It's difficult to have many threads
talking to that one drawing context.

00:33:10.279 --> 00:33:14.519
You can have your other threads in you
app definitely doing other things,

00:33:14.519 --> 00:33:21.029
in your game, physics, all kinds of stuff like that or
database access, that's a great way to use threads

00:33:21.029 --> 00:33:26.289
but generally speaking one thread per drawing
context; so if you have more than one drawing context

00:33:26.289 --> 00:33:30.420
which is also a good idea especially when
you've got very heavyweight drawing going

00:33:30.420 --> 00:33:34.930
on then try to match those two things up.

00:33:34.930 --> 00:33:40.120
I'm going to show you in a little bit how you
can have many threads going to one context;

00:33:40.119 --> 00:33:46.719
there's some locking mechanisms that we provide and also
just generally how to do that and I'm actually going

00:33:46.720 --> 00:33:51.420
to write code right here live which is, yea.

00:33:51.420 --> 00:34:06.519
Okay that's the end of the lecture; two kinds of multiple
threading programs that multithreading programming

00:34:06.519 --> 00:34:11.659
that we cover; one is yours which
you're doing in your application

00:34:11.659 --> 00:34:21.519
and the other is OpenGL Engine is multithreaded as well;
so last year at WWDC we showed, we took Doom and turned

00:34:21.519 --> 00:34:27.789
on multithreading and immediately got some,
I forget the percentage exactly but it was...

00:34:27.789 --> 00:34:28.769
>>Some.

00:34:28.769 --> 00:34:36.449
>>Some. It was significant just by multithreading the
OpenGL Engine underneath it and we get that for free.

00:34:36.449 --> 00:34:43.409
You can get that for free in Profiler
by going here in the breakpoints view

00:34:43.409 --> 00:34:59.629
and down here on...you can turn the multithreading on
and off regardless of what the application is set, okay.

00:34:59.630 --> 00:35:05.440
So let me show that really fast with...I've
got cylinder here and I'm just going

00:35:05.440 --> 00:35:15.510
to turn it on...so there's cylinder running and if
again if I stop at the end at my frame end I can say,

00:35:15.510 --> 00:35:21.970
"Well I want to see what it looks like with the multi
threading turning on" so I turn the breakpoint on,

00:35:21.969 --> 00:35:29.589
then I force multithread on, turn the breakpoint off so
it'll keep running, hit continue and now go back to cylinder

00:35:29.590 --> 00:35:33.350
and there I've got it running, now it's
running on the multithreaded OpenGL Engine

00:35:33.349 --> 00:35:36.630
and I didn't change any code at all, nothing.

00:35:36.630 --> 00:35:42.150
So just automatically flip that switch for me; so that's
something you might want to try first and just see

00:35:42.150 --> 00:35:49.910
because it's no always true that running on the multi
threaded OpenGL Engine makes your app run faster.

00:35:49.909 --> 00:35:52.940
There's a lot of factors that go into that.

00:35:52.940 --> 00:35:57.039
multithread was kind of a buzz word
for a while and it's "Well, you know,

00:35:57.039 --> 00:36:01.989
we're going to go just because we've got all these
processors we're going to spread our job out" but you've got

00:36:01.989 --> 00:36:08.909
to be careful about things like hidden serialism and stuff
like that and are you really CPU bound, are you GPU bound,

00:36:08.909 --> 00:36:15.629
these are all things you need to look at with Profiler and
our other tools before you just jump in to multithreaded

00:36:15.630 --> 00:36:22.970
because multithreading is difficult to program
and I'm going to show you why in a second.

00:36:22.969 --> 00:36:31.769
Okay and again if I want to I can stop at the
frame end, force multithreading off and say,

00:36:31.769 --> 00:36:40.259
"Well what really happened here...not a great deal
of difference; it is running a little bit slower

00:36:40.260 --> 00:36:41.980
but there's not a great deal of difference."

00:36:41.980 --> 00:36:49.210
So here's an example where I'm not specifically bound up in
any way that the multithreaded engine is going to help me;

00:36:49.210 --> 00:36:55.079
so, but let's take a look at some multi
threading issues when you're writing them

00:36:55.079 --> 00:36:57.860
in your app and how Profiler can help you with that.

00:36:57.860 --> 00:37:10.340
I did this myself yesterday...here's a piece of code and
what it's going to do is draw the famous Atlantis whales.

00:37:10.340 --> 00:37:21.480
Everybody knows Atlantis, right, being the demo
that we shipped; so...I just run this app

00:37:21.480 --> 00:37:27.730
by itself it'll lock this machine up because I have
all kinds of threading errors going on in here.

00:37:27.730 --> 00:37:35.119
I've got three threads, one for each whale you'll see
and they're all trying to talk to the same context;

00:37:35.119 --> 00:37:41.460
well when I do that I've got a command buffer that's
partially full and then another one trying to come in

00:37:41.460 --> 00:37:50.420
and override it and the whole thing just, you know, falls
apart; so I tried it; I'm not going to do here because,

00:37:50.420 --> 00:37:56.869
you know, why would you want to see my reboot
my computer, you can get that at home, right?

00:37:56.869 --> 00:38:03.519
So what I'm going to do is with Profiler is first
of all let me build the app and make sure;

00:38:03.519 --> 00:38:11.800
I opened this in Xcode and I'm going to build this so I
just, it's done, it's built and let me go in Profiler here

00:38:11.800 --> 00:38:19.680
and I'm going to say I want to break on thread
conflicts so Profiler is going to tell me

00:38:19.679 --> 00:38:24.049
if this app had a problem with
threading and there it is right there.

00:38:24.050 --> 00:38:28.310
Now it didn't give me a call stack because
the call stack was probably pretty messed up.

00:38:28.309 --> 00:38:35.840
When you have two threads smashing into each other it's pretty
hard to get state out of the machine; so even with a gdb

00:38:35.840 --> 00:38:43.850
and tools like that it's pretty hard to see what's actually
going on once you have the error but at least I know

00:38:43.849 --> 00:38:49.400
that yes I do have two threads competing for the
same resource and I've done something wrong.

00:38:49.400 --> 00:38:54.980
So, and I've done it in a safe way; I didn't
lock my machine up; that's a good thing, right?

00:38:54.980 --> 00:39:00.000
So now I can say, "Okay look at where
it's stopped, it's in color 3F."

00:39:00.000 --> 00:39:05.119
Well, that's sort of a weird place; I just
call it, how is it possible that it's...well

00:39:05.119 --> 00:39:11.440
because my thread conflict happened as soon as I made that
OpenGL call; that means that one thread was in the middle

00:39:11.440 --> 00:39:16.519
of filling a command buffer and another thread
came in and tried to make a color call, boom.

00:39:16.519 --> 00:39:19.820
So, okay, kill that.

00:39:19.820 --> 00:39:38.970
What we have is...let me find it here...CGL_LOCK
...this is a way to lock the CGL context, okay?

00:39:38.969 --> 00:39:43.859
So what we've provided is some API that
you can use and it's in Leopard, right.

00:39:43.860 --> 00:39:53.720
I don't think it's earlier than Leopard; CGLLockContext
and CGLUnlockContext; so these pieces of API allow you

00:39:53.719 --> 00:40:01.439
to lock the CGL portions of the context and I'm going to
turn those on and see what happens with my app

00:40:01.440 --> 00:40:07.490
and see if I can get, I've bracketed my draw
calls with these locks in the effort to make

00:40:07.489 --> 00:40:10.529
so that those threads don't compete;
so let's see what happens there.

00:40:10.530 --> 00:40:19.160
I'll just turn this to 1 which hopefully will turn
all that stuff on, build, and then go ahead and get my,

00:40:19.159 --> 00:40:27.889
make sure that I'm still breaking on the
thread conflicts, I am and launch and uh-oh.

00:40:27.889 --> 00:40:33.469
I got a little further but still having a problem.

00:40:33.469 --> 00:40:35.500
Remember this is my threads now, okay.

00:40:35.500 --> 00:40:38.829
I'm not in OpenGL threads; so this is my threading problem.

00:40:38.829 --> 00:40:40.440
I'm making the programming error.

00:40:40.440 --> 00:40:42.769
I take full responsibility, you know.

00:40:42.769 --> 00:40:50.420
I think we're doing some good work here
but okay, so next step then is to say,

00:40:50.420 --> 00:40:59.450
"Alright I've used...I've just tried flat making GL calls
from the different threads, that obviously didn't work."

00:40:59.449 --> 00:41:08.199
Now I've tried using the CGLLockContext routines
around my drawing calls and that got me a little farther

00:41:08.199 --> 00:41:14.109
but I'm still having problems so that means okay, I need
to reinvestigate what's going on here and really think

00:41:14.110 --> 00:41:23.539
about what I'm doing hard with my threads and it turns
out that I do still in fact need to lock more stuff myself

00:41:23.539 --> 00:41:40.239
and what I'm doing there is...let's find where this is...not
only my draw calls but...this is in NS OpenGL view subclass

00:41:40.239 --> 00:41:46.809
and you'll notice in it's reshape method which it just calls
automatically for you every time the window changes size

00:41:46.809 --> 00:41:51.110
and when a window first runs; Cocoa
programmers are familiar with this.

00:41:51.110 --> 00:41:59.120
It's going to go ahead and make some GL calls; well
I need to be aware of that and I need to lock those

00:41:59.119 --> 00:42:05.119
and again in my drawRect as well where I'm going to do
some other stuff, flush (inaudible), things like that.

00:42:05.119 --> 00:42:14.549
Okay, so I'm going to build this and let me see
what happens; now I'll get my...again I'm going

00:42:14.550 --> 00:42:22.940
to make sure the thread conflict is turned on just in
case this didn't solve the problem and run and okay.

00:42:22.940 --> 00:42:24.670
So now my whales are swimming.

00:42:24.670 --> 00:42:28.619
Well, they're swimming kind of slow but the reason again is

00:42:28.619 --> 00:42:36.929
because every single GL call that's being made Profiler is
going in and looking and doing either a p thread try lock

00:42:36.929 --> 00:42:44.579
and all kinds of stuff to see if there's a thread
conflict so I'm in there really examining what's going

00:42:44.579 --> 00:42:50.139
on with your calls, it's very invasive; so if I
just go ahead and turn that off, come back to here,

00:42:50.139 --> 00:43:02.809
there's my whales swimming and...we did
that, we got rid of the thread conflicts.

00:43:02.809 --> 00:43:05.880
( Applause )

00:43:05.880 --> 00:43:14.470
Okay, so...with that back to you Kent.

00:43:14.469 --> 00:43:15.659
>>Thanks Dave.

00:43:15.659 --> 00:43:22.949
So threading in OpenGL and switch back to slides please.

00:43:22.949 --> 00:43:23.719
( Pause )

00:43:23.719 --> 00:43:29.029
You probably, you know, if you're a frequent
attendee to WWDC we go over this every year.

00:43:29.030 --> 00:43:34.850
You know, OpenGL context are not thread safe but
you can use multithreading but you have to take care

00:43:34.849 --> 00:43:41.339
of your own locking and you know, as usual with
multithreading programming it can be difficult

00:43:41.340 --> 00:43:48.360
to find a good division of labor to make
your, the app actually get any speed

00:43:48.360 --> 00:43:51.650
up after you take care of that kind of thing.

00:43:51.650 --> 00:44:01.050
One popular way that people do use threading with OpenGL
is to for instance is to have thread that has a context,

00:44:01.050 --> 00:44:07.250
another thread that has another context and they're shared
and then the first thread will be like loading resources,

00:44:07.250 --> 00:44:13.500
textures and things and then the other thread will be
drawing and that seems to provide a pretty good speed

00:44:13.500 --> 00:44:19.630
up for people to do their own threading and as
Dave mentioned, and I'm not sure it's clear,

00:44:19.630 --> 00:44:25.700
but NSOpenGLView may call you when you're
in the middle of doing something else;

00:44:25.699 --> 00:44:34.189
so if you have spawned a thread that's doing drawing and
it's OpenGL view at any time might call you to context;

00:44:34.190 --> 00:44:41.079
so if that's the case then CGLLockContext will
allow you to prevent that from making a crash;

00:44:41.079 --> 00:44:47.000
that CGLLockContext only locks the CGL
calls so it doesn't lock the GL calls.

00:44:47.000 --> 00:44:51.360
So when that situation is appropriate
you can use CGLLockContext;

00:44:51.360 --> 00:44:56.349
otherwise if you're doing your own
threading you're kind of on your own

00:44:56.349 --> 00:45:01.779
for locking...or we also provide the multithreaded
OpenGL engine and it's been talked about in some

00:45:01.780 --> 00:45:07.010
of the other sessions this week and
like Dave said we showed it last year.

00:45:07.010 --> 00:45:11.800
It's great for a certain type of app and these
apps, apps that have done a lot of work

00:45:11.800 --> 00:45:15.190
to minimize their sync points in their application.

00:45:16.239 --> 00:45:22.949
One thing to keep in mind is that it does add some overhead;
the way the multithreading works is it adds another buffer

00:45:22.949 --> 00:45:27.469
and when you call OpenGL with the command
it just copies it and then the processing

00:45:27.469 --> 00:45:31.069
of that command buffer is done on the second CPU.

00:45:31.070 --> 00:45:35.200
So you're doing some more work and if your
division of labor is not right or you have lots

00:45:35.199 --> 00:45:39.649
of sync points and things you can slow yourself down.

00:45:39.650 --> 00:45:47.950
One example of how there's more sync points is that if
you ask OpenGL if lighting is enabled for instance; okay,

00:45:47.949 --> 00:45:52.909
if you're single threaded it goes in and checks
the state, returns to you if lighting is enabled.

00:45:52.909 --> 00:45:58.750
With the multithreaded engine if you ask OpenGL if lighting
is enabled it has to finish the command buffer before it is

00:45:58.750 --> 00:46:03.219
up to date enough to tell you whether lighting
is enabled so that adds additional overhead.

00:46:03.219 --> 00:46:07.049
That being said, it's simple to turn this on
in your app or you can use Profiler

00:46:07.050 --> 00:46:12.840
or turn on you app with this simple CGLEnable call.

00:46:12.840 --> 00:46:13.050
( Pause )

00:46:13.050 --> 00:46:23.370
So, we have another topic to discuss and that's paging, so
in the past 6 months we've had a lot of developers come in

00:46:23.369 --> 00:46:27.359
and say that, you know, they're not getting
the performance that they think they ought to

00:46:27.360 --> 00:46:33.630
or you know their performance is different from other
platforms or whatever and a lot of times it's due to paging

00:46:33.630 --> 00:46:39.920
so Dave why don't you show us the tools that
you can use to diagnose this type of situation.

00:46:39.920 --> 00:46:48.889
>>Okay...what we're talking about is
specifically texture paging and this is

00:46:48.889 --> 00:46:55.420
where we see apps gracefully degrade or
slowly degrade instead of just fall off a cliff

00:46:55.420 --> 00:46:59.650
like we saw before in the software fallback case.

00:46:59.650 --> 00:47:06.070
So if you notice that your app as you start to
load more textures especially or more resources into it,

00:47:06.070 --> 00:47:13.730
it starts to kind of get slower and slower and chug and
chug and chug, we've got some tools here to look at that.

00:47:13.730 --> 00:47:24.010
The one I'm going to show is driver monitor and I'm...up,
good; so this is OpenGL driver monitor right here

00:47:24.010 --> 00:47:26.450
and what I'm looking at are two parameters.

00:47:26.449 --> 00:47:32.929
One is called the current free video
memory and I've got quite a lot of it

00:47:32.929 --> 00:47:42.349
and what that's telling me is how much memory is available
on the video card for my textures and other resources.

00:47:42.349 --> 00:47:54.670
The other one is the texture page on data and this is
going to show me live pages as the go onto the card;

00:47:54.670 --> 00:48:00.329
so these two kind of relate to each other
obviously, right because as I put texture pages

00:48:00.329 --> 00:48:06.779
on the card I should see gradually
the amount of free memory decline

00:48:06.780 --> 00:48:20.800
and so let me launch that...spinning cylinder app
again...okay and over here we see that right as soon

00:48:20.800 --> 00:48:28.820
as I launched it there was a little dip...right there in
the amount of free memory that I have as I loaded a bunch

00:48:28.820 --> 00:48:34.250
of textures on the card and a spike in the page on data;
so there was a bunch of pages sent over to the card.

00:48:34.250 --> 00:48:38.420
Now what I can do with this app
is add a bunch of textures

00:48:38.420 --> 00:48:48.500
to it...so every time I add a texture...you'll
see I just put in a bunch more...

00:48:48.500 --> 00:48:50.280
>>Why don't you change the skeletal linear?

00:48:50.280 --> 00:48:51.940
I think it might be easier to see.

00:48:51.940 --> 00:48:52.659
>>That's a good idea.

00:48:52.659 --> 00:48:53.269
( Pause )

00:48:53.269 --> 00:48:54.280
Okay.

00:48:54.280 --> 00:48:55.440
>>At the top.

00:48:55.440 --> 00:49:00.630
>>You know what else...

00:49:00.630 --> 00:49:00.690
>>Yea.

00:49:00.690 --> 00:49:03.280
>>There we go.

00:49:03.280 --> 00:49:12.720
So you can see here this is when I first added some,
now I've added more...and then let me add a bunch more

00:49:12.719 --> 00:49:25.779
and see if I can't get that down to zero...it's
getting closer...it's kind of my challenge;

00:49:25.780 --> 00:49:31.330
there we go and you see the app is really chugging
now, look at the amount of paging that's happening here;

00:49:31.329 --> 00:49:36.940
it's spiking up; so we're getting a lot of
texture pages swapped on and off the card

00:49:36.940 --> 00:49:41.170
and I've basically used up all the card's memory now.

00:49:41.170 --> 00:49:55.059
In fact you can see it's starting to
affect the rest of the window server.

00:49:55.059 --> 00:49:55.150
( Pause )

00:49:55.150 --> 00:49:55.240
( Laughter )

00:49:55.239 --> 00:50:00.329
>>All it takes is 50, 2,000 x 2,000
pictures and the video card just...

00:50:00.329 --> 00:50:03.250
>>That's it, yea and the video card is pretty done.

00:50:03.250 --> 00:50:07.000
Now I'm going to try and reduce
the number of textures on this

00:50:07.000 --> 00:50:15.519
and see if it'll come back up...and you should
start to see that green line rise back up.

00:50:15.519 --> 00:50:18.469
There we go...

00:50:18.469 --> 00:50:19.279
>>Yea, throw more away.

00:50:19.280 --> 00:50:22.140
I think you've got the perfect working set now.

00:50:22.139 --> 00:50:31.349
>>Yea...see so now we've got where the card is, the card
is full but we're not doing a lot of paging activity.

00:50:31.349 --> 00:50:31.940
( Pause )

00:50:31.940 --> 00:50:37.530
So that's where you can use driver
monitor to go in and look at what's going

00:50:37.530 --> 00:50:41.550
on with your app when it starts to chug like that.

00:50:41.550 --> 00:50:52.070
So there's a lot of different aspects to where performance
is going and...you know, this is one aspect of it;

00:50:52.070 --> 00:50:58.070
definitely the falling off the hardware fast path
is an aspect but usually the symptom of that is

00:50:58.070 --> 00:51:01.940
that you get this instant change; you're
going along at a very high frame rate

00:51:01.940 --> 00:51:06.559
and then instantly you're several orders of
magnitude less.

00:51:06.559 --> 00:51:13.969
This kind of a symptom is, or this kind of a problem
with the symptoms of it are that you slowly degrade

00:51:13.969 --> 00:51:17.459
and then chug, chug, chug and then
kind of the whole system starts to bog

00:51:17.460 --> 00:51:21.530
because you've got the one graphics
card and you're using it all up.

00:51:21.530 --> 00:51:28.140
So that's where you'd want to pull
out driver monitor and look at that.

00:51:28.139 --> 00:51:28.609
( Pause )

00:51:28.610 --> 00:51:33.450
Okay, with that back to you Kent.

00:51:33.449 --> 00:51:36.689
>>Thanks. Okay, switch back to slides please.

00:51:36.690 --> 00:51:44.039
So let's spend a second talking about paging and video
memory and driver monitor. One thing that's important

00:51:44.039 --> 00:51:49.199
to remember is driver monitor is shared through the whole
system so it showing you just the stats from the hardware;

00:51:49.199 --> 00:51:57.919
it's not showing stats from just your application so the
free video memory is, you know, shared between everything

00:51:59.019 --> 00:52:03.829
and there's a limited amount of it and what other
apps do can affect how much you have available

00:52:03.829 --> 00:52:09.299
to you at any particular time and some things
that can get you into a paging situation

00:52:09.300 --> 00:52:18.200
or you know using a bigger working set
of textures than can fit at one time.

00:52:18.199 --> 00:52:26.889
Dirty objects is what we call objects that have been created
and modified on the video card; so one thing that piece

00:52:26.889 --> 00:52:31.609
of information that we can give you is that sometimes
those get treated differently when you're paging

00:52:31.610 --> 00:52:38.940
so if you have a lot of modified objects, dirty objects
and those...and you need more video memory those have

00:52:38.940 --> 00:52:44.090
to be copied back down to main memory before that
video memory is available; it takes longer to page

00:52:44.090 --> 00:52:52.059
and sometimes some objects are preferred over dirty objects
and that can affect your performance and a way to combat

00:52:52.059 --> 00:52:56.070
that is if you have these modified objects is to, you know,

00:52:56.070 --> 00:52:59.140
make sure that you delete them as
soon as you're finished using them.

00:52:59.139 --> 00:53:03.839
You know with textures it's not to big a deal to just
abandon them in memory because you have a copy back

00:53:03.840 --> 00:53:07.730
on the main memory, the CPU side we call it.

00:53:07.730 --> 00:53:13.119
So you have a copy but with these dirty, dirty objects
they have to get copied back so sometimes it'll say,

00:53:13.119 --> 00:53:18.769
"It's faster if we just boot this out;" So it
affects your paging and so you have to be aware

00:53:18.769 --> 00:53:21.900
that if you use a lot of dirty objects that can affect that.

00:53:21.900 --> 00:53:29.760
You can use driver monitor and Xray also has the same
driver monitor stats in it and sometimes it, you know,

00:53:29.760 --> 00:53:33.970
we like this because it monitors the whole system
all the time and you can run multiple applications

00:53:33.969 --> 00:53:38.099
but there's a time to use Xray when you know, you're
trying to profile your app and you want to see it

00:53:38.099 --> 00:53:41.069
versus the other things that your
application's doing at the same time.

00:53:41.070 --> 00:53:46.210
It's also interesting in that point of view.

00:53:46.210 --> 00:53:52.840
So to reduce your paging, if you get in a paging situation
and getting in a paging situation is not to hard to do

00:53:52.840 --> 00:53:57.460
on a video card that only has, for
instance, 32 or 64 MB of memory.

00:53:57.460 --> 00:54:00.030
I don't know what the lowest configuration
supported by Leopard is

00:54:00.030 --> 00:54:03.660
but I bet there's some 64s and there might be some 32s.

00:54:03.659 --> 00:54:08.190
So, reduce your texture size; so with these
textures an obvious thing I should have done

00:54:08.190 --> 00:54:14.329
with this application is taken the texture, you know,
use your favorite method to scale it down, you know,

00:54:14.329 --> 00:54:19.349
they're being drawn this big on this screen; there's
no sense to have to be 2,000 x 2,000 on the card

00:54:19.349 --> 00:54:22.969
so you shrink them down when you
create them; that would be easy.

00:54:22.969 --> 00:54:30.569
I can compress them, use the texture compression features
of OpenGL and as I mentioned before you want to get rid

00:54:30.570 --> 00:54:34.210
of those dirty objects as soon as you can.

00:54:34.210 --> 00:54:42.190
For a usage pattern where you create something
and use it once and then modify it, use it again,

00:54:42.190 --> 00:54:48.909
modify it and use it again or that you're only going
to use it once ever we provided a lot of control

00:54:48.909 --> 00:54:54.589
for the different types of objects that you say, "Oh well
this one is only used once therefore just use it in place

00:54:54.590 --> 00:55:02.050
and don't upload it to the video card" and for textures
that's our clients storage extensions and for vertex

00:55:02.050 --> 00:55:08.030
and pixel buffer objects you can
mark them with the stream draw hint.

00:55:08.030 --> 00:55:13.110
There's a lot of documentation about this that's
really good on the developer.apple.com website.

00:55:13.110 --> 00:55:20.300
There's a document called Optimizing OpenGL Data Throughput
on Mac OS X and then in the OpenGL programming guide

00:55:20.300 --> 00:55:25.000
for Mac OS X that's also up there, it goes into
extensive detail about client storage textures

00:55:25.000 --> 00:55:30.619
so if you're interested that's a
great way to go check that out.

00:55:30.619 --> 00:55:34.789
So, when you're faced with a performance
problem and when we're faced

00:55:34.789 --> 00:55:39.699
with a performance problem in house,
you know, what do we do?

00:55:39.699 --> 00:55:43.109
Well you have to use process of elimination.

00:55:43.110 --> 00:55:47.840
There's several places that your
system can get bottlenecked.

00:55:47.840 --> 00:55:54.240
CPU, you know if you're doing too much work on the CPU
and the graphic cards bored or vice a versa, you know.

00:55:54.239 --> 00:55:59.639
You might be doing little work with the CPU
but the graphics card is extraordinarily busy.

00:55:59.639 --> 00:56:06.409
You know, and texture creation is another bottleneck
that we spend a lot of time addressing

00:56:06.409 --> 00:56:13.069
and another problem is once you fix one thing then you can
move and you're bottlenecked at a different point then.

00:56:13.070 --> 00:56:17.940
You know, you may be CPU bound and you fix
that and all of a sudden you're fragment bound.

00:56:17.940 --> 00:56:20.190
So then you have to iterate on that.

00:56:20.190 --> 00:56:24.630
So diagnosing CPU bound is probably pretty simple.

00:56:24.630 --> 00:56:32.849
You know you hunch top or command line guys so we use
top a lot but activity monitor works just as well.

00:56:32.849 --> 00:56:38.460
Some of the people that work in my group have
the activity monitor gauges on their menu bar

00:56:38.460 --> 00:56:44.889
and they're just watching it all the time to see what
the CPU is doing when they're running their code.

00:56:44.889 --> 00:56:53.219
You can use OpenGL Profiler to exam the percentage of
time that you're spending in OpenGL versus the percentage

00:56:53.219 --> 00:56:56.049
of time you're spending in your application.

00:56:56.050 --> 00:57:03.769
Shark is also a good way to do that; you can look and see
what samples fall where and that gives you a good indication

00:57:03.769 --> 00:57:10.829
where to start, you know, and to address CPU
bound applications, you know, multiple CPUs,

00:57:10.829 --> 00:57:13.590
multithreading is a great way to get some more.

00:57:13.590 --> 00:57:17.840
So we're going to touch on texture problems.

00:57:17.840 --> 00:57:21.280
I think it's been touched on some
of the previous OpenGL sessions.

00:57:21.280 --> 00:57:24.769
In a paging scenario like we showed, you know,

00:57:24.769 --> 00:57:28.449
you can diagnose that using driver
monitor; it's about the only way to do it.

00:57:28.449 --> 00:57:34.699
I mean you might suspect but that can tell you for sure; if
you're a green line the free video memory line gets close

00:57:34.699 --> 00:57:43.509
to zero you probably are going to start noticing some
lagging performance and maybe if not with you application

00:57:43.510 --> 00:57:45.860
when you start switching applications,
switch to other things

00:57:45.860 --> 00:57:50.579
that you're definitely going to
start to notice the system lagging.

00:57:50.579 --> 00:57:56.369
So, sometimes people have problems when they're
trying to create their textures or read them back

00:57:56.369 --> 00:58:04.059
and these problems we call format commercial problems
so if you run Shark like this and you notice

00:58:04.059 --> 00:58:09.929
that you're spending a lot of time in the GL image
library; when you're in the GL image library that means

00:58:09.929 --> 00:58:17.849
that for whatever reason OpenGL is having to copy data,
convert it from one format to another or copy it; so,

00:58:17.849 --> 00:58:21.139
you know, when it's spending a
lot of time there it's converting.

00:58:21.139 --> 00:58:27.839
You know, when it's spending some time there it's probably
copying; so copying can be addressed by using extensions

00:58:27.840 --> 00:58:35.390
like client storage and the conversions
you have to understand what the hardware,

00:58:35.389 --> 00:58:38.900
your target hardware can negatively
process and there's a few formats

00:58:38.900 --> 00:58:41.789
that are well supported and most
people stick to those formats.

00:58:41.789 --> 00:58:47.750
There's also other formats that are supported but
sometimes it varies across configurations, unfortunately,

00:58:47.750 --> 00:58:52.989
but it's the capabilities, the native capabilities of the
hardware; so if you see this come up then that's a clue

00:58:52.989 --> 00:58:55.129
that you're converting data and you probably don't want to.

00:58:55.130 --> 00:59:00.170
>>So what happens when you get GPU bound?

00:59:00.170 --> 00:59:08.170
Well, fragment bound is actually kind of easy to figure
out; if you have your window, you shrink it down,

00:59:08.170 --> 00:59:15.050
your frame rates goes up, then you have, then you're
spending a lot of time doing fragment processing.

00:59:15.050 --> 00:59:21.220
So that's an easy one to diagnose, fixing
is another story but it's easy to diagnose.

00:59:21.219 --> 00:59:25.809
So some things that can make you
fragment bound is blending, for instance.

00:59:25.809 --> 00:59:31.110
It's, you know, probably 3X the amount
of fragments you have to process

00:59:31.110 --> 00:59:34.140
because when you're not blending
you just write on, you know.

00:59:34.139 --> 00:59:39.650
When you're blending you calculate one, you read what's
there, then you calculate again and you write back;

00:59:39.650 --> 00:59:43.099
so blending adds a lot of fragment processing overhead.

00:59:43.099 --> 00:59:53.849
Depth complexity also has an effect on your
fragment bound performance; if you, you know,

00:59:53.849 --> 00:59:58.989
obviously if you can use depth test
or something to early discard things,

00:59:58.989 --> 01:00:04.399
that's a good thing to do; it reduces
the back end of your pipe.

01:00:04.400 --> 01:00:12.730
Vertex bound on the GPU is probably a little bit
more difficult to diagnose because the vertex

01:00:12.730 --> 01:00:18.050
the amount of vertices you issue has a real effect
on the amount of fragments you're processing

01:00:18.050 --> 01:00:20.890
but there are some things that you can do.

01:00:20.889 --> 01:00:25.210
You can try simplifying your geometry, you
know, feed less, feed less triangles in

01:00:25.210 --> 01:00:30.340
and see what happens, see if your performance goes back up.

01:00:30.340 --> 01:00:35.300
You can simplify your vertex process if you
have complicated set up of fixed function

01:00:35.300 --> 01:00:39.860
or complicated shader; you can try using a simpler shader.

01:00:39.860 --> 01:00:45.380
I mean your drawing will be wrong but you can see if
your performance goes up and see it that's your problem.

01:00:45.380 --> 01:00:52.590
One strategy is to reuse shared vertex elements
and by that we mean that vertices that are shared

01:00:52.590 --> 01:01:01.740
between triangles you can...use strips and
fans to combat that situation, I guess.

01:01:01.739 --> 01:01:07.699
DrawElements is if you have a big set of
geometry and you're picking parts of it out,

01:01:07.699 --> 01:01:13.589
if you use DrawElements then you're reducing the amount of
data that you submit to OpenGL reducing the amount that has

01:01:13.590 --> 01:01:19.240
to be copied up to the card every
time that you submit geometry.

01:01:19.239 --> 01:01:26.489
So to sum up here, you know, think of terms of
stalling the engine; try not to do it, you know,

01:01:26.489 --> 01:01:34.619
submit your data in big chunks; as few function calls to
OpenGL as possible; you know, don't flush unless you're

01:01:34.619 --> 01:01:38.009
in one of the situations that requires flushing.

01:01:38.010 --> 01:01:41.480
Shadow your GL state; if you keep
a copy of what the state is

01:01:41.480 --> 01:01:47.699
in your application you can avoid redundantly calling OpenGL
with the same state and you can avoid calling glGet.

01:01:47.699 --> 01:01:50.179
It's a win, win situation.

01:01:50.179 --> 01:01:54.149
So, and also use these tools we
showed you and today if you're here

01:01:54.150 --> 01:01:57.630
and you have time we'll be in the lab from 2:00 to 6:00.

01:01:57.630 --> 01:02:02.960
We'd be happy to sit down, there's going to be a ton of
us there, probably a dozen; we can sit down with you,

01:02:02.960 --> 01:02:08.269
run the tools on your apps; you know, we can just
talk about how you're using OpenGL if you want to do that

01:02:08.269 --> 01:02:11.219
or we're there for specific problems
or issues that you want to talk over.