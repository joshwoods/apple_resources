---
Title:  Improving Your Video With Professional Preprocessing
Year:   2007
Web:    https://nonstrict.eu/wwdcindex/wwdc2007/601/

[!] This transcript has potential transcription errors.
---

Good morning everybody and welcome to session 601, Improving Your Video With Professional Preprocessing. And to walk us through the involved process of really preparing your media for compression is a gentleman named Cliff Wootton, who is our resident expert on the subject. So, Cliff, I'll hand it over to you.

( Applause )

Hi. Good morning. Thank you Steve. Okay. Well we're going to talk a bit about preparing your video for compression. And as the previous speaker said, this is a subject that you could spend days talking about. And, in fact, when I give this course at a college in London, we spend pretty much a whole day just on this. So video compression is like this, it's like trying to get an elephant through the eye of a needle. Don't worry about camels that was for the Bible. We're going to deal with elephants.

So we're going to talk, in this session, mainly about the preprocessing before we compress the video. It's about 90 percent of what you've got to do, but it's very necessary. And it's very, very likely that the lower the format you're going to use, safe for web or portable video, the more preprocessing you've got to do. It's less likely if you're doing Hollywood movies because the formats that you use there are producing much better quality footage and you're going out through higher bit rates.

It's important to think about your workflow. The most important thing is to make sure that you don't do something later on that undoes something that you've done earlier on in the process. So each step should be nondestructive. Don't perform a process that undoes something. Know your end goal so that you can make better choices. Don't try to accomplish too much in one step. Don't confuse the things that are happening in time with things that are happening in space. And be constantly working to clean up the video, to remove the noise and reduce complexity.

So here's an example workflow. Now you may change this around according to what you're trying to do. The green stuff goes on before we start to work on the material and the orange and blue sections are video and audio, which can be in parallel. It depends on the size of your team. And then finally we get down to the purple section where we output the video.

Now although we think of this as preprocessing, a lot of this actually could be pushed further back into the process. If we can guide the guys shooting the stuff in the first place, they can produce material that we can compress more easily and have to preprocess less. So, get involved at the planning stage if you can. Think about the target platform. And if it's a band limited transport, say a mobile phone, try and shoot something that's sympathetic to what you're trying to achieve.

For example, if you've got a talking head, choose a stationary background. This helps a lot because there's much less change from one picture to another and the compression process is all about chopping the picture into small pieces and looking for similar items and throwing away the duplicates. So with a still background, you don't have as many changes. It's quite important what the, excuse me, it's quite important what the presenter wears. If he's wearing a checkered shirt, this is going to introduce all sorts of artifacts into the movie, so a plain back shirt on a stationary background is a good idea.

Choose good transitions. If you take two images, sequences, and do a dissolve, what's going on here in the middle is a change from every frame to the next and there's not much redundancy in that picture. You're not likely to find some duplicated macro blocks looking forwards or backwards. So instead of doing a dissolve, use a wipe. Here's an example. Now that's actually two still pictures. Now what I've tried to do here is produce something that any artifacts you see are a result of the compression, not because they're moving images in the background.

And if you look at this, there's an area of sky and that doesn't transition very well. It's very crunchy. Now even though this is H264, and the codec is very good, I had to work quite hard to make it put the artifacts in. it's so good now that you have to try very hard to make it look bad. But you can see that dissolve is really crunching things up.

And there's a little crunchiness that happens just before dissolve begins. This is because the codec is preparing the buffer and emptying things out. Even choosing the kind of transition can make a different in these marginal situations. If you're on a borderline case where you're just on the edge of losing video quality, choosing a vertical wipe rather than a diagonal one is better.

And you can see where the macro blocks, marked out in red are the ones that are changing from one frame to another. So if you can reduce those changes, that's good. Now when we're bringing the video in in the first place, this can effect what we're able to preprocess.

And I think part of this preprocessing goes way back to the ingesting stage. And so if you sample things badly, if you start with bad quality at the beginning, you've got nothing left to work with. So you have to pay attention to this right from the get go.

Now here, what we're looking at is the difference between an analogue picture and a digital picture, in fact, the same applies to sound. And the critical thing is up there in the top right where the analogue wave form is constantly changing, but we only have a limited number of values that we can choose for digitizing it. And also a limited number of places that we can sample. And the difference is what we call quantization errors.

The other thing that we have to be careful with, how much we're able to get in the way of detail. Now, to get a one megahertz square wave, you'd think well, we'll just sample it at two megahertz, but actually that's not enough, we wouldn't get the edge. And you can see the amount of detail going across there at a six megahertz sample there. That's much more fine detail. So if we're not sampling at a high enough rate, we lose the detail and it all starts to get very blurred.

But a bigger problem is aliasing. Now this is where you sample at a rate that is very close to the amount of detail that's in the picture. Now here you can actually see that we're taking a sample at different points in the wave form. But when we recover it, we get a wave form that is absolutely nothing like what we originally started with, and this looks quite odd in the video.

And this is what it looks like. Now the Animusic guys let me use a bit of this because their stuff is probably the hardest test for a compressor to work with. And you can see on the verticals there's this kind of movement going on, especially when they're not quite vertical.

This is the aliasing that happens if you down sample. And you can see that, there on the verticals of those columns and especially on the pipes. Okay, so if you're not sampling it well enough in the first place you're going to get artifacts coming through, and you can't do anything about those. There's no post processing that you can do to fix that up.

Another one that happens with old video footage is color bleeding. And you can see here, this is some of the Ducati footage that they're using for Final Cut Pro. Now this is actually film that's been turned into video, but somewhere along the line the color information has got so blurred, that it's kind of washing out of the outlines of where it should be. And if you were going to do any work on restoring that, you'd probably take all the color out altogether, fix up the brightness, make a nice black and white picture and then go back and recolorize it.

Adjusting film is quite a challenge. You have all sorts of artifacts that happen with film. Gate weave is one of the things you notice when you watch a movie on TV. You can see the titles moving around a little bit. Dust and scratches, obviously. And with older film, you have a fading and motion problem, where the colors are actually sort of washing out. You can fix some of that up, but if it's really extreme, you might have to do a lot of color correction on that.

So gate weave is a real problem because it's introduced in the camera and also in the projector or tele-cine system. And they don't cancel each other out. And that compound motion is complex. Now if we think about just the discreet process of preprocessing, you might think well, this happens after the guy has finished editing the clip and before we compress. But actually, with some of the new capabilities in final cut, these steps can move further back into the production process. And the editor may well have stabilized that footage for you.

Dust is quite easy to remove, provided you try and do that early on. Once you start to change the size of the picture or move it around, the dust is going to go blurred and it's going to be harder to find the edges. So when those nice, sharp dust particles are easy to remove, once they've blurred, they're much harder. And scratches, obviously. This depends on the age of the material. If it's some old archive footage, it could be badly scratched and you need to do a lot of work on that, perhaps, to get that out.

The video, as we heard earlier, that could be even more complicated. There is so many different formats, but the hardest thing is to get rid of that interlacing problem. And I'd say, actually, if you're doing stuff with news footage for instance, that's where most of my background is, getting any text encoded properly is also very difficult.

And any noise that's in the picture just increases the bit rate because your codec can't tell the difference between noise and genuine detail, so it's going to do it's best to preserve all of that. And of course, if you're mixing stuff from a variety of different countries, you can have some problems with frame rates if you're mixing American and European content.

The previous guys told you a little bit about chrome and lumens of sampling. There's a macro block that shows you the lumen sample of full resolution and the color information sample to the lower resolutions there. You're already getting some compression going on there. And you can practice to see the effects of this if you play with Photoshop and just take an image and move it into the LAB color space and start defocusing the color channels, you can actually see how far you can go with this. Actually you can get quite extreme with blur and the color information.

The next problem with video ingest is getting good quality stuff in and it's not always just a question of just plugging your video player into a video card. Even some of the quite expensive video cards don't do any time based correction. So you can get some rather difficult synchronization problems.

Now I would warn you, the next screen is going to flicker a little bit, so if you're susceptible to that, you know, please close your eyes. And what we're going to demonstrate here is this is what it looks like if you haven't got good vertical synchronization. If you see this happening, you need to put a time base corrector in to fix the vertical sync.

The next one is horizontal sync. And, again, this is difficult to solve. You can't, you don't really want to go back and start editing frames to fix that. So this is the point, if you see these artifacts, where you need to go out and buy a little bit of extra hardware.

If you see this artifact, this is probably because your video recorder is not set up properly and perhaps it needs the service or repair. And you get this weird little sort of synching problem on the bottom if the tracking is not adjusted correctly. Now if someone's handed you this footage and you can't go back and redo it, then maybe you can crop this out yourself, later. But if you see this kind of tracking, this is gross sort of misalignment of the tracking, you've just got to set your video recorder up properly so that you don't see this. You can't fix that later either.

Now special complexity is something that makes the encoder work very, very hard. It may be that what you're trying to encode is complex, the Animusic stuff is very, very complicated video. But the complexity could come from the interlacing or it could come from the noise. You could have film grain there that's making the picture unnecessarily complex.

We can probably alter this after the edit is finished, but we might be able choices when we're editing and put in different kinds of effects. So some of this stuff is going to be very easy to compress. If you have a clip like this, in this case I've purposely chosen something that's black and white, there's no color information.

It's a background that's stationary. The only thing that's moving is the bird. So from one frame to the next there's going to be a lot of macro blocks that are the same. It'll compress very, very well. But this won't. you have, from one frame to the next, you have the train moving rapidly towards you and there's areas of the train that are getting larger as it's zooming in.

and so that area, the picture's not going to compress very well at all. This might compress slightly better because of the cyclic nature of what's going on. It might appear complex at first, but actually it's a repeating sequence and it depends how long the group of pictures are that you're encoding as to whether that cyclic nature is beneficial.

But in the end, when you've got something this complex, you're going to be challenged to encode this. And if you get a DVD from Animusic and listen to the director's commentary, they explain a lot about how they encoded this material. Excuse me. This is very interesting because they did this in MPEG2 and went to a very high bit rate.

Now temporal complexity is really where we have rapid changes in time. And most of these difficulties come from this interlacing problem. It is particularly difficult to compress interlaced material. Even if you think you're deinterlacing and turning it into a progressive raster, it's not really deinterlaced. You still want to do some work on those pixels.

And the problem is, really, that when the camera takes a progressive picture, it's taking a full frame of picture straight away at one instant in time. And when it's taking an interlaced picture it takes a picture for the odd lines and then some time later it takes a picture for the even lines, so there's some time difference between that. But it's that time difference that causes the problem. Things can move in the frame.

So let's just look at an interlaced raster. You have the alternate fields coming down here, the black one and the gray one, starts at the top, works it's way down and then goes back up to the top. And the interesting thing here is that you have two lines that are only half width.

And you might think that you could just crop those off, and as well you might if it's going to be a progressive output. But if some time later you're going to turn that back into an interlaced picture, you may just have moved everything up by one line, and you suddenly changed the timing of when the picture information is going to appear on those lines.

So as something might have been in the alt field when you ingested it, you crop it and move things up and reinterlace it, suddenly it's moved to the even field. So you have some field dominance problems. Progressive, on the other hand, obviously is much simpler. And it's easier to film it, it compresses better, it's much easier to work with.

The other issue is if you're converting between frame rates, just between American TV and European TV, you have to do this interpolation on a frame by frame basis, in fact, on a field by field basis. And you can see that after, six fields, three frames, you're out of sync. Your phase is completely ran the other way. So converting between these two timings is quite a challenge and you need some very sophisticated software to smooth that out.

So your interlaced material is basically like this. You start with the red ball on top there, it's split into two halves and recombined. And that's fine, provided that everything is stationary. But when it moves, you get this. And it looks like this on the screen. So you can see there are parts of the bus that are actually not bad. The ground and the sky are actually okay. But where the bus is moving you have this combing artifact.

And that's because on one field, the bus was here and on the next one it had moved about a half a meter. The other problem you have with interlacing is if you start putting computer graphics on to the screen, you have to be careful with just putting a single line.

If you draw a one pixel line, it's only in one field. If you draw a two pixel line, it's in both fields, but their not displayed at the same time. So the trick is to put a defocused line in. and this is what a single line looks like. This is slowed down about 25 to one, so what you see is a flickering line. It's very hard to watch.

And maybe, I'd argue, that this is slightly more annoying. And you see this sometimes on news graphics if you do infrabursts, weather shots and things, and you're not careful with how you draw the lines on the screen, you get these artifacts popping up. So the trick is to just blur the line a little bit.

Now although we're seeing this in slow motion, when that's playing back at full frame rate, it looks a lot nicer than that. So deinterlacing is tricky. And if you see a frame like this, where those drumsticks are moving rapidly around all the time, try to find some kind of interpolation date that you can put in there to correct it is a real challenge. And even when the compression software has done some work on it, it's not perfect, but at least it's better. As I said earlier, you have to be very careful about field dominance.

And if you do anything wrong with this video and spoil the field dominance, you get this very strange, what we call a twittering timeline. So normally you'd expect the fields to progress in a nice orderly manner. But if you get the field dominance ran the wrong way, it jumps forward two fields, jumps back one, jumps forwards two, jumps back one.

And this is very hard to sit in front of. You don't quite know what it is that's wrong, you just know it's wrong. It's very disturbing. And that could be introduced in a variety of ways. You could introduce it quite accidentally just by cropping, styling and moving the image.

So really what we want to try and aim to do is get a progressively scanned version of that footage so that we can do something with it. If you want to get footage off air or from a DVD or from other sources that's already encoded, now obviously we never recommend that you reencode footage because you just add more artifacts to those that are already there. But you need to go through a series of steps.

And down near the bottom there, there's one approach to getting progressive, which is called field doubling, where you take the two fields and you just copy them so that you end up with two progressively scanned frames with both fields in. it's kind of like a double frame rate. And this is very like what movie projectors do in cinemas. They actually shoot 24P, but they project 48P.

but the one thing that we always seem to forget it setting this high quality thing. And you just don't think of doing it. So if you load that video clip into QuickTime Move Player and go and command J and look at the properties panel, there's a little check box down at the bottom there called high quality, and it makes all the difference.

I've spent quite some time doing some conversions from some old MPEG2 footage and I was constantly frustrated by the quality I was getting. It just didn't look right. I knew I was doing something wrong and it wasn't until I found this checkbox that suddenly the picture sharpened up.

Now the previous speakers talked in some detail about inverse tele-cine. And I'm going to go through this a little quicker than I might have otherwise, because they've already covered that. But there are some problems with doing things in the right order. If you inverse tele-cine, try and remove that pull down, and you've done it after you've done some scaling, or after you've tried to do some processing, perhaps a bit of blurring on the image or applied an affect, what you've probably done is moved some pixel information from one line to another. And so you get some pollution of the pixel values in each field, they've been polluted from the other field, so when you deinterlace, you get some strange sort of noise patterns appearing that look like ghost images.

So if you are going to deinterlace and remove the pull down, you want to do it early on in the process before you start messing with the image and doing any processing on it. So that's quite an early step to do this. Now they already went quite deeply into this, so the trick is don't do any image processing, noise clean up or filtering or putting effects onto this until you've removed the tele-cine pull down.

This is what four of those frames look like when they are tele-cined. And there are a variety of ways of doing this. Now if you just averaged, you'd get this kind of blurred mess. It is horrible, so you just don't want to do an averaging deinterlace. That's the simplest deinterlace and it works well on still footage or things that aren't moving very quickly.

Field dropping is another approach. You basically throw one of those fields away. But what you're also doing is throwing away half of the vertical resolution. So you've only got half of the pictures left in the vertical access. And it doesn't properly do the pull down either. You end up with an extra frame, the ones that are marked in red that you still need to remove. So you do have to do this properly. And if you do it properly, you get a pretty good result provided you're doing this early on.

So by this point, you've removed the interlacing artifacts from the film process, and you've also deinterlaced it if it came from a video source. So now you can start working on the image quality. Start doing noise removal, dealing with the spatial problems, things like dust particle, scratches. So, this is an extreme example. I basically took a still picture and introduced the noise here. You wouldn't normally expect to find noise that bad unless this was some very, very old footage.

You'd have much less to deal with than that. So the noise removal filters would probably do quite a good job. And what you try to do is get from that noisy one on the left to the restored picture on the right and try and remove this pattern of dirt and dust and scratches. But if you try and do that dust removal after you've messed with the scaling, the dust particles are going to be like they are on the right hand side, a bit blurred and much harder to remove.

So denoising and removing dust, again, is something that you want to do earlier in the process rather than later. Here, and if you can see this from the back, but if you look closely that image is just gently rocking from side to side again. I took a still picture and tried to introduce something that looked like gate weave. And so there are two compound kind of motions going on there. And to clean that up, you need to track that and stabilize it.

Now this depends really on the kind of footage you're shooting. If you've gone out and done a shoot which is handheld and that's the kind of look you're going for. You don't really need to do this. You need to look at all these different preprocessing steps and think well, which ones do I need to apply? Sometimes they're all necessary and sometimes only a few of them are required. So, you would look for an object in the frame and stabilize that.

This tends to need to be done on a clip by clip basis. And I think this is the sort of thing, maybe, that should be done early on, perhaps before you've edited, which kind of forces you then to want to do the dust clean up early on in the process before you're editing. So you can see now that they preprocessing really isn't something that you can always do after the edit.

Then you have noise that you can remove. Now some noise patterns are stationary, so this would be spatial noise and you could just put a filter in. perhaps you could get rid of this by a little blurring. I'd apply the blurring in the horizontal axis in preference, rather than the vertical.

If the noise changes from one frame to the next, then it's a temporal noise pattern and it's a good trick to use, you can use film grain removal filters. It isn't film grain, but it looks like film grain as far as the compression software is concerned. So, get the order right. Do the gate weave correction after dust removal because the dust was probably there as the film was ingest in the first place and imaged. And if you're going to do any warping, kind of do that later after you've cleaned it.

Now again, the picture size that you're aiming for is maybe something that you want to feed back to the early part of he process. If you're shooting a podcast and you know it's going to go out on an iPod, you can make some decisions about what you shoot at the very outset.

But if you need to scale some stuff that's been shot for another purpose, something that you're repurposing, if you want to do it two to one, reduction in size, dropping a field will give you that two to one reduction in height and then you can scale the horizontal separately, and it'll also do the deinterlace at the same time.

So there are times when you can combine these steps and get a win, but it really depends on the context. You have to know where you're aiming to be at the end of the process. You might think you can just scale a picture, but you can't. I mean if you go out and shoot a soccer match with a high definition camera, by the time you just scaled that down and put it on a mobile phone, you probably can't even see the ball. So you need to think about framing and composition.

So now your picture size, and these are just a few examples, don't get caught up in the sort of specifics like the sizes. I'm just trying to show some relationships. And the 400 to 405 is something that we had in the U.K. years and years ago and a lot of very old shows are actually recorded in that format.

High def, in a variety of different sizes and configurations. And of course, those are all quite different to PDA devices. This can rotate on it's side, I don't if Phone is represented by the outer one there, it's about that size. But in other mobile phones are more square. And different mobile phones from different manufacturers have different sizes and so all the Nokia phones seem to be one size, and all the Sony phones seem to be another size.

So making your clip fit one mobile phone doesn't necessarily mean it fits the others properly. So do you decide to scale first or crop first? Well, there are times when you would want to crop early on in the process. Perhaps there's some gross stuff going on around the edges, if you crop that and just do a quick scale, it arrives at the size you want. I intinttively feel that it's probably better to scale it first, rather than crop it, because the mathematics for calculating size is just a little bit more complicated. Then if you're working in TV, you might have to deal with different aspect ratios.

This is something we wrestled with quite a lot in BBC News. We found out actually that a compromise of 14-9 aspect ration was probably about right. We had a lot of footage coming in that was being shot 16-9 and some older legacy footage that was 4-3, or if you think about it, 12-9. But 14-9 is a good compromise for that, so we tended to work at a 14-9 aspect ratio. And then you just did a little bit of corpping for whichever format you wanted to put it on.

But it's a bit more of a problem with movie film, because that's much wider. And I think we owe something to film directors to try and preserve the intent of what they produced in the first place. Sidney Pollack makes quite an impassioned plea on this little movie that he puts out with one of his movies, and he explains exactly what pan and scan does to a wide screen movie and why it's bad. He explains how he tries to use the entire canvas, and if you window just a part of that, you're not seeing the movie in the way that he intended.

So my instinct is that it's good to crop things to the final size. You should do that after the scaling, I think. Now if you've ingested from an old analogue TV type or something else out there, you're probably going to have to crop some stuff off the edges There's really little point in trying to waste bit rate displaying all this stuff around the edges and at the top and bottom where the sync problems are. So you want to chop that off. That would normally be over scanned in a little TV set and you wouldn't see it anyway.

Think back to the interlaced and progressive rasters. There was that time taken for the video to traverse across the screen and then fly back again. And then when it got to the bottom, it had to fly back to the top. And that's time when the video circuits just turn off and there's no pitch room information. So though we might actually digitize a lot of that video, there are portions of this that we can't use. The vertical blanking and horizontal blanking periods are not accessible, they're not visible information. And yet, some ingest systems will ingest at least a part of that area.

And if we are cropping things down to try and get the picture as small as possible, then we can afford probably to just crop a little bit around the edges just to lose some noise on the edges of the picture. And if people have shot things properly, the orange area in the middle is where the action is, that's what's going on. The text safe area and the action area is a slightly different, but we should try and preserve that middle area and not crop anymore tightly than that.

Now there's other stuff that we should crop off as well, and if we have stuff that's going through a TV studio, there could be all sorts of timing information, time codes, test signals and that other stuff going on. And this is a plot from a Techtronics Analyzer that looks at the complexity of the macro blocks that are being encoded, and you can see at the very top of the screen there, there's some complexity there from the data signals going on, so certainly you should crop that off.

And if you look along the bottom, there's some more complexity and it's only in one row of macro blocks, so it's very likely that this is a sync problem at the bottom of that frame. And you can see here that the noise problems that are in the video are introducing a great deal of compression problems because they're using up some valuable bit rate. And down the right hand edge, there's also a slight increase in the amount of complexity in the macro blocks there, so actually, we're probably losing between five and ten percent of our capacity just in encoding noise at the top and bottom and right hand edge.

Here's another example from the Ducati stuff. This is film that's been converted into video and then it's been ingested. And you can see this horrible sync problem that's going on at the bottom. Now the white rectangle is actually the entire area of the video. So the ingest system has also ingested some blanking information as well.

So there's quite a lot of that we should crop off. We should certainly crop off this little piece at the bottom that's black. We don't want to encode that, that's just a waste of time. And we could probably crop off maybe six or possible eight lines off the bottom to lose that sinking, unless you wanted to go fix it. We should probably crop a little off the left and right. By the time you've done that, you've got a nice, clean picture. At least the framing of it's clean.

You may want to also spend some time removing the dust and scratches and the flickering effects from the film as well. There's lots of other things to fix there. But if you just look at the corpping of that, there's a lot you can do. If you can shave five percent of the picture off, that's five percent bit rate you've saved.

It's five percent more bit rate that's available for improving the quality for what you're doing. The same here. This is a still from a TV program. Again, you've got the sinking problem at the bottom. And over at the left hand side, you can see, it takes a little while to stabilize the color. It's not particularly good color until we're maybe 10 or 15 pixels in. there are also some other problems here with the electronic circuits actually responding to the hard edges in the picture.

So it really depends how valuable that footage is as to whether it's worth spending the time on doing this. If you're just doing a quick import job, convert it, get it out to the web very quickly and you're not too worried about the quality, things can move quite quickly. But if it's valuable archive or footage, you could spend a lot of time fixing this up.

You also want to be careful about the cropping, too, with this field dominance issue. So if you're cropping, try and crop pairs of lines. Crop two lines from the top and two lines from the bottom. Don't crop one from the top and one from the bottom. So think in terms of even numbers.

So after we've got the size and shape of it right and it's fairly clean, we can start to do some sharpening. I think the logical time to do this is after we've scaled it. And you don't want to sharpen things too much. There is a tendency for tele-cine systems to put in some sharpening. All of the tele-cine systems are based on a (inaudible) spot and CLT scanner and they tend to be a little blurred so they sharpen it to compensate for that. And it can be a little bit too sharp.

And if you sharpen things too much, you end up introducing the noise back into the picture that you so carefully cleaned out earlier. And you also introduce these kind of difficult edges. So we find a black edge that transitions very quickly to a white, it kind of overshoots, it hits that edge and it kind of bangs up, overshoots, and then settles back to the level that you want it. It's called ringing, if you think about in an electronic circuit. It's where the circuit is kind of incapable of doing that sharp change without kind of overshooting and settling back.

You want to avoid that. Apart from reintroducing the noise, you've got all this grain that's come back. Those edges are very hard to compress. They just use more bit rate. So don't over sharpen it. It's also only worth really sharpening in the brightness channel, doubly sharpening the color. So if you have access to sharpening just on the luminance do it there.

And this is the trouble with the tools, they tend to be rather preset in the way they work. You've got a checkbox to turn something on or off, you don't really have too much find control over things. And you may just want to apply a tiny little bit of correction somewhere, and you've just got to turn some major correction thing on or off. The noise cleaning process is either there or it isn't, and you've got all of it or none of it.

So once we've got it cleaned, sharpened, then we can start to equalize the color. Now this should be done quite late on in the process. The idea here is just to set the color level of those pixels. We're not moving the pixels around, we're not interpolating between the pixels. They shouldn't be doing any movement or sharpening or blurring of the image. We're just simply setting the brightness and the contrast level. We don't want to do anything after this that might alter the color values.

So we to know a little bit about color gamut's, television sets, display, pictures made of red green and blue, so that's an additive color model. Red and green together give you yellow. The film produces in the subtractive color model. The cyan and the yellow emotion, the film gives you green image. And there are colors on film that you can't represent on video and vice versa.

So you need to correct for that. Now the human eye is amazingly forgiving. I mean it's quite happy to see things that are kind of teleshifted quite a serious amount towards one color or another and the human eye kinds of compensates for this automatically. But what we must make sure is that all our color values fit between this legal range. We might have thought black is black, it's not really. It's just a very dark gray.

Although we're working with digital video, it tends to be digitized analog video. And so we have to provide some space at the bottom for the sync pulses to live. And at the top we want to avoid the video overshooting into that top range because otherwise we start to lose detail. So we've got to stay within this range of legal values.

And if we don't get this quite right, we get this crashing effect on the whites. So what we tried to do here is brighten this up too much. Now certainly the detail has come up nicely in the bushes behind the car, but we've lost all the detail on the bonnet.

We can see the driver inside of the car, but along side of the car it's kind of washed out. It's called crushing. It's called crushing, because if you look at this fractoscope in Final Cut Pro, you can see that the whites are all crushed at the top in the right hand side. So that picture on the left is the original picture, and the one on the right is the over corrected, crushed result. And you can see that we've lost a lot of detail.

Another correction that we might think of doing is gamma correction. And again, it depends on the footage. We don't want to apply this in a general way right away through the whole clip, but there may be certain scenes that are dark and need some detail pulled out. And a lot of digital cameras are very good, but one of their weaknesses is in the dark part of the scene. They don't do very well in shadows.

So we might apply a little bit of gamma correction. And in this example I've also shown what happens if you reduce the dynamic range, so if you got video that is in 10-bit or 8-bit and you wind the available bits down, or perhaps you reduce the contrast and stretch it back out again, you get these contouring artifacts.

And they look like this, you kind of lost that beautiful continues tone around the nose of that airplane there and it's gone contoured. And you see this a lot on DVD's. If you watch Lawrence of Arabia or The Abyss, the scenes underwater with the search light shining thought the water tend to be a bright source in the middle and a beautiful sort of continuous shading and the contouring just shows up. It's the same with the sun in the sky in The Lawrence of Arabia movie, you can see the sun but then there's this kind of shimmering contouring effect.

So probably of all of the tricks with this, the color correction is the hardest to get it exactly right. And obviously you can't do this if you're color blind. You might want to be a color correction expert but if you're color blind you can't do it. So there are a few things, well I'll say you can't fix or there just very hard to fix and you have to come up with new approaches to do this.

Text obviously is difficult, try to compress text in moving video is one of those area's I think codec engineers could usefully look at and do something for us. We need to apply a different level of compression around the text and compress it perhaps not as hard. Recognizing where that text is in the frame is quite a trick.

So this is what happens with text usually, you get this kind of weird mosquito noise going on around it and it doesn't seem to matter how good a codec you use or how high of a bit rate you choose, it still seems to be there. It's very difficult to remove that.

It's even harder if the text is moving. Now here you got an interlace problem where the text is moved a few pixels between fields and so there's no point at which you can grab that text and compress it nicely. So again if you have any choice about what you do with the infographics on the bottom of this and probably actually you wouldn't actually put graphics like that on iPods. But if you're compressing, say for DVD you might choose stationary text rather than moving text because it's going to compress better.

Then you got subtle differences going on between one frame and the next. Things that shouldn't be changing but they seem to be changing. Old movies have this, this mottling of backgrounds and so you can have a camera that's locked down, nothing moving in the scene and yet from one frame to the next, there's significant differences and what I've done here is subtract one frame from the other and magnify the differences so you can see it. And you can start to see the macro block structure coming through.

And if you don't get it right, if you try and push too much through that output buffer then the codec just bust and this is what they call blowing up. And you can see here that there are certain points where in the motion and the detail are just so much that the bit rate I am trying to aim at here, again I was trying to do this at about 2megabits with an H264 codec. Bear in mind that with adding music to this with about 8megabits on an mpeg2 codec so I should probably been aiming to this with H264 or at about 5.

You can see the thing breaks down. So what I am trying to do is show you the artifacts, that if you see these things going on then you can get some idea of where you got to go back to in the process to fix these things out. And of course you got to fix the audio as well as sweetening the audio and doing all sorts of other things, again it depends where your audio is coming from, if you ingested it from some old analog material, you may have hums, crackles, pops, various little things. Obviously Soundtrack Pro is going to help you a lot with this sort of stuff. You can fix a lot of these things up.

I ingest a lot of old legacy archive material and I find that things like bio sand soap just do a good enough job, maybe its not the best tool for it, but you know when you listen to it before and after its good enough for the sort of things I'm doing.

But you need to make sure that you don't' clip the audio in the same way you could crush the video, you can distort the audio by letting it overshoot. So look for the peaks in your audio, if the software is clever enough to find the loudest passage get it to find where that is and just mobile that thing so its just a little bit below your peak level and the experts record about 3DB's down from the 0DB point is about right.

So we're about there, we've seem to run ahead of time which is great because it gives us a lot of time for questions and answers. So let's just summarize a couple of things. It's about 90 percent of what we are going to do with compressing video, what you are going to do is look for the artifacts that I've demonstrated.

And when you find them diagnose what it is that's causing them and try and fix it as early in the production process as you can. Try and get back to the shoot, at least get back as far as the edit. But of course if you are doing this all on your own and in a single machine then you're a master of your own destiny and you can do the whole thing. Work in a logical order. Don't do something later on in the process that undoes the things you fixed earlier.

And bear in mind that some of these newer tools have actually moved the responsibility of these things to other members of your team. And so you're editor may actually be fixing these things for you. And as the guys earlier on said you can't have enough CPU power, too much CPU power or disk space. This stuff is going to eat your disk space and it's good to work in as high a resolution format as you can for as long as you can, but it is going to use a lot of disk and CPU power.

And you can find lots and lots of extra tools. Things like FFMPEG. Lots of useful things for cutting a piece of video up, converting it from one format to another, just applying a little bit of correction here and there. So there we are. I'd just like to say thank you to Steve here and a few other guys, Dave Cochlan, Jeff Garrard from Animusic. And it's over to you.

Yeah, are we ready for some questions?

( Applause )

- A little plug for the book here, this came out a couple of years ago actually and as we learn more about his I'm realizing that we need to start thinking about a new revision to this, but basically what I tried to encapsulate and what I am is what takes me a day to teach in college and took me a year to write about in the book.