---
Title:  Deploying Podcast Producer
Year:   2007
Web:    https://nonstrict.eu/wwdcindex/wwdc2007/531/

[!] This transcript has potential transcription errors.
---

Hello. My name is George Cook. I'm a consulting engineer with Apple Education, US Education. I couldn't be more thrilled to be here. Because this technology is just a fabulous vehicle for education, educational contact.

( Applause )

Also with me from Apple Europe is Eric Circlaeys and Eric's the demo God of the day. So, and Eric's going to lead us through some, some incredible demos. And he's been deeply involved with this project.

( Applause )

What we're going to talk about is we're going to do a little overview. If you weren't in Dave O's great session last, we're just going to do one slide to review that last session. And then we're going to jump into an architectural overview focusing first on infrastructure briefly and then getting into the architecture of Podcast Producer.

We're also very lucky to have with us today a couple of guest speakers from De Anza College and UC Berkeley to talk about their plans to deploy this technology. And then Eric will join us in a presentation of a project that he's involved in in Europe, which is a very large scale deployment of the technology.

So, in summary of the last session, Podcast Producer was designed to be an open and flexible platform. So it's more than just a product. It's really a platform, which means customization is its DNA. And it's designed specifically to streamline the capture and delivery of content. It's designed to offload that processing from the workstation, to simplify the experience for end users, because end users, as Dave stated in the last presentation, you know, there's just too many steps involved in getting their content published. And so it simplifies that interface of them and provides consistent results. For example, putting the university logo on every presentation.

And it feeds that publishing mechanism. So it itself is not the delivery tool, it sits in the middle but then it can feed into iTunes U, to a blog wiki, to a streaming server, etcetera. So let's take a look at the infrastructure that's required for Podcast Producer. The first thing that you need, as with any, many things in Mac OS X Server, is solid DNS, forward and reverse DNS. You've got to have that first. Next, Open Directory and Kerberos. As you heard in Dave O's session it's secured with Kerberos. Open Directory is used for access control lists. So you need to have Open Directory infrastructure in place.

You need to have a shared file system. A high performance shared file system is highly preferred. Xsan fills that niche and Xsan gives you the scalability that you'll, you'll need going forward with, with Podcast Producer. You need Xgrid. Xgrid is the processing engine behind Podcast Producer. And what's great about Xgrid is that it's very simple to scale just by adding additional processing nodes.

And finally, Podcast Producer, the command and control for the entire system, and then whatever publishing points you might have. So from Apple we'll have the wiki server, for example, as a publishing point. But it doesn't necessarily have to be part of your infrastructure. For instance, you may want to publish through iTunes U and that's another workflow that will be part of Podcast Producer.

So let's take a look at some of the scaling factors for a deployment. The first thing you have to think about are storage requirements. Well, DV, which is compressed but not highly compressed video is about 13GB per hour. So if you're going to archive that DV you have to start to think, how much storage am I going to need for that archival purposes?

If you want to deliver to Apple TV that's about 1GB per hour and iPod is roughly 500MB per hour. So you're going to have to look at your delivery types, the amount of contents you want to provide and start to scale your storage to meet those needs. And then processing power, again, Xgrid makes this really easy to scale.

Initially what you're probably going to do is take some of the workflows that you're going to deploy and you are going to benchmark those workflows. You want to run some media through the workflows, benchmark the workflows, and then say, Ok, this is great. We know what one takes now we have, you know, a dozen classrooms we're initially going to deploy and we want a target of one hour for the delivery of this content.

How many nodes do we need to have to support that? So then you just add these Xgrid nodes to increase your capacity. And finally, bandwidth, as I said Xsan, ideal for the backend of the system, because it gives you the bandwidth you need to process all this media.

So that's required for the Xgrid nodes as well as the Podcast Producer command and control server and then network for the submission of this content to Podcast Producer and the delivery and distribution out to your clients. So that overview. Let's jump right into the client piece of Podcast Producer. We're going to focus in on three areas, query, control and submit.

So the first piece, query, QuickTime Player, Podcast Capture, two things that are part of Leopard and then potentially your application may want to access a workflow. So how does that happen? First I have to find out what workflows I have access to. So I talk to the Podcast Producer server. Based on ACLs on the server it delivers the set of workflows, the list of workflows that I have access to.

Once I know which workflows I have access to, then I want to submit a file. So I go to submit a file, I contact the server, submit the file with the specified workflow. Now, how does that happen? Under the covers it all works with the pcast command line utility. QuickTime Player calls through that. Podcast Capture is simply a Cocoa app that wraps the pcast command. And your app can do the exact same thing. We're going to take a deeper look at the pcast command. There's a little screen shot of the command page for pcast.

Another thing that you can do with Podcast Producer is you can bind a camera, which is used for these headless lecture capture systems. In the application, the Podcast Capture application, the GUI, you can do this from a GUI standpoint. You can bind the local camera and it registers itself with the server, it's secure.

The reason it's secure is your application or QuickTime Player or Podcast Capture, they can query the cameras. Again, using ACLs to find out which cameras I have access to. So under the covers this is all pcast again. All of the starting, pausing and stopping of that camera is done via the server.

So that's how this camera agent is controlled. So at that, at this point I'm going to hand the clicker, well, you don't need the clicker. We'll just have Eric go to the demo. So Eric will give us the demo of the client side.

( Applause )

Thank you very much, George. I've got a question before starting. How are you today? Wow, excellent. How many of you have installed Podcast Producer this week and test it?

Great, excellent. What I'm going to do now is to give you a quick overview of the pcast command line. As you know, pcast is the tool behind Podcast Capture application, which means anything you need to do like controlling an agent or submitting a file with the workflow attached to it can be done very easily with no effort. So let me show that to you in action.

First of all, pcast is a very well documented command line utility with all the input and output descriptions you need to understand it's usage. So I'm not going to go into the details and read this with you but I'm sure you can do that after the session. But what I'd like to do with you is to highlight some of these commands and show you how to use this command line utility to control some of the cameras, for example, to get the stages or to submit a file manually.

So let's do that for example. What I like to do is to list all the cameras I have access to with my credentials. So I use the pcast command with the server name. So actually this one is podcastproducer.apple.demo. I'm using my account and actually I want to list all the cameras.

Boom! That's it, very simple. Actually there is only one camera I had access to, this one in Pacific Heights' room. What I can do is to get a live status about this camera. And exactly the same way I ask for stages of that camera, named Pacific Heights and I like also to get a live preview of it so I can ask it to actually a data preview.

So there is actually the description of my status of the camera. So I got a couple of properties and one that is actually very interesting is the preview here. So you can imagine, for example, if you use that command line in your own application you can easily grab this and actually show a preview of your application like I'm doing here using Safari.

So there actually is the preview. I was not in front of the camera but you get the idea. Ok. In Podcast Capture application in addition to do and control cameras to record a course, for example, you can also submit a file manually and attach your workflow. I like to reproduce this behavior using p  cast command line. So first what I need to do here is actually get the workflow I like to use. So, same as I did before listing the cameras I can list the workflows.

OK. Here are all the workflows I can use and, for example, this one named French 1 is the workflow I like to use in that demonstration as you can read in the description. OK. Actually I'm the only one, knowing what I want, using that demo, but, trust me, this is the one I recommend for that demonstration.

The other thing I have to pass to the command to submit a file manually are the user requirements that the engine needs to complete this workflow properly. As this is described here in that node, I need to provide a title and description. OK. For the sake of the demonstration I already prepared a file, metadata .plist file with this information. Let me just show that to you.

OK. So this is a file, a plist file, describing this title and description I have to provide to the pcast command line in addition to the workflow. I'm going to pass this as a parameter. So I define the title, name, manual submission demonstration. So I think I'm ready, with all this information, to submit it by it by now. So I can get this called the submit action, specifying a file. I'm going to use an advertising from Apple, Get a Mac. I'm sure you're all familiar with that one.

I'll use the workflow I've previously selected. And I'm going to use this metadata file with the title and description this workflow needs to complete perfectly, this one. Ok. And boom! File is submitted. And the results are going to be available in a few minutes on my RSS feed. And if you subscribe now to my feed then you'll get access to this content with iTunes. I can show, maybe, this to you using Xgrid.

Ok. And this is actually being post processed. Pcast command is really a magic tool. The beauty of it is it's very easy to integrate it with your own tool. You can wrap it very fast. What I'd like to show you to complete this demonstration are two other great demo, two other great applications wrapping these two. The first one is actually a dashboard widget.

And I'd like to, if I could use, with that dashboard the exact same behavior as done previously with that pcast submit action. Let me show you that dashboard. So this is the dashboard. I run it. This one is a very simple. Let me just kill out the windows. This is just a very simple application.

I have to enter some of the information for my credentials. And I just need to drag and drop a movie to this one. So I can use another movie, like for example, this one that is coming from my camera. Ok. That's actually a cable car thing. I call this widget, I drag this to the widget and this calls, actually pcast, (unclear) the workflow based on my credentials. And same I can select a French 1 workflow as I've done previously.

Put a title, a description, and again, as easy as this I press the submit button and the file is submitted calling another pcast call with the submit option. The other demonstration is a web application. This web application is based on Ruby on Rails which is now part of Leopard and this one does exactly the same by providing a web interface to any user, using any browser to actually submit a file or control any camera. So let me run this web application on that machine.

OK. And now I should be able to connect. So, same way I need to authenticate using my credentials. And, as you can see, just by building a web application less than 200 lines of codes I can wrap this pcast command and give to other users using other type of browsers or computers the ability to submit a file very basically or to record any camera from a web interface. Like, for example, Pacific Heights' camera is actually available. Thank you very much. George.

( Applause )

So back to the slides. So that's a little look at the client. And you can see some of the opportunities there for taking your application or your custom set-up and tying it in on the client's side to submit files, to control cameras, etcetera. Now we're going to switch over and take a look at the server side and this is where there's a phenomenal opportunity for integration. Podcast Producer server, the command and control center, and Xgrid, the processing engine, are controlled by workflows.

This is the architecture. We just took a look at this piece, the client side, part of Podcast Producer. And so you can see at the center of this we have the pcast command allows you to submit, control, etcetera. In the center piece the command and control and processing we have Podcast Producer itself as well as Xgrid. And then over on the right hand side we have all these different publishing points, wiki weblog, iTunes U, etcetera.

There's also notification services as part of workflow so you may send an email to the person that submitted the content saying it's ready. Or to a list of students, for example, that are in the class, you can now subscribe to the lecture. We're going to focus in on this center piece, Podcast Producer server.

And the first piece we're going to take a look at here is the file system. Again, this is a shared file system, all of the Xgrid nodes are accessing the shared file system and one of the things that's on the shared file system are the submissions themselves, the files and the workflows that have been submitted.

Then the workflow, the cache of workflows, are accessible to all of the Xgrid nodes so they know how to execute this, and the resources for those workflows are also there. For instance, you may have an intro movie that you want to put before every, every lecture that you do in biology. And so you have a nice little biology intro video and that's part of that shared file system as well.

And then the cache of the produced content, the Podcast, the streams and archival content, by default Podcast Producer is going to save everything in its highest resolution in an archive. And this is one of the reasons that Xsan is such a great thing, because you can grow the storage and you probably need to grow the storage if you archive everything.

And then, of course, the processing piece, Xgrid. So, what's fabulous about Xgrid is to add capacity you just add additional machines to the grid. No need to tear down the system, no need to shut it off, you add additional agents and then you have more processing capacity. This is what a workflow looks like, a simple workflow.

These are all stages in the workflow that are submitted with that, that job to the grid. In this example we have a preflight script, we have, we archived the original and then we annotate, add some metadata to the file, perhaps a title, we encode in multiple formats, encode one for the iPod, encode an audio only version, and then post it to the wiki, send an email this has been done, and then a little post flight script to clean up.

So workflows, where are they? Well, there's a set of system workflows and like everything in the system library if you modify this and Apple does a software update it may go away. So you don't want to modify these workflows. However, they're a great starting point for your own workflows.

So if you go into system library Podcast Producer workflows you will see a number of workflows and these are all bundles. So if you're familiar with bundles on Mac OS X, this is a familiar concept. You can reach inside those bundles and you will see a set of resources for that workflow. Customer workflows should be installed in library Podcast Producer workflows. These will automatically be distributed across your shared file system for you. Inside of there there's a critical file that we're going to spend a little time looking at, which is the template.plist file.

So it is the technical specifications or the source code for your workflow. It includes a new feature of Xgrid, which is Scoreboarding. So in Leopard Xgrid has a new capability to target specific systems with a Scoreboarding system. So, for example, if you had workflow that had GPU intensive tasks you could target or eliminate certain systems that had no GPUs in them, for instance, from your grid. So if you had some older Xserves with no video cards they probably aren't great for doing Quartz Composer types of things. You may want to eliminate those from the workflows that need those tasks.

The task specifications themselves define the task and the dependencies and we're going to drill down on that and the user requirements, the required metadata for a workflow to execute. So this is what it looks like inside of a plist as it. You'll notice that there are some run time variables that get substituted in the workflow. This is the metadata that you submit into the job. So, for instance, the notification email, this workflow is successful executed The art conditions, that's the Scoreboarding part of the plist and then the task specifications and user requirements.

So the task specification, this is the command, the arguments and the dependencies for the workflow. So the command line executable that is actually executed at that stage in the workflow. So this could be a script, it could be a binary. If you are writing applications and you want them to run in this environment it's important to factor to the command line so that they can be executed across the grid. It includes these arguments with run time set substitutions.

That's the metadata that comes into the workflow and dependencies, any dependencies on other tasks. For instance, if you're going to publish to iTunes U the file has to be processed before you can publish. So there would be a dependency there. And this is what a task looks like.

For encoding to iPod, it's calling this script, it's actually a Ruby Script, usr/bin/pcastaction. It's a wrapper. So this is actually a Ruby Script that wraps many of the other executables that are included with Podcast Producer. We've done this to simplify the development of workflows using what Apple builds into Podcast Producer. It includes some arguments we want to encode and then the run time substitutions, the base directory where the file lives, etcetera. And then this depends on the watermark task. So this will not execute until the watermark has been applied to the source content.

If you look at pcastaction and the functions that it wraps, these include editing functions, and Dave went through some of these in his presentation, those are pre-encoding steps, things like merging, joining, splitting the movie, extracting tracks, deleting tracks, etcetera. And then there are encoding tasks that we put into this encoding category. There are things like annotation, setting the poster and the primary one, of course, encode for iPod, encode for 3G.

And you may want to extract or delete tracks after you've encoded. So, for instance, if you're going to iTunes with an audio only version, why not just extract the already encoded audio from the video instead of encoding twice? Makes sense. Then publishing tasks go to the wiki server for a group blog, publish to the streaming server, publish to iTunes U and notification to email, to iTunes U or iTunes 4, I published a new Podcast. And then some utility tasks as well. You can get help on any of these from the command line and Eric's again going to go into more detail on this by typing pcastaction help and the name of the action. And you can also get a list, etcetera.

Another piece of these workflow tasks are the metadata that flows into them. Some of it's recording metadata. So, for instance, with this DV camera it would be, this is the format, it's DV video. It was recorded for 36 minutes, etcetera. That is part of the metadata that you receive into your workflow. Then there is user metadata and title one description in Eric's last example are examples of user metadata. And then there's server metadata.

And if you came to Dave's last session you'll notice in server admin there's this properties area, all those properties are server metadata that can be tied into a workflow. There's the metadata that Apple ships as part of it and then there's custom fields that you can configure yourself. So if you have metadata that you need for a specific part of a workflow you can append your own properties into there and they're available to a workflow.

So in terms of creating your custom workflows you're going to want to bundle all these executables and scripts. If you're a developer, factor to the command line so that they can be included in a workflow. You want to install custom workflows in library Podcast Producer workflows not in system library.

And you can monitor workflow execution as Eric showed with Xgrid admin. And, of course, you can also use syslog to monitor workflow execution. So, with that, I'm going to turn it back over to Eric and I'll give him the clicker this time.

- Thank you. Can I, The slides please.
- So we need slides too.
- Thank you.

So the purpose of this demonstration is to show you how easy it is to create or modify an existing workflow. We have been using so far the French 1 workflow, if you remember. We are going to use that one and extend it. Before going through the demonstration I'd like to talk a bit about this workflow and what we are going to do actually.

So for that I have a slide. This is the typical diagram of a workflow describing the different tasks and the dependencies of these tasks. This is a French 1 workflow. In that workflow what I do is, actually, archiving the original movie then in parallel I annotate this original movie and then you can see two different branches.

The first one is actually encoding for iPod and then the other one that can be, that is executed and parallel, if you have enough power, is the encoding for audio. And then we did a post to iTunes, and finally we have some kind of image with a dependency to this send email, which is waiting for those tasks to complete properly.

So, as you can see here I have some kind of pattern of encoding and post to iTunes U. What I like to do in that demonstration is extend that workflow to encode to another format, like for 3G, for example. So the basic thing would be to reuse this pattern and extend it for a new encode for 3G and a new post to iTunes U. OK. So let's go to the demo machine now to, Can I, can you switch to the demo machine, please?

Before going through the changes I made to the workflow to encode for 3G and post to iTunes U.result, I'd like to run the demo with the Get a Mac movie so that at the end of this demo we can get the result. So for that I will use the Pcast Capture application with file submission feature and use this Get a Mac movie.

And I select my extended workflow, which is actually French 1 Plus. So this is, add from Apple, Enjoy!, here it is. So, what I did actually to create that workflow, I connected, I connected to the server and I get this workflow to have a base as a working environment.

So I duplicate this French 1 workflow that already exists and if I open the package content and browse into it, as George demonstrated, I cannot access to this template this plist file, which describes all the tasks and all these dependencies that are going to be apply and on the movie I will submit to Podcast Producer. So this is the main file to edit to actually change the behaviors of this workflow. So I'm going to edit it in editor, zoom a bit. If you remember my previous slide I define a pattern.

This pattern does an encode and then it posts to iTunes U. So then I should find, I should find this template an encode for iPod opposed to iTunes U for iPod. So then I can duplicate these ones and modify this as a start. So, if I browse into this file you'll see all these different tasks. And actually, here I added this encode for iPod. So let's duplicate this task.

This is the name of the task. Let's rename it encode3g. Dependency is exactly the same. Remember my branching? Actually the annotate task will then call for encode for iPod, encode for audio and encode for 3G. And I want these to execute in parallel so this one is correct. The command is pcastaction. It uses the encode subcommand. The parameter looks correct for me. The input is still the original movie. The output is a bit different. I want to name it 3g and the extension will be 3gp.

And the last parameter is the encoder. Well, guess what? I have no idea about the encoder name for the 3G I want to use. I know that we support it. So for that I'm going to go into the help of pcastaction to have an idea about the encoder type. So if I type pcastaction help, you'll get a list of all the subcommands we support. But let's focus on the encode part of it.

So if I go to the encode you'll see all the different parameters you need to pass to that command in your tasks so then you can use that subcommand properly. And as an encoder I like to use, actually, 3gpp_release_5. So let's go back to my template of plist file and replace this by the correct one.

So once this is done, what I want to do now is to post this output to iTunes U. So let's duplicate an iTunes U task and rename it iTunesU3g. And I want this task to depend on the previous one. So let's copy this encode_3g name and that will be my dependency. For that I'm using pcastaction coding iTunes U subcommand. Most of the parameters here are correct, only this one looks suspicious. So let me fix this one.

And that should be correct. One last thing you remember this sort of join at the end, when you submit the mail. So I want to make sure that the mail is well submitted once all these tasks are completed. So I need to add this one here to complete the chain of my workflow.

So this workflow is finished actually. You just have now to modify the main input of plist file here to put a new title and a new description. Then you can copy back this workflow on the server in /library/Podcast Producer/workflows and you have then to trigger this sync workflows command line that George demonstrated previously.

So then this workflow can now be used by the users. So let's see if my previous demonstration completed perfectly. Yes, I received an email named A Great Ad from Apple. If I go to iTunes U I should see my iPod version, my audio version and now my 3G version.

OK. It's coming. This has been posted to elementary French. And, as you can see, you have my Apple Get a Mac iPod movie.

( Movie plays )

You have the audio only.

( Audio plays )

Ok. And then you have this 3G version that has been generated properly.

( Applause )

Can we go back to the slide, please? Now, let's move forward to the case studies. And for that I am pleased and honored to have on stage Willie Pritchard from De Anza College to talk to you about podcasting initiatives and Podcast Producer. Thank you.

( Applause )

Thank you, Eric. Good job.

( Applause )

Good morning. It's good to see everybody here. I just wanted to get a quick poll. How many people here represent or are from educational institutions? Oh, this is really gratifying. Great. Let me just settle the context here first. I'm from De Anza College. It's a community college, a large urban community college in Cupertino, California, about a mile away from Infinite Loop. As you might imagine we have a few Apple products in our inventory. We serve about 25,000 students% a year.

And, as you might imagine, we're often seen as the poor step sibling in higher ed communities. So we often have challenges that many other universities or four year institutions do not face. And that primarily revolves around the staffing limitations that we have because the budget that we have is somewhat bleak when it comes to that.

However, we have been doing distance learning through a television studio for about 30 years, broadcasting out to about 300,000 homes over the local cable in San Jose, Santa Clara area. And we have been moving since that time more and more into the digital arena and also more and more into distributing our classroom media out into the classrooms.

So let me just tell you what we've done in the last, say, ten years. We've managed to move all of our, I'm sorry, about 100 of our classrooms into what we call a multimedia console environment. This console consists of a Mac mini with a flat screen for the faculty to stand at the front of the room and be able to do their lecture, also has a projector and full audio capabilities as well as a document camera so that the instructor can place objects or a document on the podium and be able to project that as well to the students.

And, as appropriate for the subject matter, we also have other equipment as appropriate. Because of the staff intensive nature of old technology we've only had one classroom to date where we've been able to do the kind of quality video that we've wanted to do. And that, even then, has requirements that we have, in our case, student helper who's basically doing the production and switching between cameras and so forth. However, we are now starting to play around with adding additional classrooms.

And we're looking at reducing further the amount of staff involvement in these productions so that we can auto-track the instructor as they move around the room, which they like to do. And we are experimenting with pads on the floor and sensing devices, audio capabilities to be able to take in the student questions and comments as well.

And we're seeing, And we fully expect that we're going to do many more of these. And one of the reasons is because the good citizens of Silicon Valley do support education. Just last year we passed a $500 million dollar bond issue.

( Applause )

Yeah. We really appreciate that.

And about $100 million of it is going to be going into technology over the next decade or so. So we do have the resources to be able to get the hardware but we still need to find a solution that's not so staff intensive. And voila, Podcast Producer comes along.

So we also, concurrent with all this are seeing needs for changes. We are seeing an increasing demands for classrooms that can record sessions in a fully automated way. We're hearing this mostly from faculty and deans but we also know that students are the ones that are motivating this desire. We know that ease of use is critically important.

Those of you who are from educational institutions know that faculty like to just walk into the classroom teach and walk out. They don't want to have to be pushing buttons or controlling devices or essentially looking like a fool in front of the classroom. So we have to make it as automatic and as easy as possible. And we also are looking for a way to automatically place the material that's recorded into our distribution medium, which in our case is iTunes U, as well as Moodle, which is an open source course management system that many of you are probably, have heard about.

For the future we want to move to an environment so that every classroom can do this. So it can record, store and distribute activities to all these other online assets that students will be able to get to. We also need to have flexibility in the scheduling. We are on a quarter system so we're rotating through quite a bit. Classrooms are often times scheduled on a sort of impromptu basis. So we need to be able to capture what's going on in those classrooms, or we have guest speakers in and so forth. So we need to have some flexibility in scheduling.

And we also need to have automatic as well as manual control. We have faculty who are now producing Podcast, as I'm sure many of you are experiencing at your home institutions. And we would like to be able to have them be able to do this and feed directly into Podcast Producer so we don't have to have a whole lot of staff intervention on that too. So we plan to set up individual Podcast development stations or faculty being able to do it right out of their office.

So now it's the time that all the geeky side of the audience likes to see, which is our flow chart for how we see this working. We really see that Podcast Producer is the glue that kind of holds together the two ends that we've sort of got in place right now. This first one is the classroom capture environment. I already mentioned our multimedia consoles where we have microphones, the DVD or VCR, computer, a document camera, etcetera. And what we're going to be doing is simply adding a camera into that mix with an audio microphone as well.

So it's a fairly low cost addition to be able to make all of our classrooms upgradeable to Podcast Producer. And then we... All of them have a mini in them already. So we can see that that can serve as our encoder in our client system for the, for the capturing.

The middle part here is Podcast Producer and it's really central to what, the success of what we're doing. This is where we handle our scheduling, storage, etcetera. And, of course, you've seen these before, if you went to the previous session and seen the Xray and Xgrid, etcetera, for being able to do some of the processing.

Traditionally, I should say, we also, as many of you know, are required to caption video that we go out for those with disabilities. And this has been a very difficult time to, in terms of expense, for staffing and the cost of finding captioners to be able to put that information in there. So that's a challenge for us.

Then the distribution, of course, we can put it out to multiple media, QuickTime server, iTunes U, our, of course, management system Moodle, which we've branded as Catalyst and then from there to the web so that students can access it. This sort of captures all of the detail. I'm not going to go through it, specifically every one, but we have locations where we're going to be able to place the Podcast Producer capture stations We have a variety of applications that we see for web archiving, distance learning, guest speakers, etcetera. Clearly there's a lot of value added by adding Podcast Producer into this mix. We have a number of capture formats. We can do it either audio only, audio and data, video, audio and data as well and distribution formats.

The one outstanding issue for us, as many of you in the audience know, is this whole idea of captioning. We are required by state and federal law to provide materials in a format so that those with disabilities can access them. So this is our biggest challenge and we're looking at speech detects technology to try to find a solution and we are very interested in talking to. Here's a developer opportunity for those of you who are working in this area. We think the market is potentially huge.

In California alone there are 109 community colleges. We serve three, I'm sorry, two and a half million students in the state of California. If you throw in UC and CSU into the mix then you're up over three million students and 150 different campuses. So the opportunity is really there. And I'd be happy and very eager to talk to anybody after the session who might be working in that area. Let me just say that our vision is to be able to automate that process as well.

Imagine dropping the lecture into the text track of a QuickTime movie time sync and then searchable through Spotlight, a student at any moment can get online, type in a concept and voila there's a whole list of all the various lectures that are available online for that particular concept they're looking for. So we think the potential for some really exciting learning opportunities is there. We're really excited about Podcast Producer. So, thank you very much. And I'm going to,

( Applause )

Turn it over to Adam Hochman from UC Berkeley.

Thanks Willie. I'm here today to talk about UC Berkeley's webcast and Podcast program and why we chose Podcast Producer as a major component for our next generation capture and delivery system. Eleven years ago computer science professor Larry Roe started a research project webcasting a few of his courses. His students loved it and the university thought, wow, this is a really good idea. So four years later they started a webcast service for the entire campus.

Today we have six webcasts and 14 Podcasts in general assignment classrooms. From the faculty's perspective it's completely automated. All they need to do is simply put a mic on their lapel and they're ready to go. From these classrooms we've captured around 82 courses in the past year. There's been a huge explosion of growth and popularity of webcasting and Podcasting on our campus.

Just recently we had a survey on campus with incoming freshman and we found that they expect Podcasting to be an essential service on campus on par with email and wireless. So for, for freshman and for students on our campus, they depend on this as a study tool and they just assume that all their classes are going to be Podcast. We started Podcasting several years ago and we were one of the first universities to deploy an iTunes U site.

We also have a worldwide audience of lifelong learners. Every dot on this map represents thousands to hundreds of thousands of users that visit our site and download our Podcasts. In 2006 alone we had over 3000 hours of lecture content. As I mentioned before, 82 courses captured, 3.5M unique views and 10.6M MP3 downloads from our webcast.berkeley.edu distritubtion channel alone.

The reason for our success is, one, all our content is open free to the public As a public institution we believe that our content should be distributed to the public for free. We also use iTunes U and Google video as major distribution channels, and what that allows us to do is a wide distribution of our content. It really puts us on a world stage. Also we happen to have really great professors and we have notable speakers come to our campus, like this past spring Jimmy Carter and Stephen Hawking came and you can see that webcast on our delivery system.

Although, although we're extremely popular the bar of expectations for our program has risen quite a bit. We receive emails from both our lifelong learners and our students, they want more quantity, they want more quality, they want more portability and they want it now and it's quite overwhelming. And to meet that demand we're hoping within the next three to five years to have 200 plus classrooms Podcast enabled.

To meet this demand though and to have these sort of ambitions we're kind of shaking in our boots because our existing system has a lot of challenges and we really need to start over. And we found that Podcast Producer really provides a scalable system and a robust and flexible system for capturing, post processing and delivering media.

So we're very excited about it. There's various challenges that we face and I'm going to go through the ways in which Podcast Producer is going to solve those for us. From a scalability standpoint our existing system was not built for high volume post processing of video and audio.

What Podcast Producer facilitates is media batched processing over the Xgrid and then also seamlessly integrates Xgrid with QuickTime and Quartz Composer. From an accessibility standpoint we are unfortunately capturing in Real. That's a legacy decision. And everyone emails us all the time. Why are capturing in Real? We need to download a Real Media Player, it's not portable, etcetera, etcetera And we're capturing in a lower bit rate and we really don't have an archive strategy. It's just been Real.

Well, the workflows that Podcast Producer provides really allows a flexible way to encode to various formats that QuickTime provides. So now we can, now we can transcode easily for the iPod or Apple TV or for the archiving. We're moving all of our content to Creative Commons. So in order to do so we need to,

( Applause )

Thank you.

So we really want to facilitate distribution everywhere and we're really excited about that. But in order to do so we need to brand and copyright all our material so people know that it's coming for UC Berkeley and they know what they can do with it by just looking at the media itself.

We do not have the staff to do this level of branding manually. What we love about Podcast Producer is that through Quartz and QuickTime we can do the composting intros and outros automatically. And I've learned a lot more about Quartz Composer this, this week and I'm really excited about the fun things we can do with it. From a sustainability standpoint our current system doesn't talk to one another, various components and it breaks down in various locations from the capture point to the post processing point to the delivery point and we don't really know what's going on. It could be the database.

It could be that the encoder didn't get an updated script. And it's just not a very stable system. So what happens is when the system breaks down it basically, basically is an exponential affect and it affects our video production staff and students. We like, we like Podcast Producer because it provides automated classroom capture. It's very stable. And it also provides automated metadata harvesting so that it injects the content coming from our registrar system so that our video production step doesn't have to do that manually.

Right now they take every single MP3 that we deliver and inject the ID3 tags themselves. From an automated distribution standpoint, now we push our stuff to Google video and iTunes U ourselves manually. It's a really, it's a really hard process and we're really excited about the fact that Podcast Producer could provide the service for us.

Our next generation system, we're looking to basically marry Sakai and Podcast Producer. If you're not familiar with Sakai, many in the audience already might be because they're from the educational domain, but Sakai is an open source product. It's essentially an open source competitor with Blackboard. It's a consortium of 90 plus universities. And we have an implementation of Sakai as a learning and management environment on our campus.

We're really excited about building a content management system inside Sakai because it's already integrated from an authentication authorization standpoint and from a metadata standpoint with the existing systems on campus. So we're basically going to put a content management system on top of Podcast Producer and orchestrate the Podcast Producer workflows through Sakai.

We're also, as I mentioned before, integrating with the campus system so that the gathering of metadata is going to be fully automated. We're just going to grab the information from the registrar and then we'll be ready to go. From a self healing and redundant system standpoint, right now if an encoder breaks down it has an exponential effect. With Podcast Producer it monitors the various workflows that are happening from capturing, post processing and delivering so we know at which various points we need to, we need to, we need to fix the system.

From a hopes and dreams standpoint, we're building from the ground up now and we can't do a lot of the sexy stuff that we like to do. In fact, we like to just jump to the sexy stuff and have someone else worry about the infrastructure. But unfortunately we need to start from the bottom up again.

One of the things that we're really, A few things that we see as developer opportunities that we would be really interested in is we have three distribution channels right now. Our local distribution channel uses AWStats. We have Google Analytics for our Google video site and we also have iTunes U giving us spreadsheets every month.

Our faculty look at stats as a big carrot on a stick. They like to know how well they're doing. And it really influences them to join our program. We have these three different ways to show stats and it would be great if we could homogenize those and deliver those through Sakai to our faculties so they can see how they're doing.

We're also moving to screen casting. And through screen casting we're really excited about the emerging video OCR technologies. And it would be great if there was a way to have time coded metadata so that students can simply just click on a tag and go to a relevant part of a video.

One other thing is that from an audio, Audio is very difficult and although our faculty only essentially put a mic on their lapel, sometimes they put it on their belt, sometimes they put it near their neck, sometimes they don't wear it at all. So almost constantly we have to adjust our audio levels. It would be wonderful if there was some automated way to adjust the audio levels to the range that we want so that a person doesn't need to get involved in that process.

So this is where we're heading next. We've created a scheduling utility to generate iCal format so that, so essentially now we're using, We have a scheduling component to schedule the workflows in Podcast Producer. So we're pulling stuff from our registrar right now and automating the workflows based on the classroom schedule. We're also doing requirements gathering from other campuses. We're really interested in understanding other campuses use cases because we want to make a generalizable tool that other campuses may be able to use to bootstrap their own webcast program.

We're also looking to, we're also looking to create a loosely coupled tool so that you could potentially work with it outside of Sakai, potentially in Moodle or some other environment. Thanks. So for Fall 2007 we're basically have a little microcosm of eight classrooms in which we're doing a Podcast Producer pilot.

We want to understand the benchmarks of the system and know what we can and can not do and whether we need to scale our stack of Xgrids. And by Summer 2008 we're looki ng to have a full roll out of our next generation system. That's all with my presentation. I'd like to give it back Eric.

Thank you.

( Applause )

Ok. I would like to talk to another project named Universia. That is a (unclear) project. Universia is one of the biggest university cooperation network, with more than 900 associated universities from 11 different countries from Latin America, from Portugal and from Spain. What they want to do is to provide an advanced Podcasting technology and advanced Podcasting service to this big network as a hosted service. And for that they are trying to put together a scalable central infrastructure based on Podcast Producer to serve this. So I'd like to show you a quick snapshot of the infrastructure that they're working on.

What they want to have first is per university recording and content creation stations so you can post from these machines the content you create to a central, sorry, to a local Podcast Producer all in one system, which will relay this content you submit to a central infrastructure where the competing power and the storage capacity will match the needs for the complex workflows they want to run.

Indeed, as a service company they need to be format and platform agnostic for the delivery of the learning measure. So what they are going to do there is extend the workflows so they can have multiple outputs leveraging the QuickTime technology as well as the Telestream new product for Podcast Producer named episode engine podcast Podcast, which allows you to actually encode to different formats such as Flash 8 or Windows Media.

And then you get access to this content with a collaboration system that can talk to the Podcast Producer engine. And thanks to this technology behind the scene they'll get a reliable and scalable architecture for this service for that school network. And both university and a Telestream will be available at the lab this afternoon at 2 PM. So if you have any questions please come.

I've got one more thing to you. What we have seen so far are the great default capabilities of this technology. What I like to show you now as a demonstration, as a final demonstration is our crazy you can, our crazy workflow can be, or creative you can go actually with this technology. Before going to the details of the workflow I'm going to use I like to run the demonstration first because it's going to take a few minutes to post process. Can you switch to the demo machine, please?

So I'm going to run a screen capture of myself presenting, of course, about something great in France. So I've got my Keynote running here. So I log into Podcast Capture. I select screen capture. My audio input and then I run the screen capture. Thank you very much for attending this session about the essence of the monument. This session is about L'Arc de Triomphe.

This monument is one of the famous one in Paris. It was commissioned in 1806 and it stands, actually, in the middle of L'Place de l'Etoile. The architecture of this monument is really close to the Roman Empire's Janus Arc and one of the important part of it is the left side of this monument that represents the Peace.

Thank you very much for attending this session and I hope to see you next one. Thank you. ( Applause ) OK. Cross our fingers. I'm going to use this, Oh! End screen capture, Podcast to iTunes U. So let's call that the essence of the monument, all about France, history. I submit it. Let's check that is going to work first.

Oh! OK. Can I go back to the slides, please? This is going, This will take, This should take about three or four minutes to post process. So, this is all about my first crazy workflow and this is for demonstration purpose only. This is not going to be part of the report. OK. So what do I have? When I press the stop button I actually receive from the camera agent a movie. This movie is actually a screen capture and as I'm running slides this is going to be a video of my slides and my speech.

Cool. What I like to do is I like to create video opening, a customized video opening of my school. So, well, that looks very easy now since I know I can use Quartz Composer. Thank you. So let's generate, let's build a Quartz composition, which will take this school logo and use a title and the order that I receive it from the agent so then I can have dynamic tasks in that movie.

The great thing would be maybe to add another track to this video opening. And maybe I can use my description that I entered previously. Why can't I do that? How can I do that, sorry? I can do that using the text to speech. We announce in Leopard and call this technology has a task, generate an audio track and have this audio track to this video opening with my description. Cool. So then I can maybe put a transition between those two things using, again, a cool Quartz composition transition like a cubic thing called the swing.

OK. So now I have, I think, a great movie. But that's still a movie and something's missing from it. What I like to have in that movie are chapters. I love to be able to jump to the end of my presentation or to the slide that actually occurs to me. So how can I do that since I have a movie?

Well, again that's a movie of my slides but I have transitions and then these are not still images. Well, I can use a QuickTime API, I can get these frames, I can use CoreImage and compile these frames together and maybe try to figure out this problem just by finding stability in this video.

So very simple I have all the tools and all the frameworks that I can build a command line for doing this task. So then I can extract from this video stable images and since I'm able to extract these images I can know about the time code at the moment this image occurs. So then I have images, time code, I have this video. Again, I have got the QuickTime Kit API to add structures to movie. So I can write another task that can add this in a movie so add chapters in this movie.

OK, great. So I can generate a video movie or I can generate a chaptered audio file for my iPod Nano, for example. But my titles are still one, two, three, four. What I like to have are actually great titles for my chapters. How can I do that since I have only picture now?

Well, I browse on the Internet and I found a great open source OCR technology. I bring, I did bring this on the platform. I compiled it. I put this final result in my bundle and I use this, actually, to OCR every image I have. So now I am able to extract the text from this image. And I suppose the first line of this text is my title. So now I'm able to generate a chapter with that title instead of my one, two, three, four counter.

Cool. OK, WWDC came up so I had to stop and actually I decided to and cut this in different multiple formats but I wanted to have also a last thing and last minute. Since I have all these descriptions, all these key words part of my images I can add this in my video itself so then I can search for the content of my slides as metadata in Spotlight instead of just the title and description. Again, easy, I've got all the tools in Podcast Action to annotate. I just need to have something to extract this. As I have it done. Let's go back to the slide to see the results. OK. Whoo!

( Applause )

Thank you. Thank you very much. OK. So I should have received an email. Ooh, cool. And this email tells me just please connect to iTunes U to see the results. OK, it's going to take a few sec. You see I have many new tracks. And I will subscribe to my feed and show you some of the results. So actually I need to show you the video I generated, something else and another one. So three different outputs that I like to highlight today. The first one is chapter order. I think I should have, cool, I should have audio.

So as I told you,

The essence of the monument (speaks French).

- So this is my voice over thing with the title, this is my speech.

( Video playing )

And this is the way I can jump from one chapter to the other. So I can go to Architecture.

( Applause )

I can go, thank you. The other one is, so this one is an audio chapter file so that works on an iPod Nano.

OK. The other one is exactly the same but as a video but actually for great video opening.

( Video playing )

And again, all my transition things and so on. If I open this one using QuickTime, for example, which is another application, you can see here actually all my chapters and this is a video so I have all the transitions. ( Video playing ) Cool.

( Applause )

Thank you. I have a last thing. Since I have these pictures, why not generate a PDF? And, again, with color graphics it's just a couple of lines.

So this is a PDF with a cover page, title of my document using the metadata, my name, the date, the logo of my school and these are the slides for the chapters and all the things. Even with my cover video I added with Quartz Composer and that's even better. If I zoom you will see some lines so then the students can take some notes. Thank you very much.

( Applause )

- Back to the slide. Now you see why we brought Eric in for the demo.

( Laughter )

OK. So, in summary, there's tremendous opportunities here for, first, starting with the infrastructure that's required, then looking at the capture, workflow and publishing components of this. And, to me, being in education this really meets this immediate need that every institution that I'm working with has of automating the processing and distribution of high value content. And I think it's just a really exciting time to, to be engaged with my education customers and I'm really excited about taking this forward
