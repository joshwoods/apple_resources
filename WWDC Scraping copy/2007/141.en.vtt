WEBVTT

00:00:10.789 --> 00:00:14.489
>> Well, good morning.

00:00:14.490 --> 00:00:20.649
Welcome to Session 141, Boosting Responsiveness
and Performance in Your Cocoa Application.

00:00:20.649 --> 00:00:25.689
This will actually be interesting for those
of you who were here a few minutes ago

00:00:25.690 --> 00:00:28.270
for Chris Kane's presentation
of partitioning your Cocoa app.

00:00:28.269 --> 00:00:31.789
Some of the things that we'll talk about
here fit in very well with the things

00:00:31.789 --> 00:00:33.780
that he talked about in the previous hour.

00:00:33.780 --> 00:00:39.310
So this would work out pretty well if you've
been in the room for both presentations.

00:00:39.310 --> 00:00:40.500
My name is Chris Parker.

00:00:40.500 --> 00:00:42.329
I work in the Cocoa Frameworks team.

00:00:42.329 --> 00:00:49.820
And today I'm going to be talking about, oddly
enough, two things, responsiveness and performance.

00:00:49.820 --> 00:00:58.100
So responsiveness, we, yes, Lord, okay, responsiveness
is generally how well your app reacts to user actions.

00:00:58.100 --> 00:01:03.670
So as the user is actually typing away in your
application or clicking the mouse and things like that,

00:01:03.670 --> 00:01:09.620
how fast your app can actually respond to those actions
and handle the things that the user is asking it to do.

00:01:09.620 --> 00:01:13.410
And performance is about getting your
applications worked on efficiently.

00:01:13.409 --> 00:01:19.369
And this is about things like your memory
usage and your CPU usage as well as on all

00:01:19.370 --> 00:01:21.490
of these new eight acore machines and things like that,

00:01:21.489 --> 00:01:27.929
keeping all of those CPUs as busy
as we possibly can keep them.

00:01:27.930 --> 00:01:31.990
Before you get started on doing any kind
of responsiveness or performance work,

00:01:31.989 --> 00:01:36.469
one of the things that you should always be doing
first is measuring what's happening in your app, right?

00:01:36.469 --> 00:01:39.579
So premature optimization is the root of all evil.

00:01:39.579 --> 00:01:47.049
You can wind up doing a whole bunch of work that either
doesn't get you a whole lot of win for your effort

00:01:47.049 --> 00:01:48.920
or really just doesn't make a difference.

00:01:48.920 --> 00:01:54.840
So it's important to know what's happening in
your application as you're working with it.

00:01:54.840 --> 00:01:59.790
So there are a lot of tools on Mac OS X that can
actually help you measure the performance of your app.

00:01:59.790 --> 00:02:04.310
And the simplest to use is installed as a command-line tool.

00:02:04.310 --> 00:02:05.670
It's called /us/bin/sample.

00:02:05.670 --> 00:02:11.009
It puts out that nice text file in /tmp that has a statistical listing

00:02:11.009 --> 00:02:13.419
of where your program is spending its time.

00:02:13.419 --> 00:02:17.280
And one nice thing about sample is that
it's actually installed on all machines.

00:02:17.280 --> 00:02:18.819
So it's even on the user DVDs.

00:02:18.819 --> 00:02:23.299
So you may be able to get reports from the field using
sample that you might not be able to get with other tools

00:02:23.300 --> 00:02:26.400
because some of these don't have
the developer tools installed.

00:02:26.400 --> 00:02:28.490
Another good tool is Shark.

00:02:28.490 --> 00:02:34.680
Shark is installed as part of the CHUD framework on
Mac OS X. And this comes with the developer tools.

00:02:34.680 --> 00:02:39.849
And this can give you a lot of information about what's
happening in your machine as far as processor usage,

00:02:39.849 --> 00:02:42.199
but also in terms of memory and a number of other traces.

00:02:42.199 --> 00:02:47.149
It has very sophisticated data mining
capabilities so you can draw some correlations

00:02:47.150 --> 00:02:51.819
and compare samples, compare Shark
runs and things like that.

00:02:51.819 --> 00:02:54.780
And new in Leopard is a developer tool
called Xray.

00:02:54.780 --> 00:03:01.939
Xray has a GarageBand-like interface that
allows you to put instruments into the interface

00:03:01.939 --> 00:03:04.859
that will show you things like memory allocation events.

00:03:04.860 --> 00:03:11.170
So Xray has actually pulled in some of the functionality
that you used to find in tools like ObjectAlloc.

00:03:11.169 --> 00:03:17.109
It also interfaces with dtrace on Mac OS X. And
you can also use dtrace directly, if you'd like,

00:03:17.110 --> 00:03:21.080
to be able to introspect what's
happening in your application.

00:03:21.080 --> 00:03:26.310
But figuring out when to use the
tool can be a little tricky, right?

00:03:26.310 --> 00:03:28.319
When is there a problem?

00:03:28.319 --> 00:03:36.019
Well, the OS actually has a really specific cue about
when there's a problem with your responsiveness.

00:03:36.020 --> 00:03:37.439
And it's pretty obvious.

00:03:37.439 --> 00:03:39.560
This pops up, right?

00:03:39.560 --> 00:03:42.819
The beachball, it's the spinning pizza of death, right?

00:03:42.819 --> 00:03:48.019
Whatever you want to call it, this usually
means that there's a problem with your app.

00:03:48.020 --> 00:03:50.250
And it's hard to tell sometimes what this means.

00:03:50.250 --> 00:03:56.169
You might get a response from using your
app that says well, I clicked on something

00:03:56.169 --> 00:04:00.219
and the beachball appeared, so I killed the app.

00:04:00.219 --> 00:04:02.379
Well, okay, that doesn't tell you much.

00:04:02.379 --> 00:04:08.650
Or I clicked on something and the beachball
appeared and I let the app sit and it recovered.

00:04:08.650 --> 00:04:11.930
And suddenly the beachball went away
and I could use the app again, right?

00:04:11.930 --> 00:04:16.540
The beachball actually indicates a
very specific targeted problem, right?

00:04:16.540 --> 00:04:19.170
It has to do with the main event loop.

00:04:19.170 --> 00:04:20.490
So what happens?

00:04:20.490 --> 00:04:26.430
When a user double clicks on your app, and this application
name gets called and the Cocoa machinery sort of comes

00:04:26.430 --> 00:04:30.069
into play, and the main event loop is initialized.

00:04:30.069 --> 00:04:32.180
And this contains a whole bunch of things.

00:04:32.180 --> 00:04:37.500
So the main event loop is basically how
Cocoa goes through and handles events.

00:04:37.500 --> 00:04:41.660
It also has the top-level autorelease pool,
so if you're not using garbage collection,

00:04:41.660 --> 00:04:47.380
all of those autoreleased objects that don't have
pools around them will eventually be freed by--

00:04:47.379 --> 00:04:52.050
will eventually get the release message sent
by the main event loop at the end of the loop.

00:04:52.050 --> 00:04:58.110
But the main event loop is mainly in charge of
dealing with events that come in from the user, right?

00:04:58.110 --> 00:05:02.990
So the user clicks on something and that mouse click goes

00:05:02.990 --> 00:05:05.720
through the USB hardware, and then
it comes up through I/O Kit.

00:05:05.720 --> 00:05:07.280
And then I/O Kit hands it off to the kernel.

00:05:07.279 --> 00:05:09.079
And the kernel goes off and it
gives it to the window server.

00:05:09.079 --> 00:05:14.669
And the window server eventually puts
it into a queue meant for the application.

00:05:14.670 --> 00:05:19.449
And as those-- as the event loop comes around,

00:05:19.449 --> 00:05:23.610
we pull those events onto the event
loop and handle them in sequence, right?

00:05:23.610 --> 00:05:28.100
And then when there are no more events, we
just hang out waiting for new things to happen.

00:05:28.100 --> 00:05:29.870
And this isn't just user events, by the way.

00:05:29.870 --> 00:05:34.990
This is also things like Apple events that are
being sent to the application from other processes.

00:05:34.990 --> 00:05:39.199
So there are a lot of things that can come in
that are handled as part of the event loop.

00:05:39.199 --> 00:05:44.039
And it's important to keep track of for us.

00:05:44.040 --> 00:05:51.560
What happens, though, if the application goes
into a tight loop on the main event loop?

00:05:51.560 --> 00:05:56.930
So the user clicks on a button, and as a result of clicking
on that button, a whole bunch of work starts getting done.

00:05:56.930 --> 00:06:02.800
Some long live computation or a download
from the network, something like that?

00:06:02.800 --> 00:06:10.689
Well, the longer the application sits there,
churning away, it's keeping the event loop

00:06:10.689 --> 00:06:14.629
from getting back around to pick up events.

00:06:14.629 --> 00:06:21.779
So as events come in, they're just sitting there,
hanging out, doing nothing, not getting handled.

00:06:21.779 --> 00:06:23.309
The windows server keeps track of this.

00:06:23.310 --> 00:06:30.339
The windows server actually keeps track of how often your
app has checked in and grabbed an event and handled it.

00:06:30.339 --> 00:06:38.169
So after a certain amount of time, if the window server
says wow, nobody's home, it puts up the beachball, right?

00:06:38.170 --> 00:06:44.020
So it doesn't necessarily mean that just because
the beachball is up, the application is hung,

00:06:44.019 --> 00:06:48.829
that it's not getting any work done, or that
the application needs to be killed, right?

00:06:48.829 --> 00:06:54.750
So this is where it's a great opportunity to get a
tool, sample it, and figure out what's going on, right?

00:06:54.750 --> 00:07:00.300
If it looks like it's just waiting for events,
well, then there's a problem with the app hanging

00:07:00.300 --> 00:07:06.860
and maybe being deadlocked, but if it's actually
churning away in some work, it's probably time to try

00:07:06.860 --> 00:07:13.259
and get that work to be done in some other way
that isn't going to block the event loop, right?

00:07:13.259 --> 00:07:15.939
This pretty much sums up the experience, right?

00:07:15.939 --> 00:07:20.290
Any time you see the beachball,
well, doc, it hurts when I do this.

00:07:20.290 --> 00:07:24.680
Okay, the answer is don't do that then, right?

00:07:24.680 --> 00:07:30.790
Let's see what we can do about avoiding the beachball.

00:07:30.790 --> 00:07:32.439
There are a lot of different ways to do it.

00:07:32.439 --> 00:07:37.480
And there are a lot of places where
the beachball can show up, right?

00:07:37.480 --> 00:07:40.100
One of them is a beachball at launch, right?

00:07:40.100 --> 00:07:45.680
One of the most unsatisfying user experiences is when the
user double clicks on the application and it sits there

00:07:45.680 --> 00:07:49.050
and it bounces in the dock for a
while, and it bounces in the dock

00:07:49.050 --> 00:07:52.730
for a little while longer, and
it keeps bouncing in the dock.

00:07:52.730 --> 00:07:56.629
Then eventually the beachball comes up, right?

00:07:56.629 --> 00:08:03.879
So other than the fact that the user now has been sitting
here doing this for the entire application launch,

00:08:03.879 --> 00:08:06.459
you might see a sample that looks like this.

00:08:06.459 --> 00:08:12.669
I took this sample, it's a 10-second sample of
an application, and we got roughly 8,600 samples.

00:08:12.670 --> 00:08:17.500
If you tell sample to sample faster than it's able to,
it will just sort of do a best effort kind of thing.

00:08:17.500 --> 00:08:21.250
I was trying to get it to do a one millisecond,
you know, a sample every millisecond.

00:08:21.250 --> 00:08:24.129
And it looks like I got about 8,600 samples here.

00:08:24.129 --> 00:08:31.300
But the key portion of this is that 8,500 of
those samples are spent in nib loading, right?

00:08:31.300 --> 00:08:35.779
So we're trying to draw in probably
MainMenu.nib, right?

00:08:35.779 --> 00:08:38.779
It's got the main menu bar and everything
else and we're trying to bring this in.

00:08:38.779 --> 00:08:45.339
And when you see samples like this,
sometimes we can get a copy of the nib.

00:08:45.340 --> 00:08:48.960
You open the nib up, and the nib looks something like this.

00:08:48.960 --> 00:08:50.830
The nib has everything and the kitchen sink in it.

00:08:50.830 --> 00:08:53.660
It has every window that this application
is going to open up.

00:08:53.659 --> 00:08:55.689
And it has all the controllers.

00:08:55.690 --> 00:08:59.620
And it has a whole bunch of other objects in it.

00:08:59.620 --> 00:09:05.019
And this is a really good way, basically,
to get the beachball to appear immediately.

00:09:05.019 --> 00:09:10.039
It has to unpack all of this stuff
in order to get the application ready

00:09:10.039 --> 00:09:11.860
because it has to resolve all of those objects.

00:09:11.860 --> 00:09:16.330
So the solution to this is hey, load smaller nibs, right?

00:09:16.330 --> 00:09:19.470
Break your nib down into smaller portions.

00:09:19.470 --> 00:09:23.500
Refactor it, mainly based on probable
utilization lines, right?

00:09:23.500 --> 00:09:30.220
So if you have multiple document types in your nib,
factor those out, put each document type that you're going

00:09:30.220 --> 00:09:33.090
to handle probably into its own nib probably.

00:09:33.090 --> 00:09:38.350
The Preferences dialog is actually
an interesting opportunity to do this.

00:09:38.350 --> 00:09:43.480
A typical usage pattern is that your user comes
up, and they launch your app for the first time,

00:09:43.480 --> 00:09:45.909
and they poke around the Preferences
dialog for the first two launches,

00:09:45.909 --> 00:09:48.319
and then they get things set right the
way they want them and they never open

00:09:48.320 --> 00:09:51.990
up the Preferences dialog again, if they don't have to.

00:09:51.990 --> 00:09:57.230
So moving that to someplace where it's only going
to be loaded on demand is a great way to get some

00:09:57.230 --> 00:09:59.080
of that stuff out of MainMenu.nib, right?

00:09:59.080 --> 00:10:04.879
And you might actually try to put inspectors either in their
own, if the inspector interface is something you're using

00:10:04.879 --> 00:10:08.570
in their own nib or in with the things
that they're going to be inspecting.

00:10:08.570 --> 00:10:11.890
And there are other classes in the kit
that can help you out with some of this.

00:10:11.889 --> 00:10:15.370
And NSViewController can actually help you deal
with views that you're going to load out on nibs

00:10:15.370 --> 00:10:19.769
on a per-view basis as well as hooking things up for you.

00:10:19.769 --> 00:10:22.579
It's actually a new class in Leopard.

00:10:22.580 --> 00:10:24.240
And we're quite proud of it.

00:10:24.240 --> 00:10:25.899
We're proud of a lot of things in Cocoa, but...

00:10:25.899 --> 00:10:31.279
Another problem can be document formats, right?

00:10:31.279 --> 00:10:33.909
Your application is going to save some documents.

00:10:33.909 --> 00:10:35.889
And there may be a lot of data to save.

00:10:35.889 --> 00:10:38.789
And one document format that some
people use is property lists.

00:10:38.789 --> 00:10:40.339
They're very convenient.

00:10:40.340 --> 00:10:44.240
Property lists come in two flavors, the
XML property list, which is a plain text,

00:10:44.240 --> 00:10:48.370
and it's a very human-friendly format
if your humans like to read XML.

00:10:48.370 --> 00:10:53.200
But it at least can be edited with a text editor, right?

00:10:53.200 --> 00:10:57.330
And the binary property list, which is
a smaller, much more compact format,

00:10:57.330 --> 00:11:01.470
and that format takes advantage of
things like some uniquing of objects.

00:11:01.470 --> 00:11:09.269
So if you have a string that's repeated many, many times,
that's only going to appear once in the binary plist, right?

00:11:09.269 --> 00:11:14.189
Here is a plist that is on almost
everybody's machine who's ever run iTunes.

00:11:14.190 --> 00:11:19.660
This is an excerpt from the iTunes
MusicLibrary.XML file.

00:11:19.659 --> 00:11:26.209
It happens to be a nice large plist that exhibits some
of the characteristics that we're talking about here.

00:11:26.210 --> 00:11:33.389
And this is actually the track that I was
least embarrassed to put on the slide, right?

00:11:33.389 --> 00:11:40.289
But you notice that in the dictionary, if you open up
this plist, it's a number of repeated dictionaries.

00:11:40.289 --> 00:11:42.539
Each dictionary is a track.

00:11:42.539 --> 00:11:50.259
And the key, these keys that appear, track
ID, name, artist, composer, stuff like that,

00:11:50.259 --> 00:11:55.100
these appear once for every single entry in the plist.

00:11:55.100 --> 00:12:01.200
So I happen to have in this particular
library I think roughly 750 tracks.

00:12:01.200 --> 00:12:08.490
For all 750 of those tracks, each one of
these appears every single time, right?

00:12:08.490 --> 00:12:10.379
So this is a lot of wasted space.

00:12:10.379 --> 00:12:12.710
Bigger files take longer to load.

00:12:12.710 --> 00:12:16.240
I actually use the plutil command

00:12:16.240 --> 00:12:23.070
to translate my iTunes Music Library
from an XML plist into a binary plist.

00:12:23.070 --> 00:12:25.490
The XML flavor is about 1.6 megs.

00:12:25.490 --> 00:12:30.960
And the binary plist version of the same file, and
it's still a property list, is about 400K, right?

00:12:30.960 --> 00:12:35.420
So there's big space savings in
using the binary plist format.

00:12:35.419 --> 00:12:40.849
So if you've been seeing a lot of time being spent in XML
parsing or if your application is going to be loading a lot

00:12:40.850 --> 00:12:46.129
of XML plists, you might consider looking at the binary
format, because that's going to load much faster.

00:12:46.129 --> 00:12:50.080
It happens to load in roughly a third of the time.

00:12:50.080 --> 00:12:57.620
So just shy of a tenth of a second for the XML plist
and three hundredths of a second for the binary plist.

00:12:57.620 --> 00:13:02.560
So it's a pretty good place to shave off some time.

00:13:02.559 --> 00:13:08.289
Property lists has some specific
performance characteristics.

00:13:08.289 --> 00:13:10.569
You have to read and write them completely, right?

00:13:10.570 --> 00:13:14.560
So when you pull in a dictionary off a disk
using it with contents of file or something

00:13:14.559 --> 00:13:16.459
like that, it has to read the entire dictionary.

00:13:16.460 --> 00:13:19.269
When you're going to write it out, it
has to write the entire dictionary out.

00:13:19.269 --> 00:13:22.289
So if you're only changing one or two objects, well,

00:13:22.289 --> 00:13:25.959
it still has to write out all 500
other things that are in that plist.

00:13:25.960 --> 00:13:28.500
And property lists only handle plist types.

00:13:28.500 --> 00:13:33.269
So if you have more sophisticated document
processing needs, this is probably not the way to go.

00:13:33.269 --> 00:13:36.419
You'll have to get stuff out of the
dictionary or out of another kind of object

00:13:36.419 --> 00:13:40.309
and spend time constructing your objects.

00:13:40.309 --> 00:13:44.109
You might shift over to the KeyedArchiver, right?

00:13:44.110 --> 00:13:50.399
So you use the binary plist format as sort of the backing store for this, but that's not a feature you should rely on.

00:13:50.399 --> 00:13:52.329
But objects are instantiated.

00:13:52.330 --> 00:13:57.480
So you get to control, as you're archiving and
unarchiving exactly what gets written out to disks.

00:13:57.480 --> 00:14:01.800
So if you have things that you could compute on the
way up, maybe that's a way to be able to solve--

00:14:01.799 --> 00:14:06.039
spend less time working with getting
the file up off of disk, right?

00:14:06.039 --> 00:14:06.569
Things like that.

00:14:06.570 --> 00:14:09.410
So you get a little more control
over what's happening in the Archiver

00:14:09.409 --> 00:14:15.459
to decide how you're going to do your writing of documents.

00:14:15.460 --> 00:14:21.230
These still have to be written out, though,
when you write out the entire document.

00:14:21.230 --> 00:14:24.920
As an entire block on disk, all right, so you have to spend
all that time to write the whole thing out.

00:14:24.919 --> 00:14:30.289
And again, so even if you change one or two objects,
you still have to write out all 500 that are there.

00:14:30.289 --> 00:14:33.860
And if you find yourself spending
lots of time in the KeyedArchiver,

00:14:33.860 --> 00:14:37.639
the next step is to move to something like Core Data, right?

00:14:37.639 --> 00:14:45.980
The documentation for core data I think uses the phrase that's
in object graph management and persistence framework.

00:14:45.980 --> 00:14:53.300
Which is a fairly long-winded way of saying that, boy, this
thing can deal with a lot of objects pretty quickly on disk.

00:14:53.299 --> 00:14:54.899
It has several store types.

00:14:54.899 --> 00:15:00.079
The XML and the binary archive store work very
similar to the way XML and binary plists work, right?

00:15:00.080 --> 00:15:03.410
They're what the Core Data team
I believe calls atomic stores.

00:15:03.409 --> 00:15:11.480
They're written out in their entirety, and then if
you write over it, the stores happen atomically.

00:15:11.480 --> 00:15:16.529
The third type of store type, though, is probably
the most interesting for this kind of situation.

00:15:16.529 --> 00:15:19.769
It's SQLite database store, which allows
partial updates, right?

00:15:19.769 --> 00:15:25.139
So if you have 50,000 objects Pstored in
your document and you change 50 of them,

00:15:25.139 --> 00:15:30.500
Core Data only has to change those 50
on disk rather than all 50,000, right?
P

00:15:30.500 --> 00:15:35.149
So you may be able to switch up to using
NSManaged Object subclasses to be able

00:15:35.149 --> 00:15:38.850
to get more efficiency out of your application.

00:15:40.789 --> 00:15:43.919
You spend a lot of time reading and
writing files, not just your documents,

00:15:43.919 --> 00:15:47.360
but also files that other people give
you to open up for your application.

00:15:47.360 --> 00:15:52.090
And there are a lot of convenient APIs in
Foundation to be able to do some of this.

00:15:52.090 --> 00:15:57.889
initWithContentsOfFile: on NSData or initWithContentsOf URL: when you pass the file URL

00:15:57.889 --> 00:16:01.750
are good ways to just pick up files right off of disk.

00:16:01.750 --> 00:16:08.049
If you have a very large file, though, you're going to spend
a lot of time and a lot of memory with initWithContentsOfFile:

00:16:08.049 --> 00:16:13.159
because it's going to malloc all that
space and hold onto the entire file in memory.

00:16:13.159 --> 00:16:22.250
So on a modest configuration Macintosh, you might find that
this 1.5GB file that you've just loaded is taking up a lot

00:16:22.250 --> 00:16:28.240
of all of the user's RAM, and the machine starts swapping,
and that's not a very good user experience either.

00:16:28.240 --> 00:16:33.000
If you're only going to be touching
portions of that 1.5GB file,

00:16:33.000 --> 00:16:36.440
you might consider something like
initWithContentsOfMappedFile:.

00:16:36.440 --> 00:16:40.850
And that allows us to go out and memory map the file so
that the whole thing isn't brought into memory at once,

00:16:40.850 --> 00:16:45.930
only the bits that you actually touch that are
on the pages that you touch are brought in.

00:16:45.929 --> 00:16:50.839
So you'll spend a lot less time in malloc
and causing swapping in the machine,

00:16:50.840 --> 00:16:54.830
you'll be able to actually get at
the file contents pretty quickly.

00:16:56.019 --> 00:16:58.460
This works great for file URLs.

00:16:58.460 --> 00:17:02.170
initWithContentsWithURL:, but
initWithContentsOfURL: is going

00:17:02.169 --> 00:17:06.869
to do its work basically right on
the event loop if you call it there.

00:17:06.869 --> 00:17:10.679
And it's going to block waiting for data
if you hand it a network URL, right?

00:17:10.680 --> 00:17:15.210
So you can hand it an HTTP URL and it will happily
go off and download that stuff from the Net.

00:17:15.210 --> 00:17:21.150
And if it's on the machine next to you or if it's on a
local machine that's to your local subnet, that's great.

00:17:21.150 --> 00:17:25.090
But, you know, the Internet is a
tremendously inconsistent place.

00:17:25.089 --> 00:17:31.639
So if you're trying to download say even something as simple
as a 300 or 400K file, but it's from a very slow web server

00:17:31.640 --> 00:17:36.410
or it's over an unreliable connection, initWithContentsOfURL:
is just going to block waiting for data.

00:17:36.410 --> 00:17:41.029
And if there's nothing there, it's just going to
sit there and wait until something comes in, right?

00:17:41.029 --> 00:17:43.049
So it's blocking the event loop.

00:17:43.049 --> 00:17:46.859
And if we sit here long enough, eventually
that beachball is going to appear.

00:17:46.859 --> 00:17:49.289
So we want to avoid the beachball.

00:17:49.289 --> 00:17:50.619
How do we do it?

00:17:50.619 --> 00:17:58.279
Avoiding the beachball with network URLs typically also,
specifically HTTP URLs is done with something like this.

00:17:58.279 --> 00:18:01.649
NSURLConnection initWithRequest: delegate: startImmediately:

00:18:01.650 --> 00:18:05.790
So NSURLConnections cooperate with the run loop, right?

00:18:05.789 --> 00:18:09.079
So avoiding the beachball means not blocking the run loop,

00:18:09.079 --> 00:18:11.849
so we're going to find an API that
doesn't block the run loop.

00:18:11.849 --> 00:18:14.189
In this case, it is NSURLConnection.

00:18:14.190 --> 00:18:18.799
What happens here is if there's no data, NSURLConnection
says, oh, that's all right.

00:18:18.799 --> 00:18:24.029
And then it yields to, it basically returns from the thing
that's getting the data, and it allows the event loop

00:18:24.029 --> 00:18:27.549
to come back around and pick those events up, right?

00:18:27.549 --> 00:18:34.289
So because it participates in the run loop
machinery, it doesn't actually block the event loop.

00:18:34.289 --> 00:18:39.639
You can find most of the APIs that do this by looking for
the scheduling APIs, things like scheduleInRunLoop:

00:18:39.640 --> 00:18:42.490
forMode: or unscheduleFromRunLoop: forMode:, right?

00:18:42.490 --> 00:18:47.420
And this allows you to be able to put these things
onto a run loop in a mode where if you need to,

00:18:47.420 --> 00:18:50.769
you can spin the run loop in a private
mode to get some of your work done

00:18:50.769 --> 00:18:53.430
and then release it to allow the event loop to come around.

00:18:53.430 --> 00:18:58.370
Or you can just schedule it in the default
modes and let the kit handle it, right?

00:18:58.369 --> 00:19:01.649
But scheduling APIs allow you
to participate in the run loop.

00:19:01.650 --> 00:19:06.060
And that's a really key idea to not
getting the beachball to come up.

00:19:06.059 --> 00:19:08.099
There are a lot of other ways to do it as well.

00:19:08.099 --> 00:19:09.490
And you can time your work.

00:19:09.490 --> 00:19:15.559
So for instance, if you're using an NSNotification queue,
you can set up idle time notifications, NSPostWhenIdle.

00:19:15.559 --> 00:19:20.710
So you can get little bits of work done
when we think there's nothing else going on.

00:19:20.710 --> 00:19:23.500
You can also schedule repeating NSTimers.

00:19:23.500 --> 00:19:26.960
And those can get little chunks
of work done every few seconds.

00:19:26.960 --> 00:19:30.240
And if you need to look at things in
terms of when things are happening

00:19:30.240 --> 00:19:31.940
in the run loop, you can use run loop observers.

00:19:31.940 --> 00:19:35.750
And that's another way to be able to
schedule your work at specific times.

00:19:35.750 --> 00:19:40.890
The key here, though, is that even though these
are ways to get information about what's happening

00:19:40.890 --> 00:19:42.450
in the run loop, you can still block the run loop.

00:19:42.450 --> 00:19:45.690
So you don't want to do lots of
work using any of these techniques.

00:19:45.690 --> 00:19:50.970
You just want to do little bits of work so that you
don't tie things up for other things on the run loop.

00:19:50.970 --> 00:19:56.100
But specifically, the event loop, all right?

00:19:56.099 --> 00:20:01.759
Once you've sort of exhausted some of these possibilities,
you may find that you're still not able to get

00:20:01.759 --> 00:20:07.509
out of blocking the event loop, so one
solution is to use simple threads, right?

00:20:07.509 --> 00:20:11.279
So we need to get this work that's blocking
the event loop and keeping those events

00:20:11.279 --> 00:20:14.000
from getting serviced someplace else, right?

00:20:14.000 --> 00:20:17.759
So maybe this is one of those downloads
or this is a bunch of work.

00:20:17.759 --> 00:20:23.170
So we'll say that this is-- this was triggered
as a result of the user clicking on a button.

00:20:23.170 --> 00:20:27.570
And that button has an action method
called startWorking, for instance.

00:20:27.569 --> 00:20:29.349
And you do a whole bunch of stuff.

00:20:29.349 --> 00:20:32.319
You're doing this heavy computation, right?

00:20:32.319 --> 00:20:36.909
We're going to shift that and try rewriting
this method in a slightly different way.

00:20:36.910 --> 00:20:41.259
The first thing we're going to do is
rewrite, call a new method called doWork.

00:20:41.259 --> 00:20:43.029
That work is going to take an NSMutableData.

00:20:43.029 --> 00:20:49.039
And that NSMutableData is basically going to sort of
be the result of just sort of append things onto it.

00:20:49.039 --> 00:20:52.920
And when this is called, it's going to
do a bunch of work and then we're going

00:20:52.920 --> 00:20:54.590
to call ourselves back on the main thread.

00:20:54.589 --> 00:20:58.569
We're going to say performSelectorOnMainThread: finished withObject:workdata,

00:20:58.569 --> 00:21:01.480
so it's going to call finished with the parameter work_data.

00:21:01.480 --> 00:21:08.990
And waitUntilDone:NO, so we'll just exit out of this
immediately and some additional clean-up will happen.

00:21:08.990 --> 00:21:13.450
And in our startWorking method, we're going to take
advantage of some new API that's available in Leopard.

00:21:13.450 --> 00:21:16.600
Chris talked about this in his talk just before this.

00:21:16.599 --> 00:21:18.939
performSelectorIn-- oh, he didn't talk about this one.

00:21:18.940 --> 00:21:19.500
I'm sorry.

00:21:19.500 --> 00:21:20.849
I get to introduce this one.

00:21:20.849 --> 00:21:22.709
performSelectorInBackground: withObject:

00:21:22.710 --> 00:21:28.420
This is a very simple way to be able to fork off a
background thread and get a bunch of work done, right?

00:21:28.420 --> 00:21:33.580
So performSelectorInBackground: withObject:
sets up a thread, right?

00:21:33.579 --> 00:21:40.500
Goes ahead and does that work, and then because we've called
waitUntilDone:NO there, right, when this work is done,

00:21:40.500 --> 00:21:42.650
the thread is going to end, it's
going to get cleaned up, right?

00:21:42.650 --> 00:21:49.600
So there's no having to call prethread creator, prethread
exit, and there's no instantiating an NSThread on your part.

00:21:49.599 --> 00:21:52.079
We're going to take care of all of that stuff for you.

00:21:52.079 --> 00:21:54.669
And this is going to basically get
your work done in a background thread.

00:21:54.670 --> 00:22:00.009
So what happens here is that when we call
that performInBackground message,

00:22:00.009 --> 00:22:04.519
all this work that was blocking the event
loop gets put onto that background thread.

00:22:04.519 --> 00:22:06.129
And now the work can happen out there.

00:22:06.130 --> 00:22:07.760
It will get cleaned up.

00:22:07.759 --> 00:22:12.779
And those events can shoot off the
edge of the screen and get handled.

00:22:12.779 --> 00:22:18.009
You may find though that you need more
control over what's happening, right?

00:22:18.009 --> 00:22:21.789
The simple threading mechanism isn't
going to give you enough of that.

00:22:21.789 --> 00:22:24.319
So you may want to drop right to NSThreads.

00:22:24.319 --> 00:22:30.609
And when you create new NSThreads in your process,
each of those NSThreads has their own run loop, right?

00:22:30.609 --> 00:22:36.339
So the main event, the main run
loop has the event loop, right?

00:22:36.339 --> 00:22:39.939
The NSThreads have their own run loops
that you can schedule work on, right?

00:22:39.940 --> 00:22:43.660
And one way to do that is with
performSelector: onThread:, right?

00:22:43.660 --> 00:22:48.330
So because they have their own run loops, they
take advantage of the schedule in the APIs.

00:22:48.329 --> 00:22:51.629
Anything you can schedule, you can
schedule on those other threads as well.

00:22:51.630 --> 00:22:54.170
And you can actually give it the
modes that you're going to use.

00:22:54.170 --> 00:22:58.620
So performSelector: onThread: withObject: waitUntilDone:

00:22:58.619 --> 00:23:04.009
And the longer version, waitUntilDone: modes:,
is how you can shift work from the event loop

00:23:04.009 --> 00:23:07.049
or from one thread to another thread, right?

00:23:07.049 --> 00:23:12.279
And this is a good way to be able to get that work off the
event loop, stop blocking, and don't get the beachball.

00:23:12.279 --> 00:23:17.950
Let's talk about some performance stuff, right?

00:23:17.950 --> 00:23:21.150
We'll combine some of the things I'm going to
talk about in performance with some of the stuff

00:23:21.150 --> 00:23:24.509
that we were just talking about in responsiveness.

00:23:24.509 --> 00:23:27.309
Performance, though, usually means one of two things, right?

00:23:27.309 --> 00:23:30.559
Your use of memory or your use of CPU.

00:23:30.559 --> 00:23:33.119
And the trade-off is the classic trade-off, right?

00:23:33.119 --> 00:23:38.259
More memory for cache results means you
only have to compute something once, right?

00:23:38.259 --> 00:23:45.180
Or computing things more often means that you don't have
to spend time storing that in memory and taking up memory.

00:23:45.180 --> 00:23:50.660
The other twist is the one I mentioned earlier, which is
we have all of these machines that have multiple cores.

00:23:50.660 --> 00:23:53.670
And it's really kind of a shame
to be having a lot of work to do

00:23:53.670 --> 00:23:56.340
and not be taking advantage of all of those cores, right?

00:23:56.339 --> 00:24:00.259
So let's talk a little bit about ways to do some of this.

00:24:00.259 --> 00:24:05.279
One of the ways that you-- one of the places that you
may find yourself spending time is in Text Layout, right?

00:24:05.279 --> 00:24:09.480
And this is a sample of the Tiger version of TextEdit.

00:24:09.480 --> 00:24:11.930
And it's just opened a 60MB file.

00:24:11.930 --> 00:24:17.779
I'm really not sure how HIToolbox managed
to get pink as their color in Shark,

00:24:17.779 --> 00:24:22.889
but that's a little perhaps unfortunate
random color choice on this run.

00:24:22.890 --> 00:24:28.009
But if you look at where this is spending
time, this is using idle time notifications.

00:24:28.009 --> 00:24:32.660
And it's using the background text layout mechanism.

00:24:32.660 --> 00:24:36.400
So what happens here is you drag
a 16MB file onto TextEdit

00:24:36.400 --> 00:24:40.440
and it starts laying all this text out line by line, right?

00:24:40.440 --> 00:24:46.700
And if you grab the scroll bar in TextEdit and scrub it
around, right, that work stops, it's not idle anymore.

00:24:46.700 --> 00:24:51.240
But as soon as you let the mouse button up, that scroll bar
is going to start moving again because it's actually laying

00:24:51.240 --> 00:24:53.450
out the additional text in the background, right?

00:24:53.450 --> 00:24:59.170
Out of this 5.5-second sample that I managed
to get, roughly 4 seconds are spent in layout.

00:24:59.170 --> 00:25:05.050
So even though we don't have a beachball up, there's still
a lot of churning going on and the CPU doing a bunch of work.

00:25:05.049 --> 00:25:09.889
If your text layout needs are fairly straightforward
and you're not doing lots of overriding and things

00:25:09.890 --> 00:25:14.300
in the text system, you can use noncontiguous
layout for your text layout, right?

00:25:14.299 --> 00:25:17.799
So NSLayoutManager setAllowsNonContiguousLayout:

00:25:17.799 --> 00:25:20.009
You pass yes to this.

00:25:20.009 --> 00:25:25.109
And the sample here actually shows that there's
practically nothing going on after the initial drag, right?

00:25:25.109 --> 00:25:28.569
Because it only lays out the bits
that it needs to lay out, right?

00:25:28.569 --> 00:25:33.019
And as soon as the user scrolls to a new place in
the document, that's where the text system goes

00:25:33.019 --> 00:25:35.940
out and lays out that chunk of text, right?

00:25:35.940 --> 00:25:37.269
It doesn't lay out all the stuff in between.

00:25:37.269 --> 00:25:40.940
It only has to lay out the things that
are actually being displayed, right?

00:25:40.940 --> 00:25:47.769
So if you spend a lot of time in text layout, this is
a great opportunity to cut that time down a lot, okay?

00:25:47.769 --> 00:25:55.809
Oh, I'm sorry, I forgot to mention, you can
actually play with this effect in TextEdit.

00:25:55.809 --> 00:25:59.299
In the sample code that's on your DVD, there's a call.

00:25:59.299 --> 00:26:02.169
You can just find the call that
setAllowsNonContiguousLayout:.

00:26:02.170 --> 00:26:05.910
Set it to no and just drag a file in
there and see how that works, right?

00:26:05.910 --> 00:26:10.340
It's a good test bed for tinkering
around with some of this stuff.

00:26:10.339 --> 00:26:12.240
Another good test bed is Sketch, right?

00:26:12.240 --> 00:26:15.529
Sketch is some example code that's
written to show a lot of different things.

00:26:15.529 --> 00:26:21.559
It shows NSDocumentUsage, but it also shows heavy
usage of key value coding and key value observing, right?

00:26:21.559 --> 00:26:26.480
Here's a 5-second sample I took of Sketch
after pasting 10,000 documents into it.

00:26:26.480 --> 00:26:30.730
And I have to admit, I poked at Sketch a little
bit to make its performance a little bit worse.

00:26:30.730 --> 00:26:38.370
So you won't see this behavior in what's on your DVD,
but the idea here is to look at this particular sample.

00:26:38.369 --> 00:26:40.859
insertObject:atIndex:, right?

00:26:40.859 --> 00:26:42.099
So remember what I did.

00:26:42.099 --> 00:26:46.379
I pasted 10,000 objects into a Sketch document.

00:26:46.380 --> 00:26:52.300
After pasting those 10,000 objects, I spent-- the beachball
came up after a little while, and I found this sample.

00:26:52.299 --> 00:26:58.039
And the catch here is that for each of those 10,000
objects, that insertObject:atIndex: is getting pounded on.

00:26:58.039 --> 00:27:01.000
We're spending all our time there doing this work.

00:27:01.000 --> 00:27:06.420
One of the ways, if you see this, that
you can get out of it is by avoiding it.

00:27:06.420 --> 00:27:09.870
Because it only handles a single object
and it's called repeatedly for each

00:27:09.869 --> 00:27:13.250
of those 10,000 objects, this probably isn't the way to go.

00:27:13.250 --> 00:27:20.269
It's probably one of the first things that gets implemented,
but you can actually modify things a little bit.

00:27:20.269 --> 00:27:23.809
The one you're looking for here is to
use the bulk accessor for this, right?

00:27:23.809 --> 00:27:28.819
So insert<Keys>:atIndexes:, in this case,
it's going to be insertObjects:atIndexes:.

00:27:28.819 --> 00:27:33.000
Or in Sketch, you might see insertGraphics:atIndexes:,
right?

00:27:33.000 --> 00:27:37.079
This handles many objects, all
10,000 of them come in at once,

00:27:37.079 --> 00:27:39.929
and the index set is provided as to where to insert them.

00:27:39.930 --> 00:27:46.710
This is a great performance opportunity to be able to take
advantage of whatever your model is or what the kits doing

00:27:46.710 --> 00:27:50.019
in Foundation in order to do these
large bulk insertions, right?

00:27:50.019 --> 00:27:57.460
And by making this change in Sketch, or miraculously
changing back to what Sketch does by default,

00:27:57.460 --> 00:28:03.350
insertObjects:atIndexes is only half
the time that we spend in the sample.

00:28:03.349 --> 00:28:06.639
And the beachball only came up for
like a fraction of the second, right?

00:28:06.640 --> 00:28:11.200
So it's a good way to be able to get a big performance
win when you're dealing with lots of objects.

00:28:11.200 --> 00:28:15.470
And staying with the bulk accessor scales fairly well.

00:28:16.579 --> 00:28:21.419
Another place that you may find that you're
spending time is in enumeration, right?

00:28:21.420 --> 00:28:28.120
Going over a list in memory, a collection,
or iterating over a dictionary, right?

00:28:28.119 --> 00:28:32.989
And one of the things about enumeration in
Tiger, this is a Tiger-style enumeration,

00:28:32.990 --> 00:28:38.120
is there's a lot of messaging going on, and there's
actually a fair amount of churn in the autorelease pool.

00:28:38.119 --> 00:28:41.299
So we're creating an object enumerator from a list.

00:28:41.299 --> 00:28:44.180
And then each time through that string enumerator there,

00:28:44.180 --> 00:28:47.049
every time we call next object,
that next object is autoreleased.

00:28:47.049 --> 00:28:49.980
And this winds up calling object:atIndex
underneath the covers.

00:28:49.980 --> 00:28:55.660
And you spend a lot of time doing this messaging
and walking over individual access, right?

00:28:55.660 --> 00:29:02.519
So just like there's bulk access for KVC and
KVO, we can tighten things up here a little bit.

00:29:02.519 --> 00:29:06.740
The first step is to realize that, hey,
we have enumeration in Leopard, right?

00:29:06.740 --> 00:29:07.880
The 4N construct.

00:29:07.880 --> 00:29:10.950
Does everybody like this, the 4N thing?

00:29:10.950 --> 00:29:13.330
Isn't that great?

00:29:13.329 --> 00:29:19.869
That's like, I keep wanting to use this in other places, and
I have to realize oh, wait, I don't have that in this language.

00:29:19.869 --> 00:29:22.819
So it's nice to be able to do it here.

00:29:22.819 --> 00:29:27.230
For NSString * string in strings_list, all
right, it's much clearer, it's much nicer.

00:29:27.230 --> 00:29:31.930
But you'll notice that it's no coincidence
there's much less messaging going on here.

00:29:31.930 --> 00:29:33.410
You see a lot fewer square brackets.

00:29:33.410 --> 00:29:41.350
And that's because 4N takes advantage of the new protocol in
Foundation called the NSFastEnumeration protocol, right?

00:29:41.349 --> 00:29:45.379
So countByEnumeratingState: objects: count, you're going

00:29:45.380 --> 00:29:49.890
to get a context thing here in NSFastEnumerationState structure.

00:29:49.890 --> 00:29:55.810
And an array to fill in, and the count parameter
there is telling you how many things to fill in.

00:29:55.809 --> 00:30:00.829
You're going to return how many things
you actually filled in from this.

00:30:00.829 --> 00:30:07.750
And this is the way that the 4N mechanism
decreases the number of messages sent.

00:30:07.750 --> 00:30:15.480
And by using this method, by implementing this method on
your collections and taking advantage of this structure,

00:30:15.480 --> 00:30:17.900
and the documentation talks about
what each of these things do.

00:30:17.900 --> 00:30:25.910
There's a state field you can fill in, the mutations
pointer is how you can notify the FastEnumerations system

00:30:25.910 --> 00:30:26.910
that a mutation occurred.

00:30:26.910 --> 00:30:30.610
So if you're enumerating over something, you get
an opportunity to throw an exception, right?

00:30:30.609 --> 00:30:37.219
Nobody's mutating collections while
they're enumerating them anymore, I hope.

00:30:37.220 --> 00:30:39.319
This allows you to take advantage of it.

00:30:39.319 --> 00:30:45.500
And what happens is because it's a bulk accessor,
you fill out say 50 or 100 things at a time.

00:30:45.500 --> 00:30:51.720
It actually gets it down to less than one message send
per object in the collection being enumerated, right?

00:30:51.720 --> 00:30:57.680
And none of those things are autoreleased because you're
providing direct access to the pointers for those things.

00:30:57.680 --> 00:30:59.000
So it's very, very fast.

00:30:59.000 --> 00:31:04.200
And we actually find that by shifting over to this in
Foundation, we got a general speed-up across the board.

00:31:04.200 --> 00:31:11.069
So for things that do a lot of enumeration, looking at
the FastEnumeration protocol is a great place to go.

00:31:11.069 --> 00:31:14.109
We've actually implemented this
for all the built-in collections.

00:31:14.109 --> 00:31:17.419
So if you're using NSArray and NSMutableArray
and things like that

00:31:17.420 --> 00:31:20.539
or the dictionary classes, this
is all taken care of for you.

00:31:20.539 --> 00:31:24.099
But if you have collections or if you
have objects that can participate in this,

00:31:24.099 --> 00:31:28.939
here's where to go to get some extra boost out of your code.

00:31:28.940 --> 00:31:34.519
I'm going to jump back to threading here.

00:31:34.519 --> 00:31:39.539
You know, the performInBackground
selector is an easy thing to use.

00:31:39.539 --> 00:31:43.649
And there are a lot of other easy
things you can do to fire off threads.

00:31:43.650 --> 00:31:47.830
And it's kind of convenient maybe when
you're writing your application to say, okay,

00:31:47.829 --> 00:31:50.149
well, I'm not going to block the event loop.

00:31:50.150 --> 00:31:53.640
That guy, Parker, told me not to do
that at WWDC, so I'm not going to do it.

00:31:53.640 --> 00:31:57.520
So what I'm going to do is I'm going to fire
up another thread that will do my downloads

00:31:57.519 --> 00:32:00.019
and maybe I have another download thread going on.

00:32:00.019 --> 00:32:03.379
And while that's going on, I'm going to throw another
thread in there that's going to do some other work

00:32:03.380 --> 00:32:04.930
because I don't want to block those other two things.

00:32:04.930 --> 00:32:06.210
And that's going to be some indexing.

00:32:06.210 --> 00:32:08.519
And I might be updating a database.

00:32:08.519 --> 00:32:12.879
And pretty soon, I've gone completely thread happy,
and I've got all these threads running around.

00:32:14.309 --> 00:32:19.579
And this winds up being a good way to get into a lot
of trouble for a bunch of different reasons, right?

00:32:19.579 --> 00:32:25.740
So creating just 35, 40 threads all at once and say, hey, you
know, I'll keep them around or I'll use them as I need to

00:32:25.740 --> 00:32:30.279
or I'll set them all doing work and then hope that, you
know, we'll just let the computer sort it out, right?

00:32:30.279 --> 00:32:33.129
It's good at that.

00:32:33.130 --> 00:32:36.330
Threads have a very real startup and teardown cost, right?

00:32:36.329 --> 00:32:43.399
So some factors in using threads are things like how often
are these threads going to be created and then thrown away?

00:32:43.400 --> 00:32:49.050
If you have a very short bit of work, it's
probably not worth the cost of firing up a thread,

00:32:49.049 --> 00:32:55.250
putting the work on the thread, letting the thread
run and then getting the thread torn down, right?

00:32:55.250 --> 00:32:59.849
Threads also hold resources, and they hold resources
in the kernel and they hold resources in your process.

00:32:59.849 --> 00:33:07.000
So it's a general load on the system to create lots of
threads and then either tell the scheduler to figure it out

00:33:07.000 --> 00:33:10.049
or have a lot of idle threads hanging
around, doing nothing, right?

00:33:10.049 --> 00:33:11.690
So there's processor contention.

00:33:11.690 --> 00:33:17.930
If all of those threads are doing work, they're all trying
to do work in much smaller number of processors, right?

00:33:17.930 --> 00:33:21.130
And you wind up with data integrity issues, right?

00:33:21.130 --> 00:33:23.670
Multithreaded programming is hard.

00:33:23.670 --> 00:33:27.620
And it's not something where, you know,
when you're messing around with locks,

00:33:27.619 --> 00:33:31.879
and suddenly all those threads need
to go for the same object, right?

00:33:31.880 --> 00:33:35.480
Suddenly everybody's pounding on that lock
trying to get in and all the threads are blocked.

00:33:35.480 --> 00:33:39.299
So you're still not getting any work done,
even though you have lots of threads around.

00:33:39.299 --> 00:33:42.529
And deadlocks can block the event loop, right?

00:33:42.529 --> 00:33:45.529
Chris alluded to this in his talk earlier.

00:33:45.529 --> 00:33:49.789
You know, you can wind up in the event loop needing
some information, and you go and ask for the lock,

00:33:49.789 --> 00:33:52.829
and then some other thread has it
because it's doing work behind that lock,

00:33:52.829 --> 00:33:55.589
and now you've blocked the event loop again, right?

00:33:55.589 --> 00:34:02.909
So what we want everybody to think about is creating,
rather than lots of threads or enough threads

00:34:02.910 --> 00:34:06.040
for an eight processor machine or enough
threads for a four processor machine,

00:34:06.039 --> 00:34:08.789
we want you to think about working
with a natural number of threads.

00:34:08.789 --> 00:34:13.710
And rather than having to figure out what that
natural number is, we're using NSOperation

00:34:13.710 --> 00:34:16.990
and NSOperationQueue to try and help everybody out.

00:34:16.989 --> 00:34:21.299
NSOperation is a class that encapsulates
your work into threadable units, basically.

00:34:21.300 --> 00:34:28.039
And it's a good place to encapsulate the data
that that work is going to have to use, right?

00:34:28.039 --> 00:34:33.079
So rather than having data sprinkled around in a bunch of
objects where they're going to have to take locks and things

00:34:33.079 --> 00:34:37.480
like that, if you can pull that all
into a single NSOperation subclass,

00:34:37.480 --> 00:34:41.409
then the operation can be self-consistent, basically.

00:34:41.409 --> 00:34:43.899
Operations can be prioritized, right?

00:34:43.900 --> 00:34:48.180
So when you put them into a queue, the queue can say,
well, I've had these four high-priority operations,

00:34:48.179 --> 00:34:50.690
and I only have these two low-priority operations.

00:34:50.690 --> 00:34:53.119
I'm going to do these other, the first four first, right?

00:34:53.119 --> 00:34:57.109
I'll do the high-priority apps first and
then I'll get around to the lower stuff.

00:34:57.110 --> 00:35:01.980
And then as new things come in with different
priorities, some load balancing can occur, right

00:35:01.980 --> 00:35:07.030
And another really important thing, especially for
responsiveness, is that it provides cancellation API, right?

00:35:07.030 --> 00:35:14.050
So if you've structured your NSOperation subclass
to handle being told that it's been canceled, right?

00:35:14.050 --> 00:35:20.890
If you look at the NSOperation API,
there's a set cancel method there, right?

00:35:20.889 --> 00:35:23.519
That's how you can do things like
providing a background operation

00:35:23.519 --> 00:35:26.809
and the user can click the little
X button or the stop sign, right?

00:35:26.809 --> 00:35:32.909
And stop that operation if they decide that it looks like
that might be taking up lots of processor time or memory.

00:35:32.909 --> 00:35:37.089
The NSOperationQueue is the thing that
actually takes care of doing all of this work.

00:35:37.090 --> 00:35:38.680
And it manages the NSOperations.

00:35:38.679 --> 00:35:42.369
It's the thing that looks at all the priorities
and says is it canceled, is it running,

00:35:42.369 --> 00:35:44.460
what's happening, what are the dependencies? Right?

00:35:44.460 --> 00:35:47.230
There's dependency management also, which is very handy.

00:35:47.230 --> 00:35:49.500
And this works with the kernel.

00:35:49.500 --> 00:35:51.880
And this is a big deal for us.

00:35:51.880 --> 00:35:56.470
NSOperationQueue is actually doing things
to make sure that it can offer flow control

00:35:56.469 --> 00:35:59.599
for your operations based on the general machine state.

00:35:59.599 --> 00:36:04.969
So what this will do is, well, here's an example.

00:36:04.969 --> 00:36:08.759
What this will do is, let's set up a download queue, right?

00:36:08.760 --> 00:36:12.230
And let's say we have a bunch of download operations here.

00:36:12.230 --> 00:36:15.219
So the queue is told to start its operations.

00:36:15.219 --> 00:36:20.189
And it says okay, well, there's enough resources right
now in the machine to be able to touch off two of these.

00:36:20.190 --> 00:36:22.400
So I'll start those going, right?

00:36:22.400 --> 00:36:24.300
And then, oh, one of the downloads is fairly quick.

00:36:24.300 --> 00:36:30.410
And it says, okay, well, there's a completed
download, so I can start off another one, right?

00:36:30.409 --> 00:36:34.299
Now, while all of this is running, let's
say something changes in the machine.

00:36:34.300 --> 00:36:38.330
Like let's say other threads in my
process suddenly go to sleep, right?

00:36:38.329 --> 00:36:41.360
Or they're blocked in a read or something else is happening.

00:36:41.360 --> 00:36:46.370
And the kernel can figure this out, and it will
say, okay, well, there's more resources available,

00:36:46.369 --> 00:36:49.239
so those threads aren't really using it right now,

00:36:49.239 --> 00:36:53.349
so let's fire off all of the remaining
download operations and get those going.

00:36:53.349 --> 00:36:55.179
And maybe we can get a little more throughput.

00:36:55.179 --> 00:37:01.009
So NSOperationQueue is working with the kernel in
order to help you provide the natural number of threads

00:37:01.010 --> 00:37:05.200
in the system rather than trying to guess
at some of that state and things like that.

00:37:05.199 --> 00:37:10.469
So NSOperationQueue is a good place to go to be able
to maximize throughput of all of those processors

00:37:10.469 --> 00:37:12.439
that you might have on the machine, right?

00:37:12.440 --> 00:37:16.849
And it isolates you from, you know, having
to call syskidles to figure

00:37:16.849 --> 00:37:20.659
out how many processors are available and running.

00:37:20.659 --> 00:37:26.299
So once you've downloaded all of that data, you
probably actually want to try and display it, right?

00:37:26.300 --> 00:37:28.620
So there are a lot of things about view drawing.

00:37:28.619 --> 00:37:32.349
But the biggest deal about view drawing is be lazy, right?

00:37:32.349 --> 00:37:35.250
My mother's going to hate me for saying that, but be lazy.

00:37:35.250 --> 00:37:37.840
Avoid invoking -display... methods directly.

00:37:37.840 --> 00:37:43.590
So if you actually go through and you look at
the NSView API, the -display... methods in there,

00:37:43.590 --> 00:37:46.200
and those are really big hammers to get your work done.

00:37:46.199 --> 00:37:50.579
You want to actually try and do things
in a small chunk as possible, right?

00:37:50.579 --> 00:37:56.079
So if you've got a document and you've only updated two
things in that document and they're separated by hundreds

00:37:56.079 --> 00:37:59.469
of pixels, you know, only mark those
rectangles that you actually dirtied.

00:37:59.469 --> 00:38:03.149
Because then the view machinery can come
around and only draw in those places, right?

00:38:03.150 --> 00:38:07.720
So setNeedsDisplayInRect: is a great place
to be able to cut down some of your drawing time

00:38:07.719 --> 00:38:10.649
if you find that samples are being spent in drawing.

00:38:10.650 --> 00:38:17.389
setNeedsDisplay: is another way to be able to just tell
one thing, you know, a view or something like that, to draw.

00:38:17.389 --> 00:38:25.529
And if you do have that situation where you have a bunch of
small rects being drawn, don't mark the entire union as dirty

00:38:25.530 --> 00:38:30.480
because you're still going to have to draw all
of those unchanged portions of the document.

00:38:30.480 --> 00:38:36.110
And that's going to spend a lot of time drawing
things that just don't need to be drawn, right

00:38:36.110 --> 00:38:37.329
Be opaque, right?

00:38:37.329 --> 00:38:38.360
Here's an easy one.

00:38:38.360 --> 00:38:42.050
If at all possible, if you can
return YES; from isOpaque, do it.

00:38:42.050 --> 00:38:46.460
Because if you don't have to draw behind you, then the
kit doesn't have to spend time figuring out what to draw.

00:38:46.460 --> 00:38:50.900
It will just stop with that view, right?

00:38:50.900 --> 00:38:54.650
NSScrollView and its clip view are opaque out of the box.

00:38:54.650 --> 00:38:59.789
And if you can do what you can to keep it
that way, that will actually help you out.

00:38:59.789 --> 00:39:04.730
And if you're drawing document views, you
know, we have these nifty Mighty Mice.

00:39:04.730 --> 00:39:06.320
I don't know who uses a Mighty Mouse.

00:39:06.320 --> 00:39:07.160
There's one here.

00:39:07.159 --> 00:39:08.039
I have one on my desk.

00:39:08.039 --> 00:39:10.989
And I love the little scroll ball.

00:39:10.989 --> 00:39:17.899
You know, and you scroll around with this
thing or you use the gesture on the track pad,

00:39:17.900 --> 00:39:23.490
and the scroll view jerks around, and it's going
to try and display bands of content, right?

00:39:23.489 --> 00:39:26.919
A new rectangle comes into view when you scroll.

00:39:26.920 --> 00:39:33.059
And so if you can draw your content in those bands,
right, very quickly, that's another good place

00:39:33.059 --> 00:39:35.849
to be able to optimize your drawing a little bit.

00:39:35.849 --> 00:39:37.130
Don't draw from the top down, right?

00:39:37.130 --> 00:39:39.730
Only draw those chunks that you need to draw.

00:39:39.730 --> 00:39:41.570
So draw as little as possible.

00:39:41.570 --> 00:39:43.350
Be opaque, right?

00:39:43.349 --> 00:39:45.029
Be minimalist, right?

00:39:45.030 --> 00:39:48.810
Here, I'll take advantage of the new enumeration
stuff in Leopard, but if your drawRects gets called

00:39:48.809 --> 00:39:57.469
and you're just iterating over all of the
elements in your array there for what to draw,

00:39:57.469 --> 00:39:59.730
that's spending a lot of time that may not be necessary.

00:39:59.730 --> 00:40:03.599
There's some good information coming in
there in the rectangle parameter drawRect.

00:40:03.599 --> 00:40:07.779
And a simple call to NSIntersectsRect to
find out what the bounds are of the thing

00:40:07.780 --> 00:40:14.320
that you're drawing can actually cut a lot of your drawing
time down, especially if you have large documents, right?

00:40:14.320 --> 00:40:19.490
One place that you sometimes see
issues is during live resize, right?

00:40:19.489 --> 00:40:22.139
When you grab the edge of the window and
you start scrubbing it back and forth.

00:40:22.139 --> 00:40:24.609
And sometimes things can start slowing down.

00:40:24.610 --> 00:40:28.220
One place that you might be able to
find out if you're having problems

00:40:28.219 --> 00:40:32.799
in live resize is catching a sample
while that's happening, right?

00:40:32.800 --> 00:40:37.680
And if the sample is spending a lot of time in CGSReenableUpdate, that's the thing that's helping out with some

00:40:37.679 --> 00:40:43.480
of the live resize machinery, that's a place to look
for doing less in your live resizing behavior, right?

00:40:43.480 --> 00:40:47.730
You can check to see if the view or the
window is in live resize mode at the moment.

00:40:47.730 --> 00:40:51.510
And maybe draw a lower quality preview
of what's going to get drawn there.

00:40:51.510 --> 00:40:54.920
And then when the live resize ends,
draw the real thing in there, right?

00:40:54.920 --> 00:40:59.110
But don't do lots of work at that point,
because if you do, you pretty much run the risk

00:40:59.110 --> 00:41:04.110
of decreasing the performance and
responsiveness of your app, right?

00:41:04.110 --> 00:41:08.430
And you can also run a follow of the
beam syncing in the windows server.

00:41:08.429 --> 00:41:11.889
The windows server is going to rate
limit the drawing that it's doing

00:41:11.889 --> 00:41:17.259
to how fast the panel, in most cases, can draw, right?

00:41:17.260 --> 00:41:19.340
So it can rate limit some of the things that you do.

00:41:19.340 --> 00:41:23.329
For instance, it could actually rate
limit -performSelectorOnMainThread:.

00:41:23.329 --> 00:41:28.900
So if you're spamming the MainThread while you're doing
lots of drawing or trying to get things to be drawn, right,

00:41:28.900 --> 00:41:36.280
well, try and break your work down into chunks that can be
drawn in one call to -performSelectorOnMainThread: rather

00:41:36.280 --> 00:41:39.150
than doing, you know, a thousand calls in a second.

00:41:39.150 --> 00:41:43.610
And the place to find out whether you're being rate
limited by the beam syncing is if you get a sample

00:41:43.610 --> 00:41:49.260
and you're spending time in CGSSynchronizedBackingStore,
that's the thing that's doing the drawing, basically,

00:41:49.260 --> 00:41:51.680
then you're probably getting limited by the windows server.

00:41:51.679 --> 00:41:57.750
Another place that you can pick up some
good performance, layer-backed NSViews.

00:41:57.750 --> 00:42:00.670
And this allows really smooth animation effects.

00:42:00.670 --> 00:42:02.090
It's very spiffy, right?

00:42:02.090 --> 00:42:05.700
The Cocoa animation talk earlier.

00:42:05.699 --> 00:42:10.919
I know you all went for the song, but there
were demos before that that were pretty good.

00:42:12.030 --> 00:42:14.640
Those animation behaviors actually
run in their own thread, right?

00:42:14.639 --> 00:42:19.049
And because it uses Core Animation, it's taking advantage
of things like the video card and stuff like that.

00:42:19.050 --> 00:42:23.289
And you can get at this by calling NSView setWantsLayer:
with YES on it.

00:42:23.289 --> 00:42:26.340
And that actually just layer enables your views.

00:42:26.340 --> 00:42:29.740
And then you can do all of the animation
effects that you were doing before.

00:42:29.739 --> 00:42:32.209
You shouldn't jump right to this,
though, if you don't have to.

00:42:32.210 --> 00:42:38.760
If you find that you're spending a lot of CPU time computing
things about your animation, then maybe it's time to look

00:42:38.760 --> 00:42:44.300
at something like layer-backed NSViews, right?

00:42:44.300 --> 00:42:45.480
64-bit.

00:42:45.480 --> 00:42:50.289
64-bit has some really interesting
performance opportunities in some ways.

00:42:50.289 --> 00:42:56.230
Intel 64 is faster for some tasks, partly because
it has more registers available so the compiler gets

00:42:56.230 --> 00:43:01.559
to play more tricks, and, you know, reorganize your
codes so that you can't read the disassembly at all.

00:43:01.559 --> 00:43:04.779
You can get more things in the collections.

00:43:04.780 --> 00:43:06.350
You can address more memory, right?

00:43:06.349 --> 00:43:12.549
And it's a great way-- you saw Steve's demo with
the Library of Congress modification, right?

00:43:12.550 --> 00:43:17.840
I went through and recolored the
image and put some text on it.

00:43:17.840 --> 00:43:24.630
And that's a great place where a compute heavy task can
take advantage of what 64-bit can do fdor you, right?

00:43:24.630 --> 00:43:30.930
And I think the stat is that almost every machine
that we sell is 64-bit capable now, right?

00:43:30.929 --> 00:43:32.099
Other than maybe the Mac mini.

00:43:32.099 --> 00:43:33.049
I don't remember.

00:43:33.050 --> 00:43:38.530
But you get the opportunity right now, especially if
you're starting in Leopard, to write 64-bit code

00:43:38.530 --> 00:43:42.380
from the start that will run in both 32-
and 64-bit source compatibly, right?

00:43:42.380 --> 00:43:49.950
So if you use the types like CGFlow and NSInteger and NSUInteger and stick with the collection classes and, you know,

00:43:49.949 --> 00:43:54.669
don't make assumptions like an int and a
point are the same size and things like that.

00:43:54.670 --> 00:43:59.450
These are great opportunities for you to be able to
take your code that you wrote 32-bit using these types,

00:43:59.449 --> 00:44:06.739
hit the little check box in Xcode, get a 64-bit binary
that you can test out and compare them side by side.

00:44:06.739 --> 00:44:12.079
Unless you have a big graphics department writing your
code for you, you probably can't do a spiffy graphics demo

00:44:12.079 --> 00:44:15.920
like Steve does, but you can at least
get the same numbers or get numbers

00:44:15.920 --> 00:44:19.030
for the same executable, 32-bit and 64-bit, right?

00:44:19.030 --> 00:44:21.290
So you can actually see what the difference will make.

00:44:21.289 --> 00:44:26.380
And it's not a whole lot of pain to be able
to do that, as long as you're using the types.

00:44:26.380 --> 00:44:27.849
Garbage collection.

00:44:27.849 --> 00:44:30.389
Garbage collection is going to
solve all of our memory woes, right?

00:44:30.389 --> 00:44:33.519
I don't have to think about retain and
release and autorelease and everything else.

00:44:33.519 --> 00:44:34.949
Well, not quite.

00:44:34.949 --> 00:44:38.509
There's still things that kick in in
garbage collection that are concerns, right?

00:44:38.510 --> 00:44:41.220
One thing is what we call unintended roots.

00:44:41.219 --> 00:44:46.089
The collector thinks of anything that's in
a stack variable or in a global variable

00:44:46.090 --> 00:44:49.329
in your code as a root for strong references, right?

00:44:49.329 --> 00:44:52.269
So it's very easy sometimes to
wind up in a situation like this

00:44:52.269 --> 00:44:56.369
where some global variable is holding
onto an entire tree of objects, right?

00:44:56.369 --> 00:44:58.000
And you set it and you kind of didn't think about it.

00:44:58.000 --> 00:45:03.409
And then suddenly you can't figure out why there's
this 500K of memory being used in your application.

00:45:03.409 --> 00:45:09.619
The place to try and fix this is basically when
you're done with the data, set that reference to nil.

00:45:09.619 --> 00:45:12.759
So what happens there is it breaks that strong reference.

00:45:12.760 --> 00:45:17.550
And then the collector gets an opportunity to come
along and grab all of that memory back, right?

00:45:17.550 --> 00:45:22.519
So even in objects that are holding big
trees of things or if you have global caches,

00:45:22.519 --> 00:45:29.159
trying to be a little bit more aggressive about
how you mark the usage of the memory of the objects

00:45:29.159 --> 00:45:32.629
that you're using is a great way to be able
to inform the collector that hey, you know,

00:45:32.630 --> 00:45:35.340
I'm done with this, you can come along and reap it.

00:45:35.340 --> 00:45:38.260
There are a bunch of other things to watch out for.

00:45:38.260 --> 00:45:41.290
One is scarce resource usage, right?

00:45:41.289 --> 00:45:47.960
So when you're working with things like mach ports or file
descriptors or things that are not garbage collectible

00:45:47.960 --> 00:45:52.940
by the collector, which is basically anything
that's memory based, right, or, for instance,

00:45:52.940 --> 00:45:56.409
memory you've allocated yourself
using malloc and free, right?

00:45:56.409 --> 00:45:59.940
That's not collected memory, per se.

00:45:59.940 --> 00:46:03.039
So the scarce resources that you use take up space.

00:46:03.039 --> 00:46:04.840
And it takes time to close those down.

00:46:04.840 --> 00:46:10.370
So typically, you might see in some
objects, you've tied the lifetime

00:46:10.369 --> 00:46:14.130
of that scarce resource to the
lifetime of the object, right?

00:46:14.130 --> 00:46:17.079
So what happens is it's hanging onto
that until it actually gets released.

00:46:17.079 --> 00:46:22.599
Well, what you probably want to do is make sure that you're
actually closing that stuff out as fast as possible, right?

00:46:22.599 --> 00:46:24.769
I used it, I'm done, I'm going to
close the file descriptor, right?

00:46:24.769 --> 00:46:26.259
I'm going to close the mach port.

00:46:26.260 --> 00:46:28.280
I'm going to free that memory immediately.

00:46:28.280 --> 00:46:32.360
And that way, you don't have this sort of piling up effect,

00:46:32.360 --> 00:46:36.760
so that eventually when the collector comes
along, then things are finalized, right?

00:46:36.760 --> 00:46:43.690
And eliminating finalizers is another big
performance opportunity in the collector, right?

00:46:43.690 --> 00:46:47.250
So, you know, there's a method finalize.

00:46:47.250 --> 00:46:49.619
And you could clean some of these things up in finalize.

00:46:49.619 --> 00:46:53.659
But really, you want to hit that point
where you don't have any finalizers at all.

00:46:53.659 --> 00:46:58.409
And that just gives the collector the
opportunity just to free all that memory at once.

00:46:58.409 --> 00:47:01.609
Finalization is order undefined.

00:47:01.610 --> 00:47:03.809
You have no idea what's going on at finalize.

00:47:03.809 --> 00:47:07.570
So objects that you may want to message in
your finalizer may not be there anymore,

00:47:07.570 --> 00:47:10.250
maybe in an inconsistent state, right?

00:47:10.250 --> 00:47:12.699
Performance really suffers when you're app crashes outright.

00:47:12.699 --> 00:47:18.869
So that's probably not a good way
to be able to get your work done.

00:47:18.869 --> 00:47:20.150
And finalizing takes time.

00:47:20.150 --> 00:47:25.130
If you have lots of finalizers, especially
finalizing things that might take time to clean up,

00:47:25.130 --> 00:47:28.720
you probably don't want to do that at all.

00:47:28.719 --> 00:47:34.149
So if you can get it out of the finalization
sequence, you'll spent less processing time, actually,

00:47:34.150 --> 00:47:38.170
basically cleaning up after yourself or having the
collector come along and clean up after yourself.

00:47:38.170 --> 00:47:42.530
And also, don't forget the C, right?

00:47:42.530 --> 00:47:48.450
Objective-C is a superset of C. And if you've got
libraries or external things that do stuff a lot faster

00:47:48.449 --> 00:47:51.369
than you could probably write it,
link it right into your app, right?

00:47:51.369 --> 00:47:55.750
And if you're spending too much time messaging, you
can always do the things like writing some functions.

00:47:55.750 --> 00:47:59.780
If you actually see samples being spent in obj C
message send, you can actually break it out

00:47:59.780 --> 00:48:02.480
and write those as functions instead, right?

00:48:02.480 --> 00:48:06.909
So you don't necessarily have to get tied
into absolutely everything that's happening

00:48:06.909 --> 00:48:10.369
to you in your code via Objective-C, right?

00:48:10.369 --> 00:48:17.019
So just to review, this is actually
for that guy in the back.

00:48:17.019 --> 00:48:18.360
I can see you.

00:48:18.360 --> 00:48:24.019
Wow, machine was sleeping too.

00:48:24.019 --> 00:48:26.719
First off, measure all your code, right?

00:48:26.719 --> 00:48:31.509
No matter what's going on, you can't make accurate
assessments over where your hot spots are,

00:48:31.510 --> 00:48:35.360
where your responsiveness problems are
without being able to see what's happening.

00:48:35.360 --> 00:48:42.200
And Shark and Sample and Xray are great tools
to be able to introspect the state of your code.

00:48:42.199 --> 00:48:47.799
dtrace, I've been playing a lot with dtrace, it's
very nifty because it gives you a lot of things,

00:48:47.800 --> 00:48:49.360
a lot of insight in the whole machine state.

00:48:49.360 --> 00:48:52.130
And these are great tools, and
they give you lots of information.

00:48:52.130 --> 00:48:54.840
So be sure to use them, right?

00:48:54.840 --> 00:48:57.620
Do your work at the right time, right?

00:48:57.619 --> 00:49:02.109
If there's little small chunks, you can probably
get them done at idle time notification, right?

00:49:02.110 --> 00:49:08.030
Doing things, you know, only when
the user actually asks them, right?

00:49:08.030 --> 00:49:11.340
Don't load nibs you don't need to load, things like that.

00:49:11.340 --> 00:49:14.579
Use APIs you can schedule, right?

00:49:14.579 --> 00:49:15.949
Participate in the event loop.

00:49:15.949 --> 00:49:20.759
If you don't need to fork off a thread to be able to get
your work done, well, maybe you don't want to do that.

00:49:20.760 --> 00:49:22.760
But again, they have real costs.

00:49:22.760 --> 00:49:28.070
And if you can schedule things on the run loop, on
the event loop, you may be able to participate in that

00:49:28.070 --> 00:49:31.769
without getting the beachball popping up all the time.

00:49:31.769 --> 00:49:34.489
Use threads, but use them wisely, right?

00:49:34.489 --> 00:49:39.349
Don't just go creating a hundred of them, because
that's probably not going to do you any favors.

00:49:39.349 --> 00:49:41.610
Use NSOperation and NSOperationQueue.

00:49:41.610 --> 00:49:47.940
The encapsulation for NSOperation is a great way to think
about your work and partition your work down into chunks.

00:49:47.940 --> 00:49:53.220
NSOperationQueue is going to cooperate with the operating
system and figure out exactly what the state is and say, hey,

00:49:53.219 --> 00:49:56.009
you know, this is what we can touch off
at the moment and we're going to hold off

00:49:56.010 --> 00:50:00.500
on other work until this stuff is done, right?

00:50:00.500 --> 00:50:02.860
Use bulk operations, right?

00:50:02.860 --> 00:50:06.050
So for enumeration, use the fast enumeration protocol.

00:50:06.050 --> 00:50:08.550
There's some big opportunities for performance wins there.

00:50:08.550 --> 00:50:16.030
In KVC and KVO, make sure that you're using
the plurals, the insert<Keys>:atIndexes: APIs.

00:50:16.030 --> 00:50:20.410
And those are great opportunities
to be able to sort of sidestep some

00:50:20.409 --> 00:50:22.819
of the more naive implementations that might be around.

00:50:22.820 --> 00:50:25.860
And finally, be lazy, right?

00:50:25.860 --> 00:50:27.230
Don't draw what you don't need to draw.

00:50:27.230 --> 00:50:28.789
Don't load what you don't need to load.

00:50:28.789 --> 00:50:34.929
Don't compute it until the user actually
goes ahead and asks for it, right?

00:50:34.929 --> 00:50:36.769
There are a bunch of labs.

00:50:36.769 --> 00:50:39.349
We still have one Cocoa Open Lab today at 2:00pm.

00:50:39.349 --> 00:50:40.529
We'll be downstairs.

00:50:40.530 --> 00:50:44.490
Performance Lab has open hours today and tomorrow.

00:50:44.489 --> 00:50:50.439
But there's a specific Performance Tuning
Lab Thursday at, it looks like 10:30am,

00:50:50.440 --> 00:50:53.960
I can't read from down there, there
we go, 10:30am and Friday at 2:00pm.

00:50:53.960 --> 00:50:58.369
So there's lots of opportunities to come and talk to
us about the performance of your app or talk to people

00:50:58.369 --> 00:51:03.359
who write Shark or Xray and figure out how
to use those tools to really get good views

00:51:03.360 --> 00:51:04.970
into what's happening in your application.