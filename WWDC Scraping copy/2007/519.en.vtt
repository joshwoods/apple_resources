WEBVTT

00:00:18.050 --> 00:00:22.880
>> My name is JD Mankovsky and I
manage Apple's professional services.

00:00:22.879 --> 00:00:30.019
We're kind of like the geniuses that actually go on
site and, and deploy real world enterprise solutions.

00:00:30.019 --> 00:00:34.969
So what I wanted to do today is kind of follow up
on, we had a session last year for those of you

00:00:34.969 --> 00:00:38.019
who were here to talk about Xsan best practices.

00:00:38.020 --> 00:00:46.030
And kind of share with you some of the next best practices
that we've uncovered over the last 10 months or so.

00:00:46.030 --> 00:00:50.660
And first I wanted to get a few
show of hands on a few questions.

00:00:50.659 --> 00:00:53.259
So I'd like audience participation.

00:00:53.259 --> 00:00:58.939
How many of you guys actually are
consultants that deploy Xsan?

00:00:58.939 --> 00:01:07.219
Okay. How many of you are actually using Xsan or
are customers that have an Xsan in place today?

00:01:07.219 --> 00:01:12.890
Wow. And how many of you guys are
looking to deploy Xsan in the near future?

00:01:12.890 --> 00:01:15.349
Right, that's, that's really good.

00:01:15.349 --> 00:01:20.569
So I think we have a lot of information for
pretty much all of you guys in the room.

00:01:20.569 --> 00:01:27.289
So for those of you who have Xsans in place today and for
the ones that are looking to deploy Xsan in the near future.

00:01:27.290 --> 00:01:31.630
And make sure that you deploy that
kind of like in a best practice way.

00:01:31.629 --> 00:01:38.159
So first I just quickly wanted to review for those
of you who are not maybe as familiar with Xsan.

00:01:38.159 --> 00:01:41.689
Take a few minutes on what is Xsan.

00:01:41.689 --> 00:01:43.789
Well Xsan is a file system.

00:01:43.790 --> 00:01:46.320
It's a SAN-based file system.

00:01:46.319 --> 00:01:49.189
And you know so we'll talk about that shortly.

00:01:49.189 --> 00:01:54.079
Also we'll talk about you know best
practices around how to set up your volumes.

00:01:54.079 --> 00:01:59.759
Some of the integration and optimization pieces
you want to talk about, we'll talk about affinities.

00:01:59.760 --> 00:02:04.650
We'll talk about optimizing your fiber channel
deployment to make sure that you'll get the best

00:02:04.650 --> 00:02:06.620
throughput and best performance out of your set up.

00:02:06.620 --> 00:02:09.330
And then we'll talk about some back up stuff.

00:02:09.330 --> 00:02:15.740
And then we're going to shift to kind of like a
second phase which is you know high availability.

00:02:15.740 --> 00:02:21.230
For those of you who are in a broadcast world who
really need high availability in a SAN deployment,

00:02:21.229 --> 00:02:24.859
what are some of the solutions that
are out there that will give you that.

00:02:24.860 --> 00:02:30.980
And then the last topic I wanted to cover is
kind of like you know there's a lot of people

00:02:30.979 --> 00:02:33.979
who do, you know who are IT datacenter people.

00:02:33.979 --> 00:02:36.269
And they love our storage because it's cheap.

00:02:36.270 --> 00:02:43.300
But it doesn't offer what some of the tier 1 vendors offer
in terms of you know snapshotting, replication, you name it.

00:02:43.300 --> 00:02:49.610
and we'll talk about a third party solution that we've
been working with that allows you to take our storage

00:02:49.610 --> 00:02:55.080
and bring it into that, that tier 1 level but
yet offer you some of the redundancy capabilities

00:02:55.080 --> 00:02:57.860
that you're accustom to from other vendors.

00:02:57.860 --> 00:02:59.850
So that sounds good?

00:02:59.849 --> 00:03:02.539
Awesome. And we have time for Q and A this year.

00:03:02.539 --> 00:03:06.909
So I promise you all that it's going to be 58 minutes.

00:03:06.909 --> 00:03:12.250
And, and that if we go over 58 minutes, we'll buy beers
to everyone here at the beer bash on Thursday night.

00:03:12.250 --> 00:03:12.599
( Laughter )

00:03:12.599 --> 00:03:17.939
So, so how does Xsan work?

00:03:17.939 --> 00:03:21.889
Well, as you guys know, you know you guys
are very familiar with direct attach disks.

00:03:21.889 --> 00:03:24.439
We use that all, you know, everyday.

00:03:24.439 --> 00:03:33.300
Here with at a SAN file based system, you know the
catalog is stored on its own separate you know disk.

00:03:33.300 --> 00:03:36.860
Right? So you've got a dedicated
set of disks for your catalog.

00:03:36.860 --> 00:03:42.510
And all that information is stored on usually a RAID-1,
you know two disks with you know hot spare.

00:03:42.509 --> 00:03:49.019
And you know every time you need to access data, to either
read and write it to the SAN, you have to basically go

00:03:49.020 --> 00:03:57.340
through the metadata server and get the information,
ask, query the server who will query that metadata LUN

00:03:57.340 --> 00:04:01.640
and ask where is, do I need to write that
data or where do I need to read the data from?

00:04:01.639 --> 00:04:05.579
And then it sends a response back to, to the client.

00:04:05.580 --> 00:04:09.680
And then the client goes and reads those
LUNs directly and grabs the data it needs.

00:04:09.680 --> 00:04:15.599
Okay, so its really important to understand
that, you know for people who want to deploy Xsan

00:04:15.599 --> 00:04:23.490
for you know potentially non video environments, that
you are going through several hoops to actually access

00:04:23.490 --> 00:04:27.410
where the data is and then actually read that data.

00:04:27.410 --> 00:04:30.900
So it's not like direct attach where
its just you know direct throughput.

00:04:30.899 --> 00:04:33.759
You know you have to basically
ask for permission every time,

00:04:33.759 --> 00:04:36.879
because there's you know Xsan is
a file locking based file system.

00:04:36.879 --> 00:04:42.800
So it has to make sure that you know every time you access
the file, you actually have permission to access into it,

00:04:42.800 --> 00:04:47.090
it's not someone else, some other individual,
some other server who's you know trying

00:04:47.089 --> 00:04:50.239
to read or write to the file at the same time.

00:04:50.240 --> 00:04:55.300
So just quickly to make sure people
understand, this is a basic Xsan diagram, okay?

00:04:55.300 --> 00:04:59.129
So most of you guys will I'm sure
have much larger deployments.

00:04:59.129 --> 00:05:03.250
In this situation we have you know a single PowerMac,

00:05:03.250 --> 00:05:07.720
you know or MacPro machine and,
and we have the metadata switch.

00:05:07.720 --> 00:05:11.280
We have the two controllers.

00:05:11.279 --> 00:05:15.439
And we have you know a metadata LUN which is that LUN1.

00:05:15.439 --> 00:05:17.509
Which is a RAID-1 with a hot spare.

00:05:17.509 --> 00:05:22.420
And then we have three what I would call data
LUNs, which are usually you know RAID-5

00:05:22.420 --> 00:05:26.830
and there's a hot spare on each of those LUNs as well.

00:05:26.829 --> 00:05:30.939
And we have two controllers, always
two controllers for redundancy.

00:05:30.939 --> 00:05:35.079
Okay? Because you want to make sure that if,
if for some reason the first controller fails

00:05:35.079 --> 00:05:39.750
that it automatically fails over to the second
controller and that your users can still you know work

00:05:39.750 --> 00:05:42.220
on editing their content and not be down.

00:05:42.220 --> 00:05:48.910
So that's just to make sure that people understand,
this is a you know very basic Xsan you know diagram.

00:05:48.910 --> 00:05:52.370
But it'll help for further down in the discussion.

00:05:52.370 --> 00:05:58.209
Everything goes, all the, the metadata
switch is really for your metadata traffic.

00:05:58.209 --> 00:06:04.620
So again every time the machine that
MacPro needs to read or write the data

00:06:04.620 --> 00:06:07.590
to the LUNs, it needs to ask for permission again.

00:06:07.589 --> 00:06:09.219
And you want a dedicated switch for that.

00:06:09.220 --> 00:06:12.280
So a lot of people are like you
know do I need a dedicated switch?

00:06:12.279 --> 00:06:13.989
Can I VLAN my switch?

00:06:13.990 --> 00:06:18.259
You know I've got the Cisco switch, can I
just now VLAN you know the switch I have?

00:06:18.259 --> 00:06:20.159
Well, yeah you can do it.

00:06:20.160 --> 00:06:24.730
But the problem is you got to guarantee
that you're going to get to that data in time.

00:06:24.730 --> 00:06:29.490
And the only way to really guarantee that is
to have a dedicated switch for your metadata.

00:06:29.490 --> 00:06:34.560
So spend the money, you know you're spending $100,000
on a SAN, make sure you're doing it right.

00:06:34.560 --> 00:06:38.589
And don't, not, don't try to shave you
know $3000 for an Ethernet switch.

00:06:38.589 --> 00:06:47.879
Right? So you know lets talk about how does the, the SAN
actually write, you know how do you write data to your SAN?

00:06:47.879 --> 00:06:57.189
Well again, imagine a MacPro, a Final Cut machine and
the task I want to do is I want to ingest 16 MB of video.

00:06:57.189 --> 00:07:01.759
And in this situation we're assuming we
have a single storage pool with four LUNs.

00:07:01.759 --> 00:07:05.629
So you have four LUNs in a single storage
pool and you've got this other RAID

00:07:05.629 --> 00:07:08.589
up there that's just for your, for your metadata, okay?

00:07:08.589 --> 00:07:13.459
And so again from a theoretical perspective,
what we usually say is you're getting

00:07:13.459 --> 00:07:17.839
about 80 MB per second from each of the LUNs.

00:07:17.839 --> 00:07:23.689
So considering you have four LUNs, you're going to
get a total throughput of 320 MB per second .

00:07:23.689 --> 00:07:24.980
Make sense?

00:07:24.980 --> 00:07:30.000
And so when you're writing the data and
considering you've got you know a stride breadth

00:07:30.000 --> 00:07:33.069
and a block size that equals a MB, right.

00:07:33.069 --> 00:07:38.110
So usually you do you know stride breadth
of 4k and 256 stride breadth or 8k,

00:07:38.110 --> 00:07:42.550
you know 128 or 16k block and you know 32.

00:07:42.550 --> 00:07:48.480
It always equates to a MB due to you know
the, the settings on the fiber channel card

00:07:48.480 --> 00:07:51.379
and kind of the optimized settings for the Xserve RAID.

00:07:51.379 --> 00:07:57.719
What's happening is it's going to, it's going to
write you know the first MB to LUN1,

00:07:57.720 --> 00:08:01.500
the second MB to LUN2, and then
the third MB to three and four.

00:08:01.500 --> 00:08:06.069
And then it's going to write, you know the
fifth MB back to LUN1, two, three,

00:08:06.069 --> 00:08:08.180
four, and then it'll go all the way to 16.

00:08:08.180 --> 00:08:09.800
But its doing that in parallel.

00:08:09.800 --> 00:08:13.079
So that's how you're getting that optimized
throughput and its how you're getting,

00:08:13.079 --> 00:08:18.379
you know the 300 MB per second is that its writing
one, two, three, four at the same time on all four LUNs,

00:08:18.379 --> 00:08:22.360
and then four, five, six, seven, you know,
five, six, seven, eight to again those LUNs.

00:08:22.360 --> 00:08:25.310
And so it's doing that very, very quickly.

00:08:25.310 --> 00:08:29.939
So that's kind of a high level review and
now we're going to dig a little bit more deeper

00:08:29.939 --> 00:08:32.649
into kind of some best practices guide lines.

00:08:32.649 --> 00:08:38.899
And what I wanted to do is bring up Stle Bjordal
whose one of my, one of our engineers at Apple to talk

00:08:38.899 --> 00:08:41.230
about some of the best practices around, around Xsan.

00:08:41.230 --> 00:08:41.850
Stle?

00:08:41.850 --> 00:08:43.080
>> Thank you.

00:08:43.080 --> 00:08:44.740
Good morning.

00:08:44.740 --> 00:08:48.259
( Applause )

00:08:48.259 --> 00:08:50.590
Let's see if we can go the right way here.

00:08:50.590 --> 00:08:54.170
JD promised top shelf alcohol by the
way at the beer bash if we stick.

00:08:54.169 --> 00:09:01.419
If we go past 58 minutes, so IX'm thinking we can
start off with a joke, maybe a Canadian and a German.

00:09:01.419 --> 00:09:02.579
Walked into a bar.

00:09:02.580 --> 00:09:03.690
( Laughter )

00:09:03.690 --> 00:09:12.130
But anyways, what we've seen for a lot of our engagement is
that power distribution and cooling is something that a lot

00:09:12.129 --> 00:09:16.169
of people either skip out on or don't prepare carefully for.

00:09:16.169 --> 00:09:21.029
So one of the, one of the highlights
of, on Xsan engagement is to make sure

00:09:21.029 --> 00:09:25.019
that you have enough power and you have enough cooling.

00:09:25.019 --> 00:09:29.049
Because you don't want to be the guy that
brings in all these great Apple equipment

00:09:29.049 --> 00:09:32.939
and then plug everything in and downs the data center.

00:09:32.940 --> 00:09:34.910
That, that makes us kind of look bad.

00:09:34.909 --> 00:09:40.429
And also you can get fired, so let's try not to do that.

00:09:40.429 --> 00:09:42.889
Make, make sure you know that you
have adequate temperature in there

00:09:42.889 --> 00:09:47.529
and that your power sensor is not right
underneath the air vent for the AC.

00:09:47.529 --> 00:09:50.980
Because you know that can give you a false negative.

00:09:50.980 --> 00:09:58.039
So we've just listed a few of the, a few of
the, the power consumption and the BTU for some

00:09:58.039 --> 00:10:01.079
of the most normal things that we deploy there.

00:10:01.080 --> 00:10:09.750
But keep in mind that a ton AC unit equals about
1300 BTU and that, we see that that's pretty normal.

00:10:09.750 --> 00:10:16.799
You want to make sure that in addition to your,
your power that you think about how do I make sure

00:10:16.799 --> 00:10:22.519
that I maintain power in case of the
building for some reason should go black.

00:10:22.519 --> 00:10:28.740
And what we've found is that the APC grade makes
some great components that can help us with this.

00:10:28.740 --> 00:10:39.419
We have a serial concentrator, a simple signaling cable, and
we also have the network monitoring card for APCs equipment.

00:10:39.419 --> 00:10:47.669
And APCs stuff is qualified with the Xserve RAID and we
don't endorse them but it's important for us to understand

00:10:47.669 --> 00:10:54.569
that if you buy their gear then you know they, they
have some stuff that works with what we deploy.

00:10:54.570 --> 00:10:58.810
You always have the PowerChute software that they
make which is a free download from their website.

00:10:58.809 --> 00:11:07.339
And what that allows the software to do is the Xserve
will get a notification when you're running low on power

00:11:07.340 --> 00:11:11.170
and will automatically start shutting down when
you've reached whatever threshold you're set

00:11:11.169 --> 00:11:13.990
on the APCs themselves.

00:11:13.990 --> 00:11:18.950
Also you want to make sure that you
have the right plugs in your datacenter.

00:11:18.950 --> 00:11:25.870
For example you have the, the APC 3000s they come
with the 30 amp twist lock which will not fit

00:11:25.870 --> 00:11:32.179
into your standard you know 120, 3 pin outlet in the wall.

00:11:32.179 --> 00:11:35.589
So make sure that you plan for all
of these different things when you,

00:11:35.590 --> 00:11:40.370
when you decide to deploy Xsan or
drop a bunch of RAIDs in there.

00:11:40.370 --> 00:11:47.340
The basic set up for UPS integration is
something like this, where you see it up there.

00:11:47.340 --> 00:11:58.389
You configure your, your cards in the APCs by, by turning on
the network monitor and you deploy the power shoot software.

00:11:58.389 --> 00:12:05.679
And what that will do is it will, like I said, shut
off the servers when, when power is getting low.

00:12:05.679 --> 00:12:12.099
The RAIDs act a little bit different in that the simple
signaling cable will not actually shut down the RAIDs.

00:12:12.100 --> 00:12:19.470
What the simple signaling solution does is that it will
force the RAIDs to write all the data directly to disk

00:12:19.470 --> 00:12:22.330
as opposed to storing in the drive cache first.

00:12:22.330 --> 00:12:29.139
And when power finally goes out then the RAIDs
are just going to die because of loss of power.

00:12:29.139 --> 00:12:32.220
But at least all the data that's
been written to the RAIDs are stored

00:12:32.220 --> 00:12:35.830
on the disk as opposed to being stored in the cache.

00:12:35.830 --> 00:12:41.340
If it were stored in the cache, then you
would lose it if you, if you lost power.

00:12:41.340 --> 00:12:46.700
The best way to manage all of this is
probably through the web interface.

00:12:46.700 --> 00:12:51.750
The network management card from
APC has a nifty, nifty web tool.

00:12:51.750 --> 00:12:55.860
And it allows you to configure all the parameters there.

00:12:55.860 --> 00:13:01.590
The best of setting this up initially is to
make sure you have the MAC address of the card.

00:13:01.590 --> 00:13:07.940
And you, you send an arp command and assign the MAC
address and IP address, but you telnet into the card

00:13:07.940 --> 00:13:12.170
and this is just going to be to just enable the web interface.

00:13:12.169 --> 00:13:18.269
One thing that's worth mentioning here is that
simple signaling shut down is not enabled by default.

00:13:18.269 --> 00:13:23.149
So you have to go into the web interface or telnet
in and actually enable that option in there.

00:13:23.149 --> 00:13:27.919
So after you plugged in all the simple signaling
cables, you have all the equipment and your testing,

00:13:27.919 --> 00:13:33.240
your not going to see anything being written straight
to disk unless you enable it in the web interface.

00:13:33.240 --> 00:13:35.909
And a lot of customers are not aware of that.

00:13:35.909 --> 00:13:39.699
And then they come screaming and because of data loss.

00:13:39.700 --> 00:13:41.850
So keep that in mind.

00:13:41.850 --> 00:13:48.879
We also have to mention that the Xserves, they
have a pretty, pretty feature where you can allow it

00:13:48.879 --> 00:13:54.220
to delay the start up after a power
failure based on an interval

00:13:54.220 --> 00:13:59.620
that you set using the set wait
for start up after power failure.

00:13:59.620 --> 00:14:02.840
And you would set this is increments of 30 seconds.

00:14:02.840 --> 00:14:09.180
And there's as you can see in the graph here,
there is a preset for this command in ARD.

00:14:09.179 --> 00:14:16.120
So you can easily highlight all your Xserves and send
this command out to all your Xserves at the same time.

00:14:16.120 --> 00:14:18.549
And the reason why you want to do this is fairly simple.

00:14:18.549 --> 00:14:24.889
You want to make sure that all your, all your
storage and all your network gear is already up

00:14:24.889 --> 00:14:29.039
and running before the, the Xserves start back up.

00:14:29.039 --> 00:14:33.059
And in this case especially because the Xserves
in this case would be metadata controllers.

00:14:33.059 --> 00:14:37.239
You really want to make sure that, that
all the other gear that you have is up

00:14:37.240 --> 00:14:40.310
and running prior to the Xserve starting up.

00:14:40.309 --> 00:14:47.809
Let's talk a little bit about how the shut down
procedure works for Xsan because if you don't follow the,

00:14:47.809 --> 00:14:50.679
the steps then there could be a potential loss of data.

00:14:50.679 --> 00:14:56.039
So you want to make sure first step all the
clients and this includes servers as well as,

00:14:56.039 --> 00:14:59.620
as Xsan clients that you unmount the volumes.

00:14:59.620 --> 00:15:04.460
And then you use your Xsan admin
tool and you stop the volume.

00:15:04.460 --> 00:15:08.290
And you turn off the SAN clients.

00:15:08.289 --> 00:15:13.379
In this case a SAN client is not just
a client that runs Mac OS X client.

00:15:13.379 --> 00:15:18.000
It could be an Xsan server that is an Xsan client

00:15:18.000 --> 00:15:24.210
or it could be a server computer that's
running ADIC's StoreNext file system.

00:15:24.210 --> 00:15:30.030
Next you want to shut down the secondary MDC
and by this we don't mean necessarily the one

00:15:30.029 --> 00:15:32.059
that you have designated as a secondary MDC.

00:15:32.059 --> 00:15:36.799
It's simply the one of the MDCs
that are not hosting any volumes.

00:15:36.799 --> 00:15:40.339
So you want to make sure that you
verify with Xsan admin which of your MDCs

00:15:40.340 --> 00:15:44.680
that actually hosting your volume before you shut them down.

00:15:44.679 --> 00:15:50.500
Next you shut down the primary MDC and
finally you shut down your storage.

00:15:50.500 --> 00:15:58.039
And you shut down the other servers that may be on your
network such as Open Directory, Mail, DNS, etcetera.

00:15:58.039 --> 00:16:00.799
And finally you shut down all of the other hardware.

00:16:00.799 --> 00:16:06.279
Such as your fiber channel fabric switches, your
Ethernet switches, be it metadata or public.

00:16:06.279 --> 00:16:12.039
The start up procedure is basically
flipped the other way around.

00:16:12.039 --> 00:16:18.870
You want to make sure you start up your fiber channel and
your metadata network switches, followed by the servers

00:16:18.870 --> 00:16:22.610
that are not related to Xsan but provide services.

00:16:22.610 --> 00:16:27.810
Especially DNS and Open Directory so that
the users can have access to all those.

00:16:27.809 --> 00:16:33.129
Next you want to get your storage up and
running and you want to make sure that the,

00:16:33.129 --> 00:16:37.279
on the Xserve RAID that you got four you know
green lights for each controller that's a part

00:16:37.279 --> 00:16:41.949
of the Xsan environment before you, before you go on.

00:16:41.950 --> 00:16:47.360
Next you want to start up the primary MDC
and then you want to go with the secondary.

00:16:47.360 --> 00:16:50.470
And then you fire up all your Xsan clients.

00:16:50.470 --> 00:16:55.440
And then you start the volume and you
mount the volumes onto your clients.

00:16:55.440 --> 00:16:59.430
Let's talk a little bit about directory
integration and ACLs.

00:16:59.429 --> 00:17:07.220
Because with Xsan 1.4, we introduced ACLs
as a part of the, of the Xsan package.

00:17:07.220 --> 00:17:15.370
And this is a great feature because it allows us an enormous
amount of flexibility when it comes to assigning groups

00:17:15.369 --> 00:17:21.399
and permissions and you can get really granular
at decided who's going to have access to what.

00:17:21.400 --> 00:17:28.900
It makes it really easy for you to allow the users that
are in your environment to collaborate on projects,

00:17:28.900 --> 00:17:35.850
you know be it video editors that need access to the same
files or, or you know however you want it to configure it.

00:17:35.849 --> 00:17:43.990
For those of you that deployed Xsan prior to
version 1.4, you can enable this retroactively.

00:17:43.990 --> 00:17:51.029
Once you upgrade to 1.4 make sure your volumes are
shut down, stopped and no clients have the volumes mounted.

00:17:51.029 --> 00:17:57.450
Then you can use Xsan admin and enable this on the volume.

00:17:57.450 --> 00:18:05.799
Excuse me, the ACLs will also help you with the, with the
umask problems, when not problem but work around rather

00:18:05.799 --> 00:18:12.049
that we saw when, when we, you wanted to allow
users to share some of the same information.

00:18:12.049 --> 00:18:20.629
The umask would allow people to get access to files to
folders by the SAN by modifying the umask for the user.

00:18:20.630 --> 00:18:24.250
And this right here negates the need to set that up.

00:18:24.250 --> 00:18:25.839
I know it's quite messy.

00:18:25.839 --> 00:18:31.119
Workgroup manager, you use that to assign to
ACLs on to Xsan just as you would assign ACLs

00:18:31.119 --> 00:18:34.689
on any other file system for OS X server.

00:18:34.690 --> 00:18:41.740
So you fire up your workgroup manager, you find
the Xsan storage and you, you use your OD users

00:18:41.740 --> 00:18:49.099
and you assign permissions like you
would as if Xsan was not involved.

00:18:49.099 --> 00:18:56.469
You want to make sure that if you deploy ACLs that
you don't use ACLs on your Final Cut pro scratch base.

00:18:56.470 --> 00:19:01.700
Because of performance, there's a potential
of dropped frames if you doing some ingesting

00:19:01.700 --> 00:19:05.029
and there are ACLs on the scratch space.

00:19:05.029 --> 00:19:11.500
ACLs will, there is a little bit of additional read
write activity there to resolve membership using ACLs.

00:19:11.500 --> 00:19:13.700
And better safe than sorry.

00:19:13.700 --> 00:19:22.200
As far as DNS goes, we have seen that it's
better to have as much DNS as you can here.

00:19:22.200 --> 00:19:27.160
We want to make sure that your forward
and reverse records are in place.

00:19:27.160 --> 00:19:31.670
And you want to make sure that you have that
for both the private and the metadata network.

00:19:31.670 --> 00:19:40.160
And if you're not sure if DNS is working or
not working, Xsan admin will tell you right away

00:19:40.160 --> 00:19:46.740
because you'll have a general sluggishness when
refreshing basically anything in Xsan admin.

00:19:46.740 --> 00:19:51.009
Refreshing volumes, refreshing to look at the LUNs.

00:19:51.009 --> 00:19:55.900
So it's very, very important that your DNS
infrastructure is set up and it's up and running.

00:19:55.900 --> 00:20:00.600
Once you have that piece figured
out Xsan performance is great.

00:20:00.599 --> 00:20:02.769
It's smooth sailing.

00:20:02.769 --> 00:20:08.579
Also you want to make sure that you know you spanning tree,
if that's running that you use Port Fast to make sure

00:20:08.579 --> 00:20:11.359
that those ports are really up and running as soon

00:20:11.359 --> 00:20:17.389
as the client network interface has been
initialized if you had to reboot a SAN client.

00:20:17.390 --> 00:20:26.070
If you're not sure what the FSM, the file system is
doing with regards to DNS, you can Use LSOF and you can,

00:20:26.069 --> 00:20:28.970
you can grep for the, for the FSM process.

00:20:28.970 --> 00:20:33.819
And the switch is there, -ni4 will
basically do a translation of all IP addresses

00:20:33.819 --> 00:20:37.539
to DNS servers using you know regular IP version 4

00:20:37.539 --> 00:20:43.869
and then it will tell you exactly what
kind of name resolution that's happening.

00:20:43.869 --> 00:20:46.889
Make sure your host name is set right
on all the clients and all the servers.

00:20:46.890 --> 00:20:54.990
The best way to do this is using scutil with a switch
set HostName then followed by fully qualified domain name.

00:20:54.990 --> 00:20:57.559
And verify your records please.

00:20:57.559 --> 00:20:58.849
Verify them a lot.

00:20:58.849 --> 00:21:03.689
Make sure that you know nsLookup
can resolve or dig or use hostname.

00:21:03.690 --> 00:21:12.990
But we really want to make sure that your DNS infrastructure
is good because it's going to help you in the long run.

00:21:12.990 --> 00:21:20.829
You can definitely have, if you decide to host your own
DNS records, then you can set up DNS server on OD master.

00:21:20.829 --> 00:21:23.799
Given you know one of the metadata controllers

00:21:23.799 --> 00:21:28.200
You can host a public zone and a private zone
on the same DNS server, that's not a problem.

00:21:28.200 --> 00:21:33.170
As long as you can just resolve on both
of the two, both of the two networks.

00:21:33.170 --> 00:21:39.500
Label your network interfaces because if you
have the fire wire interface there,

00:21:39.500 --> 00:21:44.069
you have, if you have Kona cards installed
and they throw some network interfaces in there

00:21:44.069 --> 00:21:46.899
and so its just good practice if you label your interfaces.

00:21:46.900 --> 00:21:50.780
For example, you know private LAN
or metadata LAN and public.

00:21:50.779 --> 00:21:53.609
Because when you're in there troubleshooting,
you want to make sure that you know

00:21:53.609 --> 00:21:55.699
which network interface you're looking at.

00:21:55.700 --> 00:22:00.580
And to make it even less messier, disable
the ones that you know you're not going to use.

00:22:00.579 --> 00:22:06.289
And with that, I'm going to turn it over to JD and
he is going to go talk more about fiber channel.

00:22:06.289 --> 00:22:06.549
Thank you.

00:22:06.549 --> 00:22:07.159
( Applause )

00:22:07.160 --> 00:22:09.870
>> Thank you man, good job.

00:22:09.869 --> 00:22:12.339
( Applause )

00:22:12.339 --> 00:22:16.709
So let's talk a little bit about
optimizing your fiber channel switch.

00:22:16.710 --> 00:22:23.569
And, and first you know I wanted to quickly chat about okay
a lot of people have datacenters in one area of the building

00:22:23.569 --> 00:22:27.750
and they have their editing suites or
their SAN or their storage in some other,

00:22:27.750 --> 00:22:30.670
or clients on some other side of the building.

00:22:30.670 --> 00:22:32.470
How do you interconnect both?

00:22:32.470 --> 00:22:37.009
And, and I just wanted to make sure
that you guys, I understand that,

00:22:37.009 --> 00:22:39.650
you know with fiber optics, it
makes it obviously a lot easier.

00:22:39.650 --> 00:22:46.930
The standard transceivers that you'll buy from, from Apple
or the Finisar transceivers go up to 500 meters.

00:22:46.930 --> 00:22:52.140
So you do have quite a nice length to
allow you to interconnect work stations to,

00:22:52.140 --> 00:22:58.030
to the back end fiber channel switch that might
be, that will be probably in your datacenter.

00:22:58.029 --> 00:23:05.059
Another thing you can do as well is if you have a large
amount of storage and your workstations are definitely

00:23:05.059 --> 00:23:08.990
on the other side of the building, you could
potentially segregate and have a front end set

00:23:08.990 --> 00:23:15.440
up of fiber channel switches and a backend set up of
fiber channel switches and kind of ISL those two sets

00:23:15.440 --> 00:23:19.690
of switches between the two, the two locations.

00:23:19.690 --> 00:23:25.330
And, and again you can use 2GB using the standard
transceivers but you'd probably need a lot of those

00:23:25.329 --> 00:23:28.849
because you want to have a really nice fat
pipe between the two sets of switches.

00:23:28.849 --> 00:23:33.000
Or you can also use some of the newer
10GB transceivers that are available.

00:23:33.000 --> 00:23:34.480
Those are a little bit more expensive.

00:23:34.480 --> 00:23:36.480
They're in the $2000 dollar price range.

00:23:36.480 --> 00:23:39.740
But they'll give you, you know 10GB for
each of those transceivers.

00:23:39.740 --> 00:23:42.370
And we usually recommend you get four of them right?

00:23:42.369 --> 00:23:43.609
Always redundancy.

00:23:43.609 --> 00:23:47.979
So make sure you put two on the, on the front
end set of switches and two on the back end and,

00:23:47.980 --> 00:23:51.410
and pull two pairs of cable between, between the two.

00:23:51.410 --> 00:23:57.300
Another we run into is people sometimes
have a tendency to again try to cut corners.

00:23:57.299 --> 00:23:59.649
And they'll try to pull fiber themselves.

00:23:59.650 --> 00:24:04.060
And if you're not certified and you don't know
what you're doing, I mean fiber is not Ethernet.

00:24:04.059 --> 00:24:11.399
So the days where you know we can pull cat-5 cable is
kind of nice, but cat-6 and fiber optics require people

00:24:11.400 --> 00:24:14.100
who have good skills and good certifications.

00:24:14.099 --> 00:24:19.059
So make sure you spend you know the $10,000 dollars
or whatever to get a guy who can pull fiber

00:24:19.059 --> 00:24:23.250
and actually test every strand of
fiber within that he just deployed.

00:24:23.250 --> 00:24:30.150
And at the end, he should give you a dB loss on
each of those, those strands that have been tested.

00:24:30.150 --> 00:24:36.080
Very similar to when you buy a 10 meter or a
25 meter optical cable from you know a vendor,

00:24:36.079 --> 00:24:41.359
there's a little paper that comes in that bag that
tells you the dB loss for each of those cables.

00:24:41.359 --> 00:24:46.719
Make sure you get that done, because if you start
having dropped frames on your SAN it could very well be

00:24:46.720 --> 00:24:50.329
that there's a bad fiber, there's
a bad cable on your network.

00:24:50.329 --> 00:24:54.789
So, so just best practice is make sure you do that.

00:24:54.789 --> 00:25:01.159
But let's talk a little bit about kind of
how do I lay out my data on, on my SAN?

00:25:01.160 --> 00:25:08.130
And in this example this is actually a real world
example and this customer has a SanBox 2-64.

00:25:08.130 --> 00:25:14.370
Okay, so they're not, they haven't deployed the
newer, the new switches, but kind of an older switch.

00:25:14.369 --> 00:25:17.799
But it's a switch that's been widely deployed everywhere.

00:25:17.799 --> 00:25:20.869
And so how do you, how do you kind of group things around?

00:25:20.869 --> 00:25:25.799
Well, the first thing you want to do is you kind of
want to make sure that your metadata server

00:25:25.799 --> 00:25:29.839
and your metadata LUN are on the same blade.

00:25:29.839 --> 00:25:36.569
Okay, because you know again the metadata
LUN will only talk to the metadata servers.

00:25:36.569 --> 00:25:39.500
The clients will never write to the metadata LUN, okay?

00:25:39.500 --> 00:25:41.069
Only the metadata servers.

00:25:41.069 --> 00:25:45.259
So make sure that even if you deploy you know
in a smaller environment and you have a couple

00:25:45.259 --> 00:25:51.180
of you know 16-port fiber channel switch, make sure
that the metadata server and the metadata LUN are

00:25:51.180 --> 00:25:54.769
on the same switch, okay, because
you want the lowest latency possible.

00:25:54.769 --> 00:25:59.230
You always want to think about latency in
making the distance as short as possible.

00:25:59.230 --> 00:26:02.640
So you want those to be on the
same blade or on the same switch.

00:26:02.640 --> 00:26:06.500
The next thing you want to do is you're
obviously going to build storage pools, right?

00:26:06.500 --> 00:26:09.940
And we'll talk about best practices around storage pools.

00:26:09.940 --> 00:26:15.460
But in this situation what we did is we
built four storage pools of four LUNs each.

00:26:15.460 --> 00:26:22.819
Okay? so what we did is we put for the storage pool
number one, we put storage pool number one on a blade,

00:26:22.819 --> 00:26:26.230
storage pool number two on a second
blade, and then storage pool number three

00:26:26.230 --> 00:26:28.420
on a third blade, which is slot seven and slot eight.

00:26:28.420 --> 00:26:32.750
So we made sure we kind of grouped those LUNs
together because again when you were writing data

00:26:32.750 --> 00:26:39.809
to specific storage pool, you're writing in a stripe way
like we discussed earlier, in writing that data in parallel

00:26:39.809 --> 00:26:43.220
to all four of those LUNs that are within a storage pool.

00:26:43.220 --> 00:26:47.240
So make sure you put those again on the same switch.

00:26:47.240 --> 00:26:50.750
And that again will really optimize your, your throughput.

00:26:50.750 --> 00:26:54.970
And then what we did is we put all
the clients machine around that.

00:26:54.970 --> 00:26:59.400
Right? Again for lower latency, when those
clients are going to write to those storage pools,

00:26:59.400 --> 00:27:02.300
you want to make sure they have again
the lowest latency possible.

00:27:02.299 --> 00:27:06.490
So put those, always put your, your
storage kind of like the core of the switch

00:27:06.490 --> 00:27:09.730
and put your clients around you know around it.

00:27:09.730 --> 00:27:15.380
And then what we did is we had a tape library
right, because back up is really important, right.

00:27:15.380 --> 00:27:18.590
Obviously all of you back up in this room, I'm sure of it.

00:27:18.589 --> 00:27:23.759
And in that situation, you know the customer is kind of
running out of ports on their, their high end switch,

00:27:23.759 --> 00:27:25.910
so they bought a more entry level switch.

00:27:25.910 --> 00:27:28.090
And really that's perfect for the tape back up.

00:27:28.089 --> 00:27:32.559
You pull a couple ISL cables, you interconnect
those two switches and you put your tape library

00:27:32.559 --> 00:27:37.210
and kind of like your graphics machines, kind of
the lower throughput machines on a kind of

00:27:37.210 --> 00:27:42.700
of a more entry level switch in your, your cool with that.

00:27:42.700 --> 00:27:49.269
On the QLogic side, some of the optimization
settings that you want to be aware of.

00:27:49.269 --> 00:27:55.559
If you have multiple 16-port fiber channel
switches or 20-port fiber channel switches

00:27:55.559 --> 00:28:01.990
if you count the 10GB interconnects, you
want to make sure that you lock the domain ID.

00:28:01.990 --> 00:28:06.609
Anyone remember the SCII days, the old SCII days where
you had a little SCII wheel and you put the number,

00:28:06.609 --> 00:28:08.839
you punch in the number from zero to seven?

00:28:08.839 --> 00:28:17.549
Okay, well in the, in the QLogic web
interface, its something kind of similar.

00:28:17.549 --> 00:28:21.919
Where by default every switch that you're
going to buy is going to have an ID of one.

00:28:21.920 --> 00:28:23.130
And it's all fine and dandy.

00:28:23.130 --> 00:28:26.730
You're probably going, you're going to do your
setup, you're going to power the first switch,

00:28:26.730 --> 00:28:30.230
you're going to power the second switch, you're going to
power the third switch and they're going to take,

00:28:30.230 --> 00:28:34.380
you know they're automatically going to
go ID 1, 2, and 3, which is all great.

00:28:34.380 --> 00:28:37.730
But what happens if there is a power failure?

00:28:37.730 --> 00:28:43.360
If there's a power failure, they're all going to come up at
the same time and they're all going to take an ID of one.

00:28:43.359 --> 00:28:49.439
So you want to make sure that the first thing that you do is
you go in and lock the ID and lock it down to 1, 2, and 3,

00:28:49.440 --> 00:28:52.630
and 4 and 5 and you know again if you have
five switches, make sure you lock them down.

00:28:52.630 --> 00:28:59.750
Just best practices because if that doesn't happen,
you will, you will get into some interesting scenarios.

00:28:59.750 --> 00:29:05.859
The other thing you want to do is you want to
make sure that on the, on the client side,

00:29:05.859 --> 00:29:10.569
you want to enable IO Stream Guard
and you want to disable Device Scan.

00:29:10.569 --> 00:29:17.009
Okay? So again, once all your clients are on the
switch, and they're working and they're all lit up

00:29:17.009 --> 00:29:19.660
and everything is fine, make sure
you disable the Device Scan

00:29:19.660 --> 00:29:22.640
because it scanned the device,
so it knows where the device is.

00:29:22.640 --> 00:29:25.710
So there's no need to scan the device again, right?

00:29:25.710 --> 00:29:30.400
And one would hope that you're not moving fiber channel
ports around and moving machines around all the time.

00:29:30.400 --> 00:29:32.019
So make sure you disable that.

00:29:32.019 --> 00:29:34.049
And enable IO Stream Guard.

00:29:34.049 --> 00:29:38.930
On the Xserve RAID, the Xserve RAID
uses a QLogic controller on the RAID.

00:29:38.930 --> 00:29:40.660
So you can leave it on auto.

00:29:40.660 --> 00:29:45.960
It's smart enough to know that the Xserve RAID is
actually storage which is considered a target device.

00:29:45.960 --> 00:29:48.920
And it will automatically disable IO Stream Guard.

00:29:48.920 --> 00:29:55.519
If you want to be super safe, just go ahead and disable
it on the, on the initiators, on the targets I'm sorry

00:29:55.519 --> 00:29:57.900
which is your storage and your tape libraries.

00:29:57.900 --> 00:30:05.730
Let's talk about Xsan you know volume
configurations, kind of like best practices around that.

00:30:05.730 --> 00:30:15.849
What we found is that you know a lot of customers in,
in this room I'm sure want to build very large volumes.

00:30:15.849 --> 00:30:20.709
And or in the early days, what we used
to do is build a single storage pool

00:30:20.710 --> 00:30:24.440
and put all the LUNs in one single storage pool.

00:30:24.440 --> 00:30:31.269
And what we uncovered is really what happens is a lot
of disk contention that's happening when you do that.

00:30:31.269 --> 00:30:36.009
And some of you might have run into situations where
when you're trying to ingest, you kind of hit this,

00:30:36.009 --> 00:30:39.269
this limit where you know you're ingesting a lot of data.

00:30:39.269 --> 00:30:43.700
You can't really ingest more than like you know
800 MB per second or something in that area.

00:30:43.700 --> 00:30:48.160
If you, if you build one single
storage pool with, with a lot of LUNs.

00:30:48.160 --> 00:30:54.870
And what you also, what also happens is then you run into
situations where you've got your, your SAN up and going,

00:30:54.869 --> 00:30:56.629
but a year down the road you're like you know what?

00:30:56.630 --> 00:30:59.050
I want to expand my SAN.

00:30:59.049 --> 00:31:03.549
And when that happens, you know you really
need to keep everything symmetrical.

00:31:03.549 --> 00:31:09.980
So if you have a storage pool with 10 LUNs, it probably
means that you have to buy another five Xserve RAIDs

00:31:09.980 --> 00:31:12.670
and build another storage pool with ten LUNs.

00:31:12.670 --> 00:31:15.440
Again to make sure everything is, is
very balanced and very symmetrical.

00:31:15.440 --> 00:31:22.850
So what we found is kind of the best, the best
way to, to kind of work this and make sure

00:31:22.849 --> 00:31:26.299
that you've got the lowest amount
of, of disk contention when you,

00:31:26.299 --> 00:31:30.139
when you build that, is to build smaller storage pools.

00:31:30.140 --> 00:31:34.540
And kind of the, the mix that we
found is four LUNs per storage pool,

00:31:34.539 --> 00:31:38.549
four to six LUNs per storage pool
is kind of like best practices.

00:31:38.549 --> 00:31:44.579
And that'll give you per storage
pool about 320 MB per second.

00:31:44.579 --> 00:31:50.710
But assume you have four storage pools, your getting
up to 1200 MB per second of throughput.

00:31:50.710 --> 00:31:56.890
And Xsan is very smart about you know writing
the data across different storage pool

00:31:56.890 --> 00:31:59.350
and segmenting your data across the storage pools.

00:31:59.349 --> 00:32:04.819
So from an editing perspective, the people that are actually
then editing the videos, those videos are going to get laid

00:32:04.819 --> 00:32:07.509
down very nicely across the multiple storage pools.

00:32:07.509 --> 00:32:13.809
So you really you're not going to get stuck where you know
one single machine is going to use the full 320 MB off

00:32:13.809 --> 00:32:15.470
that single storage pool.

00:32:15.470 --> 00:32:18.920
So just keep that in mind.

00:32:18.920 --> 00:32:22.820
That's kind of like the, the best practices
around, around you know creating volumes.

00:32:22.819 --> 00:32:27.589
But again, you know test it, make sure
all that works for, for your situation.

00:32:27.589 --> 00:32:32.039
And then, and then really you know in terms
of the metadata size, just, just so you know,

00:32:32.039 --> 00:32:35.319
if you have about 10 million files
you need about 10GB of space.

00:32:35.319 --> 00:32:39.869
So its not a matter of you know the metadata LUN.

00:32:39.869 --> 00:32:42.539
You're probably never going to exceed
the size of your metadata LUN.

00:32:42.539 --> 00:32:48.009
So our recommendation is just get 500GB drives which
are really nice, you know fast drives and use those

00:32:48.009 --> 00:32:54.390
for your metadata LUN and you're never going to see that
500GB of space on your, on your LUN potentially.

00:32:54.390 --> 00:32:56.480
Unless you use this for archiving.

00:32:56.480 --> 00:33:02.120
And if you're using that for archiving, you could, you
know we did have customer who had like 600 million files.

00:33:02.119 --> 00:33:05.779
And in that situation we did a zero
plus one on the metadata side.

00:33:05.779 --> 00:33:08.980
But again, it was not a video, it was not a video customer.

00:33:08.980 --> 00:33:13.450
And each volume will require about 512 MB of RAM.

00:33:13.450 --> 00:33:16.580
So make sure you've got plenty
of RAM on your metadata servers.

00:33:16.579 --> 00:33:30.629
So again just to illustrate this, kind of best practices for
us now a days is four LUNs per storage pool, 16K block size,

00:33:30.630 --> 00:33:36.240
round robin obviously because you want it to go
across the different storage pools that you're,

00:33:36.240 --> 00:33:42.039
you're putting together, obviously
enable ACLs, that just standard now.

00:33:42.039 --> 00:33:46.700
You also want to set up the stride breadth to 64 which
again, dyou know usually you want it to be a multiple

00:33:46.700 --> 00:33:50.970
of 1MB and when you do 16K block size times 64,

00:33:50.970 --> 00:33:56.339
it equals 1MB which is exactly how you
want to optimize it for your, for your Xserve RAID.

00:33:56.339 --> 00:33:59.769
And obviously rotate for the, the multipath method.

00:33:59.769 --> 00:34:04.839
And then, and then this is a typical
you know SAN deployment.

00:34:04.839 --> 00:34:11.360
In this situation where you again you've got four storage
pools and you've got four LUNs per, per storage pool.

00:34:11.360 --> 00:34:17.150
And you want to if possible, you want to
keep in an even number of LUNs.

00:34:17.150 --> 00:34:21.110
So you get a little bit of a performance
degradation if you do odd numbers.

00:34:21.110 --> 00:34:25.380
So try to keep it in an odd, in an
even number of LUNs per storage pool.

00:34:25.380 --> 00:34:31.030
So let's talk a little bit about affinities.

00:34:31.030 --> 00:34:37.280
Because affinities are very powerful but we just want to
make sure that we kind of get a high level overview

00:34:37.280 --> 00:34:39.840
of how you would want to implement affinities.

00:34:39.840 --> 00:34:47.070
So affinities really allow you to steer the data
based upon a policy that, that you would set up.

00:34:47.070 --> 00:34:53.340
So a good example to set up affinity would be, hey
I want all my Final Cut projects, because again,

00:34:53.340 --> 00:34:56.400
those Final Cut projects are kind of small, tiny files.

00:34:56.400 --> 00:35:00.440
You know in, you know 400K to a MB potentially on average.

00:35:00.440 --> 00:35:06.570
Lets say I want to dedicate a LUN to you
know to for the Final Cut projects.

00:35:06.570 --> 00:35:07.220
So you can do that.

00:35:07.219 --> 00:35:13.419
You can set up an affinity and call it you know projects
and have all your users store all their project in a, on,

00:35:13.420 --> 00:35:20.840
on a dedicated, on a dedicate storage pool that has an
affinity attached to it where people store their projects.

00:35:20.840 --> 00:35:27.220
Maybe a bad example of using affinities is,
is you know trying to do an ingest affinity

00:35:27.219 --> 00:35:30.039
and an edit affinity and a play out affinity.

00:35:30.039 --> 00:35:31.539
And, and why is that?

00:35:31.539 --> 00:35:39.690
Well, simply because let's assume you
ingest video on your ingest affinity.

00:35:39.690 --> 00:35:43.539
And then you have your editor that
takes that file and copies it

00:35:43.539 --> 00:35:47.029
from the ingest affinity over to the edit affinity.

00:35:47.030 --> 00:35:51.190
Its not really copying, its not really copying the file.

00:35:51.190 --> 00:35:54.240
Okay, it's only copying and moving the header of that file.

00:35:54.239 --> 00:35:59.419
So when that editor starts to edit the, the
file, it's actually playing off the disks

00:35:59.420 --> 00:36:03.400
that you've dedicated for your ingest side of the house.

00:36:03.400 --> 00:36:10.349
The, the way to move the file is to option copy it and this
time its actually really moving all the blocks of the file

00:36:10.349 --> 00:36:13.369
and moving it over to the, to the edit side of the house.

00:36:13.369 --> 00:36:20.199
And what we've seen is, is a lot of corporations
use you know freelancers to do a lot of work.

00:36:20.199 --> 00:36:25.809
And in that situation, try to go train a
freelancer to option click copy a file over.

00:36:25.809 --> 00:36:27.259
Not the easiest thing in the world.

00:36:27.260 --> 00:36:34.170
So make sure you, you, if you do implement affinities, make
sure you, you understand how affinities work and again,

00:36:34.170 --> 00:36:37.659
very powerful but use them and use them properly.

00:36:37.659 --> 00:36:42.559
Let's talk about backing up your config files.

00:36:42.559 --> 00:36:48.420
Because that's something that as soon as you have
your SAN up and running, you should be doing.

00:36:48.420 --> 00:36:51.610
And you know it's very simple.

00:36:51.610 --> 00:36:56.200
You just run cvgather -f with your volume name.

00:36:56.199 --> 00:37:02.239
And that will basically you know archive not
only the config file but the .cfg file,

00:37:02.239 --> 00:37:05.500
but also you know my logs and other information.

00:37:05.500 --> 00:37:08.969
And you want to do that on both metadata servers.

00:37:08.969 --> 00:37:16.619
And once you have that config file, you want to take
it, burn it to a CD, store it in a, in a safe place.

00:37:16.619 --> 00:37:26.059
Because if you ever have a situation where for example,
we had this happen so I'll share that with you.

00:37:26.059 --> 00:37:29.799
Customer plugged in some Windows servers.

00:37:29.800 --> 00:37:34.180
Right? And they hadn't, they hadn't, they
just plugged it into the fiber channel switch.

00:37:34.179 --> 00:37:37.849
They had not logged StoreNext FX on those machines.

00:37:37.849 --> 00:37:40.819
And they opened up the disk manager on Windows.

00:37:40.820 --> 00:37:45.070
Well the disk management has this little set up
assistant saying hey, I see a whole bunch of LUNs.

00:37:45.070 --> 00:37:46.440
You want me to work with them?

00:37:46.440 --> 00:37:51.500
And what happens is it goes in and unlabels
all your LUNs and your SAN goes offline.

00:37:51.500 --> 00:37:55.590
Okay? Just a bad situation to be in.

00:37:55.590 --> 00:38:03.980
Good news is we had a backup of the, of the config file,
so we were able to use CV label and reload all the,

00:38:03.980 --> 00:38:08.519
the labels on the LUNs and get the SAN
you know back up and going in a few hours.

00:38:08.519 --> 00:38:11.730
But just a situation you don't want to get into.

00:38:11.730 --> 00:38:13.460
And, and just make sure you back it up.

00:38:13.460 --> 00:38:14.300
Its, its simple.

00:38:14.300 --> 00:38:15.150
It's a small file.

00:38:15.150 --> 00:38:16.700
Just, just back it up.

00:38:16.699 --> 00:38:21.949
And, and every time you make a change to
your SAN, make sure you, you do that again.

00:38:21.949 --> 00:38:26.219
So again what we recommend is just
maybe set up a cron job right?

00:38:26.219 --> 00:38:29.750
Or use launch D or you know just to
back up that file on a regular basis.

00:38:29.750 --> 00:38:34.739
The other thing is, let's assume you run
into a situation where you do have an issue.

00:38:34.739 --> 00:38:39.119
You want to, you know you want to go back to
the log that actually has the real error.

00:38:39.119 --> 00:38:42.469
Because your log is going to get filled
with the same error over and over again.

00:38:42.469 --> 00:38:45.069
So make, so that allows you to
go back and actually see, aha!

00:38:45.070 --> 00:38:46.840
That's really what happened to my SAN.

00:38:46.840 --> 00:38:48.260
This is how I can fix it.

00:38:48.260 --> 00:38:52.110
And then the next step is really backing up your data.

00:38:52.110 --> 00:38:55.450
Right? You're setting up a RAID-5,
you've got hot spares, that's all great.

00:38:55.449 --> 00:38:58.909
But what happens if something happens
to your building, right?

00:38:58.909 --> 00:39:03.639
You've got to have some way of replicating
the data, either disk to disk

00:39:03.639 --> 00:39:06.960
or at least disk to tape and take that data offsite.

00:39:06.960 --> 00:39:10.510
So there's a couple of really you know good vendors.

00:39:10.510 --> 00:39:17.100
Atempo, ARCHIWARE is a European product that
we've had a lot of you know good success with.

00:39:17.099 --> 00:39:19.759
And the product that's called PresStore

00:39:19.760 --> 00:39:22.950
and then you obviously have the BackBone
which also does you know really well.

00:39:22.949 --> 00:39:30.769
So those are kind of like the three solutions that have both
client and server solutions available on the, on the Mac.

00:39:30.769 --> 00:39:37.940
So you don't have to rely on your IT person whose running
his Tivoli server and or his you know Veritas server

00:39:37.940 --> 00:39:44.440
and back up you know 10 or 20 terabytes
over a gigabit Ethernet using the Tivoli

00:39:44.440 --> 00:39:48.690
or the Veritas client available on the Mac.

00:39:48.690 --> 00:39:53.559
And then lets quickly talk about configuring your tape back
up unit, because that's something else you need to be aware

00:39:53.559 --> 00:39:57.259
of is when you configure your tape back up unit,
you need to make sure that you create a zone,

00:39:57.260 --> 00:40:04.150
a soft zone on your QLogic and assign all the
ports of that dedicated you know backup server.

00:40:04.150 --> 00:40:09.570
Make sure you have one of the fiber channel ports
and all the ports of the tape library in a soft zone.

00:40:09.570 --> 00:40:13.400
Again our fiber channel driver is very
smart and does a lot of really nice things

00:40:13.400 --> 00:40:15.789
in terms of balancing the data for video.

00:40:15.789 --> 00:40:21.039
But in the backup situation, you want to make sure
you've got a dedicated port for your back up.

00:40:21.039 --> 00:40:22.789
So make sure you do that.

00:40:22.789 --> 00:40:25.590
And then migrating data.

00:40:25.590 --> 00:40:26.890
So this is kind of interesting.

00:40:26.889 --> 00:40:33.289
We, we we're getting into now more and more situations
where a customer have, they've had a SAN deployed

00:40:33.289 --> 00:40:38.820
and they now want to upgrade the SAN and in some
situations they have not configured it best practices,

00:40:38.820 --> 00:40:40.120
so you need to back up all your data.

00:40:40.119 --> 00:40:47.089
And what we found is a good way to back it up is actually
to build a new SAN, kind of like a back up SAN and,

00:40:47.090 --> 00:40:54.500
and that allows us to quickly mount the two volumes and
copy the data from the, the original SAN to the backup SAN,

00:40:54.500 --> 00:40:57.599
reconfigure the original SAN and copy the data backup.

00:40:57.599 --> 00:41:03.230
And this example we copied about 10 terabytes
of data in about 11 hours off a single client.

00:41:03.230 --> 00:41:07.740
So very, very fast way to actually back up your data.

00:41:07.739 --> 00:41:14.500
Make sure that you have a UPS as well on those arrays
that you might be using temporarily to do your backup.

00:41:14.500 --> 00:41:16.949
You know again, one more thing just to be cautious.

00:41:16.949 --> 00:41:17.710
You never know.

00:41:17.710 --> 00:41:19.889
Murphy's Law right?

00:41:19.889 --> 00:41:21.519
How do you repair your SAN?

00:41:21.519 --> 00:41:25.929
Again, first thing you should do is call AppleCare, right?

00:41:25.929 --> 00:41:31.089
All of you have I mean at least in the US and people
who are in countries where AppleCare is supported,

00:41:31.090 --> 00:41:36.400
you should have your Xsan support agreement and you should
have Xsan support on and make sure you call AppleCare.

00:41:36.400 --> 00:41:38.240
That's the first thing that I would recommend.

00:41:38.239 --> 00:41:41.939
And then you can also follow up with the
article number that's up there on how

00:41:41.940 --> 00:41:45.320
to actually you know run it in read only.

00:41:45.320 --> 00:41:51.910
For instance run a cvfsck and then after the
problem is detected, use the -w option.

00:41:51.909 --> 00:41:54.210
Measuring performance on your SAN.

00:41:54.210 --> 00:42:01.340
So you know we kind of use, we use the Xsan
you know tuning tool that we have, which is,

00:42:01.340 --> 00:42:04.430
which is nice, but its not really real world.

00:42:04.429 --> 00:42:08.019
So you're really, you know this is great to make
sure you don't have like a bad cable or you're,

00:42:08.019 --> 00:42:09.989
you're getting the throughput you're expecting.

00:42:09.989 --> 00:42:14.639
But really, you know you want to use the application
you're going to be you know using on your SAN.

00:42:14.639 --> 00:42:20.989
So make sure that once you, you run the Xsan tuner and
everything looks okay, you want to then switch to Final Cut

00:42:20.989 --> 00:42:25.869
and make sure you're using the application
you're, you're deploying on, on the SAN.

00:42:25.869 --> 00:42:32.569
And also make sure that you're actually, that, that you
know that third party application you might want to use

00:42:32.570 --> 00:42:36.269
against Xsan has been tested against the product.

00:42:36.269 --> 00:42:41.239
I had a customer wanting to backup their
SAN and they started using ChronoSync.

00:42:41.239 --> 00:42:46.319
Well, I mean do you think ChronoSync
has ever heard or has ever tested with Xsan?

00:42:46.320 --> 00:42:47.200
Probably not.

00:42:47.199 --> 00:42:52.559
And you know when they started launching ChronoSync,
it said that their backup would be done in about two months.

00:42:52.559 --> 00:42:53.840
( Laughter )

00:42:53.840 --> 00:42:55.910
So again, not a good situation.

00:42:55.909 --> 00:43:01.849
And we just said well you know just use CVCP, it just,
its just fine, CVCP or CP and those are the tools

00:43:01.849 --> 00:43:04.480
that allow you to actually back up your SAN properly.

00:43:04.480 --> 00:43:07.590
And they did that and then the
number came down to two hours.

00:43:07.590 --> 00:43:10.880
So just make sure you do that.

00:43:10.880 --> 00:43:14.780
And then quickly, you know again, best practices.

00:43:14.780 --> 00:43:17.490
We talk about the DNS, Stle insisted on that.

00:43:17.489 --> 00:43:18.489
It's really important.

00:43:18.489 --> 00:43:20.779
So make sure you do that.

00:43:20.780 --> 00:43:23.670
Make sure your date and time is
synchronized on all the machines.

00:43:23.670 --> 00:43:25.130
Okay, that's also really important.

00:43:25.130 --> 00:43:29.780
Make sure you got a good NTP server working and
you're not blocking it from your firewall perspective.

00:43:29.780 --> 00:43:32.760
Backup your config files, backup your logs.

00:43:32.760 --> 00:43:36.270
Make sure you plug in both Ethernet
ports on the Xserve RAID.

00:43:36.269 --> 00:43:41.800
There are situations which are probably fixed
on the 1.51 firmware, but we do have situations

00:43:41.800 --> 00:43:44.380
where the RAID still works but when you're in RAID admin,

00:43:44.380 --> 00:43:47.640
you get that spinning beach ball and
you can't manage your RAID anymore.

00:43:47.639 --> 00:43:52.029
By plugging both Ethernet ports,
you're, you'll be, you'll be good to go.

00:43:52.030 --> 00:43:54.240
Here's a new one.

00:43:54.239 --> 00:43:58.779
Make sure your Startup Disk is set
to point to the local hard drive.

00:43:58.780 --> 00:44:04.280
And, and the reason for that is because we, we now
have the new Intel, the new fiber channel cards

00:44:04.280 --> 00:44:09.510
that we had the 4GB fiber channel cards
will allow you to boot over fiber channel.

00:44:09.510 --> 00:44:13.390
And what's happening is if you don't have
it by default set to the local hard drive,

00:44:13.389 --> 00:44:20.489
it will spend you know a few minutes where the machine is
just going to be at a blue screen, not a Windows blue screen.

00:44:20.489 --> 00:44:24.299
And will just look to try and boot off a fiber channel.

00:44:24.300 --> 00:44:29.269
So make sure you, you point it to your local
hard drive and it's all, it's all going to be good.

00:44:29.269 --> 00:44:33.400
And then if you have a spares kit, which
every one of you should have a spare,

00:44:33.400 --> 00:44:35.780
an Xserve RAID spare kit when you buy a RAID.

00:44:35.780 --> 00:44:39.510
Usually one, you know one spares
kit for about five Xserve RAID.

00:44:39.510 --> 00:44:41.680
Make sure the firmware is up to date.

00:44:41.679 --> 00:44:45.579
Right? Because you're spares kit it
probably collecting dust on a shelf.

00:44:45.579 --> 00:44:49.000
And it's probably still running 1.3 or 1.5 firmware.

00:44:49.000 --> 00:44:52.389
So make sure you update the firmware on those.

00:44:52.389 --> 00:44:56.150
Don't use the defrag tool unless you have to use it.

00:44:56.150 --> 00:44:59.720
Okay, defragging is not quite optimized for Quick Time.

00:44:59.719 --> 00:45:05.319
So make sure you don't use it unless
you really you know your volume is full

00:45:05.320 --> 00:45:10.200
and if your volume is full you probably will have
other things to worry about like getting more storage.

00:45:10.199 --> 00:45:14.509
If you, you know another option is
if you're having some drop frames

00:45:14.510 --> 00:45:17.260
on a specific project, you might
want to just duplicate the file.

00:45:17.260 --> 00:45:21.180
Or duplicate the project and see if the problem goes away.

00:45:21.179 --> 00:45:24.489
Make sure you test your metadata fail over.

00:45:24.489 --> 00:45:32.559
And don't you know don't connect the two MDC servers
in the same you know power distribution circuit.

00:45:32.559 --> 00:45:34.570
Seems basic, but we see that happen all the time.

00:45:34.570 --> 00:45:38.850
And especially now that we have Xserve
RAIDs that have dual power supplies.

00:45:38.849 --> 00:45:41.449
Right? You guys are all excited about that right?

00:45:41.449 --> 00:45:45.849
Take advantage of it!

00:45:45.849 --> 00:45:49.279
Right? Connect each RAID, same thing, in a different PDU.

00:45:49.280 --> 00:45:52.320
Make sure you balance that across, okay.

00:45:52.320 --> 00:45:56.850
And, and again make sure that you
understand the bringing up and down process.

00:45:56.849 --> 00:46:03.019
Biggest thing that I've seen is if the SAN goes
down, it'll go down while you're sleeping, right?

00:46:03.019 --> 00:46:09.409
Make sure the guy that's actually on that night shift
knows what the bring up and bring down process is,

00:46:09.409 --> 00:46:14.139
so the best recommendation is just print that
out and stick in on the side of the rack.

00:46:14.139 --> 00:46:18.429
So he can actually follow it and, and do it properly.

00:46:18.429 --> 00:46:21.489
And make sure you have a UPS.

00:46:21.489 --> 00:46:25.939
You know? You know so many times I heard customer say
like, oh yeah, we've got central UPS, everything is good,

00:46:25.940 --> 00:46:28.019
you know it's all, it's all fine and dandy.

00:46:28.019 --> 00:46:28.969
But you know what?

00:46:28.969 --> 00:46:31.849
What happens if the breaker you know breaks?

00:46:31.849 --> 00:46:33.309
And you don't have a UPS?

00:46:33.309 --> 00:46:34.880
You can get into a problem.

00:46:34.880 --> 00:46:40.079
Or we had this customer that said, hey
you know we have 1200 amps of power.

00:46:40.079 --> 00:46:41.699
You know we're never going to have a problem.

00:46:41.699 --> 00:46:46.960
And then they call us and they say, oh well, the electrical
company is having to go in and switch the transformer

00:46:46.960 --> 00:46:52.510
and we're going to have to you know the whole facility
is going to have to run on UPS for 48 hours and,

00:46:52.510 --> 00:46:57.310
thank god we had a Symetra set up there,
because we would have been out of luck.

00:46:57.309 --> 00:46:58.769
So make sure you have UPSs.

00:46:58.769 --> 00:47:01.809
Those, it's also good to have two UPSs than one.

00:47:01.809 --> 00:47:07.279
And make sure you configure email notifications
on your Xserve and on your RAID and on your SAN

00:47:07.280 --> 00:47:09.280
so you get notified if there is a problem.

00:47:09.280 --> 00:47:14.260
Okay? If the RAID starts beeping, don't
just shut it, you know turn it off.

00:47:14.260 --> 00:47:15.180
Look at the logs.

00:47:15.179 --> 00:47:16.619
Go see what's going on.

00:47:16.619 --> 00:47:22.469
Okay? So that's kind of like best practices around Xsan.

00:47:22.469 --> 00:47:26.739
Now what I wanted to talk about is and
we, we talked about this last year.

00:47:26.739 --> 00:47:30.779
But we hadn't deployed really that solution.

00:47:30.780 --> 00:47:34.450
And now we've had quite a few under
our belt under the past 10 months.

00:47:34.449 --> 00:47:40.559
And, and I wanted to talk about kind of Xsan
and the more of a high availability situation.

00:47:40.559 --> 00:47:46.480
You know and again if you look at the requirements
from some of our customers, which are broadcasters,

00:47:46.480 --> 00:47:50.829
they want obviously very close to 100 percent up time
and there is no such thing as 100 percent up time.

00:47:50.829 --> 00:47:52.630
But they want something very close.

00:47:52.630 --> 00:47:53.829
They don't want any drop frames.

00:47:53.829 --> 00:47:57.289
They want some good workflows,
you know from ingest to error.

00:47:57.289 --> 00:48:02.579
So they might go with like a building for media
solution for, for that kind of, that kind of set up.

00:48:02.579 --> 00:48:06.849
And they want ability to quickly grow their storage.

00:48:06.849 --> 00:48:12.769
And, and again by following the guidelines that I
mentioned, where you have four LUNs per storage pool,

00:48:12.769 --> 00:48:17.570
its really easy to then create a new
storage pool, add four more new LUNs

00:48:17.570 --> 00:48:22.660
and present an increased volume
size very quickly with no down time.

00:48:22.659 --> 00:48:29.359
Okay that's again back to the whole point of smaller
storage pools as more storage pools is better.

00:48:29.360 --> 00:48:33.550
And, and also they want ability to
scale very easily from SD to HD.

00:48:33.550 --> 00:48:39.720
And we all know that you know with Apple's workflow and
with Final Cut, its just, it just works out of the box.

00:48:39.719 --> 00:48:45.750
So you can go very easily from SD to HD
with, with our products and our solutions.

00:48:45.750 --> 00:48:50.610
So we worked very closely with, with Viacom Technology.

00:48:50.610 --> 00:48:59.849
And they have this 1U appliance which basically
allows you to mirror, in real time your, your Xserve RAIDs.

00:48:59.849 --> 00:49:05.480
And it's just been, you know they have this great
UI that looks a little bit like you know RAID admin,

00:49:05.480 --> 00:49:07.849
very simple to use, very simple to configure.

00:49:07.849 --> 00:49:09.619
And very scalable.

00:49:09.619 --> 00:49:14.380
And you know here's a simple example
of a video broadcast example

00:49:14.380 --> 00:49:17.720
where you would have two RAIDs, mirror to two other RAIDs.

00:49:17.719 --> 00:49:21.389
And you obviously have in this
situation you want very high speed.

00:49:21.389 --> 00:49:23.000
So you would have two engines.

00:49:23.000 --> 00:49:26.679
And each engine mirrors you know one RAID.

00:49:26.679 --> 00:49:28.449
So you kind of have a two for one ratio.

00:49:28.449 --> 00:49:32.119
Two RAIDs for one, one Vicom dual engine.

00:49:32.119 --> 00:49:39.059
And, and we've just had a great amount of you know results
and the product has been very reliable over the past,

00:49:39.059 --> 00:49:43.529
over the past ten months in multiple locations.

00:49:43.530 --> 00:49:48.870
And what that allows you to do is to really
kind of have two fiber channel switches you know

00:49:48.869 --> 00:49:50.739
that are, that are independent.

00:49:50.739 --> 00:49:56.309
You have one metadata server being hosted off one switch
and well you would obviously use the two ports on each

00:49:56.309 --> 00:49:59.610
of the metadata servers and interconnect
those to both of the switches.

00:49:59.610 --> 00:50:03.970
So you'd kind of have everything is pretty
much you know redundant in that situation.

00:50:03.969 --> 00:50:09.429
And you know this is a diagram I showed last year,
but this is NFL network and you might have heard

00:50:09.429 --> 00:50:12.500
about it in the IT overview session on Monday.

00:50:12.500 --> 00:50:17.949
This is the deployment, this was the first
deployment of Vicom you know in the world.

00:50:17.949 --> 00:50:22.839
And they have two sites and it's
been, I mean it's saved their life

00:50:22.840 --> 00:50:26.079
at least you know three times since we deployed this.

00:50:26.079 --> 00:50:30.779
And again, it was simply because
the, they had some power issues.

00:50:30.780 --> 00:50:34.760
And, and that actually you know
really, really worked out for them.

00:50:34.760 --> 00:50:37.960
So and, and here's the funny stories.

00:50:37.960 --> 00:50:44.190
How did we, we you know again, how do you get a
customer to sign off on, on a product like that?

00:50:44.190 --> 00:50:46.809
Well you just start pulling controllers out.

00:50:46.809 --> 00:50:51.869
So we were literally ingesting video and we pulled
a few controllers out, just to show the customer

00:50:51.869 --> 00:50:53.529
that there was absolutely nothing happening.

00:50:53.530 --> 00:50:56.380
The SAN just kept on working, kept on behaving properly.

00:50:56.380 --> 00:51:01.000
Pretty ballsy, but we got the, we got the sign off.

00:51:01.000 --> 00:51:05.840
So you've got in this situation, you've got you
know seven Vicom units because you've got 14 RAIDs.

00:51:05.840 --> 00:51:08.240
You've got 7 RAIDs mirrored to seven RAIDs.

00:51:08.239 --> 00:51:15.479
They're actually expanding that, so we're going next week
and expanding that with five more, five more engines.

00:51:15.480 --> 00:51:19.820
You've got your backend switch, which is your, your storage.

00:51:19.820 --> 00:51:27.590
And again in this situation we've got two pairs of two, you
know two logic switches which manage your backend storage.

00:51:27.590 --> 00:51:32.750
And then we have the front end storage which
manages all your clients and your metadata servers.

00:51:32.750 --> 00:51:38.570
So again we've segmented the backend storage from the front
end storage, which again allows us to very quickly scale

00:51:38.570 --> 00:51:42.370
but also from a redundancy perspective,
you don't want you know to mix

00:51:42.369 --> 00:51:46.219
and match your backend with your, with your front end.

00:51:47.369 --> 00:51:53.759
So rule of thumb, you know they have a single
engine version which we've never deployed.

00:51:53.760 --> 00:51:55.340
I mean why would you have a single engine?

00:51:55.340 --> 00:51:58.460
It, it adds one more point of single point of failure.

00:51:58.460 --> 00:52:04.610
So you want to get the dual engine and the dual engine will
give you about 350 MB per second of throughput.

00:52:04.610 --> 00:52:10.849
So if you don't need as much throughput, instead of going
from a two to one ratio, which is two Xserve RAIDs,

00:52:10.849 --> 00:52:16.589
you know with one dual Vicom engine, you
can go to you know four Xserve RAIDs,

00:52:16.590 --> 00:52:19.059
you know two mirrored to two with a single engine.

00:52:19.059 --> 00:52:23.170
And that'll give you approximately
you know 140 MB per second.

00:52:23.170 --> 00:52:26.970
But for play out it might be absolutely fine.

00:52:26.969 --> 00:52:30.230
So that's it on the, the Vicom side.

00:52:30.230 --> 00:52:37.670
The, the third topic I wanted to touch on today
is you know using Xserve RAID in a datacenter.

00:52:37.670 --> 00:52:41.909
And you know some people try to use Xsan in that situation

00:52:41.909 --> 00:52:46.309
which I don't think it's always a good
fit, especially in the datacenter world

00:52:46.309 --> 00:52:53.639
And, and so we've been working with, with this
company called Cloverleaf which allows you to,

00:52:53.639 --> 00:53:02.049
to take that inexpensive storage that we, that we offer and
give you some of the functionality that we hear you know

00:53:02.050 --> 00:53:05.880
from a lot of the IT folks that, that talk to us.

00:53:05.880 --> 00:53:08.910
You know so what we hear from those, those customers,

00:53:08.909 --> 00:53:12.739
you know some of the requirements are they
already have this existing storage, right.

00:53:12.739 --> 00:53:15.979
But they, you know they're interested
in adding more storage obviously.

00:53:15.980 --> 00:53:22.260
Because we all know how storage is the growth it
exponential going you know how people need more

00:53:22.260 --> 00:53:24.280
and more storage every, every day.

00:53:24.280 --> 00:53:28.550
So they want, they want if they buy new storage
from another vendor, it needs to fit in.

00:53:28.550 --> 00:53:36.350
You know they want to be able to slice the storage and
assign those, that storage to a server very, very quickly.

00:53:36.349 --> 00:53:41.940
And they want to to be able to grow that
storage also very easily on the fly, right?

00:53:41.940 --> 00:53:44.079
Which is one of the features that Xsan brings to you.

00:53:44.079 --> 00:53:51.909
They want to be able to snapshot the data and they want to
be able to replicate the data you know to another site.

00:53:51.909 --> 00:53:56.109
And again they want to quickly do a provision,
you know they have a new server that comes up.

00:53:56.110 --> 00:53:57.370
It's a new database.

00:53:57.369 --> 00:54:02.319
And they want to quickly be able to assign you
know some 100 gig of storage to that server

00:54:02.320 --> 00:54:05.530
and maybe that product that does that for you.

00:54:05.530 --> 00:54:09.220
And you know today might be 100
gig, tomorrow might be 10 terabytes.

00:54:09.219 --> 00:54:13.789
You can dynamically grow that volume
on the fly as you need it.

00:54:13.789 --> 00:54:15.969
And they're getting quotes from other vendors.

00:54:15.969 --> 00:54:18.889
I mean, you know we know all those vendors, EMC NetApp.

00:54:18.889 --> 00:54:23.750
And they're all in the $400,000 -
$500,000 price range probably.

00:54:23.750 --> 00:54:26.460
Not you know with support and maintenance and you name it.

00:54:26.460 --> 00:54:31.519
And they, they're looking for something cheaper and that
is definitely I mean, that solution is probably a third

00:54:31.519 --> 00:54:33.670
of the cost of some of the other vendors.

00:54:33.670 --> 00:54:34.300
So what is it?

00:54:34.300 --> 00:54:39.190
Well its you know Cloverleaf is
basically this agent list appliance.

00:54:39.190 --> 00:54:41.059
Let's just call it an appliance.

00:54:41.059 --> 00:54:43.920
That you put in the middle of a store, of your storage.

00:54:43.920 --> 00:54:49.680
And that allows you to like I said, do snapshoting,
do mirroring, you know mirroring your data,

00:54:49.679 --> 00:54:55.929
doing site to site replication, dynamically
expanding your volume, on the fly.

00:54:55.929 --> 00:55:00.779
So you can pretty much you know fake it and say
hey I've got 64 terabytes assigned to that server.

00:55:00.780 --> 00:55:03.140
When you really don't have 64 terabytes.

00:55:03.139 --> 00:55:05.039
You might have a few 100 GB.

00:55:05.039 --> 00:55:08.369
But its, its set and its ready and
when it sees its running out of space,

00:55:08.369 --> 00:55:11.750
it automatically allocates more storage to it on the fly.

00:55:11.750 --> 00:55:14.840
So it's very powerful in that situation.

00:55:14.840 --> 00:55:19.590
And it works, and they work with pretty much an switch
vendors, so you just plug in, plug that in the middle

00:55:19.590 --> 00:55:27.260
of your, of your system, of your storage, you know farm and
it just automatically then detects the storage and its kind of

00:55:27.260 --> 00:55:30.800
like a pass through and then you can
assign it to all your front end storage.

00:55:30.800 --> 00:55:37.360
So here's an example of a, you know a diagram of how
you would deploy you know a clover leaf solution.

00:55:37.360 --> 00:55:45.760
You've got this appliance in the middle, which right now
is, is the two, the two engines are running on Solaris.

00:55:45.760 --> 00:55:49.600
They're porting to Leopard and
they're porting to the Intel Xserve.

00:55:49.599 --> 00:55:53.599
So that'll be switching over to our hardware in the future.

00:55:53.599 --> 00:55:57.699
But we, we already use Xserves for the management console.

00:55:57.699 --> 00:55:59.529
Which is all, which is all Java.

00:55:59.530 --> 00:56:02.120
And you can see that on the back
end you've got all your storage,

00:56:02.119 --> 00:56:05.289
you've got your iSCII storage,
you've got your direct attach storage.

00:56:05.289 --> 00:56:08.800
You can even, lets assume you're out of storage.

00:56:08.800 --> 00:56:13.070
I mean you're in a situation where, you know
this, you're just, you're out of storage.

00:56:13.070 --> 00:56:19.890
You can take an NFS reshare and proxy that
and make that available as additional storage.

00:56:19.889 --> 00:56:25.190
So you could take a machine that has a 500 gig hard
drive or a terabyte hard drive and reshare that

00:56:25.190 --> 00:56:32.970
and make that available as storage to some other machine
if you, if you completely run out of storage at some point.

00:56:32.969 --> 00:56:39.669
You can obviously do snapshoting so you can snapshot
your exchange database, your Oracle database which is,

00:56:39.670 --> 00:56:45.809
which is quite powerful and you can, you can
obviously put a lot of nice Xserves and you know re,

00:56:45.809 --> 00:56:49.659
you know share, create AFP SMB servers on the fly.

00:56:49.659 --> 00:56:57.399
So again, some of the really cool features is
the dynamic LUN expansion where like I said,

00:56:57.400 --> 00:57:00.400
you know you're building a new infrastructure.

00:57:00.400 --> 00:57:05.450
You have no idea six months down the road how
much storage this department is going to need.

00:57:05.449 --> 00:57:12.359
So why spend the money ahead of time and why you know
buy a 10 terabyte storage solution or 20 terabytes

00:57:12.360 --> 00:57:18.320
when you're only going to use you know a few hundred
gigs for the first six month, year or two years.

00:57:18.320 --> 00:57:22.220
So Cloverleaf allows you to do that and
allows you to allocate only what you need

00:57:22.219 --> 00:57:26.579
for that specific group but quickly, dynamically expand it.

00:57:26.579 --> 00:57:32.239
Another one of my other nice features
is, is writable snapshots.

00:57:32.239 --> 00:57:37.919
So imagine if you're running a
database and you know you've got your,

00:57:37.920 --> 00:57:43.930
your development group that's actually
working on the new version of the database.

00:57:43.929 --> 00:57:47.949
Right? And they have a whole bunch
of patches they need to apply.

00:57:47.949 --> 00:57:53.079
But they might have you know this database
has been running and it's a live database.

00:57:53.079 --> 00:57:59.509
And the database they're testing their patches on is
some old version that's probably about a year old.

00:57:59.510 --> 00:58:02.460
Right? How many times does that happen?

00:58:02.460 --> 00:58:03.730
Every day.

00:58:03.730 --> 00:58:09.030
So what you do with Cloverleaf is you can
literally take a snapshot of that working database,

00:58:09.030 --> 00:58:14.740
mount it read write on your test server, apply all the
patches, apply the new updates and actually test it

00:58:14.739 --> 00:58:21.869
on a snapshot that you just took a few minutes ago versus
some old you know version of the database that you've been,

00:58:21.869 --> 00:58:27.889
that's been deprecated that doesn't have the
real content that you're actually using today.

00:58:27.889 --> 00:58:29.869
So very, very powerful.

00:58:29.869 --> 00:58:35.139
And imagine in the email virus situation,
that's also quite useful to go back

00:58:35.139 --> 00:58:42.489
to a snapshot five minutes ago before you got hit with
some or before one of your containers got corrupted.

00:58:42.489 --> 00:58:48.529
Again, it also allows you to do, you know
site to site replication, so you know nice,

00:58:48.530 --> 00:58:53.740
nice for customers who have multiple locations
across the country and need to replicate their data.

00:58:53.739 --> 00:59:01.209
It'll actually snapshot, it'll only replicate the snapshot
so it's also very efficient on the, on the network.

00:59:01.210 --> 00:59:07.699
So in summary, again just, just go look
at them, talk to us if you need any help.

00:59:07.699 --> 00:59:10.769
And you know looking at a solution like that.

00:59:10.769 --> 00:59:12.789
If you want more information.

00:59:12.789 --> 00:59:15.710
No host licensing, no capacity fees.

00:59:15.710 --> 00:59:16.740
You know don't you love that?

00:59:16.739 --> 00:59:21.899
The only thing they, they had like three different versions
and really more the how many snapshots do you need?

00:59:21.900 --> 00:59:27.110
So they've got like 1,000 snapshots, 10,000 snapshots,
or you know they've got different levels of snapshots,

00:59:27.110 --> 00:59:30.059
but that's pretty much all you, you get to, you pay for

00:59:30.059 --> 00:59:36.340
and the solution is sales were between
$70,00 and about $100,000.

00:59:36.340 --> 00:59:42.300
So again, yeah its not cheap, but again you take a
lot, you know all the storage you have on the backend,

00:59:42.300 --> 00:59:48.550
you divide that by multiple terabytes and you're getting
a cost per terabyte of the order of $3 or $4 and,

00:59:48.550 --> 00:59:50.660
and you get all that, that functionality.

00:59:50.659 --> 00:59:53.589
So it's very nice.

00:59:53.590 --> 00:59:58.769
So as a wrap up and you know I got 24
seconds left, so I'm really happy here.

00:59:58.769 --> 01:00:01.389
Thank you for using Xsan.

01:00:01.389 --> 01:00:08.049
You know just don't cut corners, plan your set up,
let us help you if you want help to deploy your SAN.

01:00:08.050 --> 01:00:12.039
How to contact us, consultingservices@apple.com.

01:00:12.039 --> 01:00:14.210
That's the best way to get in touch with us.

01:00:14.210 --> 01:00:19.769
We have project managers that are, that are
located around the country, east coast, west coast.

01:00:19.769 --> 01:00:21.210
Those are there.

01:00:21.210 --> 01:00:25.829
Email addresses, but again, just send us an email
to consultingservices@apple.com

01:00:25.829 --> 01:00:27.259
and we'll be glad to help you.

01:00:27.260 --> 01:00:31.260
Or apple.com/services is our, is our website.

01:00:31.260 --> 01:00:36.880
So, and then, obviously I wanted to mention
that the you know we talked about Xsan 2.0

01:00:36.880 --> 01:00:39.820
and that's going to, going to be available later this fall.

01:00:39.820 --> 01:00:42.230
And Jason will be talking about that on Friday.

01:00:42.230 --> 01:00:56.170
So don't miss the, the session around
Xsan 2.0 at 10:30 in, in this room.