WEBVTT

00:00:15.710 --> 00:00:19.570
>> Hi, and welcome to Dode Hardening Techniques.

00:00:19.570 --> 00:00:23.980
I'm Drew Yao, and I'm a Security
Engineer with the Product Security team.

00:00:23.980 --> 00:00:26.330
My co-presenter is Jacques Vidrine.

00:00:26.329 --> 00:00:29.889
He's a Security Ninja with the OS Security team.

00:00:29.890 --> 00:00:37.049
In this talk, I'm going to give an introduction
to product security and to some of our processes.

00:00:37.049 --> 00:00:42.599
I'm also going to talk about securing code and
that means both finding and fixing security bugs.

00:00:42.600 --> 00:00:51.329
And then Jacques is going to describe some of
the new security features in Leopard. Starting off

00:00:51.329 --> 00:00:57.649
with Apple product security, we're responsible
for the security of all of Apple's products.

00:00:57.649 --> 00:01:02.619
And as part of our mission, we do both
proactive and reactive efforts in order

00:01:02.619 --> 00:01:13.810
to ensure this security. Now I'm going to just
describe the life cycle of an average security bug.

00:01:13.810 --> 00:01:20.269
The new bugs are reported by a wide variety of
people, including Apple internal users and developers

00:01:20.269 --> 00:01:24.239
and security researchers and security organizations.

00:01:24.239 --> 00:01:28.579
We do...are responsible for the communication
with all these different kinds of people,

00:01:28.579 --> 00:01:32.260
and we try to maintain a good relationship with them.

00:01:32.260 --> 00:01:40.439
If you find a security bug, you can let us know about
it either via Radar or via product-security@apple.com.

00:01:40.439 --> 00:01:45.609
And you may know Radar better as bugreport.apple.com.

00:01:45.609 --> 00:01:49.030
We see all new security Radars, and we review them.

00:01:49.030 --> 00:01:54.570
So if you file a Radar with the classification
security, you can be certain that we will see it

00:01:54.569 --> 00:02:04.409
and we will handle it appropriately. Once a security bug
has been reported, we work to determine the root cause

00:02:04.409 --> 00:02:10.780
and to search for any related issues, both
in the same project and in other projects.

00:02:10.780 --> 00:02:14.580
We coordinate with the engineering team for the fix.

00:02:14.580 --> 00:02:20.790
We don't actually implement the fix, but we
kind of try to verify that the fix is complete

00:02:20.789 --> 00:02:29.319
and it really addresses the root cause. As this is going on,
we're constantly in contact with the reporter of the issue.

00:02:29.319 --> 00:02:35.590
We're giving them status reports upon request, and
we notify them right before the fix goes out so

00:02:35.590 --> 00:02:38.379
that we can coordinate an advisory with them.

00:02:38.379 --> 00:02:40.449
Once the fix is ready, we test it.

00:02:40.449 --> 00:02:43.609
It gets released, and we post the advisory.

00:02:43.610 --> 00:02:48.710
The things that I've talked about
so far were all response measures,

00:02:48.710 --> 00:02:53.260
things that we do once...when someone
else reports an issue to us.

00:02:53.259 --> 00:02:58.629
But we also do a lot of proactive measures, things
that either prevent the creation of new bugs

00:02:58.629 --> 00:03:03.340
or also trying to find existing security bugs.

00:03:03.340 --> 00:03:04.830
One of the things that we do is training.

00:03:04.830 --> 00:03:09.400
We do a lot of presentations just
like this but to Apple employees.

00:03:09.400 --> 00:03:15.490
We also do a lot of one-on-one consultation
with various engineering teams to do things

00:03:15.490 --> 00:03:19.040
like code audits, design reviews and so on.

00:03:19.039 --> 00:03:27.349
We work to analyze new features, doing a threat analysis;
and we do...we work to harden existing software.

00:03:27.349 --> 00:03:30.549
Another thing we do is what we call red team activities.

00:03:30.550 --> 00:03:35.810
This just means trying to find security bugs
through either testing or code auditing.

00:03:35.810 --> 00:03:42.000
And as part of our red team activities, we
develop and maintain and promote the use of tools;

00:03:42.000 --> 00:03:45.370
and these include fuzzing and static code analysis tools.

00:03:45.370 --> 00:03:52.650
And I'll describe these more later. Now
moving on to securing code.

00:03:53.830 --> 00:03:58.730
I'm going to give an overview of the most common
security vulnerabilities and give some tips

00:03:58.729 --> 00:04:04.289
on finding them, both by code inspection and by fuzzing.

00:04:04.289 --> 00:04:09.389
Before I go any further, I'd like to just
mention the Apple Secure Coding Guide.

00:04:09.389 --> 00:04:14.369
You can...you can find this just be Googling
Apple Secure Coding, and it covers a lot of stuff

00:04:14.370 --> 00:04:16.079
that I'm not going to cover in this talk.

00:04:16.079 --> 00:04:19.680
Some of the bullets are...are below.

00:04:19.680 --> 00:04:27.620
And so I recommend it. One of the leading
causes of security issues is buffer overflows.

00:04:27.620 --> 00:04:33.180
This, in case you don't know, it just means writing
past the end of the memory where you're supposed

00:04:33.180 --> 00:04:35.740
to be writing and then smashing into other memory.

00:04:35.740 --> 00:04:38.949
This can often lead to arbitrary code execution.

00:04:38.949 --> 00:04:44.250
And I won't talk right now about how exactly that
works because it's been covered in many other places;

00:04:44.250 --> 00:04:49.589
but just in order to find these issues, one of
the common things that you can look for is any use

00:04:49.589 --> 00:04:58.699
of an unbounded copy API such as strcpy. In this...in
this call, if bad source is longer than the...the amount

00:04:58.699 --> 00:05:02.750
of memory allocated for dest, an overflow will result.

00:05:02.750 --> 00:05:05.250
And the fix for it is pretty simple.

00:05:05.250 --> 00:05:11.970
You just switch to using a bounded copy API
like strlcpy, and the bound or the amount

00:05:11.970 --> 00:05:20.680
to copy should be somehow related to the size of the
destination. Another common cause of buffer overflows is

00:05:20.680 --> 00:05:25.470
when you do use a bounded copy, but the bound
or the amount of copy is not really validated.

00:05:25.470 --> 00:05:32.070
It might be coming directly from the user or just
being influenced by the user or the attacker.

00:05:32.069 --> 00:05:38.930
So in this case, what you can do is just do some kind
of bounds check that makes sure that it's not bigger

00:05:38.930 --> 00:05:48.280
than the size of the destination. Another common
cause of security issues is integer overflows.

00:05:48.279 --> 00:05:54.779
In this first block, we have a call to
malloc to try and allocate a certain size;

00:05:54.779 --> 00:06:01.519
and if the attacker controls this bad_
num, it could be a very large number.

00:06:01.519 --> 00:06:11.289
If we have a 32-bit program, then the size T or the
amount to malloc would be at most 2 to the 32 minus 1.
2

00:06:11.290 --> 00:06:17.140
So if the product or the sum is
greater than 2 to the 32 minus 1,

00:06:17.139 --> 00:06:22.000
then the high bits will be...will be just
discarded and only the low 32 bits will be left.

00:06:22.000 --> 00:06:27.079
So it could be a very small number that actually
gets allocated, and that could often lead

00:06:27.079 --> 00:06:34.399
to a heat buffer overflow later. A
related issue is integer underflows.

00:06:34.399 --> 00:06:41.049
And this is when instead of something being unexpectedly
small, it's something becomes unexpectedly large.

00:06:41.050 --> 00:06:50.030
This call to strncat is actually correct; but if the
dest_size is able to be influenced by the attacker at all,

00:06:50.029 --> 00:06:53.379
maybe he could legitimately set it to be zero.

00:06:53.379 --> 00:07:00.360
And so if we look at a third argument, zero
minus zero minus 1 would be negative 1.

00:07:00.360 --> 00:07:08.259
And since strncat takes a size T as the third argument,
that's unsigned, the negative 1 will be interpreted

00:07:08.259 --> 00:07:17.909
as a very large unsigned number leading to a buffer
overflow. And there are many ways to detect and handle these,

00:07:17.910 --> 00:07:20.600
but we introduced one way that's new in Leopard.

00:07:20.600 --> 00:07:23.010
And that's the checkint API.

00:07:23.009 --> 00:07:30.360
You can read about this in checkint.h and it also has
man pages, and there are a lot of different flavors

00:07:30.360 --> 00:07:36.569
of this checkint API for all the different
kinds of integer arithmetic that one can do.

00:07:36.569 --> 00:07:44.129
So, for example, when you...in this sample code, we
want to check if bad_num plus padding could overflow.

00:07:44.129 --> 00:07:48.219
And we're assuming that both of
them are unsigned 32-bit integers.

00:07:48.220 --> 00:07:54.950
We can just call check_uint32_add on bad_num and
padding and pass the point there to result variable.

00:07:54.949 --> 00:08:01.099
And if after the call, the result variable has
the overflow bit set, we know an overflow happened

00:08:01.100 --> 00:08:04.080
and we can handle it however it's appropriate.

00:08:04.079 --> 00:08:08.819
And if that didn't happen, then we know
that the overflow didn't happen in this size

00:08:08.819 --> 00:08:11.810
which was returned is a safe number to allocate.

00:08:11.810 --> 00:08:19.730
It didn't overflow. A related cause of
security issues is signedness issues.

00:08:19.730 --> 00:08:26.020
And so in this example, we have this
bad_len which is a signed integer.

00:08:26.019 --> 00:08:34.360
And we also have a check here that's trying
to do a bounds check to prevent the copy

00:08:34.360 --> 00:08:37.840
if the bad_len is bigger than the size of the destination.

00:08:37.840 --> 00:08:43.530
But if bad_len is under the control of the attacker or can
be influenced by the attacker, maybe it can be negative.

00:08:43.529 --> 00:08:50.019
If it's negative, this check will always return false
because a negative number is always less than 100.

00:08:50.019 --> 00:08:57.269
So when we get to the memcpy, it's
going to be...it's going to be interpreted

00:08:57.269 --> 00:09:02.659
as a very large unsigned number leading to a buffer
overflow. And the fix for this is pretty simple.

00:09:02.659 --> 00:09:07.319
Just whenever you have something that's being used
as, like, a length or a size or something like that,

00:09:07.320 --> 00:09:09.660
that would really never legitimately be negative.

00:09:09.659 --> 00:09:12.449
It's a good practice just to make it unsigned by default.

00:09:12.450 --> 00:09:17.810
And in general, integers should be
unsigned by default unless you have a reason

00:09:17.809 --> 00:09:24.719
that it would ever be negative. The
last common cause of security issues

00:09:24.720 --> 00:09:27.090
that I'm going to talk about is format string bugs.

00:09:27.090 --> 00:09:33.040
In this first block, we have three calls to
varying APIs where the parameter in red is

00:09:33.039 --> 00:09:37.169
like a string that's being passed
directly as the format string parameter.

00:09:37.169 --> 00:09:44.959
And when this happens, if an attacker controls the string
at all, he can set it to be like %s or %n

00:09:44.960 --> 00:09:47.360
or to have these kind of format tokens inside it.

00:09:47.360 --> 00:09:52.029
And this can lead to code execution
or other security problems

00:09:52.029 --> 00:09:54.759
So the fix is actually very simple.

00:09:54.759 --> 00:10:05.299
It's to make sure that the format parameter is a static
or fixed constant string; and then if you want to, say,

00:10:05.299 --> 00:10:10.509
print out a string, you just make sure that
you have a %s token and then follow it

00:10:10.509 --> 00:10:17.179
with a string. So most people are probably not familiar
with how exactly format strings can be exploited.

00:10:17.179 --> 00:10:19.259
So I have a sample program here.

00:10:19.259 --> 00:10:25.240
What it does is it has a stacked buffer called buff
and it copies the first argument to the program

00:10:25.240 --> 00:10:28.600
into buff and then it calls printf on the buff.

00:10:28.600 --> 00:10:33.690
And that's an incorrect call to
printf. So what can we do with that?

00:10:33.690 --> 00:10:38.270
One thing we can do is try and put in a bunch
of %x characters in the format string.

00:10:38.269 --> 00:10:46.490
And how these format string functions work is they look for
each of these format tokens like %x and for each one,

00:10:46.490 --> 00:10:52.889
it'll go on the stack looking for an argument and convert
it to a hexadecimal number and print out that number.

00:10:52.889 --> 00:10:55.949
With this call to printf, I didn't pass any arguments.

00:10:55.950 --> 00:11:00.009
So it's just going to get whatever happened
to be on the stack and print that out.

00:11:00.009 --> 00:11:06.909
And especially, you can notice
here at the end, this 41414141.

00:11:06.909 --> 00:11:13.379
This, in case you don't know, hex 41 is
the ASCII code for capital A. So actually,

00:11:13.379 --> 00:11:20.950
this comes from the user supplied format string
because it's stored on the stack. So at this point,

00:11:20.950 --> 00:11:26.140
we've just...we've just determined that
an attacker can cause some arbitrary stuff

00:11:26.139 --> 00:11:28.389
to be printed out which is no big deal.

00:11:28.389 --> 00:11:33.649
But there is another thing we can do which
is instead of for the last %x,

00:11:33.649 --> 00:11:41.259
I can put in a %n. How %n works is that it
takes the number of characters that would have been printed

00:11:41.259 --> 00:11:44.950
so far and it writes that number to a pointer.

00:11:44.950 --> 00:11:55.180
So when I ran this program, I saw that it
crashed trying to write to the pointer 41414141.

00:11:55.179 --> 00:11:58.069
Since this is under my control, I
can write to any pointer I want.

00:11:58.070 --> 00:12:02.840
But in order to get code execution, it would
also be very useful if I could control the value

00:12:02.840 --> 00:12:06.040
that gets written to this arbitrary address.

00:12:06.039 --> 00:12:09.490
And that's what this %100000x is for.

00:12:09.490 --> 00:12:13.629
What this says is at a minimum print 100,000 characters.

00:12:13.629 --> 00:12:18.779
If you remember, the %n token, what
it does is it takes the number of characters

00:12:18.779 --> 00:12:21.419
that have been printed so far and writes them.

00:12:21.419 --> 00:12:25.299
So this is exactly what I need in order
to control the value that gets written.

00:12:25.299 --> 00:12:31.889
And, in fact, we see that when I disassemble the instruction
that caused the crash, this is a store instruction

00:12:31.889 --> 00:12:36.899
which is writing the value that's
in register 24 to some memor$y.

00:12:36.899 --> 00:12:41.230
And when I inspect register 24,
we see it's approximately 100,000.

00:12:41.230 --> 00:12:46.879
So I can basically control the value that gets
written and the address that it gets written to.

00:12:46.879 --> 00:12:51.419
And you can do multiple writes using multiple
%n tokens. So it should be clear

00:12:51.419 --> 00:12:53.459
that code execution can be possible.

00:12:53.460 --> 00:12:56.019
You can write whatever you want to wherever you want.

00:12:56.019 --> 00:13:07.159
And these are a very dangerous issue but also very simple
to fix, as I described earlier. To review all these things

00:13:07.159 --> 00:13:11.629
that I've talked about, some things that you can
look for when doing a code audit include looking

00:13:11.629 --> 00:13:16.840
for unbounded copy APIs being used like strcpy, sprintf

00:13:16.840 --> 00:13:24.399
or a loop where the loop termination case doesn't...doesn't
involve the size of the destination at all.

00:13:24.399 --> 00:13:31.649
And the solution to these is just to switch over to
using the bounded version of these APIs, like strlcpy.

00:13:31.649 --> 00:13:38.490
Another thing to look for is integer arithmetic
being done on the amount to be allocated or copied.

00:13:38.490 --> 00:13:43.129
And this can often lead to integer
overflows and integer underflows.

00:13:43.129 --> 00:13:51.750
And you can use the checkint API which is new
in Leopard to try to detect these. Oops, going back.

00:13:51.750 --> 00:13:57.320
Another thing to look for is anything that's...that
represents a length or a size that is signed.

00:13:57.320 --> 00:14:00.400
It probably should be unsigned just to avoid this problem

00:14:00.399 --> 00:14:05.980
where when it's negative it can bypass
some bounds checks. Format string issues

00:14:05.980 --> 00:14:08.639
which I just went over, it's very simple to look for them.

00:14:08.639 --> 00:14:16.679
You just look for when the format string parameter
is not a fixed constant string. Now all these things

00:14:16.679 --> 00:14:23.819
that I've described so far are bad things that can
happen if some malicious input is passed to them.

00:14:23.820 --> 00:14:30.650
So, for example, strcpy is usually only if it's
possible for the attacker to pass a bad...or

00:14:30.649 --> 00:14:34.709
to control the string that gets passed as the source buffer.

00:14:34.710 --> 00:14:43.460
So another way to look at it, to look for code bugs is
instead of looking at these bad things that can happen is

00:14:43.460 --> 00:14:49.470
to use a more top down approach instead which is to look
at where data comes into the program and try and follow it

00:14:49.470 --> 00:14:58.990
through the program, watch as it gets propagated and see
where it gets used in dangerous ways. But both the top down

00:14:58.990 --> 00:15:05.899
and the bottom up approach can sometimes be
difficult or not always entirely easy to do.

00:15:05.899 --> 00:15:07.429
Let me give an example.

00:15:07.429 --> 00:15:16.039
Let's say we have a function called foo and foo reads
into a header structure from some file or from some socket

00:15:16.039 --> 00:15:22.339
which is probably untrusted and it
also mallocs a fixed size buffer.

00:15:22.340 --> 00:15:25.580
And at this point, we don't know that
any security issues has happened.

00:15:25.580 --> 00:15:34.720
And it passes these two parameters to bar, bar
passes them to baz and baz passes then to xyzzy.

00:15:34.720 --> 00:15:43.259
At this point, xyzzy reads into the buffer
using hdr.len as the amount to copy.

00:15:43.259 --> 00:15:50.679
Now you'll remember that header came from the untrusted file
or socket or whatever, so hdr.len could be arbitrary.

00:15:50.679 --> 00:15:52.120
It could be very large.

00:15:52.120 --> 00:15:55.519
And we also know that buff is a fixed size buffer.

00:15:55.519 --> 00:16:04.090
So it's pretty much certain that a buffer overflow can
result here. So you'll remember that when we looked at foo,

00:16:04.090 --> 00:16:07.769
we didn't know that any security issue had happened.

00:16:07.769 --> 00:16:13.110
You'll also remember that when we looked
at xyzzy...if we look at xyzzy alone,

00:16:13.110 --> 00:16:15.269
we also don't know that any security issue's happened.

00:16:15.269 --> 00:16:21.009
This is because we don't know the size of the buffer and
we don't know that header came from an untrusted source.

00:16:21.009 --> 00:16:27.990
So the only way that we could really understand that this is
a security issue is if we understand the entire call graph.

00:16:27.990 --> 00:16:32.669
Now in real-life programs, often the call
graph is much more complicated than this.

00:16:32.669 --> 00:16:40.939
So it can be quite complex to try and
do this, and it can also be error prone.

00:16:40.940 --> 00:16:45.720
One potential solution to this problem
is to use static code analysis tools.

00:16:45.720 --> 00:16:48.180
There are a number of commerical tools that are available.

00:16:48.179 --> 00:16:54.769
And basically, what they do is they try to do the same kind
of things that a manual auditor would do which is to look

00:16:54.769 --> 00:17:00.149
at where data comes into the program, to follow it
as it gets propagated through the program and to see

00:17:00.149 --> 00:17:03.240
where it gets used in any dangerous ways.

00:17:03.240 --> 00:17:10.009
So these are very useful tools, but they do
have some drawbacks including false positives.

00:17:10.009 --> 00:17:16.890
This just means that when you...when it returns
some kind of bug that it thinks is an error,

00:17:16.890 --> 00:17:19.370
sometimes it's really a bug, sometimes it's not.

00:17:19.369 --> 00:17:25.669
And if it's not, then it's sort of wasted a little bit
of your time trying to figure out if it was real or not.

00:17:25.670 --> 00:17:33.550
And also because static code analysis tools look at source
code, if you don't have source code, then it doesn't apply.

00:17:33.549 --> 00:17:40.470
So there's a complementary method of finding
security bugs using tools, and that is fuzzing.

00:17:41.630 --> 00:17:49.920
Fuzzing is automated robustness testing, and this
means sending malformed data to a running application.

00:17:49.920 --> 00:17:54.830
And by malformed, I mean good enough so that it appears
valid but also bad enough that it might break stuff.

00:17:54.829 --> 00:18:02.189
And I'll talk more later about how to generate
malformed data. But first let me talk a little bit more

00:18:02.190 --> 00:18:04.390
about the motivation for fuzzing.

00:18:04.390 --> 00:18:10.410
Fuzzing is a primary tool for hackers, and this is in large
part because it doesn't require access to source code.

00:18:10.410 --> 00:18:14.370
People outside of the company usually
wouldn't have access to source code.

00:18:14.369 --> 00:18:17.500
So this is the kind of thing that they would have to try.

00:18:17.500 --> 00:18:24.269
They can't do code audit or static code analysis
tools. It tends to find exploitable flaws,

00:18:24.269 --> 00:18:29.150
meaning when you run...when you just feed that
input to a program, it either crashes or it doesn't.

00:18:29.150 --> 00:18:30.910
There's no false positives.

00:18:30.910 --> 00:18:37.410
If it crashes, that's at least a denial of service and
potentially something worse. They're relatively easy

00:18:37.410 --> 00:18:40.970
to create and run, and they test assumptions in the code.

00:18:40.970 --> 00:18:45.120
And they determine or demonstrate
the importance of defensive coding.

00:18:45.119 --> 00:18:48.989
A lot of programmers code something
so...just so it's functional.

00:18:48.990 --> 00:18:56.200
For example, if they're coding an image processing program,
they'll have suite of valid images and they'll say okay,

00:18:56.200 --> 00:18:59.140
once my program can display all these images, I'm done.

00:18:59.140 --> 00:19:05.550
But if they don't take into account that deliberately
malformed image can cause security issues,

00:19:05.549 --> 00:19:12.940
then they're in for some...in for some headaches. And
attackers are actively fuzzing commercial products.

00:19:12.940 --> 00:19:17.990
We know this is true for Apple products,
and it may be true for yours as well.

00:19:17.990 --> 00:19:24.410
To drive this point home a little more thoroughly, you may
remember the month of Apple bugs which was this January.

00:19:24.410 --> 00:19:33.040
In this month, once every day some security researchers
released a security bug publicly in some Mac products.

00:19:33.039 --> 00:19:39.750
Of the 23 issues that were reported against Apple
products, 15 of them were most likely found by fuzzing.

00:19:39.750 --> 00:19:43.000
And I say most likely because I don't
know for sure how they found them.

00:19:43.000 --> 00:19:46.130
But given what we know, it's seems very likely

00:19:46.130 --> 00:19:52.490
The remaining seven issues were reported against third-party
Mac products, and of these six were most likely found

00:19:52.490 --> 00:19:59.700
by fuzzing. Now that we have the motivation
out of the way, what can we fuzz?

00:19:59.700 --> 00:20:02.210
We can fuzz any program that takes untrusted input,

00:20:02.210 --> 00:20:06.170
and this includes especially programs
that speak any network protocol.

00:20:06.170 --> 00:20:09.500
For example, Safari and Apache both speak HTTP.

00:20:09.500 --> 00:20:16.859
Anything that parses untrusted files, for example,
QuickTime parses a lot of different kinds of media files.

00:20:16.859 --> 00:20:21.899
And setuid programs because they take
a lot of untrusted input from the user.

00:20:21.900 --> 00:20:29.070
It's untrusted because the program runs with the
privileges of a different user. So once you are ready

00:20:29.069 --> 00:20:35.669
to do your fuzzing, one of the common ways of doing
fuzzing is to take a valid template and try and mutate it.

00:20:35.670 --> 00:20:40.500
For example, if you're attacking a file format,
you would take a valid file and mutate it.

00:20:40.500 --> 00:20:45.619
If you're attacking a network protocol, you would
take a valid session transcript and try to mutate it.

00:20:45.619 --> 00:20:51.669
So a very good target within these templates to go
for is any kind of size or length or count field,

00:20:51.670 --> 00:20:57.700
and this is because these values are often used
as the amount to either allocate or to copy.

00:20:57.700 --> 00:21:02.039
As we saw in the earlier section, the number
that's being used as the amount to allocate

00:21:02.039 --> 00:21:09.259
or copy can often cause integer overflows, underflows
and buffer overflows when it's used as the amount

00:21:09.259 --> 00:21:16.170
to copy. So what are some good values that
we can try to fill in in these fields?

00:21:16.170 --> 00:21:19.700
One good thing to try is anywhere
near signed or unsigned boundaries,

00:21:19.700 --> 00:21:24.450
and this is because it can trigger the
signedness issues that I mentioned earlier.

00:21:24.450 --> 00:21:28.700
Another good thing to try is powers
of 2 plus or minus a small offset.

00:21:28.700 --> 00:21:36.150
This is because programmers often allocate around
powers of 2, like 256 or 512, things like that.

00:21:36.150 --> 00:21:39.450
So if you use this kind of value,
plus or minus a small offset,

00:21:39.450 --> 00:21:43.880
sometimes you can trigger off by one or off by a few errors.

00:21:43.880 --> 00:21:50.810
Also with certain values of powers of 2, you can
trigger integer overflows or underflows by addition

00:21:50.809 --> 00:21:56.029
or subtraction. Finally, good things
to try are...include using, like,

00:21:56.029 --> 00:21:59.430
the biggest possible number divided
by some other number and then add one.

00:21:59.430 --> 00:22:02.430
And this is try and trigger integer
overflows by a multiplication.

00:22:02.430 --> 00:22:11.060
For example, SIZE_T_MAX divided by 2 plus 1 times 2 is going
to be something that's slightly larger than 2 to the 32.

00:22:11.059 --> 00:22:14.879
So mod 2 to the 32 is going to2 be some small number.

00:22:14.880 --> 00:22:17.060
And if that's used as the amount to allocate,

00:22:17.059 --> 00:22:26.119
it's going to cause potentially a buffer overflow
later. With string fields, one of the common things

00:22:26.119 --> 00:22:30.119
that you can try is just to take a
character and repeat it over and over.

00:22:30.119 --> 00:22:36.379
The point of this is to try and expose the
use of unbounded copy APIs like strcpy.

00:22:36.380 --> 00:22:43.640
And the reason you use the same character over and over is
because you might want to...like, when you get a crash log,

00:22:43.640 --> 00:22:49.060
it's pretty common if there was buffer overflow that you'll
see this character repeated over and over in the crash log,

00:22:49.059 --> 00:22:54.049
either in the registers or in the stack or otherwise.

00:22:54.049 --> 00:22:59.990
And the reason you try different lengths
is because obviously, if it was too short,

00:22:59.990 --> 00:23:04.240
then sometimes it won't cause the overflow
because the buffer won't be big enough.

00:23:04.240 --> 00:23:10.740
If you try it too long, sometimes there are partial
filters in place or incorrect bounds checks in place.

00:23:10.740 --> 00:23:18.450
So maybe, for example, the 65535 As would not 5trigger the
overflow because they would be caught by the partial filter.

00:23:18.450 --> 00:23:23.039
But the 10,000 would trigger the overflow.

00:23:23.039 --> 00:23:25.960
Another good thing to try would be these format tokens.

00:23:25.960 --> 00:23:29.940
They...if there's a format string
bug, they'll cause a crash.

00:23:29.940 --> 00:23:33.920
And binary data, when you're just
working with a text application.

00:23:33.920 --> 00:23:40.130
This might be because the application does
some kind of arithmetic on the character values

00:23:40.130 --> 00:23:42.840
or it might just be because it's unexpected.

00:23:42.839 --> 00:23:47.779
And fuzzing is about really just trying to
put in unexpected things and see what happens.

00:23:47.779 --> 00:23:52.849
And especially,null bytes are useful to
try because CStrings are null terminated.

00:23:52.849 --> 00:24:01.589
So terminating a string unexpectedly early can sometimes
cause issues. And if you know a little bit about the format

00:24:01.589 --> 00:24:04.599
that you're fuzzing, any kind of
delimiter is a really good thing to try.

00:24:04.599 --> 00:24:08.769
And this is because delimiters
are used as control information.

00:24:08.769 --> 00:24:13.889
So, for example, with HTML and
XML, we have these angle brackets.

00:24:13.890 --> 00:24:18.440
You can try to either add them or
removed them from the valid stream.

00:24:18.440 --> 00:24:26.220
So, for example, this valid HTML
becomes this slightly invalid HTML.

00:24:26.220 --> 00:24:34.670
And if the parser is not robust, it might get confused
and bad things might happen. With binary streams,

00:24:34.670 --> 00:24:41.720
like binary files or binary network protocols, often
it's kind of too much work to be very format aware.

00:24:41.720 --> 00:24:45.430
It's too much work to figure out that this
part is a length field, this part is a string,

00:24:45.430 --> 00:24:48.130
this part might be a time stamp or something like that.

00:24:48.130 --> 00:24:54.940
So there's a very surprisingly effective alternative
which is just to randomly flip some bits in the stream

00:24:54.940 --> 00:24:59.700
in a window. And let me give a more concrete example of that.

00:24:59.700 --> 00:25:06.549
Let's say you want to find a security bug in
a program that parses MP3 files like iTunes.

00:25:06.549 --> 00:25:11.329
What you could do is take a valid
MP3 file and make a copy of it

00:25:11.329 --> 00:25:15.230
and just mutuate the copy in a certain field in the file.

00:25:15.230 --> 00:25:18.390
And by mutate, I just mean flip some of the bits randomly.

00:25:18.390 --> 00:25:25.430
You can then save out this mutated copy, go back to the
original, make another copy and again mutate the copy

00:25:25.430 --> 00:25:31.420
but this time the window or the field
of mutation has shifted and then so on.

00:25:31.420 --> 00:25:36.200
You keep sliding the window across the
file, saving out these mutated files.

00:25:36.200 --> 00:25:42.420
The reason we do this sliding window is that we
want to get as much code coverage as possible.

00:25:42.420 --> 00:25:46.320
Theoretically, at least, different parts of
the code parse different parts of the file.

00:25:46.319 --> 00:25:52.269
So with each of these files, most of it is
valid; but only a small part is malformed.

00:25:52.269 --> 00:25:55.359
Therefore, just the part of the code that parses that part

00:25:55.359 --> 00:26:03.159
of the file is going get exercised more. Now once
you have created all these mutated test cases,

00:26:03.160 --> 00:26:05.460
you would then run them against your application.

00:26:05.460 --> 00:26:10.779
And there are a list of things that you would
probably want to look out for and try to log.

00:26:10.779 --> 00:26:13.569
The main one, I would say, is crashes.

00:26:13.569 --> 00:26:21.289
You probably want to, say, try to detect a crash
after running each case; and if the crash gets caused,

00:26:21.289 --> 00:26:29.109
then you log that this test case caused this crash.

00:26:29.109 --> 00:26:31.599
Another common thing that gets caused is hangs

00:26:31.599 --> 00:26:35.169
Depending on if you care or not about
hangs, you can do different things.

00:26:35.170 --> 00:26:40.080
If you don't care, you can just kill the
application every time after every test case.

00:26:40.079 --> 00:26:46.799
If you do care, then you can try to detect
it and then kill it. Rarely, very infrequently

00:26:46.799 --> 00:26:49.379
but sometimes, you can cause a kernel panic.

00:26:49.380 --> 00:26:54.790
I just wanted to note if you do cause a kernel
panic, we'd really like to know about it.

00:26:54.789 --> 00:26:59.089
So please report it. But if you cause a kernel
panic, you can't really detect it afterwards

00:26:59.089 --> 00:27:01.389
because your system is in a halted state.

00:27:01.390 --> 00:27:07.860
So what you can do is if you think a kernel panic
is likely, you can...before you run each test case,

00:27:07.859 --> 00:27:14.869
you can write to a log saying I'm about to run case
number N. And if you do get a panic, you can just reboot,

00:27:14.869 --> 00:27:22.929
look at the file, and you're pretty sure that case N is
the one that caused the panic. But fuzzing is not a panacea.

00:27:22.930 --> 00:27:23.920
It's not perfect.

00:27:23.920 --> 00:27:26.930
There's some challenges when doing it.

00:27:26.930 --> 00:27:29.789
One of them is finding or creating good seeds to mutate.

00:27:29.789 --> 00:27:34.349
For example, if you're fuzzing MP4
files, MP4 is a container format.

00:27:34.349 --> 00:27:40.500
It can contain all different kinds of audio and
video codecs and bit rates and all this stuff.

00:27:40.500 --> 00:27:48.069
If you want to get good code coverage, you would have to
generate or find a large suite of valid files to mutate.

00:27:48.069 --> 00:27:52.909
And that can be quite a hassle. Another
challenge is determining

00:27:52.910 --> 00:27:58.460
if a crash exposes a code execution bug
because not all crashes are exploitable.

00:27:58.460 --> 00:28:01.410
And the reason you would do this is for triage.

00:28:01.410 --> 00:28:05.100
Obviously, you would want to fix
these code execution bugs first.

00:28:05.099 --> 00:28:11.189
And this is...this can be quite a challenge
because if you don't have security expertise,

00:28:11.190 --> 00:28:15.799
trying to figure out to really declare
that I'm 100% sure

00:28:15.799 --> 00:28:19.419
that this test case could never
be exploited can be a lot of work.

00:28:19.420 --> 00:28:25.690
So for many people who don't necessarily have the security
expertise, it may just be easier to fix the crashes,

00:28:25.690 --> 00:28:31.950
to just treat all of them like serious security bugs
because it's more effort to really diagnose them than it is

00:28:31.950 --> 00:28:37.140
to just fix them. Another common challenge is duplicates.

00:28:37.140 --> 00:28:40.190
It's quite common that if you run, say, 5,000 cases,

00:28:40.190 --> 00:28:46.049
maybe 50 of them all caused the exact same
crash exposing the exact same bug in the code.

00:28:46.049 --> 00:28:52.950
So figuring out which ones of these are
duplicates of each other can be a lot of effort.

00:28:52.950 --> 00:28:58.710
One approach you can take to this is to...after you're done
you have all these crash logs, you can just do some kind

00:28:58.710 --> 00:29:02.829
of text processing on them to figure out
which ones are duplicates and you can do this

00:29:02.829 --> 00:29:10.099
with an automated script. Another common
challenge is nondeterministic crashes.

00:29:10.099 --> 00:29:15.809
This means that for a given test case maybe
sometimes it crashes, sometimes it doesn't.

00:29:15.809 --> 00:29:20.429
And this is often caused by heap buffer
overflows or heap corruption in general.

00:29:20.430 --> 00:29:25.600
So, for example, depending on whatever happens to
be adjacent to your heap buffer, overriding it may

00:29:25.599 --> 00:29:29.209
or may not cause a crash because maybe
it is used again later, maybe it's not.

00:29:29.210 --> 00:29:31.279
Maybe there's a pointer there; maybe there isn't.

00:29:31.279 --> 00:29:36.579
So one way to handle this is to use Guard Malloc
which you can read about in man libgmalloc.

00:29:36.579 --> 00:29:41.849
What it does is it places malloc blocks
directly adjacent to an unmapped page.

00:29:41.849 --> 00:29:49.129
So the moment you write past the end of your malloc block,
you'll immediately start writing into this unmapped page

00:29:49.130 --> 00:29:54.240
and cause a crash right away thus removing
the randomness. Another common cause

00:29:54.240 --> 00:29:57.470
of nondeterministic crashes is race conditions.

00:29:57.470 --> 00:30:01.740
Sometimes all the stars just have to be
aligned just right in order to cause a crash.

00:30:01.740 --> 00:30:05.789
So for these, there's not really a great way to handle it.

00:30:05.789 --> 00:30:10.839
Sometimes you just have to get lucky that it caused the
crash, and then afterwards you can try to run the case over

00:30:10.839 --> 00:30:14.169
and over and see if you can reproduce it.

00:30:14.170 --> 00:30:17.880
A related issue is getting good
coverage across different environments.

00:30:17.880 --> 00:30:23.710
It's not uncommon that, say, if you have a computer
over here that has certain software installed

00:30:23.710 --> 00:30:27.799
or certain configuration, that the test
case will cause a crash on this one

00:30:27.799 --> 00:30:30.269
but doesn't cause a crash on that computer.

00:30:30.269 --> 00:30:36.490
So...and especially in this vein, one
thing to watch out for is architecture.

00:30:36.490 --> 00:30:45.440
It's not uncommon again that, say, PBC versus Intel or
64-bit versus 32-bit, it'll crash on one but not on another.

00:30:45.440 --> 00:30:48.980
So in order to get code coverage or just good coverage,

00:30:48.980 --> 00:30:55.799
you have to try running your testing
across different environments.

00:30:55.799 --> 00:31:00.180
In summary, fuzzing is an automated
robustness testing technique.

00:31:00.180 --> 00:31:02.259
It's a primary tool for hackers.

00:31:02.259 --> 00:31:09.079
It's relatively cheap and easy to implement and to
use, and it's good to incorporate into the QA process.

00:31:09.079 --> 00:31:15.069
And by doing this, you're using the same kind
of techniques that outside attackers use.

00:31:15.069 --> 00:31:20.109
So you're likely to find the same bugs; and then when you
fix them ahead of time, you can just save yourself a lot

00:31:20.109 --> 00:31:25.569
of headaches. I'd also like to mention that
fuzzing is not entirely just for security.

00:31:25.569 --> 00:31:34.259
By increasing the robustness of your code, you also increase
or improve your user experience because these malformed

00:31:34.259 --> 00:31:36.690
or unexpected inputs don't always come from an attacker.

00:31:36.690 --> 00:31:40.630
Sometimes they just come from people doing crazy stuff.

00:31:40.630 --> 00:31:50.740
So when that happens, you'd much rather have, like,
just some warning message pop up than to have a crash. So

00:31:50.740 --> 00:31:55.920
that about wraps it up for me, and now I'd
like to pass it off to my co-presenter Jacques.

00:32:04.160 --> 00:32:14.250
>> Thanks, Drew. Now Drew covered a lot of techniques
that could be used to avoid introducing flaws

00:32:14.250 --> 00:32:18.190
in your software applications or
to find them and eliminate them.

00:32:18.190 --> 00:32:24.650
But I think as we all know, for any non-trivial piece
of software, if...even if you have the most disciplined

00:32:24.650 --> 00:32:29.009
and best educated team, every now
and then a bug does get through.

00:32:29.009 --> 00:32:32.329
So a strategy based on, just doing
it all right the first time

00:32:32.329 --> 00:32:37.099
or eliminating all the bugs before somebody
else finds them is kind of incomplete.

00:32:37.099 --> 00:32:39.389
And we recognize that, and we want to help out.

00:32:39.390 --> 00:32:48.520
So Leopard provides several security improvements that can
mitigate a vulnerabiity should one slip by. I'm going to talk

00:32:48.519 --> 00:32:53.869
about half a dozen different technologies
that can mitigate a vulnerability.

00:32:53.869 --> 00:32:59.949
That is, even if that bug is present in a piece of
code, it can either make it very difficult to exploit

00:32:59.950 --> 00:33:08.210
or it can reduce the impact of that if it is successfully
supported...exploited. The first thing I'm going to talk

00:33:08.210 --> 00:33:14.100
about has to do with a subtle issue
in modern user interfaces.

00:33:14.099 --> 00:33:20.849
And that's that the gesture to open a document is
the same as the gesture to launch an application.

00:33:20.849 --> 00:33:27.819
The problem with that is that malicious software
or malware can be disguised as a document.

00:33:27.819 --> 00:33:33.079
For example, you may have seen in the news
last year that on the Mac rumors site,

00:33:33.079 --> 00:33:37.619
somebody posted a Trojan called...that
was later called Leap A. But they said oh,

00:33:37.619 --> 00:33:39.419
here's some Leopard screen shots for you.

00:33:39.420 --> 00:33:45.029
And as it turns out, after downloading
it, it wasn't screenshots at all.

00:33:45.029 --> 00:33:47.399
It was actually a malicious piece of software.

00:33:47.400 --> 00:33:50.890
Now casual inspection of that might not be enough.

00:33:50.890 --> 00:33:52.390
If you just look at it, it looks good.

00:33:52.390 --> 00:33:53.420
It looks like a JPEG.

00:33:53.420 --> 00:33:55.269
It has a JPEG icon.

00:33:55.269 --> 00:33:58.019
I might as well click it and see what it has in there.

00:33:58.019 --> 00:34:03.990
If you look very carefully, you can see
that it is instead an executable file.

00:34:03.990 --> 00:34:07.950
And in this case, turns out to
be a piece of malicious software.

00:34:07.950 --> 00:34:16.960
So it's kind of unreasonable, I think, to expect
every user every time they download every item

00:34:16.960 --> 00:34:19.409
to do this kind of close inspection.

00:34:19.409 --> 00:34:25.989
In fact, sometimes I've heard some security people say to
others you know, you should never open e-mail attachments.

00:34:25.989 --> 00:34:27.589
That's dangerous.

00:34:27.590 --> 00:34:29.300
Well, it can be dangerous.

00:34:29.300 --> 00:34:36.539
But to most users, they're thinking well, what do we
have e-mail attachments for if I can't even open them.

00:34:36.539 --> 00:34:40.219
This is a problem we're trying
to solve. So with file quarantine,

00:34:40.219 --> 00:34:43.549
a new feature in Leopard, it's pretty straightforward.

00:34:43.550 --> 00:34:49.670
When content is downloaded, the downloading
application marks it with some quarantine properties.

00:34:49.670 --> 00:34:54.139
And after that point, we say that item
is quarantined, much like the Department

00:34:54.139 --> 00:34:59.339
of Agriculture might quarantine a cow before
they know if it has mad cow disease or something.

00:34:59.340 --> 00:35:05.720
Later when you go to click on that, you want to
open it, when Leopard sees that it's quarantined,

00:35:05.719 --> 00:35:10.259
it performs some additional inspection and that
might involve checking the type of the document

00:35:10.260 --> 00:35:13.240
or checking if there's user overrides or whatever.

00:35:13.239 --> 00:35:17.869
But if it turns out to be a safe document,
an actual document not an application,

00:35:17.869 --> 00:35:21.920
the quarantine state's silently removed
and everything just keeps on flowing.

00:35:21.920 --> 00:35:24.730
The user's work flow hasn't been interrupted.

00:35:24.730 --> 00:35:29.900
But if it instead turns out to be an application, the
user's presented with the context of his download.

00:35:29.900 --> 00:35:33.940
He can see when it was downloaded
and where it was downloaded from.

00:35:33.940 --> 00:35:38.470
Notice here in this dialogue, we
even have a show web page button.

00:35:38.469 --> 00:35:41.879
So the user, if he doesn't remember
because he downloaded it two weeks ago,

00:35:41.880 --> 00:35:46.809
what this was about can actually press this
button and be brought back to the web page

00:35:46.809 --> 00:35:50.989
where the download originated. Something
happens similar for Mail.

00:35:50.989 --> 00:35:56.189
If this had been from a Mail message, it would say show
message; and that would bring up the piece of e-mail

00:35:56.190 --> 00:36:00.630
that the item was previously attached to.

00:36:00.630 --> 00:36:06.039
Now this wouldn't be very effective if after having
something in quarantine moving that item around

00:36:06.039 --> 00:36:13.670
or copying it or archiving it would cause
the quarantine properties to disappear.

00:36:13.670 --> 00:36:17.970
So locked pieces of Leopard actually
propagate these properties.

00:36:17.969 --> 00:36:20.139
Let me show you an example.

00:36:20.139 --> 00:36:26.210
An initial download of a disk image, say, the
downloading application puts the quarantine properties

00:36:26.210 --> 00:36:27.470
on the disk image.

00:36:27.469 --> 00:36:29.329
Later we

00:36:29.329 --> 00:36:34.559
mount that disk image with the disk image's framework,
is it doing the work behind the scenes?

00:36:34.559 --> 00:36:35.779
Maybe we look inside.

00:36:35.780 --> 00:36:38.240
We see there's an archive, a zip archive.

00:36:38.239 --> 00:36:40.069
Of course, you know, we're going to extract that.

00:36:40.070 --> 00:36:43.420
Maybe copy it out to finder and open it up.

00:36:43.420 --> 00:36:49.700
Finally, eventually, hopefully, we're going to stop running
into archives and run into some actual files we care about

00:36:49.699 --> 00:36:54.149
and think great, we finally got
to the screenshots, let's go.

00:36:54.150 --> 00:37:01.400
Well, even after all that manipulation, we still
have that download context available for the user.

00:37:01.400 --> 00:37:02.700
So we don't lose that.

00:37:02.699 --> 00:37:07.339
I think that's really important in order to make this work.

00:37:07.340 --> 00:37:12.690
As I said, we've modified lots of Leopard in order
to make this possible like the disk images framework

00:37:12.690 --> 00:37:15.340
and our archive utilities and things of that nature.

00:37:15.340 --> 00:37:18.850
And, of course, we've modified our
network applications like Safari

00:37:18.849 --> 00:37:22.529
and Mail to add the quarantine
properties in the first place.

00:37:22.530 --> 00:37:26.620
So we'd like you guys applications
to do the same kinds of things.

00:37:26.619 --> 00:37:29.059
And, of course, to do that you'll need an API.

00:37:29.059 --> 00:37:31.619
The file quarantine API is straightforward.

00:37:31.619 --> 00:37:35.009
I'm going to talk about it in two pieces.

00:37:35.010 --> 00:37:38.570
The first is directly manipulating quarantine properties.

00:37:38.570 --> 00:37:42.500
This is handled through a new launch
services named attribute.

00:37:42.500 --> 00:37:47.210
What one does is create a dictionary with the pieces

00:37:47.210 --> 00:37:50.619
of quarantined information that
needs to be stored with the item.

00:37:50.619 --> 00:37:55.909
What type of download application it was,
the origin URL, things of that nature.

00:37:55.909 --> 00:38:01.879
And then you can us LSSetItem
attribute to store that with that item.

00:38:01.880 --> 00:38:07.430
So the information of what type of keys there
are and what their meaning are can be found

00:38:07.429 --> 00:38:11.809
in the launch services headers, LSInfo and LSQuarantine.

00:38:11.809 --> 00:38:15.699
The second part of the API is something
called automatic quarantine mode.

00:38:15.699 --> 00:38:19.349
With this, you can start your application
in automatic quarantine mode

00:38:19.349 --> 00:38:22.339
and every file that it creates will be quarantined.

00:38:22.340 --> 00:38:24.079
It will have quarantine properties.

00:38:24.079 --> 00:38:29.869
Now these properties won't be as rich as the ones that
you can get by sending them directly because, you know,

00:38:29.869 --> 00:38:35.460
Leopard doesn't know whether an arbitrary
process is doing e-mail or chatting or what not.

00:38:35.460 --> 00:38:38.220
And it doesn't know the origin for your file.

00:38:38.219 --> 00:38:40.049
It doesn't know why you created that file.

00:38:40.050 --> 00:38:46.740
But at least you have the minimum information such as the
time the file was created and what application created it

00:38:46.739 --> 00:38:53.869
so the same mechanisms can work. I'll give a
quick example of how to use these two APIs.

00:38:53.869 --> 00:38:57.069
The first is directly manipulating into properties.

00:38:57.070 --> 00:38:58.800
There's two steps.

00:38:58.800 --> 00:39:03.400
First you create a dictionary with
the pieces of quarantined information.

00:39:03.400 --> 00:39:09.519
In this example, I started out putting the
origin URL and the type of application.

00:39:09.519 --> 00:39:10.579
I've deleted the rest.

00:39:10.579 --> 00:39:13.230
These slides get long quick.

00:39:13.230 --> 00:39:17.880
The second step is to actually take that
dictionary and assign it to an item.

00:39:17.880 --> 00:39:20.430
And, again, as I said, we used LSSetItemAttribute.

00:39:20.429 --> 00:39:26.299
If you later wanted to observe what the
quarantine information is or even see

00:39:26.300 --> 00:39:35.000
if a file has some quarantine information, say, because your
file management thing that copies files or archives files,

00:39:35.000 --> 00:39:43.000
you can do that by using the LS copy item attribute
to get that same dictionary right back out.

00:39:43.000 --> 00:39:46.019
Using automatic quarantine mode's even simpler.

00:39:46.019 --> 00:39:52.110
You simply edit your info.plist and add
this one key, the LSFileQuarantineEnabled.

00:39:52.110 --> 00:39:59.269
When that's in place, when the application's launched,
it will cause all files created to be quarantined.

00:39:59.269 --> 00:40:05.579
You can optionally specify some path matching patterns
for files that you don't want to have quarantined.

00:40:05.579 --> 00:40:08.849
Now that's not as useful as you might think.

00:40:08.849 --> 00:40:14.089
It turns out that quarantining things that aren't
really downloads doesn't have any ill effects.

00:40:14.090 --> 00:40:19.970
If you have an application that starts up and creates a
preferences file and it was running in quarantine mode,

00:40:19.969 --> 00:40:22.959
that preferences file is going to get quarantined.

00:40:22.960 --> 00:40:25.210
It sounds not right.

00:40:25.210 --> 00:40:30.369
But it's actually quite rare for the user to navigate
through his library preferences directory and double click

00:40:30.369 --> 00:40:34.849
on that thing to launch the property editor.

00:40:34.849 --> 00:40:36.949
But it does happen.

00:40:36.949 --> 00:40:40.139
In that case, it'll be examined.

00:40:40.139 --> 00:40:42.509
It'll be seen that it's a regular document.

00:40:42.510 --> 00:40:44.270
The quarantine will be cleared.

00:40:44.269 --> 00:40:49.009
And, again, things just continue without
any interruption to the work flow.

00:40:49.010 --> 00:40:57.920
So I'm not sure how much utility this has,
but it is there. Why if you have the ability

00:40:57.920 --> 00:41:03.340
to directly set the quarantine properties and
especially supply more information would you want

00:41:03.340 --> 00:41:05.079
to use the automatic quarantine mode?

00:41:05.079 --> 00:41:07.519
I can think of a couple of reasons.

00:41:07.519 --> 00:41:11.170
One is because you want to start using quarantine right now.

00:41:11.170 --> 00:41:12.099
That's a fair reason.

00:41:12.099 --> 00:41:13.190
That's a good reason.

00:41:13.190 --> 00:41:16.840
But another can be illustrated by
how Safari is using quarantine today.

00:41:16.840 --> 00:41:20.390
Safari actually runs in automatic quarantine mode.

00:41:20.389 --> 00:41:24.639
So all the files that Safari creates are quarantined.

00:41:24.639 --> 00:41:32.559
But it also uses the LSSetItemAttribute
API in order to specify more details

00:41:32.559 --> 00:41:35.409
for those items that it knows are downloaded.

00:41:35.409 --> 00:41:40.170
The automatic quarantine mode picks up the
slack, though, for something like plug-ins.

00:41:40.170 --> 00:41:44.690
Safari doesn't have a knowledge
of what plug-ins might be doing.

00:41:44.690 --> 00:41:46.530
Some of them might be doing downloads.

00:41:46.530 --> 00:41:51.000
But it sure wants them to have
quarantine information associated with it.

00:41:51.000 --> 00:41:53.429
So that picks up those other pieces.

00:41:53.429 --> 00:41:57.199
Well, let's say those plug-ins evolve and start
setting quarantine information themselves.

00:41:57.199 --> 00:41:59.579
That's still going to work out
because they're just going to override

00:41:59.579 --> 00:42:03.659
that default automatically added quarantine information.

00:42:03.659 --> 00:42:10.349
So this work is working pretty well in practice. The next
thing I'd like to talk about is the Leopard Sandbox.

00:42:10.349 --> 00:42:14.659
In the security community, the Sandbox is a overloaded term.

00:42:14.659 --> 00:42:20.279
For example, if the Java security
policy is often called the Java Sandbox.

00:42:20.280 --> 00:42:26.890
In that case, the Sandbox is actually the mechanism
that's implementing and enforcing the security policy.

00:42:26.889 --> 00:42:32.569
That's in contrast to the Leopard Sandbox
which is created to harden your application.

00:42:32.570 --> 00:42:39.160
It's not a replacement or extension of the
usual operating system access controls.

00:42:39.159 --> 00:42:42.019
Rather, it's a safety mechanism.

00:42:42.019 --> 00:42:43.559
It's like a seat belt.

00:42:43.559 --> 00:42:46.320
It's there for when things go wrong.

00:42:46.320 --> 00:42:51.269
It hardens your application by letting you specify
what kinds of things your application is expected

00:42:51.269 --> 00:42:55.039
to do, only the things that it needs to do.

00:42:55.039 --> 00:42:58.840
And if it attempts to do other
things, it simply won't allow it.

00:42:58.840 --> 00:43:06.269
And this works even with root processes with processes
that have full system privileges. So the result of this is

00:43:06.269 --> 00:43:11.280
that for those applications, the impact
of the vulnerability is greatly reduced.

00:43:11.280 --> 00:43:18.300
If an attacker manages to compromise an application
in a Sandbox, that's not great, you don't like that;

00:43:18.300 --> 00:43:23.610
but it still limits what that attacker
can do with that compromise.

00:43:23.610 --> 00:43:27.750
Because of this, many system services in
Leopard are now running in a Sandbox.

00:43:27.750 --> 00:43:37.090
That includes things like BIND, the Internet name server,
little demons like portmap, the Xgrid infrastructure.

00:43:37.090 --> 00:43:42.829
These are actually all running with quite conversative
Sandboxes where everything's denied by default

00:43:42.829 --> 00:43:51.429
and we've attempted to give it only the privileges that
it needs to do its job. We also have Spotlight importers

00:43:51.429 --> 00:43:54.409
and QuickLooks plug-ins running in Sandbox.

00:43:54.409 --> 00:43:56.859
That Sandbox is a little more liberal.

00:43:56.860 --> 00:44:02.230
It does provide a speed bump, though,
for an attacker by keeping importers

00:44:02.230 --> 00:44:04.429
and plug-ins from being able to talk to the network.

00:44:04.429 --> 00:44:11.299
So this means it can't accidentally or maliciously
phone home or upload data to a remote server.

00:44:11.300 --> 00:44:18.140
So if you're writing an import or a plug-in, you
should keep that in mind. I wanted to give an example

00:44:18.139 --> 00:44:23.750
of the Sandbox profile language, the configuration
language that's used to create Sandboxes.

00:44:23.750 --> 00:44:28.599
Now for this release, this language is private interface.

00:44:28.599 --> 00:44:33.569
It's a scheme-based configuration language.

00:44:33.570 --> 00:44:41.640
And in this example...thanks, we're happy with
the flexibility from that...in this example,

00:44:41.639 --> 00:44:50.789
this profile denies everything by default and adds
the ability to read system configuration variables

00:44:50.789 --> 00:44:54.170
to do any kind of networking in this case.

00:44:54.170 --> 00:45:00.039
But it also allows some files system access but quite
restricted, some reading, some writing, some creating;

00:45:00.039 --> 00:45:04.139
but only to paths that match the regular
expressions that have been specified.

00:45:04.139 --> 00:45:06.039
That gives you just a little taste of the kind

00:45:06.039 --> 00:45:10.630
of power that's behind the scenes there. But
you may still want to use the Sandbox.

00:45:10.630 --> 00:45:15.349
Even though this is private interface, we do
have a public interface which is really simple

00:45:15.349 --> 00:45:19.480
and provides a few pre-defined Sandboxes.

00:45:19.480 --> 00:45:29.179
Those are things like a pure computation profile which
basically restricts almost any operating system access.

00:45:29.179 --> 00:45:30.619
At first it might seem weird.

00:45:30.619 --> 00:45:32.210
How can you use that?

00:45:32.210 --> 00:45:39.349
Well, one example that we've put to good use is to take a
multi-media codec and to run it in its own address space.

00:45:39.349 --> 00:45:43.380
And then we have that codec also running in a Sandbox.

00:45:43.380 --> 00:45:48.900
So its parent process with a user interface and
everything else can feed it data from whatever source,

00:45:48.900 --> 00:45:52.519
the network, files, which might be malicious.

00:45:52.519 --> 00:45:59.269
And well, codecs, image decoders, multi-media
decoders are...have...are notorious

00:45:59.269 --> 00:46:01.920
for having things like integer overflows and whatnot.

00:46:01.920 --> 00:46:09.579
But if one of these should be triggered, then
the attacker may have compromised that codec

00:46:09.579 --> 00:46:13.909
but he doesn't really have any ability to do
anything else except maybe suck some of your CPU time

00:46:13.909 --> 00:46:16.989
for a while. There's a second saving grace, too.

00:46:16.989 --> 00:46:22.129
When you're doing streaming video, sometimes
there is corruption of the data stream.

00:46:22.130 --> 00:46:25.730
Sometimes that unfortunately results in the codecs crashing.

00:46:25.730 --> 00:46:29.490
If you're running it in a separate address
space, the codec crashes and goes away.

00:46:29.489 --> 00:46:37.389
The user doesn't necessarily have to see that, especially if
you just restart the codec after you resync the data stream.

00:46:37.389 --> 00:46:44.789
You get some pretty cool stability that way. We also
provide some read-only profiles which are meant for things

00:46:44.789 --> 00:46:50.119
that are pure viewers like a PDF viewer
or a Word viewer, something like that.

00:46:50.119 --> 00:46:55.069
And I mentioned earlier about the Spotlight
plug-in...Spotlight importers and the QuickLooks plug-ins.

00:46:55.070 --> 00:46:57.890
They use a prohibit networking built-in profile.

00:46:57.889 --> 00:47:03.769
As an example of how to use these, we have this snippet.

00:47:03.769 --> 00:47:06.170
There's just one function call to make, sandbox_init

00:47:06.170 --> 00:47:12.659
and you specify a constant that details
the Sandbox that you want to be put in.

00:47:12.659 --> 00:47:16.009
When this function returns successfully,
you're in the Sandbox.

00:47:16.010 --> 00:47:18.500
The process can't escape that Sandbox.

00:47:18.500 --> 00:47:23.030
It can't enter another one.

00:47:23.030 --> 00:47:27.640
That's it. Moving on, we have a
new automatic firewall in Leopard.

00:47:27.639 --> 00:47:33.019
This has a new inbound filtering engine;
and unlike most of personal firewalls,

00:47:33.019 --> 00:47:38.190
instead of doing packet-based filtering,
it filters based on application.

00:47:38.190 --> 00:47:44.090
So no longer would one have to figure out
and select the port and protocol in order

00:47:44.090 --> 00:47:48.420
to make an application work while still keeping a firewall.

00:47:48.420 --> 00:47:54.820
In this case, I've selected iTunes and iChat, decided
I want those guys to be able to talk on the network.

00:47:54.820 --> 00:47:59.850
In particular I want them to be able
to listen for incoming connections.

00:47:59.849 --> 00:48:03.039
But I've chosen some different options for them.

00:48:03.039 --> 00:48:08.400
For iChat, since I want to get video chats from anywhere,
I've just allowed the incoming connections from anywhere.

00:48:08.400 --> 00:48:14.720
But for iTunes, I'm doing music sharing; but I don't
necessarily want the whole world to grab my music

00:48:14.719 --> 00:48:17.709
so I've restricted it to local connections only.

00:48:17.710 --> 00:48:26.429
That means connections from my locally connected
subnets. But you don't even have to go to system preferences.

00:48:26.429 --> 00:48:31.750
We've come out with, I think, a great way to
have applications almost configure themselves.

00:48:31.750 --> 00:48:35.650
So if your user wants to download
and run SubEthaEdit, you know,

00:48:35.650 --> 00:48:37.860
I decided I'm going to do some collaborative editing today.

00:48:37.860 --> 00:48:45.750
And I haven't run it before on this machine, we'll get
a dialogue that says hey, this thing needs to listen.

00:48:45.750 --> 00:48:47.590
Do you want to let it or not?

00:48:47.590 --> 00:48:51.100
If you choose...whatever you choose,
that choice is going to be recorded.

00:48:51.099 --> 00:48:53.819
You're going to be asked the one time.

00:48:53.820 --> 00:48:56.730
If I deny, it'll be stored as a deny for that application.

00:48:56.730 --> 00:48:59.500
If I allow, it'll be stored as an allow.

00:48:59.500 --> 00:49:01.880
That's a much easier configuration for most users.

00:49:01.880 --> 00:49:05.340
They don't have to figure out why
didn't SubEthaEdit not work just now.

00:49:05.340 --> 00:49:10.400
It told me I was going to be able to edit documents
across my network and stuff, but it didn't work.

00:49:10.400 --> 00:49:12.539
I'm not sure why.

00:49:12.539 --> 00:49:14.480
This way, they're totally in control of it.

00:49:14.480 --> 00:49:17.539
They don't even have to visit the sys
configuration panel unless they want to,

00:49:17.539 --> 00:49:22.980
unless they want to change their
decision later. Now IPFW is still present.

00:49:22.980 --> 00:49:28.099
Got ahead of myself.

00:49:28.099 --> 00:49:30.759
IPFW is still present for advanced users.

00:49:30.760 --> 00:49:35.320
This is the IPFW packet filtering firewall
that we've had for several releases.

00:49:35.320 --> 00:49:40.380
You can still configure it from the command line or
using the Mac OS X server user interface,

00:49:40.380 --> 00:49:44.220
or maybe some of you guys are writing
some great applications for configuring

00:49:44.219 --> 00:49:51.919
that firewall. Package signing has been added
to our PackageMaker and to our installer.

00:49:51.920 --> 00:49:58.720
In PackageMaker, you can select
the field labeled certificate,

00:49:58.719 --> 00:50:03.500
pick a certificate out of your Keychain
that's suitable for key signing.

00:50:03.500 --> 00:50:08.789
And the package that will then be produced
will be signed with that certficate.

00:50:08.789 --> 00:50:15.329
The installer, when using that, can detect any
modification that may have happened since it was signed.

00:50:15.329 --> 00:50:21.349
If it does that, it'll fail to install
and warn the user what's happened.

00:50:21.349 --> 00:50:26.960
This is a good complement to code signing
which is a slightly different beast.

00:50:26.960 --> 00:50:29.470
Code signing provides several benefits.

00:50:29.469 --> 00:50:33.849
One is that it detects malicious modification
to your code or unintentional ones.

00:50:33.849 --> 00:50:41.789
But more importantly, it allows us to keep an
application's identity across versions and updates.

00:50:41.789 --> 00:50:42.730
So that's pretty cool.

00:50:42.730 --> 00:50:52.050
It knows that wonder app version 1 and wonder app version
2 are just two different instances of the same program.

00:50:52.050 --> 00:50:57.500
Well, that's useful because other pieces of the
system, like the Keychain, can use that information.

00:50:57.500 --> 00:51:04.380
So we'll expect you'll see far fewer of the Keychain
dialogues that tend to happen when Safari or Mail

00:51:04.380 --> 00:51:10.400
or your application is updated and they
need to grab passwords from the Keychain.

00:51:10.400 --> 00:51:14.160
We shouldn't have to prompt the user so
much saying hey, is that really Mail?

00:51:14.159 --> 00:51:16.460
Do you really want me to give it your password?

00:51:16.460 --> 00:51:23.809
Because we would have maintained a stable identity across
the updates. There's also several other pieces of Leopard

00:51:23.809 --> 00:51:26.840
that use that identity when the code's signed.

00:51:26.840 --> 00:51:29.260
I mentioned the Keychain already.

00:51:29.260 --> 00:51:35.580
The automatic firewall that we just discussed
also uses that in order to configure itself.

00:51:35.579 --> 00:51:44.099
Parental controls now uses the code signing so that when
you select that I'm going to let my kid use Safari or Mail,

00:51:44.099 --> 00:51:49.029
it has that as a cryptographically signed
identity so it can allow that and only that.

00:51:49.030 --> 00:51:55.350
It's much harder to spoof a, say,
World of Warcraft and call that Safari.

00:51:55.349 --> 00:51:57.969
I stole that from Perry's talk yesterday.

00:51:57.969 --> 00:52:02.679
It was a In-Depth Code Signing
thing. So authorization services

00:52:02.679 --> 00:52:07.289
and several other pieces of the
infrastructure also use this.

00:52:07.289 --> 00:52:09.860
All of the gory details are in the Code Signing Guide.

00:52:09.860 --> 00:52:15.420
This will tell you how to sign your code and
what the ramifications are going to be of that.

00:52:15.420 --> 00:52:18.099
All I know I should tell you is please go sign your code.

00:52:18.099 --> 00:52:20.719
There's no ill effects to that.

00:52:20.719 --> 00:52:22.519
It's still going to run on Tiger.

00:52:22.519 --> 00:52:24.449
Of course, it's going to run on Leopard.

00:52:24.449 --> 00:52:26.439
Tiger will ignore the signature.

00:52:26.440 --> 00:52:32.460
But you'll be able to leverage several
benefits in Leopard as you have it today,

00:52:32.460 --> 00:52:40.429
and we believe that we'll increasingly add more
benefits to that over time. Now some of you may have gone

00:52:40.429 --> 00:52:46.139
to the compiler advances talk yesterday and
have seen a little bit of this material already,

00:52:46.139 --> 00:52:50.029
but we're going to go in a little
more depth about what's going on.

00:52:50.030 --> 00:52:53.130
The first piece is non-executable data.

00:52:53.130 --> 00:52:57.170
It's also called...I think Intel calls it execute/disable.

00:52:57.170 --> 00:53:04.329
Since Intel Tiger shipped, Mac OS X
stack has been marked non-executable.

00:53:04.329 --> 00:53:11.389
The benefit of this is that it makes
certain buffer overflow attacks impossible.

00:53:11.389 --> 00:53:17.579
When a buffer overflow occurs, a typical
attack would include delivering instructions

00:53:17.579 --> 00:53:23.509
that the attacker wants your computer to execute, some
kind of a payload; and that would go into a stacked buffer.

00:53:23.510 --> 00:53:27.430
It would also overwrite the return
address that's on the stack,

00:53:27.429 --> 00:53:30.669
and that's how the attacker controls
the instruction pointer.

00:53:30.670 --> 00:53:35.650
So we point that at his payload in the stack.

00:53:35.650 --> 00:53:38.070
That's the classic buffer overflow.

00:53:38.070 --> 00:53:41.030
But with a non-executable stack, that doesn't work.

00:53:41.030 --> 00:53:46.650
When the attacker attemps to jump into the
stack, they'll get a memory protection fault.

00:53:46.650 --> 00:53:50.990
Now there's still other places that
the attacker can put his payload.

00:53:50.989 --> 00:53:55.049
There's the heap and static data segments.

00:53:55.050 --> 00:53:59.269
But in Leopard, all 64-bit apps extend this protection.

00:53:59.269 --> 00:54:03.170
So it covers the stack and the heap and other locations.

00:54:03.170 --> 00:54:08.250
In fact, by default, the entire set
of memory regions in a 64-bit process

00:54:08.250 --> 00:54:12.800
on a Leopard is either writeable or executable.

00:54:12.800 --> 00:54:26.730
This is known as WXRX in some circles. So first a 64-bit app
that's running on a Intel Core 2 Duo or later or on a G5,

00:54:26.730 --> 00:54:33.829
the memory layout might be something like this diagram
which simply illustrates several memory regions.

00:54:33.829 --> 00:54:37.929
The green ones are the ones that
are writeable but can't be executed,

00:54:37.929 --> 00:54:41.869
and the blue one is the one in
this diagram that can be executed.

00:54:41.869 --> 00:54:43.159
But it's read only.

00:54:43.159 --> 00:54:50.839
You can't write to it. By the way, 32-bit apps will
continue to remain compatible as they are on Tiger

00:54:50.840 --> 00:54:52.950
by only providing the non-executable stack.

00:54:52.949 --> 00:54:55.029
They won't get the extra protection.

00:54:55.030 --> 00:55:01.790
This is just another reason to use 64-bit apps and deliver
them whenever possible. Now there are some applications

00:55:01.789 --> 00:55:09.000
that actually do need to generate code, do need to write
some instructions to the data segment and then execute it.

00:55:09.000 --> 00:55:11.670
Just in time filers might be an example.

00:55:11.670 --> 00:55:15.789
So in order to do that you can
just use the unprotect system call

00:55:15.789 --> 00:55:18.079
in order change the protection
on a particular memory region.

00:55:18.079 --> 00:55:26.269
So all this non-executable data stuff really
makes it harder to pull off an exploit.

00:55:26.269 --> 00:55:32.039
It's going to mitigate a lot of buffer overflows, format
string bugs and the other types of bugs we talked about.

00:55:32.039 --> 00:55:35.429
But it's not perfect.

00:55:35.429 --> 00:55:38.969
There's still ways to do an exploit.

00:55:38.969 --> 00:55:44.809
For example, an attacker, even though
he can't write the payload he wants,

00:55:44.809 --> 00:55:50.500
may find that there's a library already
loaded in memory that does just what he wants.

00:55:50.500 --> 00:55:54.380
Let's use the standard C system function as an example.

00:55:54.380 --> 00:56:01.900
The standard C system function takes one argument, a string,
and passes it to the shell and executes whatever it says.

00:56:01.900 --> 00:56:03.800
That's pretty powerful.

00:56:03.800 --> 00:56:12.350
So if an attacker can arrange that the return address
points to the system and provides on the stack a string

00:56:12.349 --> 00:56:16.139
of the command he wants to run, then
he's successfully gained control

00:56:16.139 --> 00:56:24.239
of your machine.This technique is commonly known
as "return-to-libc." Now a way to thwart this is

00:56:24.239 --> 00:56:29.379
to introduce something called address
space layout randomization or ASLR.

00:56:29.380 --> 00:56:33.260
A system without ASLR might look something like this.

00:56:33.260 --> 00:56:34.300
Here we have libSystem.

00:56:34.300 --> 00:56:41.050
That's our main kitchen sink...I mean, main
standard library with the AppKit, Core Services

00:56:41.050 --> 00:56:44.240
and some other frameworks I've added here for illustration.

00:56:44.239 --> 00:56:49.139
An attacker might be targeting that system
function we talked about in libSystem.

00:56:49.139 --> 00:56:57.809
He can do that because he knows for all Macs with the same
operating system release and same architecture the location,

00:56:57.809 --> 00:57:01.329
the memory location of that function is the same.

00:57:01.329 --> 00:57:05.940
So he can jump into that memory
location and start executing.

00:57:05.940 --> 00:57:14.159
As we see here, we start off with the prologue
of the function, saving the base pointer.

00:57:14.159 --> 00:57:17.059
So this is going to work for him.

00:57:17.059 --> 00:57:23.329
But the reason this works is because
the whole address space is predictable.

00:57:23.329 --> 00:57:31.509
With ASLR, we load common operating system libraries
in a random order, starting from a random page

00:57:31.510 --> 00:57:34.970
and put random gaps in between the libraries.

00:57:34.969 --> 00:57:37.339
This makes it much harder.

00:57:37.340 --> 00:57:43.289
The attacker now may still be aiming
for the libSystem system function,

00:57:43.289 --> 00:57:45.750
but he's maybe using the same address as before.

00:57:45.750 --> 00:57:48.570
He can't predict what the address is any longer.

00:57:48.570 --> 00:57:53.120
So his exploit is going to wind up
jumping maybe into unmapped page

00:57:53.119 --> 00:57:56.000
or maybe into the middle of some data segment in

00:57:56.000 --> 00:57:57.179
Quartz Core. That's here.

00:57:57.179 --> 00:58:06.119
He's not going to get the results that
he thinks. Now I...and I'm just kidding.

00:58:07.650 --> 00:58:23.670
That crash...that crash is what's likely to result, but
that crash is a heck of a lot better than getting owned,

00:58:23.670 --> 00:58:26.869
than letting that attacker have control of your machine.

00:58:26.869 --> 00:58:34.710
So there's still some areas that are not randomized
by default, and those might have something

00:58:34.710 --> 00:58:38.429
that the attacker can jump into in certain situations.

00:58:38.429 --> 00:58:44.469
But if you compile your applications with something
called pie or position independent executable,

00:58:44.469 --> 00:58:49.609
then that will cause your application's main
executable to be loaded at a random address as well

00:58:49.610 --> 00:58:54.340
and all the dependent libraries that
aren't already in the shared cache.

00:58:54.340 --> 00:58:56.090
So you should really do that.

00:58:56.090 --> 00:59:05.780
Take advantage of that, again. Now this is really only
effective for remote attackers, for someone trying to break

00:59:05.780 --> 00:59:09.070
into your web browser or into your network service.

00:59:09.070 --> 00:59:10.700
I just felt I should mention that.

00:59:10.699 --> 00:59:15.829
If you have a local attacker, they can pretty much
look for themselves and see where the functions are.

00:59:15.829 --> 00:59:20.139
So if you have a malicious user on your
system, this doesn't protect you much.

00:59:20.139 --> 00:59:26.500
But it's really great for those network facing
apps. We've got a couple of more options.

00:59:26.500 --> 00:59:31.920
We have now stack overflow checking as
an option in our developer tool chain.

00:59:31.920 --> 00:59:38.750
This uses a technique called Canaries that's been
implemented before by things like stack guard.

00:59:38.750 --> 00:59:43.019
The word...the term Canary comes
from, of course, the miner's Canary.

00:59:43.019 --> 00:59:48.380
The miner would go into a shaft; and the
danger there is methane gas, carbon monoxide.

00:59:48.380 --> 00:59:50.960
Sometimes that leaks out and kills you.

00:59:50.960 --> 00:59:55.650
So bring a Canary along which are
much more sensitive to the gases.

00:59:55.650 --> 01:00:00.769
If the Canary dies, you know you better
get out now because the gas is coming.

01:00:00.769 --> 01:00:02.530
So we do something similar here.

01:00:02.530 --> 01:00:05.640
I'll show you how we use a Canary in stack protection.

01:00:05.639 --> 01:00:11.759
On the right, we have a function, appropriately
named bad, that's not very well written.

01:00:11.760 --> 01:00:13.410
There's a buffer overflow there.

01:00:13.409 --> 01:00:18.420
There's a fixed size stack buffer, and
we're using sprintf on that stack buffer.

01:00:18.420 --> 01:00:23.289
But we're supplying a couple of
parameters that could be unbounded.

01:00:23.289 --> 01:00:27.210
So, of course, after the path buffer's been filled out,

01:00:27.210 --> 01:00:31.429
the data will continue to overwrite the
return address and you knows what else there.

01:00:31.429 --> 01:00:33.909
Of course, the key thing is that return address.

01:00:33.909 --> 01:00:38.129
If the attacker can control that return address,
he can control what the application does

01:00:38.130 --> 01:00:44.220
to a great degree. If you use the stack
protector, it inserts the Canary,

01:00:44.219 --> 01:00:48.559
a random value, one that the attacker can't predict.

01:00:48.559 --> 01:00:54.549
Now when the buffer overflow occurs, it'll overwrite the
Canary before it gets to the return address and may continue

01:00:54.550 --> 01:00:57.630
and successfully overwrite the return address.

01:00:57.630 --> 01:01:01.289
But the stack protector has added code.

01:01:01.289 --> 01:01:04.400
When the function is about to return, it checks the Canary.

01:01:04.400 --> 01:01:08.180
If the Canary is not the same value
it started with, then it's all over.

01:01:08.179 --> 01:01:09.849
The application aborts.

01:01:09.849 --> 01:01:15.900
Again, not the best thing; but better than being
owned. One last thing is object size checking.

01:01:15.900 --> 01:01:21.130
This can change some unsafe API
usage into some checked behavior.

01:01:21.130 --> 01:01:27.250
There's a list of them, mostly memory
movement and string manipulation functions.

01:01:27.250 --> 01:01:30.079
You turn it on very...in a very straightforward fashion.

01:01:30.079 --> 01:01:35.029
You just define four to five source to two.

01:01:35.030 --> 01:01:37.210
No one asks about the two.

01:01:37.210 --> 01:01:38.960
Just use the two.

01:01:40.829 --> 01:01:45.179
To illustrate what this does, we have the same
bad function that we had on the previous slide.

01:01:45.179 --> 01:01:49.589
I've called it before here, and
then what the compiler does to it.

01:01:49.590 --> 01:01:54.190
So first, of course, we had that
sprintf on this fixed size buffer.

01:01:54.190 --> 01:01:58.490
The compiler changes this into a call to a new function.

01:01:58.489 --> 01:02:08.289
It's built-in sprintf check and includes something called
a builtin_object_size which tells...instructs the compiler

01:02:08.289 --> 01:02:13.980
if you can at compile time how big
this thing is, pass that value here.

01:02:13.980 --> 01:02:15.990
So...and not in all cases can it tell.

01:02:15.989 --> 01:02:21.059
If you're doing dynamic memory allocation off the
heap, it's not going to be able to figure that out.

01:02:21.059 --> 01:02:29.320
But if it's a buffer on...a fixed size buffer on the
stack or if it's a fixed size buffer in your data segment

01:02:29.320 --> 01:02:35.240
or if it's part of a structure where you have
the full type definition for that, it can tell.

01:02:35.239 --> 01:02:38.199
And in those cases, it will do the sprintf as usual.

01:02:38.199 --> 01:02:46.449
But if it detects an overflow, that it's written more than
was in the buffer, then, again, we abort the process. So

01:02:46.449 --> 01:02:55.519
in summary, today we noted that security really
requires both proactive and reactive measures.

01:02:55.519 --> 01:03:00.719
Educate yourself on the different types
of security vulnerabilities that they are.

01:03:00.719 --> 01:03:03.929
Certainly do as much testing as possible.

01:03:03.929 --> 01:03:05.919
Hunt around for your own bugs.

01:03:05.920 --> 01:03:07.539
But also be prepared.

01:03:07.539 --> 01:03:11.599
It's important to have a good process in place for that day

01:03:11.599 --> 01:03:16.049
that someone else outside your organization
does report a vulnerability to you.

01:03:16.050 --> 01:03:25.539
You need to smoothly handle that and roll out an
update in a manner appropriate for that kind of a bug.

01:03:25.539 --> 01:03:30.980
Fuzzing is one of the, I think, the
easiest techniques to use for testing.

01:03:30.980 --> 01:03:34.280
It's cheap to implement, and it produces lots of results.

01:03:34.280 --> 01:03:35.290
And it's kind of fun.

01:03:35.289 --> 01:03:40.360
So if you can do that, add that to
your...when you're testing for security issues,

01:03:40.360 --> 01:03:42.039
I think you'll get a real return on that.

01:03:42.039 --> 01:03:46.440
And then finally, these new security
options, definitely use them.

01:03:46.440 --> 01:03:47.970
We're using them.

01:03:47.969 --> 01:03:50.389
We're going to make more, and we're going to use more.

01:03:50.389 --> 01:03:52.309
So I hope you enjoyed that.

01:03:52.309 --> 01:03:57.219
Craig Keithley is going to help us out with the Q&A.

01:03:57.219 --> 01:03:58.849
And we have some references here.

01:03:58.849 --> 01:04:07.219
Again, if you or a friend or an enemy knows about or
believes they know about a potential vulnerability

01:04:07.219 --> 01:04:11.199
or security issue in a Apple product, please
report that to Apple Product Security.

01:04:11.199 --> 01:04:15.009
Use a bug report, or e-mail product-security@apple.com.

01:04:15.010 --> 01:04:19.970
The Secure Coding Guide and the Code Signing
Guides are available for you for your reference.