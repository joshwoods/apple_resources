WEBVTT

00:00:14.060 --> 00:00:18.750
>> Thank you everyone for coming to session 417.

00:00:18.750 --> 00:00:23.740
My name is Babak Mahbod and I'm a Senior
Software Engineer here at Apple Computer.

00:00:23.739 --> 00:00:31.759
So today we're going to talk about what it means
to actually switch to Mac OS X OpenGL.

00:00:31.760 --> 00:00:36.810
So let's talk about what we're going to
you know, the con10t of this session.

00:00:37.939 --> 00:00:48.459
So at, today we live in an age of digital con10t and
multimedia, and at the heart of every good multimedia

00:00:48.460 --> 00:00:54.740
and digital con10t system must lie a
great 2D 3D graphics engi=ne.

00:00:54.740 --> 00:01:00.550
And here Mac OS X, we have, we feel we
have the best commercial implementation

00:01:00.549 --> 00:01:06.250
of that 2D 3D graphics API in OpenGL.

00:01:06.250 --> 00:01:14.710
And also with OpenGL it has historical origin in
just being used as a 2D 3D graphics APIs.

00:01:14.709 --> 00:01:20.729
Well you has, that scene has changed a bit, and
today it's, really I feel has evolved to become more

00:01:20.730 --> 00:01:26.070
than a 2D 3D graphics APIs, it's
just become a hardware abstraction layer

00:01:26.069 --> 00:01:33.789
that actually abstracts the graphics cards
and your GPUs from you application developers.

00:01:33.790 --> 00:01:38.110
So today we going to talk about application development,

00:01:38.109 --> 00:01:43.010
and what it means to bring your 2D 3D
graphics application to our platform.

00:01:43.010 --> 00:01:46.090
And to facilitate that process, we going to talk little bit

00:01:46.090 --> 00:01:51.329
about our utility frameworks that
will accelerate that process.

00:01:51.329 --> 00:01:55.730
And then we going to talk about some modern practices.

00:01:55.730 --> 00:01:58.859
And why is it that we want to talk about modern practices?

00:01:58.859 --> 00:02:07.640
Well today it's hard to actually separate
performance, optimization you know,

00:02:07.640 --> 00:02:17.599
from bringing your OpenGL application to a, our platform,
and it's the same situation actually with our Direct 3D
=

00:02:17.599 --> 00:02:21.359
and Direct3D 9 and 10 developers.

00:02:21.360 --> 00:02:30.510
Because when you bring your applications, you know,
when you go beyond a fast path, you need to take into a,

00:02:30.509 --> 00:02:35.209
you need to get off things like immediate
mode and fixed-function pipeline.

00:02:35.210 --> 00:02:40.439
And there is a common theme amongst all a family of APIs.

00:02:40.439 --> 00:02:46.349
Of course it's a huge difference going from
1 frame per second to 2 frames a second,

00:02:46.349 --> 00:02:48.909
to 10 frames a second, to 60 frames a second.

00:02:48.909 --> 00:02:54.740
So we need to talk about fast path best
practices on optimization techniques.

00:02:54.740 --> 00:03:05.580
And we going to also talk about, a little bit about HLSL to
GLSL, and more specifically we going to talk about the concepts

00:03:05.580 --> 00:03:13.530
like vertex buffer objects, flush buffer range, which is
closely tied to vertex buffer objects, render to texture,

00:03:13.530 --> 00:03:17.319
pixel buffer objects, and we going to talk about shaders.

00:03:17.319 --> 00:03:24.530
And as we progressing through our presentation,
more specifically with the concept of textures

00:03:24.530 --> 00:03:31.969
vertex buffer objects, render to texture, and shaders,
I'm going to be showing you some algorithmic workflows

00:03:31.969 --> 00:03:38.550
in Direct3D 9, some algorithmic
workflows in Direct3D 10, and OpenGL.

00:03:38.550 --> 00:03:48.180
So the basic idea is that you going to see that, even
though there are really no one to one and onto mapping

00:03:48.180 --> 00:03:54.020
between the APIs coming from Direct3D 9,
Direct3D 10 to OpenGL.

00:03:54.020 --> 00:03:56.469
The ideas are there.

00:03:59.530 --> 00:04:02.539
So let's talk about application development.

00:04:03.569 --> 00:04:09.009
So some of you are coming from UNIX variety of OpenGL,

00:04:09.009 --> 00:04:16.689
and you probably been developing your applications
using Xt, Motif, CDE, KDE, or gnome toolkit.

00:04:16.689 --> 00:04:18.769
So what is that you normally do here?

00:04:18.769 --> 00:04:23.289
Well, you take into account your user inputs,

00:04:23.290 --> 00:04:27.069
then you want to handle some events,
and for that you write some callbacks.

00:04:27.069 --> 00:04:32.620
Then you get a window, you set a device
context, some parameters on a device context,

00:04:32.620 --> 00:04:38.240
and then you start working with your OpenGL code.

00:04:38.240 --> 00:04:42.280
For those of you who do cross-platform development,
you probably been using GLUT,

00:04:42.279 --> 00:04:48.859
you game developers who have probably been using SDL,
Q/t from Trolltech, or wxWidgets.

00:04:48.860 --> 00:04:58.889
Again, the theme is the same, because you take your
user inputs into account, you write your callbacks,

00:04:58.889 --> 00:05:05.300
you get a window, you set some parameters on your
graphics device, and then you're off and running.

00:05:05.300 --> 00:05:12.530
And for those of you coming from Direct3D 9
and Direct3D 10, you of course been working a lot

00:05:12.529 --> 00:05:17.469
with Windows APIs and graphic device interfaces.

00:05:17.470 --> 00:05:19.680
And idea again is the same.

00:05:19.680 --> 00:05:26.910
Handle events, get a window, set some parameters
on your graphics device, and last but not least,

00:05:26.910 --> 00:05:31.270
in this case when you're coming from Windows,
you get a scene and you start drawing

00:05:31.269 --> 00:05:37.259
into a scene using Direct3D
9 or Direct3D family of APIs.

00:05:37.259 --> 00:05:43.199
On Mac OS X we recommend that you use
Cocoa for your application development.

00:05:43.199 --> 00:05:45.099
And why do we recommend using Cocoa?

00:05:45.100 --> 00:05:52.290
Well Cocoa has its origins from the NeXT days,
but it has actually grown into a very mature

00:05:52.290 --> 00:05:57.360
and very powerful family of APIs and frameworks.

00:05:57.360 --> 00:06:03.810
That allows you to rapidly develop commercial
quality application in a short period of time.

00:06:03.810 --> 00:06:14.639
There's truly a seamless integration between your tools and
your Cocoa APIs and frameworks, and as you will shortly see,

00:06:14.639 --> 00:06:20.930
it really comes down to dragging your buttons,
your windows, and, from some palettes, you know,

00:06:20.930 --> 00:06:25.910
one of our tools called Interface Builder,
and you initialize some attributes,

00:06:25.910 --> 00:06:31.360
you connect them to other objects,
and you're off and running.

00:06:31.360 --> 00:06:39.830
But Cocoa is just really more than that, because
it generally takes into account most of the events

00:06:39.829 --> 00:06:44.389
that a user, well you know, user might be using.

00:06:44.389 --> 00:06:52.389
So for example, for application, windows and workspace
management, Cocoa frameworks handles those events for you.

00:06:52.389 --> 00:06:58.589
And in addition when you start using Cocoa and you develop
a Cocoa application, you get a lot of additional things

00:06:58.589 --> 00:07:05.279
such as scriptability, comes automatically with it.

00:07:05.279 --> 00:07:11.549
So Cocoa also has, also defines a
model for behavior of an application.

00:07:11.550 --> 00:07:20.500
And when you generally develop an application, you try to
fit the application that you're developing into this model.

00:07:20.500 --> 00:07:29.079
So Cocoa applications adhere to this
model view controller design pattern.

00:07:29.079 --> 00:07:32.050
So your model basically will be your intellectual property.

00:07:32.050 --> 00:07:36.379
It will be your game engine, game physics
engine, or your computational engine.

00:07:36.379 --> 00:07:43.560
Your view for example will be your NSView where you're
actually going to be drawing your OpenGL content into.

00:07:43.560 --> 00:07:47.439
And your controllers and object,
as just like a request broker

00:07:47.439 --> 00:07:53.339
that marshals the messages between your model and a view.

00:07:53.339 --> 00:07:58.789
So at this stage I would like to bring to
stage Mr. Michael Jurewitz,

00:07:58.790 --> 00:08:00.330
he's a colleague of mine at Apple.

00:08:00.329 --> 00:08:05.879
And he's going to run through a demo that's going to show
you basically functionality of the Cocoa application.

00:08:05.879 --> 00:08:06.709
Michael?

00:08:06.709 --> 00:08:07.310
>> Thanks Babak.

00:08:07.310 --> 00:08:12.439
So as Babak mentioned, I'm a DTS Engineer, so my job
is to work primarily with developers like yourselves

00:08:12.439 --> 00:08:16.579
who are either bringing applications to the platforms,
or who have questions on how to use our frameworks.

00:08:16.579 --> 00:08:18.969
So we've got a couple demos planned for you today.

00:08:18.970 --> 00:08:24.170
We'll go ahead and start off with
our first one, OpenGL basics.

00:08:24.170 --> 00:08:30.610
So let's go ahead and build and run this
application just to get a flavor for what it does.

00:08:30.610 --> 00:08:32.050
So build and go.

00:08:32.049 --> 00:08:38.579
And once our application is launched, you'll see that
by clicking these buttons on the bottom we can go ahead

00:08:38.580 --> 00:08:43.350
and affect the way that we're actually
drawing into our OpenGL view right here.

00:08:43.350 --> 00:08:50.430
You see we have a simple Cocoa application,
complete with menus, complete with event handling,

00:08:50.429 --> 00:08:55.469
that's really actually a barebones application, so let's
dive in and see exactly what's happening right here.

00:08:55.470 --> 00:09:03.340
So we'll go into Xcode, and we'll take a look first
actually at our header file for the OpenGL basics view.

00:09:03.340 --> 00:09:07.970
And you'll see this is simply a subclass of NSOpenGLView.

00:09:07.970 --> 00:09:13.690
Now NSOpenGLView is the basic app kit class
for doing work with OpenGL in our frameworks.

00:09:13.690 --> 00:09:17.560
And this OpenGL view is itself a subclass of NSView,

00:09:17.559 --> 00:09:21.179
which is responsible for all the
drawing behavior throughout the kit.

00:09:21.179 --> 00:09:24.909
You'll see we've declared some simple state
that we want to keep track of for our view,

00:09:24.909 --> 00:09:29.719
and we've also declared a method
down here we call setClearColor.

00:09:29.720 --> 00:09:33.269
setClearColor you'll see has a return type of IB action,

00:09:33.269 --> 00:09:36.129
which might seem kind of strange
if you're near the platform.

00:09:36.129 --> 00:09:42.769
So IB action is simply a #define that Interface Builder
uses, so for you to be able to annotate on your objects

00:09:42.769 --> 00:09:47.069
that there are messages that you want
other objects to be able to send to it.

00:09:47.070 --> 00:09:50.390
We'll see this in a second when we
actually go into Interface Builder.

00:09:50.389 --> 00:09:54.029
You'll also notice that the one parameter
that we take in here is a sender.

00:09:54.029 --> 00:09:59.279
Again, that's customary with IB actions, we want to know
who's actually going to be sending this view a message.

00:09:59.279 --> 00:10:05.100
So let's go ahead and actually take a quick look at
Interface Builder, and see how we have this laid out.

00:10:05.100 --> 00:10:10.090
So we'll open up our MainMenu.nib,
and we'll take a look at our window.

00:10:10.090 --> 00:10:13.120
And you'll see this looks exactly
the way that we had it on screen,

00:10:13.120 --> 00:10:19.090
only here we have our OpenGL basics
view that at run time we render to.

00:10:19.090 --> 00:10:25.009
We also have some buttons set up here, and if we
control click we'll notice we have this inspector.

00:10:25.009 --> 00:10:32.470
And you can see that this button is set to send an
action called setClearColor to our OpenGL basics view.

00:10:32.470 --> 00:10:40.200
Similarly, the same thing for our green and our red
buttons, those are also set up to do exactly the same thing.

00:10:40.200 --> 00:10:45.950
So let's go ahead and hop back into the
implementation here, and see what's actually going on.

00:10:45.950 --> 00:10:51.140
So if we look at our OpenGL basics view
.m file, which is the implementation,

00:10:51.139 --> 00:10:54.740
we have three methods that we want
to focus on primarily right now.

00:10:54.740 --> 00:10:57.149
So we have this method called awakeFromNib.

00:10:57.149 --> 00:11:01.730
Now what I just showed you there in Interface Builder is
what's called a nib file, where we archive off our objects

00:11:01.730 --> 00:11:08.379
that at run time are going to be reinstantiated for
us, and as part of that reinstantiation process,

00:11:08.379 --> 00:11:12.529
after all the objects have been initialized,
and all the connections have been set up,

00:11:12.529 --> 00:11:15.279
they're all sent the message awakeFromNib.

00:11:15.279 --> 00:11:18.909
Now this also happens before any events
have been handled by those objects.

00:11:18.909 --> 00:11:25.240
So in this case we're actually just setting a
colorAlphaIndex for ourself, which if we look up,

00:11:25.240 --> 00:11:29.389
was back in our header, it's just part of an
enum called ClearColors.

00:11:29.389 --> 00:11:32.949
In this case we're just setting up some
basic state for our initial drawing.

00:11:32.950 --> 00:11:37.700
That's really the purpose of awakeFromNib is
for you to set up that kind of initial state.

00:11:37.700 --> 00:11:41.270
Now the next method that we want to take
a look at as drawRect.

00:11:41.269 --> 00:11:46.159
drawRect is a method that comes from NSView, and this
is a method that anything that wants to draw to screen,

00:11:46.159 --> 00:11:50.230
and is an NSView subclass implements
in order to achieve that behavior.

00:11:50.230 --> 00:11:54.100
So you'll notice that we're simply
taking some basic GL state,

00:11:54.100 --> 00:12:02.120
and using that to then call a method called drawTexture,
and then we're simply flushing our OpenGL context.

00:12:02.120 --> 00:12:05.090
Now the other method that we mentioned
earlier was setClearColor,

00:12:05.090 --> 00:12:07.899
and you'll see we have the implementation for it right here.

00:12:07.899 --> 00:12:09.980
Again, we take in a sender.

00:12:09.980 --> 00:12:13.340
Now you notice that we ask this sender for a tag.

00:12:13.340 --> 00:12:18.379
Well, all of our senders are buttons,
which are controls in the kit.

00:12:18.379 --> 00:12:24.379
Controls let you associate with them what's called
a tag, which is just an integer to identify them.

00:12:24.379 --> 00:12:29.730
In this case we've used it simply to be an
index that we're going to use for our drawing.

00:12:29.730 --> 00:12:34.409
Next, since we've actually clicked one of these buttons,
we need to give a clue to the kit to know that we need

00:12:34.409 --> 00:12:38.250
to update the drawing of our view, and
that we should go through drawRect again.

00:12:38.250 --> 00:12:41.360
In this case we say self setNeedsDisplay, YES.

00:12:41.360 --> 00:12:45.149
That simply tells us that our view is
dirty, we need to redraw it to the screen.

00:12:45.149 --> 00:12:51.059
So let's look at how we can actually put together an
interface like this, and how quick it actually is.

00:12:51.059 --> 00:12:54.609
So if we take a look at Interface Builder,
we'll go ahead and just close out our nib

00:12:54.610 --> 00:12:57.120
that we had here, and we'll make a new one.

00:12:57.120 --> 00:12:59.419
We'll just use the application template.

00:12:59.419 --> 00:13:05.729
And again, you'll see we've gotten most of the same
objects that we had before, as well as a window.

00:13:05.730 --> 00:13:09.860
So now let's take this window, and
we want to add to it an OpenGL view.

00:13:09.860 --> 00:13:15.159
So we'll use our inspector, and we'll type in NS OpenGL,

00:13:15.159 --> 00:13:19.309
and drag this window simply to,
drag that view simply to our window.

00:13:19.309 --> 00:13:21.759
We can go ahead and resize it really quickly.

00:13:21.759 --> 00:13:26.620
Now again, this is just an NSOpenGLView, but
we had a custom subclass that we had been using.

00:13:26.620 --> 00:13:33.399
So we simply go back to Xcode, and make sure that we
drag in the header file for that into Interface Builder.

00:13:33.399 --> 00:13:37.029
It'll parse that and be aware of it
so that we can use it in our nib.

00:13:37.029 --> 00:13:42.360
We'll simply make sure that we go and we
set its custom class to OpenGLBasicsView.

00:13:42.360 --> 00:13:45.370
I just typed in O, it already auto completed for me.

00:13:45.370 --> 00:13:49.560
And you'll also see that it's already parsed
the file and noticed that we have an action

00:13:49.559 --> 00:13:53.919
that we can take called ClearColor,
called, sorry, called setClearColor.

00:13:53.919 --> 00:13:56.610
Now let's go ahead and just add a button to our interface.

00:13:56.610 --> 00:14:04.230
So we'll search for button, drag that onto our
interface, and then we can just control drag to our view,

00:14:04.230 --> 00:14:09.129
and you'll see that one of the options here
is to send the message setClearColor.

00:14:09.129 --> 00:14:12.379
We simply connect that up, and we're good to go.

00:14:12.379 --> 00:14:16.799
We can go ahead and set the tag on the button if
we want, in this case we'll just leave it as 0.

00:14:16.799 --> 00:14:22.490
And that's all you have to do in order to get a
simple interface like this set up very rapidly.

00:14:22.490 --> 00:14:24.649
All right, Babak, back to you.

00:14:24.649 --> 00:14:25.139
>> Thank you Michael.

00:14:25.139 --> 00:14:28.370
We're going to see Michael a little bit later on today.

00:14:30.190 --> 00:14:31.510
Slides please.

00:14:31.509 --> 00:14:42.330
Okay. So let's talk about some of
these OpenGL utility frameworks.

00:14:42.330 --> 00:14:49.620
Of course for those of you who are coming from Windows,
and you're used to developing OpenGL on Windows,

00:14:49.620 --> 00:14:54.060
most of you are familiar with WGL, or wiggle.

00:14:54.059 --> 00:14:55.259
What does wiggle do?

00:14:55.259 --> 00:14:59.379
I mean we talked about earlier on
that once you set up the window,

00:14:59.379 --> 00:15:03.559
you want to set some attributes for that device context.

00:15:03.559 --> 00:15:04.539
Great, so how do you do that?

00:15:04.539 --> 00:15:07.349
You do that basically through wiggle.

00:15:07.350 --> 00:15:10.970
Example of which we'll be setting a pixel format.

00:15:10.970 --> 00:15:16.360
If you're coming from UNIX, the
same story is true over there.

00:15:16.360 --> 00:15:21.269
Because GLX again, you have a window
already, you have a device context,

00:15:21.269 --> 00:15:24.529
you want to set parameters on it
against let's say pixel format.

00:15:24.529 --> 00:15:27.110
So you'll be using GLX.

00:15:27.110 --> 00:15:34.320
On Mac OS X actually we ship with X11,
and we also ship GLX with X11,

00:15:34.320 --> 00:15:37.960
and it's actually optimized for our platform.

00:15:38.990 --> 00:15:45.039
On Mac OS X, Michael briefly touched
upon it, we have NSOpenGLView.

00:15:45.039 --> 00:15:52.980
And NSOpenGLView as you saw, can be setup in an
Interface Builder, and it's a subclass of NSView,

00:15:52.980 --> 00:16:03.450
NSView being its parent class, and it just basically gives
you all the facilities to display your OpenGL content.

00:16:03.450 --> 00:16:12.780
And its building blocks, in addition to NSView are OpenGL,
NSOpenGLContext, and NSOpenGLPixelFormat.

00:16:12.779 --> 00:16:18.120
So basically when you subclass NSOpenGLView,
you really don't need to do much.

00:16:18.120 --> 00:16:24.310
You don't need to subclass NSOpenGLPixelFormat,
or NSOpenGLContext.

00:16:24.309 --> 00:16:32.569
But if after trial and error you found out that perhaps
NSOpenGLView doesn't satisfy your requirement,

00:16:32.570 --> 00:16:40.550
you can directly subclass NSView, and then
you can use NSOpenGLPixelBuffer class,

00:16:40.549 --> 00:16:45.250
and NSOpenGL classes for doing full screen rendering.

00:16:45.250 --> 00:16:52.120
But if you're not by chance doing Cocoa
development, and you're using Carbon,

00:16:52.120 --> 00:16:57.879
and you're doing procedural programming, we have
actually three utility frameworks that will,

00:16:57.879 --> 00:17:00.740
two utility frameworks that will aid you in that workflow.

00:17:00.740 --> 00:17:08.349
One of them is of course is AGL is strictly for Carbon,
then there is CGL which is for both Carbon and Cocoa,

00:17:08.349 --> 00:17:12.730
and in fact this is the heart of NSOpenGL class and AGL.

00:17:12.730 --> 00:17:18.910
Both of them offer you full drawing to a window.

00:17:18.910 --> 00:17:22.820
And the advantage of course CGL is Windows system agnostic.

00:17:22.819 --> 00:17:25.129
We also ship with a version of GLUT,

00:17:25.130 --> 00:17:32.970
which is actually a native implementation
on our own platform.

00:17:32.970 --> 00:17:38.180
So basically we take actually quite a layered
up approach to design in all levels of our OS,

00:17:38.180 --> 00:17:41.410
this is just basically our implementation of OpenGL.

00:17:41.410 --> 00:17:49.110
We have the driver level, which actually has a software
rasterizer, the ATI rasterizer, and ATI driver, plug in,

00:17:49.109 --> 00:17:54.219
in video and in video rasterizer,
Intel rasterizer, and plug in.

00:17:54.220 --> 00:18:00.880
And a OpenGL engine actually comes in two varieties,
the multi-threaded and the non multi-threaded version.

00:18:00.880 --> 00:18:08.540
And you've we talked about the utility classes, and of
course once you set your pixel format, let's say using AGL

00:18:08.539 --> 00:18:18.779
or NSOpenGL or CGL, you'll be again
using OpenGL to do your, all your work.

00:18:18.779 --> 00:18:24.289
So as 2D 3D graphics application developers,
what are some of the common things that we use?

00:18:24.289 --> 00:18:27.869
Well we work a lot with textures.

00:18:27.869 --> 00:18:34.179
But before actually delving a little bit into how to
use textures with OpenGL, let's just look at couple

00:18:34.180 --> 00:18:39.830
of basic workflows in Direct3D 9
and Direct3D 10.

00:18:39.829 --> 00:18:43.699
So if you want to create an empty
texture in Direct3D 9,

00:18:43.700 --> 00:18:47.190
you just first declare a texture description structure.

00:18:47.190 --> 00:18:51.190
Then you allocate a structure,
and now you have an empty texture.

00:18:52.309 --> 00:18:59.000
With Direct3D 10, you know, the APIs are a little bit
different, so there's a little bit of different workflow.

00:18:59.000 --> 00:19:04.900
So first thing you do, you declare a 2D texture
description structure, different data structure,

00:19:04.900 --> 00:19:07.860
then you initialize the structure, and as many

00:19:07.859 --> 00:19:14.969
of you have done Direct3D 10
programming, you're familiar with this workflow.

00:19:14.970 --> 00:19:21.360
And then you set some texture parameters, use a create
textures 2D which you got off a device context.

00:19:21.359 --> 00:19:27.259
And at this case you know, you will
have an empty textures to work with.

00:19:27.259 --> 00:19:34.809
So with OpenGL, you first call, you
generate texture, and you get a texture ID.

00:19:34.809 --> 00:19:42.519
Then you bind the texture, and you tell them well I want
to texture rectangle ARB, and you pass it the texture ID,

00:19:42.519 --> 00:19:50.180
then you build the texture using the information
in a memory bucket, a void pointed in this case.

00:19:50.180 --> 00:19:56.960
And you just set some parameters, like its width
and height, and then you set the texture parameters.

00:19:56.960 --> 00:20:01.759
So one of the interesting thing here is you might
ask where do I get this memory bucket, this data?

00:20:01.759 --> 00:20:05.890
We'll talk about how to do this shortly.

00:20:05.890 --> 00:20:13.530
But before doing so, when I was actually generating
2D texture, I set some texture parameters.

00:20:13.529 --> 00:20:17.899
So these are the recommended texture
formats on our platform.

00:20:17.900 --> 00:20:23.530
Of course for those of you who are
coming from other varieties of OpenGL,

00:20:23.529 --> 00:20:28.549
namely from Windows or UNIX, all your formats are supported.

00:20:28.549 --> 00:20:35.299
But again, the optimal formats are up there.

00:20:35.299 --> 00:20:39.549
And if you're coming from other platforms
as I said, other formats are supported,

00:20:39.549 --> 00:20:44.359
but they may be swizzled by many of the cards that we ship.

00:20:44.359 --> 00:20:50.409
So, and then you saw that when I was binding a texture,
I was saying well I want a ARB texture rectangle.

00:20:50.410 --> 00:20:58.410
Well, this is actually a fast path on our platform, and
by using ARB texture rectangles, there are some tradeoffs.

00:20:58.410 --> 00:21:04.140
And the tradeoffs being that you can't use
mipmap filtering with ARB texture rectangles,

00:21:04.140 --> 00:21:08.470
when you're using ARB texture rectangles
your textures can't have borders,

00:21:08.470 --> 00:21:14.350
your textures be using not normal X texture
coordinates with ARB texture rectangles.

00:21:14.349 --> 00:21:16.889
And of course the only wrap modes they can be using

00:21:16.890 --> 00:21:21.960
with ARB texture rectangles are CLAMP,
CLAMP_TO_EDGE, and CLAMP_TO_BORDER.

00:21:21.960 --> 00:21:29.750
But for those of you that are in a world of video
processing, and for those of you who have gone to some

00:21:29.750 --> 00:21:35.059
of our session on digital video
processing using Core Video for example,

00:21:35.059 --> 00:21:41.619
there is good chance you probably will be
working with non-power-of-two textures.

00:21:41.619 --> 00:21:50.239
And this is actually prevailant theme in video
processing, but a note of caution here is with non-power-

00:21:50.240 --> 00:21:59.519
of-two texture is that certain hardware,
some texture wrap modes, they don't work.

00:21:59.519 --> 00:22:04.529
And certain hardware mipmapping may not work.

00:22:04.529 --> 00:22:10.700
And normally you, if you want to be using ARB texture
rectangle, you should check for this extension.

00:22:10.700 --> 00:22:16.420
And if one of the things that you're looking for,
it's not implemented in the hardware, then you know,

00:22:16.420 --> 00:22:20.090
you can just scale the image for
example, using gluScaleImage API,

00:22:20.089 --> 00:22:24.619
or you can segment the image into
a non-power-of-two rectangles.

00:22:26.069 --> 00:22:32.200
So let's talk about how you get
that memory bucket, that data.

00:22:32.200 --> 00:22:36.210
So here we have a framework called image I/O.

00:22:36.210 --> 00:22:42.500
So image I/O actually is a framework that allows you to
read and write platuro (assumed spelling) file formats,

00:22:42.500 --> 00:22:45.430
and allows you to also read and write metadata.

00:22:45.430 --> 00:22:51.910
It does automatic color management, and if you want to do
work with RAW camera formats, you want to be using image I/O.

00:22:51.910 --> 00:22:56.840
And it actually has incremental loading,
and it has a floating point support.

00:22:56.839 --> 00:23:02.569
So it supports all the web standards,
the HDR formats like OpenEXR,

00:23:02.569 --> 00:23:06.329
all the camera RAW formats for all
your variety of digital cameras.

00:23:06.329 --> 00:23:12.819
If you have file formats from Windows or UNIX,
supports many file formats from those platforms,

00:23:12.819 --> 00:23:18.569
supports a metadata file formats, and as more
and more file data are becoming available,

00:23:18.569 --> 00:23:24.589
the image I/O team will bringing that
also to you under the hood of image I/O.

00:23:24.589 --> 00:23:28.109
So where does actually image I/O
lie in a greater scheme of things?

00:23:28.109 --> 00:23:34.990
Well our team of engineers actually have taken
libTiff, libJpeg, and libPng that many of you

00:23:34.990 --> 00:23:40.950
from UNIX are familiar with, and they have actually
optimized them, and they gave you this image I/O framework

00:23:40.950 --> 00:23:43.680
to actually take advantage of those libraries.

00:23:43.680 --> 00:23:50.830
And you can see some for other technologies, like Quartz,
Image Kit, and Core Image leverage off of image I/O.

00:23:51.930 --> 00:23:55.930
So let's look at how you can actually read a file.

00:23:55.930 --> 00:24:00.400
So the first thing that you do is
you start with the file path, okay?

00:24:00.400 --> 00:24:03.910
So you want to covert that to a URL.

00:24:03.910 --> 00:24:09.860
The next thing you want to do is you want to create
an image from the URL, now that you have a URL.

00:24:09.859 --> 00:24:15.559
So the first thing is you actually create a image source,

00:24:15.559 --> 00:24:19.470
which is a image source reference,
which is an opaque data structure, okay?

00:24:19.470 --> 00:24:24.519
Now your image, that file might have more than
one image, so you, what you want to do is you want

00:24:24.519 --> 00:24:29.619
to say well let's say I want to get
the image at index zero, or index one.

00:24:29.619 --> 00:24:32.549
So now you have another data structure called ImageRef.

00:24:32.549 --> 00:24:38.500
And from ImageRef, what you want to do is just
you want to get some of its attribute, for example,

00:24:38.500 --> 00:24:44.829
its width and height, and of course
you want to get device's color space.

00:24:45.950 --> 00:24:50.730
So now next step is you create a bitmap context.

00:24:50.730 --> 00:24:52.579
That's where you get the data from.

00:24:52.579 --> 00:24:54.609
But we're not quite done yet.

00:24:54.609 --> 00:25:03.209
Because we want to call ContextDrawImage
API to actually fill that memory bucket.

00:25:03.210 --> 00:25:09.420
Now you're almost done, because you note that
a lot of the APIs here have create in them.

00:25:09.420 --> 00:25:13.500
That means you'll be holding the memory,
you'll be controlling that memory.

00:25:13.500 --> 00:25:23.769
So what you need to do in order to avoid memory leaks, you
want to actually release all those extra references, okay?

00:25:23.769 --> 00:25:29.799
So now we know how to read data into a texture.

00:25:29.799 --> 00:25:34.629
So what's the other things that's common to all the
2D 3D graphics programmers actually working

00:25:34.630 --> 00:25:36.440
with vertex arrays.

00:25:36.440 --> 00:25:39.210
So let's talk about vertex buffer objects.

00:25:39.210 --> 00:25:48.950
So in general, vertex arrays actually exist on clients'
side of things, and your graphics card wants to access

00:25:48.950 --> 00:25:54.620
that vertex array, it actually has to go across
a bus and fetch those vertex arrays for you.

00:25:54.619 --> 00:26:00.959
Of course, because of the limited
bandwidth of a bus, there'll be a slowdown.

00:26:00.960 --> 00:26:04.019
So that's where vertex buffer objects come in handy.

00:26:04.019 --> 00:26:17.559
So in case of vertex buffer object, OpenGL actually caches
the vertex arrays on GPU, and allows, you'll be kind of,

00:26:17.559 --> 00:26:22.879
you don't, no longer actually need to worry
about that limited bandwidth going across a bus.

00:26:22.880 --> 00:26:30.840
And when the OpenGL caches a vertex array into
VRAM, your buffer objects will be resident on a VRAM,

00:26:30.839 --> 00:26:37.669
and your vertex processor can actually take advantage
of that fat pipe that exists on your graphics card.

00:26:37.670 --> 00:26:44.080
And of course once you start using vertex buffer object,
what you need to be doing is go through your code

00:26:44.079 --> 00:26:50.539
and look at where you're using display lists and vertex
arrays, where you're you know, applying your techniques

00:26:50.539 --> 00:26:56.930
that you learned long ago, you know, using immediate
mode graphics, and adopt a vertex buffer object.

00:26:56.930 --> 00:26:59.460
So let's see how we do this in Direct3D 9.

00:26:59.460 --> 00:27:08.759
So first we define a buffer and vertex data, then you
create a vertex buffer object, and then you need to actually

00:27:08.759 --> 00:27:17.240
at this stage set out the layout so the pipeline
knows what kind of data is coming to the pipeline.

00:27:17.240 --> 00:27:20.960
But we're not done yet with Direct3D 9.

00:27:20.960 --> 00:27:29.569
So the next thing that you need to do is you configure
the vertex and buffer layout, then you're ready to draw.

00:27:29.569 --> 00:27:37.720
With Direct3D 10, as you know, it
normally involves initializing multiple stages

00:27:37.720 --> 00:27:43.450
of your Direct3D pipeline, and= you always do that
with Direct3D 10 by initializing some data structure.

00:27:43.450 --> 00:27:47.650
So let's first start here by defining
a buffer and vertex data.

00:27:47.650 --> 00:27:55.390
Then you initialize a buffer description object,
then you initialize a subresource structure,

00:27:55.390 --> 00:28:04.390
you create a vertex buffer object, then you
basically have to configure input assembler stage,

00:28:04.390 --> 00:28:10.610
and then you configure a data topology in the
input assembler stage, and then you're ready to draw.

00:28:10.609 --> 00:28:13.789
I'm sure as many of you have, who have
been working with Direct3D 10,

00:28:13.789 --> 00:28:20.230
it most of the time involves a lot
more coding than Direct3D 9.

00:28:20.230 --> 00:28:23.410
In OpenGL you first define a buffer.

00:28:23.410 --> 00:28:31.370
You then, you create a buffer, then
you modify the memory in the buffer

00:28:31.369 --> 00:28:36.269
by first mapping from buffer object into client memory.

00:28:36.269 --> 00:28:42.250
And then once you're done modifying that
vertex buffer object data, you let go of it.

00:28:42.250 --> 00:28:44.950
And then you're ready to draw.

00:28:44.950 --> 00:28:53.720
One thing I want you to remember is that the buffer offset
macro that we're going to be using throughout this session.

00:28:53.720 --> 00:28:57.839
So that's vertex buffer objects.

00:28:57.839 --> 00:29:03.079
So here the theme was again, optimization
technique, a fast path.

00:29:03.079 --> 00:29:10.199
But a concept that's actually closely tied to
vertex buffer object is actually flush buffer range.

00:29:10.200 --> 00:29:13.769
So let's talk about what flush buffer range is.

00:29:13.769 --> 00:29:18.730
So basically OpenGL commands in first in first out fashion.

00:29:18.730 --> 00:29:26.440
And buffer objects usually block the data, until
the data is processed through the OpenGL pipeline.

00:29:26.440 --> 00:29:31.870
And in order to avoid this blockage,
GL usually creates extra copies.

00:29:31.869 --> 00:29:39.429
So for partial flushing of vertex buffer objects, you
want to be using APPLE_flush_buffer_range extension.

00:29:39.430 --> 00:29:44.960
So of course inherent advantages are
that the theme is asynchronicity,

00:29:44.960 --> 00:29:50.329
and also if you want to minimize the data having to get
copied back and forth, you want to be using this extension.

00:29:50.329 --> 00:29:55.389
And of course as application developers, you
know your application better than anybody else.

00:29:55.390 --> 00:30:01.550
So you can manage this synchronization point using
fences, and then you can modify the ranges of the data

00:30:01.549 --> 00:30:04.759
that you know, your buffer object contains.

00:30:04.759 --> 00:30:11.119
And while all this magic is going on, OpenGL
might be just using part of a buffer object.

00:30:11.119 --> 00:30:22.039
So here the first step is of course you switch off flushing
on GL on map buffer, you modify the memory in the buffer,

00:30:22.039 --> 00:30:29.259
you modify the vertex buffer object, and
here you explicitly flush the modified bytes.

00:30:29.259 --> 00:30:37.470
So this is flush buffer range, and
again, the theme is optimization, fast path.

00:30:37.470 --> 00:30:40.500
So the next thing, we create an empty texture.

00:30:40.500 --> 00:30:45.710
But really, creating an empty texture and setting some
parameters on them is just kind of not terribly interesting.

00:30:45.710 --> 00:30:48.900
You won't always be able to do something with textures.

00:30:48.900 --> 00:30:51.700
So let's talk about render to texture.

00:30:53.059 --> 00:30:58.419
So one of the applications of render to
texture, and it's really a tightly coupling

00:30:58.420 --> 00:31:00.690
with this concept of multipass rendering.

00:31:00.690 --> 00:31:06.440
So for those of you who come from CG world,
you've probably seen multi pass rendering.

00:31:06.440 --> 00:31:11.940
And for those of you who don't know what multipass
rendering is, it basically involves,

00:31:11.940 --> 00:31:15.430
you have separate images, and you
want to render these separate images

00:31:15.430 --> 00:31:17.960
for different attributes that comprise a scene.

00:31:17.960 --> 00:31:25.250
And then these images, you want to take them, and
then load them into some image processing app,

00:31:25.250 --> 00:31:28.950
and then filter them together to create a final image.

00:31:28.950 --> 00:31:36.789
So in reality what you're doing, you're really
breaking up this complicated workflow into actually,

00:31:36.789 --> 00:31:42.769
to really a discrete number of steps,
and into multiple rendering passes.

00:31:42.769 --> 00:31:48.710
And then what you can do is you can combine these
passes into the framebuffer using blending,

00:31:48.710 --> 00:31:56.759
and then you can use these multiple passes to sort textures
that you'll be using in all your future rendering passes.

00:31:56.759 --> 00:32:06.750
And of course on our platform, OpenGL
implementations, this idea is basically realized

00:32:06.750 --> 00:32:10.000
through the use of framebuffer objects, or FBOs.

00:32:10.000 --> 00:32:18.430
So basically again, it's being on a fast path, optimization
technique, it really doesn't require you flushing

00:32:18.430 --> 00:32:22.610
to synchronize pixel buffer object, which
we'll talk about a little bit later,

00:32:22.609 --> 00:32:27.379
and vertex buffer object can use the
rendering results in your vertex arrays.

00:32:27.380 --> 00:32:31.280
And this is actually modern replacement also for pbuffers.

00:32:31.279 --> 00:32:33.619
Why use these FBOs instead of pbuffers?

00:32:33.619 --> 00:32:40.519
Because you know, number one pbuffers will be a you
know, a required additional OpenGL context, FBOs don't,

00:32:40.519 --> 00:32:45.049
and actually switching between frame
buffers is actually faster than pbuffers.

00:32:45.049 --> 00:32:51.149
And of course you get a low memory footprint, you
get some savings here because your render buffer

00:32:51.150 --> 00:32:55.030
and texture images can now be shared
amongst your various framebuffers.

00:32:55.029 --> 00:32:59.410
So at a high level, what's the idea?

00:32:59.410 --> 00:33:04.769
Well the idea is let's say, many of you
have seen this now famous Stamford bunny.

00:33:04.769 --> 00:33:10.579
So you have this geometry and some
texture, and you want to render this in FBO,

00:33:10.579 --> 00:33:14.849
and this result will reside, will be resident in an FBO.

00:33:14.849 --> 00:33:19.169
And then you take that result that you have in an FBO,

00:33:19.170 --> 00:33:23.490
and you have some arbitrary geometry,
and you do render everything normally.

00:33:23.490 --> 00:33:31.190
And then you have, in this case
you have a bunny on a teapot.

00:33:31.190 --> 00:33:36.330
So in Direct3D 9 how do
you do this with render to texture?

00:33:36.329 --> 00:33:40.980
Well first thing we have seen how
to create a render target texture,

00:33:40.980 --> 00:33:46.990
and then we declare a structure describing
a region that's, we want to be locked.

00:33:46.990 --> 00:33:51.650
And then we load the data into a
texture, then we start manipulating

00:33:51.650 --> 00:33:55.720
that memory bucket, and then we let go of the texture.

00:33:55.720 --> 00:34:05.370
With Direct3D 10, we create a render target
texture, we already seen how to do that again.

00:34:05.369 --> 00:34:14.230
And we then create a render target views, because we want to
describe to the pipeline how to access our target texture.

00:34:14.230 --> 00:34:20.869
And then we create a shade of resource views so the
render target can be bound to the pipeline as input.

00:34:20.869 --> 00:34:25.539
And this is again a recurring theme for all you
people who've been using Direct3D 10.

00:34:25.539 --> 00:34:29.409
Because at one stage or another that's what
you'll be doing, initializing some structure,

00:34:29.409 --> 00:34:34.369
and binding it to one stage or another in your pipeline.

00:34:34.369 --> 00:34:43.469
With OpenGL, well you first start defining
a framebuffer, then you bind framebuffer.

00:34:43.469 --> 00:34:49.949
Well you attach a texture to a framebuffer, we already seen
how to, basically we know where this texture ID comes from.

00:34:49.949 --> 00:34:58.519
And then you do a test, you make sure that a frame
buffer is valid, and then you draw to the texture.

00:34:58.519 --> 00:35:07.679
You rebind the default, to default framebuffer, and then
you use a, using a texture ID, that texture ID that we got,

00:35:07.679 --> 00:35:09.230
you use it as a source for your rendering.

00:35:09.230 --> 00:35:16.969
So let's now talk about, a little
bit about pixel buffer objects.

00:35:16.969 --> 00:35:25.559
Now pixel buffer objects, there's really no analogous
idea with Direct3D 9 or Direct3D 10.

00:35:25.559 --> 00:35:34.539
So in order to talk about pixel buffer object, you
really need to see how pixel buffer objects are used.

00:35:34.539 --> 00:35:41.190
So, basic idea of pixel buffer object's main
application is if you want to do fast copies

00:35:41.190 --> 00:35:44.440
of pixel data between various buffer objects.

00:35:44.440 --> 00:35:52.230
And some of its main application of pixel buffer objects
is streaming texture updates, stream draw pixels,

00:35:52.230 --> 00:35:56.019
asynchronous read pixels, and render-to-vertex array.

00:35:56.019 --> 00:35:59.179
Let's examine each of them just briefly.

00:35:59.179 --> 00:36:04.989
So let's look at why pixel buffer objects are ideal
candidate when you're doing the streaming texture objects.

00:36:04.989 --> 00:36:16.169
So if your applications are using the glMapBuffer and
glUnmapBuffer combination, and you're using the data

00:36:16.170 --> 00:36:28.980
for texture sub image, and you're writing that into a
buffer object, you want to eliminate an extra texture

00:36:28.980 --> 00:36:32.070
that is created during the download process.

00:36:32.070 --> 00:36:37.390
So by doing so, by using pixel buffer objects,
you'll be significantly increasing your performance.

00:36:37.389 --> 00:36:40.969
Again, that's same here being performance.

00:36:40.969 --> 00:36:50.579
For streaming draw pixels, well when you issue a glDrawPixel,
glDrawPixel sources a client memory.

00:36:50.579 --> 00:36:56.569
So client memory then can be modified
right after glDrawPixel command returns,

00:36:56.570 --> 00:36:59.400
because you don't want to disturb
the image that you're drawing into.

00:36:59.400 --> 00:37:08.240
And this basically necessitates basically unpacking and
copying the image prior to glDrawPixel call returning.

00:37:08.239 --> 00:37:19.989
So by using a PBO in conjunction with glDrawPixels, with
pixel pack buffer object, your image will return prior

00:37:19.989 --> 00:37:24.979
to unpacking, again an optimization technique.

00:37:24.980 --> 00:37:27.119
Asynchronous glReadPixels.

00:37:27.119 --> 00:37:32.329
So in this case your application, let's say your
application needs to read back a number of images,

00:37:32.329 --> 00:37:36.219
and process each of those images on a CPU.

00:37:36.219 --> 00:37:43.559
So this, because of the architects, general architecture
OpenGL, this is really difficult to pipeline.

00:37:43.559 --> 00:37:49.599
So what you, what will typically happen is driver
typically usually sends a hardware, a ReadPixel,

00:37:49.599 --> 00:37:57.000
and then it will wait for all this data to be available
before returning the control to your application.

00:37:57.000 --> 00:38:05.340
And your application at this stage can also issue another
glReadPixel, or they can process the data immediately.

00:38:05.340 --> 00:38:10.130
And in neither of these cases there
will be a lack of parallelism,

00:38:10.130 --> 00:38:13.530
and read backs will basically,
will overlap with the process.

00:38:13.530 --> 00:38:20.970
So here again using pixel buffer objects with GLReadPixel,
your application can issue multiple read backs

00:38:20.969 --> 00:38:29.169
into multiple buffer objects, and map each one of
the processes on that, and you'll introduce a measure

00:38:29.170 --> 00:38:32.440
of optimization parallelism into your application.

00:38:32.440 --> 00:38:36.139
And last but not least, render-to-vertex array.

00:38:36.139 --> 00:38:40.369
So here you have your application
that is going to be using a fragment program

00:38:40.369 --> 00:38:43.440
to render some image into one of its buffers.

00:38:43.440 --> 00:38:47.920
And then you want to read this image into
a buffer object using your ReadPixels,

00:38:47.920 --> 00:38:52.039
and then use this buffer object
as a source of your vertex data.

00:38:52.039 --> 00:38:56.489
So let's see, we'll just concentrate
only on a couple of these things.

00:38:56.489 --> 00:38:58.659
Let's first look at render-to-vertex array.

00:38:58.659 --> 00:39:05.809
So first let's create a buffer object,
our usual for a few of our vertices.

00:39:05.809 --> 00:39:11.940
And then let's render the vertex data into
a framebuffer using a fragment program.

00:39:11.940 --> 00:39:25.530
And then we going to read the vertex data back from the
framebuffer, and we'll bind the vertex, or a binding point.

00:39:25.530 --> 00:39:30.860
And then we draw, so we're done with that.

00:39:30.860 --> 00:39:34.220
So let's talk about asynchronous read pixels.

00:39:34.219 --> 00:39:40.679
The first thing you want to do, you want to create and bind
a pixel buffer object as a destination for reading pixels.

00:39:40.679 --> 00:39:49.079
Then you render to framebuffer, you bind a pixel buffer
object, and store the read back pixels asynchronously.

00:39:49.079 --> 00:39:59.380
Now here the glReadPixel call will return
after DMA transfer, then you process the image.

00:39:59.380 --> 00:40:05.740
And of course here we'll call the glMapBuffer,
and we get a memory bucket back.

00:40:05.739 --> 00:40:09.209
And then you unmap the image buffer.

00:40:09.210 --> 00:40:16.420
So we've talked about some optimization techniques here.

00:40:16.420 --> 00:40:28.590
Now in order for us to further optimize our code,
and basically introduce some stunning visual effects

00:40:28.590 --> 00:40:34.920
into our application, into our digital
content, let's talk about using shaders.

00:40:38.889 --> 00:40:41.480
So why use shaders?

00:40:41.480 --> 00:40:48.309
So for many years graphic pipelines
operated using a fixed-function pipeline.

00:40:48.309 --> 00:40:56.759
And this introduced a certain level
of determinism in each stage.

00:40:56.760 --> 00:41:03.690
And, but unfortunately with having this kind of
deterministic behavior, you had really little control

00:41:03.690 --> 00:41:07.610
over how geometry was rendered or processed.

00:41:07.610 --> 00:41:10.539
But like anything else, graphics hardwares evolved.

00:41:10.539 --> 00:41:17.500
And you know, most developers required
a higher level of flexibility.

00:41:17.500 --> 00:41:27.210
And initially this problem was solved by introducing
extensions, and extensions kind of took away that element

00:41:27.210 --> 00:41:32.079
of determinism, by just a tiny bit of a degree.

00:41:32.079 --> 00:41:36.690
So, but graphics vendors, because
it was such a competitive market,

00:41:36.690 --> 00:41:41.990
they wanted to actually introduce changes
later in their hardware development cycle.

00:41:41.989 --> 00:41:46.129
So they introduced this concept of microcode programs.

00:41:46.130 --> 00:41:52.420
And as soon as developers heard about this, they
wanted to actually utilize this functionality.

00:41:52.420 --> 00:41:57.970
So this initially, this kind of flexibility
made its appearance in DirectX 8,

00:41:57.969 --> 00:42:02.639
and little bit later in, it became available in OpenGL.

00:42:02.639 --> 00:42:07.799
So shaders then basically changed the entire landscape.

00:42:07.800 --> 00:42:15.070
And first version of the shaders were basically low level
shaders, in case of OpenGL the concept really converged

00:42:15.070 --> 00:42:20.240
under our vertex programs, our fragment programs.

00:42:20.239 --> 00:42:28.169
But later on, as again the shared languages evolved,
the high level shaders made their appearance,

00:42:28.170 --> 00:42:36.010
and they made their appearance in the shader
program languages, Cg, HLSL, and GLSL.

00:42:36.010 --> 00:42:43.240
So let's look at how actually we do these
things, we use shaders in Direct3D 9.

00:42:43.239 --> 00:42:49.029
So let's assume that we already written your
shader in HLSL, you already have that going.

00:42:49.030 --> 00:42:53.340
So first thing you want to do, you want to compile a shader.

00:42:53.340 --> 00:43:01.230
And then you create a vertex shader, and
you pretty much, well you're almost done.

00:43:01.230 --> 00:43:08.530
So then you set some parameters for your vertex shader
in your device, you initialize some shader constant,

00:43:08.530 --> 00:43:12.769
it could be a, your float constant, your
integer constant, or your bool constants.

00:43:12.769 --> 00:43:16.539
And then you tell the device where
the input data's coming from.

00:43:16.539 --> 00:43:22.570
And you basically repeat this process for
your pixel shaders under Direct3D 9.

00:43:22.570 --> 00:43:30.470
With Direct3D 10 shaders, the landscape has changed,
because versus when you have access to low level shaders

00:43:30.469 --> 00:43:35.679
and high level shaders with
Direct 3D 9 and HLSL 3,

00:43:35.679 --> 00:43:38.480
with Direct3D 10 you no longer have that luxury.

00:43:38.480 --> 00:43:43.119
You can only target Shader Model 4.

00:43:43.119 --> 00:43:50.019
But of course the offline compilation of
shaders is in a bytecode format still supported.

00:43:50.019 --> 00:43:55.750
And of course the stages for Direct
3D 10 are you compile a shader,

00:43:55.750 --> 00:43:59.079
you create a shader object, and you set the shader object.

00:43:59.079 --> 00:44:05.500
And basically you repeat this process for your
pixel shader, but you also here have you know,

00:44:05.500 --> 00:44:12.070
you do this also for your vertex shader, but
here you also have the geometry shaders as well.

00:44:12.070 --> 00:44:13.000
So how do you do this?

00:44:13.000 --> 00:44:17.829
Well you do, let's say that you've written
your HLSL for shader, and then you,

00:44:17.829 --> 00:44:20.880
first thing you want to do, you want to compile your shader.

00:44:20.880 --> 00:44:27.680
Then once the shader is compiled, you want to create a
shader object, then you want to set the shader object.

00:44:27.679 --> 00:44:36.129
By now you should have a ID3D10Device
interface, you have instantiated that, and you want to,

00:44:36.130 --> 00:44:39.210
once you have the shader object,
you want to just pass it here.

00:44:39.210 --> 00:44:47.179
And you're ready to use your shader object, and
it's right now bound to a stage in your pipeline.

00:44:47.179 --> 00:44:51.469
With OpenGL shaders there are really
three things that we need to talk about.

00:44:51.469 --> 00:44:56.239
Let's talk about first the vertex
shaders, and what vertex shaders are.

00:44:56.239 --> 00:45:03.339
So vertex shader is bound to the
vertex processor stage of the pipeline.

00:45:03.340 --> 00:45:09.789
What you can perform in the vertex shader is you
can do vertex position transform using model view

00:45:09.789 --> 00:45:17.219
and projection matrices, normal transformation, and if
you needed normalization, texture coordinate generation

00:45:17.219 --> 00:45:23.299
and transformation, lighting vertex or
computing values for lighting per pixel.

00:45:23.300 --> 00:45:26.380
You can do color computation, or you can do vertex.

00:45:26.380 --> 00:45:32.110
And the thing that I want to impress
on you here, that remember that in case

00:45:32.110 --> 00:45:36.019
of a vertex shader you'll be working on per vertex basis.

00:45:36.019 --> 00:45:42.050
And you definitely have here in this case, if
you remember the OpenGL pipeline architecture,

00:45:42.050 --> 00:45:44.650
you have no access to the framebuffer.

00:45:44.650 --> 00:45:45.880
So how do you do this?

00:45:45.880 --> 00:45:54.019
Well you create a vertex shader object first of all, and
now that you have a vertex shader object, you have a source,

00:45:54.019 --> 00:45:57.360
which could be a CString or a text file.

00:45:57.360 --> 00:46:01.950
And then you compile the vertex shader.

00:46:01.949 --> 00:46:04.899
The next thing we want to talk about is a fragment shaders.

00:46:04.900 --> 00:46:11.099
So fragment shaders are bound to the fragment
processor stage of the OpenGL pipeline.

00:46:11.099 --> 00:46:20.039
They can perform some functionality, and those
functionality being if you're working with computing colors

00:46:20.039 --> 00:46:24.980
and texture coordinates per pixel, if you
do texture applications for computation

00:46:24.980 --> 00:46:28.579
or you're computing normals for lighting per pixels.

00:46:28.579 --> 00:46:34.539
And fragment shaders has access to your OpenGL state,
and they can't change pixel coordinates.

00:46:34.539 --> 00:46:39.409
And of course in this case, again fragment
shader has no access to the framebuffer.

00:46:39.409 --> 00:46:45.440
The workflow is similar for creating a vertex
shader, so you first create a fragment shader object.

00:46:45.440 --> 00:46:53.809
Again, you have a fragment shader object, you have a
fragment shader source that comes from your C file, sorry,

00:46:53.809 --> 00:47:00.420
comes from your CString, or a text file, and
then you compile your fragment shader, okay?

00:47:00.420 --> 00:47:05.119
So let's say you've successfully compiled
your fragment shader and a vertex shader.

00:47:05.119 --> 00:47:11.409
Then you want to bind these to a program object, okay?

00:47:11.409 --> 00:47:18.299
So let's first create a program object, then you first
attach your vertex shader to your program object,

00:47:18.300 --> 00:47:23.820
then you attach your fragment shader to a program object.

00:47:23.820 --> 00:47:29.760
And here you link your program object, and if
you've successfully linked your program object,

00:47:29.760 --> 00:47:35.370
now it's time for you to use your program
object, and apply it to your various geometries.

00:47:35.369 --> 00:47:39.109
So in review, what did we do?

00:47:39.110 --> 00:47:45.559
Well we first created a vertex shader,
then we created a fragment shader.

00:47:45.559 --> 00:47:53.320
And if we were successful in those stages, we attached it
to a program object, and then we linked the program object

00:47:53.320 --> 00:47:57.440
when we were ready to use the program object.

00:47:57.440 --> 00:48:06.889
So of course each of these things, if you're coming
from Direct3D 9 or 10, and an OpenGL site,

00:48:06.889 --> 00:48:13.799
they need your shaders, and your shaders are basically
authored in the high level languages like HLSL or GLSL.

00:48:13.800 --> 00:48:23.850
But instead of going through you know, a detailed
dissertation on what are the various things that you need

00:48:23.849 --> 00:48:30.750
to do to go from HLSL to GLSL, let's
just talk about some common themes.

00:48:31.829 --> 00:48:37.170
So to that end we just going to concentrate
on some simple data structures

00:48:37.170 --> 00:48:42.090
that you probably will run into in both HLSL and GLSL.

00:48:42.090 --> 00:48:45.620
Here I'm going to concentrate on HLSL shader language four.

00:48:45.619 --> 00:48:47.440
So what are some of the common data types?

00:48:47.440 --> 00:48:52.170
Well you have, you can have a bool, a float, int or double.

00:48:52.170 --> 00:48:55.329
And this, these can be, in this case they're vectors.

00:48:55.329 --> 00:49:02.480
They can have one component, in which case you're
talking about scalers, or up to four components.

00:49:02.480 --> 00:49:08.460
But in HLSL shader language four you
can also use the SDL style notation.

00:49:10.090 --> 00:49:17.559
And vectors, you can access their members
using either position set or a color set.

00:49:17.559 --> 00:49:25.659
But you know, as usual, you know, you just can't
mix and match the color set or position set.

00:49:27.090 --> 00:49:30.940
And with HLSL you also have matrices.

00:49:30.940 --> 00:49:37.099
They can have, they could be one by one
matrix, which is not terrible interesting,

00:49:37.099 --> 00:49:41.380
up to four by four, and they can be int, float, or double.

00:49:41.380 --> 00:49:47.650
But you can also use again, SDL style notation
to actually instantiate a matrix object.

00:49:47.650 --> 00:49:56.579
You can access their, members of a matrix using a zero
base column position, or a one base row column position.

00:49:56.579 --> 00:50:05.250
And a matrix element can be accessed using array
notation, and I have some examples down there for you

00:50:05.250 --> 00:50:14.309
where I have a two by two float matrix, and I have a
vector V, which is this case is a one vector, or a scaler.

00:50:14.309 --> 00:50:18.380
And I have a float too, which is, has two elements.

00:50:18.380 --> 00:50:26.720
And then I'm just copying from my matrix, two by
two matrix, into my scaler, or in my two vector.

00:50:26.719 --> 00:50:36.329
So in GLSL again, the simple data types, the
scaler types are float, bool, and integers.

00:50:36.329 --> 00:50:48.090
And we have texture sampling types, which are sampler
{1,2,3}D, or samplerCube. And just like C,

00:50:48.090 --> 00:50:55.530
you can initialize variables when you declare them,
so here I have a float, I have two scalers A and B,

00:50:55.530 --> 00:51:02.890
and I have an integer, I'm assigning a value two
to it, and a bool that I'm assigning a value true.

00:51:02.889 --> 00:51:11.129
And GLSL again, heavily relies on using
constructor for initializing and its type casting.

00:51:11.130 --> 00:51:18.710
Here I have an integer, a scaler, and then I have a
float and I want to convert that integer to a float.

00:51:18.710 --> 00:51:24.300
So I can use constructor to do that.

00:51:24.300 --> 00:51:31.530
So here vectors are also available, so we have
a two vector, a three vector, and a four vector.

00:51:31.530 --> 00:51:37.310
In the first case there are floats, and
then B vectors are of course your booleans,

00:51:37.309 --> 00:51:39.389
and I vectors are just basically integers.

00:51:39.389 --> 00:51:44.109
They can have up to two, or from two to four elements.

00:51:44.110 --> 00:51:52.490
And you can use constructors for vectors,
and here let's look at some simple examples.

00:51:52.489 --> 00:51:59.169
Let's start with a declaration called U which is
a two vector, and V which is also a two vector.

00:51:59.170 --> 00:52:06.590
And here I want to just copy that using
my constructor into a four vector.

00:52:06.590 --> 00:52:11.570
And again, you can use the, mix and
match that with the scaler types as well.

00:52:13.170 --> 00:52:19.639
And accessing the members is again, very similar to HLSL.

00:52:19.639 --> 00:52:29.000
But here we have both the position, if you want to use
access, the individual members of a vector, you can use,

00:52:29.000 --> 00:52:34.869
we have texture coordinates available,
as well as color coordinates.

00:52:34.869 --> 00:52:43.849
And in GLSL you know, arrays can be declared just
using identical notation as in C. We have matrices,

00:52:43.849 --> 00:52:47.559
there's two matrix, three matrix, or four matrix.

00:52:47.559 --> 00:52:49.889
Again, you can use constructors here as well.

00:52:49.889 --> 00:52:55.859
Here on the second example I have
a two vector U, and a two vector V,

00:52:55.860 --> 00:53:02.809
and then I'm using a constructor to
just construct a four by four matrix.

00:53:02.809 --> 00:53:08.250
And you can actually specify all the
elements of a four by four matrix.

00:53:08.250 --> 00:53:16.579
And then you can use your basically row and column
selectors to select individual members of a matrix.

00:53:16.579 --> 00:53:29.360
And structures are very similar to C, and you can
actually use constructors against, with structures here.

00:53:29.360 --> 00:53:37.340
And you can access elements of your structure,
members of your structures using the dot notation

00:53:37.340 --> 00:53:44.990
like you would normally in C. And
you have qualifiers like const,

00:53:44.989 --> 00:53:50.500
attributes which are global variables
that may change per vertex.

00:53:50.500 --> 00:53:55.730
And they're actually passed from your OpenGL
application to your vertex shaders,

00:53:55.730 --> 00:53:58.829
and they are really only variables for vertex shaders.

00:53:58.829 --> 00:54:04.309
You have uniforms, which are basically your global
variables that may change per primitive,

00:54:04.309 --> 00:54:10.590
and they're passed from your application to the shaders,
and they can be used by both vertex and fragment shaders.

00:54:10.590 --> 00:54:14.170
And again, this is a read-only variable,
and there's also varying qualifier,

00:54:14.170 --> 00:54:19.730
which is used for interpolating data
between vertex and fragment shaders.

00:54:19.730 --> 00:54:26.230
So I'm not, I'm not you know, not talking about the
four loops, Y loops, if then elses, because you know,

00:54:26.230 --> 00:54:33.699
if then elses in HLSL all if then elses
on GLSL same with your loop constructs.

00:54:33.699 --> 00:54:40.239
So at this stage I want to bring Michael
Jurewitz one more time to the stage,

00:54:40.239 --> 00:54:44.129
and he's going to go through with you on a second demo.

00:54:44.130 --> 00:54:44.559
Michael?

00:54:44.559 --> 00:54:45.599
>> All right.

00:54:45.599 --> 00:54:48.019
>> Demo machine please.

00:54:48.019 --> 00:54:48.909
>> Thank you Babak.

00:54:48.909 --> 00:54:54.409
All right, we're going to go ahead and take a look
at our GLSL basics project here, open that up.

00:54:54.409 --> 00:54:59.019
I want to go ahead and build and run that for
you so we can take a look at what's going on.

00:54:59.019 --> 00:55:03.590
You can see, we've got a simple OpenGL view here.

00:55:03.590 --> 00:55:06.370
We're actually at this point now responding to mouse events.

00:55:06.369 --> 00:55:10.460
So here I'm actually dragging the mouse back
and forth, and I can reorient the drawing.

00:55:10.460 --> 00:55:15.449
I can also go ahead and scale this in and out.

00:55:15.449 --> 00:55:19.309
So let's go ahead and dive into the
code, and take a look at what's going on.

00:55:19.309 --> 00:55:22.909
So we'll go ahead and take a look
at our header, just like before.

00:55:22.909 --> 00:55:28.509
And again, you'll see we're a simple NSOpenGLView
subclass, just GLSL basics view.

00:55:28.510 --> 00:55:30.900
And we set up some basic state for our drawing.

00:55:30.900 --> 00:55:35.110
We haven't defined any custom methods here,
we're keeping things very, very simple.

00:55:35.110 --> 00:55:38.090
So let's go ahead and take a look at the implementation.

00:55:38.090 --> 00:55:41.450
So the first thing we want to take
a look at is initWithFrame.

00:55:41.449 --> 00:55:47.989
So for any NSView subclass after they are
instantiated by the nib at nib load time,

00:55:47.989 --> 00:55:50.879
they're sent the message initWithFrame.

00:55:50.880 --> 00:55:55.360
So this is the designated initializer for NSViews.

00:55:55.360 --> 00:55:59.250
Now NSOpenGLView gets a little more
specific, and so we actually have init

00:55:59.250 --> 00:56:02.489
WithFrame pixel format that we end up calling.

00:56:02.489 --> 00:56:06.639
This is a designated initializer for NSOpenGLView.

00:56:06.639 --> 00:56:09.949
So in object oriented programming, a
designated initializer is this idea

00:56:09.949 --> 00:56:15.349
that you can have multiple initializers that'll take
different parameters, or different numbers of parameters,

00:56:15.349 --> 00:56:19.119
but that you really only want to have one
that's doing the work for proper encapsulation,

00:56:19.119 --> 00:56:22.159
and to make sure that you have
one entry point for your class.

00:56:22.159 --> 00:56:25.179
So in this case we use initWithFrame pixelFormat.

00:56:25.179 --> 00:56:29.909
So let's go ahead and just scroll up here, and we'll
take a look at what's actually happening in this method.

00:56:29.909 --> 00:56:32.739
So in initWithFrame pixelFormat we simply
want to make sure that we're actually,

00:56:32.739 --> 00:56:39.409
that we get in a valid pixel format, and if we
don't, we're going to go ahead and set up our own.

00:56:39.409 --> 00:56:43.769
Now as with any object initialization
in Cocoa, the first thing we want

00:56:43.769 --> 00:56:47.690
to do is give our super class a chance to set up its state.

00:56:47.690 --> 00:56:53.530
So you'll see we have this statement here,
which is super initWithFrame pixelFormat,

00:56:53.530 --> 00:56:56.700
and we simply assign that back
to self with our own instance.

00:56:56.699 --> 00:56:59.579
In this case we've wrapped it in an if
statement, because we want to make sure

00:56:59.579 --> 00:57:03.289
that we actually are getting back
a valid object, and not nil.

00:57:03.289 --> 00:57:08.170
So we go ahead first, and we set up
some basic OpenGL state for ourselves.

00:57:08.170 --> 00:57:15.369
We're going to load our shaders in, we're also going to be at that
point setting up our frame size, and also setting up a timer

00:57:15.369 --> 00:57:18.039
for doing the animation that we're
actually doing to the screen.

00:57:18.039 --> 00:57:22.610
We're also setting up some further state
later on, and I'll get to that in a second.

00:57:22.610 --> 00:57:27.070
So let's take a look at our load
shaders from resource method first.

00:57:27.070 --> 00:57:32.710
So you'll see in load shaders from resource, we have a
couple of methods that are really doing all the work.

00:57:32.710 --> 00:57:40.170
We have getVertexShaderSourceFromResource, and
we also have getFragmentShaderSourceFromResource.

00:57:40.170 --> 00:57:44.730
In this case we're just passing in the input
to our function, which is the shader's name,

00:57:44.730 --> 00:57:47.000
or in this case for our function which is plasma.

00:57:47.000 --> 00:57:50.409
So let's go ahead and look at what
these methods are actually doing.

00:57:50.409 --> 00:57:56.589
So getVertexShaderSourceFromResource actually
is just calling a helper method that we have,

00:57:56.590 --> 00:57:59.690
and passing in the extension of the file that we're after.

00:57:59.690 --> 00:58:05.690
If we take a look at our, if we take a look at our
project here, go back to here, we have a couple of shaders

00:58:05.690 --> 00:58:11.380
that we've defined, Plasma.frag and Plasma.vert,
our fragment and our vertex shaders.

00:58:11.380 --> 00:58:16.190
So now we're go, so what we're doing is
we're actually loading these in at run time.

00:58:16.190 --> 00:58:20.220
So when you're doing work with Cocoa, it's
very common that you're going to have resources

00:58:20.219 --> 00:58:22.939
that you want to load in, such as these shaders.

00:58:22.940 --> 00:58:29.289
So we do here is down in the targets phase we can see
for our application we have a copy bundle resources.

00:58:29.289 --> 00:58:34.279
We've gone ahead and included our Plasma.frag
and our Plasma.vert files in there.

00:58:34.280 --> 00:58:37.240
What this'll do is when the app
is actually compiled and built,

00:58:37.239 --> 00:58:40.849
these are going to reside in our main
application bundles resources directory,

00:58:40.849 --> 00:58:43.750
and we'll be able to get to it at run time.

00:58:43.750 --> 00:58:46.820
So back to the code here, you can
see that we're doing exactly that.

00:58:46.820 --> 00:58:51.390
We ask the NS bundle class for the main
bundle, which is just the application bundle,

00:58:51.389 --> 00:58:58.230
and then we ask it for the pass the resource that we
want, whether that's Plasma.vert or Plasma.frag.

00:58:58.230 --> 00:59:04.550
Once we have that, we go ahead and read this file, and
make an NSString out of it, and convert that string

00:59:04.550 --> 00:59:08.170
to a CString before passing it back on to OpenGL.

00:59:08.170 --> 00:59:13.909
So let's head back to our initWithFrame pixelFormat.

00:59:13.909 --> 00:59:19.920
So you'll see one of the next things
we do is we set up our FrameSize.

00:59:19.920 --> 00:59:24.430
We set our FrameSize, as you see one of
the arguments to initWithFrame is a frame.

00:59:24.429 --> 00:59:29.000
Frame in Cocoa is simply a rectangle, it
defines where on the screen we're going to be.

00:59:29.000 --> 00:59:30.960
So we have an origin, a width, and a height.

00:59:30.960 --> 00:59:35.519
We want to make sure that we're
just, we set that up for consistency.

00:59:35.519 --> 00:59:41.860
So let's take a look at new update timer, which is where
we're actually setting up the callbacks to do the drawing.

00:59:41.860 --> 00:59:47.730
You'll see what we do here is we use NSTimer to
create a timer that's going to happen a periodic,

00:59:47.730 --> 00:59:53.960
at periodic intervals, and we pass
in a selector for heartbeat.

00:59:53.960 --> 00:59:58.769
You'll see up here that heartbeat is simply a
method that we use to say we need to draw back

00:59:58.769 --> 01:00:03.219
to the screen by calling self set needs display YES.

01:00:03.219 --> 01:00:07.609
So you can think of this purely as a callback,
that's exactly the function that it fills.

01:00:07.610 --> 01:00:10.579
So we want to take this timer, and we
actually installed this on our run loop

01:00:10.579 --> 01:00:12.500
so that it'll, so that we can get it called.

01:00:12.500 --> 01:00:16.159
And then we want to make sure that we're
going to, that we avoid screen tearing,

01:00:16.159 --> 01:00:19.759
so we've set up some further state with OpenGL.

01:00:19.760 --> 01:00:26.710
If we head back to initWithFrame pixelFormat,
you'll notice that after that we simply do a,

01:00:26.710 --> 01:00:29.940
we want to make sure that if our FrameSize changes,

01:00:29.940 --> 01:00:34.119
that we let things that might be
interested in that know about that event.

01:00:34.119 --> 01:00:40.730
So we simply set up the state here to make sure that we
post a notification if the frame size is going to change.

01:00:40.730 --> 01:00:45.110
So now again, you remember that we were
actually handling mouse events in this view.

01:00:45.110 --> 01:00:50.280
So let's go ahead and take a look at some
of these mouse event handling methods.

01:00:50.280 --> 01:00:56.280
Now every NSView is actually a subclass
of an abstract class called NS responder.

01:00:56.280 --> 01:01:02.220
NS responder is a class that sets up all the
event handling mechanisms throughout the app kit.

01:01:02.219 --> 01:01:06.349
In this case, the message that we've
defined here, such as mouse down, mouse up,

01:01:06.349 --> 01:01:10.069
these are all built in methods for NS responder.

01:01:10.070 --> 01:01:12.350
So let's go ahead and take a look at mouse drag,

01:01:12.349 --> 01:01:16.259
cause that's actually the most, one
of the first interesting methods.

01:01:16.260 --> 01:01:19.710
You'll see that we take this parameter called
the event, which is simply an NS event.

01:01:19.710 --> 01:01:24.750
It has many characteristics about what exactly
has happened as part of this mouse down.

01:01:24.750 --> 01:01:29.940
So once we get this mouse down, we want to check to see
is it the left mouse button or the right mouse button.

01:01:29.940 --> 01:01:35.010
If it's the right mouse, we want to go ahead and
dispatch that event to our right mouse dragged event.

01:01:35.010 --> 01:01:41.050
Otherwise, we're just going to find out where in the window
that event occurred, and we're going to update the orientation

01:01:41.050 --> 01:01:47.190
of our shape as a result, and we'll call self setNeedsDisplay
to make sure that we display that to the screen.

01:01:47.190 --> 01:01:52.980
Similarly, in right mouse drag we do, we find out where
that event occurred on screen, and based on the movement,

01:01:52.980 --> 01:01:58.539
we're going to go ahead and change the zoom, and set
whether or not we need to redisplay to the screen.

01:01:58.539 --> 01:02:01.809
And that's all you have to do to set up a
very basic OpenGL view where you're at,

01:02:01.809 --> 01:02:05.509
where you have full event handling in a Cocoa application.

01:02:05.510 --> 01:02:06.520
Babak, back to you.

01:02:06.519 --> 01:02:07.960
>> Thank you Michael.

01:02:07.960 --> 01:02:09.079
Slides please.

01:02:09.079 --> 01:02:15.449
( applause )

01:02:15.449 --> 01:02:22.839
Okay, so at this stage if you want more information,
we have our evangelist for you, who's Allan Schaffer,

01:02:22.840 --> 01:02:26.820
and he's going to take care of all
your 2D 3D graphics needs.

01:02:26.820 --> 01:02:31.500
And we also have documentation, sample code,
and many other resources that you can go

01:02:31.500 --> 01:02:37.730
to developer.apple.com/wwdc2007/ site.

01:02:37.730 --> 01:02:42.260
We have couple of interesting
sessions coming up for you tomorrow.

01:02:42.260 --> 01:02:48.480
And in fact the last demo that we did was actually an
homage to two of our OpenGL engineers,

01:02:48.480 --> 01:02:56.980
that geometry that you saw in the last demo was initially
used by our own Geoff Stahl, and he's going to be talking to you

01:02:56.980 --> 01:03:00.230
about leveraging the OpenGL Shading Language.

01:03:00.230 --> 01:03:04.599
And the shader, the plasma shader
was actually an homage to Kent Miller,

01:03:04.599 --> 01:03:08.759
and he's going to be in the session
Tune Your OpenGL Application.

01:03:08.760 --> 01:03:14.280
But before letting you go, I want to
impress on you some final thoughts.

01:03:14.280 --> 01:03:16.160
And basically what did we talk?

01:03:16.159 --> 01:03:19.960
Well we talked about a lot of optimization techniques.

01:03:19.960 --> 01:03:24.050
And we also talked about lot of common themes.

01:03:24.050 --> 01:03:29.300
You saw that while there were, you know, you didn't
see any one to one or onto mapping between APIs

01:03:29.300 --> 01:03:31.950
from Direct3D 9 and 10 to OpenGL.

01:03:31.949 --> 01:03:34.409
But you saw the ideas were common.

01:03:34.409 --> 01:03:37.599
So how can you utilize these two concepts?

01:03:37.599 --> 01:03:45.500
Well they are really tightly coupled, and they're really
you know, married together under the concept of refactoring.

01:03:45.500 --> 01:03:49.719
So if you have refactored your code, you
can just bring your Direct3D 9

01:03:49.719 --> 01:03:53.709
and Direct3D 10 application
to our platform rather rapidly.

01:03:53.710 --> 01:03:55.769
And when, with that -