---
Title:  The Encoding Process In Depth
Year:   2007
Web:    https://nonstrict.eu/wwdcindex/wwdc2007/602/

[!] This transcript has potential transcription errors.
---

And welcome to session 602 the Encoding Process In-Depth. And the way we are going to work this session today is we actually have three different speakers. The first speaker is going to be Doug Werner who's a manager on our Apple.com team who is known most famously for him amazing looking movie trailers. So he is going to talk about his process of actually creating those HD trailers that we have up on our page.

Then we are going to hand it off to Nate Caplin and John McClintock form the American Electric Power Company who are going to talk about how to build-out a distributed encoding render farm using compressors so you know going from doing just one encode to doing a whole batch of them.

And then finally we are going to end with David Singer who is on our QuickTime engineering team, who's going to talk about H264 form an Apple device perspective and how you can create content that is compatible with Apple devices and what we are doing to make that a little bit easier. So with that I am going to hand it over to Doug.

[Doug Werner]
Good afternoon and thank you for coming and seeing us today. What I'm going to do is literally take you through what I am going to do to start the encoding of a movie trailer that we are going to put up on the site probably tomorrow. If you get to the projector, there you go this is our new site, this is what we have been working on for a little while prior to WWDC.

We changed to format of the trailer site a little bit and hopefully people will appreciate the things that we've added including a specific section for HD and such so that said we will get that out of the way and get this out of the way and I've connected to my machine actually in one of my labs at Apple, via Timbuktu, and this is the Compressor App running and on my right side here which you may be familiar with if you are used to running Compressor this is your column over here that allows you to set your custom settings if your not using the presets that come with the app, so I tend to roll my own as they say.

Let me close you, anyway I'll scroll down. So what I am going to do is I'm a going to grab a file here and the file we are going to use is from New Line Cinema's Golden Compass which we, like I said will be posting on the site shortly.

I brought it into the app and with my preset settings here, I have folders already containing a set of HD resolution files at 1080, 720 and 480p and I'm going to bring those on to the app. Now when I am doing encoding and after I've done a capture. Our captures come in now mostly they come in on D5. So I have a D5 deck, I have two RAIDS that are connected as well as the encoding machines are connected all by fibre.

And my short hand when I am doing the encoding is actually to try and label what it is as I am going along so in this particular case this clip is a teaser. My short hand for 235 is that part here six channels is the number of channels that are in it and R is a ref movie. In another folder I actually have the source movie which has all eight tracks because when they come into me most of the time they will have you know left, right, surround, sub and all of that and then typically it will have two channels of dedicated stereo.

And since QuickTime has the ability to do surround sound of course we will want to take advantage of that so I note in the file so that I can have in captured this. Actually last week I can quickly look at this and know which set of settings I should jump on to it or apply to it. So what I have done is taken this folder of HD setting, brought them in and this is my base set of settings.

It's lagging a little bit and I am not exactly sure why but let me flip resolutions here and speed it up a tad. So the first thing I am looking at right off the bat is to make sure that the crop marks are going to, crops are going to come in the right position and I'll go ahead and close that.

In the settings lets just take the 480p and I'll just run through, just give you an idea of how the setting are like out here for this specific size of movie. It just, there we go. I think the button on my track pad is sticking, that's why I am getting a little bit of a delay.

So running through it, I mean often most common question that I have always been asked is well what settings you use and all of that so I am just showing you for a 480p 235 trailer. In this case what I am going to start with is a 2100 there of !course frame reordering and then in the audio of course we are going to be using AAC 5.1 surround, variable bit rating coding and I will typically kind of go to the middle of the road for the smaller files and for the larger like 1080p, kind of like your good, better, best, I'll definitely go to the highest setting for audio I can to support the surround.

In this case I have a very small amount of what I would qualify as image sharpening applied for the 480. Since you are starting with the 1080 I've noticed that it does require a bit of sharpening and from what I worked on this past week which I will show you here in a moment.

They use to run about a 50 on the details level but I am actually going to change it to 20 for this particular one and I am going to do the same to the, I don't think the 720 has any sharpening, I do have a slight bit of gamma correction, some brightness and contrast not really all that much.

I mean the 264 encoder does a really good job of pretty much getting it where you want to be and of course the last panel here, I'm telling you what size I want it to be and its, 2.35 is not true 16 by 9 so I am compensating for that. And then the crops, top and bottom.

And I do try and crop in at least devisable by four, so let me do a save and since I've shown you that process, I'm going to hop down here to the other ones and this will be 2.35, two channel HD5 and so this particular set has the lower resolution size of 640, 480, and this one is going to be one of my guinea pig files to convert for iPhone.

Then I am going to go over here and essentially triple check to make sure that these other guys are definitely the correct batch, cropped correctly so I can close that. Switch this to my cluster, I'm just going to go ahead and take off, and it will bring up the batch monitor and I'll switch this to this cluster server and this tells us what we're doing.

Right off the bat you are going to see that the four machines that I have attached my cluster, have already started to encode these particular files and I've got the other ones waiting. So in theory most of these will be done by the time I get back. To give you a point of comparison, when I started doing encoding back around '99 they did things like the Star Wars trailer, it would take about I think if memory serves it was about 12 hours to do one 480 in code and at the time once I got my lab really going and cranking I had eight machines all stacked in a pyramid in my office and I would use one machine with one setting and one machine with a slightly different setting and would literally be using them in parallel and then I'd take them out and be like and eye test, okay was this one better or was this one better and you know 12 hours at a whack you kind of wanted to try and get it going as promptly as you can, so that was the best hardware that I could throw at it at the time and now to look at it now a days you can see here this 1080p version what 1920 by some odd is probably going to take an hour, hour and ten minutes to do, so we have definitely come a long way.

With Compressor 3 you can allow a machine to have a virtual cluster, so I am looking forward to literally doubling the number of machines I have to be able to be able to take advantage of the additional horsepower that it will provide. So this is off and running and the setting that you saw me change, let me just close this stuff, gets back to, oh where did they go, let me pop to the web here real quick and here we go.

Okay here we go. I thought I had a couple sample files with me but I am going to go ahead and run down here to this guy, oops where did he go? What I was going to do, I may have to come back to it at the end of the Q and A session, I thought I had a couple files with me, I was going to show you first hand the difference, when you are encoding something and you run through it and your looking at it and it still might look a little bit crunchy, you think oh I might have to apply a little more data rate to it, what you can do is go back into that panel that I showed you previously about the percentage slider there and make a slide adjustment there and it makes a difference in having it qualifies less crunchiness in that space, so that is what I was going to show you.

And essentially that is it that is what is going to provide. Like I said during the Q and A session I might be able to come back and show them side by side, I'll go get them but I wanted to give you an example of my workflow. What I will do is, get this guy back up here, after the files are encoded they go to another machine that is actually in my office as opposed to the lab and this has a setting applied to it.

I will annotate them using Apple Script by taking a set of them for example here, whoops I'll just grab a couple and I have specific studio scripts that I will drag them onto and they already have all the factors pre loaded and I think this one is Sony Pictures.

And I would simply put in the name of the film and what it is going to do to all of those is open them, apply the copyright, whoops, the copyright information, come back here, and then complete that step automatically with having to go in and individually annotate each film.

Then I have another script that I run that creates multiple reference movies and the purpose of multiple reference movies for one file is once I put them up on the server I can see if anybody is deep linking to the file directly or if I am sharing the file with multiple people I can have you know like dash a, dash b, dash c and when I am doing my reporting I can run a report and say oh well look at how many people are looking at this file via the web as opposed to deep linking as opposed to one I may have given to product support or iTunes and that kind of thing.

So I actually tract using Apple Script and multiple movies the ability to keep track of how many iTunes people watch the trailer as opposed to from the main website and once I created the reference movies, all they do is they're just pointers, there's no speed selection or anything like that or just simple created a template file which have the little guy on there and I will just add it, throw it on top of this particular script and it automatically creates all of those files and I am ready to drag those up on to the server for tracking.

The nice thing about this in terms of Compressor 3 is it has the ability now instead of having to do that you can annotate the source movie first and then once you go through the compression and all the steps it will automatically pass that amount of information on to the other movies.

So I'm really happy about that, the other thing that is new in Compressor is the ability to separately adjust volume control, because in my experience I've noticed that the audio level drops after the encoding takes place and you can essentially over drive it slightly during the encoding process, although when it comes back out your level should be the same as where you started.

So that concludes my particular segment of it, and of course I will be here for Q and A and hopefully if we get, if I can hop back up here and run around I'll show you those two files, show you the comparison of what I was talking about how to refine the encoding a little bit tighter.

( Applause )

- Oh I did have them. Clicker. I am clickerless. Yeah.
- Podium.
- Podium.

[Nate Caplin]
Hi I am Nate Caplin from American Electric Power in Columbus, Ohio. This will take us forward, great. Okay so we are here to talk a little about our workflow. American Electric Power's a company of about 20,000 employees spread across 11 states and we use QuickTime extensively on our corporate intranet called AEP NOW which you're are seeing the homepage of right now. This is the homepage for all AEP employees, their web browser whenever they launch it up.

We've intergraded video into this site for training, for safety, for communication from executives to employees via live web casts etc. As you can see there is a tab called AEP-TV and when you click that you get to this page which has our featured videos as well as a video library by categories here at the right. All of these are QuickTime videos and this is all driven by a database back end.

When you finally get to an actual video on the site you see this large poster frame and a description and if you click the Watch Video button it will launch up the QuickTime player and it uses a QuickTime reference movie that detects the bandwidth using QuickTime 7's automatic bandwidth detection feature and feeds them a small or large file depending on the bandwidth at their location. That's what it looks like to the users, now let's talk about how we do this in our production workflow.

We are going to talk about distributed coding with Xsan and QuickTime publishing automation with AppleScript so I'm going to walk you through building and using a managed Qmaster cluster which is what we do. I'm going to step you through each of the applications that are used in building a cluster and then I am going to turn it over to John McClintock who is a streaming media developer on our team to actually demonstrate to you how we automate our workflow. These are some of the Apple technologies that we use and this is our topography of our cluster.

We have a seven node, we have seven workstations, one of them is John's personally and the others are used by our video procedures and our video manager. They're all Final Cut Pro video editing workstations that have the Qmaster services on them. There all connected together via both an Ethernet network and Xsan fibre channel network with a shared SAN volume that they all use from right within final cut.

So when they finish a file they actually save it onto the SAN volume and let us know that it is ready to be encoded and then the process that John will demo for you gets started. We do have one Xserve that acts as our Qmaster services cluster controller machine that does little else in the network in addition to the other Xserver that we have that are QuickTime streaming servers so that the QuickTime streaming server is obviously are the ones that distribute the files on demand and live to our users throughout.

Okay so starting off in the Qmaster system preferences pane under the Setup tab to make a managed cluster you have to go to each node on your cluster and turn on services only there at the top part, which I guess do we have a, on the controller you have to select services and cluster controller together. Now there's this option called QuickCluster with services which is for making kind of add hoc clusters but we found that at Qmaster's more reliable and more rock solid if you use a manage cluster instead.

In this pane you can also set up a password so that the administrator must enter a password for each node that they'd like to add into their cluster. On the advance tab, this is a key thing for using an Xsan cluster. You have to set this setting here called cluster storage.

You see there it's /Volumes/Video/qmaster. Video is the name of the Xsan volume and it's key that every node have the same exact path to the cluster storage and that path must be somewhere on the Xsan volume for you to take advantage of the faster speed that you get with an Xsan.

Because what actually happens is that instead of Qmaster distributing pieces of the file or actually the entire source file to every node before it begins encoding, all the nodes begin encoding immediately on the same file that is already on the Xsan shared by all of them. The status option, to show that on the menu bar, it puts a little status icon on the top right corner of the person's screen to let them know when their machine is being used for a cluster encoding job.

This is important because if your nodes are actually production machines that people are using Final Cut or Motion, they may want to opt out so that their machine is not part of the cluster for a period of time that they're doing some intense job. So if they see that, it's a reminder that they can go up there and open up the Qmaster tab and turn it off.

Qadministrator is an application that ships with Final Cut Studio. Once you've turned on Qmaster services on all your nodes you have to go to Qadministrator and create a new cluster and drag and drop the machines into it, which would appear at the bottom part of the window before its been setup. After that it's a simple matter of giving the cluster a name and applying your settings.

Then inside of Compressor right here you have your setting set up just as you would any other setting you are doing like Doug was showing. The two key things you want to look for are this Allow Job Segmenting which is in each preset in Compressor. If you check that, what that allows Compressor to do is to divvy up a single file and send pieces of that source file to each of the nodes to work on so that, say if you have a longer duration file, ten minutes or more, that one file will get encoded a lot faster. If you don't check that box, the Qmaster cluster will only speed up the encoding of multiple versions of the same output or multiple files.

And finally when you submit the job at the bottom left corner you have to select the name the cluster instead of this computer. Okay so now I am going to turn it over to John McClintock who will demo this. If we can, oh we don't need to switch to a demo machine, just hit next.

[John McClintock]
All righty. I'm going to run through an example of our sort of default workflow when everything is going simple and our editors, when they've completed a project, drop their files into a masters folder and we're just dragging that into Compressor and selecting a file, we like to do this manually so that we can verify aspect ratio and make sure that the project will work well with our default settings.

This one's a 16-9 project so I'm just going to drag a set of 16-9 settings on to the project and I'm going to check a sort of before and after and you can see there is a crop being applied and so forth. Then we will pretty much be able to select the cluster which in our case is called a Newton Cluster and we'll submit the job.

The batch monitor pops up and the fact that the status says Processing is a good thing, a bad thing is when it says Waiting for a long period of time. Hitting the twirlies gives you some status of the segments. There is as far as I know which segment belongs to which nodes. So if you are having a problem with a particular node, it's not always oblivious which one. When the batch is complete, it dumps the files into a destination directory and we do a little bit of extra processing using an AppleScript afterwards.

So I am going to select the files in the destination directory, queue the selection of the files and locate them in my droplet and we just drag the files onto the application and it is going to actually rehint to the movies because we need to do that and it mounts the QuickTime servers if they are not already mounted.

Copies the rehinted movies onto those servers and one onto an archive directory and right now its building a reference movie, builds XML and then makes a reference movie out of that and then uses Fetch to put it up to production. So the is the admin of our content management system and it's pretty much active server pages, classic active server pages and there's various fields that have prepopulated.

The critical thing is the file name and we use filing naming conventions so that they work on scripts throughout the entire production process and those just are the, there's a file stem that is the name which has a library number and so forth and then there's an extension that tell us the size of the file and the aspect ratio and all that gets used in various scripts to populate the user end of things appropriately.

And we're just sort of wondering around the screen. The users are able to download the video which we find reduces DVD orders they're able to order DVD's online. I've set this clip to not visible, it will still run in the interface but it doesn't show up in searches and it doesn't show up in category listings.

So I sort of verify the settings in the admin and then we'll go back to the admin screen and launch the chooser page that the video shows up on and this is what the user will end up seeing. And we'll just click the Watch Video button, eventually, and verify that we do in fact have video.

You may have noticed a little pop up window that opened and closed that's our stat tracker and that gives us some statistics on hits of the video, so we do have picture and we have sound so at least we know the video is out there on the servers.

Now when we, looking at the page you see that sort of default graphic that has nothing to do with the video, so we want to populate the page with something that is related to the project, so using another AppleScript we select an appropriate frame, something that will sort of suggest the contents and run another script out of the script menu and that's going to export a still frame out of the video.

Open it in Photoshop with a preset crop and there's some human intervention to sort of select where that goes. And for our category listing we use a small 65 pixel square thumbnail that is made in the same script. So those are being saved out to the, and Fetched up to the production servers. So we are just going to go back to the browser and refresh the page and we should have pretty much ready for use and publication and so forth.

So the Qmaster cluster has been really vary reliable for us in general but it defiantly does go down now and then. There are a couple things that are like absolutely necessary. One is that all the nodes have to be running the same version of QuickTime. They all have to be using the same Xsan folder for cluster storage.

The main reason for failure seems to be if one of the nodes has a hang for other reasons while it's crunching, the whole thing will go down. And what that looks like is in the batch monitor the thing will be waiting and usually by then you can identify which, that's there's one node in particular that is waiting, everything else might be 98 percent done.

But anyway it's easy to fix, you go to the cluster controller machine and go into its Qmaster preferences stop services and it says 10 minutes and you say no waiting zero and you stop the services, you are not going to recover them anyway. And then click options "Start Services" and this is sort of hidden, it took me a long time to figure out the option-click method to reset services and then start the services again. And then you need to go back into the Qadministrator and rebuild the cluster, which is not a big deal I mean you just rename it and drag the nodes into the thing and so forth so it's a vary straight forward process.

There's a line on software update here which is probably confusing, the key to software update is to not update any of your nodes ahead of the Xsan. The Xsan metadata controllers and so forth particularly need to be the last word, so you need to update everything else to match them. And you should do those all at once pretty much.

You don't want to have different software versions on different volumes of the whole thing. When the script is running its building a reference movie, this is just a snippet of. We're selecting different protocols for different lengths of videos. If we have, we like to do progressive download, but it doesn't work well with long files and being a corporation we are able to produce amazingly long videos and you don't want them progressively downloaded.

So this little clip here is just saying that if the clip is less then 10 minutes, it's going to be progressively downloaded, we'll have its protocol set to http, if it's longer then 10 minutes it's protocol is being set to rtsp.

And I might add that the same machines that run our QuickTime streaming server are also running web services with the same home directory so one can access the same file by progressive download or rtsp streaming just by changing the stem, which is all this does.

[Nate Caplin]
Yeah and this is just a snippet of how the XML text is being written and here's what the XML actually looks like, and this XML is saved as a, using the file stem underscore REF.QTRM and then the QTRM file is opened with Peter Hoddie's XMLtoRefMovie which is available at this website and is the only darn way I can think of to do this thing.

But it works great. So what it will make is a movie that will be called something like FILESTEM_REF.MOV and then we, the script changes the name to a .QTL for maybe vestigial reasons, we use to be more concerned about hijacking of videos by particularly WinAmp and Real Player occasionally glom things. But nothing gloms a QTL file, not even Safari knows what to do with it a QTL file.

So we've had pretty good success really with our Compressor Qmaster experience.

Yeah I mean overall it has really sped up our process. It use to be, we use to use Cleaner until about maybe a year and half ago and when one of our video produces would finish editing a project, they'd tell us it is ready to be encoded.

If they gave us a file that was five or ten minutes in duration, we'd say well we might be able to have it posted for you in two or three hours, you know to grind out the couple of versions that we do because we were doing it on one machine and now five or ten minute file, we can have it posted in a matter of ten or fifteen minutes because our cluster can crunch through it faster than real time creating multiple versions.

More over we have a lot of these very long movies, 30 minutes even an hour long, boring legal lectures or something and these things use to take a day or two to encode you know on a machine over a weekend and now we can get them done in a matter of a couple of hours.

So like Doug said, Compressors really helped out our workflow and we are really looking forward to using Compressor 3, which we hope will take even better advantage of our multiple core workstations to speed it up even more. So thanks a lot. And we'll do questions after everyone.

( Applause )

Oh next David Singer from Apple.

( Pause in speaking. )

David: Hi so now for a quick change of subject, slight change of subject perhaps. I'm going to try and deal with the question that we know a lot of you ask. How do I make a media file that will play on my friend's iPod or that new iPhone or the Apple TV or the Heads up display in the new iCar. Did we announce the new iCar yet?

So there's two basic ways that we establish suitability of a file and you could look at a file to establish whether it's suitable for a particular usage. You can look at the movie atom in the file. The movie atom contains all the declarations of the files, the structure, the codecs it uses, whether it's self contained, you can work out how interleaved it is and so on. And you can check to see whether this file actually conforms to some specifications for say a particular device or whatever so you can scan that.

Alternatively there is a way of signing a file if you look in our files you will see there is a thing called file-type atom at the front of them, it has a list in it of what are called brands, those brands claim that the file is conformal with a particular specification, so you can bypass the check for movie atom by scanning it, by just looking for a brand that asserts what you were hoping to find, and that makes life much faster and obliviously it's something we recommend.

So these specifications, what do they look like? Well there's two, going to be two basic classes of these specifications we'll be publishing. There's class-based specifications and device specific specifications, now the class-based ones are fairly easy to understand, they are going to rely on publicly defined features of the files, so things you can easily check that rely on standards and documents you can pull down from Apple and other places.

So for example what codecs do you use, you know we don't process Cinepak on the iPod for example that would be a bad codec to choose. The profiles and the levels of the codecs for MPEG codecs for example, do we do main profiles on this device or is it just baseline? What level do we go to, which tends to limit bit rate and screen size?

What file for my features are present? Is the file self contained? That generally helps if you are you are only going to put the file on another device because if it's self contained you got the media as well. Is it interleaved? Is it in time order and so on? Those are sometimes important devices which don't have a lot of bandwidth to their storage.

How fast, what's the bit rate of the file? How big can the file be and so on? So specifications listing things that you can obviously work out pretty easily from looking at the file and indeed the class-based one have unprotected and protected variants Clearly Apple devices tend to be able to play files that are protected with Apple's FairPlay system, but other devices can't and in case you are looking at files and you want to go why don't I just slide along right behind Apple so I can use the same encoding that people are using for the iPhone but just an unprotected version of it, then you can look for the tag that says this is conforming to an unprotected file.

And the class-based ones we're intending, hoping that they will be supported by one or more Apple devices over a period of time. So if you are building a library and you don't want to be re-encoding your library every time we come out with a new hip device then maybe you want to be targeting a class-based specification in the hopes that we will continue to support that class in our new devices.

So let's look at some examples of general classes here. Basic Audio, something that'll play on the iPod Shuffle and pretty well everything else, something that's a portable audio-only file. Low resolution video, something that will play on the first generation iPod Video the one we're currently shipping and the way we initially published it, you know, the 320 by 240 size that's very portable, very standards based. The basic specs for standard video, extended video, and then probably a class also for desktop video, something that we don't actually restrict the bit rates and the file sizes, because our desktop machines, they're brave. They'll attack anything, even if they drop frames occasionally.

Now let's contrast that with the device specific specifications. This is where you realize that you want to make a file that works perfectly on just one device, on a specific device. And often this is because all this is stretching the limits of a device. And so this is, the classic example of this is getting standard def video out of the iPod Video. As I said when we first launched the iPod Video, we didn't tell, we didn't actually try to do standard def video on it, we were doing 320 by 240 on it.

We realized that we could, in fact, get standard def video out of it. But the recipe to get it is a little tricky. You have to tune the bitstream so that they just get through the decoding process on that. So this is the famous low complexity mode that we publish, but we don't actually tell you what it means, and we know that, and this is what I'm telling you today, is that we know that you don't know what it means and we're going to tell you what it means.

We are working on the documentation for it. On the UUID tag that you'll find documented in some sense or at least mentioned quite a lot of blogs and websites around the internet, that is indeed the embodiment of that claim, of that low complexity tag, seeing that UUID tag.

That UUID tag is a bitstream tag. It claims that the bitstream respects the limits of and will play on a very particular device. Now, as I say, getting these things to work when you're stretching the limits of a device is sometimes a little, ohhhh, so we will publish suggested ways that you can achieve this.

We'll probably have to simplify. The real recipe may be as complicated as counting the number of motion vectors over a half second interval and multiplying that by 1.3 and subtracting the number of 4 by 4 macro blocks, adding in the number of 8 by 8 macro blocks, dividing by the phase of the moon and checking that it doesn't exceed 237. Well, that's more than we're going to write in a specification.

( Applause )

David: We'll write something that is actually comprehensible, we hope. But, you and we might experiment with what in fact works. You know? If you can prove to yourself, to your own satisfaction, that my software, that your software writes files that actually do work on the iPod Video, even though it doesn't quite follow the recipe that we publish, then bully for you, that's great. Go ahead. Now the tag, the UUID tag that I just mentioned, you have to put that in the movie atom.

But it's making a claim about the nature of the bitstream and the rest of the file, which as I said at the beginning there, you'll notice that we didn't look at the rest of the file when we looked to see whether a file was suitable for a device, we're just looking at the movie atom and the tags and the brand and the file type atom.

So the tag is a UUID atom, specific content in the sample description, in the movie atom saying something about the bitstream. So summary, let's see if we can go through this very carefully. The file tags, the brand, they assert and they confirm conformity, you see that? You can go man, the person who wrote this file claims that it conforms to this spec, I don't need to check.

If you don't see the tag you wanted, the brand you wanted, the absence doesn't deny it. You're going to have to scan the movie item to check. Why do we say this? Well, maybe the software that wrote this file wasn't aware of that specification. When the person wrote that software, maybe that specification wasn't available.

So you want to grandfather files that will in fact work on a device if you can, so check to see whether the file will work. Now, you can have device specific file tags here. So a file tag will say the entire file has been tuned to work on this device and you're only allowed to put that in if the matching bitstream tag is present in the movie atom saying the bitstreams have been tuned for that device. So the presence of that bitstream tag claims playability on a particular device.

But unlike the file level tags, the absence of that tag means that you cannot assume playability and it's not easily checked either. Because putting it in would mean that you would have to decode say the video and check the number of 4 by 4 macro blocks, multiplied by 1.3 and minus the number of 8 by 8 macro blocks and divided by the phase of the moon does not in fact exceed 237 over a half second interval.

And you're not going to do that every time you want to put a file on an iPod or an iPhone or something. That involves scanning the entire file and basically running a decoder in almost in debugging mode to check that limit. So if you can't see the bitstream tag, you give up.

It clearly wasn't claiming to be compatible, so there's a good chance it's not, in fact, compatible. So, if your software creates files, if you are a software author and you're writing files out there, if you make a stream, obviously, that will work on a specific device, then put in that bitstream tag because nobody is going to put it in after the fact.

Then look at the movie atom and look at all the specifications your software is aware of and put in the signatures of all the specifications that you are aware of, all the brands that correspond to those specifications that the file, in fact, does conform to. This is trying to catch as many people as you can and giving them a fast in so that they see the specification and they go okay, this file works on my device, I don't have to check any further.

Now please, please, please, please if you don't know what a tag means, a bitstream tag or a file level tag, if you don't know what it means, don't put it in the file. You're making an unsubstantiated, probably false, misleading, and almost certainly an unhelpful claim. You're claiming that you've checked that this file conforms to a specification you haven't even read.

So please, people around the internet are suggesting on blogs man, if you just copy this UUID atom into here, it seems to work. Well it will work some of the time, of course, because by luck, you will hit some bitstreams that do, in fact, conform to the limits, but you're telling your users, or the people that are reading your blogs, that it'll work all the time, and that's probably not true.

So if you're reading media files, flip it around. Look for the tags, the brand you support. If you see that, you're done. That's a quick check. You just can do the checks of these four character codes and if you find one that you support and the file conforms to that, you're in. We're done.

Now, if none of them are present, then do the second level check. Scan the movie atom, look for what your device requires. Now, for Apple, that means that we may be looking for bitstream tags in the sample description if the file doesn't meet suitable class space limits. Obviously if it's an iPod Video and you've put in simple video, the 320 by 240, we don't need to check for the bitstream tag because it's already a class that the iPod Video supports.

So, I'm sure you're going to want more information. We are going to publish details of the brands, the UUID tags, the low complexity modes, and how to make them. And we're aware of the lack of that documentation and we realize that you can see that we're doing something and we're not telling you what it is and that some of you are trying to guess and trying to work around that. That's not a position that we like to be in.

We will document this. We are working on it and we're apologetic that we haven't done it so far. And Ed Agabeg is your main contact, of course. If you have questions after the event, then he will find the right people and harass them to get the documentation that you need.

Then, coming up this week, if you're entered in coding, you've got to go and see how to create integrated workforce solutions with Final Cut Pro, because that's the greatest tool out there and that's the most fun you're going to have this week. Next, after that, however, if you want to have fun mastering QuickTime Digital Video and creating effective, sophisticated podcasts, don't create boring podcasts. Create effective, sophisticated podcasts. Come to Presidio on Friday.

Likewise there are labs here that we can help you with. Digital video preprocessing, media encoding and media delivery, and indeed, tomorrow you could hit the QuickTime lab, the media and graphics lab and find out about standards, where I'll be there and you can come and ask me about all the hard questions about international standards for multimedia.
