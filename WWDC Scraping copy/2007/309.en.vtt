WEBVTT

00:00:20.000 --> 00:00:27.079
>> My name is Steve Lewallen and this is
session 309, Getting Started With Xray.

00:00:27.079 --> 00:00:34.289
I'm the Performance Tools Manager within Development
Technologies at Apple and I'm here to talk about Xray.

00:00:34.289 --> 00:00:40.039
So on today's agenda we're going to define
for you what Xray is and w'ere also going

00:00:40.039 --> 00:00:44.950
to briefly cover a technology you will
probably hear often hand in hand with Xray

00:00:44.950 --> 00:00:47.940
around here at the conference and that's DTrace.

00:00:47.939 --> 00:00:53.929
Then we're going to highlight the key elements
of Xray that you need to understand how to use

00:00:53.929 --> 00:00:55.909
in order to make basic use of Xray itself.

00:00:55.909 --> 00:00:59.109
And finally we're going to have three demos.

00:00:59.109 --> 00:01:02.109
The first demo that I'm going to
give is just a general usage demo.

00:01:02.109 --> 00:01:09.950
We want to familiarize you all with the different parts of
Xray and how you use them, what a work flow is within Xray.

00:01:09.950 --> 00:01:16.290
The second demo is more about solving an
interesting problem and integration with Xcode.

00:01:16.290 --> 00:01:20.550
We'll also used an advanced feature
of Xray called the UI recorder.

00:01:20.549 --> 00:01:28.250
And finally we're going to have a talk on memory analysis
and demonstrate our memory analysis tools in Xray.

00:01:28.250 --> 00:01:30.519
So what is Xray?

00:01:30.519 --> 00:01:33.879
I like to call Xray a meta analysis tool.

00:01:33.879 --> 00:01:39.250
Most performance tools you have are focused
on one particular metric or genre of data

00:01:39.250 --> 00:01:46.420
such as memory allocations or how much
time you code is spending in one function.

00:01:46.420 --> 00:01:53.890
But Xray can do all of these things within one unifying
interface and part of this unifying interface theme has been

00:01:53.890 --> 00:01:56.870
to bring in some of our older legacy tools.

00:01:56.870 --> 00:01:59.700
Over the years, we've developed many different tools.

00:01:59.700 --> 00:02:05.329
They come from different paths in the company and different
history's and they have different UIs that you need

00:02:05.329 --> 00:02:12.539
to learn and we need to upgrading them and some of
them have started to kind of really lack the polish.

00:02:12.539 --> 00:02:15.099
Certainly not looking like a Leopard app.

00:02:15.099 --> 00:02:25.229
So we've built a great UI in Xray, polished it and
are supporting all of these tools within Xray itself.

00:02:25.229 --> 00:02:29.539
And of course I mentioned that we
include support for DTrace as well.

00:02:29.539 --> 00:02:34.289
And finally, Xray is exclusively available on Leopard.

00:02:34.289 --> 00:02:36.459
It will not run in Tiger.

00:02:36.460 --> 00:02:39.030
So why is Xray so great?

00:02:39.030 --> 00:02:42.819
Well those disparate types of data I
talked about, you can look at any one

00:02:42.819 --> 00:02:49.389
of those Xray can measure many different types,
but you can also view them simultaneously over time

00:02:49.389 --> 00:02:53.159
and you can use time as one way to correlate data together.

00:02:53.159 --> 00:03:00.969
Now instead of saying well, my app uses so much memory
around here, you can say my app spikes in memory

00:03:00.969 --> 00:03:04.039
between the time I open this file and close it

00:03:04.039 --> 00:03:09.329
and now I have another context with
which to look at that memory spike.

00:03:09.330 --> 00:03:12.480
It also provides the ability to mine the data you gather.

00:03:12.479 --> 00:03:17.569
We have various tools to flip the data around,
upside down, inside out, scope it down,

00:03:17.569 --> 00:03:21.079
to find your particular problem
you're interested in looking at.

00:03:21.080 --> 00:03:27.850
Xray also streamlines the edit, build, analysis cycle
and we'll take a look at that in demo number two.

00:03:27.849 --> 00:03:32.250
And finally Xray simplifies the use of DTrace itself.

00:03:32.250 --> 00:03:33.400
So what is DTrace?

00:03:33.400 --> 00:03:36.849
Well, this is a quote actually from Sun's DTrace manual,

00:03:36.849 --> 00:03:39.739
updated slightly to fit our needs here.

00:03:39.740 --> 00:03:46.969
Sun did a great job, very innovative technology in the
last few years in Solaris and they open sourced it.

00:03:46.969 --> 00:03:53.389
We said well that's great technology, we want to use it
at Apple and so a bunch of people at Apple from people

00:03:53.389 --> 00:04:01.669
in the kernel team to the performance team, all over Apple,
worked their butts off to port this to Leopard in a year,

00:04:01.669 --> 00:04:06.539
both for Intel and PowerPC and that wasn't
an easy job, but they did a great job at it.

00:04:06.539 --> 00:04:13.900
Now, it's a dynamic tracing facility that allows you to
trace any instruction on the system from the kernel on up

00:04:13.900 --> 00:04:22.110
and concisely answer any arbitrary question you may have
about the system and the behavior of your app and ours.

00:04:22.110 --> 00:04:23.980
So why is DTrace so great?

00:04:23.980 --> 00:04:26.509
What attracted us to DTrace?

00:04:26.509 --> 00:04:29.680
Well one of the great things is zero disabled cost.

00:04:29.680 --> 00:04:35.060
Now I was actually sitting in the room during
the OpenGL talk and they said something

00:04:35.060 --> 00:04:37.490
that I've said often about why DTrace is great.

00:04:37.490 --> 00:04:44.000
They were talking about an error API that they put in their
programs and often times developers accidentally leave

00:04:44.000 --> 00:04:46.980
that in and that slows down the
performance of their OpenGL apps.

00:04:46.980 --> 00:04:51.860
Well this is a reason why DTrace is
great, because it has zero disabled cost.

00:04:51.860 --> 00:05:00.350
Instead of specifically putting in a code that gives you
error reporting and performance metrics in you own code,

00:05:00.350 --> 00:05:04.510
you can use DTrace to dynamically
attach probes, gather some information,

00:05:04.509 --> 00:05:07.730
when you're done pull them out
and it doesn't effect you app.

00:05:07.730 --> 00:05:10.730
You can do that with apps that are
in production and already shipped.

00:05:10.730 --> 00:05:13.650
You don't need to recompile it to turn this on and off.

00:05:13.649 --> 00:05:17.299
So it's dynamic and it's system wide from the kernel on up.

00:05:17.300 --> 00:05:20.020
We have a technology now that bridges the gap.

00:05:20.019 --> 00:05:23.740
It used to be that there's the kernel
developers and they have their debugging tools

00:05:23.740 --> 00:05:30.660
and then there's the user developers and there was
this gap and DTrace bridges that gap for all of us.

00:05:30.660 --> 00:05:38.470
Now a user, a user app developer can actually see what's
going on from the kernel on up in his application.

00:05:38.470 --> 00:05:40.530
That's really phenomenal.

00:05:40.529 --> 00:05:42.879
So again, it's always available as well.

00:05:42.879 --> 00:05:49.360
We ship DTrace in Leopard on the user install,
on the developer install and on the server.

00:05:49.360 --> 00:05:53.530
You don't need to install anything
to use DTrace itself in Leopard.

00:05:53.529 --> 00:05:55.909
And finally, it's scriptable.

00:05:55.910 --> 00:06:04.530
So we call technologies that we use in Xray to
gather different pieces of data instrumentation.

00:06:04.529 --> 00:06:07.869
So what types of instrumentation does Xray have?

00:06:07.870 --> 00:06:14.290
Well it has all this technology built on the Darwin
Foundation and most of it built on Leopard frameworks.

00:06:14.290 --> 00:06:21.330
Such as for, example, object allocation and leak
instruments, general memory usage instruments.

00:06:21.329 --> 00:06:27.849
It has instruments to measure where you're
spending your time in your app a.k.a. sampler

00:06:27.850 --> 00:06:30.390
or if your app is spinning, what's
going on when it's spinning.

00:06:30.389 --> 00:06:31.560
Is it deadlocked?

00:06:31.560 --> 00:06:34.360
Is it just taking a long time with the event loop?

00:06:34.360 --> 00:06:38.400
Then we have some new innovative instruments one
of which is the UI recorder which will allow you

00:06:38.399 --> 00:06:42.159
to record the user events that are
being sent to your application.

00:06:42.160 --> 00:06:43.630
You can use this in a couple of ways.

00:06:43.629 --> 00:06:49.819
One, you can say well, is my app actually
responding to the events it should be responding to?

00:06:49.819 --> 00:06:54.870
But two, we can flip the coin here
and play those events back

00:06:54.870 --> 00:06:59.449
and automate you driving your own app
and we'll take a look at that in demo.

00:06:59.449 --> 00:07:01.879
We have another app called the OpenGL Profiler

00:07:01.879 --> 00:07:07.170
and this will help you determine how
efficiently you're using GL on the system.

00:07:07.170 --> 00:07:13.090
Then of course as I said, we have DTrace also
and we've built several instruments around DTrace

00:07:13.089 --> 00:07:16.929
such as file activity instruments,
garbage collection instruments

00:07:16.930 --> 00:07:23.250
and finally you can build your
own DTrace instruments in Xray.

00:07:23.250 --> 00:07:29.180
So what are the key elements that you need
to understand to make best use of Xray?

00:07:29.180 --> 00:07:32.490
Well first and foremost is the instrument itself.

00:07:32.490 --> 00:07:42.139
This is the key piece of technology that gathers data on
a particular metric such as memory usage, I/O, etcetera.

00:07:42.139 --> 00:07:44.759
So where do you get an instrument in Xray?

00:07:44.759 --> 00:07:46.939
Well you get it out of the instrument library.

00:07:46.939 --> 00:07:52.009
The instrument library hosts all of
the instruments that we include in Xray

00:07:52.009 --> 00:07:56.170
and if you build any instruments yourself,
that's where they will appear as well.

00:07:56.170 --> 00:07:59.500
Once you have an instrument out of
the library, what do you do with it?

00:07:59.500 --> 00:08:02.170
You apply it to the trace document.

00:08:02.170 --> 00:08:09.110
This is where all the instruments that you've selected to
measure against your particular target app will appear,

00:08:09.110 --> 00:08:11.490
as well as all the data that they gather and this is

00:08:11.490 --> 00:08:16.439
where you will spend you time mining
the data and finding your problem.

00:08:16.439 --> 00:08:21.350
Now once you've applied an instrument to the trace
document, it has certain default settings usually

00:08:21.350 --> 00:08:25.530
and we've tried our very best to
pick good, solid default settings.

00:08:25.529 --> 00:08:30.819
But if you want to tinker with that and change
them, you use the inspector on the instrument.

00:08:30.819 --> 00:08:33.080
And finally, where else can you get instruments?

00:08:33.080 --> 00:08:37.430
Well you also can get instruments from Xray trace templates.

00:08:37.429 --> 00:08:42.739
These are collections of instruments that we've
put together to look at particular problems

00:08:42.740 --> 00:08:45.500
and you can build trace templates yourself as well.

00:08:45.500 --> 00:08:52.889
And you can set these templates onto
problems from Xray itself, from Xcode,

00:08:52.889 --> 00:08:58.490
from what we call "quick start" keys
and from the command line.

00:08:58.490 --> 00:09:05.350
Now one caveat here or something
to mention is that as I said,

00:09:05.350 --> 00:09:09.600
we're trying to unify some of our
smaller tools into Xray itself.

00:09:09.600 --> 00:09:16.259
Well a couple of tools you may have used, Sampler.app
and ObjectAlloc.app are no more and in their place,

00:09:16.259 --> 00:09:21.819
in the performance tools folder, are Xray
templates that look pretty similar to those apps

00:09:21.820 --> 00:09:24.629
with a little template, cool template icon on them.

00:09:24.629 --> 00:09:26.559
So don't be surprised when you click on those

00:09:26.559 --> 00:09:32.119
that Xray actually opens instead and
you can use those with great effect.

00:09:32.120 --> 00:09:36.370
They have even more power than the apps themselves.

00:09:36.370 --> 00:09:38.190
So let's go to demos.

00:09:38.190 --> 00:09:40.970
Let me give you a general usage demo.

00:09:40.970 --> 00:09:45.500
I want to show you how you use Xray and we're not going to
solve a real problem, we're just going to kind of play around

00:09:45.500 --> 00:09:49.899
and find some issues and show Xray itself.

00:09:51.070 --> 00:09:56.629
So I have Xray on my dock here, it's
normally in developer applications.

00:09:56.629 --> 00:10:04.250
I'm going to click it and up pops Xray and on the front
of it is the Xray template we just saw on the slides.

00:10:04.250 --> 00:10:10.190
Now for the purposes of this demo, I'm actually going to
choose the least exciting template, the blank template,

00:10:10.190 --> 00:10:14.020
because I want to show you how to use the library as well.

00:10:14.019 --> 00:10:17.460
So I have the blank template selected and I'll click choose.

00:10:17.460 --> 00:10:20.930
Now we have an empty trace document
and where do I get the instruments?

00:10:20.929 --> 00:10:22.809
Again I get them from the library.

00:10:22.809 --> 00:10:29.339
So I'll go up to the upper right in the tool bar and
click on my library button and my library appears.

00:10:29.340 --> 00:10:34.560
Now these are all of the instruments that we
actually include with Xray out of the box.

00:10:34.559 --> 00:10:39.379
And I can find different things, I can search in
the library, I can say what has to do with memory?

00:10:39.379 --> 00:10:43.559
Well there's a bunch of instruments that
have to do with memory, oh how about file?

00:10:43.559 --> 00:10:45.529
There's a bunch of instruments that have to do with file.

00:10:45.529 --> 00:10:49.610
It will search all the key words
in the instrument to get these hits.

00:10:49.610 --> 00:10:51.800
I can also search by category.

00:10:51.799 --> 00:10:57.219
So I'm going to go to the top of the library and drag
down the splitter here and expand the library node

00:10:57.220 --> 00:11:01.779
and these are all the different categories
of instruments that we actually have

00:11:01.779 --> 00:11:05.429
and I am actually interested in
this category, the system category.

00:11:05.429 --> 00:11:09.000
Because I'm going to do this first
demo with a sampler instrument.

00:11:09.000 --> 00:11:13.570
So to apply an instrument to a trace
document, I select it and drag it

00:11:13.570 --> 00:11:16.940
out of the library and drop it onto the document itself.

00:11:16.940 --> 00:11:23.380
Now I've applied the sampler instrument to the
document and I'm going to go and close the library.

00:11:23.379 --> 00:11:30.370
Now the next thing I want to do is I want to change the sampling
rate of sampler from ten milliseconds to five milliseconds.

00:11:30.370 --> 00:11:38.360
So I'm going to go and click on the small I here on the
right of the instrument and that brings up the inspector.

00:11:38.360 --> 00:11:43.180
So I'm going to change this from ten to five and now I'm done.

00:11:43.179 --> 00:11:48.859
Okay. So now we have an instrument, we're all ready
with that, now we need to actually pick something

00:11:48.860 --> 00:11:51.669
to gather data on, to run this sampler against.

00:11:51.669 --> 00:11:58.129
So I'm going to go up to launch executable and I
could attach to a running process for example

00:11:58.129 --> 00:12:00.059
but I want to actually choose an executable.

00:12:00.059 --> 00:12:05.379
So I'm going to select that and my chooser
comes up and I'm just going to pick chess.

00:12:05.379 --> 00:12:07.960
Just so we can play around with that a little bit.

00:12:07.960 --> 00:12:14.860
Before I exit this dialog, I want to point out that if you
have a special setting that you like your application,

00:12:14.860 --> 00:12:20.860
your target to run with, you can set environment
settings in this box as well as command line arguments

00:12:20.860 --> 00:12:25.659
and those will be remembered for that executable
as long as you don't go back and change them.

00:12:25.659 --> 00:12:30.159
So I'll select open now on chess
and we've selected our target

00:12:30.159 --> 00:12:36.500
Now I'm actually ready to run the trace, using
the sampler instrument against my chess target.

00:12:36.500 --> 00:12:37.529
So let me do that now.

00:12:37.529 --> 00:12:41.839
I'm going to use the upper left hand button
here, record and I'm going to press that.

00:12:41.840 --> 00:12:48.170
Xray is going to launch chess and start
running the sampler instrument against it

00:12:48.169 --> 00:12:50.459
and let me just chess through it's paces again.

00:12:50.460 --> 00:12:52.660
We're just doing a little usage demo here.

00:12:52.659 --> 00:12:54.689
Okay that's good, I'll quit.

00:12:54.690 --> 00:12:56.640
Okay so what do we see?

00:12:56.639 --> 00:13:02.899
Well a lot of things have changed in Xray now, so
let's work from the top down and discuss each of those.

00:13:02.899 --> 00:13:06.189
So center top is the time display.

00:13:06.190 --> 00:13:13.510
This is actually showing me the running time of my recording
and chess was in the foreground but it was ticking away

00:13:13.509 --> 00:13:20.639
as the trace was going and data was being
populated and as we performed the trace.

00:13:20.639 --> 00:13:21.799
So we ran for twelve seconds.

00:13:21.799 --> 00:13:27.509
Now let's move down a level and we see that
there's track data next to the sampler instrument.

00:13:27.509 --> 00:13:33.610
This is CPU usage data basically, spikes and
different instruments will put different kinds

00:13:33.610 --> 00:13:37.980
of graphical representations and
graphs in these track views.

00:13:37.980 --> 00:13:39.379
Next down in my detail view.

00:13:39.379 --> 00:13:43.480
Now we saw that automatically disclose
as soon as we started the trace.

00:13:43.480 --> 00:13:46.139
This actually contains the meat of my data.

00:13:46.139 --> 00:13:50.009
The track view is more of a high level navigation tool.

00:13:50.009 --> 00:13:53.120
So I want go dig into this a bit.

00:13:53.120 --> 00:14:00.580
I want to answer what is happening in this
first spike here when the chess app starts up.

00:14:00.580 --> 00:14:03.680
So I'm going to use a few techniques to narrow that down.

00:14:03.679 --> 00:14:07.500
So the first thing I want to do is I
want to focus in on just the main thread.

00:14:07.500 --> 00:14:09.919
That's what I'm interested in, just
what happened on the main thread.

00:14:09.919 --> 00:14:17.189
So I'm going to go to the lower left hand corner and
under active thread, I'm going to select main thread.

00:14:17.190 --> 00:14:20.320
Now we see in the detail view that all the threads other

00:14:20.320 --> 00:14:24.190
than the main thread have been
eliminated from the sampling data.

00:14:24.190 --> 00:14:27.300
The next thing I like to do is invert the call tree.

00:14:27.299 --> 00:14:31.709
Because that gives me the interesting
leaf nodes of the sample.

00:14:31.710 --> 00:14:36.030
So I'm going to go about two thirds of the way
down to this invert call tree check box here

00:14:36.029 --> 00:14:39.339
under the call tree options and I'm going to select that.

00:14:39.340 --> 00:14:46.129
Now I've inverted the call tree and I want to eliminate
anything that's not Objective-C. So I'm going to go

00:14:46.129 --> 00:14:50.580
down a few check boxes and select show Objective-C only.

00:14:50.580 --> 00:14:53.490
Okay, well here we are.

00:14:53.490 --> 00:14:58.169
We've filtered this down some, flipped
it over, now I want to focus in on just

00:14:58.169 --> 00:15:03.779
that one range of time in the track view up above.

00:15:03.779 --> 00:15:09.169
So what I can do is I can filter on time
by click and dragging in the track view.

00:15:09.169 --> 00:15:18.719
So if I hold down my option key on the keyboard and then I
click and drag my mouse, I'll actually open a small region

00:15:18.720 --> 00:15:24.460
of time here and we saw the detail view filter
down a bit and that's because it's filtered

00:15:24.460 --> 00:15:26.820
out everything that's not in that time range.

00:15:26.820 --> 00:15:32.400
There's also some interesting ways to create
that time filter that we won't go into today.

00:15:32.399 --> 00:15:36.120
So on the top I see the view hierarchy
lock, lock for writing.

00:15:36.120 --> 00:15:37.039
Well what's going on?

00:15:37.039 --> 00:15:42.209
Why is that one of the hot points in
the beginning here when we loaded chess?

00:15:42.210 --> 00:15:47.690
Well I'm going to look at another view in Xray
called the extended detail view and often times,

00:15:47.690 --> 00:15:51.010
the extended detail view is loaded with stack data.

00:15:51.009 --> 00:15:55.539
So I'm going to go to the upper right tool bar item
again, this time using the view menu and we see

00:15:55.539 --> 00:16:00.740
that the detail menu is already disclosed
and I'll now select the extended detail view

00:16:00.740 --> 00:16:10.889
and out slides the stack trace and I can see, I can also
invert this, reverse the order of the stack and I can see

00:16:10.889 --> 00:16:17.470
that lock for writing is being called well
basically because we're loading bundles,

00:16:17.470 --> 00:16:19.430
we're loading the nibs and that makes perfect sense.

00:16:19.429 --> 00:16:24.979
All the UIs coming into the app and so things are
being locked and unlocked as all that's being built up.

00:16:24.980 --> 00:16:26.539
So that makes perfect sense.

00:16:26.539 --> 00:16:30.919
So that is actually the conclusion of this demo.

00:16:30.919 --> 00:16:34.919
Just to show you around how you actually run Xray.

00:16:34.919 --> 00:16:44.079
Now let's go back to the slides and we'll
review the steps that we took to do that.

00:16:44.080 --> 00:16:49.830
So, step one was we had to choose a template
and in this case we chose the most boring one

00:16:49.830 --> 00:16:52.210
of the templates to show you the library.

00:16:52.210 --> 00:16:57.620
So step two was to pick and instrument, in this case sampler
out of the library and apply it to the trace document.

00:16:57.620 --> 00:17:01.919
Then we configured the instrument
and we chose our target, chess.

00:17:01.919 --> 00:17:10.599
And step four we actually started the recording,
Xray launched chess for us, we gathered the data,

00:17:10.599 --> 00:17:16.990
we stopped the trace and then we used
our various tools within Xray to narrow

00:17:16.990 --> 00:17:23.559
down onto the issue we were interested
in which is start up time.

00:17:23.559 --> 00:17:29.129
So now let's go to a more interesting demo, now that
we're are more familiar with how we basically use Xray.

00:17:29.130 --> 00:17:32.240
So here's the scenario for the demo.

00:17:32.240 --> 00:17:39.920
You are an engineer at a large biotech company and they
have these DNA records, they have millions of DNA records

00:17:39.920 --> 00:17:45.070
and they had someone write an app that
would sort these DNA records and the person

00:17:45.069 --> 00:17:54.119
who wrote those did a simple string comparison type of sort
to sort the data and you thought you could do a better job.

00:17:54.119 --> 00:18:11.309
So let's go back to demo machine one again
and let me start that and I'm going to run it.

00:18:11.309 --> 00:18:17.629
Okay, so this is our simple app and on
the left hand side are unsorted records.

00:18:17.630 --> 00:18:22.290
For this example data set, we just have a 100,000
and on the right should be our sorted records.

00:18:22.289 --> 00:18:29.149
So when you've got the app, you perform the
default string sort and it took two thirds

00:18:29.150 --> 00:18:32.380
of a second or so, so then you added your UID Sort.

00:18:32.380 --> 00:18:38.390
You thought that if you just added a unique identifier
to each DNA record, it would be a lot faster.

00:18:38.390 --> 00:18:43.840
So you just had this idea and you just
implemented it and let's see where you got.

00:18:43.839 --> 00:18:50.449
Well you didn't do so well and
actually, this isn't totally uncommon.

00:18:50.450 --> 00:18:57.470
Often times we get an idea of how to solve our
performance issue without really digging into it a lot

00:18:57.470 --> 00:19:05.110
and we may have a sound concept overall, but something
about the execution of that actually didn't result

00:19:05.109 --> 00:19:07.699
in the performance win that we had hoped.

00:19:07.700 --> 00:19:13.200
So you think yourself wow okay, I thought this
was going to be easy, this is going to be a lot tougher.

00:19:13.200 --> 00:19:19.269
So how do I improve this, I'm going to
have to iterate over time probably.

00:19:19.269 --> 00:19:26.430
I don't want to have to go and drive this app every time and
regather the performance data myself, I'm going to use Xray

00:19:26.430 --> 00:19:29.759
and Xcode together tell me automate all of this.

00:19:29.759 --> 00:19:37.730
So let's go back to the demo app and quit it and
let's go up to Xcode's run menu and take a look

00:19:37.730 --> 00:19:39.849
at what's under, start with performance tool.

00:19:39.849 --> 00:19:43.079
Now in start with performance tool,
we have a bunch of templates here.

00:19:43.079 --> 00:19:46.859
These are all the same templates
we saw in the template chooser

00:19:46.859 --> 00:19:50.159
and in fact any new templates you
see here, you'll see in the chooser.

00:19:50.160 --> 00:19:53.220
So I'm going to select this template
at the bottom, UI recorder.

00:19:53.220 --> 00:19:57.190
I'll select that and let's see what happens.

00:19:57.190 --> 00:20:00.660
Well Xray starts up and it starts up our demo app.

00:20:00.660 --> 00:20:07.560
Now I'm going to go through the same thing
I did before and do this UID sort that's

00:20:07.559 --> 00:20:12.950
so slow and now I'll go and quit my demo app.

00:20:12.950 --> 00:20:15.340
So what happened there?

00:20:15.339 --> 00:20:20.279
Well the UI recorder instrument recorded
all of the user gestures that I sent

00:20:20.279 --> 00:20:24.569
to my target app and it can replay those for me.

00:20:24.569 --> 00:20:30.589
So I'm going to use that feature and I'm going to combine
it with that sampler instrument we saw before.

00:20:30.589 --> 00:20:39.659
So let me go back to my library and let's look
for sampler instrument again, there it is,

00:20:39.660 --> 00:20:43.650
I'll drop it on the trace document
again, I'll close my library.

00:20:43.650 --> 00:20:50.840
Now I'm going to save this with these two instruments,
along with the UI recording data which we call

00:20:50.839 --> 00:20:56.669
in this mode the driver data, as an Xray template.

00:20:56.670 --> 00:21:01.710
So I'm going to go to the Xray file
menu and say save as template.

00:21:01.710 --> 00:21:22.319
And I'm going to type in sort test and I'll just say
automated sort test of DNA app and I'll hit save.

00:21:22.319 --> 00:21:24.809
Now I'm going to close Xray completely.

00:21:24.809 --> 00:21:28.309
I don't want to save it as a document itself.

00:21:28.309 --> 00:21:33.759
Now let's go back and look at that
performance tools menu again in Xcode.

00:21:33.759 --> 00:21:37.759
Start with performance tools, now
we see a new template, sort test.

00:21:37.759 --> 00:21:40.250
So what happens if I select sort test now?

00:21:40.250 --> 00:21:43.750
I'll do that and Xray is going to start up.

00:21:43.750 --> 00:21:48.680
It's going to start the demo app, then
it's going to drive the target app for me.

00:21:48.680 --> 00:21:51.910
So it's going to perform the first
test and then the second test

00:21:51.910 --> 00:21:56.710
which took longer and then it's going to go and quit the app.

00:21:56.710 --> 00:21:59.079
So that's a nice little automation.

00:21:59.079 --> 00:22:10.750
( applause )
So what's really cool, one of the first people that saw
this was someone who works with game developers a lot

00:22:10.750 --> 00:22:14.910
and they described to me and said wow you
know, often times these game developers,

00:22:14.910 --> 00:22:18.300
they get this bug report that says
like it's Quake or something.

00:22:18.299 --> 00:22:23.779
Well I went down this hallway, I turned left, I shot that
guy, I turned right, I shot this other guy, etcetera,

00:22:23.779 --> 00:22:26.139
etcetera and that's difficult for them to reproduce.

00:22:26.140 --> 00:22:30.160
Often times they hack into their code just
so they can get to that point in the game

00:22:30.160 --> 00:22:33.570
and so this is neat to automate all sorts of applications.

00:22:33.569 --> 00:22:37.119
So now let's look at the data it actually collected.

00:22:37.119 --> 00:22:46.539
So this first large blip here, this was the amount of time
it took to do string sort and this rather bigger blip here,

00:22:46.539 --> 00:22:53.859
that was the time it took to do what was supposed
to be the faster sorting routine, the UID sort.

00:22:53.859 --> 00:23:01.309
So let's use the same techniques that we learned in
the previous demo to find out what the problem is.

00:23:01.309 --> 00:23:04.750
Okay so the first thing I do is select authorize

00:23:04.750 --> 00:23:08.369
and in this case this is a single threaded
app so it doesn't have a lot of affect.

00:23:08.369 --> 00:23:14.000
I'll go now and invert the call tree as we did
before and I'll say show Objective-C only.

00:23:14.000 --> 00:23:22.170
So at the top here is RSRecordcalculateUID, so let's
disclose our extended detail view to see the call stack.

00:23:22.170 --> 00:23:27.340
I'll go back to view menu at the
top and say extended detail.

00:23:27.339 --> 00:23:35.740
And now we can see that at the top is RSrecordcalculateUID
and we can see by the subtext below there,

00:23:35.740 --> 00:23:38.620
all the frames that have source code to them.

00:23:38.619 --> 00:23:44.169
So let's click on a calculate UID, double
click on it and bring it up in Xcode.

00:23:44.170 --> 00:23:47.500
So I look at this and I say, well
you know, this is pretty efficient,

00:23:47.500 --> 00:23:50.630
I don't think I can really optimize calculate UID.

00:23:50.630 --> 00:23:53.710
So let's close that and let's go down a frame.

00:23:53.710 --> 00:23:56.690
What about the UID method itself?

00:23:56.690 --> 00:24:03.430
Okay well this is passing back a number with the
calculated UID, but how is all this being used?

00:24:03.430 --> 00:24:08.230
Well if you look in the next few frames,
we'll see that an array is being sorted,

00:24:08.230 --> 00:24:16.769
there is a comparison function called UID compare and
that is getting the UID, which computes the UID itself

00:24:16.769 --> 00:24:19.910
for both left and right and the comparison.

00:24:19.910 --> 00:24:26.529
So that could be a lot of comparisons and a lot of
computations of the UID and that doesn't change.

00:24:26.529 --> 00:24:29.639
I mean a DNA strand remains the same the entire time.

00:24:29.640 --> 00:24:34.880
So what I'm going to do is go back
to the way we provide the UID.

00:24:34.880 --> 00:24:43.710
Let's go back to that frame and I am going to replace
this with a new method that actually caches the UID.

00:24:43.710 --> 00:24:54.450
So I'll go and delete this now and I will drag in
the new method, save that and then I go to my header

00:24:54.450 --> 00:25:04.400
and add the data member there, save that,
close, close and build and now I'm going

00:25:04.400 --> 00:25:09.259
to use another cool feature of Xcode
which basically is restart.

00:25:09.259 --> 00:25:15.470
Xcode always knows the last way you ran your app and
if you notice, Xray is also running in the background.

00:25:15.470 --> 00:25:20.259
It still has that other template that we have
the previous data with before we made our fix.

00:25:20.259 --> 00:25:24.129
So I'm going to go back to the run menu,
now I can just say go sort test.

00:25:24.130 --> 00:25:26.240
I don't even need to find the template anymore.

00:25:26.240 --> 00:25:33.450
So say go sort test and Xray is going to start up and start
the demo app again and put it through it's paces once again.

00:25:33.450 --> 00:25:35.289
That took about the same amount of time.

00:25:35.289 --> 00:25:37.420
This takes a lot less time.

00:25:37.420 --> 00:25:41.570
Now the UI recorder says I've gotta wait around
here, this took awhile so it's going to hang out there

00:25:41.569 --> 00:25:43.980
for a second and now it's going to quit the app again.

00:25:43.980 --> 00:25:47.450
So now we have performance win here.

00:25:47.450 --> 00:25:55.120
Now let's compare before and after by using yet
another feature of Xray called runs, multiple runs.

00:25:55.119 --> 00:26:00.019
So let's go back to Xray and click on the instrument.

00:26:00.019 --> 00:26:05.629
Move this detail down, click on the
inspector and say show all runs and hit done.

00:26:05.630 --> 00:26:10.160
And now what we can see is the
bottom graph is what was before.

00:26:10.160 --> 00:26:11.730
This is what took so long.

00:26:11.730 --> 00:26:14.110
The upper graph is what was improved.

00:26:14.109 --> 00:26:16.490
So let's review this really quickly in slides.

00:26:16.490 --> 00:26:18.380
So back to the slides.

00:26:22.049 --> 00:26:30.740
So the first step was to generate a UI recording and
then we can store that away and use it whenever we want.

00:26:30.740 --> 00:26:37.130
So we used Xcode to launch the UI recorder template
against the current executable in our Xcode project.

00:26:37.130 --> 00:26:45.290
We manipulated our app to teach Xray how to do it
itself and then we added the sampler instrument

00:26:45.289 --> 00:26:49.730
so that whenever we ran, we gather actual performance data.

00:26:49.730 --> 00:26:57.569
We save it as a template and then
we played it back from Xcode seeing

00:26:57.569 --> 00:27:00.589
that our new template was there in the performance menu.

00:27:03.069 --> 00:27:10.669
We identified our hot spot and we corrected
the performance issue by caching the UID away.

00:27:13.529 --> 00:27:22.700
And then we restarted from Xcode using the
restart function and verified our performance win.

00:27:22.700 --> 00:27:27.910
Now I sensed that you thought we had
failed there cause it was still longer.

00:27:27.910 --> 00:27:34.830
So actually, we improved the performance some using
one of our instruments but we can improve it more.

00:27:34.829 --> 00:27:43.539
So I'm going to invite Daniel Delwood, engineer on the
Xray team, who is going to talk about memory analysis

00:27:43.539 --> 00:27:49.680
and see what he can do to meet our goal of beating the
string sort by taking the angle of memory analysis.

00:27:49.680 --> 00:27:50.120
So Daniel.

00:27:50.119 --> 00:27:50.519
>> Thanks Steve.

00:27:50.519 --> 00:27:51.900
>> Take it away.

00:27:51.900 --> 00:27:58.480
( applause )

00:27:58.480 --> 00:27:59.089
>> Well howdy.

00:27:59.089 --> 00:28:05.879
I'm Daniel Delwood, Software Radiologist and I'm here
to talk to you today about memory analysis and Xray.

00:28:05.880 --> 00:28:12.090
So first of all, if you remember one thing I say today,
remember that memory is critical to performance, okay.

00:28:12.089 --> 00:28:15.240
If you remember two things, remember
that Xray can help with that.

00:28:15.240 --> 00:28:20.299
So without further adieu, let me jump right
into what memory analysis tools Xray brings

00:28:20.299 --> 00:28:24.289
to the table and sort of introduce you to them.

00:28:24.289 --> 00:28:26.759
So first of all, there's ObjectAlloc.

00:28:26.759 --> 00:28:30.319
Now this is an instrument that tracks
all the malloc calls and the free calls

00:28:30.319 --> 00:28:33.679
and a target application and records all that data.

00:28:33.680 --> 00:28:38.310
Now it is a lot of data, but that gives you a
lot of power because later on you can go back

00:28:38.309 --> 00:28:43.190
and get detailed address histories
for virtually any pointer.

00:28:43.190 --> 00:28:48.370
It used to be a stand alone application and we've
since improved it by speeding it up and adding features

00:28:48.369 --> 00:28:54.029
and including it in Xray and I'll talk about
this a little bit later before the demo.

00:28:55.039 --> 00:28:56.319
Next is leaks.

00:28:56.319 --> 00:28:59.419
This is a tool that checks for
unreferenced blocks of memory.

00:28:59.420 --> 00:29:05.560
If you've allocated a block and since lost all references
to it, you obviously can't deallocate it and it's a leak

00:29:05.559 --> 00:29:12.700
and it returns that and it also tells you the
allocation point at which the block you know, is created.

00:29:12.700 --> 00:29:14.920
So that's another really powerful tool.

00:29:14.920 --> 00:29:18.390
The memory usage monitor is a slightly different tool.

00:29:18.390 --> 00:29:24.460
It's very, very useful because it records high level
statistics such as virtual size, resident size,

00:29:24.460 --> 00:29:27.819
the number of page faults, number of copy on write faults

00:29:27.819 --> 00:29:31.189
that your target application makes
and graphs them over time.

00:29:31.190 --> 00:29:39.840
So the good part about his is you can visually look at your
data and say, okay when did my memory usage start to spike?

00:29:39.839 --> 00:29:41.069
Was it because I clicked a button?

00:29:41.069 --> 00:29:42.919
Was it very slow over time?

00:29:42.920 --> 00:29:45.890
Memory usage monitor will help you find that.

00:29:45.890 --> 00:29:49.870
And lastly I just wanted to mention that DTrace,
which Steve talked about earlier, is a very,

00:29:49.869 --> 00:29:52.869
very powerful technology for you
as the application developer

00:29:52.869 --> 00:29:56.589
to use the knowledge you have to solve your memory problems.

00:29:56.589 --> 00:30:01.449
Because you know the most about your code, you can
ask specific questions, probe specific functions

00:30:01.450 --> 00:30:08.279
and find out well why is your memory
spiking, why is it not being used well?

00:30:08.279 --> 00:30:12.089
So what are some, what's the benefit
of these all being together?

00:30:12.089 --> 00:30:14.720
Well you can use them all at the same time in Xray.

00:30:14.720 --> 00:30:15.960
All in the same document.

00:30:15.960 --> 00:30:19.350
So what are some common memory issues?

00:30:19.349 --> 00:30:25.179
Well leaked memory like I said, you can use the leaks
plug in or the leaks instrument along with ObjectAlloc

00:30:25.180 --> 00:30:28.279
to get more detailed histories for those leaked blocks.

00:30:28.279 --> 00:30:33.980
If you're facing large footprints, you can use the
memory usage monitor to find out was it a slow,

00:30:33.980 --> 00:30:40.960
gradual growth over time possibly due to leaks
or was it something that you did suddenly?

00:30:40.960 --> 00:30:45.590
If you're facing pointers to freed
memory, getting exec bad access,

00:30:45.589 --> 00:30:49.559
I'd use ObjectAlloc, leagues,
DTrace and really search this.

00:30:49.559 --> 00:30:54.309
And then dynamic memory usage is a little
bit less known of a memory problem.

00:30:54.309 --> 00:31:00.819
This is when you allocate an object or just a block and
then you free it and then you allocate and free and allocate

00:31:00.819 --> 00:31:03.159
and free and do this a hundred thousand times.

00:31:03.160 --> 00:31:06.890
It's a really big performance problem and
it's something you just don't need to do.

00:31:06.890 --> 00:31:11.140
You can create an object and use it for
the whole lifetime or just create a buffer

00:31:11.140 --> 00:31:17.120
and so that's what dynamic memory usage is about
and you can use ObjectAlloc to help track that down.

00:31:17.119 --> 00:31:22.579
And also, if you're tracking down memory
fragmentation, this is a very, very hard problem to track

00:31:22.579 --> 00:31:27.679
and if you use all these instruments together, you can
actually get a handle on it and it's really amazing.

00:31:27.680 --> 00:31:30.100
So I just wanted to mention that as well.

00:31:30.099 --> 00:31:34.569
There's a little bit more in ObjectAlloc
before we go to a demo of it.

00:31:34.569 --> 00:31:40.929
It's not just for objects, it's sort of a misnomer there,
but it tracks all of the malloc calls, all of the free calls

00:31:40.930 --> 00:31:44.900
and if you want, all the retain/release/autorelease
events too.

00:31:44.900 --> 00:31:48.730
This allows you to really get that detailed information.

00:31:48.730 --> 00:31:54.240
You can get statistics on what type
of objects were getting created.

00:31:54.240 --> 00:31:59.200
Was it just those three really, really big buffer
allocations that are using up your memory and you forgot

00:31:59.200 --> 00:32:03.950
to get rid of them or what it the hundred thousand
NS strings that you accidentally left around?

00:32:03.950 --> 00:32:09.340
You can find out that information as well as
view these as call trees to find out what point

00:32:09.339 --> 00:32:12.509
in your code was responsible for those allocations.

00:32:12.509 --> 00:32:17.980
Also, you can get pointer histories by using
all these events and giving it a pointer,

00:32:17.980 --> 00:32:21.490
you can find out okay, what was
the life cycle of my objects.

00:32:21.490 --> 00:32:25.569
That's what ObjectAlloc is all
about, it's a memory life cycle tool.

00:32:25.569 --> 00:32:29.089
And finally, it does work with garbage collected apps.

00:32:29.089 --> 00:32:34.500
The only difference between a garbage collected app and
a normal application when viewing it with ObjectAlloc,

00:32:34.500 --> 00:32:39.650
is that you don't actually contain, or you
don't actually control when the frees occur.

00:32:39.650 --> 00:32:46.990
So under a garbage collected app, the free is due to the
garbage collector cleaning up after you and any other blocks

00:32:46.990 --> 00:32:51.039
that you allocate manually, you'll
definitely want to watch as well.

00:32:51.039 --> 00:32:59.909
One last note on leaks before we go ahead and demo is that
it does a static memory analysis of your target application

00:32:59.910 --> 00:33:07.120
which is really, really accurate except that
it's not for garbage collected environments.

00:33:07.119 --> 00:33:11.289
This is something I just wanted to mention
since garbage collected environments

00:33:11.289 --> 00:33:14.509
and Objective-C 2.0 world are a big thing.

00:33:14.509 --> 00:33:21.579
What it does is it looks for all the malloc'd regions
in your target application and searches through them

00:33:21.579 --> 00:33:27.349
and tries to find all the blocks that are referenced and
anything it can't find as referenced, it returns as leaked

00:33:27.349 --> 00:33:30.529
and that's how you can really track
down those memory problems.

00:33:30.529 --> 00:33:37.180
It was a command line tool only and now we are both
including the command line tool and the leaks instrument

00:33:37.180 --> 00:33:45.519
and it works alongside ObjectAlloc to give you those
really detailed histories for your leaked blocks.

00:33:45.519 --> 00:33:49.220
So anyway, we move on to a demo.

00:33:49.220 --> 00:33:54.700
Steve showed us the DNA sorting demo
and we didn't quite reach our goal.

00:33:54.700 --> 00:34:01.890
Our goal was to be faster than the alpha numeric case and
sensitive string compare there and we just didn't get there.

00:34:01.890 --> 00:34:05.880
So what I'm going to do is I'm going to show you some of
the memory analysis tools in Xray and we're going to look

00:34:05.880 --> 00:34:10.860
at just the memory usage with really no concern of
performance and at the end we'll go back and say,

00:34:10.860 --> 00:34:16.309
well how much did this really help
and we'll take a look at that.

00:34:16.309 --> 00:34:21.289
So I've got the same application that he has
and I'm going to go up to my run menu and instead

00:34:21.289 --> 00:34:26.119
of using his really cool sort test, I'm
going to use object allocations plus sampler.

00:34:26.119 --> 00:34:31.420
It's one of my favorite templates and it
lets me set my own settings and save them

00:34:31.420 --> 00:34:36.579
for next time I want to use this template
on this problem or other problems.

00:34:36.579 --> 00:34:42.279
So I select the template and Xray starts
up and in the background you can see

00:34:42.280 --> 00:34:49.110
that ObjectAlloc is graphing the number of graphic
bytes in my target application and so if I go ahead

00:34:49.110 --> 00:34:54.960
and press the UID sort button, whoa, look at that spike.

00:34:54.960 --> 00:34:57.380
That's probably bad.

00:34:57.380 --> 00:35:03.519
So we need to look into that and I think I've got
enough data, but one thing to point out here is

00:35:03.519 --> 00:35:07.300
that while Steve was using 100,000
records, I'm only using 10,000 records.

00:35:07.300 --> 00:35:11.980
ObjectAlloc really does record a lot of data
and it does have a little bit of an overhead

00:35:11.980 --> 00:35:17.130
because you're recording every single event and so
while I could have done 100,000 records,

00:35:17.130 --> 00:35:20.670
it would have taken longer and it
doesn't give me the information I need

00:35:20.670 --> 00:35:23.860
because 10,000 records is just sufficient.

00:35:23.860 --> 00:35:31.250
So I'll quit my application and looking at the ObjectAlloc
instrument, I can see that the detail view

00:35:31.250 --> 00:35:39.929
down here is showing me the summary of all the objects I
created and the categories and so I can take a look here

00:35:39.929 --> 00:35:48.329
at the, let's see here, RS records and you can see
that 10,000 were allocated over the course

00:35:48.329 --> 00:35:56.329
of the application's lifetime and 10,000 were
still alive at the end of the application when I quit it.

00:35:56.329 --> 00:36:00.049
The only thing that's unexpected are these CFNumbers here.

00:36:00.050 --> 00:36:07.800
Look at this, only 432 were still
alive at the end of the application's run and I created

00:36:07.800 --> 00:36:13.490
over 279,000 or 278,000
of these while doing the sort.

00:36:13.489 --> 00:36:15.679
Hmm, that's probably a problem.

00:36:15.679 --> 00:36:20.569
The other thing that's interesting to note is
that by using sampler and the graph as well,

00:36:20.570 --> 00:36:25.360
you can see that it really did take a lot
of processing power when the memory spiked.

00:36:25.360 --> 00:36:26.160
Interesting.

00:36:26.159 --> 00:36:29.469
So I think it's probably the CFNumbers that are at fault.

00:36:29.469 --> 00:36:35.079
I'm going to select the second view, the
call tree view here to find out what point

00:36:35.079 --> 00:36:38.460
in my code is responsible for these allocations.

00:36:38.460 --> 00:36:43.250
And so I could just go in from
here, but I'll focus on CFNumbers

00:36:43.250 --> 00:36:45.300
since I'm not really interested
in anything else at the time.

00:36:45.300 --> 00:36:48.210
So I click the arrow and here we go.

00:36:48.210 --> 00:36:57.220
I'll bring in the extended detail view so we can see a stack
view, oops, and there we go and since I like customized,

00:36:57.219 --> 00:37:06.219
heaviest stack trays view here, I'm going to go ahead and
pull down on this gear and removed the source location

00:37:06.219 --> 00:37:14.129
and removed the library name and I'll go ahead and
invert the stack so it shows as I would more expect.

00:37:14.130 --> 00:37:17.420
So anyway, we see here that
4.26 megabytes worth

00:37:17.420 --> 00:37:20.659
of CFNumbers were allocated in the program's execution.

00:37:20.659 --> 00:37:26.119
So if we follow this down on the right, we see a lot
of these BSD Q sort frames and it looks like it's sort

00:37:26.119 --> 00:37:28.480
of branching out through there
because it's a recursive function.

00:37:28.480 --> 00:37:36.530
Well we've got data mining so I'm going to go to the left
and select flatten recursion and boom, there we go.

00:37:36.530 --> 00:37:44.060
So I'll select frame here and watch that
4.24 megabytes comes all the way

00:37:44.059 --> 00:37:46.690
through to our code in RS record UID.

00:37:46.690 --> 00:37:49.039
Hmm, that's interesting.

00:37:49.039 --> 00:37:55.019
If I click right one frame below that, I can see that they
all come from and it's number, number with unsigned long,

00:37:55.019 --> 00:37:59.090
long and it looks like we can see the problem.

00:37:59.090 --> 00:38:04.360
It looks like what we're doing is creating an NS number
number every single time our UID method gets called,

00:38:04.360 --> 00:38:07.950
which as Steve showed earlier, was
not a good time to calculate the UID

00:38:07.949 --> 00:38:12.179
and probably not a good time to
create and NS number either.

00:38:12.179 --> 00:38:16.699
So what I'm going to do now is look at
the lifetime of one event or one object

00:38:16.699 --> 00:38:22.029
and find out why the spike occurred
instead of sort of a flat up and down.

00:38:22.030 --> 00:38:31.940
So I'm going to go to the third view, the list view and
I'm going to go up to the graph and drag my inspection head

00:38:31.940 --> 00:38:38.079
and if you can see below, the events are going
by and matching the time of my inspection head.

00:38:38.079 --> 00:38:45.920
And so here is a bunch of CF numbers and I'll just select
one of their addresses and boom, right in the middle,

00:38:45.920 --> 00:38:52.139
malloc auto release, CF release and free, there's
the allocation life cycle of this object.

00:38:52.139 --> 00:39:00.750
So it was malloc and RS record UID,
auto released and RS record UID.

00:39:00.750 --> 00:39:02.719
Hmm. Interesting.

00:39:02.719 --> 00:39:07.750
So what it looks like we're doing is using the NS
number, number with unsigned long long method.

00:39:07.750 --> 00:39:12.130
We're creating an auto released object
every single time and it waits until the end

00:39:12.130 --> 00:39:14.260
of the event loop to release all those objects.

00:39:14.260 --> 00:39:17.060
Which is why we see the very, very visible spike.

00:39:17.059 --> 00:39:20.769
Let's go directly back to the code and fix this if we can.

00:39:20.769 --> 00:39:30.440
So I'll double click, pop right back to the code that Steve
saw earlier and I'll replace this method with a method

00:39:30.440 --> 00:39:39.809
that caches the NS number and of course, I'll need to
go back to the header file, add an instance variable

00:39:39.809 --> 00:39:49.679
for that and I should probably go up to the dealloc
method and add a release just so I'm a good citizen.

00:39:49.679 --> 00:40:01.289
So I'll go ahead and add that, build my entire, build
my application and go back to my run menu and hit go.

00:40:01.289 --> 00:40:07.690
All right, so it's starts up the application again just like
last time, but to have more of a side by side comparison,

00:40:07.690 --> 00:40:12.460
I'm going to go ahead and select the
show all run option right now.

00:40:12.460 --> 00:40:16.949
So if I hit the I and hit show all runs, you
can see that it's comparing them side by side

00:40:16.949 --> 00:40:20.219
and showing the memory usage of my application.

00:40:20.219 --> 00:40:26.129
So if I hit UID sort now, wow,
it's done and no memory spike.

00:40:26.130 --> 00:40:26.440
Excellent.

00:40:26.440 --> 00:40:29.909
That's exactly what we wanted to fix.

00:40:29.909 --> 00:40:35.960
So all right, just to verify that our objects
were created in a more reasonable fashion,

00:40:35.960 --> 00:40:41.309
I'll go back to the summary view and remove
the extended detail view so you can see this,

00:40:41.309 --> 00:40:46.769
but there are only 10,964
CF numbers created during the run.

00:40:46.769 --> 00:40:48.159
Excellent.

00:40:48.159 --> 00:40:54.219
All right and just for the last comparison,
I'm going to go back to the run menu from Xcode

00:40:54.219 --> 00:40:58.750
and just run the application separately so
that we can see what a performance impact

00:40:58.750 --> 00:41:01.269
of doing a memory analysis on this application was.

00:41:01.269 --> 00:41:07.550
So I'll set it back to 100,000 records,
string sort it, 0.7 seconds.

00:41:07.550 --> 00:41:10.190
UID sort it, 0.48.

00:41:10.190 --> 00:41:10.559
There we go.

00:41:10.559 --> 00:41:12.489
We got our win.

00:41:12.489 --> 00:41:13.739
So back to slides.

00:41:13.739 --> 00:41:13.939
( applause )

00:41:13.940 --> 00:41:23.550
So what did we just see here?

00:41:23.550 --> 00:41:32.170
Well we started our application from Xcode by using the
run with performance tool and selected my custom template

00:41:32.170 --> 00:41:36.940
that I can use on multiple different
documents, or multiple different applications.

00:41:36.940 --> 00:41:43.389
From there we took it to ObjectAlloc inside Xray and looked
for the summary view to hunt for the overall problem.

00:41:43.389 --> 00:41:46.389
To find out where our memory usage was going wrong.

00:41:46.389 --> 00:41:52.579
Then went to the call tree view to find out the culprit,
to find out what part of my code was responsible for this

00:41:52.579 --> 00:41:57.360
and then because we were interested in why the spike
occurred and the life cycle of one of these objects,

00:41:57.360 --> 00:42:04.519
went to the object list and really got the
details and got the exact lifetime of our object.

00:42:04.519 --> 00:42:12.759
Finally we went back to our code, found the offending
line and made a fix that cached the UID so that only one

00:42:12.760 --> 00:42:21.430
of them would be created, not, per object, not 27
and then we 'went back to Xray and verified

00:42:21.429 --> 00:42:24.500
that the fix did in fact solve our problem.

00:42:25.750 --> 00:42:28.530
So what did we learn?

00:42:28.530 --> 00:42:32.060
Well memory analysis is critical to performance.

00:42:32.059 --> 00:42:39.400
Just by simply caching that one instance variable,
we gained a 4x improvement in performance.

00:42:39.400 --> 00:42:40.360
That's great.

00:42:40.360 --> 00:42:45.140
So Xray has really powerful tools to help you
look at the memory usage of your application,

00:42:45.139 --> 00:42:48.079
ObjectAlloc, leaks, memory usage, DTrace and more.

00:42:48.079 --> 00:42:48.900
You can create you own.

00:42:48.900 --> 00:42:54.800
The side by side instrumentation allows you to use
these all at the same time and really correlate the data

00:42:54.800 --> 00:43:01.090
and you also get the common Xray benefits of time
scoping, of persistence, document persistence, saving it,

00:43:01.090 --> 00:43:04.840
emailing it to one of your friends and more.

00:43:04.840 --> 00:43:08.880
So with that I'll return it to Steve
to give us some closing thoughts.

00:43:08.880 --> 00:43:10.329
( applause )

00:43:10.329 --> 00:43:11.460
>> Hey Daniel, good job.

00:43:11.460 --> 00:43:13.179
Thank you.

00:43:13.179 --> 00:43:17.429
So that was a great talk on memory analysis in Xray.

00:43:17.429 --> 00:43:24.190
So in closing, just to summarize, Xray is a great
way to visually and mine your performance data.

00:43:24.190 --> 00:43:26.840
It has a lot of different instruments in it.

00:43:26.840 --> 00:43:33.329
You can use it to correlate disparate types, a new
unique power that you haven't had in other tools before.

00:43:33.329 --> 00:43:39.769
You can use it to leverage DTrace by building custom
instruments and you can use it to automate you work flow.

00:43:39.769 --> 00:43:47.869
Now speaking of DTrace, there is a talk tomorrow on
dedicated entirely to DTrace and I urge you to go to that

00:43:47.869 --> 00:43:53.259
and then on Friday there is a talk
about Xray and DTrace combined.

00:43:53.260 --> 00:43:57.360
This is sort of our advanced session and we're
going to talk about a lot of cool things in there,

00:43:57.360 --> 00:44:03.280
including other ways to invoke Xray on your
targets that are novel and interesting and helpful.

00:44:03.280 --> 00:44:10.560
DTrace, building custom instruments in DTrace,
in Xray and doing remote tracing.

00:44:10.559 --> 00:44:15.980
Building instruments in Xray, exporting
the script as DScript, running it,

00:44:15.980 --> 00:44:19.880
generating output and importing that data back into Xray.

00:44:19.880 --> 00:44:21.990
So I urge you to go to that session as well.

00:44:21.989 --> 00:44:24.000
It's really going to be exciting.

00:44:24.000 --> 00:44:31.139
And finally, you can seek out Matt Formica, our 64-bit
Dev Tools Evangelist for more information or you can go

00:44:31.139 --> 00:44:37.679
to the developer website at Apple and you can go to Sun's
website for their DTrace manual and there's also a lot

00:44:37.679 --> 00:44:40.190
of good information on the web about DTrace.