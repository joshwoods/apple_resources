WEBVTT

00:00:10.150 --> 00:00:12.260
Good afternoon.

00:00:12.320 --> 00:00:13.500
I'm Joe Wolfe.

00:00:13.540 --> 00:00:17.840
I'm a manager of the
Intel Compiler Software,

00:00:17.840 --> 00:00:21.610
sorry about that,
Technical Consulting and

00:00:21.610 --> 00:00:22.800
Support Team at Intel.

00:00:22.800 --> 00:00:26.060
And I'm Elizabeth Schneider,
and I'm a Technical Consulting

00:00:26.060 --> 00:00:29.340
Engineer and Manager in the
Intel Compiler Support Team.

00:00:29.340 --> 00:00:31.200
And welcome to our session.

00:00:31.200 --> 00:00:34.910
This is Using the
Intel Software Development Products for

00:00:34.910 --> 00:00:35.680
Mac OS X.

00:00:36.980 --> 00:00:38.700
You know, just wanted to say that,
you know,

00:00:38.700 --> 00:00:40.360
we are absolutely thrilled to be here.

00:00:40.360 --> 00:00:44.810
It's the first time attending WWDC,
and it's just been

00:00:44.920 --> 00:00:48.960
really exciting to see,
you know, just what you're doing with the

00:00:49.060 --> 00:00:52.240
new Intel-based Macs and just
the progress that you've made.

00:00:52.240 --> 00:00:54.360
This has just been
fabulous for us to see.

00:00:54.360 --> 00:00:58.700
I'd also like to thank our hosts,
you know, several people from

00:00:58.700 --> 00:01:00.510
Apple that we work with.

00:01:00.580 --> 00:01:04.820
Thank you for inviting us to the
conference and allowing us to speak here.

00:01:05.720 --> 00:01:07.560
Yeah, as I said,
it's just been a wonderful experience.

00:01:07.600 --> 00:01:10.420
But let's go ahead and just
see what it is that we're going

00:01:10.420 --> 00:01:12.000
to be talking about today.

00:01:12.000 --> 00:01:17.300
You know, so, you know, first,
I want to give you, you know,

00:01:17.300 --> 00:01:19.960
an understanding of the
software development products

00:01:19.960 --> 00:01:21.430
for the Mac OS X that we have.

00:01:21.440 --> 00:01:25.150
And I also want to spend a little bit
of time just explaining why Intel is

00:01:25.150 --> 00:01:27.090
in the software business at all.

00:01:27.120 --> 00:01:29.080
So we're going to spend
a little time there.

00:01:29.080 --> 00:01:33.350
Number two,
we're going to talk about how you can use

00:01:33.350 --> 00:01:36.300
these tools to build high-performance,
high-performance software.

00:01:36.300 --> 00:01:40.170
So looking at the unique performance
capabilities of the tools and just

00:01:40.390 --> 00:01:42.100
how you can use them in your software.

00:01:42.100 --> 00:01:45.270
And then thirdly,
we're going to look at multi-threading.

00:01:45.280 --> 00:01:50.330
You know, with the dual-core capabilities
of the Intel Core Duo,

00:01:50.330 --> 00:01:53.890
Core 2 Duo processors,
we want to make sure that you

00:01:53.890 --> 00:01:57.470
understand some of the threading
capabilities that we have in the

00:01:57.470 --> 00:02:00.810
tools and some of the techniques that
you can use to take advantage of that.

00:02:02.800 --> 00:02:06.310
Now, the way this is going to work,
I'm going to be up here talking and

00:02:06.310 --> 00:02:09.600
hand-waving and doing some things,
and Elizabeth is going

00:02:09.600 --> 00:02:10.760
to be running demos.

00:02:10.760 --> 00:02:13.600
She's going to keep me honest,
showing you that I'm just

00:02:13.600 --> 00:02:15.050
not making this stuff up.

00:02:15.080 --> 00:02:17.950
So, you know,
we're going to have a bunch of demos

00:02:18.020 --> 00:02:21.700
of different of the techniques and the
things that we're showing you here.

00:02:21.700 --> 00:02:25.590
At the end of this,
we should have plenty of time for Q&A,

00:02:25.590 --> 00:02:30.960
and we're looking forward to, you know,
interacting with you some more.

00:02:31.600 --> 00:02:34.980
We are also in the
performance lab downstairs.

00:02:34.980 --> 00:02:37.680
There's Elizabeth and I,
as well as a number of other

00:02:37.680 --> 00:02:41.620
people from the development team
and other of the tools teams,

00:02:41.620 --> 00:02:45.770
as well as some application engineers
that have had a lot of experience

00:02:45.850 --> 00:02:50.270
helping port and tune applications
for the Mac on the Intel-based Macs.

00:02:50.320 --> 00:02:53.660
So, we're looking forward to talking
with you some more there.

00:02:56.920 --> 00:02:59.730
Now, to start, I have a question.

00:02:59.820 --> 00:03:03.360
How many of you knew that
Intel is a software company?

00:03:04.710 --> 00:03:07.170
Wow, okay, that's amazing.

00:03:07.180 --> 00:03:08.430
A software company in Intel.

00:03:08.440 --> 00:03:10.800
I wasn't sure if, yeah,
I just wasn't sure what the

00:03:10.800 --> 00:03:12.510
reaction was going to be to that.

00:03:12.510 --> 00:03:17.440
Now, how many of you knew that we have,
you know, Intel compilers, libraries,

00:03:17.440 --> 00:03:19.820
or software development products?

00:03:19.820 --> 00:03:20.860
Okay.

00:03:20.860 --> 00:03:22.500
Oh, very good, very good.

00:03:23.240 --> 00:03:26.040
Okay, that's, I was,
I had no idea what the response

00:03:26.040 --> 00:03:28.160
to that question was going to be.

00:03:28.160 --> 00:03:31.270
That's great to hear that
you've heard about us.

00:03:31.270 --> 00:03:34.390
But, you know, still,
I want to give you a little bit of

00:03:34.390 --> 00:03:38.600
background of just why we're here and
why software is important to Intel and

00:03:38.600 --> 00:03:41.260
why we're in the software tools business.

00:03:41.260 --> 00:03:44.010
You know,
we know our processors very well,

00:03:44.010 --> 00:03:48.870
and we want to make sure that you get the
maximum performance on your application

00:03:48.870 --> 00:03:51.180
utilizing the Intel processors.

00:03:51.180 --> 00:03:53.020
So, we don't want you to leave.

00:03:53.020 --> 00:03:56.850
Any performance on the table when
you're developing your applications,

00:03:56.890 --> 00:04:01.080
because performance translates into
better user experience and just better,

00:04:01.080 --> 00:04:03.890
you know,
just a more pleasant experience with the,

00:04:03.890 --> 00:04:05.370
you know, with the max.

00:04:05.420 --> 00:04:10.460
So we want to make sure that you have
the tools and support and services

00:04:10.460 --> 00:04:12.710
that you need to do just that.

00:04:12.800 --> 00:04:17.010
We've been in the software business
for quite a number of years developing

00:04:17.010 --> 00:04:19.120
these tools just for that reason.

00:04:19.200 --> 00:04:23.040
We've also put together, you know,
a whole host of other.

00:04:23.040 --> 00:04:26.950
Services, you know, around, you know,
not just the software products,

00:04:26.950 --> 00:04:29.590
but around the capabilities
that we have in terms of

00:04:29.590 --> 00:04:31.430
tuning and porting experience.

00:04:31.540 --> 00:04:35.370
And, you know, so things like the
Intel software network,

00:04:35.370 --> 00:04:39.670
which is a web based community for
developers consisting of various

00:04:39.670 --> 00:04:44.100
user forums and blogs and just trying
to get trying to bring developers

00:04:44.100 --> 00:04:48.650
software developers together for
Intel's products or platforms.

00:04:48.760 --> 00:04:52.160
The Intel software college, which is.

00:04:52.160 --> 00:04:52.460
A.

00:04:52.460 --> 00:04:57.180
Training courses that we can do
on a wide range of topics around

00:04:57.360 --> 00:05:00.880
our software around performance
tuning for different processors.

00:05:00.880 --> 00:05:05.350
To early access programs looking at,
you know, early, you know,

00:05:05.540 --> 00:05:09.400
early Intel hardware and
to Intel solution services.

00:05:09.400 --> 00:05:13.720
This is providing consulting services to
help you port and tune your applications.

00:05:13.720 --> 00:05:18.420
So it's all predicated on the fact
that we know our processors well and

00:05:18.420 --> 00:05:22.120
that we want to make sure that you
are getting the most performance.

00:05:22.460 --> 00:05:24.700
So we want to make sure that you are
getting the most performance possible

00:05:24.800 --> 00:05:27.340
out of your out of the Intel processors
for your applications on the Max.

00:05:27.340 --> 00:05:29.520
And, you know,
to kick this off and just to

00:05:29.550 --> 00:05:31.870
illustrate what I'm talking about here.

00:05:31.880 --> 00:05:33.880
I wanted to show our first demo.

00:05:34.000 --> 00:05:36.590
Elizabeth, if you want to.

00:05:37.840 --> 00:05:43.400
Okay, what I have here is I'm going
to be bringing up two windows.

00:05:43.400 --> 00:05:46.800
And on the right, this is the POVray.

00:05:46.800 --> 00:05:52.600
It's the open source ray tracer,
and it's showing an image

00:05:52.600 --> 00:05:53.600
that's being rendered.

00:05:53.600 --> 00:05:59.990
And on the right-hand side is showing
that rendering under GCC 4.0.1.

00:06:00.000 --> 00:06:03.070
It's using the best options
for the GNU compiler.

00:06:03.120 --> 00:06:07.100
And on the left-hand side -- oh,
it already finished.

00:06:07.100 --> 00:06:08.890
Well, it's going to restart again.

00:06:09.000 --> 00:06:12.980
Took about 20 seconds to run
with the Intel C++ Compiler.

00:06:13.030 --> 00:06:15.090
This is version 9.1.

00:06:15.140 --> 00:06:19.270
And again, it's using the best options
for the Intel C++ Compiler.

00:06:19.340 --> 00:06:22.720
And as you can see,
it's about a 20% speedup in

00:06:22.720 --> 00:06:27.220
performance running on the Intel C++
Compiler versus the version

00:06:27.220 --> 00:06:29.290
compiled with the GCC Compiler.

00:06:29.360 --> 00:06:33.600
So that was about -- so about 20
seconds for the ICC rendering,

00:06:33.600 --> 00:06:36.390
and I think I saw it around 29
seconds for the GCC rendering.

00:06:36.400 --> 00:06:40.390
So, you know,
about a 25% or 30% performance speedup.

00:06:40.400 --> 00:06:44.400
And so if we go ahead and
flip back to the slides,

00:06:44.400 --> 00:06:46.400
you know,
that's -- so that's why we're here.

00:06:46.400 --> 00:06:49.010
We want to make sure that, you know,
you don't leave any

00:06:49.010 --> 00:06:52.370
performance on the table,
that you're getting the maximum

00:06:52.520 --> 00:06:55.900
that you can out of these
Intel processor-based Macs.

00:06:55.900 --> 00:06:59.900
And, you know, this -- the application
we were showing is,

00:06:59.900 --> 00:07:01.400
you know, it's just one application.

00:07:01.400 --> 00:07:04.400
We're not saying that it's, you know,
indicative of everything that

00:07:04.400 --> 00:07:05.700
you're going to run into.

00:07:05.700 --> 00:07:08.110
Your mileage is certainly
going to vary from different

00:07:08.130 --> 00:07:09.680
applications and benchmarks.

00:07:09.720 --> 00:07:11.910
You know,
but we just want to make sure that you

00:07:11.920 --> 00:07:15.700
have some tools available to make sure
that you are getting that performance.

00:07:18.920 --> 00:07:23.760
So, now moving into the software
development tools themselves,

00:07:23.830 --> 00:07:26.440
there's really three
guiding principles for us.

00:07:26.680 --> 00:07:31.170
Number one, as I mentioned, performance,
just making use of the processor,

00:07:31.330 --> 00:07:36.310
threading capability is a good example
of some of the new capabilities

00:07:36.310 --> 00:07:38.760
of the dual-core processors.

00:07:38.900 --> 00:07:40.810
Compatibility is another one.

00:07:40.860 --> 00:07:44.700
Now, we know that in order for you to
adopt our tools or use our tools,

00:07:44.700 --> 00:07:48.530
it's got to be as easy as
possible for you to use them in

00:07:48.530 --> 00:07:49.980
your development environment.

00:07:50.160 --> 00:07:57.520
So we've worried a lot about integration
into Xcode and complete interoperability

00:07:57.530 --> 00:08:01.550
with GCC and interoperability with
GDB so that you can even mix and

00:08:01.550 --> 00:08:09.660
match binaries built with GCC and ICC,
ICC being the Intel Compiler,

00:08:09.710 --> 00:08:15.900
and with very little to no
changes to your Makefiles,

00:08:15.940 --> 00:08:18.880
to your existing Xcode projects.

00:08:18.920 --> 00:08:23.050
So compatibility is
extremely important to us.

00:08:23.320 --> 00:08:25.770
And then the third guiding
principle is support.

00:08:25.810 --> 00:08:29.340
You know,
we have software experts that are

00:08:29.340 --> 00:08:32.750
available for training and for support
and just making sure that the experience

00:08:32.820 --> 00:08:36.050
with your tools is what you would expect.

00:08:36.070 --> 00:08:37.980
So that's why we're in
the software business:

00:08:38.030 --> 00:08:41.530
performance, compatibility, and support.

00:08:43.160 --> 00:08:45.500
Now here's the products.

00:08:45.560 --> 00:08:48.640
So first, the Intel compilers.

00:08:48.640 --> 00:08:52.040
That's our Intel Fortran
as well as C++ compilers.

00:08:52.300 --> 00:08:55.810
The performance libraries,
there's two that we're talking about.

00:08:55.880 --> 00:08:59.960
This is the Intel Integrated
Performance Primitives,

00:08:59.960 --> 00:09:04.920
set of highly optimized threaded
functions dealing primarily with

00:09:04.920 --> 00:09:07.190
some multimedia applications.

00:09:07.300 --> 00:09:09.070
I'll get into a little
bit more detail later.

00:09:09.250 --> 00:09:15.090
And then the Math Kernel Library for
more scientific applications.

00:09:15.630 --> 00:09:19.840
A new, what we're calling a new
threading methodology for C++.

00:09:19.900 --> 00:09:22.900
Now, you notice here there's
no name on the box.

00:09:22.900 --> 00:09:26.300
And, well, as I, you know,
we just talked about Intel being a,

00:09:26.300 --> 00:09:28.980
you know,
a hardware and a software company.

00:09:28.980 --> 00:09:32.770
Well, we have a lot of
marketing and legal folks,

00:09:32.770 --> 00:09:36.450
too,
and they haven't come up with a name yet.

00:09:36.490 --> 00:09:38.480
And they've been worried,
trying to decide on

00:09:38.480 --> 00:09:39.690
one for several months.

00:09:39.700 --> 00:09:42.570
And, yeah, marketing and legal,
you can't live with them,

00:09:42.620 --> 00:09:44.440
can't live without them, I guess.

00:09:46.930 --> 00:09:53.170
Anyway, it's all about, again,
bringing the performance to the Mac OS X.

00:09:54.930 --> 00:09:57.510
So, I'll go into a little bit
more detail then on what the

00:09:57.510 --> 00:10:00.630
compilers are about here.

00:10:00.670 --> 00:10:05.770
So, first of all, how many people here
are Fortran programmers?

00:10:06.820 --> 00:10:09.440
Okay, there's a, all right, there's,
you know,

00:10:09.560 --> 00:10:10.890
someone waving his hand in the front row.

00:10:10.890 --> 00:10:14.810
Okay, so maybe about 20 or so.

00:10:14.810 --> 00:10:16.390
Okay, C++.

00:10:18.220 --> 00:10:20.100
Okay, pretty much everybody else.

00:10:20.100 --> 00:10:20.780
All right.

00:10:20.810 --> 00:10:26.090
Let's see, how about Objective-C?

00:10:26.490 --> 00:10:28.860
Okay, a lot there, kind of in between,
yeah.

00:10:28.860 --> 00:10:32.580
All right, okay,
just wanted to get a feel for that.

00:10:32.600 --> 00:10:37.800
So our Fortran Compiler
supports all the basic,

00:10:37.800 --> 00:10:39.900
all the, you know,
the common standards now,

00:10:39.900 --> 00:10:43.040
or the standards now,
except we have not implemented

00:10:43.040 --> 00:10:44.980
all of Fortran 2003.

00:10:44.980 --> 00:10:47.080
That's going to be a while.

00:10:47.080 --> 00:10:51.150
There's some object-oriented
features in Fortran 2003 that,

00:10:51.150 --> 00:10:52.920
you know, we're looking at.

00:10:53.060 --> 00:10:56.620
We don't know when we'll be able
to get some of those implemented.

00:10:56.620 --> 00:11:01.700
But 77, 90, 95,
and then some other common extensions

00:11:01.700 --> 00:11:05.280
that you see in a lot of scientific
computing and various applications.

00:11:05.280 --> 00:11:10.180
The C++ Compiler is fully
ANSI ISO compatible.

00:11:11.600 --> 00:12:16.200
[Transcript missing]

00:12:18.500 --> 00:12:23.180
Then the next set of optimizations are
really oriented around multi-threading.

00:12:23.180 --> 00:12:26.260
So we'll get in a little bit more
detail later in the presentation.

00:12:26.290 --> 00:12:32.300
Auto-parallelization, OpenMP,
the OpenMP standard for the multi-core.

00:12:32.300 --> 00:12:36.280
And then we also care a lot about making
sure that for floating-point applications

00:12:36.280 --> 00:12:40.880
or floating-point intensive applications,
you have some ways of controlling

00:12:40.880 --> 00:12:43.320
precision versus optimization.

00:12:43.320 --> 00:12:45.660
And there are some models
that you can specify there.

00:12:47.000 --> 00:12:50.370
Other things that are,
two other tools that are in the

00:12:50.370 --> 00:12:52.480
package in the compiler product.

00:12:52.830 --> 00:12:55.650
With our code coverage
and test prioritization,

00:12:55.650 --> 00:12:59.500
what these are, they are,
these are tools that will

00:12:59.500 --> 00:13:02.620
use the profile-guided data,
so the runtime feedback that we get

00:13:02.620 --> 00:13:07.800
through the profile-guided optimization,
and be able to pinpoint functions and

00:13:07.800 --> 00:13:13.040
basic blocks within those functions
that have been hit or touched by,

00:13:13.040 --> 00:13:17.020
you know, the,
whatever your QA tests are, for example.

00:13:17.260 --> 00:13:20.700
So, depending on the workloads that you
provide your application in your testing,

00:13:20.700 --> 00:13:23.500
we can then provide you
information about the coverage,

00:13:23.500 --> 00:13:26.190
how well you tested,
as well as offer advice on

00:13:26.190 --> 00:13:29.690
which applications or which
tests did better or worse,

00:13:29.690 --> 00:13:32.400
and help you with that prioritization.

00:13:32.400 --> 00:13:35.190
So, it's a little bit,
it's an interesting use of the

00:13:35.190 --> 00:13:37.010
runtime feedback that we get.

00:13:37.040 --> 00:13:40.000
And then finally, the Intel Debugger.

00:13:40.000 --> 00:13:44.900
It's a highly, well, it's a,
it's a debugger, GDB compatible,

00:13:44.900 --> 00:13:47.180
command line compatible.

00:13:47.260 --> 00:13:51.480
Intended for, you know, primarily,
you know, very good with optimized

00:13:51.480 --> 00:13:53.300
and threaded applications.

00:13:53.300 --> 00:13:56.320
So, it's very good for debugging
those types of applications.

00:13:56.320 --> 00:14:00.660
Now,
a little bit more on the environment.

00:14:00.900 --> 00:16:11.800
[Transcript missing]

00:16:12.800 --> 00:16:17.940
And then finally, universal binaries.

00:16:17.940 --> 00:16:22.460
We are only an Intel processor
targeting compiler.

00:16:22.460 --> 00:16:24.270
We don't support PowerPC.

00:16:24.480 --> 00:16:28.450
So for universal binaries,
you can build the

00:16:28.450 --> 00:16:32.860
PowerPC version with GCC,
build the Intel version with ICC,

00:16:33.080 --> 00:16:37.580
and then using either Xcode
or LiPo from the command line,

00:16:37.580 --> 00:16:39.770
you can build your
universal binary that way.

00:16:39.900 --> 00:16:42.680
So we work out of Xcode.

00:16:42.680 --> 00:16:46.430
We are trying to be completely
interoperable with GCC in

00:16:46.430 --> 00:16:47.480
the Xcode environment.

00:16:47.480 --> 00:16:50.770
And that's some of our
guiding principles there.

00:16:52.100 --> 00:16:55.800
And then this slide,
so this is just an example

00:16:55.800 --> 00:16:56.700
of some more performance.

00:16:56.700 --> 00:17:03.090
We're looking at specint, rate,
and specfp, the ICC 9.1 compiler on the

00:17:03.090 --> 00:17:05.560
Core Duo processor on Mac OS X.

00:17:05.560 --> 00:17:08.860
This is something we
measured this past spring,

00:17:08.860 --> 00:17:11.820
compared to the GCC 4.0 compiler.

00:17:11.820 --> 00:17:14.760
And we're running at,
this is a comparison of what

00:17:14.760 --> 00:17:16.540
we call base optimization.

00:17:16.540 --> 00:17:19.490
And really what that means is
the best optimizations that

00:17:19.510 --> 00:17:21.250
we can find on both compilers.

00:17:21.900 --> 00:17:26.900
And in specint, specint rate,
it's about a 50% faster.

00:17:27.020 --> 00:17:30.920
In specfp, it's about 47% faster.

00:17:30.970 --> 00:17:34.520
So, you know, again,
this is just a benchmark.

00:17:34.520 --> 00:17:38.720
Your mileage is gonna vary, but this is,
you know, this is something that,

00:17:38.720 --> 00:17:41.640
you know,
that we are concerned about and making

00:17:41.640 --> 00:17:47.920
sure that we maintain a performance lead
and that you get the best performance

00:17:47.920 --> 00:17:49.700
possible for your applications.

00:17:49.700 --> 00:17:56.760
And this is an example of how, you know,
of where we are today versus GCC.

00:17:57.650 --> 00:18:00.940
So that was the compilers.

00:18:00.940 --> 00:18:02.780
Excuse me.

00:18:03.300 --> 00:18:05.460
So the Intel Performance Libraries.

00:18:05.460 --> 00:18:10.800
So the two libraries... Excuse me.

00:18:10.910 --> 00:18:11.300
Yep.

00:18:21.750 --> 00:18:26.880
So first, the Intel Integrated
Performance Primitives.

00:18:27.140 --> 00:18:30.490
So as I mentioned,
these are the libraries that we

00:18:30.520 --> 00:18:35.740
produced are intended for some
specific application domains.

00:18:35.750 --> 00:18:40.300
And for IPP,
or the Integrated Performance Libraries,

00:18:40.300 --> 00:18:45.300
these are highly tuned for the
function domains of signal processing,

00:18:45.300 --> 00:18:50.290
digital imaging, cryptography,
a whole host of different

00:18:50.330 --> 00:18:51.480
functional domains.

00:18:51.480 --> 00:18:55.610
And just like MKL,
these libraries are already threaded.

00:18:55.620 --> 00:18:59.300
And so at runtime,
the libraries will determine what

00:18:59.300 --> 00:19:04.900
sort of processor you're running on,
whether it's a Core Solo or Core Duo,

00:19:04.900 --> 00:19:06.740
and be able to implement the right thing.

00:19:06.740 --> 00:19:10.180
And also,
even from the Core to the Core 2

00:19:10.180 --> 00:19:13.260
microprocessor is the same thing.

00:19:13.260 --> 00:19:15.420
It can detect which
one you're running on,

00:19:15.430 --> 00:19:17.740
so you don't have to worry
about porting your application.

00:19:17.740 --> 00:19:21.150
It's just the library at runtime
will detect which processor

00:19:21.270 --> 00:19:23.040
and do the right thing there.

00:19:23.040 --> 00:19:24.130
Now,
MKL is targeted for the scientific side.

00:19:24.140 --> 00:19:25.140
And so it's a little bit more
complex than the other libraries.

00:19:25.140 --> 00:19:25.180
But it's a little bit more
complex than the other libraries.

00:19:25.180 --> 00:19:25.200
And so at runtime,
the libraries will determine what

00:19:25.200 --> 00:19:25.210
sort of processor you're running on,
whether it's a Core Solo or Core Duo,

00:19:25.210 --> 00:19:25.380
and be able to implement the right thing.

00:19:25.380 --> 00:19:25.380
And also,
even with the core to the Core 2

00:19:25.380 --> 00:19:25.460
microprocessor is the same thing.

00:19:25.480 --> 00:19:28.760
applications, you know,
basic linear algebra libraries,

00:19:28.760 --> 00:19:34.520
SPAR solvers, FFTs, you know, it's,
again, all of these are threaded.

00:19:34.520 --> 00:19:38.820
The team spends a lot of time just,
you know,

00:19:38.820 --> 00:19:43.170
looking at these guys just love assembly,
and it's going to be,

00:19:43.170 --> 00:19:45.620
it's pretty hard to beat them.

00:19:45.620 --> 00:19:48.910
As we're going to see in our example,
you know, even the compiler with full

00:19:48.910 --> 00:19:52.100
vectorization and optimization,
it's pretty hard to beat, say,

00:19:52.200 --> 00:19:55.620
MKL in some examples here.

00:19:55.620 --> 00:19:58.290
So, you know, we'll see that.

00:19:59.330 --> 00:20:01.530
And I said they're already threaded.

00:20:01.540 --> 00:20:06.740
So this is an example of just
the scaling that you can see with

00:20:06.800 --> 00:20:12.350
MKL going from a single threaded to
two threads on a Core Duo processor.

00:20:12.380 --> 00:20:15.860
And you can see that when you get into,
this is for a matrix multiply,

00:20:15.860 --> 00:20:17.920
a double precision matrix multiply.

00:20:17.920 --> 00:20:20.820
And when you get into
the higher matrix sizes,

00:20:20.820 --> 00:20:24.230
we get almost perfect scaling
going from about one and a

00:20:24.230 --> 00:20:26.200
half gigaflops up to three.

00:20:26.710 --> 00:20:32.440
So again, this is,
the libraries provide you with a way

00:20:32.440 --> 00:20:37.510
to get arguably the best and optimal
performance as well as threaded

00:20:37.520 --> 00:20:39.520
performance out of these applications.

00:20:39.520 --> 00:20:44.350
So with that,
I want to go ahead and we'll do a

00:20:44.820 --> 00:20:48.780
demo of our integration into Xcode.

00:20:48.780 --> 00:20:53.410
And before we switch to the MacBook,
oops, we already switched.

00:20:53.420 --> 00:20:53.800
Okay.

00:20:55.500 --> 00:20:58.940
uh... could we have the
presentation back please

00:21:00.480 --> 00:21:00.770
Thank you.

00:21:00.950 --> 00:21:01.160
Okay.

00:21:01.160 --> 00:21:04.440
So before we go to the demo,
we just wanted to show you

00:21:04.440 --> 00:21:05.520
what code we're working on.

00:21:05.520 --> 00:21:09.200
This is just a simple matrix multiply.

00:21:09.200 --> 00:21:12.260
You can see we're, you know,
at the top or in the middle

00:21:12.260 --> 00:21:16.180
is a triple nested loop where
we're doing the matrix multiply.

00:21:16.180 --> 00:21:18.350
The arrays are a size about 800.

00:21:18.360 --> 00:21:20.210
I think they're all 800.

00:21:20.220 --> 00:21:22.950
And what we're going to be
doing is showing the compiler,

00:21:22.950 --> 00:21:26.400
or we're going to be showing some
things with the Xcode integration.

00:21:26.450 --> 00:21:28.580
And then as we go
through the presentation,

00:21:28.580 --> 00:21:32.860
we'll be optimizing this with
the Compilers Vectorizer and MKL,

00:21:32.860 --> 00:21:34.820
and we'll see how we do as we go.

00:21:34.820 --> 00:21:35.460
Okay.

00:21:37.110 --> 00:21:37.600
Great.

00:21:37.600 --> 00:21:38.560
Well, look at this.

00:21:38.560 --> 00:21:42.210
I brought up the Xcode,
and I happen to have that same source

00:21:42.220 --> 00:21:44.140
that Joe just showed in the presentation.

00:21:44.160 --> 00:21:45.680
And I wanted to take a look at it.

00:21:45.680 --> 00:21:46.810
It is the same source.

00:21:46.820 --> 00:21:51.570
We'll have two different code
paths here defined by an ifdef,

00:21:51.700 --> 00:21:52.520
the MKL.

00:21:52.520 --> 00:21:53.720
So I want to point this out.

00:21:53.780 --> 00:21:56.260
We'll be using it throughout
the demo this afternoon.

00:21:56.260 --> 00:22:00.780
I want to first give you a little bit of
overview of our integration with Xcode.

00:22:00.780 --> 00:22:04.800
And I'll go ahead and bring up the
target window and take a look at that.

00:22:05.340 --> 00:22:08.160
As you can see,
we have the Intel C++ Compiler

00:22:08.160 --> 00:22:10.160
here under the collections.

00:22:10.160 --> 00:22:12.680
And we have several subsets,
and I'll go through

00:22:12.680 --> 00:22:14.000
just a couple of them.

00:22:14.000 --> 00:22:17.040
First, there's the general,
and here you can set

00:22:17.040 --> 00:22:18.880
your optimization level.

00:22:18.880 --> 00:22:22.840
I have it set for dash O2,
which is optimized for speed.

00:22:22.840 --> 00:22:25.510
This is our default optimization.

00:22:25.520 --> 00:22:28.870
If you were to compile at the
command line and you didn't

00:22:28.870 --> 00:22:32.140
specify any optimization,
you would get dash O2,

00:22:32.140 --> 00:22:34.020
which is optimized for speed.

00:22:34.020 --> 00:22:39.080
You can... compile with dash
O0 with no optimizations,

00:22:39.190 --> 00:22:44.130
or O1 for size, or you can add O3,
which is the maximized speed

00:22:44.200 --> 00:22:46.070
with high level optimizations.

00:22:46.080 --> 00:22:50.060
Now, I also wanted to show
you the optimizations.

00:22:50.120 --> 00:22:54.110
We have a checkbox here that I'll
be showing a little bit later in the

00:22:54.110 --> 00:22:56.490
presentation for parallelization.

00:22:56.580 --> 00:23:02.950
We also have the preprocessor,
where we'll be setting our preprocessor

00:23:02.950 --> 00:23:04.600
definition for MKL as well.

00:23:05.180 --> 00:23:07.630
And finally,
one more I want to show you is

00:23:07.630 --> 00:23:10.620
the diagnostics reports that
you can get from the compiler.

00:23:10.620 --> 00:23:13.620
There's an auto-parallelizer report,
and I'll be showing

00:23:13.620 --> 00:23:15.040
that a little bit later.

00:23:15.040 --> 00:23:18.960
And then there's a report of
vectorization diagnostics.

00:23:18.960 --> 00:23:21.250
Right now,
I have that set to VEC report 2,

00:23:21.250 --> 00:23:24.020
and I'll be showing those
configurations as well.

00:23:24.020 --> 00:23:26.700
So let's go ahead and
run our application.

00:23:26.710 --> 00:23:29.980
We're going to bring up
the build results window.

00:23:29.980 --> 00:23:32.080
Now,
go ahead and do a clean just to make sure

00:23:32.080 --> 00:23:34.220
there's nothing lurking on the system.

00:23:35.220 --> 00:23:37.650
I'm building at the
default optimization level,

00:23:37.740 --> 00:23:39.710
so let me go ahead and do that build.

00:23:41.720 --> 00:23:42.440
And that build's done.

00:23:42.440 --> 00:23:45.400
Let's go ahead and run the application.

00:23:45.570 --> 00:23:48.890
So this is a small matrix multiply.

00:23:50.740 --> 00:23:52.040
And it doesn't take too long.

00:23:52.040 --> 00:23:54.340
There we go.

00:23:54.340 --> 00:23:59.790
It finishes in about 8.93 seconds,
so about approximately nine seconds.

00:24:04.710 --> 00:24:10.860
I see there's some messages that
something didn't get vectorized.

00:24:10.980 --> 00:24:13.080
Yeah,
we'll talk about that in a few minutes,

00:24:13.080 --> 00:24:13.520
Joe.

00:24:13.520 --> 00:24:15.660
So hold that thought for just a minute.

00:24:15.660 --> 00:24:19.710
Well, so are you going to be able to
do better than 8.93 seconds,

00:24:19.710 --> 00:24:20.660
do you think?

00:24:20.660 --> 00:24:22.820
In fact, yes,
I will be able to do better.

00:24:22.820 --> 00:24:23.890
Okay, okay.

00:24:23.890 --> 00:24:27.860
All right, well,
just take that matrix multiplier.

00:24:27.860 --> 00:24:29.080
We ought to be able to
do a little bit better.

00:24:29.080 --> 00:24:29.440
Okay.

00:24:29.440 --> 00:24:32.190
All right, thank you.

00:24:33.840 --> 00:24:35.180
So let's go back to the slides.

00:24:35.180 --> 00:24:35.640
There we go.

00:24:35.680 --> 00:24:37.440
OK.

00:24:37.440 --> 00:24:39.360
All right,
so now we're going to talk about

00:24:39.360 --> 00:24:44.160
just how we use the compilers in the
libraries to get this performance.

00:24:44.980 --> 00:24:52.900
Now, the first thing is with the core
architecture and the Core 2 architecture,

00:24:53.050 --> 00:24:59.290
the key for performance is,
especially for computationally

00:24:59.330 --> 00:25:01.590
intensive applications,
is utilizing the

00:25:01.590 --> 00:25:03.510
streaming SIMD extensions.

00:25:03.540 --> 00:25:08.420
This is the instructor set architecture
that consists of a number of instructions

00:25:08.420 --> 00:25:13.980
that deal with single instruction,
multiple data types,

00:25:14.060 --> 00:25:17.570
as well as the operations therein,
and as well as the register set

00:25:17.570 --> 00:25:19.490
that holds these data types.

00:25:19.500 --> 00:25:25.170
Now, the data types that we're
talking about are anywhere from

00:25:25.510 --> 00:25:31.220
integers from chars to short,
int, long, as well as even up to 128-bit

00:25:31.220 --> 00:25:33.440
integer for some logical operations.

00:25:33.540 --> 00:25:37.850
And then for floating point,
what's encapsulated by the

00:25:37.890 --> 00:25:42.760
SSE instruction set and register
set are the single precision or

00:25:42.760 --> 00:25:45.700
double precision floating point.

00:25:45.720 --> 00:25:51.900
So the challenge for the compiler is to
convert your loops or different parts

00:25:51.900 --> 00:25:57.140
of your application into the SSE code,
and that's what the process

00:25:57.470 --> 00:25:59.390
of vectorization is.

00:25:59.420 --> 00:26:01.840
Now, there are other methods.

00:26:01.840 --> 00:26:03.520
And I think on the PowerShell,
there's a lot of other methods.

00:26:03.520 --> 00:26:07.480
PowerPC with AltaVec,
you could use Intrinsics or Assembly.

00:26:07.480 --> 00:26:13.640
Both of those are available with the
Intel compiler and on the IMAX today.

00:26:13.640 --> 00:26:21.860
However, the recommended way is using the
Intrinsics or the Vectorizer.

00:26:21.860 --> 00:26:25.680
We don't want you writing in
Assembly unless you absolutely have to.

00:26:25.680 --> 00:26:27.220
It's just not a portable way to go.

00:26:27.220 --> 00:26:30.810
So let's look at how vectorization works.

00:26:32.510 --> 00:26:34.480
You know, it's really, you know,
the case where we want the

00:26:34.540 --> 00:26:35.460
compiler to do the work.

00:26:35.460 --> 00:26:40.650
And what you need to worry about with
vectorization and what the compiler

00:26:40.650 --> 00:26:44.440
needs to worry about primarily is just,
you know,

00:26:44.440 --> 00:26:48.690
how to break what's called memory,
you know, just memory dependencies,

00:26:48.690 --> 00:26:51.320
you know,
across iterations of the loops or,

00:26:51.320 --> 00:26:53.880
you know,
just amongst the data that one sees

00:26:53.880 --> 00:26:56.380
or that the compiler sees in the loop.

00:26:57.400 --> 00:27:01.170
So the compiler has to worry about,
you know, iteration dependence, you know,

00:27:01.170 --> 00:27:03.080
is the data,
is data written or read in one

00:27:03.080 --> 00:27:04.920
iteration that's used in the next?

00:27:04.920 --> 00:27:10.170
Or if there's, you know,
memory disambiguation or pointer

00:27:10.180 --> 00:27:13.860
aliasing that will prevent,
you know,

00:27:13.860 --> 00:27:18.400
that will cause the compiler to have to
err on the conservative side and just

00:27:18.400 --> 00:27:23.330
assume that there's a dependence here
and not be able to vectorize the loop.

00:27:23.340 --> 00:27:25.110
You know, we also have to look at,
you know,

00:27:25.110 --> 00:27:29.400
whether there's enough work in the loop
to... to warrant doing the vectorization.

00:27:29.500 --> 00:27:33.400
So there's some things that we have to...
that the compiler has to worry about.

00:27:33.540 --> 00:27:38.630
You know, there's other things like,
you know, well, fortunately with some

00:27:38.630 --> 00:27:41.820
of the transcendentals,
so if you have calls to various

00:27:41.880 --> 00:27:45.960
intrinsics in your functions like sine,
cosine, etc., you know,

00:27:45.960 --> 00:27:49.400
the compiler can also deal with
those and vectorize those through

00:27:49.400 --> 00:27:52.200
what we call the... our small,
our short vector math library

00:27:52.200 --> 00:27:57.190
that's part of the MKL that
actually ships with the compiler.

00:27:57.470 --> 00:28:02.940
So let's look at how you can understand
what some of these dependencies are

00:28:02.940 --> 00:28:06.580
when you do see these un-vectorized
messages like what we saw in the example.

00:28:06.580 --> 00:28:11.380
We have what we call our optimization
reports that will give you

00:28:11.380 --> 00:28:15.760
different levels of detail from yes,
it vectorized to no, it didn't,

00:28:15.760 --> 00:28:17.130
and here's exactly why.

00:28:17.140 --> 00:28:22.550
And we also have some pragmas or
directives that you can give to the

00:28:22.550 --> 00:28:26.040
compiler to give it hints on what to do.

00:28:26.430 --> 00:28:28.160
You know,
particularly when you're dealing

00:28:28.230 --> 00:28:32.610
with C++ and dealing with pointer
dereferencing or aliasing.

00:28:32.620 --> 00:28:36.150
You know, in some cases,
it's just a reason to program in Fortran,

00:28:36.150 --> 00:28:36.880
you know.

00:28:36.880 --> 00:28:39.200
You just don't have to worry
about pointers that way.

00:28:39.220 --> 00:28:42.660
But in reality, though, we do.

00:28:42.660 --> 00:28:47.730
And so you can use the IVDEP pragma
with C++ or with Fortran telling

00:28:47.730 --> 00:28:52.430
the compiler that without,
you know, that I know my code,

00:28:52.430 --> 00:28:55.280
don't worry about it, you know,
go ahead and vectorize my loop.

00:28:55.460 --> 00:29:02.230
And then for letting the compiler to
disambiguate between pointer references,

00:29:02.290 --> 00:29:04.720
we can use the restrict keyword.

00:29:04.720 --> 00:29:09.960
And that will tell the compiler that
the data to which this pointer points

00:29:10.190 --> 00:29:13.060
can only be accessed by this pointer.

00:29:13.060 --> 00:29:18.820
So it's just restricting the use of the
pointer and ensuring there's no aliasing.

00:29:21.710 --> 00:29:25.540
Now in the Intel Compiler,
as Elizabeth mentioned,

00:29:25.720 --> 00:29:28.700
the vectorizer is on by default.

00:29:28.710 --> 00:29:33.120
So at -02 is our default setting,
and so the vectorizer will be turned on.

00:29:33.120 --> 00:29:36.950
You can set different
optimization levels.

00:29:36.970 --> 00:29:41.200
01 is what we would call, you know,
optimize for size or, you know,

00:29:41.200 --> 00:29:42.270
smaller binaries.

00:29:42.280 --> 00:29:44.720
We won't do much inlining, for example.

00:29:45.480 --> 00:29:51.440
02 is where we'll do some higher-level
loop transformations to maybe be able to

00:29:51.440 --> 00:29:57.460
better vectorize your code or better lay
out your code for memory and cache usage.

00:29:57.550 --> 00:30:01.740
And then, of course, we have the advanced
optimization switches of IPO,

00:30:01.740 --> 00:30:05.100
the inter-procedural
optimization I mentioned earlier,

00:30:05.100 --> 00:30:09.660
the whole program optimization,
as well as profile-guided optimization,

00:30:09.660 --> 00:30:13.310
which is really intended or very
useful for branchy code or code

00:30:13.310 --> 00:30:15.460
devs to make a lot of difference.

00:30:15.480 --> 00:30:17.340
decisions.

00:30:17.710 --> 00:30:21.350
So that's how the compiler does it,
and we'll see the example of the

00:30:21.350 --> 00:30:22.620
vectorization here in a minute.

00:30:22.620 --> 00:30:28.020
For the libraries, it's pretty simple.

00:30:28.020 --> 00:30:32.120
You just replace whole sections of
code with a call to the library,

00:30:32.120 --> 00:30:34.490
and you let the library do the work.

00:30:34.560 --> 00:30:37.920
So here is an example
of a matrix multiply.

00:30:37.920 --> 00:30:41.040
Again,
we just replace it to the call to the

00:30:41.090 --> 00:30:46.800
CBLAS DGEM for the C version of the MKL,
or for the C version of the entry point.

00:30:47.600 --> 00:30:50.690
And again,
the libraries are going to arguably

00:30:50.690 --> 00:30:53.330
give you the best performance and,
of course,

00:30:53.410 --> 00:31:00.060
the best portability across processors,
as well as be already threaded for you.

00:31:00.060 --> 00:31:04.540
So with that,
let's go ahead and see how we can do on,

00:31:04.540 --> 00:31:09.590
we were at, let's see,
8.93 when we last left.

00:31:09.700 --> 00:31:11.180
That's right, Joe.

00:31:11.180 --> 00:31:13.280
And we had this message here.

00:31:13.280 --> 00:31:15.600
Loop was not vectorized.

00:31:16.240 --> 00:31:18.240
Consistence of vector dependence.

00:31:18.240 --> 00:31:22.290
Wow, that, I wonder if we can do better
in terms of a diagnostic.

00:31:22.360 --> 00:31:24.420
Well, it turns out that we can.

00:31:24.420 --> 00:31:27.480
Let me bring up the target
window again in diagnostics.

00:31:27.480 --> 00:31:31.300
And instead of vec report 2,
I'm going to go to vec report 3,

00:31:31.300 --> 00:31:35.920
which is going to give me some dependency
information diagnostics as well for

00:31:35.920 --> 00:31:38.320
those loops that did not vectorize.

00:31:38.380 --> 00:31:41.630
Let me go ahead and close this
and go back to my build results.

00:31:41.740 --> 00:31:44.960
And I'll do a clean because
I didn't actually touch the code.

00:31:45.120 --> 00:31:46.080
And now let me build.

00:31:46.240 --> 00:31:49.240
Oh, I've got another message now.

00:31:49.240 --> 00:31:53.450
Vector dependence assumed
anti-dependence between size 2,

00:31:53.450 --> 00:31:56.010
line 27, and z, line 28.

00:31:56.040 --> 00:31:58.180
I think it's time to
take a look at the code.

00:31:58.180 --> 00:32:00.000
So I'll bring that up here.

00:32:00.000 --> 00:32:03.220
And if you take a look at size 2,
it's here.

00:32:03.220 --> 00:32:05.340
And here's z that it's talking about.

00:32:05.340 --> 00:32:09.680
And then size 2, oh,
it happens to be a global variable.

00:32:09.680 --> 00:32:11.480
And we're passing in z.

00:32:11.480 --> 00:32:14.270
So the compiler is going
to play it conservative.

00:32:14.310 --> 00:32:16.220
It's not going to vectorize that loop.

00:32:16.220 --> 00:32:17.780
But hey, wait a second.

00:32:17.780 --> 00:32:21.080
I see an integer here
that's locally defined.

00:32:21.080 --> 00:32:21.940
Let's change.

00:32:21.940 --> 00:32:27.500
Let's use z2 instead of
size 2 and see what happens.

00:32:27.500 --> 00:32:29.460
So let me go ahead over here and build.

00:32:29.460 --> 00:32:31.370
And of course, I want to save.

00:32:31.440 --> 00:32:35.740
OK, so then let's go ahead and run this
now that I've made that change.

00:32:35.850 --> 00:32:36.270
Oh, look.

00:32:36.300 --> 00:32:38.460
And our message is now we've
got that loop vectorizing.

00:32:38.610 --> 00:32:39.800
So great.

00:32:39.800 --> 00:32:40.020
All right.

00:32:40.060 --> 00:32:40.640
All right.

00:32:40.640 --> 00:32:42.600
So let's go ahead and run.

00:32:42.600 --> 00:32:43.720
Good, good.

00:32:43.720 --> 00:32:44.360
That looks better.

00:32:47.100 --> 00:32:49.400
So, 4.78 seconds.

00:32:49.510 --> 00:32:52.900
So once we vectorize that
main loop in our application,

00:32:52.900 --> 00:32:57.000
we went from about 9 seconds to
a little less than 5 seconds.

00:32:57.070 --> 00:33:00.670
Now, if you remember the code,
we've got this set up so we

00:33:00.670 --> 00:33:04.990
could also call MKL instead of
our hand-coded matrix multiply.

00:33:05.030 --> 00:33:07.000
So I'd like to try that now.

00:33:07.000 --> 00:33:10.830
So I'm going to go back to here,
the targets, and I'm going to set the

00:33:10.830 --> 00:33:14.000
preprocessor to have MKL.

00:33:15.470 --> 00:33:23.800
Okay, and then go back here and do
another clean and a build.

00:33:23.800 --> 00:33:26.080
And then let's run it now.

00:33:28.700 --> 00:33:31.000
Oh, I think it finished on us.

00:33:31.060 --> 00:33:31.630
Scroll bar up.

00:33:31.760 --> 00:33:32.390
It did.

00:33:32.660 --> 00:33:34.460
Let me run it one more
time so you believe me,

00:33:34.460 --> 00:33:35.080
it did run.

00:33:35.080 --> 00:33:36.440
There we go.

00:33:36.440 --> 00:33:38.050
1.75 seconds.

00:33:38.150 --> 00:33:40.200
That's using the MKL library.

00:33:40.200 --> 00:33:43.870
So if we compare that with
our vectorized version,

00:33:43.920 --> 00:33:46.550
we were at 4.78 seconds.

00:33:46.600 --> 00:33:51.320
So using the MKL call for matrix
multiply significantly speeded

00:33:51.320 --> 00:33:53.600
up this small application.

00:33:54.200 --> 00:33:54.770
Wow.

00:33:54.770 --> 00:33:55.420
Okay.

00:33:55.580 --> 00:33:58.110
So from 8.93.

00:33:58.110 --> 00:34:00.440
All right.

00:34:01.470 --> 00:34:01.920
Excellent.

00:34:01.920 --> 00:34:04.810
Okay,
so 8.93 down to about less than five

00:34:04.810 --> 00:34:07.180
with the compiler's vectorization.

00:34:07.180 --> 00:34:12.250
Cut that in half, and then that was an
amazing speed-up by MKL.

00:34:12.260 --> 00:34:13.360
Good job, library guys.

00:34:13.440 --> 00:34:13.660
Yeah.

00:34:13.660 --> 00:34:16.770
Okay, well, thank you very much.

00:34:16.770 --> 00:34:17.960
Let's see.

00:34:20.510 --> 00:34:23.640
So let's move on to the next topic then.

00:34:23.750 --> 00:34:27.800
So multi-threading for dual-core.

00:34:27.800 --> 00:34:30.850
So I'm going to talk about three
things here-- auto parallelization,

00:34:30.850 --> 00:34:34.840
or what the compiler can do
automatically for you for parallelism.

00:34:34.840 --> 00:34:38.440
Then we'll talk about the OpenMP,
the OpenMP standard or

00:34:38.440 --> 00:34:40.150
directives that you can use.

00:34:40.380 --> 00:34:44.910
And then we'll talk about this
unnamed parallel programming model.

00:34:46.740 --> 00:34:49.200
So first, auto-parallelization.

00:34:49.200 --> 00:34:53.460
You know, this is kind of the holy
grail of compiler technology,

00:34:53.460 --> 00:34:56.880
you know, where the compiler will
do everything for you,

00:34:56.880 --> 00:34:58.700
and, you know,
including parallelize your loop.

00:34:58.700 --> 00:35:02.570
We've, you know,
over the last several decades, you know,

00:35:02.570 --> 00:35:05.430
probably back in the '70s,
when vectorization in

00:35:05.550 --> 00:35:09.020
the supercomputing world,
vectorization technology, you know,

00:35:09.020 --> 00:35:14.280
became prevalent and pretty well done,
it's always been, you know,

00:35:14.280 --> 00:35:17.500
the hope that, you know,
compilers could do just as well

00:35:17.500 --> 00:35:21.010
with auto-parallelization or just
being able to parallelize the

00:35:21.100 --> 00:35:23.150
loops as well as a vectorizer can.

00:35:23.360 --> 00:35:28.100
And, yeah,
I'm not gonna say that our compiler is,

00:35:28.150 --> 00:35:33.060
has achieved this state, you know,
but there are simple loops

00:35:33.060 --> 00:35:36.710
where the compiler can do this,
as we'll see in our example here.

00:35:36.920 --> 00:35:39.740
And it's something that
we're working very hard on.

00:35:39.740 --> 00:35:44.080
We are putting a lot of effort into our,
you know, our parallelization technology,

00:35:44.080 --> 00:35:46.670
and we wanna know when you do
have loops or applications that

00:35:46.670 --> 00:35:50.300
you think can be parallelized,
we wanna know about that to help get the,

00:35:50.300 --> 00:35:52.300
help move the technology along.

00:35:52.300 --> 00:35:56.130
So we'll see some,
see an example of this in a minute.

00:35:57.340 --> 00:36:02.700
But OpenMP, though,
is probably our recommended method

00:36:02.700 --> 00:36:04.260
of parallelizing applications.

00:36:04.260 --> 00:36:09.790
It's a very well-defined and well-known
standard that's been developed

00:36:09.790 --> 00:36:11.400
over the last several decades.

00:36:11.400 --> 00:36:17.060
You can see the entire documentation
of the standard and exactly

00:36:17.060 --> 00:36:19.900
how it works at www.openmp.org.

00:36:19.900 --> 00:36:22.810
But here's some examples
of what it looks like.

00:36:22.880 --> 00:36:25.420
How many here have used OpenMP?

00:36:26.640 --> 00:36:28.800
So there's a, okay, a few people.

00:36:28.800 --> 00:36:29.200
Very good.

00:36:29.200 --> 00:36:33.240
So it works for both Fortran and C++.

00:36:33.280 --> 00:36:39.530
And basically what you're doing is
providing hints to the compiler to say

00:36:39.530 --> 00:36:43.550
what sections of code to parallelize.

00:36:43.560 --> 00:36:48.280
And then it also provides
some different primitives,

00:36:48.280 --> 00:36:50.820
similar to what you would
do in any threading program,

00:36:50.820 --> 00:36:53.820
about locking,
defining critical sections,

00:36:53.820 --> 00:36:57.710
defining what data should be private,
or shared amongst tasks.

00:36:57.720 --> 00:37:02.500
And it's a fairly simple language
or set of directives that you

00:37:02.500 --> 00:37:04.980
can add to your application.

00:37:05.000 --> 00:37:09.100
And underlying it is a runtime
library that will do the scheduling

00:37:09.100 --> 00:37:12.000
and take care of all of that for you.

00:37:12.020 --> 00:37:17.760
So that was the example of a parallel,
the basic operations.

00:37:17.760 --> 00:37:23.460
It also defines other operations like
sum reductions or product reductions,

00:37:23.460 --> 00:37:25.860
a common loop construct.

00:37:25.860 --> 00:37:26.040
And I'll show you a little bit
more about that in a minute.

00:37:26.060 --> 00:37:29.430
in various applications.

00:37:29.440 --> 00:37:33.040
I said earlier, you know,
there are constructs for critical

00:37:33.040 --> 00:37:37.710
sections or defining what data
and when you want to lock it.

00:37:38.100 --> 00:39:57.400
[Transcript missing]

00:39:58.500 --> 00:40:05.070
And if you notice here,
we have some parallelization

00:40:05.500 --> 00:40:07.990
going on in the demo.

00:40:08.340 --> 00:40:09.680
Let me make sure it did.

00:40:09.680 --> 00:40:11.240
I was looking for one more message.

00:40:11.240 --> 00:40:14.440
Probably did not like me closing
out everything like that.

00:40:14.440 --> 00:40:17.800
So let me make sure we
got that set over here.

00:40:17.800 --> 00:40:18.780
There we go.

00:40:18.780 --> 00:40:21.800
We want that switch on as well,
and I think I forgot to do that.

00:40:21.840 --> 00:40:24.760
So let's do one more
time through this build.

00:40:29.160 --> 00:40:30.940
There we go, that's what I wanted to see.

00:40:30.940 --> 00:40:33.200
Loop was auto-parallelized.

00:40:33.270 --> 00:40:34.700
So let's go ahead and run this now.

00:40:34.700 --> 00:40:37.340
- Now it also says that we
vectorized the loop too,

00:40:37.340 --> 00:40:37.620
huh?

00:40:37.620 --> 00:40:40.270
- That's right,
we vectorized our inner loop and

00:40:40.270 --> 00:40:43.850
we auto-parallelized the outer
loop of our matrix multiply.

00:40:43.870 --> 00:40:45.310
- All right, that's just the way
it's supposed to work,

00:40:45.320 --> 00:40:45.650
okay.

00:40:45.750 --> 00:40:48.290
- So let's go ahead and run that.

00:40:50.250 --> 00:40:52.520
5.04 seconds.

00:40:52.550 --> 00:40:56.960
Now as I recall, it was 4.93 vectorizing.

00:40:56.960 --> 00:41:03.380
Hmm, I think I want to go out here to
my X window and I want to actually

00:41:03.470 --> 00:41:07.150
time the run of it instead.

00:41:10.160 --> 00:41:15.100
Okay, now we see that our real
time was 2.55 seconds.

00:41:15.170 --> 00:41:18.970
So the clock function that we
were using within Matrix Multiply

00:41:18.980 --> 00:41:23.040
is showing the time it took to
execute on both threads combined,

00:41:23.040 --> 00:41:26.800
but our real clock time
was only 2.55 seconds.

00:41:26.800 --> 00:41:28.760
So there's a little bit
of difference there.

00:41:28.760 --> 00:41:29.700
Okay.

00:41:29.700 --> 00:41:32.810
Now I want to show you the MKL version.

00:41:32.810 --> 00:41:36.840
So let me get back over
here and turn back on MKL.

00:41:37.020 --> 00:41:38.770
So that's an important safety tip.

00:41:38.930 --> 00:41:43.460
When you are timing multi-threaded
applications on the Core Duo or

00:41:43.490 --> 00:41:47.680
the dual-core processors,
you need to think about what the

00:41:47.740 --> 00:41:53.080
system clock is reporting in terms of
clock ticks versus the real user time.

00:41:53.080 --> 00:41:55.220
So that's what we showed here.

00:41:55.220 --> 00:42:00.680
What the system clock reported
was the total of the clock

00:42:00.680 --> 00:42:03.400
ticks from both threads.

00:42:03.940 --> 00:42:06.370
In reality, though,
the user time or the real

00:42:06.370 --> 00:42:12.100
time was half or close to half
from the actual performance.

00:42:12.120 --> 00:42:17.830
Okay, now I've built it to go to the
Math Kernel Library routine.

00:42:17.910 --> 00:42:21.630
Now notice that we didn't get any
vectorization or parallelization

00:42:21.760 --> 00:42:24.380
here because we're calling
the Math Kernel Library.

00:42:24.380 --> 00:42:27.110
But back in our other routine,
we did have some

00:42:27.110 --> 00:42:31.250
initialization of our data,
and there we did get auto-parallelization

00:42:31.300 --> 00:42:33.680
and the vectorization taking place.

00:42:33.940 --> 00:42:35.440
So let's go ahead and run.

00:42:35.440 --> 00:42:39.110
I'm going to go ahead and run out here
because we already know we'll have that

00:42:39.110 --> 00:42:41.960
clock problem if we run out of Xcode.

00:42:42.000 --> 00:42:47.240
Whoa, it's already done,
but it says 1.89 seconds,

00:42:47.240 --> 00:42:50.000
and I think we were at 1.75 seconds.

00:42:50.000 --> 00:42:51.040
Hmm, okay.

00:42:51.040 --> 00:42:53.290
So what's going on here?

00:42:53.380 --> 00:42:58.220
Well, it turns out that by default,
the Math Kernel Library is running

00:42:58.220 --> 00:43:01.970
single-threaded because the
Math Kernel Library does not want to

00:43:02.000 --> 00:43:03.380
conflict if you're using something
like a single-threaded library.

00:43:03.380 --> 00:43:03.880
Okay.

00:43:03.880 --> 00:43:06.640
So it's something like the
MPI for doing your threading.

00:43:06.680 --> 00:43:09.400
So by default, it's single-threaded.

00:43:09.440 --> 00:43:12.060
But let me set a variable here.

00:43:20.150 --> 00:43:21.240
And then let me run again.

00:43:21.240 --> 00:43:26.040
Oh, it's done, and it's just one second.

00:43:26.040 --> 00:43:31.360
So if you recall,
our non-vectorized matrix

00:43:31.360 --> 00:43:33.800
multiply was about nine seconds.

00:43:33.800 --> 00:43:36.850
When we vectorized,
I think it went to about five seconds.

00:43:36.860 --> 00:43:41.980
Our auto-parallelized version
was about 2.6 seconds.

00:43:41.980 --> 00:43:45.280
And now when we threaded MKL,
we get down to a second

00:43:45.280 --> 00:43:47.200
for our matrix multiply.

00:43:47.200 --> 00:43:48.240
Excellent.

00:43:48.240 --> 00:43:53.560
Wow, so nine seconds down to basically
one second with MKL and the compiler.

00:43:53.560 --> 00:43:54.140
Excellent.

00:43:54.140 --> 00:43:55.660
I think that'll work.

00:43:55.760 --> 00:43:56.310
That'll work.

00:43:56.360 --> 00:43:58.100
Thank you, Elizabeth.

00:44:02.610 --> 00:44:05.740
Okay, so one more thing to
talk about for threading,

00:44:05.870 --> 00:44:09.610
and this is our new parallel
programming model for C++.

00:44:09.740 --> 00:44:14.280
So what this is is a
template-based runtime library.

00:44:14.280 --> 00:44:20.440
You know, we're providing the runtime
library that manages scheduling

00:44:20.440 --> 00:44:22.600
and various other things,
as we'll see,

00:44:22.600 --> 00:44:26.030
as well as the header files and
et cetera that define all the

00:44:26.030 --> 00:44:28.280
constructs and the concepts here.

00:44:29.280 --> 00:44:35.720
And what it allows you to do
for C++ programs is define the,

00:44:35.720 --> 00:44:38.310
is to define your
parallelism in terms of,

00:44:38.380 --> 00:44:41.120
you know, data,
or in terms of the tasks or patterns

00:44:41.210 --> 00:44:45.630
that you want to operate on that data,
as opposed to looking at, you know,

00:44:45.630 --> 00:44:48.550
worrying about, you know,
just how to thread it or

00:44:48.550 --> 00:44:52.400
looking at more of a functional
decomposition of your threading.

00:44:52.400 --> 00:44:57.800
So, you know, it's similar to, like,
the standard template library.

00:44:57.800 --> 00:44:59.240
You know,
if you look at different... You know,

00:44:59.240 --> 00:45:01.570
if you look at different iterators
in there where you can operate on,

00:45:01.640 --> 00:45:06.330
you know, generic data types, you know,
it works a lot in the same way,

00:45:06.330 --> 00:45:07.640
as we'll see in a minute.

00:45:07.660 --> 00:45:11.600
So it's not necessarily
intended to provide,

00:45:11.600 --> 00:45:17.550
you know, greater performance, perhaps,
than, say, OpenMP or the Pthreads,

00:45:17.600 --> 00:45:20.880
but what it is intended
to do is help you with,

00:45:21.000 --> 00:45:25.840
you know, just greater productivity,
ease of use, compared to Pthreads,

00:45:25.840 --> 00:45:28.260
as we'll see in these examples.

00:45:28.850 --> 00:45:34.220
So with... And since you are programming
in more of a data parallel manner,

00:45:34.220 --> 00:45:36.800
or since you are programming
in a data parallel manner,

00:45:36.800 --> 00:45:40.280
as opposed to functional, you know,
that is how you get greater scalability,

00:45:40.280 --> 00:45:42.620
and you can get performance
that way as well.

00:45:45.350 --> 00:45:49.400
So this is just an example of
one of the concepts that we've

00:45:49.400 --> 00:45:51.600
defined in the threading library.

00:45:51.600 --> 00:45:56.220
This is the parallel four,
fairly synonymous with the

00:45:56.280 --> 00:46:01.200
OpenMP parallel do loop or
do constructs that we saw.

00:46:01.200 --> 00:46:04.790
But what this is doing is very similar,
as I said,

00:46:04.890 --> 00:46:06.200
to the standard template library.

00:46:06.200 --> 00:46:16.270
You define what data you want to work on,
and then you think about how you want to,

00:46:16.270 --> 00:46:21.560
you know, the functions or the operations
that you want to work on that data.

00:46:21.560 --> 00:46:24.880
And just let it,
let the parallel four or the

00:46:24.880 --> 00:46:29.480
threading runtime library worry
about the scheduling and how

00:46:29.480 --> 00:46:31.180
it's going to allocate the data.

00:46:31.200 --> 00:46:34.920
work on your data.

00:46:35.100 --> 00:47:43.900
[Transcript missing]

00:47:44.400 --> 00:47:49.600
Now, this is, so that was in a
one-dimensional iteration space.

00:47:49.620 --> 00:47:53.180
Now, if you think back again
to the Pavre example,

00:47:53.180 --> 00:47:58.840
a quicker way to do,
or a more optimal way to do the rendering

00:47:58.840 --> 00:48:05.320
is to break it up into larger chunks
and just farm out more and more chunks

00:48:05.320 --> 00:48:10.250
or larger chunks of the image to be
rendered by the different threads.

00:48:10.260 --> 00:48:13.500
And to do that with POSIX,
you're going to have to

00:48:13.500 --> 00:48:17.940
write a fair amount of code,
but with the threading library, again,

00:48:17.940 --> 00:48:23.120
you let the runtime library do the work
for you because you've already defined

00:48:23.120 --> 00:48:28.270
this for the data or for the different,
for the data sections or the data that

00:48:28.280 --> 00:48:30.680
you want the iterator to operate on.

00:48:30.680 --> 00:48:34.810
In this case,
the only difference between this and

00:48:34.810 --> 00:48:40.080
the one-dimensional iteration space
was the use of this blocked range 2D,

00:48:40.080 --> 00:48:44.720
and that's where you tell the,
the runtime library that you are

00:48:44.720 --> 00:48:46.600
iterating over a two-dimensional space.

00:48:46.600 --> 00:48:50.790
And there are other constructs or
other concepts in the library that,

00:48:50.820 --> 00:48:53.140
you know, for different data types
and different dimensions,

00:48:53.140 --> 00:48:53.600
et cetera.

00:48:53.600 --> 00:48:58.060
Now, you know, again,
what we're showing here,

00:48:58.060 --> 00:49:00.470
it's not necessarily, you know,
we're not after, you know,

00:49:00.590 --> 00:49:04.790
necessarily a performance improvement,
but a productivity savings and the ease

00:49:04.790 --> 00:49:06.800
of use that you can get from doing this.

00:49:06.800 --> 00:49:11.480
So let's go ahead and take a
quick look at this Tachyon demo.

00:49:11.480 --> 00:49:12.780
You just saw it.

00:49:12.780 --> 00:49:16.020
You saw the code that we were showing,
and I think Elizabeth will

00:49:16.020 --> 00:49:17.610
show us how it looks.

00:49:17.740 --> 00:49:21.640
So what we're first going to do
is we're going to run the serial

00:49:21.840 --> 00:49:23.960
version of this Tachyon demo.

00:49:23.960 --> 00:49:26.000
So let me go ahead and do the run.

00:49:26.000 --> 00:49:28.140
So notice how it's painting.

00:49:28.140 --> 00:49:33.330
It's just doing it line by line,
and it will see how it paints

00:49:33.340 --> 00:49:36.360
with the new parallel programming
model in just a second,

00:49:36.360 --> 00:49:39.150
and we'll also get a timing
here of how much this is

00:49:39.160 --> 00:49:40.600
taking for the serial version.

00:49:44.730 --> 00:49:48.880
Okay, that's completed,
and it took about 16 seconds.

00:49:48.880 --> 00:49:52.520
So there's a little pause in here,
and then it'll start painting again.

00:49:52.520 --> 00:49:54.060
Now, notice how it's painting.

00:49:54.060 --> 00:49:57.840
It's doing it in blocks,
and as it completes,

00:49:57.840 --> 00:50:00.320
now we get another timing.

00:50:00.320 --> 00:50:04.400
Oh, 7.25 seconds,
so a significant speed-up using the

00:50:04.400 --> 00:50:07.100
new Intel Parallel Programming Model.

00:50:07.100 --> 00:50:11.960
Let me do this one more time,
just the threaded version.

00:50:12.080 --> 00:50:14.770
And notice again how it paints in blocks.

00:50:14.780 --> 00:50:17.630
It's doing the 2D,
as Joe was showing the source

00:50:17.630 --> 00:50:19.160
for this up on the screen.

00:50:19.160 --> 00:50:22.210
And notice at the very end,
it grabs an extra bit of work

00:50:22.210 --> 00:50:25.190
ahead of the block below it,
and that's because of how

00:50:25.190 --> 00:50:26.800
the scheduling is done.

00:50:26.800 --> 00:50:29.930
So it's actually able to do a little
bit of speed-up that way that isn't

00:50:29.950 --> 00:50:31.620
possible in the serial version.

00:50:31.620 --> 00:50:35.360
And I don't believe it's possible
in the P-Threads version either.

00:50:35.360 --> 00:50:35.960
Right.

00:50:35.960 --> 00:50:36.840
So.

00:50:37.100 --> 00:50:39.750
So again,
certainly you can see the speed-up

00:50:39.750 --> 00:50:43.490
from threading going from a
serial to the parallel version.

00:50:43.500 --> 00:50:49.140
There is an implementation of the
tachyon using the POSIX threads,

00:50:49.140 --> 00:50:53.820
and it's a similar performance to what
we see with the threading library.

00:50:53.820 --> 00:50:58.620
But you can see the productivity or the
coding savings that you get using that.

00:51:00.510 --> 00:51:07.270
Okay, now, so we've talked about the,
you know, so we talked about the,

00:51:07.270 --> 00:51:11.250
you know, the compilers and the basic
functionality or the performance

00:51:11.250 --> 00:51:15.640
capabilities of the compilers of
the libraries and the threading.

00:51:15.640 --> 00:51:19.800
So, you know,
one last thing we want to talk about is,

00:51:19.800 --> 00:51:25.210
you know, just a little bit on how we are
supporting the new Mac Pros,

00:51:25.210 --> 00:51:29.910
you know, utilizing the 64-bit
Core 2 Duo processors.

00:51:30.800 --> 00:51:31.610
so

00:51:33.640 --> 00:51:36.040
You know, really,
the way we're looking at this is,

00:51:36.070 --> 00:51:39.670
you know,
we're maintaining the compatibility and

00:51:39.670 --> 00:51:42.140
providing interoperability with GCC.

00:51:42.200 --> 00:51:43.880
That's still our guiding principle here.

00:51:43.880 --> 00:51:46.580
You know, obviously,
we are worrying about performance,

00:51:46.580 --> 00:51:49.820
and we're going to deliver that,
and we'll show another example running

00:51:49.900 --> 00:51:51.760
on the 64-bit system in a minute.

00:51:52.760 --> 00:51:55.910
But the way the compilers
are laid out is,

00:51:55.910 --> 00:52:01.130
you know, we're going to offer one
compiler binary for 32-bit,

00:52:01.250 --> 00:52:06.100
or for the core processors as, you know,
on the iMacs today.

00:52:06.100 --> 00:52:11.040
And then there'll be a different
binary for the 64-bit for the Mac Pros,

00:52:11.040 --> 00:52:14.270
and, you know,
that we'll be coming out with.

00:52:14.440 --> 00:52:16.600
We'll probably be starting
a beta later in the year,

00:52:16.600 --> 00:52:19.770
and, you know, I'll give you some more
details about that in a minute.

00:52:19.780 --> 00:52:22.730
But so separate binaries for 32-bit.

00:52:22.760 --> 00:52:27.580
So the 64-bit targeting compiler
will have these switches,

00:52:27.580 --> 00:52:31.380
and this is just what you
can see in GCC or with Xcode,

00:52:31.380 --> 00:52:34.760
you know,
the Xcode that's on the Mac Pros that

00:52:34.760 --> 00:52:37.620
you can see down in the lab today.

00:52:37.620 --> 00:52:42.610
There's an M32 and an M64 model switch
to determine which you're going to,

00:52:42.610 --> 00:52:45.630
you know,
which model you're going to run in.

00:52:45.640 --> 00:52:48.780
Universal binaries, of course,
are the same.

00:52:48.780 --> 00:52:52.000
You have the Intel compiler
using either Xcode or LiPo.

00:52:52.000 --> 00:52:52.740
You know, however you want to run it.

00:52:52.740 --> 00:52:53.350
However you want.

00:52:53.450 --> 00:52:56.670
Now, one thing that we're providing
in the Intel compilers,

00:52:56.670 --> 00:53:01.120
and, you know, that's proven, you know,
very valuable for us in the past in,

00:53:01.120 --> 00:53:05.120
you know, helping people port to
64-bit applications.

00:53:05.120 --> 00:53:08.420
So we implemented this WP64 option.

00:53:08.420 --> 00:53:11.120
You know,
we kind of call it our code clean option.

00:53:11.120 --> 00:53:14.950
You know, what that means is helping you,
you know, giving you diagnostics

00:53:15.070 --> 00:53:18.140
for when you're using,
you know, maybe mix-matched 32-

00:53:18.140 --> 00:53:19.640
and 64-bit pointers.

00:53:19.640 --> 00:53:22.720
You know, it's a common error
that you will run into.

00:53:22.720 --> 00:53:25.220
As you're porting,
it will give you diagnostics for

00:53:25.220 --> 00:53:27.280
those types of situations and others.

00:53:27.300 --> 00:53:29.050
So it's very, you know, very useful.

00:53:29.060 --> 00:53:30.610
We found it very useful in the past.

00:53:30.660 --> 00:53:36.050
And then as far as the ABI for LP64
or longs and pointers being 64,

00:53:36.050 --> 00:53:39.340
you know,
we're implementing the same ABI as

00:53:39.400 --> 00:53:42.010
what's been implemented in GCC.

00:53:42.140 --> 00:53:46.200
And the key things to
note here in the ABI,

00:53:46.200 --> 00:53:51.500
I think tomorrow in the
brown bag by Dilip Bandekar,

00:53:51.500 --> 00:53:52.700
I think he'll go into more detail.

00:53:52.700 --> 00:53:54.470
But I think it's important to
note that we're not going to be

00:53:54.470 --> 00:53:55.520
doing a lot of the same stuff.

00:53:55.520 --> 00:53:56.700
We're going to be doing
a lot of the same stuff.

00:53:56.700 --> 00:53:57.670
We're going to be doing
a lot of the same stuff.

00:53:57.760 --> 00:54:01.450
But the key thing for
performance is really the,

00:54:01.500 --> 00:54:06.550
you know, not in 64-bitness,
but in the fact that there's eight

00:54:06.750 --> 00:54:11.780
more XMM registers or the SIMD,
single instruction multiple data

00:54:11.780 --> 00:54:16.960
registers on the core two versus
what's on the core processor.

00:54:16.960 --> 00:54:21.640
So that allows us to do more
things in the calling conventions.

00:54:21.640 --> 00:54:22.680
We have faster calling conventions.

00:54:22.680 --> 00:54:26.410
It gives the compiler greater
flexibility for register

00:54:26.500 --> 00:54:29.240
allocation and optimization there.

00:54:29.240 --> 00:54:31.220
So, you know,
that's really where you see,

00:54:31.220 --> 00:54:34.020
where you can see some
significant performance benefits.

00:54:35.670 --> 00:54:41.480
Okay, so with that,
I think we have one last demo.

00:54:41.480 --> 00:54:44.680
All right, I'm going to move over
now to the Mac Pro,

00:54:44.680 --> 00:54:48.760
and what I've got this set up
to do is run the POV bench.

00:54:48.760 --> 00:54:51.640
It's going to run in just
command line version.

00:54:51.640 --> 00:54:54.380
We did try to do some work
here at the conference to

00:54:54.380 --> 00:54:57.620
get it working with graphics,
so you can see the same demo

00:54:57.720 --> 00:55:00.820
that you saw on the 32-bit
earlier in the presentation,

00:55:00.820 --> 00:55:04.950
that we just had some technical problems
and weren't able to do that for you.

00:55:05.000 --> 00:55:07.200
But let me go ahead and run
it over here on the right.

00:55:07.240 --> 00:55:10.560
And this is running GCC version 4.0.1.

00:55:10.560 --> 00:55:14.480
This is the Apple computer
build of the GCC.

00:55:14.500 --> 00:55:18.800
And it's just running the
POV bench benchmark scene.

00:55:18.800 --> 00:55:24.480
And it's taking 4.959 seconds.

00:55:24.480 --> 00:55:29.870
And over here...

00:55:32.130 --> 00:55:36.020
We're running the Intel C++
Compiler for Mac OS,

00:55:36.040 --> 00:55:39.100
and it's taking about 4.144.

00:55:39.100 --> 00:55:41.820
I want to point out,
this is our 64-bit compiler.

00:55:41.820 --> 00:55:45.790
You can see it's version X.X,
so this is a pre-beta compiler

00:55:45.790 --> 00:55:47.400
that we're showing here.

00:55:47.400 --> 00:55:50.040
And it will go into beta later this fall.

00:55:50.040 --> 00:55:54.710
Okay,
so about a 20% performance difference.

00:55:54.740 --> 00:56:00.990
But again, these are early copies of
both compilers for the 64-bit.

00:56:01.680 --> 00:56:05.820
And as I mentioned,
it will be going to beta with

00:56:05.820 --> 00:56:09.380
the Intel Compiler and the
Intel Libraries later in the year.

00:56:09.380 --> 00:56:13.380
And I'll give you a website
for how you can get in that.

00:56:13.460 --> 00:56:15.640
So, wow, very good.

00:56:15.640 --> 00:56:16.560
Thank you very much, Elizabeth.

00:56:21.860 --> 00:56:25.130
So I think we're, yeah,
we're at the end here, and I just want to

00:56:25.130 --> 00:56:26.340
summarize what we've done.

00:56:26.340 --> 00:56:31.280
So we've given you an introduction
to the software development products,

00:56:31.280 --> 00:56:35.080
the compilers, libraries,
our new threading library.

00:56:35.080 --> 00:56:38.040
And we've talked about, you know, just,
you know,

00:56:38.040 --> 00:56:42.010
why Intel is in the software business
and why it's important for us.

00:56:42.020 --> 00:56:46.090
And also showed why it's important
for you to be using the best tools

00:56:46.240 --> 00:56:50.340
possible to get the maximum performance
out of your applications running

00:56:50.350 --> 00:56:52.180
on the Intel processor-based Macs.

00:56:52.240 --> 00:56:57.090
You know, we also talked about, you know,
some techniques for you to thread

00:56:57.090 --> 00:57:00.300
your applications using AutoParallel,
OpenMP,

00:57:00.300 --> 00:57:03.100
and this new threading runtime library.

00:57:03.100 --> 00:57:06.840
And then, and we talked also about
the guiding principles,

00:57:06.890 --> 00:57:10.710
you know, the, obviously performance,
but we want to maintain

00:57:10.710 --> 00:57:11.740
that compatibility.

00:57:12.020 --> 00:57:14.980
With the development
environment that you use today,

00:57:14.980 --> 00:57:18.370
you know, Xcode,
interoperability with GCC, et cetera.

00:57:18.470 --> 00:57:21.430
And then, you know,
the other guiding principle is that,

00:57:21.430 --> 00:57:23.850
you know, we back all this up with,
you know,

00:57:23.860 --> 00:57:25.350
with expert support and training.

00:57:25.360 --> 00:57:27.500
So we want to make sure that
you have what you need to,

00:57:27.500 --> 00:57:30.330
you know, to be successful.

00:57:30.480 --> 00:57:33.220
So this is our website.

00:57:34.160 --> 00:57:37.500
One more thing,
I just want to let you know that,

00:57:37.500 --> 00:57:40.850
as I think I said this earlier,
but several of us,

00:57:40.960 --> 00:57:43.850
including several engineers,
are in the performance lab

00:57:43.950 --> 00:57:45.740
downstairs on the first floor.

00:57:45.740 --> 00:57:50.430
And we'll be here through, you know,
all the way until 10 o'clock tonight or,

00:57:50.590 --> 00:57:56.530
well, later if you want to buy a beer,
but that's a... And then

00:57:56.900 --> 00:57:59.770
tomorrow morning,
there is a, there's another talk by some

00:57:59.770 --> 00:58:05.060
of our performance engineers on
looking at a case study of some

00:58:05.090 --> 00:58:09.140
performance tuning they did for the,
you know, for the Macs.

00:58:09.140 --> 00:58:12.340
And that'll be a very interesting
talk tomorrow at 10.30.

00:58:12.340 --> 00:58:17.250
We mentioned Delete Bandercar is
giving a brown bag tomorrow at lunch.

00:58:17.260 --> 00:58:23.590
And then, you know, we also want you to,
you know, go to our website and

00:58:23.590 --> 00:58:26.080
sign up for future betas.

00:58:26.100 --> 00:58:29.280
We don't have any dates that
we could give you now about our

00:58:29.530 --> 00:58:31.580
beta program for 64-bit tools.

00:58:31.580 --> 00:58:33.880
But you could go here
and put your name down,

00:58:33.930 --> 00:58:36.220
and we'll be able to
get in touch with you.

00:58:36.220 --> 00:58:40.840
And then one final thing I didn't
put on the slide is that,

00:58:40.840 --> 00:58:45.650
but for attendees at WWDC,
we do have some coupons for

00:58:45.770 --> 00:58:51.120
the compilers and libraries,
if you're interested, for a 50% discount.

00:58:51.120 --> 00:58:52.800
So you can come up and see us afterwards.