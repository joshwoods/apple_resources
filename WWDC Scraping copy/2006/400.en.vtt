WEBVTT

00:00:10.190 --> 00:00:11.890
My name is John Wright.

00:00:12.050 --> 00:00:15.590
I run the Kernel
Technologies Group at Apple.

00:00:15.590 --> 00:00:19.690
I'll be talking to you a little bit
about what's new in the kernel today.

00:00:21.230 --> 00:00:26.400
So we're going to go through kind of
just an overview of what the kernel

00:00:26.490 --> 00:00:28.720
does and kind of some background on it.

00:00:28.780 --> 00:00:31.010
Then we're going to talk
a little bit about some

00:00:31.050 --> 00:00:33.910
developer features for Leopard,
particularly some things

00:00:34.160 --> 00:00:37.530
that relate to 64-bit,
some of our Unix interfaces,

00:00:37.530 --> 00:00:40.060
and some things about system tracing.

00:00:40.560 --> 00:00:44.980
And then we're going to cover some
infrastructure changes for Leopard,

00:00:44.980 --> 00:00:49.140
including things that cover scaling
and working on larger machines

00:00:49.140 --> 00:00:51.630
and some implications to security.

00:00:51.630 --> 00:00:53.060
And then we'll have some time for QA.

00:00:56.090 --> 00:00:57.720
So target audience.

00:00:57.720 --> 00:01:01.400
So the kernel is really kind of the
lowest level in the software stack,

00:01:01.400 --> 00:01:05.560
and it kind of runs right on the,
enables the bare iron of the hardware.

00:01:05.560 --> 00:01:09.580
So most of you guys are
actually implementing to

00:01:09.580 --> 00:01:12.460
much higher level frameworks.

00:01:12.460 --> 00:01:16.160
But it is still of interest to some
of you to kind of understand the lower

00:01:16.160 --> 00:01:19.760
level mechanisms that's underlying those,
and just in general the

00:01:19.760 --> 00:01:21.520
system behaviors of those.

00:01:21.520 --> 00:01:24.030
Now,
a lot of times when people think kernel,

00:01:24.030 --> 00:01:28.560
they'll think device drivers,
and the I/O Kit interfaces.

00:01:28.560 --> 00:01:29.680
And I'm not covering those.

00:01:29.730 --> 00:01:32.000
Those are actually covered
in some other talks.

00:01:32.000 --> 00:01:36.110
But I want to make sure you guys
understand that if you guys are expecting

00:01:36.130 --> 00:01:41.110
I/O Kit interfaces to be covered,
they're actually covered elsewhere.

00:01:44.220 --> 00:01:50.140
So this is your basic block
diagram of the kernel architecture.

00:01:50.190 --> 00:01:53.900
You'll see here on the right,
you've got a few libraries.

00:01:54.000 --> 00:01:58.240
There's the standalone library
that actually is used for

00:01:58.240 --> 00:02:00.840
the boot infrastructure.

00:02:00.890 --> 00:02:04.210
libkern,
which is basically some routines that

00:02:04.210 --> 00:02:06.580
are generic in the kernel that are used.

00:02:06.600 --> 00:02:10.040
And the platform expert,
which kind of abstracts away

00:02:10.040 --> 00:02:16.290
some of the lower level hardware
details away from the kernel.

00:02:17.310 --> 00:02:21.680
Down here at the Mach layer
you have virtual memory,

00:02:21.680 --> 00:02:25.340
the physical mapping memory,
the scheduler,

00:02:25.440 --> 00:02:29.580
the abstraction of tasks and threads,
your timers,

00:02:29.580 --> 00:02:34.880
your low-level primitives for
symmetric multi-processing,

00:02:34.880 --> 00:02:38.580
all important Mach IPC, messaging.

00:02:38.580 --> 00:02:43.230
There's also some device driver
infrastructure in I/O Kit,

00:02:43.280 --> 00:02:46.960
which really isn't in Mach,
it's actually kind of separated.

00:02:47.200 --> 00:02:48.230
and

00:02:48.910 --> 00:02:51.420
And then on top of that,
we built the BSD layer,

00:02:51.470 --> 00:02:58.410
which includes our POSIX interfaces,
P threads, processes, signals,

00:02:58.670 --> 00:03:05.040
our Unix security model, VFS,
which exports all the file system

00:03:05.040 --> 00:03:08.240
infrastructure out to the file system,
some of which are in the kernel,

00:03:08.240 --> 00:03:09.320
some of which are outside the kernel.

00:03:09.320 --> 00:03:12.650
And you also have some of the
networking infrastructure,

00:03:12.650 --> 00:03:15.050
the sockets and the networking stack.

00:03:17.940 --> 00:03:21.920
Now, other talks are actually going to
cover some of the file system and

00:03:21.920 --> 00:03:23.560
the networking and I/O Kit stuff.

00:03:23.560 --> 00:03:26.000
So I'm really trying to focus
kind of on the core kernel

00:03:26.000 --> 00:03:30.590
infrastructure here in this talk.

00:03:32.570 --> 00:03:35.290
and some of the talks,
there are other talks that

00:03:35.290 --> 00:03:39.310
relate to these things,
but the writing device drivers for

00:03:39.310 --> 00:03:44.390
Mac OS X covers the basics of I/O Kit,
and there's a talk dedicated to what's

00:03:44.390 --> 00:03:46.330
new in the file systems as well.

00:03:51.760 --> 00:03:54.220
So I just want to say a little
bit about target customers.

00:03:54.350 --> 00:03:58.040
Since we are kind of the lowest
level of the software stack,

00:03:58.040 --> 00:04:01.270
most of our target customers
actually end up being our frameworks.

00:04:01.470 --> 00:04:05.910
And then most of you guys are actually
developing to those frameworks.

00:04:06.310 --> 00:04:09.360
But those frameworks actually
percolate up directly to you

00:04:09.360 --> 00:04:12.300
guys and to our end users.

00:04:12.510 --> 00:04:17.360
So it is important for us to
kind of see the stack as a whole.

00:04:20.110 --> 00:04:27.100
As far as where we get influence
on how we develop the kernel,

00:04:27.130 --> 00:04:34.920
what really drives us is the internal
innovations that happen within the stack.

00:04:35.020 --> 00:04:40.010
At Apple, we're unique in that we control
the hardware architecture and the

00:04:40.540 --> 00:04:43.260
entire software stack all the way
out through the frameworks and all

00:04:43.260 --> 00:04:44.320
the way out to the applications.

00:04:45.300 --> 00:04:48.720
We do a lot of optimizations
directly with our framework teams,

00:04:48.740 --> 00:04:52.980
but we also drive this really
through looking at the whole widget.

00:04:52.980 --> 00:04:56.690
We interface with the hardware
teams and the framework teams,

00:04:56.690 --> 00:04:59.770
and we take requests from
apps to really figure out how

00:04:59.870 --> 00:05:01.720
this thing can be optimized.

00:05:03.830 --> 00:05:07.980
We continue to be influenced
by external sources.

00:05:07.980 --> 00:05:14.130
We're always looking at industry trends
and standards and seeing how they'll

00:05:14.130 --> 00:05:17.020
affect the way our software works.

00:05:17.020 --> 00:05:21.380
We're always interested in technology
our partners are working on and seeing

00:05:22.000 --> 00:05:24.000
whether we can take advantage of that.

00:05:24.220 --> 00:05:28.100
We're always looking at the
open source community and

00:05:28.100 --> 00:05:30.570
helping what they're driving.

00:05:31.150 --> 00:05:35.500
And probably the most important here
is actually requests from you guys.

00:05:35.500 --> 00:05:39.350
Our developer relations team actually
takes requests from you guys and passes

00:05:39.350 --> 00:05:43.960
them on to the engineering team and
helps make that relationship work.

00:05:43.960 --> 00:05:46.580
And we take those
requests very seriously.

00:05:46.590 --> 00:05:49.920
So when you guys come up with
an idea of how we can actually

00:05:50.020 --> 00:05:54.270
optimize things for you guys,
I encourage you guys to send that in.

00:05:57.850 --> 00:06:02.780
I want to talk a little bit
about performance philosophy.

00:06:03.000 --> 00:06:06.840
Our focus is really improving
the system level performance.

00:06:06.840 --> 00:06:12.300
And I have a quote up there, lies,
damn lies, and micro benchmarks.

00:06:15.180 --> 00:06:19.010
I've seen a lot of things that
show micro benchmarks between

00:06:19.010 --> 00:06:21.020
different operating systems.

00:06:21.020 --> 00:06:24.160
They're of less interest to us
because there's something that

00:06:24.160 --> 00:06:25.730
we've kind of learned here.

00:06:26.540 --> 00:06:30.670
That if you look at like LM Bench,
which was written for Linux,

00:06:31.010 --> 00:06:33.490
Linux runs really well with LM Bench.

00:06:33.490 --> 00:06:36.460
If you look at something like Lib Micro,
which was written for Solaris,

00:06:36.460 --> 00:06:39.020
Solaris runs very well in Lib Micro.

00:06:39.960 --> 00:06:42.330
And we run another micro
benchmark called Mach Bench,

00:06:42.330 --> 00:06:44.070
and you probably won't be surprised.

00:06:44.780 --> 00:06:46.740
That we do pretty well in Mach Bench.

00:06:46.740 --> 00:06:49.280
So we use these micro
benchmarks as a tool to kind of

00:06:49.320 --> 00:06:52.610
understand what our kernel does,
but we're much more focused on

00:06:52.680 --> 00:06:54.540
the system level benchmarks.

00:06:55.290 --> 00:06:59.430
And Apple has several teams that
run system level benchmarks both

00:06:59.430 --> 00:07:03.240
on the client and on the server
to analyze our performance.

00:07:03.240 --> 00:07:06.910
And we're much more focused
on optimizing for those.

00:07:07.130 --> 00:07:11.820
There are a couple of things that we
pay special attention to in our kernel.

00:07:11.910 --> 00:07:15.000
One is Mach messaging in IPC.

00:07:15.000 --> 00:07:21.470
Mach messaging is the underlying
communications mechanism that's used

00:07:21.470 --> 00:07:22.930
throughout many of our frameworks.

00:07:23.140 --> 00:07:27.030
We want to make sure we
optimize well for it.

00:07:27.520 --> 00:07:31.440
Another thing we pay particular
attention to is the scheduling

00:07:31.440 --> 00:07:34.980
latency and the interrupt latency.

00:07:35.400 --> 00:07:39.670
This is the underlying
technology that allows us to

00:07:39.670 --> 00:07:42.660
do our real-time performance.

00:07:42.660 --> 00:07:45.900
It also directly affects
the system interactivity.

00:07:46.100 --> 00:07:50.280
Just being able to switch
between different tasks,

00:07:50.510 --> 00:07:55.630
get things done on scheduling time,
is very important to our system

00:07:55.710 --> 00:07:58.970
because it directly affects our users.

00:08:01.670 --> 00:08:07.650
I also want to say something about the
monolithic versus microkernel debate.

00:08:07.750 --> 00:08:10.660
I think about every
six months on Slashdot,

00:08:10.690 --> 00:08:14.390
I see something go by that raises
everyone and everyone gets to put their

00:08:14.390 --> 00:08:18.900
opinion on whether microkernels are
good or monolithic kernels are good.

00:08:19.660 --> 00:08:22.450
Mark is a microkernel,
its architect is a microkernel,

00:08:22.450 --> 00:08:28.160
but we use our kernel, X and U,
as a monolithic kernel.

00:08:28.160 --> 00:08:34.260
So we build BSD and Mach together
and the device drivers together to

00:08:34.260 --> 00:08:36.240
actually build a monolithic kernel.

00:08:36.240 --> 00:08:39.600
Now we do this to minimize the
transitions across the kernel boundary.

00:08:39.680 --> 00:08:41.040
That's really what we do.

00:08:41.040 --> 00:08:44.820
And we find that what we want is that
when the code path goes into the kernel,

00:08:44.900 --> 00:08:47.220
we want to get all of its
work done before it comes

00:08:47.220 --> 00:08:48.940
back out of the kernel again.

00:08:49.560 --> 00:08:53.190
So that's where we kind
of lie on that debate,

00:08:53.190 --> 00:08:54.140
I guess.

00:08:57.230 --> 00:08:59.640
So here's our friend Darwin.

00:08:59.740 --> 00:09:03.090
There's been rumors out there
that he was pining for the

00:09:03.190 --> 00:09:07.820
fjords or something like that.

00:09:08.300 --> 00:09:11.060
So we can kind of put those
rumors to rest because we finally

00:09:11.060 --> 00:09:15.980
have our open source release
of the Darwin kernel for Intel.

00:09:15.980 --> 00:09:20.120
And I think that actually
hit MacForge yesterday.

00:09:26.160 --> 00:09:30.500
So we faced some kind of challenges
in making sure this got out.

00:09:30.940 --> 00:09:33.280
We've written lots of new code,
as you can imagine,

00:09:33.280 --> 00:09:38.080
over the last year or so to
complete the internal transition.

00:09:38.080 --> 00:09:42.860
And we had kind of a management
priority to make sure those

00:09:42.940 --> 00:09:44.740
products shipped to our customers.

00:09:44.740 --> 00:09:46.650
And that was definitely
the priority at the time.

00:09:46.780 --> 00:09:51.950
Now, when you write lots of new code
and you're doing open source,

00:09:51.960 --> 00:09:55.620
it does take some time
to review the code,

00:09:55.850 --> 00:09:59.160
engineer around code that
is actually encumbered,

00:09:59.170 --> 00:10:02.660
and making sure that it's all clean
before we can actually release it.

00:10:02.670 --> 00:10:05.380
And that did actually take us some time.

00:10:05.380 --> 00:10:08.590
The other thing is that
we really wanted to--

00:10:08.870 --> 00:10:13.840
We want to preserve the ability to
build and run the sources on the system.

00:10:13.840 --> 00:10:16.640
We probably could have thrown an
open source kernel over the wall much

00:10:16.700 --> 00:10:19.820
earlier that wouldn't build and run,
but we find this to be

00:10:19.820 --> 00:10:22.000
not very useful to you,
the developers.

00:10:22.000 --> 00:10:27.660
We want to make sure that everything
worked well before we got it out there.

00:10:27.660 --> 00:10:32.940
I did make a note that there are
some caveats here that some of

00:10:32.940 --> 00:10:36.750
the first release does require
you to pull some kecks over that

00:10:36.750 --> 00:10:42.040
aren't on your original systems,
but in general we'll be able to

00:10:42.040 --> 00:10:44.760
take care of that as we go forward.

00:10:46.870 --> 00:10:50.560
So I want to emphasize that
Darwin is very important to us.

00:10:50.600 --> 00:10:52.730
And there's really two
reasons I always quote.

00:10:52.890 --> 00:10:55.460
One is that it's really for you guys.

00:10:55.580 --> 00:10:58.040
It's transparency for you guys.

00:10:58.040 --> 00:11:02.240
You guys can look at the system
behaviors in the source code.

00:11:02.290 --> 00:11:05.160
If you want to know how
the fork system call works,

00:11:05.160 --> 00:11:08.160
you can actually go get the
source and look through the code.

00:11:08.160 --> 00:11:11.560
You can actually modify the code,
build it, stick it on your system.

00:11:11.640 --> 00:11:16.740
Even if 90% of you guys never do this,
it's good insurance just to

00:11:16.740 --> 00:11:18.490
have the ability to do it.

00:11:18.540 --> 00:11:19.720
And we really appreciate that.

00:11:19.740 --> 00:11:23.860
And we want to make sure
you guys have that ability.

00:11:23.860 --> 00:11:27.970
And then the second reason is actually
transparency to security review.

00:11:28.110 --> 00:11:30.220
And we really believe,
since this is kind of the

00:11:30.320 --> 00:11:33.670
core of the operating system,
that's important to have the sources out

00:11:33.780 --> 00:11:38.320
there for security experts out there in
the community to be able to look through

00:11:38.320 --> 00:11:43.690
and give feedback on the kernel itself.

00:11:44.430 --> 00:11:46.970
And last thing is thanks
for your patience.

00:11:46.980 --> 00:11:49.400
We're glad to have it out there,
and we're looking forward to

00:11:49.430 --> 00:11:52.520
our regularly scheduled releases
of the open source kernel.

00:11:56.120 --> 00:11:59.860
Let's wrap up the overview.

00:11:59.860 --> 00:12:03.780
There's a lot of detail
to how the kernel works.

00:12:03.800 --> 00:12:06.430
A couple of months ago,
there was a book release.

00:12:06.430 --> 00:12:10.740
Now I get no kickbacks or anything,
and Apple's not actually associated

00:12:10.740 --> 00:12:13.300
with the publishing of this book.

00:12:13.300 --> 00:12:17.920
But it actually is a great
reference for Mac OS X in general.

00:12:17.920 --> 00:12:23.940
It has several chapters on
how the kernel works itself.

00:12:23.970 --> 00:12:27.200
If you're interested in the details
of Mac IPC and things like that,

00:12:27.200 --> 00:12:30.000
I really recommend you pick this up.

00:12:30.060 --> 00:12:32.640
It's about 1,600 pages.

00:12:32.770 --> 00:12:34.980
I found it riveting reading.

00:12:34.980 --> 00:12:41.020
Some of you guys just might
find it a good reference.

00:12:41.060 --> 00:12:43.770
Let's talk a little bit
about developer features.

00:12:47.210 --> 00:12:52.410
64-bit,
it's a big theme here at the conference.

00:12:55.090 --> 00:12:57.070
If you haven't heard this before,
I'm just going to kind of

00:12:57.080 --> 00:13:01.730
reiterate some points that were
from the State of the Union.

00:13:01.830 --> 00:13:05.740
The new 64-bit Intel systems,
the Mac Pros,

00:13:05.880 --> 00:13:09.100
inherit what we call Tiger parity.

00:13:09.560 --> 00:13:14.200
We're enabling 64-bit processes
through basically our Unix interfaces.

00:13:14.290 --> 00:13:18.280
And we're using the standard
programming model that we used

00:13:18.620 --> 00:13:20.060
previously on PowerPC machines.

00:13:20.060 --> 00:13:23.600
So it's 64-bit longs and pointers.

00:13:24.710 --> 00:13:30.480
We're still writing the
kernel as a 32-bit entity,

00:13:30.480 --> 00:13:34.830
but we enabled the large address
spacing on the 64-bit processes.

00:13:35.550 --> 00:13:38.810
And this allows us to have
full compatibility with

00:13:38.810 --> 00:13:41.570
the drivers in the kecks.

00:13:43.180 --> 00:13:45.770
So the big news for Leopard is
that we're actually going to put in

00:13:45.880 --> 00:13:49.640
support for all of our frameworks,
including like Carbon and Cocoa.

00:13:49.760 --> 00:13:54.280
And that will enable all the applications
that are actually using those frameworks

00:13:54.280 --> 00:13:58.630
and not just the Unix interfaces to
actually get full 64-bit benefits.

00:14:02.250 --> 00:14:05.560
And there's a talk here about
how to actually enable your

00:14:05.680 --> 00:14:12.690
drivers for 64-bit to actually
address more large memory systems.

00:14:17.970 --> 00:14:23.180
Now, I want to talk a little bit
about how we got to 64-bit

00:14:23.180 --> 00:14:25.020
support for the Intel systems.

00:14:25.040 --> 00:14:30.120
And on the left here is
our address space map.

00:14:30.800 --> 00:14:35.280
If you look below 4 gig,
what you'll see is basically the address

00:14:35.390 --> 00:14:38.280
space map for our 32-bit machines.

00:14:38.310 --> 00:14:44.550
And you'll see your 32-bit address space
sitting beside your 32-bit kernel space.

00:14:45.550 --> 00:14:50.540
We were usually referred to this as a
4/4 split for the kernel and user space.

00:14:50.540 --> 00:14:54.590
Some kernels use a 3/1
split or a 2/2 split.

00:14:54.630 --> 00:14:58.680
And in those cases,
you'll actually see the

00:14:58.680 --> 00:15:05.320
kernel underneath or above,
but not overlapping with the user space.

00:15:05.670 --> 00:15:09.160
We actually made this split
so we could actually get full

00:15:09.160 --> 00:15:13.600
utilization of the virtual memory,
both for user and kernel,

00:15:13.890 --> 00:15:19.930
and allow our applications to be
able to address the full 4 gig.

00:15:20.800 --> 00:15:34.130
: It does mean that there is a little
bit bigger boundary to move across from

00:15:34.130 --> 00:15:34.130
user to kernel because now we have to
actually swap out the address space.

00:15:35.240 --> 00:15:39.290
But you'll notice that in 64-bit,
you have your 64-bit

00:15:39.290 --> 00:15:41.540
address space above that.

00:15:41.570 --> 00:15:43.420
And you still have your
32-bit kernel space.

00:15:43.420 --> 00:15:47.200
So we don't actually take that hit
when we go back and forth between

00:15:47.200 --> 00:15:50.180
user and kernel for 64-bit processes.

00:15:50.200 --> 00:15:53.040
Now, there is still a boundary there
that actually takes some time.

00:15:53.100 --> 00:15:56.120
But we don't actually have to
swap out the address space.

00:15:57.450 --> 00:16:02.720
So on our 64-bit machines,
we run our 32-bit kernel in what's called

00:16:02.720 --> 00:16:05.400
compatibility mode on Intel machines.

00:16:05.440 --> 00:16:10.800
And that basically means that it's
the 32-bit mode of the architecture.

00:16:12.850 --> 00:16:18.210
The big joke here,
so the 64-bit user space,

00:16:18.220 --> 00:16:21.590
the size of this right here,
is actually 47 bits.

00:16:21.670 --> 00:16:23.740
So if you really thought you
were getting full 64 bits,

00:16:23.740 --> 00:16:26.650
no, we took some away from you
and we're only giving you 47.

00:16:26.820 --> 00:16:32.800
That's actually an architectural
limit to the current Intel chips.

00:16:33.030 --> 00:16:38.340
There is a kind of a dead space
above 47 bits that actually

00:16:38.860 --> 00:16:41.810
will give you a general fault.

00:16:42.810 --> 00:16:46.200
If you actually try to address
that on the current architecture.

00:16:46.200 --> 00:16:52.660
But note that 47 bits gives you
128 terabytes of addressable space.

00:16:52.660 --> 00:16:56.820
And if you want to do
kind of the math there,

00:16:56.820 --> 00:17:01.560
128 terabytes really is a lot of space.

00:17:01.560 --> 00:17:06.000
So before you go complaining to
developer relations that you really

00:17:06.000 --> 00:17:10.490
need 48 bits of addressable space,
make sure you do the math.

00:17:10.560 --> 00:17:12.010
It's a lot.

00:17:15.730 --> 00:17:20.730
The other point is that in
the Intel architecture that

00:17:20.810 --> 00:17:24.310
you actually get to use when
you're in actually 64-bit mode,

00:17:24.310 --> 00:17:26.200
you get to use twice as many registers.

00:17:26.200 --> 00:17:29.930
So for the general registers,
there's eight on IE32,

00:17:29.930 --> 00:17:33.350
and when you're in 64-bit
mode on these machines,

00:17:33.350 --> 00:17:35.600
you actually get to use 16.

00:17:35.600 --> 00:17:42.900
So there are some performance
capabilities that you get beyond

00:17:42.900 --> 00:17:46.760
just the large address space.

00:17:52.960 --> 00:17:55.030
Unix.

00:17:55.030 --> 00:18:01.030
So standard Unix interfaces.

00:18:01.110 --> 00:18:06.400
We've supported the POSIX standard
Unix interfaces for quite some time.

00:18:06.570 --> 00:18:08.080
In Leopard,
one of the things that we want

00:18:08.080 --> 00:18:11.830
to do is move our default,
all of our behavior to

00:18:11.890 --> 00:18:14.150
the Unix 03 standard.

00:18:14.200 --> 00:18:18.430
But we'll still support
all the legacy behaviors,

00:18:18.430 --> 00:18:19.910
it's just the default will be Unix 03.

00:18:20.050 --> 00:18:25.240
And you can kind of switch back and
forth even today between these behaviors

00:18:25.240 --> 00:18:28.230
with POSIX C source as a define.

00:18:28.230 --> 00:18:34.890
It's just that you will get the
POSIX behavior by default in Leopard.

00:18:36.930 --> 00:18:40.220
If you target your binaries
to Tiger or earlier,

00:18:40.220 --> 00:18:42.820
you'll automatically
get the legacy behavior.

00:18:42.820 --> 00:18:45.730
If you do this in Xcode,
you'll automatically get the

00:18:45.730 --> 00:18:49.280
legacy behavior and things
shouldn't change in general.

00:18:50.690 --> 00:18:52.060
You can check the main pages.

00:18:52.170 --> 00:18:56.260
I think we've updated most of
them to actually explain what

00:18:56.380 --> 00:18:59.380
the default behavior is now and
what the legacy behavior is.

00:18:59.380 --> 00:19:05.620
There's a specific talk here about
developing porting Unix applications

00:19:05.620 --> 00:19:08.880
that will go more in depth on
what these interface changes are.

00:19:09.320 --> 00:19:12.500
But I do want to talk a little bit about
the kernel changes for this because

00:19:12.590 --> 00:19:15.940
there are some catches and I want
to make sure that people are aware.

00:19:19.210 --> 00:19:26.100
The first one is the Pthreads now support
all the mandatory cancellation points.

00:19:26.100 --> 00:19:30.470
Cancellation points in Pthreads
are used to synchronize the

00:19:30.570 --> 00:19:33.100
proper termination of the thread.

00:19:33.170 --> 00:19:38.180
It gives you a point to
register a callback handler,

00:19:38.180 --> 00:19:42.200
release all the resources
before the thread is terminated.

00:19:42.390 --> 00:19:46.260
The legacy behavior is that we
only support cancellation points

00:19:46.260 --> 00:19:50.140
on exit and pthread_text_cancel.

00:19:50.140 --> 00:19:54.690
And now we support all 55
mandatory cancellation points.

00:19:54.840 --> 00:20:02.770
So they're in very small font here,
but the gist is there's a lot.

00:20:03.590 --> 00:20:06.140
Most of you that are porting
things on the POSIX layer and

00:20:06.150 --> 00:20:11.110
the Pthreads layer probably are
porting from other POSIX machines,

00:20:11.110 --> 00:20:14.470
and they probably already support these
cancellation points and register callback

00:20:14.560 --> 00:20:16.480
handlers and don't have any problem.

00:20:16.480 --> 00:20:19.660
You really only have to be aware of
this if you've written one natively

00:20:19.660 --> 00:20:21.790
and have relied on the fact,
for some reason,

00:20:21.790 --> 00:20:29.360
there aren't many cancellation points
and not registering a cleanup handler.

00:20:31.550 --> 00:20:34.120
And then down here at the bottom,
I just have kind of the syntax

00:20:34.490 --> 00:20:39.760
to register the cleanup handler,
which is pthread cleanup push.

00:20:39.780 --> 00:20:47.340
And you basically give it a cleanup
routine and the set of arguments for it.

00:20:50.970 --> 00:20:57.600
The next one I want to make sure people
are aware of is partial reads and writes.

00:20:57.630 --> 00:21:01.220
I've always considered this a bug
in Mac OS X more than a feature.

00:21:01.220 --> 00:21:07.240
So when performing a read of a size
larger than what is left in the file,

00:21:07.240 --> 00:21:13.060
the legacy behavior is actually
to send back what is left of

00:21:13.060 --> 00:21:17.340
the file and an error and set
the error node to end of file.

00:21:17.340 --> 00:21:23.320
So if you say we're trying to
read 128 bytes and there were

00:21:23.320 --> 00:21:28.810
only five bytes left in the file,
what it would do is it would give you

00:21:28.810 --> 00:21:31.410
those five bytes and then set the EOF.

00:21:32.080 --> 00:21:37.300
The conforming behavior is actually to
set the five bytes and send you back

00:21:37.430 --> 00:21:40.520
how many bytes were actually read,
which would be five.

00:21:40.520 --> 00:21:44.330
And then on the next read,
you'd get the error in the EOF.

00:21:46.650 --> 00:21:52.880
So if you're using read and write
and actually looking into files,

00:21:52.880 --> 00:21:57.820
you want to make sure that you have the
correct semantics for the partial reads.

00:21:57.820 --> 00:22:02.120
Partial writes are very similar if
you're writing to a device and it's full.

00:22:02.120 --> 00:22:09.240
The semantics of writing only a
partial write are pretty much the same.

00:22:09.240 --> 00:22:12.210
They'll change to where you
write the partial write,

00:22:12.210 --> 00:22:15.260
you'll get the number of
bytes written and no error.

00:22:15.440 --> 00:22:18.270
and then on the next one,
you'll actually get the error.

00:22:22.680 --> 00:22:25.200
A couple other minor ones.

00:22:25.200 --> 00:22:26.040
Controlling terminals.

00:22:26.040 --> 00:22:32.840
All processes now get a
controlling terminal by default.

00:22:32.840 --> 00:22:37.330
And this wasn't the case in Tiger before.

00:22:37.560 --> 00:22:40.050
And you can actually opt out of
getting a controlling terminal,

00:22:40.060 --> 00:22:45.690
but you have to specify it
with the no CTTY option on an

00:22:45.700 --> 00:22:49.540
open or one of the other calls.

00:22:50.300 --> 00:22:54.850
The only thing to note here is
if you're actually relying on the

00:22:54.960 --> 00:23:00.270
fact that there's no controlling
TTY in one of your programs,

00:23:00.350 --> 00:23:03.820
you may have to nohup your processes,
for example,

00:23:03.820 --> 00:23:07.060
to keep the controlling TTY there.

00:23:08.950 --> 00:23:11.560
So just be aware of that.

00:23:11.560 --> 00:23:15.960
And likewise,
there's another minor nit with

00:23:15.960 --> 00:23:19.420
sending signals to process groups.

00:23:19.590 --> 00:23:23.700
For example, kill process group,
the system call.

00:23:23.710 --> 00:23:29.160
If you send the sending processes in that
process group that you're trying to kill,

00:23:29.160 --> 00:23:30.470
it will also get killed now.

00:23:30.480 --> 00:23:34.370
The default behavior before was
that it would not get killed.

00:23:34.420 --> 00:23:37.210
It would kill everything
else in that process group.

00:23:44.740 --> 00:23:52.270
So we're also adding a new
system called POSIX Spawn.

00:23:53.380 --> 00:24:00.720
The idea here is that fork and exec
actually will copy the address space,

00:24:00.760 --> 00:24:03.480
even if you're going to exec
it right away and get a whole

00:24:03.490 --> 00:24:04.500
new copy of the address space.

00:24:04.560 --> 00:24:06.980
They will copy the address
space of the parent.

00:24:07.050 --> 00:24:12.670
And the solution to this back
in BSD and other Unixes was

00:24:12.730 --> 00:24:16.420
to move to vfork and exec,
which would not copy it,

00:24:16.490 --> 00:24:19.280
and therefore was faster.

00:24:20.470 --> 00:24:29.080
The problem with VFork and exec is it
wasn't just a faster version of fork.

00:24:29.140 --> 00:24:33.800
It left you kind of semantically out
in the open between that VFork and exec

00:24:34.260 --> 00:24:37.860
to make modifications to the child that
would reflect directly into the parent.

00:24:37.860 --> 00:24:42.210
So, for example,
if you were trying to mark it as set UID,

00:24:42.400 --> 00:24:47.280
it would actually reflect that
change back to the parent and mark

00:24:47.280 --> 00:24:49.860
the parent as set UID as well.

00:24:51.360 --> 00:24:59.320
So we actually prefer POSIX Spun because
semantically it's a lot safer than VFork.

00:25:01.180 --> 00:25:05.970
So you can do a few things to it,
like pass file descriptors or change

00:25:05.970 --> 00:25:09.620
user and group IDs or signal mask.

00:25:10.190 --> 00:25:13.890
But you actually have to do it
specifically from the arguments.

00:25:14.910 --> 00:25:18.680
And that's semantically a lot better
than just relying on the point between

00:25:19.120 --> 00:25:21.460
your vFork and exec to do those things.

00:25:23.890 --> 00:25:28.240
So you get all the speed benefits of
going to VFork without kind of being

00:25:28.240 --> 00:25:33.280
out there in the open and exposed to
bugs and reliability in your system.

00:25:33.340 --> 00:25:38.500
So just as an example here,
I put some of the syntax.

00:25:38.500 --> 00:25:41.790
And this just basically
is positive spawn.

00:25:41.800 --> 00:25:45.560
You have to give it a PID to return.

00:25:45.640 --> 00:25:47.300
You have to get what it's going to exec.

00:25:47.300 --> 00:25:53.490
In this case, it's just going to do
a cat on etsy password.

00:25:53.700 --> 00:25:59.100
These null arguments here is where you
would actually put arguments to actually

00:25:59.100 --> 00:26:07.420
pass the either the file descriptors
or change the user and group IDs.

00:26:07.640 --> 00:26:12.770
And then you basically have the
arguments to the command that

00:26:12.770 --> 00:26:17.900
you're execing and the environment
that you'd want to pass into it.

00:26:20.700 --> 00:26:23.530
So we encourage people to look
at POSIX Spawn if you're using

00:26:23.590 --> 00:26:28.790
Fork and Exec in your programs
and take advantage of that.

00:26:31.010 --> 00:26:40.270
This last developer feature I'm
really excited about is Dtrace.

00:26:44.910 --> 00:26:48.840
So if you went to the
developer state of the union,

00:26:48.930 --> 00:26:51.660
you heard that Ted talked
a lot about X-Ray.

00:26:51.680 --> 00:26:55.480
And D-Trace is really kind of
the fundamental building block

00:26:55.500 --> 00:27:00.700
of X-Ray and being able to
make custom X-Ray instruments.

00:27:01.010 --> 00:27:06.180
This is a port of OpenSolaris
of their dynamic tracing.

00:27:06.440 --> 00:27:11.700
And it's used for profiling,
isolating code paths, exploring behaviors

00:27:12.110 --> 00:27:13.320
across the entire system.

00:27:13.320 --> 00:27:16.310
It goes through kernel and user code.

00:27:16.470 --> 00:27:18.380
The design is really great.

00:27:18.460 --> 00:27:26.120
It's really designed to be near
zero overhead in production systems.

00:27:43.030 --> 00:27:43.370
So, I'm going to talk about some of
the kind of new technology in the

00:27:43.370 --> 00:27:43.370
industry in that most of the profiling
tools that you had were either on

00:27:43.370 --> 00:27:43.370
while you were developing or kind
of on test systems that were set up,

00:27:43.370 --> 00:27:43.370
and you had to use special
software to use it.

00:27:43.370 --> 00:27:43.370
And this is compiled in.

00:27:44.460 --> 00:27:50.210
It basically uses a set of static
probe points that are around what

00:27:50.210 --> 00:27:52.370
we'll call contended routines.

00:27:52.370 --> 00:27:55.830
And these are routines that you have
to carefully get the information out

00:27:55.910 --> 00:27:58.280
of because of locking primitives,
etc.

00:28:00.410 --> 00:28:06.580
And then it also does dynamic probe
points dynamically in the code.

00:28:06.580 --> 00:28:12.380
And it will actually go in and insert
code in line to pull out the profiles.

00:28:12.420 --> 00:28:16.640
So this means in a production system,
it has very little effect at all,

00:28:16.990 --> 00:28:19.060
near zero overhead.

00:28:19.080 --> 00:28:21.700
Because the static
trace points are no ops,

00:28:21.700 --> 00:28:24.800
and the dynamic trace points
are in the code at all.

00:28:24.810 --> 00:28:26.540
And when you actually
turn on the tracing,

00:28:26.540 --> 00:28:28.630
it's relatively lightweight.

00:28:28.640 --> 00:28:32.270
It only traces the points
that you have specified.

00:28:32.710 --> 00:28:37.000
And you can feel safe about turning
this on in production systems and

00:28:37.060 --> 00:28:40.460
being able to see what behaviors
are going on in the system.

00:28:45.280 --> 00:28:51.230
So this is just a short example of
showing that this basically will

00:28:51.240 --> 00:28:57.000
return any processes in the system
that are trying to do the kill syscall,

00:28:57.210 --> 00:29:01.270
so trying to send kill
signals to other processes.

00:29:01.390 --> 00:29:03.480
And you basically can just
run this on the system,

00:29:03.480 --> 00:29:07.540
and it will start giving you exactly
which processes are running kill.

00:29:07.540 --> 00:29:10.090
And you can go explore from there.

00:29:10.590 --> 00:29:14.940
There are just thousands of uses
that you can make scripts for.

00:29:14.940 --> 00:29:21.490
The D language is a scripting
language akin to more like awk.

00:29:21.650 --> 00:29:26.420
It's a little esoteric,
but for all the old Unix hands,

00:29:26.420 --> 00:29:30.270
it probably looks familiar in a way.

00:29:31.620 --> 00:29:35.200
And there's two talks
that I'll refer you to.

00:29:35.230 --> 00:29:39.080
One is we have a
dedicated talk to DTrace.

00:29:39.100 --> 00:29:45.480
And that will go over the
D language in much more detail.

00:29:45.710 --> 00:29:52.950
The performance analysis tools talk,
which will talk about X-Ray and how they

00:29:52.950 --> 00:29:55.760
make custom instruments out of D-Trace.

00:29:55.880 --> 00:30:03.290
X-Ray is a great UI on top of D-Trace
to allow you to do these system traces

00:30:03.290 --> 00:30:10.230
graphically and see them in real time,
what your application is doing.

00:30:14.390 --> 00:30:16.460
So I'll move on to some
infrastructure features.

00:30:16.460 --> 00:30:26.400
So we're starting to see
larger and larger systems

00:30:27.900 --> 00:30:30.100
coming out of the Mac division.

00:30:32.100 --> 00:30:35.110
The newest Mac Pros that we just
released are the largest yet.

00:30:36.000 --> 00:30:42.040
They're two dual core processors,
so they really look

00:30:42.040 --> 00:30:44.970
like a four core system.

00:30:44.970 --> 00:30:50.230
It supports 16 gigabytes of RAM.

00:30:52.690 --> 00:30:55.920
And we're also starting to see
that the apps are more demanding.

00:30:56.090 --> 00:31:00.740
We're definitely pushing the
envelope on graphics performance

00:31:00.740 --> 00:31:04.470
and I think what Peter Graffagnino
referred to as wow factor.

00:31:04.500 --> 00:31:10.870
And the frameworks are starting to
support this easily on the system.

00:31:11.200 --> 00:31:16.680
So we're seeing ever increasing number
of threads usually take advantage

00:31:16.770 --> 00:31:19.730
of the multi-core architecture.

00:31:20.500 --> 00:31:23.760
And these applications are
accessing a lot more data,

00:31:23.760 --> 00:31:26.760
and they're a lot more media intensive.

00:31:26.840 --> 00:31:29.670
And we don't really see
these trends lighting up.

00:31:32.960 --> 00:31:39.550
So to keep up with those trends,
we're going to do some enhancements to

00:31:39.550 --> 00:31:44.530
the kernel itself to make sure that it
transparently still gives performance to

00:31:44.530 --> 00:31:47.190
the upper layers of the software stack.

00:31:48.720 --> 00:31:50.530
So a couple of these enhancements.

00:31:50.600 --> 00:31:55.000
The first one is the
schedule architecture itself.

00:31:55.000 --> 00:31:59.470
And we've always used a
flat scheduler architecture,

00:31:59.470 --> 00:32:04.540
where all the processes and threads
actually go into a flat run queue.

00:32:04.560 --> 00:32:08.880
We're moving that model to a hierarchical
model that will actually reflect

00:32:09.020 --> 00:32:12.760
the hardware that it's being run on.

00:32:14.750 --> 00:32:17.390
The load balancing between that
hierarchy will be automatic

00:32:18.180 --> 00:32:20.770
and transparent to the user.

00:32:22.820 --> 00:32:26.500
And we're also going to do
more idle processing without

00:32:26.500 --> 00:32:28.440
actually using an idle thread.

00:32:28.440 --> 00:32:31.190
And that will actually reduce some
of the context switch over time

00:32:31.190 --> 00:32:33.600
that we see in our current system.

00:32:36.300 --> 00:32:39.640
But the important thing to take away
from this is through all the switching,

00:32:39.640 --> 00:32:43.500
we're going to maintain our interfaces
and our current system behaviors.

00:32:43.510 --> 00:32:48.380
So all the real time
scheduling interfaces,

00:32:48.480 --> 00:32:51.780
you'll see the same
interfaces being exported.

00:32:51.780 --> 00:32:54.540
All the priority interfaces,
they'll be exported too.

00:32:54.540 --> 00:33:00.010
And this should just be transparent
to the applications themselves.

00:33:04.010 --> 00:33:08.030
Likewise, in the virtual memory space,
we're actually doing some more

00:33:08.030 --> 00:33:12.760
advanced paging algorithms to
support the larger memory and

00:33:12.760 --> 00:33:16.370
the greater use of that memory.

00:33:17.320 --> 00:33:20.960
We'll be changing our working set
algorithms to be more efficient as well,

00:33:20.960 --> 00:33:24.700
so that the code that you're actually
running in your application should

00:33:24.700 --> 00:33:27.930
be stored in memory more efficiently.

00:33:30.970 --> 00:33:34.600
We're actually making changes
to the dynamic pagers so we can

00:33:34.600 --> 00:33:37.810
allocate swap files on demand.

00:33:38.520 --> 00:33:43.040
Instead of keeping on increasing the
swap file space and only using that.

00:33:43.080 --> 00:33:46.900
So that will actually limit the
amount of swap files that are on disk,

00:33:46.900 --> 00:33:49.370
or the size of the swap files on disk.

00:33:52.700 --> 00:33:56.430
Another area that we have to look
at when we're looking at these

00:33:56.490 --> 00:33:59.340
larger machines is resource limits.

00:33:59.340 --> 00:34:03.460
And we've kind of looked
all the way through all the

00:34:03.460 --> 00:34:05.780
resource limits in the system.

00:34:06.150 --> 00:34:10.390
What we're wanting to do in
Leopard is actually target a

00:34:10.390 --> 00:34:13.840
number of them to become dynamic.

00:34:13.840 --> 00:34:16.650
An example of that is
the number of open files,

00:34:16.970 --> 00:34:21.340
so that we can actually scale up the
number of open files according to the

00:34:21.340 --> 00:34:25.480
size of the system and according to
the application workload dynamically,

00:34:25.480 --> 00:34:28.520
so you don't have to set
it on the system at all.

00:34:31.430 --> 00:34:34.740
Likewise,
we are actually adding support to

00:34:34.740 --> 00:34:40.040
cloning device drivers and this
actually means more terminal drivers or

00:34:40.040 --> 00:34:42.530
TTYs will be available to the system.

00:34:42.770 --> 00:34:46.450
And probably the thing to note
there is if you have an application

00:34:46.890 --> 00:34:53.380
such as VPN or a heavy use of
consoles in your application,

00:34:53.380 --> 00:34:57.020
there should just be more TTYs
available on the system to be

00:34:57.040 --> 00:34:59.160
able to write the application.

00:35:04.910 --> 00:35:07.660
We're also looking at some of
the default limits on the system

00:35:07.660 --> 00:35:10.880
and we're having to bump them up
because we're just supporting larger

00:35:10.880 --> 00:35:13.800
machines and larger workloads.

00:35:13.800 --> 00:35:20.250
So, for example, previous to Leopard,
we're only supporting 100

00:35:20.320 --> 00:35:25.210
processes per user and now
we're bumping that up to 266.

00:35:26.400 --> 00:35:31.500
[Transcript missing]

00:35:32.000 --> 00:35:34.960
And the last thing is we're actually
going to start enforcing some limits

00:35:35.030 --> 00:35:36.800
that were never enforced before.

00:35:37.680 --> 00:35:40.540
In the mating of Mach and BSD,
some of these limits actually

00:35:40.540 --> 00:35:42.340
don't span that boundary.

00:35:42.440 --> 00:35:46.150
And we're actually going through and
re-architecting the accounting for some

00:35:46.220 --> 00:35:49.960
of the resources to make sure that we can
actually enforce some of these limits.

00:35:49.960 --> 00:35:55.320
And most of these limits are
actually per application.

00:35:55.620 --> 00:35:58.420
So I've listed out some of them here.

00:35:58.510 --> 00:36:02.500
The maximum virtual address space,
the maximum resident memory size,

00:36:02.600 --> 00:36:06.500
and the maximum amount of
wired memory in the system.

00:36:06.530 --> 00:36:07.710
And we'll actually hook those up.

00:36:07.830 --> 00:36:12.700
They were completely unlimited before,
but being completely unlimited will

00:36:12.720 --> 00:36:17.820
also allow a rogue app or an app
that's not well behaved to go ahead

00:36:17.820 --> 00:36:19.350
and use everything on the system.

00:36:19.540 --> 00:36:23.500
And that's not the behavior
that we want for our system.

00:36:26.750 --> 00:36:31.640
A little bit about
security infrastructure.

00:36:31.640 --> 00:36:38.560
One of the things that we took a
hard look at for the Intel transition

00:36:38.560 --> 00:36:40.580
was the use of task for PID.

00:36:42.220 --> 00:36:46.390
Task for PID is actually part of
the Mach messaging infrastructure,

00:36:46.390 --> 00:36:49.890
and it allows you to get a task
port for any PID on the system.

00:36:49.940 --> 00:36:53.300
And it allows you to
inspect that task port.

00:36:53.330 --> 00:36:58.300
And starting with our Intel machines,
our Tiger-based Intel machines,

00:36:58.300 --> 00:37:03.240
we actually kind of locked down
the security of Task for PID.

00:37:03.240 --> 00:37:05.880
Task for PID is a very powerful tool.

00:37:05.880 --> 00:37:10.760
It also can be a relatively dangerous
tool if it's not used correctly.

00:37:10.940 --> 00:37:14.520
So we wanted to make sure that it
had proper privileges around it.

00:37:17.580 --> 00:37:21.680
So that behavior on the Tiger-based
Intel systems is that processes

00:37:21.680 --> 00:37:25.830
are allowed to inspect their
own task port without a problem.

00:37:25.880 --> 00:37:32.830
But they must be privileged to
inspect another process's ports,

00:37:32.920 --> 00:37:36.120
meaning privileged that
they'll have to run as root.

00:37:36.520 --> 00:37:39.480
Now, we had to make an exception
because a lot of our debug tools

00:37:39.560 --> 00:37:42.710
use TaskForPid to do their job.

00:37:42.710 --> 00:37:50.300
So we actually made a separate set of
groups called proc view and proc mod

00:37:50.360 --> 00:37:54.550
that will allow you to get task ports
for other processes in the system.

00:37:55.440 --> 00:38:01.850
But you have to be set GID, those groups,
and you also have to

00:38:01.850 --> 00:38:04.190
be a related process.

00:38:04.600 --> 00:38:09.600
Now currently what we call a
related process is basically that

00:38:09.600 --> 00:38:12.360
the effective UID is the real UID.

00:38:13.720 --> 00:38:16.770
In Leopard,
the thing that will change about that is

00:38:16.770 --> 00:38:21.600
we'll probably be a little bit stricter
about how we define a related process.

00:38:21.600 --> 00:38:26.630
We'll probably use group sets and
saved UIDs to make sure that we're

00:38:26.640 --> 00:38:33.290
a little bit tighter about which
processes these debug tools can inspect.

00:38:34.570 --> 00:38:38.960
An example of debug tools that
use this mechanism is GDB and

00:38:38.960 --> 00:38:42.000
Sample and malloc-debug.

00:38:42.010 --> 00:38:47.930
Most applications never
use this mechanism.

00:38:53.270 --> 00:39:00.550
So another area of security that
we're looking at is actually creating

00:39:01.010 --> 00:39:07.440
policies for more access controls
in the lower levels of the system.

00:39:07.470 --> 00:39:13.990
So we're adopting the mandatory
access control framework.

00:39:17.920 --> 00:39:20.830
So this was originally
developed for trusted BSD.

00:39:20.890 --> 00:39:24.520
It was ported in the community to Darwin.

00:39:24.520 --> 00:39:28.800
It was a great starting point to
start from for our architecture.

00:39:29.740 --> 00:39:34.700
It's basically an architecture for
authorization points in the kernel.

00:39:34.700 --> 00:39:37.120
The authorization actually
works via a callout mechanism,

00:39:37.120 --> 00:39:39.780
so you can actually implement
the policy out in user space.

00:39:39.780 --> 00:39:43.600
Examples of these policies
are things like SE Darwin,

00:39:43.600 --> 00:39:48.000
which is, as you can imagine,
similar to what SE Linux does,

00:39:48.040 --> 00:39:50.940
if you're familiar with that project.

00:39:51.530 --> 00:39:53.750
But you can have other policies.

00:39:53.750 --> 00:39:57.940
There's a BIBA policy and many
other different policies that

00:39:57.940 --> 00:40:00.180
can be implemented this way.

00:40:01.800 --> 00:40:08.150
It works through having labels
on objects and subjects.

00:40:08.160 --> 00:40:13.200
And objects are things like sockets,
file system objects,

00:40:13.210 --> 00:40:16.610
and subjects are things like processes.

00:40:16.860 --> 00:40:20.070
And these labels are actually
stored persistently in our

00:40:20.070 --> 00:40:23.390
extended attribute architecture.

00:40:23.830 --> 00:40:28.030
And then there's a mechanism to
load policies and arbitrate between

00:40:28.030 --> 00:40:29.680
multiple policies in the system.

00:40:29.680 --> 00:40:33.680
You can actually layer these
policies on top of each other.

00:40:35.090 --> 00:40:38.520
Note that we're not actually
exporting the interfaces in Leopard

00:40:39.060 --> 00:40:41.990
to use this directly by developers.

00:40:42.220 --> 00:40:46.230
What we want to do is create this
infrastructure and create a simpler

00:40:46.230 --> 00:40:53.420
mechanism to use it by the upper
level applications in the system.

00:40:55.290 --> 00:40:58.560
We are actually adding sandboxing
support in Leopard as well.

00:40:58.560 --> 00:41:03.530
Now, there's actually a lot more
about this from the security

00:41:03.530 --> 00:41:05.740
team in a separate session,
but I just want to kind of

00:41:05.740 --> 00:41:07.160
introduce you to the concept.

00:41:07.160 --> 00:41:10.540
It's based on the Mac framework.

00:41:10.580 --> 00:41:14.150
It's basically a process-based sandbox.

00:41:14.240 --> 00:41:16.600
It's defined by a text profile.

00:41:16.600 --> 00:41:22.230
It has a language that those
profiles are written in that the

00:41:22.230 --> 00:41:25.960
sandboxing engine interprets.

00:41:28.150 --> 00:41:31.490
It doesn't require any
special privileges to use it,

00:41:31.720 --> 00:41:35.580
but you cannot escalate
privileges based on it.

00:41:36.110 --> 00:41:39.100
This is actually included
in the developer seed,

00:41:39.130 --> 00:41:45.000
and there's some examples in user share
sandbox of profiles being applied to,

00:41:45.000 --> 00:41:47.900
I think, three system daemons.

00:41:49.090 --> 00:41:52.310
And it's designed to be very
cooperative with applications.

00:41:52.350 --> 00:41:54.460
It's really designed
with you guys in mind.

00:41:54.490 --> 00:41:57.150
We'd really like to have
your feedback on this.

00:41:57.190 --> 00:42:00.530
The idea is that if you have
an application that just

00:42:00.530 --> 00:42:04.020
needs one set of privileges,
that you can write a profile that

00:42:04.020 --> 00:42:08.390
will sandbox it and only allow
that one set of privileges out.

00:42:10.010 --> 00:42:15.070
And there's a lot more information
in the security talk about this.

00:42:20.090 --> 00:42:24.420
So just to summarize
some of the points here.

00:42:24.970 --> 00:42:30.980
For data-intensive applications,
welcome to a fully 64-bit enabled world.

00:42:31.500 --> 00:42:34.140
We kind of put a lot of this
infrastructure in Tiger,

00:42:34.210 --> 00:42:38.110
and we're going to reap all
the benefits of it in Leopard.

00:42:41.440 --> 00:42:45.580
So we're believers in standards,
and we believe standards are good.

00:42:45.600 --> 00:42:47.060
It helps in porting applications.

00:42:47.060 --> 00:42:51.290
It helps you guys to see a
common set of interfaces.

00:42:51.300 --> 00:42:55.740
But be aware that we've made some
changes here from our legacy behavior.

00:42:55.740 --> 00:43:00.040
And make sure you don't step in
any of the potholes involved.

00:43:00.080 --> 00:43:07.510
We are still very committed to
the open source Darwin kernel.

00:43:09.820 --> 00:43:15.360
We believe DTrace is a great tool
throughout the system for you guys to

00:43:15.360 --> 00:43:20.570
actually explore the system behaviors and
optimize your applications on the system.

00:43:24.250 --> 00:43:28.550
And the last point is just feel
confident that the kernel on

00:43:28.880 --> 00:43:32.570
Mac OS X is keeping up the performance
and scaling for your application,

00:43:32.680 --> 00:43:34.490
hopefully completely transparent to you.

00:43:34.490 --> 00:43:38.590
The whole idea of the kernel is that
we help you by running your system

00:43:38.920 --> 00:43:41.300
as fast as possible on the hardware.