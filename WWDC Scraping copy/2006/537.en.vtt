WEBVTT

00:00:10.830 --> 00:00:14.740
Today we're going to
be looking at Java SE6.

00:00:14.740 --> 00:00:17.760
If you were in the last session,
you heard about Mustang.

00:00:17.760 --> 00:00:20.380
Mustang and Java SE6
are one and the same.

00:00:20.380 --> 00:00:22.860
We're going to be
talking about what's new,

00:00:22.870 --> 00:00:25.380
the 64-bit JVM, and performance.

00:00:25.380 --> 00:00:29.580
We're from the Java Virtual Machine team.

00:00:29.580 --> 00:00:34.920
Normally we're down very deep, down,
down, below your application.

00:00:34.920 --> 00:00:38.870
You don't hear much from
us unless things go wrong.

00:00:39.030 --> 00:00:43.620
But every 12 months or so,
we crawl out of our holes and tell you

00:00:43.620 --> 00:00:45.450
what's new in the virtual machine world.

00:00:45.480 --> 00:00:50.760
So today, I'd like to...

00:00:52.920 --> 00:00:57.480
fill you in enough so that you can
answer the following questions.

00:00:57.480 --> 00:01:00.670
So, Java SE 6, what is it?

00:01:00.670 --> 00:01:02.300
What's new?

00:01:02.300 --> 00:01:08.320
And how is Apple enhancing
the Java SE experience?

00:01:08.320 --> 00:01:13.760
Like you to know what the
Java 64-bit virtual machine is,

00:01:13.760 --> 00:01:19.230
and I'd like you to know what some of the
tools are that you can use to understand

00:01:19.230 --> 00:01:23.360
what your Java application is doing,
and I'd like you to know and be

00:01:23.360 --> 00:01:25.180
able to answer just how does--.

00:01:27.600 --> 00:03:37.700
[Transcript missing]

00:03:37.760 --> 00:03:42.200
the Java C compiler,
but it's been hard and it's not been

00:03:42.200 --> 00:03:47.060
standardized so that you can be assured
that it's going to work through releases.

00:03:47.060 --> 00:03:49.400
And now through the
efforts of the standards,

00:03:49.400 --> 00:03:52.370
the JSR group 199,
and by the way if you want more

00:03:52.370 --> 00:03:58.790
information on these particular items,
search for JSR 199 on the web,

00:03:58.790 --> 00:04:02.220
there's an API that allows
you to use a compiler.

00:04:02.220 --> 00:04:06.700
And here's some code fragments that will
give you a flavor of what it's like.

00:04:06.700 --> 00:04:11.780
So on the top line here,
I can ask the runtime environment

00:04:11.780 --> 00:04:18.160
for the system Java compiler and it
returns a compiler object and I can

00:04:18.160 --> 00:04:23.990
take that compiler object and build
up tasks which are like compile

00:04:23.990 --> 00:04:26.320
this file and compile that file.

00:04:26.320 --> 00:04:30.280
And then if I take the task
and say get result on it,

00:04:30.280 --> 00:04:36.700
it will actually do the
compilation and return the-- Yeah.

00:04:36.700 --> 00:04:45.760
--compiled result which I can then load
through a class loader and then execute,

00:04:45.780 --> 00:04:47.870
call things through reflection.

00:04:48.110 --> 00:04:51.380
Now this gives you a
flavor of what it's like.

00:04:51.380 --> 00:04:52.380
It's still complicated.

00:04:52.380 --> 00:04:56.590
A Hello World example where you
take a simple Hello World program

00:04:56.710 --> 00:05:00.140
as a Java's text string,
compile it and execute it,

00:05:00.240 --> 00:05:01.850
it's about two pages of code.

00:05:01.860 --> 00:05:04.100
But it's a whole lot
easier than it used to be.

00:05:04.100 --> 00:05:06.530
It's complicated because
you have to set up.

00:05:06.700 --> 00:05:11.220
You have to set up kind of file
system objects to represent

00:05:11.230 --> 00:05:13.540
your text string as a file.

00:05:13.540 --> 00:05:18.220
You also have to set up paths so
that you can get back from the

00:05:18.370 --> 00:05:23.120
compiler the stream of any error
messages or warning messages.

00:05:23.210 --> 00:05:26.770
But in the end,
you get the ability to take

00:05:26.790 --> 00:05:31.820
Java text inside your code and
turn it into Java programs,

00:05:31.820 --> 00:05:34.620
Java methods that you can execute.

00:05:34.630 --> 00:05:36.080
And so the way this will change.

00:05:36.080 --> 00:05:39.050
The way this will change programming
is that you can actually use Java as

00:05:39.050 --> 00:05:44.760
kind of a scripting language and take
expressions or other program fragments,

00:05:44.760 --> 00:05:49.520
combine them with a context and
compile them and execute them.

00:05:49.520 --> 00:05:49.960
Pretty powerful.

00:05:51.700 --> 00:06:02.000
[Transcript missing]

00:06:02.410 --> 00:06:06.300
People started using annotations for,
well, there were the standard things

00:06:06.300 --> 00:06:12.520
that had been kind of there before,
like deprecation and Java doc comments.

00:06:12.520 --> 00:06:20.600
But using the Java 5 APT processor
for annotations turned out to be more

00:06:20.600 --> 00:06:22.610
difficult than anybody anticipated.

00:06:22.620 --> 00:06:27.250
So with Java 6,
there's a pluggable annotation processing

00:06:27.310 --> 00:06:32.460
API where you can write plug-ins that
don't have to do all of the work of,

00:06:32.460 --> 00:06:35.040
you know,
searching through the entire program.

00:06:35.040 --> 00:06:38.470
You can actually just write plug-ins
for the particular annotations

00:06:38.530 --> 00:06:40.070
that you're interested in.

00:06:40.100 --> 00:06:43.670
And you also have access to
what the parse tree looks like.

00:06:43.830 --> 00:06:45.280
Pretty powerful stuff as well.

00:06:47.020 --> 00:06:47.990
Scripting languages.

00:06:48.000 --> 00:06:50.700
There's a new scripting
language access API.

00:06:50.950 --> 00:06:55.970
And just looking on the internet,
I found references to almost every

00:06:55.970 --> 00:06:59.320
scripting language under the sun,
including AppleScript,

00:06:59.320 --> 00:07:02.610
that people are working on using
this API to plug into Java.

00:07:02.660 --> 00:07:08.510
So that when we get some experience
with scripting languages,

00:07:08.510 --> 00:07:13.360
you'll have much easier access
to JavaScript and a zillion

00:07:13.360 --> 00:07:13.360
other scripting languages.

00:07:13.950 --> 00:07:17.010
And lastly, I want to talk about
pre-verified class files.

00:07:17.030 --> 00:07:20.340
This doesn't change the language
so much in terms of how you use it,

00:07:20.390 --> 00:07:24.350
but it does have some interesting
things that you should know about.

00:07:24.380 --> 00:07:26.620
Let me go into detail.

00:07:26.620 --> 00:07:32.160
What split class file verification is,
is that in Java 5 and before,

00:07:32.160 --> 00:07:34.740
when you load a class
into the virtual machine,

00:07:34.740 --> 00:07:39.440
it has to verify the bytecodes to make
sure that you're not doing something

00:07:39.440 --> 00:07:43.640
that's either unsafe or malicious
that would harm the virtual machine,

00:07:43.640 --> 00:07:47.500
or give you access to things your
program isn't supposed to have access to.

00:07:47.500 --> 00:07:53.860
And there's a cost involved in
executing that verification.

00:07:53.860 --> 00:08:00.590
In order to make loading of classes
and execution startup time faster,

00:08:01.010 --> 00:08:07.680
what Java 6 has is it's split between a
compile time phase and a runtime phase.

00:08:07.680 --> 00:08:13.600
At compile time, the Java C compiler in
Java 6 now compiles.

00:08:13.640 --> 00:08:18.940
It compiles stack map attributes that
tell in the bytecodes at given points

00:08:18.940 --> 00:08:24.360
what can be on the stack at any given
point in terms of what type of objects.

00:08:24.360 --> 00:08:28.080
And the reason why this allows
us to increase speed and still

00:08:28.080 --> 00:08:32.620
maintain security is that these stack
maps are kind of hard to compute,

00:08:32.620 --> 00:08:36.580
but we can quickly
verify them at runtime.

00:08:36.580 --> 00:08:40.930
So improved startup time,
Sun is claiming 50%

00:08:40.980 --> 00:08:43.580
faster verification time.

00:08:43.640 --> 00:08:45.290
We haven't timed it ourselves.

00:08:45.340 --> 00:08:50.500
The downside of this is that
Java 6 has a new class file format.

00:08:50.500 --> 00:08:53.940
So if you're distributing class
files that are going to run

00:08:54.040 --> 00:08:58.420
on earlier virtual machines,
you need to use the dash target options

00:08:58.960 --> 00:09:04.420
to create class files that will run
on those earlier virtual machines,

00:09:04.420 --> 00:09:06.320
and they won't have the split
class file verification.

00:09:08.550 --> 00:09:10.070
Okay, library support.

00:09:10.120 --> 00:09:15.080
A few new features that come from
down deep in the virtual machine.

00:09:15.080 --> 00:09:18.300
Something that people have been
asking for for ages is now here,

00:09:18.300 --> 00:09:22.910
the ability to find out how much
free disk space is on the machine.

00:09:22.920 --> 00:09:27.090
There's some faster zip and
jar file access routines,

00:09:27.090 --> 00:09:31.380
which speed up things all
over a network file system.

00:09:31.380 --> 00:09:33.690
So if you're remote
executing over the network,

00:09:33.690 --> 00:09:36.010
you'll notice some
speed differences there.

00:09:37.780 --> 00:09:40.080
There are a bunch of
new concurrent classes.

00:09:40.100 --> 00:09:44.130
So if you're doing multi-threaded
programming and you've been

00:09:44.130 --> 00:09:47.460
using the concurrent classes,
well, if you haven't been using

00:09:47.460 --> 00:09:49.610
the concurrent classes,
you should definitely check them out.

00:09:49.660 --> 00:09:55.270
But there are some new concurrent
queues and several other classes,

00:09:55.270 --> 00:10:00.680
such as concurrent skip lists,
if you're indexing data by key.

00:10:00.680 --> 00:10:01.830
Okay.

00:10:02.750 --> 00:10:04.380
Okay, attach on demand.

00:10:04.380 --> 00:10:06.010
What is it?

00:10:06.110 --> 00:10:11.080
Well, let me take you back to Java 5 and
talk about what we didn't have there.

00:10:11.080 --> 00:10:15.010
In Java 5,
you saw a bunch of new monitoring tools,

00:10:15.010 --> 00:10:19.430
but you had to start up your
program with a special flag in order

00:10:19.580 --> 00:10:22.110
to turn on the monitoring tool.

00:10:22.620 --> 00:10:25.680
Now, for a server application,
such as something that's

00:10:25.700 --> 00:10:28.890
been running in production,
you didn't turn those on because

00:10:28.890 --> 00:10:30.260
there was a cost penalty.

00:10:30.260 --> 00:10:34.350
And by the time you realized that
there was something going on,

00:10:34.390 --> 00:10:38.710
it had been running for a day,
and there was no way to figure out how it

00:10:38.710 --> 00:10:41.690
was going on because you forgot the flag.

00:10:41.690 --> 00:10:44.250
And you wouldn't have put it on
in the first place because it's

00:10:44.250 --> 00:10:46.970
a production environment and
it was costing you performance.

00:10:46.980 --> 00:10:50.840
So in Java 6,
we introduce attach on demand.

00:10:50.840 --> 00:10:52.600
And this is a new protocol.

00:10:52.650 --> 00:10:55.010
This is a new protocol inside of
the virtual machine that allows a

00:10:55.010 --> 00:10:57.440
tool to talk to the virtual machine.

00:10:57.470 --> 00:11:00.560
And it doesn't cost you
anything until you use it.

00:11:00.700 --> 00:11:04.020
And when you do use it,
the tool will send a signal

00:11:04.020 --> 00:11:07.590
to the virtual machine,
interrupt it for a moment,

00:11:07.720 --> 00:11:12.180
and then send it one of several
commands that it knows about in order

00:11:12.300 --> 00:11:14.830
to execute and fire up the tool.

00:11:14.840 --> 00:11:21.740
So it supports the Java lang
instrument and JVMTI tool interface.

00:11:22.620 --> 00:11:28.860
And several other of these tools that
can now talk to the virtual machine.

00:11:28.860 --> 00:11:31.980
And as I said before,
great for a server environment because

00:11:32.120 --> 00:11:35.400
you can run in production mode,
yet when something seems weird,

00:11:35.400 --> 00:11:36.710
you can check it out.

00:11:36.760 --> 00:11:38.050
So let's go ahead and check it out.

00:11:39.120 --> 00:11:42.280
something that people have been
asking for for a long time,

00:11:42.280 --> 00:11:45.700
they install an experimental
version of the virtual machine,

00:11:45.700 --> 00:11:48.340
and they go to the command
line and they type Java,

00:11:48.340 --> 00:11:52.340
and they get the standard official
version that's installed on Mac OS,

00:11:52.340 --> 00:11:55.460
and they want to be able to test
it out from the command line.

00:11:55.460 --> 00:12:00.440
Well, we now allow you to change
the command line execution

00:12:00.440 --> 00:12:02.590
via the Java preferences pane.

00:12:02.600 --> 00:12:07.100
So this is the Java preferences
tool in Java 6.

00:12:07.280 --> 00:12:13.300
It looks pretty much like the Java 5 one,
but if you change the setting

00:12:13.300 --> 00:12:16.890
at the top of the list of the...

00:12:18.460 --> 00:12:24.180
So, the JVM version that's
specified for applications,

00:12:24.210 --> 00:12:27.750
it also changes it on the command line.

00:12:27.820 --> 00:12:32.300
Note that applications in their
plist encoding can specify

00:12:32.300 --> 00:12:36.300
which versions of Java that they
need and must have to execute,

00:12:36.300 --> 00:12:38.920
and so they pick the first
acceptable version on this list,

00:12:38.920 --> 00:12:41.340
but the command line will
always pick the top list.

00:12:41.340 --> 00:12:45.300
So, here I've set it to Java 6.

00:12:46.550 --> 00:12:50.000
So with my command line
now set to run Java 6,

00:12:50.000 --> 00:12:55.420
I want to give you some examples of
some new features that you can use for

00:12:55.420 --> 00:12:59.520
monitoring and measuring under Java 6.

00:13:04.120 --> 00:13:10.000
The jhat command is a
new heap analysis tool,

00:13:10.060 --> 00:13:12.630
and I'll give you an example of that.

00:13:13.840 --> 00:13:18.190
The JMAP command, which was in Java 5,
has some new options.

00:13:18.280 --> 00:13:22.960
Finalizer Info tells you things
going on in finalization.

00:13:22.970 --> 00:13:27.210
And the dump option works
with the Jhat command.

00:13:27.480 --> 00:13:28.410
We'll talk about that.

00:13:28.420 --> 00:13:30.180
I'll show you an example.

00:13:31.450 --> 00:13:34.080
JConsole is new and improved.

00:13:34.090 --> 00:13:36.230
I'll run through some examples there.

00:13:36.390 --> 00:13:40.000
JInfo, and I'll show you that.

00:13:40.050 --> 00:13:44.650
And DTrace, later on in the talk,
one of my colleagues will tell you

00:13:44.650 --> 00:13:49.770
about how DTrace support works in
Java in the Hotspot virtual machine.

00:13:52.100 --> 00:13:54.550
JConsole is new and improved.

00:13:54.550 --> 00:13:56.920
I'll run through some examples there.

00:13:56.920 --> 00:14:00.660
JInfo, and I'll show you that.

00:14:00.660 --> 00:14:05.250
And DTrace, later on in the talk,
one of my colleagues will tell you

00:14:05.250 --> 00:14:10.380
about how DTrace support works in
Java in the Hotspot virtual machine.

00:14:22.000 --> 00:14:25.940
For now, we're limited to examining
processes on the same machine.

00:14:25.940 --> 00:14:30.360
We do not have the Solaris-only
right now capability to examine

00:14:30.360 --> 00:14:32.140
processes on another machine.

00:14:34.450 --> 00:14:40.720
So, JInfo is a tool that you
give it a process ID.

00:14:40.720 --> 00:14:46.160
We'll tell you all of the properties of
the Java process that it is running with.

00:14:46.330 --> 00:14:48.780
So, for example,
if you're not finding a class

00:14:48.930 --> 00:14:53.590
in a running application and
you want to figure out...

00:14:55.140 --> 00:14:55.490
Excuse me.

00:14:55.600 --> 00:14:59.340
You want to figure out which class
path you executed the command with?

00:14:59.370 --> 00:15:03.640
Well, you can do that by simply
examining the process with JINFO.

00:15:04.030 --> 00:15:07.770
It will also tell you, for example,
which garbage collector flags and other

00:15:07.770 --> 00:15:10.650
VM flags you ran the application with.

00:15:11.260 --> 00:15:17.190
JMAP is a tool that tells you
what's going on in the virtual

00:15:17.200 --> 00:15:22.270
memory system of the garbage
collected heap inside of Java.

00:15:23.700 --> 00:15:31.120
JSTACK is a command that will tell
you what stack trace for each threads

00:15:31.310 --> 00:15:33.420
For each thread,
what is the stack trace of

00:15:33.520 --> 00:15:34.600
the running application?

00:15:34.600 --> 00:15:36.270
So it just takes a snapshot
of what it's doing.

00:15:36.280 --> 00:15:39.150
So if it's not making any progress,
you can figure out what the threads

00:15:39.300 --> 00:15:40.750
are and what state they're in.

00:15:42.860 --> 00:15:48.040
JSTAT is kind of a catch-all
command that has a lot of options.

00:15:48.040 --> 00:15:50.350
If you use dash options,
you'll get a list of them.

00:15:50.360 --> 00:15:51.920
Here's the list for Mac OS X.

00:15:51.920 --> 00:15:57.420
And I've given you two examples,
one of looking at the classes

00:15:57.420 --> 00:16:02.510
that have been loaded in the
application that's running,

00:16:02.610 --> 00:16:06.990
as well as what the compiler is compiling
and how many things it's compiled so far,

00:16:06.990 --> 00:16:06.990
the just-in-time compiler.

00:16:07.740 --> 00:16:13.600
Now, JMAP-Dump is new in Java 6,
and it will take an existing running

00:16:13.600 --> 00:16:21.460
Java application and make a snapshot
of the heap of that process.

00:16:21.460 --> 00:16:23.910
So here I've directed...

00:16:25.120 --> 00:16:29.510
Here I've directed the JMAP command
to dump this information into

00:16:29.510 --> 00:16:35.300
a file called java2d.bin,
since I'm examining the Java 2D demo.

00:16:35.820 --> 00:16:41.490
So it creates this file,
and then I use the new JHAT application,

00:16:42.290 --> 00:16:46.710
monitoring application,
and it creates a web server that

00:16:47.190 --> 00:16:50.200
shows the heap analysis of the
information that's in this dump.

00:16:50.240 --> 00:16:54.670
So if I type the JHAT command and
give it this file that I just created,

00:16:54.670 --> 00:16:57.750
it tells me that it's
reading a bunch of stuff,

00:16:57.860 --> 00:17:02.250
and then at the bottom it says,
started HTTP server on port 7000.

00:17:03.040 --> 00:17:09.280
So now I go over to Safari and
load up localhost 7000,

00:17:09.280 --> 00:17:13.820
and lo and behold, here's a web page that
describes every package that's

00:17:13.840 --> 00:17:17.030
being used in the application,
and inside each package,

00:17:17.030 --> 00:17:18.200
all of the classes.

00:17:18.200 --> 00:17:22.620
And if I click on each of these classes,
it'll tell me information about that.

00:17:22.660 --> 00:17:26.310
And what I want to focus on
is at the bottom of this page,

00:17:26.310 --> 00:17:30.060
you'll see it says other queries,
and one of those queries

00:17:30.160 --> 00:17:31.940
is the peep histogram.

00:17:31.940 --> 00:17:32.330
So I'm going to go over to Safari,
and I'm going to load up localhost 7000,

00:17:32.330 --> 00:17:32.680
and lo and behold, here's a web page that
describes every package that's

00:17:32.680 --> 00:17:33.020
being used in the application.

00:17:33.020 --> 00:17:36.950
One important thing you can do here,
if you're trying to figure out

00:17:36.950 --> 00:17:38.930
where all your memory is going,

00:17:39.870 --> 00:17:44.340
is to click on this,
and it gives you an ordered list by

00:17:44.340 --> 00:17:48.650
the total amount of storage used of
objects of each class in your system,

00:17:48.740 --> 00:17:50.720
in your running application.

00:17:50.810 --> 00:17:55.630
So if I see something high up
on the list that's way more

00:17:55.640 --> 00:17:59.920
objects than I'm expecting,
chances are I have a leak in my system,

00:17:59.920 --> 00:18:04.180
and I'm hanging on to a bunch of
objects that I really shouldn't be.

00:18:06.150 --> 00:18:08.930
JConsole is new and improved in Java 6.

00:18:08.940 --> 00:18:11.550
It was in Java 5,
but now it's an official

00:18:11.750 --> 00:18:16.320
tool that's part of Java 6,
and it has some additional capabilities.

00:18:16.320 --> 00:18:17.750
So let's focus in on this.

00:18:17.760 --> 00:18:20.640
When I started it,
it gives me a list of what

00:18:20.640 --> 00:18:25.030
JPS would have given me,
a list of the running Java processes.

00:18:25.040 --> 00:18:30.220
So let's click on the java2d.jar,
and it gives me this interactive

00:18:30.220 --> 00:18:36.420
display showing me memory usage,
threads, CPU runtime,

00:18:36.420 --> 00:18:37.240
a bunch of information.

00:18:37.240 --> 00:18:41.040
And I can click on the bar on the top and
get more detailed information further.

00:18:41.040 --> 00:18:42.200
For example, here are threads.

00:18:42.260 --> 00:18:45.870
It shows me the high watermark
of the maximum number of

00:18:46.040 --> 00:18:48.220
threads I've executed so far.

00:18:48.220 --> 00:18:53.030
And it also gives me down on the bottom
part a list of all of those threads.

00:18:53.560 --> 00:18:56.700
And if I click on a given one,
it will give me specific information

00:18:56.700 --> 00:18:58.520
about what that thread is doing.

00:18:58.520 --> 00:19:03.110
So it's a very powerful interactive
tool for understanding where your

00:19:03.570 --> 00:19:07.660
Java application may be using
more resources than necessary,

00:19:07.660 --> 00:19:12.170
or where it's getting lost,
or any number of issues that you

00:19:12.170 --> 00:19:15.480
may encounter when you're trying
to make your application run as

00:19:15.480 --> 00:19:17.740
most efficiently as possible.

00:19:19.800 --> 00:19:21.460
A note about crash reporter logs.

00:19:21.530 --> 00:19:25.500
All through the past,
we've had two separate logs when

00:19:25.590 --> 00:19:27.680
Java goes wrong and crashes.

00:19:27.700 --> 00:19:31.250
There's been a crash reporter
log and a native crash log,

00:19:31.250 --> 00:19:34.780
and we always have this little
dialogue when people submit bugs.

00:19:34.780 --> 00:19:39.020
If they don't submit both of the logs,
then we have to go back and

00:19:39.020 --> 00:19:40.970
ask them for the other one.

00:19:41.110 --> 00:19:44.200
Well, in Leopard, we've fixed this,
and we've managed to get all of the

00:19:44.200 --> 00:19:46.070
information in the crash reporter log.

00:19:46.070 --> 00:19:50.100
But if you're submitting
bugs for Tiger and before,

00:19:50.390 --> 00:19:54.420
be sure to include both of those logs,
as always.

00:19:54.440 --> 00:19:58.520
And importantly,
we want to make this Java 6 release as

00:19:58.520 --> 00:20:01.760
stable as our Java 5 release and better.

00:20:01.760 --> 00:20:07.010
So when you do encounter problems
in our developer previews or on the

00:20:07.120 --> 00:20:13.580
seed that's on the Leopard disk,
send them to us, bugreporter.apple.com.

00:20:15.350 --> 00:20:17.900
So let me introduce Victor Hernandez.

00:20:17.900 --> 00:20:21.760
He's going to tell you about
the 64-bit virtual machine.

00:20:28.830 --> 00:20:29.560
I'm Victor Hernandez.

00:20:29.560 --> 00:20:32.440
I also work on the Java VM for Mac OS X.

00:20:32.510 --> 00:20:35.320
The last couple years,
we've heard a lot of feedback

00:20:35.590 --> 00:20:41.150
about how a lot of you customers
want a 64-bit JVM for Mac OS X.

00:20:41.260 --> 00:20:43.800
Well, sure enough, this year,
we actually have the hardware and

00:20:43.800 --> 00:20:46.660
the software support available
for you to be able to run your

00:20:46.710 --> 00:20:50.430
application in a 64-bit Java VM.

00:20:50.900 --> 00:20:56.470
So, what do you need to know about that,
the 64-bit Java VM?

00:20:56.540 --> 00:21:00.580
Well, if you've been to the other
64-bit sessions here at WWDC,

00:21:00.680 --> 00:21:05.180
you found out that 64-bit environment
means that pointers are now 64-bit.

00:21:05.310 --> 00:21:09.700
The native size of the pointer has
increased from 32-bit to 64-bit.

00:21:09.760 --> 00:21:14.310
Okay, so what does that mean for Java?

00:21:14.390 --> 00:21:16.910
Well,
what it means for your application is...

00:21:17.300 --> 00:21:33.800
[Transcript missing]

00:21:33.930 --> 00:21:37.170
Just like a year ago,
you didn't have to do much to

00:21:37.170 --> 00:21:41.070
move from PowerPC to Intel,
now you don't have to do much

00:21:41.080 --> 00:21:43.170
to move from 32-bit to 64-bit.

00:21:43.180 --> 00:21:46.650
In fact,
transitioning your Java application to

00:21:46.650 --> 00:21:50.060
a 64-bit JVM is completely transparent.

00:21:50.060 --> 00:21:53.340
So if it's so easy,
why should you actually care?

00:21:53.340 --> 00:21:56.040
Well, there's one issue that
you need to know about,

00:21:56.040 --> 00:21:58.880
and it's a really big positive
for some applications.

00:21:59.530 --> 00:22:02.180
And that is the fact that
now your application can

00:22:02.180 --> 00:22:03.850
run with a larger Java heap.

00:22:03.900 --> 00:22:09.570
Before in Mac OS X, in the 32-bit world,
the maximum Java heap

00:22:09.570 --> 00:22:11.960
size was 2 gigabytes.

00:22:11.960 --> 00:22:15.960
Some of you might actually remember some
of the earliest releases of Mac OS X,

00:22:15.960 --> 00:22:18.740
that actually this limit
was actually even lower.

00:22:18.740 --> 00:22:20.800
I can't remember what
the exact number was,

00:22:20.890 --> 00:22:24.920
but we actually did some futzing around
defragmenting virtual memory to actually

00:22:24.920 --> 00:22:26.970
get that number to be around 2 gigabytes.

00:22:26.990 --> 00:22:32.360
Well, to incorporate... Increase that
even more would create some

00:22:32.380 --> 00:22:35.780
problems in virtual memory,
and we could never get anything

00:22:35.780 --> 00:22:37.240
more than 4 gigabytes anyways.

00:22:37.510 --> 00:22:44.500
Well now, with the 64-bit JVM,
you're way beyond that 2-gigabyte limit.

00:22:44.600 --> 00:22:46.600
In fact, it's a huge number.

00:22:46.600 --> 00:22:49.310
I'm not even going to mention the number,
because the real thing you need to

00:22:49.330 --> 00:22:52.870
know about is that you can use as much
memory as... You can use a Java heap

00:22:52.920 --> 00:22:56.480
the size as large as the physical
memory you have on your system.

00:22:56.520 --> 00:22:58.500
I'll be mentioning it in a little while.

00:22:58.530 --> 00:22:59.480
Why you should be doing that.

00:22:59.480 --> 00:23:03.460
You probably don't want to be using
a Java heap any larger than that.

00:23:03.560 --> 00:23:06.300
But it's very cool.

00:23:06.530 --> 00:23:08.480
So what does this mean
for your application?

00:23:08.480 --> 00:23:11.250
Well, let's talk about what kind
of applications could benefit

00:23:11.330 --> 00:23:12.480
from a larger Java heap.

00:23:12.480 --> 00:23:16.480
I think it falls into four different
categories of applications.

00:23:16.480 --> 00:23:20.640
And all of these applications have
in common that either they're using

00:23:20.640 --> 00:23:24.660
a lot of data coming off of disk,
or they're creating a lot of

00:23:24.800 --> 00:23:27.460
data during the execution of
the application themselves.

00:23:27.510 --> 00:23:29.450
So let's go through some of these.

00:23:29.640 --> 00:23:33.470
How about something that processes a
large amount of data coming from disk?

00:23:33.860 --> 00:23:37.480
Applications like gene
sequencing do that sort of thing.

00:23:37.490 --> 00:23:41.480
Another good example is an enterprise
application that's reading a lot,

00:23:41.480 --> 00:23:44.480
that's querying the database constantly.

00:23:44.510 --> 00:23:48.380
What about the situation where
suddenly that application was able

00:23:48.380 --> 00:23:54.190
to cache the full database in memory,
no longer having to add that query

00:23:54.190 --> 00:23:57.480
time to the latency of a transaction?

00:23:57.480 --> 00:23:58.480
The iTunes music store, for example.

00:23:58.480 --> 00:24:02.450
The iTunes music store, for example,
could definitely fit.

00:24:02.750 --> 00:24:05.480
Imagine if they had all their songs,
all of the album art,

00:24:05.480 --> 00:24:08.910
all of that cached in memory,
and then basically it's

00:24:08.910 --> 00:24:10.480
just that much faster.

00:24:10.480 --> 00:24:13.480
That's a really,
really powerful situation to be in.

00:24:13.650 --> 00:24:16.870
Another example are scientific
applications that do

00:24:16.880 --> 00:24:20.480
algorithmic computations of
visualizations or simulation.

00:24:20.480 --> 00:24:22.440
Things like NASA and NOAA are doing.

00:24:22.510 --> 00:24:25.730
This is a good example where
you might actually be starting

00:24:25.730 --> 00:24:29.390
off with a small amount of data,
chugging through that data in such a

00:24:29.430 --> 00:24:32.510
way that you generate a lot more data,
and then actually extract from

00:24:32.550 --> 00:24:36.460
them some sort of results,
then you write to disk.

00:24:36.710 --> 00:24:40.040
The last one actually is a set
of applications that I haven't

00:24:40.040 --> 00:24:43.480
actually seen written very much,
especially not in Java,

00:24:43.480 --> 00:24:47.960
where you're taking a large image data,
a large image, and processing it and then

00:24:47.960 --> 00:24:49.480
writing it back to disk.

00:24:49.480 --> 00:24:51.730
I'm really looking forward
to seeing those sorts of

00:24:51.760 --> 00:24:56.480
applications written for the Mac,
maybe even in Java using 64-bit JVM.

00:24:56.480 --> 00:25:00.480
So these are the hypothetical lists.

00:25:00.480 --> 00:25:04.580
I actually want to get really excited
about running real-world applications on

00:25:04.700 --> 00:25:06.480
the JVMs that we develop here at Apple.

00:25:06.480 --> 00:25:09.480
And so I went fishing
around the Internet.

00:25:09.480 --> 00:25:15.480
The application that we found that was
really cool to use was GeneSpring GX.

00:25:15.480 --> 00:25:17.480
It's from Agilent Technologies.

00:25:17.480 --> 00:25:21.480
And all I know about it is
it does gene sequencing.

00:25:21.490 --> 00:25:23.440
How many people here know
what gene sequencing is?

00:25:23.480 --> 00:25:25.460
All right.

00:25:25.540 --> 00:25:27.480
So this is a really cool application.

00:25:27.480 --> 00:25:29.480
It's a really cool application.

00:25:29.480 --> 00:25:31.480
It's a very, really cool application.

00:25:31.480 --> 00:25:33.480
It's really, really cool.

00:25:33.480 --> 00:25:35.480
It's very, very cool.

00:25:35.480 --> 00:25:36.440
It's very, very cool.

00:25:36.480 --> 00:25:38.430
It's a really, really cool application.

00:25:38.500 --> 00:25:40.480
I did not have access to it.

00:25:40.480 --> 00:25:43.480
It's not even amongst the people
holding up their hand at all.

00:25:43.480 --> 00:25:45.480
This application is a
complete black box to me.

00:25:45.500 --> 00:25:48.070
All I really know about it and
all I really care about that's

00:25:48.070 --> 00:25:51.480
really cool is that it uses -- it
generates a whole bunch of data.

00:25:51.480 --> 00:25:54.300
It's a complete black box.

00:25:54.630 --> 00:25:56.480
And I was like, "Oh, my gosh.

00:25:56.480 --> 00:25:58.480
It's a complete black box."
So we loaded some data.

00:25:58.480 --> 00:25:59.480
We loaded some data.

00:25:59.480 --> 00:26:00.390
We ran an experiment.

00:26:00.480 --> 00:26:01.220
And immediately,
it popped up this dialogue that said,

00:26:01.220 --> 00:26:01.450
"Oh, sorry.

00:26:01.480 --> 00:26:03.990
There's not enough memory." In fact,
this experiment takes

00:26:04.340 --> 00:26:05.480
almost six gigs to run.

00:26:05.480 --> 00:26:08.470
Well, clearly, in a 32-bit world,
that's not possible.

00:26:08.600 --> 00:26:09.480
And I was like, "Sweet.

00:26:09.480 --> 00:26:11.980
We have a 64-bit Java VM.

00:26:11.980 --> 00:26:16.240
Let's try that." And sure enough,
under our current Leopard Seed support,

00:26:16.250 --> 00:26:18.330
we were able to run this application.

00:26:18.680 --> 00:26:20.390
The experiment runs fine.

00:26:20.560 --> 00:26:22.390
The graphics looks great.

00:26:22.540 --> 00:26:23.480
Basically, the app just runs.

00:26:23.480 --> 00:26:27.440
And we expect that to be the case for
your application running under Leopard.

00:26:30.510 --> 00:26:34.170
Okay, so now you need to be asking
yourself a few questions.

00:26:34.270 --> 00:26:37.590
I have described some of the
nature of applications that

00:26:37.590 --> 00:26:40.900
could be using larger heap sizes,
but does that apply to your application?

00:26:40.900 --> 00:26:44.190
Well, the first question you need
to ask yourself if you need

00:26:44.190 --> 00:26:48.330
to move to a 64-bit JVM is,
have you been encountering out-of-memory

00:26:48.480 --> 00:26:50.340
errors with your application?

00:26:50.340 --> 00:26:54.470
If you are, you probably, you know,
you wouldn't be hitting them if

00:26:54.470 --> 00:26:56.620
you're using larger heap size.

00:26:56.820 --> 00:26:58.640
But keep in mind that
there is another reason,

00:26:58.710 --> 00:27:01.830
other than algorithmic complexity,
as to why your application

00:27:01.830 --> 00:27:03.590
is hitting out-of-memory.

00:27:03.600 --> 00:27:05.520
It's obvious,
but I still need to point it out.

00:27:05.540 --> 00:27:08.960
If you have a Java leak,
a Java memory leak in the 32-bit world,

00:27:08.960 --> 00:27:12.450
you're still going to have it in 64-bits,
and it's just going to take

00:27:12.450 --> 00:27:13.570
longer for you to find it.

00:27:13.660 --> 00:27:16.280
So fix it before you
actually move to 64-bits.

00:27:16.280 --> 00:27:18.080
There's another reason.

00:27:18.080 --> 00:27:22.160
So let's say your application
doesn't hit an out-of-memory error.

00:27:22.160 --> 00:27:25.150
Why would you go to 64-bits?

00:27:25.370 --> 00:27:29.120
Well, what about the case where if you
actually were to use more memory,

00:27:29.120 --> 00:27:32.350
you would actually be able to
re-architect your application so

00:27:32.410 --> 00:27:34.300
it would actually scale better?

00:27:34.320 --> 00:27:37.140
A good example is something
where you've split up tasks a

00:27:37.140 --> 00:27:40.840
bunch of different processes,
and now you can think about moving

00:27:40.840 --> 00:27:45.030
all those processes into one process,
farm them out to multiple threads,

00:27:45.140 --> 00:27:46.680
and just use a larger Java heap.

00:27:46.740 --> 00:27:49.120
That application will definitely
be scaling a lot better.

00:27:50.630 --> 00:27:55.000
But I do want to make the point
that you should be approaching

00:27:55.000 --> 00:27:58.620
all of this conversion from 32-bit
to 64-bit with not switching to

00:27:58.620 --> 00:28:01.550
64-bit just for the hell of it,
but actually convincing

00:28:01.550 --> 00:28:04.760
yourself that it's actually
needed for your application.

00:28:04.760 --> 00:28:11.290
The default should be, you know,
stick to what works for

00:28:11.290 --> 00:28:11.290
your application best.

00:28:12.110 --> 00:28:15.560
And the reason that you shouldn't
just move to 64-bit is because there's

00:28:15.560 --> 00:28:19.010
three things that you really need
to consider that will actually change

00:28:19.270 --> 00:28:21.270
once you go from 32-bit to 64-bit.

00:28:21.460 --> 00:28:23.680
Three things you need
to pay attention to.

00:28:23.700 --> 00:28:25.620
The first one is memory pressure.

00:28:25.620 --> 00:28:27.360
How much more memory are you using?

00:28:27.360 --> 00:28:29.240
Second one is the speed
of your application.

00:28:29.250 --> 00:28:32.860
Is your application just
going to simply become faster?

00:28:33.040 --> 00:28:35.300
Marketing might want you to believe that.

00:28:35.300 --> 00:28:38.540
But we'll find out the details of that.

00:28:38.540 --> 00:28:42.090
You also need to know how much
garbage collection overhead might

00:28:42.090 --> 00:28:45.300
change going from 32-bit to 64-bit.

00:28:45.300 --> 00:28:48.500
All right,
so let's go into the first one of these.

00:28:48.500 --> 00:28:51.880
Memory pressure.

00:28:51.880 --> 00:28:53.250
Well--

00:28:53.870 --> 00:28:55.610
Pointers are now 64-bit.

00:28:55.700 --> 00:28:57.020
They're not 32-bit.

00:28:57.020 --> 00:29:00.280
So your application,
every single object reference you have,

00:29:00.280 --> 00:29:03.480
every reference you have to a
Java object is now twice as large.

00:29:03.560 --> 00:29:05.990
If you've been doing a good
job of writing really good

00:29:05.990 --> 00:29:09.740
object-oriented programming,
then you're going to have

00:29:09.760 --> 00:29:12.260
a lot of these references.

00:29:12.260 --> 00:29:16.380
If you've been to any of the other
64-bit sessions here at WWDC,

00:29:16.380 --> 00:29:21.410
a comment actually has been made that
the memory pressure is really not that

00:29:21.410 --> 00:29:23.700
significant going from 32-bit to 64-bit.

00:29:23.700 --> 00:29:27.530
Because most real-world applications,
their data structures

00:29:27.750 --> 00:29:29.170
are not full of pointers.

00:29:29.500 --> 00:29:32.970
Well, with Java, that's different,
and we have to make the point here.

00:29:33.100 --> 00:29:36.550
In the worst case, an array of objects is
going to be twice as large.

00:29:36.640 --> 00:29:39.740
Most typical objects,
that's not going to be the case,

00:29:39.780 --> 00:29:43.480
but they are going to be bigger
simply because you're keeping track

00:29:43.530 --> 00:29:47.690
of the superclass and any sort of
object that you have in your fields.

00:29:47.760 --> 00:29:50.310
It's going to be bigger.

00:29:50.450 --> 00:29:56.750
So now that you know that the amount
of Java heap that you're going to

00:29:56.750 --> 00:29:59.980
be using is going to be larger,
keep in mind that you should still use

00:30:00.280 --> 00:30:03.960
the general rule of trying to use the
smallest Java heap possible anyways.

00:30:03.960 --> 00:30:08.380
Measure, increase at the given amount,
but don't just increase it

00:30:08.380 --> 00:30:11.890
two times or three times just
because you're moving a 64-bit.

00:30:13.090 --> 00:30:15.300
Also,
this is where I want to talk about the

00:30:15.390 --> 00:30:19.870
fact that if you're using a large enough
Java heap and you actually are using a

00:30:19.870 --> 00:30:24.110
heap larger than your physical memory,
because of the nature of the JVM,

00:30:24.110 --> 00:30:28.880
we're actually garbage collecting the
full heap at a given point in time.

00:30:28.880 --> 00:30:31.410
And if we actually can't
fit that all into memory,

00:30:31.480 --> 00:30:33.960
you're going to be
experiencing a lot of paging,

00:30:33.960 --> 00:30:35.830
and it's not a really good idea.

00:30:35.840 --> 00:30:41.170
If your computation requires it,
then go ahead, but do try to avoid that.

00:30:41.250 --> 00:30:46.110
Especially in the case where if you're
developing on a system with 16 gigs,

00:30:46.130 --> 00:30:49.660
sweet, your application runs,
but be aware that your users might

00:30:49.760 --> 00:30:53.100
not have that amount of memory,
and you need to handle

00:30:53.150 --> 00:30:54.770
that situation accordingly.

00:30:57.390 --> 00:31:01.310
Especially in the case where if
you're developing on a system with

00:31:01.660 --> 00:31:11.570
16GB suite your application runs,
but be aware that your users might not

00:31:11.570 --> 00:31:11.570
have that amount of memory and you need
to handle that situation accordingly.

00:31:11.730 --> 00:31:15.620
Especially in the case where if
you're developing on a system with

00:31:15.620 --> 00:31:24.520
16GB suite your application runs,
but be aware that your users might not

00:31:24.520 --> 00:31:24.520
have that amount of memory and you need
to handle that situation accordingly.

00:31:25.000 --> 00:32:34.400
[Transcript missing]

00:32:36.200 --> 00:32:38.900
Okay, the third thing you need to
be aware about the change in

00:32:38.900 --> 00:32:41.800
performance of your application
is the cost of garbage collection.

00:32:41.820 --> 00:32:46.980
If you use a larger Java heap,
it will take longer to collect it.

00:32:47.080 --> 00:32:50.480
You will experience longer pause times.

00:32:50.600 --> 00:32:55.240
So how can you change your application?

00:32:55.260 --> 00:32:57.920
You can't just use less memory.

00:32:57.940 --> 00:33:02.920
Well, one of the things that you need to
realize is that with the new Intel Macs,

00:33:03.090 --> 00:33:06.340
especially the Mac Pro we
announced on Monday,

00:33:06.340 --> 00:33:09.760
we are talking about systems
that now have four cores.

00:33:09.760 --> 00:33:14.330
You actually probably do have extra
CPU available to you for doing a

00:33:14.330 --> 00:33:19.050
lot of asynchronous computations
for your garbage collection.

00:33:19.060 --> 00:33:23.250
And we've been shipping since Java 4
alternative garbage collection

00:33:23.300 --> 00:33:27.150
algorithms outside of the default one,
the synchronous mark sweep,

00:33:27.730 --> 00:33:30.740
that until now, it might have been
somewhat compelling to use.

00:33:30.750 --> 00:33:34.220
But now when you have all these CPUs,
it really, really can actually

00:33:34.220 --> 00:33:35.380
make a huge difference.

00:33:35.800 --> 00:33:37.700
Specifically, so there's two of them.

00:33:37.700 --> 00:33:39.060
There's the parallel garbage collector.

00:33:39.060 --> 00:33:41.620
There's the concurrent mark
sweep garbage collector.

00:33:41.960 --> 00:33:45.600
And I have the, you can read what the
flags are right there.

00:33:45.730 --> 00:33:48.850
One of the things to point out
about the concurrent mark sweep

00:33:48.950 --> 00:33:52.710
is that this one actually runs
asynchronously to your application.

00:33:52.820 --> 00:33:55.700
So it takes a little
bit of CPU all the time.

00:33:57.140 --> 00:34:01.270
And therefore minimizing the actual
latency at the time when your application

00:34:01.270 --> 00:34:03.220
is only doing garbage collection.

00:34:03.220 --> 00:34:06.780
So this is another way of you can
improve the garbage collection

00:34:07.170 --> 00:34:09.090
performance while you're running.

00:34:10.710 --> 00:34:13.640
Okay,
so I've talked about a lot of stuff,

00:34:13.640 --> 00:34:15.950
but being the cynic that I am,
I really want to actually show

00:34:15.950 --> 00:34:18.900
you our 64-bit JVM in action.

00:34:18.900 --> 00:34:21.230
I don't have anything too spiffy.

00:34:21.250 --> 00:34:21.700
Let's see.

00:34:21.700 --> 00:34:23.700
Where are we?

00:34:23.700 --> 00:34:29.060
Hmm.

00:34:29.060 --> 00:34:31.780
Can we get the demo machine up?

00:34:42.600 --> 00:34:44.540
All right, I'll give it a second or two.

00:34:44.540 --> 00:34:45.490
Let's see, what can I talk about?

00:34:45.490 --> 00:34:53.030
Well, I'm just going to continue with
the slides and then see if I can...

00:34:53.400 --> 00:34:57.880
Try... Yeah,
let's just go with the slides then.

00:34:57.960 --> 00:35:00.810
Okay, so what was I running that on?

00:35:00.840 --> 00:35:02.220
Well, you don't know what I was running.

00:35:02.270 --> 00:35:06.850
But what I was running that on
is our just announced Mac Pro.

00:35:07.130 --> 00:35:10.170
Well this is exactly the sort
of configuration that we will

00:35:10.170 --> 00:35:12.020
be supporting a 64-bit JVM on.

00:35:12.230 --> 00:35:14.800
We'll be shipping this
with Mac OS X Leopard.

00:35:14.930 --> 00:35:18.380
It'll be running on all of
our 64-bit enabled Intel Macs,

00:35:18.410 --> 00:35:21.800
and it will be available
only in Java SC6.

00:35:21.800 --> 00:35:25.350
What can you expect to be able to
run in the lab on the Leopard seed

00:35:25.370 --> 00:35:29.780
or on your own Mac Pro when you buy
it and install the Leopard seed?

00:35:29.820 --> 00:35:34.100
Basically, you should be able to run...

00:35:34.560 --> 00:35:37.910
You should be able to run an application
as complicated as GeneSpring.

00:35:37.920 --> 00:35:41.850
The graphics stack works, GUI works,
networking works,

00:35:41.950 --> 00:35:42.900
just about everything works.

00:35:42.940 --> 00:35:45.500
We just barely got this
thing up and running,

00:35:45.500 --> 00:35:48.700
but we've been really excited
about how much actually we've

00:35:48.700 --> 00:35:51.690
been able to get working,
and we're excited to see what you're

00:35:51.750 --> 00:35:55.730
able to get up and running and give
us feedback on what's left to do.

00:35:55.920 --> 00:35:58.120
One thing that we do know
is a lot of the tools that

00:35:58.150 --> 00:36:02.480
Roger mentioned in the previous part,
JConsole itself does work,

00:36:02.930 --> 00:36:07.550
but a lot of the other tools like
JStack and JHeap analysis tool,

00:36:07.550 --> 00:36:10.010
those aren't there yet,
but they will be ready by

00:36:10.140 --> 00:36:12.920
the time we ship Leopard.

00:36:17.510 --> 00:36:17.850
Okay.

00:36:17.850 --> 00:36:21.400
And how do you actually turn
on 64-bit in your application?

00:36:21.400 --> 00:36:24.410
It really is as transparent
as I was mentioning before.

00:36:24.410 --> 00:36:26.780
You need to add one flag,
and one flag only.

00:36:26.780 --> 00:36:29.640
It's the minus D64 flag
on the command line.

00:36:29.640 --> 00:36:32.620
Once you've done that,
you will just get the same

00:36:32.620 --> 00:36:35.530
old default heap size,
but you're actually able

00:36:35.660 --> 00:36:37.210
to create larger heaps.

00:36:37.210 --> 00:36:40.680
So just change your heap size
with minus XMS or minus XMX,

00:36:40.680 --> 00:36:41.840
and that's it.

00:36:41.960 --> 00:36:43.730
Well, almost it.

00:36:44.120 --> 00:36:46.940
Just like last year,
if you're not a pure Java application,

00:36:46.940 --> 00:36:48.430
you do need to do more work.

00:36:48.430 --> 00:36:51.640
You actually probably do need to
pay attention to the tips and tricks

00:36:51.640 --> 00:36:53.790
mentioned in the other 64-bit sessions.

00:36:53.800 --> 00:36:55.370
Oh, there we go.

00:36:55.370 --> 00:36:56.320
All right.

00:36:56.320 --> 00:36:57.650
Let me go over here.

00:36:57.650 --> 00:37:00.080
I just want to actually prove that
we actually had this thing running.

00:37:00.080 --> 00:37:03.230
Those of you that haven't
been down to the lab,

00:37:03.230 --> 00:37:06.090
you can see here's our 32-bit JVM.

00:37:06.090 --> 00:37:07.080
No big deal.

00:37:07.120 --> 00:37:09.210
It's an obvious hello world.

00:37:09.210 --> 00:37:11.240
It's not that exciting.

00:37:11.240 --> 00:37:13.860
But right here, you can actually see
that we're running a JVM.

00:37:13.860 --> 00:37:15.550
We're running with a 64-bit JVM.

00:37:15.550 --> 00:37:16.020
All right.

00:37:16.150 --> 00:37:17.980
Let me up the ante just a tiny, tiny bit.

00:37:19.920 --> 00:37:24.800
and actually show you a large heap size.

00:37:24.880 --> 00:37:26.420
So what's big enough?

00:37:26.470 --> 00:37:28.500
Let's go with...

00:37:29.080 --> 00:37:34.880
5000 meg and a maximum heap size of what?

00:37:37.150 --> 00:37:40.770
10 gigs.

00:37:41.730 --> 00:37:45.670
And sure enough, that works.

00:37:45.670 --> 00:37:45.670
Oh.

00:37:45.670 --> 00:37:45.670
Oh, yeah, sorry.

00:37:45.670 --> 00:37:45.670
That's not completely right.

00:37:47.340 --> 00:37:50.800
And as you can see,
and as you're perfectly aware of,

00:37:50.870 --> 00:37:53.370
if I had run this without...

00:37:54.270 --> 00:37:57.320
That it actually says that it's
an invalid initial heap size.

00:37:57.320 --> 00:37:58.360
So sure enough, this works.

00:37:58.360 --> 00:37:58.990
No big deal.

00:37:58.990 --> 00:38:02.340
I was thinking of showing you something
that would show you the different

00:38:02.340 --> 00:38:04.200
GC characteristics of an application.

00:38:04.200 --> 00:38:08.720
But the reality is that all the
GC behavior is dependent on what

00:38:08.720 --> 00:38:11.190
kind of application you have.

00:38:11.190 --> 00:38:13.200
So I don't want to show you
something that contrived.

00:38:13.200 --> 00:38:18.190
What I do want to point out is one of the
other messages that I gave you earlier.

00:38:18.920 --> 00:38:21.920
That it actually says that it's
an invalid initial heap size.

00:38:21.920 --> 00:38:22.960
So sure enough, this works.

00:38:22.960 --> 00:38:23.570
No big deal.

00:38:23.600 --> 00:38:26.220
I was thinking of showing you something
that would show you the different

00:38:26.220 --> 00:38:26.220
GC characteristics of an application.

00:38:26.520 --> 00:38:28.430
So here I'm bringing up Java 2 demo.

00:38:28.550 --> 00:38:30.560
This is the 32-bit version.

00:38:30.610 --> 00:38:33.180
I'm just going to go immediately
to the composite frame.

00:38:33.180 --> 00:38:37.020
And I'm going to launch--

00:38:38.030 --> 00:38:47.400
JConsole, the same application that
Roger was mentioning before.

00:38:47.400 --> 00:38:47.400
And I'm going to go
ahead and connect to...

00:38:47.910 --> 00:38:48.890
Java 2 demo.

00:38:48.970 --> 00:38:53.800
And then while I'm doing that,
let me get the 64-bit version.

00:38:53.900 --> 00:38:57.590
And you'll see that I'm running
with the exact same heap size.

00:38:58.060 --> 00:38:59.810
That I was in the 32-bit version.

00:39:00.000 --> 00:39:02.230
Okay, so I got that running.

00:39:02.250 --> 00:39:04.220
Let me go to composite.

00:39:04.220 --> 00:39:07.970
And let me increase the
animation delay on both of these.

00:39:11.670 --> 00:39:15.540
So that we create a lot of objects.

00:39:15.540 --> 00:39:17.570
Let me get this going.

00:39:17.580 --> 00:39:19.580
There it goes.

00:39:19.580 --> 00:39:21.580
That's hung.

00:39:23.960 --> 00:39:26.330
All right.

00:39:26.400 --> 00:39:31.130
So as you can see, there's the second--

00:39:31.420 --> 00:39:49.250
Java 2 demo.

00:39:49.250 --> 00:39:49.250
So we got the two of them
running side by side.

00:39:49.250 --> 00:39:49.250
I got the animation delay up.

00:39:49.250 --> 00:39:49.250
This is the amount of memory actually
being used by the 32-bit one.

00:39:49.250 --> 00:39:49.250
And over here we have the 64-bit one,
the JConsole for it running.

00:39:49.250 --> 00:39:49.250
Let me show you these side by side.

00:39:53.560 --> 00:39:56.860
One thing to point out here actually
that is really powerful is the

00:39:56.960 --> 00:40:00.720
JConsole is running in 32-bit,
and it's introspecting

00:40:00.770 --> 00:40:02.820
a 64-bit application.

00:40:02.820 --> 00:40:04.940
You can do this totally
seamlessly on the Mac,

00:40:04.950 --> 00:40:07.960
have 32-bit and 64-bit
applications side-by-side,

00:40:07.960 --> 00:40:09.910
and have them communicating
with each other.

00:40:09.920 --> 00:40:12.390
Just like I said,
the other tools don't work yet,

00:40:12.390 --> 00:40:14.410
but we will have them running as well.

00:40:14.420 --> 00:40:16.320
Here's my point.

00:40:16.320 --> 00:40:18.950
The exact same application,
the exact same code,

00:40:18.950 --> 00:40:22.600
the exact same Java heap,
and just by running in the 32-bit,

00:40:23.000 --> 00:40:26.740
we're having about a steady state
that's well below 10 gigabytes.

00:40:26.740 --> 00:40:32.730
It says in really small right there,
7.3 megs of memory used,

00:40:32.770 --> 00:40:34.940
and that's Java memory.

00:40:34.940 --> 00:40:38.580
And then over here,
we have well above 10 megs,

00:40:38.580 --> 00:40:43.340
around 13 megs being used with
the exact same application.

00:40:46.220 --> 00:40:51.290
So watch out if you're trying to deploy
a lot of applications on the same system.

00:40:51.490 --> 00:40:52.900
Your memory pressure is going up.

00:40:52.900 --> 00:40:55.570
Let me go back to slides.

00:40:59.400 --> 00:41:00.960
Okay, well actually that's about it.

00:41:00.960 --> 00:41:03.700
I hope you,
I'm really excited to see what kind

00:41:03.700 --> 00:41:07.140
of new applications you're going to
be bringing to the Java on Mac OS X.

00:41:07.140 --> 00:41:09.800
Do let us know what runs,
what doesn't run.

00:41:09.800 --> 00:41:13.900
We'll be at the lab with 64-bit
machines available to you,

00:41:13.920 --> 00:41:15.300
so we want to see your
application running.

00:41:15.300 --> 00:41:16.640
And thank you very much.

00:41:16.690 --> 00:41:20.190
I'll bring up Pratik Solanki now
to talk about a bunch of new tools.

00:41:20.190 --> 00:41:20.980
Thank you.

00:41:27.200 --> 00:44:40.100
[Transcript missing]

00:44:40.620 --> 00:44:43.260
So I'm going to give you a
very simple example script.

00:44:43.260 --> 00:44:46.380
And there's a detrace
session tomorrow at 10:15,

00:44:46.380 --> 00:44:48.590
so I highly encourage you to go see that.

00:44:48.750 --> 00:44:49.980
But here's a very simple example.

00:44:49.980 --> 00:44:55.910
It's sort of like a
simple contrived example.

00:44:56.050 --> 00:44:59.120
What if I wanted to find out
what processes were opening

00:44:59.120 --> 00:45:00.140
which files on my system?

00:45:00.140 --> 00:45:04.060
So I just want to know what files
are being opened on my system

00:45:04.060 --> 00:45:05.700
and what process is opening it.

00:45:05.960 --> 00:45:09.160
Well, I'd write a very simple script
that looks something like this.

00:45:09.360 --> 00:45:11.370
And what is this doing?

00:45:11.510 --> 00:45:15.420
So the first line over there,
all that it's telling detrace is,

00:45:15.430 --> 00:45:17.720
I'm interested in the open syscall.

00:45:17.940 --> 00:45:21.500
Fire this probe when the
open syscall is entered.

00:45:21.780 --> 00:45:23.780
And what happens when
the probe gets fired?

00:45:23.830 --> 00:45:26.740
Well, you're just going to do a printf,
a simple printf that says,

00:45:26.920 --> 00:45:28.360
what's the name of the executable?

00:45:28.420 --> 00:45:31.710
Exec name out there is a
built-in detrace variable.

00:45:31.850 --> 00:45:33.480
That's the name of the executable.

00:45:33.780 --> 00:45:38.020
And what's important in
the second part is arg0.

00:45:38.020 --> 00:45:40.260
arg0 is the first argument to open.

00:45:40.260 --> 00:45:43.500
And if you look at the man page,
that's nothing but the path to the file.

00:45:43.500 --> 00:45:44.980
So that's a simple detrace script.

00:45:44.980 --> 00:45:48.180
You run it on your
Mac OS X Leopard system on the

00:45:48.180 --> 00:45:50.100
seed that you get right now.

00:45:50.120 --> 00:45:51.760
And you'll see output like this.

00:45:51.760 --> 00:45:53.460
So I ran it on my system.

00:45:53.460 --> 00:45:56.600
And while I was running this script,
I was actually doing a cat

00:45:56.620 --> 00:45:59.920
of one of my favorite files,
the java.crash.log file.

00:45:59.920 --> 00:46:00.920
I get that a lot.

00:46:00.920 --> 00:46:02.220
So I do open that a lot.

00:46:02.220 --> 00:46:03.770
So I was doing a cat of that.

00:46:03.780 --> 00:46:06.820
And you can see cat's opening
up a bunch of to start up.

00:46:07.050 --> 00:46:11.990
And you can see it opened up the
java.crash.log towards the end.

00:46:12.000 --> 00:46:17.010
And the last two lines over there
is basically spotlight hard at work.

00:46:17.320 --> 00:46:18.290
So that was DTrace.

00:46:18.320 --> 00:46:21.640
That was a very simple DTrace,
like a two-slide overview

00:46:21.640 --> 00:46:23.200
of what DTrace is.

00:46:23.220 --> 00:46:25.400
How is that important to you?

00:46:25.400 --> 00:46:26.580
What do you need to worry about?

00:46:26.620 --> 00:46:29.140
Why is DTrace important
to you as Java developers?

00:46:29.140 --> 00:46:34.900
Well, in Mustang or in Java SE 6,
we have built-in support for DTrace,

00:46:34.900 --> 00:46:39.630
which means that the JVM exposes
certain probe points.

00:46:39.640 --> 00:46:45.150
It exposes a variety of probe points,
which are kind of divided

00:46:45.150 --> 00:46:46.140
into two categories.

00:46:46.540 --> 00:46:48.900
In DTrace lingo,
they're called providers.

00:46:48.900 --> 00:46:52.200
So what are these probe points,
and what are these providers?

00:46:52.200 --> 00:46:54.860
Well,
the first one is the hotspot provider.

00:46:54.860 --> 00:47:01.160
And this is an example of some
of the probes it gives you.

00:47:01.160 --> 00:47:03.210
It's basically giving you
access to VM-level probes.

00:47:03.300 --> 00:47:07.480
You know, all the VM internals, you know,
GC start, GCN, monitor, enter, exit,

00:47:07.480 --> 00:47:10.650
class loading, unloading, thread start.

00:47:10.740 --> 00:47:14.740
So all these VM-level, low-level things,
it's kind of what the hotspot

00:47:14.810 --> 00:47:16.450
provider is giving you access to.

00:47:16.460 --> 00:47:20.750
So you can write your DTrace script to,
you know,

00:47:20.870 --> 00:47:25.540
for listening to these probe events.

00:47:27.040 --> 00:47:29.320
The second one is a very
straightforward one.

00:47:29.350 --> 00:47:30.810
It's the Hotspot JNI provider.

00:47:30.920 --> 00:47:31.940
It's very simple.

00:47:31.940 --> 00:47:35.550
It's just an entry and return probe
point for each and every JNI method.

00:47:35.780 --> 00:47:40.440
So for any JNI method,
just put a dash entry and dash return,

00:47:40.440 --> 00:47:43.600
and that's your detrace probe point.

00:47:45.340 --> 00:47:48.840
So, you know, here's a very simple
example that I wrote up.

00:47:48.940 --> 00:47:52.190
And this is basically, you know,
what I'm going to show here is

00:47:52.190 --> 00:47:55.500
one of the most frequently asked
questions in the Java world is you

00:47:55.500 --> 00:47:58.980
always want to know how much time
the garbage collector is taking.

00:47:58.980 --> 00:48:00.190
You know, your app's running slow.

00:48:00.340 --> 00:48:02.090
You want to figure out, hey,
is the GC taking too much

00:48:02.090 --> 00:48:03.120
time or what's going on?

00:48:03.180 --> 00:48:09.220
So here's a very simple DTRA script
that you might write to figure that out.

00:48:09.340 --> 00:48:13.240
And let me explain to you what this,
you know, block of code's doing.

00:48:14.160 --> 00:48:18.260
The first thing is, you know,
the probe points, the probe entry points.

00:48:18.260 --> 00:48:21.170
Hotspot, because it's a hotspot probe.

00:48:21.220 --> 00:48:24.000
GC begin, GC end, you know,
straightforward,

00:48:24.000 --> 00:48:25.110
the name of the entry points.

00:48:25.160 --> 00:48:29.180
The $1 over here, what is the $1?

00:48:29.180 --> 00:48:32.120
Well, $1 is nothing but the first
argument to your script.

00:48:32.220 --> 00:48:36.210
And you need that because what you
typically pass to the script is the PID,

00:48:36.280 --> 00:48:38.280
or the process ID of
your Java application.

00:48:38.280 --> 00:48:40.940
So that DTRAs know which
process you're interested in.

00:48:41.100 --> 00:48:43.960
So, hotspot $1, colon, colon, colon.

00:48:43.980 --> 00:48:44.520
And GC begin.

00:48:44.520 --> 00:48:46.110
Why the three colons?

00:48:46.180 --> 00:48:48.500
Well, you know, you've got to go to the
DTRA stock to find that out.

00:48:51.680 --> 00:48:52.660
What do you do when GC starts?

00:48:52.740 --> 00:48:54.900
All you're doing over here,
all I'm doing is just

00:48:55.010 --> 00:48:55.900
saving the timestamp.

00:48:55.950 --> 00:48:58.100
I'm just saving the timestamp
in a start variable,

00:48:58.100 --> 00:49:00.260
and when GC ends,
I'm going to calculate the

00:49:00.270 --> 00:49:01.110
total time that it took.

00:49:01.180 --> 00:49:03.700
So I'm going to calculate the
current timestamp minus what I saved,

00:49:03.740 --> 00:49:07.470
and I'm just converting that
into milliseconds because

00:49:07.470 --> 00:49:09.480
timestamp is in nanoseconds.

00:49:09.480 --> 00:49:11.480
And then I just print it out.

00:49:11.540 --> 00:49:12.580
Very simple script.

00:49:12.660 --> 00:49:16.310
I can run it against a Java process.

00:49:16.320 --> 00:49:20.340
And just like as Roger talked about,
attach on demand,

00:49:20.340 --> 00:49:23.690
where you don't need to start the
Java VM with particular arguments

00:49:23.750 --> 00:49:27.400
in order to use JConsole now,
it's the same thing with DTrace.

00:49:27.520 --> 00:49:30.030
You really don't need to
start your Java VM with any,

00:49:30.040 --> 00:49:31.840
your Java program with
any particular arguments.

00:49:31.840 --> 00:49:34.760
You could run the script on
any running Java process and,

00:49:34.760 --> 00:49:39.570
well, not any running Java process,
the one that's using Java 6.

00:49:39.580 --> 00:49:43.030
But you could run the script
without having to start the

00:49:43.030 --> 00:49:44.720
VM with any special arguments.

00:49:44.740 --> 00:49:49.320
So what happens when you run
the script on a Leopard system?

00:49:49.320 --> 00:49:51.090
Well, let me show you.

00:49:51.140 --> 00:49:53.920
If I can get to my demo machine.

00:49:53.920 --> 00:49:54.490
All right.

00:49:54.560 --> 00:49:55.440
Okay, thank you.

00:49:55.460 --> 00:50:01.150
So I'm going to show
you how DTrace works.

00:50:01.220 --> 00:50:07.360
I'm taking the Java 2D demo
as an example application.

00:50:07.380 --> 00:50:10.320
Consider it your long-time
running server process,

00:50:10.320 --> 00:50:11.800
if you will.

00:50:12.020 --> 00:50:18.790
So what you need to know is, let's see,
you need the process ID of the,

00:50:19.320 --> 00:50:20.740
of your Java app.

00:50:20.850 --> 00:50:22.250
In this case, it's 365.

00:50:22.370 --> 00:50:24.310
And here I'm going to just run.

00:50:26.400 --> 00:50:29.860
I'm just running the exact same
script that I just showed you.

00:50:29.940 --> 00:50:34.080
I need to run DTRACE as root,
so enter my secret password.

00:50:34.080 --> 00:50:36.960
And there you go.

00:50:36.960 --> 00:50:39.560
It just keeps printing as GC happens.

00:50:39.560 --> 00:50:44.960
As you move around,
you'll see GC taking 500, 17, 12.

00:50:44.960 --> 00:50:48.020
It just keeps printing the
amount of time that GC is taking.

00:50:48.020 --> 00:50:50.340
Well, all that's good.

00:50:50.620 --> 00:50:54.310
Let me just start off under the script,
and let me tell you what

00:50:54.380 --> 00:50:55.460
I'm going to do over here.

00:50:55.990 --> 00:50:58.840
So that was a very simple example.

00:50:58.840 --> 00:51:01.240
It just printed out the
amount of time that it took.

00:51:01.310 --> 00:51:05.180
But really, the power of DTRACE lies
in the D language,

00:51:05.180 --> 00:51:06.250
or the D scripting language.

00:51:06.260 --> 00:51:09.940
And there's a lot of features to it,
and one of the small features that

00:51:09.940 --> 00:51:12.320
I'm going to show you is that it
allows you to kind of print out a

00:51:12.360 --> 00:51:14.260
nice little statistical distribution.

00:51:14.260 --> 00:51:17.480
So instead of seeing numbers
scrolled by like 500,

00:51:17.490 --> 00:51:24.180
12, 16, you may want to know, well,
on average, how much is it taking?

00:51:24.180 --> 00:51:25.630
Or what's the statistical distribution?

00:51:25.680 --> 00:51:27.440
And that's the distribution
of my GC times.

00:51:27.510 --> 00:51:29.390
And DTRACE lets you do that.

00:51:29.570 --> 00:51:32.470
And DTRACE, in fact,
from the script that I showed you,

00:51:32.490 --> 00:51:36.480
I just made one line change,
and I'm running that script right now.

00:51:36.480 --> 00:51:37.880
And when I stop it,

00:51:38.020 --> 00:51:38.830
Here's what it's telling you.

00:51:38.930 --> 00:51:41.180
It's telling you, well,
most of the garbage collections

00:51:41.200 --> 00:51:43.350
are taking somewhere between
8 and 16 milliseconds.

00:51:43.430 --> 00:51:46.520
So it's like in the time period
that I had the script running,

00:51:46.520 --> 00:51:52.160
13 GCs occurred that just took
less than 16 milliseconds.

00:51:52.240 --> 00:51:54.100
But there were a few that took more time.

00:51:54.100 --> 00:51:56.720
They took around between
half a second to one second.

00:51:56.720 --> 00:52:00.000
So it's a better way of
visualizing your data instead of

00:52:00.000 --> 00:52:02.180
just having standard printers.

00:52:02.180 --> 00:52:04.310
And DTRACE is very powerful
and flexible in that way.

00:52:05.410 --> 00:52:09.710
So that's just my very simple
demo on DTRACE and how it runs

00:52:09.720 --> 00:52:10.750
and what you can do with it.

00:52:10.800 --> 00:52:14.680
So let's go back to the slides.

00:52:17.400 --> 00:52:20.330
I know what my next slide is,
so let me just tell you

00:52:20.340 --> 00:52:21.840
what I was going to say.

00:52:21.840 --> 00:52:25.050
We have some caveats with DTrace.

00:52:25.060 --> 00:52:26.240
It's a new technology.

00:52:26.320 --> 00:52:31.060
Obviously, we've just started getting
it to run on Mac OS X.

00:52:31.060 --> 00:52:35.360
In fact,
the Leopard Seed that you have right now,

00:52:35.360 --> 00:52:39.200
the Java 6 on that Leopard Seed,
it's not DTrace-enabled.

00:52:39.200 --> 00:52:42.910
So you can't really run the script
that I showed you on your Leopard Seed.

00:52:43.310 --> 00:52:48.430
But we will make it available come
spring 2007 when Leopard ships.

00:52:48.520 --> 00:52:50.860
We will make DTrace
support in Java enabled,

00:52:51.070 --> 00:52:52.460
and it will be running.

00:52:52.460 --> 00:52:55.030
And you would be able to
run all those fun little,

00:52:55.030 --> 00:52:58.820
definitely the script that I showed you,
and a lot of other scripts

00:52:58.910 --> 00:53:00.310
that you can find on the web.

00:53:00.360 --> 00:53:02.310
You should be able to run that.

00:53:04.180 --> 00:53:09.300
So the next thing that I wanted to
talk about after D-Trace was X-Ray.

00:53:09.300 --> 00:53:12.540
Again, how many people have heard
about X-Ray or know about X-Ray?

00:53:12.540 --> 00:53:14.840
Because it's been talked
a lot at this conference.

00:53:15.000 --> 00:53:15.160
Yeah.

00:53:15.160 --> 00:53:17.000
So, okay, we're back.

00:53:17.000 --> 00:53:18.880
Let me just...

00:53:19.900 --> 00:53:21.500
You know, told you about the caveats.

00:53:21.570 --> 00:53:22.680
It's Java 6 only.

00:53:22.680 --> 00:53:24.750
Sorry, it's not available for Java 5.

00:53:24.800 --> 00:53:28.590
Okay, so let's move on to X-Ray.

00:53:28.600 --> 00:53:30.180
What's X-Ray?

00:53:30.180 --> 00:53:32.100
Well, you know, that's X-Ray.

00:53:32.100 --> 00:53:33.500
You've heard about it.

00:53:33.610 --> 00:53:35.910
You've seen demos in
Ted Goldstein's talk.

00:53:35.990 --> 00:53:41.410
And there's actually a session
on X-Ray today at 2 o'clock,

00:53:41.540 --> 00:53:42.950
so, you know, go for that.

00:53:43.150 --> 00:53:43.880
Check it out.

00:53:44.000 --> 00:53:50.090
It's a new tracing profiling tool,
very GarageBand-like, where you can add,

00:53:50.090 --> 00:53:52.090
you know,
different kinds of instruments and

00:53:52.100 --> 00:53:59.570
see how your app or how the system
behaves with respect to all this,

00:53:59.570 --> 00:54:03.550
you know, this data that the instruments
will gather for you.

00:54:06.610 --> 00:54:08.170
The 64-bit environment is
a great place to start.

00:54:08.170 --> 00:54:10.440
You'll learn about memory consumption,
CPU consumption, file access,

00:54:10.580 --> 00:54:12.520
disk access, all these kinds of things
you can trace in X-Ray.

00:54:12.520 --> 00:54:16.020
And again, why is that important to
you as Java developers?

00:54:16.020 --> 00:54:19.580
Well, in Leopard,
we'll have built-in support for Java.

00:54:19.580 --> 00:54:22.530
So in X-Ray,
you would be able to profile and

00:54:22.650 --> 00:54:24.960
trace your Java applications.

00:54:24.960 --> 00:54:28.440
And you could do thread tracing,
memory tracing,

00:54:28.450 --> 00:54:31.500
and it'll be fully supported in Leopard.

00:54:31.500 --> 00:54:36.090
Unfortunately, it's not available in your
developer seed right now.

00:54:36.510 --> 00:54:38.630
But we will have it
available for Leopard.

00:54:38.640 --> 00:54:44.040
So here to give a small demo of
X-Ray and how it works with Java,

00:54:44.040 --> 00:54:45.820
here's Lin Salameh.

00:54:55.420 --> 00:54:57.750
I just want to show you
a little demonstration of

00:54:57.780 --> 00:55:00.120
how X-Ray works with Java.

00:55:00.120 --> 00:55:02.550
If you've been to Francois' talk,
you might have seen this before,

00:55:02.550 --> 00:55:04.040
but we thought we'd do it again.

00:55:04.040 --> 00:55:05.040
All right.

00:55:05.530 --> 00:55:06.040
So, let's see.

00:55:06.040 --> 00:55:07.110
So,
we're going to start with the first one.

00:55:07.890 --> 00:55:10.330
Here's my X-ray application,
and as you can see,

00:55:10.330 --> 00:55:12.300
we have all the instruments
down here at the bottom.

00:55:12.300 --> 00:55:15.500
I'm going to drag up the
Java thread instrument up here,

00:55:15.660 --> 00:55:19.020
and to start profiling,
I'm going to press play.

00:55:19.960 --> 00:55:25.040
And as usual, we're going to select the
Java 2D demo and start profiling it.

00:55:25.130 --> 00:55:28.820
So the cool thing about X-Ray is that
it allows you to see the results of

00:55:28.820 --> 00:55:33.310
your Java profiling at the same time
that you're running your application.

00:55:33.400 --> 00:55:37.770
So I could, you know,
here's my Java 2D demo launching up,

00:55:37.840 --> 00:55:41.850
and I could play around with it,
you know, change colors a little bit,

00:55:41.920 --> 00:55:44.310
and then, you know, stop it.

00:55:44.800 --> 00:55:47.520
As you can see,
the results of my profiling,

00:55:47.520 --> 00:55:51.680
let me zoom in a little bit,
shows me all the threads that

00:55:51.780 --> 00:55:53.200
have been running for a while.

00:55:53.350 --> 00:55:56.460
Threads that are green are
threads that are running,

00:55:56.460 --> 00:55:59.530
and the yellow colors are
threads that are waiting.

00:55:59.630 --> 00:56:02.200
Threads that are blocked
are actually shown in red.

00:56:02.330 --> 00:56:07.730
I'm actually interested in
the threads that are blocked,

00:56:07.730 --> 00:56:07.730
so let me scrub over to
threads that are blocked.

00:56:07.970 --> 00:56:11.080
And let's see right here where
my main thread is blocked.

00:56:11.080 --> 00:56:14.780
And I'm going to click the info
button to show me more information.

00:56:14.780 --> 00:56:17.740
And as you can see,
I have all the names of the threads of

00:56:17.740 --> 00:56:21.640
that time slice and their priorities,
whether they're daemon or not,

00:56:21.640 --> 00:56:23.400
and whether they're blocked.

00:56:23.400 --> 00:56:25.780
So I don't know if you
can see this very well,

00:56:25.780 --> 00:56:29.150
but the main thread is actually
blocked on App Class Loader.

00:56:29.150 --> 00:56:31.580
And for more detail,
I can click the Extended

00:56:31.600 --> 00:56:34.240
Detail button right here,
and I can see the stack

00:56:34.240 --> 00:56:36.540
trace of what's happening.

00:56:37.900 --> 00:56:41.020
Other threads are actually running.

00:56:41.170 --> 00:56:48.600
And I can also scrub along and see here
my event queue thread is actually--

00:56:49.000 --> 00:57:09.400
[Transcript missing]

00:57:12.630 --> 00:57:13.830
Okay, back to the slides.

00:57:13.830 --> 00:57:18.920
Okay,
so that was how X-Ray works with Java.

00:57:18.920 --> 00:57:23.720
So those were the two new tools
that we have for you in Leopard,

00:57:23.720 --> 00:57:25.120
you know, great new tools.

00:57:25.190 --> 00:57:29.510
I really encourage you to try them
out once you get a hand on them,

00:57:29.550 --> 00:57:32.480
and it should make
your life a lot easier.

00:57:33.260 --> 00:57:34.160
So let's move on.

00:57:34.160 --> 00:57:36.720
Let's move on to performance, you know,
numbers.

00:57:36.770 --> 00:57:40.370
I'm going to talk to you about
the performance of the Java 6

00:57:40.370 --> 00:57:42.170
VM that you have right now.

00:57:42.190 --> 00:57:45.930
We're going to go over, you know,
we're going to go over some of the

00:57:45.930 --> 00:57:50.160
improvements that have been made
in Java 6 as compared to J2SE 5.

00:57:50.160 --> 00:57:52.770
We're going to, you know,
I'm going to explain to you what I'm

00:57:52.770 --> 00:57:56.660
measuring my performance benchmarks on,
you know, what benchmarks I'm measuring.

00:57:56.660 --> 00:57:59.630
And then we're going to look
at some graphs that tell us,

00:57:59.740 --> 00:58:02.340
you know,
how does Java 6 compare to J2SE 5

00:58:02.440 --> 00:58:03.240
in terms of the performance.

00:58:03.260 --> 00:58:07.060
So let's move on to the client
and server compilers and,

00:58:07.060 --> 00:58:09.890
you know,
how does Java on Mac OS X compare

00:58:09.940 --> 00:58:12.110
to Java running on Windows.

00:58:13.740 --> 00:58:16.260
So let's look at client performance.

00:58:16.420 --> 00:58:17.720
So what has happened in Java 6?

00:58:17.820 --> 00:58:19.400
Well, Sun's been busy.

00:58:19.400 --> 00:58:20.270
It's been hard at work.

00:58:20.330 --> 00:58:24.840
And some of the improvements that
they've made in Java 6 in terms

00:58:24.840 --> 00:58:29.460
of the client compiler has made
quite a bit of performance impact,

00:58:29.460 --> 00:58:30.270
in fact.

00:58:30.310 --> 00:58:33.150
So what they did was they changed
the intermediate representation

00:58:33.240 --> 00:58:34.480
for the client compiler.

00:58:34.480 --> 00:58:36.820
They now use the
SSA intermediate representation,

00:58:36.820 --> 00:58:38.600
which is static single assignment.

00:58:38.600 --> 00:58:40.850
That's what SSA stands for.

00:58:41.000 --> 00:58:43.580
And it's a very powerful form
of intermediate representation.

00:58:43.600 --> 00:58:46.920
In fact, that's what's being used
in the server compiler,

00:58:46.920 --> 00:58:49.500
and it's being used in JVC 5 as well.

00:58:49.500 --> 00:58:51.760
And it lends itself to
better optimization.

00:58:51.760 --> 00:58:55.590
So it's very powerful,
and the client compiler

00:58:55.590 --> 00:58:57.660
is now using the SSA IR.

00:58:57.660 --> 00:59:01.840
Thanks to that,
they've also added now a new register

00:59:01.850 --> 00:59:04.860
allocator in the client compiler.

00:59:04.860 --> 00:59:07.980
It's a very simple register allocator.

00:59:07.980 --> 00:59:10.940
It's a linear scan,
simple register allocator.

00:59:10.940 --> 00:59:13.880
It's certainly not something
as complex as the one that you

00:59:13.880 --> 00:59:16.590
find in the server compiler,
but it gets its job done,

00:59:16.680 --> 00:59:18.770
and it does bring in a
good bang for the buck,

00:59:18.860 --> 00:59:19.710
so to speak.

00:59:19.800 --> 00:59:21.920
It does bring in a nice
little performance boost.

00:59:23.610 --> 00:59:26.580
Another important improvement
that they've made is that the

00:59:26.780 --> 00:59:29.880
client compiler now makes use
of SSE/SSE2 instruction set,

00:59:29.890 --> 00:59:32.500
which means that, going back to what
Victor was talking about,

00:59:32.620 --> 00:59:37.090
how you may not see a big performance
boost in long double performance

00:59:37.090 --> 00:59:40.600
between the 32-bit and the 64-bit world.

00:59:40.600 --> 00:59:42.600
This is one of the reasons.

00:59:42.600 --> 00:59:45.580
If you're using SSE/SSE2
instruction in the 32-bit world,

00:59:45.630 --> 00:59:48.600
you're already getting a lot
of the 64-bit advantages.

00:59:48.810 --> 00:59:52.600
You may not see a big boost over
there when you move to 64-bit.

00:59:52.870 --> 00:59:59.950
The client compiler is using these
instructions and it's helped it a lot.

01:00:00.590 --> 01:00:03.010
The server compiler was always fast.

01:00:03.110 --> 01:00:06.240
It was really very fast.

01:00:06.240 --> 01:00:10.080
In Java 6,
it's doing more aggressive inlining.

01:00:10.150 --> 01:00:11.190
It's generally gotten better.

01:00:11.360 --> 01:00:12.770
There's some bug fixes, some tweaks.

01:00:12.820 --> 01:00:21.420
It's generally been improved
over the last two years that

01:00:21.420 --> 01:00:21.420
Sun's been working on it.

01:00:22.130 --> 01:00:26.060
Things are looking better in 1.6.

01:00:26.060 --> 01:00:27.320
So what's our system configuration?

01:00:27.450 --> 01:00:28.340
What are we using?

01:00:28.380 --> 01:00:29.960
I'm using a standard Intel iMac.

01:00:30.070 --> 01:00:33.120
It's got some extra RAM,
and you can read everything over here.

01:00:33.120 --> 01:00:37.730
The thing to note over there is I'm
using comparable versions on Tiger,

01:00:37.830 --> 01:00:39.650
Leopard, and Windows.

01:00:39.650 --> 01:00:45.450
And I'm using RDP4,
because that's what you have on Leopard.

01:00:47.750 --> 01:00:48.620
What are we measuring?

01:00:48.710 --> 01:00:51.300
I'm going to show you graphs
that measure two benchmarks.

01:00:51.300 --> 01:00:52.540
One of them is the CIMARC benchmark.

01:00:52.540 --> 01:00:55.470
It's a numerical benchmark,
computationally intensive benchmark.

01:00:55.480 --> 01:00:58.370
And the second one is a
business logic benchmark,

01:00:58.480 --> 01:01:01.790
kind of to give a feel for
what the real-world performance

01:01:01.790 --> 01:01:03.770
impact of Java 6 will be like.

01:01:03.860 --> 01:01:06.020
So let's dig in.

01:01:06.060 --> 01:01:10.300
First slide, we're going to compare
Java 6 versus Java 5,

01:01:10.300 --> 01:01:13.620
and we're going to look
at the client compiler.

01:01:14.360 --> 01:01:16.350
I'm going to look at
CIMARC composite scores,

01:01:16.360 --> 01:01:18.330
so larger is better over here.

01:01:18.490 --> 01:01:20.580
The bigger the number,
the better the score, the faster the VM.

01:01:20.580 --> 01:01:22.570
This is how it looks.

01:01:22.570 --> 01:01:27.570
We've got two bars you see over there,
and obviously, as you can see,

01:01:27.570 --> 01:01:29.330
Java 6 is better than Java 5.

01:01:29.340 --> 01:01:33.740
And in fact, Java 6 is about 18%
faster than JVM 5 was.

01:01:33.820 --> 01:01:35.700
So straight out of the box,
just by switching VMs,

01:01:35.700 --> 01:01:38.290
you're going to get a performance
boost on your client compiler.

01:01:41.150 --> 01:01:42.010
What about the server compiler?

01:01:42.010 --> 01:01:44.580
Well, the server compiler is also faster.

01:01:44.580 --> 01:01:49.660
It's not as fast as the client compiler,
but it's also got a modest 4% gain.

01:01:49.660 --> 01:01:52.640
It's faster than J2SE 5.

01:01:52.640 --> 01:01:55.630
So across the board,
you'll see a nice performance boost

01:01:55.630 --> 01:01:57.840
when you move from Java 5 to Java 6.

01:01:57.840 --> 01:02:01.270
If you look at our business
logic benchmark to get a sense

01:02:01.270 --> 01:02:05.730
for the real-world performance,
the bottom two bars that you see

01:02:05.750 --> 01:02:11.020
over there is Java 5 and Java 6
compared on the client compiler.

01:02:11.100 --> 01:02:15.750
And again, the client compiler is
about 17% faster in Java 6,

01:02:15.760 --> 01:02:19.260
but the server compiler
really shines out here.

01:02:19.260 --> 01:02:22.050
In fact,
the server compiler has gotten about

01:02:22.050 --> 01:02:26.300
37% faster between Java 5 and Java 6,
as you would expect.

01:02:26.410 --> 01:02:29.360
This is like a business logic benchmark,
so it's a long-running app.

01:02:29.480 --> 01:02:32.640
Server compiler is definitely
better suited for it,

01:02:32.730 --> 01:02:33.950
and it's quite fast.

01:02:36.530 --> 01:02:39.600
Now we're going to look at
performance numbers across all the

01:02:39.600 --> 01:02:42.610
three different OSes that I can
install right now on my iMac.

01:02:42.650 --> 01:02:45.670
I can install Mac OS X Leopard,
Mac OS X Tiger,

01:02:45.770 --> 01:02:47.560
and Windows XP using Boot Camp.

01:02:47.560 --> 01:02:51.460
So I'm going to show you SIMAC numbers
across all three different OSes,

01:02:51.550 --> 01:02:52.830
and how does it look?

01:02:52.840 --> 01:02:56.260
Well, it's pretty comparable.

01:02:56.260 --> 01:02:58.720
All three OSes perform comparable.

01:03:00.140 --> 01:03:03.400
In the past,
we've had questions and reports

01:03:03.500 --> 01:03:06.440
that Java on Mac OS X is
slower than Java on Windows.

01:03:06.440 --> 01:03:07.840
Well, no more.

01:03:07.840 --> 01:03:11.060
You give it the same hardware,
and Java on Mac OS X performs

01:03:11.060 --> 01:03:12.440
just as well as Windows.

01:03:12.440 --> 01:03:15.720
You shouldn't see any performance
degradations when switching OSes.

01:03:15.720 --> 01:03:18.230
This is a client compiler.

01:03:18.230 --> 01:03:21.020
Server compiler is the same.

01:03:21.020 --> 01:03:25.970
All three OSes are pretty
identical in terms of performance.

01:03:29.520 --> 01:03:30.120
64-bit.

01:03:30.150 --> 01:03:37.200
Victor just announced the 64-bit VM that
we have right now as part of Java 6.

01:03:37.200 --> 01:03:39.000
How does it compare?

01:03:39.000 --> 01:03:41.240
I'm going to show you CIMAC again.

01:03:41.240 --> 01:03:44.060
These are the bars for
the client compiler,

01:03:44.060 --> 01:03:46.420
the 32-bit client compiler.

01:03:46.420 --> 01:03:49.200
This is a numerical benchmark,
so you expect the server

01:03:49.280 --> 01:03:50.540
compiler to do better.

01:03:50.540 --> 01:03:53.450
Sure enough,
the 32-bit server compiler is

01:03:53.630 --> 01:03:55.800
better in most of these benchmarks.

01:03:57.560 --> 01:03:58.770
What about 64-bit?

01:03:58.980 --> 01:03:59.860
How does it compare?

01:03:59.860 --> 01:04:01.710
The result's mixed.

01:04:01.760 --> 01:04:05.390
Sometimes it's a bit faster,
sometimes not.

01:04:05.430 --> 01:04:09.900
I would like to add the caveat, though,
that this is, as Victor said,

01:04:09.900 --> 01:04:10.900
we just got this running.

01:04:10.900 --> 01:04:13.980
We obviously haven't had any time
for any kind of performance tuning.

01:04:13.980 --> 01:04:19.060
This is a beta Java 6,
beta 64-bit support on a beta Leopard OS,

01:04:19.170 --> 01:04:25.170
so the final numbers will definitely look
different than what you see over here.

01:04:25.720 --> 01:04:29.490
This is just to give you an idea
of how the 64-bit VM performs.

01:04:31.220 --> 01:04:33.460
So, in summary,
what have we seen in all these

01:04:33.460 --> 01:04:35.120
wonderful little bar charts?

01:04:35.190 --> 01:04:37.550
We've seen that, you know,
the performance of Java on

01:04:37.660 --> 01:04:39.020
Mac OS X and Windows is at par.

01:04:39.020 --> 01:04:42.460
It's not something you
should concern yourself with.

01:04:42.460 --> 01:04:45.760
Java 6 is faster than J2SE 5, so,
you know,

01:04:45.760 --> 01:04:50.150
I definitely encourage you guys to
kind of go try it out and run your

01:04:50.150 --> 01:04:51.860
app and see how well it performs.

01:04:51.860 --> 01:04:54.530
The client compiler has
received a significant boost,

01:04:54.540 --> 01:04:57.360
so you should see an improvement
straight out of the box.

01:04:57.440 --> 01:04:59.190
You know,
the client compiler is the default,

01:04:59.200 --> 01:05:02.040
so you should see much
faster performance.

01:05:03.260 --> 01:05:05.670
and 64-bit is not really for everyone.

01:05:05.690 --> 01:05:08.190
You really need to sit and look
at your app and you need to see

01:05:08.190 --> 01:05:10.040
whether you need the extra memory.

01:05:10.040 --> 01:05:16.170
You need to run in a 64-bit environment
before jumping and passing the

01:05:16.290 --> 01:05:18.640
minus 64 flag to your applications.

01:05:21.110 --> 01:05:23.380
So that brings us to
the end of our session.

01:05:23.380 --> 01:05:26.940
To quickly go over what
we've talked today,

01:05:26.940 --> 01:05:31.400
we've talked about 64-bit
support for Java on Leopard.

01:05:31.400 --> 01:05:35.800
There's a wealth of new tools that
you're going to have in Leopard.

01:05:35.800 --> 01:05:38.800
You've got all your JMAP, JConsole,
JInfo tools.

01:05:38.800 --> 01:05:40.140
You've got DTrace.

01:05:40.200 --> 01:05:41.360
You've got X-Ray.

01:05:41.360 --> 01:05:44.180
And something we didn't
talk about in this session,

01:05:44.180 --> 01:05:47.740
but which Victor and Rick talked
about in the previous session,

01:05:47.740 --> 01:05:48.680
you have Shark.

01:05:48.840 --> 01:05:50.600
Shark's been available on Tiger.

01:05:50.840 --> 01:05:51.440
It's there on Leopard.

01:05:51.440 --> 01:05:53.960
You can use it for profiling
and tracing your Java apps.

01:05:53.960 --> 01:05:54.980
Use it.

01:05:55.140 --> 01:05:58.020
Find your performance bottlenecks.

01:05:58.020 --> 01:05:59.400
Improve your applications.

01:05:59.400 --> 01:06:04.100
And Java 6, it's available right now.

01:06:04.100 --> 01:06:05.900
We announced DP5 on Tuesday.

01:06:05.900 --> 01:06:07.700
Go ahead, download it.

01:06:07.850 --> 01:06:09.200
Try it out on your Tiger systems.

01:06:09.200 --> 01:06:14.750
For Leopard, it's there on your developer
seat that you got this week.

01:06:14.820 --> 01:06:16.030
Try it out.

01:06:16.100 --> 01:06:17.870
Give us your feedback.

01:06:17.880 --> 01:06:19.540
Bugreporter.apple.com.

01:06:20.560 --> 01:06:21.170
Mark that site.

01:06:21.180 --> 01:06:21.930
File bugs.

01:06:22.140 --> 01:06:22.750
Tell us about it.

01:06:22.840 --> 01:06:25.520
Tell us any issues,
problems you run into.

01:06:27.420 --> 01:06:33.400
and just would like to point out
some related sessions we've got.

01:06:33.400 --> 01:06:36.090
Most of the Java team is going
to be in the IT lab on the first

01:06:36.090 --> 01:06:39.810
floor today between 3:30 to 5:00.

01:06:39.940 --> 01:06:43.980
Find us and give us your feedback,
ask questions.

01:06:43.980 --> 01:06:45.750
I'll be there.

01:06:45.760 --> 01:06:47.470
We have a feedback forum tomorrow.

01:06:47.730 --> 01:06:50.030
It's at 9 o'clock in the morning,
so if you're not hungover

01:06:50.030 --> 01:06:53.560
from the beer bash tonight,
stop by, give us your feedback,

01:06:53.750 --> 01:06:55.180
tell us what you think.

01:06:55.190 --> 01:06:57.580
And I don't think we
have any time for Q&A,

01:06:57.580 --> 01:07:00.940
so we're going to be around over here,
so feel free to step forward

01:07:00.940 --> 01:07:03.740
and ask any questions.