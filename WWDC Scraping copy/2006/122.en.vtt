WEBVTT

00:00:10.400 --> 00:00:15.520
Hi, welcome to session 122,
Optimizing Core Data Applications,

00:00:15.520 --> 00:00:18.520
or more specifically,
Optimizing Your Core Data Applications,

00:00:18.520 --> 00:00:21.470
because really those are the
only ones you care about.

00:00:24.200 --> 00:00:27.170
Checklist basically of things
that you should look for,

00:00:27.270 --> 00:00:30.360
look at when you're looking into
optimizing your application.

00:00:30.590 --> 00:00:33.530
First of which is it's awfully hard
to optimize a Core Data application if

00:00:33.530 --> 00:00:35.490
you don't have a Core Data application.

00:00:36.930 --> 00:00:40.120
Last year when we introduced Core Data,
we had a fixed set of

00:00:40.120 --> 00:00:44.060
file formats supported,
the XML, binary, in-memory,

00:00:44.060 --> 00:00:45.560
and SQLite stores.

00:00:45.560 --> 00:00:48.620
And a lot of you made it very,
very clear that you wanted to use

00:00:48.620 --> 00:00:52.120
Core Data with your own file formats,
that you had legacy file formats

00:00:52.160 --> 00:00:55.220
that you'd been shipping,
that your customers were using,

00:00:55.220 --> 00:00:57.800
that were in wide distribution,
and gosh darn it,

00:00:57.910 --> 00:00:59.980
you wanted Core Data to work with those.

00:00:59.980 --> 00:01:03.950
You asked, we obeyed,
we now have an Atomic Store API that you

00:01:03.950 --> 00:01:06.680
can use to put your own file formats in.

00:01:06.700 --> 00:01:09.060
under Core Data.

00:01:10.400 --> 00:01:14.080
Basically, your data in our world.

00:01:14.190 --> 00:01:18.800
Much like the XML and binary stores,
and much like the name would hint,

00:01:18.970 --> 00:01:21.290
files are read and written atomically.

00:01:21.400 --> 00:01:25.540
This means that all of your
application data comes into

00:01:25.540 --> 00:01:28.900
Core Data when the store is added,
and all of it is written

00:01:28.970 --> 00:01:30.350
when the store is saved.

00:01:30.540 --> 00:01:35.640
There's two classes involved,
NSAtomicStore and NSAtomicStoreCacheNode.

00:01:35.760 --> 00:01:37.880
And this is sort of how they work.

00:01:38.240 --> 00:01:42.130
can see that we've got a persistent
store coordinator and we've got a file.

00:01:42.190 --> 00:01:45.400
As many of you, all of you know,
persistent store coordinators,

00:01:45.400 --> 00:01:48.790
the center of the Core Data world,
that's really your first

00:01:48.790 --> 00:01:50.480
entry point for stores.

00:01:50.660 --> 00:01:55.960
User decides they want to open a
file containing your legacy data.

00:01:55.960 --> 00:01:59.230
They tell the persistent store
coordinator to add a store.

00:01:59.230 --> 00:02:03.240
Persistent store coordinator looks
in its dictionary of store types

00:02:03.240 --> 00:02:07.210
to find out what clash should be
instantiated to handle that store

00:02:07.210 --> 00:02:10.020
data and creates an instance.

00:02:10.020 --> 00:02:12.880
It then sends a load method,
which is the atomic

00:02:12.880 --> 00:02:16.010
store's queue to go off,
look at the store file,

00:02:16.010 --> 00:02:21.030
find each managed object's external
representation in that file,

00:02:21.050 --> 00:02:22.690
and create a cache node.

00:02:22.850 --> 00:02:27.160
Does this for all of the data in the
file and then calls add cache nodes,

00:02:27.430 --> 00:02:31.360
which causes those cache nodes to
be registered in the atomic store.

00:02:31.600 --> 00:02:34.990
Load returns,
add persistent store with type

00:02:35.140 --> 00:02:37.160
on the coordinator returns.

00:02:37.260 --> 00:02:40.100
And you've got a fully
configured Core Data stack.

00:02:40.330 --> 00:02:45.960
Just like any of the other store types,
Core Data can now query, edit, save,

00:02:46.030 --> 00:02:48.700
delete, update,
do whatever they'd like with the user

00:02:48.700 --> 00:02:53.140
data in the managed object context,
living on top of your store format.

00:02:53.260 --> 00:02:55.720
Once the user's done with whatever
it is they were planning on

00:02:55.720 --> 00:02:59.970
doing-- adding new objects,
deleting objects, updating data--

00:03:00.530 --> 00:03:02.900
They're going to call
save on the context.

00:03:03.010 --> 00:03:04.600
They're going to hit a save button.

00:03:04.680 --> 00:03:06.440
You're going to call save on the context.

00:03:06.530 --> 00:03:09.640
That's going to get sent down to
the persistent store coordinator.

00:03:09.770 --> 00:03:12.140
And then interesting
things start to happen.

00:03:12.300 --> 00:03:16.780
First off, for every newly inserted
managed object in the context,

00:03:16.780 --> 00:03:19.730
new reference object for managed
object is going to be called.

00:03:19.890 --> 00:03:24.060
This is your cue to create some form of
a persistent object identifier that can

00:03:24.070 --> 00:03:29.510
be used to uniquely identify that managed
object within its inheritance hierarchy.

00:03:30.460 --> 00:03:34.870
Once we've done this,
we switch in the data you've

00:03:34.950 --> 00:03:39.110
created into the persistent,
into the managed object IDs,

00:03:39.310 --> 00:03:42.200
thus assigning persistent
object IDs to all of those

00:03:42.200 --> 00:03:44.900
objects that were just created.

00:03:44.900 --> 00:03:48.190
Once we've done that,
we call new cache node for managed object

00:03:48.300 --> 00:03:52.120
for all of these newly inserted objects.

00:03:52.120 --> 00:03:54.400
This is your cue to go off
and create a cache node,

00:03:54.400 --> 00:03:57.710
much like the ones you created
in the load phase earlier,

00:03:57.710 --> 00:04:02.100
an external representation
of your managed objects.

00:04:02.660 --> 00:04:05.260
Once we've handled all of
the newly inserted objects,

00:04:05.260 --> 00:04:08.260
we start calling updateCacheNode
for managed objects with all of

00:04:08.260 --> 00:04:10.740
the cached nodes that have been,
or with all of the managed objects

00:04:10.740 --> 00:04:13.400
that have been edited in the context.

00:04:13.520 --> 00:04:16.950
This method should go through,
take all of the attribute values

00:04:16.950 --> 00:04:21.160
out of the edited managed object
and push those into the cache node.

00:04:21.520 --> 00:04:24.450
Once we've done that for
all of the updated objects,

00:04:24.530 --> 00:04:28.490
we send a willRemoveCacheNodes method to
the atomic store telling it what store,

00:04:28.580 --> 00:04:32.500
what cached, what managed objects have
been marked for deletion.

00:04:32.630 --> 00:04:37.540
Finally, we call save,
which is your cue to find whatever set

00:04:37.540 --> 00:04:42.270
of cache nodes exists in the atomic
store and write those out to file.

00:04:43.840 --> 00:04:44.740
That's pretty much it.

00:04:44.740 --> 00:04:46.000
That's all there is to it.

00:04:46.000 --> 00:04:48.700
We provide, as I said,
two classes to help you do this.

00:04:48.790 --> 00:04:52.700
An Atomic Store,
which is an abstract class,

00:04:52.810 --> 00:04:55.900
provides all of the mechanisms
necessary for Core Data to

00:04:55.900 --> 00:04:58.700
interact with your external data.

00:04:58.700 --> 00:05:00.640
It does, however,
require that you provide

00:05:00.710 --> 00:05:03.480
the translation layer,
since we have no clue what it is you

00:05:03.480 --> 00:05:05.700
want your external data to look like.

00:05:05.700 --> 00:05:07.820
And it also requires that
you handle the metadata,

00:05:07.820 --> 00:05:10.940
that you somehow take care of saving
the store's unique identifier and

00:05:10.940 --> 00:05:13.520
any of the versioning information.

00:05:20.500 --> 00:05:22.560
You have to-- in order to
implement an atomic store,

00:05:22.560 --> 00:05:24.580
you need to override five methods.

00:05:24.580 --> 00:05:26.780
Don't worry, if you miss one,
we'll throw an exception and let

00:05:26.780 --> 00:05:30.890
you know that something really
important somewhere got missed.

00:05:31.350 --> 00:05:35.090
Those five methods are load,
we already explained that,

00:05:35.240 --> 00:05:39.830
new reference object for managed object,
new cache node for managed object,

00:05:39.830 --> 00:05:43.380
update cache node from managed object,
and save.

00:05:43.380 --> 00:05:47.290
Those are the only five methods you
really need to concern yourself with.

00:05:49.130 --> 00:05:50.220
I've mentioned cache nodes.

00:05:50.300 --> 00:05:51.000
What are they?

00:05:51.150 --> 00:05:55.800
They're an intermediary representation
that lives between whatever's living

00:05:55.800 --> 00:05:57.800
in the file format and managed objects.

00:05:57.800 --> 00:05:58.810
Why do we have them?

00:05:58.830 --> 00:06:00.830
Why don't we just use managed objects?

00:06:00.830 --> 00:06:05.520
Because managed objects have to exist
inside a managed object context.

00:06:05.520 --> 00:06:07.770
They can only be used by
that managed object context,

00:06:07.770 --> 00:06:09.940
they're tracked by that
managed object context.

00:06:09.940 --> 00:06:13.030
A persistent stack can have
multiple managed object contexts,

00:06:13.030 --> 00:06:16.220
so there's a question of, you know,
where would we put those?

00:06:16.850 --> 00:06:21.370
So instead of trying to invert our
stack and put things under that should

00:06:21.370 --> 00:06:26.850
be over and all that kind of fun stuff,
we have this intermediate representation,

00:06:26.850 --> 00:06:32.290
one per managed object that is going
to be stored in the external store,

00:06:33.130 --> 00:06:36.400
The only requirement on a cache
node is that it be KVC compliant.

00:06:36.620 --> 00:06:39.460
It needs to return wrapped
values for the attributes.

00:06:39.460 --> 00:06:42.180
It needs to return
collections of cache nodes,

00:06:42.240 --> 00:06:44.220
related cache nodes for relationships.

00:06:44.360 --> 00:06:46.120
This is also true of 2-1 relationships.

00:06:46.190 --> 00:06:49.330
If you have a 2-1 relationship,
you need to return a collection

00:06:49.330 --> 00:06:51.140
containing one element.

00:06:51.140 --> 00:06:54.890
We provide a concrete class that
allows you to wrap a dictionary.

00:06:54.890 --> 00:06:58.420
You provide, you instantiate,
you alloc and edit and

00:06:58.650 --> 00:07:02.310
then hand it a dictionary,
at which point everything just works.

00:07:02.310 --> 00:07:05.000
You're free to override it if you'd like.

00:07:05.000 --> 00:07:09.460
All you need to do is make
sure it remains KVC compliant.

00:07:09.460 --> 00:07:11.630
So just to prove that, you know,
we're not just talking,

00:07:11.630 --> 00:07:13.400
that we can actually do this,
I have a demo.

00:07:15.450 --> 00:07:18.400
This is actually, I believe,
associated with this

00:07:18.400 --> 00:07:20.400
session on the ADC website.

00:07:20.400 --> 00:07:22.320
So you can go off and
find the code for this.

00:07:22.480 --> 00:07:25.880
But it's a simple HTML star.

00:07:25.920 --> 00:07:28.390
I'm just going to build it and run it.

00:07:31.360 --> 00:07:34.340
I've got a little application.

00:07:34.340 --> 00:07:40.730
It lets me enter user information,
pick on one of my coworkers,

00:07:40.740 --> 00:07:44.670
whose goal is pretty much take
over the world with bindings.

00:07:45.800 --> 00:07:51.290
He also wrote this demo application,
so I figure he deserves some credit here.

00:07:51.320 --> 00:07:52.280
Add another user.

00:07:52.300 --> 00:07:56.890
If I can remember not to hit
the middle button on the mouse.

00:07:58.630 --> 00:08:01.300
another one of my coworkers,
whose goal is to make sure everybody

00:08:01.300 --> 00:08:03.870
in the world unit tests everything.

00:08:06.700 --> 00:08:09.740
and a lot of coworkers
with grandiose plans.

00:08:09.820 --> 00:08:13.360
So I've saved it.

00:08:13.380 --> 00:08:15.680
Now if I go off and look--

00:08:17.120 --> 00:08:22.980
applications,
library application support.

00:08:22.980 --> 00:08:24.790
We have something called HTML store.

00:08:24.970 --> 00:08:28.870
It's storing something that
looks awfully like an HTML file.

00:08:29.380 --> 00:08:32.880
And voila, here's the information
I entered in my application.

00:08:32.940 --> 00:08:37.560
But wait, you say,
that might just be dummy data.

00:08:37.610 --> 00:08:39.980
Wouldn't be the first time in a demo.

00:08:41.590 --> 00:08:43.220
So we've got this image well over here.

00:08:43.290 --> 00:08:45.450
So I'm going to go off and
I've got some pictures.

00:08:45.550 --> 00:08:47.570
That's where I want to be.

00:08:49.150 --> 00:08:51.900
That's actually a pretty good
picture for all of my coworkers since

00:08:51.900 --> 00:08:54.600
FOOS is really big on our floor.

00:08:55.500 --> 00:08:57.400
Save it.

00:08:57.420 --> 00:08:59.680
Reload this file.

00:08:59.710 --> 00:09:02.410
And voila, we've added an image.

00:09:02.460 --> 00:09:04.560
It's a pretty simple store format.

00:09:04.640 --> 00:09:06.480
Every entity has its own table.

00:09:06.540 --> 00:09:08.540
Attributes are stored
in individual columns.

00:09:08.650 --> 00:09:12.080
If you've got relationships,
they're stored as hyperlinks

00:09:12.080 --> 00:09:13.440
in a final column.

00:09:13.490 --> 00:09:16.220
I could add more and more
stuff to show it off,

00:09:16.250 --> 00:09:18.580
but you get the basic point here.

00:09:18.630 --> 00:09:20.070
We have an HTML store.

00:09:20.080 --> 00:09:21.660
We've shipped the source code for it.

00:09:21.810 --> 00:09:25.380
Like I said, you can go off and get
it from the ADC website.

00:09:25.780 --> 00:09:27.860
And really, this is the meat of it.

00:09:28.150 --> 00:09:33.400
One class, HTML store,
has an init method, has a dialog method,

00:09:33.510 --> 00:09:37.470
returns its identifier because we
wanted to do fancy things there.

00:09:39.290 --> 00:09:41.640
goes off and calls helper
functions for load,

00:09:41.640 --> 00:09:44.190
but most of those are
concerned with parsing HTML.

00:09:44.330 --> 00:09:46.040
Save.

00:09:49.420 --> 00:09:54.410
New Cache Node, Update Cache Node.

00:09:58.310 --> 00:10:01.400
and New Reference Object for
Managed Object ID.

00:10:01.400 --> 00:10:04.040
And we catch this method
that's being overridden.

00:10:04.040 --> 00:10:06.980
We don't really need to,
but it's convenient.

00:10:06.980 --> 00:10:08.800
All of that in about 200 lines of code.

00:10:08.800 --> 00:10:10.460
Your very own store.

00:10:18.510 --> 00:10:21.740
So you can do this too.

00:10:21.740 --> 00:10:24.210
You can go off, write your own store.

00:10:24.300 --> 00:10:25.820
Some things to think about.

00:10:25.940 --> 00:10:29.680
Because these are atomic stores,
everything's going to get read up front.

00:10:29.850 --> 00:10:33.220
You might want to consider deferring some
of the work of doing that loading if you

00:10:33.240 --> 00:10:35.460
know that you've got a lot of objects.

00:10:35.490 --> 00:10:38.590
You only ever need to
deal with a tiny subset.

00:10:38.800 --> 00:10:39.970
It's expensive to parse stuff.

00:10:40.070 --> 00:10:41.920
You're pulling stuff in.

00:10:41.950 --> 00:10:42.840
That's expensive enough.

00:10:42.840 --> 00:10:45.300
You might not want to add the
additional load of all the parsing,

00:10:45.300 --> 00:10:49.160
so you can defer loading and
wrapping values until you actually

00:10:49.160 --> 00:10:51.660
try and access those objects.

00:10:53.240 --> 00:10:55.300
But you say you really want
to be living in Core Data,

00:10:55.300 --> 00:10:58.060
you want to be using an SQL store.

00:10:58.060 --> 00:11:01.480
It still might be interesting for you to
write an atomic store simply as a way to

00:11:01.480 --> 00:11:03.630
migrate your legacy data into Core Data.

00:11:03.660 --> 00:11:06.590
It's probably going to be easier for
you to write an atomic store that

00:11:06.590 --> 00:11:09.140
can interpret your file formats.

00:11:09.140 --> 00:11:12.220
Use those to load your data and then
call migrate on the persistent store

00:11:12.220 --> 00:11:15.930
coordinator and have it translate
all of the data into one of the more

00:11:15.930 --> 00:11:18.710
standard formats like say the SQL format.

00:11:18.800 --> 00:11:21.520
It can also give you interoperability
with other standards.

00:11:21.520 --> 00:11:25.100
You can load data from a Core Data file
and save it through a legacy file

00:11:25.300 --> 00:11:28.970
atomic store that will give you
some kind of format that some other

00:11:28.970 --> 00:11:30.940
application you use might need.

00:11:30.940 --> 00:11:33.900
But like all atomic stores,
they're a little bit problematic with

00:11:33.900 --> 00:11:36.910
large data sets simply because you
have to load everything up front,

00:11:36.910 --> 00:11:38.240
save everything all at once.

00:11:38.240 --> 00:11:42.860
There's a cycles performance
impact there and there's also

00:11:42.860 --> 00:11:45.800
a memory space issue because,
well, if you got a significantly

00:11:45.800 --> 00:11:48.330
large data set,
you're going to be using a lot of memory.

00:11:48.420 --> 00:11:52.240
So now you're in Core Data and we
can start doing interesting things.

00:11:52.280 --> 00:11:52.680
things.

00:11:54.980 --> 00:11:57.410
First thing to do if you want to
make your Core Data application

00:11:57.520 --> 00:11:59.470
fast is pick the proper store.

00:11:59.610 --> 00:12:01.480
We've got a number of store types,
each of which has their

00:12:01.510 --> 00:12:04.340
own characteristics,
depending on what you want to do.

00:12:04.420 --> 00:12:06.840
We have an in-memory store which
allows you to create objects

00:12:06.840 --> 00:12:09.660
that are only useful for the
duration of that application.

00:12:09.740 --> 00:12:12.560
But boy,
is it blazingly fast when you save.

00:12:13.590 --> 00:12:15.250
We've got our atomic stores.

00:12:15.360 --> 00:12:17.340
Their big benefit is
they're very easy to use.

00:12:17.340 --> 00:12:19.460
They don't require that you
learn anything about SQL.

00:12:19.460 --> 00:12:21.900
They're fairly fast for small data sets.

00:12:21.900 --> 00:12:25.440
And in the case of the XML store,
at least, it's human readable,

00:12:25.440 --> 00:12:27.660
so it makes it easier for you to debug.

00:12:27.660 --> 00:12:30.270
There's your atomic store class,
which may or may not be human

00:12:30.270 --> 00:12:33.100
readable depending on what you've
decided to use as a format.

00:12:33.100 --> 00:12:35.660
And definitely,
and this is the only store

00:12:35.730 --> 00:12:38.630
where you can get it,
contains whatever requirements

00:12:39.160 --> 00:12:40.660
are important to you.

00:12:40.660 --> 00:12:43.420
We can't know, but you can when you
build your store file.

00:12:43.500 --> 00:12:46.680
And then there's the SQL Lite store,
which is honestly the most

00:12:46.680 --> 00:12:48.040
scalable of our stores.

00:12:48.040 --> 00:12:52.020
It's best at dealing
with large data sets.

00:12:52.840 --> 00:12:54.860
It's more efficient both
in memory and on disk.

00:12:55.070 --> 00:12:55.390
Why?

00:12:55.470 --> 00:12:59.060
Because it doesn't need all the
extra overhead that goes into

00:12:59.060 --> 00:13:02.910
archiving or creating an XML file.

00:13:03.080 --> 00:13:05.630
It's faster loading because you
only load the objects you need.

00:13:05.640 --> 00:13:08.930
There's no upfront overhead when
you add an SQL light store because,

00:13:08.930 --> 00:13:12.320
well, until you ask it for objects,
we don't try and load any.

00:13:12.340 --> 00:13:14.140
You're going to have faster searching.

00:13:14.140 --> 00:13:16.570
SQL stores are generally
designed for doing things like

00:13:16.570 --> 00:13:18.340
relational queries and searching.

00:13:18.340 --> 00:13:22.020
It is, however, less forgiving,
and this is where we really get

00:13:22.020 --> 00:13:25.500
into the meat of optimization,
if you've got a bad model.

00:13:29.000 --> 00:13:32.340
Optimizing your model is really
the place to start when you want

00:13:32.340 --> 00:13:35.070
to make Core Data application fast.

00:13:36.810 --> 00:13:40.500
Because no matter what you do,
if you've got a model that really

00:13:40.500 --> 00:13:44.220
doesn't work for your applications data,
there's just nothing you

00:13:44.230 --> 00:13:45.600
can do to make it fast.

00:13:45.620 --> 00:13:49.010
You need to design your model
around your applications data,

00:13:49.010 --> 00:13:52.290
but to a certain extent,
you also need to consider designing your

00:13:52.290 --> 00:13:54.300
application around the data you've got.

00:13:54.300 --> 00:13:57.090
One of the things you really don't
want to do is build the kitchen

00:13:57.090 --> 00:14:00.040
sink window where you try and
display everything all at once.

00:14:00.040 --> 00:14:02.340
That means you're going to have
to load all of your data up front.

00:14:02.370 --> 00:14:03.760
That's slow, that's painful.

00:14:04.540 --> 00:14:07.040
It's probably also going to be really
confusing to your user who's going

00:14:07.040 --> 00:14:10.600
to be stuck sorting through all kinds
of stuff that doesn't necessarily

00:14:10.720 --> 00:14:13.070
need to be seen at the same time.

00:14:15.470 --> 00:14:20.380
So how do you design a
data model for efficiency?

00:14:20.430 --> 00:14:21.510
This is a pattern we see a lot.

00:14:21.650 --> 00:14:24.340
People just throw
everything onto one entity.

00:14:24.420 --> 00:14:27.640
Here we have a recipes entity
that seems to be our theme.

00:14:27.730 --> 00:14:30.180
Recipes, we like to cook.

00:14:31.300 --> 00:14:34.360
If we look at this entity,
it's actually easier often to try

00:14:34.360 --> 00:14:40.060
and optimize if you actually put
some data into a table representing

00:14:40.060 --> 00:14:43.240
what you would actually create if
you created instances of that entity.

00:14:43.350 --> 00:14:46.000
So I've done that,
and I'm looking at my table.

00:14:46.080 --> 00:14:48.040
The first thing I see is this column.

00:14:48.170 --> 00:14:51.290
That looks suspiciously
like a flattened array,

00:14:51.290 --> 00:14:53.440
an array of strings actually.

00:14:53.990 --> 00:14:57.660
That's really kind of inconvenient and
you really don't want to do that because,

00:14:57.660 --> 00:15:04.080
well, Core Data and a lot of other things
get much happier if they just have

00:15:04.080 --> 00:15:06.660
NSValue type attributes to work on.

00:15:06.700 --> 00:15:08.700
So we're going to break those
out into their own table.

00:15:08.700 --> 00:15:10.570
Call it normalization.

00:15:10.620 --> 00:15:11.840
Move it off.

00:15:11.980 --> 00:15:13.500
We've now got an ingredients entity.

00:15:13.500 --> 00:15:17.140
Contains all of the ingredients
that were in that column in the

00:15:17.140 --> 00:15:19.600
original table and their quantities.

00:15:20.160 --> 00:15:22.270
One of the advantages to this
is it's now a lot easier to

00:15:22.270 --> 00:15:23.910
search for recipes by ingredient.

00:15:25.640 --> 00:15:29.000
Now, if I'm doing normalization,
the first thing I need to do is put

00:15:29.000 --> 00:15:31.910
some kind of a foreign key on this
table so I can link it back to the

00:15:32.040 --> 00:15:33.490
recipe the ingredient came from.

00:15:33.500 --> 00:15:36.490
You'll notice that just using the
recipe name is going to be kind

00:15:36.490 --> 00:15:39.300
of inconvenient because I've got
multiple recipes with the same name.

00:15:39.300 --> 00:15:41.750
So I would decide, now,
you'll probably want to use

00:15:41.760 --> 00:15:44.620
just numerical ID and put that
back on the recipes table.

00:15:44.620 --> 00:15:45.160
And you know what?

00:15:45.290 --> 00:15:46.000
This is Core Data.

00:15:46.050 --> 00:15:47.000
Forget all of that.

00:15:47.020 --> 00:15:49.810
You don't need to know about it
except insofar as you know that

00:15:49.810 --> 00:15:51.600
this is how normalization works.

00:15:51.780 --> 00:15:53.770
There's something like that
going on behind the scenes.

00:15:53.770 --> 00:15:56.200
Core Data takes care
of all of it for you.

00:15:56.200 --> 00:15:59.920
So we're rid of the ingredients column.

00:15:59.920 --> 00:16:01.520
What can we do next?

00:16:01.520 --> 00:16:04.100
Well, for those of you who are
familiar with Objective-C,

00:16:04.100 --> 00:16:06.780
you've probably zoomed in on
this column because that looks

00:16:06.910 --> 00:16:08.140
an awful lot like an NSData.

00:16:08.140 --> 00:16:11.070
And given that the title
of the column is Pitcher,

00:16:11.070 --> 00:16:12.130
you'd be right.

00:16:12.180 --> 00:16:13.840
That's a picture of the recipe.

00:16:13.840 --> 00:16:16.420
What do we know about image data?

00:16:16.440 --> 00:16:17.590
We know it's big.

00:16:19.590 --> 00:16:23.940
We know given this data,
given the entity we saw earlier,

00:16:23.960 --> 00:16:26.110
given this data,
we know that we're going to load that

00:16:26.140 --> 00:16:29.440
large chunk of data even if all we
want to do is display recipe names

00:16:29.440 --> 00:16:30.980
in a table view or an outline view.

00:16:30.980 --> 00:16:34.870
We're going to move that off onto
its own separate entity as well.

00:16:36.730 --> 00:16:40.240
We've just speeded up our load time a
lot if we don't have to pull 5 megabytes

00:16:40.280 --> 00:16:44.000
worth of image data in for every recipe
we want to display in our table view.

00:16:44.000 --> 00:16:45.840
So what can we do next?

00:16:47.970 --> 00:16:49.020
Here's a good place to start.

00:16:49.080 --> 00:16:51.290
If you're doing normalization,
one of the things you're

00:16:51.290 --> 00:16:54.950
always thinking is,
I want to reduce, as much as I can,

00:16:54.960 --> 00:16:57.230
duplicate data in my tables.

00:16:57.650 --> 00:16:59.860
There's some duplicate data.

00:17:01.600 --> 00:17:04.270
This is actually kind of a deceiving
example because in the interest of

00:17:04.280 --> 00:17:06.940
getting everything into Keynote,
I made the table small.

00:17:06.940 --> 00:17:09.750
The chef would probably be
split across several columns,

00:17:09.890 --> 00:17:12.940
first name and last name,
possibly some biography information.

00:17:12.940 --> 00:17:16.360
It's going to be entered in
every single row in the table.

00:17:16.360 --> 00:17:17.420
It means what?

00:17:17.440 --> 00:17:18.940
I have to load it every time.

00:17:18.940 --> 00:17:21.710
It bloats my database because I've
got all of this data that's repeated

00:17:21.710 --> 00:17:22.940
over and over and over again.

00:17:22.950 --> 00:17:24.940
And if for some reason I ever
have to change one element,

00:17:24.940 --> 00:17:28.940
Ben gets sick and tired of being a
T in the alphabet and decides that no,

00:17:28.940 --> 00:17:29.940
he wants to be a Ferlet too.

00:17:29.940 --> 00:17:33.940
I'm going to have to go change
how many rows in my database?

00:17:33.940 --> 00:17:35.940
It's much easier if I just
stick that all in its own table.

00:17:35.940 --> 00:17:39.910
Have one entry per chef,
have those related.

00:17:39.940 --> 00:17:45.500
Similarly,
we've got a cuisine going here.

00:17:46.410 --> 00:17:48.490
Italian Cuisine x2.

00:17:48.510 --> 00:17:54.960
Do I really need that x2 or x10 or x1000
once for every recipe in the database?

00:17:54.960 --> 00:17:55.000
Nope.

00:17:55.190 --> 00:17:56.940
Let's make that go away too.

00:17:56.940 --> 00:18:00.540
And since we're on a roll,
we'll look at the recipe names and, hey,

00:18:00.540 --> 00:18:03.290
wow,
we've got duplicate data in there too.

00:18:03.360 --> 00:18:05.120
This is where you sort of
have to stop and think,

00:18:05.120 --> 00:18:07.020
what does that duplication mean?

00:18:07.080 --> 00:18:10.400
In the case of a chef or
in the case of cuisine,

00:18:10.440 --> 00:18:13.910
duplicate data really is, in a way,
identical.

00:18:14.120 --> 00:18:16.890
It's actually referring to
the same thing in all places.

00:18:17.180 --> 00:18:20.280
Is a recipe name unique in the same way?

00:18:20.480 --> 00:18:24.720
Or if I change a recipe name,
it just changes that one recipe.

00:18:24.720 --> 00:18:27.810
It doesn't change all
recipes with that name.

00:18:28.790 --> 00:18:31.930
These recipe names are pretty
integral to the identity of a recipe,

00:18:31.940 --> 00:18:35.820
so we're going to leave
those in this table.

00:18:35.820 --> 00:18:38.540
We're going to call it done because
pretty much everything we've got left

00:18:38.610 --> 00:18:41.260
really is integral to this table.

00:18:41.260 --> 00:18:45.840
So we had this and we've
made it look like that.

00:18:45.840 --> 00:18:50.300
It's more complex, but odds are very good
it's going to be faster.

00:18:50.300 --> 00:18:52.470
Recipes are going to load faster,
querying by cuisine

00:18:52.470 --> 00:18:56.020
is going to be faster,
querying by chef is going to be faster.

00:18:56.020 --> 00:18:57.980
And hey,
we've added the ability to easily

00:18:57.980 --> 00:19:00.690
query by ingredients as well.

00:19:00.900 --> 00:19:03.660
But you know, normalization isn't always
what you want to do.

00:19:03.830 --> 00:19:06.120
Sometimes you actually
want to go the other way.

00:19:06.240 --> 00:19:07.800
Take, for example, iCal.

00:19:07.800 --> 00:19:11.300
You might have heard in session yesterday
that they've started using Core Data,

00:19:11.800 --> 00:19:14.550
which means we actually had to think
about their model a little bit,

00:19:14.570 --> 00:19:17.500
just ourselves, make sure they weren't
doing anything wrong.

00:19:17.570 --> 00:19:19.220
You'll notice they've got these badges.

00:19:19.270 --> 00:19:23.020
They display primarily events,
but the events have information about

00:19:23.420 --> 00:19:26.330
things that are related to the events.

00:19:26.430 --> 00:19:27.870
If I was making a first
pass at their model,

00:19:27.880 --> 00:19:29.680
I'd build something that
looks a lot like this.

00:19:29.680 --> 00:19:30.660
I have a base event.

00:19:30.690 --> 00:19:34.780
It has relationships off to people,
alarms, and notes.

00:19:34.780 --> 00:19:37.280
But you know, that's really expensive
when I start doing their UI,

00:19:37.280 --> 00:19:39.590
because in order to display
any of those badges,

00:19:39.710 --> 00:19:42.480
I have to fault in all
of these relationships.

00:19:42.480 --> 00:19:44.560
And that's a lot of extra work.

00:19:44.560 --> 00:19:47.770
What I'd probably want to do instead
is create a Boolean that contains

00:19:47.770 --> 00:19:51.270
metadata about the relationships
and put that on the base entity.

00:19:51.500 --> 00:19:54.980
Then I can put up my badges or not,
depending on what the

00:19:54.980 --> 00:19:56.840
Boolean value is set to.

00:19:56.840 --> 00:19:59.060
This is going to require that
you write a little bit more code.

00:19:59.060 --> 00:20:02.780
You're going to have to actually add
accessor methods and put code in those

00:20:02.780 --> 00:20:06.980
accessor methods to update the Booleans
as the relationships are updated.

00:20:06.980 --> 00:20:09.720
But it's going to be faster.

00:20:11.310 --> 00:20:14.050
So what are the design tips we
can give you to go away with?

00:20:14.080 --> 00:20:23.890
If you can break entities down,
put subsidiary attributes onto entities

00:20:23.900 --> 00:20:26.920
at the other end of relationships in
order to speed uploading of your base

00:20:26.920 --> 00:20:29.700
entities for display and table views,
outline views,

00:20:29.700 --> 00:20:31.980
or something that really wants
a smaller subset of the data,

00:20:32.090 --> 00:20:32.970
do it.

00:20:33.270 --> 00:20:35.780
Move NSData onto the other
end of 2.1 relationships.

00:20:35.780 --> 00:20:37.670
It's almost always the right thing to do.

00:20:37.890 --> 00:20:39.400
Consider relationships carefully.

00:20:39.400 --> 00:20:40.320
They're very useful.

00:20:40.320 --> 00:20:41.760
They speed up searching.

00:20:41.870 --> 00:20:44.380
They allow you to minimize the
amount of duplicate data you've got,

00:20:44.380 --> 00:20:46.860
which makes updates faster,
makes your database smaller,

00:20:46.860 --> 00:20:49.380
makes your data set smaller,
because you don't have that data

00:20:49.380 --> 00:20:50.830
in memory in multiple places.

00:20:50.950 --> 00:20:53.620
They do take a little
bit of time to update.

00:20:53.700 --> 00:20:56.620
And they're a little bit slower
if you're doing key path queries

00:20:56.620 --> 00:20:58.480
across a lot of relationships.

00:20:58.480 --> 00:21:00.120
But it's probably also
going to be faster,

00:21:00.120 --> 00:21:03.770
like I said,
to do a strict equality check when you're

00:21:04.320 --> 00:21:07.740
querying then to do string
comparisons across a table.

00:21:07.870 --> 00:21:09.840
You also want to consider
inheritance carefully.

00:21:09.950 --> 00:21:14.210
There's not a lot of cost to inheritance,
but if you've got a very large data set,

00:21:15.420 --> 00:21:18.790
Those costs can build up over time.

00:21:19.040 --> 00:21:22.370
So I've told you to change your model.

00:21:23.770 --> 00:21:26.100
And I know at least some
of you are thinking,

00:21:26.100 --> 00:21:27.940
but you know,
it's a pain to migrate data.

00:21:27.940 --> 00:21:30.680
Or at least it was in
the Tiger timeframe.

00:21:30.680 --> 00:21:34.860
We've tried to help solve that problem
as well by adding a mechanism for

00:21:34.860 --> 00:21:38.520
model migration that conveniently
helps you optimize because you don't

00:21:38.520 --> 00:21:42.830
need to worry about the pain of writing
migration code every time you decide

00:21:42.830 --> 00:21:44.310
to change your model to make it faster.

00:21:44.320 --> 00:21:48.620
Core Data provides support for
model versioning and for migration.

00:21:48.640 --> 00:21:52.220
We put version information
in the store metadata,

00:21:52.730 --> 00:21:55.510
and we provide the ability to
create mapping models that allow

00:21:55.510 --> 00:21:58.750
you to describe transformations
from one Core Data version

00:21:58.870 --> 00:22:00.430
to another Core Data version.

00:22:01.980 --> 00:22:03.750
If you want to see how this works,
you can go look at the

00:22:03.750 --> 00:22:05.500
NS Migration Manager,
NS Mapping Model,

00:22:05.500 --> 00:22:08.010
NS Store Migration Policy,
and a bunch of other classes that

00:22:08.010 --> 00:22:10.600
Malcolm has kindly documented for you.

00:22:11.840 --> 00:22:15.980
Out of the box, what you need to know is
we provide facilities for

00:22:15.980 --> 00:22:18.470
adding and removing entities,
adding and removing properties,

00:22:18.480 --> 00:22:20.370
for factoring properties
into separate entities at the

00:22:20.450 --> 00:22:22.880
end of to-one relationships,
absorbing entities that were

00:22:22.880 --> 00:22:26.050
on to-one relationships,
and changing relationship cardinality,

00:22:26.050 --> 00:22:27.970
making it to-one and
to-many or vice versa,

00:22:27.970 --> 00:22:30.370
as long as it was only one
object and then to-many.

00:22:30.380 --> 00:22:32.970
Unfortunately, a lot of optimization is
a little bit more complex,

00:22:32.970 --> 00:22:34.940
and you're probably going
to have to write code.

00:22:35.380 --> 00:22:38.340
If you're uniting objects,
which you would do to improve query

00:22:38.340 --> 00:22:42.240
speed and to minimize the amount of data
you've got in the database or in memory,

00:22:42.240 --> 00:22:45.000
you're probably going to have to write
a custom entity migration policy.

00:22:45.000 --> 00:22:48.280
If you want to do data duplication,
we'll get more into that later when

00:22:48.280 --> 00:22:52.050
we're talking about database queries,
you might want to consider doing

00:22:52.080 --> 00:22:54.310
some text canonicalization up front.

00:22:54.320 --> 00:22:56.150
And for that,
you're probably going to want to

00:22:56.150 --> 00:22:57.800
write a custom function expression.

00:22:57.800 --> 00:23:00.840
That's really all I'm going to say
about migration other than it's there.

00:23:00.840 --> 00:23:03.920
It's very useful in the context
of optimizing your data model.

00:23:03.920 --> 00:23:07.790
And Malcolm has written really
great... great documentation about it.

00:23:09.700 --> 00:23:13.480
So hopefully by now you've
got a reasonably optimized

00:23:13.480 --> 00:23:14.520
model in your application.

00:23:14.520 --> 00:23:17.910
You can start getting down
to the nitty gritties.

00:23:18.360 --> 00:23:20.220
How do you get data into
your application quickly?

00:23:20.420 --> 00:23:21.600
Well, there's a number of ways.

00:23:21.720 --> 00:23:23.300
The fetch request cycle is pretty basic.

00:23:23.300 --> 00:23:28.090
The user does something which causes
a fetch request to be created and

00:23:28.120 --> 00:23:31.040
execute fetch requests to be called
on the managed object context.

00:23:31.040 --> 00:23:34.040
That's sent down to the persistent store,
which sends it down to any

00:23:34.050 --> 00:23:37.560
persistent store coordinate,
which sends it down to any of the stores.

00:23:38.040 --> 00:23:39.110
It's an atomic store.

00:23:39.110 --> 00:23:41.750
The predicate is evaluated
on the cache nodes in memory.

00:23:41.750 --> 00:23:44.570
Otherwise, if it's an SQL store,
we create an SQL statement,

00:23:44.640 --> 00:23:46.940
send that out to the database
where it's evaluated,

00:23:46.940 --> 00:23:49.180
and we see if we can
find any matching data.

00:23:49.180 --> 00:23:51.880
If we find matching data,
it's brought in, registered.

00:23:52.070 --> 00:23:54.930
Managed objects are created or
found depending on whether you'd

00:23:54.930 --> 00:23:58.170
already loaded the managed object,
passed back to the coordinator,

00:23:58.180 --> 00:24:00.720
passed back to the context,
which registers them if it

00:24:00.720 --> 00:24:03.900
doesn't already know about them,
and returned to the user.

00:24:03.900 --> 00:24:05.340
It's a pretty basic process.

00:24:05.350 --> 00:24:07.450
Many of you are probably
familiar with it.

00:24:07.510 --> 00:24:07.900
You've read our document.

00:24:08.080 --> 00:24:10.010
We've done a lot of documentation.

00:24:10.050 --> 00:24:10.740
This isn't always what you want, though.

00:24:10.740 --> 00:24:15.140
This is really good for the basic,
small data set, moderate data set,

00:24:15.190 --> 00:24:17.340
even the largest data set user case.

00:24:17.340 --> 00:24:19.410
But really,
it's not always what you want because

00:24:19.460 --> 00:24:22.520
sometimes you don't need all of the
data that ends up getting loaded.

00:24:22.520 --> 00:24:25.270
For example, a lot of the time,
you're only actually going to

00:24:25.270 --> 00:24:28.410
want to know how many objects in
the database meet the criteria

00:24:28.460 --> 00:24:30.460
that were set in the predicate.

00:24:30.460 --> 00:24:33.140
With the existing API,
you'd actually have to fetch all

00:24:33.140 --> 00:24:35.860
of those objects into memory,
count the number of them that

00:24:35.860 --> 00:24:37.020
were in the result array.

00:24:37.020 --> 00:24:38.020
You don't need to do that.

00:24:38.040 --> 00:24:38.340
We don't need to do that anymore.

00:24:38.340 --> 00:24:40.380
We've added API to the
managed object context,

00:24:40.380 --> 00:24:43.420
count for fetch request,
which allows you to just

00:24:43.420 --> 00:24:45.130
get the number back.

00:24:45.220 --> 00:24:47.400
We've also added some
stuff to NSFetchRequest.

00:24:47.400 --> 00:24:50.000
If you're doing a fetch on
an inheritance hierarchy,

00:24:50.000 --> 00:24:53.100
you often don't want all of
the entities in that hierarchy.

00:24:53.220 --> 00:24:55.150
You may want just one specific entity.

00:24:55.160 --> 00:25:00.360
You can tell the fetch request to include
or exclude subentities to determine

00:25:00.360 --> 00:25:03.150
precisely which objects you want back.

00:25:03.220 --> 00:25:06.240
If all you want back
is a managed object ID,

00:25:06.240 --> 00:25:07.930
you're interested in the
identity of the object.

00:25:08.040 --> 00:25:10.040
Not any other information about them.

00:25:10.040 --> 00:25:14.100
You can tell the fetch request to
return the result as managed object

00:25:14.100 --> 00:25:17.080
IDs instead of creating faults.

00:25:18.000 --> 00:25:20.200
Related to that is whether or
not you actually want to fetch

00:25:20.200 --> 00:25:22.740
the attribute values from the
database when you do the fetch.

00:25:22.740 --> 00:25:26.020
Normally, we fetch all of the values
for the object back,

00:25:26.160 --> 00:25:28.930
register it in the row cache,
and return a fault.

00:25:28.940 --> 00:25:31.150
When you trip the fault,
we go to the row cache,

00:25:31.240 --> 00:25:34.430
populate the managed object,
and you now have attribute

00:25:34.430 --> 00:25:36.160
values you can work with.

00:25:36.180 --> 00:25:38.250
Sometimes that's not what you want.

00:25:38.350 --> 00:25:41.050
You may have a very large data set
coming back for which you still want

00:25:41.140 --> 00:25:44.550
faults because you're going to need
to treat them as managed objects

00:25:44.600 --> 00:25:45.950
to access their attribute values.

00:25:46.320 --> 00:25:48.380
But you may not need all of that data.

00:25:48.380 --> 00:25:51.050
You may have 100,000 objects
that you're trying to bring back,

00:25:51.150 --> 00:25:53.500
and you're only ever going to display 10,
20, 30.

00:25:53.500 --> 00:25:55.570
At that point,
it may make more sense to leave

00:25:55.570 --> 00:25:58.110
the attribute values in the
database until you actually

00:25:58.170 --> 00:26:00.870
trip the managed object fault,
and then make the round trip to

00:26:00.900 --> 00:26:04.050
the database to pull in just the
specific attributes you actually need.

00:26:08.250 --> 00:26:10.300
An extension of that,
or actually not an extension,

00:26:10.300 --> 00:26:13.720
sort of the other extreme is that you
know up front that you're going to

00:26:13.720 --> 00:26:16.970
want all of the attribute information
from those managed objects pretty much

00:26:16.970 --> 00:26:18.380
immediately after you do the fetch.

00:26:18.380 --> 00:26:21.520
At this point,
you can tell the fetch request that it

00:26:21.520 --> 00:26:24.150
should not return the objects as faults.

00:26:24.220 --> 00:26:26.110
In that case,
we'll go out to the database,

00:26:26.110 --> 00:26:29.510
pull all the attribute values back,
and create your managed object faults,

00:26:29.550 --> 00:26:31.480
and then populate them immediately.

00:26:31.870 --> 00:26:34.900
This saves you the trip through the
fault handlers if you know up front

00:26:34.900 --> 00:26:38.440
that you're actually going to need
all of those managed objects realized.

00:26:38.440 --> 00:26:44.380
Related to that is the ability to set
relationship key paths for prefetching.

00:26:44.400 --> 00:26:45.440
What does this do?

00:26:45.440 --> 00:26:47.160
Sometimes you know when
you load an object,

00:26:47.160 --> 00:26:49.240
you're always going to
want some related object.

00:26:49.240 --> 00:26:51.380
For my recipes,
I may know that because of

00:26:51.380 --> 00:26:54.960
the way I'm displaying data,
not only do I always want the recipe,

00:26:54.960 --> 00:26:57.600
I'm always going to immediately,
whenever I use a recipe,

00:26:57.600 --> 00:26:59.020
try and access its cuisine.

00:26:59.020 --> 00:27:01.670
I can specify the relationship key path.

00:27:01.860 --> 00:27:03.680
I can specify the relationship key path.

00:27:03.830 --> 00:27:07.790
This will tell Core Data that whenever
you fetch recipes from the database,

00:27:07.860 --> 00:27:10.780
also fetch back their associated
cuisines and register those.

00:27:10.840 --> 00:27:13.670
This can minimize the number of trips
you have to make to the database,

00:27:13.670 --> 00:27:19.360
minimize the amount of work you have
to do after every trip to the database.

00:27:20.260 --> 00:27:24.780
and it will make handling faulting
relationships a lot faster.

00:27:24.840 --> 00:27:25.990
So there's no one silver bullet.

00:27:26.110 --> 00:27:29.610
No one of these things is going to be
right for all of your applications.

00:27:29.860 --> 00:27:32.350
You're going to have to decide how it
is your user is trying to use data,

00:27:32.350 --> 00:27:35.830
what it is you're trying to achieve,
and which set of flags it is

00:27:35.910 --> 00:27:37.860
that's appropriate for you.

00:27:39.340 --> 00:27:42.760
Once you've got your data,
there's a couple other things

00:27:42.830 --> 00:27:45.530
you really want to think about,
mostly having to do with how much of it

00:27:45.540 --> 00:27:48.190
you want to keep in memory at one time.

00:27:48.450 --> 00:27:50.790
We ended up like this at the end
of the last fetch request cycle.

00:27:50.990 --> 00:27:52.440
We just had a couple objects in memory.

00:27:52.460 --> 00:27:54.720
But you know, your user's not just going
to look at two objects.

00:27:54.800 --> 00:27:57.560
They're going to ask for more and more.

00:27:57.570 --> 00:28:00.110
And eventually,
you're going to have lots.

00:28:00.750 --> 00:28:04.300
At some point, if they've only looked
at those objects once,

00:28:04.420 --> 00:28:05.940
you're probably going
to want to release them.

00:28:05.940 --> 00:28:08.770
So first,
you only want to fetch what you need,

00:28:08.790 --> 00:28:10.810
but second is you only want
to retain what you need.

00:28:10.860 --> 00:28:14.620
And some things that can help you
figure out what it is you're retaining,

00:28:14.620 --> 00:28:18.410
whether you knew it or not,
is that contexts retain objects

00:28:18.410 --> 00:28:20.660
that have been modified,
but not objects that

00:28:20.660 --> 00:28:22.060
haven't been modified.

00:28:22.060 --> 00:28:25.750
So if you're not retaining
something that hasn't been modified,

00:28:25.750 --> 00:28:27.400
it's not being retained.

00:28:27.400 --> 00:28:30.360
When its release count goes to zero,
it's released, deallocated,

00:28:30.450 --> 00:28:32.840
memory gets scavenged,
you get to reuse it at some point.

00:28:32.860 --> 00:28:36.560
Often it will surprise you if
you've got a wild pointer and other

00:28:36.980 --> 00:28:38.420
things end up in the same place.

00:28:38.420 --> 00:28:40.370
Weirdness happens when
you're trying to debug.

00:28:40.380 --> 00:28:41.360
Heisenbugs aren't fun.

00:28:41.360 --> 00:28:44.940
Undo managers retain object IDs only.

00:28:47.700 --> 00:28:49.100
There's something to think about.

00:28:49.320 --> 00:28:50.840
And you know,
we're subject to the rules of

00:28:50.840 --> 00:28:53.060
Cocoa Memory Management just
the way you are.

00:28:53.170 --> 00:28:55.840
So if you've tripped
a relationship fault,

00:28:55.890 --> 00:28:59.430
relationships retain the
objects they're related to.

00:28:59.560 --> 00:29:02.900
This is called, in the vernacular,
a retain cycle.

00:29:02.970 --> 00:29:04.700
If you want for some of
those objects to go away,

00:29:04.700 --> 00:29:07.420
you're going to need to figure out
how to break that retain cycle.

00:29:07.490 --> 00:29:09.470
There's a couple of ways to do that.

00:29:09.700 --> 00:29:11.620
The one you're probably going
to want to use most of all is

00:29:11.650 --> 00:29:13.480
refresh object merge changes.

00:29:13.560 --> 00:29:17.040
This is on the managed object context,
and it causes the object to

00:29:17.040 --> 00:29:18.820
be turned back into a fault.

00:29:18.910 --> 00:29:22.410
And if you say merge changes no,
the object remains a fault.

00:29:22.430 --> 00:29:25.150
If you say merge changes yes,
it will be re-realized,

00:29:25.180 --> 00:29:27.330
and the changes will be applied,
but the relationship

00:29:27.420 --> 00:29:28.560
faults won't be tripped.

00:29:28.660 --> 00:29:31.440
This allows you to break
relationships between objects,

00:29:31.440 --> 00:29:33.870
break retain cycles,
and allow whatever is at the other

00:29:33.870 --> 00:29:39.270
end of those relationships to be,
well, released, dealloced, scavenged.

00:29:39.430 --> 00:29:41.250
There is another option,
which is much more of

00:29:41.250 --> 00:29:42.850
a nuke and pave option,
which is reset.

00:29:42.920 --> 00:29:46.240
You can call that on the managed object
context to blow away everything that's

00:29:46.280 --> 00:29:50.730
been done in that context and reset
the state to the way it was initially.

00:29:50.850 --> 00:29:52.800
This includes blowing
away the undo stack,

00:29:52.920 --> 00:29:55.260
so it's a pretty heavyweight option.

00:29:55.260 --> 00:29:57.520
But sometimes it's really what
you're going to want to do,

00:29:57.520 --> 00:30:00.080
and it's going to be a lot
faster than refreshing every

00:30:00.080 --> 00:30:02.210
single object in the context.

00:30:10.360 --> 00:30:12.270
Things start to get tricky at this point.

00:30:12.350 --> 00:30:13.730
A lot of optimization really is.

00:30:13.730 --> 00:30:17.000
It becomes more a matter of
looking at what you've got,

00:30:17.000 --> 00:30:19.640
trying to figure out
what it's telling you,

00:30:19.640 --> 00:30:21.230
and then trying to figure
out what to do about it.

00:30:21.320 --> 00:30:22.960
How do you do that in Core Data?

00:30:23.000 --> 00:30:27.800
We've added a default,
com apple core data SQL debug.

00:30:27.800 --> 00:30:31.270
This allows you to tell
Core Data to log all of its

00:30:31.270 --> 00:30:33.940
transactions with the database.

00:30:33.940 --> 00:30:36.220
You can set it to a
value between 1 and 3.

00:30:36.220 --> 00:30:39.840
1 displays the least information,
3 is the most.

00:30:39.840 --> 00:30:42.500
1 is probably actually for most of
you going to be the most useful.

00:30:42.500 --> 00:30:45.560
It'll log all of the SQL that's
being sent to the database.

00:30:45.560 --> 00:30:49.000
It'll tell you how many objects were
returned as a result of that SQL,

00:30:49.000 --> 00:30:50.840
and it'll tell you how long it took.

00:30:50.840 --> 00:30:53.460
If you find that's not
enough for some reason,

00:30:53.460 --> 00:30:56.210
there's always Shark,
which will tell you exactly where

00:30:56.210 --> 00:30:59.040
your application is spending cycles,
and where you really want

00:30:59.040 --> 00:31:02.120
to be concentrating the bulk
of your optimization work.

00:31:03.770 --> 00:31:08.280
What kind of things might you see
in the logs that Core Data prints

00:31:08.280 --> 00:31:09.460
when it goes to the database?

00:31:09.710 --> 00:31:12.480
You might see that you're
doing one big fetch up front,

00:31:12.500 --> 00:31:15.550
and then a lot of individual
fetches that are on related objects

00:31:15.620 --> 00:31:19.600
that are only after one object,
that are only returning one object.

00:31:19.600 --> 00:31:21.860
What this means is that you're
probably firing a lot of

00:31:21.860 --> 00:31:23.600
relationship faults individually.

00:31:23.600 --> 00:31:28.600
This is a good place for you to use
relationship keypath prefetching.

00:31:28.710 --> 00:31:31.600
Go grab those objects up front
instead of doing it one at a time.

00:31:31.600 --> 00:31:35.940
This is a specialized subset of
what we call a bad access pattern

00:31:35.940 --> 00:31:38.600
of repeated trips to the database.

00:31:38.600 --> 00:31:40.600
Going to the database is I/O.

00:31:40.600 --> 00:31:44.600
We all know that I/O is slower
than operating on stuff in memory.

00:31:44.600 --> 00:31:49.600
You don't want to do it repeatedly
for very small object sets.

00:31:49.600 --> 00:31:52.600
You want to try and maximize the
amount of data you get for the

00:31:52.600 --> 00:31:54.550
overhead of the trip to the database.

00:31:54.610 --> 00:31:56.600
Try and load as much as you can.

00:31:56.600 --> 00:31:59.600
If you see you're bringing back
lots of individual objects,

00:31:59.600 --> 00:31:59.600
try and find out if there's a
way to aggregate that somehow.

00:31:59.600 --> 00:32:02.600
In operators are a very
good way to do this.

00:32:02.600 --> 00:32:05.580
You can use the in operator to return.

00:32:05.610 --> 00:32:10.840
You can write a predicate that basically
says my object ID in a random collection

00:32:10.840 --> 00:32:14.600
of object IDs that you get somehow.

00:32:14.600 --> 00:32:18.470
This will bring a whole bunch of
otherwise unrelated objects back

00:32:18.470 --> 00:32:20.590
into memory all at the same time.

00:32:20.920 --> 00:32:22.940
Sometimes you'll find out you're
loading more data than you need,

00:32:22.940 --> 00:32:26.970
that the predicate you thought you
were setting isn't actually being set.

00:32:27.160 --> 00:32:30.700
or you're not setting a
specific enough predicate.

00:32:30.700 --> 00:32:31.590
Something else to look at.

00:32:31.610 --> 00:32:34.370
Sometimes you'll notice that you're not
actually doing a lot of database queries,

00:32:34.570 --> 00:32:36.920
but boy, are you spending a lot
of time in the database.

00:32:36.920 --> 00:32:38.580
At this point,
you want to look at your where

00:32:38.690 --> 00:32:40.520
clause and see what it says.

00:32:40.680 --> 00:32:43.400
If you've got a complex predicate,
it might just be that you're

00:32:43.400 --> 00:32:44.710
doing things in the wrong order.

00:32:44.720 --> 00:32:47.900
You want to order the simple parts first.

00:32:47.960 --> 00:32:50.680
If you have a salary comparison
and then some kind of a regex,

00:32:50.680 --> 00:32:56.530
you want to do the numerical
salary comparison first.

00:32:56.570 --> 00:33:00.500
you can cut down the number of rows
you actually have to do a regex on.

00:33:01.680 --> 00:33:02.460
Well, text.

00:33:02.530 --> 00:33:04.180
That's our last bullet point up there.

00:33:04.320 --> 00:33:05.540
Red desk is expensive.

00:33:05.780 --> 00:33:06.940
There's just no way around it.

00:33:07.160 --> 00:33:10.630
It's a whole bunch of stuff that we have
to do to set that up to make it work.

00:33:10.730 --> 00:33:14.300
The more flexibility you give
your user in querying text,

00:33:14.300 --> 00:33:17.270
the more expensive your
query is going to be.

00:33:17.790 --> 00:33:23.130
Basically, case and diacritic sensitive
comparisons are faster than case and

00:33:23.130 --> 00:33:25.460
diacritic insensitive comparisons.

00:33:25.530 --> 00:33:28.630
Equality is faster than
substring comparison,

00:33:28.630 --> 00:33:31.570
is faster than regex.

00:33:31.680 --> 00:33:35.860
You may notice that you're doing
case and diacritic insensitive regex.

00:33:35.950 --> 00:33:38.860
You might want to ask yourself,
is that really what you need?

00:33:38.940 --> 00:33:41.040
Do you really need the case
and diacritic insensitivity,

00:33:41.040 --> 00:33:43.610
or are all of your users
Americans and wouldn't know an

00:33:43.610 --> 00:33:46.170
accent if one snuck up on them?

00:33:49.180 --> 00:33:52.380
Do you really need full regex or
is substring support good enough?

00:33:52.500 --> 00:33:54.030
A lot of the time,
substrings are actually what

00:33:54.040 --> 00:33:55.760
you really want to be using.

00:33:55.830 --> 00:33:59.260
If you know that you really do need
case and diacritic insensitivity,

00:33:59.260 --> 00:34:01.510
you might actually want to
think about doing some string

00:34:01.580 --> 00:34:05.560
canonicalization up front,
creating a shadow attribute that contains

00:34:05.560 --> 00:34:09.120
a canonicalized version of whatever
the text is that you want to search on.

00:34:09.240 --> 00:34:11.900
This is going to make it a little bit
more expensive to create your objects,

00:34:11.900 --> 00:34:15.530
a little bit more expensive to save them.

00:34:15.750 --> 00:34:19.100
But boy, is it going to save you
time when you're searching.

00:34:19.170 --> 00:34:22.260
Because every time you do a case
or diacritic insensitive search,

00:34:22.370 --> 00:34:23.870
we have to normalize the text.

00:34:24.130 --> 00:34:26.980
And when we're done with the search,
we just throw that away.

00:34:27.040 --> 00:34:29.930
Well, you can imagine that that would
build up if you're doing 30

00:34:30.120 --> 00:34:33.040
queries across the same column,
all of which have to do a whole

00:34:33.040 --> 00:34:34.800
bunch of work and then throw it away.

00:34:34.850 --> 00:34:37.860
All of which are doing the same whole
bunch of work and then throwing it away.

00:34:37.940 --> 00:34:41.080
You might want to consider
uploading that up front.

00:34:41.140 --> 00:34:43.270
Relationships are something that
can also be really expensive.

00:34:43.500 --> 00:34:45.680
They can be very useful if
you're just following one link.

00:34:45.700 --> 00:34:47.680
You're following a different
relationship key path,

00:34:47.680 --> 00:34:49.460
and you're doing an
identity-based comparison.

00:34:49.590 --> 00:34:53.170
It gets a lot uglier if you're following
13 of them and doing some kind of

00:34:53.260 --> 00:34:55.930
obscure text manipulation at each step.

00:34:56.170 --> 00:34:58.830
You want to try and minimize the
set of objects you're working with.

00:34:58.980 --> 00:35:02.240
So you might want to see if there's
a way you can refactor your UI or

00:35:02.240 --> 00:35:05.510
your data set to move some of that

00:35:05.960 --> 00:35:10.390
Relationship information onto
other objects and not do large

00:35:10.390 --> 00:35:12.810
amounts of key path following.

00:35:13.480 --> 00:35:14.620
Some other stuff we've seen.

00:35:14.780 --> 00:35:18.000
This is actually a fairly common
pattern if people are creating lots

00:35:18.000 --> 00:35:20.040
and lots of objects all at once.

00:35:20.280 --> 00:35:22.540
They'll hit the database
repeatedly to find out if they've

00:35:22.540 --> 00:35:23.640
already created an object.

00:35:23.810 --> 00:35:27.710
This is common if they want to use some
kind of unique information that is not,

00:35:27.710 --> 00:35:30.390
however,
unique in the data set they started with.

00:35:30.550 --> 00:35:32.850
Cuisines are actually a good example.

00:35:33.030 --> 00:35:36.670
When I write my code to create
new recipes that have cuisines,

00:35:36.690 --> 00:35:39.870
I can look at the cuisine field,
pull out that string value,

00:35:40.010 --> 00:35:42.180
and do a database query to find
out whether or not I've already

00:35:42.180 --> 00:35:44.940
created a cuisine with that name.

00:35:45.020 --> 00:35:46.220
This is going to be slow.

00:35:46.300 --> 00:35:49.400
What you're probably going to want
to do is take the cuisine name,

00:35:49.580 --> 00:35:52.010
create a cuisine,
and then register it in a local cache

00:35:52.140 --> 00:35:56.220
dictionary that I can use to find out
if I've already created that object.

00:35:56.330 --> 00:35:57.470
Avoid the database trip.

00:35:57.610 --> 00:35:59.790
Everybody's happier.

00:36:00.090 --> 00:36:01.410
Don't save after every insert.

00:36:01.480 --> 00:36:02.440
We've also seen this.

00:36:02.440 --> 00:36:04.210
Try and batch them.

00:36:04.430 --> 00:36:08.750
Do your inserts in lots of 100 or
1,000 or whatever makes sense for you.

00:36:08.850 --> 00:36:11.950
One of the reasons people were doing
a lot of saves after inserts was

00:36:11.950 --> 00:36:16.310
so they could get permanent object
IDs assigned as quickly as possible.

00:36:19.370 --> 00:36:24.610
We've added API to the managed object
context that allows you to have

00:36:25.100 --> 00:36:33.010
and I'm going to show you how to use
Core Data to manage large amounts of

00:36:33.010 --> 00:36:41.350
data efficiently while maintaining
peak application performance.

00:36:42.950 --> 00:36:44.520
Deletions.

00:36:44.580 --> 00:36:47.140
As I mentioned before,
relationships are one of

00:36:47.140 --> 00:36:48.460
those mixed blessings.

00:36:48.490 --> 00:36:51.520
If an object participates in a
relationship that has an inverse,

00:36:51.520 --> 00:36:54.840
in order to delete the object,
we have to fault in all the objects

00:36:54.880 --> 00:36:58.460
that are on the other end of that
relationship so we can tell them

00:36:58.610 --> 00:37:03.690
that their relationship to this
source object needs to be cleaned up.

00:37:05.350 --> 00:37:08.720
Well, if you know up front that you're
deleting all objects that are at

00:37:08.740 --> 00:37:10.600
the other end of that relationship,
you may want to nil out

00:37:10.600 --> 00:37:11.790
the relationship first.

00:37:11.830 --> 00:37:15.370
This will save Core Data a whole
bunch of work doing the delete

00:37:15.370 --> 00:37:18.840
propagation for stuff that,
well, is going to be going away anyway.

00:37:21.720 --> 00:37:24.170
If you don't want to do that,
but you know that there's a

00:37:24.170 --> 00:37:26.040
whole bunch of objects at the
other end of the relationship,

00:37:26.040 --> 00:37:28.220
rather than tripping
those faults one by one,

00:37:28.220 --> 00:37:30.700
we mentioned that a few slides ago,
you might want to consider doing

00:37:30.700 --> 00:37:33.300
some prefetching when you load
those objects in the first place.

00:37:33.300 --> 00:37:36.870
Fetch whatever's on the other end
of the relationship so you're not

00:37:36.870 --> 00:37:40.530
tripping those faults individually
one by one by one by whatever the

00:37:40.530 --> 00:37:42.770
order of magnitude of work on the I.O.

00:37:42.770 --> 00:37:43.580
there is.

00:37:43.580 --> 00:37:46.120
And again, don't save after every delete.

00:37:49.900 --> 00:37:53.200
So you've got all those
patterns and you're looking

00:37:53.200 --> 00:37:55.060
at the numbers you're getting.

00:37:55.060 --> 00:37:57.480
You're saying, "Does this make sense?

00:37:57.480 --> 00:38:00.650
Can I do better?" A large part of
knowing whether or not you can do better,

00:38:00.650 --> 00:38:02.450
whether or not it's
worth spending the time,

00:38:02.450 --> 00:38:05.640
is knowing what to expect
in the first place.

00:38:05.700 --> 00:38:08.580
Core Data performs really well.

00:38:08.860 --> 00:38:10.940
for non-large data sets.

00:38:11.080 --> 00:38:12.830
What's a large data set?

00:38:12.960 --> 00:38:19.010
Unless your objects are 5 meg each,
5,000 objects is not a large data set.

00:38:19.080 --> 00:38:21.680
A large data set,
depending on the size of your objects,

00:38:21.680 --> 00:38:24.880
is going to start somewhere in the
hundreds of thousands of objects.

00:38:24.990 --> 00:38:27.020
Core Data can load
moderately sized objects,

00:38:27.100 --> 00:38:29.040
about 100,000 of them a second.

00:38:29.040 --> 00:38:32.240
That's in the latest version of Tiger.

00:38:32.360 --> 00:38:34.930
Ben will talk about some performance
improvements we've made in Leopard.

00:38:34.960 --> 00:38:37.860
We can save about 5,000 objects a second.

00:38:37.870 --> 00:38:40.470
We can delete about
1,000 objects a second.

00:38:40.480 --> 00:38:43.430
If these are the numbers you're seeing,
you're probably doing about

00:38:43.430 --> 00:38:47.040
as well as Core Data can do,
which means that you're at

00:38:47.040 --> 00:38:51.200
the point where you've done
all you can in a simple case.

00:38:51.200 --> 00:38:55.790
I'm going to bring Ben up here to
talk about the perils and patterns

00:38:56.000 --> 00:38:59.510
of the more complicated case,
otherwise known as attempting

00:38:59.510 --> 00:39:01.270
to multi-thread Core Data.

00:39:08.600 --> 00:39:09.660
Hey, good afternoon, everyone.

00:39:09.740 --> 00:39:12.360
So I'm going to show you some
stuff about multithreading.

00:39:12.360 --> 00:39:15.770
I'm going to preface this by
saying that it's a lot of work,

00:39:15.840 --> 00:39:19.090
and I don't really recommend
you go down this path until

00:39:19.160 --> 00:39:21.980
you really absolutely have to.

00:39:21.980 --> 00:39:23.660
But everybody asks eventually.

00:39:23.660 --> 00:39:26.500
So some of the motivations
for using threads,

00:39:26.500 --> 00:39:30.610
probably the best reason to add threads
to an application is responsiveness,

00:39:30.730 --> 00:39:34.140
where you have a long-running operation
and you don't want your users to

00:39:34.210 --> 00:39:36.160
get the little spinning pizza.

00:39:36.160 --> 00:39:38.240
And in this case,
a long-running operation is

00:39:38.240 --> 00:39:41.600
maybe 200 milliseconds or so.

00:39:41.600 --> 00:39:44.650
So threads can be a way to avoid
using a progress bar and do

00:39:44.650 --> 00:39:48.320
something in the background and
get your application's UI back to

00:39:48.320 --> 00:39:50.590
the user as quickly as possible.

00:39:50.590 --> 00:39:55.650
And in Core Data, another way you can use
threads are to do batch saves.

00:39:55.680 --> 00:39:57.850
So if you have a really
large block of saves,

00:39:57.880 --> 00:39:59.760
that can take a little bit of time.

00:39:59.760 --> 00:40:01.870
We know we have some more
performance work to do here,

00:40:01.870 --> 00:40:05.730
but one way you can get a boost is
if you're saving unrelated changes,

00:40:05.730 --> 00:40:07.470
you can break them up
into different groups.

00:40:07.480 --> 00:40:11.440
different groups and you can get a
performance improvement that way.

00:40:12.100 --> 00:40:16.780
So for Core Data's thread safety,
like much of Cocoa,

00:40:17.040 --> 00:40:19.760
there isn't a whole lot of
intrinsic thread safety going on.

00:40:19.760 --> 00:40:21.060
You need to do some locking.

00:40:21.200 --> 00:40:25.990
And we need you to help us understand
the scope of a transaction,

00:40:25.990 --> 00:40:30.880
what changes you want and don't want
to be controlled by that thread.

00:40:30.880 --> 00:40:33.050
So we need you to do some locking
on the managed object context and

00:40:33.080 --> 00:40:36.850
on the persistent store coordinator
to give us some scoping information.

00:40:37.030 --> 00:40:41.660
The managed objects themselves are always
owned by their managed object context.

00:40:41.810 --> 00:40:45.660
So whenever you're concerned about
the thread safety of managed object,

00:40:45.660 --> 00:40:49.140
you need to take a look
at who owns its context.

00:40:49.140 --> 00:40:52.820
Managed object IDs are immutable,
and they're always thread safe.

00:40:55.090 --> 00:41:00.030
So here's our recommended approach when
you do decide to jump into this pool.

00:41:00.030 --> 00:41:03.480
And that's basically a thread
creates a managed object context.

00:41:03.480 --> 00:41:05.280
A thread can have many
managed object contexts.

00:41:05.280 --> 00:41:08.670
But in particular,
the managed object context stays

00:41:08.710 --> 00:41:12.700
exclusively under the control
of the thread that created it.

00:41:12.700 --> 00:41:16.440
So only the creator thread ever sees it,
knows about it.

00:41:16.460 --> 00:41:19.210
There's no violations of encapsulation.

00:41:19.210 --> 00:41:23.710
Basically, the managed object context
is confined to that thread.

00:41:23.900 --> 00:41:24.980
This is easier to do.

00:41:25.000 --> 00:41:51.050
So there's a lot of interdependencies
that require synchronization.

00:41:51.050 --> 00:41:55.460
So there's a lot of interdependencies
that require synchronization.

00:41:55.460 --> 00:41:56.200
So there's a lot of interdependencies
that require synchronization.

00:41:56.200 --> 00:41:56.500
So there's more concurrency.

00:41:56.500 --> 00:42:02.040
So it basically requires that you
break things up a little bit more

00:42:02.040 --> 00:42:06.040
and plan your application around
larger aggregate operations.

00:42:06.040 --> 00:42:08.260
But you can get more
performance this way.

00:42:10.440 --> 00:42:13.500
So in this scenario,
Core Data is actually automatically

00:42:13.500 --> 00:42:15.200
going to do some of the locking for you.

00:42:15.200 --> 00:42:17.800
So you don't have to explicitly
lock a context if you're never

00:42:17.810 --> 00:42:20.670
sharing it with another thread,
in the same way that if you

00:42:20.780 --> 00:42:24.310
have a mutable dictionary and
no other thread ever sees it,

00:42:24.310 --> 00:42:26.170
then you don't have to lock it.

00:42:27.500 --> 00:42:29.810
And Core Data,
the managed object context,

00:42:29.810 --> 00:42:32.380
when it needs resources
from the persistent store

00:42:32.380 --> 00:42:36.300
coordinator or from the database,
will handle all the locking for you.

00:42:36.320 --> 00:42:39.060
So you don't have to worry about
whether or not the database

00:42:39.100 --> 00:42:41.210
resources need extra synchronization.

00:42:41.220 --> 00:42:44.060
You still need to lock the
persistent store coordinator

00:42:44.060 --> 00:42:45.860
when you message it explicitly.

00:42:45.860 --> 00:42:48.710
So if you're, say,
adding a new persistent store or

00:42:48.710 --> 00:42:52.080
you're asking a persistent store
coordinator to take a URI and

00:42:52.080 --> 00:42:55.290
give you back a managed object ID,
some stuff like that,

00:42:55.410 --> 00:42:57.390
then you'll need to lock the core.

00:42:57.410 --> 00:42:59.790
So you can lock the persistent
store coordinator if it's being

00:42:59.790 --> 00:43:01.190
shared amongst multiple threads.

00:43:01.200 --> 00:43:03.930
If you have a document-based application,
then you might not have to do

00:43:03.930 --> 00:43:06.580
this because the persistent store
coordinator might also be confined

00:43:06.650 --> 00:43:07.970
to a thread in a similar way.

00:43:07.980 --> 00:43:11.070
And another reason why you might want
to lock the persistent store coordinator

00:43:11.070 --> 00:43:12.700
is actually to get less concurrency.

00:43:12.700 --> 00:43:16.550
So if you have a bunch of operations,
you want to do some fetches,

00:43:16.550 --> 00:43:20.230
you want to do a couple saves,
and you want one context to own the

00:43:20.350 --> 00:43:24.250
coordinator for a specific block
and not let anybody else interpose

00:43:24.250 --> 00:43:27.450
some edits until you're done,
you can lock the coordinator.

00:43:28.100 --> 00:43:32.760
that only one context has access to
the database for some amount of time.

00:43:33.790 --> 00:43:36.110
And in Leopard,
we're now shipping a debug version

00:43:36.110 --> 00:43:37.720
of the Core Data Framework.

00:43:37.720 --> 00:43:40.400
And when you use the debug version
of the Core Data Framework,

00:43:40.460 --> 00:43:43.560
we added some threading
debugging assertions.

00:43:43.560 --> 00:43:47.890
So we basically keep track of additional
state about what you've locked and what

00:43:47.980 --> 00:43:52.160
you haven't locked and which thread
has got its fingers on which objects.

00:43:52.160 --> 00:43:56.930
And if you break any of our assumptions,
we'll throw an assertion failure

00:43:56.930 --> 00:43:59.370
and we'll basically kill your app.

00:43:59.430 --> 00:44:03.240
And if you're running in GDB,
this is really useful to get a backtrace

00:44:03.280 --> 00:44:03.680
of all the things that you've locked.

00:44:03.740 --> 00:44:12.240
So you set up the DLD image suffix,
and this turns on the debugging.

00:44:12.240 --> 00:44:15.490
If you man DLD, you can get some more
information about this.

00:44:15.490 --> 00:44:18.290
And when you've set up the
information correctly and

00:44:18.290 --> 00:44:22.450
you've passed this user default,
com, apple, core data, threading debug,

00:44:22.470 --> 00:44:24.720
and in this our threading
debug level one,

00:44:24.720 --> 00:44:27.670
we'll log a little message
saying that we've enabled the

00:44:27.670 --> 00:44:29.620
multi-threading assertions.

00:44:29.620 --> 00:44:33.130
And then you can break on
the NS assert functions.

00:44:33.140 --> 00:44:33.680
So if you're running a code,
you can break on the NS assert functions.

00:44:33.680 --> 00:44:34.750
So there's a really big one.

00:44:34.750 --> 00:44:38.260
I just look it up in the
foundation documentation

00:44:38.260 --> 00:44:40.390
and then throw my GDB in it.

00:44:40.540 --> 00:44:43.260
And you can see an example
of background threading,

00:44:43.300 --> 00:44:46.740
sorry, an example of multi-threading,
where each thread has a

00:44:46.780 --> 00:44:50.500
confined context and they don't
pass context between threads.

00:44:50.500 --> 00:44:52.480
This is actually a ship done tiger.

00:44:52.480 --> 00:44:55.700
It's in developer examples, core data,
background fetching.

00:44:55.700 --> 00:44:58.900
And the threads pass the immutable
object IDs between each other.

00:44:58.900 --> 00:45:02.040
And since they're immutable,
no synchronization is required.

00:45:02.040 --> 00:45:03.660
So threads can talk to each other.

00:45:03.660 --> 00:45:07.050
And so they can pass information
about the objects they're working

00:45:07.050 --> 00:45:10.820
with without actually exposing their
private copies of those objects.

00:45:10.820 --> 00:45:13.650
And it's an example of
threading for responsiveness.

00:45:13.780 --> 00:45:17.460
The background fetching doesn't
actually make the fetching any faster.

00:45:17.470 --> 00:45:19.980
But it does mean that when
you bring up the window,

00:45:19.980 --> 00:45:23.060
the user doesn't wait for all
the fetching to complete before

00:45:23.060 --> 00:45:25.000
the table view is rendered.

00:45:26.700 --> 00:45:31.000
So there's also the hard way,
which we really try to

00:45:31.000 --> 00:45:34.080
dissuade people from doing,
but some user scenarios

00:45:34.080 --> 00:45:34.830
actually require it.

00:45:34.940 --> 00:45:38.720
And that's when you want to pass a
managed object context between threads.

00:45:38.720 --> 00:45:41.400
So you can't confine it to
the thread that created it.

00:45:41.590 --> 00:45:44.330
You need to pass it off to another
thread at a later point in time.

00:45:44.340 --> 00:45:47.090
And in this case,
you really have to lock and unlock the

00:45:47.190 --> 00:45:50.910
context as you move them between threads,
and you want to basically

00:45:50.910 --> 00:45:54.780
transfer ownership of who's using
that managed object context.

00:45:55.830 --> 00:45:58.510
Managed objects, again,
I really need to iterate this.

00:45:58.520 --> 00:46:01.770
Even if you do value for key,
you do an accessor method

00:46:01.780 --> 00:46:05.680
on a managed object,
that thread needs to own the lock on

00:46:05.680 --> 00:46:08.740
that object's managed object context.

00:46:08.740 --> 00:46:10.660
And reading is not thread safe.

00:46:10.740 --> 00:46:12.760
Managed objects are not immutable.

00:46:12.760 --> 00:46:13.950
They're not NSDictionary's.

00:46:13.960 --> 00:46:18.360
And one of the real concerns here is
the side effect on Core Data is caching.

00:46:18.380 --> 00:46:20.070
So you might trigger a fault.

00:46:20.140 --> 00:46:22.680
You might trigger a callback.

00:46:22.680 --> 00:46:25.170
There are any number of
things that can go on.

00:46:25.590 --> 00:46:29.360
So we don't consider reading to
be thread safe intrinsically.

00:46:29.360 --> 00:46:30.220
You need to lock.

00:46:32.910 --> 00:46:35.660
and here's some sort
of higher level notes.

00:46:35.680 --> 00:46:39.000
Whenever you move any kind of
Cocoa object between threads,

00:46:39.140 --> 00:46:40.760
you need to retain anything you lock.

00:46:40.760 --> 00:46:44.430
So if you lock a managed object
context or you lock a persistent store

00:46:44.430 --> 00:46:48.630
coordinator or you lock an NS lock,
you need to own or retain on that.

00:46:48.680 --> 00:46:51.440
If that object gets deallocated
from underneath you while you're

00:46:51.440 --> 00:46:54.300
depending on its synchronization,
you will be very unhappy.

00:46:54.300 --> 00:46:56.680
And then objects that get
pushed across threads,

00:46:56.690 --> 00:47:00.020
whether they're managed objects
or any other kind of Cocoa object,

00:47:00.530 --> 00:47:04.420
need to be retained by the sending thread
and released by the receiving thread.

00:47:04.420 --> 00:47:07.460
And that's the only way you can make
sure that the lifespan of that object

00:47:07.540 --> 00:47:12.000
actually survives long enough for the
receiving thread to do something with it.

00:47:12.100 --> 00:47:15.880
And then managed objects go
wherever their contexts go.

00:47:18.520 --> 00:47:21.600
So again,
our threading assertions work for

00:47:21.600 --> 00:47:23.840
doing things the hard way as well.

00:47:23.840 --> 00:47:26.600
You bump up the threading
debug level to level three,

00:47:26.600 --> 00:47:27.940
and that kind of lets
you run with scissors.

00:47:27.940 --> 00:47:30.260
And it's basically the same.

00:47:30.260 --> 00:47:34.560
You just break on the NS assertion
and handle failure and method.

00:47:34.560 --> 00:47:38.850
And at that point,
you can do thread apply all and then BT,

00:47:38.850 --> 00:47:43.720
and that will get you backtraced
for all the threads running.

00:47:46.460 --> 00:47:51.010
And another note,
Core Data's undo facility is built on top

00:47:51.020 --> 00:47:53.320
of foundation about the NSUndoManager.

00:47:53.320 --> 00:47:57.150
We're just pushing our own
functions onto the undo stack,

00:47:57.220 --> 00:47:58.530
so it's not really all that magical.

00:47:58.540 --> 00:48:02.010
We're just observing all the changes
to your managed object context and

00:48:02.010 --> 00:48:03.820
doing some aggregation on them.

00:48:03.840 --> 00:48:07.360
What this means is the undo
manager is not thread safe.

00:48:07.400 --> 00:48:11.170
And the groups by event facility in
particular cannot be thread safe.

00:48:11.260 --> 00:48:14.840
There's no amount of locking that
will make groups by event run.

00:48:14.840 --> 00:48:17.800
So it needs to be disabled
on any undo managers you're

00:48:17.800 --> 00:48:19.730
using in background threads.

00:48:19.740 --> 00:48:23.410
You can either turn off...

00:48:24.370 --> 00:48:28.380
You can either set groups by event off,
or you can tell that context

00:48:28.390 --> 00:48:30.400
that you don't need undo
management on a background thread.

00:48:30.400 --> 00:48:34.420
In fact, many background threads don't
really need undo management.

00:48:34.420 --> 00:48:39.280
If you're doing a batch save and
something happens and you want to undo,

00:48:39.280 --> 00:48:42.200
you might just redo
that work and try again.

00:48:42.340 --> 00:48:47.360
Or if you're fetching in the background,
you don't need undo for that.

00:48:47.360 --> 00:48:50.800
So when you disable groups by event,
you can just manually

00:48:50.800 --> 00:48:54.710
push and pop undo stack,
basically bracketing yourself,

00:48:54.710 --> 00:48:57.320
and it's just the Foundation API.

00:48:58.390 --> 00:49:02.050
And a final note on threading
is about detached threads.

00:49:02.140 --> 00:49:05.640
Now, you can review some information
about POSIX threading to get the full

00:49:05.750 --> 00:49:07.610
technical detail about detached threads.

00:49:07.650 --> 00:49:11.080
But basically,
all NS threads are considered detached.

00:49:11.080 --> 00:49:14.090
And what this means is detached
threads are optional workers.

00:49:14.100 --> 00:49:19.400
The process is not required
to wait for them to finish.

00:49:19.400 --> 00:49:22.880
So an application can quit even if
there's detached threads running

00:49:22.880 --> 00:49:24.520
in the background doing work.

00:49:24.600 --> 00:49:28.260
And if you want the application,
if you want the main thread,

00:49:28.280 --> 00:49:28.280
you can quit.

00:49:28.300 --> 00:49:32.410
But to remain active and not quit,
then you're required to do

00:49:32.410 --> 00:49:36.930
some manual synchronization,
whether it's a condition signal or a

00:49:37.240 --> 00:49:39.640
thread join or some other work there.

00:49:39.640 --> 00:49:43.680
But basically, what this means is if you
save in the background,

00:49:43.680 --> 00:49:46.980
the application could quit
before your save is done,

00:49:46.980 --> 00:49:50.610
halfway through the save,
any point during the save.

00:49:50.640 --> 00:49:55.510
Now, this isn't necessarily a
big deal for the database.

00:49:55.510 --> 00:49:59.110
The SQLite database has got
full transactional support.

00:49:59.230 --> 00:50:01.940
They're completely ACID compliant.

00:50:01.940 --> 00:50:05.080
So the database will be fine,
but your users may not really

00:50:05.080 --> 00:50:09.410
appreciate that you had a clean
document window and you quit,

00:50:09.410 --> 00:50:12.050
and yet their changes aren't
actually saved to disk.

00:50:12.050 --> 00:50:15.380
So you'll want to do some additional
synchronization if you go too far

00:50:15.380 --> 00:50:17.400
into the threading using NS threads.

00:50:19.780 --> 00:50:24.300
and here I'm going to switch over
to the demo machine now and do

00:50:24.720 --> 00:50:29.070
sort of a modified reprise of some
of the demonstrations from last

00:50:29.140 --> 00:50:36.210
night and show in particular,
yeah, I don't care about the HTML store,

00:50:36.220 --> 00:50:42.940
and in particular show you some stuff in
Shark where you can see both how to use

00:50:42.940 --> 00:50:48.360
Shark and how I would approach Shark and
look at the hotspots and what things

00:50:48.360 --> 00:50:52.700
evolved between the different versions
of the application that we're working on.

00:50:52.700 --> 00:50:58.640
So this is basically just fetching
500,000 words from a dictionary database

00:50:58.640 --> 00:51:03.820
and I'm just warming it up so it's
sort of a fair comparison for everybody.

00:51:03.820 --> 00:51:14.610
And so here in the first one,
this is a basic project that's

00:51:14.610 --> 00:51:14.610
using SQLite directly and

00:51:20.610 --> 00:51:22.300
And basically, it's written in Rossi.

00:51:22.510 --> 00:51:24.520
It's using the SQLite APIs.

00:51:24.640 --> 00:51:28.640
It's using Core Foundation to
do the collection management.

00:51:28.680 --> 00:51:32.320
And the key point here is we
don't have a model object.

00:51:32.320 --> 00:51:34.300
We just have a generic dictionary.

00:51:34.390 --> 00:51:38.480
So this is pretty convenient
to use Core Foundation.

00:51:38.710 --> 00:51:41.990
And we're running our own SQL.

00:51:42.040 --> 00:51:42.350
Pretty easy.

00:51:42.360 --> 00:51:43.780
We iterate through everything.

00:51:43.920 --> 00:51:47.310
And that's pretty much it.

00:51:49.760 --> 00:51:55.390
So in Shark, we will-- this one.

00:51:56.100 --> 00:52:01.340
Take just a second here to run.

00:52:01.910 --> 00:52:07.210
Shark runs quite nicely
on a quad processor.

00:52:09.500 --> 00:52:12.810
and I'm going to show you how to use
Core Data to manage large amounts of

00:52:12.810 --> 00:52:16.420
data efficiently while maintaining
peak application performance.

00:52:39.500 --> 00:52:41.480
Melissa Turner,
Ben Trumbull and I'm going to show

00:52:41.480 --> 00:52:44.290
you how to use Core Data to manage
large amounts of data efficiently while

00:52:44.290 --> 00:52:46.290
maintaining peak application performance.

00:52:54.780 --> 00:52:58.380
So basically,
we can see here in the main function,

00:52:58.390 --> 00:53:03.250
we're spending a lot of time releasing
values and a lot of time doing the set.

00:53:03.340 --> 00:53:07.030
We spend a little bit of time in SQLite
and a lot of time wrapping values.

00:53:07.110 --> 00:53:09.200
And with working in the database,
it's actually pretty typical

00:53:09.540 --> 00:53:11.260
in pulling data to and from.

00:53:11.270 --> 00:53:15.560
You have to really wrap the values to
put these things into a Cocoa View.

00:53:15.560 --> 00:53:19.040
Let's see if I can
persuade Shark to-- eh.

00:53:19.040 --> 00:53:22.500
Shark doesn't want to open my source.

00:53:22.500 --> 00:53:24.010
How sad.

00:53:25.730 --> 00:53:32.350
This is the penalty I get for
not building on this machine.

00:53:32.580 --> 00:53:36.690
Basically, just walking you through it,
a lot of this dictionary work is

00:53:36.690 --> 00:53:40.610
going on right in here as we pull
back each of the values using the

00:53:40.610 --> 00:53:42.840
SQLite API to get each column value.

00:53:42.840 --> 00:53:44.660
And we need to wrap this.

00:53:44.660 --> 00:53:47.850
And because we don't
actually have a model object,

00:53:47.950 --> 00:53:53.070
we just have these keys defining sort of
loosely an attribute name with a column.

00:53:53.080 --> 00:53:58.260
We need to wrap them in
CFNumbers and CFStrings all the time.

00:53:58.920 --> 00:54:05.560
And as you can see in the shark trace,
that starts to add up like 15% of the

00:54:05.560 --> 00:54:08.460
time just working a little dictionary.

00:54:10.510 --> 00:54:13.210
You can see that the dictionary
object is really convenient,

00:54:13.210 --> 00:54:17.300
but probably not as fast
as we can possibly get.

00:54:17.400 --> 00:54:19.130
It took about 100 lines
of code to do that.

00:54:19.180 --> 00:54:24.260
And in this sample here,
I did some work to address the fact that,

00:54:24.260 --> 00:54:28.240
and I'm repeating it just
to keep everything fair,

00:54:28.340 --> 00:54:29.510
so to speak.

00:54:29.560 --> 00:54:35.870
So this is actually a good 40% faster,
so we're fetching about 200,000 lines,

00:54:35.870 --> 00:54:39.320
200,000 rows per second this way.

00:54:39.450 --> 00:54:45.980
It's also using exclusively SQLite.

00:54:54.300 --> 00:54:56.570
and we're doing some stuff
in Coconaut because we can

00:54:56.570 --> 00:54:57.410
get some stuff for free here.

00:54:57.480 --> 00:55:00.930
So the key performance enhancement
now is to throw out that generic

00:55:01.040 --> 00:55:04.620
dictionary and have a real object
that we can directly assign Ivers to.

00:55:04.620 --> 00:55:07.020
So we really cut back on all the
overhead we spent in hashing.

00:55:07.020 --> 00:55:12.760
And all that hashing also contributed
to the retain and release overhead.

00:55:12.760 --> 00:55:15.800
You can also see that we're spending
some serious time here hacking on

00:55:15.800 --> 00:55:19.760
retain and release because that came
up pretty heavily in the Shark sample.

00:55:19.780 --> 00:55:24.260
So I'll run this in Shark as well.

00:55:24.300 --> 00:55:25.460
Okay.

00:55:35.190 --> 00:55:39.320
So release is still taking
up a big amount of time,

00:55:39.340 --> 00:55:41.710
but you see most of the dictionary
hashing now has gone away,

00:55:41.720 --> 00:55:42.450
which makes sense.

00:55:42.510 --> 00:55:46.470
It's now focused on creating
the CFString object,

00:55:46.510 --> 00:55:48.050
strap the string values.

00:55:48.190 --> 00:55:52.000
But in here, we get to assign the numbers
directly into our IVARs.

00:55:52.150 --> 00:55:55.760
So that's actually a pretty
big performance improvement.

00:55:55.820 --> 00:56:00.630
And we also cut down on some of
the message sending going on.

00:56:12.500 --> 00:56:20.110
So in here,
where we used to be spending more time,

00:56:23.420 --> 00:56:26.240
With the dictionary hashing,
we're now spending most of

00:56:26.280 --> 00:56:30.490
our time creating the string
wrappers about what we expect.

00:56:30.730 --> 00:56:34.080
We basically have a CFDictionary here
to unique the values.

00:56:34.120 --> 00:56:36.970
So this is kind of like how you
might implement a row cache,

00:56:37.020 --> 00:56:38.690
basically.

00:56:38.750 --> 00:56:41.680
And we've cut back on some of
the retaining and releasing here

00:56:41.680 --> 00:56:44.130
using these custom callbacks.

00:56:48.330 --> 00:56:52.790
So the Core Foundation collections,
you can tweak their custom callbacks.

00:56:52.800 --> 00:56:55.440
And I keep hitting the
middle mouse button,

00:56:55.440 --> 00:56:56.280
excuse me.

00:56:56.310 --> 00:56:58.560
But instead of using
the default callbacks,

00:56:58.560 --> 00:57:00.340
which we'll call the
retain and release methods,

00:57:00.340 --> 00:57:03.020
we're using basically static functions,
which are sort of the

00:57:03.130 --> 00:57:06.290
Objective-C equivalent
of a non-virtual method.

00:57:06.350 --> 00:57:09.440
We've gotten rid of the overhead
of spin locking using the OS atomic

00:57:09.440 --> 00:57:11.330
increment and decrement operations.

00:57:11.440 --> 00:57:17.360
And as you can see down here,
we're a good 40% faster or so.

00:57:17.380 --> 00:57:23.300
And maybe a third more code.

00:57:30.170 --> 00:57:32.530
and I will give you the performance data.

00:57:32.580 --> 00:57:36.990
So here in Core Data,
basically we're doing all this for

00:57:36.990 --> 00:57:42.190
you and we're getting there just
under 500,000 rows per second.

00:57:49.500 --> 00:57:52.050
and here's my model.

00:57:52.410 --> 00:57:53.920
So this is a pretty simple model,
obviously.

00:57:54.200 --> 00:57:55.170
It's just a word.

00:57:55.180 --> 00:57:58.680
There's not a whole lot of data there,
but it does highlight the overhead

00:57:58.680 --> 00:58:01.740
that Core Data would have to work
with because each row has a certain

00:58:01.750 --> 00:58:05.900
amount of overhead regardless
of how much data you put in it.

00:58:05.900 --> 00:58:09.020
So for some of you,
this is hopefully an introduction to

00:58:09.100 --> 00:58:12.160
the new Objective-C property syntax,
which is really actually a

00:58:12.160 --> 00:58:15.920
very exciting addition to the
Objective-C programming language.

00:58:15.920 --> 00:58:18.980
And it allows you to do type
safe compiler check key paths,

00:58:18.980 --> 00:58:23.120
which is a feature I know a lot of people
have been asking for for a long time.

00:58:23.190 --> 00:58:26.130
And Core Data is going to
generate all the support for

00:58:26.130 --> 00:58:28.520
accessor methods on the fly.

00:58:28.580 --> 00:58:33.300
So you don't actually have to write
any of the accessor methods to do that,

00:58:33.490 --> 00:58:39.090
which doesn't look very exciting until
we look at the main body of the code.

00:58:40.420 --> 00:58:46.680
Here, and we're using the new
property syntax and this method,

00:58:46.750 --> 00:58:52.680
which is the text accessor method,
it's sort of syntactically equivalent.

00:58:53.650 --> 00:58:54.880
to doing that.

00:58:54.930 --> 00:58:56.960
And this method gets
generated for you on the fly.

00:58:56.960 --> 00:59:00.690
We'll take a look at the object and
see if there's any optimizations

00:59:00.750 --> 00:59:02.180
we can apply to do that.

00:59:02.430 --> 00:59:05.540
And it's quite a bit faster than Tiger.

00:59:05.590 --> 00:59:11.580
And another introduction here that
we're using now are the fast enumeration

00:59:11.710 --> 00:59:13.550
protocol that Objective-C is using.

00:59:13.570 --> 00:59:17.980
And this is probably the fastest way
to iterate through a Cocoa collection.

00:59:18.020 --> 00:59:20.210
It's quite nice,
and it's also much more succinct

00:59:20.420 --> 00:59:23.540
than in the first example
where we had to ask the array.

00:59:23.570 --> 00:59:28.470
to get every object and stuff like that.

00:59:28.710 --> 00:59:29.680
This is really a simple app.

00:59:29.760 --> 00:59:32.480
We create a Core Data stack here.

00:59:32.480 --> 00:59:34.040
We're creating a fetch request.

00:59:34.190 --> 00:59:38.460
We're using some of the new API to
tell Core Data that we don't really

00:59:38.460 --> 00:59:41.190
want any of the lazy initialization
that goes on with faulting,

00:59:41.190 --> 00:59:44.490
because we're going to just touch
all the objects immediately.

00:59:44.610 --> 00:59:46.960
And we execute the fetch request.

00:59:49.280 --> 00:59:53.380
And if we show you in Shark,
obviously being twice as fast,

00:59:53.380 --> 00:59:56.750
it will look quite a bit different.

01:00:06.330 --> 01:00:12.600
First thing that you'll note is main
actually is kind of down here somewhere.

01:00:12.600 --> 01:00:13.190
There we go.

01:00:13.240 --> 01:00:18.270
So when we execute a
fetch request in Leopard,

01:00:18.320 --> 01:00:23.890
and this didn't quite make the seed,
but it will be forthcoming

01:00:23.890 --> 01:00:28.220
for the ADR members who get
Leopard seeds very soon now.

01:00:28.240 --> 01:00:30.700
If you ask for enough data,
we're going to spawn

01:00:30.720 --> 01:00:32.150
some background threads,
and we're going to do

01:00:32.180 --> 01:00:34.180
some pipelining for you.

01:00:34.180 --> 01:00:39.050
And here, we do a much better job of
load balancing across this G5,

01:00:39.050 --> 01:00:42.240
whereas in the previous apps,
we basically left the

01:00:42.250 --> 01:00:44.900
whole processor idle,
doing nothing.

01:00:47.920 --> 01:00:51.090
We populate some of the row values,
we do some of the

01:00:51.280 --> 01:00:54.820
registration and the context,
some of the fault firing,

01:00:54.870 --> 01:00:58.620
and you can see everything's
broken up pretty neatly here

01:00:58.620 --> 01:01:00.790
in no one particular place.

01:01:03.900 --> 01:01:14.900
[Transcript missing]

01:01:15.300 --> 01:01:19.080
But most of the work is going on
as we basically create wrapper

01:01:19.080 --> 01:01:23.870
objects for-- I can't show you that.

01:01:25.480 --> 01:01:27.200
Wow, Shark did something fun.

01:01:27.200 --> 01:01:29.960
All right,
but most of the work is going on as

01:01:29.960 --> 01:01:34.610
we create Cocoa Wrapper objects for
you for each of the column values.

01:01:36.200 --> 01:01:39.640
and we'll be wrapping up and
taking questions shortly.

01:01:39.640 --> 01:01:42.080
If we can go back over to the slides.

01:01:43.130 --> 01:01:44.050
Yeah.

01:01:44.120 --> 01:01:47.680
So we spent a lot of effort
optimizing stuff for you in Leopard.

01:01:47.680 --> 01:01:51.020
Like I said,
you'll get a chance to play with this

01:01:51.020 --> 01:01:53.400
in an upcoming seed really soon now.

01:01:53.400 --> 01:01:56.970
But as Melissa mentioned,
the Leopard seed is already about

01:01:56.970 --> 01:01:59.020
five times faster than Tiger GM.

01:01:59.020 --> 01:02:04.600
You can get about 125,000,
150,000 rows per second

01:02:04.770 --> 01:02:06.660
on a 2 gigahertz G5.

01:02:06.700 --> 01:02:10.890
The new machines are a good
twice the speed of that.

01:02:11.320 --> 01:02:12.980
And that's what we have.

01:02:12.980 --> 01:02:17.950
We've done a lot of work in optimizing
a bunch of other things as well.

01:02:17.960 --> 01:02:23.350
And I really had a lot of fun testing my
app on the quad and the lab yesterday.

01:02:23.350 --> 01:02:26.580
So 800,000 rows per second.

01:02:26.580 --> 01:02:28.230
I'm happy about that.

01:02:28.260 --> 01:02:29.670
Anybody else?

01:02:29.720 --> 01:02:32.590
So...

01:02:36.880 --> 01:02:39.250
So some things to look forward
to is we're really committed

01:02:39.260 --> 01:02:42.800
to fixing performance bugs,
so please follow those.

01:02:42.800 --> 01:02:45.670
And in an upcoming seed,
you'll see our support for

01:02:45.670 --> 01:02:47.380
Objective-C properties.

01:02:47.380 --> 01:02:49.800
You'll get to play with
some of our pipelining,

01:02:49.800 --> 01:02:53.500
and we're building across
four architectures now.

01:02:53.500 --> 01:02:56.450
I don't know what else the
hardware guys will spring on us,

01:02:56.580 --> 01:03:01.660
but we'll be participating in pretty much
all of the Leopard platform initiatives.

01:03:03.450 --> 01:03:06.040
and for more information,
you can send an email to Derek Horn,

01:03:06.050 --> 01:03:07.740
who's the Application Frameworks
Evangelist,

01:03:07.740 --> 01:03:10.320
and the documentation and
all the good stuff is there.

01:03:10.320 --> 01:03:13.000
The Core Data Programming
Guide is fantastic.

01:03:13.050 --> 01:03:14.460
It has a section on multi-threading.

01:03:14.460 --> 01:03:17.360
It has a section on common
performance problems.

01:03:17.360 --> 01:03:19.310
I really recommend you
take a look at that.

01:03:19.390 --> 01:03:22.880
Malcolm is adding new sections
in response to your feedback.