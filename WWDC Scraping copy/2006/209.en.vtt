WEBVTT

00:00:10.400 --> 00:00:14.230
Hello,
my name's William Stewart and I work

00:00:14.400 --> 00:00:15.830
for Apple on the Core Audio team.

00:00:16.020 --> 00:00:20.020
Welcome to session 209,
Core Audio Update.

00:00:20.200 --> 00:02:40.500
[Transcript missing]

00:02:43.300 --> 00:02:45.620
Thanks, Bill.

00:02:45.700 --> 00:02:50.400
So the Media Hardware Control,
I'll start out just by introducing

00:02:50.400 --> 00:02:54.300
what it is and who it's for,
talk a bit about some of the

00:02:54.300 --> 00:02:55.850
devices that it supports.

00:02:55.960 --> 00:02:58.920
They're kind of intense and
complicated in some ways.

00:02:58.920 --> 00:03:05.270
And then I'll go through some basic
tasks in the API for receiving

00:03:05.270 --> 00:03:09.470
input from these devices and
sending feedback back to them.

00:03:10.190 --> 00:03:13.610
So here's a screenshot,
actually several windows from

00:03:13.620 --> 00:03:16.100
Emagic's Logic application.

00:03:16.100 --> 00:03:19.460
And this is fairly typical of
today's digital audio workstation.

00:03:19.710 --> 00:03:21.470
In the upper right,
we've got the transport

00:03:21.560 --> 00:03:26.110
control with lots of buttons,
your current locators,

00:03:26.110 --> 00:03:31.510
locators where you're
going to punch in and out.

00:03:31.860 --> 00:03:34.670
Over here we have the mixer window.

00:03:34.670 --> 00:03:38.120
And this is kind of a
pretty direct analog to an

00:03:38.120 --> 00:03:40.770
old-fashioned mixing console.

00:03:40.770 --> 00:03:46.320
We have channel strips, volume, panning,
mute, solo, effect inserts, and so on.

00:03:46.480 --> 00:03:52.470
And on the right we have automation
showing on top of some audio events.

00:03:52.470 --> 00:03:58.480
I think I'm automating the balance
between the two channels in this example.

00:03:58.860 --> 00:04:04.960
Now the mixer and the transport both
have real-world physical analogs.

00:04:05.060 --> 00:04:08.630
If you go back,
we've got tape machines with

00:04:08.630 --> 00:04:10.960
buttons on them and the mixer.

00:04:10.960 --> 00:04:14.960
It's only been with the advent of
computer-based systems that we've got

00:04:14.960 --> 00:04:18.030
this intense capability for automation.

00:04:20.840 --> 00:04:24.030
So, in any case,
those applications can be a

00:04:24.060 --> 00:04:27.800
bit unwieldy to deal with with
just a mouse and keyboard,

00:04:27.930 --> 00:04:30.450
so now we're starting to
see devices like this.

00:04:30.450 --> 00:04:33.200
This is the Mackie control.

00:04:33.200 --> 00:04:35.920
Actually, it's the eMagic control.

00:04:38.110 --> 00:04:41.980
And as you can see,
it has the same channel strips,

00:04:42.070 --> 00:04:45.880
there are mutant solo buttons,
you can select tracks,

00:04:45.920 --> 00:04:51.400
transport controls in the lower right,
a jog wheel, and so on.

00:04:51.400 --> 00:04:57.090
So, we've got this movement back towards
these richer control interfaces

00:04:57.220 --> 00:05:01.310
for these complex applications.

00:05:02.810 --> 00:05:08.550
Now since these control surfaces right
now all have these custom protocols,

00:05:08.550 --> 00:05:10.770
and we're seeing an increasing
number of applications,

00:05:10.830 --> 00:05:14.340
not just digital audio
workstations like Performer is my

00:05:14.340 --> 00:05:18.640
example in the upper left there,
but also Final Cut Pro is getting some

00:05:18.640 --> 00:05:21.760
increasingly advanced audio capabilities.

00:05:22.880 --> 00:05:27.840
So the purpose of MHC is to sit in the
middle and abstract the differences

00:05:27.910 --> 00:05:33.680
between these various devices and make it
so all these different applications can

00:05:33.680 --> 00:05:37.380
communicate through a single interface.

00:05:40.920 --> 00:05:45.400
So looking in more detail
about how these devices work,

00:05:45.460 --> 00:05:47.010
so this is the Mac-E control again.

00:05:47.720 --> 00:05:50.420
A lot of them use MIDI as a transport.

00:05:50.420 --> 00:05:54.480
Some others use like Ethernet and so on.

00:05:54.480 --> 00:05:58.690
And in those situations,
the hardware manufacturer can

00:05:58.690 --> 00:06:03.120
create a custom driver to deal
with that transport layer.

00:06:04.460 --> 00:06:08.340
For devices that are MIDI-based,
with MHC,

00:06:08.340 --> 00:06:13.580
we should be able to create just
profiles that are data-driven for the

00:06:13.580 --> 00:06:15.880
most part to support these devices.

00:06:15.880 --> 00:06:21.360
And in either case, whether it's a driver
or a custom protocol,

00:06:21.360 --> 00:06:26.650
or a custom profile rather,
the purpose of that profile or the

00:06:27.160 --> 00:06:32.640
driver will be to translate what's
going on at the transport layer

00:06:32.640 --> 00:06:34.440
into just a series of profiles.

00:06:34.480 --> 00:06:38.560
For devices that are MIDI-based,
with MHC,

00:06:38.560 --> 00:06:39.350
we should be able to create just
profiles that are data-driven for the

00:06:39.350 --> 00:06:39.350
most part to support these devices.

00:06:41.600 --> 00:06:44.500
And just a little bit about MIDI here.

00:06:44.500 --> 00:06:47.780
This goes both into the
implementation of MHC,

00:06:47.780 --> 00:06:49.120
but also how things are layered.

00:06:49.120 --> 00:06:54.220
Some applications will still want
to deal with Core MIDI directly

00:06:54.220 --> 00:06:58.280
if you're recording musical
performances from a keyboard.

00:06:58.280 --> 00:07:02.550
But if you wanted to just deal with
control surfaces and you're not a music

00:07:02.640 --> 00:07:06.160
application that's working with MIDI,
you can deal directly with

00:07:06.320 --> 00:07:10.440
the MHC portion of the
Core MIDI framework and just speak

00:07:10.530 --> 00:07:11.570
in terms of functional methods.

00:07:12.400 --> 00:07:14.460
And just a little bit about MIDI here.

00:07:14.460 --> 00:07:17.120
This goes both into the
implementation of MHC,

00:07:17.120 --> 00:07:19.240
but also how things are layered.

00:07:19.240 --> 00:07:23.230
Some applications will still want
to deal with Core MIDI directly

00:07:23.240 --> 00:07:26.920
if you're recording musical
performances from a keyboard.

00:07:26.920 --> 00:07:31.420
But if you wanted to just deal with
control surfaces and you're not a music

00:07:31.490 --> 00:07:35.510
application that's working with MIDI,
you can deal directly with

00:07:35.510 --> 00:07:38.990
the MHC portion of the
Core MIDI framework and just speak

00:07:39.000 --> 00:07:41.580
in terms of functional methods.

00:07:43.620 --> 00:07:51.340
So from just the MHC API point of view,
when you're dealing with devices,

00:07:51.500 --> 00:08:09.900
[Transcript missing]

00:08:10.670 --> 00:08:14.270
Through the API,
the devices that appear to

00:08:14.270 --> 00:08:16.960
your application through the
API will come from two places,

00:08:16.960 --> 00:08:21.330
either those data-driven profiles
or from the driver plug-ins,

00:08:21.360 --> 00:08:25.190
which can automatically detect
the presence of hardware.

00:08:28.010 --> 00:08:31.660
Through the API,
the devices that appear to

00:08:31.670 --> 00:08:34.360
your application through the
API will come from two places,

00:08:34.380 --> 00:08:38.760
either those data-driven profiles
or from the driver plug-ins,

00:08:38.760 --> 00:08:42.540
which can automatically detect
the presence of hardware.

00:08:55.240 --> 00:08:59.250
So this little bit of code here
is the one function call that

00:08:59.300 --> 00:09:03.140
connects your application to MHC.

00:09:03.140 --> 00:09:05.640
MHC client create.

00:09:05.640 --> 00:09:10.600
You pass a unique identifier
for your application or client.

00:09:10.600 --> 00:09:15.950
And that's used because there's
this concept of device-specific,

00:09:15.950 --> 00:09:20.360
or rather application-specific
preferences.

00:09:20.360 --> 00:09:23.150
My message callback is the
function that will get called when

00:09:23.150 --> 00:09:25.540
messages arrive from the device.

00:09:25.540 --> 00:09:30.210
And you supply a run loop on which
you'll receive those messages.

00:09:30.550 --> 00:09:33.020
And at the end,
you get back this client object,

00:09:33.020 --> 00:09:35.310
which you can pass to
other API functions.

00:09:38.500 --> 00:09:59.500
[Transcript missing]

00:09:59.790 --> 00:10:03.640
So you could use a loop,
something like this, to populate, say,

00:10:03.640 --> 00:10:06.870
a scrolling list of the
devices that the user needs to

00:10:06.940 --> 00:10:09.100
choose just one to work with.

00:10:10.610 --> 00:10:15.240
So once having chosen a device
to work with in the application,

00:10:15.240 --> 00:10:18.800
you can call MHC Client Connect Device.

00:10:18.800 --> 00:10:21.930
And what that does is simply says, OK,
so everything that this

00:10:21.940 --> 00:10:27.160
device sends to the computer,
I want my client via that callback

00:10:27.160 --> 00:10:30.460
function to receive those messages.

00:10:33.300 --> 00:11:59.700
[Transcript missing]

00:12:00.190 --> 00:12:03.460
You get at the bottom of the
structure the value of the

00:12:03.460 --> 00:12:05.940
control that was changed.

00:12:05.940 --> 00:12:10.390
And you also get this MHC function
object which we'll look at in a

00:12:10.390 --> 00:12:15.900
second and that specifies the actual
application function to be performed.

00:12:18.310 --> 00:12:25.080
So the kinds of functions that
MHC defines for being controllable from

00:12:25.080 --> 00:12:31.840
these control surfaces include transport,
stop, start, rewind, move to a marker,

00:12:31.840 --> 00:12:33.140
and so on.

00:12:33.140 --> 00:12:38.800
Mixer and effects control volume, pan,
mute, solo, balance,

00:12:39.510 --> 00:12:46.250
So the kinds of functions that
MHC defines for being controllable from

00:12:46.330 --> 00:12:53.030
these control surfaces include transport,
stop, start, rewind, move to a marker,

00:12:53.140 --> 00:12:54.340
and so on.

00:12:54.340 --> 00:13:00.000
Mixer and effects control volume, pan,
mute, solo, balance,

00:13:10.980 --> 00:13:17.350
And there's also,
also kind of analogously to Apple Script,

00:13:17.580 --> 00:13:21.490
you can define custom application
behavior that's controllable through

00:13:21.490 --> 00:13:24.100
MHC by having a private function suite.

00:13:24.100 --> 00:13:26.860
So inside the structure,
the first member is a suite,

00:13:26.860 --> 00:13:28.650
which is a four-character code.

00:13:28.680 --> 00:13:31.440
And again,
you can have a private suite there,

00:13:31.480 --> 00:13:36.400
but we'll have defined some common ones
for those classes of functionality.

00:13:37.780 --> 00:13:40.890
So there's the suite,
there's a function within that suite.

00:13:40.960 --> 00:13:44.970
That function may need to
be qualified in some way.

00:13:44.980 --> 00:13:48.250
For instance,
if the function is track volume,

00:13:48.250 --> 00:13:51.780
then the group might say, okay,
we're dealing with the tracks here.

00:13:51.780 --> 00:13:54.820
Or it could also say I'm
dealing with buses or outputs.

00:13:54.880 --> 00:13:58.720
And then the specifier says, okay,
whether it's tracks or outputs,

00:13:58.720 --> 00:14:01.550
which track or output are
we talking about here?

00:14:01.560 --> 00:14:05.320
So that's how an
MHC function is specified.

00:14:08.780 --> 00:14:13.280
Now, going back to the code example,
you've registered a client,

00:14:13.330 --> 00:14:16.700
you've connected to a device,
and now you're going to start

00:14:16.700 --> 00:14:19.830
receiving messages from the device.

00:14:20.200 --> 00:14:24.100
Receiving input is pretty
much straightforward.

00:14:24.100 --> 00:14:29.070
The only thing about it is that
it can be tedious because there

00:14:29.070 --> 00:14:31.660
are a lot of different messages
you might want to respond to.

00:14:31.660 --> 00:14:34.380
So you end up writing a
lot of switch statements.

00:14:34.390 --> 00:14:35.880
So you get this message callback.

00:14:35.880 --> 00:14:40.680
There are several other kinds of messages
other than the control having changed,

00:14:40.680 --> 00:14:42.960
but the control having changed
is the most common one,

00:14:42.960 --> 00:14:46.460
so we'll just follow that
through for the moment.

00:14:47.670 --> 00:14:51.020
So we'll dispatch to another
function to do that because we

00:14:51.020 --> 00:14:52.920
have more switch statements.

00:14:52.920 --> 00:14:55.600
So here, after control has changed,
we'll say, OK,

00:14:55.600 --> 00:14:57.480
so what suite is this function in?

00:14:57.480 --> 00:15:00.100
OK, it's the transport suite.

00:15:00.100 --> 00:15:04.160
Given that it's the transport suite,
which function is it?

00:15:04.160 --> 00:15:07.050
To keep this from getting
completely full of code,

00:15:07.110 --> 00:15:09.060
I'm just showing stop and play.

00:15:09.060 --> 00:15:14.040
So you'll call your doStop
and doPlay functions.

00:15:14.040 --> 00:15:17.630
And that's pretty much how your
input code will end up looking,

00:15:17.750 --> 00:15:21.040
just lots of switch statements like
that to dispatch the individual messages

00:15:21.040 --> 00:15:24.390
to your application's functions.

00:15:25.160 --> 00:15:28.780
Just to continue here
are some more examples.

00:15:28.780 --> 00:15:34.190
The channel strip,
and here's the track number as the

00:15:34.190 --> 00:15:39.090
specifier as an example of how those
other fields in the message work.

00:15:39.170 --> 00:15:44.250
And here we're handling the
mute and volume messages,

00:15:44.260 --> 00:15:47.900
and we're passing along
the value of the muter,

00:15:47.900 --> 00:15:50.690
the volume control as it was received.

00:15:52.240 --> 00:15:57.720
Before we go further into the code
example and look at how we send

00:15:57.720 --> 00:16:04.530
data back to the control surface,
it's useful now to look at what's

00:16:04.560 --> 00:16:07.780
actually inside one of these
MHC devices and how it's represented.

00:16:07.780 --> 00:16:10.580
Because to send feedback,
we're going to have to go through

00:16:10.580 --> 00:16:12.410
and query the device a little more.

00:16:13.770 --> 00:16:19.210
Before we go further into the code
example and look at how we send

00:16:19.210 --> 00:16:26.050
data back to the control surface,
it's useful now to look at what's

00:16:26.060 --> 00:16:29.280
actually inside one of these
MHC devices and how it's represented.

00:16:29.280 --> 00:16:32.080
Because to send feedback,
we're going to have to go through

00:16:32.080 --> 00:16:33.920
and query the device a little more.

00:16:37.010 --> 00:16:42.900
There's this concept of a configuration
which comes into play when you have

00:16:43.080 --> 00:16:48.280
devices that are kind of generic
MIDI controllers with presets.

00:16:48.280 --> 00:16:56.370
I won't go further into that because
here I'm focusing on the devices with

00:16:56.700 --> 00:16:59.080
large suites of dedicated functionality.

00:17:00.190 --> 00:17:03.270
Generally,
these more complex devices will

00:17:03.300 --> 00:17:05.610
just have one configuration.

00:17:05.620 --> 00:17:10.080
So within the configuration,
there are groups which basically

00:17:10.080 --> 00:17:14.280
just organize the actual controls,
which we call elements,

00:17:14.420 --> 00:17:18.490
borrowing terminology
from the USB HID spec.

00:17:21.700 --> 00:17:25.500
So given elements,
there are three types that

00:17:25.520 --> 00:17:27.150
you need to be concerned with.

00:17:27.340 --> 00:17:29.140
Some are input-only.

00:17:29.140 --> 00:17:32.530
As you see there, a push button,
also the jog wheel at the bottom

00:17:32.530 --> 00:17:35.440
right of the Mac key control.

00:17:35.440 --> 00:17:37.160
Those are the simple ones to deal with.

00:17:37.160 --> 00:17:40.560
They move, you get a message,
you respond to them.

00:17:40.560 --> 00:17:46.410
Some devices, or some controls rather,
are input devices with feedback,

00:17:46.410 --> 00:17:49.980
meaning that in some way they are
showing to you what you're doing,

00:17:50.060 --> 00:17:55.310
whether it's a push button with a light
on it to indicate you're in play mode,

00:17:55.320 --> 00:17:56.860
for instance.

00:17:56.860 --> 00:18:03.150
Here in the slide we've got a rotary
encoder which shows some LEDs to indicate

00:18:03.150 --> 00:18:07.340
the current position of the dial.

00:18:07.340 --> 00:18:14.500
That same Mac key control also has
motorized faders on the volume controls.

00:18:14.500 --> 00:18:17.490
So those controls are
the same as the dial.

00:18:17.500 --> 00:18:17.500
They're not the same as the dial.

00:18:17.500 --> 00:18:19.540
They're controls with feedback in them.

00:18:19.540 --> 00:18:22.720
The application has responsibility
for sending feedback,

00:18:22.720 --> 00:18:26.420
sometimes even while that knob
is actually being controlled.

00:18:26.420 --> 00:18:31.180
So you'll get some information about the
element to determine how to handle that.

00:18:31.200 --> 00:18:35.320
And lastly, there are elements that are
output or feedback only,

00:18:35.320 --> 00:18:38.860
meaning that you'll never
receive a message from them,

00:18:38.890 --> 00:18:41.540
but you might want to
send something to them.

00:18:41.540 --> 00:18:45.470
In the example here,
we've got an LED display from the

00:18:45.470 --> 00:18:50.430
Mac key control that's showing
the current position in the song.

00:18:53.740 --> 00:18:59.740
So in terms of what you do in the
application to actually send feedback,

00:18:59.740 --> 00:19:03.180
this is a brief overview
of the steps to do this.

00:19:03.440 --> 00:19:08.070
You'll walk through the device's
elements in some way to go and find

00:19:08.680 --> 00:19:15.130
the elements with feedback for the
functions that the application supports.

00:19:15.580 --> 00:19:21.130
So in terms of what you do in the
application to actually send feedback,

00:19:21.350 --> 00:19:25.060
this is a brief overview
of the steps to do this.

00:19:25.060 --> 00:19:30.350
You'll walk through the device's
elements in some way to go and find

00:19:30.350 --> 00:19:36.940
the elements with feedback for the
functions that the application supports.

00:19:45.560 --> 00:19:47.140
place state.

00:19:47.140 --> 00:19:51.640
To do that, we'll have had to have
located those elements which

00:19:51.640 --> 00:19:53.370
provide that kind of feedback.

00:19:56.130 --> 00:20:02.350
So looking at the code behind that,
when we first start the application,

00:20:02.520 --> 00:20:06.400
we can make a call to MHC object,
apply function to children,

00:20:06.400 --> 00:20:12.500
which essentially just traverses the
entire device hierarchy of elements.

00:20:12.500 --> 00:20:15.480
And here we've defined
a callback function,

00:20:15.480 --> 00:20:19.320
scan one element,
and that will get called for every

00:20:19.320 --> 00:20:21.960
group and element inside the device.

00:20:21.990 --> 00:20:27.770
So inside the function scan one element,
info not equals null is

00:20:28.460 --> 00:20:32.690
MHC element info is a structure
that contains a bunch of

00:20:32.690 --> 00:20:34.220
details about the element.

00:20:34.330 --> 00:20:36.540
And if it's null,
then it's probably a group that

00:20:36.660 --> 00:20:38.500
we're looking at and we don't care.

00:20:38.500 --> 00:20:40.930
But if info is non-null
and we look inside the info

00:20:41.020 --> 00:20:44.380
structure and it has feedback,
then we can say, "Okay,

00:20:44.410 --> 00:20:46.420
let's look at this element.

00:20:46.420 --> 00:20:51.900
Does this element correspond to a
function that we care about?" And here,

00:20:51.900 --> 00:20:54.300
again,
in the interests of brevity and space,

00:20:54.310 --> 00:20:56.010
I'm just showing one example.

00:20:56.040 --> 00:20:59.890
So here we're looking to see, "Okay,
so is this the element in the

00:20:59.930 --> 00:21:04.360
transport suite reflecting
the play state?" And if so,

00:21:04.380 --> 00:21:09.070
then I'm going to cache a reference
to that element in gplay element.

00:21:10.620 --> 00:21:13.190
And then later I'll be able to use that.

00:21:13.330 --> 00:21:16.430
So in a more realistic example,
you would be doing switch statements

00:21:16.460 --> 00:21:23.560
here again to keep track of
the elements that correspond

00:21:23.560 --> 00:21:26.150
to your application's functions.

00:21:28.530 --> 00:21:35.770
So inside your audio engine then,
so earlier we saw there's

00:21:35.830 --> 00:21:38.080
functions to do start and do stop.

00:21:38.240 --> 00:21:41.200
So the first thing you would do
in do start is whatever you have

00:21:41.200 --> 00:21:45.440
to do to start actually playing,
load audio off disk or whatever,

00:21:45.530 --> 00:21:47.070
start the hardware.

00:21:47.210 --> 00:21:50.430
And then the last thing
you would do is call this,

00:21:50.430 --> 00:21:54.090
I factored out doStart and doStop
so that they do all this engine work

00:21:54.110 --> 00:22:00.370
and then they make a single call to
update MHC PlayState to reflect that

00:22:00.370 --> 00:22:04.310
current PlayState to the MHC device.

00:22:04.980 --> 00:22:09.290
So I've got a safety check
in that function to see if

00:22:09.360 --> 00:22:11.020
gplay element actually exists.

00:22:11.020 --> 00:22:16.790
And if we found one when we started up,
then I'll set the value

00:22:17.310 --> 00:22:20.450
local variable to a Boolean,
true or false,

00:22:20.450 --> 00:22:22.130
whether we're playing or not.

00:22:22.140 --> 00:22:24.970
And then I can send that
value to the element that

00:22:24.970 --> 00:22:26.720
corresponds to the play state.

00:22:26.720 --> 00:22:28.660
So if that element that we found earlier,
for instance,

00:22:28.670 --> 00:22:31.550
was a little green LED sitting
above the play button,

00:22:31.550 --> 00:22:35.230
then at this point we would
be making that element,

00:22:35.230 --> 00:22:37.970
that LED, turn green.

00:22:37.980 --> 00:22:39.790
And that's feedback in a nutshell.

00:22:42.920 --> 00:22:48.880
I just want to touch briefly on
some of the more advanced features.

00:22:48.880 --> 00:22:54.420
There's touch and release which comes
into play when dealing with automation.

00:22:54.420 --> 00:22:57.500
For those of you who've used
Logic or Digital Performer

00:22:57.500 --> 00:23:00.950
or Pro Tools or whatever,
these applications when

00:23:00.950 --> 00:23:07.840
playing back recorded volume,
pan and effects automation parameters,

00:23:07.840 --> 00:23:09.280
it's great.

00:23:09.280 --> 00:23:12.070
You can move the sliders on the
screen or if you've got a control

00:23:12.090 --> 00:23:15.490
surface you can control your mix
from the hardware as it's going along

00:23:15.490 --> 00:23:19.640
and the program will just record all
this and you'll get a little graph

00:23:19.670 --> 00:23:23.480
of what you've done when you're done.

00:23:23.480 --> 00:23:25.840
Then what will happen
often when you're mixing,

00:23:25.840 --> 00:23:29.160
you'll say, "Okay,
I didn't quite get this part right.

00:23:29.160 --> 00:23:34.960
I want to change the volume curve just
over this one little phrase here and

00:23:34.960 --> 00:23:39.030
then let it keep going the way it was."
And the friendly way to do that is to put

00:23:39.030 --> 00:23:44.210
a track into overwrite automation mode.

00:23:44.540 --> 00:23:48.650
Now, these control surfaces devices
are pretty cool in that they

00:23:48.650 --> 00:23:50.930
don't only send messages,
well, not all of them,

00:23:50.940 --> 00:23:54.440
but the fancy ones,
not only will they send messages

00:23:54.440 --> 00:23:56.880
when you move the slider,
but they will send a message

00:23:56.880 --> 00:23:58.160
when you touch the slider.

00:23:58.660 --> 00:24:03.250
So from the point of view of editing
existing automation data or saying,

00:24:03.250 --> 00:24:07.660
okay, I just want to change part of it,
you can touch it when you want the

00:24:07.660 --> 00:24:11.570
existing automation to stop playing,
at which point then you're

00:24:11.570 --> 00:24:15.730
recording anything new that you do,
or you could just hold it to erase it.

00:24:15.780 --> 00:24:18.960
And then when you release it,
you're done recording, and the previous

00:24:18.960 --> 00:24:20.400
automation keeps playing.

00:24:20.400 --> 00:24:24.280
So in any case,
MHC supports this by having this

00:24:24.280 --> 00:24:27.620
concept of touch and release events.

00:24:27.620 --> 00:24:28.620
You'll get a message.

00:24:28.620 --> 00:24:32.330
Okay, the volume slider on track
one has been touched,

00:24:32.330 --> 00:24:35.410
and you can respond
to that appropriately.

00:24:37.430 --> 00:24:42.270
A lot of these devices
have multiple modes,

00:24:42.270 --> 00:24:46.900
and this is the second advanced feature,
meaning that controls,

00:24:46.900 --> 00:24:52.930
whether they're like arrow buttons or
the rotary encoders across the top,

00:24:53.000 --> 00:24:58.860
do very different things depending
upon the context of the application

00:24:58.860 --> 00:25:03.490
or a mode that's been selected
on the control surface itself.

00:25:05.320 --> 00:25:09.300
To the extent possible,
we're going to try to hide that

00:25:09.300 --> 00:25:17.230
inside the driver and profile,
but that's something that's...

00:25:17.440 --> 00:25:20.500
Not fully baked like the rest of the API.

00:25:20.520 --> 00:25:23.120
But that's just something to be aware of.

00:25:24.600 --> 00:25:30.170
The other interesting thing
to think about with MHC,

00:25:30.250 --> 00:25:34.810
not only can we send
simple volume commands,

00:25:34.810 --> 00:25:38.500
for instance, to a motorized fader, say,
okay, slide up to the top or

00:25:38.510 --> 00:25:41.680
to 0 dB or whatever,
but we also have these

00:25:41.680 --> 00:25:44.160
SMPTE or Barbie unit displays.

00:25:44.640 --> 00:25:47.870
And to do that, we've defined structures
where you can say,

00:25:47.930 --> 00:25:51.210
okay, I'm going to send this
SMPTE time to this element.

00:25:51.210 --> 00:25:54.550
And that's in there.

00:25:54.550 --> 00:25:59.020
As controls are moved,
sometimes these devices will have

00:25:59.020 --> 00:26:03.360
facilities for displaying the name
of the parameter that's currently

00:26:03.360 --> 00:26:05.990
being affected and its current value.

00:26:06.000 --> 00:26:08.030
And that's text labels.

00:26:08.080 --> 00:26:12.350
On many of these devices,
we also have the ability

00:26:12.360 --> 00:26:14.280
to graphically display.

00:26:14.280 --> 00:26:17.180
In some way,
what's happening with the parameter,

00:26:17.180 --> 00:26:21.710
whether it's the LED ring
around the rotary encoder or

00:26:21.730 --> 00:26:25.680
even a bit mapped graphic,
for instance,

00:26:25.680 --> 00:26:32.450
with a stereo spread parameter
on an effect that might be

00:26:33.040 --> 00:26:38.660
illustrated as a graphic like that,
but you might only have to send one value

00:26:38.660 --> 00:26:41.540
while specifying that feedback mode.

00:26:41.630 --> 00:26:43.920
In any case,
these are all some of the more advanced.

00:26:43.920 --> 00:26:47.180
advanced details that are in the API.

00:26:51.610 --> 00:26:56.080
So just to review,
the basic idea here is that MHC takes

00:26:56.150 --> 00:27:00.940
care of a lot of this complexity under
the hood of these control surfaces.

00:27:00.940 --> 00:27:04.570
Whereas in the past, to support them,
you'd get deeply into

00:27:04.570 --> 00:27:06.240
parsing MIDI messages.

00:27:06.240 --> 00:27:12.420
Your whole internal representation
of how to support a control surface

00:27:12.420 --> 00:27:17.660
is this large map of MIDI messages
going to and from the device.

00:27:18.560 --> 00:27:21.750
And since there are so many
devices that do it so differently,

00:27:21.760 --> 00:27:25.900
we'd like to pop up a level and let
you just deal with these devices

00:27:25.900 --> 00:27:27.040
in a more functional manner.

00:27:27.040 --> 00:27:30.190
So we have a preliminary
implementation in the seed,

00:27:30.190 --> 00:27:35.060
and that's in the Core MIDI Framework,
the Header File Media Hardware Control.

00:27:35.060 --> 00:27:38.180
And there's a fair amount
of commenting there.

00:27:38.180 --> 00:27:42.290
And for those of you who are
working on applications and hardware

00:27:42.490 --> 00:27:45.810
that can take advantage of this,
we'd really like to hear from you.

00:27:45.820 --> 00:27:48.540
And we hope you'll keep
in touch and let us know.

00:27:48.560 --> 00:27:50.880
what you need from us about this.

00:27:50.880 --> 00:27:52.780
Thank you.

00:27:54.470 --> 00:27:57.390
So that's Media Hardware Control.

00:27:57.390 --> 00:28:02.390
I'd just like to add a few words
about the Core Audio file format.

00:28:03.400 --> 00:28:42.100
[Transcript missing]

00:28:42.320 --> 00:28:46.660
But it is chunky like AIFF and WAV,
so everything you know about

00:28:46.670 --> 00:28:50.730
how to parse those files is
applicable in a general sense.

00:28:51.500 --> 00:28:55.100
There's two basic approaches
you can use for supporting CAF.

00:28:55.200 --> 00:29:00.410
You can either use our audio file API,
which makes CAF appear as just

00:29:00.500 --> 00:29:06.490
another format like AIFF or WAV,
MP4, and so on.

00:29:06.500 --> 00:29:09.590
Or you may have
cross-platform requirements,

00:29:09.690 --> 00:29:13.820
in which case you might look at
an open-source audio library.

00:29:13.820 --> 00:29:17.440
But for that matter,
you could write your own code.

00:29:17.440 --> 00:29:21.020
The specification is
very detailed and clear.

00:29:22.370 --> 00:29:25.390
And we're already seeing a number
of applications already using CAF.

00:29:25.540 --> 00:29:28.540
iTunes can play CAF files.

00:29:28.540 --> 00:29:34.400
Digital Performer, I believe,
can both read and write as can Amadeus.

00:29:34.400 --> 00:29:37.120
But I'm just bringing this
up because it's out there,

00:29:37.120 --> 00:29:39.940
we think it's a good format,
and wish more of you would

00:29:40.180 --> 00:29:45.140
please incorporate support
for it in your applications.

00:29:45.330 --> 00:29:46.130
Just one more.

00:29:46.130 --> 00:29:48.800
This is, yeah,
two more things about this.

00:29:48.800 --> 00:29:52.960
One thing we really like about
CAF is that it's really a fairly

00:29:52.960 --> 00:29:57.570
complete generic container format,
meaning that pretty much any

00:29:57.570 --> 00:30:01.740
kind of audio data you can think
of and describe with one of our

00:30:01.770 --> 00:30:06.520
audio stream basic description
structures you can put in a CAF file,

00:30:06.530 --> 00:30:08.190
whether it's PCM.

00:30:09.580 --> 00:30:12.250
And within PCM,
whether it's big or little endian,

00:30:12.380 --> 00:30:15.860
float or integer, 8, 24, 16, 32 bits.

00:30:15.860 --> 00:30:18.180
It can hold compressed formats.

00:30:19.830 --> 00:30:25.330
It has a structure similar to
an audio channel layout for

00:30:25.500 --> 00:30:27.400
describing channel layouts.

00:30:27.400 --> 00:30:30.300
It holds a magic cookie
for decoding formats.

00:30:30.520 --> 00:30:36.100
This reflects the way that our
audio file and audio format or

00:30:36.100 --> 00:30:45.100
converter APIs think of files and
what's in them as separate things.

00:30:45.300 --> 00:30:46.460
Which is useful.

00:30:46.460 --> 00:30:51.240
You can have files even if you
don't have the decoder to actually

00:30:51.340 --> 00:30:52.450
listen to the audio in it.

00:30:52.460 --> 00:30:55.340
The file is still intact.

00:30:57.100 --> 00:32:10.500
[Transcript missing]

00:32:11.840 --> 00:32:17.920
And as I said before,
the entire verbose clear CAP spec

00:32:17.920 --> 00:32:22.260
is online at the developer,
Apple, the Apple developer audio site.

00:32:22.260 --> 00:32:23.710
And you can see it there.

00:32:23.710 --> 00:32:25.780
And that's the CAP file.

00:32:25.780 --> 00:32:26.540
Thank you very much.

00:32:34.450 --> 00:32:35.390
Thank you, Doug.

00:32:35.390 --> 00:32:41.880
So the rest of the talk we're
going to go through the AudioQ API.

00:32:41.880 --> 00:32:46.320
This is a new API in Leopard.

00:32:46.320 --> 00:32:50.060
It's a high-level API service
to play buffers of audio,

00:32:50.390 --> 00:32:56.260
record buffers of audio in linear PCM,
playback you can play any content,

00:32:56.260 --> 00:33:01.900
the header files in the
audio toolbox framework.

00:33:01.900 --> 00:33:05.500
And by high-level service,
we really have become very aware of

00:33:05.500 --> 00:33:09.230
some of the complexities developers
have to deal with to do what

00:33:09.390 --> 00:33:11.710
should be fairly simple tasks.

00:33:11.790 --> 00:33:17.200
And so the idea of this API is to
provide a much simpler interface where

00:33:17.200 --> 00:33:22.820
a lot of the work that Core Audio will
do to get the data out of the system

00:33:22.820 --> 00:33:27.870
or get the data into your application
is taken care of underneath the system.

00:33:27.980 --> 00:33:30.100
So we're going to go through the
core audio framework and we're

00:33:30.240 --> 00:33:31.390
going to go through the core audio
framework and we're going to go

00:33:31.420 --> 00:33:31.900
through the core audio framework.

00:33:31.900 --> 00:33:34.520
You'll notice similarities to,
in some respects anyway,

00:33:34.560 --> 00:33:37.900
to the Sound Manager API with
the AudioQ API.

00:33:38.190 --> 00:33:40.890
However,
the Sound Manager is deprecated in

00:33:40.890 --> 00:33:43.660
Leopard and this is a formal deprecation.

00:33:43.660 --> 00:33:49.850
I think informally we've been
deprecating it for some years now.

00:33:49.890 --> 00:33:52.850
But Sound Manager will also
not be available in 64-bit.

00:33:52.850 --> 00:33:57.820
All of the Core Audio frameworks are
available to 64-bit applications.

00:33:57.820 --> 00:34:02.000
So if you're going forward
with your application,

00:34:02.000 --> 00:34:06.890
now is a very good time, I think,
to move off Sound Manager if you've still

00:34:06.890 --> 00:34:11.090
got code there and this API should be
very appropriate for that kind of use.

00:34:13.370 --> 00:34:16.630
So when we go through this,
there's several roles we want

00:34:16.630 --> 00:34:18.160
to describe in the queue.

00:34:18.160 --> 00:34:21.380
There's the creation of the queue itself.

00:34:21.380 --> 00:34:26.260
It's how the queue manages its buffers,
how it manages state like start and stop,

00:34:26.390 --> 00:34:30.900
priming, pausing, resuming,
what reset is and how it works.

00:34:31.220 --> 00:34:36.440
You can send parameters to the queue
so that you can change playback

00:34:36.800 --> 00:34:38.620
characteristics of the queue.

00:34:38.620 --> 00:34:43.500
And the queue also provides
some timing services.

00:34:43.500 --> 00:34:47.730
And we'll just have a brief
overview of what that is.

00:34:48.150 --> 00:34:50.280
One of the things,
as we've already mentioned,

00:34:50.280 --> 00:34:53.160
is the queue handles
both input and output.

00:34:53.160 --> 00:34:57.760
And the way that we've decided to
do this is to share as much of the

00:34:58.140 --> 00:35:01.090
code and the API between both roles.

00:35:01.140 --> 00:35:06.810
And so when you have an
API that's specific for output,

00:35:06.980 --> 00:35:10.090
as you'll see in a moment,
to create an audio queue

00:35:10.090 --> 00:35:13.980
object to do output,
that API will be audio queue, new output,

00:35:13.980 --> 00:35:15.680
whatever it's called.

00:35:16.780 --> 00:35:19.990
And same for input,
but a lot of the cases you'll actually

00:35:19.990 --> 00:35:24.320
see that it's an audio queue API and you
can use it for either input or output.

00:35:25.960 --> 00:35:32.340
The QObjects themselves are not
doing input and output together.

00:35:32.340 --> 00:35:35.750
They're either an input
or an output object.

00:35:36.350 --> 00:35:40.220
So when describing what the
queue does and how it works,

00:35:40.220 --> 00:35:43.500
I thought the best way to approach
this would be to look through

00:35:43.500 --> 00:35:48.580
an example of what it would take
to play a file with the queue.

00:35:48.580 --> 00:35:53.300
The code itself uses two primary,
two APIs in the audio toolbox,

00:35:53.390 --> 00:35:59.060
the audio file API that Doug just sort
of mentioned in the context of CAF files,

00:35:59.060 --> 00:36:03.550
and the audio queue API,
and the audio queue API is obviously

00:36:03.550 --> 00:36:05.800
the thing that interests us.

00:36:05.800 --> 00:36:07.740
Because we're dealing
with the audio file API,

00:36:07.740 --> 00:36:12.080
the code is also going to be very general
and it's going to deal with any kind of

00:36:12.080 --> 00:36:15.740
format that Core Audio can understand,
whether it's compressed,

00:36:15.740 --> 00:36:18.760
variable bitrate audio, or linear PCM.

00:36:18.760 --> 00:36:22.320
So the code itself that we'll
be looking through will deal

00:36:22.390 --> 00:36:24.220
with those circumstances.

00:36:27.340 --> 00:36:35.510
So when we play a file,
the basic jobs we have to do,

00:36:36.760 --> 00:36:42.100
is to open the file and we need
to read some data about the file.

00:36:42.100 --> 00:36:47.760
And then we use that information to
create the audio cue and to configure it.

00:36:47.760 --> 00:36:50.650
Then we'll need to allocate
buffers to read the data into.

00:36:50.650 --> 00:36:55.100
And then those are the buffers
that we'll cue up to the cue.

00:36:55.100 --> 00:36:57.780
Then we'll start the cue object to play.

00:36:57.780 --> 00:37:00.760
And then that'll decode existing buffers.

00:37:00.760 --> 00:37:05.470
And then the cue's runtime state
is managed in its communications

00:37:05.490 --> 00:37:07.970
to the client with a callback.

00:37:07.980 --> 00:37:12.700
And so the cue will call a callback
and you'll see what we'll do

00:37:12.700 --> 00:37:16.800
to deal with that callback and
keep the program doing its work.

00:37:16.800 --> 00:37:19.680
And then at the end of the
file we dispose and clean up.

00:37:19.680 --> 00:37:23.580
So they're the main steps that we're
going to have a look through now.

00:37:23.580 --> 00:37:25.720
There's no real demo here.

00:37:25.720 --> 00:37:27.400
The demo is beep.

00:37:27.400 --> 00:37:28.960
Play the file.

00:37:28.960 --> 00:37:29.690
So AQ test and the next
step is to create the demo.

00:37:29.690 --> 00:37:30.120
And then we'll have to
do a demo of the demo.

00:37:30.180 --> 00:37:30.560
And then we'll have to
do a demo of the demo.

00:37:30.560 --> 00:37:30.560
And then we'll have to
do a demo of the demo.

00:37:30.560 --> 00:37:30.560
And then we'll have to
do a demo of the demo.

00:37:30.560 --> 00:37:30.560
And then we'll have to
do a demo of the demo.

00:37:30.560 --> 00:37:30.560
And then we'll have to
do a demo of the demo.

00:37:30.560 --> 00:37:33.240
the name of the file
that you want to play.

00:37:33.240 --> 00:37:39.070
The first thing we have to do to play
the file is to find out is to open the

00:37:39.170 --> 00:37:45.450
file and so the next line is to make
an FSRef from the file path and then

00:37:45.590 --> 00:37:48.310
audio file open will open that file.

00:37:48.310 --> 00:37:52.840
If that succeeds of course then
we have got a valid audio file.

00:37:52.840 --> 00:37:57.510
You will notice the last argument
there to the audio file open

00:37:57.620 --> 00:38:01.000
call is myinfo.m audio file.

00:38:01.000 --> 00:38:06.230
The myinfo is a structure that we are
going to define in our program which

00:38:06.230 --> 00:38:12.000
I have just given it a type of AQ test
info and that contains basically the

00:38:12.010 --> 00:38:17.940
information that we need to configure or
keep around in order to run this program.

00:38:17.940 --> 00:38:22.640
So it is the file ID,
the description of the

00:38:22.990 --> 00:38:25.060
format that is in the file,
the data format.

00:38:25.130 --> 00:38:28.550
It is contained within the file,
the queue itself, the buffers that we are

00:38:28.610 --> 00:38:33.420
going to use with the queue,
where we are reading from in the file,

00:38:33.420 --> 00:38:36.770
how many packets of the file we
can read at a particular time

00:38:36.870 --> 00:38:40.500
and packet descriptions which
we will go into in a minute.

00:38:40.500 --> 00:38:44.760
Then the other thing aside from just the
procedural code of calling the APIs that

00:38:44.840 --> 00:38:49.490
we will need to define is the callback
and we will have a look at that as well.

00:38:50.080 --> 00:38:54.470
So our next step is to get
the format from the file,

00:38:54.470 --> 00:38:57.530
the data format that's
contained within the file.

00:38:57.540 --> 00:39:01.680
And then once we have that,
we have enough information

00:39:01.680 --> 00:39:03.880
to create an output queue.

00:39:03.880 --> 00:39:08.770
Because when you create an output queue,
the one thing you should define

00:39:08.770 --> 00:39:12.570
is the format that the queue
is going to be dealing with,

00:39:12.640 --> 00:39:14.540
the format of the data it's
going to be dealing with.

00:39:14.720 --> 00:39:19.160
So we read that data format,
create the queue.

00:39:19.780 --> 00:39:23.720
You'll notice that I'm specifying
see if run loop get current and

00:39:23.870 --> 00:39:25.980
see if run loop common modes.

00:39:25.980 --> 00:39:29.230
And if I passed in null for those,
that would be the value

00:39:29.300 --> 00:39:30.830
of those two arguments.

00:39:30.840 --> 00:39:34.790
And what they define,
as you saw with MHC as well,

00:39:34.790 --> 00:39:38.010
is that they define the thread
and the mode that the queue

00:39:38.010 --> 00:39:40.960
object can call your callback on.

00:39:41.020 --> 00:39:46.120
And that gives you some control about
the priority of the thread that you're

00:39:46.310 --> 00:39:48.460
going to use to fill the buffers.

00:39:49.360 --> 00:39:53.020
And you can have that behavioral
control in your program.

00:39:53.020 --> 00:39:55.610
And then we get back a
queue object from this call.

00:39:57.020 --> 00:40:00.240
So with buffer management,
we allocate buffers,

00:40:00.350 --> 00:40:03.260
but we ask the queue to
allocate the buffers for us,

00:40:03.310 --> 00:40:05.280
and the queue will own the buffers.

00:40:05.280 --> 00:40:08.880
But before we can allocate the buffers,
we need to know some

00:40:09.310 --> 00:40:10.840
things about the format.

00:40:10.840 --> 00:40:15.360
Basically, how big we want,
which at the moment in the program,

00:40:15.460 --> 00:40:17.850
we'll just keep a constant size.

00:40:17.860 --> 00:40:20.920
But we also want to really know
if we're dealing with variable

00:40:20.920 --> 00:40:22.860
bitrate or constant bitrate audio.

00:40:23.630 --> 00:40:27.180
And just as a review,
I thought we'll go through what

00:40:27.210 --> 00:40:32.280
the characteristics of these
two audio kind of types mean.

00:40:32.280 --> 00:40:36.590
So CVR audio, constant bitrate audio,
is linear PCM,

00:40:36.590 --> 00:40:39.200
which is uncompressed audio.

00:40:39.200 --> 00:40:42.340
There's also a collection of CVR codecs.

00:40:42.340 --> 00:40:45.440
IMA4 is one, QDesign is another.

00:40:45.440 --> 00:40:52.880
And they generate packets of audio
that have both the same size of bytes,

00:40:52.880 --> 00:40:56.070
number of bytes,
and the number of sample frames

00:40:56.070 --> 00:40:58.810
in each packet is also the same.

00:40:58.860 --> 00:41:01.700
Linear PCM, there's one frame per packet.

00:41:01.770 --> 00:41:06.200
So in stereo linear PCM, you'd have left,
right, left, right.

00:41:06.340 --> 00:41:08.860
And the left and right together
is what we call a packet.

00:41:08.860 --> 00:41:12.150
And compressed audio,
it will be a block of audio.

00:41:12.160 --> 00:41:14.820
So you can see the
diagram there that CVR,

00:41:14.820 --> 00:41:16.960
every packet is the same size.

00:41:16.960 --> 00:41:20.910
In the audio stream basic description,
bytes and frames per packet are

00:41:20.910 --> 00:41:23.220
both specified with non-zero values.

00:41:24.970 --> 00:41:29.320
Now in our program,
we've just got an idea of 64K

00:41:29.320 --> 00:41:32.500
value for G buffer size bytes.

00:41:32.500 --> 00:41:38.830
And then we can use the bytes per
packet field to tell us how many

00:41:39.110 --> 00:41:43.610
packets we can read at a given time.

00:41:43.610 --> 00:41:46.740
And so that's what we need
to understand in our program.

00:41:46.740 --> 00:41:48.790
And this is, of course,
based on the data format

00:41:48.790 --> 00:41:50.110
contained within the file.

00:41:50.760 --> 00:41:54.620
And because it's CBR,
we can calculate from any

00:41:54.620 --> 00:41:57.110
place where the packets are.

00:41:57.110 --> 00:41:59.810
So we don't need packet descriptions.

00:41:59.820 --> 00:42:04.450
We don't need any external information
to tell us the packet 20 is here.

00:42:04.450 --> 00:42:07.080
Now, that's not true in VBR.

00:42:07.080 --> 00:42:09.400
So in VBR,
we have to do a little bit more work.

00:42:09.480 --> 00:42:13.220
So with VBR, let's try and understand,
well, what is VBR?

00:42:13.220 --> 00:42:16.330
Each packet of audio is a
different size in bytes.

00:42:16.330 --> 00:42:17.980
That's a common case.

00:42:17.980 --> 00:42:23.470
You can get VBR where you'll
have also the frames contained

00:42:23.470 --> 00:42:25.220
in each packet differing.

00:42:25.500 --> 00:42:29.770
But the more common case is that the
size of each packet is different.

00:42:29.820 --> 00:42:35.500
An example is MPEG-4's AAC, MPEG-1 or 2,
Layer 3.

00:42:35.590 --> 00:42:36.940
They're both VBR formats.

00:42:36.940 --> 00:42:38.800
Apple Lossless, FLAC.

00:42:39.070 --> 00:42:41.700
These are all VBR formats.

00:42:41.700 --> 00:42:45.790
And in an audio stream basic description,
a VBR format,

00:42:46.060 --> 00:42:50.040
you can tell because the bytes per
packet will have a value of zero.

00:42:50.080 --> 00:42:51.900
In other words, we don't know.

00:42:51.900 --> 00:42:53.440
Each packet's different.

00:42:54.650 --> 00:43:00.010
And so now to locate a packet
in just a big blob of data,

00:43:00.020 --> 00:43:03.110
we need to know a couple
of bits of information.

00:43:03.120 --> 00:43:06.860
We need to know where in that
blob of data a packet is,

00:43:06.870 --> 00:43:09.950
and we need to know the size
of that particular packet.

00:43:10.000 --> 00:43:14.660
So the audio stream packet description,
which is a structure in CordioTypes,

00:43:14.690 --> 00:43:19.940
it defines both where each packet
begins and how big each packet is.

00:43:20.430 --> 00:43:25.300
And the diagram there is fairly clear in
that each packet can be a different size.

00:43:30.400 --> 00:43:36.420
In our program, we use the complete test,
which is bytes or frames

00:43:36.420 --> 00:43:37.520
per packet is zero.

00:43:37.520 --> 00:43:40.030
In other words,
the file can't give you a constant

00:43:40.040 --> 00:43:42.100
value for either of those two fields.

00:43:42.100 --> 00:43:44.000
Now we have VBR data.

00:43:44.000 --> 00:43:51.950
Then we go and we ask the file,
what is the largest size of the packets

00:43:52.300 --> 00:43:55.100
of data that you have in your file?

00:43:55.100 --> 00:43:57.920
What is the largest size
of one of those packets?

00:43:58.100 --> 00:44:01.440
If I go back to the preceding slide,
you'll see the,

00:44:01.440 --> 00:44:04.180
I'm going to use the laser pointer
because everyone tells me not to.

00:44:04.180 --> 00:44:07.520
You see this guy here
is the largest packet.

00:44:07.520 --> 00:44:10.940
But I don't want to have to start
right from the beginning and go

00:44:10.940 --> 00:44:14.280
all the way through because in
some formats that might mean,

00:44:14.280 --> 00:44:16.560
some file formats,
that might mean I'll have

00:44:16.560 --> 00:44:17.830
to read the whole file.

00:44:17.840 --> 00:44:23.500
So the call that we're
using here is an estimation.

00:44:23.500 --> 00:44:27.740
And the file can usually,
if it doesn't know specifically,

00:44:28.100 --> 00:44:32.340
without having to pass the whole file,
it can make an estimation.

00:44:32.340 --> 00:44:34.340
And this will be a
conservative estimation.

00:44:34.340 --> 00:44:38.090
And that will give you back
the maximum packet size that

00:44:38.090 --> 00:44:39.640
could be contained in that file.

00:44:39.780 --> 00:44:41.760
And so this is a cheap call.

00:44:41.930 --> 00:44:44.350
There's another call where
you can get the actual value,

00:44:44.410 --> 00:44:46.830
but for some formats
like MP3 as an example,

00:44:46.900 --> 00:44:50.480
with a large MP3 file,
that can take you a long time because

00:44:50.480 --> 00:44:52.890
you have to read the whole file.

00:52:24.700 --> 00:52:34.700
[Transcript missing]

00:52:42.500 --> 00:52:59.100
[Transcript missing]

00:53:00.900 --> 00:53:14.700
[Transcript missing]

00:53:46.500 --> 00:53:56.500
[Transcript missing]

00:54:11.900 --> 00:54:20.500
[Transcript missing]

00:54:47.400 --> 00:55:36.700
[Transcript missing]

00:56:46.500 --> 00:57:15.300
[Transcript missing]

00:57:56.900 --> 00:58:18.800
[Transcript missing]

00:58:49.900 --> 00:59:00.100
[Transcript missing]

00:59:05.800 --> 00:59:16.800
[Transcript missing]