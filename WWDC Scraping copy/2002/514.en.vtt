WEBVTT

00:00:04.830 --> 00:00:06.480
Hello, good afternoon everyone.

00:00:06.710 --> 00:00:08.800
Please have a seat.

00:00:08.900 --> 00:00:13.060
Welcome to session 514,
OpenGL Performance Optimization.

00:00:13.060 --> 00:00:17.700
This is the last dedicated OpenGL session
at the conference and a must attend

00:00:18.060 --> 00:00:22.120
for all of those coding for OpenGL.

00:00:22.140 --> 00:00:29.980
We're going to show you a specially
designed tool for profiling and

00:00:29.980 --> 00:00:30.610
optimizing OpenGL coding and

00:00:30.890 --> 00:00:32.800
That tool is really cool.

00:00:32.800 --> 00:00:37.500
OpenGL profiler is going to ease your way
and the performance of your application.

00:00:37.500 --> 00:00:39.990
But most importantly,
you're going to hear the do's

00:00:40.050 --> 00:00:45.400
and the don'ts of OpenGL coding
from the man responsible for

00:00:45.570 --> 00:00:47.300
Apple's OpenGL implementation.

00:00:47.360 --> 00:00:51.570
And I'm happy to introduce
you to the stage,

00:00:51.580 --> 00:00:55.370
Apple OpenGL manager, John Stauffer.

00:01:00.260 --> 00:01:02.330
Thanks Sergio.

00:01:02.400 --> 00:01:07.170
Okay, today we're going to talk about
how to optimize OpenGL and

00:01:08.030 --> 00:01:09.990
let's jump right into it.

00:01:11.530 --> 00:01:12.540
So that's me.

00:01:12.550 --> 00:01:16.010
I manage the OpenGL engineering
group at Apple.

00:01:16.760 --> 00:01:20.260
We have a great team of people
who work really hard to bring you

00:01:20.260 --> 00:01:22.760
a quality OpenGL implementation.

00:01:22.760 --> 00:01:28.350
And what I want to talk about today,
briefly, is more of a summary of what

00:01:28.350 --> 00:01:33.340
we see developers coming
to us with over the year.

00:01:33.340 --> 00:01:37.670
So we want to give you some basic
suggestions about how to use OpenGL,

00:01:37.780 --> 00:01:41.810
what will work well for you,
what to avoid,

00:01:41.810 --> 00:01:45.680
try to direct you down the right paths.

00:01:45.680 --> 00:01:49.670
And also to point out some of
the recent additions to OpenGL,

00:01:49.920 --> 00:01:52.840
both in optimizations and in extensions.

00:01:52.840 --> 00:01:55.350
So we've been working hard to
optimize current paths that

00:01:55.350 --> 00:01:56.560
you may already be using.

00:01:56.560 --> 00:02:01.690
So you may get some benefit from
OpenGL just by installing Jaguar.

00:02:01.690 --> 00:02:04.500
And then the extension side,
there's some really advanced

00:02:04.540 --> 00:02:07.660
optimization extensions that
you'll want to try to use.

00:02:07.660 --> 00:02:08.660
And then we want to show you
how to use them if you can.

00:02:08.660 --> 00:02:12.950
It'll get you a lot of performance
if you can utilize these extensions,

00:02:12.950 --> 00:02:14.880
as I'll show in the demos.

00:02:15.200 --> 00:02:24.100
Using Threads The use of threads can
bring you a unique set of performance

00:02:24.100 --> 00:02:28.100
optimizations depending on what
type of rendering you're doing.

00:02:28.100 --> 00:02:32.400
We'll go through a couple possible
uses for threads and how you can try

00:02:32.400 --> 00:02:35.100
to leverage that in your application.

00:02:35.500 --> 00:02:39.720
Tools As Sergio mentioned,
we're going to be shipping a new tool

00:02:39.720 --> 00:02:42.100
in Jaguar called the OpenGL Profiler.

00:02:42.100 --> 00:02:46.740
It is targeted towards helping you
understand what your application

00:02:47.240 --> 00:02:52.240
performance issues are and helps
you try to identify where time is

00:02:52.240 --> 00:02:54.100
being spent in the OpenGL pipeline.

00:02:54.260 --> 00:02:58.320
So you'll see that it's a powerful
tool once we go through it and

00:02:58.390 --> 00:03:02.100
hopefully it'll give you some
benefit when you start using it.

00:03:02.460 --> 00:03:04.030
Sampler I briefly mentioned Sampler here.

00:03:04.130 --> 00:03:06.100
I'm not really going to
go into Sampler much.

00:03:06.100 --> 00:03:10.100
But it is a tool that you should use
in conjunction with our Profiler.

00:03:10.100 --> 00:03:12.100
It's a very powerful system level tool.

00:03:12.140 --> 00:03:17.100
That will give you a more broader view
of your application performance issues.

00:03:17.100 --> 00:03:20.470
We won't be focusing on that,
but it is a tool that you

00:03:20.510 --> 00:03:22.100
ought to be familiar with.

00:03:22.100 --> 00:03:26.060
And then lastly we'll go into a
little bit of where to look for help.

00:03:26.370 --> 00:03:27.100
App Services

00:03:29.200 --> 00:03:31.500
So, every now and then I'm going to
pull up a slide and it's going

00:03:31.590 --> 00:03:33.490
to be titled Basic Optimizations.

00:03:33.950 --> 00:03:39.850
So, what these slides are is
just the do's and don'ts.

00:03:39.850 --> 00:03:39.850
So,

00:03:40.500 --> 00:03:44.840
The first thing that I want to talk
about on basic optimization is the thing

00:03:44.840 --> 00:03:50.150
that people need to try to identify
in their application is what are their

00:03:50.150 --> 00:03:55.840
bottlenecks and what kind of data are
they primarily passing around the system.

00:03:55.960 --> 00:04:00.150
So what we usually find in applications
is they're either passing lots of pixels,

00:04:00.350 --> 00:04:04.040
so they're moving lots of pixels around,
or they're passing lots of geometry.

00:04:04.040 --> 00:04:07.660
Rarely actually are people passing both,
believe it or not.

00:04:07.840 --> 00:04:12.670
So I tried to point out that you
should look at your application and

00:04:12.670 --> 00:04:16.490
try to identify what is your data type
that you're trying to pass around.

00:04:16.570 --> 00:04:21.600
And we'll talk about specifically
optimizations that you can apply to

00:04:21.730 --> 00:04:24.620
those particular types of data sets.

00:04:24.840 --> 00:04:28.160
So once you've identified
what you're passing around,

00:04:28.160 --> 00:04:33.670
you'll also want to look at other
things your application's doing,

00:04:33.670 --> 00:04:34.380
like what's dynamic.

00:04:34.380 --> 00:04:38.060
Are some of those data sets static,
or are they dynamic?

00:04:38.060 --> 00:04:41.910
The different optimizations you'll
apply to that will depend on whether

00:04:41.910 --> 00:04:44.170
they are dynamic data or static data.

00:04:44.180 --> 00:04:47.520
And also, how complex is your data?

00:04:47.520 --> 00:04:52.040
There is different techniques you'll
want to apply for depending on how

00:04:52.040 --> 00:04:55.680
complex the data you're passing around,
or complex I mean by size.

00:04:55.850 --> 00:04:59.960
So if it's very large data,
maybe it's something that you'll

00:05:00.110 --> 00:05:03.140
have to treat in a unique way,
or if it's smaller,

00:05:03.140 --> 00:05:05.570
you can probably just pass it
down through some of the more

00:05:05.690 --> 00:05:08.460
standard techniques and let
OpenGL deal with it and not have

00:05:08.630 --> 00:05:10.580
to get a little more complicated.

00:05:10.580 --> 00:05:15.380
So another last thing that
I'd like to have you look at

00:05:15.380 --> 00:05:17.450
your application and ask is,
are you spooling data

00:05:17.450 --> 00:05:18.620
from disk in real time?

00:05:18.620 --> 00:05:23.300
There's some techniques to use to
getting data spooled on and off the disk,

00:05:23.940 --> 00:05:25.400
and we'll go a little bit into that.

00:05:27.810 --> 00:05:31.070
So firstly,
just putting the OpenGL pipeline,

00:05:31.070 --> 00:05:33.820
a real basic drawing of the
OpenGL pipeline up here so we

00:05:33.820 --> 00:05:37.460
can get an idea of the different
groups of different areas of the

00:05:37.460 --> 00:05:41.000
pipeline that we want to just think
about as we're talking about this.

00:05:41.160 --> 00:05:43.800
So the first one is vertices.

00:05:43.800 --> 00:05:47.140
Vertices are the geometric data,
obviously, that go through the system.

00:05:47.240 --> 00:05:50.640
And that is primarily what
people think of when they think

00:05:50.700 --> 00:05:52.770
of passing data to OpenGL.

00:05:53.110 --> 00:05:55.950
But also there's a category
that's equally as important,

00:05:55.980 --> 00:05:57.640
and that's the state data.

00:05:57.640 --> 00:06:00.600
State is really anything
that OpenGL retains.

00:06:00.640 --> 00:06:03.240
It's a current state of the pipeline.

00:06:03.410 --> 00:06:09.410
So state is the configuration of the
card or anything that OpenGL is going to

00:06:09.510 --> 00:06:11.240
not just simply pass through but retain.

00:06:11.240 --> 00:06:14.100
And a lot of that state can
actually be retrieved by you

00:06:14.100 --> 00:06:16.430
back out through the API.

00:06:16.530 --> 00:06:18.810
And as you'll see in
some of the discussion,

00:06:19.020 --> 00:06:22.440
there is an interesting issue
with when we start talking about

00:06:22.440 --> 00:06:23.980
caching data in the system.

00:06:24.070 --> 00:06:28.250
There's an interesting performance issues
with that related to the that we have

00:06:28.250 --> 00:06:29.700
to do bookkeeping in OpenGL to keep it.

00:06:29.830 --> 00:06:31.940
We have to make maybe a
copy of it and keep it.

00:06:32.030 --> 00:06:34.630
So those are the two categories.

00:06:34.750 --> 00:06:38.370
Textures fall under the state category
in this diagram that I have here.

00:06:38.610 --> 00:06:40.500
So you're passing,
when you're passing a texture,

00:06:40.500 --> 00:06:44.090
really a texture is a piece of
state that you can retrieve back.

00:06:44.260 --> 00:06:44.920
It can be bound.

00:06:44.940 --> 00:06:46.820
It can be deleted.

00:06:46.820 --> 00:06:50.570
It can be replaced and such.

00:06:51.510 --> 00:06:54.500
So, so the first thing,
my first suggestion is, um,

00:06:54.680 --> 00:06:58.400
I highlight it in red because I want
to make sure that everyone understands.

00:06:58.460 --> 00:07:02.930
Uh, we ask people to almost
never call geo flush.

00:07:03.020 --> 00:07:06.370
And you'll see at the bottom,
to never call geo finish.

00:07:06.770 --> 00:07:09.650
And the reason I say almost on the
top one is that the only reason you

00:07:09.650 --> 00:07:13.840
ever want to call Geo flush is if
you're a single buffered application.

00:07:13.910 --> 00:07:16.540
And we don't even like
applications to be single buffered.

00:07:16.540 --> 00:07:18.100
We'd rather you be double buffered.

00:07:18.230 --> 00:07:22.500
So we really ask that people
try to stay away from these.

00:07:23.180 --> 00:07:30.700
And I brought this up first because it
is the number one easy performance trick

00:07:30.700 --> 00:07:32.390
that you can do to your application.

00:07:32.490 --> 00:07:33.960
And if you don't think
you're calling that,

00:07:33.990 --> 00:07:38.740
but you're not 100% sure,
search your code, look for Geo flush,

00:07:38.740 --> 00:07:42.700
Geo finish, and if you find them,
comment them out.

00:07:42.700 --> 00:07:45.330
If you're a double buffered application,
just comment out those lines

00:07:45.330 --> 00:07:46.700
because you don't need them.

00:07:48.420 --> 00:07:51.880
They can give you potentially up
to about a 20% speed improvement

00:07:51.880 --> 00:07:55.850
if you're calling GL finish just by
commenting out that one line because

00:07:55.940 --> 00:08:00.980
what GL finish does is it actually is
a synchronous call that will truncate

00:08:01.070 --> 00:08:05.000
the command stream and send it to the
graphics card and wait for it to return

00:08:05.000 --> 00:08:06.800
after the graphics card is finished.

00:08:06.960 --> 00:08:11.040
So what you've in effect done is
you've stalled the CPU waiting

00:08:11.040 --> 00:08:14.540
for the graphics card to finish
the processing of the data.

00:08:14.660 --> 00:08:17.950
So you're gonna wait for the
graphics card to eat all the data,

00:08:18.020 --> 00:08:21.850
return back around and tell
the CPU that it's done.

00:08:22.240 --> 00:08:25.260
So the CPU's stuck, it's idle,
it's not doing anything while

00:08:25.260 --> 00:08:28.330
that's happening and you're
fundamentally operating in synchronous

00:08:28.970 --> 00:08:30.540
behavior to the graphics card.

00:08:30.540 --> 00:08:36.550
You're not operating asynchronously
to the graphics processing unit.

00:08:39.510 --> 00:08:41.100
So, some other basic suggestions.

00:08:41.340 --> 00:08:43.880
And we're going to go over the basics
and then we're going to get into

00:08:43.920 --> 00:08:47.960
some more complex things like the
title of the session is advanced.

00:08:48.100 --> 00:08:50.140
But we'll cover these basics real quick.

00:08:50.310 --> 00:08:52.840
So, avoid using GeoReadPixels.

00:08:53.240 --> 00:08:55.840
ReadPixels calls an implicit GeoFinish.

00:08:56.020 --> 00:08:59.160
So anytime you retrieve
pixels back out of the system,

00:08:59.250 --> 00:09:01.360
we have to flush the entire command
stream because the pixels that

00:09:01.360 --> 00:09:04.950
you're reading in the command buffer,
I'm sorry, in the frame buffer,

00:09:04.950 --> 00:09:08.640
need to be the pixels that represent
the state of the system at that point.

00:09:08.650 --> 00:09:10.880
So we need to guarantee that
we've rendered everything.

00:09:10.880 --> 00:09:15.040
So,
ReadPixels calls an implicit GeoFinish.

00:09:15.040 --> 00:09:19.080
And it'll have the same performance
impact as if you were to call GeoFinish

00:09:19.540 --> 00:09:22.940
and then some because obviously then
you're reading data back across a bus.

00:09:22.980 --> 00:09:27.590
So, really the only time that you
want to be calling GeoFinish is if

00:09:27.590 --> 00:09:32.750
you're looking to spool data off the
graphics card and save it to disk.

00:09:32.760 --> 00:09:35.640
Maybe some type of,
you're using the graphics card

00:09:35.640 --> 00:09:37.840
for doing a rendering of a
sequence and you want to save it.

00:09:38.080 --> 00:09:44.380
We discourage it from being used for
things that are meant to be interactive,

00:09:44.380 --> 00:09:47.380
like you just want to save a copy of
something so you can keep refreshing it.

00:09:47.380 --> 00:09:50.570
There's better ways to
save data for refresh,

00:09:50.600 --> 00:09:53.440
refreshing dirty areas on the screen.

00:09:53.440 --> 00:09:56.480
ReadPixels is usually
a slow way to do it.

00:09:56.480 --> 00:10:01.370
So we recommend that you look
into the other techniques first

00:10:01.370 --> 00:10:04.320
before you resort to ReadPixels.

00:10:04.730 --> 00:10:09.000
So the second item here is
the parallel to read pixels.

00:10:09.090 --> 00:10:10.640
It's GL draw pixels.

00:10:10.750 --> 00:10:16.500
And we also recommend that you don't
use that function call because it's a

00:10:16.500 --> 00:10:19.100
very hard call to optimize in OpenGL.

00:10:19.210 --> 00:10:23.810
The reason being is it is a call that
will require us to copy the data.

00:10:24.050 --> 00:10:26.990
And as you'll see in some of the
demos that I'm going to give,

00:10:27.000 --> 00:10:31.100
there's ways to allow us
to not even copy the data,

00:10:31.100 --> 00:10:34.200
but in fact the data to be read directly
from your memory up to the graphics card.

00:10:34.200 --> 00:10:35.900
So the driver's not copying the data.

00:10:35.900 --> 00:10:40.680
So we're going to advertise to you that
the best thing to do is to use APIs that

00:10:40.710 --> 00:10:44.360
allow us to operate asynchronous.

00:10:44.360 --> 00:10:47.050
The CPUs are allowed to operate
asynchronous to the graphics card.

00:10:47.300 --> 00:10:49.200
Drop pixels really doesn't
do a good job of that.

00:10:49.200 --> 00:10:52.020
There's better ways to do it.

00:10:53.910 --> 00:10:57.970
So before we jump into
some more complex subjects,

00:10:58.040 --> 00:11:00.480
last suggestion here,
minimize state changes.

00:11:00.520 --> 00:11:04.000
State changes, again, are textures,
enables, disables.

00:11:04.000 --> 00:11:07.800
Anything that you're fiddling
with in the state machine,

00:11:07.800 --> 00:11:08.500
you want to minimize.

00:11:08.500 --> 00:11:11.520
It has an impact on the system.

00:11:11.520 --> 00:11:14.960
Usually the impact is that we
have to synchronize some software.

00:11:14.960 --> 00:11:16.680
We have to go notify the graphics card.

00:11:16.680 --> 00:11:18.760
It has to change the state
of the graphics card,

00:11:18.760 --> 00:11:22.380
maybe do some conversion of
the state into something the

00:11:22.380 --> 00:11:23.380
graphics card understands.

00:11:23.540 --> 00:11:25.340
So there's processing that
goes on behind the background.

00:11:25.340 --> 00:11:30.780
So some state changes,
while they may seem trivial,

00:11:30.780 --> 00:11:33.940
sometimes they can add up to be
quite a bit of time being spent.

00:11:33.950 --> 00:11:37.390
And it can be a surprising amount
of performance loss if you're

00:11:37.600 --> 00:11:39.060
really banging on the state machine.

00:11:44.210 --> 00:11:46.340
Okay, so what's new in Jaguar?

00:11:46.340 --> 00:11:49.980
So even though I mentioned
previously that we discourage

00:11:49.980 --> 00:11:52.660
you from using draw pixels,
read pixels, there they are,

00:11:52.680 --> 00:11:56.560
we do understand that people
have applications and they have

00:11:56.560 --> 00:11:58.320
code that previously was written.

00:11:58.320 --> 00:12:01.840
They don't have an opportunity
to use other techniques or it's

00:12:01.840 --> 00:12:03.470
just very inconvenient for them.

00:12:03.480 --> 00:12:06.070
So we actually are spending
quite a bit of time to optimize

00:12:06.070 --> 00:12:07.300
those paths for those people.

00:12:07.300 --> 00:12:12.220
So in Jaguar, you'll see that draw
pixels now actually will,

00:12:12.520 --> 00:12:14.890
under the covers,
simulate the technique that

00:12:14.890 --> 00:12:16.680
we're trying to advertise to you.

00:12:16.680 --> 00:12:19.520
It will copy the data once,
so there'll be a data copy,

00:12:19.520 --> 00:12:22.210
but then once we copy the data,
it will give an optimized

00:12:22.210 --> 00:12:23.820
upload to the graphics card.

00:12:23.820 --> 00:12:27.710
So it won't be as good as
some of the other techniques,

00:12:27.750 --> 00:12:30.560
but it gets as close as we possibly can.

00:12:30.560 --> 00:12:31.960
So geo-read pixels.

00:12:31.960 --> 00:12:38.280
The previous release of OpenGL would
actually use the CPU to read

00:12:38.280 --> 00:12:41.590
the pixels back across the bus,
and reading the pixels back across

00:12:41.590 --> 00:12:43.600
the bus obviously is a bad idea.

00:12:43.600 --> 00:12:47.430
You're consuming CPU time and
you're only nibbling away across

00:12:47.630 --> 00:12:49.390
a PCI bus to get the data back.

00:12:49.710 --> 00:12:51.960
So now we DMA the data.

00:12:51.960 --> 00:12:53.760
We have the graphics card
pushed into a piece of memory

00:12:53.760 --> 00:12:56.360
and it's significantly faster.

00:12:56.360 --> 00:12:59.920
So the numbers that we're seeing,
we're seeing about an order of

00:12:59.930 --> 00:13:01.620
magnitude performance increase.

00:13:01.630 --> 00:13:06.450
So we went from about 6 to 9 megabytes
a second to 60 to 90 megabytes a

00:13:06.530 --> 00:13:07.980
second of read pixels performance.

00:13:07.980 --> 00:13:10.060
We're looking to improve that as well.

00:13:10.060 --> 00:13:12.890
We think there's still headroom
to grow and improve that.

00:13:13.020 --> 00:13:14.920
But that's something that's new.

00:13:14.920 --> 00:13:17.570
So text sub-image.

00:13:17.600 --> 00:13:20.400
That is now a VRAM to VRAM copy.

00:13:20.400 --> 00:13:25.630
So that will give you a
on-video card copy from one

00:13:25.630 --> 00:13:27.950
region of memory to another.

00:13:27.960 --> 00:13:29.220
It will never touch the CPU.

00:13:29.220 --> 00:13:34.410
And if you read that texture back,
beware we'll have to update the system

00:13:34.410 --> 00:13:38.800
copy because we now have stagnated,
or the system copy has gone stale.

00:13:38.800 --> 00:13:41.910
We've said this one is not the
master copy anymore because you

00:13:41.910 --> 00:13:43.000
have updated it on the video card.

00:13:43.000 --> 00:13:47.050
So if you read that texture back,
if you want those bits out of it,

00:13:47.230 --> 00:13:50.150
we will have to go through an
operation in the driver to read the

00:13:50.150 --> 00:13:52.750
bits back off the graphics card,
put them in the system copy

00:13:52.750 --> 00:13:53.670
before we give them to you.

00:13:53.860 --> 00:13:57.690
So beware that if you're using that call,
don't ask for the texture

00:13:57.690 --> 00:14:00.080
back because it's going to
take a little while to get it.

00:14:03.240 --> 00:14:03.480
DisplayList.

00:14:03.480 --> 00:14:06.420
So DisplayList now are very optimized.

00:14:06.420 --> 00:14:10.740
They use some of the extensions I'll
be talking about internally to OpenGL,

00:14:10.740 --> 00:14:14.030
one of them being the
vertex array object.

00:14:14.290 --> 00:14:20.110
Vertex array object is built on top
of vertex array range and offers very

00:14:20.110 --> 00:14:24.280
good performance for static data.

00:14:24.280 --> 00:14:27.830
And it's our intent that we
will continue to optimize this,

00:14:28.050 --> 00:14:29.600
improve the algorithms.

00:14:30.560 --> 00:14:33.760
Basically, how it works right now is
that we take the data that

00:14:33.760 --> 00:14:36.010
you put into a display list,
we will examine it,

00:14:36.100 --> 00:14:39.080
post-process it into something
that's more optimal for the hardware,

00:14:39.080 --> 00:14:42.510
cache it into that optimal format
so that when you go to draw with it,

00:14:42.690 --> 00:14:46.300
we're not reformatting it with a
CPU or copying the data around.

00:14:46.300 --> 00:14:47.960
Basically, at that point,
all we do is submit it

00:14:47.960 --> 00:14:48.860
to the graphics card.

00:14:48.860 --> 00:14:53.560
So drawing a display list now
is fairly low burden on the CPU.

00:14:53.560 --> 00:14:58.560
It's just a matter of a submission
call to the graphics card for drawing.

00:14:58.560 --> 00:15:00.240
So vertex arrays.

00:15:00.580 --> 00:15:02.260
I'm not talking about
vertex array range here.

00:15:02.260 --> 00:15:04.720
I'm talking about just standard
vertex arrays without any extensions.

00:15:04.720 --> 00:15:06.300
We've optimized that as well.

00:15:06.300 --> 00:15:08.660
This is better than it was.

00:15:08.760 --> 00:15:10.370
It's still not the best you can do.

00:15:10.380 --> 00:15:11.230
We'll see later.

00:15:11.240 --> 00:15:12.390
Image processing.

00:15:12.600 --> 00:15:15.660
So we've been improving
our image processing code.

00:15:15.660 --> 00:15:18.760
There is a number of formats,
pixel formats,

00:15:18.760 --> 00:15:24.340
that we have optimized with Altevec,
tried to get the maximum performance

00:15:24.760 --> 00:15:28.360
of texture upload and image
conversion through the system.

00:15:31.340 --> 00:15:34.100
Okay, so I'm going to jump
into some specifics here.

00:15:34.100 --> 00:15:36.640
Let's talk about the texture
pipeline a little bit.

00:15:36.890 --> 00:15:41.630
So the diagram we see here shows that the

00:15:41.790 --> 00:15:44.870
Basic path that textures take
to get to the graphics card.

00:15:45.000 --> 00:15:46.750
So each of these blocks...

00:16:22.110 --> 00:16:24.100
Okay, how about now?

00:16:24.100 --> 00:16:26.100
Okay, how much did you miss?

00:16:26.100 --> 00:16:28.860
It was boring anyways.

00:16:30.820 --> 00:16:34.670
Okay, so,
the two boxes that I have up here,

00:16:34.670 --> 00:16:38.940
those represent the number of
times a texture may get copied

00:16:39.080 --> 00:16:40.200
as it goes through the system.

00:16:40.200 --> 00:16:44.460
So, as I talked about before,
textures are state,

00:16:44.460 --> 00:16:47.840
and we have to retain that state,
because you may ask for it back.

00:16:47.960 --> 00:16:51.750
So, what OpenGL does is it has to make
a retained copy of the texture,

00:16:51.870 --> 00:16:53.970
and, in case you ask for it back.

00:16:54.360 --> 00:16:58.120
So, what we do is we take a texture,
we copy it into a retained area,

00:16:58.120 --> 00:17:01.040
and then when the first
time you go to draw with it,

00:17:01.040 --> 00:17:04.930
the graphics card takes that
retained copy and copies it into

00:17:05.000 --> 00:17:07.500
a hardware specific format for
uploading to the graphics card.

00:17:07.500 --> 00:17:10.760
So, if you're looking at using the
standard OpenGL texturing path for

00:17:10.900 --> 00:17:13.330
spooling data up to the system,
up to the graphics card,

00:17:13.330 --> 00:17:16.050
you're going to see that
there's two copies of the data.

00:17:16.050 --> 00:17:18.220
We're going to undergo two copies.

00:17:18.220 --> 00:17:21.630
So, the optimizations that we
want to show today are how to

00:17:21.820 --> 00:17:23.820
eliminate both those copies.

00:17:23.820 --> 00:17:27.340
So, there's extensions that will offer a
way to eliminate those copies and get

00:17:27.340 --> 00:17:29.490
you substantial performance increases.

00:17:29.620 --> 00:17:32.620
So, again,
this is a standard OpenGL pipeline.

00:17:32.620 --> 00:17:34.790
We'll see how we can improve it.

00:17:36.310 --> 00:17:40.840
So, again, some basic texture
optimization suggestions.

00:17:41.000 --> 00:17:44.250
So what you want to do is
you want to think about,

00:17:44.250 --> 00:17:46.640
again,
how your application is using textures.

00:17:46.760 --> 00:17:51.520
You want to think about how much room
you have in the graphics card and scale

00:17:51.660 --> 00:17:54.690
your textures to fit on the hardware.

00:17:55.720 --> 00:17:56.880
The best thing to do,
and I'm not going to

00:17:56.880 --> 00:17:59.730
go into this session,
is to examine the graphics card for

00:17:59.730 --> 00:18:01.770
how much video memory is available.

00:18:01.890 --> 00:18:05.530
Scale your textures such that
they'll approximately scale

00:18:05.590 --> 00:18:07.520
to that piece of hardware.

00:18:07.640 --> 00:18:12.140
So the second thing is don't second
guess OpenGL's texture paging.

00:18:12.200 --> 00:18:15.010
The texture paging in
OpenGL is very efficient,

00:18:15.010 --> 00:18:16.620
in Apple's OpenGL, it's very efficient.

00:18:16.620 --> 00:18:18.320
It uses very little CPU time.

00:18:18.400 --> 00:18:21.830
Basically we've already pre-compiled
the data into a format that's

00:18:21.830 --> 00:18:23.420
ready for the hardware to consume.

00:18:23.560 --> 00:18:27.710
So if the texture has to be uploaded
to the graphics card a second time,

00:18:27.710 --> 00:18:28.660
it's very simple for us.

00:18:28.730 --> 00:18:31.220
It's very similar to what
we do to display lists,

00:18:31.220 --> 00:18:31.980
for instance.

00:18:32.280 --> 00:18:37.010
We post-process it into a format
that the next time through all we

00:18:37.030 --> 00:18:40.700
have to do is submit a token into
the stream and upload that texture.

00:18:40.870 --> 00:18:47.020
So if you are thinking you're going to be
running into a texture paging condition,

00:18:47.020 --> 00:18:50.580
you might want to not try to second
guess OpenGL's texture paging.

00:18:50.670 --> 00:18:52.480
Because what you'll end
up doing is fighting it or

00:18:52.480 --> 00:18:53.420
being inefficient with video.

00:18:53.420 --> 00:18:55.410
member usage.

00:18:57.770 --> 00:19:01.740
So the formats that you want to
use for textures preferably are the

00:19:01.740 --> 00:19:10.420
BGRA unsigned short 1555 format and
the BGRA unsigned int 888 format.

00:19:10.420 --> 00:19:12.950
And those formats are the,
believe it or not,

00:19:12.980 --> 00:19:15.510
the native pixel formats
for the Macintosh.

00:19:15.580 --> 00:19:18.050
The naming convention came from the ARM.

00:19:18.080 --> 00:19:18.960
They're a little confusing.

00:19:18.960 --> 00:19:24.770
The way the naming works is that
BGRA and the reverse on the type

00:19:25.270 --> 00:19:28.680
reverses the nomenclature on the BGRA.

00:19:28.680 --> 00:19:31.040
So it ends up being ARGB.

00:19:31.040 --> 00:19:33.600
And that is the native
pixel type of the Macintosh.

00:19:33.750 --> 00:19:36.240
So these are the data types you
want to use for uploading images.

00:19:36.240 --> 00:19:39.080
These will be the most direct
path through the system.

00:19:42.410 --> 00:19:46.340
Okay, so let's get into optimizing that
diagram that I showed you before and

00:19:46.340 --> 00:19:49.900
how to remove some of those copies so
you can get the maximum performance.

00:19:50.070 --> 00:19:52.660
So the first one,
the first extension is OpenGL texture

00:19:52.780 --> 00:19:55.740
extension is the Apple client storage.

00:19:55.840 --> 00:20:00.770
Eliminates the first block,
the first copy that OpenGL makes.

00:20:01.050 --> 00:20:03.240
It was the retained copy.

00:20:03.300 --> 00:20:07.610
And what it does is this extension
tells OpenGL that I don't

00:20:07.610 --> 00:20:09.930
want you to keep a copy of it.

00:20:10.010 --> 00:20:12.120
I want you to use the application's copy.

00:20:12.400 --> 00:20:15.490
So the caveat to using this
extension is that you have to

00:20:15.490 --> 00:20:17.150
keep a copy around for OpenGL.

00:20:17.150 --> 00:20:21.500
So you have the texture,
you use this extension and now OpenGL is

00:20:21.500 --> 00:20:26.600
just going to simply put a pointer
towards your copy of the texture

00:20:26.740 --> 00:20:29.750
such that if we need it again we're
going to come back and ask you for it.

00:20:29.850 --> 00:20:31.910
So you can't delete the
texture off from underneath us.

00:20:32.040 --> 00:20:33.940
You've got the retained copy, you own it.

00:20:34.060 --> 00:20:36.300
We're not going to copy it again for you.

00:20:36.410 --> 00:20:39.500
So the benefits of this are obviously
one that we're not going to copy

00:20:39.500 --> 00:20:41.400
the pixels that you already have.

00:20:41.670 --> 00:20:45.590
So obviously there's
some caveats to that.

00:20:45.800 --> 00:20:48.400
You need to use a format that we
can be compatible with and such.

00:20:48.400 --> 00:20:52.230
But the other benefit
is it can save memory.

00:20:52.230 --> 00:20:55.040
So if you're going to keep your
copy of the texture around anyways,

00:20:55.040 --> 00:20:57.840
no use to us keeping a copy as well.

00:20:57.840 --> 00:21:02.000
So we can eliminate potentially one
copy of that texture residing in system

00:21:02.000 --> 00:21:05.890
memory somewhere and save some memory,
maybe up the performance.

00:21:05.920 --> 00:21:08.900
You just have to follow the
rules and keep the texture around

00:21:08.900 --> 00:21:10.300
for us if we need it later.

00:21:14.510 --> 00:21:18.340
Okay, so the next extension is
the apple texture range.

00:21:18.400 --> 00:21:23.670
This extension is very similar to
the vertex array range where what

00:21:23.810 --> 00:21:28.040
we do is you are telling OpenGL,
I've got this texture.

00:21:28.040 --> 00:21:30.690
Please map that texture into AGP space.

00:21:30.760 --> 00:21:32.700
So you've allocated a piece of memory.

00:21:32.700 --> 00:21:33.630
You've handed it to us.

00:21:33.700 --> 00:21:39.060
We are going to use this extension to
define that piece of memory to OpenGL,

00:21:39.060 --> 00:21:41.860
and now we're going to
map that memory into AGP,

00:21:42.240 --> 00:21:45.000
and given that you followed
some of the basic rules of what

00:21:45.000 --> 00:21:49.340
the format of that texture is,
if you've given the texture

00:21:49.340 --> 00:21:52.360
format as the preferred format
that I previously listed,

00:21:52.360 --> 00:21:55.560
what will happen is that we
will map that memory into AGP,

00:21:55.560 --> 00:21:58.200
and now the graphics card is
talking directly to your memory.

00:21:58.200 --> 00:22:01.560
You won't even have to convert
it to a harder specific format.

00:22:01.560 --> 00:22:04.490
You've basically already provided that,
and what we're going to do is

00:22:04.540 --> 00:22:06.360
we're going to map that into AGP,
and we're going to have the graphics

00:22:06.510 --> 00:22:07.800
card DMA it straight from your copy.

00:22:07.800 --> 00:22:13.270
So the performance gain and the CPU,
the burden that we lessen by

00:22:13.280 --> 00:22:16.820
doing this is quite a bit,
and we'll see in a demonstration

00:22:16.820 --> 00:22:20.690
I'll give momentarily how
substantial that impact is.

00:22:20.760 --> 00:22:25.570
So one thing that I want to mention is
that there is a synchronization issue.

00:22:25.580 --> 00:22:30.260
So if you've got the graphics card coming
around spooling bits out of your memory,

00:22:30.260 --> 00:22:32.100
obviously that's an asynchronous process.

00:22:32.100 --> 00:22:34.730
We don't know exactly when that graphics
card is going to come around and do this,

00:22:34.840 --> 00:22:38.320
so you'll have to take care of
some synchronization issues,

00:22:38.810 --> 00:22:43.400
making sure that you are... talking
to the graphics card as to when you're

00:22:43.400 --> 00:22:47.220
going to update it and find out yourself
when it's going to be completed.

00:22:47.220 --> 00:22:51.800
So the extension we provide to do
this is the GLAppleFence extension,

00:22:51.800 --> 00:22:55.880
and that is a synchronization extension
for providing tokens into the stream

00:22:55.880 --> 00:23:00.450
where you then can query if a particular
operation's done and find out if

00:23:00.450 --> 00:23:04.260
that texture is done being used by
the current commands in the stream.

00:23:06.200 --> 00:23:08.100
We'll talk a little bit
more about that later.

00:23:08.100 --> 00:23:11.970
I wanted to just mention it
and we'll go into it more.

00:23:12.790 --> 00:23:17.600
Okay, so the third extension here,
off the top it doesn't seem

00:23:17.600 --> 00:23:20.690
like it has anything to do with
what we were talking about.

00:23:20.820 --> 00:23:22.600
But it turns out that it does.

00:23:22.770 --> 00:23:27.640
The texture rectangle is the
third missing piece in our full

00:23:27.640 --> 00:23:29.960
optimization path through OpenGL.

00:23:30.100 --> 00:23:34.660
What texture rectangle does is
it allows non-power 2 textures to

00:23:34.660 --> 00:23:37.330
be defined and given to OpenGL.

00:23:37.510 --> 00:23:40.390
It is the fastest path through
our system and there are hardware

00:23:40.390 --> 00:23:42.790
specific reasons why that is.

00:23:42.910 --> 00:23:45.900
It's some of the hardware,
the Power 2 textures are

00:23:45.920 --> 00:23:46.900
required to be swizzled.

00:23:46.900 --> 00:23:51.090
So, since the non-Power 2 textures
don't have to be swizzled into

00:23:51.140 --> 00:23:54.050
a hardware specific format,
it allows us to point the hardware

00:23:54.050 --> 00:23:58.020
directly towards your copy,
not forcing us to swizzle it

00:23:58.350 --> 00:24:01.160
into another copy that we retain.

00:24:01.320 --> 00:24:04.730
So, there are,
it is required to use this extension

00:24:04.800 --> 00:24:10.030
if you want to spool data at maximum
performance up to the graphics card.

00:24:10.250 --> 00:24:15.100
So, we think that this is an okay thing,
that you want to be,

00:24:15.100 --> 00:24:19.050
that we're requiring you to use
this primarily for the reason that

00:24:19.240 --> 00:24:22.740
if you're using Power 2 textures,
usually you're looking at having

00:24:22.740 --> 00:24:26.100
the graphics card retain those,
use them frame, one frame to another,

00:24:26.540 --> 00:24:31.000
and not,
you're not looking to spool data for,

00:24:31.000 --> 00:24:32.700
up to the graphics card for blitting,
for instance.

00:24:32.700 --> 00:24:36.770
If you're looking to play video,
or if you're looking to, um,

00:24:36.770 --> 00:24:40.690
just blit images to the screen for
one shot images and then discard it,

00:24:40.690 --> 00:24:44.520
a power, uh,
non-Power 2 is actually okay,

00:24:44.680 --> 00:24:48.700
because that's, usually that's very, um,
conducive to the environment that that,

00:24:48.700 --> 00:24:50.090
uh, situation arises.

00:24:50.100 --> 00:24:53.000
So, there are some restrictions
using this extension.

00:24:53.000 --> 00:24:55.890
Uh, the first one is, is that it doesn't
allow mipmap filtering.

00:24:55.890 --> 00:25:00.300
So, so mipmap filtering means that
obviously you have one layer.

00:25:00.300 --> 00:25:02.500
You have the base layer
and there are no filters.

00:25:02.500 --> 00:25:06.500
There are no higher levels of
mipmaps associated with that texture.

00:25:06.560 --> 00:25:08.680
It also doesn't allow GL repeat.

00:25:09.020 --> 00:25:11.300
So, if you were mapping a
texture to a surface,

00:25:11.300 --> 00:25:14.900
it won't allow you to repeat that
continuously across the surface.

00:25:14.970 --> 00:25:17.390
So, it's, again, it's,
it's going to be useful for just

00:25:17.390 --> 00:25:21.400
blitting an image to the screen,
but it's not going to be real useful for,

00:25:21.440 --> 00:25:24.500
uh,
doing generic games or other types of,

00:25:24.730 --> 00:25:28.240
uh, interactive, uh, applications.

00:25:28.710 --> 00:25:32.680
So, these three extensions that I just
went through are the exact three

00:25:32.680 --> 00:25:38.440
extensions that we use to get the Quartz
Extreme to run at optimal performance.

00:25:38.590 --> 00:25:42.700
So, these are the extensions and
the techniques that we use.

00:25:42.700 --> 00:25:45.680
And you'll see, I don't know how many of
you have seen it already,

00:25:45.680 --> 00:25:50.440
but we're able to composite
with deep video compositing

00:25:50.440 --> 00:25:51.540
where we have DVD playing.

00:25:51.540 --> 00:25:55.550
We've got ten terminals over that
are semi-translucent and able

00:25:55.550 --> 00:25:57.620
to maintain decent frame rate.

00:25:57.910 --> 00:25:59.890
We're able to do all the
things you see on the desktop

00:26:00.330 --> 00:26:01.600
using those three extensions.

00:26:01.730 --> 00:26:04.720
So, they're very powerful once
you get those integrated

00:26:04.790 --> 00:26:09.540
correctly into your application,
once you are integrated to a point

00:26:09.540 --> 00:26:13.590
where you're able to run asynchronous
from the graphics processor.

00:26:14.410 --> 00:26:17.970
One last mention about this extension
is the texture coordinates are no

00:26:17.970 --> 00:26:21.800
longer normalized texture coordinates,
they are in textual coordinates.

00:26:22.020 --> 00:26:28.760
So if you are using this extension
you'll have to adjust your

00:26:28.760 --> 00:26:28.760
texture coordinates accordingly.

00:26:29.620 --> 00:26:32.300
Okay, so we're going to run a quick demo.

00:26:32.360 --> 00:26:35.000
If we can switch to demo machine two.

00:26:40.420 --> 00:26:46.150
So, the visual side of this
isn't all that appealing,

00:26:46.150 --> 00:26:47.740
but what we want to do is two things.

00:26:47.740 --> 00:26:51.640
We want to show the CPU monitor and
the effect that these extensions have

00:26:51.640 --> 00:26:55.500
both on performance and CPU usage.

00:27:02.860 --> 00:27:05.140
So I have three check boxes here.

00:27:05.280 --> 00:27:08.100
Each of these check boxes basically
represents one of the extensions

00:27:08.100 --> 00:27:09.580
that I was just talking about.

00:27:09.580 --> 00:27:12.590
So I'm going to turn these off,
and I've got two sliders here.

00:27:12.650 --> 00:27:15.600
The top one represents how
many images I'm paging between,

00:27:15.600 --> 00:27:18.720
so you'll see the number toggling
up there in the middle of the image,

00:27:18.720 --> 00:27:21.050
just to prove to you that
these are different images.

00:27:21.190 --> 00:27:23.960
And they are being uploaded every frame,
so I'm not caching them

00:27:24.050 --> 00:27:25.630
on the graphics card.

00:27:25.630 --> 00:27:29.380
I'm uploading them and
deleting them basically.

00:27:29.380 --> 00:27:33.020
And I've got a frame rate modifier here,
so I can dictate how fast

00:27:33.130 --> 00:27:34.540
I want the frame rate to go.

00:27:34.610 --> 00:27:36.440
So let's just crank
everything up to the maximum,

00:27:36.440 --> 00:27:37.820
turn all the extensions off.

00:27:37.850 --> 00:27:43.510
So what you'll see is that I'm basically
consuming 100% of one of the CPUs.

00:27:43.510 --> 00:27:45.050
So that's as fast as I can go.

00:27:45.050 --> 00:27:49.930
I'm pretty much CPU limited,
and I'm pegged at 22 frames a second,

00:27:49.930 --> 00:27:52.610
a transfer rate of 95 megabytes

00:27:52.960 --> 00:27:54.000
So there's two bad things about this.

00:27:54.000 --> 00:27:57.980
One is I'm consuming a CPU,
which means that I'm taking

00:27:58.040 --> 00:28:00.090
that away from what your
application could be using.

00:28:00.200 --> 00:28:03.640
And the second bad thing is that
I'm only getting 22 frames a second.

00:28:03.730 --> 00:28:05.900
Obviously if I'm bleeding an image,
I'd like to be a little

00:28:05.900 --> 00:28:07.340
bit better than that.

00:28:07.500 --> 00:28:09.590
So let's do a couple things.

00:28:09.710 --> 00:28:11.830
Let's turn on the client storage,
which was the first

00:28:11.840 --> 00:28:13.360
extension I mentioned.

00:28:13.460 --> 00:28:15.690
So you'll see that we went
from 22 frames a second,

00:28:15.690 --> 00:28:18.680
95 megabytes a second,
up to 152 megabytes a second.

00:28:18.840 --> 00:28:22.480
So right there we got about
50% speed improvement.

00:28:22.850 --> 00:28:42.510
But we've noticed that
CPU burden is unchanged.

00:28:42.510 --> 00:28:42.510
So again,
we're still making a copy of the data.

00:28:42.510 --> 00:28:42.510
So as you remember, we have two copies.

00:28:42.510 --> 00:28:42.510
That eliminated one of the copies.

00:28:42.510 --> 00:28:42.510
We still have one copy we're making,
so we're still CPU limited.

00:28:42.510 --> 00:28:42.510
We're using the CPU to make a copy
and that's the limiting factor here.

00:28:42.510 --> 00:28:42.510
So let's turn on some more
extensions and see what happens here.

00:28:43.130 --> 00:28:48.540
So now if we turn on texture rectangle,
we go to 210 megabytes a second.

00:28:48.640 --> 00:28:51.280
So there we got about another
30% speed improvement.

00:28:51.340 --> 00:28:53.800
And that was simply from
the fact that this is a more

00:28:53.800 --> 00:28:56.300
optimal path through the driver.

00:28:57.780 --> 00:28:59.230
So now the last thing we're
going to do is we're going to

00:28:59.240 --> 00:29:00.860
turn on the third extension.

00:29:00.930 --> 00:29:04.700
And once we turn them all on,
good things happen.

00:29:04.850 --> 00:29:09.730
So you'll see that immediately
the CPU burden went down.

00:29:10.100 --> 00:29:14.600
And the frame rate went up and now
we're pushing 350 megabytes a second.

00:29:14.740 --> 00:29:20.490
So we're using hardly any CPU usage and
now we're pushing 350 megabytes a second.

00:29:21.100 --> 00:29:22.850
And the reason is,
is that we're not making

00:29:22.850 --> 00:29:25.400
any copies with the CPU,
we're running asynchronous

00:29:25.400 --> 00:29:29.120
to the graphics card,
we're only synchronizing when we have to.

00:29:29.170 --> 00:29:30.280
So there's a couple things about this.

00:29:30.440 --> 00:29:32.040
One is that I'm overdriving the system.

00:29:32.040 --> 00:29:36.220
I'm telling it I want 150 frames
a second here on my slider.

00:29:36.220 --> 00:29:37.860
That's not very reasonable.

00:29:37.860 --> 00:29:41.180
If we dial it down to something that
would probably be more realistic.

00:29:41.180 --> 00:29:45.440
Let's say I want to push almost
the refresh rate of the monitor,

00:29:45.440 --> 00:29:47.390
let's say about 50 frames a second.

00:29:47.400 --> 00:29:51.020
So you'll see the CPU usage,
the little we were using,

00:29:51.020 --> 00:29:51.940
dropped even further.

00:29:51.940 --> 00:29:56.390
Once we stopped overdriving it
and forcing the CPU to block

00:29:56.390 --> 00:29:58.180
against the graphics card.

00:29:59.250 --> 00:30:04.680
And the last thing I want to mention
about this is the reason I have the

00:30:04.680 --> 00:30:05.660
number of buffers I have up here.

00:30:05.660 --> 00:30:06.170
I have five.

00:30:06.180 --> 00:30:08.620
So five isn't all that interesting,
it turns out.

00:30:09.020 --> 00:30:11.390
But at least having two is.

00:30:11.440 --> 00:30:14.990
So now I'm toggling between
texture zero and one.

00:30:15.000 --> 00:30:17.300
And you'll see that the,
if I pump it back up

00:30:17.440 --> 00:30:20.270
to overdriving again,
the performance didn't change.

00:30:20.280 --> 00:30:24.140
So I could go from here, which is 355,
up to here.

00:30:24.140 --> 00:30:25.070
It's unchanged.

00:30:25.080 --> 00:30:28.520
The interesting thing about
this is if I go down to,

00:30:29.160 --> 00:30:33.090
uh... a single buffer
now driving the system

00:30:33.180 --> 00:30:36.260
Then I drop down to 250 megabytes
a second instead of 350.

00:30:36.260 --> 00:30:40.260
The reason is, is that,

00:30:40.770 --> 00:30:44.300
The double buffering allows me to operate
more asynchronous to the graphics card.

00:30:44.460 --> 00:30:46.770
So as the graphics card
is reading one buffer,

00:30:46.810 --> 00:30:48.040
I'm updating the other, right?

00:30:48.040 --> 00:30:51.330
So I'm ping-ponging back and forth,
giving the graphics card time

00:30:51.440 --> 00:30:54.200
to read the data while I'm
working on the other data set.

00:30:54.410 --> 00:30:56.940
So you can get some benefit
by double buffering.

00:30:56.940 --> 00:30:58.540
You don't necessarily have to.

00:30:58.660 --> 00:31:01.400
There's still a benefit,
a very large benefit to

00:31:01.910 --> 00:31:03.460
going with a single buffer.

00:31:03.460 --> 00:31:06.140
And again, once I dial it down and not,
don't overdrive it.

00:31:06.440 --> 00:31:10.680
You can still see I'm
not using CPU very much.

00:31:10.700 --> 00:31:12.650
I'm getting good transfer rate.

00:31:12.920 --> 00:31:17.420
And in fact, the lower you dial it down,
that also gives it time for the

00:31:17.420 --> 00:31:19.700
graphics card time to upload the data.

00:31:19.700 --> 00:31:23.100
So I'm not hitting up against the
graphics card and stalling against it.

00:31:23.290 --> 00:31:26.940
So this demo kind of shows the
benefit that the combination

00:31:26.940 --> 00:31:29.010
of those three extensions has.

00:31:29.130 --> 00:31:32.340
And how,
basically how big of a performance

00:31:32.340 --> 00:31:36.940
gain you can get by using at
least some combination of these.

00:31:36.940 --> 00:31:38.260
You don't have to
necessarily use all three.

00:31:38.260 --> 00:31:40.140
Each one has its own benefit.

00:31:40.160 --> 00:31:43.530
But the combination of three together
gives you the maximum benefit.

00:31:43.540 --> 00:31:50.840
Okay, can you switch back slides?

00:31:59.000 --> 00:32:01.130
We're going to jump off that
topic and we're going to get into

00:32:01.140 --> 00:32:04.040
Vertex pipeline a little bit.

00:32:04.170 --> 00:32:06.270
So the Vertex pipeline,
I like to think of it as

00:32:06.450 --> 00:32:09.740
having two distinct paths that
can go through the system.

00:32:09.840 --> 00:32:13.490
We have the medium of path,
which is the top flow chart there,

00:32:13.490 --> 00:32:16.940
and we have the Vertex array path,
which is the bottom chart.

00:32:18.450 --> 00:32:21.840
The immediate mode path
has an immediate penalty,

00:32:21.890 --> 00:32:25.510
basically,
built into it where any data you pass in,

00:32:25.510 --> 00:32:28.540
fundamentally, we're going to have to
retain a copy of it.

00:32:28.550 --> 00:32:30.400
So, you'll notice in the OpenGL API,
I'm not sure how

00:32:30.400 --> 00:32:32.990
familiar you are with it,
but you can retrieve the current color,

00:32:32.990 --> 00:32:35.010
current texture coordinate,
current normals.

00:32:35.010 --> 00:32:37.040
You can retrieve that
data back out of the API.

00:32:37.040 --> 00:32:39.930
So, that means we have to have it
somewhere where you can get to it.

00:32:39.930 --> 00:32:42.370
So, the first thing we have to do
when you pass in our normal

00:32:42.370 --> 00:32:44.710
color or texture coordinate,
we have to save it.

00:32:44.710 --> 00:32:48.140
We have to keep it there because we're
not sure in the medium mode path,

00:32:48.140 --> 00:32:51.160
we're not sure what the
next call is in the stream.

00:32:51.170 --> 00:32:54.300
You may be done there and the next thing
you may do is you may ask for it back.

00:32:54.500 --> 00:32:57.960
So, we have to have it somewhere where we
can retrieve it and give it back to you.

00:32:57.960 --> 00:32:59.940
So,
that's a penalty of the immediate mode.

00:33:00.060 --> 00:33:02.510
Then, we have to take that copy and
we push it on the command stream

00:33:02.610 --> 00:33:04.130
for the graphics card to consume.

00:33:04.260 --> 00:33:07.110
So, right there's two copies
just like textures.

00:33:07.170 --> 00:33:10.810
We have to save it in the current
state and have it in a location

00:33:10.810 --> 00:33:14.450
where we can retrieve it as
well as copy it into a command,

00:33:14.450 --> 00:33:17.040
into a hardware specific format.

00:33:17.100 --> 00:33:20.240
Whereas vertex arrays give you the
immediate benefit where you're giving us

00:33:20.240 --> 00:33:24.410
an entire stream of the data and in fact,
the definition of vertex arrays

00:33:24.410 --> 00:33:27.540
in OpenGL is that the current
state of the normal color and

00:33:27.540 --> 00:33:31.000
texture coordinates are undefined
after the operation is completed.

00:33:31.040 --> 00:33:33.920
So, if you pass us a vertex
array for drawing,

00:33:33.920 --> 00:33:37.630
the definition is that it is
undefined after that's completed.

00:33:37.630 --> 00:33:39.100
So, we don't make a copy of it at all.

00:33:39.100 --> 00:33:40.280
So, we never retain it.

00:33:40.280 --> 00:33:44.670
If you ask for it back,
it'll be undefined what you get.

00:33:46.650 --> 00:33:49.900
Okay,
so let's go over some basics of how we

00:33:49.900 --> 00:33:52.730
would go about optimizing this path.

00:33:53.060 --> 00:33:55.000
The first thing we would do
is we would try to avoid the

00:33:55.000 --> 00:33:56.590
medium of path altogether.

00:33:56.610 --> 00:33:58.590
That's a path that is just not optimal.

00:33:58.620 --> 00:34:00.340
It never will be as
optimal as it could be.

00:34:01.060 --> 00:34:03.060
Maximize the,
so if you're stuck on that path,

00:34:03.180 --> 00:34:03.900
let's just talk about that.

00:34:04.000 --> 00:34:06.520
Maximize the number of
vertices per begin in.

00:34:06.600 --> 00:34:09.890
So what you want to do is you
want to pack as many vertices

00:34:09.890 --> 00:34:11.940
between begin in as possible.

00:34:11.940 --> 00:34:14.090
And we'll go over a code example
of that in just a second.

00:34:14.090 --> 00:34:16.070
Use efficient primitive types.

00:34:16.400 --> 00:34:16.580
So use efficient primitive types.

00:34:16.720 --> 00:34:18.250
Use triangle strips, quad strips.

00:34:18.250 --> 00:34:20.640
That reduces the number
of vertices per primitive,

00:34:20.680 --> 00:34:21.700
giving you more efficiency.

00:34:21.700 --> 00:34:24.470
And use AGL macros and CGL macros dot H.

00:34:24.530 --> 00:34:27.820
I'm not going to talk about those much,
but what those do is those allow you to

00:34:27.820 --> 00:34:30.940
drill down into the OpenGL API slightly,
down a layer underneath

00:34:30.940 --> 00:34:33.030
our top level framework,
and it reduces the

00:34:33.030 --> 00:34:34.500
function call overhead.

00:34:34.500 --> 00:34:39.420
It also removes some of the
lookups of the current context.

00:34:39.470 --> 00:34:41.640
So if you're interested,
write those down.

00:34:41.640 --> 00:34:44.140
If you're using the medium of path,
look at those.

00:34:44.670 --> 00:34:49.040
Those macros, those files,
if you utilize those,

00:34:49.410 --> 00:34:51.680
those can give you about
a 20% speed improvement.

00:34:51.710 --> 00:34:55.370
So you're spending a lot of
time in function calls when

00:34:55.530 --> 00:34:58.340
you're in the medium of path,
and those will show you how much.

00:34:58.370 --> 00:35:02.490
Okay, so some extensions of how
we optimize this path.

00:35:02.490 --> 00:35:05.490
So you'll see there's a little
new jelly button up there.

00:35:05.680 --> 00:35:10.290
GL apple vertex array range,
we've talked about a little bit already.

00:35:10.380 --> 00:35:15.460
It's similar to the texture array range,
texture range extension,

00:35:15.460 --> 00:35:18.500
where you are basically
giving us a pointer to memory.

00:35:18.500 --> 00:35:20.940
We are taking that pointer
of a specified format,

00:35:20.940 --> 00:35:23.240
we're mapping it in AGP,
and then we're allowing

00:35:23.240 --> 00:35:25.590
you to dump data into that,
and we're going to tell the graphics

00:35:25.740 --> 00:35:29.320
card to spool it directly using a
DMA engine up to the graphics card.

00:35:29.320 --> 00:35:31.460
CP will not make a copy of that.

00:35:31.510 --> 00:35:33.160
So there are some restrictions.

00:35:33.160 --> 00:35:36.420
You want to use it if available,
but the restrictions are that it requires

00:35:36.420 --> 00:35:39.740
the graphics card to do transform
clipping and lighting and hardware.

00:35:39.810 --> 00:35:41.740
So if the graphics card
doesn't have that capability,

00:35:41.740 --> 00:35:44.530
we can't give you this extension.

00:35:44.540 --> 00:35:46.540
Because obviously if you're
using a graphics card,

00:35:46.570 --> 00:35:49.540
if the idea is to not have
the CPU touch the data,

00:35:49.540 --> 00:35:52.310
the graphics card better be
able to do all the operations

00:35:52.310 --> 00:35:54.590
required for that data set.

00:35:55.180 --> 00:35:59.020
So briefly, again,
what it does is that this is a

00:35:59.020 --> 00:36:02.710
process of you handing us memory,
just like in textures,

00:36:02.830 --> 00:36:05.160
we dynamically map that
memory into AGP space.

00:36:05.200 --> 00:36:12.500
It's, it's, in OS X, we have a built-in
technology such that you can,

00:36:12.500 --> 00:36:18.180
that we can map dispersed areas of
memory into AGP and maintain those,

00:36:18.180 --> 00:36:22.800
and these, these memory regions can
reside in the client's memory,

00:36:22.900 --> 00:36:27.060
they can reside in the driver, reside in,
just about anywhere, and we manage those,

00:36:27.060 --> 00:36:28.810
mapping them, unmapping them.

00:36:28.820 --> 00:36:32.150
So again,
just like in the texture range extension,

00:36:32.180 --> 00:36:36.270
we have to provide a synchronization
mechanism to applications such that

00:36:36.400 --> 00:36:39.810
if you are writing on the data,
you can have a mechanism for determining

00:36:39.810 --> 00:36:42.580
if the graphics card is completed reading
the data before you touch it again.

00:36:44.630 --> 00:36:48.160
So another extension is
the vertex array object.

00:36:48.160 --> 00:36:49.200
This is fairly simple.

00:36:49.300 --> 00:36:52.500
It gives you the same level
of functionality as texture

00:36:52.500 --> 00:36:54.140
objects provide for textures.

00:36:54.260 --> 00:36:58.830
So it's a parallel of that analogy
such that you can have multiple texture

00:36:58.830 --> 00:37:04.840
arranged objects and each object
can have its own AGP mapping region.

00:37:05.000 --> 00:37:10.610
So it allows you to give a parallel
paradigm to texture objects.

00:37:11.150 --> 00:37:12.370
Okay, so compile vertex array.

00:37:12.530 --> 00:37:16.100
This was last year's
winner for performance.

00:37:16.100 --> 00:37:18.600
And now we're demoting it to number two.

00:37:18.770 --> 00:37:21.760
So you only want to use
this path if the range,

00:37:22.010 --> 00:37:24.540
array range extension is not offered.

00:37:24.690 --> 00:37:28.950
So this one is still going to be
the fastest path for non-TCL cards.

00:37:29.090 --> 00:37:34.780
and you'll want to use the array
range extension if it's available.

00:37:36.630 --> 00:37:38.860
So let's go through a quick code example.

00:37:39.010 --> 00:37:42.730
So this code example just
starts off with a piece of code,

00:37:42.750 --> 00:37:44.430
um,
and what we're going to do is we're going

00:37:44.430 --> 00:37:47.410
to walk through trying to optimize it and
see what kind of steps people should take

00:37:47.410 --> 00:37:49.300
when they look at optimizing their code.

00:37:49.430 --> 00:37:51.660
So here it looks, average piece of code.

00:37:51.790 --> 00:37:52.980
What we're going to do is,
the first thing we

00:37:52.980 --> 00:37:55.360
notice is that the state,
uh, is static.

00:37:55.490 --> 00:37:58.040
It doesn't change, uh,
every time through the loop.

00:37:58.040 --> 00:37:59.240
It's static.

00:37:59.240 --> 00:38:01.610
So let's remove the state
change out of the loop,

00:38:01.610 --> 00:38:05.670
and, uh, save the graphics pipeline from
having to thrash the state.

00:38:05.980 --> 00:38:07.500
Because what we don't do
in the graphics car- uh,

00:38:07.500 --> 00:38:10.520
driver is we don't examine
whether the state really changed.

00:38:10.630 --> 00:38:13.620
We assume that you're doing your
job of only sending us state

00:38:13.620 --> 00:38:14.860
changes when they've changed.

00:38:14.950 --> 00:38:17.260
So we make the assumption that
if you change a piece of state,

00:38:17.260 --> 00:38:18.660
that's different than the last time.

00:38:18.760 --> 00:38:19.820
We don't check.

00:38:19.930 --> 00:38:22.880
So let's move it out of there,
let's do our job on the application

00:38:22.890 --> 00:38:26.730
side and get that state changed,
uh, to an appropriate level

00:38:26.730 --> 00:38:28.160
in the-in the for loop.

00:38:28.320 --> 00:38:32.340
So the next thing that we do is we
notice that we're passing triangles,

00:38:32.340 --> 00:38:34.600
but we're only passing one
triangle per loop through the,

00:38:34.600 --> 00:38:35.130
uh, through the for loop.

00:38:35.290 --> 00:38:38.320
So what we want to do is we
want to move that begin end pair

00:38:38.320 --> 00:38:42.200
outside the for loop and get,
uh, as many vertices per

00:38:42.330 --> 00:38:44.400
begin end pair as we can.

00:38:44.680 --> 00:38:47.820
Next thing we want to do is we
want to simplify the data types.

00:38:47.960 --> 00:38:51.410
So we were passing through
a double form of the color.

00:38:51.520 --> 00:38:53.590
Um, OpenGL is not going to want doubles.

00:38:53.660 --> 00:38:54.720
It's going to want floats.

00:38:54.950 --> 00:38:58.300
So, uh, let's just pass natively floats
through the system and not cause us

00:38:58.330 --> 00:39:00.110
to do double the float conversion.

00:39:00.200 --> 00:39:03.230
Uh, the second thing we did here is we
passed through a vector form of the

00:39:03.230 --> 00:39:04.580
vertex instead of individual conversion.

00:39:04.580 --> 00:39:06.680
of individual components.

00:39:06.770 --> 00:39:08.780
Slightly more optimal.

00:39:09.730 --> 00:39:11.850
So the next thing we do,
like I said in my slides,

00:39:11.860 --> 00:39:14.940
we want to use optimal primitive types.

00:39:14.940 --> 00:39:19.300
So we change from a triangle,
individual triangles to a triangle strip.

00:39:19.400 --> 00:39:22.740
So now you'll see that we've
basically eliminated the number

00:39:22.740 --> 00:39:25.440
of vertex calls by factor three.

00:39:25.540 --> 00:39:29.090
So we're going to get significantly
better bandwidth doing that.

00:39:29.980 --> 00:39:34.980
Now, what we would like to be able to
do is be able to use vertex arrays.

00:39:35.260 --> 00:39:37.970
So, I've looked in my code and I said,
well, you know what,

00:39:37.980 --> 00:39:38.970
this is just an array of data.

00:39:38.970 --> 00:39:40.650
I can pass it through a vertex array.

00:39:40.650 --> 00:39:42.570
I can eliminate the for loop altogether.

00:39:42.690 --> 00:39:45.430
Basically, what this does is it moves
the for loop into OpenGL.

00:39:45.460 --> 00:39:48.830
It allows us to optimize
around the for loop inside,

00:39:49.040 --> 00:39:51.680
internal to OpenGL.

00:39:51.680 --> 00:39:54.310
And the last thing I do is
I use vertex array range to,

00:39:54.390 --> 00:39:57.060
to get the maximum bandwidth
through the system.

00:39:57.110 --> 00:40:00.390
So, the previous slide showed
using vertex arrays.

00:40:00.390 --> 00:40:06.060
Now, I add in the three calls to enable
and define the pointer to OpenGL,

00:40:06.210 --> 00:40:07.300
setting up the vertex array range.

00:40:07.300 --> 00:40:10.910
Now, the one thing I don't show in this
slide is the fact that you don't want

00:40:10.920 --> 00:40:12.300
to be doing all these calls every time.

00:40:12.300 --> 00:40:14.290
Like, for instance,
I'm doing a vertex pointer and

00:40:14.840 --> 00:40:17.680
enabling some state and setting
up the vertex array range.

00:40:18.030 --> 00:40:20.160
Ideally, you want to do this
as little as possible,

00:40:20.160 --> 00:40:22.240
just like,
like the other examples of moving

00:40:22.240 --> 00:40:23.670
things out of the for loops.

00:40:23.670 --> 00:40:26.400
So, what you would like to do is
set this up potentially once

00:40:26.400 --> 00:40:29.100
somewhere in your application and
then draw from it multiple times.

00:40:29.180 --> 00:40:32.900
Use draw elements multiple times,
or draw arrays multiple times

00:40:32.950 --> 00:40:34.170
to get the drawing command.

00:40:34.180 --> 00:40:37.300
Okay, so let's show a quick demo of that.

00:40:37.910 --> 00:40:40.490
So we can go to demo machine two.

00:40:40.490 --> 00:40:40.490
And we're

00:40:43.300 --> 00:40:48.670
Okay, so again we have a,
this is a demo that I used last year,

00:40:48.740 --> 00:40:52.600
so if anyone was here,
we're going to show this.

00:40:52.600 --> 00:40:52.600
So,

00:40:52.940 --> 00:40:55.310
What I've got is I've got a slider
that goes up the different levels

00:40:55.310 --> 00:40:57.140
of optimization that I just showed.

00:40:57.300 --> 00:41:00.500
So the bottom one is doing the
individual triangles very slow.

00:41:00.610 --> 00:41:04.300
You can see we're only getting
about 690,000 triangles a second.

00:41:04.450 --> 00:41:09.180
This next notch up shows moving the
begin and pair outside of the for loop

00:41:09.180 --> 00:41:11.300
using a more optimized primitive type.

00:41:11.420 --> 00:41:14.400
So you can see that we almost doubled,
about doubled in performance

00:41:14.800 --> 00:41:15.710
just by doing that.

00:41:15.890 --> 00:41:19.140
So that was a significant
benefit to OpenGL.

00:41:19.330 --> 00:41:23.220
This notch here, and each time,
by the way, you can see the color coding

00:41:23.220 --> 00:41:25.010
of where time's being spent.

00:41:25.130 --> 00:41:26.480
I guess I should have
mentioned that before.

00:41:26.690 --> 00:41:30.900
The red is where time's being spent
elsewhere outside the application.

00:41:30.900 --> 00:41:33.800
The green is time being spent
calculating the wave and blue

00:41:33.800 --> 00:41:35.240
is the time spent in OpenGL.

00:41:35.310 --> 00:41:38.670
So it's our job as the
OpenGL team to minimize the blue.

00:41:38.880 --> 00:41:40.680
So we're giving you techniques
to minimize the blue.

00:41:40.680 --> 00:41:43.140
It's your job to minimize
the red and the green.

00:41:43.140 --> 00:41:45.140
So we've gone to draw arrays.

00:41:45.140 --> 00:41:46.140
We've gotten a little
bit better performance.

00:41:46.140 --> 00:41:49.140
We went from 1.4 million triangles
a second to about 1.5 million.

00:41:49.140 --> 00:41:51.970
This top notch is vertex array range.

00:41:52.110 --> 00:41:55.990
So now using vertex array range,
you can see the time spent in

00:41:55.990 --> 00:41:58.380
OpenGL has gone down substantially.

00:41:58.380 --> 00:42:03.450
And we've gone from basically 1.7 million
triangles a second to almost 5 million.

00:42:03.870 --> 00:42:07.900
So, the next thing obviously to do
is to utilize the fact that we

00:42:07.970 --> 00:42:09.800
have multiple CPUs on this system.

00:42:09.800 --> 00:42:12.940
So now we're pushing about 10
million triangles a second.

00:42:12.940 --> 00:42:15.860
Um, and we, remember we started off
at about a half a million.

00:42:16.230 --> 00:42:19.860
So, that's about, um,

00:42:21.720 --> 00:42:23.440
You know,
that's 20 times the speed improvement

00:42:23.600 --> 00:42:25.990
just by using these extensions.

00:42:26.060 --> 00:42:27.560
There's no change in the
algorithms elsewhere,

00:42:27.710 --> 00:42:28.800
just in how it's driving OpenGL.

00:42:28.800 --> 00:42:33.110
So let's switch back slides.

00:42:39.530 --> 00:42:40.130
Okay, Apple Fence.

00:42:40.210 --> 00:42:41.740
So I've been mentioning
that here and there.

00:42:41.840 --> 00:42:43.330
We'll just briefly talk about it.

00:42:43.340 --> 00:42:46.320
I'm not going to go into
all the details of using it.

00:42:46.400 --> 00:42:49.340
We've got some other things we want to
show and we want to have time to do that.

00:42:49.430 --> 00:42:51.760
So Apple Fence provides
synchronization tokens for putting

00:42:51.760 --> 00:42:55.390
into the OpenGL command stream to
allow you to synchronize with these

00:42:55.400 --> 00:42:58.550
different extensions that will
require you to talk to the graphics

00:42:58.760 --> 00:43:00.600
card and determine when it's done.

00:43:00.680 --> 00:43:01.640
So there's two ways to do it.

00:43:01.710 --> 00:43:03.400
You can do it synchronously
or asynchronously.

00:43:03.400 --> 00:43:07.100
There's a call that you can call and say,
I'm waiting for this token.

00:43:07.100 --> 00:43:09.430
Please don't return until
you have completed that.

00:43:09.520 --> 00:43:12.310
Or you can do it asynchronously
where you can query and say,

00:43:12.310 --> 00:43:13.080
are you done?

00:43:13.080 --> 00:43:15.900
And if it says no, maybe you can go off
and do some other work.

00:43:16.000 --> 00:43:18.270
So if there's a possibility
you have something better

00:43:18.270 --> 00:43:20.880
to be doing with your time,
you can go do that with the CPU.

00:43:22.330 --> 00:43:27.160
So, the other uses for this is there,
it does provide a mechanism for

00:43:27.160 --> 00:43:28.470
synchronizing between threads.

00:43:28.510 --> 00:43:30.700
So it is a general
synchronization mechanism.

00:43:30.800 --> 00:43:34.180
So if you have multiple threads that
are looking to perform an operation,

00:43:34.280 --> 00:43:37.410
you can start looking at,
at this extension as a way to talk

00:43:37.490 --> 00:43:41.780
between threads for synchronizing,
um, operations between threads.

00:43:42.170 --> 00:43:44.820
And again,
you'll want to use this for synchronizing

00:43:44.820 --> 00:43:46.410
vertex and texture range operations.

00:43:48.080 --> 00:43:48.670
So using threads.

00:43:48.740 --> 00:43:54.840
Loading textures in a second thread is
one possible use of threads in OpenGL.

00:43:54.840 --> 00:43:57.400
In a second,
I'll show a brief example of that.

00:43:57.490 --> 00:44:02.560
But one benefit of that is you can have
two shared contexts talking to a single

00:44:02.560 --> 00:44:04.680
pipeline through the OpenGL stream.

00:44:04.680 --> 00:44:07.880
And you can use one thread, for instance,
for loading those textures,

00:44:07.880 --> 00:44:09.350
and another thread for drawing.

00:44:09.360 --> 00:44:14.220
And then start utilizing the preemptive
nature of our operating system to flatten

00:44:14.740 --> 00:44:17.430
out the time spent in a given operation.

00:44:18.850 --> 00:44:21.470
So the--

00:44:22.310 --> 00:44:25.120
So what you don't want to do,
the danger of using threads is that

00:44:25.550 --> 00:44:30.540
people immediately want to start calling
a single context from multiple threads.

00:44:30.670 --> 00:44:33.900
While we do allow that,
there's a danger with that and that is

00:44:33.950 --> 00:44:37.430
if you have two threads without careful
synchronization between those threads

00:44:37.630 --> 00:44:41.350
talking to a single OpenGL context,
you'll crash your application because

00:44:41.350 --> 00:44:44.760
what happens is you'll be poking data
into the OpenGL stream and confusing

00:44:44.840 --> 00:44:48.950
the OpenGL engine from multiple threads,
contaminating the command stream

00:44:49.110 --> 00:44:51.200
and bringing the system down.

00:44:51.360 --> 00:44:57.110
So just a note about threads, that's not,
if you do want to drive multiple threads,

00:44:57.220 --> 00:44:59.170
be very cautious how you do it.

00:44:59.210 --> 00:45:01.300
You can get yourself in trouble.

00:45:01.450 --> 00:45:04.740
Okay, so a brief diagram here.

00:45:04.740 --> 00:45:07.510
So what I was talking about
before was using two contexts,

00:45:07.690 --> 00:45:08.430
two threads.

00:45:08.540 --> 00:45:11.840
These contexts in this diagram
are set up to share textures so

00:45:11.860 --> 00:45:14.730
that one context can be loading
textures while the other is drawing.

00:45:14.820 --> 00:45:18.050
And it looks basically
like this where the,

00:45:18.280 --> 00:45:21.920
the texture is cached into the context
through the first thread and then

00:45:21.920 --> 00:45:24.240
utilized and drawn by the second thread.

00:45:24.330 --> 00:45:27.160
And let's do a,
let's do a quick demo of that.

00:45:27.510 --> 00:45:30.510
So if we can go to demo machine two.

00:45:38.180 --> 00:45:42.900
So this is also a demo that I did
last year and I felt it was important

00:45:42.900 --> 00:45:45.100
enough to leave it in the material.

00:45:45.240 --> 00:45:51.240
So what this does is, is a,
something similar to a screen saver.

00:45:51.280 --> 00:45:53.020
In fact,
let's just kill the CPU monitor here.

00:45:53.020 --> 00:45:56.400
Let's get it out of the way.

00:45:56.920 --> 00:45:59.920
So what this is doing is if you
were to hear the hard disk in here,

00:45:59.920 --> 00:46:02.430
we have one thread
spooling data off disk,

00:46:02.430 --> 00:46:04.890
decompressing it,
pumping it into the OpenGL stream

00:46:05.050 --> 00:46:06.150
while the other thread's drawing.

00:46:06.160 --> 00:46:10.830
And what this allows us to do is to
keep both CPUs busy with the process

00:46:10.920 --> 00:46:12.560
of getting data to the screen.

00:46:12.560 --> 00:46:16.030
So what you'll see is this is
similar to screensaver on steroids,

00:46:16.180 --> 00:46:17.360
basically, right?

00:46:17.360 --> 00:46:22.480
You can pump up how quickly
you page through the images.

00:46:22.480 --> 00:46:26.260
And again, this is paging this
data off disk real time.

00:46:26.520 --> 00:46:29.570
Spooling through it, displaying it,
and you can see you can get nice

00:46:29.570 --> 00:46:32.390
smooth animations even though
the disk is going nuts over here.

00:46:35.010 --> 00:46:36.640
Okay, let's switch back to slides.

00:46:36.700 --> 00:46:38.800
We're moving kind of quick
because I wanted to save

00:46:38.800 --> 00:46:40.820
some time for the profiler.

00:46:41.090 --> 00:46:43.440
Profiler is a great tool.

00:46:47.990 --> 00:46:50.600
So the OpenGL profiler,
let's get to a good subject here.

00:46:50.710 --> 00:46:51.900
This is a new tool that we're providing.

00:46:51.900 --> 00:46:56.900
It has a lot of powerful features
you'll want to look into and several

00:46:56.900 --> 00:46:58.890
things that it can try to help you with.

00:46:58.950 --> 00:47:00.740
As the name implies,
it can help you profile,

00:47:00.740 --> 00:47:03.430
but it also potentially can
help you debug your application.

00:47:03.560 --> 00:47:08.740
And I'll show you some potential
means of utilizing it for that.

00:47:08.880 --> 00:47:11.490
So one of the things it
does is it provides general

00:47:11.720 --> 00:47:13.740
statistics of OpenGL calls.

00:47:13.820 --> 00:47:15.040
It also provides a call trace.

00:47:15.080 --> 00:47:17.660
So it captures a stream
of your OpenGL commands.

00:47:18.030 --> 00:47:20.890
And you can view that for the
sequence of commands that OpenGL is

00:47:20.890 --> 00:47:23.100
seeing coming from the application.

00:47:23.100 --> 00:47:25.080
The other thing it does is
it has a driver stats window.

00:47:25.230 --> 00:47:28.910
So you can monitor kernel level data
and see what the graphics card's doing.

00:47:29.130 --> 00:47:30.200
There's lots of useful data.

00:47:30.200 --> 00:47:32.270
There's about 25 parameters
you can monitor that are

00:47:32.270 --> 00:47:33.860
kernel level driver data.

00:47:33.890 --> 00:47:40.100
That is a direct view into the driver
level picture of what's going on.

00:47:40.130 --> 00:47:43.840
And the other thing it'll do is it
will allow you to set breakpoints.

00:47:43.960 --> 00:47:47.820
So for instance,
you can say that you can set a breakpoint

00:47:47.820 --> 00:47:50.970
and you can at that breakpoint you can
view the call stack of the application.

00:47:51.100 --> 00:47:53.060
You can also look at the OpenGL state.

00:47:53.060 --> 00:47:55.830
So for instance,
if you're trying to debug something

00:47:56.220 --> 00:48:00.060
or look at the state of OpenGL at
a particular moment in time,

00:48:00.060 --> 00:48:03.850
you can set a breakpoint, stop there,
and examine the contents of the

00:48:03.850 --> 00:48:06.020
OpenGL state machine at that point.

00:48:06.060 --> 00:48:08.910
So the other functionality
it has is you can no op and

00:48:08.910 --> 00:48:11.050
profile any particular function.

00:48:11.140 --> 00:48:13.890
So for instance,
you can go to the OpenGL API and say

00:48:13.980 --> 00:48:16.060
I don't want to call that anymore.

00:48:16.060 --> 00:48:17.780
And you can just hit a no op command
and it'll just turn that off.

00:48:17.780 --> 00:48:21.900
You can also turn off profilings if
you're not interested in a particular

00:48:21.900 --> 00:48:23.780
application or a particular function.

00:48:23.780 --> 00:48:28.630
Maybe it's causing some performance
issues when you're profiling it.

00:48:28.630 --> 00:48:32.780
You can turn it off and it will free
up profiling that particular function.

00:48:32.780 --> 00:48:35.440
You can also cause it
to force the buffer,

00:48:35.470 --> 00:48:37.500
flush the buffer after drawing.

00:48:37.830 --> 00:48:40.850
So for instance,
it has a flag where you can hook up

00:48:40.900 --> 00:48:45.790
a flush command to any OpenGL drawing
command and it'll flush the back

00:48:46.010 --> 00:48:49.730
buffer to the front and show you the
contents after you draw something.

00:48:49.730 --> 00:48:53.460
So this will allow you to potentially
step through an application and watch one

00:48:53.470 --> 00:48:54.740
item appear at a time in the background.

00:48:54.790 --> 00:48:58.520
So you can step through it and
see the scene being built up.

00:48:58.740 --> 00:49:04.210
So, let's get to another demo
and let's look at that.

00:49:06.530 --> 00:49:08.700
So this is on the Jaguar seed.

00:49:08.740 --> 00:49:12.930
I have a version that's about two
weeks newer than what's on the seed,

00:49:13.050 --> 00:49:14.740
so I'm going to,
it's going to be slightly

00:49:14.740 --> 00:49:17.070
different in a couple cases.

00:49:17.240 --> 00:49:18.500
So let's pull up a simple application.

00:49:18.500 --> 00:49:23.290
So what you do is you choose your
application and you hit launch.

00:49:24.950 --> 00:49:29.020
And now we're going to turn
on a couple effects here.

00:49:29.070 --> 00:49:30.500
Okay, so you've got something going on.

00:49:30.500 --> 00:49:34.600
You've got some strange
chess board going.

00:49:34.630 --> 00:49:36.900
And what you do is you have
this green button here.

00:49:36.970 --> 00:49:41.340
So the green button is just a master
switch for turning profiling on and off.

00:49:41.350 --> 00:49:45.520
So I'm going to click that and I'm
going to start my profiling process.

00:49:45.520 --> 00:49:46.770
Now we've got a number of options here.

00:49:46.930 --> 00:49:48.840
You can see we've got the function stats.

00:49:49.030 --> 00:49:51.080
Like I mentioned, we can collect stats.

00:49:51.080 --> 00:49:52.820
We can capture call trace.

00:49:52.820 --> 00:49:54.630
That's what this button is.

00:49:54.630 --> 00:49:56.250
And we can force flush.

00:49:56.360 --> 00:49:57.840
So we can do these independently.

00:49:57.990 --> 00:50:01.020
One thing to remember with the profiler,
it is performance invasive.

00:50:01.040 --> 00:50:04.180
If you have a lot of function
calls going through the system,

00:50:04.300 --> 00:50:06.990
it will induce a slight overhead
to those function calls.

00:50:07.100 --> 00:50:09.280
If you're using an immediate
mode function path,

00:50:09.310 --> 00:50:12.290
it can actually start
inducing quite a bit.

00:50:12.320 --> 00:50:17.410
So you'll want to potentially turn things
on and off if you're seeing the profiler

00:50:17.410 --> 00:50:20.140
affecting your application performance.

00:50:20.140 --> 00:50:22.370
So let's look stats real quick.

00:50:22.830 --> 00:50:24.460
So this is what it looks like.

00:50:24.520 --> 00:50:30.080
It's fundamentally a list of all your
function calls going through the system.

00:50:30.150 --> 00:50:33.740
It times them and it tries
to determine where you're

00:50:33.740 --> 00:50:36.730
spending your time in OpenGL.

00:50:36.850 --> 00:50:40.590
So for instance we can see here
that it says we're spending 98%

00:50:40.590 --> 00:50:42.920
of our time in GL call list.

00:50:43.400 --> 00:50:45.760
So let's shrink that
window up a little bit.

00:50:45.760 --> 00:50:48.570
We're only working with a
1024 by 768 display here,

00:50:48.690 --> 00:50:50.840
so we're a little bit cramped for room.

00:50:50.970 --> 00:50:53.800
So let's pull up call trace
just to look at it real quickly.

00:50:54.160 --> 00:50:54.550
So here it is.

00:50:54.640 --> 00:51:01.980
It's just nothing more than the function
calls going through the system and

00:51:03.370 --> 00:51:08.600
Unfortunately, it's not happy with that.

00:51:08.670 --> 00:51:12.640
Okay,
so there you got a quick look at it.

00:51:13.410 --> 00:51:15.940
We're going to start it again.

00:51:16.080 --> 00:51:19.180
So this is still in
development obviously.

00:51:20.650 --> 00:51:24.090
Okay, so let's get back to where we were.

00:51:24.170 --> 00:51:27.970
Let's get the chessboard
doing what we want.

00:51:30.300 --> 00:51:32.300
So let's move it off to the side.

00:51:32.440 --> 00:51:34.140
Let's set these up.

00:51:34.230 --> 00:51:36.800
Okay, so the other thing,
let me just check this other box here.

00:51:36.890 --> 00:51:37.600
So it's force flush.

00:51:37.910 --> 00:51:41.940
So there you see it's swap
buffering many times a frame.

00:51:41.940 --> 00:51:45.340
It's just showing the contents
of the back buffer in real time.

00:51:45.340 --> 00:51:49.290
Not really useful when you're not stopped
and looking at it in a break point.

00:51:49.400 --> 00:51:51.440
Um, frame rate,
there's another button down here

00:51:51.440 --> 00:51:52.440
that will tell you the frame rate.

00:51:52.440 --> 00:51:55.400
So if you have an application
that doesn't list,

00:51:55.400 --> 00:51:57.600
you don't have an explicit frame rate
counter built in the application,

00:51:57.600 --> 00:52:02.440
you can just launch this and use it
to monitor the frame rate right here.

00:52:02.440 --> 00:52:04.460
Okay,
so let's get into usefulness of this.

00:52:04.930 --> 00:52:08.440
Um, so break points.

00:52:08.710 --> 00:52:13.430
So here's a, a, the break point window.

00:52:15.420 --> 00:52:19.640
And what this does,
this isn't the version I was

00:52:19.640 --> 00:52:22.640
wanting to run actually,
I don't know where this came from.

00:52:22.670 --> 00:52:26.280
So what this does is this allows
you to break at any given function.

00:52:26.500 --> 00:52:29.790
It allows you to turn profiling on
and off and it allows you to turn

00:52:29.810 --> 00:52:32.160
off execution of that function.

00:52:32.310 --> 00:52:36.160
So we noticed from the call stats before,
let's pull those back up,

00:52:36.180 --> 00:52:38.700
that we're spending
time in our call list.

00:52:38.770 --> 00:52:39.900
So we'll shrink that back down.

00:52:39.900 --> 00:52:41.200
So we're spending time in call list.

00:52:41.410 --> 00:52:44.110
So let's see just briefly
here what we can do with that.

00:52:46.150 --> 00:52:52.340
So if we tab up, if I can learn to spell,
if we tab up the call list right

00:52:52.840 --> 00:52:55.800
there and we set a breakpoint,
so you can see we're stopped there.

00:52:55.800 --> 00:52:58.110
Now,
one of the useful things you can do there

00:52:58.120 --> 00:53:04.660
is you can set force flush and you can
basically step through your functions,

00:53:04.660 --> 00:53:09.100
your call trees,
and every time you're at a breakpoint,

00:53:09.100 --> 00:53:12.930
what you can do is you can stop and you
can open up the OpenGL state and you can

00:53:12.930 --> 00:53:17.300
look through your state determining if at
that given point your state is correct.

00:53:21.340 --> 00:53:23.380
So the thing that's missing on this
version that I wanted to show you and

00:53:23.490 --> 00:53:26.750
the reason that I wanted to bring a newer
copy here is that there's a tab here

00:53:26.750 --> 00:53:28.640
now and you can look at your call stack.

00:53:28.740 --> 00:53:32.930
So you can look at the OpenGL call stack,
you can look at your state and in

00:53:32.930 --> 00:53:37.350
conjunction with your call trace window,
you can look at how you got there, right?

00:53:37.510 --> 00:53:40.290
So three pieces of information
available at any given

00:53:40.290 --> 00:53:45.170
breakpoint are the call stack,
call trace and the OpenGL state.

00:53:45.210 --> 00:53:47.990
So potentially,
if somebody is having problems with a

00:53:48.040 --> 00:53:53.360
rendering technique you can backtrack
the system and find out why that's there.

00:53:53.820 --> 00:53:55.340
Now, as the name implies,
this is actually most

00:53:55.640 --> 00:53:58.550
useful for profiling,
at least we think it is.

00:53:58.600 --> 00:54:02.460
One of the things that we like
to do when we are profiling an

00:54:02.610 --> 00:54:05.330
application is we just let it run.

00:54:05.340 --> 00:54:09.810
And the first thing we want to do is we
want to... Let's turn off force flush.

00:54:09.920 --> 00:54:12.400
We want to no-op out all the
OpenGL commands and determine how

00:54:12.760 --> 00:54:15.660
fast the application will run if
OpenGL is infinite in performance.

00:54:15.660 --> 00:54:18.400
So what we would do is we
would say execute none.

00:54:18.400 --> 00:54:20.640
So now you'll see that
there's nothing running,

00:54:20.640 --> 00:54:22.360
nothing visually updating here.

00:54:22.910 --> 00:54:26.520
But what we do is we go over here and
we look at the frame rate counter.

00:54:27.400 --> 00:54:31.300
So,
we can see we were graphics card limited.

00:54:31.400 --> 00:54:34.530
This application obviously
is not the bottleneck,

00:54:34.530 --> 00:54:35.170
right?

00:54:36.140 --> 00:54:38.300
So, you know,
I encourage everybody to do that

00:54:38.300 --> 00:54:41.510
because it's good to just see how
fast your application will run without

00:54:41.510 --> 00:54:45.760
OpenGL and get a feel for whether
you can actually blame us or not.

00:54:50.940 --> 00:54:52.670
Okay, so let me turn execute back on.

00:54:52.680 --> 00:54:55.840
Yeah, briefly, this is a powerful tool.

00:54:55.840 --> 00:54:57.240
You all have it on your Jaguar seed.

00:54:57.240 --> 00:54:58.300
Give it a try.

00:54:58.300 --> 00:55:02.340
If you have any suggestions,
tell us about them.

00:55:02.340 --> 00:55:04.300
I'm going to show you
one last thing here,

00:55:04.300 --> 00:55:08.190
which is kind of the no op,
maybe potential use for the no op.

00:55:08.290 --> 00:55:11.660
So if I turn off execution of threads,
I'm sorry, of call list,

00:55:11.740 --> 00:55:13.780
I can see all my pieces went away.

00:55:13.780 --> 00:55:15.010
So those are all being
drawn with call list.

00:55:15.190 --> 00:55:19.580
I turn force flush back on,
and I want to break at GL begin.

00:55:20.200 --> 00:55:22.300
So let's just set a
break point at GL begin.

00:55:22.300 --> 00:55:24.770
And, okay, I'm stopped there.

00:55:24.780 --> 00:55:28.040
So one potential use is you can
sit here and step-by-step go

00:55:28.040 --> 00:55:30.940
through your application and
determine the contents of it.

00:55:30.990 --> 00:55:33.780
So this is a very simplistic application,
obviously,

00:55:33.780 --> 00:55:39.070
but it potentially can give you the
opportunity to see what the back

00:55:39.070 --> 00:55:42.940
buffer of your application has,
what the state is, and debug some of your

00:55:42.940 --> 00:55:44.500
rendering that you're doing.

00:55:49.300 --> 00:55:55.840
I'm going to quit this application and
we're going to go back to the slides.

00:55:55.980 --> 00:55:57.840
Okay, so we're going to wrap up.

00:55:57.980 --> 00:56:01.010
So, briefly,

00:56:01.190 --> 00:56:06.200
the optimization techniques that you
want to use are application dependent,

00:56:06.200 --> 00:56:09.470
so there's a variety of techniques,
depending on your application and

00:56:09.630 --> 00:56:10.940
what you're trying to perform.

00:56:10.940 --> 00:56:13.670
Try to understand where
your bottlenecks are,

00:56:13.820 --> 00:56:16.420
use the OpenGL Profiler,
use Sampler to find where

00:56:16.560 --> 00:56:19.180
you're spending your time,
and apply the available

00:56:19.420 --> 00:56:21.100
extensions to the problem.

00:56:21.100 --> 00:56:22.840
We've got a number of extensions.

00:56:23.070 --> 00:56:26.560
We've got 30 new extensions for
Jaguar that you can look at for

00:56:26.780 --> 00:56:31.070
optimizing your application,
tuning it, getting it to run, grading it,

00:56:31.080 --> 00:56:31.080
etc.

00:56:31.100 --> 00:56:32.970
on macros 10.

00:56:38.710 --> 00:56:42.040
Okay, so for more information,
I suggest everybody buys a copy

00:56:42.040 --> 00:56:47.760
of the OpenGL programming guide
and the OpenGL reference manual.

00:56:47.850 --> 00:56:48.370
These are great books.

00:56:48.470 --> 00:56:49.490
I use them all the time.

00:56:49.580 --> 00:56:51.490
They're always on my desk.

00:56:56.420 --> 00:56:58.150
Okay, the roadmap.

00:56:58.290 --> 00:57:01.830
So, we're a little bit late into the,
into WWDC,

00:57:01.920 --> 00:57:05.720
so we're already through a few of these,
but for reference, once you get back and,

00:57:05.880 --> 00:57:10.030
and want to potentially review some
of the material that was given here,

00:57:10.040 --> 00:57:12.400
we're going to show this again.

00:57:12.400 --> 00:57:16.210
Graphics and Imaging Overview is,
was a great session.

00:57:16.410 --> 00:57:20.320
If you haven't seen a lot about
how to use the graphicsing,

00:57:20.450 --> 00:57:23.880
general graphicsing power of OS X,
some of these sessions will

00:57:23.880 --> 00:57:25.350
be good for you to review.

00:57:25.550 --> 00:57:28.320
So, the second one as well,
Exploring Quartz

00:57:28.320 --> 00:57:32.400
Compositor and Session 504,
Going into OpenGL Graphics Programming.

00:57:32.400 --> 00:57:36.380
That one talked about our OpenGL shader,
uh, application,

00:57:36.490 --> 00:57:40.360
which will help you program, uh,
shaders and, and write code for the

00:57:40.560 --> 00:57:42.610
graphics card and hopefully,
uh, help you do that a

00:57:42.610 --> 00:57:43.400
little more efficiently.

00:57:43.400 --> 00:57:46.350
OpenGL Graphics, uh,
Integrated Graphics 1 went into some

00:57:46.400 --> 00:57:49.220
of the system integration issues,
how to do certain things

00:57:49.230 --> 00:57:52.410
within the operating system,
integrate your code better with the

00:57:52.560 --> 00:57:54.400
operating system and work with it.

00:57:54.400 --> 00:57:57.400
And hopefully, uh, to a better product.

00:57:57.430 --> 00:58:01.170
Integrated Graphics 2, same thing,
went into some of the graphics, uh,

00:58:01.200 --> 00:58:04.380
techniques that are generally applicable
for system integration issues.

00:58:04.400 --> 00:58:09.480
Um, ColorSync, Digital Media, um,
and some game solutions

00:58:09.480 --> 00:58:11.390
at the bottom there.

00:58:13.750 --> 00:58:16.460
Advanced 3D was a session
right before this.

00:58:16.510 --> 00:58:20.260
Hopefully that was useful for people that
saw it on how to put together some of the

00:58:20.260 --> 00:58:24.860
advanced rendering techniques that people
use in NVIDIA and ATI for producing some

00:58:24.860 --> 00:58:26.690
of these amazing demos that they do.

00:58:26.700 --> 00:58:29.700
So 5.14 is the one we're in now.

00:58:29.700 --> 00:58:33.540
And so what we have coming up tomorrow is
graphics and imaging performance tuning

00:58:33.650 --> 00:58:36.700
and graphics and imaging feedback form.

00:58:36.700 --> 00:58:39.700
So if you have any suggestions,
show up at the feedback form tomorrow.

00:58:39.700 --> 00:58:43.770
We'll be there to listen to your
suggestions and hopefully improve

00:58:44.090 --> 00:58:45.570
the product the next time around.

00:58:45.700 --> 00:58:48.700
Well, in fact, even this time around
since you've got Jaguar.

00:58:48.700 --> 00:58:51.430
So I'd like to get
Sergio Mello back up on stage.

00:58:51.580 --> 00:58:54.690
He is a contact point for Apple.

00:58:54.700 --> 00:58:58.270
If you have questions or
suggestions after the feedback form,

00:58:58.270 --> 00:58:59.700
email them to Sergio.

00:58:59.700 --> 00:59:02.690
He will do what he can to help.