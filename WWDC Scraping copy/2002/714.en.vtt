WEBVTT

00:00:00.880 --> 00:00:03.020
So if we could take our seats.

00:00:03.020 --> 00:00:05.980
We'd like to get ready
for the next session.

00:00:09.350 --> 00:00:14.740
This is always a popular
session with a very lively Q&A.

00:00:14.740 --> 00:00:20.500
And so I would like to introduce
Brian Fitzpatrick and Rich Flewelling,

00:00:20.640 --> 00:00:23.310
optimizing WebObjects applications.

00:00:28.580 --> 00:00:30.600
Thanks Bob.

00:00:30.740 --> 00:00:32.930
It's always nice to present
this sort of advanced session.

00:00:32.930 --> 00:00:35.900
We get some people who have been
with WebObjects for quite a while.

00:00:36.030 --> 00:00:38.140
And although some of the
material can be a little bit dry,

00:00:38.140 --> 00:00:41.270
so Rich and I have got a
stack of t-shirts we want to

00:00:41.270 --> 00:00:43.440
give away here for starters.

00:00:43.440 --> 00:00:46.690
And since some of you people have been
with WebObjects for a really long time,

00:00:46.690 --> 00:00:49.190
we're going to start off with
a little question and answer,

00:00:49.190 --> 00:00:50.010
multiple choice.

00:00:50.030 --> 00:00:53.730
So when you see the answer that you think
is the proper answer to this question,

00:00:53.810 --> 00:00:56.660
I want to hear you start clapping
and Rich is going to determine

00:00:56.660 --> 00:00:58.480
who answered the question right.

00:00:58.540 --> 00:00:59.380
And then we're going
to whip out a t-shirt.

00:00:59.480 --> 00:01:05.500
So first, what was the name of the event
where WebObjects was introduced?

00:01:05.500 --> 00:01:08.120
Was it A, Web Hysteria?

00:01:08.120 --> 00:01:10.820
Web Mania?

00:01:13.540 --> 00:01:19.030
Webaholics Anonymous or D, WebWorld.

00:01:20.300 --> 00:01:21.900
I think I only heard one person.

00:01:21.900 --> 00:01:22.400
I heard one.

00:01:22.400 --> 00:01:23.940
I think it might have been in this area.

00:01:23.940 --> 00:01:24.860
The answer is B, WebMania.

00:01:27.030 --> 00:01:28.640
Next question.

00:01:28.770 --> 00:01:30.960
Now this is actually more
related to optimizing your app.

00:01:31.010 --> 00:01:35.600
How many classes load when you
start your WebObjects application?

00:01:37.110 --> 00:01:42.660
1 to 100, 101 to 1,000.

00:01:44.330 --> 00:01:46.520
1001 to 2000.

00:01:46.520 --> 00:01:48.720
All of them.

00:01:51.600 --> 00:01:55.850
Again, the correct answer is C,
1,001 to 2,000 classes.

00:01:55.960 --> 00:01:56.600
Center?

00:01:56.600 --> 00:01:58.110
In the center over there.

00:02:01.010 --> 00:02:06.660
Next question, what's the longest method
name in WebObjects?

00:02:06.700 --> 00:02:11.870
Is it the ever popular add object to
both sides of relationship with key?

00:02:12.270 --> 00:02:13.150
No?

00:02:13.300 --> 00:02:14.450
Is it the delegate method?

00:02:14.450 --> 00:02:18.440
Database context will run login
panel to open database channel.

00:02:21.250 --> 00:02:23.080
is the other delegate method.

00:02:23.100 --> 00:02:28.440
Adapter channels should construct
stored procedure return values.

00:02:28.470 --> 00:02:35.400
Or the often obscure, rarely called,
object store coordinator should wait...

00:02:38.750 --> 00:02:41.290
I'll go ahead and let the
translators catch up on that one.

00:02:41.300 --> 00:02:42.290
I'll go in this section.

00:02:42.290 --> 00:02:44.080
You guys haven't had one yet.

00:02:44.190 --> 00:02:45.100
Oh, empty row.

00:02:45.100 --> 00:02:46.890
Whoever can get it first.

00:02:46.990 --> 00:02:48.000
What's that?

00:02:48.120 --> 00:02:48.800
Whoever can get it first.

00:02:48.800 --> 00:02:49.340
Whoever can get it first?

00:02:49.480 --> 00:02:49.700
Yep.

00:02:49.760 --> 00:02:51.600
Let them fight over it in the back.

00:02:51.740 --> 00:02:54.500
We have two more questions.

00:02:54.630 --> 00:02:57.310
What's in Bob Frazier's backpack?

00:02:57.570 --> 00:03:01.610
Is it A WebObjects marketing plan?

00:03:02.560 --> 00:03:04.400
Is it B, a ham sandwich?

00:03:04.510 --> 00:03:08.920
Is it C, Steve Heyman's shirt?

00:03:11.670 --> 00:03:13.970
Or is it D, another hat?

00:03:13.980 --> 00:03:16.710
What do you think?

00:03:16.720 --> 00:03:17.180
I don't know.

00:03:17.180 --> 00:03:17.560
What do you think?

00:03:17.620 --> 00:03:19.120
I wasn't... I'll go left side here.

00:03:19.140 --> 00:03:20.380
A little bit over there maybe this time?

00:03:20.380 --> 00:03:21.740
Oh!

00:03:21.740 --> 00:03:22.880
Oh!

00:03:22.880 --> 00:03:26.800
And our last question
before we get started.

00:03:26.800 --> 00:03:30.980
What is the most popular
error that EO Modeler throws?

00:03:33.260 --> 00:03:35.720
Is it A, selector not found?

00:03:35.720 --> 00:03:39.840
B, NS internal inconsistency error?

00:03:42.900 --> 00:03:46.880
C, NSMutableArray, index out of bounds.

00:03:46.930 --> 00:03:52.690
Or D, NSBoy, I really hope you saved
this a few minutes ago.

00:03:55.010 --> 00:03:57.260
You've got a pretty good arm there.

00:03:57.290 --> 00:03:58.330
Not bad, huh?

00:03:58.330 --> 00:03:59.360
Not bad at all.

00:03:59.360 --> 00:04:02.930
Now I'm going to turn it over
to Rich Flewelling to talk.

00:04:03.040 --> 00:04:05.990
Let's get you started
on the optimization.

00:04:07.700 --> 00:04:12.340
Okay, so now to bring it down a little
bit and a little bit more cerebral,

00:04:12.340 --> 00:04:12.750
I guess.

00:04:13.050 --> 00:04:16.710
What we're going to talk about today
is to find and eliminate performance

00:04:16.710 --> 00:04:18.880
bottlenecks within your application.

00:04:18.900 --> 00:04:22.750
And the main areas that we're going
to look at is what are the tools that

00:04:22.760 --> 00:04:27.090
WebObjects gives you out of the box to
help you identify any trouble spots.

00:04:27.340 --> 00:04:30.440
If you look at the architecture of
a typical WebObjects application,

00:04:30.440 --> 00:04:34.700
where are some of the bottlenecks
that typically pop up,

00:04:34.700 --> 00:04:37.710
and how can you go about
eliminating those problems?

00:04:43.600 --> 00:04:48.010
So what we'll be doing today is
looking at when is the right time

00:04:48.260 --> 00:04:51.230
within the application development
lifecycle to go about investing

00:04:51.260 --> 00:04:53.240
your time in performance tuning.

00:04:53.240 --> 00:04:57.720
Looking at WoE Event Center which
comes with WebObjects to help you

00:04:57.720 --> 00:05:00.100
go about and tune your application.

00:05:00.120 --> 00:05:03.310
And a third-party tool from
Borland called OptimizeIt that

00:05:03.310 --> 00:05:05.260
also can help you in this regard.

00:05:05.260 --> 00:05:08.230
And we'll also be looking at,
specifically within the

00:05:08.230 --> 00:05:10.910
application server tier,
at the WebObjects and

00:05:10.910 --> 00:05:12.700
EnterpriseObjects frameworks.

00:05:13.500 --> 00:05:18.510
Techniques of using the
software that we give you,

00:05:18.590 --> 00:05:21.400
techniques that help you
improve the overall performance

00:05:21.410 --> 00:05:23.490
of the application server.

00:05:24.150 --> 00:05:26.610
And once you've done all that,
there are times when you actually

00:05:26.610 --> 00:05:30.140
just have to upgrade your hardware
and we'll show you some of the

00:05:30.320 --> 00:05:34.000
Unix utilities that can help you
identify those problems as well.

00:05:36.090 --> 00:05:37.940
So first of all,
when should you start tuning when

00:05:38.210 --> 00:05:40.070
you're developing an application?

00:05:40.080 --> 00:05:43.610
You probably don't want to start tuning
your application early on because you

00:05:43.680 --> 00:05:47.440
really have a bunch of functionality
that the users are looking for to be

00:05:47.470 --> 00:05:50.830
implemented in the system and make
sure that it's functionally stable.

00:05:50.840 --> 00:05:54.780
So functional stability is
the first thing to look for,

00:05:54.780 --> 00:05:58.860
but you shouldn't just go out and develop
functionality without thinking about,

00:05:58.860 --> 00:06:02.920
well, what's a good design to go about
implementing this so you're

00:06:02.970 --> 00:06:06.590
not just fetching things from
a database constantly writing

00:06:06.590 --> 00:06:12.390
to various files on the system,
but do things in a way that will give

00:06:12.820 --> 00:06:17.760
you 80% of that performance that you
need and then go about tuning it once you

00:06:17.890 --> 00:06:19.630
get all the functionality that you want.

00:06:19.890 --> 00:06:26.010
So another key piece is to set your
milestones for what you want your system

00:06:26.080 --> 00:06:28.260
to perform in terms of benchmarks.

00:06:28.450 --> 00:06:33.000
So that way you can go back and
measure and do some optimization,

00:06:33.000 --> 00:06:35.320
measure again, and see the progress that
you're actually making.

00:06:35.320 --> 00:06:38.010
actually making, if any.

00:06:38.850 --> 00:06:43.460
So from the infrastructure
side of the house,

00:06:43.460 --> 00:06:46.860
if you have the luxury of
being able to get enough

00:06:47.250 --> 00:06:50.700
Hardware and software in place
that can actually mirror what

00:06:50.850 --> 00:06:53.560
your deployment environment
would be in a test environment,

00:06:53.560 --> 00:06:55.770
that's the ideal because
that way any changes you make

00:06:55.810 --> 00:06:58.120
in your test environment,
when you roll it to the

00:06:58.120 --> 00:07:01.350
deployment environment,
you'll see the performance

00:07:01.350 --> 00:07:05.120
improvements just like you
saw in the test environment.

00:07:05.120 --> 00:07:07.710
Likewise,
having a test environment allows

00:07:07.710 --> 00:07:11.270
you to eliminate a lot of the
extraneous variables of different

00:07:11.490 --> 00:07:15.290
users hitting your system while
you're going through testing.

00:07:15.300 --> 00:07:18.870
This allows you to isolate
and test for a specific thing.

00:07:21.410 --> 00:07:24.670
On the other side of it,
from the software side of it,

00:07:24.670 --> 00:07:28.280
we mentioned earlier that you should
establish some acceptance criteria.

00:07:28.280 --> 00:07:29.550
And make these concrete.

00:07:29.550 --> 00:07:32.010
Go about and put down some numbers.

00:07:32.020 --> 00:07:35.710
For example, all pages should return
in under half a second.

00:07:35.720 --> 00:07:40.340
And on this BigQuery search that
we're going about and querying,

00:07:40.340 --> 00:07:43.500
the users will accept something in
under 5 seconds or under 10 seconds,

00:07:43.500 --> 00:07:44.710
whatever that number is.

00:07:44.820 --> 00:07:48.090
But put those in your requirements
documents so that you can then test

00:07:48.230 --> 00:07:51.730
for the performance of the system and
come back and verify that your system

00:07:51.770 --> 00:07:53.300
is performing like it should be.

00:07:53.360 --> 00:07:58.210
And then create some test cases
in your system that will allow you

00:07:58.210 --> 00:08:02.110
to exercise these portions of your
application and actually find out if

00:08:02.230 --> 00:08:03.940
you are meeting these criteria or not.

00:08:06.410 --> 00:08:10.200
So we saw this slide earlier,
and this is one of the most complex

00:08:10.280 --> 00:08:13.800
architectures that you could
probably have with a Web application,

00:08:13.840 --> 00:08:16.860
but it really points out all the
different places in this chain that

00:08:16.920 --> 00:08:20.690
can really become the weakest link
for the performance of your system.

00:08:20.700 --> 00:08:24.630
From the time that the user hits
a button on the Web browser and

00:08:24.630 --> 00:08:28.610
the request is sent through,
look at all the different hops

00:08:28.700 --> 00:08:30.680
this request can go through.

00:08:30.760 --> 00:08:34.040
You can go through the Web server tier,
firewalls,

00:08:34.080 --> 00:08:38.260
networks between the various tiers,
through your application instances,

00:08:38.260 --> 00:08:41.410
perform some kind of functionality,
searches out of the database,

00:08:41.410 --> 00:08:42.660
and then the round trip back.

00:08:42.740 --> 00:08:46.680
So what we're going to do in the next
few slides is look at each of these tiers

00:08:46.680 --> 00:08:51.230
and point out a few tips for things that
would help you get the best performance

00:08:51.230 --> 00:08:55.400
out of each of those because ultimately,
wherever your weakest link is in the

00:08:55.400 --> 00:08:58.750
system is going to be the weakest link
for the performance of your system.

00:08:59.120 --> 00:09:03.760
So keeping all these things tuned as
closely to optimal as possible will

00:09:04.080 --> 00:09:05.720
give you the best performance overall.

00:09:07.880 --> 00:09:11.040
So let's look at the browser
or the client desktop that

00:09:11.040 --> 00:09:12.600
your end users are using.

00:09:12.600 --> 00:09:18.300
One of the major factors is
connectivity to the back-end system.

00:09:18.300 --> 00:09:22.260
So are they over a dial-up line
or are they on an internal LAN?

00:09:22.260 --> 00:09:27.100
Are they on some ISP with
a very fast connection?

00:09:27.100 --> 00:09:31.420
Those really have a lot of impact
on just sending the requests

00:09:31.630 --> 00:09:32.660
and receiving the requests.

00:09:32.780 --> 00:09:38.330
But there's also a big performance impact
on what size of the pages are coming back

00:09:38.540 --> 00:09:40.400
to the desktop and what's in those pages.

00:09:40.400 --> 00:09:43.090
For example,
are there many images that then,

00:09:43.180 --> 00:09:47.350
once the HTML is brought to the browser,
the browser has to go out over the same

00:09:47.350 --> 00:09:49.560
connection and pull those things back?

00:09:49.600 --> 00:09:53.110
Is there a bunch of JavaScript that's
embedded in your pages that needs to

00:09:53.110 --> 00:09:55.280
be parsed and processed on the desktop?

00:09:55.280 --> 00:09:59.440
One way to overcome that is
to use cascading style sheets,

00:09:59.480 --> 00:10:02.760
which can really help you
limit the amount of HTML.

00:10:02.780 --> 00:10:07.060
But that also incurs an overhead
with the browser needing to

00:10:07.060 --> 00:10:08.240
parse through those things.

00:10:10.040 --> 00:10:13.680
Likewise,
the hardware on the client side can be

00:10:13.680 --> 00:10:17.460
affected based on what kind of browsers
and plug-ins are being pulled in.

00:10:17.460 --> 00:10:19.120
You might have Flash movies
that are playing.

00:10:19.120 --> 00:10:21.240
You might have QuickTime movies.

00:10:21.240 --> 00:10:25.170
So all these things are factors
down on the client side.

00:10:31.550 --> 00:10:33.920
Overall,
we also need to look at the server

00:10:33.920 --> 00:10:35.790
sizing for each of the boxes.

00:10:35.790 --> 00:10:37.660
And as you know from
computer science classes,

00:10:37.660 --> 00:10:42.340
you have resources of CPU memory, memory,
and disk.

00:10:42.500 --> 00:10:44.740
And really the memory is virtual memory.

00:10:44.910 --> 00:10:48.680
And you really never want to have to
use the virtual side of that memory.

00:10:48.680 --> 00:10:51.910
You want to be able to keep everything
resident in physical memory.

00:10:52.460 --> 00:10:55.270
And since we're in a
networked environment,

00:10:55.270 --> 00:10:57.940
the network also plays a huge effect.

00:10:58.140 --> 00:11:02.220
So what we want to do is make sure that
the processing that we have going on

00:11:02.220 --> 00:11:07.210
on each of these servers is using those
resources in the most effective manner.

00:11:07.220 --> 00:11:09.920
So there's a couple of
utilities that Unix gives you

00:11:09.920 --> 00:11:11.550
and also Mac OS X gives you.

00:11:11.560 --> 00:11:15.140
For example, Top, I think Avi mentioned
that in the keynote,

00:11:15.140 --> 00:11:18.710
is something that he uses when
he evaluates applications.

00:11:18.800 --> 00:11:22.120
And what we're going to do is go through.

00:11:22.220 --> 00:11:27.880
I'm going to do a demo.

00:11:31.660 --> 00:11:33.210
We're going to go
through the demo machine,

00:11:33.300 --> 00:11:38.280
which is demo 4,
and show you we have an application

00:11:38.280 --> 00:11:41.580
here for this first demo that will...

00:11:42.870 --> 00:11:45.530
Show our need for speed
against the movie schema,

00:11:45.710 --> 00:11:50.860
which I'm sure you're
familiar with the example.

00:11:51.400 --> 00:11:53.530
In the movie schema,
what we have is a bunch of movies

00:11:53.540 --> 00:11:56.720
and the roles of the actors
that were played in that movie,

00:11:56.730 --> 00:11:58.480
and so there's an
EO model behind all this.

00:11:58.630 --> 00:12:00.960
For this first demo, though,
we're not really using the EO model.

00:12:00.960 --> 00:12:05.190
What we're doing is we have something
that will go off and do a ton of

00:12:05.190 --> 00:12:08.910
computations in the background,
which we basically are

00:12:09.110 --> 00:12:10.740
saying is spamming the CPU.

00:12:10.740 --> 00:12:13.370
But first of all,
there's a couple of utilities.

00:12:13.380 --> 00:12:16.110
CPU monitor,
if you can see up here in the

00:12:16.110 --> 00:12:20.500
right-hand side of the screen,
can show you the usage of the CPU.

00:12:21.300 --> 00:12:24.330
And the blue line is user space,
which is where we're running this

00:12:24.330 --> 00:12:28.400
application in the background,
and the red is the operating system.

00:12:28.400 --> 00:12:33.900
And then I've started up top
with a couple other parameters,

00:12:33.900 --> 00:12:40.380
dash U, which gives me a ranking by CPU,
and it's refreshing every five seconds,

00:12:40.460 --> 00:12:43.180
and a dash D parameter
on the top command,

00:12:43.180 --> 00:12:44.860
and you can look this
up in the man pages,

00:12:44.860 --> 00:12:48.320
but that gives you the deltas between the
last snapshot and the current snapshot.

00:12:48.320 --> 00:12:52.940
So what we're going to do
is set up a... off this

00:12:53.470 --> 00:12:54.400
This is a request.

00:12:54.500 --> 00:12:58.440
And you'll see immediately in the
CPU monitor how we've pegged the CPU.

00:12:58.440 --> 00:13:01.910
And if you notice here,

00:13:02.700 --> 00:13:05.010
The Java application instance,
which is the application

00:13:05.120 --> 00:13:08.390
server in this case,
has risen to the top of the

00:13:08.530 --> 00:13:10.580
stack of the processes that
are running on this machine.

00:13:10.580 --> 00:13:12.780
It's using 87% of the CPU.

00:13:12.780 --> 00:13:17.250
The load average on the machine
at the top has really peaked,

00:13:17.350 --> 00:13:21.610
and now it's finished processing,
and so the processing

00:13:21.610 --> 00:13:22.920
time has come back down.

00:13:22.920 --> 00:13:24.980
So this is one of the
tools that you can use.

00:13:25.040 --> 00:13:31.070
VMStat is another that allows you to
look at virtual memory and applications.

00:13:31.310 --> 00:13:34.260
There's a variety of other tools
as well out on the net that you

00:13:34.260 --> 00:13:35.280
can bring over to the platform.

00:13:35.280 --> 00:13:36.900
So that's the first demo.

00:13:36.900 --> 00:13:39.290
I'm going to turn it over to
Fitz now and I'll be back up

00:13:39.290 --> 00:13:41.180
for the third demo after that.

00:13:41.410 --> 00:13:41.780
Thanks.

00:13:48.050 --> 00:13:48.410
Thanks, Rich.

00:13:48.440 --> 00:13:51.760
Got to find my remote control.

00:13:55.770 --> 00:13:59.970
Now we're going to talk about a couple
of issues related to your web server

00:13:59.970 --> 00:14:05.190
as well as your database server and how
we can profile your app using some of

00:14:05.190 --> 00:14:08.840
the tools that come with WebObjects,
namely WoeStats and WoeEventCenter.

00:14:08.840 --> 00:14:10.830
So first we have your web server.

00:14:10.830 --> 00:14:12.920
Now,
that's something that's often ignored

00:14:12.940 --> 00:14:14.990
because you're very focused on the code.

00:14:15.000 --> 00:14:17.370
There's a number of different things
you can do with your web server

00:14:17.470 --> 00:14:18.800
to increase the performance of it.

00:14:18.820 --> 00:14:21.340
You can increase the
RAM and file cache sizes.

00:14:21.440 --> 00:14:23.710
Again, as Rich said,
you want to make sure you're never

00:14:23.710 --> 00:14:25.560
digging in a swap on a production server.

00:14:25.740 --> 00:14:29.300
Because your performance goes down to
zero pretty darn quickly at that point.

00:14:29.320 --> 00:14:31.890
Install the biggest,
fastest drives that you can because

00:14:31.970 --> 00:14:34.540
if you're going to be reading
data off the drives as well,

00:14:34.540 --> 00:14:37.920
serving your web server resources,
static images and the like.

00:14:37.980 --> 00:14:39.900
Disable reverse DNS lookups.

00:14:39.900 --> 00:14:41.750
This is related to logging.

00:14:41.760 --> 00:14:44.670
It takes time for your web server
to go back and look up the name

00:14:44.670 --> 00:14:47.720
corresponding to the number
of a request that's coming in.

00:14:47.780 --> 00:14:51.050
And important not only for
optimization but security,

00:14:51.090 --> 00:14:55.600
you want to make sure you're up to
date on your operating system patches.

00:14:55.700 --> 00:14:56.940
I'M GOING TO GO WITH THE

00:14:57.110 --> 00:14:59.040
We talked about disabling
reverse lookups.

00:14:59.110 --> 00:15:04.090
If your web server, for example, Apache,
is generating logs for every request

00:15:04.180 --> 00:15:06.260
and you're never going to use these,
turn it off.

00:15:06.260 --> 00:15:07.780
That's the best thing you can do.

00:15:07.780 --> 00:15:09.880
You'll increase your performance
and the ability to scale.

00:15:09.880 --> 00:15:12.050
If you are going to use it,
see if you can't,

00:15:12.130 --> 00:15:15.730
log it to a separate disk or make
sure you're on a fast disk subsystem.

00:15:16.990 --> 00:15:18.700
Increase the TCP listen backlog.

00:15:18.700 --> 00:15:20.510
Now, basically,
once you start getting many

00:15:20.600 --> 00:15:23.570
multiple requests per second,
users are going to start backing up,

00:15:23.770 --> 00:15:25.600
not only queuing up in your app,
but queuing up on the

00:15:25.600 --> 00:15:26.700
operating system level.

00:15:26.700 --> 00:15:29.490
And after a certain point,
the operating system will

00:15:29.500 --> 00:15:30.930
start to refuse requests.

00:15:30.930 --> 00:15:33.850
So by increasing this,
you can make a longer queue.

00:15:33.850 --> 00:15:37.140
It's not going to make it any faster,
but at least the users won't

00:15:37.160 --> 00:15:40.440
get the not available or
machine not contacted message.

00:15:40.440 --> 00:15:43.530
Use the latest releases of HTTP server.

00:15:43.540 --> 00:15:48.560
I'm happy to say that Apache 2.0.36
was released on Tuesday of this week,

00:15:48.560 --> 00:15:51.600
and it does compile and run
beautifully on Mac OS X.

00:15:51.620 --> 00:15:56.320
And web objects,
the CGI bin adapter does work with it.

00:15:56.370 --> 00:15:59.430
However,
we're working on getting other on the,

00:15:59.430 --> 00:16:01.670
we call it mod web objects,
working with that.

00:16:01.710 --> 00:16:05.140
For additional performance info,
specifically related to Apache,

00:16:05.140 --> 00:16:08.990
you can take a look at the
Apache website at the page right there.

00:16:10.570 --> 00:16:11.230
Database server.

00:16:11.230 --> 00:16:13.260
On the back end,
you've got your database server,

00:16:13.260 --> 00:16:15.630
and there's a lot of different
things that you can do to tweak out

00:16:15.640 --> 00:16:19.190
your database server to get every
little bit of performance out of it.

00:16:19.280 --> 00:16:23.370
A lot of different vendors recommend
particular philosophies with how

00:16:23.370 --> 00:16:26.840
to set up your database server,
where to put data files,

00:16:26.840 --> 00:16:30.080
what kind of hardware to use,
how to tune memory allocations.

00:16:30.080 --> 00:16:32.160
In fact,
Oracle recommends a whole number of

00:16:32.290 --> 00:16:35.430
kernel configurations for your machine
to make sure that they can get every

00:16:35.770 --> 00:16:37.320
last bit of performance out of it.

00:16:38.520 --> 00:16:39.320
Query tuning.

00:16:39.320 --> 00:16:44.320
If you turn your database on in
monitoring mode so that you can keep an

00:16:44.320 --> 00:16:48.710
eye on what's going on with the database,
you can see what queries are coming in.

00:16:48.950 --> 00:16:51.990
What can we do with the database
to make each query go faster?

00:16:51.990 --> 00:16:53.680
Do we need another index somewhere?

00:16:53.680 --> 00:16:56.080
Your primary keys obviously
should be indexed,

00:16:56.080 --> 00:16:58.900
but if you're querying on a
particular attribute often,

00:16:58.900 --> 00:17:01.020
you may want to create an index on that.

00:17:01.060 --> 00:17:02.750
Cache data into memory.

00:17:02.750 --> 00:17:06.890
I've been to some places where
they get this great big beefy

00:17:06.890 --> 00:17:08.500
database server with a map.

00:17:08.500 --> 00:17:09.500
They've got a massive
amount of RAM in it,

00:17:09.500 --> 00:17:11.790
and they manage to squeeze
their entire database into RAM.

00:17:11.800 --> 00:17:14.870
That's one way to speed
things up for certain.

00:17:16.460 --> 00:17:19.890
Now, application level tuning.

00:17:19.960 --> 00:17:22.240
When you're looking at
your WebObjects components,

00:17:22.250 --> 00:17:23.740
you want to find out which one's slow.

00:17:23.790 --> 00:17:25.940
Obviously,
clicking through the application,

00:17:25.980 --> 00:17:30.600
you can find out pretty easily what's
taking the most time out of your app.

00:17:30.850 --> 00:17:33.950
However,
Woe Stats is something that's going to

00:17:33.980 --> 00:17:38.610
be in your application and you can access
this page to tell you how much time,

00:17:38.610 --> 00:17:42.100
down to hundreds of a second,
each page is taking to render,

00:17:42.200 --> 00:17:46.020
as well as a minimum, a maximum,
and an average request time.

00:17:46.120 --> 00:17:48.820
Woe Event Center can give you
detailed statistics on your app on

00:17:48.820 --> 00:17:52.750
the component and the sub-component
level and show you how many times

00:17:52.750 --> 00:17:57.890
each sub-component was referred to,
how many times each component was hit.

00:17:58.220 --> 00:18:00.510
And lastly,
if database access might be the

00:18:00.510 --> 00:18:04.050
thing that's slowing you down,
and Rich is going to talk more about this

00:18:04.050 --> 00:18:07.240
in the next demo when he talks about EOF,
batching, and prefetching,

00:18:07.240 --> 00:18:08.360
and that sort of thing.

00:18:08.360 --> 00:18:10.910
But if you set
EOAdapterDebugEnabled to true,

00:18:10.970 --> 00:18:13.720
you can see all the SQL that
is being generated by your

00:18:13.800 --> 00:18:15.630
app and sent to the database.

00:18:15.640 --> 00:18:18.890
And in addition to that,
WebObjects will have a little timestamp.

00:18:18.960 --> 00:18:22.390
It'll say the minute and second that
your requested database started and then

00:18:22.390 --> 00:18:24.380
the minute and second that it finished.

00:18:24.560 --> 00:18:27.500
So you can see, that'll show you A,
perhaps your one query

00:18:27.500 --> 00:18:28.730
is taking a long time.

00:18:28.740 --> 00:18:32.500
Or B, perhaps by firing a lot of faults,
you're doing a whole bunch of

00:18:32.500 --> 00:18:35.920
round trips to the database,
which is not ever really a good thing.

00:18:37.870 --> 00:18:39.690
So, as I said,
we can view the transaction

00:18:39.690 --> 00:18:42.420
times via WoeStats,
turn on event recording

00:18:42.420 --> 00:18:43.740
in Woe Event Setup.

00:18:43.990 --> 00:18:47.460
Now, Woe Event Setup is like an
on-the-fly profiling tool.

00:18:47.460 --> 00:18:50.720
Anybody from here from the
Ejective C days remembers GProf.

00:18:50.820 --> 00:18:53.450
Crank your,
compile your application with profiling,

00:18:53.450 --> 00:18:56.160
crank it up, stop the application,
examine the data.

00:18:56.160 --> 00:19:01.210
Well, go to Woe Event Setup, set up the,
tell the application to

00:19:01.210 --> 00:19:02.880
log all these events.

00:19:02.880 --> 00:19:06.090
And it, it,
WebObjects can log just an absolutely

00:19:06.090 --> 00:19:09.810
ridiculous amount of events per second
without a serious performance hit.

00:19:10.000 --> 00:19:11.870
And then it'll start monitoring all this.

00:19:11.900 --> 00:19:13.540
You can come back to the
Woe Event Display page and

00:19:13.570 --> 00:19:14.630
see what it's got to offer.

00:19:16.210 --> 00:19:19.610
So this will help you pretty
easily detect which pages don't

00:19:19.610 --> 00:19:20.980
meet your acceptance criteria.

00:19:20.980 --> 00:19:24.700
You can find out exactly what
the performance problem is.

00:19:24.760 --> 00:19:28.110
But remember to evaluate the
times relative to the entire time.

00:19:28.120 --> 00:19:30.540
If you have a request
that's taking 10 seconds,

00:19:30.540 --> 00:19:33.140
and 8 of those seconds are
because of database fetch,

00:19:33.140 --> 00:19:35.290
and 2 of those seconds are
because of a little calculation,

00:19:35.340 --> 00:19:37.310
a sort or something
you're doing on the side,

00:19:37.320 --> 00:19:40.510
you'd probably do best to
focus on the database fetch.

00:19:40.910 --> 00:19:43.460
Focus on the larger of the
two problems in this case.

00:19:44.520 --> 00:19:47.770
Now, if I could have the demo
machine back up here.

00:19:48.650 --> 00:19:52.300
I'm going to go ahead and do a little
demo here with using WolfStats.

00:19:52.300 --> 00:19:55.110
So let's close this up.

00:19:56.790 --> 00:19:59.380
We'll come into our application
here and check out demo number two.

00:19:59.380 --> 00:20:03.110
And first thing I'm going to do is
I'm going to go into WoEventSetup,

00:20:03.110 --> 00:20:05.060
which is password protected.

00:20:05.060 --> 00:20:07.330
So we'll log in here.

00:20:07.340 --> 00:20:10.690
And you see there's several different
kinds of events that you can

00:20:10.830 --> 00:20:13.340
monitor or you can pick up if you're
looking for something in particular.

00:20:13.340 --> 00:20:15.260
What I'm going to do
now is set them to all.

00:20:15.260 --> 00:20:18.170
We'll take a quick peek at the
event log and you'll see that it's

00:20:18.270 --> 00:20:21.500
pretty much just logged the event
of me coming to this very page.

00:20:21.600 --> 00:20:25.750
So that being done,
we'll go back into the application.

00:20:29.650 --> 00:20:32.260
and what we'll do here
is we'll sort some stuff.

00:20:32.300 --> 00:20:34.700
Now,
obviously this is a little contrived.

00:20:34.700 --> 00:20:36.480
We know that we're sort-- I'm
hitting this one component.

00:20:36.530 --> 00:20:38.210
There's something that's
taking a lot of time.

00:20:38.240 --> 00:20:40.680
You can see the CPU is cranking up again.

00:20:41.000 --> 00:20:44.880
But--so I have an idea of where to look,
of what's going on.

00:20:44.910 --> 00:20:46.810
But when I go look at Woe
Stats or Woe Events Setup,

00:20:46.810 --> 00:20:48.900
it's going to tell me
exactly which component,

00:20:48.940 --> 00:20:53.010
the name of the component that's taking
so much time to complete and what's

00:20:53.010 --> 00:20:56.120
making the expensive calculation here.

00:20:56.200 --> 00:21:00.460
Okay, so we sorted 25,000 items and
we took a good chunk of time.

00:21:00.700 --> 00:21:02.270
So let's go take a look at Woe Stats.

00:21:04.500 --> 00:21:05.060
Log in again.

00:21:05.060 --> 00:21:08.360
Now, you'll see at the top,
what stats tells you some

00:21:08.360 --> 00:21:09.580
nice information here.

00:21:09.580 --> 00:21:12.940
Overall transactions, component action,
how long your app's been up.

00:21:13.120 --> 00:21:15.600
It tells you some great information
down here about sessions.

00:21:15.600 --> 00:21:17.880
How long have your sessions been idle.

00:21:17.880 --> 00:21:20.940
So, and the session stats are
something that can help you

00:21:20.940 --> 00:21:23.560
to tune your session timeout,
which is something you should

00:21:23.640 --> 00:21:27.460
get as low as possible to avoid
your sessions keeping all the

00:21:27.460 --> 00:21:28.680
memory around for that stuff.

00:21:28.720 --> 00:21:29.940
Total memory usage.

00:21:30.110 --> 00:21:31.640
And now we get down to
what I'm looking for,

00:21:31.640 --> 00:21:33.140
the component action stats.

00:21:33.780 --> 00:21:35.740
You'll see here,
we have the name of the component,

00:21:35.740 --> 00:21:39.460
how many of them are served, the minimum,
average, and maximum time.

00:21:39.460 --> 00:21:40.820
So, stats demo.

00:21:40.820 --> 00:21:42.870
Okay, there's nothing really
big going on there.

00:21:42.880 --> 00:21:45.800
Utils demo that Rich did,
we saw that that was pretty slow.

00:21:45.800 --> 00:21:46.380
Wow.

00:21:46.380 --> 00:21:47.900
And here, oh, bubble sort.

00:21:47.900 --> 00:21:49.990
Okay,
so we probably don't want to be doing

00:21:50.000 --> 00:21:52.340
a bubble sort in this application,
so let's go ahead and change

00:21:52.340 --> 00:21:54.200
that over to a quick sort.

00:21:54.200 --> 00:21:56.160
And we'll save that.

00:21:56.200 --> 00:21:59.460
Again, rapid turnaround,
not going to restart the application.

00:21:59.480 --> 00:22:02.420
We just go back in,
and we'll try and sort our data again.

00:22:04.000 --> 00:22:06.350
Okay,
that was a little bit faster right there.

00:22:06.350 --> 00:22:09.260
That's quite an improvement actually.

00:22:09.280 --> 00:22:10.420
I think I should get a raise, Rich.

00:22:10.870 --> 00:22:12.930
Anyway, WoEventDisplay.

00:22:12.940 --> 00:22:15.950
Let's take a quick look at what
WoEventDisplay has to tell us about

00:22:15.970 --> 00:22:17.500
all the stuff that's happened here.

00:22:17.590 --> 00:22:20.600
Okay, let's open this up.

00:22:20.790 --> 00:22:22.740
and we've got all these
different information.

00:22:22.740 --> 00:22:25.160
Here's the events it's logged
and here are the comments,

00:22:25.160 --> 00:22:26.520
the classes that they come from.

00:22:26.540 --> 00:22:31.470
It keeps that information,
how much time it takes and how many times

00:22:31.510 --> 00:22:33.080
it was called and relative to the whole.

00:22:33.190 --> 00:22:42.060
So if we go in our stats demo
which we were just working on,

00:22:42.070 --> 00:22:42.260
you can see that our table
element which contained our

00:22:42.530 --> 00:22:43.500
Sorry about that.

00:22:43.550 --> 00:22:47.270
Which contained our Aqua button which
invoked the quick sort bubble sort

00:22:47.270 --> 00:22:49.660
is what took the most amount of time.

00:22:50.820 --> 00:22:52.730
That's Woe Stats and
that's Woe Event Center.

00:22:52.730 --> 00:22:56.500
Now what I'm going to do is turn it
back over to Rich to show us a little

00:22:56.500 --> 00:23:00.700
bit more about EOF and what you can
do to tune your database access.

00:23:00.700 --> 00:23:05.630
Don't forget to restart the app.

00:23:12.480 --> 00:23:15.080
So what we're going to do now is
we talked earlier about all the

00:23:15.080 --> 00:23:20.300
different application tiers within this
system for a typical WebObjects app.

00:23:20.310 --> 00:23:22.800
And what we're going to do now is
focus on the WebObjects app itself.

00:23:22.800 --> 00:23:25.800
And as you know,
there's multiple layers that

00:23:25.800 --> 00:23:29.270
your software goes through
to talk to any database.

00:23:31.260 --> 00:23:34.730
EOF makes it so easy to talk to
databases that we want to leverage

00:23:34.730 --> 00:23:37.520
that software that's available,
but we also want to use it

00:23:37.520 --> 00:23:38.950
in the most effective manner.

00:23:41.660 --> 00:23:44.940
So what are a few things that
we can do for Enterprise Objects

00:23:45.100 --> 00:23:46.420
Framework to improve performance?

00:23:46.530 --> 00:23:49.380
Well, first and foremost,
make sure that you're not traversing

00:23:49.380 --> 00:23:52.930
from your application server to
the database more times than you

00:23:52.930 --> 00:23:57.080
really need to to bring in the data
or send the data to the system.

00:23:57.080 --> 00:24:01.720
And a couple ways of helping that is
with batch vaulting and prefetching,

00:24:01.720 --> 00:24:05.630
and we'll talk about what each
of those techniques bring to the

00:24:05.630 --> 00:24:07.720
table in the next few slides.

00:24:08.250 --> 00:24:11.490
Another way to go about this is
with the shared editing context.

00:24:11.560 --> 00:24:15.020
And how many people know what
a shared editing context is?

00:24:15.070 --> 00:24:17.560
Okay, a pretty good number.

00:24:17.560 --> 00:24:21.120
And the biggest benefit for the
rest of you is that it allows you

00:24:21.400 --> 00:24:25.530
to bring read-only memory into the
application instance one time and

00:24:25.530 --> 00:24:28.000
use that across multiple sessions.

00:24:28.000 --> 00:24:31.850
So each session within your application
doesn't need to bring in that same

00:24:31.850 --> 00:24:35.800
set of data and use it over and over,
for example, in things that don't change

00:24:35.860 --> 00:24:37.540
a lot in your application.

00:24:37.950 --> 00:24:40.980
Like the pop-up lists,
different browsers, select items.

00:24:41.110 --> 00:24:44.090
You want to read that stuff in
once when the application loads and

00:24:44.090 --> 00:24:45.960
leverage that throughout the app.

00:24:46.050 --> 00:24:49.310
If you have the luxury of making
your application read-only,

00:24:49.310 --> 00:24:52.300
that would be a tremendously
fast application because,

00:24:52.300 --> 00:24:56.150
again, you could bring most of the things
into a shared editing context,

00:24:56.260 --> 00:24:59.620
operate on it there, for example,
in a reporting application.

00:24:59.620 --> 00:25:03.720
If you could make everything read-only,
that would be extremely fast.

00:25:03.720 --> 00:25:08.220
And ultimately, as I mentioned earlier,
you just want to eliminate the constantly

00:25:08.820 --> 00:25:11.990
fetching the same data over and over.

00:25:13.560 --> 00:25:17.240
Another way to go about
doing this is using raw rows.

00:25:17.350 --> 00:25:21.570
What raw rows allow you to do is
eliminate the overhead of taking

00:25:21.570 --> 00:25:24.470
the data from the database and then
turning it into business objects.

00:25:24.610 --> 00:25:28.870
This is a great advantage in cases
where you're not going to do a bunch

00:25:28.870 --> 00:25:33.490
of changes on that data and then
persisting it down to the database or

00:25:33.490 --> 00:25:39.310
leveraging the business logic in the
objects that are resident in WebObjects.

00:25:39.380 --> 00:25:41.820
in your application,
but you just want to bring in the data.

00:25:41.820 --> 00:25:45.480
For example, reporting, again,
is a great example.

00:25:45.480 --> 00:25:50.840
Bring the data in from raw rows,
use it as is, and go on your merry way.

00:25:50.880 --> 00:25:55.140
Another thing that you should
use for your application to

00:25:55.140 --> 00:25:58.670
protect your application from
users doing huge searches,

00:25:58.680 --> 00:26:02.670
searching and trying to bring in all
the data from the database into your

00:26:02.670 --> 00:26:06.260
application instance and bloating
memory is to set fetch limits.

00:26:07.550 --> 00:26:10.160
For example,
you might determine that for your

00:26:10.160 --> 00:26:14.780
application a user really can't operate
on datasets more than 250 records.

00:26:14.820 --> 00:26:18.160
It just is unwieldy,
and you want to give them some feedback

00:26:18.160 --> 00:26:20.540
on how to restrict that search down.

00:26:20.560 --> 00:26:23.280
So fetch limits within
EOF really can help you do that,

00:26:23.340 --> 00:26:26.740
and it helps you eliminate unrestricted
searches within your application.

00:26:28.540 --> 00:26:33.670
If you have very large object graphs,
making changes to these object

00:26:34.570 --> 00:26:37.150
graphs becomes a problem.

00:26:37.160 --> 00:26:40.900
What you really want to do is have small
sets of data that are being operated on.

00:26:40.900 --> 00:26:44.130
And one way to do that is
with nested editing contexts.

00:26:44.140 --> 00:26:46.850
And another is with
peer-to-peer editing contexts.

00:26:46.860 --> 00:26:49.900
This allows you to encapsulate
the data that's going to change

00:26:49.930 --> 00:26:54.570
and operate on it in a very small,
restricted fashion,

00:26:55.090 --> 00:26:57.020
make the changes there,
and then send them to the database

00:26:57.020 --> 00:27:01.670
instead of having this very large
set of data that the editing

00:27:01.730 --> 00:27:03.690
context is trying to manage.

00:27:07.420 --> 00:27:11.680
A couple ways to keep data within
your application from going stale.

00:27:11.680 --> 00:27:14.750
And this can happen in a case where,
for example,

00:27:14.820 --> 00:27:18.150
you have an admin application that
makes changes to the database and then

00:27:18.150 --> 00:27:20.900
you also have an Internet application
that is leveraging that data.

00:27:20.900 --> 00:27:23.460
In many cases,
you make changes from the admin

00:27:23.460 --> 00:27:28.170
application in the database and you
want that data to be replicated out to

00:27:28.170 --> 00:27:30.980
the Internet as quickly as possible.

00:27:31.300 --> 00:27:35.360
One way to do that in a brute force
method would be to use invalidate all

00:27:35.360 --> 00:27:37.660
objects on the Internet instances.

00:27:37.660 --> 00:27:43.340
And what would happen in that case is it
would tell EOF that all these snapshots

00:27:43.340 --> 00:27:48.210
within my system are invalid and so next
time somebody comes to access this data,

00:27:48.210 --> 00:27:51.940
you need to refetch that data and
bring the snapshots up to speed.

00:27:51.940 --> 00:27:54.720
And so that's one way
to go about doing that.

00:27:55.150 --> 00:27:58.420
Another way, though, is to,
instead of doing a brute force

00:27:58.420 --> 00:28:02.240
method on the entire object graph,
is to bring that into a

00:28:02.240 --> 00:28:04.840
more restricted set of EOs,
if possible.

00:28:04.840 --> 00:28:09.230
And there's a couple methods that
you can set on a fetch specification.

00:28:09.240 --> 00:28:12.220
Set refreshes, refetched objects to true.

00:28:12.220 --> 00:28:16.840
And so you create a search,
you bring those data objects in,

00:28:16.840 --> 00:28:19.960
and you set that to true,
and that will then refetch that subset.

00:28:19.960 --> 00:28:22.260
So instead of working on the
entire data set that you had

00:28:22.260 --> 00:28:25.810
in your application instance,
you can restrict that down to,

00:28:25.810 --> 00:28:29.660
ultimately,
to things that have actually changed.

00:28:34.570 --> 00:28:40.120
Another way to do this is to set a
time lag on the snapshots themselves.

00:28:40.120 --> 00:28:42.780
The default value out
of the box is one hour.

00:28:42.780 --> 00:28:47.200
That might meet your needs fine,
but in cases where you're making

00:28:47.200 --> 00:28:50.480
changes rapidly to the admin side
and you want to see this reflected,

00:28:50.480 --> 00:28:52.660
you probably want to bring
that time stamp down.

00:28:52.660 --> 00:28:55.860
But understand that the smaller
you bring that time stamp down,

00:28:56.230 --> 00:28:59.590
that will cause fetches to the
database to happen more often.

00:28:59.600 --> 00:29:03.150
So it's really up to you guys
to determine what's the most

00:29:03.150 --> 00:29:06.000
effective for the functionality
you're trying to perform.

00:29:06.100 --> 00:29:11.440
So let's go through a demonstration
of batch faulting and prefetching.

00:29:11.530 --> 00:29:16.350
Great, we have the demo application up.

00:29:17.400 --> 00:29:22.030
First thing I need to do is restart
the application to clear out any of

00:29:22.030 --> 00:29:23.800
the changes that were made earlier.

00:29:23.890 --> 00:29:28.690
Um, and so that'll just take a second.

00:29:30.130 --> 00:29:33.510
And you'll notice that I'm
running everything on this laptop.

00:29:33.510 --> 00:29:39.420
So some of the times that you see in the
searches will be pretty large in terms

00:29:39.430 --> 00:29:44.390
of seconds because I have the browser,
project builder, the application,

00:29:44.510 --> 00:29:46.900
the database,
everything running on this one machine.

00:29:46.900 --> 00:29:51.080
So let's go into the application again.

00:29:51.080 --> 00:29:56.360
And we're on demo 3.

00:29:58.780 --> 00:30:02.120
The first thing we want to do is
go through a couple different fetch

00:30:02.120 --> 00:30:03.640
mechanisms against the database.

00:30:03.640 --> 00:30:08.180
If you remember earlier,
I mentioned that what we're using is a

00:30:08.210 --> 00:30:12.390
movie object and it has a one-to-many
relationship to the roles in that movie.

00:30:12.400 --> 00:30:17.350
The first way to go about doing
a fetch is a regular fetch.

00:30:17.460 --> 00:30:20.440
Go out, search for a bunch of movies,
and then pull in the

00:30:20.560 --> 00:30:21.910
movie roles for that.

00:30:21.960 --> 00:30:25.500
If you look at, you can see how long it
took to refetch here,

00:30:25.500 --> 00:30:27.470
and if I go down here to update,

00:30:30.420 --> 00:30:35.850
You can see that this took 5.65
seconds to return that data set.

00:30:35.960 --> 00:30:39.420
And the data set that's returning,
there's about 100 movies and

00:30:39.420 --> 00:30:41.700
about 450 rolls for those movies.

00:30:41.700 --> 00:30:45.140
And if we look,
I've also turned on SQL debugging.

00:30:45.600 --> 00:30:49.300
So what you can see
here is how many times

00:30:51.080 --> 00:30:53.500
It has had to go to the
database to do selects,

00:30:53.630 --> 00:30:56.500
so let me highlight one here.

00:30:57.210 --> 00:30:59.750
What you can see is it's
selecting a movie roll,

00:30:59.930 --> 00:31:02.580
and again it's selecting a movie roll,
again it's selecting a movie roll.

00:31:02.580 --> 00:31:05.570
So it's going across this
bridge from the database,

00:31:05.640 --> 00:31:09.600
or across the network from the database
to the application server many,

00:31:09.610 --> 00:31:10.340
many times.

00:31:10.380 --> 00:31:14.660
So let's look at a better way to do this,
or one better way to do this.

00:31:17.210 --> 00:31:18.790
Batch Vaulting.

00:31:18.790 --> 00:31:20.970
Here again you can see in
the background the number of

00:31:20.970 --> 00:31:23.850
round trips to the database,
but the performance was

00:31:23.850 --> 00:31:25.790
much better in this case.

00:31:27.610 --> 00:31:29.380
And we're down to 1.73 seconds.

00:31:29.480 --> 00:31:32.760
And so what's happening in this case
is that movies are being selected

00:31:33.190 --> 00:31:38.490
and then when I go to fault in the
movie roles for a particular movie,

00:31:38.490 --> 00:31:42.850
I also tell the system within EO Modeler
to go off and bring in a batch of

00:31:42.990 --> 00:31:47.450
movie roles next time you go across
that when you go to the database.

00:31:47.460 --> 00:31:49.500
So I'm telling it to
bring in a set of 20.

00:31:49.500 --> 00:31:56.100
And this really cuts down
the round trips from 100...

00:31:56.930 --> 00:32:02.410
100 and 1 for the regular fetch down to
about 20 for the batch faulting case.

00:32:03.980 --> 00:32:06.400
In the third case,
we can use prefetching.

00:32:06.410 --> 00:32:09.200
In this case,
we have the fastest performance

00:32:09.200 --> 00:32:12.800
because it's only having to
go to the database two times.

00:32:12.910 --> 00:32:15.750
One to get the movies because
we're doing a qualified search,

00:32:15.750 --> 00:32:19.590
and then another time to get the
movie rolls for those movies.

00:32:19.600 --> 00:32:22.760
We only go to the database twice,
and you can see what the time

00:32:22.910 --> 00:32:25.260
is in this case is 0.74 seconds.

00:32:25.340 --> 00:32:28.210
To help you compare and
contrast each of these,

00:32:28.210 --> 00:32:31.290
we can go through a little
bit more detail about each

00:32:31.290 --> 00:32:33.110
of the different fetches.

00:32:33.840 --> 00:32:37.830
As you see at the top one,
we do one round trip for the movies and

00:32:37.830 --> 00:32:40.810
then one round trip for each fault fired.

00:32:40.820 --> 00:32:43.900
That's the slowest performance.

00:32:43.900 --> 00:32:46.460
Batch faulting helps you cut
that down by when you go to

00:32:46.460 --> 00:32:48.700
the database for the faults,
you say, hey,

00:32:48.700 --> 00:32:51.400
give me a collection of those every time
instead of taking them one at a time.

00:32:51.400 --> 00:32:53.020
That really helps you
bring down the time.

00:32:53.020 --> 00:32:54.990
The last is prefetching.

00:32:55.020 --> 00:32:58.130
In this case,
you create a fetch specification.

00:32:58.140 --> 00:33:01.470
You create the movies,
and you tell it that I want

00:33:01.870 --> 00:33:03.280
to follow a key path.

00:33:03.780 --> 00:33:05.440
You then send the movie
to the movie rolls.

00:33:05.440 --> 00:33:08.700
In this case,
it brings in the movies and then sends

00:33:08.700 --> 00:33:12.390
off one more trip to the database to
pull in all the movie rolls associated

00:33:12.390 --> 00:33:13.650
with those in that first collection.

00:33:13.680 --> 00:33:16.470
That's why we get the
best time for that case.

00:33:19.770 --> 00:33:23.600
There's one other part to this demo,
raw rows.

00:33:23.640 --> 00:33:29.690
And we mentioned that earlier that
it's a great use for reporting.

00:33:29.690 --> 00:33:34.120
And so if we go off and search,
you can see up in the

00:33:34.150 --> 00:33:38.600
right-hand corner here,
we have, pardon?

00:33:39.160 --> 00:33:39.440
Thank you.

00:33:39.460 --> 00:33:44.740
I need to restart because I already
have cached a bunch of data here.

00:34:03.800 --> 00:34:06.200
This will just tell me to
start my session again,

00:34:06.200 --> 00:34:06.760
so we'll do that.

00:34:06.800 --> 00:34:18.030
Okay, so we're back to the raw rows
part of the demonstration.

00:34:18.040 --> 00:34:20.670
And we'll click on the rows.

00:34:20.890 --> 00:34:24.210
We bring in 453 movie rolls,
and you can see the time in

00:34:24.570 --> 00:34:26.420
that case is 0.44 seconds.

00:34:26.460 --> 00:34:31.640
And if we turn that data that
we pull back into objects,

00:34:31.820 --> 00:34:34.440
there should be some additional
overhead associated with that,

00:34:34.680 --> 00:34:37.220
and that comes back in 0.96 seconds.

00:34:38.880 --> 00:34:42.980
When you want to use these,
there's two different scenarios.

00:34:42.980 --> 00:34:45.780
One is you just want to
interact with the data itself.

00:34:45.780 --> 00:34:48.720
You don't really need the business
logic that the EOs give you.

00:34:48.720 --> 00:34:51.460
And the second case is you want to
make a bunch of changes to things

00:34:51.550 --> 00:34:53.200
and leverage the business logic.

00:34:53.200 --> 00:34:58.140
And so that's when you should incur
the overhead of the 0.96 seconds.

00:34:58.250 --> 00:35:00.340
Now remember,
these times are way out of whack

00:35:00.340 --> 00:35:03.820
because this is all running on this
one laptop in a real environment.

00:35:03.940 --> 00:35:06.880
These would be probably
orders of magnitude smaller.

00:35:06.880 --> 00:35:10.040
But it gives you the effect
for what the changes are.

00:35:10.060 --> 00:35:12.300
So with that,
I'll turn it back over to Fitz.

00:35:12.390 --> 00:35:13.160
Thank you.

00:35:13.200 --> 00:35:14.250
Thank you.

00:35:21.000 --> 00:35:23.300
Thanks again, Rich.

00:35:23.370 --> 00:35:26.600
Now,
I'm going to focus now on a little bit,

00:35:26.600 --> 00:35:28.540
a little bit on things
a little bit lower.

00:35:28.540 --> 00:35:33.050
Anyone here go to the
Java performance tuning sessions?

00:35:33.300 --> 00:35:35.380
Okay, that was a big, real big hit,
I can see.

00:35:35.380 --> 00:35:38.600
We're going to talk a little bit
about what you can do down in the

00:35:38.940 --> 00:35:42.480
language level to improve your
performance of your application.

00:35:42.480 --> 00:35:45.910
And finally,
we're going to talk about bad algorithms.

00:35:45.910 --> 00:35:49.220
For example, you saw, you know,
I was sorting 25,000

00:35:49.290 --> 00:35:51.870
objects using bubble sort,
which takes a little bit of time.

00:35:51.880 --> 00:35:52.970
Memory demands.

00:35:52.970 --> 00:35:57.500
Are you pulling tons of objects into
your application that are unnecessary?

00:35:58.220 --> 00:35:58.810
Memory leaks.

00:35:58.820 --> 00:36:00.250
Do you have circular references?

00:36:00.280 --> 00:36:04.100
What can you do to help the garbage
collector out and make it easier for it

00:36:04.130 --> 00:36:05.940
to clean up as you run out of memory?

00:36:05.940 --> 00:36:08.920
And finally,
which I'm really excited about showing,

00:36:08.920 --> 00:36:12.900
is using OptimizeIt to look inside
the Java virtual machine at your app.

00:36:12.980 --> 00:36:15.020
Is there anyone here
who's used OptimizeIt?

00:36:15.060 --> 00:36:16.420
Can I see a show of hands on that?

00:36:16.440 --> 00:36:17.410
Okay, that's great.

00:36:17.460 --> 00:36:20.740
Having used OptimizeIt,
it's like you realize that

00:36:20.740 --> 00:36:24.330
before that I was just looking
at this blind ball of mud,

00:36:24.350 --> 00:36:26.640
which was the JVM,
and I was kind of guessing at what

00:36:26.730 --> 00:36:28.080
was happening based on my code.

00:36:28.170 --> 00:36:30.980
But now I'm going to show
you how to use OptimizeIt to

00:36:30.980 --> 00:36:34.730
look inside the Java virtual
machine and see what's going on.

00:36:34.870 --> 00:36:37.040
So improving the performance of your app.

00:36:37.140 --> 00:36:40.360
First of all, tune the JVM heap size.

00:36:40.360 --> 00:36:42.540
And then test it with the
different deployment environments

00:36:42.610 --> 00:36:43.700
that you're going to use.

00:36:43.750 --> 00:36:47.460
Remember your development environment,
your laptop or your workstation,

00:36:47.460 --> 00:36:51.620
is going to be different than the machine
that you deploy the application on.

00:36:51.980 --> 00:36:54.660
The heap size does play an
important role because when

00:36:54.750 --> 00:36:58.480
every time that your application
has to increase the heap size,

00:36:58.580 --> 00:37:02.050
if it's not at maximum already,
it incurs a small performance penalty

00:37:02.050 --> 00:37:06.550
because the garbage collector is going
to run either a little bit or a lot.

00:37:06.720 --> 00:37:09.480
One of the things that I recommend
and that a lot of actual vendors

00:37:09.580 --> 00:37:12.780
do recommend with Java application
servers is to set the minimum heap

00:37:12.930 --> 00:37:14.320
size to the maximum heap size.

00:37:14.340 --> 00:37:18.500
The minimum heap size tells your app
what to malloc when it first starts up.

00:37:18.660 --> 00:37:19.980
It says grab this big hunk of memory.

00:37:19.980 --> 00:37:23.980
The maximum says keep grabbing until
you hit this number and grab no further.

00:37:23.980 --> 00:37:27.280
So if that memory is there,
if it's available for your Java app,

00:37:27.380 --> 00:37:29.640
it's not going to be
used by anything else.

00:37:29.640 --> 00:37:32.520
And it shouldn't because if
it's used by something else,

00:37:32.520 --> 00:37:35.520
you may max out and go into swap,
which as we know is death.

00:37:36.490 --> 00:37:40.580
So minimum heap size, maximum heap size.

00:37:40.760 --> 00:37:44.920
Now in WebObjects 4.5 we had the
nice verbose NSJavaMinHeapSize

00:37:44.920 --> 00:37:48.520
and NSJavaMaxHeapSize settings,
which have been deprecated

00:37:48.520 --> 00:37:52.150
because now there's no longer an
Objective-C wrapper around your JVM.

00:37:52.520 --> 00:37:54.460
We're invoking Java directly.

00:37:54.460 --> 00:38:00.820
We're using the -XMS for minimum
size or -XMX for maximum heap size.

00:38:00.820 --> 00:38:04.490
They default to 32 and 64,
however you can change

00:38:04.490 --> 00:38:06.100
that if you'd like to.

00:38:06.290 --> 00:38:06.790
Deployment.

00:38:06.930 --> 00:38:09.870
As Rich said earlier,
examine the machine using TOP, VMStat,

00:38:09.990 --> 00:38:11.370
or other performance tools.

00:38:11.400 --> 00:38:14.920
See how much memory your operating
system is using or any other

00:38:14.920 --> 00:38:16.500
tasks running on that machine.

00:38:16.500 --> 00:38:19.220
Configure your application
to use whatever's left.

00:38:19.300 --> 00:38:22.700
So if you have a machine with a gigabyte
of RAM and your operating system

00:38:22.700 --> 00:38:27.300
is using under 100 meg of overhead,
it gives you about 900 meg left,

00:38:27.360 --> 00:38:30.890
so you can either give one
instance 900 megabytes or

00:38:31.160 --> 00:38:32.840
nine instances 100 megabytes.

00:38:32.840 --> 00:38:34.840
Or in the instance of
the Deutsche Bank guys,

00:38:34.840 --> 00:38:39.220
your E10K with four terabytes of memory,
you can give 480 instances,

00:38:39.220 --> 00:38:40.440
whatever they need.

00:38:42.180 --> 00:38:43.720
Setting references to null.

00:38:43.780 --> 00:38:47.410
When you're done with an object,
not necessarily in the local scope,

00:38:47.410 --> 00:38:51.460
a local variable in a method is the
garbage collector knows it's out of scope

00:38:51.570 --> 00:38:53.100
and it will deal with that appropriately.

00:38:53.190 --> 00:38:55.610
But fields in your classes,
when you're done with this field,

00:38:55.620 --> 00:38:57.650
you know you're done with it,
set it to null.

00:38:58.070 --> 00:39:02.130
Make one less reference for the
garbage collector to have to navigate.

00:39:03.910 --> 00:39:04.840
Be aware of finalize.

00:39:05.130 --> 00:39:07.440
Finalize is something that's
going to happen during or after

00:39:07.540 --> 00:39:11.250
garbage collection and there's
a penalty for calling finalize.

00:39:11.250 --> 00:39:12.550
It costs more time.

00:39:12.550 --> 00:39:15.660
You shouldn't be invoking it explicitly.

00:39:15.790 --> 00:39:19.440
Finally, if you must implement finalize,
remember to call super.

00:39:19.510 --> 00:39:21.360
Otherwise,
you're going to have some weird problems.

00:39:21.700 --> 00:39:23.910
Now, I want to touch a little
bit on garbage collection.

00:39:23.910 --> 00:39:27.710
And this is always an
interesting and strange voodoo

00:39:27.710 --> 00:39:30.400
behind the garbage collector.

00:39:30.400 --> 00:39:33.040
And so I tracked down some
of the JBM guys at Apple this

00:39:33.040 --> 00:39:34.520
week and I cornered them.

00:39:34.520 --> 00:39:37.150
I said,
so what happens when you call system.gc?

00:39:37.170 --> 00:39:38.910
We've been told it's a hint.

00:39:39.070 --> 00:39:42.580
And the specification for the
Java virtual machine says that it

00:39:42.640 --> 00:39:46.780
doesn't have to run the garbage
collector when you say system.gc.

00:39:46.780 --> 00:39:48.970
I've seen bizarre little bits of code.

00:39:48.990 --> 00:39:51.680
In fact, I've written some myself that
call the garbage collector.

00:39:51.680 --> 00:39:54.040
And then check the free memory
and call it again and check the

00:39:54.050 --> 00:39:55.470
free memory and keep doing that.

00:39:57.710 --> 00:40:02.350
When you call systems.gc with Apple's
Hotspot VM we ship with Mac OS X,

00:40:02.420 --> 00:40:04.190
it does a full garbage collection sweep.

00:40:04.400 --> 00:40:06.020
Now that was actually news to me.

00:40:06.020 --> 00:40:07.030
I thought it was just a hint.

00:40:07.040 --> 00:40:10.500
So when I say full sweep,
that means we're suspending all threads

00:40:10.500 --> 00:40:13.790
and then doing a full sweep through
the VM for anything we can get rid of.

00:40:13.920 --> 00:40:15.050
That's expensive.

00:40:15.050 --> 00:40:16.360
It's time consuming.

00:40:16.360 --> 00:40:20.700
There really is no good time to do
a full sweep of your application.

00:40:20.740 --> 00:40:25.490
I met a person who said,
why are you so worried about this?

00:40:25.590 --> 00:40:26.500
In session terminate?

00:40:26.890 --> 00:40:30.870
I call system.gc and
the session's done with.

00:40:31.120 --> 00:40:32.260
What's to worry about?

00:40:32.260 --> 00:40:33.660
Well, what about the other people?

00:40:33.660 --> 00:40:34.950
The sessions are currently running.

00:40:34.950 --> 00:40:37.210
We get to sit there while your
garbage collector does its thing.

00:40:39.390 --> 00:40:41.490
Now, we have a little demo
here with OptimizeIt.

00:40:41.590 --> 00:40:43.880
And just to point out that there is...

00:40:45.940 --> 00:40:48.020
There is another application
out there called JProbe,

00:40:48.060 --> 00:40:50.400
but Optimizeit runs on
Mac OS X quite well,

00:40:50.400 --> 00:40:53.140
I might add,
so we're going to demonstrate that.

00:40:53.200 --> 00:40:55.840
Now the first thing I'm
going to point out with this

00:40:56.020 --> 00:40:58.730
is-- These guys are so good,
I don't even notice them.

00:40:58.740 --> 00:41:02.680
I just assume things have changed,
and it sure did.

00:41:02.820 --> 00:41:05.290
When your application starts up,

00:41:05.810 --> 00:41:09.210
We've got, you see this massive,
massive line here.

00:41:09.490 --> 00:41:14.160
Java, and here you'll see the XMX64,
64 meg Mac, 32 min,

00:41:14.160 --> 00:41:18.730
and then some different defaults,
and a whole load of directories

00:41:18.960 --> 00:41:20.800
for your class path.

00:41:20.830 --> 00:41:24.280
All the frameworks it's going to pull in,
the Java VM framework,

00:41:24.300 --> 00:41:26.480
the jar for your application itself.

00:41:27.260 --> 00:41:31.300
So what you do with that on, oh,
I'm doing fine.

00:41:31.300 --> 00:41:35.110
What you want to do with that is
copy that and create a shell script

00:41:35.230 --> 00:41:37.380
and modify that line a little bit.

00:41:37.420 --> 00:41:44.390
So we've got right here a little shell
script that I've cobbled together.

00:41:44.600 --> 00:42:25.600
[Transcript missing]

00:42:25.830 --> 00:42:27.140
It says port is 1470.

00:42:27.140 --> 00:42:30.090
Here's a little bit of information
that optimize is telling us.

00:42:30.160 --> 00:42:34.500
So what it's saying is we've opened
port 1470 for you to attach with your

00:42:34.620 --> 00:42:39.000
optimize it suite to get information
about the running application,

00:42:39.000 --> 00:42:39.980
about the JVM.

00:42:40.010 --> 00:42:44.100
Now it takes a good bit longer now
because every action is being audited and

00:42:44.100 --> 00:42:47.120
all this information is being generated.

00:42:47.210 --> 00:42:50.610
So now I've got optimize it
started over here and I'm going

00:42:50.610 --> 00:42:53.360
to attach to my running instance.

00:42:53.390 --> 00:42:55.500
And in pretty short order,
we're going to see the answer

00:42:55.500 --> 00:42:56.720
to one of our questions before.

00:42:56.850 --> 00:43:00.450
How many classes does your
application load when it starts up?

00:43:00.840 --> 00:43:05.200
Well, first of all,
we've got 21,000 instances of char array.

00:43:05.200 --> 00:43:07.340
We have 16,000 strings.

00:43:07.340 --> 00:43:09.640
We have enough string
buffers to fill a truck.

00:43:09.660 --> 00:43:12.950
And if I scroll down here,
these are all the classes that

00:43:12.950 --> 00:43:16.450
we've got loaded in our application.

00:43:16.590 --> 00:43:20.640
Notice I'm still scrolling.

00:43:20.640 --> 00:43:20.640
Still scrolling.

00:43:22.220 --> 00:43:34.340
We've got WebObjects Foundation,
Print Streamlogger, Apache Xerces stuff,

00:43:34.540 --> 00:43:36.810
Text Decimal Formats.

00:43:36.930 --> 00:43:41.060
And this is one way you can look at
all the instances of your objects.

00:43:41.130 --> 00:43:42.790
You can get an idea of how
much memory they're taking,

00:43:42.790 --> 00:43:45.530
how many instances you
have of each object.

00:43:46.200 --> 00:43:48.460
We can come over here and this
is actually my very favorite

00:43:48.600 --> 00:43:51.230
part here and we can find out
how much heap size are we using?

00:43:51.240 --> 00:43:53.360
How much is available to us?

00:43:53.480 --> 00:43:54.110
How much is used?

00:43:54.180 --> 00:43:55.730
What's the garbage collector doing?

00:43:55.740 --> 00:43:57.220
How many active threads?

00:43:57.280 --> 00:44:00.480
For those of you who say, oh,
my application isn't multi-threaded.

00:44:00.610 --> 00:44:03.640
It's impossible to write a WebObjects
application that's not multi-threaded.

00:44:03.700 --> 00:44:05.620
You have 24 just from the start.

00:44:05.770 --> 00:44:07.600
Didn't do anything special here,
24 threads.

00:44:07.640 --> 00:44:10.340
Loaded classes, 1,036.

00:44:10.380 --> 00:44:13.320
Did anyone else get
surprised by this number?

00:44:13.320 --> 00:44:15.390
I was like, wow, you know,
I knew there was a lot of stuff going on,

00:44:15.390 --> 00:44:17.710
but that seems like an
awful lot of information.

00:44:17.740 --> 00:44:21.490
So what I'll do now is
I'll kick back to this.

00:44:21.520 --> 00:44:24.740
We'll sort by instance count and
we'll go into our running application,

00:44:24.740 --> 00:44:27.920
which is going to take a little
bit longer to go through the first

00:44:27.920 --> 00:44:30.640
time because it's got a whole lot
more information to be generated.

00:44:32.470 --> 00:44:34.590
So, there we are.

00:44:34.650 --> 00:44:36.630
This is going to return now.

00:44:36.630 --> 00:44:39.060
And we're going to go to demo 4.

00:44:39.060 --> 00:44:40.340
Now, I've got a couple of
different things here.

00:44:40.340 --> 00:44:42.780
The first thing I'm going to do
is go ahead and leak some memory.

00:44:42.800 --> 00:44:46.850
Now, I've set my session timeout to
a really short session timeout.

00:44:46.900 --> 00:44:49.420
And so at the end of your session,
obviously,

00:44:49.470 --> 00:44:52.530
I've created a whole bunch of objects
and put them in a cache in my session.

00:44:52.540 --> 00:44:56.830
And when the session times out,
what this should do is

00:44:56.830 --> 00:44:58.960
release those objects.

00:44:59.030 --> 00:45:03.540
So, we're going to give this a second
here and the session will time out.

00:45:03.540 --> 00:45:05.540
Now,
go back to optimize it and take a look.

00:45:05.540 --> 00:45:07.680
Now,
if you peek and optimize it real quick

00:45:07.820 --> 00:45:11.040
and sort by instance counts here,
we'll see that on the fly it's

00:45:11.040 --> 00:45:12.540
picked up some big object.

00:45:12.540 --> 00:45:16.410
And we have 15,000 of these that
are taking up quite a bit of RAM.

00:45:16.510 --> 00:45:22.380
So, let's check here if this thing
is ever going to terminate.

00:45:22.540 --> 00:45:25.870
Did you turn session
termination off on me,

00:45:25.870 --> 00:45:26.540
Rich?

00:45:28.790 --> 00:45:30.120
You can just cut this out, right?

00:45:30.120 --> 00:45:33.310
Should I do the Steve Hayman and say,
bite me, bite me, bite me,

00:45:33.310 --> 00:45:35.030
or something like that?

00:45:39.500 --> 00:45:40.870
So, there we go.

00:45:41.130 --> 00:45:43.450
Our session finally terminated.

00:45:43.470 --> 00:45:46.160
Now we'll come back to optimize it.

00:45:46.160 --> 00:45:48.970
And notice everything's still here.

00:45:49.020 --> 00:45:51.150
Nothing's really changed.

00:45:51.710 --> 00:45:53.930
Nothing's been garbage collected.

00:45:53.960 --> 00:45:54.490
Why?

00:45:54.490 --> 00:45:57.780
The garbage collector
doesn't need to run.

00:45:57.780 --> 00:45:59.330
There's a lot of objects that we
can dispose of that we don't need.

00:45:59.330 --> 00:45:59.330
So I'm going to run the garbage
collector by hand here and

00:45:59.330 --> 00:45:59.330
we'll see some stuff change.

00:45:59.330 --> 00:45:59.330
But

00:45:59.400 --> 00:46:08.600
[Transcript missing]

00:46:09.530 --> 00:46:11.300
We can see where it's allocated.

00:46:11.300 --> 00:46:13.920
It's going to pull a backtrace and
walk all the way down the call stack so

00:46:13.920 --> 00:46:15.700
you can see where this is referred to.

00:46:15.700 --> 00:46:18.690
Way down here, all the way in the
bottom right-hand corner.

00:46:18.700 --> 00:46:21.910
Called from key value coding.

00:46:24.100 --> 00:46:25.410
So there you are.

00:46:25.540 --> 00:46:27.880
Allocation, location, JVM demo leak.

00:46:27.950 --> 00:46:30.800
So I'm going to pop into
Project Builder real quick and take

00:46:30.820 --> 00:46:32.740
a look at the JVM demo component.

00:46:34.270 --> 00:46:36.870
So, specifically, the leak method.

00:46:36.940 --> 00:46:39.340
So, we'll take a quick look.

00:46:39.340 --> 00:46:40.840
Here's our leak method.

00:46:40.900 --> 00:46:45.120
Okay, so,
got a cache session and I'm stuffing all

00:46:45.190 --> 00:46:49.750
these objects into this cache object,
cacheMutableArrayInSession.

00:46:49.760 --> 00:46:53.040
So, we'll come up here,
we'll take a look at session.

00:46:53.160 --> 00:46:54.670
Here's our cache method.

00:46:54.910 --> 00:46:56.280
Okay, underscore cache.

00:46:56.280 --> 00:46:58.270
Now I can't figure out
why that's leaking yet.

00:46:58.360 --> 00:46:59.700
Let's take a look at
the instance variable.

00:46:59.700 --> 00:47:01.270
Ah, so there's our answer.

00:47:01.270 --> 00:47:02.720
We've declared it statically.

00:47:02.720 --> 00:47:03.680
How foolish of us.

00:47:03.680 --> 00:47:07.370
So we can go ahead and fix that, save it,
recompile the app,

00:47:07.370 --> 00:47:10.240
and it'll go ahead and allocate properly.

00:47:10.240 --> 00:47:12.840
So we'll go back here,
and now for the really

00:47:12.840 --> 00:47:15.420
fun part that I like,
is run out of memory.

00:47:15.470 --> 00:47:19.940
I'm sure no one here has ever had that
problem with the Java virtual machine,

00:47:19.950 --> 00:47:20.790
right?

00:47:20.820 --> 00:47:22.080
Ever run out of memory?

00:47:22.790 --> 00:47:25.910
Okay, what I'm going to do here is start
allocating objects by the thousand.

00:47:25.910 --> 00:47:29.260
And they're basically just going to
start consuming the virtual machine

00:47:29.260 --> 00:47:31.940
until it's forced to increase the heap.

00:47:32.410 --> 00:47:34.250
Remember,
our maximum heap is set to 64 meg.

00:47:34.250 --> 00:47:36.090
It's currently using the minimum heap.

00:47:36.090 --> 00:47:37.780
In fact, it's not even near that.

00:47:37.790 --> 00:47:39.380
In fact,
I'll run the garbage collector and

00:47:39.380 --> 00:47:40.770
make sure everything's cleaned up.

00:47:40.840 --> 00:47:45.030
Garbage collector did a full sweep,
100% activity.

00:47:45.030 --> 00:47:47.350
Over here, about 8 meg used.

00:47:47.350 --> 00:47:51.150
So we'll come back to our app,
and I'll say, run out of memory.

00:47:51.240 --> 00:47:52.460
And I'll rush back over here.

00:47:54.300 --> 00:48:01.300
[Transcript missing]

00:48:05.200 --> 00:48:27.900
[Transcript missing]

00:48:28.610 --> 00:48:32.200
Okay, full sweep, all the way to the top,
right there.

00:48:32.240 --> 00:48:35.500
And we're getting pretty close,
and now we're at the top of our heap.

00:48:35.650 --> 00:48:39.100
Slam into it, the garbage collector
runs as hard as it can.

00:48:39.140 --> 00:48:41.200
Now this is all happening
inside a WOL component,

00:48:41.270 --> 00:48:45.000
so our request handler
is going to handle this,

00:48:45.030 --> 00:48:47.080
grab the exception,
and then the garbage collector

00:48:47.080 --> 00:48:51.200
successfully deallocates all of those
objects and dumps this back down.

00:48:51.420 --> 00:48:53.000
Now look how hard that's running.

00:48:53.020 --> 00:48:58.190
That is from time start 5 minutes and
30 seconds to 5 minutes and 50 seconds.

00:48:58.730 --> 00:49:01.040
And now we're back down to 8 meg.

00:49:01.080 --> 00:49:06.500
So that's my Optimizer demo for you.

00:49:10.200 --> 00:49:11.850
I believe that's about it.

00:49:11.910 --> 00:49:14.280
Again,
to be considered for the WebObjects beta,

00:49:14.280 --> 00:49:16.460
even if you've already
been in a beta before,

00:49:16.460 --> 00:49:20.170
you should sign up at
applec.apple.com slash webobjects.

00:49:20.210 --> 00:49:21.310
The lab is downstairs.

00:49:21.430 --> 00:49:23.770
If you haven't been to the lab,
I recommend going by,

00:49:23.840 --> 00:49:27.520
especially if you have one of those
impossible problems that's bugging you.

00:49:27.670 --> 00:49:28.890
Bring your laptop down there.

00:49:28.890 --> 00:49:31.840
We've got engineers from WebObjects,
engineers from Java who will be

00:49:31.840 --> 00:49:33.280
glad to take a look at it for you.

00:49:34.310 --> 00:49:34.740
Roadmap.

00:49:34.930 --> 00:49:37.010
We have a feedback
session this afternoon,

00:49:37.030 --> 00:49:39.540
which I heard is going to
be extremely entertaining,

00:49:39.600 --> 00:49:40.880
a feedback session.

00:49:40.880 --> 00:49:43.110
Much better than any of those
other feedback sessions that

00:49:43.170 --> 00:49:44.510
we'll be having this afternoon.

00:49:44.520 --> 00:49:45.420
Who to contact?

00:49:45.420 --> 00:49:49.670
You can contact Tony Trujillo-Vian,
Bob Frazier, Apple Professional Services,

00:49:49.700 --> 00:49:51.380
which is where Rich and I work.

00:49:51.400 --> 00:49:53.520
We give her training, support,
and consulting.

00:49:53.520 --> 00:49:57.140
And more information,
we have a whole bunch of URLs.