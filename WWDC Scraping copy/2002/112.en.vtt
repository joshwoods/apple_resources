WEBVTT

00:00:02.530 --> 00:00:05.240
This is session 112,
Writing Threaded Apps for Mac OS X.

00:00:05.240 --> 00:00:06.640
My name is Mark Tozer-Vilchez.

00:00:06.640 --> 00:00:09.400
I'm the hardware evangelist
in Developer Relations.

00:00:09.460 --> 00:00:10.900
Good morning.

00:00:11.070 --> 00:00:15.900
As we all know, Mac OS X is a fully
threaded operating system.

00:00:15.900 --> 00:00:18.240
For that reason,
you should be writing apps

00:00:18.310 --> 00:00:19.640
to take advantage of that.

00:00:19.640 --> 00:00:22.160
We ship dual processor systems as well.

00:00:22.310 --> 00:00:25.640
So writing a fully optimized
application will take advantage

00:00:25.640 --> 00:00:27.390
of that second processor.

00:00:27.400 --> 00:00:29.640
I just want to show you
a couple examples of,

00:00:29.640 --> 00:00:32.060
you know,
an application taking advantage of that

00:00:32.060 --> 00:00:36.160
second processor and an application not.

00:00:36.440 --> 00:00:40.840
So the first example is
a simple QuickTime movie.

00:00:41.060 --> 00:00:43.670
We'll go ahead and play
all the movies here.

00:00:48.520 --> 00:00:50.440
Can I get the demo screen?

00:00:50.550 --> 00:00:51.640
Demo two.

00:00:51.640 --> 00:00:53.640
Thank you.

00:00:53.640 --> 00:00:56.230
So I'll just run that application.

00:00:56.300 --> 00:00:59.190
Let's run Thread Viewer,
take a look at what's going

00:01:01.740 --> 00:01:03.110
Video is not important.

00:01:03.240 --> 00:01:07.420
But what I want to show you as an example
is clicking back to the QuickTime movie,

00:01:07.420 --> 00:01:10.580
holding down the menu,
you'll see another thread actually

00:01:10.710 --> 00:01:14.380
get started there for the menu,
but the movie is still playing.

00:01:19.050 --> 00:01:21.930
Going to another application.

00:01:21.950 --> 00:01:24.760
This is just showing a molecule rotating.

00:01:24.820 --> 00:01:27.080
Again,
we'll go ahead and attach Thread Viewer.

00:01:27.180 --> 00:01:30.890
And you can also see the
processor is getting pinged there.

00:01:37.520 --> 00:01:39.050
So you have a single thread.

00:01:39.130 --> 00:01:43.740
What happens when you
hold down the menu button?

00:01:43.740 --> 00:01:44.400
Drawing stops.

00:01:44.400 --> 00:01:47.300
That second thread actually
does not get created.

00:01:47.390 --> 00:01:50.360
What gets created is actually
the thread for the menu system,

00:01:50.360 --> 00:01:52.330
which is the OS,
actually taking advantage of that.

00:01:52.480 --> 00:01:56.500
So for your application,
what you want to do is have the user

00:01:56.500 --> 00:02:00.680
interface give the user the feedback
that things can still be occurring.

00:02:00.740 --> 00:02:04.470
By being able to drop down that menu,
perform some actions,

00:02:04.480 --> 00:02:08.680
and still have the window being
drawn is a very huge advantage,

00:02:08.860 --> 00:02:10.220
particularly when you
have dual processors.

00:02:10.220 --> 00:02:13.830
And for applications like this,
a scientific application,

00:02:13.860 --> 00:02:15.620
that comes in really handy.

00:02:15.620 --> 00:02:18.360
Go back to slides, please.

00:02:22.440 --> 00:02:25.540
So I want to bring up Matt Watson,
Core and Technologies Engineer,

00:02:25.540 --> 00:02:29.370
who will present to you the
information today on threading,

00:02:29.370 --> 00:02:32.920
how to thread your applications,
and give you all the new features that

00:02:32.920 --> 00:02:35.410
we've added to Jaguar for threading.

00:02:35.470 --> 00:02:37.240
Thank you.

00:02:39.200 --> 00:02:42.900
Thanks, Mark.

00:02:43.570 --> 00:02:44.140
I'm Matt Watson.

00:02:44.140 --> 00:02:46.350
I work in the
Core Technologies Group at Apple.

00:02:46.350 --> 00:02:50.970
I've been at Apple about ten years now,
mostly working on the BSD,

00:02:50.970 --> 00:02:55.240
Darwin layer and the threads
implementation down there.

00:02:55.300 --> 00:02:58.720
Today I'll talk to you a little bit
about writing multithreaded apps in OS X,

00:02:58.720 --> 00:03:02.130
some of the APIs we provide,
the different API layers,

00:03:02.150 --> 00:03:06.020
things you need to know,
what makes our platform a little

00:03:06.020 --> 00:03:08.120
different from other platforms.

00:03:09.940 --> 00:03:11.830
So why do you want to use
threads in your application?

00:03:11.840 --> 00:03:14.230
The first one is something
that Mark mentioned,

00:03:14.240 --> 00:03:15.580
the customer expectation.

00:03:15.580 --> 00:03:18.620
If they spend a bunch of money
on a dual processor system,

00:03:18.620 --> 00:03:20.920
they're going to want to get the
benefit of that second processor.

00:03:20.920 --> 00:03:25.110
As he showed you,
there's applications that can

00:03:25.260 --> 00:03:27.880
take advantage of the second
processor fairly easily,

00:03:27.880 --> 00:03:31.430
but you can also write an application
that's just a port from an existing

00:03:31.430 --> 00:03:37.620
classic app that will just block the API,
excuse me, block the UI unexpectedly.

00:03:38.020 --> 00:03:40.870
So you really want to design your
application to take advantage of

00:03:40.880 --> 00:03:42.310
all the features of the system.

00:03:43.850 --> 00:03:44.640
Scalability.

00:03:44.640 --> 00:03:48.500
As you know,
Mac OS X is a fully preemptive,

00:03:48.530 --> 00:03:50.460
multi-threaded operating system.

00:03:50.460 --> 00:03:55.700
So when you use an API that lets you
take advantage of multiple threads,

00:03:55.840 --> 00:03:58.960
if you happen to be running that
application on a dual processor system,

00:03:58.960 --> 00:04:01.490
you can take advantage
of that second processor,

00:04:01.680 --> 00:04:03.590
sometimes without even you knowing it.

00:04:05.300 --> 00:04:06.290
Preemption.

00:04:06.290 --> 00:04:10.890
Because the way the system
slices time between threads on

00:04:10.930 --> 00:04:15.650
a kind of a round-robin basis,
your application, if it's multithreaded,

00:04:15.650 --> 00:04:19.260
will get more than another
application's share of that time slice.

00:04:21.040 --> 00:04:24.900
There's some APIs in the system that are
synchronous that you really can't avoid.

00:04:24.900 --> 00:04:28.920
So, for instance,
hostname lookups classically have

00:04:28.920 --> 00:04:33.310
been these blocking APIs where you
just have to wait for the response

00:04:33.420 --> 00:04:35.540
to come back from the network.

00:04:35.540 --> 00:04:42.500
And if you use a second thread,
that means your application can go and

00:04:42.500 --> 00:04:42.750
continue and do other things while you're
waiting for that response to come back.

00:04:43.170 --> 00:04:43.610
Polling.

00:04:43.690 --> 00:04:46.340
As Avi mentioned in the keynote,
polling is bad.

00:04:46.340 --> 00:04:50.090
You really don't want to have your
application sitting there iterating

00:04:50.090 --> 00:04:52.380
on waiting for an event to occur.

00:04:52.380 --> 00:04:55.850
So one way to avoid that might be to
create a second thread that just waits

00:04:55.930 --> 00:05:01.440
for the event and then notifies the
main thread when that event occurs.

00:05:01.440 --> 00:05:03.590
Threads are really,
really good for data-driven tasks.

00:05:03.650 --> 00:05:08.350
And in a dual processor system,
you can really get a huge performance

00:05:08.810 --> 00:05:12.260
boost if the way your application
is designed is such that the

00:05:12.260 --> 00:05:16.450
data can be partitioned across
multiple threads and each processor

00:05:16.580 --> 00:05:18.720
can just crank on the data.

00:05:18.720 --> 00:05:21.340
And I'll show you a
little example of that.

00:05:21.340 --> 00:05:23.380
This is a slide we've shown before.

00:05:23.380 --> 00:05:26.520
For a multiprocessor system,
the scaling you can get,

00:05:26.740 --> 00:05:29.140
the numbers at the end
of the slide are the,

00:05:29.140 --> 00:05:32.460
the multipliers for the benefit
for the second processor.

00:05:32.460 --> 00:05:38.340
Now, one thing you might notice in this,
these are basically Photoshop filters

00:05:38.490 --> 00:05:41.730
that have been optimized
for a dual processor system.

00:05:41.740 --> 00:05:46.640
The second bar there shows
you a 2.3x improvement.

00:05:46.640 --> 00:05:48.060
Well, that sounds kind of strange.

00:05:48.060 --> 00:05:50.640
How can you get more than 2x
when you have two processors?

00:05:50.960 --> 00:05:53.810
Well, the,
the trick is you get a second cache

00:05:53.830 --> 00:05:55.880
when you get that second processor.

00:05:55.880 --> 00:06:00.270
So if your application was using
data that didn't quite fit in the

00:06:00.270 --> 00:06:05.500
primary cache of one processor and
you split that task up into two tasks,

00:06:05.500 --> 00:06:09.550
and both of those tasks now fit
into the caches of both processors,

00:06:09.550 --> 00:06:13.040
now you get a little bit of benefit
where you're not calling into main

00:06:13.040 --> 00:06:14.800
memory all the time to get your data.

00:06:17.800 --> 00:06:19.960
There are some cases where you
might want to avoid threads.

00:06:20.300 --> 00:06:22.850
While it sounds attractive,
you still have to be careful

00:06:22.960 --> 00:06:23.950
when you're using threads.

00:06:24.020 --> 00:06:25.800
There's some added complexity.

00:06:25.800 --> 00:06:28.140
For instance,
if you're porting an application

00:06:28.140 --> 00:06:31.400
that was single threaded and you
want to add multiple threads to it,

00:06:31.400 --> 00:06:34.070
you have to be careful of
the global data in the task.

00:06:34.190 --> 00:06:37.120
You're going to have to add a locking
mechanism if you want multiple

00:06:37.480 --> 00:06:41.250
threads to access that global data,
and that might introduce some complexity

00:06:41.250 --> 00:06:43.140
that you'll just have to manage.

00:06:44.410 --> 00:06:46.940
Threading adds a little bit
of overhead to an application

00:06:47.010 --> 00:06:48.370
that you have to be aware of.

00:06:48.750 --> 00:06:51.820
There's kernel resources
associated with that.

00:06:52.200 --> 00:06:54.860
There's context switching
associated with that.

00:06:55.000 --> 00:06:58.040
So when you're adding threads,
you have to decide whether the

00:06:58.040 --> 00:07:00.940
benefits of the extra thread
are worth it for your task.

00:07:01.060 --> 00:07:04.620
In a lot of cases,
there may be other options that are

00:07:04.620 --> 00:07:08.390
better suited for what you're doing,
like timers.

00:07:08.420 --> 00:07:12.150
If you just want to have something
that periodically puts up a little

00:07:12.150 --> 00:07:17.060
display or increments timers,
on the screen, that might be perfect

00:07:17.060 --> 00:07:19.000
for a clock display.

00:07:19.440 --> 00:07:22.140
You might want to use a timer rather
than a dedicated thread sitting

00:07:22.140 --> 00:07:24.040
there just firing every second.

00:07:24.100 --> 00:07:28.460
Given that a lot of applications,
a GUI application will have

00:07:28.550 --> 00:07:33.290
an event loop that's already
handling events fairly constantly,

00:07:33.290 --> 00:07:35.500
you can plug into that pretty easily.

00:07:37.160 --> 00:07:40.750
If you find that you're creating
hundreds of threads in your application,

00:07:40.810 --> 00:07:43.030
you might want to rethink
the design of that.

00:07:43.340 --> 00:07:48.510
You really want to make sure that
your thread model follows the data,

00:07:48.520 --> 00:07:52.880
meaning if you have data sources
coming from disk or network or the UI,

00:07:52.880 --> 00:07:55.520
that's really the only place
that the system can take

00:07:55.520 --> 00:07:57.360
advantage of multiple threads.

00:07:57.360 --> 00:08:01.510
If you're creating 100 threads to
read parts of a file off the disk,

00:08:01.510 --> 00:08:05.150
that doesn't make sense because
the file is just going to come

00:08:05.150 --> 00:08:07.020
from the same part of the system.

00:08:07.100 --> 00:08:11.590
anyway, so that all those threads are
gonna be serialized in effect.

00:08:13.000 --> 00:08:15.000
A little bit about thread
overhead that I mentioned.

00:08:15.000 --> 00:08:20.080
The way the system switches between
threads is called a context switch.

00:08:20.260 --> 00:08:23.030
So every thread has a set of
register state and resources

00:08:23.030 --> 00:08:24.600
that's associated with it.

00:08:24.890 --> 00:08:27.760
And whenever the system
switches between threads,

00:08:27.790 --> 00:08:32.380
it has to save the context that was being
used in the previous thread and restore

00:08:32.380 --> 00:08:34.890
it when that thread comes back to life.

00:08:36.130 --> 00:08:39.430
In the PowerPC architecture,
the floating point and vector

00:08:39.470 --> 00:08:41.160
state is pretty expensive.

00:08:41.160 --> 00:08:42.780
We have a lot of registers.

00:08:42.780 --> 00:08:44.680
The vector registers are large.

00:08:44.870 --> 00:08:47.410
So if you're heavily using
that in your threads,

00:08:47.490 --> 00:08:51.680
you may notice that the context
switch time is going to cost you.

00:08:53.080 --> 00:08:55.750
There's also memory footprint
associated with each thread.

00:08:55.750 --> 00:09:00.640
Besides the actual thread structures
that are being used in the system,

00:09:00.640 --> 00:09:04.230
every thread by default
has 512K of stack.

00:09:04.300 --> 00:09:07.560
And that may sound pretty large,
but the memory itself is virtual,

00:09:07.560 --> 00:09:10.690
meaning the system doesn't charge
your application that memory

00:09:10.690 --> 00:09:12.480
until it's touching the pages.

00:09:13.820 --> 00:09:18.070
But if you look at the address space,
you have 4GB of address space,

00:09:18.220 --> 00:09:22.040
so half a meg of stack size is
going to get eaten up pretty quick.

00:09:22.130 --> 00:09:25.860
There's APIs I'll talk about in a little
bit that help you reduce that stack

00:09:25.940 --> 00:09:29.790
overhead if you know that your thread
isn't going to be using a lot of stack.

00:09:31.710 --> 00:09:34.670
Thread creation time is also a factor.

00:09:35.060 --> 00:09:37.630
There are APIs that
let you create threads,

00:09:37.780 --> 00:09:41.320
let the threads exit,
but you may want to be aware

00:09:41.340 --> 00:09:43.380
of the actual cost of that.

00:09:43.690 --> 00:09:46.100
And if you want, you can create what's
called a thread pool,

00:09:46.100 --> 00:09:50.020
where you just keep a set of threads kind
of on the side and just signal them to

00:09:50.020 --> 00:09:52.230
let them know that they have work to do.

00:09:52.240 --> 00:09:55.410
Because if you just use
the system resources,

00:09:55.410 --> 00:09:59.410
you're creating all of these
resources over and over every

00:09:59.410 --> 00:10:00.780
time you do a thread create.

00:10:02.120 --> 00:10:06.220
All the APIs in Mac OS X that deal
with threads have some common concepts.

00:10:06.380 --> 00:10:09.670
They let you create threads,
destroy threads.

00:10:09.670 --> 00:10:11.490
They are synchronization primitives.

00:10:11.670 --> 00:10:15.150
So depending on the API set you're using,
there's mutex locks,

00:10:15.210 --> 00:10:17.980
there's condition variables
that can signal that events

00:10:18.580 --> 00:10:20.460
have occurred between threads.

00:10:21.220 --> 00:10:24.450
And every API set has the
set of thread-safe services.

00:10:24.450 --> 00:10:28.190
And as we work on improving Mac OS X,
we try and make that set

00:10:28.220 --> 00:10:31.780
of APIs more and more rich,
whereas you shouldn't have

00:10:31.780 --> 00:10:36.010
to worry about which APIs are
thread-safe and which aren't.

00:10:39.040 --> 00:10:40.760
A little bit about the
internal implementation.

00:10:40.850 --> 00:10:43.300
As I said,
threads are the scheduling primitive.

00:10:43.300 --> 00:10:48.440
The kernel doesn't deal with tasks
per se as a scheduling primitive.

00:10:48.440 --> 00:10:49.280
It deals with threads.

00:10:49.450 --> 00:10:53.080
So, as I mentioned before,
if your task has multiple threads in it,

00:10:53.130 --> 00:10:57.000
the kernel is going to look at your task
more often through the scheduling loop.

00:10:58.500 --> 00:11:00.980
Since the system is fully preempted,
that means a thread can get

00:11:01.020 --> 00:11:02.400
interrupted at any time.

00:11:02.580 --> 00:11:06.440
Now, there's some high-level APIs that
represent cooperative threads,

00:11:06.440 --> 00:11:10.060
but underlying the system,
those cooperative threads actually get

00:11:10.180 --> 00:11:12.100
interrupted in between instructions.

00:11:12.100 --> 00:11:14.440
So there's no guarantee of when
that thread will get interrupted.

00:11:14.540 --> 00:11:21.900
If you're using the cooperative API,
we're trying to encourage people

00:11:21.940 --> 00:11:23.390
to get off of that and use the
higher-level preemptive APIs.

00:11:23.600 --> 00:11:27.710
We use a priority-based scheduling model.

00:11:27.790 --> 00:11:32.460
The default scheduling for a thread gives
every thread an equal priority kind of

00:11:32.470 --> 00:11:34.460
in the middle of the priority range.

00:11:34.500 --> 00:11:36.950
If you want to enhance that,
you can increase the

00:11:37.240 --> 00:11:38.500
priority of a thread.

00:11:38.500 --> 00:11:41.930
If you know that you have a
thread that's not very important,

00:11:41.930 --> 00:11:45.100
you just want it kind of going off
in the background doing some work,

00:11:45.100 --> 00:11:49.030
you can decrease the priority of
that thread and it won't impact

00:11:49.570 --> 00:11:51.590
higher-level priority threads.

00:11:52.000 --> 00:11:55.960
Another implementation detail is we
use a one-to-one threading model,

00:11:55.960 --> 00:11:59.530
meaning we map one kernel
thread to one user-level thread.

00:11:59.540 --> 00:12:03.350
And that's somewhat different from
other implementations that you might

00:12:03.400 --> 00:12:06.840
have seen where there's multiplexing,
where multiple user threads

00:12:06.950 --> 00:12:08.120
map to a kernel thread.

00:12:08.140 --> 00:12:11.050
The main reason for this is
simplicity of the design,

00:12:11.050 --> 00:12:14.550
and it scales a little bit
better on multiprocessor systems.

00:12:14.580 --> 00:12:18.170
With the multiplexing implementation,
there'd have to be some signaling

00:12:18.460 --> 00:12:21.450
to the kernel when the user-level
threads switch context.

00:12:21.800 --> 00:12:25.200
So we don't have that
in our implementation.

00:12:26.960 --> 00:12:30.120
Mach is the API that you may
have heard about in the kernel.

00:12:30.120 --> 00:12:34.500
That's where the threading implementation
lives at its very lowest level.

00:12:34.500 --> 00:12:38.890
You can inspect Mach threads and the
Mach thread attributes in a task,

00:12:38.890 --> 00:12:44.220
but we generally recommend that you use
the higher level threading APIs instead.

00:12:44.220 --> 00:12:48.260
The reason behind that is if
you use a low level Mach API,

00:12:48.260 --> 00:12:52.050
you kind of subvert the
higher level API's usage.

00:12:52.260 --> 00:12:55.830
So if you change a priority of a
Mach thread directly and the P thread

00:12:56.240 --> 00:12:59.280
wants to get the priority also,
it might get confused.

00:12:59.280 --> 00:13:01.940
Those priorities might get out of sync.

00:13:05.190 --> 00:13:07.490
Mac is full symmetric multiprocessing.

00:13:07.490 --> 00:13:10.620
It was designed from the ground
up to handle systems with

00:13:10.620 --> 00:13:12.410
symmetric multiprocessors.

00:13:12.410 --> 00:13:17.140
So all of the code that we use
for locking and synchronization

00:13:17.140 --> 00:13:19.230
is designed for that use.

00:13:19.230 --> 00:13:22.340
We have a single kernel for
uniprocessor and multiprocessor.

00:13:22.490 --> 00:13:25.560
Basically,
that simplifies our customer support.

00:13:25.680 --> 00:13:27.920
We have a single binary that we ship.

00:13:27.920 --> 00:13:29.300
We have one install.

00:13:29.300 --> 00:13:32.960
So basically,
you can take a disk that you installed

00:13:33.200 --> 00:13:35.080
on your dual processor system and
you can install it on your Mac OS X.

00:13:35.100 --> 00:13:38.580
Bring it over to a single processor
system and it'll work just fine.

00:13:38.580 --> 00:13:41.570
You don't have to worry about
whether that was specifically

00:13:41.570 --> 00:13:42.900
designed to be UP or MP.

00:13:44.620 --> 00:13:48.440
One of the implementation details
of Mach is we have lazy floating

00:13:48.440 --> 00:13:50.490
point and vector context save.

00:13:50.490 --> 00:13:54.860
I mentioned this was one of the costs
of threading in the context area was

00:13:54.860 --> 00:13:59.000
how you have this floating point and
vector state that has to be saved

00:13:59.000 --> 00:14:01.430
and restored on context switches.

00:14:01.580 --> 00:14:05.080
Well, Mach has a little optimization
where if your thread hasn't used

00:14:05.200 --> 00:14:08.780
any floating point or vector state,
we know that and will lazily save

00:14:08.990 --> 00:14:12.960
and restore that depending on only if
the thread has used those features.

00:14:15.700 --> 00:14:19.460
The Mach scheduler is what our
scheduling system is based off of.

00:14:19.540 --> 00:14:22.850
It came from the OSF,
the Open Software Foundation.

00:14:22.960 --> 00:14:26.070
We've heavily modified it
since we originally got it,

00:14:26.210 --> 00:14:29.560
and it's been tuned for the
higher layers of the system.

00:14:29.560 --> 00:14:32.590
It uses a global run queue,
meaning that we don't have

00:14:32.590 --> 00:14:34.220
a run queue per processor.

00:14:34.220 --> 00:14:38.280
We have a run queue for the whole system,
and basically as threads block

00:14:38.280 --> 00:14:41.930
and other threads become runnable,
the system will schedule it

00:14:42.060 --> 00:14:44.230
based on the available processor.

00:14:45.110 --> 00:14:47.750
There's a notion of an
idle processor signal,

00:14:47.750 --> 00:14:50.170
so if a processor
happens to be not in use,

00:14:50.170 --> 00:14:52.910
there's a signal that occurs
that lets the system know that,

00:14:53.050 --> 00:14:55.660
okay, I can now schedule a
thread on this processor.

00:14:55.660 --> 00:14:59.120
One of the things that's a
little bit different in Jaguar is

00:14:59.120 --> 00:15:01.330
we've tuned the thread affinity.

00:15:01.340 --> 00:15:04.500
Thread affinity is basically the
notion that you want a thread

00:15:04.500 --> 00:15:08.190
to continue running on the same
processor that it's been running on.

00:15:08.240 --> 00:15:12.090
The reason behind that
is for cache affinity,

00:15:12.090 --> 00:15:14.440
because when you're using
a cache on the system,

00:15:14.440 --> 00:15:14.440
you're not going to be able to
run a thread on the same processor

00:15:14.440 --> 00:15:14.440
that it's been running on.

00:15:14.490 --> 00:15:17.360
So if you have a cache on the system,
you don't want to have to migrate your

00:15:17.360 --> 00:15:21.440
data kind of back and forth between
the two caches on the processor.

00:15:21.440 --> 00:15:24.330
So in Jaguar, we try and be a lot more
aggressive about keeping threads

00:15:24.450 --> 00:15:25.960
running on the same processor.

00:15:26.020 --> 00:15:31.240
We don't have any high-level API for
binding threads to a specific processor,

00:15:31.460 --> 00:15:35.020
but you'll notice if you're using
the CPU monitor app and you have

00:15:35.020 --> 00:15:38.570
a single-threaded process running,
that thread is not going to

00:15:38.570 --> 00:15:42.190
bounce back and forth as much
between the multiple processors.

00:15:42.610 --> 00:15:45.230
The Mac schedule is
responsible for the preemption.

00:15:45.230 --> 00:15:47.280
So just to reiterate,
your threads can get

00:15:47.280 --> 00:15:51.320
interrupted at any time,
and you have to be able to react to that.

00:15:51.450 --> 00:15:56.340
So if you're using atomic operations,
you're protected from that.

00:15:56.470 --> 00:16:00.430
But depending on global data,
you really have to make sure that

00:16:00.440 --> 00:16:03.880
you're using the synchronization
primitives that the Thread API provides.

00:16:06.250 --> 00:16:08.110
I'll talk a little bit
about Pthreads now.

00:16:08.370 --> 00:16:13.190
This is the lowest level API that we
recommend people using in the system.

00:16:13.190 --> 00:16:17.200
It's what the Darwin thread
model is based off of.

00:16:18.880 --> 00:16:21.730
Like I said, it's,
it's used by all the thread APIs.

00:16:21.860 --> 00:16:25.640
So the Carbon, the Cocoa,
and the Java thread APIs all call

00:16:25.660 --> 00:16:27.660
into the POSIX implementation.

00:16:28.080 --> 00:16:31.860
The, the benefit of that is whenever
we make improvements to the

00:16:31.930 --> 00:16:34.880
POSIX thread implementation,
all the other thread models

00:16:34.880 --> 00:16:36.370
can take advantage of that.

00:16:36.450 --> 00:16:38.680
So if we make mutexes faster,
if we make context

00:16:38.910 --> 00:16:41.820
switching a little faster,
all these high-level thread

00:16:41.860 --> 00:16:43.710
APIs can take advantage of that.

00:16:45.030 --> 00:16:47.980
I call it a POSIX-like
implementation because we don't

00:16:47.990 --> 00:16:51.940
have a conformance test suite that
we pass when we implement this API,

00:16:51.940 --> 00:16:56.750
but when we refer to it,
we want to use the POSIX naming and

00:16:56.750 --> 00:17:04.640
conventions because it's fairly easy
to go down to your local bookstore

00:17:04.640 --> 00:17:04.640
and pick up a book on Pthreads
and just start using it on Darwin.

00:17:05.130 --> 00:17:08.160
Like I said, we have a one-to-one
mock-to-Pthread implementation.

00:17:08.160 --> 00:17:11.000
Simplifies the user-level APIs.

00:17:11.000 --> 00:17:12.100
Simplifies debugging.

00:17:12.100 --> 00:17:17.880
All the applications that you see would
have to be much more complex if we had

00:17:17.880 --> 00:17:20.580
a multiplexing thread implementation.

00:17:20.580 --> 00:17:24.260
Pthreads is, like I said,
a fairly common API.

00:17:24.260 --> 00:17:28.820
It's easy to go find a reference for
it and pick it up fairly quickly.

00:17:28.820 --> 00:17:31.730
There are some misuses you might
have to be aware of I'll mention in

00:17:31.730 --> 00:17:36.680
a little bit that are fairly common
for people who are new to the API.

00:17:36.680 --> 00:17:40.930
One thing that we currently have,
if you're looking at the CD that

00:17:40.930 --> 00:17:44.690
you got at the conference,
we don't have any system-wide types yet.

00:17:44.890 --> 00:17:51.310
So POSIX specifies an implementation
that provides process-wide or system-wide

00:17:51.310 --> 00:17:54.400
mutexes and condition variables.

00:17:54.400 --> 00:17:57.880
So process-wide means that they're
visible within the same task.

00:17:58.080 --> 00:18:01.260
I can have a mutex that I lock
and unlock in the same task.

00:18:01.640 --> 00:18:05.600
System-wide means multiple tasks can
put a mutex or a condition variable

00:18:05.690 --> 00:18:07.590
in shared memory and use that.

00:18:07.840 --> 00:18:11.490
This is pretty common on
databases or server applications,

00:18:11.490 --> 00:18:14.210
but as of today, we don't have that yet.

00:18:14.270 --> 00:18:15.390
Okay.

00:18:16.670 --> 00:18:20.110
One thing to be aware of in Pthreads
is synchronization is not cheap.

00:18:20.190 --> 00:18:22.820
You really want to make sure that
your threads are data-driven.

00:18:22.820 --> 00:18:26.960
You want to take full advantage
of the processors in your system.

00:18:26.960 --> 00:18:29.400
You want the threads just to
be cranking on the data and

00:18:29.400 --> 00:18:30.570
then signal when they're done.

00:18:30.580 --> 00:18:33.840
You don't want threads to be
sending status updates all the time.

00:18:33.840 --> 00:18:36.120
There's other mechanisms to do that.

00:18:36.120 --> 00:18:39.670
You can peek at the thread and
check its status if you just want

00:18:39.670 --> 00:18:42.110
a user-level UI notification.

00:18:42.960 --> 00:18:45.650
But if you're ping-ponging
between threads back and forth,

00:18:45.720 --> 00:18:47.140
that's going to cost you a little bit.

00:18:48.620 --> 00:18:51.360
By default,
the specification for Pthread says that

00:18:51.360 --> 00:18:56.460
threads are what's called joinable,
meaning the system will worry about that

00:18:56.540 --> 00:18:58.800
thread and keep track of it for you.

00:18:58.800 --> 00:19:02.140
And if you really want that thread
just to go off and do its job and you

00:19:02.230 --> 00:19:07.200
don't want to hear about it anymore,
you have to use what's called detach API,

00:19:07.200 --> 00:19:10.570
meaning you either create the
thread detached or you can detach

00:19:10.570 --> 00:19:12.720
the thread after it's been created.

00:19:13.180 --> 00:19:16.030
This basically lets the system
know that you don't really care

00:19:16.030 --> 00:19:18.400
when that thread exits anymore,
you just want it to

00:19:18.400 --> 00:19:19.580
go off and do its job.

00:19:19.600 --> 00:19:24.040
What you'll notice if you don't detach is
that these threads will just hang around

00:19:24.040 --> 00:19:28.860
in the system consuming these resources
until someone joins them or cancels them.

00:19:31.120 --> 00:19:34.660
There's a stack issue, like I said,
with threads where by default

00:19:34.660 --> 00:19:37.580
you get a fairly large stack,
and this doesn't cost you too

00:19:37.580 --> 00:19:40.380
much as long as your application
isn't using very many threads.

00:19:40.650 --> 00:19:43.340
But once you get up to, you know,
a lot of threads,

00:19:43.510 --> 00:19:47.420
the stack size actually becomes
a limitation because your virtual

00:19:47.840 --> 00:19:50.020
address space starts to get smaller.

00:19:50.020 --> 00:19:53.430
The API and P threads that let you
shrink your stack size will allow

00:19:53.740 --> 00:19:55.390
you to do that at creation time.

00:19:55.390 --> 00:19:59.200
So you specify, I only want to use 16K
of stack for my thread.

00:19:59.200 --> 00:20:00.930
And this is probably enough for
you to do that at creation time.

00:20:01.040 --> 00:20:02.580
But this is probably
enough for most usage.

00:20:02.580 --> 00:20:05.340
So if you're creating threads a lot,
you might want to take a look at this.

00:20:05.360 --> 00:20:09.440
Checking predicates is very
important in P threads.

00:20:09.450 --> 00:20:14.210
A predicate is the global
notion of a condition that has

00:20:14.210 --> 00:20:16.020
occurred or you're waiting for.

00:20:16.020 --> 00:20:19.950
So you usually have a global variable,
and if you are waiting for a

00:20:19.970 --> 00:20:24.050
condition to be signaled using
the P thread condition mechanisms,

00:20:24.050 --> 00:20:27.560
what you do is lock a mutex,
check the global variable to see

00:20:27.760 --> 00:20:29.920
if the condition has occurred.

00:20:29.920 --> 00:20:33.390
And that condition is only
manipulated within that mutex.

00:20:33.390 --> 00:20:37.200
If the condition hasn't occurred yet,
you then wait on the condition,

00:20:37.200 --> 00:20:39.560
which simultaneously unlocks the mutex.

00:20:39.680 --> 00:20:44.010
Now, if you don't have a predicate,
that causes some scheduling problems,

00:20:44.010 --> 00:20:48.170
and your application will not respond
like you want because you basically

00:20:48.190 --> 00:20:51.300
kind of cheated the system by saying,
oh, I know what I'm doing.

00:20:51.300 --> 00:20:53.020
I'll just wait on this condition.

00:20:53.020 --> 00:20:56.110
Well, there's race conditions
implicit in this API,

00:20:56.120 --> 00:20:58.120
so you have to have a predicate.

00:20:58.840 --> 00:21:01.020
And you always have to make
sure that it's checked.

00:21:01.590 --> 00:21:05.020
Another reason is because the
condition wait implementation

00:21:05.020 --> 00:21:06.390
can spuriously wake up.

00:21:06.580 --> 00:21:10.310
The specification actually says
that a condition wait can wake up

00:21:10.310 --> 00:21:14.610
with a success result even though
the condition hasn't been signaled.

00:21:14.620 --> 00:21:17.790
And the reason behind that is
on a multiprocessor system,

00:21:17.790 --> 00:21:21.150
it's very difficult to implement
this atomic unlock the mutex

00:21:21.150 --> 00:21:24.950
and wait on the condition,
so they give you a little bit of leeway.

00:21:24.960 --> 00:21:27.760
And once your condition
has been signaled,

00:21:27.760 --> 00:21:31.600
you also get a successful wake up,
so you also have to check that predicate

00:21:31.600 --> 00:21:34.510
every time your condition wait returns.

00:21:36.300 --> 00:21:39.670
There's an API for canceling threads,
which basically means I would

00:21:39.710 --> 00:21:41.610
like that thread to stop running.

00:21:41.610 --> 00:21:44.300
And you do this from an outside thread.

00:21:44.300 --> 00:21:48.700
The two models are deferred cancellation
and asynchronous cancellation.

00:21:48.700 --> 00:21:51.960
Deferred cancellation is good
because it's a lot more well-defined.

00:21:51.960 --> 00:21:55.360
You tell the thread more as a
request that you'd like it to cancel.

00:21:55.360 --> 00:21:58.110
The thread, if it gets to a point
where it's safe to cancel,

00:21:58.110 --> 00:22:01.140
will then exit itself,
clean up its resources, and go away.

00:22:02.980 --> 00:22:05.950
Async cancellation,
asynchronous cancellation is

00:22:05.950 --> 00:22:09.180
not considered very good because
you don't really know where the

00:22:09.180 --> 00:22:10.250
thread is when it's running.

00:22:10.260 --> 00:22:12.840
If it's not at a safe point
and you tell it to go away,

00:22:12.920 --> 00:22:16.540
it could be holding a critical system
resource like a lock and you basically

00:22:16.540 --> 00:22:18.600
just yank that out from underneath it.

00:22:18.760 --> 00:22:23.420
So we discourage the use of that,
but it's part of the API specification.

00:22:25.980 --> 00:22:29.170
A little bit more detail
on Pthread Cancel.

00:22:29.170 --> 00:22:35.250
In Jaguar, we've added more cancellation
points besides Pthread Test Cancel.

00:22:35.260 --> 00:22:40.890
So the system-defined cancellation points
are described in the POSIX specification.

00:22:40.900 --> 00:22:45.370
They're kind of the common Unix
system calls like read and select,

00:22:45.370 --> 00:22:50.660
all these things that could normally
block for an indefinite amount of time.

00:22:50.660 --> 00:22:55.780
You want to make sure that you can wake
up a thread that's blocked in that API.

00:22:56.320 --> 00:22:59.930
One of the common uses is Pthread
condition weight as one of these places

00:23:00.080 --> 00:23:03.320
where you might want to cancel a thread
while it's in the middle of this API.

00:23:03.320 --> 00:23:06.360
One of the interesting things
about a Pthread condition weight,

00:23:06.360 --> 00:23:09.090
like I said,
it unlocks the mutex that you were

00:23:09.090 --> 00:23:10.560
using to protect your predicate.

00:23:10.560 --> 00:23:14.490
So when you cancel a thread,
it reacquires that mutex.

00:23:14.640 --> 00:23:18.140
So you have to use what's called a
cleanup handler when you cancel a thread

00:23:18.140 --> 00:23:20.210
that's blocked in a condition weight.

00:23:20.320 --> 00:23:24.570
That cleanup handler will unlock the
mutex and let the thread exit cleanly

00:23:24.580 --> 00:23:27.430
because you don't want to have a thread
exiting holding a mutex because that

00:23:27.470 --> 00:23:30.600
means that no other thread in the process
will be able to acquire that again.

00:23:33.200 --> 00:23:35.520
Another added API is Pthread at Fork.

00:23:35.530 --> 00:23:39.800
Now, this is kind of esoteric in that
it's usually only used for library

00:23:39.800 --> 00:23:43.950
implementations or plug-ins that
need to really worry about when the

00:23:43.960 --> 00:23:46.650
process has forked a new child process.

00:23:46.700 --> 00:23:51.230
The problem with this is it's very
hard to do correctly because usually

00:23:51.230 --> 00:23:55.750
all the subsystems that are using
Pthread at Fork need to be intimately

00:23:55.750 --> 00:23:59.950
aware of each other so that they don't
introduce any deadlock conditions.

00:23:59.990 --> 00:24:06.210
Because if I'm depending on API such
that that API needs to acquire or release

00:24:06.210 --> 00:24:11.020
a mutex before the process has forked,
you need to make sure that all

00:24:11.020 --> 00:24:14.290
the at fork routines have been
registered in the proper order.

00:24:14.300 --> 00:24:20.900
So we kind of restrict its use and
mainly provide it just to supply the API.

00:24:23.290 --> 00:24:27.800
Another set of new additions are the
attributes on conditions and mutexes.

00:24:27.800 --> 00:24:31.360
This was a big request from a lot
of our customers who were saying

00:24:31.360 --> 00:24:35.130
that they were finding it difficult
to port existing applications

00:24:35.130 --> 00:24:37.540
because we didn't provide this API.

00:24:37.540 --> 00:24:41.420
Like I said, right now the system-wide
attributes aren't supported,

00:24:41.420 --> 00:24:43.950
but if you look in the
pthread.h header file,

00:24:44.060 --> 00:24:46.600
you can see the attributes
that we support.

00:24:47.840 --> 00:24:51.570
One of the interesting ones is
the get and set stack attribute.

00:24:51.610 --> 00:24:56.180
Now that is an addition in what's called
the single-unit specification version 3,

00:24:56.180 --> 00:25:00.400
which is kind of an aggregate that
contains the POSIX thread specification.

00:25:00.400 --> 00:25:05.740
This allows you to get and set
the stack size and stack location.

00:25:05.740 --> 00:25:08.630
So if you're creating and
destroying a lot of threads,

00:25:08.630 --> 00:25:12.160
you may want to actually pick a place
that you want the stack to start

00:25:12.160 --> 00:25:16.080
at for that thread so the system
doesn't have to allocate stack for it.

00:25:16.220 --> 00:25:17.620
And you can also specify
the size of the stack.

00:25:17.620 --> 00:25:20.570
So if you know your thread is
consuming very little stack,

00:25:20.570 --> 00:25:22.780
you can optimize that a little bit more.

00:25:25.520 --> 00:25:28.350
Another thing that's been
added is per-thread signaling,

00:25:28.350 --> 00:25:30.280
a very commonly requested feature.

00:25:30.280 --> 00:25:35.170
The three APIs that are implemented
under this are PthreadKill,

00:25:35.170 --> 00:25:37.420
PthreadSigMask, and SigWait.

00:25:37.440 --> 00:25:41.240
PthreadKill is the mechanism that
you use to tell a thread that

00:25:41.240 --> 00:25:43.240
you want it to be interrupted.

00:25:43.360 --> 00:25:46.500
The thread, if it handles that signal,
will be interrupted,

00:25:46.610 --> 00:25:49.340
do what it normally does
in a signal handler,

00:25:49.340 --> 00:25:51.120
and then continue execution.

00:25:53.080 --> 00:25:56.180
PthreadSigMask is the API that
specifies which signals a

00:25:56.380 --> 00:25:57.990
thread is willing to handle.

00:25:58.000 --> 00:26:02.710
So a common use is if an application is
multithreaded and it can get external

00:26:02.780 --> 00:26:07.390
signals from outside the process,
you dedicate a thread with PthreadSigMask

00:26:07.390 --> 00:26:09.640
to handle those external signals.

00:26:11.060 --> 00:26:14.480
SIGWAIT is a mechanism that will
allow you to basically block a thread

00:26:14.480 --> 00:26:16.300
until one of these signals occur.

00:26:16.300 --> 00:26:19.660
So you can just dedicate that
thread to handling a signal and it

00:26:19.660 --> 00:26:23.540
doesn't have to do any work besides
sitting in its SIGWAIT routine.

00:26:23.560 --> 00:26:28.630
This is very helpful in porting a lot
of Unix applications like Apache 2.0

00:26:28.720 --> 00:26:31.640
makes heavy use of per-thread signaling.

00:26:34.470 --> 00:26:37.600
Another commonly requested
feature was read-write locks.

00:26:37.680 --> 00:26:43.190
Pthread read-write lock will allow you
to use global state if it's commonly

00:26:43.250 --> 00:26:47.800
read but not as frequently written,
then you can optimize

00:26:48.230 --> 00:26:50.360
this using this API.

00:26:50.500 --> 00:26:53.020
Our current implementation
prefers writers,

00:26:53.020 --> 00:26:57.760
meaning that if you have multiple readers
waiting for a lock that there's one

00:26:57.760 --> 00:27:01.180
writer on and another writer comes in,
that writer will take precedence.

00:27:01.200 --> 00:27:04.800
The idea is that that will allow
the system to progress a little bit

00:27:04.800 --> 00:27:09.000
faster because writers usually need
to go and make a change and continue,

00:27:09.000 --> 00:27:12.980
whereas readers, you know,
you want to have more than a few readers

00:27:12.980 --> 00:27:17.410
reading at a time where you only want
to have one writer writing at a time.

00:27:17.460 --> 00:27:20.460
This is now mandatory in the
single-unit configuration.

00:27:20.630 --> 00:27:23.720
We have a unique specification
for the threads extension,

00:27:23.720 --> 00:27:26.040
so we decided to implement that as well.

00:27:26.040 --> 00:27:28.480
There's a couple new mutex types.

00:27:28.600 --> 00:27:32.500
Pthread mutex error check is very handy.

00:27:32.500 --> 00:27:35.470
It'll allow you to determine
whether a thread would deadlock

00:27:35.890 --> 00:27:38.710
when it attempts to lock a mutex,
or it will let you know when

00:27:38.710 --> 00:27:41.760
a thread that unlocks a mutex
wasn't actually the mutex holder.

00:27:41.760 --> 00:27:45.840
This functionality has been in
Puma using the debug lib system,

00:27:46.090 --> 00:27:47.860
if you know how to do that.

00:27:47.860 --> 00:27:50.360
There's two versions of
the system framework.

00:27:50.500 --> 00:27:53.210
One that has some debug help in it.

00:27:53.280 --> 00:27:56.270
If you use the DYLD image
suffix environment variable,

00:27:56.270 --> 00:27:59.730
you can specify that you want your
program to use the debug flavor

00:27:59.850 --> 00:28:01.790
while you're under development.

00:28:03.170 --> 00:28:06.620
The recursive mutex is there
mostly for completeness,

00:28:06.620 --> 00:28:10.430
but usually I've never found a
case where you couldn't design

00:28:10.430 --> 00:28:14.800
a locking implementation that
didn't need recursive mutexes.

00:28:14.800 --> 00:28:18.200
It's usually for people who are porting
something that depends on recursive

00:28:18.200 --> 00:28:22.100
mutexes and you haven't quite spent
the time to reimplement that yet.

00:28:24.420 --> 00:28:26.670
For references in Pthreads,
the man pages have

00:28:26.680 --> 00:28:29.240
been updated in Jaguar,
so you can now use those

00:28:29.530 --> 00:28:31.640
as a pretty good reference.

00:28:31.660 --> 00:28:35.450
The Darwin CVS repository is where
the implementation actually lives,

00:28:35.590 --> 00:28:37.260
so you can follow the progress.

00:28:37.570 --> 00:28:41.590
Like I said, we'll be making some changes
since the CD that you got

00:28:41.590 --> 00:28:45.230
before Jaguar is finished,
and you can track that in the

00:28:45.230 --> 00:28:46.940
LibC and the XNU projects.

00:28:47.000 --> 00:28:50.110
XNU is the kernel that has
the high-level or low-level,

00:28:50.250 --> 00:28:54.650
depending on your perspective,
implementation of some of the primitives

00:28:54.660 --> 00:28:56.700
that are used by the LibC project.

00:28:56.700 --> 00:29:01.580
The Open Group has a nice
website with the single-unit

00:29:01.580 --> 00:29:06.180
specification that we kind of model,
and if you want to go there

00:29:06.180 --> 00:29:09.600
and get a nice bookmark there
page for the Pthreads API,

00:29:09.600 --> 00:29:11.010
it's a fairly good reference.

00:29:11.050 --> 00:29:15.020
And the News Group Comp Programming
Threads is where a lot of

00:29:15.020 --> 00:29:17.600
Pthreads experts like to hang out.

00:29:20.350 --> 00:29:22.600
I'll talk a little bit now
about the Carbon MP API.

00:29:22.600 --> 00:29:27.640
It's one of the high-level APIs that
lives on top of the Darwin POSIX threads.

00:29:27.640 --> 00:29:33.370
One of the notions that is a
little bit different in Carbon is

00:29:33.370 --> 00:29:37.880
the MP tasks are what I was
referring to as threads previously.

00:29:37.880 --> 00:29:42.190
So in Classic,
you had MP tasks that ran in

00:29:42.190 --> 00:29:45.150
a process's address space,
and those are basically what I've

00:29:45.410 --> 00:29:46.750
been referring to as threads.

00:29:48.100 --> 00:29:50.790
A difference between
Classic and Mac OS X,

00:29:50.790 --> 00:29:53.100
obviously,
is you now have separate address spaces,

00:29:53.100 --> 00:29:56.970
so MP tasks won't be able to
communicate like they could in

00:29:56.970 --> 00:30:00.430
Classic between multiple address spaces,
so you have to be aware of that.

00:30:02.800 --> 00:30:06.490
Like all the thread APIs,
there's several mechanisms that

00:30:06.650 --> 00:30:08.790
exist to coordinate MP tasks.

00:30:08.920 --> 00:30:11.400
There's semaphores,
which are simple signaling mechanisms.

00:30:11.400 --> 00:30:15.830
Message queues,
which allow you to create fairly

00:30:16.250 --> 00:30:20.270
complex worker-client implementations.

00:30:20.300 --> 00:30:23.640
There are event groups,
so you can wait for lots of

00:30:23.640 --> 00:30:27.840
different signals to happen
using a single entry point.

00:30:27.880 --> 00:30:33.480
There's also critical regions,
where if you have a set of code that you

00:30:33.480 --> 00:30:36.150
only want one thread to be in at a time,
you can specify that

00:30:36.150 --> 00:30:37.320
as a critical region.

00:30:37.320 --> 00:30:40.680
It also provides recursive entry,
so it knows that the same thread

00:30:40.680 --> 00:30:42.520
can enter that critical region.

00:30:44.760 --> 00:30:50.160
The MPTask API also provides some handy
atomic increment/decrement operations.

00:30:50.310 --> 00:30:54.180
So if you have a very common operation
like a reference count that you

00:30:54.180 --> 00:30:57.900
want to increment or decrement,
rather than taking a full-blown lock,

00:30:58.260 --> 00:31:01.860
changing the variable and unlock,
you can just use one of

00:31:01.860 --> 00:31:03.840
these atomic operations.

00:31:04.070 --> 00:31:08.870
Examples of the APIs in Mac OS X that
use the MPTask are the Synchronous

00:31:08.870 --> 00:31:10.920
File Manager and OpenTransport.

00:31:11.130 --> 00:31:14.110
Both take advantage of this API.

00:31:14.450 --> 00:31:17.800
The Carbon API has a list
of thread-safe services,

00:31:17.950 --> 00:31:24.180
and that's documented in Tech Note 2006,
if you want to take a look at that.

00:31:25.810 --> 00:31:29.980
Next I'll talk about Cocoa Threads,
another high level thread API,

00:31:30.110 --> 00:31:32.700
kind of a peer to the Carbon threading.

00:31:32.700 --> 00:31:36.560
NSThread is the Cocoa Thread class.

00:31:36.920 --> 00:31:38.090
It's very simple to use.

00:31:38.600 --> 00:31:43.700
There's very few APIs that
you have to learn to use this.

00:31:43.700 --> 00:31:47.700
Most threading models have the
notion of a start function.

00:31:47.830 --> 00:31:53.470
So in Objective-C you have a start
method that your class will implement.

00:31:53.750 --> 00:31:58.110
In NSThreads, they keep track of the
Objective-C exception model.

00:31:58.120 --> 00:32:00.550
So when you raise an
Objective-C exception,

00:32:00.560 --> 00:32:04.960
that raise occurs in the specific
NSThread rather than kind of

00:32:05.180 --> 00:32:07.350
throughout the whole process.

00:32:09.110 --> 00:32:11.120
There's an exit notification,
which is kind of like the

00:32:11.230 --> 00:32:12.850
joining mechanism I talked about.

00:32:12.860 --> 00:32:15.700
When a thread exits, you may just want to
know that it's gone away,

00:32:15.700 --> 00:32:18.850
so you can register for that
notification through the normal

00:32:18.850 --> 00:32:20.620
Cocoa notification mechanisms.

00:32:20.620 --> 00:32:24.180
Each NS thread also has
a per-thread dictionary.

00:32:24.180 --> 00:32:27.880
So this is kind of an extension
of the notion of per-thread data,

00:32:27.880 --> 00:32:33.000
where a thread can have a set of data
that's just for that specific thread.

00:32:33.000 --> 00:32:35.400
And in Cocoa,
we provide a nice little wrapper

00:32:35.480 --> 00:32:39.230
that lets you put an object-oriented
NSDictionary on top of that

00:32:39.230 --> 00:32:41.490
data for key value type access.

00:32:44.920 --> 00:32:48.220
There's an AppKit extension in
NSThreads which basically is a hint

00:32:48.410 --> 00:32:51.250
to the system that says I'm going
to be creating a background thread

00:32:51.340 --> 00:32:52.710
that may be doing some drawing.

00:32:52.710 --> 00:32:55.520
So if you look in the
NSApplication class,

00:32:55.520 --> 00:32:57.380
it's called DetachedDrawingThread.

00:32:57.380 --> 00:33:00.530
And that's, like I said,
it's basically a hint to the

00:33:00.530 --> 00:33:04.130
system that lets it know that the
main thread may need to respond

00:33:04.250 --> 00:33:08.370
to requests from this background
thread to do drawing operations.

00:33:09.330 --> 00:33:11.150
Each NSThread has a separate run loop.

00:33:11.350 --> 00:33:14.850
So you may see some interesting
behavior that you have to worry about

00:33:14.850 --> 00:33:17.940
where if you post a notification,
it doesn't go to the full

00:33:17.980 --> 00:33:20.540
application run loop,
the main run loop that the

00:33:20.550 --> 00:33:22.700
event handling is occurring in.

00:33:22.700 --> 00:33:24.750
It only goes to your thread's run loop.

00:33:24.800 --> 00:33:28.190
So there's other mechanisms
that you can use if you want a

00:33:28.200 --> 00:33:32.560
notification to be broadcast more
broadly outside of your thread.

00:33:32.560 --> 00:33:35.060
You also need to start
the run loop explicitly.

00:33:35.060 --> 00:33:38.400
So when you create a new thread
and you want that thread to

00:33:38.410 --> 00:33:39.060
have a run loop to handle it,
you need to start the

00:33:39.060 --> 00:33:39.060
run loop explicitly.

00:33:39.070 --> 00:33:42.260
So if you want to handle things
like these notifications,

00:33:42.260 --> 00:33:44.540
that run loop hasn't been running yet.

00:33:44.560 --> 00:33:48.380
You have to kind of think about how this
thread was created and decide once you've

00:33:48.380 --> 00:33:52.100
set up everything to go ahead and start
its run loop and let it do its thing.

00:33:52.140 --> 00:33:56.510
There's also an auto-release pool
associated with every thread.

00:33:56.670 --> 00:34:00.070
So as a thread is created,
the memory management that's

00:34:00.140 --> 00:34:03.750
part of Cocoa that allows
you to auto-release objects,

00:34:03.750 --> 00:34:06.900
meaning you can kind of
defer the deallocation of

00:34:06.900 --> 00:34:09.060
that object to a later time.

00:34:09.080 --> 00:34:12.350
And in an NSThread,
every thread has a pool

00:34:12.420 --> 00:34:14.700
that's associated with it.

00:34:14.870 --> 00:34:17.980
So when you auto-release an object,
it goes into the thread's pool.

00:34:17.980 --> 00:34:20.380
When the thread exits,
that auto-release pool

00:34:20.380 --> 00:34:21.640
also gets destroyed.

00:34:24.900 --> 00:34:30.490
Some of the future things we're working
on in all of the thread APIs are

00:34:30.490 --> 00:34:32.350
the notion of priority inheritance.

00:34:32.360 --> 00:34:35.590
This is kind of a problem where
once you've created threads

00:34:35.590 --> 00:34:38.770
with different priorities,
you may find that a higher priority

00:34:38.770 --> 00:34:42.450
thread is blocked waiting for a lower
priority thread to release a lock.

00:34:42.530 --> 00:34:45.650
But because of the scheduling behavior,
that lower priority thread

00:34:45.650 --> 00:34:49.040
won't get to run while this
priority thread is blocked.

00:34:49.240 --> 00:34:53.540
So an implementation that could be
designed would allow that lower priority

00:34:53.550 --> 00:34:57.840
thread to temporarily inherit the
priority of the higher priority thread.

00:34:57.840 --> 00:35:02.440
Now, this would allow the higher priority
thread to let the lower priority

00:35:02.770 --> 00:35:06.960
thread release whatever resources
it was holding and continue.

00:35:08.540 --> 00:35:11.050
System Shared Resources, like I said,
we're working on that.

00:35:11.230 --> 00:35:15.140
It's very commonly requested
by server and database clients,

00:35:15.140 --> 00:35:20.030
so we really want to make sure that we
provide all the APIs that they need.

00:35:20.060 --> 00:35:20.940
Performance.

00:35:20.970 --> 00:35:23.820
There's always room for
improvement in performance.

00:35:23.970 --> 00:35:27.940
We're really trying to make the
threading APIs as efficient as possible.

00:35:29.660 --> 00:35:34.230
There's been some talk about things like
implementing thread pools so that you

00:35:34.230 --> 00:35:39.060
can have a nice high-level way to create
thread pools in the POSIX-type API.

00:35:39.060 --> 00:35:43.300
Other things, just low-level making the
context switch faster,

00:35:43.420 --> 00:35:45.980
making threading overall improve.

00:35:45.980 --> 00:35:49.280
And like I said, when we make performance
improvements at the pthread level,

00:35:49.370 --> 00:35:51.740
all the other thread layers
take advantage of that.

00:35:53.150 --> 00:35:56.110
So if you want to follow this,
you should watch the Darwin Repository

00:35:56.180 --> 00:35:59.920
because that's where the threading and
the kernel implementations live for the

00:35:59.970 --> 00:36:01.980
Pthreads and the Mach implementation.

00:36:04.930 --> 00:36:07.260
So now I'd like to bring
up Robert Bowdidge,

00:36:07.260 --> 00:36:12.110
who works in the Developer Tools team,
and he's going to show a demo of a

00:36:12.310 --> 00:36:17.850
multithreaded application and how to
inspect what's going on at the time.

00:36:23.700 --> 00:36:25.540
Okay, thank you, Matt.

00:36:25.540 --> 00:36:27.190
As Matt mentioned,
my name is Robert Bowdidge.

00:36:27.200 --> 00:36:29.310
I am a member of the
Developer Tools Group,

00:36:29.310 --> 00:36:32.240
where I'm responsible for the
performance tools on Mac OS X.

00:36:32.270 --> 00:36:36.280
Now, what Matt has gone through is a
little bit of the how on threads.

00:36:36.280 --> 00:36:38.580
He's also told us a little
of the why on threads,

00:36:38.580 --> 00:36:40.340
about why we actually might need them.

00:36:40.470 --> 00:36:43.760
What I'd like to do is take that
one step further and try to give you

00:36:43.760 --> 00:36:48.140
some examples of good thread use,
to give you some examples about

00:36:48.140 --> 00:36:53.260
how Apple has actually used
threading in its own applications.

00:36:55.520 --> 00:36:59.260
The way that I'm going to do this is I'm
going to use a performance tool called

00:36:59.400 --> 00:37:01.210
Thread Viewer that's on the developer CD.

00:37:01.350 --> 00:37:03.560
How many of you have actually tried this?

00:37:04.240 --> 00:37:04.690
That's good.

00:37:04.810 --> 00:37:07.800
How many of you understand
what it gives out?

00:37:07.920 --> 00:37:08.590
Good.

00:37:08.620 --> 00:37:11.540
Sort of good.

00:37:12.640 --> 00:37:16.940
What ThreadViewer does is it
provides a timeline visualization of

00:37:16.940 --> 00:37:18.440
what's going on in an application.

00:37:18.440 --> 00:37:20.520
It tends to be kind of coarse-grained,
but it's very nice for

00:37:20.650 --> 00:37:23.600
understanding sort of overall
trends of what your app is doing.

00:37:23.670 --> 00:37:26.910
The first app I'm going
to look at is the Finder.

00:37:27.100 --> 00:37:30.490
Now, the Finder's actually a
really interesting example

00:37:30.700 --> 00:37:34.310
for threading because,
first of all, it's our primary access

00:37:34.310 --> 00:37:35.770
into the file system.

00:37:35.800 --> 00:37:39.000
You know,
it has a direct manipulation interface,

00:37:39.030 --> 00:37:41.960
and so we expect that when
we drag a folder around,

00:37:41.960 --> 00:37:45.070
we want to imagine as if we're
actually dragging a folder

00:37:45.160 --> 00:37:46.310
from one place to another.

00:37:46.310 --> 00:37:49.900
And so the Finder must be as responsive
as possible for us to be happy.

00:37:49.960 --> 00:37:52.880
On the other hand,
the Finder also has the problem

00:37:52.880 --> 00:37:56.640
that it's dealing with two of the
slowest devices on the system.

00:37:56.730 --> 00:37:58.350
It's dealing with the disk,

00:37:58.870 --> 00:38:00.910
which when it goes out to get
accesses is going to take a

00:38:00.910 --> 00:38:02.650
while to come back with data.

00:38:02.790 --> 00:38:04.570
And it's dealing with the
network which is even worse

00:38:04.650 --> 00:38:07.690
because nothing may come back.

00:38:08.430 --> 00:38:12.490
And so the finder has to be extremely
good and has to try as hard as it can to

00:38:12.660 --> 00:38:15.880
try to make sure that it's as responsive
as possible while dealing with these

00:38:15.880 --> 00:38:20.680
resources that tend to be extremely slow.

00:38:22.670 --> 00:38:25.550
So what we have at the top window
here is Thread Viewer showing

00:38:26.250 --> 00:38:28.260
what's going on in the finder.

00:38:28.260 --> 00:38:29.860
As you can see,
you have a timeline view going from

00:38:29.860 --> 00:38:31.920
the distant past into the present.

00:38:31.920 --> 00:38:35.070
And if I actually do some
activities in the finder,

00:38:40.780 --> 00:38:43.140
We see some actions going on.

00:38:43.260 --> 00:38:47.960
And what you see here is you see little
colored blocks on each of the horizontal

00:38:47.960 --> 00:38:50.430
lines representing each of the threads.

00:38:50.540 --> 00:38:53.390
The blocks represent what was
going on in that thread during

00:38:53.390 --> 00:38:55.040
a point in time in the past.

00:38:55.110 --> 00:38:57.560
Thread viewer checks every
20 milliseconds to see what's

00:38:57.570 --> 00:38:58.740
going on in the thread.

00:38:58.870 --> 00:39:04.780
The green blocks, such as this one,
let me turn on the demo mode

00:39:04.780 --> 00:39:07.740
to make this a little easier.

00:39:08.170 --> 00:39:10.650
Display in large demo mode.

00:39:12.380 --> 00:39:13.300
There we go.

00:39:13.300 --> 00:39:17.670
The large blocks, or the green blocks,
represent that the thread when

00:39:17.670 --> 00:39:21.300
ThreadViewer checked had been
actually executing at that point.

00:39:21.300 --> 00:39:24.190
And when we actually click on it,
we get a backtrace illustrating

00:39:24.300 --> 00:39:27.460
exactly what code was executing
in hopes of giving us some idea

00:39:27.460 --> 00:39:29.570
of what the application was doing.

00:39:29.570 --> 00:39:33.960
The yellow blocks indicate that when
ThreadViewer stopped the program,

00:39:34.100 --> 00:39:35.790
nothing was happening.

00:39:35.790 --> 00:39:36.610
The thread was waiting.

00:39:36.610 --> 00:39:39.320
However, the thread had been running
since the last time it checked.

00:39:39.470 --> 00:39:41.790
So this indicates some
execution had been occurring.

00:39:43.650 --> 00:39:48.780
The dark green blocks indicate
that we were running in the kernel.

00:39:49.030 --> 00:39:51.760
that the thread was actually running,
but it was running down in the kernel.

00:39:51.760 --> 00:39:55.340
And that usually implies that we were
doing things like accessing the disk,

00:39:55.410 --> 00:39:57.680
for example,
where it could be a long running or

00:39:57.680 --> 00:40:01.250
where it's actually a task that's
blocking and the application has to wait

00:40:01.250 --> 00:40:03.700
for the kernel to come back with data.

00:40:03.700 --> 00:40:05.470
Then the pastel colors
tend to represent waiting.

00:40:05.470 --> 00:40:08.280
The green, for example, represents you're
sitting in the wait loop.

00:40:08.390 --> 00:40:11.680
You can tell from the stack backtrace
here that the CFRUNLOOPRUN call

00:40:11.680 --> 00:40:15.550
happens to be in the backtrace,
and the thread is actually

00:40:15.790 --> 00:40:17.980
waiting on the Mach message call.

00:40:18.110 --> 00:40:21.110
It's just sent off a message to the
Windows server saying let me know

00:40:21.110 --> 00:40:24.420
when something actually happens,
and it's waiting for the response.

00:40:24.540 --> 00:40:28.160
And then other colors such as red
indicates waiting on a semaphore.

00:40:29.000 --> 00:40:31.570
So what we see here is that the
thread-- or is that the finder is

00:40:31.620 --> 00:40:34.080
actually using multiple threads.

00:40:34.520 --> 00:40:36.810
As with most of the
applications with GUIs,

00:40:36.810 --> 00:40:39.450
you have one main thread,
which tends to have most

00:40:39.570 --> 00:40:41.160
of the drawing code on it.

00:40:41.250 --> 00:40:43.540
And so this is the thread where
you want to do all the activity

00:40:43.720 --> 00:40:47.300
for doing the direct manipulation,
for moving things around,

00:40:47.300 --> 00:40:49.400
for resizing windows and the like.

00:40:49.540 --> 00:40:52.630
And that thread tends to have a
fair amount of activity on it.

00:40:52.740 --> 00:40:55.390
The other threads are a
little more interesting,

00:40:55.390 --> 00:40:55.390
though.

00:40:56.800 --> 00:40:58.940
For example,
here we found that every time

00:40:58.940 --> 00:41:02.330
that we opened a new folder
that we'd never seen before,

00:41:04.960 --> 00:41:06.960
A new thread's created.

00:41:07.080 --> 00:41:11.340
And the reason for that is
that when we open a folder,

00:41:11.380 --> 00:41:13.460
or when we go to a folder
that we've seen before,

00:41:13.570 --> 00:41:19.060
the finder actually goes off and
queries that directory to find out what

00:41:19.060 --> 00:41:22.880
the files are that are inside of it.

00:41:22.880 --> 00:41:22.880
Excuse me?

00:41:24.770 --> 00:41:28.120
And so what happens is the finder
actually spawns off this thread.

00:41:28.210 --> 00:41:30.120
The thread then goes off
and it asks the disk,

00:41:30.250 --> 00:41:32.320
what are the files in that directory?

00:41:32.420 --> 00:41:35.490
And because that operation may block,
the finder wants to make sure it

00:41:35.600 --> 00:41:38.750
actually is on a separate thread so
that if we're going off an iDisk,

00:41:38.870 --> 00:41:40.750
let's say,
where it might take a long time

00:41:40.760 --> 00:41:43.490
for that to actually come back,
this is not going to block

00:41:43.490 --> 00:41:47.290
the main thread and cause the
user interface to hang on us.

00:41:49.120 --> 00:41:52.360
This also happens when we go
into a directory after we've

00:41:52.360 --> 00:41:55.250
done it for the first time,
because the contents of that

00:41:55.250 --> 00:41:58.100
directory may have changed
since the last time we looked.

00:41:58.100 --> 00:42:02.100
And so the thread can actually
go off and gather the data.

00:42:02.100 --> 00:42:05.000
There's actually a second thread,
which we can see was doing

00:42:05.000 --> 00:42:08.100
activity about the same time that
each of those threads was formed.

00:42:08.100 --> 00:42:10.910
The Finder team calls
this the Sync Thread.

00:42:11.300 --> 00:42:16.100
And that actually is the thread that
maintains the database of information

00:42:16.100 --> 00:42:17.100
on folders that we've already opened.

00:42:17.100 --> 00:42:20.590
And so the Sync Thread is actually
responsible for spawning the

00:42:20.590 --> 00:42:24.100
threads to gather information
and also update the database,

00:42:24.110 --> 00:42:27.100
which the main thread can then
actually query to find out what the

00:42:27.100 --> 00:42:28.960
contents of a given directory are.

00:42:29.100 --> 00:42:34.490
This is a second reason to use threading,
the idea of separating out the logic

00:42:34.490 --> 00:42:39.310
of dealing with the database of
current file contents from the idea of

00:42:39.310 --> 00:42:45.100
dealing with the UI or from the idea of
actually querying the data on the disk.

00:42:45.100 --> 00:42:48.100
And so having the Sync Thread
actually logically separates things.

00:42:48.200 --> 00:42:55.100
So that's the second reason we
actually wanted to use threading.

00:42:56.970 --> 00:42:59.430
Let's imagine we do a duplicate.

00:42:59.520 --> 00:43:03.870
So go up to the finder and do duplicate.

00:43:04.900 --> 00:43:06.900
We see a relatively long-running app.

00:43:07.010 --> 00:43:08.530
And we see that there
are two threads spawned,

00:43:08.560 --> 00:43:10.370
and in fact,
both have lots of dark green blocks,

00:43:10.510 --> 00:43:11.990
which indicate we're
doing a lot of blocking,

00:43:11.990 --> 00:43:14.580
waiting for the file system to do work.

00:43:14.700 --> 00:43:18.790
Now, when we're doing a copy... Actually,
let's let this continue.

00:43:18.940 --> 00:43:22.450
When we're doing a copy,
this is an activity that probably

00:43:22.510 --> 00:43:24.170
we want to do in the background.

00:43:24.280 --> 00:43:29.090
We don't want the user interface to hang
while we wait for the copy to finish.

00:43:30.000 --> 00:43:33.070
and therefore the finder actually
spawns this off on separate

00:43:33.070 --> 00:43:35.820
threads as a background activity,
puts up a dialog box to let

00:43:35.820 --> 00:43:39.080
us know what's going on,
and we can continue to do work while

00:43:39.080 --> 00:43:40.490
the copy goes on in the background.

00:43:42.620 --> 00:43:45.190
Now,
one of the things you may be asking is,

00:43:45.270 --> 00:43:46.330
well, why were two threads spawned?

00:43:46.390 --> 00:43:48.570
We only were doing one copy.

00:43:49.490 --> 00:43:52.260
So one of the other reasons that you
may want to use threading is the idea of

00:43:52.260 --> 00:43:54.740
being able to do operations in parallel.

00:43:54.740 --> 00:43:57.920
So if we're doing a copy from, let's say,
a single disk,

00:43:57.970 --> 00:44:00.720
copying from one place to another,
every time that we do a read,

00:44:00.720 --> 00:44:01.800
we have to do a write.

00:44:01.840 --> 00:44:04.600
And because those are
going to be sequential,

00:44:04.600 --> 00:44:08.520
we have to do read, then write,
then read, then write.

00:44:08.640 --> 00:44:11.620
However, if we end up copying from
one volume to another,

00:44:11.730 --> 00:44:14.150
we have an opportunity for parallelism.

00:44:14.380 --> 00:44:18.210
Because as we're writing each block,
we can start reading the

00:44:18.210 --> 00:44:19.130
next block off of the disk.

00:44:19.240 --> 00:44:22.920
And we can do those in parallel because
they're dealing with different devices.

00:44:22.920 --> 00:44:26.570
And so the finder actually uses
two threads so that as block,

00:44:26.760 --> 00:44:29.490
let's say block n is
being written to disk,

00:44:29.490 --> 00:44:32.180
block n plus one can be read
into memory at the same time.

00:44:32.250 --> 00:44:34.180
And this can double throughput.

00:44:34.180 --> 00:44:37.550
And the same approach of using two
threads is used for all the copies

00:44:37.550 --> 00:44:40.680
to make sure that it solves that case
and because there's no particular

00:44:40.680 --> 00:44:43.150
inefficiency in not using it.

00:44:46.860 --> 00:44:50.040
Now, one of the other issues that
the Finder team ran into is

00:44:50.040 --> 00:44:51.660
the issue of legacy code.

00:44:51.660 --> 00:44:53.700
How many of you actually have
code that you didn't write or

00:44:53.700 --> 00:44:57.130
that you're responsible for
and you don't quite understand?

00:44:57.980 --> 00:44:58.900
Oh, good.

00:44:58.900 --> 00:45:02.950
So one of the issues that some of
the teams that use Mac OS X have

00:45:02.950 --> 00:45:06.190
internally is that some of
the frameworks that we use,

00:45:06.190 --> 00:45:09.330
some of the bits of library code,
have been inherited from Mac OS 9,

00:45:09.410 --> 00:45:13.210
which were inherited from Mac OS 8,
which were inherited from and so on.

00:45:13.310 --> 00:45:16.680
And, in fact,
there were some parts of the system that

00:45:16.680 --> 00:45:22.780
actually ended up being...were written
without thinking about multi-threading,

00:45:22.780 --> 00:45:25.600
that multiple people might actually be
trying to use the APIs at the same time.

00:45:25.600 --> 00:45:28.530
And one of the problems that
the Finder team actually had

00:45:28.630 --> 00:45:31.730
was the issue of icon services,
which is the part of the code

00:45:31.730 --> 00:45:34.570
that actually goes off and
gets resources out of files,

00:45:34.650 --> 00:45:35.580
gets icons and the like.

00:45:35.580 --> 00:45:37.880
And, in fact,
they ran into some interesting

00:45:37.880 --> 00:45:42.820
problems on 10.0 and 10.1,
where they had to do the accesses to

00:45:42.820 --> 00:45:46.830
the icon services on the main thread,
because they couldn't guarantee

00:45:46.840 --> 00:45:49.990
that there weren't two things
trying to do it at the same time.

00:45:50.310 --> 00:45:52.840
and as a result,
many of those operations ended up being

00:45:52.840 --> 00:45:54.440
done on the main thread and blocking.

00:45:54.440 --> 00:45:56.980
This is actually one of the things
I believe they're fixing for 10.2,

00:45:56.990 --> 00:45:59.430
that they've actually got a
better way to deal with the icons.

00:45:59.540 --> 00:46:02.640
But this introduces the
question of even with,

00:46:03.010 --> 00:46:05.440
even when you have an application that
may be very good for multithreading,

00:46:05.440 --> 00:46:09.140
you may run into issues where there's
blocks of code that you can't actually

00:46:09.300 --> 00:46:12.210
multithread because they weren't
designed for this and you can't

00:46:12.370 --> 00:46:14.220
actually do multiple access to them.

00:46:14.220 --> 00:46:16.070
And so this is something to keep
in mind as you look at code and as

00:46:16.070 --> 00:46:18.490
you look at multithreading issues,
if there's going to be issues

00:46:18.640 --> 00:46:20.980
trying to deal with things
that shouldn't be threaded.

00:46:20.980 --> 00:46:25.390
Okay, so that's the finder example.

00:46:29.100 --> 00:46:33.130
Okay, the second example I'm going
to do is the QuickTime Player.

00:46:33.410 --> 00:46:36.990
And to be self-referential,
what I'm going to use as a

00:46:36.990 --> 00:46:38.850
demo is last year's movie.

00:46:40.490 --> 00:46:44.470
So, let's see what's going
on in QuickTime Player.

00:46:44.550 --> 00:46:46.030
Let's again run ThreadViewer.

00:46:46.110 --> 00:46:48.780
We'll attach to the QuickTime Player.

00:46:52.600 --> 00:46:54.830
And we see that multiple
threads are running.

00:46:54.870 --> 00:46:56.020
Okay, so what's going on here?

00:46:56.190 --> 00:46:58.740
And if we actually stop the program...

00:46:58.710 --> 00:47:00.120
Actually,
I'm not going to stop at BS--well,

00:47:00.130 --> 00:47:00.690
we'll try it.

00:47:00.690 --> 00:47:03.240
We'll see what happens.

00:47:03.240 --> 00:47:05.200
We can get some ideas
about what's going on.

00:47:05.280 --> 00:47:09.060
Once again, the main thread, thread zero,
is where all the drawing goes on.

00:47:10.600 --> 00:47:11.940
and where all the user interface happens.

00:47:11.940 --> 00:47:15.280
So if we're doing resizes,
if we're clicking around on buttons,

00:47:15.280 --> 00:47:17.030
that's where the activity goes on.

00:47:17.140 --> 00:47:19.880
The rest of the threads
are actually created by the

00:47:19.880 --> 00:47:22.080
QuickTime libraries themselves.

00:47:22.740 --> 00:47:26.230
If we actually let this run,
eventually we're going to see some

00:47:26.280 --> 00:47:28.000
disk accesses on one of the threads.

00:47:28.100 --> 00:47:31.490
There's going to be occasional
green blocks as QuickTime goes

00:47:31.490 --> 00:47:32.440
off and gets data.

00:47:32.440 --> 00:47:35.810
So as with Finder,
the QuickTime code actually wants

00:47:35.910 --> 00:47:39.300
to make sure that when it goes
out to get files off of disk,

00:47:39.300 --> 00:47:41.470
that it doesn't block,
that it doesn't cause the

00:47:41.470 --> 00:47:43.850
user interface to hang waiting
for those blocks to come in.

00:47:44.560 --> 00:47:48.440
And so the QuickTime thread for
getting the data can actually

00:47:48.560 --> 00:47:51.420
grab large blocks of data,
can copy them in,

00:47:51.420 --> 00:47:54.160
and doesn't have to worry about
what happens if that blocks.

00:47:54.260 --> 00:47:55.710
There goes one.

00:47:57.920 --> 00:47:58.390
Yes, read.

00:47:58.390 --> 00:48:01.900
There's a second thread that tends
to be doing a lot of activity,

00:48:01.900 --> 00:48:05.420
probably the top one,
that actually represents

00:48:05.570 --> 00:48:07.340
the decompression algorithm.

00:48:07.350 --> 00:48:09.960
So that's actually being
run on a separate thread,

00:48:09.960 --> 00:48:13.170
which follows the idea of trying
to separate different tasks on

00:48:13.170 --> 00:48:16.970
different threads just to make it
easier to reason about the program.

00:48:17.840 --> 00:48:20.440
And then finally,
when the data is decompressed and

00:48:20.440 --> 00:48:24.310
it's being sent to the screen or
being sent to the audio device,

00:48:24.310 --> 00:48:27.720
rather than taking large chunks
of data as we did with the disk,

00:48:27.900 --> 00:48:31.020
the audio device probably wants very
small bits of data and wants to send

00:48:31.150 --> 00:48:34.030
them to the audio device as quickly
as possible to minimize latency.

00:48:34.040 --> 00:48:38.120
And so the writing to the audio device...
Let's see if we can actually find that.

00:48:43.400 --> 00:48:45.350
Actually, here we are.

00:48:45.360 --> 00:48:46.630
Code in the I/O thread.

00:48:46.640 --> 00:48:52.220
This is probably actually the
thread that's doing the audio data.

00:48:52.220 --> 00:48:57.370
That actually ends up being on
a separate thread so that it can

00:48:57.370 --> 00:48:57.370
keep up its real-time behavior.

00:48:59.000 --> 00:49:02.670
A final thing to notice about this
version of Thread Viewer that is on

00:49:02.770 --> 00:49:07.330
the May 2002 developer CD is that not
only do we have a thread identifier,

00:49:07.400 --> 00:49:11.380
but we also have this little
set of letters and parentheses.

00:49:11.380 --> 00:49:14.780
That actually represents the scheduling
algorithm for each of the threads.

00:49:14.830 --> 00:49:18.130
With the finder, we saw TS,
which stands for basically

00:49:18.130 --> 00:49:20.950
a time-sharing thread,
which runs whenever the

00:49:20.950 --> 00:49:22.180
kernel gives it a chance to.

00:49:22.370 --> 00:49:25.030
If it runs too much,
then the kernel bumps down its priority

00:49:25.030 --> 00:49:27.140
and gives somebody else a chance,
and so on.

00:49:27.140 --> 00:49:29.040
The other threads are what
are called round robin.

00:49:29.230 --> 00:49:31.020
They're sort of a real-time thread.

00:49:31.040 --> 00:49:32.700
In this case,
what ends up happening is that

00:49:32.700 --> 00:49:34.540
when you create the thread,
you actually say,

00:49:34.560 --> 00:49:38.440
"I need 20 milliseconds every
second to do my work." The kernel

00:49:38.570 --> 00:49:40.840
tries to schedule that time.

00:49:40.840 --> 00:49:44.680
For the real-time nature of this,
for dealing with the media,

00:49:44.990 --> 00:49:49.420
having those have some sort of real-time
guarantee is actually a good thing.

00:49:49.420 --> 00:49:53.380
Now,
the times when I actually put this in,

00:49:53.380 --> 00:49:56.050
the folks on the kernel who deal
with scheduling were a little aghast

00:49:56.050 --> 00:49:58.470
because they were afraid that we
would all go off and immediately

00:49:58.470 --> 00:50:02.870
make our threads high priority to
try to get as much CPU as possible.

00:50:02.870 --> 00:50:07.860
This is a very bad idea because the
system's been designed so that the

00:50:07.860 --> 00:50:12.000
things that actually need the time should
be running as high-priority threads.

00:50:12.000 --> 00:50:14.180
And if you start running
your stuff at high priority,

00:50:14.190 --> 00:50:18.840
if you decide that maybe you want your
user interface running with round robin,

00:50:18.840 --> 00:50:21.040
you can actually run into some
cases where you might have priority

00:50:21.040 --> 00:50:24.280
inversions where you end up
deadlocking other parts of the system.

00:50:24.280 --> 00:50:26.900
Or, worse yet,
you might be a bad citizen.

00:50:26.980 --> 00:50:29.340
So let's imagine your application's
running and you've somehow set it up

00:50:29.340 --> 00:50:31.170
so that it's using extra priority.

00:50:31.170 --> 00:50:36.440
Then somebody comes along and says, "Oh,
I want to burn a CD in iTunes."

00:50:38.200 --> 00:50:41.630
Well, the CD device actually has some
relatively strict scheduling that

00:50:41.630 --> 00:50:44.500
has to be done to make sure that
data actually gets out to the device.

00:50:44.620 --> 00:50:46.900
And there are actually times
on DVDs where if you don't

00:50:46.980 --> 00:50:49.600
get that data just right,
you can actually mess up disks and

00:50:49.600 --> 00:50:52.860
corrupt them in ways so that you
basically have a piece of plastic.

00:50:52.860 --> 00:50:55.500
So as a result,
you want to be very careful about how you

00:50:55.640 --> 00:50:59.930
might actually use scheduling so that you
don't cause people to generate bad DVDs.

00:51:00.070 --> 00:51:03.970
So there are different ways that
you can actually schedule things

00:51:03.970 --> 00:51:05.850
that are known to be real time.

00:51:05.850 --> 00:51:06.960
Use them extremely sparingly.

00:51:09.650 --> 00:51:11.660
So that's my example for today.

00:51:11.850 --> 00:51:13.910
Hopefully that gives you some ideas
about how you might actually use

00:51:13.940 --> 00:51:17.390
threading in your own applications and
how Apple actually uses it in theirs.

00:51:17.490 --> 00:51:18.900
Thank you.

00:51:24.430 --> 00:51:25.960
Thank you, Robert.

00:51:26.060 --> 00:51:27.370
So let's give you a roadmap.

00:51:27.400 --> 00:51:30.470
Go back to the podium.

00:51:30.510 --> 00:51:33.520
So a couple -- obviously
since this is Thursday,

00:51:33.570 --> 00:51:36.440
some of these sessions
have already occurred.

00:51:36.440 --> 00:51:38.730
But for those of you who will
be looking back either through

00:51:38.730 --> 00:51:42.690
the website or through the DVDs,
these are some of the sessions to

00:51:42.740 --> 00:51:45.800
look at for performance optimization.

00:51:46.260 --> 00:51:47.600
Who to contact?

00:51:47.600 --> 00:51:50.560
Matt Watson has been kind
enough to provide his own email,

00:51:50.560 --> 00:51:54.340
so he's available and
myself also available.

00:51:54.340 --> 00:51:58.160
From time to time,
I do hold kitchens for performance

00:51:58.160 --> 00:52:02.800
optimization or specifically
for MP or threading kitchens.

00:52:02.800 --> 00:52:05.240
So if those are things
that might interest you,

00:52:05.240 --> 00:52:07.980
if you need more assistance,
please contact me.

00:52:07.980 --> 00:52:11.470
I'd be happy to work with you
to set up a schedule for that.

00:52:12.940 --> 00:52:17.990
Some more areas for documentation,
the Carbon thread links and

00:52:18.010 --> 00:52:23.540
Cocoa threads and all of these URLs are
available at the main URL site that

00:52:23.640 --> 00:52:25.420
is being provided for the conference.

00:52:25.420 --> 00:52:29.410
Some more tech doc notes.

00:52:29.790 --> 00:52:33.030
So again,
the takeaway from today's session

00:52:33.030 --> 00:52:35.260
is threads can work for you.

00:52:35.310 --> 00:52:36.860
They can also work against you.

00:52:36.860 --> 00:52:39.100
So use them where it makes sense.

00:52:39.100 --> 00:52:41.860
Use them where the user
experience will be enhanced.

00:52:41.880 --> 00:52:44.740
Threads don't necessarily mean
that you have to have a dual

00:52:44.820 --> 00:52:46.790
processor to take advantage of them.

00:52:46.800 --> 00:52:50.930
They will assist you in that case when
you do have a dual processor system.

00:52:50.940 --> 00:52:55.300
But as Robert showed you in his examples,
these could be applications that

00:52:55.300 --> 00:52:58.350
are taking advantage of the fact
that they need to read and write

00:52:58.380 --> 00:53:00.580
on a single processor machine.

00:53:00.580 --> 00:53:05.120
So with that, I'd like to start the Q&A.