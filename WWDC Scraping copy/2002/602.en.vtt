WEBVTT

00:00:00.800 --> 00:00:01.700
Good afternoon.

00:00:01.710 --> 00:00:02.540
Does this work?

00:00:02.540 --> 00:00:02.600
Good.

00:00:02.670 --> 00:00:04.040
Excellent.

00:00:04.130 --> 00:00:04.360
Hi.

00:00:04.360 --> 00:00:08.450
Welcome to session 602, QuickTime for
Video-Intensive Applications.

00:00:08.700 --> 00:00:12.030
And this is when application
became more video-intensive.

00:00:12.120 --> 00:00:14.340
This is PowerPoint running
a QuickTime movie for all

00:00:14.340 --> 00:00:15.140
of those who were wondering.

00:00:15.140 --> 00:00:16.860
It's pretty cool.

00:00:16.860 --> 00:00:18.930
New this year at WWDC.

00:00:20.250 --> 00:00:21.390
My name is Tim Chernna.

00:00:21.640 --> 00:00:24.880
I'm manager of the
QuickTime Pro Media Group.

00:00:24.880 --> 00:00:30.060
We specialize in support for high-end
video applications and audio applications

00:00:30.060 --> 00:00:35.380
and do the support for the DV codec
and YUV SD and HD and Final Cut and

00:00:35.520 --> 00:00:40.850
iMovie and Adobe Premiere and
a bunch of other developers.

00:00:40.850 --> 00:00:43.640
So that's kind of what we focus on.

00:00:43.730 --> 00:00:46.930
Today's session,
we're actually going to talk a little bit

00:00:47.020 --> 00:00:51.410
more about video and audio in general,
things that you can do in QuickTime for

00:00:51.410 --> 00:00:54.820
any application that wants to
become more video intensive.

00:00:54.820 --> 00:01:00.520
And the three areas that we're going
to be talking about are acquisition,

00:01:00.520 --> 00:01:02.480
video processing, and video output.

00:01:02.670 --> 00:01:05.800
Acquisition is basically
capturing video and audio,

00:01:05.800 --> 00:01:08.960
and we're going to be talking a little
bit about some of the new camera support

00:01:08.960 --> 00:01:10.570
we have in QuickTime 6 and Jaguar.

00:01:10.570 --> 00:01:12.660
Video processing,
we're going to be showing you some

00:01:12.660 --> 00:01:16.350
techniques for doing cool things to
video that you have in your movies or

00:01:16.350 --> 00:01:18.560
with your camera that you're capturing.

00:01:18.800 --> 00:01:22.710
And video output, finally,
is the way that you can take

00:01:22.710 --> 00:01:27.590
the video and output it to
an external video device.

00:01:27.860 --> 00:01:32.230
Some of you have seen the overview slide,
the graphic that we made.

00:01:32.610 --> 00:01:34.510
This is sort of showing
the different components of

00:01:34.530 --> 00:01:36.570
QuickTime that exist in the system.

00:01:36.700 --> 00:01:39.390
And the ones that are highlighted
are the ones that we're

00:01:39.390 --> 00:01:40.750
going to be talking about.

00:01:40.950 --> 00:01:45.050
So the standard compression,
standard sound, the Sequence Grabber,

00:01:45.520 --> 00:01:47.370
and then some of the
components that we have,

00:01:47.380 --> 00:01:49.670
which are the eat and spit,
which are the import

00:01:49.670 --> 00:01:53.700
and export components,
Vout, which is to send video to a device,

00:01:53.700 --> 00:01:55.700
and the digitizers.

00:01:55.700 --> 00:01:57.660
And with that,
I'd like to introduce Kevin Marks,

00:01:57.780 --> 00:02:00.700
who's going to be talking about
acquisition with QuickTime.

00:02:09.500 --> 00:02:10.850
Hi there.

00:02:10.990 --> 00:02:13.320
I just want to make it clear that
acquisition is not about getting

00:02:13.320 --> 00:02:15.380
your company bought by Apple.

00:02:26.540 --> 00:02:30.960
What I'm going to talk about
is the Sequence Grabber,

00:02:31.000 --> 00:02:33.540
which is QuickTime's way of getting
video and audio from the outside

00:02:33.540 --> 00:02:35.970
world into QuickTime movies so that
you can use in other applications

00:02:36.420 --> 00:02:38.460
like you saw this morning.

00:02:38.880 --> 00:02:53.950
are all here.

00:02:55.050 --> 00:02:55.050
There's two parts to what I'm saying.

00:02:55.050 --> 00:02:55.050
I'm going to give an overview of
how the Sequence Grabber works.

00:02:55.050 --> 00:02:55.050
For those of you who aren't
familiar with QuickTime,

00:02:55.050 --> 00:02:55.050
this API has been around
for about 10 years now,

00:02:55.050 --> 00:02:55.050
and it's served its time
pretty well over there.

00:02:55.320 --> 00:02:57.880
I'm going to give some introductory
stuff about how that works,

00:02:57.880 --> 00:03:00.170
and then I'm going to give some
details of some of the changes we've

00:03:00.170 --> 00:03:03.940
made for QuickTime 6 and Jaguar,
which we have more interest

00:03:03.940 --> 00:03:06.850
to specialized developers who
already know something about this.

00:03:06.860 --> 00:03:09.130
So there's a mixture of the two in this.

00:03:09.140 --> 00:03:12.060
And then we'll have some nice
demos and lobsters and things.

00:03:14.270 --> 00:03:19.150
So, QuickTime provides an abstraction
that lets you capture video

00:03:19.150 --> 00:03:21.070
and audio and other formats.

00:03:21.290 --> 00:03:25.410
The Sequence Grabber is a generalized
way of capturing time-based

00:03:25.410 --> 00:03:26.930
media from an external device.

00:03:26.940 --> 00:03:31.030
At the moment, we only provide video and
audio capture components.

00:03:31.040 --> 00:03:33.420
In principle, you could add other
ones if you wanted to,

00:03:33.420 --> 00:03:35.300
and if there are things that
you're interested in that,

00:03:35.370 --> 00:03:35.780
let us know.

00:03:35.820 --> 00:03:41.860
The idea is that the Sequence Grabber
abstracts this from your application,

00:03:41.890 --> 00:03:44.100
so you don't have to know anything
about the hardware you're dealing with.

00:03:44.200 --> 00:03:47.500
You just say what kind of media you want,
and let the user choose what

00:03:47.600 --> 00:03:49.360
they're going to capture.

00:03:52.070 --> 00:03:54.900
The Sequence Grabber holds
a series of channels.

00:03:54.900 --> 00:03:57.800
So in order to capture something,
you create a Sequence Grabber

00:03:57.870 --> 00:04:00.600
component and you add channels to
it for the kinds of media you want,

00:04:00.600 --> 00:04:02.050
video and audio channels.

00:04:02.060 --> 00:04:05.140
The channels are the ones
that deal with the hardware,

00:04:05.140 --> 00:04:07.940
talk to the devices,
and get the data out in a usable

00:04:08.030 --> 00:04:10.100
form and turn that into a movie.

00:04:10.100 --> 00:04:12.020
Any number of channels is possible.

00:04:12.020 --> 00:04:15.320
The constraint is normally the
hardware you've got attached.

00:04:16.320 --> 00:04:20.200
And the source code for this,
the example source code, remains HackTV,

00:04:20.200 --> 00:04:24.830
which has stood the test of time as it's
been source code for about 10 years now.

00:04:24.840 --> 00:04:27.990
It's been updated a bit for OS X,
and we intend to update it

00:04:28.050 --> 00:04:29.800
a bit further in the future.

00:04:29.800 --> 00:04:33.540
URLs for source code will
show up in the final slide.

00:04:37.100 --> 00:04:41.790
So the basic way you would use the
Sequence Grabber to capture something,

00:04:41.790 --> 00:04:45.420
there's a straightforward
series of calls you make.

00:04:45.500 --> 00:04:48.680
You create the Sequence Grabber,
and you create channels

00:04:48.780 --> 00:04:50.070
and add those to it.

00:04:50.080 --> 00:04:52.580
And then you would call
SGSettingsDialog for each channel

00:04:52.660 --> 00:04:54.100
that you're interested in.

00:04:54.120 --> 00:04:58.790
This provides a very full user interface
for the user to make complex series

00:04:59.010 --> 00:05:01.510
of choices about what's available.

00:05:01.520 --> 00:05:03.920
They can choose between
different devices.

00:05:03.920 --> 00:05:06.040
They can choose the compression format.

00:05:07.000 --> 00:05:11.130
And set other parameters about
controlling the capture devices.

00:05:11.140 --> 00:05:17.060
For example,
setting the input for a video camera,

00:05:17.060 --> 00:05:19.390
or adjusting color and
that kind of thing.

00:05:19.400 --> 00:05:22.890
There's a large amount of user
interface there that's constructed

00:05:22.900 --> 00:05:26.280
for you by the Sequence Grabber,
so save you having to do that as well.

00:05:27.560 --> 00:05:30.840
Once you've done that and you're ready,
you call SG Prepare.

00:05:30.840 --> 00:05:37.600
This gives the devices
time to start recording,

00:05:37.600 --> 00:05:39.260
to start buffering up data.

00:05:39.260 --> 00:05:42.000
It pre-allocates the files
on the disk and gets ready,

00:05:42.070 --> 00:05:45.520
so when you call SG Start Record,
it can start straight away.

00:05:45.520 --> 00:05:49.060
Then while you're recording,
you call SG Idle at regular intervals.

00:05:49.060 --> 00:05:52.620
At the moment, we haven't got this hooked
up to the Idle Manager,

00:05:52.620 --> 00:05:56.860
but the rule of thumb is call it at least
as often as the frame rate you want.

00:05:57.500 --> 00:06:00.910
On OS 9 and Windows,
you would call this from the

00:06:00.910 --> 00:06:03.720
WaitNext Event loop or in a tight loop.

00:06:03.810 --> 00:06:06.360
On OS 10,
you can use a CF1 loop to call this.

00:06:06.380 --> 00:06:09.080
And when you're finished recording,
you call SG Stop.

00:06:09.140 --> 00:06:11.840
At that point,
QuickTime will stop all the

00:06:11.840 --> 00:06:16.220
devices and then create the movie
header that describes the file.

00:06:16.220 --> 00:06:20.060
This describes the media that's
already recorded to the disk.

00:06:24.820 --> 00:06:30.060
So moving on to some of the new
things of editing QuickTime 6.

00:06:30.110 --> 00:06:32.990
These are mostly incremental
improvements for the Sequence Grabber.

00:06:33.060 --> 00:06:36.760
The basic way it works hasn't changed,
but we've made a series of small

00:06:36.760 --> 00:06:42.730
changes to update it and provide
new user interface and better

00:06:42.730 --> 00:06:44.930
user experience in various places.

00:06:45.210 --> 00:06:49.270
And some of this is involved with
adding new programming APIs to make

00:06:49.270 --> 00:06:51.700
life easier for the developers too.

00:06:54.920 --> 00:06:57.720
The Sequence Grabber has a way of
finding the devices that are attached.

00:06:57.720 --> 00:07:02.970
Up to QuickTime 5,
that will just tell you the devices.

00:07:03.000 --> 00:07:04.690
If you wanted to find any
more information about them,

00:07:04.690 --> 00:07:06.350
you had to open them
individually and query them.

00:07:06.360 --> 00:07:09.150
We've extended that structure so
it will now tell you what inputs

00:07:09.150 --> 00:07:12.740
the devices have available,
and you can pass a new flag to get that.

00:07:12.760 --> 00:07:16.650
In addition to that,
we've added some new utility

00:07:16.650 --> 00:07:20.970
function calls to let you adjust
these input parameters without

00:07:21.840 --> 00:07:23.930
having to make direct driver calls.

00:07:24.570 --> 00:07:27.640
And without having to make the
different driver calls for audio

00:07:27.640 --> 00:07:28.720
and video that you had to do before.

00:07:28.720 --> 00:07:31.720
So these are listed here.

00:07:31.720 --> 00:07:34.510
There's going to be more details in the
QuickTime 6 developer documentation.

00:07:34.520 --> 00:07:41.210
But the SGGetChannelDevice and
InputNames lets you find out the device's

00:07:41.210 --> 00:07:43.700
name without calling device list,
walking the device tree,

00:07:43.700 --> 00:07:45.680
and then making further
calls to find the input name.

00:07:45.680 --> 00:07:49.480
And SetChannelDeviceInput
gives you a channel-independent

00:07:49.480 --> 00:07:51.340
way of changing the input.

00:07:55.260 --> 00:07:58.070
We've made some significant changes
to the Sequence Grabber panels,

00:07:58.070 --> 00:08:01.480
mostly in UI terms.

00:08:01.520 --> 00:08:04.540
They're now much more modern looking.

00:08:04.540 --> 00:08:10.260
They've been updated to fit
in with the OS X Aqua style.

00:08:10.260 --> 00:08:15.050
They're resizable, and as part of that,
we need to give the SGPanels,

00:08:15.050 --> 00:08:18.620
which are the Video Digitizer's way
of extending that user interface,

00:08:18.620 --> 00:08:21.410
as a way of telling us
how we can resize them.

00:08:22.180 --> 00:08:25.230
So we have a new call,
SGPanel getDittlesize,

00:08:25.390 --> 00:08:27.760
where we pass you the size that we
want you to fit the dialog into,

00:08:27.760 --> 00:08:30.970
and you return the dialog layout for us.

00:08:30.980 --> 00:08:36.080
And there are some additional...
You don't have to support every size.

00:08:36.100 --> 00:08:37.960
If you support largest
and smallest sizes,

00:08:37.960 --> 00:08:39.690
we'll interpolate the
dialog elements for you.

00:08:41.280 --> 00:08:47.210
and we have another utility called
SGGetChannelRefCon because that

00:08:47.210 --> 00:08:47.210
seemed to be missing from the API.

00:08:48.360 --> 00:08:52.930
A key change we made to the Sequence
Grabber panels and the settings is that

00:08:52.930 --> 00:08:56.950
we now store far more information so
that we can properly identify the VDIG.

00:08:56.960 --> 00:09:02.000
The previous assumption in the Sequence
Grabber was that video digitizers

00:09:02.210 --> 00:09:04.500
were on cards in your machine.

00:09:04.500 --> 00:09:08.380
You'd probably have one of them,
and you wouldn't change it very often.

00:09:08.380 --> 00:09:13.610
In a world of USB cameras and FireWire
cameras where devices are hot-pluggable,

00:09:13.750 --> 00:09:15.540
this isn't true anymore.

00:09:16.020 --> 00:09:18.820
The devices can come and go,
and we need to keep track

00:09:18.820 --> 00:09:20.960
of more information to
find out which one's which,

00:09:20.970 --> 00:09:22.640
so that when you save
and restore settings,

00:09:22.720 --> 00:09:24.580
you get the same camera
back you got before,

00:09:24.580 --> 00:09:26.120
even if you got two or three plugged in.

00:09:26.140 --> 00:09:31.220
So we now store extra information,
but we're still careful to... If we

00:09:31.220 --> 00:09:33.850
can't find the camera we're looking for,
we'll fall back to a different camera,

00:09:33.850 --> 00:09:34.990
depending on what camera you've got.

00:09:35.090 --> 00:09:38.190
So you can still use...

00:09:38.330 --> 00:09:41.000
You can use the settings call
in a general way and we'll

00:09:41.000 --> 00:09:42.280
cope with what you have.

00:09:42.370 --> 00:09:45.070
But if you've got the same
camera you started with before,

00:09:45.110 --> 00:09:47.510
we'll make sure we get
that one back again.

00:09:49.830 --> 00:09:52.190
As part of these changes,
we've made some changes to

00:09:52.190 --> 00:09:54.520
the way the Sequence Grabber
interacts with the Video Digitizer.

00:09:54.530 --> 00:10:01.510
For those of you who are
developing Video Digitizers,

00:10:01.510 --> 00:10:01.510
there are some

00:10:01.690 --> 00:10:04.920
Small changes to the way this API works.

00:10:04.920 --> 00:10:09.400
In particular,
the recommended video digitizer API is

00:10:09.400 --> 00:10:14.710
to use the VD compressed one frame,
a VD compressed done call.

00:10:14.720 --> 00:10:18.910
VD compressed done second parameter
was defined as a Boolean saying,

00:10:19.180 --> 00:10:23.120
yes, I have a frame, meaning one, zero,
I don't have a frame.

00:10:23.380 --> 00:10:27.140
We've redefined this to be the number of
frames that you actually have queued up

00:10:27.150 --> 00:10:31.140
inside so that we can make further calls
to pull only out to deal with variations

00:10:31.140 --> 00:10:33.870
in idle timing and that kind of thing.

00:10:33.880 --> 00:10:36.590
The notion is that the VD is doing
the buffering and the Sequence Grabber

00:10:36.590 --> 00:10:38.300
will pull out the frames that you have.

00:10:38.340 --> 00:10:41.380
And as an application,
you can get access to this

00:10:41.490 --> 00:10:45.380
information by setting an
SG grab compressed complete proc,

00:10:45.470 --> 00:10:50.310
calling through to the Sequence Grabber,
and then looking at this frame's value.

00:10:52.000 --> 00:10:56.410
Another change to this interaction
that we've added is that previously

00:10:56.430 --> 00:10:59.490
the Sequence Grabber and the VDIG,
the Sequence Grabber kept

00:10:59.490 --> 00:11:00.470
the VDIG in the dark.

00:11:00.550 --> 00:11:03.350
The VDIG didn't know whether it
was being recorded or previewed

00:11:03.380 --> 00:11:04.780
or what was going on at all.

00:11:04.780 --> 00:11:07.220
It just had to handle giving
the Sequence Grabber bits,

00:11:07.220 --> 00:11:10.650
and the Sequence Grabber would deal
with what it did with them afterwards.

00:11:13.610 --> 00:11:17.450
With the kind of VDs that we need now
when you're plugging multiple ones,

00:11:17.460 --> 00:11:19.380
they need to know when they
should allocate bandwidth

00:11:19.390 --> 00:11:21.010
on the USB or the FireWire.

00:11:21.020 --> 00:11:23.120
They need to know more information
about what's going on so they can

00:11:23.120 --> 00:11:24.550
make sensible decisions themselves.

00:11:24.630 --> 00:11:31.150
VD developers up to now have had to
use heuristics about our call sequence

00:11:31.160 --> 00:11:32.430
to try and guess what's going on here.

00:11:32.440 --> 00:11:35.580
So we've added a new call,
VD Capture State Changing,

00:11:35.580 --> 00:11:40.420
which tells the video digitizer when
we're changing from a preview state

00:11:40.540 --> 00:11:42.300
to a recording state to a stop state.

00:11:42.620 --> 00:11:46.890
And there are additional flags in
there to provide further information.

00:11:49.770 --> 00:11:53.200
Two of these flags are accessible from
outside for applications to pass through.

00:11:53.200 --> 00:11:56.450
This is SetGrabLowLatencyCapture.

00:11:56.460 --> 00:12:00.940
The idea of that is for applications
such as video conferencing,

00:12:00.940 --> 00:12:04.160
live streaming,
or real-time image processing,

00:12:04.160 --> 00:12:06.720
where you're not concerned
about getting every frame,

00:12:06.740 --> 00:12:08.140
you just want to make sure
you get a fresh frame.

00:12:08.140 --> 00:12:10.690
If you set that flag,
that will be passed through

00:12:10.730 --> 00:12:12.810
to the video digitizer,
and it can adjust its

00:12:12.810 --> 00:12:13.830
buffering accordingly.

00:12:15.420 --> 00:12:18.060
The second flag,
SetGrabAlwaysUseTimeBase,

00:12:18.060 --> 00:12:22.340
is designed to tell the video digitizer
that it should really pay attention

00:12:22.340 --> 00:12:25.890
to the time base it's passed in,
rather than just round off every

00:12:26.030 --> 00:12:29.270
frame to the same duration,
which is a technique that many

00:12:29.270 --> 00:12:32.580
VDICs have used in the past,
which fits better with the way

00:12:32.580 --> 00:12:37.510
broadcast thinks about video as a
series of uniformly spaced frames.

00:12:37.520 --> 00:12:40.560
But if you're trying to synchronize that
to another source inside the computer,

00:12:40.560 --> 00:12:44.290
it's more useful to know the
exact start time of the frame,

00:12:44.410 --> 00:12:46.910
rather than round it off,
because you find that

00:12:46.910 --> 00:12:48.100
over time they'll diverge.

00:12:48.120 --> 00:12:53.110
And if you're running a security camera
application 24 hours a day for a month,

00:12:53.200 --> 00:12:57.180
any small divergence will
be bad after that time.

00:13:02.900 --> 00:13:07.180
Other changes we've made to the Sequence
Grabber and Video Digitizer interaction.

00:13:07.180 --> 00:13:13.100
We've made it easier for Video Digitizers
to support more than one device.

00:13:13.100 --> 00:13:16.230
Previously,
because we always used the component

00:13:16.230 --> 00:13:20.120
name as the thing we displayed,
you effectively had to register one

00:13:20.170 --> 00:13:21.790
component for each device you had.

00:13:21.800 --> 00:13:24.700
And that was particularly
cumbersome under 10,

00:13:24.700 --> 00:13:29.160
because you end up registering them
with every application you launch,

00:13:29.160 --> 00:13:30.010
rather than doing it globally.

00:13:31.050 --> 00:13:35.660
So we've added a Video Digitizer call,
VDGetDeviceName and flags.

00:13:37.420 --> 00:13:41.480
which is designed for VDIG to
dynamically report what the name of

00:13:41.480 --> 00:13:45.440
the device is currently got plugged in,
rather than having a

00:13:45.440 --> 00:13:47.540
generic name from the VDIG.

00:13:47.600 --> 00:13:50.670
So this is particularly useful
for hot-pluggable cameras,

00:13:50.830 --> 00:13:54.360
where you could have one generic
VDIG supporting many different ones,

00:13:54.360 --> 00:13:57.860
or you could come up with a user
way of naming the devices and then

00:13:57.910 --> 00:14:02.040
report those names back if you wanted
to store preferences like that.

00:14:04.470 --> 00:14:08.490
Additionally,
we've added these unique ID APIs to help

00:14:08.670 --> 00:14:11.600
you identify a specific hardware device.

00:14:11.600 --> 00:14:15.980
FireWire devices have
unique IDs by default.

00:14:16.150 --> 00:14:17.670
USB ones don't.

00:14:17.670 --> 00:14:20.080
As part of the standard,
they can have those added

00:14:20.170 --> 00:14:21.280
in ROMs or whatever.

00:14:21.280 --> 00:14:23.320
You may have a private
API to query those.

00:14:23.320 --> 00:14:26.220
The point of these is for
the persistent settings that

00:14:26.590 --> 00:14:28.340
the Sequence Grabber stores.

00:14:31.300 --> 00:14:35.480
The Sequence Grabber will call
VDIG at unique IDs and ask for

00:14:35.560 --> 00:14:39.860
the unique identifier for the
device and the input in use,

00:14:39.860 --> 00:14:41.860
and it will store those
in the preferences.

00:14:41.860 --> 00:14:44.860
When it wants to restore that,
it will call VD_SELECT_UNIQUE_IDs.

00:14:45.160 --> 00:14:49.200
Note that it's select, not set,
because we can't change the unique ID.

00:14:49.200 --> 00:14:52.140
We just want to say, if you have a device
with that ID attached,

00:14:52.200 --> 00:14:54.350
please start using it.

00:14:58.040 --> 00:15:00.500
Back to a more general piece.

00:15:00.500 --> 00:15:07.040
When we moved to OS X,
we deprecated SND record to file.

00:15:07.040 --> 00:15:09.950
Well, we had actually deprecated
it a while back on 9,

00:15:10.060 --> 00:15:13.460
but we didn't implement it at
all on 10 because it didn't fit

00:15:13.470 --> 00:15:15.180
in with the way that OS X works.

00:15:15.180 --> 00:15:17.470
The recommended way for capturing
sound is to use the Sequence

00:15:17.470 --> 00:15:18.720
Grabber with a sound channel.

00:15:21.800 --> 00:15:28.300
In QuickTime 5.04 on Mac OS X and
now in QuickTime 6 on all platforms,

00:15:28.320 --> 00:15:32.800
we've adapted the sound recordings to
use much better sample rate conversion

00:15:32.800 --> 00:15:38.100
and to allow bit depth and channel
conversion so that you can record from,

00:15:38.220 --> 00:15:41.700
say,
a stereo 48 kHz source at 8 kHz mono.

00:15:45.300 --> 00:16:06.600
[Transcript missing]

00:16:08.940 --> 00:16:13.740
Other enhancements we've
made to video capture,

00:16:13.970 --> 00:16:18.530
as was mentioned in Tim's
keynote this morning,

00:16:18.530 --> 00:16:22.830
we've added support for
the iIDC class of cameras.

00:16:22.840 --> 00:16:28.970
This is a general spec for FireWire
cameras that you can plug in different

00:16:28.970 --> 00:16:33.200
ones for multiple manufacturers,
and there's a wire format

00:16:33.230 --> 00:16:34.880
defined for what they're sending.

00:16:35.260 --> 00:16:39.050
The data is not compressed,
but it can be YUV or RGB,

00:16:39.050 --> 00:16:42.350
and we've got some
broad support for that.

00:16:42.380 --> 00:16:45.740
In addition, as I said,
we've changed the settings user

00:16:45.740 --> 00:16:50.620
interface to add a series of features,
which we'll demonstrate for you shortly,

00:16:50.620 --> 00:16:53.940
to bring it up to date
with the rest of the OS.

00:16:53.940 --> 00:16:58.220
And there's some extra
features specifically for

00:16:58.280 --> 00:17:00.900
supporting the iIDC cameras.

00:17:01.700 --> 00:17:08.990
So I'd like to invite Sean Williams up
to show us these new IDC cameras.

00:17:15.210 --> 00:17:23.000
As Kevin mentioned, Jaguar,
we support a new class of firewire

00:17:23.000 --> 00:17:26.090
devices called the IIDC cameras.

00:17:26.100 --> 00:17:27.920
It's a mouthful of an acronym.

00:17:27.920 --> 00:17:31.540
It stands for something
like Instrumentation and

00:17:31.550 --> 00:17:33.460
Industrial Digital Camera.

00:17:33.460 --> 00:17:40.640
But the spec is flexible enough that it
provides for a wide range of devices,

00:17:40.640 --> 00:17:46.470
ranging from lower-priced
consumer webcam-type cameras for

00:17:46.470 --> 00:17:54.640
under $100 up to higher-level
$1,000 3CD fancy optic devices.

00:17:54.640 --> 00:17:58.140
So I'd real quickly like to
demonstrate that for you all.

00:17:58.160 --> 00:18:04.100
Since it is firewire, as you can imagine,
you can plug up to 60... 63 of

00:18:04.510 --> 00:18:11.010
these devices into your computer,
and we'd like to essentially let you

00:18:11.160 --> 00:18:15.770
digitize from all the cameras which
you have firewire bandwidth for.

00:18:15.890 --> 00:18:20.220
So I'm going to quickly show
the different scenarios in which

00:18:20.220 --> 00:18:25.880
multiple cameras can be used
under Jaguar with QuickTime 6.

00:18:25.930 --> 00:18:30.010
So the first thing I'd like to do
is show you a single application

00:18:32.400 --> 00:19:03.200
[Transcript missing]

00:19:03.720 --> 00:19:07.600
and you'll see one application
using multiple inputs.

00:19:07.600 --> 00:19:10.860
Similarly,
there's no reason you need to limit

00:19:10.860 --> 00:19:15.260
yourself to just one application.

00:19:15.260 --> 00:19:18.310
Let's go back to single window mode here.

00:19:20.880 --> 00:19:25.600
Here I have one application again,
grabbing from one camera.

00:19:25.740 --> 00:19:27.790
And I'll just start up
a second application.

00:19:27.810 --> 00:19:30.910
And you have two streams
running simultaneously,

00:19:31.050 --> 00:19:31.800
different apps.

00:19:31.800 --> 00:19:35.390
As long as I had,
I could conceivably launch several

00:19:35.450 --> 00:19:40.380
more applications and be capturing
from all of them concurrently.

00:19:40.700 --> 00:19:45.190
So finally,
you can imagine applications such as

00:19:45.390 --> 00:19:49.210
maybe stereoscopic imaging or something
like that where it would be useful to

00:19:49.220 --> 00:19:55.100
have one application simultaneously
capturing from two different cameras.

00:19:55.100 --> 00:19:59.300
And I've got a quick little demo of
that sort of operation going on here.

00:19:59.300 --> 00:20:03.100
And as you can see,
a single application could open

00:20:03.100 --> 00:20:07.600
up multiple video channels and
concurrently be grabbing from them.

00:20:07.600 --> 00:20:14.130
So you can imagine different
applications for that in the future.

00:20:14.630 --> 00:20:17.930
Finally,
Kevin mentioned that the Sequence

00:20:17.930 --> 00:20:22.780
Grabber settings dialog has been
revised to become more Aqua compliant,

00:20:22.960 --> 00:20:25.470
so I'd like to show you that briefly.

00:20:27.820 --> 00:20:31.790
The first thing you'll notice
is that as opposed to being a

00:20:31.790 --> 00:20:39.250
pop-up menu-driven interface,
we now are a tab-based interface

00:20:39.250 --> 00:20:45.000
consistent with the look and
feel of other OS X applications.

00:20:45.980 --> 00:20:51.080
Similarly, for the source menu,
instead of being a pop-up,

00:20:51.080 --> 00:20:57.970
it's a scrollable list so I can
just seamlessly toggle back

00:20:57.970 --> 00:21:00.880
and forth between devices.

00:21:01.870 --> 00:21:09.620
The observant few, or many in here,
would notice that there's a new

00:21:09.620 --> 00:21:12.880
set of panels that are available.

00:21:12.920 --> 00:21:15.060
Let me quickly jump over here.

00:21:15.150 --> 00:21:22.610
In addition to the existing compression,
image, and source panels of the past,

00:21:22.840 --> 00:21:25.920
we've added a new color,

00:21:26.200 --> 00:21:39.600
[Transcript missing]

00:21:40.400 --> 00:22:54.700
[Transcript missing]

00:22:55.230 --> 00:22:59.930
There's a, in addition to the standard
live preview window,

00:22:59.940 --> 00:23:03.590
we have another preview
source where you could,

00:23:03.700 --> 00:23:06.060
for example,
be looking at the compressed image.

00:23:06.100 --> 00:23:10.450
If you needed to,
you could throw it into a

00:23:10.450 --> 00:23:14.040
vectorscope mode and quickly see...

00:23:14.200 --> 00:23:21.100
[Transcript missing]

00:23:22.100 --> 00:23:27.100
So that pretty much covers the IIDC and
the new Sequence Grabber panels.

00:23:27.100 --> 00:23:29.520
So thank you very much, Kevin.

00:23:35.800 --> 00:23:44.540
introduce Tom Dowdy to talk
about video processing.

00:23:44.540 --> 00:23:47.630
Thanks, Kevin.

00:23:47.630 --> 00:23:47.630
I'm taller than Tim is.

00:23:49.660 --> 00:23:53.230
One of the most common questions that
we get asked when talking about video

00:23:53.230 --> 00:23:58.300
capture or movie playback is how
to perform processing on the video.

00:24:00.160 --> 00:24:02.580
and it's a reasonable question
for developers to ask.

00:24:02.760 --> 00:24:06.330
There are lots of ways for QuickTime to
perform operations on video,

00:24:06.340 --> 00:24:08.630
either video you've already captured
or video you're in the process

00:24:08.630 --> 00:24:11.300
of capturing or video that you're
in the process of playing back.

00:24:11.510 --> 00:24:14.330
And it can be confusing to find
your way through all the APIs.

00:24:14.450 --> 00:24:21.370
So we thought we'd take some time today
to talk about the various techniques you

00:24:21.370 --> 00:24:22.690
can use to get your hands on the video,
perform modifications of

00:24:22.690 --> 00:24:22.690
it within your application.

00:24:24.990 --> 00:24:28.860
So the first type of processing that
we think is appropriate for people to

00:24:28.860 --> 00:24:32.380
consider is processing live capture.

00:24:32.870 --> 00:24:35.460
This is a situation where you
may have a camera that's being

00:24:35.490 --> 00:24:38.990
digitized coming through QuickTime,
and the compressed data can be

00:24:38.990 --> 00:24:42.240
given to your application before
anything else is done to it.

00:24:42.330 --> 00:24:45.070
This is done through the
application's SGDataProc,

00:24:45.180 --> 00:24:46.920
which you install.

00:24:46.980 --> 00:24:49.510
At that point,
you can decompress the video,

00:24:49.730 --> 00:24:55.770
display it to the screen,
you can process the video,

00:24:55.770 --> 00:24:55.770
save it to a file,
or a combination of the two.

00:24:57.980 --> 00:24:58.860
So what's good about this?

00:24:58.890 --> 00:25:00.860
Well, the good thing about this
is it takes place live,

00:25:01.070 --> 00:25:03.800
interactively,
while the user is digitizing the video.

00:25:03.800 --> 00:25:05.190
What's bad about this?

00:25:05.360 --> 00:25:08.060
Well, it takes place live,
while the user is digitizing the video,

00:25:08.060 --> 00:25:10.660
which means that if your processing
algorithm takes a long time,

00:25:10.730 --> 00:25:15.040
you can cause dropped frames to
take place during the capture.

00:25:15.040 --> 00:25:17.520
This isn't really an appropriate
sort of thing for you to be doing

00:25:17.590 --> 00:25:21.860
if you're doing pro-level capture,
but if you have a capture application

00:25:22.040 --> 00:25:26.410
that's for lower data rate or smaller
size video or situations where perfect

00:25:26.790 --> 00:25:30.990
frame capture is not necessary,
for example, maybe you're doing a

00:25:30.990 --> 00:25:32.960
preview capture of a tape,
a roll-through,

00:25:32.960 --> 00:25:36.150
the user is going to do some adjustments,
they want to take a look at it,

00:25:36.230 --> 00:25:39.570
and then they're going to later go
make a second pass through the video,

00:25:39.570 --> 00:25:40.360
do a real capture.

00:25:40.360 --> 00:25:43.720
It might be okay to do this kind
of adjustment at that point.

00:25:43.720 --> 00:25:47.450
It's also fine to use for operations
like webcams or where you might

00:25:47.450 --> 00:25:50.780
be performing detection on the
video stream which is coming in,

00:25:50.780 --> 00:25:53.240
and you're going to,
based upon the detection,

00:25:53.270 --> 00:25:54.250
do some actual capture.

00:25:54.260 --> 00:25:54.260
So, you're going to be able to do that.

00:25:54.370 --> 00:25:55.800
So, that's the first action.

00:25:55.800 --> 00:25:59.260
The source code that demonstrates
how to do live capture processing,

00:25:59.260 --> 00:26:03.670
the SGDataProc sample,
which used to be known as Minimung,

00:26:03.670 --> 00:26:08.420
there is one really important
thing about this sample code.

00:26:08.420 --> 00:26:11.730
If you've previously
downloaded samples of Minimung,

00:26:11.730 --> 00:26:13.610
you're going to nod, right?

00:26:14.290 --> 00:26:16.340
If you've previously downloaded
examples of Minimung,

00:26:16.340 --> 00:26:17.880
you should make sure you download,
and you,

00:26:17.880 --> 00:26:21.490
and incorporate them in your application,
you should make sure that you download

00:26:21.610 --> 00:26:26.040
the latest sample code and check
it out because there was one very

00:26:26.040 --> 00:26:29.490
small bug in the Minimung example
code that could cause some problems

00:26:29.590 --> 00:26:33.320
in your application depending on
what you're doing with the data.

00:26:33.450 --> 00:26:34.550
So, enough of that.

00:26:34.760 --> 00:26:36.400
How about a demo?

00:26:39.670 --> 00:26:41.110
Okay, take it away, Kevin.

00:26:41.110 --> 00:26:46.510
Okay, so we've had a lot of requests
for people to do live demos,

00:26:46.520 --> 00:26:49.980
and one of the most unusual ones we heard
of was from someone called Robert Huber,

00:26:49.980 --> 00:26:53.160
who wanted to use the Sequence
Grabber to detect lobsters in a tank.

00:26:53.160 --> 00:26:56.020
So we thought this was an
interesting approach for the demo.

00:26:56.020 --> 00:26:58.540
So...

00:26:58.730 --> 00:27:04.120
I'm going to launch the Sequence Grabber,
choose the camera here.

00:27:04.120 --> 00:27:05.350
Wrong one.

00:27:05.350 --> 00:27:05.350
Oops.

00:27:07.960 --> 00:27:15.510
and even I've got the Lobster
Detection Program running here.

00:27:15.510 --> 00:27:15.510
So if I'm going to bring
my lobster in here,

00:27:19.100 --> 00:27:34.100
[Transcript missing]

00:27:40.220 --> 00:27:41.110
Want to tell us how that works, Tom?

00:27:41.350 --> 00:27:42.060
Sure.

00:27:42.360 --> 00:27:45.140
I suspect that the person who
is doing scientific detecting

00:27:45.140 --> 00:27:48.100
of lobsters in a tank is using
a slightly more sophisticated

00:27:48.100 --> 00:27:55.300
algorithm than the one we used here,
which we're using the SG data sample.

00:27:55.590 --> 00:27:56.750
are all involved in this.

00:27:56.750 --> 00:27:58.600
The first step is to capture the video.

00:27:58.640 --> 00:28:01.270
The data comes in,
we decompress it into an off-screen.

00:28:01.270 --> 00:28:04.230
At that point we scan through the video,
converting it into YUV,

00:28:04.230 --> 00:28:06.960
and looking for colors of red
that are present in lobsters.

00:28:07.120 --> 00:28:09.620
And when we detect that there
is enough red in the frame,

00:28:09.620 --> 00:28:12.770
we say, "Hmm, there must be a lobster
there." We record the left,

00:28:12.970 --> 00:28:15.100
right, top,
and bottom area where the lobster is.

00:28:15.280 --> 00:28:17.730
That forms the rectangle
that's drawn on the screen.

00:28:17.840 --> 00:28:21.200
And then based upon the area of the
screen that's covered with the rectangle,

00:28:21.330 --> 00:28:25.440
well that's how big the lobster is and
how much melted butter you would need.

00:28:29.630 --> 00:28:31.560
It's a recurring theme
in the QuickTime team,

00:28:31.630 --> 00:28:33.260
lobsters for some strange reason.

00:28:33.410 --> 00:28:35.100
Slides, please.

00:28:39.410 --> 00:28:40.800
Okay.

00:28:40.890 --> 00:28:43.700
So the next type of question
we get all the time is,

00:28:43.720 --> 00:28:45.900
"Alright, I don't want to process the
movie as I'm capturing it.

00:28:45.900 --> 00:28:48.780
I want to capture the movie
and then later I want to do

00:28:48.800 --> 00:28:54.000
some processing on it." So,
what goes on here?

00:28:54.000 --> 00:28:56.470
You've got a movie,
it's saved out on disk somewhere,

00:28:56.800 --> 00:28:59.870
you read the movie in,
it's going to come into QuickTime.

00:29:00.140 --> 00:29:02.050
You direct that movie into an off-screen.

00:29:02.260 --> 00:29:04.390
QuickTime will give you
the raw pixel information.

00:29:04.530 --> 00:29:06.030
It will go into the off-screen.

00:29:06.090 --> 00:29:07.900
At that point,
you can perform whatever processing

00:29:07.900 --> 00:29:09.380
you want to do on the off-screen.

00:29:09.640 --> 00:29:13.430
For example, here we're placing a text
overlay on top of the video.

00:29:13.510 --> 00:29:15.850
You can then send the
data back into QuickTime,

00:29:16.070 --> 00:29:19.420
have it be recompressed and exported
in whatever format QuickTime supports,

00:29:19.420 --> 00:29:21.770
in this case an MPEG-4 file,
and it gets written out

00:29:21.770 --> 00:29:23.770
into a brand-new movie.

00:29:26.350 --> 00:29:29.500
So, what are the pros and
cons of this approach?

00:29:29.860 --> 00:29:32.320
Well, one of the pros is that all
the frames get modified.

00:29:32.390 --> 00:29:34.580
Since you're processing
them one at a time,

00:29:34.740 --> 00:29:37.100
you're sure that they all
go through the system.

00:29:37.180 --> 00:29:38.660
There's no time constraints here.

00:29:38.780 --> 00:29:41.530
If you have an algorithm that takes
one hour to process every frame,

00:29:41.750 --> 00:29:42.600
that's just fine.

00:29:42.730 --> 00:29:44.560
Every frame will still get processed.

00:29:44.620 --> 00:29:45.600
None will be skipped.

00:29:45.700 --> 00:29:47.450
It might take a while
to do the whole video,

00:29:47.600 --> 00:29:49.790
but they all will go through.

00:29:49.890 --> 00:29:51.550
The downside to this
is it's not real time.

00:29:52.110 --> 00:29:53.860
And that's on both sides of the fence.

00:29:53.860 --> 00:29:56.700
If your algorithm does take a long time,
it's going to take greater than

00:29:56.700 --> 00:30:00.730
real time for the movie to be
processed or displayed to the user.

00:30:00.980 --> 00:30:03.550
Similarly, if your algorithm is
faster than real time,

00:30:03.610 --> 00:30:06.770
you're going to proceed through the
movie quicker than in real time.

00:30:06.880 --> 00:30:10.740
Once again, that might be confusing
or annoying to the user.

00:30:11.410 --> 00:30:15.200
Also, because this process
is potentially lengthy,

00:30:15.270 --> 00:30:17.980
it's difficult to have more
than one setting for the user.

00:30:18.140 --> 00:30:20.120
Typically,
you set up the things at the beginning,

00:30:20.120 --> 00:30:22.200
and you do a batch process,
and you go through all the frames.

00:30:22.340 --> 00:30:24.980
This isn't a really great thing
for interacting with the user,

00:30:24.980 --> 00:30:27.240
and they want to change
things as they go along.

00:30:27.360 --> 00:30:28.880
But what are some things
you might do here?

00:30:29.110 --> 00:30:31.550
Well, the real basic one is if you're
just recompressing the movie

00:30:31.550 --> 00:30:34.990
from one format to another,
that's a great thing to be doing here.

00:30:35.230 --> 00:30:37.330
But before you do that compression,
you might want to be

00:30:37.330 --> 00:30:39.730
doing a 3-2 pull-down,
you might want to blur

00:30:39.730 --> 00:30:41.990
or sharpen the image,
deinterlace it,

00:30:42.080 --> 00:30:45.730
do all those other sorts of
pixel image processing operations

00:30:45.790 --> 00:30:47.640
you might want to do on video.

00:30:47.750 --> 00:30:50.580
The canonical source to this,
which has been out there for a while,

00:30:50.700 --> 00:30:52.340
is called Convert to Movie Junior.

00:30:52.520 --> 00:30:57.090
It shows an example of how
to do this basic operation.

00:30:57.210 --> 00:31:01.280
But let's have a demo instead.

00:31:02.960 --> 00:31:09.060
So what we're going to do for this
demo is add an overlay onto the movie.

00:31:09.110 --> 00:31:11.290
So imagine you just
made this great movie,

00:31:11.300 --> 00:31:12.760
you wanted to send that
to someone for approval,

00:31:12.800 --> 00:31:15.030
but you wanted to make sure it
had your overlay on it so they

00:31:15.030 --> 00:31:16.890
wouldn't use it before they paid you.

00:31:17.070 --> 00:31:23.180
So I'm going to open up this
Jellyfish movie that I filmed earlier.

00:31:23.820 --> 00:31:32.560
choose the compression I'm going to use,
in this case, JPEG,

00:31:32.560 --> 00:31:32.560
and run the processing.

00:31:32.560 --> 00:31:32.560
I'm going to save it out as...

00:31:33.800 --> 00:31:51.100
[Transcript missing]

00:31:53.760 --> 00:32:05.620
and the rest of the team
are working on the project.

00:32:05.620 --> 00:32:15.390
Tim Cherna, Kevin Marks, Sean Williams,
Tom Dowdy, Jean-Michel Berthoud

00:32:17.410 --> 00:32:19.560
Couple of things to note about that demo.

00:32:19.810 --> 00:32:22.640
First of all,
when you're doing video compression,

00:32:22.640 --> 00:32:25.360
Kevin brought up the standard
video compression dialogue and

00:32:25.390 --> 00:32:26.700
the options that were there.

00:32:26.890 --> 00:32:29.020
If you have an application
that's doing video compression,

00:32:29.090 --> 00:32:32.880
it's really strongly recommended that
you use the standard compression dialogue

00:32:32.880 --> 00:32:35.030
to let your user configure the options.

00:32:35.160 --> 00:32:36.850
By doing that,
you make sure that whenever

00:32:36.900 --> 00:32:39.530
we add additional options
specific to a particular codec,

00:32:39.930 --> 00:32:43.010
they're available to the
user to tweak the settings.

00:32:43.200 --> 00:32:47.190
If you need to do batch processing
or you need to have scripting

00:32:47.190 --> 00:32:48.840
type interfaces to this,
you can also do the

00:32:48.840 --> 00:32:51.630
same settings via code,
but it's always preferable to have

00:32:51.630 --> 00:32:54.920
some way for the user to get to the
settings via the dialogue and save

00:32:54.930 --> 00:32:56.780
them away so they can later do them.

00:32:56.890 --> 00:32:58.580
This is, like I said,
the preferred way to do

00:32:58.580 --> 00:33:00.450
recompression or compression of data.

00:33:00.810 --> 00:33:02.430
And once again,
the convert to movie junior

00:33:02.430 --> 00:33:04.760
source code shows example of
how to bring up the dialogue,

00:33:04.760 --> 00:33:09.070
how to run this compression and
put the data back out into a movie.

00:33:10.400 --> 00:34:49.200
[Transcript missing]

00:34:49.840 --> 00:34:55.350
The third type of processing that people
want to do on movies is to process a

00:34:55.350 --> 00:34:57.170
movie in real time while it plays back.

00:34:57.170 --> 00:34:59.320
Now there's a feature of
QuickTime movies that's been

00:34:59.320 --> 00:35:02.780
around since QuickTime 3.0 called
the QuickTime Effects Architecture,

00:35:02.780 --> 00:35:05.530
and certainly it's worth taking a look
at that if you're not aware of it.

00:35:05.550 --> 00:35:07.080
We're not going to
focus a lot on it today,

00:35:07.080 --> 00:35:09.110
but we're going to talk about
it briefly for those of you

00:35:09.130 --> 00:35:10.360
who aren't familiar with it.

00:35:10.610 --> 00:35:14.320
The QuickTime Effects Architecture is
a way to operate on tracks,

00:35:14.320 --> 00:35:16.950
a track or tracks,
and do image processing or

00:35:17.050 --> 00:35:18.640
effects on those tracks.

00:35:18.640 --> 00:35:23.730
For example,
transitions between one track or another,

00:35:23.800 --> 00:35:30.210
or a traveling matte, or a gradient wipe,
or a blur or a sharpen.

00:35:30.910 --> 00:35:34.100
The QuickTime Effects architecture,
however, operates on individual tracks,

00:35:34.240 --> 00:35:35.460
not entire movies.

00:35:35.570 --> 00:35:39.860
If you're interested in how to do
processing of movies using effects,

00:35:39.970 --> 00:35:42.270
you can look at the
Make Effect Movie Source Code that's

00:35:42.270 --> 00:35:43.590
available on Apple's website.

00:35:43.730 --> 00:35:47.450
Today we're going to focus more, however,
on processing the movie

00:35:47.450 --> 00:35:49.200
within your application.

00:35:49.300 --> 00:35:52.560
So this is a type of processing that
operates on the entire movie at once.

00:35:52.670 --> 00:35:54.800
That is to say, the whole frame,
which might be composed

00:35:54.860 --> 00:35:56.060
of multiple tracks.

00:35:56.090 --> 00:35:58.310
An example of this that you
may be aware of today is the

00:35:58.640 --> 00:36:01.600
Video Adjustments feature,
which is inside QuickTime Player.

00:36:01.670 --> 00:36:03.660
This feature is implemented
by using the techniques that

00:36:03.660 --> 00:36:06.060
we're about to talk about.

00:36:06.210 --> 00:36:08.110
So how does this all work?

00:36:09.250 --> 00:36:13.480
You have a movie, and QuickTime is going
to play the movie back.

00:36:13.590 --> 00:36:16.260
Your application registers
a draw complete proc and

00:36:16.460 --> 00:36:18.240
directs the movie off screen.

00:36:18.370 --> 00:36:22.100
QuickTime then decompresses the movie,
producing raw pixel data,

00:36:22.190 --> 00:36:25.230
and calls your application back
whenever there's actually a

00:36:25.230 --> 00:36:28.450
change that's taken place in what
should be displayed to the user.

00:36:28.530 --> 00:36:31.980
You can then take the resulting data,
you can display it to the screen,

00:36:32.090 --> 00:36:35.890
you can process it, save it away,
do both, whatever is appropriate for the

00:36:35.890 --> 00:36:37.690
type of thing you're trying to do.

00:36:37.800 --> 00:36:39.000
Pros and cons again.

00:36:41.310 --> 00:36:42.830
are all involved in this.

00:36:42.830 --> 00:36:47.120
The user can interact with the playback
and it works on the whole movie at once,

00:36:47.210 --> 00:36:49.340
no matter how many frames there are.

00:36:49.340 --> 00:36:51.150
There is a downside to this.

00:36:51.420 --> 00:36:55.550
And that's that as the movie is playing,
QuickTime will use its normal frame

00:36:55.640 --> 00:37:00.260
skipping algorithm to skip frames if
your processing or the video playback

00:37:00.260 --> 00:37:01.870
is not able to keep up with real time.

00:37:02.150 --> 00:37:05.040
That's so that the video
stays in sync with the audio.

00:37:05.160 --> 00:37:07.140
The other downside to this,
it can be difficult to package

00:37:07.140 --> 00:37:09.520
your particular processing
code up because it's taking

00:37:09.570 --> 00:37:10.950
place within your application.

00:37:11.050 --> 00:37:14.060
So if this is something that needs to
be available in multiple applications

00:37:14.060 --> 00:37:18.060
or needs to be able to be delivered
independent of the movie itself,

00:37:18.200 --> 00:37:21.180
the effect approach would
be more appropriate.

00:37:21.390 --> 00:37:23.900
Like I said,
a good example of use of this is

00:37:23.900 --> 00:37:27.670
live movie adjustments or adjusting
the various video settings that

00:37:27.680 --> 00:37:29.710
are done in QuickTime Player today.

00:37:30.050 --> 00:37:33.680
The example code for this is called
MovieGWorlds and it's been out on Apple's

00:37:33.870 --> 00:37:37.390
QuickTime example code site for a while.

00:37:37.510 --> 00:37:38.960
How about another demo?

00:37:39.020 --> 00:37:41.450
Okay.

00:37:41.450 --> 00:37:41.450
So...

00:37:43.670 --> 00:37:47.530
What we're going to do here is play
back the jellyfish movie again and

00:37:47.800 --> 00:37:49.140
adjust the color while it's playing.

00:37:49.160 --> 00:37:50.620
So it's playing here.

00:37:50.620 --> 00:37:52.340
You can see it's drawing
a histogram of the red,

00:37:52.420 --> 00:37:53.720
green, and blue in the picture.

00:37:53.720 --> 00:37:57.030
Say we wanted to get rid of
that blue and gradually turn it

00:37:57.310 --> 00:37:58.970
down so that the sea is green.

00:37:58.980 --> 00:38:01.840
We can do that by adjusting
the range that the blue

00:38:01.840 --> 00:38:03.770
occupies on the fly like this.

00:38:03.780 --> 00:38:07.390
And again, if we didn't like the red,
we can turn that down and make

00:38:07.390 --> 00:38:11.540
the jellyfish greenish too
and put the blue back to full.

00:38:11.540 --> 00:38:13.330
We've got a sort of reddish jellyfish.

00:38:13.340 --> 00:38:20.240
We can even completely mess
up the thing by putting the...

00:38:21.700 --> 00:38:36.600
[Transcript missing]

00:38:38.520 --> 00:38:39.350
and others.

00:38:39.460 --> 00:38:40.840
So you can see there's a fair
amount of processing going on there.

00:38:40.850 --> 00:38:42.570
I mean, if nothing else,
just displaying the histograms

00:38:42.580 --> 00:38:44.570
is something that might
be useful to the user.

00:38:44.680 --> 00:38:46.640
But here we're actually allowing
the user to adjust those things.

00:38:46.640 --> 00:38:49.940
And we're still achieving very
good frame rate movie playback.

00:38:50.020 --> 00:38:53.040
As I said, there is the possibility of
frames being skipped here.

00:38:53.040 --> 00:38:54.540
That doesn't mean they
have to be skipped.

00:38:54.620 --> 00:38:57.760
This machine is more than
capable of keeping up with this.

00:38:57.760 --> 00:39:00.900
And I assure you that I'm not
using particularly sophisticated

00:39:00.900 --> 00:39:04.720
technique for drawing that graph.

00:39:04.750 --> 00:39:07.130
So we'll go back to slides now.

00:39:11.780 --> 00:39:14.640
Okay,
so we talk about processing the video.

00:39:14.640 --> 00:39:16.400
So what do we mean by
processing the video?

00:39:16.400 --> 00:39:18.820
How can you actually
perform the processing?

00:39:18.960 --> 00:39:21.800
Well, as I said,
one thing you could do is QuickTime has

00:39:21.800 --> 00:39:26.160
a number of effects that are built in:
blurs, sharpens, film noise, transitions,

00:39:26.160 --> 00:39:26.660
et cetera.

00:39:26.660 --> 00:39:31.360
You could take advantage of these effects
and call them from any of the processing

00:39:31.360 --> 00:39:33.770
techniques that I just outlined.

00:39:34.150 --> 00:39:36.850
Another common thing to want to
do is to write some custom code.

00:39:36.900 --> 00:39:39.340
If you want to look for
lobsters in your application,

00:39:39.340 --> 00:39:41.290
you're probably going to have
to write some custom code.

00:39:41.410 --> 00:39:45.040
I don't think the lobster finding
algorithm is going to make its way into

00:39:45.060 --> 00:39:48.100
QuickTime any time in the near future,
but you never know.

00:39:48.100 --> 00:39:50.580
So you're going to have custom
code in your application

00:39:50.670 --> 00:39:52.040
to perform the processing.

00:39:52.050 --> 00:39:57.200
The biggest issue here is if you
want to be able to... Excuse me.

00:40:02.980 --> 00:40:03.710
That was great.

00:40:03.720 --> 00:40:07.380
Okay, so the biggest issue here is if
you want to be able to perform your

00:40:07.380 --> 00:40:11.270
processing live on video as it's
being captured or on movies as they're

00:40:11.410 --> 00:40:14.720
being played back and you want to
have the user have a good experience,

00:40:14.830 --> 00:40:16.830
you need to concern
yourself with performance.

00:40:16.830 --> 00:40:19.780
But even if your application is just
a movie grinding type application,

00:40:19.820 --> 00:40:22.330
you're wanting to perform processing
on a movie and save it out,

00:40:22.330 --> 00:40:26.060
you still should think about performance
because if your particular movie,

00:40:26.170 --> 00:40:28.760
as it processes the movie and
saves it out into a movie,

00:40:28.870 --> 00:40:32.110
takes four times real time, well,
your users are going to be a lot

00:40:32.110 --> 00:40:35.920
less likely to want to feed an hour's
worth of video through that thing.

00:40:36.050 --> 00:40:38.000
So performance is always an issue.

00:40:38.080 --> 00:40:40.130
So how to deal with performance?

00:40:40.330 --> 00:40:43.030
Well, the first thing is just do
your basic optimization,

00:40:43.050 --> 00:40:43.460
right?

00:40:43.460 --> 00:40:44.490
Make things faster.

00:40:44.540 --> 00:40:45.480
That's always a good idea.

00:40:45.570 --> 00:40:49.190
But you should also take advantage
of things like the hardware,

00:40:49.190 --> 00:40:52.230
such as the velocity engine
that's available in the G4.

00:40:52.230 --> 00:40:55.360
A lot of pixel processing algorithms
lend themselves very much to

00:40:55.420 --> 00:40:57.670
use of the G4 velocity engine.

00:40:57.670 --> 00:41:00.960
Similarly, almost all these algorithms
have some amount of performance.

00:41:00.960 --> 00:41:01.410
So if you're going to be able to do
a lot of processing live with a G4,

00:41:01.410 --> 00:41:01.980
you want to take advantage of the
fact that you're able to use a lot of

00:41:02.020 --> 00:41:03.860
the processor separability to them.

00:41:03.970 --> 00:41:07.580
So being able to process a single frame
of video using multiple processors via

00:41:07.700 --> 00:41:11.650
threads is a very smart idea when this is
the kind of thing you're talking about.

00:41:13.040 --> 00:41:15.340
A third type of processing that
you might not have thought of

00:41:15.400 --> 00:41:17.050
is using the OpenGL hardware.

00:41:17.160 --> 00:41:20.930
There's some sessions here that talk
about integrating OpenGL with QuickTime.

00:41:21.210 --> 00:41:23.240
Unfortunately,
the session was just before this one,

00:41:23.240 --> 00:41:26.600
so some of you might have missed that.

00:41:26.690 --> 00:41:29.760
But in the session,
they talk about using the 3D engine as

00:41:29.770 --> 00:41:33.720
essentially a math engine to perform
some of this processing for you.

00:41:33.850 --> 00:41:36.600
Not all algorithms are suited to this,
and it can sometimes be

00:41:36.690 --> 00:41:38.500
very hardware-dependent,
but once again,

00:41:38.500 --> 00:41:42.630
that might be appropriate for
your type of image manipulation.

00:41:44.120 --> 00:41:47.920
Another thing that's often an issue
in this realm or this space is how to

00:41:47.920 --> 00:41:50.560
actually get the data back to the screen.

00:41:50.830 --> 00:41:54.630
Surprisingly enough, I mean,
often you would think that

00:41:54.680 --> 00:41:56.870
that would be obvious,
but it's not.

00:41:56.910 --> 00:41:59.780
And part of the reason it's
not obvious is there's a bunch

00:41:59.780 --> 00:42:01.340
of different ways to do it.

00:42:01.600 --> 00:42:03.750
The simplest method,
and if you don't have

00:42:03.750 --> 00:42:06.960
complicated performance
requirements or special needs,

00:42:07.180 --> 00:42:11.580
these are probably listed in the
order of simpler to more complicated,

00:42:11.810 --> 00:42:13.810
are the ways in which you
should deal with this,

00:42:13.900 --> 00:42:15.540
is to make use of the 2D graphics calls.

00:42:15.660 --> 00:42:19.380
For example, copy bits if you're familiar
with the Carbon World,

00:42:19.490 --> 00:42:22.480
NSImage if you're a Cocoa developer,
and that's the type of

00:42:22.480 --> 00:42:23.740
mechanism you want to use.

00:42:23.820 --> 00:42:26.910
A third thing that you consider,
a lot of people aren't aware of this,

00:42:26.980 --> 00:42:29.730
but it's very easy to make a
decompression sequence within

00:42:29.900 --> 00:42:33.010
QuickTime that can perform the
2D graphics operations for you

00:42:33.010 --> 00:42:35.920
for transferring data from an
off screen onto the screen.

00:42:36.040 --> 00:42:38.470
The big advantage of using a
decompression sequence is that

00:42:38.510 --> 00:42:41.190
with a decompression sequence
you're able to factor out the

00:42:41.320 --> 00:42:45.640
setup portion of your call from the
actual drawing portion of your call.

00:42:45.960 --> 00:42:49.330
This can make the subsequent
draws when you're processing

00:42:49.620 --> 00:42:51.410
multiple frames much faster.

00:42:52.330 --> 00:42:56.760
Another way to get data to the screen
is to build in your application a

00:42:56.760 --> 00:43:01.300
decompression component that performs
the video processing and at the same

00:43:01.300 --> 00:43:03.640
time draws the data to the screen.

00:43:03.640 --> 00:43:09.350
This is a very powerful technique as used
in several of the demos that we did here,

00:43:09.350 --> 00:43:13.140
because you are pipelining the
processing of the pixels along with the

00:43:13.140 --> 00:43:15.670
drawing of the pixels to the screen.

00:43:15.670 --> 00:43:21.200
It's also a very easy way to deal with
all of the various frame buffer formats,

00:43:21.310 --> 00:43:25.600
clipping, cursor hiding,
flushing of the screen, et cetera,

00:43:25.600 --> 00:43:29.250
by simply putting your code inside
of a decompression component,

00:43:29.250 --> 00:43:32.340
using it within that environment,
all those issues are dealt

00:43:32.340 --> 00:43:33.610
with for you by QuickTime.

00:43:35.570 --> 00:43:38.970
The third way to get the data to the
screen is to take the QuickTime movie

00:43:39.030 --> 00:43:42.510
that's in the G world and place
it in an OpenGL texture and then

00:43:42.620 --> 00:43:46.730
use the normal OpenGL calls to
render that texture to the screen.

00:43:46.730 --> 00:43:49.620
This has a great
advantage because OpenGL,

00:43:49.620 --> 00:43:52.410
assuming that you've set up your
textures properly and they're aligned

00:43:52.410 --> 00:43:55.840
appropriately and everything and the
hardware is set up so that it's doing

00:43:55.980 --> 00:43:59.580
all the things you need it to do,
OpenGL is able to asynchronously

00:43:59.580 --> 00:44:04.210
DMA the memory directly from the
buffer you have up onto the card.

00:44:04.440 --> 00:44:07.080
This allows you to essentially
pipeline additional processing

00:44:07.080 --> 00:44:08.680
while that transfer is taking place.

00:44:08.700 --> 00:44:13.980
There's two examples on Apple's website
that are worth taking a look here.

00:44:14.100 --> 00:44:17.110
One is called Fast Textures,
this is in the 3D section,

00:44:17.110 --> 00:44:19.180
another one is called OpenGL Movie.

00:44:19.230 --> 00:44:22.350
These both show techniques
for taking data off screen and

00:44:22.440 --> 00:44:25.660
transferring it quickly on screen
by using the OpenGL engine.

00:44:25.660 --> 00:44:30.090
How about more demos?

00:44:31.080 --> 00:44:32.200
We always like more demos.

00:44:32.220 --> 00:44:33.340
Everyone loves demos.

00:44:33.470 --> 00:44:34.790
Well, maybe not everyone.

00:44:34.890 --> 00:44:35.580
Okay.

00:44:36.120 --> 00:44:41.760
So,
we've got a... We showed various effects.

00:44:41.760 --> 00:44:43.840
We showed a single effect
for a Sequence Grabber,

00:44:43.850 --> 00:44:45.700
for Movie Conversion, and for Playback.

00:44:45.830 --> 00:44:50.560
What I'm going to do now is show the
effect you choose isn't dependent

00:44:50.560 --> 00:44:51.830
on the way you're doing it.

00:44:51.840 --> 00:44:55.570
So I'm going to show Sequence
Grabbing with an alpha overlay.

00:44:59.730 --> 00:45:03.360
So here you can see what it would be
like if I had a lobster on my head.

00:45:03.370 --> 00:45:08.400
In this case, we're capturing the video
with the Sequence Grabber,

00:45:08.400 --> 00:45:11.250
drawing it off screen,
compositing that with the

00:45:11.330 --> 00:45:16.070
lobster image we used before,
and drawing that back to the screen.

00:45:16.080 --> 00:45:19.990
And you can see the frame rate is
keeping up pretty well because the

00:45:19.990 --> 00:45:24.110
Sequence Grabber is dealing with
getting the data in the right format

00:45:24.110 --> 00:45:27.740
and getting it to the GWorld for you,
and then you can do pixel

00:45:27.750 --> 00:45:29.350
processing after that.

00:45:38.600 --> 00:45:44.830
Now we'll do the color adjustment
on the Live Sequence Grabber now.

00:45:44.910 --> 00:45:45.960
So this is coming in.

00:45:46.040 --> 00:45:50.880
I can make myself more red.

00:45:50.880 --> 00:45:50.880
I can...

00:45:51.720 --> 00:45:53.240
Take out the blue.

00:45:53.240 --> 00:45:55.440
I can posterize myself.

00:45:55.490 --> 00:45:58.480
Make the screen go a
funny color behind me.

00:46:04.980 --> 00:46:10.530
come up with this nice sort
of 1970s-looking effect here.

00:46:10.900 --> 00:46:13.040
And again,
this is doing the same pixel processing

00:46:13.040 --> 00:46:17.100
operations we were doing before on
the movie as it was playing back,

00:46:17.230 --> 00:46:19.740
but we're doing it on the
GWorld that's being fed from

00:46:19.760 --> 00:46:24.490
data from the Sequence Grabber,
because the two parts are separable.

00:46:26.120 --> 00:46:31.730
This is an example of
applying a QuickTime effect.

00:46:31.730 --> 00:46:31.730
So...

00:46:32.220 --> 00:46:35.320
The film noise effect is being
applied over the top of me,

00:46:35.330 --> 00:46:37.130
so I'm going to black and white.

00:46:37.270 --> 00:46:39.360
There are film scratches coming up.

00:46:41.240 --> 00:46:52.010
are all involved in the project.

00:46:52.010 --> 00:46:52.010
Tim Cherna, Kevin Marks, Sean Williams,
Tom Dowdy, Jean-Michel Berthoud

00:46:58.130 --> 00:47:09.560
and as we have two IDC cameras attached,
we can add a QuickTime effect that takes

00:47:09.580 --> 00:47:12.810
two sources and blends them together.

00:47:19.200 --> 00:47:23.510
So we can have this nice background here,
and then we can bring

00:47:23.510 --> 00:47:25.970
up the heart around,
head in the right place.

00:47:26.000 --> 00:47:30.000
I can maybe respond to it, Tom.

00:47:30.000 --> 00:47:32.200
So we can see we're performing
this effect on there.

00:47:32.200 --> 00:47:37.310
Both cameras are actually
capturing that's going on here.

00:47:41.780 --> 00:47:45.400
And similarly, we can apply these same
filters to the movie playback.

00:47:45.490 --> 00:47:47.140
So for example,
we could do the movie playback

00:47:47.260 --> 00:47:51.650
of the jellyfish with the
lobster over it in real time.

00:47:51.700 --> 00:47:58.700
The processing stage is independent of
the way you get the data in and out.

00:47:58.700 --> 00:48:01.300
Okay.

00:48:02.370 --> 00:48:07.640
Thanks, Kevin.

00:48:07.800 --> 00:48:10.490
Okay, now to Jean-Michel.

00:48:17.000 --> 00:48:22.160
Thank you, Tom.

00:48:22.490 --> 00:48:25.940
So Kevin talked to you
about digitizing video.

00:48:26.030 --> 00:48:29.090
Then Tom talked to you about
processing this video that

00:48:29.090 --> 00:48:31.560
you digitize on your computer.

00:48:31.650 --> 00:48:36.180
So the last step you might want
to add to your application is the

00:48:36.180 --> 00:48:40.970
capability of outputting these
movies to a specific video device.

00:48:41.160 --> 00:48:44.580
And that's what video
output are all about.

00:48:46.120 --> 00:48:49.870
So originally QuickTime was
capable of playing movies

00:48:49.880 --> 00:48:53.170
only on your computer desktop,
and that's why we had to come up

00:48:53.400 --> 00:48:57.520
with this video output component in
order to support different devices

00:48:57.660 --> 00:49:00.500
like Analog One or Digital Now.

00:49:00.650 --> 00:49:05.110
But basically the idea is to be
able to send this video to a device

00:49:05.110 --> 00:49:07.500
which is not a computer desktop.

00:49:08.100 --> 00:49:12.180
So that does include
third-party I/O cards,

00:49:12.300 --> 00:49:15.390
fire-wired devices,
and any other peripherals that

00:49:15.710 --> 00:49:19.320
third-party could add to your system.

00:49:20.000 --> 00:49:24.930
Later on, we're going to show you some
demo of this video output stuff,

00:49:25.070 --> 00:49:30.420
and the sample code is on our website,
and it's called Simple Video Output.

00:49:30.520 --> 00:49:31.700
It's a simple application.

00:49:31.700 --> 00:49:33.080
You can use the code.

00:49:33.320 --> 00:49:36.190
We did add an old word
post-it with the same name,

00:49:36.200 --> 00:49:41.210
so you might want to check it out
for the updated version we have now.

00:49:42.860 --> 00:49:48.650
So movies plays on the G-Wall anywhere,
whether you play it on your desktop

00:49:48.740 --> 00:49:51.250
or on your video output devices.

00:49:51.370 --> 00:49:55.180
So this video output component
provides the G-Wall so you can

00:49:55.180 --> 00:49:58.120
set them up and point to them.

00:49:58.370 --> 00:50:03.460
The thing you have to understand is that
only QuickTime can use this G-World.

00:50:03.690 --> 00:50:07.000
It's not known as a QuickDraw G-World,
so you cannot use QuickDraw and

00:50:07.000 --> 00:50:08.390
do a bunch of drawing on it.

00:50:08.520 --> 00:50:13.970
You have to use QuickTime in order
to draw to this specific G-World.

00:50:14.400 --> 00:50:18.810
Video output components provide some
information about their capabilities.

00:50:18.990 --> 00:50:23.310
They might be attached to an
audio output device as well,

00:50:23.310 --> 00:50:28.530
so you might want to figure out
what's the hardware setup to play

00:50:28.890 --> 00:50:31.300
audio and video on the same device.

00:50:31.480 --> 00:50:35.800
They can provide some clock
components so they maintain the

00:50:35.800 --> 00:50:39.000
synchronization between audio and video.

00:50:39.210 --> 00:50:43.490
Some of them support what
we call the EchoPort,

00:50:43.540 --> 00:50:47.750
which is basically the capability to
output to this specific device and

00:50:47.750 --> 00:50:55.030
to display a kind of preview on your
desktop computer at the same time.

00:50:56.950 --> 00:51:00.180
Video outputs are just components.

00:51:00.300 --> 00:51:03.760
You find them like any regular component.

00:51:03.900 --> 00:51:08.670
You use the FindNext component,
and the type of this video output

00:51:08.670 --> 00:51:12.570
component is QtVideoOutputComponentType.

00:51:13.370 --> 00:51:18.990
One thing you have to be careful
of is that in order to have this...

00:51:19.290 --> 00:51:22.210
Video output component,
QuickTime has built in a

00:51:22.210 --> 00:51:26.130
base video output component,
which is always going to show up in the

00:51:26.130 --> 00:51:30.250
list of video output component available
in order to take it out of your list

00:51:30.250 --> 00:51:34.300
so you present to the user only the
real device available on the system.

00:51:34.300 --> 00:51:43.080
You have to set this flag mask called
KQT video output don't display to user,

00:51:43.080 --> 00:51:43.710
so we take it out of the
list of available devices.

00:51:44.740 --> 00:51:52.380
So the way you are getting this device's
capabilities is to use three APIs.

00:51:52.460 --> 00:51:55.490
The first one is Qt Video Output
Get Display Mode List,

00:51:55.490 --> 00:51:58.700
which provides a list of all
the different resolutions of

00:51:58.970 --> 00:52:03.420
timing that this device supports,
like, for instance, NTSC, square pixel,

00:52:03.530 --> 00:52:07.170
non-square pixel,
everything this device can support,

00:52:07.240 --> 00:52:10.980
they should list them as a
different mode in their list.

00:52:11.960 --> 00:52:15.570
The way you figure out about the...

00:52:15.900 --> 00:52:19.970
The sound capability of this
video output device is to use the

00:52:20.070 --> 00:52:22.890
QtVideoOutputGetIndexedSum output.

00:52:22.900 --> 00:52:27.020
And this will tell you if this
device has a specific audio

00:52:27.020 --> 00:52:28.900
device attached to it or not.

00:52:28.900 --> 00:52:34.980
And the last thing is the
QtVideoOutputGetClark API,

00:52:34.980 --> 00:52:38.930
which lets you figure out if
this specific device needs

00:52:39.090 --> 00:52:41.170
or doesn't need a clock.

00:52:45.730 --> 00:52:50.360
So how do you select this video output
component as soon as you find it?

00:52:50.420 --> 00:52:52.560
Basically, it's a two-step process.

00:52:52.820 --> 00:52:56.800
The first one,
you have to set up this video output

00:52:56.960 --> 00:53:01.600
component and tell it how you're
going to decide to output your movies.

00:53:01.600 --> 00:53:05.050
So you're doing that using the
video output component itself.

00:53:05.060 --> 00:53:08.810
The second step is to tell the
QuickTime movie toolbox that the

00:53:09.360 --> 00:53:14.200
movie you had somewhere is going to be
pointed to this video output component.

00:53:16.120 --> 00:53:21.880
So there is four APIs in order to
set up the video output component.

00:53:22.100 --> 00:53:26.210
You have to tell this video
output component what display

00:53:26.570 --> 00:53:28.410
mode they have to use.

00:53:28.480 --> 00:53:33.240
You have to start it using the
QtVideoOutputBegin API just to

00:53:33.350 --> 00:53:37.000
tell the hardware you are about
to play a movie on this device.

00:53:37.330 --> 00:53:41.790
You have to get this GRO from
this component as well.

00:53:42.020 --> 00:53:45.990
And we're going to see
how we use it later on.

00:53:46.220 --> 00:53:55.870
The last one is to tell this device if
you want to have an echo port or not.

00:53:55.870 --> 00:53:58.700
In this example,
I'm passing Neil to this Qt

00:53:58.700 --> 00:54:03.120
Video Output Set Echo Port API to
tell this device I don't want to

00:54:03.120 --> 00:54:06.510
see anything on the desktop anymore.

00:54:07.280 --> 00:54:11.170
So the second step is about the
QuickTime movie tool block itself.

00:54:11.270 --> 00:54:14.620
So you have to tell the tool block
that this movie is about to point

00:54:14.800 --> 00:54:16.990
to this video output component.

00:54:17.110 --> 00:54:22.650
And the next one is to basically set
the movie G-roll to whatever this

00:54:22.740 --> 00:54:26.390
output component device returns to you.

00:54:26.710 --> 00:54:33.500
So it's pretty simple, I mean,
just not that much to be concerned about.

00:54:33.800 --> 00:54:35.560
The Echo Port.

00:54:35.560 --> 00:54:37.870
The Echo Port is something, as I say,
which is optional.

00:54:38.240 --> 00:54:44.520
So not all devices are able to
output to their hardware at the

00:54:44.600 --> 00:54:49.700
same time that they can still play
something on your computer desktop.

00:54:50.240 --> 00:54:55.580
Our own built-in FireWire component,
for instance, do support a kind of

00:54:55.670 --> 00:54:57.000
preview on the desktop.

00:54:57.000 --> 00:55:00.510
It's not playing all the frame,
it's not the best quality,

00:55:00.650 --> 00:55:04.940
but at least the user has some
feedback of what's happening on

00:55:04.960 --> 00:55:09.890
the computer screen and is able to
see on FireWire device connected

00:55:09.890 --> 00:55:12.600
the full frame rate of the video.

00:55:13.320 --> 00:55:18.130
In order to figure out if this
VR component is implemented or not,

00:55:18.130 --> 00:55:21.640
this echo port,
you have to use this Get Component

00:55:21.730 --> 00:55:26.440
Implemented with this selector,
kqt-video-output-set-echoport-select.

00:55:26.440 --> 00:55:28.440
It's a pretty short one, isn't it?

00:55:28.440 --> 00:55:36.270
Then you have, if as soon as a component
does support the echo port,

00:55:36.630 --> 00:55:40.930
You can use this API Qt Video Output
Set Echo Port to whatever your

00:55:40.960 --> 00:55:43.970
Windows want on your computer desktop.

00:55:45.600 --> 00:55:50.820
And the next thing they have to do is to
use the regular QuickTime API to set the

00:55:50.820 --> 00:55:54.970
movie G-Wall to basically your window.

00:55:57.440 --> 00:56:03.360
So when you want to stop to output
this movie to this video device,

00:56:03.360 --> 00:56:06.500
basically you point back
to your Windows URL,

00:56:06.570 --> 00:56:11.680
you use this API chooseMovieClock
basically to reset the clock that

00:56:12.000 --> 00:56:13.440
QuickTime is using for the movie.

00:56:13.440 --> 00:56:17.260
We'll see later on why I'm
putting that in this slide.

00:56:17.260 --> 00:56:19.420
I didn't show you any
example of the clock,

00:56:19.510 --> 00:56:24.060
but in case the component had a clock,
you had to reset it.

00:56:24.180 --> 00:56:28.240
So it's much, much safer to call this
API all the time you do that.

00:56:28.480 --> 00:56:32.940
And then you set the movie video to nil.

00:56:33.080 --> 00:56:36.800
And the last thing you have to do now
that the movie is no longer pointing

00:56:36.800 --> 00:56:44.320
to this device is to stop the hardware
by calling the Qt Video output N.

00:56:46.320 --> 00:56:47.030
So the sound.

00:56:47.030 --> 00:56:48.500
As I said, this is optional.

00:56:48.500 --> 00:56:53.430
Not all devices are
attached to a sound output.

00:56:54.200 --> 00:57:06.800
[Transcript missing]

00:57:07.790 --> 00:57:12.750
If the component does implement it,
then you get this sound output

00:57:12.750 --> 00:57:17.700
component instance using Qt
Video Output Get Index Sound Output.

00:57:17.730 --> 00:57:22.710
And the last thing you have to do in
order to point the movie to this specific

00:57:22.710 --> 00:57:28.250
sound device is to basically loop on
all the sound media track that your movie

00:57:28.270 --> 00:57:33.500
has and use the media set sound output
component with this sound component

00:57:33.500 --> 00:57:36.490
that the video output reported to you.

00:57:38.450 --> 00:57:39.370
The clock.

00:57:39.430 --> 00:57:46.000
Most of these devices need
some synchronization mechanism

00:57:46.000 --> 00:57:48.400
between audio and video.

00:57:48.400 --> 00:57:53.890
If they want that to happen,
they need to provide their own clock,

00:57:53.940 --> 00:57:56.500
which is basically driving
their own hardware,

00:57:56.550 --> 00:58:01.400
rather than relying on the
clock we have on the CPU side.

00:58:01.400 --> 00:58:04.370
So,
same thing that the two other optional

00:58:04.390 --> 00:58:07.560
functions of this video output component.

00:58:07.730 --> 00:58:12.220
You need to figure out if they
do implement that by using the

00:58:12.220 --> 00:58:15.400
kqt-video-output-get-clock-select.

00:58:15.400 --> 00:58:19.380
And if they do,
then same thing for the sound one.

00:58:19.400 --> 00:58:23.070
You ask them what their clock
component is all about using

00:58:23.230 --> 00:58:25.400
kqt-video-output-get-clock.

00:58:25.400 --> 00:58:29.120
And to set it, you're using this
setMovieMasterClock API with the

00:58:29.120 --> 00:58:31.390
clock component they did recently.

00:58:31.400 --> 00:58:32.920
too.

00:58:34.820 --> 00:58:39.940
So now let's switch to the demo and show
you what all this stuff is all about.

00:58:39.940 --> 00:58:41.030
Can we switch to the demo one?

00:58:41.290 --> 00:58:42.130
Yeah.

00:58:42.740 --> 00:58:47.040
Okay, so we don't have video going
straight into the projector,

00:58:47.040 --> 00:58:52.160
so I'm showing the video from the camera
by digitizing it with the FireWire camera

00:58:52.160 --> 00:58:54.350
we were using earlier and displaying
it in another window on the screen.

00:58:54.360 --> 00:58:57.060
So that's what that video
input you can see there is now.

00:58:57.080 --> 00:59:00.870
It's a picture of the
display on the camera.

00:59:01.600 --> 00:59:04.500
I'm going to open the
Simple Video Out example application,

00:59:04.500 --> 00:59:07.130
and it's searched the system
for video output components.

00:59:07.160 --> 00:59:09.510
It's found that we've only got the
FireWire video output component,

00:59:09.510 --> 00:59:12.260
and there's a choice of modes
that this component can do.

00:59:12.260 --> 00:59:18.220
You'll notice that one of the features
we've added in QuickTime 6 is DVC ProPal,

00:59:18.220 --> 00:59:21.620
which is very handy if you come from
Europe like myself and Jean-Michel.

00:59:21.620 --> 00:59:25.580
But as we're in America,
we'll stick with NTSC.

00:59:25.580 --> 00:59:27.620
And it's telling us the
dimensions of the output port,

00:59:27.680 --> 00:59:32.650
720x480, the refresh rate,
which is rounded off to 29 from 3997,

00:59:32.700 --> 00:59:35.080
and the pixel type it's expecting,
which is DV.

00:59:35.080 --> 00:59:38.500
So we should try and play
back a DV movie file to it.

00:59:38.500 --> 00:59:41.900
Fortunately,
I have one of those I made earlier.

00:59:45.510 --> 00:59:49.440
So you can see, as this has come up,
it has switched the display on

00:59:49.440 --> 00:59:51.260
the camera out to show the frame.

00:59:51.260 --> 00:59:54.680
And as I scrub about in it,
it will update with a slight

00:59:54.680 --> 00:59:58.100
lag over the movie I have here.

00:59:59.000 --> 01:00:12.700
[Transcript missing]

01:00:12.940 --> 01:00:15.690
and I can turn sound on and off.

01:00:16.010 --> 01:00:20.000
So if you've got demo for sound up,
I'll play it with sound on.

01:00:43.340 --> 01:00:46.310
We turn the sound off and I'll
turn the video back on and you

01:00:46.350 --> 01:00:50.210
can see that it's playing through.

01:00:50.400 --> 01:00:53.550
You notice we can get a choice
of using the video out clock or

01:00:53.550 --> 01:00:55.610
the default clock for the movie.

01:00:55.880 --> 01:00:58.730
And there's additional options in
this thing that use the API that

01:00:58.730 --> 01:01:00.180
Jean-Michel was just showing us.

01:01:00.410 --> 01:01:04.850
And this is a QuickTime movie
like any other,

01:01:04.850 --> 01:01:07.420
so we can scrub through it.

01:01:08.900 --> 01:01:14.210
are all here today to talk about the
new feature of the QuickTime app.

01:01:16.300 --> 01:01:22.300
[Transcript missing]

01:01:54.300 --> 01:02:05.600
[Transcript missing]

01:02:09.300 --> 01:02:10.540
Thank you Kevin.

01:02:10.540 --> 01:02:11.450
Back to Tim.

01:02:11.450 --> 01:02:15.300
Thank you Jean-Michel, thank you Kevin.

01:02:15.300 --> 01:02:19.260
Standard feature to have Kevin's
children in our demos during our session.

01:02:21.550 --> 01:02:22.210
slides please?

01:02:22.390 --> 01:02:22.950
There they are.

01:02:23.140 --> 01:02:25.710
So now you get to close off and talk
a little bit about the road map for

01:02:25.710 --> 01:02:28.990
some of the sessions that you may
have seen or you may have wanted to

01:02:29.120 --> 01:02:30.810
see or you may see in the future.

01:02:30.820 --> 01:02:34.580
So, just to give you an idea,
the overview session this morning was an

01:02:34.580 --> 01:02:41.960
overview of the QuickTime technologies
in QuickTime 6 and Jaguar and where

01:02:42.070 --> 01:02:43.690
we were and where we're going.

01:02:43.690 --> 01:02:46.220
And then 601 was also this morning which
was talking about techniques you can use

01:02:46.220 --> 01:02:50.220
to build a savvy QuickTime application
during 602 which is this session.

01:02:50.400 --> 01:02:51.220
603 is just coming up.

01:02:51.250 --> 01:02:59.210
It's integrating
QuickTime media together,

01:02:59.400 --> 01:03:08.490
interactive technologies which can
tie different kinds of media together

01:03:08.490 --> 01:03:14.770
and then more interactive sessions
following that this afternoon.

01:03:14.770 --> 01:03:14.770
And then

01:03:15.190 --> 01:03:17.820
and this is interesting,
these are all different than mine.

01:03:18.070 --> 01:03:22.100
But in any case,
the feedback forum is Friday at 10:30.

01:03:22.100 --> 01:03:28.100
Also Friday afternoon there's a
session on QuickTime for the web

01:03:28.110 --> 01:03:32.790
and a session Friday later in the
afternoon on QuickTime for MPEG-4.

01:03:33.150 --> 01:03:39.470
And so the important thing
I wanted to point out as well was

01:03:39.470 --> 01:03:41.820
every afternoon from 1 to 4 p.m.

01:03:41.890 --> 01:03:45.100
the QuickTime engineering
team is having hands-on.

01:03:45.990 --> 01:03:52.680
and over here the contact information
is DTS at Apple.com and Jeff Low is

01:03:52.700 --> 01:03:57.220
the technology evangelist and
that's Jeff Low at Apple.com

01:03:57.220 --> 01:04:00.540
and I think I should have some
URLs coming up which are these.

01:04:00.640 --> 01:04:05.270
So the standard QuickTime documentation
is at developer.apple.com/quicktime

01:04:05.370 --> 01:04:08.960
and from there you can navigate
down to the sample code and you

01:04:09.080 --> 01:04:11.690
can see the URLs for the sample code.

01:04:11.750 --> 01:04:18.050
All these URLs are actually on
the developer.apple.com/wwc/urls

01:04:18.180 --> 01:04:22.900
URL I believe and so if you are crafty
with your web browser you can find all

01:04:22.990 --> 01:04:26.530
of these and so you can see the different
ones we showed and the simple video

01:04:26.530 --> 01:04:31.910
out which has been updated and the SGData
proc sample which used to be Minimun.

01:04:32.660 --> 01:04:37.980
and there's the slide for the
hands-on which is in 1-4 in room

01:04:38.120 --> 01:04:40.990
G out all the way down and you'll find
lots of QuickTime engineers there.

01:04:41.790 --> 01:04:42.300
Thanks.