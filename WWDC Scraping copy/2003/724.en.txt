---
Title:  What's New with QuickTime VR
Year:   2003
Web:    https://nonstrict.eu/wwdcindex/wwdc2003/724/

[!] This transcript was generated using Whisper, it has known transcription errors.
---

So without further ado, I'm going to introduce Jim Anders from Kydan. Jim? Thank you. Good morning, everyone. When I was asked to speak at the conference here, my first inclination was to do a, you know, what's new from a product point of view in QuickTime VR. But realizing I was going to have an audience full of developers, I wanted to change gears a little bit and talk about what's new and the way of opportunities for development. And to give you a sense of what the market is like. Because it's a vital market, and it's one that's continuing to grow. So to start out with what's new with VR, well, this is one thing that was new.

I was really glad to see that Apple, on the morning of the introduction of the G5, chose to once again use QuickTime VR to show the inner workings of the new G5. And for those of you who might not be familiar with object movies, this is a QuickTime VR object movie.

As you may or may not know, QuickTime VR supports both object-oriented images as well as panoramic images. And usually you can just simply do a simple rotation of an object. In this one, they're doing some more interesting animation effects. You can see the cover coming off and zooming in and out to see all the neat details of the unit. So that's really cool.

What I'm going to be talking about this morning is essentially give you a quick overview of QuickTime VR. Kaidan, our company, has been involved right from the very beginning of QuickTime VR. Actually, we got started making accessory products for the Apple QuickTake camera. And then shortly after the Apple QuickTake camera was introduced, Apple announced QuickTime VR. So we've been involved right from the very beginning.

And I'm going to give you a sense of a little bit of the history, a sense of where are we currently in the technology, what the current and potential market is. I'll try to give you some sense as best I can. And what opportunities are that I think are for third-party development. And at the very end, after Terry's talk, we'll have a Q&A session. Can I let that snow?

So where have we been? When QuickTime VR was introduced, gee, seven, eight years ago, Apple had a product called the QuickTime VR Authoring Tools Suite. For those of you who remember MPW, it was MPW-based. You actually typed, you know, stitched this movie in a command line interface. There was a dongle.

It was fairly expensive. And for those who went and took the training class at Apple, the predominant camera, the preferred camera, was a 35mm camera with film. And we actually shot film. They had photo CDs returned. And that's how you did it. And image quality was, as you might expect, fairly nice with a photo CD. But as I was mentioning, at that same time, Apple introduced the QuickTake camera.

And we had been making, at Kadan, close-up lenses and wide-angle lenses. So we thought it would be really cool to be able to develop a tripod head for that Apple camera. And at the time, a lot of people were saying, 35mm is the way to go. But you managed to get some really kind of nifty shots. And it was clear to us back then that digital was going to be the way these images were going to be shot. Bless you.

So that kind of kicked it off for us, and in fact for the industry. Things just really started to take off shortly thereafter. Apple did kind of the next generation of tools, the QuickTime VR authoring studio, which still is available today. And actually there's probably no better stitcher for doing cylindrical panoramas than that product today.

There was another startup company back then called Panimation. They made a product called Nodester and Widgetizer. And today you can see the successors of those products, the descendants of those products, in the VR Toolbox Company product line. There was also a company called Live Picture that made a product called PhotoVista, and that still is available today under a new company name called IC Media. was also another startup company called OmniView, and they're known today as iPix. New digital cameras really started to take off. Apple revved their camera line. Kodak came out with digital cameras. And that was really the beginning of the emergence of digital cameras. Things really went crazy.

At that time, tripod heads, which are used to actually create back then and still today the panoramic images, were close to $1,000. And when we got involved, we decided to kind of democratize the market. And we introduced a tripod head called the Kiwi for $100. And things went nuts. Schools, kids started to use this technology. It just really became a vibrant market.

In the past few years, we've just seen an explosion of applications. As I mentioned, Panimation, those products are now being sold and continually be updated through VR Toolbox. There's a product called RealViz Stitcher that does multi-row panoramas where you can create very high-res panoramas. Authoring Studio is still around.

But really, the story of VR has been what the third parties have done with it. And for those of you who are developers out there, I mean, that's your challenge. I mean, there's a lot of things going on, a lot of companies out there creating really great products and doing really interesting things with VR, both in the object and the panoramic realms.

So today, we have a stable, mature environment to which to build applications on that Apple has provided. You know, Apple's kind of in an interesting situation. They developed the enabling technology, and then many times they also developed the consumer applications. And QuickTime VR Authoring Studio hasn't been updated in a long time, and a lot of our customers and people who are actually buying products, they bemoan the fact that it hasn't been updated. Well, the good news for developers is that this has been a fertile ground for third-party development, and that's the good news. Apple's kind of in a no-win situation, but it's really a good news for the development community.

QuickTime VR as a format is the most popular immersive imaging format on the web. And we've, at Kaidan, we've tried to quantify that by doing fairly exhaustive Google searches and actually canvassing and looking at what formats out there on the web. And still today it's true that there are no other formats that are more popular out there other than QuickTime VR. That's because they're both objects and panoramas, and a lot of the other competing file formats are perhaps strictly limited to panoramas and things like that.

QuickTime VR also gives you a very rich playback environment because you have the ability to do all the other kind of neat QuickTime things and incorporate that into your movies, things like sound. And the recent announcements in QuickTime regarding sound is going to be very interesting for developers as far as surrounding sound and 3D sound and things like that.

I also think QuickTime VR gives you the best playback experience. There are some Java viewers out there that display panoramas and objects, but generally they provide a pretty poor experience. The cursor doesn't continue to activate as you move off the window as it does in the QuickTime environment, and it's really... The Java players are kind of annoying. And of course, with OS X and Quartz Extreme... Since we're dealing with photographic images and graphic intensive content, there's no better platform to develop than on the Mac.

So things are good right now. And things are good-- I can say they're good, but yeah, Jim, why don't you tell me how and show me how good they are? Well, there are a number of really good success stories out there that one can look at to see how good things are. We have-- you can't find an automotive website that doesn't use QuickTime VR to show off the interior of a new car or the exterior of a new car.

Motion Pictures. Obviously, Apple has had a great deal of success with movie trailers. Well, we're now starting to see that in addition to movie trailers, the movie studios are doing VR content of the sets. And The Matrix is an example, Harry Potter. And in addition, educational and industrial applications is just a tremendous use. And I'll show you briefly here on the demo machine some other examples of VR content. If we can switch over to the demo machine.

Sorry we had to do this. Keynote doesn't play QuickTime VR, and there's another development opportunity, actually. Okay, this is an interior of a new Audi A8, I believe. And this is a VR movie that was shot by Tim Petros. His company is Gyro VR, and it's a QuickTime VR cubic, so we can look all the way up, out through the sunroof, and down. Here we go.

at the Dash. We can zoom in. As I said, just about every automotive company has this kind of content on their site. And they've done a lot of studies and tests. QuickTime does it for them. They're very happy with QuickTime. They've also found out that if you want to be able to zoom in to see enough detail on the dash, that was really important in all their testing that they did, so that you have enough detail so it's like sitting in the driver's seat.

That was a panorama. In addition to panoramas, of course, QuickTime VR supports objects. So you can do neat things like, instead of just a flat rotation, well, let's show the car off and zoom in and zoom out as we move around. And the fact that it's interactive, the fact that you're in control, the end user's in control, as opposed to just a movie, makes all the difference in the world.

One of the other areas of success has been in, as I said, motion picture and media content. Tim Petros, who did the Audi automotive interiors and stuff, has also been doing a lot of work with Warner Brothers. They create models of all their intellectual property, like Bugs Bunny. And in order to make sure that the licensing is upheld and all the people who have licensed Bugs Bunny to make Bugs Bunny keychains and Bugs Bunny dolls, in order to make sure that it's been reproduced faithfully, they make models.

Well, it's a lot easier to distribute a 3D virtual model than it is a real model to all the licensees. So here's an example of a multi-row object movie that I can turn around and look at all different sides of the object. That's really neat. Another one, Tweety.

mentioned industrial and scientific. This is a shot that was done with a pano-scan camera. A pano-scan camera is a very high-resolution digital scanning panoramic camera. And what you're looking at here is the interior of the space shuttle. This is a pano-scan camera. And here's an example where Cubic VR, one of the more recent additions to the file format by Apple, really shines. I mean, if you're shooting a house or you're shooting on an exterior scene somewhere, generally it's not that important to be able to look straight up. But when you have something happening on every side, as in this interior shot, you can see that that's really important.

Actually, this curved beam here that you see on the interior, That is actually a shoot that's used for when the astronauts have to bail out of the shuttle. There's a strap that they hook up on that curved rod and then they jump out the door, which is that round thing right here.

and actually see the text. And this is a relatively low-- this is like a medium res file. I think this is only two megs. I have a higher res version that you can actually read every piece of writing really crisp. Just amazing. Obviously, NASA loves this kind of technology.

This isn't really industrial or educational, but I just liked the panorama. This is Las Vegas. And that's another example of a cubic image that was shot with Stitcher and a Kaidan multi-row head. This is just a really stunning image, although I suspect the moon was put in afterwards.

Okay, we'll go back to the slides now. So market-wise, I'm going to try to give you an idea of what is really the potential for the market. In the eight years that Kaidan has been around, we've sold tens of thousands of tripod heads. And for a good part of that time, I would say for the first five years, those have been sold to the early adopters. These are the guys that were, you know, read about QuickTime VR, found out it was really cool. People like Dennis, who's going to be giving the talk later on after Terry's in my talk.

But people that have really kind of blazed the trail. And at Kydan, we kind of look at this kind of pyramid effect, where for the first part of our existence, we've been kind of selling at that kind of peak of the pyramid, the people who have been really blazing the trails. But as time has been going on, we've been coming further down the pyramid into a larger, wider user base.

You know, kids, grade school kids, creating object movies of bugs. You know, they weren't the first people who bought our product, certainly. The other thing that's really helped us is the digital camera market has just gone nuts. The market forecast. And I've taken several. I mean, kind of combine them a little bit here. All the four, even the most.

[Transcript missing]

The other dynamic in the industry that's happening is that photographers out there, the professional and commercial photographers out there, they've been struggling. And they've been looking for new and different ways of getting their content over. And wedding photographers, we have wedding photographers who are looking at new ways of capturing weddings with immersive imaging. What?

[Transcript missing]

The other thing that has changed is that the applications have changed significantly from the days of MPW and typing in commands. You know, there are dozens of easy-to-use, click-and-drag applications to create this kind of content. And that's really made a big difference.

As I said, Apple created this enabling technology, and now it's up to us, third-party developers, to really make it happen. And I've tried to put my thoughts together as far as what I think are some of the low-hanging fruit, as it were, for what the development opportunities would be.

There's a lot of them, and I tried just to pick a few of the things that are either needed in the marketplace or conditions that exist in the marketplace that really have made this opportunity come to light. And one of the biggest changes has been the availability of bandwidth.

When we started with panoramic images and object images, there was a big push to get objects like less than 200K because people had dial-up modems. You know, with a 9600 baud connection, it's tough to bring in a 2 or 3 megabyte object movie. Well, that's obviously not the case anymore.

So, for example, the automotive companies, they have no problem putting a 2 meg object movie or a very high-res detailed panoramic image up on the site. And people want that detail. They want to be able to zoom in and read the gauges on the dash. They want to be able to see the texture of the cloth or the details or the inside of the new G5.

Object movies. Originally, object movies were just flat spinning objects that would move on one row, flat spinning objects. Multi-row object movies like the Bugs Bunny and the Tweety that I showed where you can move it in all directions, a long time ago that wasn't done because the file sizes were every new row that you added to the image would essentially double the size of the image or triple the size of the image for each additional row. Multi-row object movies are coming back into vogue.

People initially tried to use them and they were too big and then they throttled back to single row. We're seeing more and more multi-row object rigs being sold, more and more of that kind of content being distributed on the web. It's undergoing a real revival. So there's a real opportunity for content providers to be able to provide this kind of multi-role object movies.

Stereo. I know Dennis is going to be showing some stereo examples later on. But stereo is something that's really never taken off and become commonplace. And it's a shame because you can get some amazing imagery with some stereo effects, either with panoramas, as Dennis will be showing, or with objects.

And in the case of object movies, you get stereo for free. A QuickTime VR object movie is essentially an array, a matrix of images taking around and up and down. And in order to get the stereo effect, all you have to do is display any given image in that matrix and the adjacent image, which is taken at a slightly different perspective, rotated. And if you display both of those images, either with shuttered eyeglasses or with the anaglyph, red, blue type glasses, you get this stereo effect and it's quite amazing.

So it's free. It's already there. All that needs to be done is someone has to do and package and put together some neat tools to easily create them and display them. Same with panoramas. We had made a, Kaidan had made a stereo imaging tripod head where you could take two shots at once. And people didn't really do all that well in the marketplace. But I think with the appropriate playback stuff, there'd be some really good. a nice revival for that.

Real estate virtual tours are one example of VR, but to be able to see this house that you're looking to buy in stereo could be really quite compelling. Cubix, QuickTime VR Cubix. Several years ago, Apple added that capability so that you could look up and down and all the way around.

And there's a lot of opportunities to make that... Image process of gathering those images are easy and convenient. One of the products at Cadian that we've had a great deal of success with is our one-shot product, where in one shot you can capture a full 360-degree panorama. It does not yet handle the full view of cubics, but we're working on it.

And there's some ideas that we have, and the lesson learned there is that if you can make the capture part of it easy, it makes the whole process easier along the way. And there's a whole range of new and innovative optical techniques and things like that that would just stimulate that whole process. So there's some good opportunities there.

True 3D, QuickTime VR, whether it's objects or panoramas, is essentially flat images projected in a new way. But you can take those flat images and actually do some interesting things with them. For example, if we were to shoot several panoramas in this room, you can take the similar points analyzed at different locations and construct 3D models.

True 3D models that you could then navigate and move around. Same with objects. You could capture an object movie like Bugs or Tweety. And instead of just being essentially a digital flipbook of images simulating 3D, you could actually take that data, the photographic data, and create a 3D model. And then use those photographs to texture map it. There's another example of things that can be done. And we certainly have the computing power to pull that off today.

Scripting, scripting and authoring. Apple Script Studio, in the latest Mac Tech, Tim Monroe did a great little article on how easy and cool Apple Script Studio would be to use. There's really no convenient, easy ways and tools out there to do that, but it certainly could be done. There are Live Stage Pro and another application called Revolution. They have support for QuickTime VR, and you can generate some compelling content with those tools. And that's more on the content creation side than it is for the software development side.

One of the areas that hasn't been explored all that much is high dynamic range imaging. If you're not familiar with this, this is a technique where you take multiple exposures of a scene at different photographic exposures and then intelligently combine them to create a very dramatic image. If I were to take a panorama here, I have a huge dynamic range.

I've got the bright lights and I've got the dark room. But if I took a series of photographs at all the possible different exposure ranges, I would see you guys clearly in the audience, the bright lights and up here would be clear. And then you combine that and it just creates amazing images.

There's some examples of that out there. HDR Shop and Photomatix are two examples of some software that do that on conventional images. We could certainly do it on objects and panoramas as well. And there could be some possibilities with a pixelate codec to be able to pull that off as well. CodeX is another really ripe example for innovation. It's really not clear today what CodeX are optimized for VR, and there's just kind of a general confusion out there about CodeX and what CodeX really work well and properly in the VR environment. So there's some ripe areas there.

For the most part, objects are created by putting an object on a turntable and spinning it, like a car or something like that, or something bugs and Tweety, for example. But there are some objects that you just can't put on a rotating turntable, like a statue in a park, for example. It's there, and you have to walk around the object in order to capture it.

There are today no really easy-to-use tools that allow you to walk around a house or a battleship or a statue in the park that allow you to create an object movie easily. And if you're looking to get in the software business and create a killer app, there's a great example.

Just the ability to animate objects as well. As you saw with the G5 example, how the door opened and the parts flew apart. There's no good tools to be able to do that well either. It's all kind of painstakingly done by hand and pulled out and Photoshopped and things like that. Some other examples, if we can move back over to the demo machine.

Objects. I mentioned briefly eBay. I'm sure everyone has seen eBay or bought off eBay, but today you take multiple pictures of your object to make sure that the person buying it can see that there's nothing broken on it or going on with it. But why not use object movies?

We were developing a new piece of object software to make object capture really easy. It wasn't ready to be shown here. But that's one area where we're going to try to go after, is making it accessible for the common eBay user to create this kind of content and to put this up on their eBay page as opposed to five or six images that show the object.

This is another example. Really makes a difference when you have that ability to animate it and do things. Now in this case it's an object movie, but we're not spinning the object around. We're just, kind of like the G5 example, we're just articulating the object to show how it works. That's another common way of showing this kind of technology.

Several weeks ago, I came across a technical paper where they were using

[Transcript missing]

These kind of complex 3D mathematically described surfaces, there's a whole kind of open possibilities there for using QuickTime VR to describe these kind of complex surfaces. Here again, with OpenGL and the kind of connection between 3D and QuickTime VR, there's another great opportunity. Thank you.

So that concludes my part of the talk. Next up will be Terry Breheny, and he'll kind of get into more of the specifics about some of the new products and things that are available out there today in the VR space. And I guess in final closing, assuming most of you are developers, if you're interested and wanted to learn more about some of the possibilities of developing VR applications, just see me after the session. I'd be glad to chat with you and tell you more. Thank you.

Okay, thanks. This is a pretty decent turnout. I appreciate everybody coming in this afternoon, or this morning rather. I should know it's morning because I'm not a morning person. Staying with a friend in Knob Hill and about four in the morning, all of a sudden they're doing some kind of construction on the cable lines running up the street. So forgive me if I'm not quite awake fully.

So what I'm going to do today is actually show you, as Jim mentioned, both some hardware and some software, kind of what's new. And certainly there's a fair amount of development going on, which is very encouraging. And some of the stuff here today is brand new, and actually some of it's so new that it's not even here yet.

How many of you, first of all, went to the Michael Schaaf's interactive QuickTime presentation yesterday? I don't know if you did. Okay, a few of you? Okay, good. What I'm going to do then is just kind of show a brief outline of the stuff I'm going to show and then just jump right into it because I do have quite a few things to kind of get through here.

Okay, software. I'll be hopefully looking at LiveStage Pro 4.1 this morning, VRWorks 2.5, which is in beta, Zoomifier VR version 2, which was recently announced and released, and PhotoWarp 201. And just quickly, I put some prices up for you as well. LiveStage, this release, 4.0, was kind of a revamping of the whole interface of the software.

And then 4.1, they called it the VR release. The folks at TotallyHip were really encouraging, trying to get input from the VR community. They recognized the potential there. And so you'll be surprised, those of you who haven't seen it yet. There's just tons of QuickTime VR functionality now built into LiveStage and done so in a way that makes it quite easy for anyone to use, even if you don't know how to do any kind of queue scripting. So we'll look at that.

Like I said, VRWorks 2.5 is in beta. They're showing it downstairs as well in the exhibit booth, so I'd recommend you go down there. But I'll also get into it just briefly up here. And that's a QuickTime VR, that's a complete authoring package. As Jim mentioned, QuickTime VR authoring studio from Apple, which was originally released back in like 1997 or so, was kind of at the time the only complete authoring package. VR Toolbox came along, and they released VRWorks, which has similar capability. And now I'm pleased to say they're revving that for OS X and adding some features and functions as well.

And then Zoomifier, for those who haven't seen, is a nice way to do very high resolution image streaming. And initially they started with just images, but they've incorporated VR capability. And then PhotoWarp is actually software which is bundled with an optic that Kaidan sells. It's a one-shot optic. And I'll be showing actually a similar product from another company that was just released today.

So hardware, actually, that's the optic I was referring to. The company's 0 to 360, and they have a panoramic optic out. It's a one-shot solution. Manfrotto Bogan has a new... This is a cubic/spherical head that has just come out. In fact, it was just shipped from Italy to me yesterday. And then this round shot VR drive, unfortunately, is not here yet. And something tells me it's probably going to arrive this afternoon.

So what I would like to do probably is, maybe at the QuickTime feedback session, I'll kind of be in the corner afterwards, so that if it does actually arrive from Switzerland and anybody's interested in seeing it, I'll have it there. You can just come over and I'll show it to you. But it's just an automatic rotating platform that Sights and RoundShot have done. And then hopefully if there's time, Denis Bila is going to show a customized pano head that he had built for him, specifically for a project he's doing at the Smithsonian. So let's jump over here.

And this will all, I'll leave this all up here too afterwards so you guys can come up and actually get your hands on it and see what it's all about. But this is the new...

[Transcript missing]

And some of the feedback that I and Scott Height in his office have given them is they need to put a little retainer clip on this so you don't lose this important piece. But then this is actually just going to fold up like that. And then this gets returned back into this position there. And then kind of the second part of the unit is this rotator base here.

And what this is, it's an indexed base that you can use with the head, basically allowing you then to have these click stops that are adjustable. You pull out this tab, and you have essentially from 5 degree increments to 90 degrees. So anywhere from, say, 4 shots, 6 shots, 8, 10, 12, 15, 18, 24, 36, or 72 shots.

And that's a nice solid piece. You know, it definitely clicks and stops at each increment. So you're welcome to come up and look at that afterwards. Let me just show you that quickly. And this is called the 303 SPH. How many of you have attempted to shoot a multi-row panorama before? A few of you, okay. So as you know, it's not quite easy just yet, but with products like this and also Kaidan offers a multi-row head as well, it's starting to get a lot better.

[Transcript missing]

Well, if I can't get this to go on here, I think I have the wrong plate on here. The nice thing about this head, actually I don't need the camera to show it to you, but so basically what it allows you to do is you need to set the nodal point this way. So basically it's going to move the camera in three different axes. So you put the camera on here, and you can align the nodal point in this direction. And then likewise, this is for shooting the different tilt ranges.

And then in this case-- If you shoot like this, you're going to be able to move in this direction too. Okay, so I'll get that camera up there, and maybe we can even shoot a panorama at the end with Dennis. That gives you kind of a sense of how that works.

So let's jump in, then jump ahead to software, and I'll get back to the other hardware as well. We're going to start with Zoomifier. Okay, Zoomifier, it's basically you don't need any server software. It's a, you know, it all happens on the client side. And the actual application is either a droplet that you use, which I'm going to use today, or it also is available as a Photoshop plug-in. But in this case, I have a bunch of images. It's just actually kind of a subset of images I shot of a sculpture. Uncompressed, these are all like 9-meg images. I think they're from the Coolpix 995 or something.

So, you know, you wouldn't want to necessarily do a big object movie with 9-meg images, you know, of 36 images or whatever, because it would just be huge. So I'm just going to grab all those and then just drop it on the droplet. And then you'll see here, we have these tabs, image, object animation, slideshow, panorama. It knew that I had dragged more than one image, so it assumed that I want to do an object, which is the case. So then you're just going to choose where the destination is.

Okay, then you can choose the display width and height, the background color, the zoom, compression. You can add copyright information, set the initial view, and then you can tell it which kind of files you want it to generate. Basically, what they recommend is kind of doing like an auto-detect and checking all these, and that's definitely going to be a fail-safe thing to do because it'll generate every file that you need, and then you just put them up on the server, and then the software is smart enough to know whether or not the client has either the Zoomify plug-in, the QuickTime plug-in, or it's going to use ActiveX or Java. There's all kinds of different ways it can do it. It's pretty nice, actually. And it is a QuickTime component. Let me just emphasize that. So you can just generate just a QuickTime movie, and then it's part of the third-party download component system.

So we're going to do that. You can watch it do its thing. And basically-- What it's doing is it's taking each of those images and it's tiling them up. And there's some technical name for it. Smart, bare metal, preferred image serving or something like that. But it's going to take those images and just pretty much dice them into tiles.

And then upon playback, it's only going to serve the specific area that you need to see at any time. So the nice thing about it then is you're not having to download a big movie because maybe someone's only going to look at one view. Or when they go to zoom in, you don't need to zoom in all the other views that aren't being seen at that time. So it's done. Okay, so look at that.

I'm going to open that in QuickTime Player. OK, so there's my movie. And-- So you can see then, it's showing me kind of the low res version now, and then as I turn it, it's going to look like it's getting blurry because it's pulling in those new tiles now.

So it's only going to refresh once you get to the new-- the image data that's not there. But then the great thing, of course, is as you zoom in, it's just going to serve that image data that you need. And you can get some really nice detail this way.

And so when we go back and look at that file, This is a reference movie, so it's only 8K. This PFF file right here, that's the image data, basically, and that's only 1.6 megs. So it took each of those seven images that were 8 megs apiece uncompressed, and the image data has now been compressed to only 1.6 megs. So this file sits on the server, and this little movie just calls the data as it's needed. So that is Zoomifier. Highly recommended. Okay, so next then we're going to look at the 0-360 optic.

So this is a one-shot optic, as I mentioned, available from zero to 360.com. And there's a few of these on the market now. But as you'll see, it just screws onto a digital camera. This is a 360-degree shot of a VR. The nice thing about this is that you can freeze motion. People walking in the room can capture motion.

Assuming the light allows you to, you can shoot at high enough shutter speeds to catch motion. There are some disadvantages and advantages. The disadvantage is that all of that data of 360 degrees is going to be captured on one frame. The resolution isn't going to be nearly that of shooting multiple images and stitching them together.

This is more of a web-friendly, low-resolution way, and a very fast way, I might add, to get panoramas. If you're looking to do nice, high-quality panoramas that you can print or something, then you'd want to do more of a traditional route of stitching. I'll let you guys come and look at this. this as well afterwards.

So what we'll do then is look at an image that was taken with this. Now, their software that they have, they have apparently an application that's Windows only right now. But they do have a Photoshop action for OS X. It's kind of neat. So we'll take this. This is the image here. Open it in Photoshop.

Okay, so there's the image. I'm gonna go to my action here. It's called the 0 to 60 Unwrapper. I'm just going to hit Play. And it's going to throw up these messages for me. Please crop to just mirror and then press Play again when you're finished. OK, so I'm going to choose the crop tool.

I'll just kind of quickly do this here. About like that. Adjust that just a little bit. Okay. I'm going to say crop. Okay, and then I'm going to hit play again, like it told me to do. That's going to say, you know, this step you can change the image, the canvas size, basically, if you wanted to resize it, or you can just continue.

So we're going to just continue, let it do that to this size. It's going to automatically pull up the polar coordinates filter to do the remapping. I hit OK. Image size, OK. And then now it's going to say, now crop just to the image, and then press Play again. So I'll just crop roughly there.

Again. And you're done. You can adjust levels, sharpness, or whatever. Let me just brighten this up just a bit so you can see it. Okay, so then from there you just save it and then open it in any other application to actually export the VR. They don't export the VR from the Photoshop action. So what we can do is we'll put it here.

Next one for now. Okay, so that's saved there. So actually what we're going to do is we're going to kind of cheat. We're going to look at that now. And the other application that we're going to be talking about today, which is VRWorks. Okay, how many of you have used VRWorks in the past, either version one or version two?

Okay, a few of you. It's a really nice application. It's just kind of a tabbed setup up here, and it allows you to stitch multiple images, allows you to bring in existing panoramas like the one we just did, which is what I'm going to do. It does hotspots, multi-node scenes, and such. So basically what they're doing now is they have revved this for OS X.

This is a beta release, and so they still have some things they'd like to do, some of which, you know, they're going to redo the buttons and the icons to be all, you know, 3D and conform to Aqua. All the modal dialogs are going to be sheet windows.

But one of the things from a non-programmer's point of view is they're going to try to make this pane a little bit smarter, which is the setup. In other words, you'll be able to just drag your images on there, and it's going to be kind of an auto configuration.

Right now, you have to, you know, determine the-- what kind of image it is, how many of them there are, you know, what size they are, that kind of thing. But hopefully when this is actually released, you'll just be able to drag your images in there, and the software will figure all that out for you, so you can kind of skip that step. What I'm going to do then, actually, is just import a single panorama.

Actually, let's just drag and drop it. So the one that we just did from that other app, which we called-- Thank you. I'm just going to drag that there. It's going to ask me if I want to rotate it. I happen to know that I don't need to rotate that. It's already oriented correctly.

and it's going to bring it in for us. So we can kind of look in there. The nice thing is, is they've always, from the beginning actually, although it's very seldom used by a lot of people, but you can actually have access to filters, all the QuickTime filters, special effects.

You know, if you wanted to add, if you wanted to use QuickTime to do blurring, sharpening, that kind of stuff, you could do that all from within here. They have a built-in image editor, so you can click here, bring it up, and do some kind of basic editing.

But also what's going to be new in this version is the option to, you know, say I'd rather use Photoshop, basically, and then when you click that button, it's going to load the image into Photoshop for you. So we'll jump ahead to hotspots. And you basically choose a tool, outline where you want your hotspot to be. Tell it what kind of hotspot it is, you know, a link or URL, whatever you want it to be. Let's call it miscellaneous.

And then another nice thing that they've added in this version is the ability to set all this information and then basically choose a preset so that you can always just go back then, just drop down and choose a kind of a template for all of the other ones. So we're just going to look at this quickly.

Oh, and you can do, within the software now, you can do fast start and web fast track previews. So some of you have seen, you know, you usually get the grid, which you can also add so you can bring in a low resolution preview for the VR. Yeah, preview the coming year.

So there's our VR there. You can come up here, maybe make it a little bit bigger. This is our hotspot. You can see the cursor change. Basically, you can add annotations and stuff. Set the initial view if you want to open up on that flower. You can go over here and set that to be the initial view. And then export. So what I'm going to do is export that here. Call this Garden Movie.

Oh, and then the other nice thing. So this is a project file right now. I'm going to close this project. Oh, rats, I forgot to save it, right? Well, so what they've done now is I can go back in to VRWorks, and they have this nifty little thing called Recompose Project for Movie. So those of you who have been using VR, you'll see kind of the benefit to this.

Now I can take the movie that was just generated, open it, And it's going to recreate the project. So now I can go back in there and I can re-edit it. There's my hot-- you know, it's pulled the source basically back out with the hot spots intact and everything. So now I don't have to worry about saving all those project files anymore. You can just recompose them from the finalized movie. That's a very powerful feature. We don't need that. Close that. Okay, so let's see. Photo warp.

So PhotoWarp then is the software aspect to the camera from IC360 and Kaidan called the i360 VR. And it's a similar unit to this. Like I say, there's about four or five companies doing similar things. Kaidan is here downstairs if you want to go down and take a look at their optic and their software.

But this is some very nice software, you know, that a lot of time and thought has been put in to doing it. So first of all, I could just -- I have an image, actually a fairly old image from one of their optics that I can just drag in there.

I saw. Try that one more time. Oh, it doesn't like aliases. Okay. Yeah, it should be here. There it is. Yeah, okay. I'll have to tell Michael. He doesn't like aliases. So it recognizes then that this is one of its own images, a 361 VR image. You can also import a cylindrical or spherical image. Then you can, under format, you have QuickTime VR. It'll also spit out-- Java in this version, right? And yeah, PT Viewer. You know, there's several other formats that it'll spit out as well. So now here we, again, choose the compression, choose the view. So we have view.

You know, tell it what size. Again, you can also generate the fast start preview here, or you can choose a-- pull in a different image there. Okay, so we'll leave that there. You can set a target size if you thought, well, I'd like to have the key to move around, you know, 300K or whatever. And let's just do this. Click on Warp.

And it's going to unwrap that movie for us. And then it's putting it down there for us so we can see it. So then the other nice thing that I want to show you is we can also then go back. I'm going to change this to a cylindrical image.

I'm not sure if I can just drag this in or not. We'll find out if it'll replace it on the fly or if I have to delete that one first. But the other image I shot, which is this one, So then this is actually the cylindrical image shot with this other lens after it had gone through the Photoshop action. So you can go ahead and import a cylindrical image as well.

and again, go through all those steps. But I highly recommend you go down to the Kaidan booth because there's actually a lot of nice features. There's some batch processing capabilities and such that you should really try to take a look at down there if you are interested. All right, now let's jump into the live stage. How many of you are live stage pro users currently? A few of you, okay.

Okay, well LiveStage Pro is a QuickTime authoring application. Very, very, very powerful. And it's come a long way since it was first done, and they're trying to make it, you know, despite the Pro title, they're trying to also now make it a little bit easier for people that don't want to dive in and have to learn kind of a scripting language and syntax and all that stuff.

So it still is a very powerful program that, you know, if you want to get into that side of things, you certainly can. But as I mentioned with this 4.1 release, they've really gone out of their way to target the VR crowd specifically and to make it much easier because they have found, like other, as have other software developers for VR, that, you know, a lot of the VR producers are photographers, and sure, they can use a Mac and such, but they're not coming from the same background probably as a lot of people at this particular conference are.

So they wanted to kind of make it a little bit easier for people to get into that. So they wanted to kind of make it as easy as possible. So what I'm going to do is I'm just going to take one of those movies. Here's my library. I'm going to drag it over here on the stage. Pops it up and it's going to add a VR track for me down here.

Now, so one of the new features in 4 then was the addition of these things called FastTracks. So in the old days, what I'd have to do is I'd have to add a sprite track, have to add a sprite, and then, you know, on the handlers, tell it, you know, on mouse down, do this, do that, and I'd have to know all that syntax. But now all I can do, or all I need to do really is I can just say, "I want to add some controls."

So it's going to pop up this VR editor. Okay, and it's going to add that track for me automatically right here. The nice thing about it is it comes with default media, which can be changed very easily. I think they give you some other options here, too. Basically, all you need to do is from your library, just click and drag and bring it over. And then it's going to replace it on the fly like that.

So let's go back to the VR editor. So here's the node we're in now. Okay, this is all live here. And you can change speed, et cetera, et cetera. Basically, but that's all there is to having to do that. So I'm going to close that, though, just for a second and just preview this just so you can see how simple this is. Okay.

So there's my movie, as you can see. And I can use it the traditional way, or I can go down here and use these buttons this way. And that is that image that I dragged in, just kind of without looking what it was. Zooming in here. Okay, so I mean, that's a huge thing for anybody that's ever seen. That would have taken 40 minutes to do prior to version 4 because you'd have to do it all by hand and do all the coding. So now you can say, "Well, you know what? I also want to maybe do a... Maybe a compass.

I'm going to add a compass track. Depending on the application, compasses are kind of popular, you know, kind of giving you an orientation as to where you're looking, especially if you're going to be jumping around nodes. So again, they give you default media, which you can use or not.

And in fact, you can choose a linear style like that and have it kind of scroll across like a dial or a radial one, based either on pan angle or tilt angle. So we'll leave it at that. And say we want to look there. I'm going to set that as north. So now that's going to be north so that the arrow's pointing up at that particular view.

Close that, and I can simply go over here, drag that around. If I were building this, you know, I might have a nice background image. What I'm going to do is just use their basic background, but I'll go ahead and change it to...

[Transcript missing]

I don't know if you can tell from back there, but here's my indicator. And as I'm panning, it's panning as well. And as I face that fountain, it's giving me the direction of north.

So again, that would have taken a considerable, significantly amount of time to do prior to this version. And then they also-- let's see, they do-- you can do directional sounds that way. You can add sounds. Let's go ahead, though, and look at the VR editor again for a second. Even though they don't do any stitching, they have given us now the capability to do hotspots within the application.

So there's the hotspot that was created previously. I can go in here and see it. And I can alter it, you know, there it is there. I have to grab this tool. I can move it around, put it where I want, go back, change the settings associated to it. I can use custom cursors.

I can change the way it links. You know, I can tell it where it's linking to. You can do all that kind of stuff. So it's very powerful. And then if you do want to get into the QScript type of thing, this is kind of the traditional way to do it, where the handlers are here. If you, you know, didn't want to use the fast tracks.

And then another very cool feature that they added then-- let me change this back a little bit. Back to my local library. I'm going to take my other movie. I'm just going to simply go down here. And it's going to say append, and voila, now I have a multi-node movie.

And not only that, but the software was smart enough to go ahead and automatically extend those two tracks that it created for me. So now I have two nodes, and the controller and the compass are going to go ahead and be there for both nodes. So I can go back to this node.

HotSpot. This is node one. There's node two. Link to node. You'll tell it where it's going to go. All that kind of stuff. So I can add-- I can create additional HotSpots here if I wanted. Choose a color. And again, just go in there. And now instead of using the one that was in there before, I could create my own. So, very, very powerful, very, very easy. And they're also having a pretty unbelievable sale price for the show. So you might want to try to hook up with those guys if you can. What else was there to show?

Let's see, we did the Zoomify and the 360 optic. We did VRWorks. And again, VRWorks and PhotoWarp, they're both downstairs. So I didn't want to spend a lot of time going through them. Both of them have a lot more features and functionality than what I've shown, but since they're downstairs, I'd recommend you go down there.

Live Stage Pro we did. Looked at the Manfrotto head. Oh, Dennis. Is Dennis still here? Yes. So what we'll do, it's 10 now, a little after 10. Dennis will take a few minutes, show us a custom head that he had made, and then we'll do some Q&A. Thank you.

This is a VR head that we had custom fabricated for our project. I'm working at the National Air and Space Museum, part of the Smithsonian. We'll be talking about a case study. I need a microphone. Okay, sorry. Is this good? Can you use this one? She's waving to me. It must be okay. Thumbs up. I got thumbs up now.

So this is a custom fabricated head. We have a lot of issues on our project building and shooting all these aircraft. We have 200 aircraft to shoot, and we're using Jim's standard spherical head. But we had some issues with going into cockpits of jets. It takes 15 minutes to raise and lower the canopies. So picture you had to raise and lower the canopy for every shot. You'd need to do 36. So we'd be there a few days. So we had a gentleman. A gentleman in the audience, Dr.

Lewis Knapp. And he came up with this motorized head. Unfortunately, Terry's still trying to figure out how to work with his other stuff. I got it. But basically, it would just mount on a tripod. We mount it inside the aircraft. We hit start, close the canopy, and then the head would automatically start to rotate and put the camera in the correct position. Does the full 36 shots or whatever it's programmed for. And it fires off the camera. So then we can open up the canopy, then pull our equipment out and move on to another aircraft.

So... Lots of different things that we've had to do, and we'll talk about that in my presentation, but Terry wanted me to show another solution out there. Don't know how much it would cost on the market. You'd have to talk to Louis. I think he's into taking your firstborn.

So, or at least, you know, the right arm, you know, whichever is the trigger finger. So that's kind of it for my presentation. Wow. Okay. Terry. Great. So we'll do some Q&A if Jim wants to come back up. I have flyers, actually, for the Manfrotto. I forgot that what they do, actually, is they supply you with two sets of brackets. So I had the wrong bracket on there, which is nice, because they'll do larger brackets for bigger SLR cameras like this, or they'll supply smaller brackets if you're going to be using a consumer, prosumer-type digital camera.
