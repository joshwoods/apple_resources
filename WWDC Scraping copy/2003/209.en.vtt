WEBVTT

00:00:21.740 --> 00:00:22.330
Good afternoon.

00:00:22.340 --> 00:00:25.360
Welcome to session 209,
Advanced OpenGL Optimizations.

00:00:25.360 --> 00:00:26.300
I'm Travis Brown.

00:00:26.300 --> 00:00:29.430
I'm sure by now you know what I do,
so we'll cover that.

00:00:29.480 --> 00:00:33.530
But this is a really good session
for you to attend because we're going

00:00:33.530 --> 00:00:37.830
to be talking about the techniques
to optimize OpenGL on Mac OS X.

00:00:37.840 --> 00:00:40.300
And I want to just make a couple
quick comments and get out

00:00:40.300 --> 00:00:43.120
of the way because we sort of
have a supersized session here.

00:00:43.120 --> 00:00:45.500
So we're going to try to fit it
in the allotted amount of time.

00:00:45.500 --> 00:00:47.000
It's going to be a
little bit of a struggle,

00:00:47.000 --> 00:00:48.180
but we've got great content.

00:00:48.180 --> 00:00:52.130
But the key thing I want to sort of
point out is that one of the advantages

00:00:52.130 --> 00:00:56.310
Apple has in terms of our implementation
of an operating system is that we deliver

00:00:56.310 --> 00:00:58.320
the driver and also the OpenGL stack.

00:00:58.340 --> 00:01:00.740
And because of that,
we're able to put in certain fast

00:01:00.840 --> 00:01:04.250
paths that enable you to really
unlock incredible performance out

00:01:04.260 --> 00:01:06.120
of the latest generations of GPUs.

00:01:06.160 --> 00:01:10.090
And since we also work on the operating
system and create our own tools,

00:01:10.090 --> 00:01:13.180
we have a tool chain that's
available to you to be able to

00:01:13.180 --> 00:01:16.470
really take a look at how your
OpenGL application is performing,

00:01:16.560 --> 00:01:21.140
debug it, and also just unlock it so it
runs as wide open as it can.

00:01:21.140 --> 00:01:23.700
So it's my pleasure to
welcome John Stauffer,

00:01:23.700 --> 00:01:25.660
the manager of the
OpenGL engineering team,

00:01:25.660 --> 00:01:26.900
to the stage to take you
through the presentation.

00:01:33.930 --> 00:01:34.340
Thank you, Travis.

00:01:34.340 --> 00:01:37.500
As Travis said,
I manage the OpenGL engineering

00:01:37.500 --> 00:01:39.730
team at Apple,
and this is going to be a

00:01:39.740 --> 00:01:43.660
session on optimizing OpenGL,
trying to get the most out

00:01:43.700 --> 00:01:45.540
of OpenGL on the Macintosh.

00:01:45.620 --> 00:01:50.490
So what we're going to go over today is
we're going to try to cover some basics.

00:01:50.550 --> 00:01:53.750
We're going to try to move through
those as quickly as possible and get

00:01:53.840 --> 00:01:57.210
into some techniques that you'll want
to try to leverage in your application

00:01:57.300 --> 00:01:59.300
to get the maximum performance.

00:01:59.300 --> 00:02:02.220
So some of those things are
optimizing texture uploads,

00:02:02.330 --> 00:02:06.330
optimizing your vertex data throughput,
optimizing for one-shot images.

00:02:06.330 --> 00:02:09.630
If you're just blitting an image up to
the screen and you want to dispose of it,

00:02:09.700 --> 00:02:11.480
that's what I call a one-shot image.

00:02:11.500 --> 00:02:14.570
Optimizing for copy pixels,
if you want to move pixels around,

00:02:14.570 --> 00:02:16.040
how do you do that quickly?

00:02:16.040 --> 00:02:17.720
Using threads in OpenGL.

00:02:17.720 --> 00:02:20.830
OpenGL is thread-safe,
and a great way to leverage

00:02:20.830 --> 00:02:22.940
our systems is to use threads.

00:02:22.980 --> 00:02:25.680
And lastly, we're going to go into
the OpenGL Profiler,

00:02:25.820 --> 00:02:29.270
which is a tool you can use to
hopefully animate your application.

00:02:29.300 --> 00:02:33.530
So you can analyze and look for hotspots,
look for blocks in your code where

00:02:33.530 --> 00:02:35.970
it may be blocking up against OpenGL.

00:02:36.320 --> 00:02:39.050
Okay, so the goals of optimizing,
there's a couple goals.

00:02:39.170 --> 00:02:42.820
One is to maximize
performance of your rendering.

00:02:42.820 --> 00:02:44.730
So you may want to get
maximum performance,

00:02:44.730 --> 00:02:47.600
and that means utilizing the
CPU and GPU in a combination that

00:02:47.600 --> 00:02:49.260
will get you that performance.

00:02:49.940 --> 00:02:51.900
Another possible goal is
to minimize CPU burden.

00:02:51.910 --> 00:02:53.260
So it's a little different.

00:02:53.310 --> 00:02:55.410
Maybe sometimes they
result in the same code,

00:02:55.480 --> 00:02:56.790
but sometimes they don't.

00:02:56.860 --> 00:03:01.200
And to minimize CPU burden usually
means maximize burden on the GPU.

00:03:01.200 --> 00:03:06.080
You may want to have a technique to
offload as much burden on the GPU,

00:03:06.080 --> 00:03:09.260
leaving the CPU free
for doing other work.

00:03:09.360 --> 00:03:12.350
So key concepts to keep
in mind while I'm talking.

00:03:12.380 --> 00:03:15.970
Keep these things in mind so
that hopefully the concepts I'll

00:03:15.970 --> 00:03:18.060
be presenting will make sense.

00:03:18.080 --> 00:03:18.790
If I'm not pointing
them out as a mistake,

00:03:18.810 --> 00:03:19.520
I'm not going to be able to do that.

00:03:19.600 --> 00:03:21.580
I'm going to be as clear as I need to be.

00:03:21.580 --> 00:03:24.710
Eliminating CPU copies is a
key goal to any optimization.

00:03:24.910 --> 00:03:28.010
You want to reduce the amount
of times you're touching data.

00:03:28.010 --> 00:03:30.200
So you want to move
it through the system,

00:03:30.200 --> 00:03:32.940
get it to where it needs to go,
and start operating or

00:03:32.990 --> 00:03:34.450
start drawing on it.

00:03:34.540 --> 00:03:36.220
Cache static data in VRAM.

00:03:36.220 --> 00:03:40.280
So the video card has a higher
memory bandwidth than system memory.

00:03:40.280 --> 00:03:43.920
So if you have static data,
an ideal place to do it, to put it,

00:03:43.920 --> 00:03:45.310
is up in video memory.

00:03:45.310 --> 00:03:49.540
Put it in video memory, leave it there,
and draw with it from there.

00:03:49.560 --> 00:03:51.180
And you'll get dramatically
higher performance,

00:03:51.180 --> 00:03:52.340
as I'll show in some of the demos.

00:03:52.360 --> 00:03:55.520
Maximize asynchronous
behavior between CPU and GPU.

00:03:55.520 --> 00:03:56.600
That's key.

00:03:56.600 --> 00:04:00.280
You've got two asynchronous
pieces of hardware.

00:04:00.280 --> 00:04:02.060
You're going to want
to stay asynchronous.

00:04:02.060 --> 00:04:05.240
You're going to want to run
one in parallel to the other.

00:04:05.240 --> 00:04:07.190
You're not going to want to
block against each other.

00:04:07.190 --> 00:04:09.280
That's a key concept to
getting maximum performance.

00:04:09.330 --> 00:04:12.480
And again, like I said,
using threads is a concept that

00:04:12.480 --> 00:04:14.280
can be beneficial at times.

00:04:14.280 --> 00:04:16.180
So basic things to avoid.

00:04:16.210 --> 00:04:18.140
So we're into the basics of
just a general overview of

00:04:18.200 --> 00:04:19.200
what we don't want to do.

00:04:19.560 --> 00:04:22.110
And what you usually don't
want to do is call geoflush.

00:04:22.110 --> 00:04:24.560
Flush is a command buffer
up to the hardware.

00:04:24.560 --> 00:04:26.740
It uses resources in the driver.

00:04:26.740 --> 00:04:31.070
It can cost you a little bit of
function overhead getting into

00:04:31.160 --> 00:04:33.580
the driver to make that happen.

00:04:33.580 --> 00:04:34.770
Don't do it unless you have to.

00:04:34.770 --> 00:04:36.490
There's a couple reasons
you might have to.

00:04:36.490 --> 00:04:37.970
We'll cover those a little bit later.

00:04:37.970 --> 00:04:38.990
In general, avoid it.

00:04:39.060 --> 00:04:40.230
Never call geofinish.

00:04:40.230 --> 00:04:43.590
I frankly don't know of any cases
where geofinish is really required.

00:04:43.590 --> 00:04:46.580
There's other ways to do it,
possibly more efficiently.

00:04:46.580 --> 00:04:48.960
Avoid calling georeadpixels.

00:04:49.600 --> 00:04:53.020
Georeadpixels is only really required
when you want to take the pixels back off

00:04:53.030 --> 00:04:55.060
the video card and save them somewhere.

00:04:55.060 --> 00:04:55.880
Save them for later.

00:04:55.880 --> 00:04:58.810
But if you're going to use an
algorithm for rendering an effect

00:04:58.810 --> 00:05:01.290
and you have readpixels in there,
you probably want to look

00:05:01.390 --> 00:05:02.040
for a better way to do it.

00:05:02.400 --> 00:05:06.070
Like caching the data somewhere else
in the video card and then reusing it

00:05:06.070 --> 00:05:10.150
by just copying it out of that cache
on video memory back into your scene.

00:05:10.160 --> 00:05:12.930
Avoid immediate mode drawing.

00:05:12.970 --> 00:05:16.880
So immediate mode drawing is when
you use a GL begin and GL end and you

00:05:16.880 --> 00:05:19.280
have a series of vertices and colors.

00:05:19.580 --> 00:05:20.980
You put in between those the begin end.

00:05:20.980 --> 00:05:22.990
There's one caveat to that.

00:05:22.990 --> 00:05:25.600
You can use immediate mode
drawing in display lists.

00:05:25.660 --> 00:05:27.810
We have a post processor
that will go through,

00:05:27.810 --> 00:05:30.640
take that begin end sequence,
post process it, optimize it,

00:05:30.730 --> 00:05:32.390
cache it in video memory for you.

00:05:32.440 --> 00:05:34.240
So display lists are static data.

00:05:34.240 --> 00:05:37.110
You can't modify display
lists once you've created it.

00:05:37.230 --> 00:05:39.120
So by definition,
it fundamentally is static.

00:05:39.120 --> 00:05:41.720
So we will treat it like static data,
cache it in video memory.

00:05:41.870 --> 00:05:44.270
So display lists is a good
place to put your static data.

00:05:44.280 --> 00:05:45.690
Minimize state changes.

00:05:45.690 --> 00:05:48.480
So state changes in the
hardware can be expensive.

00:05:49.610 --> 00:05:52.250
The more complex the hardware gets,
the more expensive they tend to get.

00:05:52.410 --> 00:05:54.510
So therefore,
you want to group your rendering

00:05:54.510 --> 00:05:55.950
according to state change.

00:05:55.960 --> 00:05:59.010
There's usually a hierarchy
of how you want to group it.

00:05:59.060 --> 00:06:02.030
Maybe like group it by texture,
group it by blending modes,

00:06:02.100 --> 00:06:05.890
group it by drawing method
where you coalesce your

00:06:05.890 --> 00:06:07.940
type of primitive triangles,
quads.

00:06:08.020 --> 00:06:12.300
But coalescing your database
according to state will cause less

00:06:12.300 --> 00:06:16.030
state transitions in the hardware,
and that can be very

00:06:16.030 --> 00:06:18.170
beneficial to performance.

00:06:19.820 --> 00:06:22.160
Okay, so jumping into optimizing
texture uploads.

00:06:22.160 --> 00:06:25.320
First, what we're going to go through
is we're going to do an overview

00:06:25.320 --> 00:06:27.210
of the texture pipeline,
and we're going to talk

00:06:27.210 --> 00:06:28.120
briefly about that.

00:06:28.190 --> 00:06:32.720
And then we're going to go into
texture optimization basics,

00:06:32.720 --> 00:06:36.150
just some overview of
what we want to look at.

00:06:36.360 --> 00:06:38.120
And then we're going to go
into some OpenGL extensions,

00:06:38.120 --> 00:06:40.160
and we're going to break those
down into two categories.

00:06:40.160 --> 00:06:43.020
We're going to break them down
into Power of Two extensions

00:06:43.090 --> 00:06:44.920
and Non-Power of Two extensions.

00:06:44.920 --> 00:06:47.070
There's ways to optimize
slightly differently for

00:06:47.070 --> 00:06:48.330
those two different cases.

00:06:49.820 --> 00:06:53.740
Okay, so the open gel pipeline
generally looks like this.

00:06:54.290 --> 00:06:56.330
For this part of the talk,
for optimizing texture uploads,

00:06:56.340 --> 00:06:57.810
we're going to focus in
on the pixel pipeline.

00:06:57.810 --> 00:07:01.140
So we're going to focus in on the
highlighted yellow boxes there.

00:07:01.140 --> 00:07:04.070
And to zoom in on that a little
bit and talk a little more in

00:07:04.070 --> 00:07:07.740
depth on what happens while the
data is moving through the system,

00:07:07.740 --> 00:07:09.800
here we have a basic block diagram.

00:07:09.800 --> 00:07:15.880
And each block on this diagram,
oval or block, the data may be copied.

00:07:15.880 --> 00:07:18.270
So you have the application,
you the application has

00:07:18.360 --> 00:07:19.460
a copy of the texture.

00:07:19.930 --> 00:07:20.710
You hand it to OpenGL.

00:07:20.720 --> 00:07:23.200
OpenGL may make a copy of the data
and store it in the framework.

00:07:23.200 --> 00:07:25.970
When it goes to draw it,
the driver may make a copy into

00:07:25.970 --> 00:07:29.430
some harder or specific format
for uploading to video memory.

00:07:29.460 --> 00:07:32.320
And then, of course,
video memory has a copy, right?

00:07:32.320 --> 00:07:35.800
So theoretically,
it's possible that you might have up to

00:07:35.900 --> 00:07:38.460
four copies in your system at some point.

00:07:38.480 --> 00:07:41.920
So the goal of some of this discussion
is how to avoid some of that and

00:07:41.940 --> 00:07:43.810
how to control how that operates.

00:07:45.710 --> 00:07:46.850
Okay, so basics.

00:07:46.900 --> 00:07:49.040
So again, like I said,
we want to minimize

00:07:49.040 --> 00:07:50.640
CPU copies and conversions.

00:07:50.640 --> 00:07:53.540
It is possible that you pass data
that is not necessarily in the

00:07:53.540 --> 00:07:57.040
format that the hardware wants it,
and we'll have to do a conversion.

00:07:57.040 --> 00:08:00.930
So you're going to want to pick
data formats that are optimal,

00:08:00.930 --> 00:08:02.800
and I mentioned some here.

00:08:02.800 --> 00:08:11.270
The BGRA unsigned int 8888 reverse,
BGRA unsigned short 1555 reverse,

00:08:11.270 --> 00:08:14.600
and the YUV format for YCBCR data.

00:08:15.460 --> 00:08:18.740
Those formats can be used for
fast paths through the system,

00:08:18.740 --> 00:08:22.260
and without any other types of
state that may cause conversions,

00:08:22.480 --> 00:08:26.810
those do not need to be converted for the
hardware to natively understand those.

00:08:30.330 --> 00:08:34.960
Okay, so like I said before,
you'll want to avoid geofleshes,

00:08:35.070 --> 00:08:37.240
but there are exceptions.

00:08:37.240 --> 00:08:40.300
And one exception is when you
have the GPU asynchronously

00:08:40.300 --> 00:08:43.800
reading data from your data cache,
so if you have a texture and the

00:08:43.800 --> 00:08:46.370
GPU is going to read directly from it,
you want to stay

00:08:46.370 --> 00:08:48.000
asynchronous with the GPU.

00:08:48.000 --> 00:08:50.100
So you may have to double buff your data.

00:08:50.100 --> 00:08:54.630
For instance, you may have to have
texture one and texture two,

00:08:54.630 --> 00:08:58.780
and while the CPU is uploading
or working on texture one,

00:08:58.780 --> 00:09:00.180
you'll have the GPU, which is going to be
working on texture two.

00:09:00.200 --> 00:09:02.190
And we're going to go
into more details here,

00:09:02.190 --> 00:09:04.890
but I wanted to mention it,
so you'll keep it in mind as we

00:09:04.890 --> 00:09:06.540
look at some of the diagrams.

00:09:06.540 --> 00:09:09.190
Okay, so double buffering.

00:09:09.230 --> 00:09:13.180
So like I said, what you want to do is,
to stay asynchronous,

00:09:13.180 --> 00:09:16.120
you want to have double
buffering of the data.

00:09:16.120 --> 00:09:28.500
So if you double buffer your data,
it looks like this, right?

00:09:29.110 --> 00:09:35.820
A few OpenGL extensions of how to
optimize your texture pipeline.

00:09:35.820 --> 00:09:41.490
Apple Client Storage Apple Client
Storage is where you tell OpenGL that

00:09:41.490 --> 00:09:44.200
I will allocate a piece of memory
and I'll keep it around and you

00:09:44.200 --> 00:09:45.260
can just have a pointer to it.

00:09:45.420 --> 00:09:47.830
So we will retain a pointer to your data.

00:09:47.830 --> 00:09:50.570
We will not copy the data
and retain it locally.

00:09:50.580 --> 00:09:54.670
So that requires that you retain your
copy of the texture until you delete it,

00:09:54.670 --> 00:09:57.130
because we're going to be referencing it.

00:09:57.750 --> 00:09:59.880
Another extension is Apple Texture Range.

00:09:59.880 --> 00:10:03.310
That has a couple interesting
modes that you can define.

00:10:03.320 --> 00:10:06.490
One is cached,
which means that you're going to

00:10:06.490 --> 00:10:08.600
want the data cached in video memory.

00:10:08.600 --> 00:10:10.940
One is shared, where it says that I don't
want it cached in video memory.

00:10:10.940 --> 00:10:12.600
I want you to leave it in AGP space.

00:10:12.600 --> 00:10:13.850
Don't put it in video memory.

00:10:13.860 --> 00:10:18.480
And what Texture Range does is
it defines a region of memory.

00:10:18.480 --> 00:10:19.540
You put a texture there.

00:10:19.540 --> 00:10:23.590
We will map that region of memory
in AGP space and leave it there.

00:10:23.650 --> 00:10:27.560
So that the GPU is able
to come and DMA directly.

00:10:27.660 --> 00:10:30.330
from that piece of memory without us
having to copy it out of that region

00:10:30.330 --> 00:10:31.880
of memory and put it into AGP space.

00:10:32.020 --> 00:10:34.680
We will map that memory
directly in AGP space.

00:10:37.730 --> 00:10:40.670
Okay, so if we look at what these
extensions do to the stack,

00:10:40.940 --> 00:10:44.600
so client storage,
what it does is it bypasses one

00:10:44.780 --> 00:10:46.780
copy that a texture may undergo.

00:10:46.780 --> 00:10:49.790
So it goes from the application
to the driver without having

00:10:49.790 --> 00:10:51.470
to be copied by the framework.

00:10:51.470 --> 00:10:54.590
So that will automatically increase
your performance if you happen to be

00:10:54.590 --> 00:10:56.300
incurring a copy in the framework.

00:10:57.320 --> 00:10:58.560
We'll go over some sample code.

00:10:58.560 --> 00:10:59.970
It's pretty easy to enable.

00:10:59.970 --> 00:11:01.890
All you have to do is make a single call.

00:11:01.890 --> 00:11:05.170
When you bind to a texture,
you make a call to enable client storage,

00:11:05.170 --> 00:11:06.750
and you just set it to true.

00:11:09.330 --> 00:11:11.340
Okay,
the texture range and rectangle texture.

00:11:11.340 --> 00:11:16.900
Now, rectangle texture,
that extension is for allowing some

00:11:16.900 --> 00:11:18.960
hardware to do direct DMA of the texture.

00:11:18.960 --> 00:11:21.780
And the reason for that
is that some hardware,

00:11:21.860 --> 00:11:24.530
the power of two textures,
and to define what power of

00:11:24.540 --> 00:11:27.230
two is versus non-power of two,
is that power of two meaning a power

00:11:27.230 --> 00:11:30.640
of two width height versus rectangle,
which means any dimension, right,

00:11:30.660 --> 00:11:33.660
is not restricted to a
power of two dimension,

00:11:33.720 --> 00:11:38.520
is required by some hardware to do
direct DMA because some hardware requires

00:11:38.520 --> 00:11:43.640
a hardware-specific format for the
data to be in before it can upload it.

00:11:43.700 --> 00:11:46.480
So, therefore,
rectangle texture is required when you

00:11:46.480 --> 00:11:48.440
use texture range to get direct DMA.

00:11:48.440 --> 00:11:51.100
And you'll need to use
those in conjunction.

00:11:51.100 --> 00:11:53.380
And when you do,
you can bypass a driver's copy.

00:11:53.380 --> 00:11:56.200
So now we've showed how to
bypass two independently.

00:11:56.200 --> 00:11:59.980
And looking at the sample
code for texture range,

00:11:59.980 --> 00:12:03.040
like I said, there's the cached hint.

00:12:03.080 --> 00:12:06.640
And the cached hint in this
case is for storing the data.

00:12:06.660 --> 00:12:07.340
It's up in video memory.

00:12:07.340 --> 00:12:09.180
And it's for non-power of two.

00:12:09.180 --> 00:12:11.660
And if we look at the shared hint,
here's how you set it.

00:12:11.700 --> 00:12:12.300
It's the same.

00:12:12.300 --> 00:12:13.870
It's just that you have a,
instead of cached hint,

00:12:13.870 --> 00:12:14.730
you have a shared hint.

00:12:14.760 --> 00:12:19.060
And just for those that,
if I'm going too fast,

00:12:19.320 --> 00:12:21.660
there's sample code that'll
be up on the website.

00:12:21.660 --> 00:12:22.660
You can look at that.

00:12:22.680 --> 00:12:23.760
And it has all these features.

00:12:23.760 --> 00:12:26.170
So don't get too worried about
writing these things down.

00:12:26.180 --> 00:12:27.440
You can reference the sample code.

00:12:27.440 --> 00:12:29.890
Okay,
so if we use those two in conjunction,

00:12:29.890 --> 00:12:31.940
we end up bypassing all the copies.

00:12:31.960 --> 00:12:35.920
We end up going straight from
your copy of the texture,

00:12:36.420 --> 00:12:38.100
directly into video memory.

00:12:38.100 --> 00:12:43.390
And therefore, the GPU is directly
DMAing from your memory.

00:12:43.400 --> 00:12:47.930
So the GPU and the application are
directly talking to one another.

00:12:47.940 --> 00:12:50.600
OpenGL fundamentally has
been moved out of the way.

00:12:50.600 --> 00:12:54.000
OpenGL did the setup,
but the transfer is happening between

00:12:54.000 --> 00:12:55.800
your application and that GPU.

00:12:58.450 --> 00:13:01.580
Okay,
so looking at putting this all together

00:13:01.580 --> 00:13:05.460
and looking at a little bit of a piece of
code that does all these things together.

00:13:05.460 --> 00:13:09.090
For non-power of two,
the first thing we do is we're going

00:13:09.200 --> 00:13:12.590
to bind to a rectangle texture,
and then we're going to

00:13:12.590 --> 00:13:15.760
set up the cached hint,
and that is going to work in

00:13:15.760 --> 00:13:20.780
conjunction with the client storage,
which is next on the fourth line.

00:13:20.780 --> 00:13:25.030
And between those two,
that's going to set up for a direct DMA.

00:13:25.140 --> 00:13:30.110
And then when we call the text image
2D with a rectangle texture target,

00:13:30.110 --> 00:13:34.210
it is going to set up the GPU for
a direct DMA of your texture from

00:13:34.360 --> 00:13:37.770
directly DMAing it from your memory,
right?

00:13:37.780 --> 00:13:41.070
So pretty simple to do,
but this particular setup that I'm

00:13:41.070 --> 00:13:45.890
showing right now does require that you
are going to be using rectangle texture.

00:13:45.900 --> 00:13:48.910
And you'll want to read the rectangle
texture specification because

00:13:48.910 --> 00:13:50.780
it does have some restrictions.

00:13:50.780 --> 00:13:54.250
It does have some
restrictions on functionality,

00:13:54.260 --> 00:13:57.730
so it's not quite the same
as a power of two texture,

00:13:57.730 --> 00:14:01.050
which allows for MIT maps,
allows for different

00:14:01.050 --> 00:14:03.120
clamping modes and such.

00:14:03.120 --> 00:14:05.310
So you'll want to read the
extension and see if rectangle

00:14:05.310 --> 00:14:06.500
texture suits your needs.

00:14:06.500 --> 00:14:10.670
Okay, so for power of two,
it's slightly different, but not much.

00:14:10.760 --> 00:14:13.800
All I did here in this piece of code,
different from the previous one,

00:14:13.960 --> 00:14:16.160
is change rectangle
texture to texture 2D.

00:14:16.160 --> 00:14:22.000
And texture 2D then allows me
to... Use a power of two texture,

00:14:22.000 --> 00:14:25.500
get some of the additional functionality
that power of two textures bring to me,

00:14:26.050 --> 00:14:28.560
but it won't give you a direct DMA.

00:14:28.560 --> 00:14:30.240
It's going to incur one copy,
so it's not going to be

00:14:30.390 --> 00:14:31.400
quite as fast performance.

00:14:31.440 --> 00:14:35.330
Typically, we see that as okay because
rectangle textures are usually okay

00:14:35.330 --> 00:14:37.140
for things like video and such.

00:14:37.140 --> 00:14:40.050
Games like Quake 3 are
going to use power of two,

00:14:40.210 --> 00:14:44.370
and they're going to load them at
the beginning of the game or a level,

00:14:44.370 --> 00:14:47.580
and you're not going to need to do
real-time texture loading as much.

00:14:47.580 --> 00:14:50.720
So rectangle textures is
very powerful for playing.

00:14:50.720 --> 00:14:53.800
You can play video,
playing through images that you

00:14:53.800 --> 00:14:58.120
want to get to the screen fast,
which typically are non-power of two.

00:14:58.120 --> 00:15:00.740
Okay,
so let's switch to the demo machine.

00:15:00.740 --> 00:15:02.810
I'm going to show you a demo of that.

00:15:07.160 --> 00:15:10.470
Okay, so the first thing we're going
to do is just look at this

00:15:10.470 --> 00:15:12.620
and explain what the demo is.

00:15:12.830 --> 00:15:15.800
This demo, it's hard to see,
but it has numbers in

00:15:15.900 --> 00:15:17.770
the middle of that image.

00:15:17.770 --> 00:15:21.500
The numbers go from 1 to 5,
and it is uploading a 1024,

00:15:21.600 --> 00:15:26.770
even though it's a small window,
it is a 1024 by 1024 32-bit image.

00:15:26.770 --> 00:15:30.130
It is uploading it across AGP bus and
blending it on the screen every frame.

00:15:31.400 --> 00:15:34.880
So, you can see that we're getting
about 650 megabytes a second,

00:15:34.880 --> 00:15:37.440
and you'll also see that
we've got a couple sliders.

00:15:37.440 --> 00:15:40.510
I can switch from single buffered
all the way up to five buffers to

00:15:40.510 --> 00:15:43.610
test the different effects that
may have on the parallelization

00:15:43.610 --> 00:15:45.380
of the hardware and the CPU.

00:15:45.380 --> 00:15:48.230
You can also see a frame rate
slider and a number of check boxes

00:15:48.230 --> 00:15:50.120
turn off the different extensions.

00:15:50.120 --> 00:15:52.950
So, the frame rate slider goes
all the way up to 1,000.

00:15:52.950 --> 00:15:55.010
We actually had to add
that to test the G5.

00:15:56.900 --> 00:15:58.710
But we're on a G4,
so we're going to keep it in the middle.

00:15:58.710 --> 00:16:03.080
So the interesting note here is,
like I had said, is that the idea is to

00:16:03.100 --> 00:16:04.720
eliminate CPU copies.

00:16:04.720 --> 00:16:06.410
Well, this actually eliminates
all the CPU copies,

00:16:06.410 --> 00:16:06.780
right?

00:16:06.780 --> 00:16:10.360
And you can see that the CPU monitor
is showing very little activity.

00:16:10.360 --> 00:16:13.980
The CPU actually isn't doing much here
other than running the event loop and

00:16:13.990 --> 00:16:15.940
drawing a little quad on the screen.

00:16:15.940 --> 00:16:19.780
So the CPU's been effectively removed
from the bulk of the work of this demo.

00:16:19.780 --> 00:16:28.220
Now, if we turn off, say,
all the extensions,

00:16:28.220 --> 00:16:28.220
let's just start turning
these things off.

00:16:29.320 --> 00:16:32.060
You can see that our performance
dropped from 650 megabytes a second

00:16:32.060 --> 00:16:34.680
down to 111 megabytes a second.

00:16:34.680 --> 00:16:38.040
And you can see now we have
effectively saturated one CPU.

00:16:38.040 --> 00:16:40.030
So now we're a single-threaded app.

00:16:40.030 --> 00:16:41.340
We've taken one CPU.

00:16:41.340 --> 00:16:46.220
We are basically memory-bound by a
CPU copying the data to get it into a

00:16:46.470 --> 00:16:49.200
format that can be uploaded by the GPU.

00:16:50.680 --> 00:16:53.270
So with those extensions, again,
I'll turn them back on,

00:16:53.370 --> 00:16:58.980
not only do you get higher bandwidth,
but you save CPU work, right?

00:16:58.980 --> 00:17:01.780
Because you're not using a CPU,
and you're getting higher throughput.

00:17:01.780 --> 00:17:06.190
So for people who are able to
use some of these extensions,

00:17:06.190 --> 00:17:08.490
you can get quite a benefit.

00:17:08.500 --> 00:17:12.850
Okay, back to the slides, please.

00:17:19.330 --> 00:17:21.560
Okay, let's jump into optimizing
vertex throughput.

00:17:21.560 --> 00:17:24.800
Optimizing vertex throughput
actually is very parallel to

00:17:24.800 --> 00:17:28.160
optimizing texture throughput,
and you'll see as I go through the slides

00:17:28.160 --> 00:17:30.030
that it parallels the same concepts.

00:17:30.100 --> 00:17:34.270
In fact, we did that on purpose so that
it has very analogous concepts.

00:17:34.860 --> 00:17:38.100
Okay, so we're going to look at an
overview of the vertex pipeline.

00:17:38.100 --> 00:17:42.100
We're going to go through some of the
basic optimizations that can be done.

00:17:42.100 --> 00:17:44.940
We're going to go through some
of the APIs that can help you,

00:17:45.080 --> 00:17:47.620
and we're going to break this
into a couple categories,

00:17:47.910 --> 00:17:49.610
static and dynamic, and display list.

00:17:49.610 --> 00:17:53.080
So those are three separate categories
we're going to touch on that will,

00:17:53.530 --> 00:17:56.550
slightly different techniques
for each of those categories.

00:17:56.560 --> 00:17:58.510
Okay, again, same pipeline.

00:17:58.790 --> 00:18:03.330
This time we're going to focus in on
the display list and the vertex path.

00:18:06.360 --> 00:18:07.590
Let's get into the basics.

00:18:08.480 --> 00:18:13.420
For minimizing the
CPU copies for vertex data,

00:18:13.420 --> 00:18:15.910
just like pixel data,
you're going to want it into a

00:18:15.910 --> 00:18:17.250
format the hardware understands.

00:18:17.260 --> 00:18:18.960
A safe data type is GeoFloat.

00:18:19.040 --> 00:18:21.740
If you keep all your data in GeoFloats,
you're pretty safe.

00:18:21.830 --> 00:18:24.900
All the hardware knows
how to read GeoFloats.

00:18:24.980 --> 00:18:30.270
If you start using doubles or bytes
for vertex data or some combination

00:18:30.290 --> 00:18:34.600
that's a little bit off the normal,
the driver may say,

00:18:34.600 --> 00:18:37.800
I can't directly upload this to the GPU.

00:18:37.800 --> 00:18:40.000
I may have to do a CPU copy,
do a conversion,

00:18:40.000 --> 00:18:41.620
maybe some slow conversion.

00:18:41.620 --> 00:18:42.930
You may find your performance dismal.

00:18:42.940 --> 00:18:44.360
So stick with GeoFloats.

00:18:44.560 --> 00:18:47.700
That's a guarantee to be
one of the faster paths.

00:18:47.700 --> 00:18:49.740
Use vertex arrays.

00:18:49.750 --> 00:18:52.820
So like I said before,
stay away from immediate mode drawing,

00:18:52.830 --> 00:18:56.040
just because that encourages...
You may have to do some more overheads,

00:18:56.070 --> 00:18:57.850
overhead, per function call overhead
and some other overhead I'm

00:18:57.850 --> 00:18:58.790
going to go into in a minute.

00:18:58.800 --> 00:19:03.200
So use the standard GL array
function calls and maximize

00:19:04.020 --> 00:19:06.650
your vertices per draw command.

00:19:06.660 --> 00:19:10.540
So I will show some performance charts
in a little bit that will show the

00:19:10.540 --> 00:19:15.000
benefit of maximizing the number of
vertices you passed OpenGL at one time.

00:19:15.020 --> 00:19:17.580
So for instance,
instead of drawing one quad at a time,

00:19:17.580 --> 00:19:20.790
if you draw 100 quads at a time,
you'll get dramatically better

00:19:20.790 --> 00:19:24.060
performance because you're lowering
per function call overhead.

00:19:24.060 --> 00:19:26.830
You're lowering... You're
lowering the driver having to do

00:19:26.910 --> 00:19:28.570
work on a per primitive basis.

00:19:28.580 --> 00:19:31.340
Cache your static data VRAM.

00:19:31.340 --> 00:19:32.120
We've already said that.

00:19:32.220 --> 00:19:35.750
And use vertex programs
to offload your CPU work.

00:19:35.820 --> 00:19:39.160
I'm going to show a demo in a
bit that will show how you can do

00:19:39.160 --> 00:19:42.880
actual work with vertex programs
and freeing up CPU cycles,

00:19:42.880 --> 00:19:46.560
not just in the data transfer aspect,
but actually in the effects that you

00:19:46.560 --> 00:19:49.060
may want to do with your application.

00:19:50.850 --> 00:19:53.540
Okay, and again, the same thing,
double buff your data.

00:19:53.600 --> 00:19:56.570
It's analogous to the textures,
and we have the same double buffer

00:19:56.620 --> 00:19:59.580
data diagram where if you have
the GPU reading your data directly

00:19:59.580 --> 00:20:02.690
out of your application's memory,
you're going to need to have some

00:20:02.690 --> 00:20:06.390
isolation between the asynchronous
behavior of the GPU and your application.

00:20:06.390 --> 00:20:08.560
So you're going to want
to double buff your data,

00:20:08.650 --> 00:20:11.660
give the CPU a buffer to work on
while the GPU is working on a buffer,

00:20:11.670 --> 00:20:13.060
and toggle them back and forth.

00:20:13.180 --> 00:20:15.650
So when you do that,
you get asynchronous behavior,

00:20:15.650 --> 00:20:18.310
you can get some significant
performance improvements.

00:20:18.420 --> 00:20:20.780
We'll show some of
that in a demo as well.

00:20:20.800 --> 00:20:22.680
You'll notice I have a geoflush there.

00:20:22.680 --> 00:20:25.400
What you want to do is when the
CPU's done with doing some work,

00:20:25.400 --> 00:20:28.080
you'll want to get that data
in flight to the graphics card.

00:20:28.140 --> 00:20:30.940
So as soon as the CPU's done,
issue geoflush, send it on its way,

00:20:30.940 --> 00:20:33.650
and hopefully you've done a
substantial amount of work where

00:20:33.650 --> 00:20:36.870
you're not calling flush too
often because that will hurt you.

00:20:40.220 --> 00:20:41.720
Again,
very much like the texture pipeline.

00:20:41.720 --> 00:20:44.060
When vertex data comes
through the pipeline,

00:20:44.060 --> 00:20:48.330
it can go through multiple copies,
depending on what APIs you're using

00:20:48.330 --> 00:20:50.580
and how the data is formatted.

00:20:50.580 --> 00:20:56.150
So, we can end up with the data
going from your application,

00:20:56.150 --> 00:21:00.880
and if it's going to media mode,
OpenGL is required to capture

00:21:01.080 --> 00:21:02.940
the current vertex state.

00:21:02.960 --> 00:21:06.660
So, we retain a golden image of
basically the current vertex state

00:21:06.660 --> 00:21:08.690
when you're running a media mode.

00:21:08.700 --> 00:21:10.500
If you're running vertex arrays,
we don't have to do that.

00:21:10.690 --> 00:21:14.490
So, the first copy we have to do is into
a local storage of a single vertex

00:21:14.500 --> 00:21:16.730
instance of a current vertex state.

00:21:16.880 --> 00:21:19.730
So, we incur that one copy if
you're going to media mode,

00:21:19.730 --> 00:21:23.940
and then we're going to have to copy it
to a format for the hardware to upload.

00:21:23.940 --> 00:21:26.120
So, we're going to have to copy
it somewhere into AGP space

00:21:26.190 --> 00:21:28.180
for the hardware to DMA it up,
and then eventually it

00:21:28.180 --> 00:21:29.140
makes it to the GPU.

00:21:30.780 --> 00:21:32.760
So, if you use vertex arrays,
you immediately just

00:21:32.760 --> 00:21:35.340
eliminate that one copy,
and that one's easy to do.

00:21:35.340 --> 00:21:38.020
Immediate mode's an
easy one to work around.

00:21:38.020 --> 00:21:39.920
No extensions needed,
just use the right API.

00:21:42.240 --> 00:21:44.220
Okay, so let's talk a little
bit about dynamic data.

00:21:44.220 --> 00:21:48.040
Analogous to the texture range
extension we previously talked about,

00:21:48.040 --> 00:21:49.700
we have a vertex array range extension.

00:21:49.700 --> 00:21:52.000
And it is exactly parallel.

00:21:52.000 --> 00:21:56.040
It has the same storage hints
where you have a shared hint for

00:21:56.040 --> 00:21:57.650
leaving the data in AGP space.

00:21:57.660 --> 00:22:00.100
And that's what you're going
to want to do for dynamic data.

00:22:00.100 --> 00:22:02.060
You're not going to want to
necessarily cache it in video memory.

00:22:02.060 --> 00:22:03.780
You're going to want to
leave it in AGP space.

00:22:03.780 --> 00:22:07.070
And what happens there is that
you've allocated an array of

00:22:07.070 --> 00:22:08.880
memory in your application.

00:22:09.140 --> 00:22:14.010
We come along, we map that into AGP,
we wire it down,

00:22:14.010 --> 00:22:16.670
and then the application can come
along and poke values into it,

00:22:16.880 --> 00:22:19.900
tell the hardware, I'm done with that,
issue a draw command, we'll DMA it up.

00:22:19.960 --> 00:22:24.990
And therefore, the GPU is reading
directly from your arrays,

00:22:24.990 --> 00:22:28.220
and it never makes it in video memory.

00:22:28.220 --> 00:22:30.900
And for dynamic data, obviously,
that could have a benefit,

00:22:30.900 --> 00:22:33.060
that you don't want it to
be cached in video memory,

00:22:33.080 --> 00:22:35.900
because you're going to change
it again the very next frame.

00:22:37.610 --> 00:22:39.920
Okay, so what does it look like
if we use that extension?

00:22:40.150 --> 00:22:43.420
We have vertex arrays and we
use the vertex array range.

00:22:43.420 --> 00:22:47.100
And just like texture range,
we bypass all the copies in the driver

00:22:47.100 --> 00:22:51.180
and we're DMAing directly from your
copy of the application's arrays.

00:22:51.180 --> 00:22:54.440
So we can get very high
throughput doing that,

00:22:54.720 --> 00:22:56.950
very low CPU work is going on.

00:22:57.840 --> 00:23:00.610
Okay, so looking at a little bit
of sample code for that.

00:23:00.610 --> 00:23:03.180
The first two calls are just a
standard vertex pointer setup,

00:23:03.230 --> 00:23:06.020
standard OpenGL for
setting up a vertex array.

00:23:06.020 --> 00:23:09.520
The next two calls then is
setting up a vertex range.

00:23:09.520 --> 00:23:12.720
And what you do is you pass
it in a size and a pointer,

00:23:12.720 --> 00:23:15.210
and you tell us what memory to map in.

00:23:15.210 --> 00:23:17.400
So you're just going to give
us a pointer with a size,

00:23:17.400 --> 00:23:19.080
and we're going to map that memory in.

00:23:19.080 --> 00:23:22.640
And then the last call
on this is a flush.

00:23:22.640 --> 00:23:25.630
Now, that's an important call,
because every time you change that data,

00:23:25.630 --> 00:23:27.550
you're going to have to
tell us you changed it.

00:23:27.800 --> 00:23:33.420
And what we'll do with that is
potentially flush hardware GPU caches,

00:23:33.420 --> 00:23:36.780
or we may DMA it to some other location.

00:23:36.780 --> 00:23:39.600
But what's important with that
is that you have to tell us

00:23:39.720 --> 00:23:41.360
the areas that you've changed.

00:23:41.360 --> 00:23:45.000
So every frame that you come along,
and you write some more vertices,

00:23:45.000 --> 00:23:47.450
and you change that data,
you have to tell us the

00:23:47.450 --> 00:23:50.340
pointer and the size offset,
the size from that pointer

00:23:50.340 --> 00:23:51.940
that you want us to flush.

00:23:51.940 --> 00:23:52.850
You've changed it.

00:23:52.890 --> 00:23:55.800
We will then know that that has
changed and update the hardware.

00:23:57.640 --> 00:23:59.080
Okay, so static vertex data.

00:23:59.080 --> 00:24:01.360
Very similar.

00:24:01.360 --> 00:24:04.650
You can use the vertex array range,
but instead of using the shared hint,

00:24:04.650 --> 00:24:06.050
you can use the cached hint.

00:24:06.100 --> 00:24:09.330
And what will happen is that
when you define the vertex array,

00:24:09.400 --> 00:24:11.460
if it has a cached
hint and you say flush,

00:24:11.460 --> 00:24:13.790
then we'll know that you've changed it.

00:24:13.970 --> 00:24:16.380
We will DMA a copy up into video
memory and we'll keep it there.

00:24:17.250 --> 00:24:20.120
Every time you call flush, though,
we will have to re-DMA that

00:24:20.120 --> 00:24:23.100
back up into video memory,
but it'll be cached in video memory,

00:24:23.100 --> 00:24:25.490
and if you're going to draw
from it multiple times,

00:24:25.490 --> 00:24:28.580
it's quite a benefit because you're
not having to re-read that data

00:24:28.590 --> 00:24:30.390
across the AGP bus every time.

00:24:30.390 --> 00:24:34.880
Instead, what you're doing is you're
local to the video cards bus,

00:24:35.230 --> 00:24:37.320
which is a very high-speed bus.

00:24:38.700 --> 00:24:41.740
And like I said previously,
you can use display list with begin end.

00:24:42.120 --> 00:24:47.670
The one caveat for using display list is
that we do have an optimizer that goes

00:24:47.740 --> 00:24:52.120
back through the data and parses it and
reconfigures it into an optimal format.

00:24:52.120 --> 00:24:54.300
You can fool that optimizer.

00:24:54.300 --> 00:24:59.450
And what you want to avoid is
using inconsistent vertex data.

00:24:59.460 --> 00:25:03.510
And what I mean by that is that if you
go through GL begin and you say GL color,

00:25:03.550 --> 00:25:06.820
GL vertex, GL color, GL vertex,
that's consistent.

00:25:06.820 --> 00:25:11.510
Inconsistent would be GL begin, GL color,
GL vertex, GL vertex, GL vertex,

00:25:11.510 --> 00:25:12.380
GL vertex.

00:25:12.380 --> 00:25:15.260
You did a color for the first
vertex but not the following ones.

00:25:15.260 --> 00:25:19.460
You may fool the optimizer into
not being able to handle that.

00:25:19.460 --> 00:25:22.740
So if you want to play it safe,
just keep it into consistent

00:25:22.740 --> 00:25:26.780
formats and the optimizer will
definitely be able to take that data,

00:25:26.780 --> 00:25:29.440
pack it into a format that
we can then categorize.

00:25:29.460 --> 00:25:33.440
cache and video memory and you
can get optimal performance.

00:25:34.890 --> 00:25:38.310
So one last caveat then for display
list is that there's a minimum

00:25:38.420 --> 00:25:40.620
threshold for which it's worthwhile
for us to work on the data.

00:25:40.620 --> 00:25:42.420
And that threshold is 16 vertices.

00:25:42.520 --> 00:25:45.770
If you have less than 16 vertices,
we won't even consider optimizing it.

00:25:45.840 --> 00:25:49.730
And that's just,
we just found that out by testing

00:25:49.850 --> 00:25:54.640
different machines and finding out where
the threshold was and deciding that,

00:25:54.640 --> 00:25:57.260
you know, if it's not going to give
you performance benefit,

00:25:57.260 --> 00:25:59.000
in fact,
it can actually slow you down because of

00:25:59.170 --> 00:26:03.000
other overhead of doing work on the data,
that 16 was the minimum.

00:26:05.610 --> 00:26:08.380
Okay,
so what does that diagram look like then?

00:26:08.420 --> 00:26:11.490
So when using static data with
either display lists or with

00:26:11.490 --> 00:26:15.740
the cached vertex array range,
what happens is the data gets

00:26:15.870 --> 00:26:19.120
de-emated into video memory,
and then the GPU draws from that, right?

00:26:19.120 --> 00:26:23.340
So it's gonna be taking the data from
the video memory cache and drawing.

00:26:23.400 --> 00:26:26.780
So you get very high throughput for
data that you draw more than once.

00:26:26.980 --> 00:26:31.240
And the sample code for that, again,
it looks like for static data,

00:26:31.290 --> 00:26:34.200
we're setting up a standard vertex array.

00:26:34.200 --> 00:26:37.820
Again, we set up the hint.

00:26:37.820 --> 00:26:41.180
This time, the hint for the vertex
array range is cached.

00:26:41.270 --> 00:26:42.680
It's not shared like it was for dynamic.

00:26:42.680 --> 00:26:44.990
And like before,
we set up the vertex array

00:26:45.080 --> 00:26:48.640
range pointer in size,
and then again, we tell it to flush.

00:26:49.060 --> 00:26:51.610
And again, the flush, this time,
instead of just,

00:26:51.620 --> 00:26:54.220
the flush is going to cause
us to re-upload that data.

00:26:54.220 --> 00:26:56.700
So if it's not there already,
we'll upload it.

00:26:56.890 --> 00:26:59.770
If you have touched the data
again and it was uploaded,

00:26:59.860 --> 00:27:01.960
we'll refresh it with another copy.

00:27:01.960 --> 00:27:04.630
So it's like a text sub-image
call where we're going to refresh

00:27:04.630 --> 00:27:06.060
the data on the video memory.

00:27:07.750 --> 00:27:10.290
Okay, so for basic review of what
display lists look like,

00:27:10.350 --> 00:27:11.380
it's pretty simple.

00:27:11.380 --> 00:27:13.720
You just call begin list,
draw your drawing,

00:27:13.720 --> 00:27:16.190
and then call end list,
and you can pack anything

00:27:16.190 --> 00:27:17.340
you want in there.

00:27:17.340 --> 00:27:18.520
It takes any OpenGL calls.

00:27:18.530 --> 00:27:21.930
If you put your geometry in
between begin list and end list,

00:27:21.930 --> 00:27:26.340
hopefully we'll be able to optimize
it and get it cached in video memory.

00:27:27.950 --> 00:27:30.920
Okay, so looking at what this can
do for you for performance,

00:27:31.050 --> 00:27:33.470
this is a chart of low
vertex count performance.

00:27:33.530 --> 00:27:38.300
So on the x-axis, we have the number of
vertices per draw command,

00:27:38.300 --> 00:27:41.740
and on the y-axis,
we have millions of triangles.

00:27:42.080 --> 00:27:45.190
So as you can see,
the orange is immediate mode,

00:27:45.190 --> 00:27:48.730
and orange tops out pretty
quickly as to what benefit you

00:27:48.760 --> 00:27:50.900
can get by going down that path.

00:27:50.990 --> 00:27:52.720
And the red, then, is vertex arrays.

00:27:52.720 --> 00:27:55.520
Vertex arrays has a little bit
lower per function call overhead,

00:27:55.520 --> 00:27:57.890
a little more,
give you a little more performance.

00:27:57.920 --> 00:28:00.980
But if you look at the blue,
the blue is vertex array range.

00:28:00.980 --> 00:28:03.930
Vertex array range has great
potential for performance,

00:28:03.990 --> 00:28:07.170
and it doesn't give you a whole
lot until you start giving OpenGL a

00:28:07.190 --> 00:28:08.960
lot of work to do at one time.

00:28:08.960 --> 00:28:10.600
So that's the key.

00:28:10.600 --> 00:28:11.980
The key is giving
OpenGL lots of work to do.

00:28:12.070 --> 00:28:13.870
So you can see here,
I'm giving OpenGL lots

00:28:13.870 --> 00:28:16.130
of work at one time,
and then the green, the top one,

00:28:16.130 --> 00:28:17.140
is displayless.

00:28:17.390 --> 00:28:20.360
So, you know, it goes up to,
on this chart, it goes up to about 12

00:28:20.360 --> 00:28:24.030
million triangles a second,
issuing 30 triangles per draw command.

00:28:24.040 --> 00:28:27.630
Now, this is the high vertex
count performance,

00:28:27.630 --> 00:28:30.830
and picking up a little bit
where the other one left off,

00:28:30.910 --> 00:28:34.850
you can see that some of these
continue to grow quite a bit.

00:28:34.910 --> 00:28:37.920
So you can see that the vertex
arrays in immediate mode stay flat.

00:28:38.130 --> 00:28:41.400
Array range basically
grows until you're limited,

00:28:41.400 --> 00:28:45.610
and in this case, the test I was running
was AGP bus limited.

00:28:45.870 --> 00:28:48.840
So I limited about 640 megabytes
a second of vertex data that

00:28:48.890 --> 00:28:50.570
I could transmit across the bus.

00:28:50.580 --> 00:28:53.360
So I pretty much
bottlenecked that AGP bus,

00:28:53.420 --> 00:28:56.170
and that's all the data
I could get across.

00:28:56.260 --> 00:28:59.090
But in the display list case
that I was testing here,

00:28:59.140 --> 00:29:01.150
the data was effectively static.

00:29:01.240 --> 00:29:02.350
It only went across the bus once.

00:29:02.420 --> 00:29:05.840
So the GPU was able to utilize
its internal bus bandwidth,

00:29:05.940 --> 00:29:08.800
which in the case I was
running on an R300,

00:29:08.800 --> 00:29:10.980
that's about 20 gigabytes a second.

00:29:10.980 --> 00:29:12.480
So it can transfer a whole lot more data.

00:29:12.480 --> 00:29:15.640
And you can see that at the number,
the top number I quoted here,

00:29:15.800 --> 00:29:20.080
it was about 2.8 gigabytes a second
worth of geometry going into the GPU.

00:29:20.080 --> 00:29:23.490
So that's quite a bit of data,
almost 90 million triangles a second.

00:29:23.500 --> 00:29:28.250
So let's do a demo and
show a little bit of this.

00:29:34.020 --> 00:29:36.550
Okay, so what we've got here,
if anybody that's been

00:29:36.600 --> 00:29:38.890
in my session before,
it's the same old thing,

00:29:38.890 --> 00:29:40.920
but next iteration of improvement.

00:29:40.920 --> 00:29:44.160
So initially we're drawing with quads,
and we're doing the

00:29:44.610 --> 00:29:46.090
standard basic GL begin end.

00:29:46.090 --> 00:29:49.880
Not too impressive, we're getting about
800,000 triangles a second.

00:29:49.880 --> 00:29:52.440
So what I'm going to do is I'm
going to step through the different,

00:29:52.440 --> 00:29:54.310
as I move the slider up,
I'm going to step through

00:29:54.360 --> 00:29:56.780
different optimizations and
using different extensions,

00:29:56.780 --> 00:29:59.260
and we'll see what effect
that has on the performance.

00:30:00.000 --> 00:30:02.180
Down at the bottom,
you see the color coding.

00:30:02.260 --> 00:30:04.960
The color coding represents
where time's being spent.

00:30:05.000 --> 00:30:07.930
So red is system time,
time spent outside the application.

00:30:08.000 --> 00:30:11.880
Green is time spent calculating the wave,
and blue is time spent in OpenGL.

00:30:11.880 --> 00:30:14.290
So you can see right now that I'm
spending a lot of time in OpenGL,

00:30:14.290 --> 00:30:15.770
a lot of time calculating the wave.

00:30:15.820 --> 00:30:19.280
So if we start moving up
the level of optimizations,

00:30:19.360 --> 00:30:20.800
I went to quad strips.

00:30:20.950 --> 00:30:23.990
That got us quite a bit
of speed improvement,

00:30:23.990 --> 00:30:27.020
about 25%. And that
was pretty easy to do,

00:30:27.020 --> 00:30:27.920
worthwhile.

00:30:27.920 --> 00:30:29.700
But let's not stop there.

00:30:29.820 --> 00:30:31.750
Let's keep going up.

00:30:32.220 --> 00:30:35.000
So if we go to vertex arrays,
a little bit more.

00:30:35.030 --> 00:30:37.470
That wasn't a great improvement.

00:30:40.190 --> 00:30:41.220
Then we go vertex array range.

00:30:41.230 --> 00:30:42.720
So here's where it gets interesting.

00:30:42.720 --> 00:30:45.390
Now you can see that the
time spent in OpenGL,

00:30:45.390 --> 00:30:48.550
which was the blue,
went from filling basically the

00:30:48.670 --> 00:30:50.970
top of that bar almost to nothing.

00:30:50.970 --> 00:30:53.480
So now the time spent in
OpenGL is very little,

00:30:53.590 --> 00:30:57.230
and we're basically now saturated
on the calculation of the wave.

00:30:57.240 --> 00:31:00.440
We are not able to calculate the wave
fast enough to get the data to OpenGL.

00:31:00.440 --> 00:31:04.830
So if we move up one more notch,
and we see what Altevec can do to us.

00:31:05.620 --> 00:31:09.490
So we Altevec the wave calculation,
because that was my bottleneck.

00:31:09.580 --> 00:31:13.010
Once I optimized OpenGL,
OpenGL was no longer the bottleneck,

00:31:13.010 --> 00:31:13.850
so the CPU was.

00:31:13.940 --> 00:31:16.840
I optimized that,
and then we do one last thing.

00:31:16.840 --> 00:31:19.360
Like I said before,
you may want to offload

00:31:19.360 --> 00:31:21.110
calculations onto the GPU.

00:31:21.110 --> 00:31:24.200
So what if we write a vertex
program to do that wave?

00:31:25.650 --> 00:31:27.810
And now, again,
the interesting thing to watch is

00:31:27.970 --> 00:31:31.590
that we are calculating a wave motion,
and we are sending almost 12 million

00:31:31.590 --> 00:31:33.320
triangles a second to the screen.

00:31:33.320 --> 00:31:34.110
And look at the CPU.

00:31:34.110 --> 00:31:35.800
The CPU's almost doing nothing, right?

00:31:35.800 --> 00:31:38.970
So we basically,
not only have we optimized it,

00:31:39.160 --> 00:31:42.380
but we've offloaded the
CPU from doing any work.

00:31:42.530 --> 00:31:44.310
Now the CPU, again,
is just doing an event loop.

00:31:44.560 --> 00:31:47.900
CPU doesn't know that this
complex wave is being calculated.

00:31:47.900 --> 00:31:49.990
And if we actually look
at the density of this,

00:31:50.030 --> 00:31:51.150
it's a really dense wave.

00:31:51.190 --> 00:31:52.980
There's a lot of triangles there.

00:31:55.500 --> 00:31:59.540
Okay, back to the slides, please.

00:32:04.750 --> 00:32:07.650
Okay, so let's go into a new subject,
optimizing for one-shot images.

00:32:07.650 --> 00:32:10.290
One-shot images, again,
are images that you may have that

00:32:10.290 --> 00:32:13.060
you want to get to the screen as
fast as you can and discard it.

00:32:13.250 --> 00:32:15.320
You're not going to blidge
to the screen multiple times.

00:32:15.320 --> 00:32:16.230
It's just one shot.

00:32:16.360 --> 00:32:18.880
So one possible way of
doing that is draw pixels.

00:32:18.880 --> 00:32:22.060
Draw pixels is fairly
effective in some cases.

00:32:22.060 --> 00:32:24.120
It's best with small images.

00:32:24.120 --> 00:32:26.680
If you have lots of little small
widgets you want to draw somewhere,

00:32:26.680 --> 00:32:29.170
draw pixels is probably the
fastest way to get the data there.

00:32:29.320 --> 00:32:31.450
It's a very optimized path, very quick.

00:32:32.380 --> 00:32:36.440
For images larger than 128 by 128,
you probably want to start considering

00:32:36.540 --> 00:32:39.310
doing some kind of texturing,
like our previous demo showed,

00:32:39.390 --> 00:32:42.300
where you don't have to make a copy,
because draw pixels is going

00:32:42.300 --> 00:32:43.780
to make a copy of the data.

00:32:43.780 --> 00:32:46.720
The larger the image gets,
the more data there is to copy,

00:32:46.900 --> 00:32:50.560
and your benefit for draw pixels,
for instance, is going to go down because

00:32:50.560 --> 00:32:51.780
it will make a copy.

00:32:56.130 --> 00:33:00.010
Okay, so the trick for one-shot images
using draw pixels is to get your

00:33:00.010 --> 00:33:02.160
state right where you're going
to go down the optimized path.

00:33:02.250 --> 00:33:03.030
There's different paths.

00:33:03.060 --> 00:33:05.460
There's three different paths in
OpenGL for how to draw these things.

00:33:05.460 --> 00:33:07.310
You want to hit the one that's fast.

00:33:07.310 --> 00:33:10.740
So the first thing you're going to
need to do is get your state right,

00:33:10.810 --> 00:33:13.680
and listed here is a number of
disables of things you need to

00:33:13.680 --> 00:33:16.730
have disabled before you will
be going down the fast path.

00:33:17.020 --> 00:33:18.760
Again,
don't worry about writing them down.

00:33:18.810 --> 00:33:20.870
We'll have a demo posted
that you can look at.

00:33:22.950 --> 00:33:25.850
Okay, so a little bit more code.

00:33:25.930 --> 00:33:26.990
DrawPixel is very basic, right?

00:33:27.010 --> 00:33:29.550
You disable some options
and you call DrawPixels.

00:33:29.730 --> 00:33:33.440
You feed it the right pixel format type,
like we talked about before,

00:33:33.530 --> 00:33:37.160
that will be a format that the
hardware natively understands,

00:33:37.180 --> 00:33:39.240
and you give it the
image and off it goes.

00:33:39.260 --> 00:33:44.210
Okay, we're gonna do another demo,
please.

00:33:51.760 --> 00:33:53.480
- Quit it and relaunch it here.

00:33:53.700 --> 00:33:56.750
Okay, so first thing I'm gonna do

00:33:57.710 --> 00:34:00.080
This is a little bit strange,
but I got an infinite button,

00:34:00.130 --> 00:34:03.150
and that infinite button
is to sit in a... Yeah,

00:34:03.170 --> 00:34:03.920
it doesn't really go infinite.

00:34:03.920 --> 00:34:07.620
It's going to sit in a for loop,
and it's going to beat on it really hard,

00:34:07.620 --> 00:34:10.560
because it goes so fast that just running
through an event loop is too slow.

00:34:10.670 --> 00:34:13.610
So it sits in a for loop really
fast and bangs on it really hard.

00:34:13.640 --> 00:34:15.780
And I reduced the image size two by two.

00:34:15.780 --> 00:34:19.780
Now, most of you don't see that,
but the key point here is how fast can we

00:34:19.780 --> 00:34:22.380
really get through the stack to OpenGL?

00:34:22.380 --> 00:34:26.600
And we can get 660,000 of these
little images up to the screen.

00:34:27.130 --> 00:34:29.440
So you can get a lot of little
things up to the screen.

00:34:29.440 --> 00:34:32.210
And that's one of the things to remember,
because other paths through the

00:34:32.210 --> 00:34:34.930
system may have more per-function
call overhead and limit you

00:34:34.930 --> 00:34:37.990
not because of the pixel data,
but because of what you have

00:34:37.990 --> 00:34:39.620
to do to get through OpenGL.

00:34:39.620 --> 00:34:42.540
So that's the benefit of DropPixels,
is it has a low per-function call

00:34:42.600 --> 00:34:46.360
overhead and can get lots of little
small things up to the screen.

00:34:46.360 --> 00:34:50.140
So if I start increasing
the size of these... Sorry,

00:34:50.140 --> 00:34:51.430
I wanted to go a little
smaller than that.

00:34:51.580 --> 00:34:55.300
So here's a 75 by 75 image.

00:34:56.540 --> 00:34:58.400
Megabytes per second is
about 400 megabytes a second.

00:34:58.400 --> 00:35:02.440
Believe it or not,
I'm already memory bottlenecked here.

00:35:02.460 --> 00:35:07.250
I'm basically saturated my memory,
and it's no longer function call

00:35:07.250 --> 00:35:09.640
overhead that's stopping me.

00:35:09.640 --> 00:35:10.400
It's memory bandwidth.

00:35:10.400 --> 00:35:13.430
Obviously, with the G5,
these numbers all change

00:35:13.430 --> 00:35:15.360
because these go much faster.

00:35:15.360 --> 00:35:19.980
And that's actually another trick,
is how to tune for the different systems.

00:35:20.020 --> 00:35:21.990
It can be a delicate job.

00:35:22.000 --> 00:35:24.790
So if you start increasing
the size of this,

00:35:24.790 --> 00:35:30.020
we quickly... run into... some
rather slower frame rates,

00:35:30.020 --> 00:35:30.690
right?

00:35:30.720 --> 00:35:32.990
So now we're down to... We're
still at 400 megabytes a second.

00:35:33.000 --> 00:35:34.700
So we have bottlenecked the memory bus.

00:35:34.700 --> 00:35:35.820
We are just flat-lined now.

00:35:35.820 --> 00:35:39.500
And as I increase the number of pixels,
I will proportionally decrease

00:35:39.550 --> 00:35:42.640
the frame rate because I am
400 megabytes a second limited.

00:35:42.640 --> 00:35:44.020
That's all I can get through the system.

00:35:44.020 --> 00:35:45.020
That's my limiting factor.

00:35:45.020 --> 00:35:46.520
So as I increase it, I go slower.

00:35:46.520 --> 00:35:49.080
And that's why when you
get to larger images,

00:35:49.080 --> 00:35:52.900
it's better to relieve the memory bus of
that work and go down the texture path.

00:35:52.900 --> 00:35:55.640
But for small images,
DropPixels is great.

00:35:56.710 --> 00:35:59.740
Okay, back to slides, please.

00:36:01.190 --> 00:36:04.350
Okay, optimizing pixel copy operations.

00:36:04.350 --> 00:36:09.180
So, there's a lot of cases where
you want to draw something,

00:36:09.350 --> 00:36:11.850
save it off,
and then you want to be able to

00:36:11.970 --> 00:36:16.100
grab a saved copy and blit it
back to maybe your back buffer,

00:36:16.100 --> 00:36:20.780
use it for some part of your scene,
and you want to render it and save it.

00:36:21.100 --> 00:36:23.700
So, one of the things you can use
to do that is copy pixels.

00:36:23.780 --> 00:36:26.200
So, copy pixels will allow you
to do a VRAM to VRAM copy.

00:36:26.230 --> 00:36:30.120
It's like drop pixels where you're going
to have to set up your state correctly.

00:36:30.120 --> 00:36:34.560
One area you can store the
data is in an auxiliary buffer.

00:36:34.560 --> 00:36:38.500
So, on OS X,
you can create auxiliary buffers.

00:36:38.500 --> 00:36:41.430
An auxiliary buffer is
just another back buffer.

00:36:41.430 --> 00:36:44.590
So, if you have your main back buffer,
you can create another one off to

00:36:44.590 --> 00:36:47.980
the side and use that as a temporary
holding area for copying data into.

00:36:47.980 --> 00:36:50.940
You can either draw to it directly or you
can copy data between your back buffers.

00:36:51.100 --> 00:36:52.280
So, you can have a back buffer
and this auxiliary buffer.

00:36:52.280 --> 00:36:55.650
One additional extension that
we have that allows some more

00:36:56.230 --> 00:36:58.970
flexibility is the aux depth stencil,
which not only will it

00:36:59.070 --> 00:37:01.090
create the back buffer,
but it'll also create the

00:37:01.150 --> 00:37:03.940
depth and stencil buffers
associated with that back buffer.

00:37:03.940 --> 00:37:07.060
So, you can have two depth buffers,
two stencil buffers,

00:37:07.060 --> 00:37:11.170
and therefore you can copy your not only
color data between these aux buffers,

00:37:11.240 --> 00:37:14.900
but you can copy depth and stencil
data and use it as a temporary holding

00:37:14.900 --> 00:37:17.200
area for fast refresh of some pixels.

00:37:17.200 --> 00:37:19.490
So, there's a number of techniques
that people use for interacting

00:37:19.870 --> 00:37:21.080
with very complex objects.

00:37:21.100 --> 00:37:21.500
So, there's a number of techniques
that people use for interacting

00:37:21.570 --> 00:37:21.920
with very complex geometry.

00:37:21.920 --> 00:37:24.190
That becomes an important technique.

00:37:24.240 --> 00:37:27.130
So, like draw pixels,
there are certain states that you'll

00:37:27.200 --> 00:37:29.120
need to have right to make it go fast.

00:37:29.190 --> 00:37:31.550
It's very similar to draw pixel state.

00:37:31.600 --> 00:37:35.010
And basically,
what you don't want to be doing is

00:37:35.060 --> 00:37:40.070
you don't want to be trying to dither
or alpha test or blend or things.

00:37:40.080 --> 00:37:42.600
Basically, what it comes down to,
you don't want to do anything that can't

00:37:42.600 --> 00:37:43.940
be done by the 2D engine on the GPU.

00:37:43.940 --> 00:37:46.940
Because this is a 2D operation
and we need to be able to stick

00:37:47.050 --> 00:37:50.400
within the feature set of the 2D
pipeline on the graphics card.

00:37:50.400 --> 00:37:50.430
So, you can have a 2D pipeline
on the graphics card.

00:37:51.100 --> 00:37:52.300
So,
you need to disable all the operations

00:37:52.360 --> 00:37:53.410
that require the 3D pipeline.

00:37:53.420 --> 00:37:55.910
3D pipeline is not
going to be as optimal.

00:37:55.920 --> 00:37:57.820
It's just a memory copy that
you can do through the 2D pipe.

00:37:57.840 --> 00:38:01.620
So, there's a number of states
that you want to disable.

00:38:01.620 --> 00:38:06.320
And you can look at the draw
pixels example for what state.

00:38:06.340 --> 00:38:07.060
It's very similar.

00:38:09.830 --> 00:38:12.240
Okay, so looking at some sample code.

00:38:12.390 --> 00:38:12.810
Very basic.

00:38:13.120 --> 00:38:17.250
We have the standard
disable the write state,

00:38:17.310 --> 00:38:19.660
so you can go down the fast path,
and then when you go to draw,

00:38:19.660 --> 00:38:21.880
you're going to want to set your
read buffer and your draw buffer.

00:38:21.880 --> 00:38:23.340
It's just a source and destination.

00:38:23.340 --> 00:38:26.260
Source and destination can be any
of the buffers you have allocated,

00:38:26.260 --> 00:38:29.170
whether it's the back buffer,
aux buffer 1, 2, what have you,

00:38:29.170 --> 00:38:30.730
and you can copy between those two.

00:38:30.730 --> 00:38:33.140
Then you issue your copy pixels,
and the transfer will be

00:38:33.140 --> 00:38:34.520
a VRAM to VRAM transfer.

00:38:36.970 --> 00:38:40.980
Okay, so let's jump into using
threads with OpenGL.

00:38:41.170 --> 00:38:43.840
So let's go over first the rules
for using threads with OpenGL,

00:38:44.310 --> 00:38:46.570
and then we'll talk about some
possible ways to divide up your

00:38:46.650 --> 00:38:48.160
work onto multiple threads.

00:38:48.180 --> 00:38:51.030
And then we'll talk about what
data you can share between

00:38:51.030 --> 00:38:54.660
those different threads,
and how to synchronize those threads.

00:38:57.170 --> 00:38:57.900
So rules for threading.

00:38:57.900 --> 00:39:01.120
What you can't do is
per thread re-entrance,

00:39:01.160 --> 00:39:02.550
per context re-entrance.

00:39:02.590 --> 00:39:05.080
So if you have an OpenGL context
and you have two threads,

00:39:05.140 --> 00:39:07.920
only one of those threads
can be in OpenGL referencing

00:39:08.480 --> 00:39:09.890
that context at a time.

00:39:09.900 --> 00:39:13.190
If both threads are in
OpenGL with that same context,

00:39:13.300 --> 00:39:17.060
you're going to cause corruption
in your OpenGL state and all

00:39:17.100 --> 00:39:19.360
kinds of bad things can happen.

00:39:19.360 --> 00:39:23.920
What you can do is you can share
context state across threads and you

00:39:23.920 --> 00:39:26.720
can share surfaces across contexts.

00:39:27.100 --> 00:39:30.690
And I'll show some diagrams of how
that can be put together to help

00:39:30.820 --> 00:39:32.780
you with threaded applications.

00:39:32.780 --> 00:39:35.240
Okay, so divisions of work.

00:39:35.470 --> 00:39:39.290
One possible division of work is to move
OpenGL as a whole onto a separate thread.

00:39:39.300 --> 00:39:40.880
This is like what Quake 3 does.

00:39:40.880 --> 00:39:43.620
Quake 3 moves OpenGL onto one
thread and has a bunch of other

00:39:43.620 --> 00:39:46.600
CPU work for the game logic and
other work on the other thread.

00:39:46.620 --> 00:39:49.490
And it's a reasonable division
of work that's easy to manage.

00:39:49.500 --> 00:39:54.190
Other more complex ways to divide
your work are to potentially

00:39:54.190 --> 00:39:58.100
split your texture work with
your general... geometry work.

00:39:58.190 --> 00:40:00.810
So you may have texture data that's
getting spooled off of a disk.

00:40:00.980 --> 00:40:04.950
You may have another thread that's
doing other work for the application,

00:40:05.090 --> 00:40:08.880
but then it comes along and uses geometry
to utilize those textures for drawing.

00:40:08.980 --> 00:40:13.350
Another possible way to divide
the work is to split your output,

00:40:13.350 --> 00:40:14.440
your surface.

00:40:14.640 --> 00:40:18.350
And when I say a surface,
I mean the OpenGL back buffer

00:40:18.430 --> 00:40:21.590
is basically the surface of
the piece of memory in video

00:40:21.590 --> 00:40:23.310
memory that you're drawing to.

00:40:23.380 --> 00:40:24.400
So that's what we call surface.

00:40:24.500 --> 00:40:26.850
So you can split the
processing of a surface.

00:40:26.860 --> 00:40:30.570
So let's say you want that you
can have your CPU work be divided

00:40:30.570 --> 00:40:33.540
amongst regions in the surface.

00:40:33.560 --> 00:40:37.390
Then it might be beneficial to split
those onto separate threads and leverage

00:40:37.390 --> 00:40:39.490
both CPUs to get that work done.

00:40:39.960 --> 00:40:41.630
Okay, so sharing data between contexts.

00:40:41.670 --> 00:40:43.700
What gets shared?

00:40:43.700 --> 00:40:47.430
So when you share two contexts,
when two contexts are sharing state,

00:40:47.490 --> 00:40:50.260
the things that get
shared are display lists,

00:40:50.260 --> 00:40:54.670
textures, vertex array objects,
and vertex and fragment programs.

00:40:54.700 --> 00:40:57.630
So those are the things that get shared,
and those are really all objects.

00:40:57.700 --> 00:41:00.800
Those are things that usually have a
bind and some name associated with them,

00:41:00.940 --> 00:41:03.240
and those things are the
shared items between OpenGL.

00:41:03.240 --> 00:41:07.270
There's lots of other state in an
OpenGL context that does not get shared,

00:41:07.270 --> 00:41:10.910
and those are going to be per context,
even if you've set these

00:41:10.960 --> 00:41:12.600
contexts up to share that state.

00:41:12.620 --> 00:41:16.560
So you can share,
like I briefly touched on before,

00:41:16.680 --> 00:41:19.900
you can share a surface between contexts.

00:41:19.950 --> 00:41:22.280
So you can have two contexts,
multiple contexts,

00:41:22.280 --> 00:41:24.920
drawing to the same surface.

00:41:24.920 --> 00:41:29.170
And that's another way
to have sharing of data.

00:41:29.180 --> 00:41:31.480
Okay,
so let's look at some of the diagrams

00:41:31.540 --> 00:41:35.260
of how to divide up your work and
move it onto different threads.

00:41:35.280 --> 00:41:38.980
So here's the first example of just
moving OpenGL on a separate thread.

00:41:38.980 --> 00:41:39.700
Very basic.

00:41:39.800 --> 00:41:41.940
You have one thread doing
work for the application.

00:41:41.940 --> 00:41:44.340
You have another thread
that's driving OpenGL.

00:41:44.340 --> 00:41:47.920
So thread one is generating data
that is used for input to thread

00:41:47.920 --> 00:41:51.820
two to draw into the OpenGL context,
which goes to the surface,

00:41:51.820 --> 00:41:53.280
which gets swapped to the frame buffer.

00:41:55.980 --> 00:41:58.360
Okay,
you can split your texture and vertex

00:41:58.360 --> 00:42:01.410
processing onto different threads,
different contexts.

00:42:01.410 --> 00:42:04.360
So you can have two threads,
two OpenGL contexts.

00:42:04.500 --> 00:42:07.750
They're sharing the same,
some of the same state, right?

00:42:07.820 --> 00:42:09.540
They have shared state,
and they're going to be

00:42:09.540 --> 00:42:10.840
attached to the same surface.

00:42:11.560 --> 00:42:15.740
And what you can do is you can have
asynchronous processing between the two,

00:42:15.740 --> 00:42:19.160
where you can have one thread
spooling data from a disk,

00:42:19.180 --> 00:42:23.570
say, decompressing JPEGs,
decompressing a movie, what have you,

00:42:24.000 --> 00:42:25.940
reading that data,
those textures into the

00:42:25.940 --> 00:42:28.210
OpenGL state machine,
and then having the

00:42:28.210 --> 00:42:32.160
other thread come along,
referencing those textures and drawing.

00:42:32.160 --> 00:42:35.820
So that's a way to split your workload if
you have spooling or some kind of work to

00:42:35.920 --> 00:42:38.220
do with imaging that you want to offload.

00:42:39.810 --> 00:42:42.660
Another possibility, then,
is to use our new API for P-buffers,

00:42:42.740 --> 00:42:45.930
where you're not reading, say, the data,
but you're using geometry

00:42:45.930 --> 00:42:46.940
to generate a texture.

00:42:46.940 --> 00:42:49.710
You're using some geometry
to draw into a P-buffer,

00:42:49.710 --> 00:42:51.280
which is in video memory.

00:42:51.280 --> 00:42:55.120
That, then, is used as a texture,
which is then referenced

00:42:55.120 --> 00:42:58.070
by Thread1's context,
which then is drawn,

00:42:58.180 --> 00:43:01.870
which then goes to the surface
and to the frame buffer.

00:43:03.330 --> 00:43:07.840
So, just to be clear now,
the only difference between

00:43:07.840 --> 00:43:10.440
these two examples is that one,
we're dynamically, this example,

00:43:10.440 --> 00:43:13.130
we're dynamically creating
the surface by drawing to it,

00:43:13.200 --> 00:43:14.410
the texture by drawing to it.

00:43:14.670 --> 00:43:17.260
Previous example,
we were basically loading a

00:43:17.260 --> 00:43:19.360
texture through the OpenGL API.

00:43:20.210 --> 00:43:25.060
Okay, so we can also split the
OpenGL processing of a surface,

00:43:25.060 --> 00:43:25.560
right?

00:43:25.560 --> 00:43:30.080
So we can take the surface and we can
split it across some line and use one

00:43:30.080 --> 00:43:34.720
OpenGL context to render one part of it
and an OpenGL context to render another.

00:43:35.650 --> 00:43:39.410
And where this might be beneficial is
if you're CPU bound and your CPU work

00:43:39.500 --> 00:43:44.390
could be regionally divided along some
portion of the screen real estate,

00:43:44.400 --> 00:43:46.660
where you have a lot of work
to do geometric calculations or

00:43:46.680 --> 00:43:49.010
what have you in one portion,
you can split that across

00:43:49.140 --> 00:43:52.170
two CPUs and divide your work
across regions of the surface.

00:43:52.180 --> 00:43:54.920
So one way to do that is
to just create two threads,

00:43:55.140 --> 00:43:57.710
two OpenGL contexts,
not have the state shared,

00:43:57.710 --> 00:44:00.350
and they're just open
loop drawing to a surface,

00:44:00.420 --> 00:44:03.100
but they're drawing to different regions.

00:44:03.100 --> 00:44:04.880
Now the way you separate
what regions they draw to,

00:44:04.880 --> 00:44:05.620
you can use OpenGL.

00:44:05.620 --> 00:44:07.220
You can use a scissor and a viewport.

00:44:07.220 --> 00:44:09.200
So you can just set the
scissor and the viewport to

00:44:09.270 --> 00:44:11.670
the region you want to control,
and with a scissor rack,

00:44:11.670 --> 00:44:13.300
the pixels will not come out of that.

00:44:13.450 --> 00:44:16.990
So you can just set it to one half
for one context and one half for the

00:44:16.990 --> 00:44:20.980
other context and allow the drawing
to be open loop to that surface.

00:44:21.000 --> 00:44:22.270
Okay.

00:44:23.010 --> 00:44:26.450
Or, if your application wanted to,
you could just share state.

00:44:26.660 --> 00:44:28.260
There's no reason you
couldn't be sharing state.

00:44:28.320 --> 00:44:31.760
Same basic concept,
just that they're sharing

00:44:31.960 --> 00:44:36.390
possibly geometry,
programs, textures, to do their work of

00:44:36.390 --> 00:44:38.700
drawing into the surface.

00:44:41.320 --> 00:44:45.280
Okay, so how do we set up
OpenGL shared context?

00:44:45.280 --> 00:44:50.320
So here's a little bit of sample code
to show how we would create a context,

00:44:50.320 --> 00:44:52.780
attach another context to
it as a shared context.

00:44:52.810 --> 00:44:58.810
So this example assumes that you've
already created an OpenGL view through,

00:44:58.810 --> 00:45:03.540
say, AppKit, and now you come to, say,
your NIT frame,

00:45:03.540 --> 00:45:08.040
and all you're going to do is
create an NSOpenGL context.

00:45:08.880 --> 00:45:11.250
And you can see we're
creating NSOpenGL context,

00:45:11.380 --> 00:45:14.160
ALEC, and then we come along and
we do a NIT with format,

00:45:14.160 --> 00:45:17.090
and we're going to take self,
the format from self.

00:45:17.270 --> 00:45:20.080
So we're inside of a, the creation of a,
of a context,

00:45:20.110 --> 00:45:23.880
or in a view already that has a context,
so we're just going to take the

00:45:23.880 --> 00:45:27.730
pixel format out of that context,
and we're going to use it as the

00:45:27.740 --> 00:45:31.790
pixel format to create a new context,
and we're going to provide the

00:45:31.900 --> 00:45:35.340
current view's OpenGL context
as the shared context.

00:45:35.360 --> 00:45:36.720
So we're going to create a new context.

00:45:36.720 --> 00:45:42.340
We're going to, create,
and when we attach it, or I'm sorry,

00:45:42.340 --> 00:45:44.460
when we create it,
we're going to hand in the pixel

00:45:44.460 --> 00:45:48.110
format and the already created
context for sharing against the state,

00:45:48.140 --> 00:45:51.440
and that's all you need to do to
make sure that the two are connected.

00:45:51.440 --> 00:45:57.080
And the key line here then would be the
self OpenGL context on the third line,

00:45:57.080 --> 00:46:00.360
which hands the new context,
the previously created

00:46:00.360 --> 00:46:01.300
context for our sharing.

00:46:01.300 --> 00:46:06.240
Okay, then the next two are fairly
standard OpenGL concepts where you're

00:46:06.240 --> 00:46:10.540
just making the current context,
you're attaching it to the view.

00:46:11.010 --> 00:46:14.430
So one small deviation on that, then,
is that if we wanted to have

00:46:14.850 --> 00:46:17.680
two contexts that talk to a
surface but don't share state,

00:46:17.760 --> 00:46:23.880
instead of passing in the already created
context into the newly created context,

00:46:23.880 --> 00:46:26.840
we just pass nil,
but we attach it to the same view.

00:46:26.840 --> 00:46:29.210
So we're creating two
independent contexts,

00:46:29.210 --> 00:46:32.180
we're attaching it to the same view,
that will allow them to

00:46:32.280 --> 00:46:35.560
talk to the same surface,
but be independent as far as state.

00:46:39.760 --> 00:46:41.120
Okay, thread synchronization.

00:46:41.120 --> 00:46:43.940
The main tool you'll have
for thread synchronization,

00:46:43.970 --> 00:46:46.960
obviously, is going to be the
OS tools that are provided,

00:46:46.960 --> 00:46:47.860
the OS APIs.

00:46:47.860 --> 00:46:50.680
So you'll have NSThread and NSLock.

00:46:50.760 --> 00:46:53.330
Those are going to be what
you'll mostly need to leverage.

00:46:53.480 --> 00:46:56.690
There is one interesting API that
you'll want to be familiar with,

00:46:56.720 --> 00:46:58.080
which is NSAppleFence.

00:46:58.080 --> 00:47:01.560
AppleFence is a way to insert tokens
into the OpenGL command stream and

00:47:01.700 --> 00:47:03.550
then to test when they're done.

00:47:03.560 --> 00:47:06.500
So I can do a set fence and I can
test when that token I've inserted

00:47:06.980 --> 00:47:10.080
into the OpenGL command stream
has gone through the GPU and made

00:47:10.080 --> 00:47:11.960
a round trip and is completed.

00:47:11.960 --> 00:47:16.030
So there's ways to test when
portions of your drawing are done,

00:47:16.030 --> 00:47:19.800
and that's another way to
potentially synchronize events

00:47:19.800 --> 00:47:21.950
within your OpenGL commands.

00:47:23.710 --> 00:47:29.170
So we'll look at a little bit
of sample code how to do that.

00:47:31.190 --> 00:47:33.940
Okay,
so there's two basic ways you can do it.

00:47:34.110 --> 00:47:37.020
You can do it with the set fence,
which you can see here on the

00:47:37.020 --> 00:47:40.230
first little piece of sample code,
which is I'm setting a fence,

00:47:40.260 --> 00:47:41.440
and I'm giving it a name.

00:47:41.440 --> 00:47:44.310
So I can give it any name I want,
and you can set that token

00:47:44.310 --> 00:47:47.270
into the OpenGL command stream,
and then do some work and

00:47:47.270 --> 00:47:49.150
later test to see if it's done.

00:47:49.160 --> 00:47:52.440
So you would do a finish fence apple,
and that call will block

00:47:52.440 --> 00:47:54.360
until that token is completed.

00:47:56.390 --> 00:47:58.050
There's another simpler API.

00:47:58.100 --> 00:48:02.200
If you're wanting to block against
a texture upload being completed,

00:48:02.210 --> 00:48:06.260
or a draw against a texture,
or a draw against a vertex array object,

00:48:06.470 --> 00:48:08.870
you can just simply test for that object.

00:48:08.870 --> 00:48:12.750
So what you do is you call finish object,
and finish object apple,

00:48:12.790 --> 00:48:16.020
and what you do is you pass it
in the type of target you're

00:48:16.020 --> 00:48:18.930
wanting to look against,
or check against.

00:48:19.070 --> 00:48:23.190
So you may have a GL texture or
a GL vertex array as the type,

00:48:23.190 --> 00:48:26.160
and again, you pass in the ID number,
and you can see that

00:48:26.160 --> 00:48:26.160
it's a GL vertex array.

00:48:26.180 --> 00:48:31.410
So that'll be an ID number that
you use to create or bind to the

00:48:31.410 --> 00:48:34.480
texture or vertex array object.

00:48:36.700 --> 00:48:38.780
Okay,
so let's do a little bit of a demo again.

00:48:38.780 --> 00:48:41.920
And this one is going to be
the same demo we did before,

00:48:41.920 --> 00:48:46.630
but what we didn't show before is we
have a multi-threaded button at the top.

00:48:46.650 --> 00:48:49.040
And I want to talk a
little bit about that.

00:48:49.210 --> 00:48:52.620
So, if we enable multi-threading,
we can see that we went from

00:48:52.620 --> 00:48:57.820
800,000 triangles a second to
1.5 million triangles a second.

00:48:57.820 --> 00:49:00.840
So, we got pretty good parallelization,
right?

00:49:00.840 --> 00:49:05.140
We almost got a 2x speed improvement
just by doing multi-threading.

00:49:05.480 --> 00:49:06.740
So, that was pretty worthwhile.

00:49:06.770 --> 00:49:07.980
And you can see the CPU monitor.

00:49:07.980 --> 00:49:09.450
We're working two CPUs pretty hard.

00:49:09.450 --> 00:49:12.280
Now, what's interesting about
this is if I increase the

00:49:12.280 --> 00:49:15.520
optimization level of OpenGL,
if you look at the performance,

00:49:15.520 --> 00:49:17.420
it's not doing a whole lot, right?

00:49:17.420 --> 00:49:20.140
Well,
the problem is that the workload for

00:49:20.220 --> 00:49:23.520
calculating the wave is the bottleneck,
right?

00:49:23.520 --> 00:49:25.690
The drawing of the OpenGL is not.

00:49:25.800 --> 00:49:29.890
So, we're not going to gain by
improving OpenGL because the wave

00:49:30.030 --> 00:49:32.370
calculation is the bottleneck.

00:49:34.460 --> 00:49:36.670
So, with the vertex array
range in the Altevec,

00:49:36.670 --> 00:49:39.870
now we've again removed the
bottleneck of the wave calculation.

00:49:39.870 --> 00:49:42.390
Now, multi-threading is paying off,
right?

00:49:42.390 --> 00:49:49.340
So, now we're getting the 10.5 million
triangles a second as opposed to the 8.5.

00:49:49.360 --> 00:49:55.030
So, it's not 2x because, as you can see,
even with Altevec, the wave calculation,

00:49:55.030 --> 00:49:59.240
which is represented by the green,
is still significantly more

00:49:59.240 --> 00:50:02.120
expensive than the OpenGL drawing.

00:50:03.240 --> 00:50:07.610
So, we're going to get some benefit
by moving the system and the

00:50:07.610 --> 00:50:10.520
OpenGL drawing off to another thread.

00:50:10.520 --> 00:50:15.300
Okay, back to the slides, please.

00:50:19.470 --> 00:50:21.430
Let's go into an important
subject that we wanted to

00:50:21.430 --> 00:50:22.670
spend quite a bit of time on.

00:50:22.710 --> 00:50:24.220
It's the OpenGL Profiler.

00:50:24.220 --> 00:50:26.120
It's a tool that comes
with the developer CD.

00:50:26.120 --> 00:50:28.140
It's a very powerful tool.

00:50:28.140 --> 00:50:31.530
It does have a lot of features,
and it will take a little bit of learning

00:50:31.530 --> 00:50:34.000
to understand how to use it effectively.

00:50:34.000 --> 00:50:37.870
What you can use it for is optimizing,
debugging, and experimenting with

00:50:37.870 --> 00:50:39.420
your OpenGL application.

00:50:39.440 --> 00:50:41.820
There's a lot of
different features in it,

00:50:41.820 --> 00:50:44.520
so the Profiler is a bit
of a restricted name.

00:50:44.520 --> 00:50:45.920
It does a lot more than just profile.

00:50:47.850 --> 00:50:50.610
Let's go through some of the
screens and have a brief overview

00:50:50.610 --> 00:50:52.520
of what the Profiler can do for you.

00:50:52.560 --> 00:50:54.960
First, the OpenGL Profiler,
like some of the other

00:50:54.960 --> 00:50:56.910
tools in the system,
you can have it launch

00:50:56.930 --> 00:50:58.330
your application for you.

00:50:58.350 --> 00:51:01.950
It will launch and basically
attach to your application,

00:51:01.950 --> 00:51:04.860
or you can attach to
a running application.

00:51:04.860 --> 00:51:07.780
If you already have an
OpenGL application running,

00:51:07.850 --> 00:51:11.250
you can just attach to it and
start utilizing the services of the

00:51:11.470 --> 00:51:15.540
Profiler just by simply attaching
to a pre-running application.

00:51:15.960 --> 00:51:20.490
One of the services it provides is it
will provide function statistics for you.

00:51:20.750 --> 00:51:26.300
It will time in and out times of
all the OpenGL functions and provide

00:51:26.300 --> 00:51:32.040
you counts and percent times and
overall times spent in each function.

00:51:32.040 --> 00:51:34.090
This way,
you can quickly get an idea of which

00:51:34.090 --> 00:51:37.120
functions you're spending time in
OpenGL and quickly get an idea of

00:51:37.130 --> 00:51:38.810
how expensive those are for you.

00:51:40.560 --> 00:51:43.240
It'll generate,
you can capture call traces,

00:51:43.240 --> 00:51:45.960
so you can simply enable
call trace capture,

00:51:45.960 --> 00:51:49.780
and it'll capture all the OpenGL commands
and their arguments so that you can

00:51:49.790 --> 00:51:53.670
scroll through it and look what your
application is feeding OpenGL and

00:51:53.720 --> 00:51:55.720
get an idea of the call sequence.

00:51:58.170 --> 00:52:01.740
It will capture textures, vertex,
and pixel programs.

00:52:01.740 --> 00:52:04.710
So you can actually run your
program and it will capture all

00:52:04.710 --> 00:52:06.720
the textures that you've passed in.

00:52:06.720 --> 00:52:09.910
It will capture the pixel
programs and vertex programs.

00:52:09.910 --> 00:52:14.140
You can look at those and you can see,
make sure that you've got the textures

00:52:14.140 --> 00:52:17.990
you think you have loaded under
the right names or what have you.

00:52:19.850 --> 00:52:21.940
You can set breakpoints.

00:52:21.990 --> 00:52:24.710
So you can go to an
OpenGL function and you can say,

00:52:24.710 --> 00:52:25.800
I want a break here.

00:52:25.800 --> 00:52:30.790
And at that breakpoint,
it will give you application call stack.

00:52:30.930 --> 00:52:34.040
So you can see what your application
call stack was at that point.

00:52:34.090 --> 00:52:37.480
It'll also give you a complete
listing of the OpenGL state.

00:52:37.630 --> 00:52:40.510
So you can sit there and thumb
through the OpenGL state,

00:52:40.630 --> 00:52:44.750
make sure that at that breakpoint,
the state is what you expected it to be.

00:52:45.890 --> 00:52:48.850
It'll also, at a breakpoint,
let you look at the off-screen buffers.

00:52:48.850 --> 00:52:52.540
So it'll let you look at the back buffer,
depth buffer, stencil, alpha buffer,

00:52:52.540 --> 00:52:56.210
and you can look at it at any
point you can set a breakpoint.

00:52:58.910 --> 00:53:01.560
It'll let you write scripts
and execute OpenGL commands.

00:53:01.570 --> 00:53:05.100
So at a breakpoint, you can type in an
OpenGL command and say,

00:53:05.100 --> 00:53:06.680
well, I think that state's wrong.

00:53:06.680 --> 00:53:07.780
I'll modify it right here.

00:53:07.780 --> 00:53:10.910
Type an OpenGL command, hit execute,
and it'll poke that OpenGL command

00:53:11.030 --> 00:53:14.070
right into your application and
change some OpenGL state for you.

00:53:14.620 --> 00:53:18.240
So one useful thing for this, then,
is going to be debugging.

00:53:18.240 --> 00:53:21.390
If you think that you've got
a bug in your state setup,

00:53:21.390 --> 00:53:23.220
you can modify it on the fly.

00:53:23.220 --> 00:53:26.550
Scripts can be attached to breakpoints,
so they can be auto-executed if

00:53:26.550 --> 00:53:29.640
you wanted it to be executed every
time a breakpoint came along.

00:53:31.350 --> 00:53:34.140
The OpenGL Driver Monitor,
another powerful tool.

00:53:34.140 --> 00:53:37.960
What this does is it attaches to the
driver itself and starts collecting

00:53:38.040 --> 00:53:40.120
stats out of your graphics driver.

00:53:40.120 --> 00:53:42.510
There's a number of
parameters you can monitor,

00:53:42.710 --> 00:53:45.030
like video memory usage,
hardware wait times,

00:53:45.030 --> 00:53:48.480
so you can watch to see if the
CPU is stalled against the hardware.

00:53:48.480 --> 00:53:50.740
You can watch what kind of stall it is.

00:53:50.840 --> 00:53:54.050
It breaks down into many different
categories of why the CPU may

00:53:54.120 --> 00:53:55.880
be blocked up against the GPU.

00:53:55.880 --> 00:53:57.750
You can try to monitor those.

00:53:58.500 --> 00:54:01.020
You can look at bandwidth
usage of how much data you're

00:54:01.020 --> 00:54:03.410
getting through the system,
so it'll track bytes per

00:54:03.560 --> 00:54:05.080
second through the system.

00:54:05.080 --> 00:54:06.890
So there's a whole bunch of useful stats.

00:54:06.930 --> 00:54:11.170
It takes a little bit of studying
this tool to get useful data out of

00:54:11.320 --> 00:54:13.820
it because it is somewhat complex.

00:54:13.820 --> 00:54:16.480
So we'll go through a little
bit of that in one of our demos.

00:54:16.480 --> 00:54:19.290
So why don't we switch to the
demo machine and let's do that.

00:54:27.690 --> 00:54:30.580
So, quickly here,
before we go any further,

00:54:30.580 --> 00:54:35.400
screenshots I didn't show,
you can also customize your pixel format.

00:54:35.400 --> 00:54:38.880
So, for instance, if I wanted to make a
custom pixel format,

00:54:38.880 --> 00:54:41.980
I can come in here and change
my pixel format attributes

00:54:41.980 --> 00:54:43.860
that the application uses.

00:54:43.860 --> 00:54:45.750
So,
if you have a pre-compiled application,

00:54:45.780 --> 00:54:49.140
you can modify your pixel formats on the
fly without having to recompile them.

00:54:50.380 --> 00:54:53.060
What you can also do is
you can emulate hardware.

00:54:53.090 --> 00:54:56.820
Now, when I say emulate, yeah, it's neat,
but I'm going to give

00:54:56.820 --> 00:54:58.440
you the bad part now.

00:55:00.630 --> 00:55:02.670
All it really does is deprecate
your current hardware to

00:55:02.990 --> 00:55:05.680
some less capable hardware.

00:55:06.520 --> 00:55:11.080
So, for instance,
if I'm running an R300 like I am here,

00:55:11.080 --> 00:55:15.300
and I wanted this hardware to look
to the application like a RAGE 128,

00:55:15.300 --> 00:55:20.830
I could say,
choose driver RAGE 128 that got released,

00:55:20.830 --> 00:55:22.820
the same feature set
that got released in,

00:55:22.820 --> 00:55:24.120
say, OS 10.3.

00:55:24.590 --> 00:55:28.500
And any time your application would
come along and make a query into

00:55:28.500 --> 00:55:32.150
OpenGL for some kind of capability,
like an extension,

00:55:32.190 --> 00:55:36.270
some kind of min-max values,
the driver will return a value

00:55:36.270 --> 00:55:38.100
that looks like a RAGE 128.

00:55:38.100 --> 00:55:41.880
So, if your application is coded
correctly to respect extension

00:55:42.270 --> 00:55:46.470
strings and values that are queryable,
it's a powerful utility for

00:55:46.540 --> 00:55:50.960
making your application think
it's running on a RAGE 128.

00:55:53.140 --> 00:55:55.080
This was actually a feature
request from last WWDC.

00:55:55.080 --> 00:55:57.030
So we got it in there.

00:55:57.040 --> 00:56:03.070
Okay, so I contrived an application,
a slight variation of the texture

00:56:03.070 --> 00:56:04.260
range demo I showed before.

00:56:04.260 --> 00:56:08.240
And what I did is I did
what I said not to do,

00:56:08.240 --> 00:56:09.620
and I stuck a GL finish in there.

00:56:09.620 --> 00:56:13.240
So first thing we're going to do is
we're going to look at the statistics

00:56:13.240 --> 00:56:15.120
that this thing's collecting.

00:56:16.070 --> 00:56:17.120
So what do we see?

00:56:17.120 --> 00:56:23.610
We see GL finish is taking 82%
of the percent time in GL and

00:56:23.620 --> 00:56:25.060
40% of the application time.

00:56:25.080 --> 00:56:28.190
So a couple values,
let's go over the screen real quick,

00:56:28.260 --> 00:56:31.210
a couple values that are interesting
to look at when you pull the screen up.

00:56:31.250 --> 00:56:35.720
One is the number down here,
which I highlighted.

00:56:35.720 --> 00:56:38.940
That's the estimated
percent time spent in GL.

00:56:38.940 --> 00:56:42.090
So that will try to estimate
how much of the time,

00:56:42.090 --> 00:56:44.380
total time, is spent in OpenGL.

00:56:44.380 --> 00:56:46.740
So we can see we're spending
about 60%. So that's about 67%

00:56:46.750 --> 00:56:47.840
of the total time in OpenGL.

00:56:47.840 --> 00:56:52.420
Of that total time,
we're spending 55%, 56%

00:56:52.480 --> 00:56:54.390
of that in GL finish.

00:56:54.400 --> 00:57:00.130
So somebody's calling a synchronous call
GL finish and causing the application

00:57:00.130 --> 00:57:03.880
to stall and wait for the GPU to
flush the pipeline on that call.

00:57:03.880 --> 00:57:05.170
So here's what we're going to do.

00:57:05.180 --> 00:57:09.420
Since I don't like that call,
we're going to go in here and we're

00:57:09.420 --> 00:57:14.140
going to pull up the breakpoints window,
and we're going to get rid of it.

00:57:17.660 --> 00:57:18.940
So there's GeoFinish.

00:57:18.960 --> 00:57:20.840
You'll notice not only can
we set breakpoints before

00:57:20.840 --> 00:57:24.100
or after a function call,
but we can also stop executing functions.

00:57:24.100 --> 00:57:25.880
So I'm just going to
disable that function.

00:57:25.880 --> 00:57:28.820
This is a favorite tool at Apple,
by the way.

00:57:34.380 --> 00:57:37.460
When we catch applications doing things,
we'll just disable it, right?

00:57:37.460 --> 00:57:41.030
So now you can see that things
are looking a little better,

00:57:41.030 --> 00:57:41.660
right?

00:57:41.660 --> 00:57:43.080
So now we got rid of the GL finish.

00:57:43.080 --> 00:57:46.160
Now we're only spending
24% of the time in OpenGL.

00:57:46.160 --> 00:57:48.100
We're not spending the
65% that we were before.

00:57:48.100 --> 00:57:50.800
We are spending the time
where we want to be.

00:57:50.800 --> 00:57:54.830
We're spending it basically in GL begin,
where some real work is going on of

00:57:54.900 --> 00:57:56.000
getting the data up to the system.

00:57:56.000 --> 00:57:59.300
And things look good.

00:57:59.510 --> 00:58:03.010
Now, I talked before about double
buffering and the importance of double

00:58:03.060 --> 00:58:04.340
buffering data stays asynchronous.

00:58:04.340 --> 00:58:08.700
Well, this application has the ability
to switch down to one buffer,

00:58:08.700 --> 00:58:09.500
right?

00:58:09.500 --> 00:58:13.030
So I can make it look like I'm
only feeding one buffer at a time.

00:58:13.040 --> 00:58:16.760
And you can see I'm stuck
on buffer on texture zero.

00:58:16.760 --> 00:58:19.120
So real quick, let's just see what the
performance impact is.

00:58:19.120 --> 00:58:21.900
So right here,
I'm at about 500 megabytes a second.

00:58:21.900 --> 00:58:26.940
If I'm at five, I'm at about 600,
sometimes 630 megabytes a second.

00:58:26.940 --> 00:58:29.570
So quite a performance
difference by stalling,

00:58:29.720 --> 00:58:34.340
having the hardware stall on the CPU,
having to prepare the next texture.

00:58:34.340 --> 00:58:38.340
So let's look at the difference of what
the call stats will show in this case.

00:58:38.340 --> 00:58:42.130
And what we're going to do is we're
going to pull up the driver monitor.

00:58:42.140 --> 00:58:43.860
So let's look at a couple
of things in conjunction.

00:58:43.860 --> 00:58:47.320
Okay.

00:58:50.880 --> 00:58:54.190
Okay, so quickly here,
let me move this back up a little bit.

00:58:54.320 --> 00:58:56.470
So what we're seeing here
on the driver monitor is we

00:58:56.470 --> 00:58:57.980
have three lines I'm drawing.

00:58:57.980 --> 00:59:00.670
I'm drawing the hardware
wait time in red,

00:59:00.670 --> 00:59:05.200
which represents the total time the
CPU is waiting for the hardware.

00:59:05.200 --> 00:59:07.890
And so anytime the CPU is
blocked up against the hardware,

00:59:07.890 --> 00:59:10.050
it's going to start
registering wait time.

00:59:11.060 --> 00:59:13.710
In the yellow,
I'm measuring texture page and bytes.

00:59:13.710 --> 00:59:16.870
So since this is a texture demo,
it's uploading lots of textures,

00:59:16.880 --> 00:59:20.020
I'm going to record the number of
bytes worth of textures per second

00:59:20.020 --> 00:59:21.840
I'm sending up to the hardware.

00:59:21.840 --> 00:59:27.590
And green is the swap complete wait time.

00:59:27.590 --> 00:59:29.290
Now, let's see what happens.

00:59:29.290 --> 00:59:32.280
We can see what the changes are
when I go through and go from

00:59:32.330 --> 00:59:35.870
single buffer to double buffer,
and we can watch the effect that has

00:59:35.870 --> 00:59:39.550
on some of the statistics and give you
a little bit of an idea of how to use

00:59:39.550 --> 00:59:40.950
this tool and watch for the changes.

00:59:41.990 --> 00:59:45.440
Okay, so now that was single buffered,
and you can see up in the stats

00:59:45.730 --> 00:59:48.860
that when I'm single buffered,
I'm spending all my time

00:59:49.040 --> 00:59:51.000
basically in GL text sub image 2D.

00:59:51.000 --> 00:59:53.410
So as I change the
pixels for that texture,

00:59:53.410 --> 00:59:57.350
I'm spending all my time there,
and I'm spending my time there because

00:59:57.350 --> 00:59:59.850
I'm blocked against the hardware.

00:59:59.860 --> 01:00:02.710
The hardware maybe hasn't
completed uploading that texture,

01:00:02.820 --> 01:00:04.740
and the CPU is ready
to give it another one,

01:00:04.740 --> 01:00:07.070
but the CPU has to wait for
the hardware to be done.

01:00:07.070 --> 01:00:09.410
So we're going to block,
and that's the effect that

01:00:09.410 --> 01:00:11.040
single buffering is doing.

01:00:11.690 --> 01:00:14.600
Okay, so now what's happening to me
is that the CPU is not running

01:00:14.750 --> 01:00:15.860
asynchronous to the GPU.

01:00:15.970 --> 01:00:18.090
So now if I move this up
and I double buffer this,

01:00:18.140 --> 01:00:21.340
we can start seeing some of the effects,
and I'm going to change a couple

01:00:21.390 --> 01:00:24.930
options here to give me a little
bit of a better vantage point here.

01:00:25.780 --> 01:00:28.860
Okay, so again,
the red is the hardware wait time,

01:00:28.860 --> 01:00:31.600
and you can see that when
I went to two buffers,

01:00:31.610 --> 01:00:34.650
you can see, and it's subtle,
so you have to watch,

01:00:34.710 --> 01:00:38.190
you can see that the red line went down,
so I'm now waiting,

01:00:38.190 --> 01:00:40.980
CPU's now waiting less on the hardware.

01:00:41.810 --> 01:00:44.050
And you can see that
the yellow line went up,

01:00:44.050 --> 01:00:47.810
meaning that I'm getting more bytes
per second up to the graphics card.

01:00:47.920 --> 01:00:50.400
So by double buffering,
I have made myself more

01:00:50.400 --> 01:00:53.810
asynchronous to the GPU,
allowing for better parallelization

01:00:53.860 --> 01:00:56.340
and less blocking on the CPU's behalf.

01:00:59.590 --> 01:01:02.280
So, there's a couple other things here.

01:01:02.280 --> 01:01:04.160
Let's play these stats again
and just look at what effect

01:01:04.160 --> 01:01:05.060
that had on the stats.

01:01:05.110 --> 01:01:07.110
So,

01:01:10.290 --> 01:01:14.750
So previously, I was spending all my
time in text subimage.

01:01:14.830 --> 01:01:15.780
I still am.

01:01:15.780 --> 01:01:18.240
Let's bump it up a little more
and see what happens here.

01:01:18.250 --> 01:01:20.690
If we go up to five like we were.

01:01:21.490 --> 01:01:24.060
So now the blocking point
switched back again.

01:01:24.080 --> 01:01:27.780
So you can see that we're actually
able to catch the driver blocking

01:01:27.860 --> 01:01:31.240
at different points as we move
to different numbers of buffers.

01:01:31.330 --> 01:01:34.040
So we can see that double
buffering wasn't quite enough,

01:01:34.040 --> 01:01:34.710
was it?

01:01:34.950 --> 01:01:37.710
I can see that double buffering
doesn't quite get me the same

01:01:38.010 --> 01:01:39.600
behavior that three buffers does.

01:01:39.600 --> 01:01:46.380
Now, one thing to watch out for that can
potentially fool you is that there's

01:01:46.380 --> 01:01:49.620
only limited numbers of different
types of resources in the driver.

01:01:49.620 --> 01:01:52.120
As you vary the way
your application works,

01:01:52.120 --> 01:01:55.910
you can actually start consuming
those different resources.

01:01:55.940 --> 01:01:59.080
And when you consume a resource,
the driver's going to have to block

01:01:59.080 --> 01:02:01.260
waiting for that resource to become free.

01:02:01.600 --> 01:02:05.600
So what is happening here
is that as I'm only at,

01:02:05.600 --> 01:02:10.130
say, three buffers,
I'm running out of one type of resource,

01:02:10.140 --> 01:02:13.370
and that is I'm probably blocked up
against the hardware waiting for the

01:02:13.370 --> 01:02:15.200
completion of that command buffer.

01:02:15.200 --> 01:02:17.710
But when I go to five buffers...

01:02:18.010 --> 01:02:24.170
It changes because I believe I'm
blocked against swap buffers.

01:02:24.170 --> 01:02:27.140
There's a particular packet type in
the driver that is needed to swap,

01:02:27.140 --> 01:02:28.520
and there's only four of them.

01:02:28.520 --> 01:02:31.900
When I switch up to
five different buffers,

01:02:31.930 --> 01:02:36.230
I've now made the CPU so
asynchronous that I'm running out

01:02:36.230 --> 01:02:38.870
of a different type of resource.

01:02:38.910 --> 01:02:42.480
I'm so separated from the hardware
that I'm consuming a driver resource

01:02:42.480 --> 01:02:44.630
that is making me block somewhere else.

01:02:46.380 --> 01:02:48.510
So the key points here, though,
are hardware wait time is

01:02:48.570 --> 01:02:50.680
always a good one to look at,
and what kind of byte

01:02:50.830 --> 01:02:52.270
throughput you're getting.

01:02:52.270 --> 01:02:55.700
So you can look at a variety of
different stats for byte throughput.

01:02:55.700 --> 01:02:59.200
Let me pull up the different stats here.

01:03:00.940 --> 01:03:03.860
So we can look at Command Bytes
GL if we wanted to.

01:03:03.860 --> 01:03:08.020
For instance, if I poke that down there
and I disable this other one.

01:03:13.340 --> 01:03:16.330
That one's not very interesting.

01:03:16.370 --> 01:03:18.800
Actually looks like a bug.

01:03:18.900 --> 01:03:21.840
In any case, there's lots of different
stats you can put up in here.

01:03:21.880 --> 01:03:26.420
And we're going to be releasing
another version of this that has

01:03:26.460 --> 01:03:30.000
a little more descriptive names,
hopefully with some better information.

01:03:30.040 --> 01:03:31.360
They are a little bit cryptic.

01:03:31.360 --> 01:03:33.390
If you need some more
detailed information,

01:03:33.430 --> 01:03:37.500
don't be afraid to post information
up onto the OpenGL mailing list.

01:03:37.550 --> 01:03:39.660
Can I switch back to the slides, please?

01:03:42.150 --> 01:03:44.000
Okay, so let's wrap up.

01:03:44.000 --> 01:03:47.250
Okay, so texture optimizations.

01:03:47.370 --> 01:03:49.880
The goal is to minimize your
CPU copies of pixel data.

01:03:50.000 --> 01:03:52.000
There's different ways to
optimize for power of two,

01:03:52.000 --> 01:03:54.000
non-power of two.

01:03:54.130 --> 01:03:57.370
Vertex optimizations,
you'll want to use the vertex

01:03:57.370 --> 01:04:02.000
array range for dynamic data
with the shared storage hint.

01:04:02.000 --> 01:04:05.440
And for static data,
use the vertex array range with the

01:04:05.440 --> 01:04:07.910
cache storage hint or display list.

01:04:08.340 --> 01:04:11.440
Offload the CPU onto the
GPU with vertex programs,

01:04:11.440 --> 01:04:13.500
free up some work onto the GPU.

01:04:13.540 --> 01:04:14.250
Use threads.

01:04:14.450 --> 01:04:16.290
You can share different types
of data between threads,

01:04:16.300 --> 01:04:17.800
surfaces, context data.

01:04:17.800 --> 01:04:22.120
Draw pixels for one-shot images
and copy pixels for fast VRAM to

01:04:22.220 --> 01:04:25.340
VRAM copies of your data,
of your pixels.

01:04:25.340 --> 01:04:30.320
Use the OpenGL Profiler to find
hotspots and points in your code that

01:04:30.320 --> 01:04:33.160
may be getting blocked in OpenGL.

01:04:35.560 --> 01:04:37.860
And with that,
if you have more questions,

01:04:37.930 --> 01:04:40.930
you can contact myself or Travis Brown.

01:04:50.870 --> 01:04:51.820
So, quickly, references.

01:04:51.900 --> 01:04:56.110
We got the OpenGL org
webpage that you can go to.

01:04:56.140 --> 01:04:57.800
We have the Apple developer page.

01:04:57.800 --> 01:05:02.990
And we have some Apple documentation
that is available on the developer page.

01:05:02.990 --> 01:05:06.730
And with that, I'm going to bring
Travis up for the road map.

01:05:07.340 --> 01:05:10.380
All right, we're rapidly running out of
sessions at this year's WWDC.

01:05:10.380 --> 01:05:13.180
Let me actually skip forward.

01:05:16.100 --> 01:05:21.550
The next session in the
Graphics and Imaging track isn't

01:05:21.550 --> 01:05:26.180
specifically related to OpenGL,
but it's certainly a popular session

01:05:26.180 --> 01:05:27.620
nonetheless as Mac OS X printing.

01:05:27.620 --> 01:05:30.510
Tomorrow, again,
we have Introduction to Core Services,

01:05:30.520 --> 01:05:34.700
which is if you're a game developer or a
full-screen OpenGL application developer,

01:05:34.700 --> 01:05:36.040
please attend the session.

01:05:36.040 --> 01:05:39.530
We'll be covering the core APIs that
the system uses to do display

01:05:39.530 --> 01:05:41.440
configuration and management.

01:05:42.320 --> 01:05:47.280
Our hardware partners from ATI are going
to give us a presentation on Friday.

01:05:47.280 --> 01:05:48.720
Well, actually, tomorrow is Friday.

01:05:48.720 --> 01:05:52.840
It's Cutting Edge OpenGL Techniques,
where they're going to really show

01:05:52.840 --> 01:05:55.870
us some of the absolute latest
things they're able to do with

01:05:55.890 --> 01:05:58.280
their current Radeon products.

01:06:00.630 --> 01:06:02.580
We also have a session on accessibility.

01:06:02.630 --> 01:06:05.160
This actually will contain
some content that may be of

01:06:05.170 --> 01:06:07.600
interest to game developers,
because we'll be covering,

01:06:07.600 --> 01:06:10.920
at least in a slide or so,
issues affecting using

01:06:10.990 --> 01:06:13.850
assistive technology,
which is software that adapts

01:06:13.940 --> 01:06:16.970
the function of the computer
with OpenGL applications that

01:06:17.000 --> 01:06:18.540
take over the full screen.

01:06:18.540 --> 01:06:21.000
We have a suggestion there
for some possible ways that

01:06:21.000 --> 01:06:22.580
you can ensure compatibility.

01:06:22.960 --> 01:06:26.510
And then we have, historically,
the last session of WWDC,

01:06:26.560 --> 01:06:29.780
which is the Graphics and
Imaging Feedback Forum.

01:06:29.780 --> 01:06:33.180
If you want to voice opinions,
give suggestions, please take the time to

01:06:33.180 --> 01:06:35.750
attend the feedback forum,
because that's where we get a lot

01:06:35.760 --> 01:06:38.160
of the information that we use to
create great new features in the

01:06:38.160 --> 01:06:39.540
operating system for next year.