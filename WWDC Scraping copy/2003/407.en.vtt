WEBVTT

00:00:26.300 --> 00:00:29.390
I'm Craig Linssen, Music and
Audio Partnership Manager at Apple,

00:00:29.530 --> 00:00:31.690
and today's session,
you're going to learn why

00:00:31.690 --> 00:00:34.100
Mac OS X audio truly does rock.

00:00:40.220 --> 00:00:42.550
So what we're going to cover today,
we're going to go over some

00:00:42.550 --> 00:00:44.040
developer market opportunities.

00:00:44.070 --> 00:00:46.510
We at Apple,
we're excited about our advancements

00:00:46.510 --> 00:00:48.550
in the music and audio space recently.

00:00:48.600 --> 00:00:51.600
And we'd like you to be able
to share in our success.

00:00:51.620 --> 00:00:54.320
The market is really large,
and I'm going to go over a

00:00:54.330 --> 00:00:57.380
couple of slides to show you
just how large that market is,

00:00:57.400 --> 00:01:00.670
and hopefully show you some new
opportunities that you can tap

00:01:00.670 --> 00:01:02.360
into with your applications.

00:01:02.370 --> 00:01:05.930
We're going to cover some audio
device driver changes in Panther.

00:01:05.930 --> 00:01:10.200
And we're going to go over the core
audio architecture design objectives.

00:01:10.500 --> 00:01:12.260
Finally,
we're going to dive right into the

00:01:12.260 --> 00:01:13.960
APIs and show you how to get started.

00:01:14.060 --> 00:01:21.380
Whether you're a game developer,
a music and audio developer,

00:01:21.510 --> 00:01:25.500
or you just want to input, output,
or process music or audio

00:01:25.500 --> 00:01:25.500
with your application,
you're going to learn about the

00:01:25.500 --> 00:01:25.500
APIs that you need to get started today.

00:01:27.700 --> 00:01:29.100
So market.

00:01:29.100 --> 00:01:31.820
The following is a slide of the
estimated number of music and audio

00:01:31.820 --> 00:01:34.660
creators in the United States today.

00:01:34.660 --> 00:01:36.630
At the top end of the
spectrum is the pro market.

00:01:36.680 --> 00:01:43.120
There's approximately 50,000 aspiring,
sorry, 50,000 professionals who are doing

00:01:43.120 --> 00:01:46.590
music and audio day in and day
out and making a living at it.

00:01:46.670 --> 00:01:51.360
100% of those individuals are using
a computer in their creation process.

00:01:51.380 --> 00:01:55.960
Now, in the middle end of the pyramid is
the aspiring professional market.

00:01:56.010 --> 00:01:59.340
These are individuals who aspire
to be at the top of the pyramid.

00:01:59.380 --> 00:02:02.700
They aren't quite making a living at it,
but they spend a lot

00:02:02.700 --> 00:02:05.180
of money on their gear,
and it's a very large market.

00:02:05.680 --> 00:02:08.300
However,
only about 30% of those use a computer in

00:02:08.380 --> 00:02:10.750
their music and audio creation process.

00:02:10.760 --> 00:02:15.500
And at the bottom end of the pyramid,
you'll see the creative individuals.

00:02:15.500 --> 00:02:19.800
55.9 million individuals in the
United States who are creatively

00:02:19.800 --> 00:02:21.480
inclined to do music and audio,
and they're not just going

00:02:21.560 --> 00:02:22.340
to be doing music and audio
in some fashion or another.

00:02:22.380 --> 00:02:26.960
These could be guitar players,
people who are just learning

00:02:26.960 --> 00:02:34.000
to play a musical instrument,
students, DJs, hobbyists, etc.

00:02:34.570 --> 00:02:38.910
But only about 5% of those individuals
currently use a computer in their

00:02:38.910 --> 00:02:41.200
music and audio creation process.

00:02:41.200 --> 00:02:43.610
And one of the things we want you
to be thinking about in today's

00:02:43.610 --> 00:02:49.850
session is how you can be using our
core audio API services to create

00:02:50.150 --> 00:02:56.380
applications that are easy to use,
and are going to show these individuals

00:02:56.380 --> 00:02:56.380
how they can use a computer in their
music and audio creation process.

00:02:59.160 --> 00:03:03.440
This represents about 26% of
the United States population.

00:03:03.440 --> 00:03:06.900
That's one in four
individuals is your market.

00:03:07.100 --> 00:03:09.850
It's a really big market,
and there's a lot of opportunities

00:03:09.880 --> 00:03:11.100
there for you to tap into.

00:03:11.120 --> 00:03:13.810
So let's drill down into it
just a little bit further.

00:03:15.010 --> 00:03:18.670
The purple wedge that you see up
here represents guitar players.

00:03:18.830 --> 00:03:21.810
Now, there's about 28 million guitar
players in the United States.

00:03:21.880 --> 00:03:25.890
A lot of guitar players.

00:03:27.280 --> 00:03:34.070
15 million keyboard players,
9 million DJs and remixers and producers,

00:03:34.070 --> 00:03:36.890
and the rest of the pie
chart breaks down via brass,

00:03:36.890 --> 00:03:40.040
woodwind, percussion, orchestral, etc.

00:03:40.160 --> 00:03:43.940
And again, the point I want to drive home
here is that not a lot of these

00:03:43.940 --> 00:03:47.320
individuals are even aware that
they can use a computer in their

00:03:47.380 --> 00:03:50.110
music and audio creation process.

00:03:51.290 --> 00:03:54.230
It's never been easier than
today to create a music and

00:03:54.240 --> 00:03:56.070
audio application on the Mac.

00:03:56.070 --> 00:03:59.440
Using our Core Audio API services,
you're going to find out

00:03:59.440 --> 00:04:01.310
today just how easy it is.

00:04:03.620 --> 00:04:05.680
So what were some of our
design objectives in our

00:04:05.680 --> 00:04:07.490
Core Audio API services?

00:04:07.570 --> 00:04:11.680
Well, two things:
ease of use and performance.

00:04:11.780 --> 00:04:14.650
We wanted simplified user
configuration for the end user,

00:04:14.700 --> 00:04:17.600
and streamlined development
for the developer.

00:04:17.970 --> 00:04:21.580
Performance that was built
with the professional in mind.

00:04:22.070 --> 00:04:24.350
In a lot of cases,
it was built with direct feedback

00:04:24.560 --> 00:04:28.300
from the professional music and audio
developer and musician communities.

00:04:31.050 --> 00:04:35.160
It's the most feature-rich
audio platform out there.

00:04:35.360 --> 00:04:37.880
Core audio is multi-channel
and high resolution,

00:04:37.930 --> 00:04:42.090
with sample rates up to 24-bit, 96k,
and beyond.

00:04:42.130 --> 00:04:46.200
It's extremely low latency,
and we have native MIDI support built in.

00:04:46.200 --> 00:04:48.400
If you've ever looked in
your Utilities folder,

00:04:48.400 --> 00:04:50.580
you might have seen this
little keyboard icon up here,

00:04:50.580 --> 00:04:52.190
which represents AudioMIDI setup.

00:04:52.260 --> 00:04:58.000
You can configure your entire Audio and
MIDI studio with this utility.

00:04:58.000 --> 00:04:58.000
Very cool stuff.

00:04:58.750 --> 00:05:01.490
We have Class Driver Support,
plug-and-play support

00:05:01.540 --> 00:05:04.510
for all of your hardware,
spec-compliant USB and FireWire

00:05:04.510 --> 00:05:05.980
Audio and MIDI devices.

00:05:06.100 --> 00:05:09.200
We highly encourage all the
hardware developers in the audience

00:05:09.250 --> 00:05:13.400
to really look at making your
hardware devices spec-compliant.

00:05:13.520 --> 00:05:14.200
It's really important.

00:05:14.200 --> 00:05:16.220
It cuts down on your
development time and costs,

00:05:16.330 --> 00:05:18.460
and it makes it much,
much easier on the end user.

00:05:18.460 --> 00:05:19.700
It's plug-and-play device support.

00:05:19.700 --> 00:05:22.430
You just plug it into Mac OS X,
and your device will work.

00:05:22.620 --> 00:05:25.450
No need to worry about device drivers.

00:05:27.370 --> 00:05:32.320
And finally, AudioUnits and AudioCodecs:
Apple platform standards which

00:05:32.380 --> 00:05:36.510
extend the capabilities of the
operating system via DSP plugins,

00:05:36.510 --> 00:05:40.330
virtual instruments, and AudioCodecs,
making it much,

00:05:40.330 --> 00:05:42.330
much easier in your development.

00:05:42.590 --> 00:05:45.550
Now, we're going to get into AudioUnits
and AudioCodecs in a lot more

00:05:45.550 --> 00:05:48.840
detail in Bill's session coming
up here in just a few minutes.

00:05:48.840 --> 00:05:52.860
But one of the biggest questions I get
from developers about AudioUnits is,

00:05:52.860 --> 00:05:54.270
well, who uses this?

00:05:57.720 --> 00:05:59.700
The following slide should
really speak for itself.

00:05:59.700 --> 00:06:03.380
A really large development community
has already sprung up around AudioUnits,

00:06:03.470 --> 00:06:05.700
and it's getting bigger every day.

00:06:05.700 --> 00:06:10.750
There's a lot of individuals out there
who are very excited about the work

00:06:10.750 --> 00:06:16.330
that Bill Stewart's team has done,
and he's going to get up here in just a

00:06:16.330 --> 00:06:19.670
second and get into a little more detail.

00:06:19.680 --> 00:06:22.140
So I'd like to bring up Nick Thompson.

00:06:22.140 --> 00:06:22.140
He's going to talk about audio
device drivers in Mac OS X.

00:06:26.200 --> 00:06:29.390
Thanks, Craig.

00:06:29.450 --> 00:06:33.870
Hi, my name's Nick Thompson,
and I manage the audio driver

00:06:33.910 --> 00:06:36.040
team in Apple's hardware division.

00:06:36.280 --> 00:06:39.600
I wanted to kind of
give you an update on,

00:06:39.660 --> 00:06:42.770
kind of talk about the
drivers that are in Darwin,

00:06:42.770 --> 00:06:45.320
and how that's structured,
and also give you a little

00:06:45.320 --> 00:06:49.040
bit of an update on what we've
done for the Power Mac G5,

00:06:49.060 --> 00:06:54.350
and changes that you might
need to make for your product.

00:06:56.010 --> 00:07:01.760
And then I wanted to cover class
drivers for USB and FireWire,

00:07:01.760 --> 00:07:06.580
and point you to some resources for
when you're writing your own drivers.

00:07:07.080 --> 00:07:09.740
So looking at the structure,
kind of a block diagram of

00:07:09.830 --> 00:07:15.050
kernel-based drivers on Mac OS X,
they're all pretty much

00:07:15.050 --> 00:07:17.320
based on our audio family.

00:07:17.340 --> 00:07:21.620
When you look at the built-in drivers,
you'll see there's basically a

00:07:21.620 --> 00:07:26.240
super-class Apple Onboard Audio,
which encapsulates most of the

00:07:26.240 --> 00:07:30.680
common chip features for each chip.

00:07:30.680 --> 00:07:34.920
And then we write plug-ins for
each chip specific to the platform.

00:07:34.920 --> 00:07:36.760
So when you're looking
at the code in Darwin,

00:07:36.780 --> 00:07:38.760
that's kind of the structure of it.

00:07:38.860 --> 00:07:43.820
And we also develop class
drivers for USB and FireWire.

00:07:43.860 --> 00:07:47.460
And the source code for the
USB driver is in Darwin currently.

00:07:47.580 --> 00:07:50.580
The source code for the FireWire
driver isn't in Darwin currently.

00:07:50.750 --> 00:07:54.740
And we're planning on getting
that in there after Panther.

00:07:56.130 --> 00:07:59.430
For the Power Mac G5,
there's a couple of new things that

00:07:59.430 --> 00:08:00.930
you've probably already heard about.

00:08:01.050 --> 00:08:04.940
I think the biggest one is this is
the first computer from Apple with

00:08:04.940 --> 00:08:07.050
built-in digital I/O for audio.

00:08:07.120 --> 00:08:10.350
And we're really excited about this.

00:08:10.570 --> 00:08:13.060
We've also made some improvements
to the analog section.

00:08:13.060 --> 00:08:15.120
It's basically similar
to previous computers,

00:08:15.240 --> 00:08:23.050
but we've added support for 24-bit data,
as well as 16-bit data,

00:08:23.240 --> 00:08:26.100
and also added support for
different sampling frequencies.

00:08:26.100 --> 00:08:28.940
So previously,
it was basically CD quality output.

00:08:28.940 --> 00:08:35.580
Now you can have 44:1, 48,
32K at different depths.

00:08:35.720 --> 00:08:38.060
And I want to talk a little bit
about some of the changes that

00:08:38.060 --> 00:08:42.170
are needed for devices and device
drivers on the new computer platform.

00:08:44.540 --> 00:08:47.760
The really cool thing about
the digital section is that

00:08:47.760 --> 00:08:49.290
we do clock recovery on input.

00:08:49.490 --> 00:08:53.100
This means that you can do bit-accurate
copies of original source material,

00:08:53.100 --> 00:08:56.190
which, if you're a musician,
really matters to you.

00:08:56.290 --> 00:08:59.150
The other thing, as I mentioned,
is that both on the

00:08:59.150 --> 00:09:02.670
analog and digital parts,
we've got support for new sampling

00:09:02.670 --> 00:09:05.390
frequencies and different sample sizes.

00:09:06.910 --> 00:09:13.840
The connector that we use is
basically a Toslink connector,

00:09:13.950 --> 00:09:17.430
and the specs that
cover this are up there.

00:09:17.850 --> 00:09:22.990
It's IEC 608.74-617.

00:09:22.990 --> 00:09:26.300
It's basically the standard friction
lock connector that you'll see

00:09:26.300 --> 00:09:31.820
on most consumer AV devices that
have optical connectors on them.

00:09:34.650 --> 00:09:40.290
So the back panel,
you'll see the two connectors.

00:09:40.970 --> 00:09:55.260
We're testing with every piece of
consumer AV gear that we can find.

00:09:55.260 --> 00:09:58.130
The cable is just the standard
TOSLINK connector that you'll

00:09:58.130 --> 00:10:02.970
be familiar with if you've come
across optical gear before.

00:10:03.780 --> 00:10:07.170
I wanted to talk a little
bit about AC3 support.

00:10:07.330 --> 00:10:10.600
Obviously,
because we support digital output,

00:10:10.600 --> 00:10:15.680
it's possible to either stream PCM data
across there or encoded streams.

00:10:15.760 --> 00:10:19.430
There's an important thing to
know about encoded streams.

00:10:19.850 --> 00:10:25.480
You can either output data
from all apps as PCM data,

00:10:25.480 --> 00:10:29.100
and it's mixed together in the same
way that the analog section is today.

00:10:29.210 --> 00:10:33.000
Or you can have one
single AC3-encoded stream,

00:10:33.000 --> 00:10:35.240
so if you have, say, a DVD player app.

00:10:35.360 --> 00:10:38.340
It's important to note that
you won't hear system alerts

00:10:38.440 --> 00:10:42.580
if you're in this mode,
which we've termed "hog mode."

00:10:45.580 --> 00:10:48.230
If you're developing PCI cards,
there's some changes that

00:10:48.230 --> 00:10:49.450
you need to be aware of.

00:10:49.510 --> 00:10:53.360
The biggest one is that we're no longer
supporting 5-volt signaling on cards.

00:10:53.430 --> 00:10:56.940
And you can tell whether a card
is keyed for 5-volt signaling.

00:10:56.940 --> 00:11:00.100
There's basically a notch
at the back end of the card.

00:11:00.200 --> 00:11:03.780
If it has both notches removed,
it's a 3.3-volt universal card,

00:11:03.780 --> 00:11:05.370
so you're OK.

00:11:05.450 --> 00:11:08.680
We're encouraging you to
visit the compatibility lab,

00:11:08.680 --> 00:11:11.870
and make sure, if you have your cards,
that they work in the new computer.

00:11:11.990 --> 00:11:15.510
And the G5 labs are downstairs.

00:11:17.260 --> 00:11:21.280
There's also some changes that you'd want
to make in a kernel-based device driver.

00:11:21.520 --> 00:11:24.330
Basically, we need you to make your
drivers 64-bit safe,

00:11:24.440 --> 00:11:27.810
and we've seen a number of drivers from
third parties that currently don't work.

00:11:27.890 --> 00:11:30.960
If you have any questions about this,
come find me.

00:11:31.060 --> 00:11:34.240
We're happy to work with developers
and make machines available

00:11:34.240 --> 00:11:37.670
if you can come to Cupertino,
so that you can get your stuff working.

00:11:37.790 --> 00:11:39.620
But basically,
there's a bunch of macros that

00:11:39.800 --> 00:11:41.550
are kind of ambiguous right now.

00:11:41.700 --> 00:11:44.940
They've been replaced with
specific macros for the

00:11:44.940 --> 00:11:47.270
word size that you're using.

00:11:49.720 --> 00:11:52.750
You also need to remove any assumptions
you have in your driver about logical

00:11:52.790 --> 00:11:56.540
and physical addresses being the same.

00:11:56.630 --> 00:12:00.600
When we were porting the
Apple onboard audio drivers,

00:12:00.710 --> 00:12:04.740
we basically came across places
where we were making these

00:12:04.740 --> 00:12:06.600
assumptions and we weren't working.

00:12:06.600 --> 00:12:10.510
So, you know, we had a call in there,
physical to KV, which maps physical

00:12:10.510 --> 00:12:12.400
addresses to kernel virtual.

00:12:12.400 --> 00:12:14.420
You need to basically
work around these issues.

00:12:14.600 --> 00:12:17.060
And then finally,
you also need to make sure that

00:12:17.060 --> 00:12:18.510
you prepare memory for I/O.

00:12:18.570 --> 00:12:22.600
If you do this, a Dart entry is created
and the world is good.

00:12:22.600 --> 00:12:26.200
If you don't do this,
memory isn't where you think it is.

00:12:27.790 --> 00:12:29.360
Talk about the class drivers a bit.

00:12:29.620 --> 00:12:30.700
First with USB.

00:12:30.970 --> 00:12:34.490
Basically, using our driver is going to
save you development costs.

00:12:34.500 --> 00:12:39.430
So you should try and make sure that
if you're developing a USB device,

00:12:39.520 --> 00:12:42.090
it conforms to the USB audio spec.

00:12:43.320 --> 00:12:48.000
We've basically implemented support
for everything we've seen so far.

00:12:48.150 --> 00:12:49.970
And I think the message of this slide is,
you know,

00:12:49.970 --> 00:12:52.650
if you have a device that you're
working on with a mixer unit,

00:12:52.650 --> 00:12:55.460
for example, let us know,
and we'll make sure that

00:12:55.460 --> 00:12:57.210
the driver works with that.

00:12:58.320 --> 00:13:02.540
We're also working on the
USB Device 2.0 specification,

00:13:02.540 --> 00:13:05.360
which is kind of different to USB 2.0.

00:13:05.360 --> 00:13:08.840
It gets a bit confusing here,
but this is basically the specification

00:13:08.840 --> 00:13:13.200
for USB audio devices on both
full-speed and high-speed USB.

00:13:13.200 --> 00:13:17.630
We're going to be making sure
that we provide support for those

00:13:17.630 --> 00:13:19.960
new devices in the class driver.

00:13:20.200 --> 00:13:23.060
If you are working on
a USB 2.0 audio device,

00:13:23.060 --> 00:13:23.960
let us know.

00:13:23.970 --> 00:13:27.490
We're interested in taking a
look at it and making sure that

00:13:27.590 --> 00:13:30.000
we work with your hardware.

00:13:31.620 --> 00:13:33.360
This year is going to be
a big year for FireWire,

00:13:33.360 --> 00:13:33.900
I think.

00:13:33.900 --> 00:13:37.500
We're working with a number of
developers doing FireWire products.

00:13:37.540 --> 00:13:42.160
Again, using the standards-based driver
is great for both us and you.

00:13:42.650 --> 00:13:45.880
It reduces your development costs.

00:13:46.020 --> 00:13:47.740
And for us,
it makes it easier for customers.

00:13:47.740 --> 00:13:50.780
When they buy a device,
they can plug it into their Mac,

00:13:50.780 --> 00:13:52.290
and it should just work.

00:13:52.630 --> 00:13:54.730
Basically,
there's kind of two flavors of FireWire

00:13:54.730 --> 00:13:56.140
devices out there at the moment.

00:13:56.380 --> 00:13:59.620
There's AVC devices,
and we're seeing silicon from Bridge,

00:13:59.620 --> 00:14:02.800
Conox, and Semiconductor for those.

00:14:02.800 --> 00:14:05.900
And there's MLan devices from
a variety of manufacturers,

00:14:05.900 --> 00:14:09.490
including Yamaha, Korg, Atari, Presonus,
Kurzweil, Apogee,

00:14:09.510 --> 00:14:11.990
and the list is actually growing.

00:14:12.090 --> 00:14:15.950
And we're aiming to basically support
any silicon that anyone comes up with

00:14:15.950 --> 00:14:18.090
that's basically class-compliant.

00:14:20.040 --> 00:14:23.280
In Panther, we've made some changes.

00:14:23.350 --> 00:14:26.820
The driver that we shipped in Jaguar
was essentially a driver for speakers.

00:14:26.910 --> 00:14:31.550
We are now adding music subunit support,
so we're providing input

00:14:31.550 --> 00:14:33.370
and output support,
different numbers of

00:14:33.370 --> 00:14:36.300
input and output streams,
support for MIDI.

00:14:36.380 --> 00:14:38.400
We're also working on lowering
the latency in Jitter.

00:14:38.400 --> 00:14:42.100
This is really important to
us for a variety of reasons.

00:14:43.660 --> 00:14:47.280
The other thing that we're doing is,
if you have a network of devices such as

00:14:47.280 --> 00:14:51.530
an MLAN network or a network of speakers,
we're making some changes

00:14:51.530 --> 00:14:52.670
in how they're presented.

00:14:52.770 --> 00:14:57.700
I wanted to talk a little bit about
what happens when you hot-plug a device.

00:14:59.940 --> 00:15:02.030
So basically, when you hot-plug a device,
it'll show up.

00:15:02.040 --> 00:15:04.220
We'll create a unit for it.

00:15:04.250 --> 00:15:06.900
And we'll start building
the stack that we need.

00:15:06.900 --> 00:15:08.360
So we'll build a device reference.

00:15:08.400 --> 00:15:12.190
We'll build an engine reference
and start linking that up.

00:15:12.320 --> 00:15:16.530
And then we'll start building stream
references for input and output.

00:15:20.400 --> 00:15:22.520
We're going to start building stream
rests for the output stream and

00:15:22.520 --> 00:15:24.000
stream rests for the input stream.

00:15:24.210 --> 00:15:27.830
What happens when you plug in
a new device right now is that

00:15:27.830 --> 00:15:31.150
we'll create a new engine,
which is inefficient because

00:15:31.150 --> 00:15:33.500
you're going to start getting
interrupts on each engine.

00:15:33.500 --> 00:15:36.220
So what we're going to do in Panther is
basically start linking the whole

00:15:36.220 --> 00:15:40.270
thing together so the entire network
is presented as a single device.

00:15:40.280 --> 00:15:43.180
So a new device is hot-plugged.

00:15:43.180 --> 00:15:46.520
We'll actually create a new
stream ref for the input,

00:15:46.520 --> 00:15:50.100
but the output will be
the same output device.

00:15:50.100 --> 00:15:53.940
So the way that this is going to
wind up getting presented is you'll

00:15:53.940 --> 00:15:58.180
see two input devices with four
streams on them and a single output

00:15:58.210 --> 00:16:00.590
device with eight streams on it.

00:16:00.870 --> 00:16:03.720
So the goal here is essentially
to present a network as

00:16:03.720 --> 00:16:07.470
a single block device,
which is the intention of MLan networks,

00:16:07.550 --> 00:16:10.720
but it's also, for speakers,
a much more intelligent

00:16:10.720 --> 00:16:12.890
way of doing things.

00:16:15.400 --> 00:16:18.650
Finally, I wanted to point you at
some developer resources.

00:16:18.730 --> 00:16:20.600
There's driver code in Darwin.

00:16:20.770 --> 00:16:25.290
You should definitely check
out iAudio Family if you're

00:16:25.290 --> 00:16:27.490
doing a kernel-based driver.

00:16:27.580 --> 00:16:30.710
You should also really consider whether
your driver needs to be in the kernel.

00:16:30.830 --> 00:16:35.740
It's possible to hook into Core Audio and
write a driver that sits in user land,

00:16:35.740 --> 00:16:38.300
and that's often a better
way of doing things.

00:16:38.400 --> 00:16:41.020
For PCI cards,
you do want to be in the kernel.

00:16:41.170 --> 00:16:43.200
For FireWire,
maybe you want to be in the kernel,

00:16:43.200 --> 00:16:43.950
maybe you don't.

00:16:44.040 --> 00:16:48.620
You need to think about it
on a device-specific basis.

00:16:48.710 --> 00:16:51.820
We've also got sample code in the
SDK for the Phantom Audio Driver,

00:16:51.840 --> 00:16:53.500
which is a great place to start.

00:16:53.510 --> 00:16:57.080
And we're looking at,
hopefully by the Panther timeframe,

00:16:57.170 --> 00:17:00.040
getting out a sample PCI driver
for a couple of devices,

00:17:00.040 --> 00:17:02.800
because a number of developers
have been asking for that.

00:17:02.850 --> 00:17:06.060
And as always, you should check out the
Audio Developer page at

00:17:06.090 --> 00:17:08.200
developer.apple.com/audio.

00:17:08.400 --> 00:17:10.570
So that's it for drivers.

00:17:10.680 --> 00:17:15.290
I want to introduce Bill Stewart to
talk about Core Audio.

00:17:16.060 --> 00:17:20.770
Thanks, Greg.

00:17:23.900 --> 00:18:27.900
[Transcript missing]

00:18:28.100 --> 00:19:30.500
[Transcript missing]

00:19:32.900 --> 00:19:37.860
As Craig discussed earlier,
when we first started with Cordio,

00:19:38.110 --> 00:19:42.280
we wanted to set a high
standard for ourselves to reach.

00:19:42.280 --> 00:19:47.110
I think this was a very important
initial step to take for us because

00:19:47.210 --> 00:19:52.240
it's extremely difficult if you
aim low and then have to scale up.

00:19:52.320 --> 00:19:57.040
It's a lot easier if you aim as
high as you need to aim and then

00:19:57.040 --> 00:20:00.120
you can appropriately scale back.

00:20:00.220 --> 00:20:04.400
We really looked at what was
required from the pro audio market.

00:20:04.400 --> 00:20:10.010
This is not to say that this is a
set of APIs that can only be used

00:20:10.010 --> 00:20:16.100
in musical applications or pro
audio workstations and things.

00:20:16.100 --> 00:20:21.560
It really can scale down to games
and to lower sample rates and lower

00:20:21.560 --> 00:20:24.780
quality abstractions and so forth.

00:20:24.870 --> 00:20:27.420
We wanted to start at this point.

00:20:27.420 --> 00:20:29.120
We had requirements.

00:20:30.260 --> 00:20:34.000
We had requirements for latency
and jitter that were very important

00:20:34.000 --> 00:20:36.010
to us both for MIDI and for audio.

00:20:36.020 --> 00:20:40.160
We wanted obviously no
restriction on sample rate,

00:20:40.160 --> 00:20:44.760
which was a problem with
previous versions of the OS.

00:20:44.830 --> 00:20:48.440
Multi-channel awareness
throughout the system,

00:20:48.530 --> 00:20:51.700
not just with devices
but also with codecs,

00:20:51.750 --> 00:20:54.360
with audio units,
with the whole way that we

00:20:54.360 --> 00:20:56.140
think about audio in the system.

00:20:56.140 --> 00:20:59.820
And we didn't want to
be limited to just some.

00:21:00.240 --> 00:21:03.780
We wanted to have a small subset
of how we can represent audio data.

00:21:03.780 --> 00:21:09.440
We wanted to have rich abstractions that
can be applied throughout the system.

00:21:09.440 --> 00:21:13.440
And the session after this one
will go into some more detail

00:21:13.610 --> 00:21:17.610
about how we represent data in the
different subsystems of core audio.

00:21:20.150 --> 00:21:24.190
So let's start at the bottom and
we'll kind of work our way up.

00:21:24.280 --> 00:21:28.630
So I'm not going to spend a lot
of time in the Cordial HAL part.

00:21:28.790 --> 00:21:32.800
This is very much a low
level interface to devices.

00:21:32.800 --> 00:21:36.710
There's a lot of abstraction
here for the devices,

00:21:36.810 --> 00:21:42.110
but there's also a lot of specific
device state that you need to manage.

00:21:42.170 --> 00:21:46.420
And if you are in a situation
where you really need to interact

00:21:46.420 --> 00:21:51.020
very intimately with the device,
this is the API that you use.

00:21:51.020 --> 00:21:52.660
This is in the Cordial framework.

00:21:52.660 --> 00:21:58.400
We affectionately call it the HAL,
the hardware abstraction layer.

00:21:58.400 --> 00:22:01.920
And you'll get all of the characteristics
of devices published here,

00:22:01.920 --> 00:22:07.830
configuration, system device preferences,
management of the device status

00:22:07.830 --> 00:22:10.270
and all that kind of thing.

00:22:10.890 --> 00:22:14.290
And for MIDI,
we've got the Core MIDI Framework,

00:22:14.350 --> 00:22:20.320
and this is really the APIs that are
published through here for transporting

00:22:20.440 --> 00:22:24.200
MIDI data through the system,
both in and out of the

00:22:24.200 --> 00:22:28.170
system through drivers,
as well as into application.

00:22:28.330 --> 00:22:33.340
In Jaguar's Core MIDI,
we have a concept of virtual

00:22:33.340 --> 00:22:38.300
sources and destinations,
and we've found that a lot of

00:22:38.300 --> 00:22:44.300
developers from Mac OS 9 and the
MIDI services that OMS and FreeMIDI gave,

00:22:44.470 --> 00:22:49.650
that one of the things that have
been missing from the way the

00:22:49.650 --> 00:22:53.700
system is used is an IAC bus,
which is an Inter-Application

00:22:53.700 --> 00:22:54.800
Communication Bus.

00:22:54.990 --> 00:22:58.150
And this is basically just a
driver that looks at... It's a

00:22:58.150 --> 00:23:02.260
software that looks like a driver,
but it actually gives you a way to kind

00:23:02.290 --> 00:23:06.580
of connect MIDI between different apps,
and it looks like you're

00:23:06.580 --> 00:23:10.080
dealing with drivers,
rather than sort of having

00:23:10.080 --> 00:23:14.290
to do extra work to look for
virtual sources and destinations.

00:23:14.300 --> 00:23:17.300
So this will be a new feature in Panther.

00:23:17.300 --> 00:23:20.710
And the other thing, of course,
with Core MIDI is needing to

00:23:20.710 --> 00:23:24.300
configure device and publish device
characteristics and so forth.

00:23:24.300 --> 00:23:29.460
I'm going to go to the demo machine
and just... very briefly walk through

00:23:29.650 --> 00:23:34.930
the Audio MIDI Setup application,
just as a way to kind of give you some

00:23:35.440 --> 00:23:38.300
sense of how all this is put together.

00:23:38.300 --> 00:23:40.220
So this is the Audio tab.

00:23:40.360 --> 00:23:43.300
We've got the Mark the
Unicorn 896 box here.

00:23:43.300 --> 00:23:45.290
We use different devices each year.

00:23:45.300 --> 00:23:48.800
We've used eMagic and
Delta M-Audio devices.

00:23:48.800 --> 00:23:51.300
We thought we'd use
the Motu one this year.

00:23:51.480 --> 00:23:56.800
This top part of the section
here is the System Settings,

00:23:56.800 --> 00:23:59.790
and these are the
default input and output.

00:23:59.800 --> 00:24:03.800
They're typically the devices
that are used by apps like iTunes,

00:24:03.800 --> 00:24:07.740
by QuickTime Player, by games.

00:24:07.840 --> 00:24:11.800
And the user can typically
see in the sound press,

00:24:11.800 --> 00:24:14.800
they can see like these are all
the output devices I've got,

00:24:14.800 --> 00:24:18.800
and they can choose which one they
want to use as their default output.

00:24:18.800 --> 00:24:25.800
And another thing we introduced in
Mac OS X was a distinction between

00:24:25.800 --> 00:24:28.350
the device that you would use,
for playing audio on,

00:24:28.410 --> 00:24:32.290
and the device that you would use for
things like sys beeps and so forth.

00:24:32.370 --> 00:24:37.290
So the system output device is
the device where your beeps go.

00:24:37.700 --> 00:28:14.700
[Transcript missing]

00:28:15.330 --> 00:28:23.070
If I go to the MIDI section now,
I've got one USB device here from Roland.

00:28:23.330 --> 00:28:29.400
It's an MPU64,
and it has four MIDI ins and outs.

00:28:29.720 --> 00:28:35.100
I've got a studio set up
here and -- that's not Dre.

00:28:35.100 --> 00:28:38.720
I'll leave that over there.

00:28:38.720 --> 00:28:40.730
Early software.

00:28:40.870 --> 00:28:45.740
So one of the things I wanted
to talk about with this app is

00:28:45.740 --> 00:28:50.490
a little bit of confusion about
exactly what it's meant to be doing,

00:28:50.490 --> 00:28:54.120
and this really reflects,
as the audio side does,

00:28:54.120 --> 00:28:57.060
both of these apps,
if you're developing and

00:28:57.060 --> 00:29:01.440
you're familiar with the API,
they really reflect the --

00:29:01.440 --> 00:29:06.240
a lot of the structures that
are in the API themselves.

00:29:06.240 --> 00:29:09.920
And so you can sort of see this as
like this is what the user sees,

00:29:09.920 --> 00:29:12.750
but also as a developer,
we can -- just with a couple

00:29:12.750 --> 00:29:15.220
of grafting concepts here,
we can understand what you're

00:29:15.220 --> 00:29:18.070
seeing from an API point of view.

00:29:18.070 --> 00:29:20.040
So this is a driver.

00:29:20.040 --> 00:29:24.590
This driver has what is in
MIDI is called MIDI entities,

00:29:24.590 --> 00:29:28.880
and it has four MIDI entities,
which are these pairs

00:29:28.880 --> 00:29:31.900
of in and out ports,
and the in and out ports

00:29:31.900 --> 00:29:35.120
are MIDI end points,
and each MIDI end point

00:29:35.120 --> 00:29:38.640
takes a full MIDI stream,
so that's 16 channels,

00:29:38.640 --> 00:29:42.520
and you're able to, you know,
talk to whatever is at the end

00:29:42.520 --> 00:29:46.160
of that stream or get the data
from the end of that stream.

00:29:46.160 --> 00:29:50.100
So this configuration here
has four MIDI entities,

00:29:50.110 --> 00:29:54.060
and each MIDI entity has an
end point for in and out,

00:29:54.190 --> 00:29:58.490
and what we're doing here
is describing the driver.

00:29:58.520 --> 00:30:01.480
Now, what is out here is just three
devices that I've added by just

00:30:01.480 --> 00:30:05.840
doing this add device thing,
and I can add a new external device,

00:30:05.840 --> 00:30:10.540
and I'm not actually creating any
-- it's not like I'm going to really

00:30:10.630 --> 00:30:12.320
create like a whole patch flow here.

00:30:12.320 --> 00:30:16.290
All I'm doing is describing to
the system what I've got plugged

00:30:16.290 --> 00:30:20.370
into what the system knows about,
which is the actual driver.

00:30:20.390 --> 00:30:23.760
You can't really do through connections
here in the sense that that will

00:30:23.760 --> 00:30:25.300
like just automatically route.

00:30:25.300 --> 00:30:27.160
You have to route these with your cables.

00:30:27.160 --> 00:30:30.830
You really just have to
route these with your cables.

00:30:30.830 --> 00:30:35.450
So this is a very simple way of
describing to the system the keyboards

00:30:35.450 --> 00:30:40.000
or the control surfaces or the
modules that you have on your system,

00:30:40.070 --> 00:30:43.140
and you can save
different configurations,

00:30:43.140 --> 00:30:47.180
and if I unplug the USB device,
the driver will go offline,

00:30:47.180 --> 00:30:49.840
and you'll see that reflected in AMS.

00:30:49.840 --> 00:30:53.370
And what can be done here is
so on -- rather than sort of

00:30:53.370 --> 00:30:57.790
showing this as port 4 of USB,
you know, SMPU64,

00:30:57.820 --> 00:31:02.540
you can actually present
by querying core midis,

00:31:02.540 --> 00:31:05.470
APIs,
you can actually present my synth module

00:31:05.580 --> 00:31:09.790
as the destination for that to the user.

00:31:09.900 --> 00:31:13.100
Now the thing that's missing from
this that I'm sure many of you who

00:31:13.100 --> 00:31:18.060
have dealt with OMS and FreeMIDI is
some way to describe what is

00:31:18.060 --> 00:31:19.990
actually in the device itself.

00:31:20.110 --> 00:31:26.550
If it's a Roland U-20 or U-220 thing,
what patches does it have,

00:31:26.550 --> 00:31:29.320
and what is the current
patch banks that I've had,

00:31:29.320 --> 00:31:31.790
what are the capabilities of the device?

00:31:31.800 --> 00:31:36.680
We've worked with the MIDI Manufacturers
Association to describe a document

00:31:37.200 --> 00:31:38.800
format for that using XML.

00:31:38.800 --> 00:31:44.860
The spec has been ratified and
has passed through all of the

00:31:45.010 --> 00:31:47.180
MMA processes for doing that.

00:31:47.300 --> 00:31:51.170
We wanted to do this through
a body rather than as an

00:31:51.170 --> 00:31:55.570
Apple sort of only initiative,
just to make this something that

00:31:55.570 --> 00:31:59.410
could be broadly adopted both by
manufacturers and other computer

00:31:59.410 --> 00:32:03.030
companies besides ourselves,
so that for the user,

00:32:03.030 --> 00:32:05.180
there's one data format.

00:32:05.650 --> 00:32:08.690
The document's not available
yet from the MMA site,

00:32:08.810 --> 00:32:09.700
though it will be soon.

00:32:09.700 --> 00:32:14.090
We're going through the final stage
of actually making the documents

00:32:14.110 --> 00:32:18.700
clearer about what it contains,
so that it's an easy

00:32:18.700 --> 00:32:20.390
to understand document.

00:32:20.760 --> 00:32:25.300
You'll be able to author these XML files
yourself to describe custom patches,

00:32:25.300 --> 00:32:29.520
and we hope that there will be
websites available that manufacturers

00:32:29.520 --> 00:32:31.900
will publish them for their devices.

00:32:31.900 --> 00:32:34.900
And so then the user
can see my synth module,

00:32:34.900 --> 00:32:39.100
and it's a Roland synth module, or yada,
yada, and it's got these patches on it.

00:32:39.100 --> 00:32:43.050
And just like with OMS and
FreeMIDI on Mac OS 9,

00:32:43.190 --> 00:32:48.200
it should be as easy an
experience for the user on 10.

00:32:48.320 --> 00:32:50.980
If we can go back to slides, please.

00:32:54.080 --> 00:32:57.200
Right, so that's the bottom layers.

00:32:57.200 --> 00:32:59.190
Let's get into AudioUnits.

00:32:59.210 --> 00:33:05.190
So AudioUnits, we have a logo,
and that's the logo.

00:33:05.190 --> 00:33:05.190
I have to...

00:33:08.330 --> 00:33:11.640
took some effort, I can tell you.

00:33:11.640 --> 00:33:19.240
So audio units and I'm going to say
that these are a generalized plug-in

00:33:19.240 --> 00:33:24.350
format and by generalized I mean
that it has very many different uses.

00:33:24.360 --> 00:33:27.520
It's not just for effects,
it's not just for software instruments

00:33:27.990 --> 00:33:32.240
and what we'll do today is later on
as a demo for some other audio units

00:33:32.240 --> 00:33:36.450
and I just want to give an overview
generally of what audio units are,

00:33:36.450 --> 00:33:39.570
the types of audio units that
you can have and their kind of

00:33:39.570 --> 00:33:42.150
categories and their functionality.

00:33:42.460 --> 00:33:43.280
So how does it work?

00:33:43.370 --> 00:33:48.280
An audio unit uses the component manager,
and we use the component manager because

00:33:48.280 --> 00:33:50.440
it has some nice features about it.

00:33:50.440 --> 00:33:52.510
It has discovery mechanisms.

00:33:52.520 --> 00:33:54.380
Find next component.

00:33:54.380 --> 00:33:58.040
You can just make this call,
and you can specify the type of

00:33:58.150 --> 00:34:00.860
audio unit that you're looking for,
and we have different types.

00:34:00.860 --> 00:34:04.100
Once you find the audio
unit that you want,

00:34:04.100 --> 00:34:06.410
and you can either be doing
this programmatically or you

00:34:06.410 --> 00:34:09.580
can present menus based on what
you've discovered to the user,

00:34:09.580 --> 00:34:13.740
then you open that component,
and once you've opened the component,

00:34:13.740 --> 00:34:15.830
you get back what's called
a component instance.

00:34:15.840 --> 00:34:20.090
So you can think of a component in
object-oriented terms as a class,

00:34:20.210 --> 00:34:25.180
specifies an API, specifies what a member
of that class can do,

00:34:25.180 --> 00:34:29.010
and the audio unit itself is the
component instance is like an object,

00:34:29.010 --> 00:34:30.380
an instance of the class.

00:34:30.380 --> 00:34:35.100
And so audio unit as a type def is
type def to a component instance.

00:34:38.500 --> 00:34:40.240
So you've opened your audio unit.

00:34:40.240 --> 00:34:42.410
So what do you need to do to it?

00:34:42.550 --> 00:34:45.830
Well,
it can be as simple and complex as the

00:34:45.830 --> 00:34:49.860
type of audio unit you're dealing with,
what you want to do with it.

00:34:49.920 --> 00:34:55.330
And the first step, really,
for an audio unit is to look

00:34:55.330 --> 00:34:56.820
at the properties that it has.

00:34:56.820 --> 00:35:00.600
And properties really represent,
in this kind of sense of

00:35:00.600 --> 00:35:04.910
the property mechanism,
it's the state of the audio unit.

00:35:05.060 --> 00:35:08.240
And so it is a general mechanism.

00:35:08.520 --> 00:35:09.160
It's extensible.

00:35:09.160 --> 00:35:10.770
We define property types.

00:35:10.820 --> 00:35:13.540
You can get information
about the property.

00:35:13.540 --> 00:35:15.380
How big is the property?

00:35:15.380 --> 00:35:18.360
Can I read the property or
write the property or both?

00:35:18.400 --> 00:35:25.200
I can use the property mechanism to find
out the state that the unit comes up in,

00:35:25.200 --> 00:35:27.870
and I can change the
state of it and so forth.

00:35:27.990 --> 00:35:31.880
And it's really the way that you manage
that fundamental state of an audio unit.

00:35:33.880 --> 00:35:36.380
And then once you've sort of
set up the state of the unit,

00:35:36.380 --> 00:35:39.770
then we have a second phase,
which is initialisation.

00:35:39.780 --> 00:35:44.120
We split these up because there's
often a lot of things you might want to

00:35:44.120 --> 00:35:47.780
discover about what an audio unit can do,
particularly if you're in, like,

00:35:47.780 --> 00:35:51.100
a hosting environment,
before you initialise it and make it

00:35:51.170 --> 00:35:53.970
able to render and able to do its job.

00:35:53.980 --> 00:35:57.590
And so audio unit initialises
this concept of allocation

00:35:58.040 --> 00:36:00.450
in order to actually operate.

00:36:00.460 --> 00:36:05.510
And once an audio unit is initialised,
then it's considered to be

00:36:05.510 --> 00:36:07.320
in a state to be usable.

00:36:07.320 --> 00:36:13.540
And that is the one call that you do,
really, to use it, is audio unit render.

00:36:13.540 --> 00:36:18.650
And I'm not going to go into the
specific details of the API for that,

00:36:18.750 --> 00:36:23.710
but there's a lot of arguments that you
can pass to this and flags and so forth,

00:36:23.820 --> 00:36:26.520
and they're fairly well documented
in the headers and you can

00:36:26.520 --> 00:36:27.670
ask questions on the list.

00:36:29.920 --> 00:36:33.500
Now, we're ready to go.

00:36:33.500 --> 00:36:36.080
We're going to call it a unit render,
but where are we going

00:36:36.080 --> 00:36:37.260
to get input data from?

00:36:37.260 --> 00:36:40.800
You can get inputs for an audio
unit from two different places.

00:36:40.900 --> 00:36:44.760
We wanted to have, with audio units,
an idea that we can connect

00:36:44.760 --> 00:36:48.820
them up into processing graphs,
or we can use them independently,

00:36:48.910 --> 00:36:52.830
either just one-off,
or maybe two or three,

00:36:52.970 --> 00:36:56.080
and then I want to provide data to it,
but I don't want to have to

00:36:56.080 --> 00:36:58.900
be an audio unit to provide
data to another audio unit.

00:36:58.900 --> 00:37:03.900
So you can also have a callback function,
or you can have the connection.

00:37:03.900 --> 00:37:07.880
So there's two ways that you can
provide data to an audio unit,

00:37:07.890 --> 00:37:10.890
and at this point we're talking
about audio data to an audio unit.

00:37:10.900 --> 00:37:14.150
And so when you call audio
unit render on an audio unit,

00:37:14.150 --> 00:37:18.890
it's going to go, if it wants input,
and some audio units may not want input,

00:37:18.920 --> 00:37:20.740
and we'll have a look
at those in a minute.

00:37:20.900 --> 00:37:25.900
It'll call its input proc,
or its connection for its input data.

00:37:25.980 --> 00:37:27.900
When that returns,
it's now got input data.

00:37:27.910 --> 00:37:29.880
It's now got input data to process.

00:37:29.900 --> 00:37:33.020
It processes that data,
and then you get that back

00:37:33.030 --> 00:37:36.610
in the buffer list that you
provide to audio unit render,

00:37:36.610 --> 00:37:37.900
and you're done.

00:37:38.380 --> 00:37:39.500
Well, are we done?

00:37:39.500 --> 00:37:41.420
No, not quite.

00:37:41.520 --> 00:37:45.160
Because one of the things you want
to do when you're processing audio

00:37:45.160 --> 00:37:46.950
is you want to be able to tweak it.

00:37:46.950 --> 00:37:49.980
You want to be able to set
delay times differently.

00:37:49.980 --> 00:37:52.590
You may want to be able
to set frequencies.

00:37:52.590 --> 00:37:56.920
If you're talking about volumes,
you want to change volumes and so forth.

00:37:56.920 --> 00:38:00.430
So all of these are considered as real
time operations on the audio unit,

00:38:00.430 --> 00:38:03.410
things that you can do to the
audio unit while you're in

00:38:03.410 --> 00:38:05.740
the process of rendering it.

00:38:05.740 --> 00:38:09.400
And we abstract that into
what we call parameters.

00:38:09.400 --> 00:38:12.460
An audio unit using the
property mechanism publishes a

00:38:12.460 --> 00:38:16.010
list of the parameters that it
allows the user to manipulate.

00:38:16.010 --> 00:38:19.370
It publishes things like what's
the range of the parameter,

00:38:19.470 --> 00:38:24.680
what kind of values does it have,
maybe dB or hertz or maybe just a

00:38:24.680 --> 00:38:27.860
generic zero to one sort of parameter.

00:38:28.350 --> 00:38:32.110
There's a whole bunch of
different types of parameters

00:38:32.110 --> 00:38:32.840
that an audio unit may publish.

00:38:33.240 --> 00:38:38.440
And it really, this can,
we've seen some third party units that

00:38:38.460 --> 00:38:40.100
have a couple of hundred parameters.

00:38:40.140 --> 00:38:42.330
A lot of our units may be fairly simple.

00:38:42.330 --> 00:38:44.560
They may have just two
or three parameters.

00:38:44.560 --> 00:38:48.100
It really depends on what the unit is
doing and what the developer of the

00:38:48.100 --> 00:38:51.890
unit wants you to be able to manipulate.

00:38:52.950 --> 00:38:58.120
So we have effects units,
and that's really kind of the meat

00:38:58.120 --> 00:39:02.100
of a lot of where we think the third
parties will be developing units.

00:39:02.100 --> 00:39:05.680
In Jaguar, we ship various filters.

00:39:05.680 --> 00:39:09.900
There's high, low pass, band pass,
high shelf and low shelf filters.

00:39:09.900 --> 00:39:14.380
We ship a reverb unit,
and the reverb unit has quality

00:39:14.380 --> 00:39:15.970
settings that you can adjust.

00:39:15.980 --> 00:39:21.080
The quality really determines how much
CPU the unit's going to take at runtime,

00:39:21.750 --> 00:39:24.120
and it actually affects the
quality of the rendering.

00:39:24.120 --> 00:39:29.130
And for things like games and stuff,
they may be less concerned about a very

00:39:29.130 --> 00:39:33.130
high quality and more concerned about
the load that the unit's going to take.

00:39:33.200 --> 00:39:36.220
And we have a digital delay unit.

00:39:36.220 --> 00:39:37.460
We have a peak limiter.

00:39:37.460 --> 00:39:40.860
In Panther,
we've added a multiband compressor unit.

00:39:40.860 --> 00:39:45.120
It's a four-band compressor,
and it's pretty nice, actually.

00:39:45.120 --> 00:39:48.910
And we're not going to publish
a couple of hundred audio

00:39:48.910 --> 00:39:50.280
units as a company ourselves.

00:39:50.680 --> 00:39:54.300
This is, for us,
the big part of audio units is what

00:39:54.360 --> 00:39:55.920
developers are going to do with this.

00:39:55.920 --> 00:39:59.650
This is where it can get very
interesting and very bizarre sometimes.

00:40:01.510 --> 00:40:09.080
To sort of summarize that, we create one,
we've got the state management,

00:40:09.080 --> 00:40:12.580
we've got the resource allocation,
we've got the rendering,

00:40:12.670 --> 00:40:15.350
and we've got the
control of the rendering.

00:40:15.350 --> 00:40:17.200
Well, is that all we need?

00:40:18.670 --> 00:40:21.890
No.

00:40:21.950 --> 00:40:24.830
Typically,
if you've used Logic or if you've used

00:40:24.830 --> 00:40:30.190
Digital Performer or any of these sort
of hosting environment type applications,

00:40:30.190 --> 00:40:33.490
you want to present some kind
of view to the audio unit so

00:40:33.490 --> 00:40:36.030
the user can interact with them.

00:40:36.030 --> 00:40:40.890
We've published a generic view which
will just query the parameters that

00:40:40.890 --> 00:40:44.990
the unit tells us and we'll assemble
like a bunch of sliders and that's,

00:40:44.990 --> 00:40:50.140
you know, it's not bad but it's probably
not as good as what you can do if

00:40:50.140 --> 00:40:52.760
you really understand your DSP.

00:40:52.760 --> 00:40:56.910
And so a developer of an audio
unit can publish a custom

00:40:56.910 --> 00:41:00.860
view and some of the views,
if you've seen these, are pretty creative

00:41:00.860 --> 00:41:02.420
and pretty interesting.

00:41:02.420 --> 00:41:06.400
In Jaguar, we only had the ability
to publish Carbon views.

00:41:06.400 --> 00:41:09.280
In Panther,
we're adding support for Cocoa.

00:41:09.280 --> 00:41:13.940
So you can publish a class that
implements a Cocoa protocol.

00:41:13.980 --> 00:41:19.710
And it can be discovered from asking
the audio unit for its Cocoa view.

00:41:19.710 --> 00:41:25.170
And a Carbon app can put a Cocoa UI up
in a separate window and a Cocoa app can

00:41:25.280 --> 00:41:28.740
put a Carbon UI up in a separate window.

00:41:28.740 --> 00:41:34.600
So there's not a lot of extra work on
the hosting side to deal with both of

00:41:34.600 --> 00:41:39.670
these and we think that probably a lot
of developers will be very interested

00:41:39.670 --> 00:41:41.650
in the Cocoa UI so it's there now.

00:41:43.370 --> 00:41:48.340
And the other side of this is
communication and control mechanisms.

00:41:48.340 --> 00:41:51.560
In Jaguar we have a
parameter listener API.

00:41:51.620 --> 00:41:56.330
It's in Audio Toolbox,
Audio Unit Utilities.h and it is

00:41:56.330 --> 00:41:58.710
an API called AUParameterListener.

00:41:58.710 --> 00:42:01.300
I always get told off
when I'm wandering around,

00:42:01.310 --> 00:42:06.600
but I just can't stand still
so I'm going to keep wandering.

00:42:06.660 --> 00:42:07.940
Excuse me.

00:42:07.940 --> 00:42:12.050
So the parameter listener,
when we were looking

00:42:12.140 --> 00:42:16.470
at this to design this,
there's two ways that you can do this.

00:42:16.470 --> 00:42:19.620
You can have a UI or an
app that is going to,

00:42:19.620 --> 00:42:24.020
you know, 30 times a second or whatever,
it's going to poll for the

00:42:24.020 --> 00:42:26.870
values of the parameters,
see if anything's changed,

00:42:26.870 --> 00:42:31.420
and that seemed to us a less than
elegant way of dealing with this.

00:42:31.420 --> 00:42:38.660
So we decided to do a notification
service and the notification service is

00:42:38.660 --> 00:42:40.960
aimed at allowing anybody who's using
the app to be able to use the app.

00:42:40.960 --> 00:42:41.320
So we decided to do a notification
service and the notification service

00:42:41.320 --> 00:42:42.810
is aimed at allowing anybody who
wants to know about a parameter

00:42:42.810 --> 00:42:46.880
changing on an audio unit to be
able to listen to that parameter,

00:42:46.890 --> 00:42:50.620
to see that that parameter has changed
and then to react appropriately.

00:42:50.620 --> 00:42:53.310
And then when they want to
set a value of a parameter,

00:42:53.370 --> 00:42:57.220
if they just use the standard
audio unit set parameter call,

00:42:57.220 --> 00:42:59.740
that's not going to
invoke the notification.

00:42:59.740 --> 00:43:04.460
You need to use the AUParameterSet call
which is in this header file.

00:43:04.460 --> 00:43:10.940
And that basically then will tell
the notification mechanism that,

00:43:10.990 --> 00:43:12.600
you know, if you've got anyone
who's listening for this,

00:43:12.600 --> 00:43:15.040
you better tell them about it.

00:43:15.040 --> 00:43:20.350
We've decided to extend this a
little bit in Panther and to include

00:43:20.350 --> 00:43:27.640
the ability to notify state changes
from the audio unit property.

00:43:27.640 --> 00:43:32.160
And so you can do both parameter
changes and property changes

00:43:32.160 --> 00:43:34.960
using this notification mechanism.

00:43:34.960 --> 00:43:39.910
Now one of the important things about
audio units with all of this kind of

00:43:40.100 --> 00:43:44.550
stuff is that we're never going to
know everything that we need to know

00:43:44.550 --> 00:43:48.840
about every possible audio unit that
every developer is ever going to write.

00:43:48.840 --> 00:43:53.320
And so there are mechanisms in place
to be able to share private data with

00:43:53.320 --> 00:43:57.810
private property IDs and all this
kind of thing between your audio units

00:43:57.810 --> 00:44:00.200
and your views or this kind of stuff.

00:44:00.200 --> 00:44:04.240
And so this mechanism can be used to
communicate that there's a need to

00:44:04.290 --> 00:44:08.040
go and get some state that may be in
the audio unit if you're the view.

00:44:08.180 --> 00:44:10.900
And it can be done in
a thread-safe manner.

00:44:10.900 --> 00:44:10.900
So you can do that.

00:44:10.900 --> 00:44:14.890
You can call this sort of
API from your render thread

00:44:15.230 --> 00:44:17.660
as well as from a UI thread.

00:44:17.760 --> 00:44:22.190
The other weakness that I think we had
in Jaguar with the Carbon UI is that we

00:44:22.190 --> 00:44:27.070
had this idea if you're doing automation
that you need to know like start and

00:44:27.070 --> 00:44:31.220
end state as you're doing automation.

00:44:31.220 --> 00:44:33.740
And we sort of put that into
the view and that really wasn't

00:44:33.740 --> 00:44:35.570
the right place for that.

00:44:35.650 --> 00:44:40.490
And it kind of restricted some of the
use of it where the audio unit may

00:44:40.490 --> 00:44:43.660
know that it's a start and end state,
not the view.

00:44:43.660 --> 00:44:48.000
And so we added to the
Panther services for this,

00:44:48.200 --> 00:44:52.040
this idea of a begin and end
of a parameter ramp state.

00:44:52.040 --> 00:44:54.500
So you could imagine if
you've got a control surface,

00:44:54.500 --> 00:44:58.150
when the user touches a control,
some of these control surfaces

00:44:58.220 --> 00:45:00.500
are sensitive to actual touch.

00:45:00.500 --> 00:45:04.300
So you could touch the control and
then that would be a signal to say,

00:45:04.300 --> 00:45:06.950
hey, I'm about to start
ramping this parameter.

00:45:06.960 --> 00:45:10.220
And the UI could reflect that
the user's touched that control.

00:45:10.220 --> 00:45:11.050
00:19:00:00 - 00:19:18:00
Unknown So we've got a control

00:45:11.050 --> 00:45:12.480
with the changing button in the UI.

00:45:12.590 --> 00:45:16.730
And by putting this into the controller,
this means that we can also support

00:45:16.830 --> 00:45:20.630
this with Cocoa UIs as well as
Carbon UIs without having to add

00:45:20.630 --> 00:45:23.130
additional logic to the Cocoa UI.

00:45:23.160 --> 00:45:27.040
So I think this is a very
nice addition to this.

00:45:27.040 --> 00:45:30.190
And as I said before,
this is real time thread safe and

00:45:30.270 --> 00:45:35.900
we'll continue to work very hard
to ensure that that remains true.

00:45:37.200 --> 00:48:20.100
[Transcript missing]

00:48:20.980 --> 00:48:27.180
One of the things that we're working on,
this is to address some concerns

00:48:27.300 --> 00:48:33.380
that were raised by Waves,
who are a very large developer

00:48:33.380 --> 00:48:37.900
of audio processing plugins.

00:48:37.900 --> 00:48:39.900
And they wanted to have a
way to do offline rendering.

00:48:39.900 --> 00:48:44.500
Offline rendering is typically
done when you want to actually

00:48:44.500 --> 00:48:47.200
process a file of data,
and you want to look at the

00:48:47.200 --> 00:48:49.840
whole contents of the file,
not just in real time.

00:48:49.900 --> 00:48:54.980
All of the AudioUnit development that
we've done up until this particular unit

00:48:55.040 --> 00:48:57.800
is really aimed at working in real time.

00:48:57.900 --> 00:49:01.900
And so it has constraints about
having to work in real time.

00:49:01.900 --> 00:49:03.900
You need to report latency.

00:49:03.900 --> 00:49:07.940
You need to report how long it takes
you to process sounds in terms of the

00:49:07.940 --> 00:49:10.900
time delay between input and output.

00:49:11.030 --> 00:49:14.310
With an offline unit,
you need to be able to look at the data,

00:49:14.310 --> 00:49:18.870
all of the data that you're going to
be asked to process before you process.

00:49:18.900 --> 00:49:20.860
So there are two render
phases with an offline unit.

00:49:20.960 --> 00:49:23.900
There's an analyze phase,
and then there's a render phase.

00:49:23.900 --> 00:49:27.160
So if you think of reversing
the sample order in a file,

00:49:27.230 --> 00:49:30.880
you need to actually start at
the end and work your way back.

00:49:30.940 --> 00:49:34.770
If you think of an offline
unit that may normalize,

00:49:34.770 --> 00:49:39.720
you need to look at the whole audio
data before you start to process

00:49:39.720 --> 00:49:42.690
it so you can do the normalization.

00:49:42.850 --> 00:49:47.400
There are not really any
additional API changes for this.

00:49:47.400 --> 00:49:49.260
There are a couple of different flags.

00:49:49.260 --> 00:49:52.920
There are a couple of properties that
are specific for an offline unit.

00:49:52.920 --> 00:49:56.770
There's a new audio unit type AUOL,
audio unit offline.

00:49:56.770 --> 00:50:01.610
It's not in your Panther headers
yet because we're still revising

00:50:01.610 --> 00:50:06.380
and discussing this with Waves
and some other companies.

00:50:06.510 --> 00:50:12.140
This will be published in Panther and
we're getting pretty close.

00:50:12.220 --> 00:50:14.390
If people are interested,
they can contact me and I'll

00:50:14.390 --> 00:50:18.400
send them the spec and the code
that we've got at the moment.

00:50:18.400 --> 00:50:23.080
We will ship an audio unit that
does reversal in the SDK at some

00:50:23.130 --> 00:50:27.560
point as an example and there
will be code there as well as to

00:50:27.560 --> 00:50:30.180
how you host these offline units.

00:50:30.850 --> 00:50:33.460
Okay,
so when I said generalized audio unit,

00:50:33.460 --> 00:50:38.190
we're still sort of like in the
general field at the moment about

00:50:38.680 --> 00:50:40.490
normal types of audio units.

00:50:40.540 --> 00:50:45.500
Now, let's look at some abnormal
type of audio units.

00:50:45.500 --> 00:50:48.700
And one of those types is mixer units.

00:50:48.880 --> 00:50:54.670
So in Jaguar, we had two mixers,
a stereo mixer that takes mono

00:50:54.670 --> 00:50:59.810
or stereo inputs and gives you
a mixed single stereo output.

00:51:00.290 --> 00:51:04.980
And in Jaguar as well, we had a 3D mixer.

00:51:04.980 --> 00:51:08.160
The 3D mixer will take multiple inputs.

00:51:08.650 --> 00:51:11.880
It will have a single output,
and it will be in either two-,

00:51:12.160 --> 00:51:14.570
four-, or five-channel output.

00:51:14.680 --> 00:51:17.230
And the four-channel
is like a quad setup,

00:51:17.300 --> 00:51:21.200
which is pretty much what
we've got in the room today,

00:51:21.310 --> 00:51:26.300
and 5.0, where we don't actually do the
3D stuff into the LFE channel,

00:51:26.300 --> 00:51:30.100
we just do the five channels.

00:51:30.210 --> 00:51:33.200
And what you can do with
this 3D mixer is quite a lot.

00:51:33.200 --> 00:51:35.930
You can pan and localize
within a 3D space.

00:51:36.030 --> 00:51:38.340
You have a number of on/off options.

00:51:38.550 --> 00:51:42.950
And I'll get Chris Rogers to come up,
and we're just going to give you a

00:51:42.950 --> 00:51:45.570
fairly quick demo of the 3D mixer.

00:51:52.820 --> 00:51:56.470
Well, thanks, Bill,
for setting me up there.

00:51:56.520 --> 00:52:01.290
Last year, I gave a more complete
demonstration of the 3D mixer,

00:52:01.330 --> 00:52:06.840
but some things have changed since
last year because developers have

00:52:06.840 --> 00:52:08.670
made some requests of the mixer.

00:52:08.710 --> 00:52:16.800
So we put some new
features into the 3D mixer,

00:52:16.800 --> 00:52:17.500
and we can have a look right here.

00:52:18.040 --> 00:52:21.500
What I have right here
is a simple little app,

00:52:21.520 --> 00:52:25.460
simple little user
interface onto the 3D mixer,

00:52:25.460 --> 00:52:30.690
and it has a number of different
controls for choosing the type

00:52:30.690 --> 00:52:32.880
of rendering for the source.

00:52:32.880 --> 00:52:34.400
In this demo,
there are going to be three sources,

00:52:34.400 --> 00:52:41.030
or there can be up to three sources,
and you can choose equal power panning,

00:52:41.030 --> 00:52:45.180
simple spherical head model,
an HRTF model,

00:52:45.250 --> 00:52:49.030
and these first three are for
rendering to stereo output,

00:52:49.030 --> 00:52:54.150
and then the last two,
sound field and vector based,

00:52:54.150 --> 00:53:00.920
those can be used for stereo, quad,
or 5.0.

00:53:00.920 --> 00:53:05.040
Then over here,
we have some check boxes that let

00:53:05.040 --> 00:53:13.800
certain features of the mixer be enabled
or disabled for individual sources.

00:53:13.960 --> 00:53:18.290
Down here we have master volume control.

00:53:18.330 --> 00:53:22.690
And here this is kind of an
obscure slider that controls

00:53:22.690 --> 00:53:24.760
distance attenuation.

00:53:24.760 --> 00:53:29.290
That is when sources -- when
sound sources get farther away,

00:53:29.290 --> 00:53:30.540
they get quieter.

00:53:30.540 --> 00:53:34.470
But how much quieter do they get,
say if they're 10 meters

00:53:34.480 --> 00:53:37.330
away or 100 meters away,
how much quieter do they get?

00:53:37.470 --> 00:53:40.420
This can control what that
curve is at the falloff.

00:53:40.420 --> 00:53:47.170
And that's a feature that
developers have been asking for.

00:53:47.890 --> 00:53:53.910
Down here in this part of the display,
we have some meters,

00:53:53.910 --> 00:53:58.170
which the 3D mixer now
supports live metering.

00:53:58.240 --> 00:54:02.320
You can meter the input
levels and output levels,

00:54:02.430 --> 00:54:06.500
both RMS power and peak levels.

00:54:06.500 --> 00:54:10.430
And metering is something that we
put into a couple of our audio units,

00:54:10.510 --> 00:54:15.630
and later on today we'll see
that new audio unit matrix

00:54:15.630 --> 00:54:21.250
mixer also supports this,
which is kind of interesting.

00:54:21.330 --> 00:54:27.400
So maybe I should just
bring a source in and

00:54:37.500 --> 00:54:50.500
[Transcript missing]

00:54:58.930 --> 00:55:00.900
Maybe I've turned all my sources off.

00:55:00.900 --> 00:55:06.190
Okay, here we go.

00:55:12.610 --> 00:55:15.870
So, I'm using vector-based
panning right here,

00:55:15.970 --> 00:55:19.840
and I've turned these sources off,
so we're not listening to those,

00:55:19.840 --> 00:55:21.600
we're just listening
to this blue one here.

00:55:21.680 --> 00:55:33.830
But if I put this dot right here,
then we're essentially

00:55:34.180 --> 00:55:36.790
just in the center channel.

00:55:44.700 --> 00:55:48.250
Hold on,
we have the helicopter coming in,

00:55:48.250 --> 00:55:49.080
I'm sorry.

00:55:49.080 --> 00:55:50.080
There he is.

00:55:50.080 --> 00:55:52.130
Let me turn him off.

00:55:52.140 --> 00:55:53.060
OK.

00:55:53.060 --> 00:55:58.180
I think now maybe our meters
will show this a little better.

00:55:58.180 --> 00:55:59.730
OK.

00:55:59.760 --> 00:56:02.360
So, I'm about straight ahead here.

00:56:02.360 --> 00:56:04.200
I should be coming out
of the center speaker.

00:56:04.280 --> 00:56:08.270
And the channel ordering
down here is left,

00:56:08.370 --> 00:56:12.560
right, surround left, right, center.

00:56:20.900 --> 00:56:27.800
[Transcript missing]

00:56:29.800 --> 00:56:38.100
[Transcript missing]

00:56:40.800 --> 00:56:42.560
Okay.

00:56:42.590 --> 00:56:45.980
Now, let me change this sound.

00:56:58.000 --> 00:57:09.800
[Transcript missing]

00:57:14.060 --> 00:57:17.480
It looks like we're running
a little bit short on time,

00:57:17.590 --> 00:57:22.380
so I'll try to wrap it up here.

00:57:23.080 --> 00:57:23.080
Basically,

00:57:23.920 --> 00:57:28.560
The new features that are the most
important are the ability to turn

00:57:28.560 --> 00:57:31.100
off or on individual features here.

00:57:31.100 --> 00:57:33.930
And that affects the performance
that you're going to get.

00:57:33.930 --> 00:57:39.170
This distance filter is a lowpass
filter that makes sounds sound more

00:57:39.170 --> 00:57:41.050
muted as they're getting further away.

00:57:41.060 --> 00:57:43.840
And some developers had
some comments about that,

00:57:43.840 --> 00:57:47.480
that they didn't necessarily want
their sounds to get more muted.

00:57:47.480 --> 00:57:50.380
So there's a way that that
can be turned on or off.

00:57:50.520 --> 00:57:55.750
And any of these characteristics
can be turned on or off separately.

00:57:55.920 --> 00:57:58.330
And as far as performance goes,
we've made some

00:57:58.330 --> 00:58:00.090
optimizations to the mixer.

00:58:00.090 --> 00:58:04.060
And to give you an idea of the
kind of performance that you can

00:58:04.060 --> 00:58:10.200
get for an individual source using
equal power panning and stereo,

00:58:10.200 --> 00:58:14.540
I think on a pretty modest
machine like an 800 megahertz G4,

00:58:14.540 --> 00:58:20.240
you can get a single equal power
source -- -- -- -- -- -- at,

00:58:20.240 --> 00:58:26.190
I think it's 0.18% of the CPU.

00:58:26.290 --> 00:58:30.650
And HRTF, which would be our high-quality
stereo panning mode,

00:58:30.720 --> 00:58:36.920
that's at about .55%
of the CPU per source,

00:58:36.960 --> 00:58:41.300
so a little tiny bit
more than half a percent.

00:58:42.200 --> 00:58:47.100
Now I have a... We'll just move on,
because we're running out of time.

00:58:47.100 --> 00:58:49.100
Okay.

00:58:49.100 --> 00:58:53.100
Go back to the slides.

00:58:53.120 --> 00:58:54.700
Thank you, Chris.

00:59:00.120 --> 00:59:02.200
The other demo that
we were going to show,

00:59:02.200 --> 00:59:04.970
but we're running a bit short,
is a very speed unit,

00:59:05.090 --> 00:59:08.720
and that's also new in Panther,
and you're able to have your

00:59:08.920 --> 00:59:13.250
sound come into the very speed,
and it can go faster or slower.

00:59:13.250 --> 00:59:16.390
It can go kind of a chipmunk effect.

00:59:16.460 --> 00:59:19.150
We'll show you that later on.

00:59:19.210 --> 00:59:24.300
We'll be in a lab tomorrow
from 1:00 to 6:00,

00:59:24.310 --> 00:59:28.190
the QuickTime lab, and we can give you a
demo there if you like.

00:59:29.320 --> 00:59:29.670
Okay.

00:59:29.890 --> 00:59:34.160
So in Panther as well,
we have a matrix mixer.

00:59:34.160 --> 00:59:38.920
Matrix mixer is a very powerful beast,
and we'll be going into some detail

00:59:38.920 --> 00:59:40.820
about that in the next session.

00:59:40.820 --> 00:59:45.040
All mixers have metering
capabilities in Panther,

00:59:45.040 --> 00:59:47.920
so you'll see some of
that in the next demo,

00:59:47.920 --> 00:59:49.180
next session.

00:59:49.180 --> 00:59:52.450
The other type of audio unit
that we have is a converter unit.

00:59:52.450 --> 00:59:56.230
We'll be talking about the audio
converter in the next session as well,

00:59:56.270 --> 00:59:59.180
and this brings some of the
functionality of the audio

00:59:59.190 --> 01:00:01.560
converter into the audio unit world.

01:00:01.560 --> 01:00:06.470
Essentially, all of the conversion
operations to do with PCM audio,

01:00:06.470 --> 01:00:11.270
so sample rates, bit depths,
channel mapping, and so forth.

01:00:11.350 --> 01:00:13.730
And all of this is
configured with properties,

01:00:13.730 --> 01:00:16.580
and actually,
there's very little configuration

01:00:16.790 --> 01:00:20.840
of it for you to do because just
describing to the audio unit what

01:00:20.840 --> 01:00:24.600
your input and your output format is,
is enough to tell the converter

01:00:24.600 --> 01:00:26.040
what work it should do.

01:00:27.860 --> 01:00:33.060
The Converter Unit's functionality is
included as a part of the Output Unit.

01:00:33.060 --> 01:00:35.700
The Output Unit is
interfaced to a device.

01:00:35.700 --> 01:00:39.320
There is no additional latency,
there is no runtime cost to you

01:00:39.470 --> 01:00:41.680
for dealing with the Output Units.

01:00:41.690 --> 01:00:46.690
You can manage how much work
the Output Unit does for you by

01:00:46.720 --> 01:00:51.730
seeing the difference between
the format of the device,

01:00:51.730 --> 01:00:54.890
which is on the Output Unit,
and the format that you provide it.

01:00:55.110 --> 01:00:59.010
In Jaguar, we only did output,
and now our output units do input,

01:00:59.020 --> 01:01:01.870
so that's why they're
RabbitEars output units now.

01:01:01.880 --> 01:01:07.070
In Panther,
the output units will do output

01:01:07.190 --> 01:01:14.520
as they do in Jaguar on bus one,
and on element one or bus zero, I mean,

01:01:14.520 --> 01:01:17.380
on element one or bus one,
you can do input.

01:01:17.380 --> 01:01:19.550
And so what does this look like?

01:01:19.620 --> 01:01:20.770
It looks like this.

01:01:20.780 --> 01:01:22.300
So I'm going to use the slide.

01:01:22.300 --> 01:01:24.020
You know,
they hate us using these things,

01:01:24.020 --> 01:01:24.670
but I love it.

01:01:24.760 --> 01:01:26.490
So here's your output unit.

01:01:26.500 --> 01:01:32.140
On the output side,
here is your device output,

01:01:32.140 --> 01:01:34.750
and this is on bus zero,
and then this is either a

01:01:34.750 --> 01:01:38.420
callback or a connection that
you make to the audio unit,

01:01:38.420 --> 01:01:41.230
and this is if you're using this unit,
this is what you're doing today.

01:01:41.240 --> 01:01:47.100
In Panther, you can also see if
there is input available.

01:01:47.100 --> 01:01:52.070
There's a property to query that,
and then the device's input is actually

01:01:52.070 --> 01:01:53.930
on the input side of the output unit.

01:01:53.940 --> 01:01:54.960
Confused yet?

01:01:55.150 --> 01:01:56.330
It took me a while.

01:01:56.380 --> 01:02:02.060
And then the application actually
calls audio unit render for bus one,

01:02:02.060 --> 01:02:04.460
and that's where it gets
the input from the device.

01:02:04.460 --> 01:02:07.220
And it can do the
conversion for you as well.

01:02:07.220 --> 01:02:11.380
So if your device is 20 channels
and you only want four channels,

01:02:11.380 --> 01:02:15.040
then it will remove those 20 channels
and just give you the four channels,

01:02:15.040 --> 01:02:18.390
and you can tell the output
unit which four channels that

01:02:18.390 --> 01:02:20.860
you want from the device,
including rate conversion,

01:02:20.860 --> 01:02:21.740
all this sort of thing.

01:02:21.740 --> 01:02:27.600
And if your device just has input,
and you need to know when to get input,

01:02:27.600 --> 01:02:30.740
then you can get a callback,
and it will tell you, hey,

01:02:30.740 --> 01:02:32.150
the input's ready, go and get it.

01:02:32.220 --> 01:02:35.500
And so that's new in Panther.

01:02:35.500 --> 01:02:36.750
Thank you.

01:02:37.530 --> 01:02:40.490
Okay, so audio units,
we talked about connection,

01:02:40.520 --> 01:02:43.370
we talked about wanting to be
able to connect all these up

01:02:43.370 --> 01:02:48.750
and we have a structure in the
audio toolbox APIs called AUGraph

01:02:48.750 --> 01:02:52.460
and the AUGraph manages the
connections between these units.

01:02:52.460 --> 01:02:56.750
It'll manage the state,
it has a very abstract representation

01:02:56.750 --> 01:03:01.320
of the graph and then the graph itself
has a couple of different states.

01:03:01.320 --> 01:03:05.590
You open the graph and that'll basically
open the audio units that you've

01:03:05.590 --> 01:03:09.900
described as being a part of your graph,
then you can initialize them and then

01:03:09.900 --> 01:03:11.860
you can actually start the graph running.

01:03:11.860 --> 01:03:15.640
And you can update the state of
the graph while it's changing.

01:03:15.640 --> 01:03:18.980
You can make or break connections,
you can have a bunch of audio

01:03:18.980 --> 01:03:22.100
units sitting off to the
side that may be one channel,

01:03:22.100 --> 01:03:27.110
one chain into a mixer or something and
then you can just connect that chain in,

01:03:27.110 --> 01:03:31.440
play your sound, disconnect it and the
graph will do all of this.

01:03:31.440 --> 01:03:33.960
It'll manage the different
threads of the thread that

01:03:34.070 --> 01:03:36.750
you're doing the rendering in,
the thread that you're doing the

01:03:36.750 --> 01:03:41.220
state management from and it'll
just make this a lot simpler to do

01:03:41.350 --> 01:03:45.960
than you can write your own code
but if you're going to do this,

01:03:45.960 --> 01:03:48.960
it's a good API to look at.

01:03:48.960 --> 01:03:53.400
Another API in the toolbox
is the Music Sequence API.

01:03:53.400 --> 01:03:57.980
Music sequences are a collection
of events and there's really two

01:03:57.980 --> 01:04:04.040
different types of events and we
have two different types of tracks.

01:04:04.040 --> 01:04:05.990
They're still just basically a track.

01:04:06.080 --> 01:04:09.120
A music sequence has
some concept of tempo.

01:04:09.120 --> 01:04:14.780
Music sequences talk about their
timing in terms of beats and so a tempo

01:04:14.780 --> 01:04:17.120
describes how many beats per second.

01:04:17.120 --> 01:04:21.040
If you want to deal in seconds,
you can just make a sequence with the

01:04:21.040 --> 01:04:24.610
tempo event of 60 beats per minute
and then you can deal in seconds.

01:04:24.620 --> 01:04:29.570
And then you've got any number of events
tracks and the events tracks can take

01:04:29.940 --> 01:04:31.680
any number of different types of events.

01:04:31.680 --> 01:04:34.600
You can have MIDI events,
you can have user events where you

01:04:34.600 --> 01:04:38.140
can put your own data in there and
you can have parameter events so

01:04:38.140 --> 01:04:44.860
you can talk directly to particular
parameters on different audio units.

01:04:44.860 --> 01:04:47.830
And of course the connection is
that you have a sequence and you

01:04:47.830 --> 01:04:51.600
connect that up to a graph and
we'll show you that in a minute.

01:04:51.860 --> 01:04:55.360
You can create a sequence
from a MIDI file,

01:04:55.360 --> 01:04:57.580
or you can create a
sequence programmatically.

01:04:57.580 --> 01:05:01.040
You can once created a sequence,
you can save the sequence

01:05:01.040 --> 01:05:02.340
off to a MIDI file.

01:05:02.340 --> 01:05:05.650
We'll only save the MIDI type events that
are in that sequence to the MIDI file,

01:05:05.650 --> 01:05:06.320
obviously.

01:05:06.320 --> 01:05:09.740
We won't do the other ones.

01:05:09.740 --> 01:05:11.500
And you can iterate over the events.

01:05:11.500 --> 01:05:15.980
You can loop, mute,
solo tracks when you're playing them.

01:05:15.980 --> 01:05:20.510
And you can copy, paste, insert,
edit them, and these can be edited while

01:05:20.510 --> 01:05:24.330
the sequence is actually
being applied in real time.

01:05:24.730 --> 01:05:28.920
And you can target the tracks that are in
a sequence to two different destinations.

01:05:28.920 --> 01:05:32.740
You can target them to a specific
AudioUnit that's in a graph that

01:05:32.920 --> 01:05:36.420
you've attached to the sequence,
or you can target a sequence's

01:05:36.420 --> 01:05:42.740
track to a MIDI endpoint,
so you could be sending from

01:05:42.990 --> 01:05:43.790
a sequence that you're playing
directly out to a MIDI device.

01:05:44.200 --> 01:08:52.000
[Transcript missing]

01:08:52.510 --> 01:08:56.800
Okay, so they're the four frameworks:
Core Audio for drivers,

01:08:56.800 --> 01:08:58.340
Core MIDI for MIDI.

01:08:58.340 --> 01:09:02.530
The AudioUnits really,
that framework just publishes the API for

01:09:02.570 --> 01:09:07.530
the extendable AudioUnits and Codecs,
and then the toolbox for formats, files.

01:09:07.940 --> 01:09:12.110
We'll be talking a lot about the
format stuff in the next session.

01:09:12.990 --> 01:09:15.500
Wrap-up.

01:09:15.500 --> 01:09:18.480
Roadmap, there's some of the sessions.

01:09:18.480 --> 01:09:20.570
We have the Audio and
QuickTime session tomorrow,

01:09:20.570 --> 01:09:23.130
which is going to be a
very interesting session,

01:09:23.130 --> 01:09:24.620
I think, for you to go to.

01:09:24.730 --> 01:09:35.040
Feedback forum for us is after then,
and Nick and Craig and myself

01:09:35.040 --> 01:09:35.040
and others will be there.

01:09:35.040 --> 01:09:35.040
Who to contact?

01:09:35.770 --> 01:09:41.020
And for more information,
we've got the Audio Technologies for

01:09:41.050 --> 01:09:44.520
Mac OS X website,
developer.apple.com/audio.