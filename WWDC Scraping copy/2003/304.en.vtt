WEBVTT

00:00:25.150 --> 00:00:29.720
As you probably all know,
we jammed a new GCC 3.3

00:00:29.720 --> 00:00:36.870
compiler this week at the show,
and today what I would like to do

00:00:37.160 --> 00:00:42.370
is introducing you to that compiler,
answering any questions you may have that

00:00:42.780 --> 00:00:48.570
are preventing you from moving forward,
and I encourage you to move to 3.3.

00:00:48.570 --> 00:00:53.010
Also, I want to introduce you to
one of our partners from IBM.

00:00:53.090 --> 00:00:58.390
We work very closely in terms
of delivering the 3.3 compiler,

00:00:58.440 --> 00:01:03.370
particularly focused on the
G5 and the new G5 system,

00:01:03.400 --> 00:01:09.090
and also leave you with some
idea of future directions for us.

00:01:09.750 --> 00:01:15.840
So we had a challenge in putting
together the 3.3 compiler.

00:01:15.840 --> 00:01:19.090
We wanted to deliver a very
robust compiler because we

00:01:19.090 --> 00:01:21.320
know that's what you expect.

00:01:21.320 --> 00:01:24.140
We wanted to address compile speed.

00:01:24.190 --> 00:01:28.220
We've heard very much from you in
terms of compile speed and comparing

00:01:28.220 --> 00:01:31.660
us against the Code Warrior compiler.

00:01:31.660 --> 00:01:35.010
And also in terms of code quality
because we were introducing

00:01:35.010 --> 00:01:38.000
a brand new system this week,
a G5 system,

00:01:38.000 --> 00:01:41.860
and we needed to have terrific
optimizations for that system

00:01:41.980 --> 00:01:43.440
coming out of the chute.

00:01:43.440 --> 00:01:45.370
Well, that's a very hard problem.

00:01:45.370 --> 00:01:49.450
I've worked in the compiler area
for quite a number of years,

00:01:49.450 --> 00:01:54.610
and usually you get to pick two of
those three and you can deliver either

00:01:54.610 --> 00:01:59.270
a robust compiler with a lot of great
code quality or you can deliver a

00:01:59.440 --> 00:02:02.440
robust compiler that's really fast.

00:02:02.600 --> 00:02:05.130
But to try and deliver a
compiler that's really that

00:02:05.320 --> 00:02:07.080
meets all three of those goals.

00:02:07.080 --> 00:02:08.240
This is a real challenge.

00:02:10.210 --> 00:02:12.560
So I want to talk a little
bit about why we were able

00:02:12.560 --> 00:02:16.620
to accomplish that challenge,
and I think you'll see that when

00:02:16.620 --> 00:02:20.330
you install and use GCC 3.3.

00:02:20.450 --> 00:02:24.110
First of all, as you know,
it's based on the GCC,

00:02:24.110 --> 00:02:31.860
the Free Software Foundation technology,
and today that technology is very mature

00:02:31.860 --> 00:02:35.240
and stable and continuing to evolve.

00:02:35.330 --> 00:02:40.860
Primarily from the advent of
Linux systems and Linux system

00:02:41.290 --> 00:02:47.800
vendors putting together compiler
production release compilers.

00:02:47.910 --> 00:02:54.210
Since that time, the GCC compilers really
matured significantly.

00:02:54.280 --> 00:02:58.160
There are billions of lines of
code that have been put through it.

00:02:58.280 --> 00:03:04.360
We build our own Mac OS X operating
system with GCC compiler.

00:03:04.400 --> 00:03:09.830
We have very extensive test suite,
something on the order of 30,000

00:03:09.830 --> 00:03:12.510
tests a day and growing all the time.

00:03:12.680 --> 00:03:17.630
So just a very robust experience,
and I want to assure you that

00:03:17.630 --> 00:03:22.210
when you install the 3.3 compiler,
you will see the same thing.

00:03:22.280 --> 00:03:28.980
One example is one of our early
seeds for 3.3 was one of you

00:03:29.150 --> 00:03:33.420
folks with an application of about
26 million lines of C++ code.

00:03:33.420 --> 00:03:41.490
That entire application was migrated
to 3.3 with essentially no problems.

00:03:42.800 --> 00:03:44.240
So what does Apple contribute?

00:03:44.340 --> 00:03:48.780
Because we also have been
putting a big effort in.

00:03:48.780 --> 00:03:52.740
And I want to tell you that
we're a very active member of

00:03:52.740 --> 00:03:55.360
the free software community.

00:03:55.360 --> 00:04:00.140
We have experienced engineers on
staff that have worked in that

00:04:00.140 --> 00:04:02.660
community for quite a while.

00:04:02.660 --> 00:04:06.060
We are an active maintainer.

00:04:06.060 --> 00:04:10.560
The Free Software Foundation has
actually recognized some of our

00:04:10.560 --> 00:04:17.840
efforts and they have made Darwin a
reference platform for GCC releases.

00:04:17.840 --> 00:04:21.160
Something that is really fantastic.

00:04:21.160 --> 00:04:25.340
New optimizations, as I mentioned,
G5 was really important

00:04:25.490 --> 00:04:27.340
to us for this release.

00:04:27.340 --> 00:04:32.690
This system, as you've probably seen in
some other presentations,

00:04:32.690 --> 00:04:39.240
is an order of magnitude more
complex to deal with than the G4.

00:04:39.240 --> 00:04:44.150
And our mission, part of our mission,
is to make that happen for you so

00:04:44.320 --> 00:04:49.140
that you don't have to do all of the
work of extracting the power from G5.

00:04:49.140 --> 00:04:51.720
So we've done quite a
bit of optimization.

00:04:51.720 --> 00:04:53.860
You'll hear some about that today.

00:04:54.000 --> 00:04:58.660
You'll hear some from our partner
IBM who worked with us on that.

00:04:58.660 --> 00:05:01.520
As I mentioned,
compilation speed is important.

00:05:01.520 --> 00:05:06.080
And so we made that a high
priority within our organization.

00:05:06.080 --> 00:05:08.360
And I will show you some of
the performance improvements

00:05:08.460 --> 00:05:10.180
in terms of compilation speed.

00:05:10.180 --> 00:05:12.940
And finally, just general maintenance.

00:05:12.940 --> 00:05:15.160
Our customers report problems.

00:05:15.160 --> 00:05:16.160
We fix them.

00:05:16.160 --> 00:05:18.540
We put them into the community.

00:05:18.740 --> 00:05:22.600
And so we're very active
and correct members,

00:05:22.600 --> 00:05:24.700
if you will, of the community.

00:05:24.700 --> 00:05:30.700
So let me get into talking about
the three things that we focused on

00:05:30.700 --> 00:05:34.890
for this release besides robustness.

00:05:35.340 --> 00:05:39.290
In the language feature area,
as you know,

00:05:39.340 --> 00:05:44.560
GCC is already very compliant
with the ISO and ANSI standards.

00:05:44.620 --> 00:05:49.080
And so it's mature in that way,
but it's not 100% compliant.

00:05:49.250 --> 00:05:50.800
And so it continues to grow.

00:05:50.800 --> 00:05:54.010
And in this release,
you'll see some of that,

00:05:54.100 --> 00:06:00.120
particularly with respect to now
being able to identify incorrect

00:06:00.290 --> 00:06:05.140
code that may have slipped by in
earlier releases of the Compiler.

00:06:05.210 --> 00:06:11.110
We've also added a feature in
Panther wide character support,

00:06:11.110 --> 00:06:13.200
a missing feature.

00:06:13.200 --> 00:06:16.640
Now, as you know,
within our own frameworks

00:06:16.640 --> 00:06:20.200
and within Apple,
we encourage you to use Unicode,

00:06:20.200 --> 00:06:24.700
which is a much more powerful means
of dealing with wide characters.

00:06:24.700 --> 00:06:30.250
But we have heard your desire
to have applications more easily

00:06:30.250 --> 00:06:33.200
ported into our environment.

00:06:33.200 --> 00:06:35.180
And in some cases,
that requires a lot of work.

00:06:35.680 --> 00:06:39.180
So that will be there
with the Panther release.

00:06:39.180 --> 00:06:42.710
You will not have it with Jaguar.

00:06:42.980 --> 00:06:49.080
Objective C and Objective C++, of course,
we maintain and we do

00:06:49.080 --> 00:06:52.140
enhancement in this.

00:06:52.140 --> 00:06:55.760
One of the problems that you
have told us about is that we

00:06:55.800 --> 00:07:00.820
did not have an exception model,
particularly for Objective C.

00:07:00.850 --> 00:07:02.470
We've added that.

00:07:02.560 --> 00:07:08.490
That's also available in conjunction
with the Panther OS release.

00:07:08.500 --> 00:07:13.510
Finally, and I know you've heard some of
these things in other forums,

00:07:13.510 --> 00:07:18.790
but finally, we've added another
migration tool for you,

00:07:18.900 --> 00:07:23.590
which is the ability to use
inline assembly or port inline

00:07:23.590 --> 00:07:26.260
assembly from the Code Warrior.

00:07:26.480 --> 00:07:29.520
So completely compatible
with Code Warrior,

00:07:29.520 --> 00:07:33.290
other than bugs you may find
since it's a brand new feature.

00:07:33.340 --> 00:07:35.460
But I think it's pretty robust.

00:07:35.460 --> 00:07:38.770
We've ported quite a bit of code with it.

00:07:40.080 --> 00:07:47.360
So, compatibility from release to release
is always a concern and an issue.

00:07:47.360 --> 00:07:51.180
The main thing I'd like to point out
to you is what you see here is a very

00:07:51.180 --> 00:07:54.340
short list of issues to deal with.

00:07:54.340 --> 00:07:58.760
So, we're compatible in many, many ways.

00:07:58.760 --> 00:08:02.820
One of the things that you will
want to do though is that you will

00:08:02.820 --> 00:08:05.560
want to rebuild your C++ apps.

00:08:05.560 --> 00:08:11.580
A necessity in terms of making
some enhancements to C++,

00:08:11.590 --> 00:08:14.660
we've had an ABI change.

00:08:14.660 --> 00:08:21.620
And so, you simply just need to
recompile all of your C++ apps.

00:08:22.300 --> 00:09:20.800
[Transcript missing]

00:09:21.850 --> 00:09:28.060
The other thing that we have done
within GCC 3.3 is that in looking

00:09:28.060 --> 00:09:34.870
at the migration of some code,
people were getting tripped up

00:09:34.870 --> 00:09:36.410
a little bit with the flags.

00:09:36.550 --> 00:09:40.100
We had certain flags that
you use for CPP Precomp.

00:09:40.190 --> 00:09:43.870
We have some others for PFE,
and now we have PCH flags.

00:09:43.880 --> 00:09:48.300
And so if you were in your
development environment,

00:09:48.300 --> 00:09:53.400
getting those flags corrected was
recognizing that you needed to

00:09:53.400 --> 00:09:55.300
correct them even was a problem.

00:09:55.300 --> 00:10:00.660
And so we've made the use of
invalid flags for the particular

00:10:00.660 --> 00:10:04.000
compiler you're using a warning.

00:10:04.000 --> 00:10:05.770
So you'll get a heads up.

00:10:05.770 --> 00:10:11.000
If you see warnings from compiler
flags now that you hadn't seen before,

00:10:11.000 --> 00:10:13.240
you should deal with those.

00:10:13.860 --> 00:10:16.770
They're really there to
try and help you out.

00:10:17.990 --> 00:10:26.900
One of the things that we get as a
result of deprecating CPP Precomp

00:10:26.900 --> 00:10:33.500
is that CPP Precomp was built on a
preprocessor model which was KNR based.

00:10:33.580 --> 00:10:38.260
And so you had to flip some
switches within the compiler if

00:10:38.260 --> 00:10:42.800
you wanted to actually use the
ANSI standards C preprocessor.

00:10:42.890 --> 00:10:47.400
Now that we no longer
have that encumbrance,

00:10:47.440 --> 00:10:52.530
we have made the default
CPP Precomp CPP preprocessor

00:10:53.050 --> 00:10:55.700
the ANSI standard preprocessor.

00:10:55.780 --> 00:11:03.080
It aligns us with all other GCC compilers
that are being delivered today.

00:11:03.770 --> 00:11:06.360
And finally,
one other flag that I would just

00:11:06.360 --> 00:11:13.720
warn you about because we've seen
some resulting difficulty with this

00:11:13.860 --> 00:11:19.470
as well is the no standard include
flag was originally intended to

00:11:19.470 --> 00:11:23.220
not look in any system directories.

00:11:23.220 --> 00:11:27.080
We found that we actually had a
problem with the implementation

00:11:27.340 --> 00:11:32.610
in the 3.1 compiler and it,
in fact, was looking and finding header

00:11:32.610 --> 00:11:34.860
files in a system directory.

00:11:34.990 --> 00:11:37.520
Well, that's corrected now.

00:11:37.520 --> 00:11:40.800
And so if, in fact,
you were taking advantage of

00:11:40.800 --> 00:11:46.580
the fact that certain system
directories were being searched,

00:11:46.580 --> 00:11:51.050
then you'll need to
deal with that as well.

00:11:53.100 --> 00:13:21.400
[Transcript missing]

00:13:22.040 --> 00:13:28.020
This makes the assumption that header
files are a significant portion of

00:13:28.020 --> 00:13:30.440
your actual compilation process.

00:13:30.440 --> 00:13:34.470
And that's certainly true if you're
using large frameworks like Carbon or

00:13:34.590 --> 00:13:38.000
Cocoa or AppKit or others like that.

00:13:38.000 --> 00:13:43.710
So your code is typically a very small
portion of what is actually compiled

00:13:43.710 --> 00:13:46.960
when you're building files like that.

00:13:47.000 --> 00:13:50.980
To make the best use of
pre-compiled headers,

00:13:51.060 --> 00:13:55.990
it works best if you can actually
identify a common set of headers

00:13:56.000 --> 00:14:01.890
that are used by all of the files
that you're building in a project.

00:14:02.000 --> 00:14:07.570
What you can do with that is that
you can create a prefix header,

00:14:07.650 --> 00:14:11.320
as we call it,
which is a pre-compiled header that

00:14:11.320 --> 00:14:13.990
contains those common header files.

00:14:14.000 --> 00:14:16.000
Then you simply include that
prefix header in the header file.

00:14:16.000 --> 00:14:21.030
And that prefix header in your file that
you're building and the compiler will

00:14:21.030 --> 00:14:27.150
restore a significant amount of state,
bypass all of that compilation process,

00:14:27.270 --> 00:14:31.000
and move straight into
compiling the rest of the code.

00:14:33.160 --> 00:14:37.960
The next feature is
predictive compilation.

00:14:37.960 --> 00:14:40.600
And I know that this has been
talked about a little bit

00:14:40.600 --> 00:14:42.070
in the Xcode discussions.

00:14:42.160 --> 00:14:47.800
I have a picture maybe that
will help you understand.

00:14:47.800 --> 00:14:52.600
In predictive compilation,
we once again are making the assumption

00:14:52.600 --> 00:14:58.260
that the header files are a big
portion of your compilation process.

00:14:58.260 --> 00:15:01.610
And furthermore,
if you're going to modify a header,

00:15:01.610 --> 00:15:04.940
you do that in the context of
modifying that header file,

00:15:05.060 --> 00:15:08.080
not the source file you're editing.

00:15:08.080 --> 00:15:11.560
And so what happens with
predictive compilation is that

00:15:11.560 --> 00:15:16.530
when you begin editing a file,
the compiler in the background begins the

00:15:16.530 --> 00:15:19.580
compilation process on the header files.

00:15:19.580 --> 00:15:23.220
And it will proceed up until the
point where your code begins,

00:15:23.220 --> 00:15:26.120
the code that you're working on.

00:15:26.120 --> 00:15:30.790
Then once you save that code,
the compiler proceeds on and predicts.

00:15:30.900 --> 00:15:34.660
And predictively compiles
that file for you.

00:15:37.840 --> 00:15:43.300
You can see in the timeline that
I provided here a representation of that.

00:15:44.900 --> 00:17:23.000
[Transcript missing]

00:17:23.180 --> 00:17:28.100
The middle point,
which we offered in December tool set,

00:17:28.190 --> 00:17:34.010
primarily was the addition of being able
to use the dual processor on your tower.

00:17:34.010 --> 00:17:38.040
So that using both processors
we were able to significantly

00:17:38.040 --> 00:17:40.090
reduce the amount of compile time.

00:17:40.540 --> 00:17:42.090
Still had PFE though.

00:17:43.100 --> 00:17:48.710
With the introduction this
week of GCC 3.0 and Xcode,

00:17:48.830 --> 00:17:53.630
PCH is the new capability and
you'll see on the chart there

00:17:53.630 --> 00:18:00.030
the performance over and above
PFE we're able to obtain with PCH.

00:18:00.100 --> 00:18:03.740
I wanted to draw your attention
though to one other point on there

00:18:03.740 --> 00:18:07.920
and that's the green one down at the
bottom that says distributed build.

00:18:08.100 --> 00:18:12.100
This is the result of building this
application with six Xcode components.

00:18:13.170 --> 00:18:16.080
So we have two Xserves,
dual processor Xserves.

00:18:16.100 --> 00:18:19.100
Six because we had them available.

00:18:19.100 --> 00:18:25.100
Actually, don't know that this app
required the use of all six.

00:18:25.100 --> 00:18:31.100
But essentially you have a
means now of adding horsepower

00:18:31.100 --> 00:18:37.070
to get faster performance,
even above dual processor.

00:18:40.180 --> 00:18:43.330
So code quality,
and I mentioned that we had

00:18:43.330 --> 00:18:46.940
a big focus on code quality,
particularly with respect

00:18:46.950 --> 00:18:50.040
to the G5 processor.

00:18:50.270 --> 00:18:56.310
When you're in the process of trying to
focus on code quality within compilers,

00:18:56.800 --> 00:19:01.870
probably the most important tool
you can have is a real benchmark.

00:19:01.980 --> 00:19:06.990
And that's a benchmark that is
in a harness so it's easy to run.

00:19:07.150 --> 00:19:10.020
It provides reproducible results.

00:19:10.090 --> 00:19:16.650
It represents applications
similar to what you deal with.

00:19:16.780 --> 00:19:21.190
And prior to G5,
we had used an internal benchmark

00:19:21.300 --> 00:19:23.830
that was called Skidmarks.

00:19:24.010 --> 00:19:30.730
And Skidmarks was composed of kernels
of code from various applications

00:19:30.730 --> 00:19:34.510
that we felt were important in Apple.

00:19:34.680 --> 00:19:37.720
When we reached G5, though,
we had a problem.

00:19:37.720 --> 00:19:46.260
The problem was that not only were those
files small enough to fit into cache

00:19:46.260 --> 00:19:51.450
so that they didn't really represent
true applications on the system,

00:19:51.450 --> 00:19:58.270
but also they weren't self-checking
such that if we broke an optimization,

00:19:58.330 --> 00:20:02.200
the code might still run and
produce incorrect results.

00:20:02.200 --> 00:20:03.820
We didn't have an idea of that.

00:20:03.820 --> 00:20:06.000
We just knew how fast it ran.

00:20:06.010 --> 00:20:13.660
So we looked around in the industry
and we chose the spec benchmark.

00:20:13.660 --> 00:20:17.690
There are pluses and minuses
with the spec benchmark.

00:20:17.690 --> 00:20:21.560
You can argue as to whether
they're representative of

00:20:21.570 --> 00:20:26.230
Macintosh applications or not,
but we determined that they

00:20:26.230 --> 00:20:30.060
were close enough that we
could make some good progress.

00:20:30.220 --> 00:20:33.400
And, oh, by the way,
we also needed to produce spec

00:20:33.400 --> 00:20:36.080
numbers for this new processor.

00:20:36.080 --> 00:20:43.970
So spec represents 12 integer benchmarks,
14 floating point benchmarks.

00:20:43.970 --> 00:20:48.980
They're real applications that have
been encapsulated into the test bench,

00:20:48.980 --> 00:20:55.750
and they run in a harness and they're
predictable and validate their results.

00:20:56.240 --> 00:21:02.580
So let me just show you the results of
G5 performance with the spec benchmarks.

00:21:02.580 --> 00:21:09.720
And what I'm comparing here is our 3.1
compiler versus our 3.3 compiler today.

00:21:09.720 --> 00:21:14.100
So the compiler you're using today
versus the one that hopefully you'll

00:21:14.220 --> 00:21:16.540
be using later on this afternoon.

00:21:16.540 --> 00:21:20.710
You can see from specint,
and this is an aggregate across

00:21:20.710 --> 00:21:25.910
the 12 benchmarks in specint,
that we actually have a 17%

00:21:25.980 --> 00:21:34.590
performance increase over what
we're able to extract from the 3.1

00:21:35.780 --> 00:21:40.820
Correspondingly for Floating Point,
and this is a Floating

00:21:40.820 --> 00:21:46.550
Point machine as has been noted
in almost every presentation.

00:21:46.650 --> 00:21:50.290
In Floating Point,
we're able to get 30% better

00:21:50.290 --> 00:21:55.370
performance than we can with
the 3.1 compiler on a G5,

00:21:55.370 --> 00:22:00.210
and this is a single processor G5 2 GHz.

00:22:02.460 --> 00:22:09.860
So what does this mean for you in terms
of how can you take advantage and build

00:22:09.860 --> 00:22:13.140
your code for the G5 and get performance?

00:22:13.240 --> 00:22:17.530
Well, there are several situations
that you may be dealing with.

00:22:17.800 --> 00:22:20.940
First of all,
you may have an app that you want to

00:22:20.940 --> 00:22:24.540
run on more systems than just the G5.

00:22:24.540 --> 00:22:30.320
You may want to have that app which has
some computationally intensive code,

00:22:30.340 --> 00:22:34.180
but by and large,
the rest of the app is not dependent

00:22:34.220 --> 00:22:37.920
upon the performance of a G5 system.

00:22:37.920 --> 00:22:42.890
And so you might break that app up
such that you put the computational

00:22:42.890 --> 00:22:46.280
intensive portion into a runtime library.

00:22:46.500 --> 00:22:54.560
You tune that very heavily for G5 and
leave the rest of your code as G4 or G3,

00:22:54.560 --> 00:23:02.300
and you can produce runtime libraries
for each category of system.

00:23:02.430 --> 00:23:09.610
You can do that by turning on the
MCPU Frag and getting G5 instructions

00:23:10.180 --> 00:23:14.260
and M-Tune and getting G5 scheduling.

00:23:14.730 --> 00:23:25.840
Let's suppose though that your app also
uses long longs or double data types.

00:23:25.840 --> 00:23:33.520
Then you may want to take advantage of
the 64-bit arithmetic power of the G5.

00:23:33.600 --> 00:23:39.460
And what we have provided if you use
the Empower PC64 switch is that you

00:23:39.460 --> 00:23:46.480
actually enable 64-bit arithmetic and
it does amazing things then with your

00:23:46.840 --> 00:23:48.600
long long arithmetic or your doubles.

00:23:48.600 --> 00:23:55.300
And loading and storing 64 bits
and doing arithmetic on that.

00:24:02.440 --> 00:24:05.650
Believe me, you'll applaud once you've
had a chance to taste it,

00:24:05.650 --> 00:24:08.500
if you're using that.

00:24:09.100 --> 00:25:12.600
[Transcript missing]

00:25:14.790 --> 00:25:17.560
So let me call David Edelsohn
up to the stage.

00:25:17.560 --> 00:25:23.230
David and others within IBM have worked
very heavily with us on optimizing

00:25:23.330 --> 00:25:26.420
for the G5 and the 3.3 release.

00:25:26.420 --> 00:25:27.030
David?

00:25:27.040 --> 00:25:30.250
Thanks very much, Ron.

00:25:33.160 --> 00:25:37.600
So my name is David Edelsohn,
and I work at IBM Research.

00:25:37.600 --> 00:25:41.390
My main focus there is on open
source issues and technology,

00:25:41.460 --> 00:25:42.810
particularly GCC.

00:25:42.830 --> 00:25:47.160
I'm glad to see so many people here
at the conference interested in GCC.

00:25:47.160 --> 00:25:49.900
So first let me give you a
little idea of what I'm going to

00:25:49.900 --> 00:25:51.180
talk about in this presentation.

00:25:51.180 --> 00:25:56.340
I'm going to talk about the PowerPC 970
processor and issues in the processor

00:25:56.350 --> 00:26:00.380
that are important for a compiler to
target to get the highest performance.

00:26:00.380 --> 00:26:04.210
We're also going to talk about how
we have optimized GCC to extract

00:26:04.320 --> 00:26:07.660
that best performance on this
processor that Apple is now using.

00:26:07.660 --> 00:26:10.810
And we're going to mention a little
bit about the future optimizations

00:26:10.810 --> 00:26:15.330
that are going to be coming down the
pike in later releases of GCC and about

00:26:15.330 --> 00:26:20.030
how IBM and Apple are both working
together with the open source community

00:26:20.360 --> 00:26:26.300
to engage them and produce the best
compiler for the PowerPC processors.

00:26:26.300 --> 00:26:29.660
So let's start with a little bit of
information about this processor.

00:26:29.730 --> 00:26:32.510
This big step in processor performance.

00:26:32.510 --> 00:26:36.670
We now have a 64-bit
PowerPC processor on the desktop.

00:26:36.670 --> 00:26:42.670
The PowerPC architecture was designed
from day one as a 64-bit architecture.

00:26:42.970 --> 00:26:46.570
The previous implementations
have been the 32-bit subset,

00:26:46.570 --> 00:26:50.580
and now we have an implementation
in Apple's computers that use

00:26:50.700 --> 00:26:53.300
the full 64-bit architecture.

00:26:53.300 --> 00:26:56.950
And this architecture has instructions
that operate on both 32-bit

00:26:57.070 --> 00:26:57.970
size data and 64-bit size data.

00:26:57.970 --> 00:26:58.680
And the architecture is based on the
32-bit size data and 64-bit size data.

00:26:58.680 --> 00:26:58.680
And the architecture is based on the
32-bit size data and 64-bit size data.

00:26:58.680 --> 00:26:58.680
And the architecture is based on the
32-bit size data and 64-bit size data.

00:26:58.680 --> 00:26:59.670
And the architecture is based on the
32-bit size data and 64-bit size data.

00:26:59.680 --> 00:27:03.670
And in 64-bit mode,
when it's operating on

00:27:03.680 --> 00:27:06.860
twice the amount of data,
and it's the same performance whether

00:27:06.860 --> 00:27:10.240
you're in the 32-bit mode or 64-bit mode,
same latency,

00:27:10.240 --> 00:27:13.610
the same speed of the instructions,
and you're operating on

00:27:13.610 --> 00:27:15.280
twice the amount of data.

00:27:15.280 --> 00:27:18.460
This processor has a lot of
resources available at its

00:27:18.570 --> 00:27:22.440
disposal to attack whatever
application you have to throw at it.

00:27:22.440 --> 00:27:25.830
It has two complete symmetric
floating point units.

00:27:25.830 --> 00:27:28.300
It has two symmetric load store units.

00:27:28.680 --> 00:27:33.680
It has two almost symmetric instruction
integer units in this processor.

00:27:33.730 --> 00:27:37.400
And these are a lot of capabilities
now to bring to bear on your problems.

00:27:37.400 --> 00:27:41.000
And this increase in resources
is an increase in performance

00:27:41.000 --> 00:27:42.040
for your application.

00:27:43.380 --> 00:27:49.290
So this is a pictorial depiction
of the processor core in the 970.

00:27:49.290 --> 00:27:53.180
I just want you to have a
visual representation for this

00:27:53.180 --> 00:27:55.890
processor in the upcoming slides.

00:27:55.970 --> 00:28:01.100
So let's go through and talk about how an
instruction flows through this processor.

00:28:01.200 --> 00:28:09.100
First, instructions are fetched from the
L1 cache into the instruction queue.

00:28:09.220 --> 00:28:12.960
And in this instruction queue,
the instructions are then decoded

00:28:13.300 --> 00:28:17.100
and placed into the dispatch groups.

00:28:17.100 --> 00:28:21.850
And up to five instructions can be
dispatched at a time to the various

00:28:21.860 --> 00:28:25.790
instruction function unit issue queues.

00:28:26.100 --> 00:28:29.450
from the issue queues,
you can dispatch to any of these

00:28:29.450 --> 00:28:32.140
12 function units in the processor.

00:28:32.200 --> 00:28:35.840
So this is a lot of resources,
a very powerful chip,

00:28:35.880 --> 00:28:40.160
a lot of complexity that the
compiler needs to harness to

00:28:40.160 --> 00:28:42.570
give you the best performance.

00:28:43.100 --> 00:31:10.200
[Transcript missing]

00:31:10.600 --> 00:33:14.500
[Transcript missing]

00:33:14.670 --> 00:33:17.850
So I want to make sure that
you understand that while this

00:33:18.030 --> 00:33:23.160
processor has a lot of capabilities
that the compiler can leverage,

00:33:23.160 --> 00:33:25.940
that this processor works very
well with any sort of code

00:33:25.940 --> 00:33:26.910
that you're going to throw at.

00:33:26.960 --> 00:33:31.440
That if you're working on G3 or G4 code,
there's a lot of dynamic capability

00:33:31.500 --> 00:33:34.730
in the processor to extract the
most performance out of that.

00:33:35.270 --> 00:33:38.090
You can work with the compiler to
achieve the maximum performance

00:33:38.160 --> 00:33:41.920
and get that little extra percent,
but if you're working on an

00:33:41.920 --> 00:33:47.130
application that needs to be
targeted at G3 and G4 and the new G5,

00:33:47.130 --> 00:33:50.910
that application will scream
on all of these processors.

00:33:50.920 --> 00:33:53.490
And it will scream on the G5 as well.

00:33:53.490 --> 00:33:58.710
So this processor will not just
fall down if presented with G4 code.

00:34:00.990 --> 00:34:04.130
So how can you help the compiler to
produce better code now that we've

00:34:04.140 --> 00:34:08.300
discussed what the compiler -- what
we've done in the compiler groups to

00:34:08.300 --> 00:34:10.850
try to help tune it for this processor?

00:34:10.890 --> 00:34:13.360
First of all,
one thing that you need to do is to

00:34:13.370 --> 00:34:17.580
make sure that this -- that the compiler
can be as aggressive as possible

00:34:17.580 --> 00:34:20.020
in its transformations of the code.

00:34:20.020 --> 00:34:23.180
And one of these areas is to try to make
sure that the compiler doesn't need to

00:34:23.180 --> 00:34:25.660
be more conservative than it need be.

00:34:25.660 --> 00:34:28.580
An area where this is
important is in aliasing.

00:34:28.690 --> 00:34:32.660
That's where the compiler cannot tell
or where two different memory -- two

00:34:32.660 --> 00:34:37.010
different accesses to memory could
potentially -- two variables could

00:34:37.090 --> 00:34:39.340
point to the same place in memory.

00:34:39.340 --> 00:34:41.510
And so if the compiler
cannot distinguish this,

00:34:41.510 --> 00:34:44.490
the compiler needs to be more
conservative to ensure that it's

00:34:44.560 --> 00:34:48.280
going to perform the calculations
in the appropriate order.

00:34:48.280 --> 00:34:52.200
So what you can do to allow the
compiler to see and understand more of

00:34:52.200 --> 00:34:56.250
the procedure that you're working on
is to use local variables and to avoid

00:34:56.250 --> 00:34:58.620
taking the addresses of variables.

00:34:58.790 --> 00:35:03.340
And this also includes areas where
the calling convention may implicitly

00:35:03.340 --> 00:35:06.490
pass something by an address,
because then the compiler needs

00:35:06.620 --> 00:35:10.210
to sort of throw up its hands
if it can't fully understand the

00:35:10.210 --> 00:35:15.140
consequences of what the -- something
may be happening behind its back.

00:35:15.140 --> 00:35:19.330
So that's one area where you can help
the compiler produce more effective code.

00:35:19.410 --> 00:35:23.370
Another area is in simplifying loops,
where if you can make this loop as simple

00:35:23.390 --> 00:35:26.830
as possible and as direct as possible,
the compiler has much more

00:35:26.970 --> 00:35:27.950
opportunity to make it more effective.

00:35:27.960 --> 00:35:27.960
Thank you.

00:35:28.760 --> 00:35:31.420
So you can take the loop
and do the same thing.

00:35:31.520 --> 00:35:34.600
You can also do the same thing that
you would do if you had a loop,

00:35:34.600 --> 00:35:36.420
but you have to make a loop.

00:35:36.420 --> 00:35:38.850
So the compiler needs to be
able to make transformations

00:35:38.850 --> 00:35:40.410
that will improve performance.

00:35:40.560 --> 00:35:43.420
One example of this is to not have
changes in flow control inside the loop.

00:35:43.420 --> 00:35:44.440
So, for instance,
if you have a loop that has

00:35:44.440 --> 00:35:45.470
a branch inside the loop,
if it's possible,

00:35:45.470 --> 00:35:46.850
it would be better to move that branch,
that conditional,

00:35:46.850 --> 00:35:48.210
outside of the loop and actually
duplicate the loop in both

00:35:48.210 --> 00:35:49.150
branches of the conditional.

00:35:49.510 --> 00:35:53.480
And that allows the compiler to then
optimize each of those loops much more

00:35:53.730 --> 00:35:57.960
effectively when it can better understand
exactly what's going to happen.

00:35:57.960 --> 00:35:58.020
Thank you.

00:35:58.770 --> 00:36:01.950
Another area is indexes into arrays.

00:36:02.180 --> 00:36:07.320
Again, try to have as simplified an
index as possible so that,

00:36:07.320 --> 00:36:11.210
again, the compiler can understand what's
going on and make transformations

00:36:11.500 --> 00:36:14.580
with prefetching and other sorts
of optimizations that would

00:36:14.580 --> 00:36:17.840
be much more effective in the
throughput of this processor.

00:36:17.960 --> 00:36:20.370
And finally is obeying the type rules.

00:36:20.470 --> 00:36:23.880
The type rules are something that is
essentially an agreement between the

00:36:24.020 --> 00:36:28.240
programmer and the language about how
you're going to use the various types.

00:36:28.340 --> 00:36:33.380
And if you use the types appropriately
and don't start changing accesses

00:36:33.440 --> 00:36:36.020
behind the compiler's back in
ways that it doesn't expect,

00:36:36.200 --> 00:36:39.820
you can use the most
aggressive optimizations,

00:36:39.860 --> 00:36:42.360
as Ron mentioned,
and get the best performance

00:36:42.380 --> 00:36:43.560
from your program.

00:36:43.700 --> 00:36:47.400
So let me talk a little bit about
where this technology came from.

00:36:47.450 --> 00:36:50.350
That a lot of this work that
we've been doing comes from IBM's

00:36:50.350 --> 00:36:54.360
vast experience in developing
compilers over the past decades,

00:36:54.410 --> 00:36:57.860
including some of the earliest
compilers for computers.

00:36:57.860 --> 00:37:01.900
So we have a worldwide research
and development organization

00:37:01.900 --> 00:37:05.410
that has been brought to bear in
partnership with Apple in improving

00:37:05.410 --> 00:37:08.100
this compiler for the G5 processor.

00:37:08.100 --> 00:37:11.700
Some of this involves taking the
technology that IBM has developed

00:37:11.700 --> 00:37:17.780
for its Power 4 processor from
which the 970 was derived and used

00:37:17.780 --> 00:37:21.220
in developing IBM's own compiler,
taking that knowledge,

00:37:21.220 --> 00:37:24.490
taking that experience,
and driving that technology and

00:37:24.490 --> 00:37:27.830
that understanding into GCC,
so leveraging all of that

00:37:27.830 --> 00:37:29.240
history of development.

00:37:29.240 --> 00:37:32.720
And we're trying to -- using all
of that to exploit this processor

00:37:32.720 --> 00:37:37.280
and give Apple and its customers
the best performance possible.

00:37:37.980 --> 00:37:40.990
Now let me mention a little bit about
where GCC is going in the future.

00:37:41.130 --> 00:37:44.600
There are a lot of very exciting
optimizations that are going to be

00:37:44.660 --> 00:37:48.220
included in the compiler in the future,
which will yet further enhance

00:37:48.220 --> 00:37:49.880
the performance of this processor.

00:37:49.900 --> 00:37:52.900
We have a new register
allocator that is coming.

00:37:52.930 --> 00:37:54.900
There is improvements in
the instruction scheduler,

00:37:54.900 --> 00:37:58.610
which will allow even better
ability to model the complicated

00:37:58.610 --> 00:38:00.900
dispatch groups that I mentioned.

00:38:00.900 --> 00:38:04.190
There is work on software pipelining,
which will help improve the

00:38:04.320 --> 00:38:05.840
floating point performance.

00:38:05.970 --> 00:38:08.850
There is work on an
SSA optimization infrastructure,

00:38:08.970 --> 00:38:12.840
which allows one to describe the
program in a way that allows much

00:38:12.840 --> 00:38:14.900
more aggressive optimizations.

00:38:14.900 --> 00:38:18.930
This will allow easier implementation
of loop optimizations and auto

00:38:18.930 --> 00:38:20.750
vectorization in the future.

00:38:21.350 --> 00:38:24.450
Further work on inter-procedural
optimizations to be able to,

00:38:24.450 --> 00:38:27.870
again, have the compiler understand
more of the program,

00:38:27.900 --> 00:38:30.900
understand what's going
to happen with aliasing,

00:38:30.900 --> 00:38:34.900
and work past limitations that the
programmer may not have intended.

00:38:34.900 --> 00:38:38.780
Profile directed feedback,
so that the compiler can reorder the

00:38:38.780 --> 00:38:42.950
instructions to take advantage of
how the application is actually run

00:38:42.950 --> 00:38:44.900
with the data sets that you have.

00:38:44.900 --> 00:38:48.400
And of course,
continued improvement in the compiler

00:38:48.700 --> 00:38:51.690
speed to more rapidly generate the code.

00:38:52.000 --> 00:38:56.530
So all of this stems from this
partnership that IBM and Apple have in

00:38:56.530 --> 00:38:59.640
developing and further improving GCC.

00:38:59.640 --> 00:39:03.640
We are both very committed to
GCC and to the open source community.

00:39:03.840 --> 00:39:09.900
There are a large number of developers
for GCC inside Apple and inside IBM.

00:39:09.900 --> 00:39:14.030
I am a member of the GCC steering
committee and a member of Ron's team

00:39:14.030 --> 00:39:16.380
is on the GCC steering committee.

00:39:16.410 --> 00:39:19.850
I'm one of the maintainers of
the PowerPC port of the compiler

00:39:20.040 --> 00:39:23.660
and a member of Ron's team is my
co-maintainer on the compiler.

00:39:23.660 --> 00:39:27.730
And we are fully engaged with
this community to help design the

00:39:27.730 --> 00:39:31.160
future of this compiler and taking
a leadership position to make sure

00:39:31.160 --> 00:39:35.470
that this is the best compiler for
Apple systems and for the PowerPC.

00:39:36.900 --> 00:40:04.900
[Transcript missing]

00:40:09.320 --> 00:40:12.400
Actually,
it's a pretty exciting time for us.

00:40:12.400 --> 00:40:14.540
In the compiler world,
when you're presented with

00:40:14.600 --> 00:40:19.150
a challenge like this,
it just makes your day

00:40:19.150 --> 00:40:21.800
or makes your year.

00:40:23.610 --> 00:40:24.940
Future directions.

00:40:25.030 --> 00:40:28.380
Well, as you can see,
we've just embarked on this

00:40:28.380 --> 00:40:34.100
journey with the new processor and
extracting the performance from that.

00:40:34.100 --> 00:40:41.900
And we really consider our role to be one
of trying to make this processor work for

00:40:41.900 --> 00:40:46.500
you without you having to jump through
hoops or go through a lot of gyrations.

00:40:46.500 --> 00:40:51.230
Right now, we're telling you,
please do a few gyrations if you

00:40:51.250 --> 00:40:53.820
want to get the performance out.

00:40:53.950 --> 00:40:59.580
But we're working, as David showed you,
on any number of areas within

00:40:59.580 --> 00:41:03.950
the GCC community to take the
optimization capabilities of the

00:41:03.950 --> 00:41:06.360
GNU Compiler to the next level.

00:41:06.500 --> 00:41:11.100
We also don't consider our work
done in terms of compile speed.

00:41:11.100 --> 00:41:14.580
I think you will agree we've
made some really dramatic

00:41:14.580 --> 00:41:16.300
progress in the past year.

00:41:16.300 --> 00:41:20.220
And if I were you,
I would expect from us that we'll make

00:41:20.290 --> 00:41:25.490
as good a progress in the coming year
because we're going to nail performance.

00:41:25.500 --> 00:41:26.900
That's really important.

00:41:26.900 --> 00:41:31.130
And we want to remove this
compiler from being an obstruction

00:41:31.130 --> 00:41:33.390
to you getting your work done.

00:41:33.500 --> 00:41:37.370
In terms of language features,
we'll move along at a slower

00:41:37.370 --> 00:41:41.500
pace because the language is
moving at a slower pace today.

00:41:41.500 --> 00:41:46.100
But you can count on us continuing
to move towards full compliance.

00:41:46.100 --> 00:41:49.890
with the ANSI and ISO standards.

00:41:52.990 --> 00:41:57.100
So, this,
even though it's being jammed today,

00:41:57.100 --> 00:42:04.060
is being offered to you as a
part of the Xcode tools package.

00:42:04.060 --> 00:42:07.900
There's documentation in that
package that you can reach.

00:42:07.900 --> 00:42:09.290
There's the release notes.

00:42:09.390 --> 00:42:15.700
One piece of documentation that you'll
probably want to look for is in terms

00:42:15.700 --> 00:42:17.610
of performance tuning your code.

00:42:17.610 --> 00:42:21.140
And I would encourage you
to attend the session,

00:42:21.140 --> 00:42:22.880
which occurs the next
day or the next week.

00:42:22.920 --> 00:42:26.840
And I would encourage you
to attend the session,

00:42:26.840 --> 00:42:30.460
which occurs the next
day or the next week.

00:42:32.860 --> 00:42:33.800
Okay.

00:42:33.800 --> 00:42:38.750
Anyway, there's a performance session
during the next period of time,

00:42:38.750 --> 00:42:41.290
and I would encourage you to attend that.

00:42:41.360 --> 00:42:43.790
I was at the CHUD session
that preceded this,

00:42:43.800 --> 00:42:47.800
and I was happy to see
an overflow room there.

00:42:47.800 --> 00:42:53.210
We've got some dramatic capabilities
with our tools to help you improve

00:42:53.360 --> 00:42:55.140
the performance of your code.

00:42:55.140 --> 00:42:58.890
If you have contact
that you want to make,

00:42:58.890 --> 00:43:03.300
Gafi DiGiorgi,
who's our technology manager,

00:43:03.300 --> 00:43:07.220
and you'll meet him in just a moment,
his email address.

00:43:07.220 --> 00:43:11.010
There's a feedback address
for the development tools,

00:43:11.010 --> 00:43:15.500
and of course,
we're always looking for bug reports.

00:43:15.500 --> 00:43:20.090
Well, I guess we're not happily
looking for bug reports,

00:43:20.210 --> 00:43:22.910
but we appreciate the feedback.

00:43:23.790 --> 00:43:29.120
Here's the 305 in Presidio
as the performance tools

00:43:29.120 --> 00:43:31.880
section that I was talking to.

00:43:31.880 --> 00:43:36.690
Some of the other sessions that you might
be interested in is Apple Script Studio,

00:43:36.690 --> 00:43:39.700
Carbon Development, and so forth.

00:43:39.700 --> 00:43:43.660
We encourage you tomorrow,
there will be a feedback forum where

00:43:43.660 --> 00:43:50.110
you can come and let us know what
you would like to feedback to us and

00:43:50.110 --> 00:43:54.690
give us your impression of the tools.