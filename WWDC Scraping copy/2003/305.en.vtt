WEBVTT

00:00:27.810 --> 00:00:28.140
Thank you.

00:00:28.140 --> 00:00:34.500
So let's get the clicker working.

00:00:34.500 --> 00:00:37.200
It just worked when I was last up here.

00:00:37.200 --> 00:00:40.500
Okay, let's talk about what we're
going to cover in this session.

00:00:40.500 --> 00:00:45.120
First I'm going to talk a bit about
some performance analysis concepts.

00:00:45.240 --> 00:00:48.150
As you're going through the
process of thinking about

00:00:48.150 --> 00:00:51.730
making your application fast,
what are some of the things you want

00:00:51.810 --> 00:00:53.750
to consider in the process of that?

00:00:54.400 --> 00:00:58.080
Then we'll take a look at some
specific examples of uses of two

00:00:58.080 --> 00:01:04.730
different classes of performance
applications on specific test cases.

00:01:04.740 --> 00:01:09.200
So we've got some high-level tools,
Sampler, Malloc Debug, things like that.

00:01:09.260 --> 00:01:12.690
And then the Chud tools that
have been talked about some

00:01:12.840 --> 00:01:15.900
earlier in this conference,
we'll take a look at both

00:01:15.900 --> 00:01:18.560
of those in this session and
where they're applicable.

00:01:18.590 --> 00:01:23.090
And also a little bit about the
integration with Xcode with these.

00:01:24.060 --> 00:01:27.660
Now one thing that this session is not
really going to cover in detail is,

00:01:27.660 --> 00:01:31.090
oh, you should not use this
API and you should use that

00:01:31.090 --> 00:01:32.900
API and use this one here.

00:01:32.900 --> 00:01:38.040
There's a lot of other sessions
like the Carbon performance session,

00:01:38.040 --> 00:01:40.520
which I think was
Friday morning if I recall,

00:01:40.520 --> 00:01:42.720
where you can get some details on that.

00:01:42.780 --> 00:01:46.690
And there's a lot of great performance
documentation that can cover a

00:01:46.750 --> 00:01:48.540
lot of those details as well.

00:01:48.540 --> 00:01:50.860
Now this is going to
focus on the tools here.

00:01:50.860 --> 00:01:53.600
But first let's talk about motivation.

00:01:53.600 --> 00:01:55.360
Why worry about performance?

00:01:55.360 --> 00:01:57.320
You know, it's a selling point.

00:01:57.450 --> 00:01:58.530
We see it across the board.

00:01:58.540 --> 00:02:00.940
It's a selling point for
Apple with the hardware.

00:02:00.940 --> 00:02:03.460
It's a selling point
with your application.

00:02:03.460 --> 00:02:07.390
If you've got competitors that
do similar things to your product

00:02:07.490 --> 00:02:11.170
and they're a lot faster than you,
you know, that's a big competitive

00:02:11.400 --> 00:02:13.560
advantage for them and vice versa.

00:02:13.560 --> 00:02:16.300
So, let's talk about motivation.

00:02:18.040 --> 00:02:20.160
performance problems may go unnoticed.

00:02:20.160 --> 00:02:24.470
I've seen a couple examples of this in
recent days where you look at the system

00:02:24.470 --> 00:02:29.410
and it's just sitting there idle with
a window up and maybe an inspector up.

00:02:29.410 --> 00:02:35.830
Then you look at the CPU usage and
notice that 95% of the CPU is being used.

00:02:35.880 --> 00:02:37.940
But it's sitting there idle.

00:02:37.940 --> 00:02:39.140
What is going on?

00:02:39.280 --> 00:02:44.070
Sometimes you actually have to look
for these things and detect them or the

00:02:44.230 --> 00:02:49.800
issues of scalability that you don't see
when you're working with your unit tests.

00:02:49.800 --> 00:02:52.010
But when it gets out into the
field and people are really

00:02:52.140 --> 00:02:55.750
throwing lots of data at it,
then problems occur.

00:02:57.310 --> 00:03:03.510
Remember, unlike with Mac OS 9,
where you had control at certain points,

00:03:03.510 --> 00:03:06.120
you are not the only app on the system.

00:03:06.120 --> 00:03:08.720
There's potentially a lot
of other things going on,

00:03:08.720 --> 00:03:11.080
system demons in the background, etc.

00:03:11.190 --> 00:03:15.460
It's not nice to nice your
process up to try to fool the unit

00:03:15.460 --> 00:03:18.140
scheduling and things like that.

00:03:18.170 --> 00:03:20.680
You really want to make sure
that you play well with the

00:03:20.680 --> 00:03:22.500
other applications on the system.

00:03:22.500 --> 00:03:26.740
And finally, you want to start thinking
about performance from the

00:03:26.990 --> 00:03:29.680
get-go with your application.

00:03:29.710 --> 00:03:33.700
It can be really hard to finish up your
whole development cycle and then say,

00:03:33.810 --> 00:03:37.120
it's too slow,
and then try to come back in and

00:03:37.200 --> 00:03:39.840
graft performance on at the end.

00:03:39.840 --> 00:03:44.760
You might want to wait
and do tuning later on.

00:03:44.880 --> 00:03:48.870
Don't obfuscate your code from
the beginning with no purpose,

00:03:48.870 --> 00:03:52.430
but think about performance
issues as you go along.

00:03:52.500 --> 00:03:54.220
go along.

00:03:54.500 --> 00:06:06.600
[Transcript missing]

00:06:06.780 --> 00:06:09.260
Once you've defined your benchmarks,
then you want to add

00:06:09.300 --> 00:06:12.750
some instrumentation in,
maybe specific API calls at the start

00:06:12.900 --> 00:06:17.230
and the end so that every time around
it's real easy to collect the statistics

00:06:17.700 --> 00:06:20.190
of how long did these operations take.

00:06:20.290 --> 00:06:25.740
You want to be able to measure this
on a precise basis time after time.

00:06:25.740 --> 00:06:29.800
And that's the key to,
throughout your development process,

00:06:29.810 --> 00:06:32.130
tracking results as you go along.

00:06:32.180 --> 00:06:35.380
People ask, how did Safari get so fast?

00:06:35.380 --> 00:06:36.480
How did they do this?

00:06:36.480 --> 00:06:40.320
They tracked performance
throughout their development.

00:06:40.320 --> 00:06:42.600
It was a key issue from the beginning.

00:06:42.600 --> 00:06:46.660
And they never allowed performance
regressions to get into their code.

00:06:46.700 --> 00:06:48.680
I'm sorry, that makes it slower.

00:06:48.680 --> 00:06:52.420
Each engineer was required to
run the performance analysis

00:06:52.420 --> 00:06:56.340
test suite in Safari before
they could check their code in.

00:06:56.340 --> 00:06:59.530
And if it made it slower,
they weren't allowed to check it in.

00:06:59.540 --> 00:07:03.440
That's a great feature, but I'm sorry,
performance is the number one feature,

00:07:03.440 --> 00:07:05.910
so it doesn't get in
unless you make it faster.

00:07:07.810 --> 00:07:09.600
And finally,
once you've gone through all this effort,

00:07:09.600 --> 00:07:14.270
then out pop the hot spots that then
you can go in and start to tune these

00:07:14.270 --> 00:07:16.300
where it really makes a difference.

00:07:16.370 --> 00:07:19.770
Because, you know,
you've probably all observed that

00:07:20.130 --> 00:07:23.650
we can tend to be notoriously bad
at guessing in advance where our

00:07:23.650 --> 00:07:25.430
performance problems are going to be.

00:07:25.440 --> 00:07:28.700
Gee, it was fun to spend a week
optimizing that particular routine,

00:07:28.700 --> 00:07:30.120
but it made no difference.

00:07:30.140 --> 00:07:37.540
So when I say Safari, you know,
it was really a part of their process.

00:07:37.700 --> 00:07:41.850
They actually embedded into their
application and into the development

00:07:41.850 --> 00:07:47.090
versions internally instrumentation
in the form of a panel here that their

00:07:47.090 --> 00:07:52.800
engineers and their QA staff and managers
could pop up and run tests at any

00:07:52.800 --> 00:07:55.700
point through the development process.

00:07:55.700 --> 00:07:58.920
It really made it an integral part
of what they were doing because

00:07:59.060 --> 00:08:00.510
it was so important to them.

00:08:00.520 --> 00:08:03.860
They could do things like
check for memory leaks and

00:08:03.860 --> 00:08:05.920
sample directly from here.

00:08:05.920 --> 00:08:07.500
So you might want to consider.

00:08:07.890 --> 00:08:09.760
Adding that kind of thing
to your application.

00:08:09.760 --> 00:08:12.960
So when we talk about benchmarking,
what kinds of things

00:08:13.010 --> 00:08:14.630
might you want to look at?

00:08:14.740 --> 00:08:18.190
There's a wide variety of
factors that play a major role

00:08:18.370 --> 00:08:20.280
in performance on Mac OS X.

00:08:20.280 --> 00:08:24.960
You've probably heard us talk time
and time again about memory use.

00:08:24.960 --> 00:08:28.760
We have a limited amount
of RAM space on the system.

00:08:28.760 --> 00:08:31.090
And once we eat through that,
then we're starting to

00:08:31.260 --> 00:08:32.230
page out to the disk.

00:08:32.300 --> 00:08:33.520
And that's a lot slower.

00:08:33.520 --> 00:08:37.680
So if you're using a lot of
static memory or leaking memory,

00:08:37.700 --> 00:08:39.320
that can be a big problem.

00:08:39.320 --> 00:08:40.110
So measure that.

00:08:40.120 --> 00:08:45.140
Maybe you're not actually using that
much more static memory over time,

00:08:45.140 --> 00:08:48.830
but your dynamic memory,
how much you used during this

00:08:48.840 --> 00:08:51.440
particular operation really spiked up.

00:08:51.710 --> 00:08:53.680
And that can cause problems.

00:08:53.700 --> 00:08:57.010
So that's an area for measurement.

00:08:57.710 --> 00:09:00.600
CPU use, I mentioned launch time.

00:09:00.600 --> 00:09:04.010
There's other things
that are fairly obvious.

00:09:04.190 --> 00:09:07.480
Gee, this is one of the major
operations of my system.

00:09:07.610 --> 00:09:09.040
How long does that take?

00:09:09.180 --> 00:09:12.300
If it's a fast operation,
maybe you want to scale it up and run

00:09:12.300 --> 00:09:17.900
it 10,000 times and measure how long
does it take to do 10,000 runs of this.

00:09:17.950 --> 00:09:19.060
Again, idle time.

00:09:19.150 --> 00:09:21.500
You're not the only app on the system.

00:09:21.500 --> 00:09:25.620
If you're not doing anything in your app,
it shouldn't be taking any time.

00:09:25.620 --> 00:09:29.130
And then the spinning watch cursor,
the spinning rainbow cursor.

00:09:29.130 --> 00:09:31.670
That shouldn't ever
come up on our system.

00:09:31.890 --> 00:09:35.320
Well, it does occasionally in my
apps and it might in yours,

00:09:35.330 --> 00:09:36.980
but let's go fix that.

00:09:36.980 --> 00:09:39.830
We'll show you some ways to tackle that.

00:09:40.080 --> 00:09:42.340
Drawing.

00:09:42.360 --> 00:09:44.980
It might not be obvious,
but sometimes you're drawing

00:09:44.980 --> 00:09:46.380
too many times to the screen.

00:09:46.380 --> 00:09:48.970
We've got some great tools
to take a look at that.

00:09:49.000 --> 00:09:55.990
Now that we're doing live resizing of
windows or live resizing of split views,

00:09:56.140 --> 00:09:58.480
are you getting smooth
resizing during that?

00:09:58.660 --> 00:10:03.000
There's a variety of things
to consider for benchmarking.

00:10:03.030 --> 00:10:07.000
So once you've identified
your benchmarks,

00:10:07.000 --> 00:10:10.370
then you need some tools to
take a look at the issues.

00:10:10.520 --> 00:10:14.760
So we've got a variety of tools on the
system for both monitoring what's going

00:10:14.760 --> 00:10:17.390
on and then for getting in and saying,
okay, I see that I've got

00:10:17.390 --> 00:10:18.990
problems with CPU usage.

00:10:18.990 --> 00:10:21.820
Where is the time actually being spent?

00:10:21.820 --> 00:10:28.120
And so we can look at memory use and
CPU behavior and resource usage like file

00:10:28.120 --> 00:10:31.530
systems and system calls and drawing.

00:10:31.540 --> 00:10:32.760
So what's the best way to do that?

00:10:32.760 --> 00:10:36.570
So we'll cover a lot of
these tools as we go through.

00:10:37.480 --> 00:10:42.130
One thing to bear in mind as we think
about performance is that there's

00:10:42.130 --> 00:10:46.420
actually a lot of different levels of
performance in the system that can make a

00:10:46.420 --> 00:10:48.680
huge impact on your overall application.

00:10:48.720 --> 00:10:52.780
So let's think about layers
of design abstraction.

00:10:52.820 --> 00:10:54.270
Your application architecture.

00:10:54.270 --> 00:10:58.130
If you're a multi-threaded application,
do you get deadlocks

00:10:58.130 --> 00:10:59.230
between your threads?

00:10:59.320 --> 00:11:02.380
We have tools like Thread
Viewer to take a look at that.

00:11:02.380 --> 00:11:06.200
Maybe you're multi-process and
you're getting network hangs.

00:11:06.980 --> 00:11:11.600
If you've got complex
object-oriented architecture,

00:11:11.750 --> 00:11:15.420
are you sending too many messages
between the various objects?

00:11:15.420 --> 00:11:18.810
Or maybe one object is acting as
the bottleneck for everything,

00:11:18.820 --> 00:11:21.180
a god object that everything
has to go through.

00:11:21.270 --> 00:11:25.600
These are sort of architecture-level
issues that you might want to

00:11:25.610 --> 00:11:27.790
consider from the beginning.

00:11:27.860 --> 00:11:31.650
Then within a specific module,
a specific class,

00:11:31.740 --> 00:11:33.950
you can think about things
like your data structures,

00:11:34.000 --> 00:11:36.480
your algorithms.

00:11:36.540 --> 00:11:38.320
Are you allocating too much
memory here in this process?

00:11:38.320 --> 00:11:41.730
Or is the algorithm itself a
poor algorithm for scaling up?

00:11:41.840 --> 00:11:44.320
What's the interaction with the OS?

00:11:44.520 --> 00:11:47.630
Again,
the documentation covers a lot of things

00:11:47.640 --> 00:11:53.320
like this call in Carbon to enumerate
the directory structure is slow.

00:11:53.320 --> 00:11:55.240
You might want to consider
using this instead.

00:11:55.320 --> 00:11:59.120
Then bottleneck routines.

00:11:59.180 --> 00:12:01.650
Once you've isolated it down, okay,
we seem to be spending a

00:12:01.650 --> 00:12:02.900
lot of time in this routine.

00:12:02.910 --> 00:12:07.270
So on the right of this diagram here,
we we show that we've got a number

00:12:07.400 --> 00:12:09.770
of high-level tools that you
can look at some of the higher

00:12:09.770 --> 00:12:11.900
levels of the design abstraction.

00:12:11.930 --> 00:12:14.310
Once you get down to things
like the interaction with the

00:12:14.310 --> 00:12:19.490
OS and the bottleneck routines,
then the sampler profiling tool and

00:12:19.490 --> 00:12:24.500
the shark tool from the chud package
that we'll talk about later start to

00:12:24.500 --> 00:12:26.280
kind of overlap in their capabilities.

00:12:26.360 --> 00:12:31.300
They both let you do profiling and look
at things in somewhat different ways.

00:12:31.380 --> 00:12:32.810
So both can be helpful.

00:12:33.970 --> 00:12:36.980
When you really get down to trying to
optimize the use of your processor,

00:12:36.980 --> 00:12:40.780
your memory,
Shark is a great tool for that,

00:12:40.920 --> 00:12:42.620
plus other chud tools.

00:12:42.620 --> 00:12:47.470
And then Activity Monitor lets you
take a look through everything as well.

00:12:47.690 --> 00:12:51.070
So we'll be taking a look at a
number of new features on the system.

00:12:51.280 --> 00:12:56.280
On the user CD, there's a new Activity
Monitor application that replaces

00:12:56.280 --> 00:12:59.460
CPU Monitor and Process Viewer
and things like this.

00:12:59.480 --> 00:13:02.420
Really nice application
that the Core OS team did.

00:13:03.940 --> 00:13:07.420
Spin Control,
a new application to see what's going

00:13:07.420 --> 00:13:10.750
on when the watch cursor's spinning.

00:13:10.980 --> 00:13:16.600
Take a look at integration
of the tools with Xcode.

00:13:16.600 --> 00:13:20.160
There's a number of new features in
Sampler that we'll take a look at.

00:13:20.190 --> 00:13:23.950
And then with chud,
where you can really get in and

00:13:24.000 --> 00:13:27.840
see what's going on now with
the G5 in addition to the G4,

00:13:28.050 --> 00:13:29.430
things like that.

00:13:29.530 --> 00:13:31.410
So,

00:13:32.110 --> 00:13:35.270
With that, let me go ahead and turn
it over to Robert Bowdidge,

00:13:35.270 --> 00:13:39.200
Performance Engineer, for looking at some
of the specific tools.

00:13:39.200 --> 00:13:40.730
Thank you, Dave.

00:13:40.740 --> 00:13:41.390
Thanks, Robert.

00:13:47.200 --> 00:13:49.290
OK.

00:13:49.400 --> 00:13:50.760
What's the first thing we
need in order to actually

00:13:50.880 --> 00:13:52.400
demonstrate the Performance Tools?

00:13:52.400 --> 00:13:55.760
we need a victim,
and the victim we've chosen this

00:13:55.760 --> 00:13:58.200
year is the Sketch application.

00:13:58.200 --> 00:14:02.070
This is a small Cocoa application that's
available in the Developer Tools CD.

00:14:02.260 --> 00:14:05.180
So, for those of you who've seen
us using Carbon Apps through

00:14:05.180 --> 00:14:08.530
all the Xcode demos today,
this allows you to realize that the

00:14:08.650 --> 00:14:11.080
tools actually do work on Cocoa as well.

00:14:11.080 --> 00:14:12.620
Now,
if you actually go and look at Sketch,

00:14:12.620 --> 00:14:14.870
you won't see any performance problems.

00:14:14.870 --> 00:14:17.840
This is a program that's intended
to do simple line drawings.

00:14:17.840 --> 00:14:21.420
You know, draw a few rectangles,
put some text in, maybe do an org chart.

00:14:21.490 --> 00:14:23.850
But if you look at it,
you don't necessarily see any

00:14:23.850 --> 00:14:25.570
serious performance problems.

00:14:25.570 --> 00:14:28.500
The guys who wrote it did a pretty
good job of making it a typical

00:14:28.550 --> 00:14:31.460
Cocoa app with no performance problems.

00:14:31.460 --> 00:14:35.450
So,
we need to add some performance problems.

00:14:35.450 --> 00:14:35.450
And, I'm

00:14:35.590 --> 00:14:39.240
and actually the way that we did it
this time was rather than adding some,

00:14:39.240 --> 00:14:43.520
salting some bugs in there,
we decided to try to increase the scope.

00:14:43.610 --> 00:14:46.560
So rather than trying
to do small drawings,

00:14:46.640 --> 00:14:48.220
we said, "Well,
let's imagine our boss comes

00:14:48.220 --> 00:14:50.870
into our office and says,
'Hey, you know, that Sketch app,

00:14:50.950 --> 00:14:52.020
that's really good.

00:14:52.060 --> 00:14:55.330
I think we could do architectural
software with that.'"

00:14:55.680 --> 00:14:59.030
And so suddenly,
instead of drawing tens of rectangles,

00:14:59.030 --> 00:15:01.700
five rectangles,
we're drawing thousands of rectangles.

00:15:01.700 --> 00:15:04.260
And the question is,
what's going to happen?

00:15:04.350 --> 00:15:06.320
Are we going to find any
performance problems?

00:15:06.320 --> 00:15:08.650
Are we going to find that our
memory uses a heck of a lot

00:15:08.770 --> 00:15:10.240
more than we ever expected?

00:15:10.350 --> 00:15:15.100
Are we going to find CPU problems
where we're running too much code?

00:15:15.100 --> 00:15:18.310
And hopefully this is a situation
that many of you run into in your own

00:15:18.310 --> 00:15:21.580
code as you look at applications and
find out that on certain data sets it

00:15:21.580 --> 00:15:24.040
doesn't quite behave as you expected.

00:15:24.100 --> 00:15:26.120
So let's take a look at that.

00:15:27.180 --> 00:15:30.270
So I'd like to bring Kristy Warren up,
who is the performance

00:15:30.270 --> 00:15:35.970
engineer for the text team,
to actually do a demonstration for us.

00:15:36.120 --> 00:15:39.190
To actually start, actually let's go on
the slides for a sec.

00:15:43.250 --> 00:15:44.150
Thank you.

00:15:44.450 --> 00:15:48.480
So, one question is how you actually
find the performance problems.

00:15:48.480 --> 00:15:51.470
As Dave gave us an idea of some of the
processes that you might go through,

00:15:51.620 --> 00:15:55.290
whether that's looking for regressions
or following a certain pattern of

00:15:55.290 --> 00:15:58.980
measuring certain things every time,
but sometimes you don't have that.

00:15:58.980 --> 00:16:01.410
Sometimes you start with a new
application and you're not quite

00:16:01.410 --> 00:16:03.020
sure where to start looking.

00:16:03.020 --> 00:16:06.890
So, the way I like to start and the way
our Vice President likes to start is to

00:16:07.010 --> 00:16:10.360
use either the command line tool top,
which hopefully you've

00:16:10.360 --> 00:16:13.690
seen in previous years,
or thanks to Eric Paton and some

00:16:13.770 --> 00:16:16.670
of the folks on the CoreOS team,
we now have a new tool

00:16:16.790 --> 00:16:19.710
called Activity Monitor,
which gives us a way to look at this.

00:16:20.100 --> 00:16:22.680
If we could switch to
the demo machine now.

00:16:27.210 --> 00:16:27.950
Thank you.

00:16:28.220 --> 00:16:33.500
Okay, so we have activity monitor
over here on the side.

00:16:33.510 --> 00:16:37.870
And the way activity monitor's divided
up is the information at the bottom

00:16:37.870 --> 00:16:42.170
of the screen represents the system
wide information about your computer.

00:16:42.170 --> 00:16:44.740
So in this window we're
looking at system memory.

00:16:44.740 --> 00:16:48.860
And one interesting piece of
number here is the page ins,

00:16:48.940 --> 00:16:52.500
page outs down at the bottom,
which represents the amount of swapping

00:16:52.630 --> 00:16:53.940
your virtual memory system is doing.

00:16:53.940 --> 00:16:55.750
How many pages are being
written off to disk?

00:16:55.750 --> 00:16:58.110
The other things, the wedge,
the numbers here,

00:16:58.110 --> 00:17:01.290
represent how physical memory
is divided up on your system.

00:17:01.440 --> 00:17:02.730
How much of it's used for user stuff?

00:17:02.820 --> 00:17:04.310
How much of it's used for the kernel?

00:17:04.440 --> 00:17:07.130
How much of the memory is wired
down because there are structures

00:17:07.130 --> 00:17:10.860
the kernel doesn't dare page out
like the virtual memory system?

00:17:10.860 --> 00:17:14.490
The other tabs, for example, CPU,
give you an idea about how much

00:17:14.560 --> 00:17:18.510
work the CPU's doing in general,
kind of like the CPU monitor

00:17:18.510 --> 00:17:20.060
application does.

00:17:20.060 --> 00:17:22.920
And the other tabs for disk activity,
disk usage, and so on,

00:17:23.000 --> 00:17:24.510
also give you summary data.

00:17:24.520 --> 00:17:29.170
The information at the top gives you
details about specific processes.

00:17:29.190 --> 00:17:31.840
And so we can see activity
monitor sketch and so on.

00:17:31.910 --> 00:17:34.420
And we get information not
only about what's running,

00:17:34.420 --> 00:17:36.200
but how much CPU usage they're doing.

00:17:36.200 --> 00:17:39.910
And we can sort this list according
to what's the most CPU intensive or

00:17:39.960 --> 00:17:45.520
we can look in terms of process name
or hierarchy in the process groups.

00:17:45.520 --> 00:17:48.010
So Christie already has sketch running.

00:17:48.150 --> 00:17:52.420
And we can double click on that entry
to get a little more detail on sketch.

00:17:52.510 --> 00:17:56.910
And the important numbers here is the,
the percent CPU as usual and the

00:17:56.940 --> 00:18:00.480
private memory size down on the bottom.

00:18:00.640 --> 00:18:03.310
Now, private memory size is kind
of an interesting number.

00:18:03.320 --> 00:18:06.450
It represents the amount of
resident private memory that's

00:18:06.450 --> 00:18:08.290
being used by this application.

00:18:08.290 --> 00:18:12.320
That is the memory that's resident
in physical memory and the memory

00:18:12.470 --> 00:18:14.580
that's only needed by your app.

00:18:14.640 --> 00:18:17.540
And so this ends up being a nice
number because it represents

00:18:17.540 --> 00:18:21.580
sort of the footprint of your
application because that memory is,

00:18:21.580 --> 00:18:22.030
first of all,
only based on what you're using.

00:18:22.040 --> 00:18:23.640
And then you have the number of memory
that's being used by your application.

00:18:23.640 --> 00:18:23.640
And then you have the number of memory
that's being used by your application.

00:18:23.640 --> 00:18:23.640
And then you have the number of memory
that's being used by your application.

00:18:23.640 --> 00:18:24.310
So it's the number of memory that's
being used by your application.

00:18:24.310 --> 00:18:25.830
So you can see,
based on what your application is doing.

00:18:25.940 --> 00:18:27.560
And secondly,
it's the memory you can control.

00:18:27.560 --> 00:18:30.530
It's the memory being used for
the heap or it's the memory that

00:18:30.530 --> 00:18:32.580
you're allocating via VM allocate.

00:18:32.580 --> 00:18:36.610
And so it gives you a good idea of,
of what your fault is and how much you

00:18:36.640 --> 00:18:39.690
can reduce as opposed to the others
which tend to have a lot of details of

00:18:39.780 --> 00:18:41.900
amounts that you can't actually reduce.

00:18:41.900 --> 00:18:46.540
So we can see here that just having
sketch up took up about 1.64 megabytes.

00:18:46.540 --> 00:18:47.930
Not great, not bad.

00:18:47.990 --> 00:18:48.950
That'll do.

00:18:49.300 --> 00:18:54.240
So if Christie can now load one
of our architectural drawings.

00:18:54.240 --> 00:18:56.230
We have a factory here.

00:18:56.310 --> 00:18:57.760
Okay, we're going to build factories.

00:18:57.890 --> 00:19:03.140
And when the architect goes
to the customer and says,

00:19:03.140 --> 00:19:07.840
"Here's your factory," the customer says,
"Oh, I want six floors, not three." Okay,

00:19:07.840 --> 00:19:08.540
we can do that.

00:19:08.660 --> 00:19:14.920
We can select the entire building,
we can copy it, and we can paste it.

00:19:15.800 --> 00:19:17.990
Now we have six floors.

00:19:18.040 --> 00:19:18.780
Oh no, that's not enough.

00:19:18.850 --> 00:19:19.750
Let's make it twice as wide.

00:19:19.760 --> 00:19:20.580
So let's do it again.

00:19:20.760 --> 00:19:23.700
We'll select all.

00:19:23.700 --> 00:19:26.690
We'll copy.

00:19:26.730 --> 00:19:28.140
And copy is taking a little while.

00:19:28.160 --> 00:19:29.150
That's not good.

00:19:29.230 --> 00:19:30.990
And we can paste.

00:19:33.920 --> 00:19:37.130
and so we're drawing a couple thousand
rectangles here to draw that building but

00:19:37.140 --> 00:19:38.530
we're already noticing a couple issues.

00:19:38.580 --> 00:19:41.560
One was that copy was getting
a little slow and we're going

00:19:41.560 --> 00:19:44.200
to find out it actually gets
a lot slower as we go along.

00:19:44.220 --> 00:19:47.110
But the other thing is if we go
over and look at Activity Monitor we

00:19:47.110 --> 00:19:51.300
find out that we're actually
using 7.6 megabytes of memory.

00:19:51.990 --> 00:19:56.020
Okay, so 7.6 megabytes minus 1 megabyte,
or 1.5 megabytes.

00:19:56.020 --> 00:20:01.890
We used about 6 megabytes of memory
to do those two copies and pastes.

00:20:01.990 --> 00:20:03.700
Okay,
so we've got a performance problem here.

00:20:03.700 --> 00:20:06.960
We have a problem in what we're
doing in terms of the copy,

00:20:07.010 --> 00:20:09.970
so in terms of CPU,
and we have a memory problem.

00:20:09.970 --> 00:20:15.060
Could we switch back to the slides,
please?

00:20:18.530 --> 00:20:21.560
Oh, another interesting thing about
Activity Monitor is because it's

00:20:21.560 --> 00:20:24.270
looking at the entire system,
that means that you can see what's

00:20:24.270 --> 00:20:25.720
going on in other processes.

00:20:25.720 --> 00:20:29.330
And one of the things to
remember is on Mac OS X,

00:20:29.330 --> 00:20:34.500
your application's work on the
system is not just a matter of what

00:20:34.500 --> 00:20:36.220
your application is responsible for.

00:20:36.220 --> 00:20:38.490
There are other processes,
whether they're little

00:20:38.550 --> 00:20:40.590
demons that are on the side,
or more importantly,

00:20:40.590 --> 00:20:44.290
things like the Windows server,
where if you're doing a lot of drawing,

00:20:44.290 --> 00:20:47.800
now your application may only
be taking up 60% of the CPU,

00:20:47.800 --> 00:20:51.070
but the Windows server could be
taking up the other 40%. So when

00:20:51.120 --> 00:20:54.430
you're looking at Activity Viewer,
you also need to look at the whole system

00:20:54.430 --> 00:20:57.760
to understand what else your application
may be doing so that you can find other

00:20:57.980 --> 00:20:59.330
ways that you might be able to optimize.

00:21:04.630 --> 00:21:06.240
Okay, so let's attack the first problem.

00:21:06.350 --> 00:21:09.120
What do we do if memory
use seems a little high?

00:21:09.120 --> 00:21:10.360
Well, why do we care?

00:21:10.360 --> 00:21:13.000
Why don't we just like use
as much memory as we can?

00:21:13.020 --> 00:21:16.480
This will at least make the
people who sell SIMs happy.

00:21:16.480 --> 00:21:17.740
Well, there's a couple reasons for that.

00:21:17.750 --> 00:21:20.390
One of the--and generally,
using too much memory

00:21:20.390 --> 00:21:21.530
is not a good thing.

00:21:21.530 --> 00:21:25.580
One of the reasons is your application
is slow because suddenly all the

00:21:25.610 --> 00:21:29.120
data that you want the CPU to be
processing as fast as possible,

00:21:29.200 --> 00:21:31.930
especially on one of these
G5s that can really race,

00:21:31.980 --> 00:21:34.810
is--can't fit in cache
or you'll chase it out.

00:21:34.810 --> 00:21:37.810
And so suddenly,
you're having to rely on the speed of

00:21:37.810 --> 00:21:40.040
the main memory instead of the cache.

00:21:40.040 --> 00:21:43.570
And so you want to keep your
application as memory lean as

00:21:43.570 --> 00:21:49.170
possible so that you can have as
much as possible in the cache.

00:21:49.230 --> 00:21:52.970
If you're not using the memory, well,
then it's just sort of wasting space

00:21:53.060 --> 00:21:57.120
because the--it's sitting in physical
memory and maybe you're not touching it.

00:21:57.310 --> 00:21:59.840
And if I come along and I start
playing iTunes or I start

00:21:59.840 --> 00:22:02.640
running iPhoto or I start using
Mail or I start doing Safari,

00:22:02.680 --> 00:22:08.300
which every one of your customers is also
doing when they're running their app,

00:22:08.300 --> 00:22:08.300
I'm

00:22:08.980 --> 00:22:12.490
That means that when Safari needs
more memory to put in some big page,

00:22:12.560 --> 00:22:14.940
some of your pages may have
to get forced out of physical

00:22:14.940 --> 00:22:16.180
memory and written off to disk.

00:22:16.240 --> 00:22:18.670
And so the computer's going to have
to do a lot more work just because

00:22:18.740 --> 00:22:20.220
you want to keep that memory around.

00:22:20.300 --> 00:22:23.480
So you want to keep your memory
footprint slow for that reason.

00:22:23.570 --> 00:22:29.030
And if you've forgotten about the memory,
if you've allocated it and you've

00:22:29.030 --> 00:22:33.470
forgotten to get rid of it,
it's even worse because you can't free

00:22:33.470 --> 00:22:33.470
it at that point and it's just going
to get copied around on the disk.

00:22:35.020 --> 00:22:40.250
And because of the virtual memory system,
you can actually run into some

00:22:40.470 --> 00:22:43.970
rather interesting problems
where you might not have expected

00:22:44.050 --> 00:22:45.380
things to go as badly as they did.

00:22:45.480 --> 00:22:46.240
So here's an example.

00:22:46.240 --> 00:22:48.280
Let's imagine we've got
some really large file.

00:22:48.280 --> 00:22:50.340
You know,
it's 10 megabytes or 100 megabytes.

00:22:50.480 --> 00:22:54.800
And reading it in when we
need it seems a little slow.

00:22:56.090 --> 00:22:56.840
Well, I know what I'll do.

00:22:56.840 --> 00:23:00.200
I'll just read it in before
I need it so that it's available.

00:23:00.200 --> 00:23:03.630
I'll read it into memory and
that way when I need that file,

00:23:03.630 --> 00:23:04.830
it's right there.

00:23:04.880 --> 00:23:08.840
The problem with that is that
what happens if I go off and

00:23:08.840 --> 00:23:13.760
I run iPhoto and I run iTunes and
I run Mail and everything else?

00:23:13.760 --> 00:23:15.140
Those start to need memory.

00:23:15.150 --> 00:23:19.480
And so some of your pages that you've
brought in get chased out to disk.

00:23:19.570 --> 00:23:21.550
And then when you actually
need that file or that parsed

00:23:21.550 --> 00:23:24.080
representation of the file,
say, suddenly it has to be

00:23:24.080 --> 00:23:25.740
brought in off of disk again.

00:23:25.850 --> 00:23:28.360
And so in order to save
that disk read that you did,

00:23:28.360 --> 00:23:31.850
you've now read it in memory,
written it out to memory,

00:23:31.850 --> 00:23:33.210
and read it back in.

00:23:34.290 --> 00:23:36.550
"So you don't want to do that.

00:23:36.640 --> 00:23:39.380
You want to try to keep your memory
footprint as low as possible.

00:23:39.380 --> 00:23:41.880
And you want to do that in terms
of both the memory you use and

00:23:41.880 --> 00:23:44.780
the memory that you've forgotten
about and that you're leaking.

00:23:44.820 --> 00:23:46.340
Now there's two tools that
you can use to do this.

00:23:46.470 --> 00:23:49.040
One is called Object-to-Alec and
it looks at your memory use in

00:23:49.040 --> 00:23:50.830
terms of how many objects you have.

00:23:50.940 --> 00:23:54.130
And the second one is called Malic
Debug and it refers to things,

00:23:54.210 --> 00:23:57.170
it refers to allocations in terms of
where they are so that you can see

00:23:57.170 --> 00:24:01.160
particular places in your code that
tend to allocate a lot of memory.

00:24:01.160 --> 00:24:03.320
And let's take a look
at the first of those,

00:24:03.470 --> 00:24:04.220
Object-to-Alec.

00:24:04.220 --> 00:24:07.730
And actually let's switch
to the demo screen.

00:24:11.840 --> 00:24:13.410
Okay, so here I am.

00:24:13.510 --> 00:24:17.280
I'm running Sketch in Xcode
because Xcode's really cool.

00:24:17.380 --> 00:24:19.520
And I want to go and do
some performance analysis.

00:24:19.520 --> 00:24:22.510
Okay, how do you do that?

00:24:26.100 --> 00:24:28.670
Well, the first step I usually do,
or at least the first step I always

00:24:28.670 --> 00:24:31.590
hear from everybody is go hunting
around on disk trying to figure out

00:24:31.590 --> 00:24:32.990
where the performance tools are.

00:24:33.090 --> 00:24:37.230
Actually, who knows where the
performance tools are?

00:24:39.190 --> 00:24:39.480
Okay.

00:24:39.490 --> 00:24:42.140
The developer tools are
in developer applications.

00:24:42.140 --> 00:24:42.620
That's nice.

00:24:42.620 --> 00:24:43.880
The performance tools are there too.

00:24:43.880 --> 00:24:45.750
But the problem is,
you've got to go hunting around for them.

00:24:45.860 --> 00:24:49.460
You've got to use the finder which was
computer-centric and not human-centric.

00:24:49.460 --> 00:24:51.460
And that kind of,
and that wasn't very good.

00:24:51.520 --> 00:24:53.440
I was going to use another
word but I won't say that.

00:24:53.650 --> 00:24:55.800
And so, what, and we've improved that.

00:24:55.860 --> 00:24:58.630
So now what you can do is,
you're going along and you say,

00:24:58.630 --> 00:25:01.220
"I want to look at performance."
And you can go up to the debug menu

00:25:01.260 --> 00:25:04.600
now and there's now an entry called
Launch using Performance Tool.

00:25:04.600 --> 00:25:06.480
And it will list the three perform--.

00:25:06.550 --> 00:25:06.980
Ooh.

00:25:06.980 --> 00:25:10.860
It'll list the performance
tools that are--.

00:25:10.860 --> 00:25:13.400
Geez, if I'd known this would,
if we'd known this

00:25:13.400 --> 00:25:15.490
would make people happy.

00:25:15.500 --> 00:25:17.540
And in fact, if you actually had
installed the Chud tools,

00:25:17.540 --> 00:25:19.800
which sadly I did not because
I wasn't a good person,

00:25:19.920 --> 00:25:22.240
you'd actually have Shark there too.

00:25:22.240 --> 00:25:24.820
And I'd suggest you install Shark so that
you can actually see it on that list.

00:25:24.900 --> 00:25:27.350
And so we can launch ObjectAlloc here.

00:25:27.790 --> 00:25:30.400
And here's the Object Alloc window.

00:25:30.400 --> 00:25:34.670
And let us launch SketchInit.

00:25:38.310 --> 00:25:41.290
And what ObjectAlloc does
is it instrument your code,

00:25:41.410 --> 00:25:45.340
it runs it, you answer a few questions,
but it keeps track of how many

00:25:45.340 --> 00:25:48.920
objects have been created and
it updates that constantly.

00:25:48.920 --> 00:25:52.370
And it shows not only the current number
of objects of that type that exist,

00:25:52.370 --> 00:25:54.780
but the peak number that
have ever existed during the

00:25:54.780 --> 00:25:57.630
lifetime of your program,
the total number you've allocated

00:25:57.630 --> 00:25:59.200
during the entire program.

00:25:59.250 --> 00:26:04.550
And so we can go to our little example.

00:26:04.550 --> 00:26:05.010
We can open our factory.

00:26:08.080 --> 00:26:10.720
And we can see that we're creating huge
numbers of CFStrings and all sorts of

00:26:10.720 --> 00:26:13.260
other things as part of doing this work.

00:26:13.260 --> 00:26:14.000
And here's our factory.

00:26:14.000 --> 00:26:19.190
So let's again do our select all.

00:26:19.840 --> 00:26:23.000
and Copy and our Paste.

00:26:23.000 --> 00:26:28.370
And Object Alloc is doing its good work.

00:26:31.680 --> 00:26:32.800
and you can see that things are updating.

00:26:32.800 --> 00:26:35.500
And let's do that again if we could.

00:26:35.500 --> 00:26:38.360
Now, you can notice that to the far side
of the numbers there's some histogram.

00:26:38.430 --> 00:26:41.310
There's some bars there indicating
how many objects you have graphically.

00:26:41.390 --> 00:26:44.170
And that's very nice because that
gives you a way to directly perceive

00:26:44.350 --> 00:26:45.550
how fast things are changing.

00:26:45.550 --> 00:26:46.730
So you can see, oh, my God.

00:26:46.830 --> 00:26:48.960
I'm creating a lot of these
objects really quickly.

00:26:48.960 --> 00:26:51.930
And the colors actually have meaning
because if it's colored yellow,

00:26:51.930 --> 00:26:55.320
then that implies that the current number
of objects of that type is only about

00:26:55.320 --> 00:26:59.100
20 percent of what the peak is or less,
which implies that you created a whole

00:26:59.100 --> 00:27:02.320
bunch of them and then you backed off,
which may imply that maybe you're not

00:27:02.320 --> 00:27:05.440
auto-releasing things quickly enough or
maybe you're just creating a huge number.

00:27:05.440 --> 00:27:07.430
But it's hopefully going to
make you look at that to try to

00:27:07.430 --> 00:27:09.400
figure out why you had so many.

00:27:09.400 --> 00:27:12.830
And the red indicates that you
have only 10 percent of peak value.

00:27:14.440 --> 00:27:16.960
Okay, so we've now done our
copy and we can go over.

00:27:17.060 --> 00:27:20.570
And now what we do is what we should
do in all the performance tools.

00:27:20.640 --> 00:27:22.860
What we're doing is
we're looking at these,

00:27:23.240 --> 00:27:24.840
basically scrubbing our
nose against the data,

00:27:24.920 --> 00:27:27.190
looking for something that
looks suspicious because the

00:27:27.190 --> 00:27:30.340
performance tool can't really say,
"Oh, this is the problem.

00:27:30.340 --> 00:27:33.980
If you fix this piece of code,
you'll be happy." In general,

00:27:33.980 --> 00:27:37.080
it tends to be much more of a,
you look at it and you say, "Oh, gee,

00:27:37.080 --> 00:27:37.970
I didn't expect that.

00:27:37.970 --> 00:27:41.540
Why is that happening?" And then
you go and track down the bug.

00:27:41.540 --> 00:27:46.290
And what we can see on this immediately
is that the second most common

00:27:46.350 --> 00:27:49.630
object after general block 14,
that is mallocs of size 14,

00:27:49.630 --> 00:27:53.100
because object alloc will look
at both mallocs and CF objects

00:27:53.180 --> 00:27:56.340
and Objective-C objects,
is we can see that we have

00:27:56.340 --> 00:27:59.300
4,000 NS invocation objects.

00:28:01.560 --> 00:28:03.100
NS Invocation.

00:28:03.130 --> 00:28:05.900
That's not in my code.

00:28:05.900 --> 00:28:07.440
And in fact, you know,
not only do we have

00:28:07.440 --> 00:28:10.340
4,000 of those things,
but if we check count as bytes,

00:28:10.500 --> 00:28:15.680
we find out that out of 2.9 megabytes of
memory that are used for all the objects,

00:28:16.130 --> 00:28:18.840
800K of it is used for NS Invocation.

00:28:18.840 --> 00:28:23.190
So about 25% of my memory
is because of these.

00:28:23.920 --> 00:28:24.800
That's odd.

00:28:24.800 --> 00:28:27.560
Well, ObjectAlloc gives us a
way to track that down.

00:28:27.670 --> 00:28:31.090
So what we can do is go over
to the Instance Browser.

00:28:31.320 --> 00:28:33.590
and we can select NS Invocation
and we get a list of all

00:28:33.590 --> 00:28:34.930
the objects of that type.

00:28:34.930 --> 00:28:37.660
And if when we launch the
application we happen to see,

00:28:37.710 --> 00:28:41.160
check the little box that said
keep track of retains and releases,

00:28:41.160 --> 00:28:43.950
for that object we would see
all of the times that we did a

00:28:43.950 --> 00:28:47.790
retain in Objective-C and did a
release on that object so that

00:28:47.880 --> 00:28:50.660
we could find over-retains.

00:28:50.700 --> 00:28:53.280
Or we could click on allocation event
as Christie's done here and we can take

00:28:53.280 --> 00:28:57.660
a look at the back trace indicating
exactly where that object was allocated.

00:28:57.750 --> 00:29:01.400
And we see here that it's allocated
in our select graphic object.

00:29:01.450 --> 00:29:04.960
Now, this also shows another feature
that's new in the performance tools.

00:29:04.960 --> 00:29:07.300
That in the past you'd find something
simple and you wouldn't be able

00:29:07.350 --> 00:29:08.910
to track down where it came from.

00:29:09.000 --> 00:29:11.030
Now,
we take a look at the STABs information,

00:29:11.110 --> 00:29:13.720
the debugging information in your binary.

00:29:13.720 --> 00:29:17.000
And if we can find the
location of that function,

00:29:17.000 --> 00:29:20.280
we actually will highlight
it in the performance tools,

00:29:20.280 --> 00:29:22.860
either with a little file
icon or by underlining it.

00:29:22.970 --> 00:29:27.600
And so you can double click on that
and project build--and Xcode will

00:29:27.660 --> 00:29:30.910
actually show the code for you.

00:29:34.230 --> 00:29:37.470
And what we find out is that
the NS invocation objects

00:29:37.470 --> 00:29:40.290
are being used for undo's.

00:29:40.670 --> 00:29:45.390
So every time that we select a rectangle,
that we copy it, that we paste it,

00:29:45.680 --> 00:29:49.960
for each of those thousands we end
up creating an NS invocation object

00:29:49.960 --> 00:29:52.430
to handle undoing that at the end.

00:29:53.190 --> 00:29:55.700
Okay, so we're creating
thousands of these things.

00:29:55.740 --> 00:29:57.700
Okay, so this is an interesting problem.

00:29:57.700 --> 00:29:58.840
We've got some solutions here.

00:29:58.930 --> 00:30:04.480
We could just decide that the
undo support in Cocoa is just

00:30:04.480 --> 00:30:07.300
such a big win productivity-wise
that we just don't care.

00:30:07.350 --> 00:30:08.090
That's a fine answer.

00:30:08.090 --> 00:30:11.760
If we really care because we're going
to be doing lots of architecture stuff,

00:30:11.940 --> 00:30:14.480
then maybe we actually want
to change this and we want to

00:30:14.480 --> 00:30:16.320
create our own undo mechanism.

00:30:16.350 --> 00:30:19.340
Or a third option is we could say,
"Why are we allowing undo to

00:30:19.340 --> 00:30:22.740
select because the HI guidelines
don't require us to?" And so you

00:30:22.820 --> 00:30:24.340
could actually get rid of that.

00:30:24.410 --> 00:30:28.530
So this is one of the ways that you
can step through finding something

00:30:28.610 --> 00:30:32.710
suspicious and tracking down why that's
happening and tracking it down to your

00:30:32.720 --> 00:30:33.860
code to understand what the problem is.

00:30:33.860 --> 00:30:35.510
And that's how you can
use the performance tools.

00:30:35.510 --> 00:30:38.520
So can we go back to the slides, please?

00:30:51.350 --> 00:30:53.830
Okay, second question:
What do we do when the

00:30:53.870 --> 00:30:55.330
CPU use seems too high?

00:30:55.440 --> 00:30:56.760
First of all, why do we care again?

00:30:57.010 --> 00:30:59.880
Well, answer: If you're doing something
and it's taking too long,

00:31:00.030 --> 00:31:01.960
it's not only making your
application look bad,

00:31:01.960 --> 00:31:04.440
but you're going to make my iTunes skip.

00:31:04.450 --> 00:31:05.660
And I don't like that.

00:31:05.660 --> 00:31:08.460
So you need to worry both about your
own application and how it performs

00:31:08.590 --> 00:31:11.780
and how you're affecting the rest of
the system because you're not alone.

00:31:11.840 --> 00:31:15.000
There's lots of other things
running on all our computers.

00:31:15.320 --> 00:31:18.580
So there's a few tools you
can do to track down CPU use.

00:31:18.660 --> 00:31:21.360
One of those is Sampler, our profiler.

00:31:21.470 --> 00:31:24.740
Sampler can also be used to look at
what's called dynamic memory footprint,

00:31:24.760 --> 00:31:26.770
as Christy puts it,
which is a way of understanding

00:31:26.770 --> 00:31:30.340
where your calls to malloc are and
using those as suggestions of where

00:31:30.340 --> 00:31:32.700
you might be doing too much work.

00:31:32.700 --> 00:31:34.780
And there's also a tool called
Spin Control that's new on the

00:31:34.780 --> 00:31:37.760
release that gives you a way to
automatically sample when you look

00:31:37.760 --> 00:31:39.730
at when the spinning cursor comes up.

00:31:39.730 --> 00:31:41.560
And I'm going to show all three of these.

00:31:41.560 --> 00:31:44.310
In ports debug, look at it on your own.

00:31:44.970 --> 00:31:50.970
So with Sampler,
Sampler is a statistical profiler,

00:31:50.970 --> 00:31:52.900
technically.

00:31:52.900 --> 00:31:56.900
And what that means is
that every 10 milliseconds,

00:31:56.900 --> 00:31:59.940
5 milliseconds, 20 milliseconds,
Sampler stops your program and says,

00:31:59.970 --> 00:32:04.120
"Hey, what's going on?" And it goes
and it gets a backtrace from

00:32:04.120 --> 00:32:05.760
every thread that's running.

00:32:06.140 --> 00:32:09.010
and looks to see what work is going on.

00:32:09.020 --> 00:32:10.320
So it gathers the backtrace.

00:32:10.450 --> 00:32:12.170
And then it lets the application
run for a little while

00:32:12.190 --> 00:32:13.280
longer and keeps doing that.

00:32:13.370 --> 00:32:16.400
And at the end of the sampling,
it gathers all those backtraces together

00:32:16.500 --> 00:32:19.890
and smashes them together into a tree
so that you understand the range of

00:32:19.890 --> 00:32:22.120
ways that your application is behaving.

00:32:23.200 --> 00:32:25.020
and then it presents in a graphical way.

00:32:25.100 --> 00:32:27.670
Now, there's a couple of things you
need to remember about Sampler.

00:32:27.770 --> 00:32:29.620
Because it's statistical,
because it's only stopping

00:32:29.620 --> 00:32:33.080
the program at times,
it doesn't know what happened in between.

00:32:33.120 --> 00:32:35.990
And so that means that it may
not catch all the functions,

00:32:36.360 --> 00:32:40.020
though any function should appear in the
samples in proportion to the amount of

00:32:40.130 --> 00:32:42.460
time that it's actually spending running.

00:32:44.530 --> 00:32:48.220
Now, if sampling every 10 milliseconds
isn't good enough for you,

00:32:48.440 --> 00:32:50.640
that you need finer resolution,
then you should try using

00:32:50.640 --> 00:32:53.400
the Performance Tools chart,
which you'll see after this.

00:32:53.520 --> 00:32:57.000
And if you need to know
about every single call,

00:32:57.000 --> 00:33:01.160
then you might want to
consider actually using Gprof,

00:33:01.490 --> 00:33:05.500
which is a standard Unix profiler,
which requires you to

00:33:05.500 --> 00:33:05.580
actually recompile your code.

00:33:05.580 --> 00:33:05.580
So, let's take a look at Sampler.

00:33:05.580 --> 00:33:05.580
Could we switch to the
demo machine again?

00:33:09.890 --> 00:33:13.720
Okay, so we have Sampler up.

00:33:13.770 --> 00:33:16.000
Up in the upper left-hand
corner now on the new version,

00:33:16.000 --> 00:33:18.800
this is a new UI for this release.

00:33:18.800 --> 00:33:22.040
And up in the upper left-hand corner you
get the type of sampling you're doing.

00:33:22.040 --> 00:33:24.690
You can sample either based on time
or you can get a back trace every

00:33:24.690 --> 00:33:27.500
time Malik's called or you can
look for specific function calls.

00:33:27.500 --> 00:33:29.860
We're just going to do time samples here.

00:33:29.960 --> 00:33:33.410
And what we'll do is we'll
launch Sketch in this.

00:33:37.130 --> 00:33:40.040
We're going to look at that copy
because copy seemed like it was going

00:33:40.040 --> 00:33:42.350
a little slow and I don't like that.

00:33:42.370 --> 00:33:45.510
So we open up the factory again.

00:33:45.760 --> 00:33:50.200
Let's do what we did before.

00:33:50.200 --> 00:33:52.830
First of all, we need to start sampling.

00:33:52.880 --> 00:33:55.730
If you remember how Sampler used to be,
you actually had to switch over to the

00:33:55.800 --> 00:33:58.600
Sampler window and press the button
and go back to your application.

00:33:58.600 --> 00:34:01.510
That was annoying because you often
would get lots of garbage because

00:34:01.510 --> 00:34:04.400
of having to raise the window,
data that you didn't care about.

00:34:04.490 --> 00:34:07.030
Sampler now has a hotkey.

00:34:07.110 --> 00:34:12.030
Christie can actually hit
Command-Option-Control-R to

00:34:12.030 --> 00:34:12.030
start and stop sampling.

00:34:15.300 --> 00:34:16.550
Thank you, thank you.

00:34:16.620 --> 00:34:17.700
We appreciate it.

00:34:17.740 --> 00:34:22.330
And she can do the copy and paste.

00:34:22.330 --> 00:34:22.330
And again.

00:34:25.310 --> 00:34:26.200
and Kristi Krohn.

00:34:26.360 --> 00:34:28.860
And Kristi can stop.

00:34:28.860 --> 00:34:32.650
Now we can go over to Sampler and we can
try to take a look at what's going on.

00:34:32.710 --> 00:34:34.950
Now this is the way that you
used to look at Sampler as well,

00:34:34.950 --> 00:34:35.710
with a browser.

00:34:35.720 --> 00:34:38.460
And the browser has some good
points and some bad points.

00:34:38.530 --> 00:34:40.690
However, there were a lot of people at
Apple who actually would write their

00:34:40.690 --> 00:34:44.380
own tools to sort of parse this data.

00:34:44.380 --> 00:34:45.660
Because they like to display
it in an outline view.

00:34:45.660 --> 00:34:48.230
And so Kristi actually was
very nice enough to actually

00:34:48.230 --> 00:34:51.540
put in an outline view,
so make sure to thank her.

00:34:51.540 --> 00:34:53.640
And so you can actually
look at the outline,

00:34:53.640 --> 00:34:57.080
an outline view and actually turn
down triangles to see your call tree.

00:34:57.080 --> 00:34:59.720
So for example,
we can see here that in every one

00:34:59.720 --> 00:35:02.660
of the samples we were in main,
main always called

00:35:02.660 --> 00:35:04.760
NS application main and so on.

00:35:04.760 --> 00:35:07.320
And we can sort of step down in there,
snooping around,

00:35:07.330 --> 00:35:10.370
and we can find where we're
calling into the menu code,

00:35:10.420 --> 00:35:12.300
which is right about here.

00:35:13.820 --> 00:35:17.390
Now, actually one of the things that
you saw was that the counts were

00:35:17.460 --> 00:35:19.460
originally in terms of the samples,
how many times the

00:35:19.470 --> 00:35:20.320
program had been stopped.

00:35:20.380 --> 00:35:22.520
And Christie actually just
switched this so it was actually

00:35:22.520 --> 00:35:24.440
showing it in terms of time,
which tends to be a better

00:35:24.440 --> 00:35:27.650
way to actually understand it,
even though remember that's statistical

00:35:27.730 --> 00:35:32.640
and so you can't say that took,
you know, that took 0.01 seconds.

00:35:32.640 --> 00:35:36.290
And what we find is in that time
that we were doing the sampling,

00:35:36.290 --> 00:35:39.840
we spent about 2.44 seconds in copy.

00:35:40.640 --> 00:35:42.360
Okay, that seems a little odd.

00:35:42.450 --> 00:35:44.810
And we can actually turn down
the triangle and see where

00:35:44.810 --> 00:35:46.100
the time was spent in copying.

00:35:46.100 --> 00:35:49.750
It turns out that we called four
routines there that took all the time.

00:35:51.300 --> 00:35:52.200
Gee, that's weird.

00:35:52.350 --> 00:35:54.500
Well,
luckily we still have that way of linking

00:35:54.500 --> 00:35:57.200
to the source code because I can't
understand it from this point of view.

00:35:57.310 --> 00:36:01.700
And so, Christy can double click on
Copy there and we get our source code.

00:36:01.820 --> 00:36:05.130
And we find out that what's happening
is that when we do that copy,

00:36:05.130 --> 00:36:08.870
we create a PDF file, well, PDF clipping,
we create a TIFF clipping,

00:36:09.050 --> 00:36:11.910
and we create the Sketch internal
version of clipping.

00:36:11.910 --> 00:36:12.510
Okay?

00:36:12.750 --> 00:36:17.000
This is because Cocoa has this
nice feature where you can say,

00:36:17.000 --> 00:36:19.100
"Hey, I can give you a clipping
in any of these formats."

00:36:19.440 --> 00:36:21.900
Okay, that's very good because then
the application that you're

00:36:21.900 --> 00:36:24.540
pasting it into can say,
"I only work in PDF, I need a TIFF,

00:36:24.540 --> 00:36:26.860
I need a whatever," and it works.

00:36:26.930 --> 00:36:29.260
But when we're doing
thousands of objects,

00:36:29.270 --> 00:36:31.940
doing all three tends
to be a little wasteful.

00:36:32.170 --> 00:36:35.410
and so a better way of doing this
would be to use another feature of

00:36:35.640 --> 00:36:39.900
App Kit which is to basically say,
"Here are the things I can produce,

00:36:39.900 --> 00:36:43.100
but I'm not going to produce
until you ask for them."

00:36:43.280 --> 00:36:46.150
And so we could change this
code so that we only said,

00:36:46.350 --> 00:36:49.290
"These are the types of clippings we
create." And then only when somebody

00:36:49.290 --> 00:36:52.600
did the paste would we actually
create the clipping for that.

00:36:53.010 --> 00:36:54.740
And so that would get rid
of this performance problem.

00:36:54.740 --> 00:36:58.490
We'd make copy a lot faster at the
expense of making paste a little slower.

00:36:58.500 --> 00:37:04.090
Okay,
could we go back to the slides please?

00:37:10.210 --> 00:37:13.700
Now, the performance tools, as I've said,
are very good for exploring your data.

00:37:13.790 --> 00:37:17.590
They're good for looking around and
trying to figure out what's going on.

00:37:17.700 --> 00:37:19.940
But that's not always
the best way to work.

00:37:20.150 --> 00:37:22.830
Because when you found a
particular performance problem,

00:37:22.830 --> 00:37:25.820
such as the Safari people found,
that they really cared about page times,

00:37:25.820 --> 00:37:27.730
about the page load
times and nothing else,

00:37:27.730 --> 00:37:30.150
having to run Sampler every
time to gather the amount

00:37:30.150 --> 00:37:31.630
of time would be wasteful.

00:37:31.630 --> 00:37:34.390
And so, if you know what you're
going to be measuring,

00:37:34.450 --> 00:37:37.050
try instrumenting your code,
putting in print statements to

00:37:37.110 --> 00:37:40.160
learn how much time was spent or
automatically logging that time.

00:37:40.160 --> 00:37:42.500
And this is really good because it
means that you can automatically

00:37:42.500 --> 00:37:45.170
gather statistics so that you
can check for regressions.

00:37:45.170 --> 00:37:49.300
And it means that you're always watching
exactly what you want to be watching.

00:37:49.400 --> 00:37:50.580
And there's many ways
that you can do this.

00:37:50.580 --> 00:37:54.360
There's a number of APIs in
Mac OS X for looking at time.

00:37:54.500 --> 00:37:56.450
Some of the ones that are
interesting are uptime,

00:37:56.450 --> 00:37:58.930
which tends to have
nanosecond resolution.

00:37:58.960 --> 00:38:03.220
Or you can use get time of day if
you prefer BSD or the NSDate class

00:38:03.220 --> 00:38:05.390
if you're in Objective-C.

00:38:06.000 --> 00:38:09.410
When I actually did this on copy,
actually it's very strange because

00:38:09.410 --> 00:38:11.880
I didn't expect to find anything,
but I thought, let's do this.

00:38:11.900 --> 00:38:15.880
I actually found that I actually
started graphing out the amount of

00:38:16.020 --> 00:38:20.520
time spent for each of the clippings
and for this task at the beginning,

00:38:20.520 --> 00:38:23.180
which was called ordering the list,
which was sorting the things that

00:38:23.350 --> 00:38:25.000
you clipped from back to front.

00:38:25.040 --> 00:38:30.620
Okay, so first one, you know,
the PDF was the longest, second one,

00:38:30.620 --> 00:38:32.830
sketch was the longest,
and then suddenly when I got

00:38:32.830 --> 00:38:37.700
to about 4,000 objects,
suddenly the sort would take forever.

00:38:38.200 --> 00:38:40.350
And unless I actually measured
this and unless I tried it on

00:38:40.350 --> 00:38:43.660
a bunch of different sizes,
I never would have seen this.

00:38:44.130 --> 00:38:47.020
And so this is one of the
advantages of instrumenting,

00:38:47.020 --> 00:38:49.950
is it makes it very easy for
you to check to see when things

00:38:49.950 --> 00:38:51.810
go wrong and why they are.

00:38:51.950 --> 00:38:55.490
And if you actually look at
the code what you find is that

00:38:55.670 --> 00:39:00.580
Sketch had--Sketch was basically made
for dealing with tens of objects.

00:39:00.580 --> 00:39:03.400
And the way that it would do the
ordered list is it would use the

00:39:03.400 --> 00:39:06.720
NSArray sort method for those
of you who are Objective-C fans.

00:39:06.720 --> 00:39:10.570
And so it would basically say, "Hey,
go sort this." And there--and you

00:39:10.570 --> 00:39:13.440
had to provide a comparison routine
to be able to say this is how you

00:39:13.520 --> 00:39:16.220
compare two of these rectangles.

00:39:16.240 --> 00:39:18.680
And the way the rectangles would
be compared is it would say,

00:39:18.680 --> 00:39:21.740
"Hey, what's the index of each of
these in the big array that lists

00:39:21.740 --> 00:39:26.260
everything that's being drawn?" Okay,
is this the first one, the fifth one,

00:39:26.260 --> 00:39:27.360
the tenth one?

00:39:27.360 --> 00:39:28.100
That's pretty efficient.

00:39:29.610 --> 00:39:33.820
Except that that code would take your
NSArray and it would make a copy over

00:39:33.820 --> 00:39:36.780
here in a nice static array so that
it could do the search really easily.

00:39:36.780 --> 00:39:38.950
So it would have to malloc huge
amounts of memory and then it

00:39:38.950 --> 00:39:39.820
would have to do a linear search.

00:39:39.820 --> 00:39:42.580
So that meant that the comparison
was an order n operation,

00:39:42.710 --> 00:39:45.500
which meant that sort ended up
being like an order n squared

00:39:45.500 --> 00:39:47.880
log n or something like that.

00:39:47.990 --> 00:39:51.180
And so you end up with this funky
thing where sort looked really fine

00:39:51.180 --> 00:39:54.180
until you got about 4,000 elements
and then suddenly it was huge.

00:39:54.290 --> 00:39:56.690
So this is why you want to instrument.

00:39:58.820 --> 00:40:02.650
Now, another thing that we've now looked
at a couple of ways that you can go

00:40:02.650 --> 00:40:04.650
looking for things that are suspicious.

00:40:04.650 --> 00:40:08.490
Now, one of the interest--one of the
interesting things about big objectives,

00:40:08.490 --> 00:40:11.680
object-oriented systems is that
you tend to have a lot of layers

00:40:11.680 --> 00:40:14.890
because you've got this thing called
instrument or information hiding,

00:40:14.890 --> 00:40:15.640
which is great.

00:40:15.680 --> 00:40:18.070
And so you don't really know how
people in the line that thinks below,

00:40:18.070 --> 00:40:20.320
but you sort of hope they're
doing the right thing.

00:40:20.420 --> 00:40:23.800
But the problem is that often
they make assumptions you don't.

00:40:23.800 --> 00:40:26.000
You're using the API in
ways that they don't expect.

00:40:26.020 --> 00:40:28.000
And so,
some call that you might be making into

00:40:28.000 --> 00:40:30.920
some layer might go all the way down
to the bottom of the system and back

00:40:31.000 --> 00:40:33.600
up and take huge amounts of effort.

00:40:33.600 --> 00:40:37.490
Or you may have something that you think
is inexpensive like that sort that ends

00:40:37.650 --> 00:40:40.420
up being a very expensive operation.

00:40:40.590 --> 00:40:43.410
So, Christie actually came to Apple and
suggested that one of the ways that

00:40:43.420 --> 00:40:46.320
we should be looking at systems
is to be looking for this kind of

00:40:46.320 --> 00:40:50.740
repetition because object oriented
systems tend to suffer from this.

00:40:50.740 --> 00:40:53.330
And one of the ways that you can do
this is you can look for mallocs because

00:40:53.330 --> 00:40:57.080
mallocs tend to be time consuming
and memory intensive operations and

00:40:57.350 --> 00:40:59.360
everybody uses them all over the place.

00:40:59.420 --> 00:41:02.020
And so if we can poke around and
see where mallocs are being called,

00:41:02.080 --> 00:41:04.580
we might be able to see where
we're doing repetitive work we

00:41:04.600 --> 00:41:06.260
really don't intend to be doing.

00:41:06.260 --> 00:41:09.290
So,
let's switch over to the demo machine.

00:41:12.910 --> 00:41:17.020
Okay, so Christy will now switch to
watching memory allocations and to

00:41:17.080 --> 00:41:19.960
using what's called the trace view,
which is a way to actually look at

00:41:20.030 --> 00:41:22.530
these mallocs in a very interesting way.

00:41:22.680 --> 00:41:24.940
And we can go back over to
Sketch and we're going to do a

00:41:24.950 --> 00:41:27.600
very small example because when
you're doing sampling by time,

00:41:27.780 --> 00:41:30.090
you want to have lots of stuff
so that you hopefully find all

00:41:30.090 --> 00:41:31.480
the functions you're looking at.

00:41:31.840 --> 00:41:35.330
Here we're looking at every single call,
so you want to make your

00:41:35.560 --> 00:41:37.000
example relatively small.

00:41:37.000 --> 00:41:40.480
And we're going to look at what
the mallocs are being--what mallocs

00:41:40.480 --> 00:41:40.480
are being done when we do our copy.

00:41:41.000 --> 00:41:43.900
And so,
Christie has the two rectangles there.

00:41:44.010 --> 00:41:47.100
She'll hit the hot key
to start recording,

00:41:47.200 --> 00:41:52.290
do the copy, stop recording,
and we find out to do that

00:41:52.290 --> 00:41:56.190
we required 6,000 mallocs.

00:41:58.850 --> 00:42:00.130
You know,
and this probably isn't that unusual,

00:42:00.140 --> 00:42:02.940
but it's a big system and
there's a lot of things going on.

00:42:03.000 --> 00:42:05.670
And in fact, if we poke around,
the idea is that this graph

00:42:05.800 --> 00:42:09.600
actually shows you the height of
the call stack going to each malloc.

00:42:09.640 --> 00:42:13.450
So how many functions you had to get
to before you got to malloc from main.

00:42:13.670 --> 00:42:18.470
and if we zoom in on one of those,
we'll actually find that you start

00:42:18.470 --> 00:42:20.380
seeing these repetitive patterns.

00:42:20.470 --> 00:42:24.070
See how it's kind of like a EKG,
you know, so blip, blip, blip, blip,

00:42:24.110 --> 00:42:27.190
blip, at very regular patterns,
which implies that there's actually

00:42:27.190 --> 00:42:29.930
some very regular operation going
on there if we're seeing that

00:42:29.930 --> 00:42:31.360
signature over and over again.

00:42:31.360 --> 00:42:35.310
And in fact,
if we go look we find out that we're down

00:42:35.310 --> 00:42:37.980
in some code that's parsing an XML file.

00:42:38.030 --> 00:42:41.470
And it turns out that when we do
a clipping and it's a PDF file,

00:42:41.610 --> 00:42:44.930
the PDF file has to get information
on the printer because the printer

00:42:45.230 --> 00:42:47.770
is used for the size of the page.

00:42:48.290 --> 00:42:51.250
and the printer ends up going through the
CUPS daemon and the CUPS daemon ends up

00:42:51.250 --> 00:42:54.480
giving us back XML and we have to parse
the XML and so we do lots of mallocs.

00:42:54.480 --> 00:42:56.740
We never would have known this and
it might not show up in Sampler,

00:42:56.740 --> 00:42:59.430
but this is a way to understand
sort of what the costs are.

00:42:59.530 --> 00:43:01.220
And some of these are cases
where you might be able to say,

00:43:01.220 --> 00:43:03.400
"Oh gee,
I shouldn't do that." And a lot of those

00:43:03.440 --> 00:43:06.610
are cases where Apple needs to say,
"Oh gee, we ought to fix that and we

00:43:06.610 --> 00:43:10.050
can actually fix it for you so
you never run into it." Okay,

00:43:10.050 --> 00:43:16.480
can we switch back to the slides please?

00:43:18.990 --> 00:43:22.280
Okay, the final demo I'll do
today is Spin Control,

00:43:22.280 --> 00:43:24.350
which is a new application.

00:43:24.450 --> 00:43:28.370
So the problem here is that
in general when you have,

00:43:28.370 --> 00:43:32.360
when your application takes
too long to do something,

00:43:32.360 --> 00:43:34.810
when it keeps,
when messages coming from the

00:43:34.810 --> 00:43:38.870
Windows Server don't get responded
to within about five seconds usually,

00:43:38.870 --> 00:43:41.420
the Windows Server puts
up the spinning cursor.

00:43:42.350 --> 00:43:44.980
So usually this implies that your
application is behaving badly.

00:43:45.000 --> 00:43:49.700
It's not responding quickly
enough for the Windows Server.

00:43:49.700 --> 00:43:50.800
And so these tend to be bugs.

00:43:50.800 --> 00:43:52.360
You know, you're doing too much work.

00:43:52.390 --> 00:43:55.010
The problem is you can't
sample them because,

00:43:55.060 --> 00:43:57.210
first of all,
they're sort of difficult to

00:43:57.210 --> 00:43:59.520
catch because they tend to
sort of appear and disappear.

00:43:59.630 --> 00:44:02.740
And even if you could get to sampler,
usually your machine's doing other things

00:44:02.740 --> 00:44:04.360
because there's a spinning cursor up.

00:44:04.440 --> 00:44:07.300
And so there's not really a chance
to actually go and attach to it.

00:44:07.310 --> 00:44:09.790
And so the idea is that
SpinControl automatically

00:44:09.790 --> 00:44:11.720
samples your application for you.

00:44:11.820 --> 00:44:13.430
So let's switch back to the demo machine.

00:44:19.480 --> 00:44:22.070
So Christie's Launch Spin Control,
which is in Developer Applications,

00:44:22.080 --> 00:44:24.400
and you have to go find that yourself,
sadly.

00:44:24.400 --> 00:44:29.400
And it has--it basically keeps a list
of every time that it detects a spin.

00:44:29.400 --> 00:44:36.400
And you can set it for only one
application or all applications.

00:44:36.490 --> 00:44:40.580
And we can do that copy that we were
doing that was causing us all that grief.

00:44:40.580 --> 00:44:40.580
So we can select all again.

00:44:40.580 --> 00:44:40.580
We can copy.

00:44:41.520 --> 00:44:43.400
And we can paste.

00:44:43.480 --> 00:44:45.980
We can do that again.

00:44:46.020 --> 00:44:48.660
And sometimes you actually need to click
on the window so that there's a window

00:44:48.660 --> 00:44:50.070
event that you might need to notice.

00:44:50.210 --> 00:44:52.000
That's usually when the
spinning cursor comes up.

00:44:52.100 --> 00:44:53.850
And we can see here,
the spinning cursor just came up,

00:44:53.950 --> 00:44:57.100
because we copied one of those
things that takes 800 seconds.

00:44:57.210 --> 00:44:57.950
Hopefully not.

00:44:57.950 --> 00:45:00.100
I think I need to get off the stage soon.

00:45:00.100 --> 00:45:02.030
And it automatically sampled it.

00:45:02.030 --> 00:45:04.890
And now we could copy that and
paste it into email to send to a

00:45:04.910 --> 00:45:06.500
developer to say something's wrong.

00:45:06.570 --> 00:45:09.600
Or we can double click on it and
we get a sampler like Vue where

00:45:09.600 --> 00:45:11.410
we can actually look at the code.

00:45:11.520 --> 00:45:14.550
And in fact, we can go and see that
we're calling--oh boy,

00:45:14.550 --> 00:45:15.370
that's nice.

00:45:15.380 --> 00:45:18.060
We're in copy,
which turns out to be in NSArray,

00:45:18.060 --> 00:45:20.550
which ends up calling
CFArrayGetValuedIndex,

00:45:20.550 --> 00:45:22.060
just like I was explaining.

00:45:22.130 --> 00:45:22.930
So I wasn't lying.

00:45:24.910 --> 00:45:27.430
So, Spin Control gives you a
way to see the invisible.

00:45:27.450 --> 00:45:30.730
It lets you actually see the kinds of
things that you otherwise can't sample.

00:45:30.790 --> 00:45:31.800
So, this is a cool tool.

00:45:31.800 --> 00:45:34.800
Try running it on your system,
leaving it up, and seeing what you catch.

00:45:34.800 --> 00:45:36.790
Could we go back to the slides, please?

00:45:36.790 --> 00:45:40.790
And thank you very much, Christy.

00:45:50.080 --> 00:45:53.000
There's a number of other tools
that you need to check out yourself.

00:45:53.000 --> 00:45:54.950
We don't have time for everything, sadly.

00:45:54.950 --> 00:45:58.920
Hopefully you've seen these in
previous years if you've been here.

00:45:59.030 --> 00:46:02.140
If you haven't,
take a look at some of these tools.

00:46:02.140 --> 00:46:06.100
Take a look at the performance
book to find out how to use them.

00:46:06.100 --> 00:46:10.350
But they all will have--they're
all valuable and interesting ways.

00:46:10.380 --> 00:46:12.240
They might be able to help you
on certain types of problems,

00:46:12.240 --> 00:46:15.160
and you need to explore how to use
them and which sorts of problems

00:46:15.160 --> 00:46:16.960
are best found using any of these.

00:46:16.960 --> 00:46:20.040
And make sure to watch your applications.

00:46:20.040 --> 00:46:22.820
And with that,
I'd like to bring up Nathan Slingerland

00:46:22.940 --> 00:46:25.780
to talk about the Chud tools,
which is--allows you to look

00:46:25.780 --> 00:46:29.290
at code one level deeper than
what we've been looking at now.

00:46:31.200 --> 00:46:32.360
Good luck.

00:46:32.360 --> 00:46:32.950
Good luck.

00:46:32.950 --> 00:46:33.470
There we go.

00:46:33.470 --> 00:46:38.100
Okay, so as Robert said,
I'm Nathan Slingerland and I'm going to

00:46:38.210 --> 00:46:40.980
talk to you today about the CHUD tools,
or Computer Hardware

00:46:40.980 --> 00:46:42.820
Understanding Developer Tools.

00:46:42.820 --> 00:46:48.660
And these are tools written by the
Apple Architecture and Performance Group.

00:46:48.660 --> 00:46:52.340
They're a suite of tools that
give you low-level access

00:46:52.400 --> 00:46:54.640
to the performance monitors.

00:46:54.640 --> 00:46:59.200
So these are counters that are built
in to our hardware in the processors,

00:46:59.200 --> 00:47:02.240
memory controller,
operating system like that.

00:47:02.300 --> 00:47:05.270
And using these counters,
you can find problems in your

00:47:05.350 --> 00:47:07.010
code and improve your code.

00:47:07.020 --> 00:47:09.730
And of course,
CHUD tools are freely available

00:47:10.270 --> 00:47:12.200
with the Developer Tools CD.

00:47:12.200 --> 00:47:16.640
You can bring up Shark and
Xcode as you saw.

00:47:16.640 --> 00:47:18.650
And they're freely
available on the web too,

00:47:18.650 --> 00:47:20.380
so you can check there for updates.

00:47:20.400 --> 00:47:24.400
If you were here last year,
we introduced CHUD.

00:47:24.640 --> 00:47:29.170
We're happy to have 3.0 this year
with a lot of great improvements.

00:47:29.240 --> 00:47:34.520
Shark is an instruction-level profiler,
so if you've ever used Shikari

00:47:34.520 --> 00:47:38.720
from the older CHUD tools,
Shark is the successor to Shikari.

00:47:38.720 --> 00:47:41.590
Monster is a spreadsheet
for performance events,

00:47:41.590 --> 00:47:46.280
so you can look at these counter results
in either a spreadsheet or a chart form.

00:47:46.280 --> 00:47:50.530
And Saturn is a new tool for
visualizing function call behavior.

00:47:53.100 --> 00:47:56.970
And of course we have a set of other
lower level tools that you can use for

00:47:56.970 --> 00:48:01.690
tuning things like AlteVec code or very
CPU intensive code that you want to

00:48:01.740 --> 00:48:07.060
simulate using SIMG4 or soon SIMG5 that
will let you see exactly what's happening

00:48:07.060 --> 00:48:08.930
at the lowest levels on the processor.

00:48:10.120 --> 00:48:13.340
And of course we provide the Chud
Framework API so you can write your

00:48:13.340 --> 00:48:16.390
own tools or control the Chud tools.

00:48:16.420 --> 00:48:19.980
So the performance counters, as I said,
are in our processor and memory

00:48:19.980 --> 00:48:21.800
controller and operating system.

00:48:21.860 --> 00:48:25.390
And what they do is they count
interesting low-level performance events,

00:48:25.390 --> 00:48:28.600
so things like cache
misses on the processor,

00:48:28.620 --> 00:48:32.800
execution stall cycles,
page faults in the operating system.

00:48:32.870 --> 00:48:37.000
And Chud lets you control
these and view the result.

00:48:37.110 --> 00:48:39.180
So the first tool that we're
going to talk about that

00:48:39.180 --> 00:48:41.590
uses these counters is Shark.

00:48:41.620 --> 00:48:46.820
Shark is a system-wide profiling tool and
using Shark you can profile a process,

00:48:46.820 --> 00:48:49.700
a particular thread or the entire system.

00:48:49.700 --> 00:48:54.350
And in the most general usage of
Shark you can create a time profile.

00:48:54.390 --> 00:48:59.000
So this lets you visualize performance
hotspots either in your code or not.

00:48:59.000 --> 00:49:01.260
You can see if your hotspot,
your bottleneck,

00:49:01.260 --> 00:49:03.320
is actually in your code using this.

00:49:03.320 --> 00:49:06.870
You can also use it to find
event profiles so you can

00:49:06.870 --> 00:49:10.330
relate performance events,
things like cache misses to

00:49:10.330 --> 00:49:15.100
your code to find out where
cache misses are coming from.

00:49:15.100 --> 00:49:18.640
It captures everything, drivers,
kernel applications.

00:49:18.690 --> 00:49:22.300
What this means is if you're a driver
writer or a kernel extension writer,

00:49:22.300 --> 00:49:25.160
you can use Shark to see the call
stacks and find out where the time

00:49:25.260 --> 00:49:27.150
is being spent in your driver.

00:49:27.220 --> 00:49:31.900
And we're very low overhead because
we're handling everything in the kernel.

00:49:31.900 --> 00:49:32.490
In addition, once you have your
sampling session taken,

00:49:32.490 --> 00:49:33.340
you can use Shark to find out where
the time is being spent in your driver.

00:49:33.340 --> 00:49:34.900
And we're very low overhead because
we're handling everything in the kernel.

00:49:34.900 --> 00:49:34.900
In addition, once you have your
sampling session taken,

00:49:34.900 --> 00:49:35.900
you can use Shark to find out where
the time is being spent in your driver.

00:49:35.900 --> 00:49:36.900
And we're very low overhead because
we're handling everything in the kernel.

00:49:36.900 --> 00:49:37.890
And we're very low overhead because
we're handling everything in the kernel.

00:49:37.900 --> 00:49:38.900
And we're very low overhead because
we're handling everything in the kernel.

00:49:38.900 --> 00:49:39.050
And we're very low overhead because
we're handling everything in the kernel.

00:49:39.050 --> 00:49:39.900
And we're very low overhead because
we're handling everything in the kernel.

00:49:39.900 --> 00:49:40.900
We provide automated analysis.

00:49:40.900 --> 00:49:41.110
We attempt to annotate your source
code and the disassembly of that

00:49:41.610 --> 00:49:45.680
source code to point out common
problems and other things that

00:49:45.690 --> 00:49:48.240
you can do to optimize your code.

00:49:48.450 --> 00:49:51.600
There's a static analysis
feature to find suboptimal code.

00:49:51.600 --> 00:49:53.960
So if you were in the
earlier Chud session,

00:49:54.040 --> 00:49:58.680
you know that there are some
instructions that are on the G5 that

00:49:58.680 --> 00:50:01.280
you need to look for and watch out
for and this will help you find them.

00:50:01.280 --> 00:50:04.750
And we also provide
optimization tips as it says.

00:50:04.910 --> 00:50:06.380
So we have a scriptable
command line version.

00:50:06.470 --> 00:50:08.900
You can tell that in and sample things.

00:50:08.920 --> 00:50:12.620
And of course you can save and review
sessions and pass those around.

00:50:12.750 --> 00:50:17.030
So without further ado,
the best way to see this,

00:50:17.030 --> 00:50:20.450
how to use the Chud tools
and Shark is to have a demo.

00:50:20.600 --> 00:50:23.880
So for that, we're going to use the
Noble Ape simulation.

00:50:23.880 --> 00:50:28.100
This is an open source program
written by Tom Barbele.

00:50:28.100 --> 00:50:30.280
And to help me demo,
I'm going to bring up Sanjay Patel,

00:50:30.280 --> 00:50:33.130
also the architecture
and performance group.

00:50:36.800 --> 00:50:42.430
Okay, so first thing we'll do
is we'll bring up Noble 8.

00:50:46.000 --> 00:50:47.210
Okay, so here we are.

00:50:47.330 --> 00:50:49.680
We're simulating thinking
apes on an island,

00:50:49.680 --> 00:50:50.960
a tropical island.

00:50:50.960 --> 00:50:53.830
And this map window is showing
us an overview of the island

00:50:53.840 --> 00:50:56.280
and the little red dots,
each red dot is an ape.

00:50:56.310 --> 00:50:59.490
And we can look at,
we can focus in on one ape at a time.

00:50:59.590 --> 00:51:02.670
That's the ape with the red
square around him there.

00:51:02.680 --> 00:51:06.330
And the brain window to the right
here shows what his brain is,

00:51:06.330 --> 00:51:10.270
how the changes are occurring in his
brain when he's walking around the

00:51:10.480 --> 00:51:12.840
island and thinking about things.

00:51:12.840 --> 00:51:15.920
So, you know,
our every good performance tool is here.

00:51:16.020 --> 00:51:37.180
The first thing we'll do is we'll
use Shark to see what's happening in

00:51:37.250 --> 00:51:44.620
the system while we run Noble Ape.

00:51:44.870 --> 00:51:46.910
So this is the main Shark window.

00:51:46.920 --> 00:51:48.690
By default we go to the time profile.

00:51:48.750 --> 00:51:52.640
There are other built-in profiles,
of course, too, that take advantage of

00:51:52.650 --> 00:51:53.800
the performance counters.

00:51:53.800 --> 00:51:56.200
But for now we'll just
use the time profile.

00:51:56.230 --> 00:51:57.910
And we also have a global hotkey.

00:51:57.910 --> 00:52:00.430
You can put Shark,
it doesn't have to be in the

00:52:00.430 --> 00:52:02.260
foreground to use it either.

00:52:02.450 --> 00:52:08.410
So let's sample five or so
seconds and see what's happening.

00:52:16.220 --> 00:52:19.390
So here's the profile listing
the important functions from

00:52:19.610 --> 00:52:21.100
most sampled to least sampled.

00:52:21.100 --> 00:52:26.680
And in the lower left here we
have the process pop-up and this

00:52:26.680 --> 00:52:31.100
lists all the things that we
sampled during this time period.

00:52:31.190 --> 00:52:33.080
So at the top is Noble Ape
and we kind of expect that.

00:52:33.120 --> 00:52:39.100
We know that our simulation is CPU bound,
but it's only 50% of the time.

00:52:39.100 --> 00:52:42.100
And you kind of wonder, well, okay,
why is that?

00:52:42.100 --> 00:52:46.100
Well, if we go to the thread pop-up,
we can see that, in fact,

00:52:46.110 --> 00:52:48.100
this application is single-threaded.

00:52:48.100 --> 00:52:51.330
And because it's single-threaded,
we're not using half of

00:52:51.330 --> 00:52:53.040
our dual processor machine.

00:52:53.100 --> 00:52:56.090
So our first step in optimization was,
hey, let's thread this thing.

00:52:56.180 --> 00:53:02.100
We used the Carbon MP API and
threaded Noble Ape.

00:53:02.100 --> 00:53:04.800
So let's see what the
performance improvement was like.

00:53:06.120 --> 00:53:09.810
Remember we had 1200 thoughts
per second before and we're

00:53:09.810 --> 00:53:13.050
getting almost double that,
so that's pretty good.

00:53:13.140 --> 00:53:18.470
But let's profile again and see
what we can do with this code.

00:53:25.100 --> 00:53:27.780
So now we can see that we're taking
up a much greater portion of the time

00:53:27.780 --> 00:53:29.620
on the machine and that's reassuring.

00:53:29.780 --> 00:53:32.000
We want to do that for our simulation.

00:53:32.000 --> 00:53:35.990
And we can see that we've
spawned these threads now.

00:53:36.030 --> 00:53:40.590
We've got the main thread at 8%
and then two other threads that are

00:53:40.680 --> 00:53:43.000
processing the apes in parallel,
40% apiece.

00:53:43.010 --> 00:53:46.790
So the next step we can do is we
can double click on any entry in

00:53:46.790 --> 00:53:50.290
this profile view and it'll show
us our source code colored with

00:53:50.290 --> 00:53:51.990
where the samples were taken.

00:53:52.000 --> 00:53:57.380
So what this tells you is what lines of
source code the most time was spent on.

00:53:57.740 --> 00:54:01.110
So if we look here,
the scroll bar also gives us a way

00:54:01.120 --> 00:54:03.360
to jump quickly to the hotspot.

00:54:03.520 --> 00:54:06.630
So the hotspot is literally
just this function,

00:54:06.790 --> 00:54:11.450
just this piece of the function,
this for loop, inside of the Cycle Troop

00:54:11.450 --> 00:54:13.360
Brain Scaler function.

00:54:13.490 --> 00:54:19.800
So it turns out that this is about
94% of the time if we highlight this.

00:54:20.100 --> 00:54:20.800
Right?

00:54:20.940 --> 00:54:26.200
So if we look,
Shark gives us a hint on how to fix

00:54:26.320 --> 00:54:28.840
our code or how to make it better.

00:54:28.840 --> 00:54:30.980
We click on this little
exclamation point.

00:54:30.980 --> 00:54:36.470
It says, OK,
this loop contains 8-bit integer.

00:54:36.530 --> 00:54:37.810
It's taking a lot of time.

00:54:37.820 --> 00:54:39.410
You're spending a lot
of time in this loop.

00:54:39.550 --> 00:54:42.940
Maybe it would be worth the
effort to vectorize this loop.

00:54:43.050 --> 00:54:44.280
So that was our next step.

00:54:44.280 --> 00:54:47.740
We went and we vectorized.

00:54:47.740 --> 00:54:49.850
So let's go back.

00:54:53.800 --> 00:54:56.240
Remember 2400?

00:54:56.240 --> 00:54:59.020
Let's turn on vector.

00:54:59.020 --> 00:55:01.330
Alright, so 10,000.

00:55:01.330 --> 00:55:01.940
That's nice.

00:55:01.940 --> 00:55:04.240
But we're still not done yet.

00:55:04.240 --> 00:55:09.280
Let's look again with Shark and
see what else we could do.

00:55:14.800 --> 00:55:17.640
So we see the vector
function showing up there.

00:55:17.640 --> 00:55:20.270
We'll double click.

00:55:20.310 --> 00:55:21.390
And we're in the vector code.

00:55:21.650 --> 00:55:22.180
That's good.

00:55:22.180 --> 00:55:26.120
If you're a Shikari user,
you probably know that we

00:55:26.120 --> 00:55:29.250
had this disassembly view
that was similar to this.

00:55:29.250 --> 00:55:30.880
And you can still get this back.

00:55:30.880 --> 00:55:36.940
This disassembly view is actually set
right now to show G5 dispatch groups.

00:55:36.970 --> 00:55:41.200
And there's more detail on
that in the full Chud session.

00:55:41.200 --> 00:55:43.730
We'll go back to the source code for now.

00:55:43.840 --> 00:55:46.660
And if you look closely
at the scroll bar,

00:55:46.810 --> 00:55:48.890
we can see that actually,
even though we're spending a lot of time

00:55:48.900 --> 00:55:52.280
in the vector code that we optimized,
now we're spending a relatively

00:55:52.280 --> 00:55:55.860
bigger portion of the time inside
of the scalar code that we didn't

00:55:55.860 --> 00:56:00.450
optimize before in the first step,
that we didn't vectorize before.

00:56:00.670 --> 00:56:04.320
So our next step is, hey,
maybe we should vectorize the rest of

00:56:04.320 --> 00:56:09.820
this since all these loops are fairly
similar and that's what Shark says to do.

00:56:09.940 --> 00:56:14.160
So let's go back to Noble Ape.

00:56:15.250 --> 00:56:20.100
So about 10,000, 9,500,
turn on vector optimized,

00:56:20.100 --> 00:56:21.360
and we're almost 15,000.

00:56:21.430 --> 00:56:25.820
So this is around 14 or so
times the original performance.

00:56:25.830 --> 00:56:28.940
And what we're able to do is
take advantage of this massive

00:56:29.000 --> 00:56:35.200
bandwidth we have available on
the Power Mac G5 by using AltaVec.

00:56:35.200 --> 00:56:38.710
OK, so could we have the slides again,
please?

00:56:38.720 --> 00:56:43.800
Thank you, Sanjay.

00:56:47.700 --> 00:56:49.500
Okay, we did that.

00:56:49.610 --> 00:56:50.420
Oh, wait.

00:56:50.600 --> 00:56:51.300
Yeah.

00:56:51.300 --> 00:56:55.530
So, just to summarize,
we compared this against

00:56:55.530 --> 00:56:57.330
the Power Mac G4.

00:56:57.330 --> 00:57:03.260
So, this is the scalar code running
on the current Power Mac G4 top of

00:57:03.260 --> 00:57:06.740
the line against the Power Mac G5.

00:57:06.740 --> 00:57:10.020
And you can see that actually
they're not all that far apart.

00:57:10.020 --> 00:57:13.330
In the scalar code,
we actually have a longer pipe on the G5,

00:57:13.330 --> 00:57:14.600
a longer pipeline.

00:57:15.220 --> 00:57:19.150
And so, we're not entirely scaling
with this higher frequency.

00:57:19.150 --> 00:57:24.120
We're entirely bound
in this CPU for this.

00:57:24.120 --> 00:57:27.660
So, when we added the threading,
we can see that we get a bigger

00:57:27.660 --> 00:57:30.000
jump than what the G4 got,
right,

00:57:30.000 --> 00:57:31.960
going from scalar to scalar threaded.

00:57:31.960 --> 00:57:35.840
Then vector, an even bigger jump.

00:57:35.840 --> 00:57:39.380
And vector optimized,
an even bigger difference, right?

00:57:39.380 --> 00:57:41.900
And the reason is that
as we improve this code,

00:57:41.980 --> 00:57:44.960
we're more and more
constrained by the memory band.

00:57:45.020 --> 00:57:47.020
So, we have a lot more memory
bandwidth available on the system.

00:57:47.020 --> 00:57:49.020
While on the G5,
we're simply not as constrained, right?

00:57:49.020 --> 00:57:52.020
We have a lot more memory
bandwidth to play with here.

00:57:52.020 --> 00:57:55.020
So, by vectorizing your code, you can,
you know,

00:57:55.020 --> 00:57:59.020
if we had just thrown this on the G5,
we would see a very marginal improvement.

00:57:59.020 --> 00:58:02.620
But by putting the effort into vectorize,
we're able to take advantage

00:58:02.620 --> 00:58:05.900
of a lot more of the system,
a lot more of what it has to offer.

00:58:06.880 --> 00:58:11.540
So in addition to Shark,
we have some other tools.

00:58:11.550 --> 00:58:15.620
Monster allows you to directly configure
the performance monitor counters,

00:58:15.740 --> 00:58:20.020
collect data based on these timed
intervals or event counts or hotkey,

00:58:20.040 --> 00:58:23.050
and then look at this in
spreadsheet or chart form.

00:58:23.450 --> 00:58:25.250
It also has the ability
to compute metrics,

00:58:25.400 --> 00:58:28.600
so things like bandwidth
or cycles per instruction,

00:58:28.600 --> 00:58:30.890
and actually that's how we got
our bandwidth numbers for this

00:58:30.890 --> 00:58:32.550
when we were looking at it.

00:58:32.560 --> 00:58:37.130
This is a command line version
of Monster and you can also save

00:58:37.150 --> 00:58:39.010
and review sessions for that.

00:58:39.310 --> 00:58:41.900
Saturn is the last tool
we're going to talk about.

00:58:42.170 --> 00:58:44.320
Saturn is similar in some ways to Gprof.

00:58:44.400 --> 00:58:48.150
It gives you an exact profile
and allows you to visualize the

00:58:48.220 --> 00:58:50.340
call tree of an application.

00:58:50.370 --> 00:58:56.110
It uses GCC to instrument each function
in your application at entry and exit,

00:58:56.380 --> 00:58:58.900
cords the function call
history to a trace file,

00:58:58.900 --> 00:59:03.020
and then for each function it
can give you the call counts.

00:59:03.100 --> 00:59:06.020
It can also use the performance
monitors to tell you the counts for

00:59:06.020 --> 00:59:12.420
each function as well as the execution
times using a low level timer.

00:59:12.420 --> 00:59:14.170
So okay,
at this point I'd like to bring up

00:59:14.170 --> 00:59:15.740
Dave Payne again for session wrap up.

00:59:24.300 --> 01:03:00.700
[Transcript missing]